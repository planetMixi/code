{
    "schema":{
        "fields":[
            {
                "name":"index",
                "type":"integer"
            },
            {
                "name":"vuln_id",
                "type":"string"
            },
            {
                "name":"cwe_id",
                "type":"string"
            },
            {
                "name":"score",
                "type":"number"
            },
            {
                "name":"chain",
                "type":"string"
            },
            {
                "name":"dataset",
                "type":"string"
            },
            {
                "name":"summary",
                "type":"string"
            },
            {
                "name":"published_date",
                "type":"string"
            },
            {
                "name":"chain_len",
                "type":"integer"
            },
            {
                "name":"project",
                "type":"string"
            },
            {
                "name":"commit_href",
                "type":"string"
            },
            {
                "name":"commit_sha",
                "type":"string"
            },
            {
                "name":"patch",
                "type":"string"
            },
            {
                "name":"chain_ord",
                "type":"string"
            },
            {
                "name":"before_first_fix_commit",
                "type":"string"
            },
            {
                "name":"last_fix_commit",
                "type":"string"
            },
            {
                "name":"chain_ord_pos",
                "type":"number"
            },
            {
                "name":"commit_datetime",
                "type":"string"
            },
            {
                "name":"message",
                "type":"string"
            },
            {
                "name":"author",
                "type":"string"
            },
            {
                "name":"comments",
                "type":"string"
            },
            {
                "name":"stats",
                "type":"string"
            },
            {
                "name":"files",
                "type":"string"
            },
            {
                "name":"message_norm",
                "type":"string"
            },
            {
                "name":"language",
                "type":"string"
            },
            {
                "name":"entities",
                "type":"string"
            },
            {
                "name":"classification_level_1",
                "type":"string"
            },
            {
                "name":"classification_level_2",
                "type":"string"
            },
            {
                "name":"list_files",
                "type":"string"
            },
            {
                "name":"num_files",
                "type":"number"
            }
        ],
        "primaryKey":[
            "index"
        ],
        "pandas_version":"1.4.0"
    },
    "data":[
        {
            "index":1792,
            "vuln_id":"GHSA-fx7m-j728-mjw3",
            "cwe_id":"{'CWE-185'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/ua-parser\/uap-core\/commit\/010ccdc7303546cd22b9da687c29f4a996990014', 'https:\/\/github.com\/ua-parser\/uap-core\/commit\/156f7e12b215bddbaf3df4514c399d683e6cdadc'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects uap-core An issue was discovered in regex.yaml (aka regexes.yaml) in UA-Parser UAP-Core before 0.6.0. A Regular Expression Denial of Service (ReDoS) issue allows remote attackers to overload a server by setting the User-Agent header in an HTTP(S) request to a value containing a long digit string. (The UAP-Core project contains the vulnerability, propagating to all implementations.)",
            "published_date":"2019-03-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/ua-parser\/uap-core",
            "commit_href":"https:\/\/github.com\/ua-parser\/uap-core\/commit\/010ccdc7303546cd22b9da687c29f4a996990014",
            "commit_sha":"010ccdc7303546cd22b9da687c29f4a996990014",
            "patch":"MULTI",
            "chain_ord":"['156f7e12b215bddbaf3df4514c399d683e6cdadc', '010ccdc7303546cd22b9da687c29f4a996990014']",
            "before_first_fix_commit":"{'764947f552c6fc9ac80759acb5165a83ee746678'}",
            "last_fix_commit":"010ccdc7303546cd22b9da687c29f4a996990014",
            "chain_ord_pos":2.0,
            "commit_datetime":"12\/14\/2018, 07:19:47",
            "message":"0.6.0",
            "author":"commenthol",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'package.json': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ua-parser\/uap-core\/raw\/010ccdc7303546cd22b9da687c29f4a996990014\/package.json', 'patch': '@@ -1,7 +1,7 @@\\n {\\n   \"name\": \"uap-core\",\\n   \"description\": \"The regex file necessary to build language ports of Browserscope\\'s user agent parser.\",\\n-  \"version\": \"0.5.0\",\\n+  \"version\": \"0.6.0\",\\n   \"maintainers\": [\\n     {\\n       \"name\": \"Tobie Langel\",'}}",
            "message_norm":"0.6.0",
            "language":"",
            "entities":"[('0.6.0', 'VERSION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['package.json'])",
            "num_files":1.0
        },
        {
            "index":3497,
            "vuln_id":"GHSA-xvjm-fvxx-q3hv",
            "cwe_id":"{'CWE-190'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4c0ee937c0f61c4fc5f5d32d9bb4c67428012a60'}",
            "dataset":"osv",
            "summary":"CHECK-fail due to integer overflow ### Impact\nAn attacker can trigger a denial of service via a `CHECK`-fail in  caused by an integer overflow in constructing a new tensor shape:\n\n```python\nimport tensorflow as tf\n\ninput_layer = 2**60-1\nsparse_data = tf.raw_ops.SparseSplit(\n    split_dim=1, \n    indices=[(0, 0), (0, 1), (0, 2), \n    (4, 3), (5, 0), (5, 1)],\n    values=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    shape=(input_layer, input_layer),\n    num_split=2,\n    name=None\n    )\n```\n  \nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0908c2f2397c099338b901b067f6495a5b96760b\/tensorflow\/core\/kernels\/sparse_split_op.cc#L66-L70) builds a dense shape without checking that the dimensions would not result in overflow:\n\n```cc\nsparse::SparseTensor sparse_tensor;\nOP_REQUIRES_OK(context,\n               sparse::SparseTensor::Create(\n                 input_indices, input_values,\n                 TensorShape(input_shape.vec<int64>()), &sparse_tensor));\n```\n\nThe [`TensorShape` constructor](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f9896890c4c703ae0a0845394086e2e1e523299\/tensorflow\/core\/framework\/tensor_shape.cc#L183-L188) uses a `CHECK` operation which triggers when [`InitDims`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f9896890c4c703ae0a0845394086e2e1e523299\/tensorflow\/core\/framework\/tensor_shape.cc#L212-L296) returns a non-OK status.\n                    \n```cc               \ntemplate <class Shape>\nTensorShapeBase<Shape>::TensorShapeBase(gtl::ArraySlice<int64> dim_sizes) {\n  set_tag(REP16);\n  set_data_type(DT_INVALID);\n  TF_CHECK_OK(InitDims(dim_sizes));\n}\n```\n\nIn our scenario, this occurs when adding a dimension from the argument results in overflow:\n\n```cc\ntemplate <class Shape>\nStatus TensorShapeBase<Shape>::InitDims(gtl::ArraySlice<int64> dim_sizes) {\n  ...\n  Status status = Status::OK();\n  for (int64 s : dim_sizes) {\n    status.Update(AddDimWithStatus(internal::SubtleMustCopy(s)));\n    if (!status.ok()) {\n      return status;\n    }\n  }\n}\n\ntemplate <class Shape>\nStatus TensorShapeBase<Shape>::AddDimWithStatus(int64 size) {\n  ...\n  int64 new_num_elements;\n  if (kIsPartial && (num_elements() < 0 || size < 0)) {\n    new_num_elements = -1;\n  } else {\n    new_num_elements = MultiplyWithoutOverflow(num_elements(), size);\n    if (TF_PREDICT_FALSE(new_num_elements < 0)) {\n        return errors::Internal(\"Encountered overflow when multiplying \",\n                                num_elements(), \" with \", size,\n                                \", result: \", new_num_elements);\n      }\n  }\n  ...\n}\n```\n\nThis is a legacy implementation of the constructor and operations should use `BuildTensorShapeBase` or `AddDimWithStatus` to prevent `CHECK`-failures in the presence of overflows.\n\n### Patches\nWe have patched the issue in GitHub commit [4c0ee937c0f61c4fc5f5d32d9bb4c67428012a60](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4c0ee937c0f61c4fc5f5d32d9bb4c67428012a60).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by researchers from University of Virginia and University of California, Santa Barbara.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4c0ee937c0f61c4fc5f5d32d9bb4c67428012a60",
            "commit_sha":"4c0ee937c0f61c4fc5f5d32d9bb4c67428012a60",
            "patch":"SINGLE",
            "chain_ord":"['4c0ee937c0f61c4fc5f5d32d9bb4c67428012a60']",
            "before_first_fix_commit":"{'0908c2f2397c099338b901b067f6495a5b96760b'}",
            "last_fix_commit":"4c0ee937c0f61c4fc5f5d32d9bb4c67428012a60",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 22:55:00",
            "message":"Prevent overflow in sparse op\n\nPiperOrigin-RevId: 372442006\nChange-Id: I60fe31cd7e56fb3501e97c63500caf902ddeee96",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 3, 'total': 13}",
            "files":"{'tensorflow\/core\/kernels\/sparse_split_op.cc': {'additions': 10, 'deletions': 3, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/4c0ee937c0f61c4fc5f5d32d9bb4c67428012a60\/tensorflow%2Fcore%2Fkernels%2Fsparse_split_op.cc', 'patch': '@@ -63,11 +63,18 @@ class SparseSplitOp : public OpKernel {\\n                                         input_shape.vec<int64>()(axis),\\n                                         \"), got \", num_split_));\\n \\n+    \/\/ Prevent overflow by constructing the dense shape separately\\n+    TensorShape dense_shape;\\n+    const auto input_shape_flat = input_shape.flat<int64>();\\n+    for (int i = 0; i < input_shape.NumElements(); i++) {\\n+      OP_REQUIRES_OK(context,\\n+                     dense_shape.AddDimWithStatus(input_shape_flat(i)));\\n+    }\\n+\\n     sparse::SparseTensor sparse_tensor;\\n     OP_REQUIRES_OK(context,\\n-                   sparse::SparseTensor::Create(\\n-                       input_indices, input_values,\\n-                       TensorShape(input_shape.vec<int64>()), &sparse_tensor));\\n+                   sparse::SparseTensor::Create(input_indices, input_values,\\n+                                                dense_shape, &sparse_tensor));\\n \\n     std::vector<sparse::SparseTensor> outputs;\\n     OP_REQUIRES_OK(context, sparse::SparseTensor::Split<T>('}}",
            "message_norm":"prevent overflow in sparse op\n\npiperorigin-revid: 372442006\nchange-id: i60fe31cd7e56fb3501e97c63500caf902ddeee96",
            "language":"nl",
            "entities":"[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('372442006', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_split_op.cc'])",
            "num_files":1.0
        },
        {
            "index":163,
            "vuln_id":"GHSA-2xgj-xhgf-ggjv",
            "cwe_id":"{'CWE-120'}",
            "score":3.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `BandedTriangularSolve` ### Impact\nAn attacker can trigger a heap buffer overflow in Eigen implementation of `tf.raw_ops.BandedTriangularSolve`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n  \nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_array = np.array([1,1])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)\ntf.raw_ops.BandedTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc#L269-L278) calls `ValidateInputTensors` for input validation but fails to validate that the two tensors are not empty:\n  \n```cc\nvoid ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0, const Tensor& in1) {\n  OP_REQUIRES(\n      ctx, in0.dims() >= 2, \n      errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n\n  OP_REQUIRES(\n      ctx, in1.dims() >= 2,\n      errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1.dims()));\n}\n``` \n\nFurthermore, since `OP_REQUIRES` macro only stops execution of current function after setting `ctx->status()` to a non-OK value, callers of helper functions that use `OP_REQUIRES` must check value of `ctx->status()` before continuing. This doesn't happen [in this op's implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc#L219), hence the validation that is present is also not effective.\n\n### Patches\nWe have patched the issue in GitHub commit [ba6822bd7b7324ba201a28b2f278c29a98edbef2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2) followed by GitHub commit [0ab290774f91a23bebe30a358fde4e53ab4876a0](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ye Zhang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2",
            "commit_sha":"ba6822bd7b7324ba201a28b2f278c29a98edbef2",
            "patch":"MULTI",
            "chain_ord":"['ba6822bd7b7324ba201a28b2f278c29a98edbef2', '0ab290774f91a23bebe30a358fde4e53ab4876a0']",
            "before_first_fix_commit":"{'327ef310be67923824814e85e13007e9699f4e0d'}",
            "last_fix_commit":"0ab290774f91a23bebe30a358fde4e53ab4876a0",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 23:06:54",
            "message":"Fix OOB issue with `tf.raw_ops.SparseSparseMinimum`.\n\nPiperOrigin-RevId: 371005787\nChange-Id: Ib686ccc077836e8b980b8b5a03936d36a8ecaf71",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ba6822bd7b7324ba201a28b2f278c29a98edbef2\/tensorflow%2Fcore%2Fkernels%2Fsparse_sparse_binary_op_shared.cc', 'patch': '@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n                                           \" for dimension \", i));\\n     }\\n \\n+    OP_REQUIRES(\\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\\n+        errors::InvalidArgument(\\n+            \"Indices\\' dimensions do not match: got \", a_indices_t->dim_size(1),\\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\\n     const int num_dims = a_indices_t->dim_size(1);\\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\\n     const auto b_indices_mat = b_indices_t->matrix<int64>();'}}",
            "message_norm":"fix oob issue with `tf.raw_ops.sparsesparseminimum`.\n\npiperorigin-revid: 371005787\nchange-id: ib686ccc077836e8b980b8b5a03936d36a8ecaf71",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('oob', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371005787', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc'])",
            "num_files":1.0
        },
        {
            "index":2151,
            "vuln_id":"GHSA-hwr7-8gxx-fj5p",
            "cwe_id":"{'CWE-476'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/301ae88b331d37a2a16159b65b255f4f9eb39314'}",
            "dataset":"osv",
            "summary":"Null pointer dereference in `RaggedTensorToTensor` ### Impact\nSending invalid argument for `row_partition_types` of `tf.raw_ops.RaggedTensorToTensor` API results in a null pointer dereference and undefined behavior:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedTensorToTensor(\n  shape=1,\n  values=10,\n  default_value=21,\n  row_partition_tensors=tf.constant([0,0,0,0]),\n  row_partition_types=[])\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/47a06f40411a69c99f381495f490536972152ac0\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc#L328) accesses the first element of a user supplied list of values without validating that the provided list is not empty.\n\n### Patches\nWe have patched the issue in GitHub commit [301ae88b331d37a2a16159b65b255f4f9eb39314](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/301ae88b331d37a2a16159b65b255f4f9eb39314).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/301ae88b331d37a2a16159b65b255f4f9eb39314",
            "commit_sha":"301ae88b331d37a2a16159b65b255f4f9eb39314",
            "patch":"SINGLE",
            "chain_ord":"['301ae88b331d37a2a16159b65b255f4f9eb39314']",
            "before_first_fix_commit":"{'e787d206757e3e87b04ab7bafa8b1e4130a9f774'}",
            "last_fix_commit":"301ae88b331d37a2a16159b65b255f4f9eb39314",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/12\/2021, 16:59:54",
            "message":"Fix null ptr deref in tf.raw_ops.RaggedTensorToTensor\n\nPiperOrigin-RevId: 384257511\nChange-Id: I0484ad285039d132d6c41b284a7fcdd2b774a38e",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/301ae88b331d37a2a16159b65b255f4f9eb39314\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_tensor_op.cc', 'patch': '@@ -348,6 +348,9 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n   Status GetFirstDimensionSize(OpKernelContext* context, INDEX_TYPE* result) {\\n     const Tensor first_partition_tensor =\\n         context->input(kFirstPartitionInputIndex);\\n+    if (row_partition_types_.empty()) {\\n+      return errors::InvalidArgument(\"No row_partition_types given.\");\\n+    }\\n     const RowPartitionType first_partition_type = row_partition_types_[0];\\n     switch (first_partition_type) {\\n       case RowPartitionType::FIRST_DIM_SIZE:'}}",
            "message_norm":"fix null ptr deref in tf.raw_ops.raggedtensortotensor\n\npiperorigin-revid: 384257511\nchange-id: i0484ad285039d132d6c41b284a7fcdd2b774a38e",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('384257511', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc'])",
            "num_files":1.0
        },
        {
            "index":284,
            "vuln_id":"GHSA-3p92-886g-qxpq",
            "cwe_id":"{'CWE-201'}",
            "score":5.1,
            "chain":"{'https:\/\/github.com\/soldair\/node-floody\/commit\/6c44722312131f4ac8a1af40f0f861c85efe01b0'}",
            "dataset":"osv",
            "summary":"Remote Memory Exposure in floody Versions of `floody` before 0.1.1 are vulnerable to remote memory exposure.\n\n.write(number)` in the affected `floody` versions passes a number to Buffer constructor, appending a chunk of uninitialized memory.\n\nProof of Concept: \n\n```\nvar f = require('floody')(process.stdout); \nf.write(USERSUPPLIEDINPUT); \n'f.stop();\n\n\n## Recommendation\n\nUpdate to version 0.1.1 or later.",
            "published_date":"2019-06-04",
            "chain_len":1,
            "project":"https:\/\/github.com\/soldair\/node-floody",
            "commit_href":"https:\/\/github.com\/soldair\/node-floody\/commit\/6c44722312131f4ac8a1af40f0f861c85efe01b0",
            "commit_sha":"6c44722312131f4ac8a1af40f0f861c85efe01b0",
            "patch":"SINGLE",
            "chain_ord":"['6c44722312131f4ac8a1af40f0f861c85efe01b0']",
            "before_first_fix_commit":"{'2a150c5552b8ce2f2a12ae4a3fd33882d5827afd'}",
            "last_fix_commit":"6c44722312131f4ac8a1af40f0f861c85efe01b0",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/15\/2016, 13:27:13",
            "message":"adding fix for exposing uninitalized memory found by @chalker",
            "author":"Ryan Day",
            "comments":"{'com_1': {'author': 'ChALkeR', 'datetime': '01\/15\/2016, 20:42:58', 'body': \"POC: `var f = require('floody')(process.stdout); f.write(1000); f.stop();`.\"}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/soldair\/node-floody\/raw\/6c44722312131f4ac8a1af40f0f861c85efe01b0\/index.js', 'patch': \"@@ -28,7 +28,7 @@ module.exports = function(options){\\n \\n     if(writes.length > windowSize) writes.shift();\\n \\n-    data = data instanceof Buffer ? data : new Buffer(data);\\n+    data = data instanceof Buffer ? data : new Buffer(data+'');\\n     bufLen += data.length;\\n \\n     buf.push(data);\"}}",
            "message_norm":"adding fix for exposing uninitalized memory found by @chalker",
            "language":"en",
            "entities":"[('adding', 'ACTION', ''), ('uninitalized memory', 'SECWORD', ''), ('found', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":517,
            "vuln_id":"GHSA-4wm8-c2vv-xrpq",
            "cwe_id":"{'CWE-79'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/DSpace\/DSpace\/commit\/28eb8158210d41168a62ed5f9e044f754513bc37', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/f7758457b7ec3489d525e39aa753cc70809d9ad9'}",
            "dataset":"osv",
            "summary":"JSPUI Possible Cross Site Scripting in \"Request a Copy\" Feature ### Impact\nThe JSPUI \"Request a Copy\" feature does not properly escape values submitted and stored from the \"Request a Copy\" form.  This means that item requests could be vulnerable to XSS attacks.  This vulnerability only impacts the JSPUI.\n\n_This vulnerability does NOT impact the XMLUI or 7.x._\n\n### Patches\n\n_DSpace 6.x:_ \n* Fixed in 6.4 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/503a6af57fd720c37b0d86c34de63baa5dd85819\n* 6.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/503a6af57fd720c37b0d86c34de63baa5dd85819.patch (may be applied manually if an immediate upgrade to 6.4 is not possible)\n\n_DSpace 5.x:_\n* Fixed in 5.11 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/28eb8158210d41168a62ed5f9e044f754513bc37\n* 5.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/28eb8158210d41168a62ed5f9e044f754513bc37.patch (may be applied manually if an immediate upgrade to 5.11 or 6.4 is not possible)\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs \/ configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### Workarounds\nAs a workaround, you can temporarily disable the \"Request a Copy\" feature by either commenting out the below configuration (or setting its value to empty):\n```\n# Comment out this default value\n# request.item.type = all\n```\nOnce your JSPUI site is patched, you can re-enable this setting. See https:\/\/wiki.lyrasis.org\/display\/DSDOC6x\/Request+a+Copy for more information on this setting.\n\n### References\nDiscovered & reported by Andrea Bollini of 4Science\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
            "published_date":"2022-08-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/DSpace\/DSpace",
            "commit_href":"https:\/\/github.com\/DSpace\/DSpace\/commit\/f7758457b7ec3489d525e39aa753cc70809d9ad9",
            "commit_sha":"f7758457b7ec3489d525e39aa753cc70809d9ad9",
            "patch":"MULTI",
            "chain_ord":"['f7758457b7ec3489d525e39aa753cc70809d9ad9', '28eb8158210d41168a62ed5f9e044f754513bc37']",
            "before_first_fix_commit":"{'56e76049185bbd87c994128a9d77735ad7af0199'}",
            "last_fix_commit":"28eb8158210d41168a62ed5f9e044f754513bc37",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/08\/2020, 00:48:56",
            "message":"[DS-4133] Improve URL handling in Controlled Vocab JSPUI servlet",
            "author":"Kim Shepherd",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 2, 'total': 12}",
            "files":"{'dspace-jspui\/src\/main\/java\/org\/dspace\/app\/webui\/servlet\/ControlledVocabularyServlet.java': {'additions': 10, 'deletions': 2, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DSpace\/DSpace\/raw\/f7758457b7ec3489d525e39aa753cc70809d9ad9\/dspace-jspui%2Fsrc%2Fmain%2Fjava%2Forg%2Fdspace%2Fapp%2Fwebui%2Fservlet%2FControlledVocabularyServlet.java', 'patch': '@@ -14,6 +14,7 @@\\n import javax.servlet.http.HttpServletRequest;\\n import javax.servlet.http.HttpServletResponse;\\n \\n+import org.apache.log4j.Logger;\\n import org.dspace.authorize.AuthorizeException;\\n import org.dspace.core.Context;\\n \\n@@ -25,8 +26,8 @@\\n  *\/\\n public class ControlledVocabularyServlet extends DSpaceServlet\\n {\\n-    \/\/ private static Logger log =\\n-    \/\/ Logger.getLogger(ControlledVocabularyServlet.class);\\n+    private static Logger log =\\n+    Logger.getLogger(ControlledVocabularyServlet.class);\\n \\n     protected void doDSGet(Context context, HttpServletRequest request,\\n             HttpServletResponse response) throws ServletException, IOException,\\n@@ -37,6 +38,13 @@ protected void doDSGet(Context context, HttpServletRequest request,\\n         String filter = \"\";\\n         String callerUrl = request.getParameter(\"callerUrl\");\\n \\n+        \/\/ callerUrl must starts with URL outside DSpace request context path\\n+        if(!callerUrl.startsWith(request.getContextPath())) {\\n+            log.error(\"Controlled vocabulary caller URL would result in redirect outside DSpace web app: \" + callerUrl + \". Rejecting request with 400 Bad Request.\");\\n+            response.sendError(400, \"The caller URL must be within the DSpace base URL of \" + request.getContextPath());\\n+            return;\\n+        }\\n+\\n         if (request.getParameter(\"ID\") != null)\\n         {\\n             ID = request.getParameter(\"ID\");'}}",
            "message_norm":"[ds-4133] improve url handling in controlled vocab jspui servlet",
            "language":"en",
            "entities":"[('improve', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dspace-jspui\/src\/main\/java\/org\/dspace\/app\/webui\/servlet\/ControlledVocabularyServlet.java'])",
            "num_files":1.0
        },
        {
            "index":498,
            "vuln_id":"GHSA-4vrf-ff7v-hpgr",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f61c57bd425878be108ec787f4d96390579fb83e'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite's implementation of `EmbeddingLookup` The implementation of the `EmbeddingLookup` TFLite operator is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e4b29809543b250bc9b19678ec4776299dd569ba\/tensorflow\/lite\/kernels\/embedding_lookup.cc#L73-L74):\n\n```cc\nconst int row_size = SizeOfDimension(value, 0);\nconst int row_bytes = value->bytes \/ row_size;\n```\n\nAn attacker can craft a model such that the first dimension of the `value` input is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [f61c57bd425878be108ec787f4d96390579fb83e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f61c57bd425878be108ec787f4d96390579fb83e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f61c57bd425878be108ec787f4d96390579fb83e",
            "commit_sha":"f61c57bd425878be108ec787f4d96390579fb83e",
            "patch":"SINGLE",
            "chain_ord":"['f61c57bd425878be108ec787f4d96390579fb83e']",
            "before_first_fix_commit":"{'e4b29809543b250bc9b19678ec4776299dd569ba'}",
            "last_fix_commit":"f61c57bd425878be108ec787f4d96390579fb83e",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 19:57:00",
            "message":"Prevent division by 0\n\nPiperOrigin-RevId: 370966645\nChange-Id: I831bfd96c7eb77b02d7ebb744335f59f6e5728cb",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/lite\/kernels\/embedding_lookup.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f61c57bd425878be108ec787f4d96390579fb83e\/tensorflow%2Flite%2Fkernels%2Fembedding_lookup.cc', 'patch': '@@ -71,6 +71,10 @@ TfLiteStatus EvalSimple(TfLiteContext* context, TfLiteNode* node,\\n                         const TfLiteTensor* lookup, const TfLiteTensor* value,\\n                         TfLiteTensor* output) {\\n   const int row_size = SizeOfDimension(value, 0);\\n+  if (row_size == 0) {\\n+    \/\/ Propagate empty tensor if input is empty\\n+    return kTfLiteOk;\\n+  }\\n   const int row_bytes = value->bytes \/ row_size;\\n \\n   char* output_raw = GetTensorData<char>(output);'}}",
            "message_norm":"prevent division by 0\n\npiperorigin-revid: 370966645\nchange-id: i831bfd96c7eb77b02d7ebb744335f59f6e5728cb",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('370966645', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/embedding_lookup.cc'])",
            "num_files":1.0
        },
        {
            "index":647,
            "vuln_id":"GHSA-5jfw-35xp-5m42",
            "cwe_id":"{'CWE-124'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/pmmp\/BedrockProtocol\/commit\/e3fce7632b94e83fd6a518a87dcaf6a11681c4ac'}",
            "dataset":"osv",
            "summary":"Buffer length underflow in LoginPacket causing unchecked exceptions to be thrown ### Impact\n`LoginPacket` uses `BinaryStream->getLInt()` to read the lengths of JSON payloads it wants to decode. Unfortunately, `BinaryStream->getLInt()` returns a signed integer, meaning that a malicious client can craft a packet with a large uint32 value for payload buffer size (which would be interpreted as a negative signed int32), causing `BinaryStream->get()` to throw an exception.\n\nIn the context of PocketMine-MP, this leads to a server crash when the vulnerability is exploited.\n\n### Patches\ne3fce7632b94e83fd6a518a87dcaf6a11681c4ac\n\n### Workarounds\nThis can be worked around by registering a custom `LoginPacket` implementation into `PacketPool` which overrides [this code](https:\/\/github.com\/pmmp\/BedrockProtocol\/blob\/47532c95ea37d5f0365b23f734d70d943ff95295\/src\/LoginPacket.php#L54) to patch it.\n\n### For more information\n* Email us at [team@pmmp.io](mailto:team@pmmp.io)",
            "published_date":"2022-04-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/pmmp\/BedrockProtocol",
            "commit_href":"https:\/\/github.com\/pmmp\/BedrockProtocol\/commit\/e3fce7632b94e83fd6a518a87dcaf6a11681c4ac",
            "commit_sha":"e3fce7632b94e83fd6a518a87dcaf6a11681c4ac",
            "patch":"SINGLE",
            "chain_ord":"['e3fce7632b94e83fd6a518a87dcaf6a11681c4ac']",
            "before_first_fix_commit":"{'a740f6095b35278c0e0dac6db84a5e4d2456b113'}",
            "last_fix_commit":"e3fce7632b94e83fd6a518a87dcaf6a11681c4ac",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/01\/2022, 21:41:00",
            "message":"LoginPacket: fixed buffer length underflow in payload decoding",
            "author":"Dylan K. Taylor",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 2, 'total': 16}",
            "files":"{'src\/LoginPacket.php': {'additions': 14, 'deletions': 2, 'changes': 16, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pmmp\/BedrockProtocol\/raw\/e3fce7632b94e83fd6a518a87dcaf6a11681c4ac\/src%2FLoginPacket.php', 'patch': '@@ -54,7 +54,13 @@ protected function decodePayload(PacketSerializer $in) : void{\\n \\tprotected function decodeConnectionRequest(string $binary) : void{\\n \\t\\t$connRequestReader = new BinaryStream($binary);\\n \\n-\\t\\t$chainDataJson = json_decode($connRequestReader->get($connRequestReader->getLInt()));\\n+\\t\\t$chainDataJsonLength = $connRequestReader->getLInt();\\n+\\t\\tif($chainDataJsonLength <= 0){\\n+\\t\\t\\t\/\/technically this is always positive; the problem results because getLInt() is implicitly signed\\n+\\t\\t\\t\/\/this is inconsistent with many other methods, but we can\\'t do anything about that for now\\n+\\t\\t\\tthrow new PacketDecodeException(\"Length of chain data JSON must be positive\");\\n+\\t\\t}\\n+\\t\\t$chainDataJson = json_decode($connRequestReader->get($chainDataJsonLength));\\n \\t\\tif(!is_object($chainDataJson)){\\n \\t\\t\\tthrow new PacketDecodeException(\"Failed decoding chain data JSON: \" . json_last_error_msg());\\n \\t\\t}\\n@@ -68,7 +74,13 @@ protected function decodeConnectionRequest(string $binary) : void{\\n \\t\\t}\\n \\n \\t\\t$this->chainDataJwt = $chainData;\\n-\\t\\t$this->clientDataJwt = $connRequestReader->get($connRequestReader->getLInt());\\n+\\t\\t$clientDataJwtLength = $connRequestReader->getLInt();\\n+\\t\\tif($clientDataJwtLength <= 0){\\n+\\t\\t\\t\/\/technically this is always positive; the problem results because getLInt() is implicitly signed\\n+\\t\\t\\t\/\/this is inconsistent with many other methods, but we can\\'t do anything about that for now\\n+\\t\\t\\tthrow new PacketDecodeException(\"Length of clientData JWT must be positive\");\\n+\\t\\t}\\n+\\t\\t$this->clientDataJwt = $connRequestReader->get($clientDataJwtLength);\\n \\t}\\n \\n \\tprotected function encodePayload(PacketSerializer $out) : void{'}}",
            "message_norm":"loginpacket: fixed buffer length underflow in payload decoding",
            "language":"en",
            "entities":"[('fixed', 'ACTION', ''), ('underflow', 'SECWORD', ''), ('decoding', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/LoginPacket.php'])",
            "num_files":1.0
        },
        {
            "index":332,
            "vuln_id":"GHSA-4278-2v5v-65r4",
            "cwe_id":"{'CWE-787', 'CWE-120'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eebb96c2830d48597d055d247c0e9aebaea94cd5'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `RaggedBinCount` ### Impact\nIf the `splits` argument of `RaggedBincount` does not specify a valid [`SparseTensor`](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/sparse\/SparseTensor), then an attacker can trigger a heap buffer overflow:\n\n```python\nimport tensorflow as tf\ntf.raw_ops.RaggedBincount(splits=[0], values=[1,1,1,1,1], size=5, weights=[1,2,3,4], binary_output=False)\n```\n\nThis will cause a read from outside the bounds of the `splits` tensor buffer in the [implementation of the `RaggedBincount` op](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8b677d79167799f71c42fd3fa074476e0295413a\/tensorflow\/core\/kernels\/bincount_op.cc#L430-L433):\n\n```cc\n    for (int idx = 0; idx < num_values; ++idx) {\n      while (idx >= splits(batch_idx)) {\n        batch_idx++;\n      }\n      ...\n    }\n```\n\nBefore the `for` loop, `batch_idx` is set to 0. The user controls the `splits` array, making it contain only one element, 0. Thus, the code in the `while` loop would increment `batch_idx` and then try to read `splits(1)`, which is outside of bounds.\n\n### Patches\nWe have patched the issue in GitHub commit [eebb96c2830d48597d055d247c0e9aebaea94cd5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eebb96c2830d48597d055d247c0e9aebaea94cd5).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2 and TensorFlow 2.3.3, as these are also affected.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eebb96c2830d48597d055d247c0e9aebaea94cd5",
            "commit_sha":"eebb96c2830d48597d055d247c0e9aebaea94cd5",
            "patch":"SINGLE",
            "chain_ord":"['eebb96c2830d48597d055d247c0e9aebaea94cd5']",
            "before_first_fix_commit":"{'8b677d79167799f71c42fd3fa074476e0295413a'}",
            "last_fix_commit":"eebb96c2830d48597d055d247c0e9aebaea94cd5",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2021, 21:18:51",
            "message":"Fix an invalid address vulnerability in `tf.raw_ops.RaggedBincount`.\n\nPiperOrigin-RevId: 368293153\nChange-Id: I4b4e493d3fd05e7dc55a55de3a041a80a4f275c3",
            "author":"Amit Patankar",
            "comments":"{'com_1': {'author': 'Rayyan335', 'datetime': '05\/14\/2021, 19:00:36', 'body': 'tensorflow\/core\/kernels\/bincount_op.cc'}}",
            "stats":"{'additions': 9, 'deletions': 0, 'total': 9}",
            "files":"{'tensorflow\/core\/kernels\/bincount_op.cc': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/eebb96c2830d48597d055d247c0e9aebaea94cd5\/tensorflow%2Fcore%2Fkernels%2Fbincount_op.cc', 'patch': '@@ -420,6 +420,15 @@ class RaggedBincountOp : public OpKernel {\\n     int num_values = values.size();\\n     int batch_idx = 0;\\n \\n+    OP_REQUIRES(ctx, splits(0) == 0,\\n+                errors::InvalidArgument(\"Splits must start with 0, not with \",\\n+                                        splits(0)));\\n+\\n+    OP_REQUIRES(ctx, splits(num_rows) == num_values,\\n+                errors::InvalidArgument(\\n+                    \"Splits must end with the number of values, got \",\\n+                    splits(num_rows), \" instead of \", num_values));\\n+\\n     Tensor* out_t;\\n     OP_REQUIRES_OK(\\n         ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));'}}",
            "message_norm":"fix an invalid address vulnerability in `tf.raw_ops.raggedbincount`.\n\npiperorigin-revid: 368293153\nchange-id: i4b4e493d3fd05e7dc55a55de3a041a80a4f275c3",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('368293153', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/bincount_op.cc'])",
            "num_files":1.0
        },
        {
            "index":519,
            "vuln_id":"GHSA-4wv4-mgfq-598v",
            "cwe_id":"{'CWE-94'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/AnneTheDev\/nobelprize\/commit\/00639d375b0efd097bc1eca18d9dc021691b9286'}",
            "dataset":"osv",
            "summary":"Code injection in nobelprizeparser Code injection through use of eval.",
            "published_date":"2021-03-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/AnneTheDev\/nobelprize",
            "commit_href":"https:\/\/github.com\/AnneTheDev\/nobelprize\/commit\/00639d375b0efd097bc1eca18d9dc021691b9286",
            "commit_sha":"00639d375b0efd097bc1eca18d9dc021691b9286",
            "patch":"SINGLE",
            "chain_ord":"['00639d375b0efd097bc1eca18d9dc021691b9286']",
            "before_first_fix_commit":"{'23abc78c8bf9eddce8ec40f0ec7bbb586a3ebe9f', '29126617df6f313d81588d695d94982cba03d82e'}",
            "last_fix_commit":"00639d375b0efd097bc1eca18d9dc021691b9286",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/23\/2021, 09:03:46",
            "message":"Merge pull request from GHSA-4wv4-mgfq-598v\n\nReplace eval with JSON.parse",
            "author":"AnneTheDev",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/AnneTheDev\/nobelprize\/raw\/00639d375b0efd097bc1eca18d9dc021691b9286\/lib%2Findex.js', 'patch': '@@ -10,7 +10,7 @@ function output(laureate) {\\n class Parser {\\n     \/\/ Parse JSON data\\n     constructor(data) {\\n-        this.laureates = eval(`(${data})`).laureates;\\n+        this.laureates = JSON.parse(data}).laureates;\\n     }\\n \\n     inYear(year) {'}}",
            "message_norm":"merge pull request from ghsa-4wv4-mgfq-598v\n\nreplace eval with json.parse",
            "language":"en",
            "entities":"[('ghsa-4wv4-mgfq-598v', 'VULNID', 'GHSA'), ('eval', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/index.js'])",
            "num_files":1.0
        },
        {
            "index":2130,
            "vuln_id":"GHSA-hv9c-qwqg-qj3v",
            "cwe_id":"{'CWE-1188'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/electron\/electron\/commit\/bab968ca776be28791e4dddfd50c86bd5fae62fa', 'https:\/\/github.com\/electron\/electron\/commit\/80221e52d93a96ea704cb6748ead669c55cff504', 'https:\/\/github.com\/electron\/electron\/commit\/519a02d8d4d28e8a467acb40fb26172a80c9454f', 'https:\/\/github.com\/electron\/electron\/commit\/ef0a6d9a1c96efc4657c6dd3a6624eba969f095b'}",
            "dataset":"osv",
            "summary":"Electron webPreferences vulnerability can be used to perform remote code execution GitHub Electron 1.7.15, 1.8.7, 2.0.7, and 3.0.0-beta.6, in certain scenarios involving IFRAME elements and \"nativeWindowOpen: true\" or \"sandbox: true\" options, is affected by a webPreferences vulnerability that can be leveraged to perform remote code execution.\n\nMore information to determine if you are impacted can be found on the [electron blog](https:\/\/electronjs.org\/blog\/web-preferences-fix).\n\n\n## Recommendation\n\nUpgrade Electron to >=3.0.0-beta.7, >=2.0.8, >=1.8.8, or >=1.7.16.",
            "published_date":"2018-08-23",
            "chain_len":4,
            "project":"https:\/\/github.com\/electron\/electron",
            "commit_href":"https:\/\/github.com\/electron\/electron\/commit\/bab968ca776be28791e4dddfd50c86bd5fae62fa",
            "commit_sha":"bab968ca776be28791e4dddfd50c86bd5fae62fa",
            "patch":"MULTI",
            "chain_ord":"['ef0a6d9a1c96efc4657c6dd3a6624eba969f095b', '80221e52d93a96ea704cb6748ead669c55cff504', '519a02d8d4d28e8a467acb40fb26172a80c9454f', 'bab968ca776be28791e4dddfd50c86bd5fae62fa']",
            "before_first_fix_commit":"{'7fa3eba9512da5bb3a8a61433bb3921c2be67459'}",
            "last_fix_commit":"bab968ca776be28791e4dddfd50c86bd5fae62fa",
            "chain_ord_pos":4.0,
            "commit_datetime":"08\/22\/2018, 17:36:02",
            "message":"fix: inheritance of webPreferences sub properties",
            "author":"Samuel Attard",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'lib\/browser\/guest-window-manager.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/electron\/electron\/raw\/bab968ca776be28791e4dddfd50c86bd5fae62fa\/lib%2Fbrowser%2Fguest-window-manager.js', 'patch': \"@@ -26,11 +26,11 @@ const mergeOptions = function (child, parent, visited) {\\n   visited.add(parent)\\n   for (const key in parent) {\\n     if (!hasProp.call(parent, key)) continue\\n-    if (key in child) continue\\n+    if (key in child && key !== 'webPreferences') continue\\n \\n     const value = parent[key]\\n     if (typeof value === 'object') {\\n-      child[key] = mergeOptions({}, value, visited)\\n+      child[key] = mergeOptions(child[key] || {}, value, visited)\\n     } else {\\n       child[key] = value\\n     }\"}}",
            "message_norm":"fix: inheritance of webpreferences sub properties",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/browser\/guest-window-manager.js'])",
            "num_files":1.0
        },
        {
            "index":3409,
            "vuln_id":"GHSA-xc7v-wxcw-j472",
            "cwe_id":"{'CWE-200'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/request\/tunnel-agent\/commit\/9ca95ec7219daface8a6fc2674000653de0922c0'}",
            "dataset":"osv",
            "summary":"Memory Exposure in tunnel-agent Versions of `tunnel-agent` before 0.6.0 are vulnerable to memory exposure.\n\nThis is exploitable if user supplied input is provided to the auth value and is a number.\n\nProof-of-concept:\n```js\nrequire('request')({\n  method: 'GET',\n  uri: 'http:\/\/www.example.com',\n  tunnel: true,\n  proxy:{\n    protocol: 'http:',\n    host:'127.0.0.1',\n    port:8080,\n    auth:USERSUPPLIEDINPUT \/\/ number\n  }\n});\n```\n\n\n## Recommendation\n\nUpdate to version 0.6.0 or later.",
            "published_date":"2019-06-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/request\/tunnel-agent",
            "commit_href":"https:\/\/github.com\/request\/tunnel-agent\/commit\/9ca95ec7219daface8a6fc2674000653de0922c0",
            "commit_sha":"9ca95ec7219daface8a6fc2674000653de0922c0",
            "patch":"SINGLE",
            "chain_ord":"['9ca95ec7219daface8a6fc2674000653de0922c0']",
            "before_first_fix_commit":"{'8a7c86e6e2a1c3fa8577e5b0e14923d54c659552'}",
            "last_fix_commit":"9ca95ec7219daface8a6fc2674000653de0922c0",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/05\/2017, 00:29:52",
            "message":"Use .from",
            "author":"Mikeal Rogers",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/request\/tunnel-agent\/raw\/9ca95ec7219daface8a6fc2674000653de0922c0\/index.js', 'patch': \"@@ -128,7 +128,7 @@ TunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\\n   if (connectOptions.proxyAuth) {\\n     connectOptions.headers = connectOptions.headers || {}\\n     connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\\n-        new Buffer(connectOptions.proxyAuth).toString('base64')\\n+        Buffer.from(connectOptions.proxyAuth).toString('base64')\\n   }\\n \\n   debug('making CONNECT request')\"}}",
            "message_norm":"use .from",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":30,
            "vuln_id":"GHSA-2598-2f59-rmhq",
            "cwe_id":"{'CWE-89'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/sequelize\/sequelize\/commit\/ee4017379db0059566ecb5424274ad4e2d66bc68'}",
            "dataset":"osv",
            "summary":"SQL Injection in sequelize Versions of `sequelize` prior to 3.35.1 are vulnerable to SQL Injection. The package fails to sanitize JSON path keys in the Postgres dialect,  which may allow attackers to inject SQL statements and execute arbitrary SQL queries.\n\n\n## Recommendation\n\nUpgrade to version 3.35.1 or later.",
            "published_date":"2019-11-08",
            "chain_len":1,
            "project":"https:\/\/github.com\/sequelize\/sequelize",
            "commit_href":"https:\/\/github.com\/sequelize\/sequelize\/commit\/ee4017379db0059566ecb5424274ad4e2d66bc68",
            "commit_sha":"ee4017379db0059566ecb5424274ad4e2d66bc68",
            "patch":"SINGLE",
            "chain_ord":"['ee4017379db0059566ecb5424274ad4e2d66bc68']",
            "before_first_fix_commit":"{'75c1fdbc676d73a28a5e0bca49b2a6d4a9f8708c'}",
            "last_fix_commit":"ee4017379db0059566ecb5424274ad4e2d66bc68",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/20\/2019, 05:26:22",
            "message":"fix(postgres): json path key quoting (#11088)",
            "author":"Sushant",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'lib\/dialects\/abstract\/query-generator.js': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sequelize\/sequelize\/raw\/ee4017379db0059566ecb5424274ad4e2d66bc68\/lib%2Fdialects%2Fabstract%2Fquery-generator.js', 'patch': \"@@ -2198,7 +2198,8 @@ var QueryGenerator = {\\n             path[path.length - 1] = $tmp[0];\\n           }\\n \\n-          $baseKey = self.quoteIdentifier(key)+'#>>\\\\'{'+path.join(', ')+'}\\\\'';\\n+          var pathKey = self.escape('{' + path.join(', ') + '}');\\n+          $baseKey = self.quoteIdentifier(key)+'#>>'+pathKey;\\n \\n           if (options.prefix) {\\n             if (options.prefix instanceof Utils.literal) {\"}}",
            "message_norm":"fix(postgres): json path key quoting (#11088)",
            "language":"en",
            "entities":"[('fix(postgres', 'ACTION', ''), ('key', 'SECWORD', ''), ('#11088', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/dialects\/abstract\/query-generator.js'])",
            "num_files":1.0
        },
        {
            "index":3302,
            "vuln_id":"GHSA-wp3c-xw9g-gpcg",
            "cwe_id":"{'CWE-617'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7ae2af34087fb4b5c8915279efd03da3b81028bc'}",
            "dataset":"osv",
            "summary":"Lack of validation in `SparseDenseCwiseMul` ### Impact\nDue to lack of validation in `tf.raw_ops.SparseDenseCwiseMul`, an attacker can trigger denial of service via `CHECK`-fails or accesses to outside the bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\nindices = tf.constant([], shape=[10, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\nshape = tf.constant([0, 0], shape=[2], dtype=tf.int64)\ndense = tf.constant([], shape=[0], dtype=tf.int64)\n  \ntf.raw_ops.SparseDenseCwiseMul(\n    sp_indices=indices, sp_values=values, sp_shape=shape, dense=dense)\n```\n\nSince the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/38178a2f7a681a7835bb0912702a134bfe3b4d84\/tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc#L68-L80) only validates the rank of the input arguments but no [constraints between dimensions](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/raw_ops\/SparseDenseCwiseMul), an attacker can abuse them to trigger internal `CHECK` assertions (and cause program termination, denial of service) or to write to memory outside of bounds of heap allocated tensor buffers.\n\n### Patches\nWe have patched the issue in GitHub commit [7ae2af34087fb4b5c8915279efd03da3b81028bc](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7ae2af34087fb4b5c8915279efd03da3b81028bc).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7ae2af34087fb4b5c8915279efd03da3b81028bc",
            "commit_sha":"7ae2af34087fb4b5c8915279efd03da3b81028bc",
            "patch":"SINGLE",
            "chain_ord":"['7ae2af34087fb4b5c8915279efd03da3b81028bc']",
            "before_first_fix_commit":"{'38178a2f7a681a7835bb0912702a134bfe3b4d84'}",
            "last_fix_commit":"7ae2af34087fb4b5c8915279efd03da3b81028bc",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 04:30:50",
            "message":"Fix heap-buffer-overflow issue with `tf.raw_ops.SparseDenseCwiseMul`.\n\nPiperOrigin-RevId: 372054410\nChange-Id: Ifcce0491e2e3816838c87e73be30a1e61b65174d",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/7ae2af34087fb4b5c8915279efd03da3b81028bc\/tensorflow%2Fcore%2Fkernels%2Fsparse_dense_binary_op_shared.cc', 'patch': '@@ -78,6 +78,11 @@ class SparseDenseBinaryOpShared : public OpKernel {\\n                     \"but received shapes: \",\\n                     values_t->shape().DebugString(), \" and \",\\n                     shape_t->shape().DebugString()));\\n+    OP_REQUIRES(\\n+        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"The first dimension of values and indices should match. (\",\\n+            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\\n \\n     const auto indices_mat = indices_t->matrix<int64>();\\n     const auto shape_vec = shape_t->vec<int64>();'}}",
            "message_norm":"fix heap-buffer-overflow issue with `tf.raw_ops.sparsedensecwisemul`.\n\npiperorigin-revid: 372054410\nchange-id: ifcce0491e2e3816838c87e73be30a1e61b65174d",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('372054410', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc'])",
            "num_files":1.0
        },
        {
            "index":590,
            "vuln_id":"GHSA-58jx-f5rf-qgqf",
            "cwe_id":"{'CWE-22', 'CWE-502'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/apache\/hadoop\/commit\/ba041fe6d34215f075e0a7b2078d7273147e14b7', 'https:\/\/github.com\/apache\/hadoop\/commit\/227d64ab59e8aa6477769b2542ad0cd7a6d855cb', 'https:\/\/github.com\/apache\/hadoop\/commit\/45801fba8b00257ab32c02a7d1a05948ba687a49'}",
            "dataset":"osv",
            "summary":"User account escalation in Apache Hadoop In Apache Hadoop 2.2.0 to 2.10.1, 3.0.0-alpha1 to 3.1.4, 3.2.0 to 3.2.2, and 3.3.0 to 3.3.1, a user who can escalate to yarn user can possibly run arbitrary commands as root user. Users should upgrade to Apache Hadoop 2.10.2, 3.2.3, 3.3.2 or higher.",
            "published_date":"2022-06-16",
            "chain_len":3,
            "project":"https:\/\/github.com\/apache\/hadoop",
            "commit_href":"https:\/\/github.com\/apache\/hadoop\/commit\/227d64ab59e8aa6477769b2542ad0cd7a6d855cb",
            "commit_sha":"227d64ab59e8aa6477769b2542ad0cd7a6d855cb",
            "patch":"MULTI",
            "chain_ord":"['ba041fe6d34215f075e0a7b2078d7273147e14b7', '45801fba8b00257ab32c02a7d1a05948ba687a49', '227d64ab59e8aa6477769b2542ad0cd7a6d855cb']",
            "before_first_fix_commit":"{'ba041fe6d34215f075e0a7b2078d7273147e14b7'}",
            "last_fix_commit":"227d64ab59e8aa6477769b2542ad0cd7a6d855cb",
            "chain_ord_pos":3.0,
            "commit_datetime":"05\/24\/2022, 05:07:19",
            "message":"YARN-11162. Set the zk acl for nodes created by ZKConfigurationStore. (#4350)\n\n(cherry picked from commit f390edaec44cfa91b2b09549091f033f1749d8ac)\n\nConflicts:\n\thadoop-yarn-project\/hadoop-yarn\/hadoop-yarn-server\/hadoop-yarn-server-resourcemanager\/src\/main\/java\/org\/apache\/hadoop\/yarn\/server\/resourcemanager\/scheduler\/capacity\/conf\/ZKConfigurationStore.java\n\n(cherry picked from commit 88a8752fa2ba0c70b0df94a78eb9fd86b965acd5)",
            "author":"Owen O'Malley",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'hadoop-yarn-project\/hadoop-yarn\/hadoop-yarn-server\/hadoop-yarn-server-resourcemanager\/src\/main\/java\/org\/apache\/hadoop\/yarn\/server\/resourcemanager\/scheduler\/capacity\/conf\/ZKConfigurationStore.java': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/hadoop\/raw\/227d64ab59e8aa6477769b2542ad0cd7a6d855cb\/hadoop-yarn-project%2Fhadoop-yarn%2Fhadoop-yarn-server%2Fhadoop-yarn-server-resourcemanager%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fyarn%2Fserver%2Fresourcemanager%2Fscheduler%2Fcapacity%2Fconf%2FZKConfigurationStore.java', 'patch': '@@ -97,13 +97,13 @@ public void initialize(Configuration config, Configuration schedConf,\\n     zkManager.delete(fencingNodePath);\\n \\n     if (!zkManager.exists(logsPath)) {\\n-      zkManager.create(logsPath);\\n+      zkManager.create(logsPath, zkAcl);\\n       zkManager.setData(logsPath,\\n           serializeObject(new LinkedList<LogMutation>()), -1);\\n     }\\n \\n     if (!zkManager.exists(confStorePath)) {\\n-      zkManager.create(confStorePath);\\n+      zkManager.create(confStorePath, zkAcl);\\n       HashMap<String, String> mapSchedConf = new HashMap<>();\\n       for (Map.Entry<String, String> entry : schedConf) {\\n         mapSchedConf.put(entry.getKey(), entry.getValue());'}}",
            "message_norm":"yarn-11162. set the zk acl for nodes created by zkconfigurationstore. (#4350)\n\n(cherry picked from commit f390edaec44cfa91b2b09549091f033f1749d8ac)\n\nconflicts:\n\thadoop-yarn-project\/hadoop-yarn\/hadoop-yarn-server\/hadoop-yarn-server-resourcemanager\/src\/main\/java\/org\/apache\/hadoop\/yarn\/server\/resourcemanager\/scheduler\/capacity\/conf\/zkconfigurationstore.java\n\n(cherry picked from commit 88a8752fa2ba0c70b0df94a78eb9fd86b965acd5)",
            "language":"en",
            "entities":"[('#4350', 'ISSUE', ''), ('commit f390edaec44cfa91b2b09549091f033f1749d8ac', 'SHA', 'prefix_sha'), ('server', 'SECWORD', ''), ('server', 'SECWORD', ''), ('server', 'SECWORD', ''), ('commit 88a8752fa2ba0c70b0df94a78eb9fd86b965acd5', 'SHA', 'prefix_colon_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['hadoop-yarn-project\/hadoop-yarn\/hadoop-yarn-server\/hadoop-yarn-server-resourcemanager\/src\/main\/java\/org\/apache\/hadoop\/yarn\/server\/resourcemanager\/scheduler\/capacity\/conf\/ZKConfigurationStore.java'])",
            "num_files":1.0
        },
        {
            "index":531,
            "vuln_id":"GHSA-52q8-877j-gghq",
            "cwe_id":"{'CWE-22'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/moinwiki\/moin-1.9\/commit\/6b96a9060069302996b5af47fd4a388fc80172b7'}",
            "dataset":"osv",
            "summary":"remote code execution via cache action in MoinMoin ### Impact\nThe cache action in action\/cache.py allows directory traversal through a crafted HTTP request. An attacker who can upload attachments to\nthe wiki can use this to achieve remote code execution.\n\n### Patches\nUsers are strongly advised to upgrade to a patched version.\n\nMoinMoin Wiki 1.9.11 has the necessary fixes and also contains other important fixes.\n\n### Workarounds\nIt is not advised to work around this, but to upgrade MoinMoin to a patched version.\n\nThat said, a work around via disabling the `cache` or the `AttachFile` action might be possible.\n\nAlso, it is of course helpful if you give `write` permissions (which include uploading attachments) only to trusted users.\n\n### Credits\n\nThis vulnerability was discovered by Michael Chapman.\n\n### For more information\nIf you have any questions or comments about this advisory, email me at [twaldmann@thinkmo.de](mailto:twaldmann@thinkmo.de).",
            "published_date":"2020-11-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/moinwiki\/moin-1.9",
            "commit_href":"https:\/\/github.com\/moinwiki\/moin-1.9\/commit\/6b96a9060069302996b5af47fd4a388fc80172b7",
            "commit_sha":"6b96a9060069302996b5af47fd4a388fc80172b7",
            "patch":"SINGLE",
            "chain_ord":"['6b96a9060069302996b5af47fd4a388fc80172b7']",
            "before_first_fix_commit":"{'d1e5fc7d3708d877353ca64dd4aa7cfd1cde4cb4', '31de9139d0aabc171e94032168399b4a0b2a88a2'}",
            "last_fix_commit":"6b96a9060069302996b5af47fd4a388fc80172b7",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/08\/2020, 16:21:56",
            "message":"Merge pull request from GHSA-52q8-877j-gghq\n\nsecurity: fix remote code execution via cache action, CVE-2020-25074",
            "author":"TW",
            "comments":null,
            "stats":"{'additions': 20, 'deletions': 7, 'total': 27}",
            "files":"{'MoinMoin\/action\/cache.py': {'additions': 20, 'deletions': 7, 'changes': 27, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/moinwiki\/moin-1.9\/raw\/6b96a9060069302996b5af47fd4a388fc80172b7\/MoinMoin%2Faction%2Fcache.py', 'patch': \"@@ -103,6 +103,19 @@ def key(request, wikiname=None, itemname=None, attachname=None, content=None, se\\n     return key\\n \\n \\n+def valid_key(key):\\n+    # make sure the key looks like keys generated by key()\\n+    if not isinstance(key, unicode):\\n+        # key is None (not given in url args) or something unexpected\\n+        return False\\n+    try:\\n+        int(key, 16)  # try to evaluate as hex number\\n+    except ValueError:\\n+        # was not a hex number\\n+        return False\\n+    return len(key) == 40  # hmac-sha1 hexdigest == 40 hex chars\\n+\\n+\\n def put(request, key, data,\\n         filename=None,\\n         content_type=None,\\n@@ -234,14 +247,14 @@ def _do_remove(request, key):\\n     remove(request, key)\\n \\n \\n-def _do(request, do, key):\\n-    if do == 'get':\\n-        _do_get(request, key)\\n-    elif do == 'remove':\\n-        _do_remove(request, key)\\n-\\n def execute(pagename, request):\\n     do = request.values.get('do')\\n     key = request.values.get('key')\\n-    _do(request, do, key)\\n+    valid = valid_key(key)  # validate untrusted input\\n+    if valid and do == 'get':\\n+        _do_get(request, key)\\n+    elif valid and do == 'remove':\\n+        _do_remove(request, key)\\n+    else:\\n+        request.status_code = 404\"}}",
            "message_norm":"merge pull request from ghsa-52q8-877j-gghq\n\nsecurity: fix remote code execution via cache action, cve-2020-25074",
            "language":"en",
            "entities":"[('ghsa-52q8-877j-gghq', 'VULNID', 'GHSA'), ('security', 'SECWORD', ''), ('fix', 'ACTION', ''), ('remote code execution', 'SECWORD', ''), ('cve-2020-25074', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['MoinMoin\/action\/cache.py'])",
            "num_files":1.0
        },
        {
            "index":1966,
            "vuln_id":"GHSA-h2wq-prv9-2f56",
            "cwe_id":"{'CWE-20'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/098e7762d909bac47ce1dbabe6dfd06294cb9d58'}",
            "dataset":"osv",
            "summary":"Missing validation crashes `QuantizeAndDequantizeV4Grad` ### Impact\nThe implementation of [`tf.raw_ops.QuantizeAndDequantizeV4Grad`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f3b9bf4c3c0597563b289c0512e98d4ce81f886e\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc#L148-L226) does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=tf.constant(1, shape=[2,2], dtype=tf.float64),\n  input=tf.constant(1, shape=[2,2], dtype=tf.float64),\n  input_min=tf.constant([], shape=[0], dtype=tf.float64),\n  input_max=tf.constant(-10, shape=[], dtype=tf.float64),\n  axis=-1)\n```\n\nThe code assumes `input_min` and `input_max` are scalars but there is no validation for this.\n\n### Patches\nWe have patched the issue in GitHub commit [098e7762d909bac47ce1dbabe6dfd06294cb9d58](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/098e7762d909bac47ce1dbabe6dfd06294cb9d58).\n    \nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Neophytos Christou from Secure Systems Lab at Brown University.",
            "published_date":"2022-05-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/098e7762d909bac47ce1dbabe6dfd06294cb9d58",
            "commit_sha":"098e7762d909bac47ce1dbabe6dfd06294cb9d58",
            "patch":"SINGLE",
            "chain_ord":"['098e7762d909bac47ce1dbabe6dfd06294cb9d58']",
            "before_first_fix_commit":"{'e505acc64062d9250ad4452ce57529bed8fd2160'}",
            "last_fix_commit":"098e7762d909bac47ce1dbabe6dfd06294cb9d58",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 18:06:02",
            "message":"Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280",
            "author":"Alan Liu",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 2, 'total': 10}",
            "files":"{'tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc': {'additions': 8, 'deletions': 2, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/098e7762d909bac47ce1dbabe6dfd06294cb9d58\/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -174,13 +174,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\\n     OP_REQUIRES(ctx,\\n                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\\n                 errors::InvalidArgument(\\n-                    \"Input min tensor must have dimension 1. Recieved \",\\n+                    \"Input min tensor must have dimension 0 or 1. Received \",\\n                     input_min_tensor.dims(), \".\"));\\n     const Tensor& input_max_tensor = ctx->input(3);\\n     OP_REQUIRES(ctx,\\n                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\\n                 errors::InvalidArgument(\\n-                    \"Input max tensor must have dimension 1. Recieved \",\\n+                    \"Input max tensor must have dimension 0 or 1. Received \",\\n                     input_max_tensor.dims(), \".\"));\\n     if (axis_ != -1) {\\n       OP_REQUIRES(\\n@@ -203,6 +203,12 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\\n                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));\\n \\n     if (axis_ == -1) {\\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),\\n+                  errors::InvalidArgument(\\n+                      \"input_min must be a scalar if axis is unspecified\"));\\n+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),\\n+                  errors::InvalidArgument(\\n+                      \"input_max must be a scalar if axis is unspecified\"));\\n       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\\n       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\\n         input.template flat<T>(), input_min_tensor.scalar<T>(),'}}",
            "message_norm":"fix tf.raw_ops.quantizeanddequantizev4grad vulnerability with invalid input_min or input_max.\n\ncheck that argument is actually a scalar before treating it as such.\n\npiperorigin-revid: 445198280",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('445198280', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc'])",
            "num_files":1.0
        },
        {
            "index":1972,
            "vuln_id":"GHSA-h3fg-h5v3-vf8m",
            "cwe_id":"{'CWE-352'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/solidusio\/solidus\/commit\/a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6', 'https:\/\/github.com\/solidusio\/solidus\/commit\/4d17cacf066d9492fc04eb3a0b16084b47376d81'}",
            "dataset":"osv",
            "summary":"CSRF forgery protection bypass in solidus_frontend ### Impact\nCSRF vulnerability that allows a malicious site to add an item to the user's cart without their knowledge.\n\nAll `solidus_frontend` versions are affected. If you're using your own storefront, please, follow along to make sure you're not affected.\n\nTo reproduce the issue:\n\n- Pick the id for a variant with available stock. From the rails console:\n\n  ```ruby\n  Spree::Variant.in_stock.pluck(:id)\n  ```\n\n  Say we pick variant id `2`.\n\n- Launch your application, for instance, on `http:\/\/localhost:3000`:\n\n  ```bash\n  bin\/rails server\n  ```\n\n- Open your browser dev tools.\n\n- Click on whatever link in your store.\n\n- Copy the value of the `Cookie` request header sent for the previous request from your browser dev tools.\n\n- Execute the following, using your previously selected variant id and the value of the `Cookie` header (notice how it doesn't contain any authentication token):\n\n  ```bash\n  curl -X POST -d \"variant_id=2&quantity=1\" -H \"Cookie: guest_token=eyJfcmFpbHMiOnsibWVzc2FnZSI6IklrWlRVMWRQWnpKMVZVdFNXRzlPVW1aaWJHTjZZa0VpIiwiZXhwIjpudWxsLCJwdXIiOiJjb29raWUuZ3Vlc3RfdG9rZW4ifX0%3D--5006ba5d346f621c760a29b6a797bf351d17d1b8; _sandbox_session=vhutu5%2FL9NmWrUpGc3DxrFA%2FFsQD1dHn1cNsD7nvE84zcjWf17Af4%2F%2F2Vab3md71b6KTb9NP6WktdXktpwH4eU01jEGIBXG5%2BMzW5nL0nb4W269qk1io4LYljvoOg8%2BZVll7oJCVkJLKKh0sSoS0Kg8j%2FCHHs%2BsShohP%2BGnA%2Bfr9Ub8H6HofpSmloSpsfHHygmX0ho03fEgzHJ4DD5wJctaNKwg7NhVikHh5kgIPPHl84OGCgv3p2oe9jR19HTxOKq7BtyvDd7XZsecWhkcfS8BPnvDDUWZG6qpAEFI5kWo81KkpSJ%2Bp6Q1HOo8%3D--n3G2vgaDG7VS%2B%2FhF--ZTjxBAkfGG3hpr4GRQ2S1Q%3D%3D; __profilin=p%3Dt\" http:\/\/localhost:3000\/orders\/populate\n  ```\n\n- Reload your browser and look at how your cart got updated.\n\n### Patches\n\nPlease, upgrade `solidus` to versions `3.1.5`, `3.0.5` or `2.11.14`.\n\nAfter upgrading, make sure you read the \"Upgrade notes\"  section below.\n\n### Upgrade notes\n\nThe patch adds CSRF token verification to the \"Add to cart\" action. Adding forgery protection to a form that missed it can have some side effects.\n\n#### `InvalidAuthenticityToken` errors\n\nIf you're using the `:exception` strategy, it's likely that after upgrading, you'll see more `ActionController::InvalidAuthenticityToken` errors popping out in your logs. Due to browser-side cache, a form can be re-rendered and sent without any attached request cookie (for instance, when re-opening a mobile browser). That will cause an authentication error, as the sent token won't match with the one in the session (none in this case). That's a known problem in the Rails community (see https:\/\/github.com\/rails\/rails\/issues\/21948), and, at this point, there's no perfect solution.\n\nAny attempt to mitigate the issue should be seen at the application level. For an excellent survey of all the available options, take a look at https:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md. The latter is a third-party link. As the information is relevant here, we're going to copy it below, but it should be clear that all the credit goes to @kemenaran:\n\n> # Protecting against request forgery using CRSF tokens\n> \n> ## Context\n> \n> Rails has CSRF protection enabled by default, to protect against POST-based CSRF attacks.\n> \n> To protect from this, Rails stores two copies of a random token (the so-named CSRF token) on each request:\n> - one copy embedded in each HTML page,\n> - another copy in the user session.\n> \n> When performing a POST request, Rails checks that the two copies match \u2013 and otherwise denies the request. This protects against an attacker that would generate a form secretly pointing to our website: the attacker can't read the token in the session, and so can't post a form with a valid token.\n> \n> The problem is that, much more often, this has false positives. There are several cases for that, including:\n> \n> 1. The web browser (often mobile) loads a page containing a form, then is closed by the user. Later, when the browser is re-opened, it restores the page from the cache. But the session cookie has expired, and so is not restored \u2013 so the copy of the CSRF token stored in the session is missing. When the user submits the form, they get an \"InvalidAuthenticityToken\" exception.\n> \n> 2. The user attempts to fill a form, and gets an error message (usually in response to a POST request). They close the browser. When the browser is re-opened, it attempts to restore the page. On Chrome this is blocked by the browser, because the browser denies retrying a (probably non-idempotent) POST request. Safari however happily retries the POST request \u2013 but without sending any cookies (in an attempt to avoid having unexpected side-effects). So the copy of the CSRF token in the session is missing (because no cookie was sent), and the user get an \"InvalidAuthenticityToken\" exception.\n> \n> ## Options considered\n> \n> ### Extend the session cookie duration\n> \n> We can configure the session cookie to be valid for a longer time (like 2 weeks).\n> \n> Pros:\n> - It solves 1., because when the browser restores the page, the session cookie is still valid.\n> \n> Cons:\n> - Users would be signed-in for a much longer time by default, which has unacceptable security implications.\n> - It doesn't solve 2. (because Safari doesn't send any cookie when restoring a page from a POST request)\n> \n> ### Change the cache parameters\n> \n> We can send a HTTP cache header stating 'Cache-Control: no-store, no-cache'. This instructs the browser to never keep any copy of the page, and to always make a request to the server to restore it.\n> \n> This solution was attempted during a year in production, and solved 1. \u2013 but also introduced another type of InvalidAuthenticityToken errors. In that scenario, the user attempts to fill a form, and gets an error message (usually in response to a POST request). They then navigate on another domain (like France Connect), then hit the \"Back\" button. Crossing back the domain boundary may cause the browser to either block the request or retry an invalid POST request.\n> \n> Pros:\n> - It solves 1., because on relaunch the browser requests a fresh page again (instead of serving it from its cache), thus retrieving a fresh session and a fresh matching CSRF token.\n> \n> Cons:\n> - It doesn't solve 2.\n> - It causes another type of InvalidAuthenticityToken errors.\n> \n> ### Using a null-session strategy\n> \n> We can change the default protect_from_forgery strategy to :null_session. This makes the current request use an empty session for the request duration.\n> \n> Pros:\n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted.\n> \n> Cons:\n> - The user is asked to sign-in only after filling and submitting the form, losing their time and data\n> - The user will not be redirected to their original page after signing-in\n> - It has potential security implications: as the (potentically malicious) request runs anyway, variables cached by a controller before the Null session is created may allow the form submission to succeed anyway (https:\/\/www.veracode.com\/blog\/managing-appsec\/when-rails-protectfromforgery-fails)\n> \n> ### Using a reset-session strategy\n> \n> We can change the default protect_from_forgery strategy to :reset_session. This clears the user session permanently, logging them out until they log in again.\n> \n> Pros: \n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted.\n> \n> Cons:\n> - A forgery error in a browser tab will disconnect the user in all its open tabs\n> - It has potential security implications: as the (potentically malicious) request runs anyway, variables cached by a controller before the Null session is created may allow the form submission to succeed anyway (https:\/\/www.veracode.com\/blog\/managing-appsec\/when-rails-protectfromforgery-fails)\n> - It allows an attacker to disconnect an user on demand, which is not only inconvenient, but also has security implication (the attacker could then log the user on it's own attacker account, pretending to be the user account)\n> \n> ### Redirect to login form\n> \n> When a forgery error occurs, we can instead redirect to the login form.\n> \n> Pros:\n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted (but the user data is lost).\n> - It kind of solves 2., by redirecting to a \"Please sign-in\" page when a previously POSTed form is reloaded.\n> \n> Cons:\n> - Not all forms require authentication \u2013 so for public forms there is no point redirecting to the login form. \n> - The user will not be redirected to their original page after signing-in (because setting the redirect path is a state-changing action, and it is dangerous to let an unauthorized request changing the state \u2013 an attacker could control the path where an user is automatically redirected to.)\n> - The implementation is finicky, and may introduce security errors. For instance, a naive implementation that catches the exception and redirect_to the sign-in page will prevent Devise from running a cleanup code \u2013 which means the user will still be logged, and the CSRF protection is bypassed. However a well-tested implementation that lets Devise code run should avoid these pittfalls.\n> \n> ### Using a long-lived cookie for CSRF tokens\n> \n> Instead of storing the CSRF token in the session cookie (which is deleted when the browser is closed), we can instead store it in a longer-lived cookie. For this we need to patch Rails.\n> \n> Pros:\n> - It solves 1., because when the user submits a stale form, even if the session cookie because stale, the long-lived CSRF cookie is still valid.\n> \n> Cons:\n> - It doesn't solve 2., because when Safari retries a POST request, it sends none of the cookies (not even long-lived ones).\n> - Patching Rails may introduce security issues (now or in the future)\n\n#### Broken behavior due to session expiration + template cache\n\nAlthough pretty unlikely, you should make sure that your current setup for cache\/session expiration is compatible. The upgrade can break the addition of products to the cart if both:\n\n- The \"Add to cart\" form is being cached (usually along with the variant information).\n\n- A user session is reset at every or every few requests.\n\nThe token validation depends on the issuing and consuming sessions being the same. If a product page is cached with the token in it, it can become stale on a subsequent rendering if the session changes.\n\nTo check that you're safe, after having upgraded locally, go through the following steps:\n\n- Enable cache on dev mode:\n\n  ```bash\n  bin\/rails dev:cache\n  ```\n\n- Visit the page for a variant with stock.\n\n- Reload that page several times.\n\n- Click on the \"Add to cart\"  button.\n\n- Remember to rerun `bin\/rails dev:cache` to turn off cache again.\n\nNo error or session reset should happen.\n\nOtherwise, you can try with:\n\n- Revisiting how your session gets expired.\n- Changing the caching strategy to exclude the token.\n\n#### Using weaker CSRF protection strategies\n\nIt's also important to understand that a complete fix will only be in place when using the `:exception` forgery protection strategy. The `solidus_frontend` engine can't do pretty much anything otherwise. Using weaker CSRF strategies should be an informed and limited decision made by the application team. After the upgrade:\n\n- An app using `:null_session` should also be safe, but there will be side effects. That strategy runs with a null object session. As such, no order and no user is found on it. A new `cart` state order is created in the database, associated with no user. Next time the user visits the site, they won't find any difference in its cart state.\n\n- An app using `:reset_session` is not entirely safe. That strategy resets the session. That means that registered users will be logged out. Next time a user visits, they'll see the cart with the items added during the CSRF attack, although it won't be associated with their account in the case of registered users.\n\n#### Reversing the update\n\nIf you still want to deploy the upgraded version before changing your application code (if the latter is needed), you can add the following workaround to your `config\/application.rb` (however, take into account that you'll keep being vulnerable):\n\n```ruby\nconfig.after_initialize do\n  Spree::OrdersController.skip_before_action :verify_authenticity_token, only: [:populate]\nend\n```\n\n### Workarounds\n\nIf an upgrade is not an option, you can work around the issue by adding the following to `config\/application.rb`:\n\n```ruby\nconfig.after_initialize do\n  Spree::OrdersController.protect_from_forgery with: ApplicationController.forgery_protection_strategy.name.demodulize.underscore.to_sym, only: [:populate]\nend\n```\n\nHowever, go through the same safety check detailed on \"Upgrade notes\" above.\n\n### References\n\n- [CSRF on the Rails guides](https:\/\/guides.rubyonrails.org\/security.html#cross-site-request-forgery-csrf)\n- [How CSRF tokens are generated and validated on Rails](https:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef)\n- [Solidus security](https:\/\/solidus.io\/security\/)\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an [issue](https:\/\/github.com\/solidusio\/solidus\/issues) or a [discussion](https:\/\/github.com\/solidusio\/solidus\/discussions) in Solidus.\n* Email us at [security@solidus.io](mailto:security@soliidus.io)\n* Contact the core team on [Slack](http:\/\/slack.solidus.io\/)",
            "published_date":"2022-01-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/solidusio\/solidus",
            "commit_href":"https:\/\/github.com\/solidusio\/solidus\/commit\/a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6",
            "commit_sha":"a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6",
            "patch":"MULTI",
            "chain_ord":"['4d17cacf066d9492fc04eb3a0b16084b47376d81', 'a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6']",
            "before_first_fix_commit":"{'4d17cacf066d9492fc04eb3a0b16084b47376d81', 'c6b892696881f88d209efaedd8bb378e8261953f'}",
            "last_fix_commit":"a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6",
            "chain_ord_pos":2.0,
            "commit_datetime":"12\/20\/2021, 08:25:33",
            "message":"Merge pull request from GHSA-h3fg-h5v3-vf8m\n\nProtect `Spree::OrdersController#populate` against CSRF attacks",
            "author":"Marc Busqu\u00e9",
            "comments":null,
            "stats":"{'additions': 0, 'deletions': 1, 'total': 1}",
            "files":"{'frontend\/app\/controllers\/spree\/orders_controller.rb': {'additions': 0, 'deletions': 1, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/solidusio\/solidus\/raw\/a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6\/frontend%2Fapp%2Fcontrollers%2Fspree%2Forders_controller.rb', 'patch': \"@@ -10,7 +10,6 @@ class OrdersController < Spree::StoreController\\n     before_action :assign_order, only: :update\\n     # note: do not lock the #edit action because that's where we redirect when we fail to acquire a lock\\n     around_action :lock_order, only: :update\\n-    skip_before_action :verify_authenticity_token, only: [:populate]\\n \\n     def show\\n       @order = Spree::Order.find_by!(number: params[:id])\"}}",
            "message_norm":"merge pull request from ghsa-h3fg-h5v3-vf8m\n\nprotect `spree::orderscontroller#populate` against csrf attacks",
            "language":"en",
            "entities":"[('ghsa-h3fg-h5v3-vf8m', 'VULNID', 'GHSA'), ('protect', 'ACTION', ''), ('csrf', 'SECWORD', ''), ('attacks', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['frontend\/app\/controllers\/spree\/orders_controller.rb'])",
            "num_files":1.0
        },
        {
            "index":3133,
            "vuln_id":"GHSA-vjj6-5m9f-wqjw",
            "cwe_id":"{'CWE-476'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/hyperledger\/fabric\/pull\/2838\/commits\/ebf94b10ecc86d3a91619b98befc52277b1e3474'}",
            "dataset":"osv",
            "summary":"NULL Pointer Dereference in HyperLedger Fabric A vulnerability has been detected in HyperLedger Fabric v1.4.0, v2.0.0, v2.1.0. This bug can be leveraged by constructing a message whose payload is nil and sending this message with the method 'forwardToLeader'. This bug has been admitted and fixed by the developers of Fabric. If leveraged, any leader node will crash.",
            "published_date":"2022-05-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/hyperledger\/fabric",
            "commit_href":"https:\/\/github.com\/hyperledger\/fabric\/pull\/2838\/commits\/ebf94b10ecc86d3a91619b98befc52277b1e3474",
            "commit_sha":"ebf94b10ecc86d3a91619b98befc52277b1e3474",
            "patch":"SINGLE",
            "chain_ord":"['ebf94b10ecc86d3a91619b98befc52277b1e3474']",
            "before_first_fix_commit":"{'bb8bada7b864d4135aafe1785674be31d6cc78cb'}",
            "last_fix_commit":"ebf94b10ecc86d3a91619b98befc52277b1e3474",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/18\/2021, 14:18:10",
            "message":"FAB18529 added nil check in channel header parsing\n\nFuzz testing has reported SEGV while sending incomplete\/null\nmessage request to orderer.\n\nSigned-off-by: Parameswaran Selvam <parselva@in.ibm.com>",
            "author":"Parameswaran Selvam",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'protoutil\/commonutils.go': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hyperledger\/fabric\/raw\/ebf94b10ecc86d3a91619b98befc52277b1e3474\/protoutil%2Fcommonutils.go', 'patch': '@@ -212,6 +212,10 @@ func IsConfigBlock(block *cb.Block) bool {\\n \\n \/\/ ChannelHeader returns the *cb.ChannelHeader for a given *cb.Envelope.\\n func ChannelHeader(env *cb.Envelope) (*cb.ChannelHeader, error) {\\n+\\tif env == nil {\\n+\\t\\treturn nil, errors.New(\"Invalid envelope payload. can\\'t be nil\")\\n+\\t}\\n+\\n \\tenvPayload, err := UnmarshalPayload(env.Payload)\\n \\tif err != nil {\\n \\t\\treturn nil, err'}}",
            "message_norm":"fab18529 added nil check in channel header parsing\n\nfuzz testing has reported segv while sending incomplete\/null\nmessage request to orderer.\n\nsigned-off-by: parameswaran selvam <parselva@in.ibm.com>",
            "language":"en",
            "entities":"[('fab18529', 'SHA', 'generic_sha'), ('added', 'ACTION', ''), ('fuzz', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['protoutil\/commonutils.go'])",
            "num_files":1.0
        },
        {
            "index":2472,
            "vuln_id":"GHSA-mvqp-q37c-wf9j",
            "cwe_id":"{'CWE-74'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/ratpack\/ratpack\/commit\/c560a8d10cb8bdd7a526c1ca2e67c8f224ca23ae', 'https:\/\/github.com\/ratpack\/ratpack\/commit\/efb910d38a96494256f36675ef0e5061097dd77d'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects io.ratpack:ratpack-core ## CWE-113: Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting')\n\nVersions of Ratpack 0.9.1 through and including 1.7.4 are vulnerable to [HTTP Response Splitting](https:\/\/www.owasp.org\/index.php\/HTTP_Response_Splitting), \nif untrusted and unsanitized data is used to populate the headers of an HTTP response.\nAn attacker can utilize this vulnerability to have the server issue any HTTP response they specify.\n\nIf your application uses arbitrary user input as the value of a response header it is vulnerable.\nIf your application does not use arbitrary values as response header values, it is not vulnerable.\n\nPreviously, Ratpack did not validate response header values.\nNow, adding a header value that contains the header value termination characters (CRLF) produces a runtime exception.\nSince there is no mechanism for escaping or encoding the termination characters in a String, a runtime exception is necessary.\n\nAs potentially dangerous values now cause runtime exceptions, it is a good idea to continue to validate and sanitize any user-supplied values being used as response headers.\n\nWe would like to thank [Jonathan Leitschuh](https:\/\/github.com\/JLLeitschuh) for reporting this vulnerability.\n\n### Vulnerable Example\n\nThe following example server uses a query parameter value as a response header, without validating or sanitizing it.\n```java\nRatpackServer startedServer =  RatpackServer.start(server -> {\n    server.handlers(chain -> chain.all(ctx -> {\n        \/\/ User supplied query parameter\n        String header = ctx.getRequest().getQueryParams().get(\"header\");\n        \/\/ User supplied data used to populate a header value.\n        ctx.header(\"the-header\", header)\n            .render(\"OK!\");\n    }));\n});\n```\n\nSending a request to the server with the following value for the `header` query param would allow the execution of arbitrary Javascript.\n\n```\nContent-Type: text\/html\nX-XSS-Protection: 0\n\n<script>alert(document.domain)<\/script>\n```\n\n### Impact\n\n- Cross-User Defacement\n- Cache Poisoning\n- Cross-Site Scripting\n- Page Hijacking\n\n### Patches\n\nThis vulnerability has been patched in Ratpack version 1.7.5.\n\n### Root Cause\n\nThe root cause was due to using the netty `DefaultHttpHeaders` object with verification disabled.\n\nhttps:\/\/github.com\/ratpack\/ratpack\/blob\/af1e8c8590f164d7dd84d4212886fad4ead99080\/ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java#L159\n\nThis vulnerability is now more clearly documented in the Netty documentation: https:\/\/github.com\/netty\/netty\/pull\/9646\n\n### Workarounds\n\nThe workaround for this vulnerability is to either not use arbitrary input as response header values or validate such values before being used to ensure they don't contain a carriage return and\/or line feed characters.\n\n### References\n\n - [CWE-113: Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting')](https:\/\/cwe.mitre.org\/data\/definitions\/113.html)\n - Fix commit: https:\/\/github.com\/ratpack\/ratpack\/commit\/efb910d38a96494256f36675ef0e5061097dd77d\n \n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an issue in [ratpack\/ratpack](https:\/\/github.com\/ratpack\/ratpack\/issues)\n* Ask in our [Slack channel](https:\/\/slack-signup.ratpack.io\/)",
            "published_date":"2019-10-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/ratpack\/ratpack",
            "commit_href":"https:\/\/github.com\/ratpack\/ratpack\/commit\/efb910d38a96494256f36675ef0e5061097dd77d",
            "commit_sha":"efb910d38a96494256f36675ef0e5061097dd77d",
            "patch":"MULTI",
            "chain_ord":"['efb910d38a96494256f36675ef0e5061097dd77d', 'c560a8d10cb8bdd7a526c1ca2e67c8f224ca23ae']",
            "before_first_fix_commit":"{'efb910d38a96494256f36675ef0e5061097dd77d'}",
            "last_fix_commit":"c560a8d10cb8bdd7a526c1ca2e67c8f224ca23ae",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/08\/2019, 23:24:24",
            "message":"Enable HTTP header validation",
            "author":"Luke Daley",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ratpack\/ratpack\/raw\/efb910d38a96494256f36675ef0e5061097dd77d\/ratpack-core%2Fsrc%2Fmain%2Fjava%2Fratpack%2Fserver%2Finternal%2FNettyHandlerAdapter.java', 'patch': '@@ -156,7 +156,7 @@ private void newRequest(ChannelHandlerContext ctx, HttpRequest nettyRequest) thr\\n       channel.attr(CLIENT_CERT_KEY).get()\\n     );\\n \\n-    HttpHeaders nettyHeaders = new DefaultHttpHeaders(false);\\n+    HttpHeaders nettyHeaders = new DefaultHttpHeaders();\\n     MutableHeaders responseHeaders = new NettyHeadersBackedMutableHeaders(nettyHeaders);\\n     AtomicBoolean transmitted = new AtomicBoolean(false);'}}",
            "message_norm":"enable http header validation",
            "language":"nl",
            "entities":"[('header validation', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java'])",
            "num_files":1.0
        },
        {
            "index":3137,
            "vuln_id":"GHSA-vjxv-45g9-9296",
            "cwe_id":"{'CWE-347'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/sigstore\/cosign\/commit\/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94'}",
            "dataset":"osv",
            "summary":"cosign's `cosign verify-attestaton  --type` can report a false positive if any attestation exists `cosign verify-attestation` used with the `--type` flag will report a false positive verification when:\n\n- There is at least one attestation with a valid signature\n- There are NO attestations of the type being verified (--type defaults to \"custom\")\n\nThis can happen when signing with a standard keypair and with \"keyless\" signing with Fulcio. Users should upgrade to cosign version 1.10.1 or greater for a patch. Currently the only workaround is to upgrade.",
            "published_date":"2022-08-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/sigstore\/cosign",
            "commit_href":"https:\/\/github.com\/sigstore\/cosign\/commit\/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
            "commit_sha":"c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
            "patch":"SINGLE",
            "chain_ord":"['c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94']",
            "before_first_fix_commit":"{'641f02b146816da54f112e1c1227747da17e5020'}",
            "last_fix_commit":"c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/04\/2022, 16:05:27",
            "message":"Merge pull request from GHSA-vjxv-45g9-9296\n\nToday the verification logic:\n1. Verifies signatures on attestations (at least one must verify, or it errors),\n2. All attestations matching the specified `--type` must pass any specified Cue\/Rego policies,\n3. *All* signature-verified attestations are then printed.\n\nHowever, if NONE of the attestations match the specified `--type` then `2.` is considered satisfied and we proceed to `3.`\n\nThis changes the above logic to:\n1. Same.\n2. Same, but these are put into a `checked` list,\n3. `checked` must be non-empty (or an error is printed about no attestations matching `--type`),\n4. *Just* the `checked` attestations are printed.\n\n---\n\nThe bug at HEAD:\n```shell\n$ cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nVerification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - Any certificates were verified against the Fulcio roots.\nCertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\nCertificate issuer URL:  https:\/\/token.actions.githubusercontent.com\nCertificate extension GitHub Workflow Trigger: schedule\nCertificate extension GitHub Workflow SHA: 7e7572e578de7c51a2f1a1791f025cf315503aa2\nCertificate extension GitHub Workflow Name: Create Release\nCertificate extension GitHub Workflow Trigger distroless\/static\nCertificate extension GitHub Workflow Ref: refs\/heads\/main\n{\"payloadType\":\"application\/vnd.in-toto+json\",\"payload\":\"eyJfdHlwZSI6Imh0dHBzOi8vaW4tdG90by5pby9TdGF0ZW1lbnQvdjAuMSIsInByZWRpY2F0ZVR5cGUiOiJjb3NpZ24uc2lnc3RvcmUuZGV2L2F0dGVzdGF0aW9uL3Z1bG4vdjEiLCJzdWJqZWN0IjpbeyJuYW1lIjoiZ2hjci5pby9kaXN0cm9sZXNzL3N0YXRpYyIsImRpZ2VzdCI6eyJzaGEyNTYiOiJkZDc2MTRiNWExMmJjNGQ2MTdiMjIzYzU4OGI0ZTBjODMzNDAyYjhmNDk5MWZiNTcwMmVhODNhZmFkMTk4NmUyIn19XSwicHJlZGljYXRlIjp7Imludm9jYXRpb24iOnsicGFyYW1ldGVycyI6bnVsbCwidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2Rpc3Ryb2xlc3Mvc3RhdGljL2FjdGlvbnMvcnVucy8yNzc5MjEyNzA1IiwiZXZlbnRfaWQiOiIyNzc5MjEyNzA1IiwiYnVpbGRlci5pZCI6IkNyZWF0ZSBSZWxlYXNlIn0sInNjYW5uZXIiOnsidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2FxdWFzZWN1cml0eS90cml2eSIsInZlcnNpb24iOiIwLjI5LjIiLCJkYiI6eyJ1cmkiOiIiLCJ2ZXJzaW9uIjoiIn0sInJlc3VsdCI6eyIkc2NoZW1hIjoiaHR0cHM6Ly9qc29uLnNjaGVtYXN0b3JlLm9yZy9zYXJpZi0yLjEuMC1ydG0uNS5qc29uIiwicnVucyI6W3siY29sdW1uS2luZCI6InV0ZjE2Q29kZVVuaXRzIiwib3JpZ2luYWxVcmlCYXNlSWRzIjp7IlJPT1RQQVRIIjp7InVyaSI6ImZpbGU6Ly8vIn19LCJyZXN1bHRzIjpbXSwidG9vbCI6eyJkcml2ZXIiOnsiZnVsbE5hbWUiOiJUcml2eSBWdWxuZXJhYmlsaXR5IFNjYW5uZXIiLCJpbmZvcm1hdGlvblVyaSI6Imh0dHBzOi8vZ2l0aHViLmNvbS9hcXVhc2VjdXJpdHkvdHJpdnkiLCJuYW1lIjoiVHJpdnkiLCJydWxlcyI6W10sInZlcnNpb24iOiIwLjI5LjIifX19XSwidmVyc2lvbiI6IjIuMS4wIn19LCJtZXRhZGF0YSI6eyJzY2FuU3RhcnRlZE9uIjoiMjAyMi0wOC0wMlQwMjozMzo0N1oiLCJzY2FuRmluaXNoZWRPbiI6IjIwMjItMDgtMDJUMDI6MzM6NTNaIn19fQ==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"MEYCIQCovBtLOBXyB2zpvhp3j6QzqLtsH0\/RC7fRINSApySqxAIhAIKlzu1fXuKPPOIheNnsPmBOB6XfZbRs5sDW1yFSch1A\"}]}\n```\n\nThe same with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\nError: none of the attestations matched the predicate type: spdx\nmain.go:62: error during command execution: none of the attestations matched the predicate type: spdx\nexit status 1\n```\n\nA valid `--type` with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type vuln ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nVerification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - Any certificates were verified against the Fulcio roots.\nCertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\nCertificate issuer URL:  https:\/\/token.actions.githubusercontent.com\nCertificate extension GitHub Workflow Trigger: schedule\nCertificate extension GitHub Workflow SHA: 7e7572e578de7c51a2f1a1791f025cf315503aa2\nCertificate extension GitHub Workflow Name: Create Release\nCertificate extension GitHub Workflow Trigger distroless\/static\nCertificate extension GitHub Workflow Ref: refs\/heads\/main\n{\"payloadType\":\"application\/vnd.in-toto+json\",\"payload\":\"eyJfdHlwZSI6Imh0dHBzOi8vaW4tdG90by5pby9TdGF0ZW1lbnQvdjAuMSIsInByZWRpY2F0ZVR5cGUiOiJjb3NpZ24uc2lnc3RvcmUuZGV2L2F0dGVzdGF0aW9uL3Z1bG4vdjEiLCJzdWJqZWN0IjpbeyJuYW1lIjoiZ2hjci5pby9kaXN0cm9sZXNzL3N0YXRpYyIsImRpZ2VzdCI6eyJzaGEyNTYiOiJkZDc2MTRiNWExMmJjNGQ2MTdiMjIzYzU4OGI0ZTBjODMzNDAyYjhmNDk5MWZiNTcwMmVhODNhZmFkMTk4NmUyIn19XSwicHJlZGljYXRlIjp7Imludm9jYXRpb24iOnsicGFyYW1ldGVycyI6bnVsbCwidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2Rpc3Ryb2xlc3Mvc3RhdGljL2FjdGlvbnMvcnVucy8yNzc5MjEyNzA1IiwiZXZlbnRfaWQiOiIyNzc5MjEyNzA1IiwiYnVpbGRlci5pZCI6IkNyZWF0ZSBSZWxlYXNlIn0sInNjYW5uZXIiOnsidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2FxdWFzZWN1cml0eS90cml2eSIsInZlcnNpb24iOiIwLjI5LjIiLCJkYiI6eyJ1cmkiOiIiLCJ2ZXJzaW9uIjoiIn0sInJlc3VsdCI6eyIkc2NoZW1hIjoiaHR0cHM6Ly9qc29uLnNjaGVtYXN0b3JlLm9yZy9zYXJpZi0yLjEuMC1ydG0uNS5qc29uIiwicnVucyI6W3siY29sdW1uS2luZCI6InV0ZjE2Q29kZVVuaXRzIiwib3JpZ2luYWxVcmlCYXNlSWRzIjp7IlJPT1RQQVRIIjp7InVyaSI6ImZpbGU6Ly8vIn19LCJyZXN1bHRzIjpbXSwidG9vbCI6eyJkcml2ZXIiOnsiZnVsbE5hbWUiOiJUcml2eSBWdWxuZXJhYmlsaXR5IFNjYW5uZXIiLCJpbmZvcm1hdGlvblVyaSI6Imh0dHBzOi8vZ2l0aHViLmNvbS9hcXVhc2VjdXJpdHkvdHJpdnkiLCJuYW1lIjoiVHJpdnkiLCJydWxlcyI6W10sInZlcnNpb24iOiIwLjI5LjIifX19XSwidmVyc2lvbiI6IjIuMS4wIn19LCJtZXRhZGF0YSI6eyJzY2FuU3RhcnRlZE9uIjoiMjAyMi0wOC0wMlQwMjozMzo0N1oiLCJzY2FuRmluaXNoZWRPbiI6IjIwMjItMDgtMDJUMDI6MzM6NTNaIn19fQ==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"MEYCIQCovBtLOBXyB2zpvhp3j6QzqLtsH0\/RC7fRINSApySqxAIhAIKlzu1fXuKPPOIheNnsPmBOB6XfZbRs5sDW1yFSch1A\"}]}\n```\n\nSigned-off-by: Matt Moore <mattmoor@chainguard.dev>",
            "author":"Matt Moore",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 1, 'total': 11}",
            "files":"{'cmd\/cosign\/cli\/verify\/verify_attestation.go': {'additions': 10, 'deletions': 1, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sigstore\/cosign\/raw\/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94\/cmd%2Fcosign%2Fcli%2Fverify%2Fverify_attestation.go', 'patch': '@@ -201,6 +201,7 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t}\\n \\t\\t}\\n \\n+\\t\\tvar checked []oci.Signature\\n \\t\\tvar validationErrors []error\\n \\t\\tfor _, vp := range verified {\\n \\t\\t\\tpayload, err := policy.AttestationToPayloadJSON(ctx, c.PredicateType, vp)\\n@@ -217,6 +218,7 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t\\tcueValidationErr := cue.ValidateJSON(payload, cuePolicies)\\n \\t\\t\\t\\tif cueValidationErr != nil {\\n \\t\\t\\t\\t\\tvalidationErrors = append(validationErrors, cueValidationErr)\\n+\\t\\t\\t\\t\\tcontinue\\n \\t\\t\\t\\t}\\n \\t\\t\\t}\\n \\n@@ -225,8 +227,11 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t\\tregoValidationErrs := rego.ValidateJSON(payload, regoPolicies)\\n \\t\\t\\t\\tif len(regoValidationErrs) > 0 {\\n \\t\\t\\t\\t\\tvalidationErrors = append(validationErrors, regoValidationErrs...)\\n+\\t\\t\\t\\t\\tcontinue\\n \\t\\t\\t\\t}\\n \\t\\t\\t}\\n+\\n+\\t\\t\\tchecked = append(checked, vp)\\n \\t\\t}\\n \\n \\t\\tif len(validationErrors) > 0 {\\n@@ -237,10 +242,14 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\treturn fmt.Errorf(\"%d validation errors occurred\", len(validationErrors))\\n \\t\\t}\\n \\n+\\t\\tif len(checked) == 0 {\\n+\\t\\t\\treturn fmt.Errorf(\"none of the attestations matched the predicate type: %s\", c.PredicateType)\\n+\\t\\t}\\n+\\n \\t\\t\/\/ TODO: add CUE validation report to `PrintVerificationHeader`.\\n \\t\\tPrintVerificationHeader(imageRef, co, bundleVerified, fulcioVerified)\\n \\t\\t\/\/ The attestations are always JSON, so use the raw \"text\" mode for outputting them instead of conversion\\n-\\t\\tPrintVerification(imageRef, verified, \"text\")\\n+\\t\\tPrintVerification(imageRef, checked, \"text\")\\n \\t}\\n \\n \\treturn nil'}}",
            "message_norm":"merge pull request from ghsa-vjxv-45g9-9296\n\ntoday the verification logic:\n1. verifies signatures on attestations (at least one must verify, or it errors),\n2. all attestations matching the specified `--type` must pass any specified cue\/rego policies,\n3. *all* signature-verified attestations are then printed.\n\nhowever, if none of the attestations match the specified `--type` then `2.` is considered satisfied and we proceed to `3.`\n\nthis changes the above logic to:\n1. same.\n2. same, but these are put into a `checked` list,\n3. `checked` must be non-empty (or an error is printed about no attestations matching `--type`),\n4. *just* the `checked` attestations are printed.\n\n---\n\nthe bug at head:\n```shell\n$ cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nverification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nthe following checks were performed on each of these signatures:\n  - the cosign claims were validated\n  - existence of the claims in the transparency log was verified offline\n  - any certificates were verified against the fulcio roots.\ncertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\ncertificate issuer url:  https:\/\/token.actions.githubusercontent.com\ncertificate extension github workflow trigger: schedule\ncertificate extension github workflow sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2\ncertificate extension github workflow name: create release\ncertificate extension github workflow trigger distroless\/static\ncertificate extension github workflow ref: refs\/heads\/main\n{\"payloadtype\":\"application\/vnd.in-toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0\/rc7frinsapysqxaihaiklzu1fxukppoihennspmbob6xfzbrs5sdw1yfsch1a\"}]}\n```\n\nthe same with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\nerror: none of the attestations matched the predicate type: spdx\nmain.go:62: error during command execution: none of the attestations matched the predicate type: spdx\nexit status 1\n```\n\na valid `--type` with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type vuln ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nverification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nthe following checks were performed on each of these signatures:\n  - the cosign claims were validated\n  - existence of the claims in the transparency log was verified offline\n  - any certificates were verified against the fulcio roots.\ncertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\ncertificate issuer url:  https:\/\/token.actions.githubusercontent.com\ncertificate extension github workflow trigger: schedule\ncertificate extension github workflow sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2\ncertificate extension github workflow name: create release\ncertificate extension github workflow trigger distroless\/static\ncertificate extension github workflow ref: refs\/heads\/main\n{\"payloadtype\":\"application\/vnd.in-toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0\/rc7frinsapysqxaihaiklzu1fxukppoihennspmbob6xfzbrs5sdw1yfsch1a\"}]}\n```\n\nsigned-off-by: matt moore <mattmoor@chainguard.dev>",
            "language":"en",
            "entities":"[('ghsa-vjxv-45g9-9296', 'VULNID', 'GHSA'), ('verifies', 'ACTION', ''), ('verify', 'ACTION', ''), ('signature', 'SECWORD', ''), ('verified', 'ACTION', ''), ('changes', 'ACTION', ''), ('error', 'FLAW', ''), ('bug', 'FLAW', ''), ('validated', 'ACTION', ''), ('verified', 'ACTION', ''), ('verified', 'ACTION', ''), ('certificate', 'SECWORD', ''), ('https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main', 'URL', ''), ('certificate', 'SECWORD', ''), ('https:\/\/token.actions.githubusercontent.com', 'URL', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2', 'SHA', 'prefix_colon_sha'), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0', 'SECWORD', ''), ('error', 'FLAW', ''), ('error', 'FLAW', ''), ('command execution', 'SECWORD', ''), ('validated', 'ACTION', ''), ('verified', 'ACTION', ''), ('verified', 'ACTION', ''), ('certificate', 'SECWORD', ''), ('https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main', 'URL', ''), ('certificate', 'SECWORD', ''), ('https:\/\/token.actions.githubusercontent.com', 'URL', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2', 'SHA', 'prefix_colon_sha'), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0', 'SECWORD', ''), ('mattmoor@chainguard.dev', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['cmd\/cosign\/cli\/verify\/verify_attestation.go'])",
            "num_files":1.0
        },
        {
            "index":2452,
            "vuln_id":"GHSA-mq5c-prh3-3f3h",
            "cwe_id":"{'CWE-665'}",
            "score":3.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9'}",
            "dataset":"osv",
            "summary":"Invalid validation in `QuantizeAndDequantizeV2` ### Impact\nThe validation in `tf.raw_ops.QuantizeAndDequantizeV2` allows invalid values for `axis` argument:\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([0.0], shape=[1], dtype=float)\ninput_min = tf.constant(-10.0)\ninput_max = tf.constant(-10.0)\n\ntf.raw_ops.QuantizeAndDequantizeV2(\n  input=input_tensor, input_min=input_min, input_max=input_max,\n  signed_input=False, num_bits=1, range_given=False, round_mode='HALF_TO_EVEN',\n  narrow_range=False, axis=-2)\n``` \n\nThe [validation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc#L74-L77) uses `||` to mix two different conditions:\n\n```cc\nOP_REQUIRES(ctx,\n  (axis_ == -1 || axis_ < input.shape().dims()),\n  errors::InvalidArgument(...));\n```\n\nIf `axis_ < -1` the condition in `OP_REQUIRES` will still be true, but this value of `axis_` results in heap underflow. This allows attackers to read\/write to other data on the heap.\n\n### Patches\nWe have patched the issue in GitHub commit [c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9",
            "commit_sha":"c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9",
            "patch":"SINGLE",
            "chain_ord":"['c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9']",
            "before_first_fix_commit":"{'ab6fafc1e32fb20855b7f3a642e36cb08aedbbbf'}",
            "last_fix_commit":"c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/30\/2021, 17:39:05",
            "message":"Fix the CHECK failure in tf.raw_ops.QuantizeAndDequantizeV2.\n\nPiperOrigin-RevId: 371361603\nChange-Id: Ia70e34d41adaadddf928e95e5e5c5c97d5bc60d0",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9\/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -72,6 +72,9 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& input = ctx->input(0);\\n+    OP_REQUIRES(\\n+        ctx, axis_ >= -1,\\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\\n     OP_REQUIRES(\\n         ctx, (axis_ == -1 || axis_ < input.shape().dims()),\\n         errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,'}}",
            "message_norm":"fix the check failure in tf.raw_ops.quantizeanddequantizev2.\n\npiperorigin-revid: 371361603\nchange-id: ia70e34d41adaadddf928e95e5e5c5c97d5bc60d0",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('371361603', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc'])",
            "num_files":1.0
        },
        {
            "index":21,
            "vuln_id":"GHSA-24m3-w8g9-jwpq",
            "cwe_id":"{'CWE-178', 'CWE-200'}",
            "score":3.0,
            "chain":"{'https:\/\/github.com\/simplesamlphp\/simplesamlphp\/commit\/47968d26a2fd3ed52da70dc09210921d612ce44e'}",
            "dataset":"osv",
            "summary":"Information disclosure of source code in SimpleSAMLphp ### Background\n\nThe module controller in `SimpleSAML\\Module` that processes requests for pages\nhosted by modules, has code to identify paths ending with `.php` and process\nthose as PHP code. If no other suitable way of handling the given path exists it\npresents the file to the browser.\n\n### Description\n\nThe check to identify paths ending with `.php` does not account for uppercase\nletters. If someone requests a path ending with e.g. `.PHP` and the server is\nserving the code from a case-insensitive file system, such as on Windows, the\nprocessing of the PHP code does not occur, and the source code is instead\npresented to the browser.\n\n### Affected versions\n\nSimpleSAMLphp versions **1.18.5 and older**.\n\n### Impact\n\nAn attacker may use this issue to gain access to the source code in third-party\nmodules that is meant to be private, or even sensitive. However, the attack\nsurface is considered small, as the attack will only work when SimpleSAMLphp\nserves such content from a file system that is not case-sensitive, such as on\nWindows.\n\n### Resolution\n\nUpgrade the SimpleSAMLphp installation to version **1.18.6**.\n\n### Credit\n\nThis vulnerability was discovered and reported by S\u0142awek Naczy\u0144ski.",
            "published_date":"2020-04-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/simplesamlphp\/simplesamlphp",
            "commit_href":"https:\/\/github.com\/simplesamlphp\/simplesamlphp\/commit\/47968d26a2fd3ed52da70dc09210921d612ce44e",
            "commit_sha":"47968d26a2fd3ed52da70dc09210921d612ce44e",
            "patch":"SINGLE",
            "chain_ord":"['47968d26a2fd3ed52da70dc09210921d612ce44e']",
            "before_first_fix_commit":"{'228e4f2287fd5d73727178b87de7a9652bf1c5b0'}",
            "last_fix_commit":"47968d26a2fd3ed52da70dc09210921d612ce44e",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/16\/2020, 12:17:24",
            "message":"Fix source code disclosure on case-insensitive file systems\n\nIf the file system containing the PHP code is case-insensitive, a\nrequest containing an uppercase file extension will return the\ncontents of the PHP file to the browser instead of executing it.\n\nE.g. a request for this URL will return the source code:\n\n  https:\/sp.example.org\/simplesaml\/module.php\/core\/frontpage_welcome.PHP\n\nFix that by converting the path to lowercase before checking the file\nextension.\n\nSee the following page for details:\n\n  https:\/\/github.com\/simplesamlphp\/simplesamlphp\/security\/advisories\/GHSA-24m3-w8g9-jwpq",
            "author":"Olav Morken",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/SimpleSAML\/Module.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/simplesamlphp\/simplesamlphp\/raw\/47968d26a2fd3ed52da70dc09210921d612ce44e\/lib%2FSimpleSAML%2FModule.php', 'patch': \"@@ -259,7 +259,7 @@ function ($val) {\\n             throw new Error\\\\NotFound('The URL wasn\\\\'t found in the module.');\\n         }\\n \\n-        if (substr($path, -4) === '.php') {\\n+        if (mb_strtolower(substr($path, -4), 'UTF-8') === '.php') {\\n             \/\/ PHP file - attempt to run it\\n \\n             \/* In some environments, $_SERVER['SCRIPT_NAME'] is already set with $_SERVER['PATH_INFO']. Check for that\"}}",
            "message_norm":"fix source code disclosure on case-insensitive file systems\n\nif the file system containing the php code is case-insensitive, a\nrequest containing an uppercase file extension will return the\ncontents of the php file to the browser instead of executing it.\n\ne.g. a request for this url will return the source code:\n\n  https:\/sp.example.org\/simplesaml\/module.php\/core\/frontpage_welcome.php\n\nfix that by converting the path to lowercase before checking the file\nextension.\n\nsee the following page for details:\n\n  https:\/\/github.com\/simplesamlphp\/simplesamlphp\/security\/advisories\/ghsa-24m3-w8g9-jwpq",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('disclosure', 'SECWORD', ''), ('https:\/sp.example.org', 'URL', ''), ('https:\/\/github.com\/simplesamlphp\/simplesamlphp\/security\/advisories\/ghsa-24m3-w8g9-jwpq', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/SimpleSAML\/Module.php'])",
            "num_files":1.0
        },
        {
            "index":2965,
            "vuln_id":"GHSA-rmj8-8hhh-gv5h",
            "cwe_id":"{'CWE-200'}",
            "score":8.0,
            "chain":"{'https:\/\/github.com\/puma\/puma\/commit\/b70f451fe8abc0cff192c065d549778452e155bb'}",
            "dataset":"osv",
            "summary":"Information Exposure when using Puma with Rails ### Impact\nPrior to `puma` version `5.6.2`, `puma` may not always call `close` on the response body. Rails, prior to version `7.0.2.2`, depended on the response body being closed in order for its `CurrentAttributes` implementation to work correctly.\n\nFrom Rails:\n\n> Under certain circumstances response bodies will not be closed, for example a bug in a webserver[1] or a bug in a Rack middleware. In the event a response is not notified of a close, ActionDispatch::Executor will not know to reset thread local state for the next request. This can lead to data being leaked to subsequent requests, especially when interacting with ActiveSupport::CurrentAttributes.\n\nThe combination of these two behaviors (Puma not closing the body + Rails' Executor implementation) causes information leakage.\n\n### Patches\nThis problem is fixed in Puma versions 5.6.2 and 4.3.11.\n\nThis problem is fixed in Rails versions 7.02.2, 6.1.4.6, 6.0.4.6, and 5.2.6.2.\n\nSee: \nhttps:\/\/github.com\/advisories\/GHSA-wh98-p28r-vrc9 \nfor details about the rails vulnerability\n\nUpgrading to a patched Rails _or_ Puma version fixes the vulnerability.\n\n### Workarounds\n\nUpgrade to Rails versions 7.02.2, 6.1.4.6, 6.0.4.6, and 5.2.6.2.\n\nThe [Rails CVE](https:\/\/groups.google.com\/g\/ruby-security-ann\/c\/FkTM-_7zSNA\/m\/K2RiMJBlBAAJ?utm_medium=email&utm_source=footer&pli=1) includes a middleware that can be used instead.\n\n### References\n\n* Rails CVE: [CVE-2022-23633](https:\/\/groups.google.com\/g\/ruby-security-ann\/c\/FkTM-_7zSNA\/m\/K2RiMJBlBAAJ?utm_medium=email&utm_source=footer&pli=1)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [puma](https:\/\/github.com\/puma\/puma)\n* See our [security policy](https:\/\/github.com\/puma\/puma\/security\/policy)",
            "published_date":"2022-02-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/puma\/puma",
            "commit_href":"https:\/\/github.com\/puma\/puma\/commit\/b70f451fe8abc0cff192c065d549778452e155bb",
            "commit_sha":"b70f451fe8abc0cff192c065d549778452e155bb",
            "patch":"SINGLE",
            "chain_ord":"['b70f451fe8abc0cff192c065d549778452e155bb']",
            "before_first_fix_commit":"{'15dd1166ac0750e74720fecee7904e6069ad6d7f'}",
            "last_fix_commit":"b70f451fe8abc0cff192c065d549778452e155bb",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/11\/2022, 14:58:08",
            "message":"Ensure `close` is called on the response body no matter what\n\nAnother fallout from https:\/\/github.com\/puma\/puma\/pull\/2809 is that\nin some cases the `res_body.close` wasn't called because some previous code\nraised.\n\nFor Rails apps it means CurrentAttributes and a few other important\nstates aren't reset properly.\n\nThis is being improved on the Rails side too, but I believe it would\nbe good to harden this on the puma side as well.",
            "author":"Jean Boussier",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 5, 'total': 15}",
            "files":"{'lib\/puma\/request.rb': {'additions': 10, 'deletions': 5, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/puma\/puma\/raw\/b70f451fe8abc0cff192c065d549778452e155bb\/lib%2Fpuma%2Frequest.rb', 'patch': '@@ -171,11 +171,16 @@ def handle_request(client, lines, requests)\\n         end\\n \\n       ensure\\n-        uncork_socket io\\n-\\n-        body.close\\n-        client.tempfile.unlink if client.tempfile\\n-        res_body.close if res_body.respond_to? :close\\n+        begin\\n+          uncork_socket io\\n+\\n+          body.close\\n+          client.tempfile.unlink if client.tempfile\\n+        ensure\\n+          # Whatever happens, we MUST call `close` on the response body.\\n+          # Otherwise Rack::BodyProxy callbacks may not fire and lead to various state leaks\\n+          res_body.close if res_body.respond_to? :close\\n+        end\\n \\n         after_reply.each { |o| o.call }\\n       end'}}",
            "message_norm":"ensure `close` is called on the response body no matter what\n\nanother fallout from https:\/\/github.com\/puma\/puma\/pull\/2809 is that\nin some cases the `res_body.close` wasn't called because some previous code\nraised.\n\nfor rails apps it means currentattributes and a few other important\nstates aren't reset properly.\n\nthis is being improved on the rails side too, but i believe it would\nbe good to harden this on the puma side as well.",
            "language":"en",
            "entities":"[('ensure', 'ACTION', ''), ('https:\/\/github.com\/puma\/puma\/pull\/2809', 'URL', ''), ('improved', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/puma\/request.rb'])",
            "num_files":1.0
        },
        {
            "index":2511,
            "vuln_id":"GHSA-p55x-7x9v-q8m4",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/miekg\/dns\/commit\/43913f2f4fbd7dcff930b8a809e709591e4dd79e'}",
            "dataset":"osv",
            "summary":"Denial of Service in miekg-dns A denial of service flaw was found in miekg-dns before 1.0.4. A remote attacker could use carefully timed TCP packets to block the DNS server from accepting new connections.",
            "published_date":"2021-06-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/miekg\/dns",
            "commit_href":"https:\/\/github.com\/miekg\/dns\/commit\/43913f2f4fbd7dcff930b8a809e709591e4dd79e",
            "commit_sha":"43913f2f4fbd7dcff930b8a809e709591e4dd79e",
            "patch":"SINGLE",
            "chain_ord":"['43913f2f4fbd7dcff930b8a809e709591e4dd79e']",
            "before_first_fix_commit":"{'862243b3b1e77ca9f73771fc95a7148d11cebb55'}",
            "last_fix_commit":"43913f2f4fbd7dcff930b8a809e709591e4dd79e",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/25\/2018, 10:36:19",
            "message":"Fix for CVE-2017-15133 TCP DOS (#631)\n\nserveTCP calls reader.ReadTCP in the accept loop rather than in\r\nthe per-connection goroutine. If an attacker opens a connection\r\nand leaves it idle, this will block the accept loop until the\r\nconnection times out (2s by default). During this time no other\r\nincoming connections will succeed, preventing legitimate queries\r\nfrom being answered.\r\n\r\nThis commit moves the call to reader.ReadTCP into the per-connection\r\ngoroutine. It also adds a missing call to Close whose absence allowed\r\nfile-descirptors to leak in select cases.\r\n\r\nThis attack and fix have no impact on serving UDP queries.",
            "author":"Miek Gieben",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 5, 'total': 13}",
            "files":"{'server.go': {'additions': 8, 'deletions': 5, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/miekg\/dns\/raw\/43913f2f4fbd7dcff930b8a809e709591e4dd79e\/server.go', 'patch': '@@ -472,11 +472,14 @@ func (srv *Server) serveTCP(l net.Listener) error {\\n \\t\\t\\t}\\n \\t\\t\\treturn err\\n \\t\\t}\\n-\\t\\tm, err := reader.ReadTCP(rw, rtimeout)\\n-\\t\\tif err != nil {\\n-\\t\\t\\tcontinue\\n-\\t\\t}\\n-\\t\\tgo srv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\\n+\\t\\tgo func() {\\n+\\t\\t\\tm, err := reader.ReadTCP(rw, rtimeout)\\n+\\t\\t\\tif err != nil {\\n+\\t\\t\\t\\trw.Close()\\n+\\t\\t\\t\\treturn\\n+\\t\\t\\t}\\n+\\t\\t\\tsrv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\\n+\\t\\t}()\\n \\t}\\n }'}}",
            "message_norm":"fix for cve-2017-15133 tcp dos (#631)\n\nservetcp calls reader.readtcp in the accept loop rather than in\r\nthe per-connection goroutine. if an attacker opens a connection\r\nand leaves it idle, this will block the accept loop until the\r\nconnection times out (2s by default). during this time no other\r\nincoming connections will succeed, preventing legitimate queries\r\nfrom being answered.\r\n\r\nthis commit moves the call to reader.readtcp into the per-connection\r\ngoroutine. it also adds a missing call to close whose absence allowed\r\nfile-descirptors to leak in select cases.\r\n\r\nthis attack and fix have no impact on serving udp queries.",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('cve-2017-15133', 'VULNID', 'CVE'), ('dos', 'SECWORD', ''), ('#631', 'ISSUE', ''), ('attacker', 'SECWORD', ''), ('preventing', 'ACTION', ''), ('adds', 'ACTION', ''), ('leak', 'SECWORD', ''), ('attack', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server.go'])",
            "num_files":1.0
        },
        {
            "index":823,
            "vuln_id":"GHSA-6f89-8j54-29xf",
            "cwe_id":"{'CWE-787', 'CWE-119'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/12c727cee857fa19be717f336943d95fca4ffe4f'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `FractionalAvgPoolGrad` ### Impact\nThe implementation of `tf.raw_ops.FractionalAvgPoolGrad` is vulnerable to a heap buffer overflow:\n  \n```python\nimport tensorflow as tf\n\norig_input_tensor_shape = tf.constant([1, 3, 2, 3], shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([2], shape=[1, 1, 1, 1], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\n\n\ntf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/dcba796a28364d6d7f003f6fe733d82726dda713\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc#L216) fails to validate that the pooling sequence arguments have enough elements as required by the `out_backprop` tensor shape.\n\n### Patches\nWe have patched the issue in GitHub commit [12c727cee857fa19be717f336943d95fca4ffe4f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/12c727cee857fa19be717f336943d95fca4ffe4f).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/12c727cee857fa19be717f336943d95fca4ffe4f",
            "commit_sha":"12c727cee857fa19be717f336943d95fca4ffe4f",
            "patch":"SINGLE",
            "chain_ord":"['12c727cee857fa19be717f336943d95fca4ffe4f']",
            "before_first_fix_commit":"{'dcba796a28364d6d7f003f6fe733d82726dda713'}",
            "last_fix_commit":"12c727cee857fa19be717f336943d95fca4ffe4f",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 21:02:47",
            "message":"Validate inputs of `FractionalAvgPoolGrad`.\n\nPiperOrigin-RevId: 372420640\nChange-Id: Icc583928e6cdc3062e12498e4d2337a8fe3da016",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
            "files":"{'tensorflow\/core\/kernels\/fractional_avg_pool_op.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/12c727cee857fa19be717f336943d95fca4ffe4f\/tensorflow%2Fcore%2Fkernels%2Ffractional_avg_pool_op.cc', 'patch': '@@ -250,6 +250,19 @@ class FractionalAvgPoolGradOp : public OpKernel {\\n     const int64 out_cols = out_backprop.dim_size(2);\\n     const int64 out_depth = out_backprop.dim_size(3);\\n \\n+    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\\n+                errors::InvalidArgument(\"Given out_backprop shape \",\\n+                                        out_backprop.shape().DebugString(),\\n+                                        \", row_seq_tensor must have at least \",\\n+                                        out_rows + 1, \" elements, but got \",\\n+                                        row_seq_tensor.NumElements()));\\n+    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\\n+                errors::InvalidArgument(\"Given out_backprop shape \",\\n+                                        out_backprop.shape().DebugString(),\\n+                                        \", col_seq_tensor must have at least \",\\n+                                        out_cols + 1, \" elements, but got \",\\n+                                        col_seq_tensor.NumElements()));\\n+\\n     auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();\\n     auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();\\n     auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();'}}",
            "message_norm":"validate inputs of `fractionalavgpoolgrad`.\n\npiperorigin-revid: 372420640\nchange-id: icc583928e6cdc3062e12498e4d2337a8fe3da016",
            "language":"it",
            "entities":"[('validate', 'ACTION', ''), ('372420640', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/fractional_avg_pool_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3015,
            "vuln_id":"GHSA-rv87-vcv4-fjvr",
            "cwe_id":"{'CWE-918'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/jenkinsci\/urltrigger-plugin\/commit\/aec43e370550b26636aa9cab0f23a5cbcffdc44f', 'https:\/\/github.com\/jenkinsci\/urltrigger-plugin\/commit\/46220e69c220bacf8eb23911c8feba9dd68d1a26'}",
            "dataset":"osv",
            "summary":"URLTrigger Plugin server-side request forgery vulnerability A server-side request forgery vulnerability exists in Jenkins URLTrigger Plugin 0.41 and earlier in URLTrigger.java that allows attackers with Overall\/Read access to cause Jenkins to send a GET request to a specified URL. As of version 0.43, this form validation method no longer connects to a user provided URL.",
            "published_date":"2022-05-14",
            "chain_len":2,
            "project":"https:\/\/github.com\/jenkinsci\/urltrigger-plugin",
            "commit_href":"https:\/\/github.com\/jenkinsci\/urltrigger-plugin\/commit\/aec43e370550b26636aa9cab0f23a5cbcffdc44f",
            "commit_sha":"aec43e370550b26636aa9cab0f23a5cbcffdc44f",
            "patch":"MULTI",
            "chain_ord":"['46220e69c220bacf8eb23911c8feba9dd68d1a26', 'aec43e370550b26636aa9cab0f23a5cbcffdc44f']",
            "before_first_fix_commit":"{'46220e69c220bacf8eb23911c8feba9dd68d1a26'}",
            "last_fix_commit":"aec43e370550b26636aa9cab0f23a5cbcffdc44f",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/29\/2018, 21:33:01",
            "message":"Given that the URL is polled, may be valid at poll-time but not at\nconfiguration-time and may contain environment variables that could\nchange the URL at poll-time, validating it during configuration is\npointless.",
            "author":"Tony Noble",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 15, 'total': 17}",
            "files":"{'src\/main\/java\/org\/jenkinsci\/plugins\/urltrigger\/URLTrigger.java': {'additions': 2, 'deletions': 15, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/urltrigger-plugin\/raw\/aec43e370550b26636aa9cab0f23a5cbcffdc44f\/src%2Fmain%2Fjava%2Forg%2Fjenkinsci%2Fplugins%2Furltrigger%2FURLTrigger.java', 'patch': '@@ -743,21 +743,8 @@ public FormValidation doCheckURL(@QueryParameter String value) {\\n             if ( value.contains( \"$\" ) ) {\\n             \\treturn FormValidation.warning( \"URL is parameterised and cannot be fully validated\" ) ;\\n             }\\n-\\n-            try {\\n-                URI uri = new URI(value);\\n-                if (uri.getScheme().equals(\"ftp\")) {\\n-                    FTPClient ftpClient = getFTPClientObject(value, null, null);\\n-                    ftpClient.getModificationTime(uri.getPath());\\n-                } else {\\n-                    ClientConfig cc = new DefaultClientConfig();\\n-                    Client client = Client.create(cc);\\n-                    client.resource(value).get(ClientResponse.class);\\n-                }\\n-                return FormValidation.ok();\\n-            } catch (Exception e) {\\n-                return FormValidation.error(e.getMessage());\\n-            }\\n+            \\n+            return FormValidation.ok();\\n         }\\n \\n         public FormValidation doCheckTimeout(@QueryParameter String value) {'}}",
            "message_norm":"given that the url is polled, may be valid at poll-time but not at\nconfiguration-time and may contain environment variables that could\nchange the url at poll-time, validating it during configuration is\npointless.",
            "language":"en",
            "entities":"[('change', 'ACTION', ''), ('validating', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/org\/jenkinsci\/plugins\/urltrigger\/URLTrigger.java'])",
            "num_files":1.0
        },
        {
            "index":1676,
            "vuln_id":"GHSA-f6g6-54hm-fhxv",
            "cwe_id":"{'CWE-362', 'CWE-119'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/mvertescher\/libsbc-rs\/commit\/a34d6e10f6f5654ed01a35288cf683d014ebc9c4'}",
            "dataset":"osv",
            "summary":"Data races in libsbc Affected versions of this crate implements `Send` for `Decoder<R>` for any `R: Read`. This allows `Decoder<R>` to contain `R: !Send` and carry (move) it to another thread.\n\nThis can result in undefined behavior such as memory corruption from data race on `R`, or dropping `R = MutexGuard<_>` from a thread that didn't lock the mutex.\n\nThe flaw was corrected in commit a34d6e1 by adding trait bound `R: Send` to the `Send` impl for `Decoder<R>`.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/mvertescher\/libsbc-rs",
            "commit_href":"https:\/\/github.com\/mvertescher\/libsbc-rs\/commit\/a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
            "commit_sha":"a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
            "patch":"SINGLE",
            "chain_ord":"['a34d6e10f6f5654ed01a35288cf683d014ebc9c4']",
            "before_first_fix_commit":"{'7278b23901f93d956d9739fdfc4ced147cc3f242'}",
            "last_fix_commit":"a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/23\/2021, 02:06:34",
            "message":"Add R: Send bound to Send impl of Decoder<R>\nfixes issue #4",
            "author":"JOE1994",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/lib.rs': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mvertescher\/libsbc-rs\/raw\/a34d6e10f6f5654ed01a35288cf683d014ebc9c4\/src%2Flib.rs', 'patch': '@@ -33,7 +33,7 @@ where\\n \\n unsafe impl<R> Send for Decoder<R>\\n where\\n-        R: Read,\\n+        R: Read + Send,\\n {\\n }'}}",
            "message_norm":"add r: send bound to send impl of decoder<r>\nfixes issue #4",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('decoder', 'SECWORD', ''), ('#4', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/lib.rs'])",
            "num_files":1.0
        },
        {
            "index":1915,
            "vuln_id":"GHSA-gq4h-f254-7cw9",
            "cwe_id":"{'CWE-362'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/kvark\/ticketed_lock\/pull\/8\/commits\/a986a9335d591fa5c826157d1674d47aa525357f'}",
            "dataset":"osv",
            "summary":"Data races in ticketed_lock Affected versions of this crate unconditionally implemented `Send` for `ReadTicket<T>` & `WriteTicket<T>`.\nThis allows to send non-Send `T` to other threads.\n\nThis can allows creating data races by cloning types with internal mutability and sending them to other threads (as `T` of `ReadTicket<T>`\/`WriteTicket<T>`). Such data races can cause memory corruption or other undefined behavior.\n\nThe flaw was corrected in commit a986a93 by adding `T: Send` bounds to `Send` impls of `ReadTicket<T>`\/`WriteTicket<T>`.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/kvark\/ticketed_lock",
            "commit_href":"https:\/\/github.com\/kvark\/ticketed_lock\/pull\/8\/commits\/a986a9335d591fa5c826157d1674d47aa525357f",
            "commit_sha":"a986a9335d591fa5c826157d1674d47aa525357f",
            "patch":"SINGLE",
            "chain_ord":"['a986a9335d591fa5c826157d1674d47aa525357f']",
            "before_first_fix_commit":"{'6d85af9eb5d8bb7cf142de8e832ce3af7e47e306'}",
            "last_fix_commit":"a986a9335d591fa5c826157d1674d47aa525357f",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/24\/2021, 04:07:17",
            "message":"'T: Send' to prevent misuse",
            "author":"JOE1994",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'src\/lib.rs': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/kvark\/ticketed_lock\/raw\/a986a9335d591fa5c826157d1674d47aa525357f\/src%2Flib.rs', 'patch': '@@ -50,7 +50,7 @@ pub struct ReadTicket<T> {\\n     data: Arc<UnsafeCell<T>>,\\n }\\n \\n-unsafe impl<T> Send for ReadTicket<T> {}\\n+unsafe impl<T: Send> Send for ReadTicket<T> {}\\n \\n #[cfg(not(feature = \"futures\"))]\\n impl<T> ReadTicket<T> {\\n@@ -112,7 +112,7 @@ pub struct WriteTicket<T> {\\n     data: Arc<UnsafeCell<T>>,\\n }\\n \\n-unsafe impl<T> Send for WriteTicket<T> {}\\n+unsafe impl<T: Send> Send for WriteTicket<T> {}\\n \\n #[cfg(not(feature = \"futures\"))]\\n impl<T> WriteTicket<T> {'}}",
            "message_norm":"'t: send' to prevent misuse",
            "language":"en",
            "entities":"[('prevent', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/lib.rs'])",
            "num_files":1.0
        },
        {
            "index":1437,
            "vuln_id":"GHSA-9vwf-54m9-gc4f",
            "cwe_id":"{'CWE-862', 'CWE-284'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/1699c09758e56f740437674a8d6ba36443399f24'}",
            "dataset":"osv",
            "summary":"snipe-it is vulnerable to Improper Access Control snipe-it prior to version 5.3.4 is vulnerable to Improper Access Control. Regular users with `DENY` set to all models permissions can still view model information via the \/models\/{id}\/clone endpoint due to no authorize('view') permission being set.",
            "published_date":"2021-12-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/1699c09758e56f740437674a8d6ba36443399f24",
            "commit_sha":"1699c09758e56f740437674a8d6ba36443399f24",
            "patch":"SINGLE",
            "chain_ord":"['1699c09758e56f740437674a8d6ba36443399f24']",
            "before_first_fix_commit":"{'918e7c8dae4d41935f534901a582ea8488bbf603'}",
            "last_fix_commit":"1699c09758e56f740437674a8d6ba36443399f24",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/09\/2021, 13:42:18",
            "message":"Update AssetModelsController.php",
            "author":"Haxatron",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'app\/Http\/Controllers\/AssetModelsController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/1699c09758e56f740437674a8d6ba36443399f24\/app%2FHttp%2FControllers%2FAssetModelsController.php', 'patch': \"@@ -269,7 +269,7 @@ public function show($modelId = null)\\n     *\/\\n     public function getClone($modelId = null)\\n     {\\n-        $this->authorize('view', AssetModel::class);\\n+        $this->authorize('create', AssetModel::class);\\n         \/\/ Check if the model exists\\n         if (is_null($model_to_clone = AssetModel::find($modelId))) {\\n             return redirect()->route('models.index')->with('error', trans('admin\/models\/message.does_not_exist'));\"}}",
            "message_norm":"update assetmodelscontroller.php",
            "language":"it",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/AssetModelsController.php'])",
            "num_files":1.0
        },
        {
            "index":1252,
            "vuln_id":"GHSA-8rmh-55h4-93h5",
            "cwe_id":"{'CWE-22'}",
            "score":7.2,
            "chain":"{'https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199'}",
            "dataset":"osv",
            "summary":"DSpace ItemImportService API Vulnerable to Path Traversal in Simple Archive Format Package Import ### Impact\nItemImportServiceImpl is vulnerable to a path traversal vulnerability. This means a malicious SAF (simple archive format) package could cause a file\/directory to be created anywhere the Tomcat\/DSpace user can write to on the server.  However, this path traversal vulnerability is only possible by a user with special privileges (either Administrators or someone with command-line access to the server).  This vulnerability impacts the XMLUI, JSPUI and command-line.\n\n_This vulnerability does NOT impact 7.x._\n\n### Patches\n\n_DSpace 6.x:_ \n* Fixed in 6.4 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0\n* 6.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0.patch (may be applied manually if an immediate upgrade to 6.4 or 7.x is not possible)\n\n_DSpace 5.x:_\n* Fixed in 5.11 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199\n* 5.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199.patch (may be applied manually if an immediate upgrade to 5.11 or 6.4 or 7.x is not possible)\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs \/ configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### Workarounds\n\nAs a basic workaround, you may block all access to the following URL paths:\n* If you are using the XMLUI, block all access to `\/admin\/batchimport` path (this is the URL of the Admin Batch Import tool). Keep in mind, if your site uses the path \"\/xmlui\", then you'd need to block access to `\/xmlui\/admin\/batchimport`.\n* If you are using the JSPUI, block all access to `\/dspace-admin\/batchimport` path (this is the URL of the Admin Batch Import tool).  Keep in mind, if your site uses the path \"\/jspui\", then you'd need to block access to `\/jspui\/dspace-admin\/batchimport`.\n\nKeep in mind, only an Administrative user or a user with command-line access to the server is able to import\/upload SAF packages. Therefore, assuming those users do not blindly upload untrusted SAF packages, then it is unlikely your site could be impacted by this vulnerability.\n\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
            "published_date":"2022-08-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/DSpace\/DSpace",
            "commit_href":"https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0",
            "commit_sha":"7af52a0883a9dbc475cf3001f04ed11b24c8a4c0",
            "patch":"MULTI",
            "chain_ord":"['7af52a0883a9dbc475cf3001f04ed11b24c8a4c0', '56e76049185bbd87c994128a9d77735ad7af0199']",
            "before_first_fix_commit":"{'73cdff26fdc40bb022e21dcfdeefebf28057cde7'}",
            "last_fix_commit":"56e76049185bbd87c994128a9d77735ad7af0199",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/08\/2020, 00:44:54",
            "message":"[DS-4131] Fix zip import handling to avoid path traversal exploit",
            "author":"Kim Shepherd",
            "comments":null,
            "stats":"{'additions': 36, 'deletions': 7, 'total': 43}",
            "files":"{'dspace-api\/src\/main\/java\/org\/dspace\/app\/itemimport\/ItemImportServiceImpl.java': {'additions': 36, 'deletions': 7, 'changes': 43, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DSpace\/DSpace\/raw\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0\/dspace-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdspace%2Fapp%2Fitemimport%2FItemImportServiceImpl.java', 'patch': '@@ -55,6 +55,8 @@\\n import javax.xml.transform.TransformerException;\\n import java.io.*;\\n import java.net.URL;\\n+import java.nio.file.Path;\\n+import java.nio.file.Paths;\\n import java.sql.SQLException;\\n import java.text.SimpleDateFormat;\\n import java.util.*;\\n@@ -1630,26 +1632,36 @@ public String unzip(File zipfile, String destDir) throws IOException {\\n         {\\n             log.error(\"Zip file \\'\" + zipfile.getAbsolutePath() + \"\\' does not exist, or is not readable.\");\\n         }\\n+        log.debug(\"Extracting zip at \" + zipfile.getAbsolutePath());\\n \\n         String destinationDir = destDir;\\n         if (destinationDir == null){\\n         \\tdestinationDir = tempWorkDir;\\n         }\\n+        log.debug(\"Using directory \" + destinationDir + \" for zip extraction. (destDir arg is \" + destDir +\\n+                \", tempWorkDir is \" + tempWorkDir + \")\");\\n \\n         File tempdir = new File(destinationDir);\\n         if (!tempdir.isDirectory())\\n         {\\n-            log.error(\"\\'\" + ConfigurationManager.getProperty(\"org.dspace.app.itemexport.work.dir\") +\\n-                    \"\\' as defined by the key \\'org.dspace.app.itemexport.work.dir\\' in dspace.cfg \" +\\n+            log.error(\"\\'\" + ConfigurationManager.getProperty(\"org.dspace.app.batchitemexport.work.dir\") +\\n+                    \"\\' as defined by the key \\'org.dspace.app.batchitemexport.work.dir\\' in dspace.cfg \" +\\n                     \"is not a valid directory\");\\n         }\\n \\n         if (!tempdir.exists() && !tempdir.mkdirs())\\n         {\\n             log.error(\"Unable to create temporary directory: \" + tempdir.getAbsolutePath());\\n         }\\n-        String sourcedir = destinationDir + System.getProperty(\"file.separator\") + zipfile.getName();\\n-        String zipDir = destinationDir + System.getProperty(\"file.separator\") + zipfile.getName() + System.getProperty(\"file.separator\");\\n+\\n+        if(!destinationDir.endsWith(System.getProperty(\"file.separator\"))) {\\n+            destinationDir += System.getProperty(\"file.separator\");\\n+        }\\n+\\n+        String sourcedir = destinationDir + zipfile.getName();\\n+        String zipDir = destinationDir + zipfile.getName() + System.getProperty(\"file.separator\");\\n+\\n+        log.debug(\"zip directory to use is \" + zipDir);\\n \\n \\n         \/\/ 3\\n@@ -1660,11 +1672,27 @@ public String unzip(File zipfile, String destDir) throws IOException {\\n         while (entries.hasMoreElements())\\n         {\\n             entry = entries.nextElement();\\n+            \/\/ Check that the true path to extract files is never outside allowed temp directories\\n+            \/\/ without creating any actual files on disk\\n+            log.debug(\"Inspecting entry name: \" + entry.getName() + \" for path traversal security\");\\n+            File potentialExtract = new File(zipDir + entry.getName());\\n+            String canonicalPath = potentialExtract.getCanonicalPath();\\n+            log.debug(\"Canonical path to potential File is \" + canonicalPath);\\n+            if(!canonicalPath.startsWith(zipDir)) {\\n+                log.error(\"Rejecting zip file: \" + zipfile.getName() + \" as it contains an entry that would be extracted \" +\\n+                        \"outside the temporary unzip directory: \" + canonicalPath);\\n+                throw new IOException(\"Error extracting \" + zipfile + \": Canonical path of zip entry: \" +\\n+                        entry.getName() + \" (\" + canonicalPath + \") does not start with permissible temp unzip directory (\" + destinationDir +\\n+                        \")\");\\n+            }\\n+\\n             if (entry.isDirectory())\\n             {\\n-                if (!new File(zipDir + entry.getName()).mkdir())\\n-                {\\n+                \/\/ Log error and throw IOException if a directory entry could not be created\\n+                File newDir = new File(zipDir + entry.getName());\\n+                if (!newDir.mkdirs()) {\\n                     log.error(\"Unable to create contents directory: \" + zipDir + entry.getName());\\n+                    throw new IOException(\"Unable to create contents directory: \" + zipDir + entry.getName());\\n                 }\\n             }\\n             else\\n@@ -1673,6 +1701,7 @@ public String unzip(File zipfile, String destDir) throws IOException {\\n                 log.info(\"Extracting file: \" + entry.getName());\\n \\n                 int index = entry.getName().lastIndexOf(\\'\/\\');\\n+                log.debug(\"Index of \" + entry.getName() + \" is \" + index);\\n                 if (index == -1)\\n                 {\\n                     \/\/ Was it created on Windows instead?\\n@@ -1701,11 +1730,11 @@ public String unzip(File zipfile, String destDir) throws IOException {\\n                         }\\n                     }\\n \\n-\\n                 }\\n                 byte[] buffer = new byte[1024];\\n                 int len;\\n                 InputStream in = zf.getInputStream(entry);\\n+                log.debug(\"Reading \" + zipDir + entry.getName() + \" into InputStream\");\\n                 BufferedOutputStream out = new BufferedOutputStream(\\n                         new FileOutputStream(zipDir + entry.getName()));\\n                 while((len = in.read(buffer)) >= 0)'}}",
            "message_norm":"[ds-4131] fix zip import handling to avoid path traversal exploit",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('path traversal', 'SECWORD', ''), ('exploit', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dspace-api\/src\/main\/java\/org\/dspace\/app\/itemimport\/ItemImportServiceImpl.java'])",
            "num_files":1.0
        },
        {
            "index":2587,
            "vuln_id":"GHSA-ph5x-h23x-7q5q",
            "cwe_id":"{'CWE-79', 'CWE-116'}",
            "score":7.4,
            "chain":"{'https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/27f839133d41877e538d35fa88274b50a1c00b9b'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in wiki manager join wiki page ### Impact\nWe found a possible XSS vector in the `WikiManager.JoinWiki ` wiki page related to the \"requestJoin\" field.\n\n### Patches\nThe issue is patched in versions 12.10.11, 14.0-rc-1, 13.4.7, 13.10.3.\n\n### Workarounds\nThe easiest workaround is to edit the wiki page `WikiManager.JoinWiki` (with wiki editor) and change the line\n\n```\n<input type='hidden' name='requestJoin' value=\"$!request.requestJoin\"\/>\n```\n\ninto\n\n```\n<input type='hidden' name='requestJoin' value=\"$escapetool.xml($!request.requestJoin)\">\n```\n\n### References\n  * https:\/\/jira.xwiki.org\/browse\/XWIKI-19292\n  * https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/27f839133d41877e538d35fa88274b50a1c00b9b\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Jira XWiki](https:\/\/jira.xwiki.org)\n* Email us at [security mailing list](mailto:security@xwiki.org)",
            "published_date":"2022-05-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/xwiki\/xwiki-platform",
            "commit_href":"https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/27f839133d41877e538d35fa88274b50a1c00b9b",
            "commit_sha":"27f839133d41877e538d35fa88274b50a1c00b9b",
            "patch":"SINGLE",
            "chain_ord":"['27f839133d41877e538d35fa88274b50a1c00b9b']",
            "before_first_fix_commit":"{'bd935320bee3c27cf7548351b1d0f935f116d437'}",
            "last_fix_commit":"27f839133d41877e538d35fa88274b50a1c00b9b",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/04\/2022, 10:35:46",
            "message":"XWIKI-19292: Fix bad escaping",
            "author":"Thomas Mortagne",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'xwiki-platform-core\/xwiki-platform-wiki\/xwiki-platform-wiki-ui\/xwiki-platform-wiki-ui-mainwiki\/src\/main\/resources\/WikiManager\/JoinWiki.xml': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/xwiki\/xwiki-platform\/raw\/27f839133d41877e538d35fa88274b50a1c00b9b\/xwiki-platform-core%2Fxwiki-platform-wiki%2Fxwiki-platform-wiki-ui%2Fxwiki-platform-wiki-ui-mainwiki%2Fsrc%2Fmain%2Fresources%2FWikiManager%2FJoinWiki.xml', 'patch': '@@ -245,7 +245,7 @@\\n                   &lt;a href=\"$backUrl\" class=\\'button secondary\\'&gt;{{translation key=\"platform.wiki.users.join.request.cancel.label\"\/}}&lt;\/a&gt;\\n                 &lt;\/span&gt;\\n                 &lt;input type=\\'hidden\\' name=\\'wikiId\\' value=\"$!wikiId\"\/&gt;\\n-                &lt;input type=\\'hidden\\' name=\\'requestJoin\\' value=\"$!request.requestJoin\"\/&gt;\\n+                &lt;input type=\\'hidden\\' name=\\'requestJoin\\' value=\"$escapetool.xml($!request.requestJoin)\"\/&gt;\\n                 &lt;input type=\"hidden\" name=\"form_token\" value=\"$!escapetool.xml($services.csrf.getToken())\" \/&gt;\\n               &lt;\/dl&gt;\\n             &lt;\/form&gt;'}}",
            "message_norm":"xwiki-19292: fix bad escaping",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('escaping', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['xwiki-platform-core\/xwiki-platform-wiki\/xwiki-platform-wiki-ui\/xwiki-platform-wiki-ui-mainwiki\/src\/main\/resources\/WikiManager\/JoinWiki.xml'])",
            "num_files":1.0
        },
        {
            "index":2659,
            "vuln_id":"GHSA-pwwm-pwx2-2hw7",
            "cwe_id":"{'CWE-209'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/178e44095141ab805c282f563fb088df1a10b2e2'}",
            "dataset":"osv",
            "summary":"Generation of Error Message Containing Sensitive Information in Snipe-IT Snipe-IT prior to version 5.3.11 is vulnerable to Generation of Error Message Containing Sensitive Information.",
            "published_date":"2022-02-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/178e44095141ab805c282f563fb088df1a10b2e2",
            "commit_sha":"178e44095141ab805c282f563fb088df1a10b2e2",
            "patch":"SINGLE",
            "chain_ord":"['178e44095141ab805c282f563fb088df1a10b2e2']",
            "before_first_fix_commit":"{'321be4733d3997fc738f0118e1b9af5905f95439'}",
            "last_fix_commit":"178e44095141ab805c282f563fb088df1a10b2e2",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/16\/2022, 02:09:58",
            "message":"Added usleep :(\n\nSigned-off-by: snipe <snipe@snipe.net>",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'app\/Http\/Controllers\/Auth\/ForgotPasswordController.php': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/178e44095141ab805c282f563fb088df1a10b2e2\/app%2FHttp%2FControllers%2FAuth%2FForgotPasswordController.php', 'patch': \"@@ -87,6 +87,8 @@ public function sendResetLinkEmail(Request $request)\\n             \\\\Log::info('Password reset attempt: User '.$request->input('username').'failed with exception: '.$e );\\n         }\\n \\n+        \/\/ Prevent timing attack to enumerate users.\\n+        usleep(500000 + random_int(0, 1500000));\\n \\n         if ($response === \\\\Password::RESET_LINK_SENT) {\\n             \\\\Log::info('Password reset attempt: User '.$request->input('username').' WAS found, password reset sent');\"}}",
            "message_norm":"added usleep :(\n\nsigned-off-by: snipe <snipe@snipe.net>",
            "language":"en",
            "entities":"[('added', 'ACTION', ''), ('snipe@snipe.net', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/Auth\/ForgotPasswordController.php'])",
            "num_files":1.0
        },
        {
            "index":971,
            "vuln_id":"GHSA-75vw-3m5v-fprh",
            "cwe_id":"{'CWE-611'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/stanfordnlp\/corenlp\/commit\/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd'}",
            "dataset":"osv",
            "summary":"corenlp is vulnerable to Improper Restriction of XML External Entity Reference corenlp is vulnerable to Improper Restriction of XML External Entity Reference",
            "published_date":"2022-01-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/stanfordnlp\/corenlp",
            "commit_href":"https:\/\/github.com\/stanfordnlp\/corenlp\/commit\/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
            "commit_sha":"1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
            "patch":"SINGLE",
            "chain_ord":"['1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd']",
            "before_first_fix_commit":"{'820192ce1ad1062057cf6abcb359cd635988bf63'}",
            "last_fix_commit":"1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/16\/2022, 06:10:35",
            "message":"Fix XML schema vulnerability",
            "author":"Haxatron",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'src\/edu\/stanford\/nlp\/util\/XMLUtils.java': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/stanfordnlp\/CoreNLP\/raw\/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd\/src%2Fedu%2Fstanford%2Fnlp%2Futil%2FXMLUtils.java', 'patch': '@@ -302,6 +302,7 @@ public static DocumentBuilder getValidatingXmlParser(File schemaFile) {\\n       DocumentBuilderFactory dbf = safeDocumentBuilderFactory();\\n \\n       SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);\\n+      factory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\\n       Schema schema = factory.newSchema(schemaFile);\\n       dbf.setSchema(schema);'}}",
            "message_norm":"fix xml schema vulnerability",
            "language":"ro",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/edu\/stanford\/nlp\/util\/XMLUtils.java'])",
            "num_files":1.0
        },
        {
            "index":402,
            "vuln_id":"GHSA-4c4g-crqm-xrxw",
            "cwe_id":"{'CWE-908'}",
            "score":4.4,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8933b8a21280696ab119b63263babdb54c298538', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/537bc7c723439b9194a358f64d871dd326c18887'}",
            "dataset":"osv",
            "summary":"Use of unitialized value in TFLite ### Impact\nAll TFLite operations that use quantization can be made to use unitialized values. [For example](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/lite\/kernels\/depthwise_conv.cc#L198-L200):\n\n```cc\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n```\n\nThe issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code.\n\n### Patches\nWe have patched the issue in GitHub commits [537bc7c723439b9194a358f64d871dd326c18887](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/537bc7c723439b9194a358f64d871dd326c18887),\n[4a91f2069f7145aab6ba2d8cfe41be8a110c18a5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5) and [8933b8a21280696ab119b63263babdb54c298538](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8933b8a21280696ab119b63263babdb54c298538).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":3,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/537bc7c723439b9194a358f64d871dd326c18887",
            "commit_sha":"537bc7c723439b9194a358f64d871dd326c18887",
            "patch":"MULTI",
            "chain_ord":"['537bc7c723439b9194a358f64d871dd326c18887', '4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', '8933b8a21280696ab119b63263babdb54c298538']",
            "before_first_fix_commit":"{'e35be978351a8578549d30b6f483825d36dc0f8b'}",
            "last_fix_commit":"8933b8a21280696ab119b63263babdb54c298538",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/16\/2021, 16:35:48",
            "message":"Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385163909\nChange-Id: I2beb8d50649b6542db224c163033fbcbaa49314f",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
            "files":"{'tensorflow\/lite\/kernels\/svdf.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/537bc7c723439b9194a358f64d871dd326c18887\/tensorflow%2Flite%2Fkernels%2Fsvdf.cc', 'patch': '@@ -256,14 +256,21 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n                                                      output_temp_size_array));\\n \\n     \/\/ Calculate effective scales.\\n+    TF_LITE_ENSURE(context, input->quantization.type != kTfLiteNoQuantization);\\n     auto* input_params =\\n         reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\\n+    TF_LITE_ENSURE(context,\\n+                   weights_feature->quantization.type != kTfLiteNoQuantization);\\n     auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\\n         weights_feature->quantization.params);\\n+    TF_LITE_ENSURE(context, state->quantization.type != kTfLiteNoQuantization);\\n     auto* state_params =\\n         reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\\n+    TF_LITE_ENSURE(context,\\n+                   weights_time->quantization.type != kTfLiteNoQuantization);\\n     auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\\n         weights_time->quantization.params);\\n+    TF_LITE_ENSURE(context, output->quantization.type != kTfLiteNoQuantization);\\n     auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\\n         output->quantization.params);\\n     const double effective_scale_1 = input_params->scale->data[0] *'}}",
            "message_norm":"fix a null pointer exception caused by branching on uninitialized data.\n\nthis is due to not checking that the params for the quantization exists. if there is no quantization, we should not access the `.params` field.\n\npiperorigin-revid: 385163909\nchange-id: i2beb8d50649b6542db224c163033fbcbaa49314f",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('null pointer exception', 'SECWORD', ''), ('uninitialized', 'SECWORD', ''), ('385163909', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/svdf.cc'])",
            "num_files":1.0
        },
        {
            "index":2807,
            "vuln_id":"GHSA-qr2j-wrhx-4829",
            "cwe_id":"{'CWE-20'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/ethereum\/go-ethereum\/commit\/106d196ec4a6451efedc60ab15957f231fa85639'}",
            "dataset":"osv",
            "summary":"Improper Input Validation In Go Ethereum (aka geth) before 1.8.14, TraceChain in eth\/api_tracer.go does not verify that the end block is after the start block.",
            "published_date":"2021-05-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/ethereum\/go-ethereum",
            "commit_href":"https:\/\/github.com\/ethereum\/go-ethereum\/commit\/106d196ec4a6451efedc60ab15957f231fa85639",
            "commit_sha":"106d196ec4a6451efedc60ab15957f231fa85639",
            "patch":"SINGLE",
            "chain_ord":"['106d196ec4a6451efedc60ab15957f231fa85639']",
            "before_first_fix_commit":"{'6d1e292eefa70b5cb76cd03ff61fc6c4550d7c36'}",
            "last_fix_commit":"106d196ec4a6451efedc60ab15957f231fa85639",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/21\/2018, 07:48:53",
            "message":"eth: ensure from<to when tracing chain (credits Chen Nan via bugbounty)",
            "author":"Martin Holst Swende",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'eth\/api_tracer.go': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ethereum\/go-ethereum\/raw\/106d196ec4a6451efedc60ab15957f231fa85639\/eth%2Fapi_tracer.go', 'patch': '@@ -119,6 +119,9 @@ func (api *PrivateDebugAPI) TraceChain(ctx context.Context, start, end rpc.Block\\n \\tif to == nil {\\n \\t\\treturn nil, fmt.Errorf(\"end block #%d not found\", end)\\n \\t}\\n+\\tif from.Number().Cmp(to.Number()) >= 0 {\\n+\\t\\treturn nil, fmt.Errorf(\"end block (#%d) needs to come after start block (#%d)\", end, start)\\n+\\t}\\n \\treturn api.traceChain(ctx, from, to, config)\\n }'}}",
            "message_norm":"eth: ensure from<to when tracing chain (credits chen nan via bugbounty)",
            "language":"en",
            "entities":"[('ensure', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['eth\/api_tracer.go'])",
            "num_files":1.0
        },
        {
            "index":436,
            "vuln_id":"GHSA-4hvf-hxvg-f67v",
            "cwe_id":"{'CWE-787', 'CWE-125'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038'}",
            "dataset":"osv",
            "summary":"Read and Write outside of bounds in TensorFlow ### Impact\nAn attacker can craft a TFLite model that would allow limited reads and writes outside of arrays in TFLite. This exploits missing validation in [the conversion from sparse tensors to dense tensors](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ca6f96b62ad84207fbec580404eaa7dd7403a550\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc#L252-L293).\n\n### Patches\nWe have patched the issue in GitHub commit [6364463d6f5b6254cac3d6aedf999b6a96225038](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038",
            "commit_sha":"6364463d6f5b6254cac3d6aedf999b6a96225038",
            "patch":"SINGLE",
            "chain_ord":"['6364463d6f5b6254cac3d6aedf999b6a96225038']",
            "before_first_fix_commit":"{'3e49ff637ad4f05c133d235a568943d19216fa9a'}",
            "last_fix_commit":"6364463d6f5b6254cac3d6aedf999b6a96225038",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/16\/2021, 23:37:14",
            "message":"[lite] Add some safety checks to avoid out of bound access for sparsity format\n\nPiperOrigin-RevId: 416910386\nChange-Id: Ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
            "author":"Karim Nosir",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 7, 'total': 18}",
            "files":"{'tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc': {'additions': 11, 'deletions': 7, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6364463d6f5b6254cac3d6aedf999b6a96225038\/tensorflow%2Flite%2Fkernels%2Finternal%2Futils%2Fsparsity_format_converter.cc', 'patch': '@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\\n   block_size_.resize(block_map_.size());\\n   for (int i = 0; i < original_rank; i++) {\\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\\n-      int orig_dim = traversal_order_[original_rank + block_dim];\\n-      block_size_[block_dim] = dense_size[orig_dim];\\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\\n-      block_dim++;\\n+      if (original_rank + block_dim < traversal_order_.size()) {\\n+        int orig_dim = traversal_order_[original_rank + block_dim];\\n+        block_size_[block_dim] = dense_size[orig_dim];\\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\\n+        block_dim++;\\n+      }\\n     } else {\\n       blocked_shape_[i] = dense_shape_[i];\\n     }\\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\\n                src_data_ptr, dest_data);\\n     }\\n-  } else {\\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\\n     const auto& array_segments = dim_metadata_[metadata_idx];\\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\\n          i++) {\\n-      indices[level] = array_indices[i];\\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      if (i < array_indices.size() && level < indices.size()) {\\n+        indices[level] = array_indices[i];\\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      }\\n     }\\n   }\\n }'}}",
            "message_norm":"[lite] add some safety checks to avoid out of bound access for sparsity format\n\npiperorigin-revid: 416910386\nchange-id: ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('safety checks', 'SECWORD', ''), ('out of bound access', 'SECWORD', ''), ('416910386', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc'])",
            "num_files":1.0
        },
        {
            "index":3504,
            "vuln_id":"GHSA-xw93-v57j-fcgh",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5'}",
            "dataset":"osv",
            "summary":"Division by 0 in `SparseMatMul` ### Impact\nAn attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.SparseMatMul`:\n\n```python\nimport tensorflow as tf\n\na = tf.constant([100.0, 100.0, 100.0, 100.0], shape=[2, 2], dtype=tf.float32)\nb = tf.constant([], shape=[0, 2], dtype=tf.float32)\n\ntf.raw_ops.SparseMatMul(\n    a=a, b=b, transpose_a=True, transpose_b=True,\n    a_is_sparse=True, b_is_sparse=True)\n``` \n    \nThe division by 0 occurs deep in Eigen code because the `b` tensor is empty.\n    \n### Patches\nWe have patched the issue in GitHub commit [7f283ff806b2031f407db64c4d3edcda8fb9f9f5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "commit_sha":"7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "patch":"SINGLE",
            "chain_ord":"['7f283ff806b2031f407db64c4d3edcda8fb9f9f5']",
            "before_first_fix_commit":"{'05a63e605a31e86c5dd96c5c8a763eda9ac7bb33'}",
            "last_fix_commit":"7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 22:00:39",
            "message":"Fix FPE issue in external Eigen source code issue with `tf.raw_ops.SparseMatMul`.\n\nPiperOrigin-RevId: 370992919\nChange-Id: Icfb276fef5fb40928b27c3e44608d2aca72c9fd7",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/sparse_matmul_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5\/tensorflow%2Fcore%2Fkernels%2Fsparse_matmul_op.cc', 'patch': '@@ -1039,6 +1039,10 @@ class SparseMatMulOp : public OpKernel {\\n     if (transpose_b) {\\n       \/\/ TODO(agarwal): avoid transposing the matrix here and directly handle\\n       \/\/ transpose in CreateDenseSlices.\\n+      OP_REQUIRES(ctx, right->dim_size(0) != 0,\\n+                  errors::InvalidArgument(\"b has an entry 0 in it\\'s shape.\"));\\n+      OP_REQUIRES(ctx, right->dim_size(1) != 0,\\n+                  errors::InvalidArgument(\"b has an entry 0 in it\\'s shape.\"));\\n       right_tr.reset(\\n           new Tensor(right->dtype(),\\n                      TensorShape({right->dim_size(1), right->dim_size(0)})));'}}",
            "message_norm":"fix fpe issue in external eigen source code issue with `tf.raw_ops.sparsematmul`.\n\npiperorigin-revid: 370992919\nchange-id: icfb276fef5fb40928b27c3e44608d2aca72c9fd7",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('issue', 'FLAW', ''), ('issue', 'FLAW', ''), ('370992919', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_matmul_op.cc'])",
            "num_files":1.0
        },
        {
            "index":371,
            "vuln_id":"GHSA-46hv-7769-j7rx",
            "cwe_id":"{'CWE-548'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/sintaxi\/harp\/commit\/1ec790baeeb2bfdb4584f1998af3d10a8fa31210'}",
            "dataset":"osv",
            "summary":"Unauthorized File Access in harp Affected versions of `harp` are vulnerable to Unauthorized File Access. The package states that it ignores files and directories with names that start with an underscore, such as `_secret-folder`. If the underscore character is URL encoded the server delivers the file.\n\n## Recommendation\n\nUpgrade to version `0.40.2` or later.",
            "published_date":"2019-06-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/sintaxi\/harp",
            "commit_href":"https:\/\/github.com\/sintaxi\/harp\/commit\/1ec790baeeb2bfdb4584f1998af3d10a8fa31210",
            "commit_sha":"1ec790baeeb2bfdb4584f1998af3d10a8fa31210",
            "patch":"SINGLE",
            "chain_ord":"['1ec790baeeb2bfdb4584f1998af3d10a8fa31210']",
            "before_first_fix_commit":"{'d3f7ba27c7554251a91f2987d702a6d4cfe8f081'}",
            "last_fix_commit":"1ec790baeeb2bfdb4584f1998af3d10a8fa31210",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/02\/2021, 18:56:59",
            "message":"Resolves serving private file via encoded underscore. #646",
            "author":"Brock Whitten",
            "comments":null,
            "stats":"{'additions': 867, 'deletions': 1027, 'total': 1894}",
            "files":"{'package-lock.json': {'additions': 867, 'deletions': 1027, 'changes': 1894, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sintaxi\/harp\/raw\/1ec790baeeb2bfdb4584f1998af3d10a8fa31210\/package-lock.json', 'patch': None}}",
            "message_norm":"resolves serving private file via encoded underscore. #646",
            "language":"it",
            "entities":"[('private file', 'SECWORD', ''), ('encoded', 'SECWORD', ''), ('#646', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['package-lock.json'])",
            "num_files":1.0
        },
        {
            "index":200,
            "vuln_id":"GHSA-35g4-qx3c-vjhx",
            "cwe_id":"{'CWE-306'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/matrix-org\/matrix-appservice-bridge\/commit\/b69e745584a34fcfd858df33e4631e420da07b9f'}",
            "dataset":"osv",
            "summary":"Automatic room upgrade handling can be used maliciously to bridge a room non-consentually  ### Impact\n\nIf a bridge has room upgrade handling turned on in the configuration (the `roomUpgradeOpts` key when instantiating a new `Bridge` instance.), any `m.room.tombstone` event it encounters will be used to unbridge the current room and bridge into the target room. However, the target room `m.room.create` event is not checked to verify if the `predecessor` field contains the previous room. This means that any mailcious admin of a bridged room can repoint the traffic to a different room without the new room being aware.\n\n\n### Patches\n\nVersions 2.6.1 and greater are patched.\n\n### Workarounds\n\nDisabling the automatic room upgrade handling can be done by removing the `roomUpgradeOpts` key from the `Bridge` class options. \n\n### References\n\nThe issue is patched by https:\/\/github.com\/matrix-org\/matrix-appservice-bridge\/pull\/330\n\n### For more information]\n\nIf you have any questions or comments about this advisory, email us at security@matrix.org.",
            "published_date":"2021-06-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/matrix-org\/matrix-appservice-bridge",
            "commit_href":"https:\/\/github.com\/matrix-org\/matrix-appservice-bridge\/commit\/b69e745584a34fcfd858df33e4631e420da07b9f",
            "commit_sha":"b69e745584a34fcfd858df33e4631e420da07b9f",
            "patch":"SINGLE",
            "chain_ord":"['b69e745584a34fcfd858df33e4631e420da07b9f']",
            "before_first_fix_commit":"{'1b587e2455cbd30779f5052d2d2d46d58463a3e2'}",
            "last_fix_commit":"b69e745584a34fcfd858df33e4631e420da07b9f",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/28\/2021, 09:32:25",
            "message":"Check m.room.create event on room upgrade",
            "author":"Will Hunt",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
            "files":"{'src\/components\/room-upgrade-handler.ts': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/matrix-org\/matrix-appservice-bridge\/raw\/b69e745584a34fcfd858df33e4631e420da07b9f\/src%2Fcomponents%2Froom-upgrade-handler.ts', 'patch': \"@@ -145,6 +145,13 @@ export class RoomUpgradeHandler {\\n     private async onJoinedNewRoom(oldRoomId: string, newRoomId: string) {\\n         log.debug(`Joined ${newRoomId}`);\\n         const intent = this.bridge.getIntent();\\n+        const { predecessor } = await intent.getStateEvent(newRoomId, 'm.room.create');\\n+        if (predecessor.room_id !== oldRoomId) {\\n+            log.error(\\n+    `Room doesn't have a matching predecessor (expected: ${oldRoomId}, got: ${predecessor.room_id}), not bridging.`\\n+            );\\n+            return false;\\n+        }\\n         const asBot = this.bridge.getBot();\\n         if (this.opts.migrateStoreEntries) {\\n             const success = await this.migrateStoreEntries(oldRoomId, newRoomId);\"}}",
            "message_norm":"check m.room.create event on room upgrade",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/components\/room-upgrade-handler.ts'])",
            "num_files":1.0
        },
        {
            "index":322,
            "vuln_id":"GHSA-3wwj-wh2w-g4xp",
            "cwe_id":"{'CWE-93'}",
            "score":7.6,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/f0e338f1b7dc5ec9d99231f4ed3fa6245a5eb128'}",
            "dataset":"osv",
            "summary":"CRLF Injection in microweber CRLF Injection leads to Stack Trace Exposure due to lack of filtering at https:\/\/demo.microweber.org\/ in Packagist microweber\/microweber prior to 1.2.11.",
            "published_date":"2022-02-19",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/f0e338f1b7dc5ec9d99231f4ed3fa6245a5eb128",
            "commit_sha":"f0e338f1b7dc5ec9d99231f4ed3fa6245a5eb128",
            "patch":"SINGLE",
            "chain_ord":"['f0e338f1b7dc5ec9d99231f4ed3fa6245a5eb128']",
            "before_first_fix_commit":"{'7bdd97ec1ff4740ac8fa898b74ef9bce56bcf193'}",
            "last_fix_commit":"f0e338f1b7dc5ec9d99231f4ed3fa6245a5eb128",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/17\/2022, 14:49:46",
            "message":"Update UrlManager.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 3, 'total': 5}",
            "files":"{'src\/MicroweberPackages\/Helper\/UrlManager.php': {'additions': 2, 'deletions': 3, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/f0e338f1b7dc5ec9d99231f4ed3fa6245a5eb128\/src%2FMicroweberPackages%2FHelper%2FUrlManager.php', 'patch': '@@ -111,9 +111,8 @@ public function redirect($url)\\n             }\\n         }\\n \\n-        if (!filter_var($redirectUrl, FILTER_VALIDATE_URL)) {\\n-            $redirectUrl = site_url();\\n-        }\\n+        $redirectUrl = str_replace(\"\\\\r\", \"\", $redirectUrl);\\n+        $redirectUrl = str_replace(\"\\\\n\", \"\", $redirectUrl);\\n \\n         if (headers_sent()) {\\n             echo \\'<meta http-equiv=\"refresh\" content=\"0;url=\\' . $redirectUrl . \\'\">\\';'}}",
            "message_norm":"update urlmanager.php",
            "language":"sv",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"SUBMIT_CENTERED",
            "list_files":"dict_keys(['src\/MicroweberPackages\/Helper\/UrlManager.php'])",
            "num_files":1.0
        },
        {
            "index":742,
            "vuln_id":"GHSA-6445-fm66-fvq2",
            "cwe_id":"{'CWE-190'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b51b82fe65ebace4475e3c54eb089c18a4403f1c', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a68f68061e263a88321c104a6c911fe5598050a8'}",
            "dataset":"osv",
            "summary":"Integer overflows in Tensorflow ### Impact \nThe [implementation of `AddManySparseToTensorsMap`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc) is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service):\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ntf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices=[(0,0),(0,1),(0,2),(4,3),(5,0),(5,1)],\n    sparse_values=[1,1,1,1,1,1],\n    sparse_shape=[2**32,2**32],\n    container='',\n    shared_name='',\n    name=None)\n```\n\nWe are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The latter is an instance of [TFSA-2021-198](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/security\/advisory\/tfsa-2021-198.md) (CVE-2021-41197) and is easily fixed by replacing a call to `TensorShape` constructor with a call to `BuildTensorShape` static helper factory.\n### Patches\nWe have patched the issue in GitHub commits [b51b82fe65ebace4475e3c54eb089c18a4403f1c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b51b82fe65ebace4475e3c54eb089c18a4403f1c) and [a68f68061e263a88321c104a6c911fe5598050a8](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a68f68061e263a88321c104a6c911fe5598050a8).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
            "published_date":"2022-02-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b51b82fe65ebace4475e3c54eb089c18a4403f1c",
            "commit_sha":"b51b82fe65ebace4475e3c54eb089c18a4403f1c",
            "patch":"MULTI",
            "chain_ord":"['b51b82fe65ebace4475e3c54eb089c18a4403f1c', 'a68f68061e263a88321c104a6c911fe5598050a8']",
            "before_first_fix_commit":"{'e8f4be7958736823b9f56090611ec2fb09824d51'}",
            "last_fix_commit":"a68f68061e263a88321c104a6c911fe5598050a8",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/09\/2021, 22:32:48",
            "message":"Add missing validation to `AddManySparseToTensorsMap`.\n\nSparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\nPiperOrigin-RevId: 415358027\nChange-Id: I96cbb672999cd1da772c22fabbd15507e32e12dc",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 2, 'total': 17}",
            "files":"{'tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc': {'additions': 15, 'deletions': 2, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b51b82fe65ebace4475e3c54eb089c18a4403f1c\/tensorflow%2Fcore%2Fkernels%2Fsparse_tensors_map_ops.cc', 'patch': '@@ -231,16 +231,29 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\\n                 errors::InvalidArgument(\\n                     \"Input indices should be a matrix but received shape \",\\n                     input_indices->shape().DebugString()));\\n-\\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\\n                 errors::InvalidArgument(\\n                     \"Input values should be a vector but received shape \",\\n                     input_values->shape().DebugString()));\\n-\\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\\n                 errors::InvalidArgument(\\n                     \"Input shape should be a vector but received shape \",\\n                     input_shape->shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context,\\n+        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Number of values must match first dimension of indices. \", \"Got \",\\n+            input_values->shape().dim_size(0),\\n+            \" values, indices shape: \", input_indices->shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context,\\n+        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\\n+        errors::InvalidArgument(\\n+            \"Number of dimensions must match second dimension of indices. \",\\n+            \"Got \", input_shape->shape().dim_size(0),\\n+            \" dimensions, indices shape: \",\\n+            input_indices->shape().DebugString()));\\n \\n     int rank = input_shape->NumElements();'}}",
            "message_norm":"add missing validation to `addmanysparsetotensorsmap`.\n\nsparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\npiperorigin-revid: 415358027\nchange-id: i96cbb672999cd1da772c22fabbd15507e32e12dc",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('415358027', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":2921,
            "vuln_id":"GHSA-rcvx-rmvf-mxch",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/eclipse\/hawkbit\/commit\/94b7c12cde1b38eda5414bd88d6d068008cfb9f9'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Eclipse Hawkbit In all version of Eclipse Hawkbit prior to 0.3.0M7, the HTTP 404 (Not Found) JSON response body returned by the REST API may contain unsafe characters within the path attribute. Sending a POST request to a non existing resource will return the full path from the given URL unescaped to the client.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/eclipse\/hawkbit",
            "commit_href":"https:\/\/github.com\/eclipse\/hawkbit\/commit\/94b7c12cde1b38eda5414bd88d6d068008cfb9f9",
            "commit_sha":"94b7c12cde1b38eda5414bd88d6d068008cfb9f9",
            "patch":"SINGLE",
            "chain_ord":"['94b7c12cde1b38eda5414bd88d6d068008cfb9f9']",
            "before_first_fix_commit":"{'8816396d18880d2020743ce2e83a08446449d0db'}",
            "last_fix_commit":"94b7c12cde1b38eda5414bd88d6d068008cfb9f9",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/12\/2021, 10:56:44",
            "message":"Fixes #1067\n\nJSON body response for HTTP 404 error may contain unsafe URL path characters. Thus removing path from the response\n\nSigned-off-by: Dominic Schabel <dominic.schabel@bosch.io>",
            "author":"Dominic Schabel",
            "comments":null,
            "stats":"{'additions': 22, 'deletions': 4, 'total': 26}",
            "files":"{'hawkbit-runtime\/hawkbit-update-server\/src\/main\/java\/org\/eclipse\/hawkbit\/app\/ErrorController.java': {'additions': 22, 'deletions': 4, 'changes': 26, 'status': 'renamed', 'raw_url': 'https:\/\/github.com\/eclipse\/hawkbit\/raw\/94b7c12cde1b38eda5414bd88d6d068008cfb9f9\/hawkbit-runtime%2Fhawkbit-update-server%2Fsrc%2Fmain%2Fjava%2Forg%2Feclipse%2Fhawkbit%2Fapp%2FErrorController.java', 'patch': '@@ -8,6 +8,8 @@\\n  *\/\\n package org.eclipse.hawkbit.app;\\n \\n+import java.util.Map;\\n+\\n import javax.servlet.http.HttpServletRequest;\\n import javax.servlet.http.HttpServletResponse;\\n \\n@@ -23,22 +25,23 @@\\n \/**\\n  * Error page controller that ensures that ocet stream does not return text in\\n  * case of an error.\\n- *\\n  *\/\\n @Controller\\n \/\/ Exception squid:S3752 - errors need handling for all methods\\n @SuppressWarnings(\"squid:S3752\")\\n-public class StreamAwareErrorController extends BasicErrorController {\\n+public class ErrorController extends BasicErrorController {\\n+\\n+    private static final String PATH = \"path\";\\n \\n     \/**\\n-     * A new {@link StreamAwareErrorController}.\\n+     * A new {@link ErrorController}.\\n      * \\n      * @param errorAttributes\\n      *            the error attributes\\n      * @param serverProperties\\n      *            configuration properties\\n      *\/\\n-    public StreamAwareErrorController(final ErrorAttributes errorAttributes, final ServerProperties serverProperties) {\\n+    public ErrorController(final ErrorAttributes errorAttributes, final ServerProperties serverProperties) {\\n         super(errorAttributes, serverProperties.getError());\\n     }\\n \\n@@ -48,4 +51,19 @@ public ResponseEntity<Void> errorStream(final HttpServletRequest request, final\\n         return new ResponseEntity<>(status);\\n     }\\n \\n+    @Override\\n+    @RequestMapping\\n+    public ResponseEntity<Map<String, Object>> error(final HttpServletRequest request) {\\n+        final HttpStatus status = getStatus(request);\\n+        final Map<String, Object> body = getErrorAttributesWithoutPath(request);\\n+        return new ResponseEntity<>(body, status);\\n+    }\\n+\\n+    private Map<String, Object> getErrorAttributesWithoutPath(final HttpServletRequest request) {\\n+        final Map<String, Object> body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL));\\n+        if (body != null && body.containsKey(PATH)) {\\n+            body.remove(PATH);\\n+        }\\n+        return body;\\n+    }\\n }'}}",
            "message_norm":"fixes #1067\n\njson body response for http 404 error may contain unsafe url path characters. thus removing path from the response\n\nsigned-off-by: dominic schabel <dominic.schabel@bosch.io>",
            "language":"en",
            "entities":"[('fixes', 'ACTION', ''), ('#1067', 'ISSUE', ''), ('error', 'FLAW', ''), ('unsafe', 'SECWORD', ''), ('removing', 'ACTION', ''), ('dominic.schabel@bosch.io', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['hawkbit-runtime\/hawkbit-update-server\/src\/main\/java\/org\/eclipse\/hawkbit\/app\/ErrorController.java'])",
            "num_files":1.0
        },
        {
            "index":2799,
            "vuln_id":"GHSA-qq74-vgcf-54c3",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/e5d575928b1371a7e07b09b6592822298335062a'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in ShowDoc ShowDoc is vulnerable to stored cross-site scripting via viva cshtm file upload in in versions 2.10.3 and prior. A patch is available and anticipated to be part of version 2.10.4.",
            "published_date":"2022-03-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/e5d575928b1371a7e07b09b6592822298335062a",
            "commit_sha":"e5d575928b1371a7e07b09b6592822298335062a",
            "patch":"SINGLE",
            "chain_ord":"['e5d575928b1371a7e07b09b6592822298335062a']",
            "before_first_fix_commit":"{'ba45d19e1d77a7eea866dab30eff5da552694891'}",
            "last_fix_commit":"e5d575928b1371a7e07b09b6592822298335062a",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2022, 05:07:40",
            "message":"bug",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'server\/Application\/Api\/Model\/AttachmentModel.class.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/e5d575928b1371a7e07b09b6592822298335062a\/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': '@@ -311,6 +311,7 @@ public function isDangerFilename($filename){\\n \\t\\t\\t|| $isDangerStr($filename , \".asa\")\\n \\t\\t\\t|| $isDangerStr($filename , \".cshtml\")\\n \\t\\t\\t|| $isDangerStr($filename , \".axd\")\\n+\\t\\t\\t|| $isDangerStr($filename , \"htm\")\\n \\t\\t) {\\n \\t\\t\\treturn true;\\n \\t\\t}'}}",
            "message_norm":"bug",
            "language":"id",
            "entities":"[('bug', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Model\/AttachmentModel.class.php'])",
            "num_files":1.0
        },
        {
            "index":246,
            "vuln_id":"GHSA-3ff2-r28g-w7h9",
            "cwe_id":"{'CWE-787', 'CWE-120'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c79ba87153ee343401dbe9d1954d7f79e521eb14'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `Transpose` ### Impact\nThe [shape inference function for `Transpose`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/ops\/array_ops.cc#L121-L185) is vulnerable to a heap buffer overflow:\n\n```python\nimport tensorflow as tf\n@tf.function\ndef test():\n  y = tf.raw_ops.Transpose(x=[1,2,3,4],perm=[-10])\n  return y\n\ntest()\n```\n\nThis occurs whenever `perm` contains negative elements. The shape inference function does not validate that the indices in `perm` are all valid:\n        \n```cc\nfor (int32_t i = 0; i < rank; ++i) {\n  int64_t in_idx = data[i];\n  if (in_idx >= rank) {\n    return errors::InvalidArgument(\"perm dim \", in_idx,\n                                   \" is out of range of input rank \", rank);\n  }\n  dims[i] = c->Dim(input, in_idx);\n}\n```\n\nwhere `Dim(tensor, index)` accepts either a positive index less than the rank of the tensor or the special value `-1` for unknown dimensions.\n\n### Patches\nWe have patched the issue in GitHub commit [c79ba87153ee343401dbe9d1954d7f79e521eb14](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c79ba87153ee343401dbe9d1954d7f79e521eb14).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-11-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c79ba87153ee343401dbe9d1954d7f79e521eb14",
            "commit_sha":"c79ba87153ee343401dbe9d1954d7f79e521eb14",
            "patch":"SINGLE",
            "chain_ord":"['c79ba87153ee343401dbe9d1954d7f79e521eb14']",
            "before_first_fix_commit":"{'042dc3be4c54a51c2608ad53dabaeb34afa3e63c'}",
            "last_fix_commit":"c79ba87153ee343401dbe9d1954d7f79e521eb14",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/15\/2021, 02:39:00",
            "message":"Make Transpose's shape inference function validate that negative `perm` values are within the tensor's rank.\n\nPiperOrigin-RevId: 403252853\nChange-Id: Ia6b31b45b237312668bb31c2c3b3c7bbce2d2610",
            "author":"Penporn Koanantakool",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'tensorflow\/core\/ops\/array_ops.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c79ba87153ee343401dbe9d1954d7f79e521eb14\/tensorflow%2Fcore%2Fops%2Farray_ops.cc', 'patch': '@@ -168,7 +168,7 @@ Status TransposeShapeFn(InferenceContext* c) {\\n \\n     for (int32_t i = 0; i < rank; ++i) {\\n       int64_t in_idx = data[i];\\n-      if (in_idx >= rank) {\\n+      if (in_idx >= rank || in_idx <= -rank) {\\n         return errors::InvalidArgument(\"perm dim \", in_idx,\\n                                        \" is out of range of input rank \", rank);\\n       }'}}",
            "message_norm":"make transpose's shape inference function validate that negative `perm` values are within the tensor's rank.\n\npiperorigin-revid: 403252853\nchange-id: ia6b31b45b237312668bb31c2c3b3c7bbce2d2610",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('403252853', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/ops\/array_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":1031,
            "vuln_id":"GHSA-7gfg-6934-mqq2",
            "cwe_id":"{'CWE-287'}",
            "score":5.6,
            "chain":"{'https:\/\/github.com\/pion\/dtls\/commit\/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0'}",
            "dataset":"osv",
            "summary":"Improper Authenication in Pion DTLS handleIncomingPacket in conn.go in Pion DTLS before 1.5.2 lacks a check for application data with epoch 0, which allows remote attackers to inject arbitrary unencrypted data after handshake completion.",
            "published_date":"2021-06-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/pion\/dtls",
            "commit_href":"https:\/\/github.com\/pion\/dtls\/commit\/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
            "commit_sha":"fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
            "patch":"SINGLE",
            "chain_ord":"['fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0']",
            "before_first_fix_commit":"{'82948855ecb86a9e0b86c8dd43d010cbc545dc94'}",
            "last_fix_commit":"fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/11\/2019, 09:12:16",
            "message":"Assert that ApplicationData has epoch != 0\n\nOtherwise we may accept unencrypted\/unauthenticated ApplicationData\nfrom a remote",
            "author":"Sean DuBois",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'conn.go': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pion\/dtls\/raw\/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0\/conn.go', 'patch': '@@ -559,6 +559,10 @@ func (c *Conn) handleIncomingPacket(buf []byte) (*alert, error) {\\n \\t\\tc.log.Trace(\"<- ChangeCipherSpec\")\\n \\t\\tc.setRemoteEpoch(c.getRemoteEpoch() + 1)\\n \\tcase *applicationData:\\n+\\t\\tif h.epoch == 0 {\\n+\\t\\t\\treturn &alert{alertLevelFatal, alertUnexpectedMessage}, fmt.Errorf(\"ApplicationData with epoch of 0\")\\n+\\t\\t}\\n+\\n \\t\\tc.decrypted <- content.data\\n \\tdefault:\\n \\t\\treturn &alert{alertLevelFatal, alertUnexpectedMessage}, fmt.Errorf(\"unhandled contentType %d\", content.contentType())'}}",
            "message_norm":"assert that applicationdata has epoch != 0\n\notherwise we may accept unencrypted\/unauthenticated applicationdata\nfrom a remote",
            "language":"en",
            "entities":"[('unencrypted', 'SECWORD', ''), ('unauthenticated', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['conn.go'])",
            "num_files":1.0
        },
        {
            "index":2213,
            "vuln_id":"GHSA-j85q-whc9-g4p9",
            "cwe_id":"{'CWE-338'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/4b962c1740311e0d46775023b6acba39ad60e370'}",
            "dataset":"osv",
            "summary":"Use of Cryptographically Weak Pseudo-Random Number Generator in showdoc showdoc is vulnerable to Use of Cryptographically Weak Pseudo-Random Number Generator (PRNG)",
            "published_date":"2021-09-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/4b962c1740311e0d46775023b6acba39ad60e370",
            "commit_sha":"4b962c1740311e0d46775023b6acba39ad60e370",
            "patch":"SINGLE",
            "chain_ord":"['4b962c1740311e0d46775023b6acba39ad60e370']",
            "before_first_fix_commit":"{'db53edb8323dd358dc955e71d8f1fad5dab4ab7b', '034328ab35fc2bf640bf7fef2be40a5d13123b11'}",
            "last_fix_commit":"4b962c1740311e0d46775023b6acba39ad60e370",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/03\/2021, 17:19:35",
            "message":"Merge pull request #1438 from michaellrowley\/security-patch\n\nCVE-2021-3678 Patch",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'server\/Application\/Api\/Controller\/AdminSettingController.class.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/4b962c1740311e0d46775023b6acba39ad60e370\/server%2FApplication%2FApi%2FController%2FAdminSettingController.class.php', 'patch': '@@ -166,7 +166,7 @@ public function getLoginSecretKey(){\\n         $this->checkAdmin();\\n         $login_secret_key = D(\"Options\")->get(\"login_secret_key\") ;\\n         if(!$login_secret_key){\\n-            $login_secret_key = md5(\"rgrsfsrfsrf\".time().rand(1,9000000000000000).uniqid());\\n+            $login_secret_key = bin2hex( random_bytes( 16 ) );\\n             D(\"Options\")->set(\"login_secret_key\",$login_secret_key) ;\\n         }\\n         $this->sendResult(array(\"login_secret_key\"=>$login_secret_key));\\n@@ -176,7 +176,7 @@ public function getLoginSecretKey(){\\n     public function resetLoginSecretKey(){\\n         $login_user = $this->checkLogin();\\n         $this->checkAdmin();\\n-        $login_secret_key = md5(\"rgrsfsrfsrf\".time().rand(1,9000000000000000).uniqid());\\n+        $login_secret_key = bin2hex( random_bytes( 16 ) );\\n         D(\"Options\")->set(\"login_secret_key\",$login_secret_key) ;\\n         $this->sendResult(array(\"login_secret_key\"=>$login_secret_key));'}}",
            "message_norm":"merge pull request #1438 from michaellrowley\/security-patch\n\ncve-2021-3678 patch",
            "language":"en",
            "entities":"[('#1438', 'ISSUE', ''), ('security', 'SECWORD', ''), ('cve-2021-3678', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Controller\/AdminSettingController.class.php'])",
            "num_files":1.0
        },
        {
            "index":82,
            "vuln_id":"GHSA-2cpx-427x-q2c6",
            "cwe_id":"{'CWE-190'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c'}",
            "dataset":"osv",
            "summary":"CHECK-fail in AddManySparseToTensorsMap ### Impact\nAn attacker can trigger a denial of service via a `CHECK`-fail in  `tf.raw_ops.AddManySparseToTensorsMap`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nsparse_indices = tf.constant(530, shape=[1, 1], dtype=tf.int64)\nsparse_values = tf.ones([1], dtype=tf.int64)\n\nshape = tf.Variable(tf.ones([55], dtype=tf.int64))\nshape[:8].assign(np.array([855, 901, 429, 892, 892, 852, 93, 96], dtype=np.int64))\n\ntf.raw_ops.AddManySparseToTensorsMap(sparse_indices=sparse_indices,\n                    sparse_values=sparse_values,\n                    sparse_shape=shape)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f9896890c4c703ae0a0845394086e2e1e523299\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc#L257) takes the values specified in `sparse_shape` as dimensions for the output shape: \n\n```cc\n    TensorShape tensor_input_shape(input_shape->vec<int64>());\n```\n\nThe [`TensorShape` constructor](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f9896890c4c703ae0a0845394086e2e1e523299\/tensorflow\/core\/framework\/tensor_shape.cc#L183-L188) uses a `CHECK` operation which triggers when [`InitDims`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f9896890c4c703ae0a0845394086e2e1e523299\/tensorflow\/core\/framework\/tensor_shape.cc#L212-L296) returns a non-OK status.\n  \n```cc\ntemplate <class Shape>\nTensorShapeBase<Shape>::TensorShapeBase(gtl::ArraySlice<int64> dim_sizes) {\n  set_tag(REP16);\n  set_data_type(DT_INVALID);\n  TF_CHECK_OK(InitDims(dim_sizes));\n}\n```\n\nIn our scenario, this occurs when adding a dimension from the argument results in overflow:\n\n```cc\ntemplate <class Shape>\nStatus TensorShapeBase<Shape>::InitDims(gtl::ArraySlice<int64> dim_sizes) {\n  ...\n  Status status = Status::OK();\n  for (int64 s : dim_sizes) {\n    status.Update(AddDimWithStatus(internal::SubtleMustCopy(s)));\n    if (!status.ok()) {\n      return status;\n    }\n  }\n}\n\ntemplate <class Shape>\nStatus TensorShapeBase<Shape>::AddDimWithStatus(int64 size) {\n  ...\n  int64 new_num_elements;\n  if (kIsPartial && (num_elements() < 0 || size < 0)) {\n    new_num_elements = -1;\n  } else {\n    new_num_elements = MultiplyWithoutOverflow(num_elements(), size);\n    if (TF_PREDICT_FALSE(new_num_elements < 0)) {\n        return errors::Internal(\"Encountered overflow when multiplying \",\n                                num_elements(), \" with \", size,\n                                \", result: \", new_num_elements);\n      }\n  }\n  ...\n}\n```\n\nThis is a legacy implementation of the constructor and operations should use `BuildTensorShapeBase` or `AddDimWithStatus` to prevent `CHECK`-failures in the presence of overflows.\n\n### Patches\nWe have patched the issue in GitHub commit [69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c",
            "commit_sha":"69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c",
            "patch":"SINGLE",
            "chain_ord":"['69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c']",
            "before_first_fix_commit":"{'6f9896890c4c703ae0a0845394086e2e1e523299'}",
            "last_fix_commit":"69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/20\/2021, 19:14:41",
            "message":"Fix overflow CHECK issue with `tf.raw_ops.AddManySparseToTensorsMap`.\n\nPiperOrigin-RevId: 369492969\nChange-Id: I1d70d6c0c92e3d7a25bc3b3aa2a0c0ac9688bf81",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 7, 'total': 26}",
            "files":"{'tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc': {'additions': 19, 'deletions': 7, 'changes': 26, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c\/tensorflow%2Fcore%2Fkernels%2Fsparse_tensors_map_ops.cc', 'patch': '@@ -21,16 +21,14 @@ limitations under the License.\\n #include <utility>\\n #include <vector>\\n \\n-#include \"tensorflow\/core\/framework\/op_kernel.h\"\\n-#include \"tensorflow\/core\/framework\/register_types.h\"\\n-\\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n #include \"tensorflow\/core\/framework\/resource_mgr.h\"\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_util.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\\n+#include \"tensorflow\/core\/util\/overflow.h\"\\n #include \"tensorflow\/core\/util\/sparse\/sparse_tensor.h\"\\n \\n namespace tensorflow {\\n@@ -254,16 +252,30 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\\n         errors::InvalidArgument(\\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\\n \\n-    TensorShape tensor_input_shape(input_shape->vec<int64>());\\n+    auto input_shape_vec = input_shape->vec<int64>();\\n+    int new_num_elements = 1;\\n+    bool overflow_ocurred = false;\\n+    for (int i = 0; i < input_shape_vec.size(); i++) {\\n+      new_num_elements =\\n+          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\\n+      if (new_num_elements < 0) {\\n+        overflow_ocurred = true;\\n+      }\\n+    }\\n+\\n+    OP_REQUIRES(\\n+        context, !overflow_ocurred,\\n+        errors::Internal(\"Encountered overflow from large input shape.\"));\\n+\\n+    TensorShape tensor_input_shape(input_shape_vec);\\n     gtl::InlinedVector<int64, 8> std_order(rank);\\n     std::iota(std_order.begin(), std_order.end(), 0);\\n     SparseTensor input_st;\\n     OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\\n                                                  tensor_input_shape, std_order,\\n                                                  &input_st));\\n \\n-    auto input_shape_t = input_shape->vec<int64>();\\n-    const int64 N = input_shape_t(0);\\n+    const int64 N = input_shape_vec(0);\\n \\n     Tensor sparse_handles(DT_INT64, TensorShape({N}));\\n     auto sparse_handles_t = sparse_handles.vec<int64>();\\n@@ -274,7 +286,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\\n     \/\/ minibatch entries.\\n     TensorShape output_shape;\\n     OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\\n-                                input_shape_t.data() + 1,\\n+                                input_shape_vec.data() + 1,\\n                                 input_shape->NumElements() - 1, &output_shape));\\n \\n     \/\/ Get groups by minibatch dimension'}}",
            "message_norm":"fix overflow check issue with `tf.raw_ops.addmanysparsetotensorsmap`.\n\npiperorigin-revid: 369492969\nchange-id: i1d70d6c0c92e3d7a25bc3b3aa2a0c0ac9688bf81",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('369492969', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":2747,
            "vuln_id":"GHSA-qfxv-qqvg-24pg",
            "cwe_id":"{'CWE-78'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/Turistforeningen\/node-im-metadata\/commit\/ea15dddbe0f65694bfde36b78dd488e90f246639'}",
            "dataset":"osv",
            "summary":"OS Command Injection in im-metadata im-metadata through 3.0.1 allows remote attackers to execute arbitrary commands via the \"exec\" argument. It is possible to inject arbitrary commands as part of the metadata options which is given to the \"exec\" function.",
            "published_date":"2021-04-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/Turistforeningen\/node-im-metadata",
            "commit_href":"https:\/\/github.com\/Turistforeningen\/node-im-metadata\/commit\/ea15dddbe0f65694bfde36b78dd488e90f246639",
            "commit_sha":"ea15dddbe0f65694bfde36b78dd488e90f246639",
            "patch":"SINGLE",
            "chain_ord":"['ea15dddbe0f65694bfde36b78dd488e90f246639']",
            "before_first_fix_commit":"{'049ce24dbb4302811b9247444347da6561605a8a'}",
            "last_fix_commit":"ea15dddbe0f65694bfde36b78dd488e90f246639",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/03\/2020, 21:26:09",
            "message":"fix: check path argument before processing (#10)\n\nhotfix to re mediate command injection",
            "author":"Sam Sanoop",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 6, 'total': 15}",
            "files":"{'index.js': {'additions': 9, 'deletions': 6, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Turistforeningen\/node-im-metadata\/raw\/ea15dddbe0f65694bfde36b78dd488e90f246639\/index.js', 'patch': \"@@ -9,15 +9,18 @@ module.exports = function(path, opts, cb) {\\n     opts = {};\\n   }\\n \\n-  var cmd = module.exports.cmd(path, opts);\\n-  opts.timeout = opts.timeout || 5000;\\n-\\n-  exec(cmd, opts, function(e, stdout, stderr) {\\n-    if (e) { return cb(e); }\\n+  if(\/;|&|`|\\\\$|\\\\(|\\\\)|\\\\|\\\\||\\\\||!|>|<|\\\\?|\\\\${\/g.test(JSON.stringify(path))) {\\n+    console.log('Input Validation failed, Suspicious Characters found');\\n+  } else {\\n+    var cmd = module.exports.cmd(path, opts);\\n+    opts.timeout = opts.timeout || 5000;\\n+    exec(cmd, opts, function(e, stdout, stderr) {\\n+      if (e) { return cb(e); }\\n     if (stderr) { return cb(new Error(stderr)); }\\n \\n-    return cb(null, module.exports.parse(path, stdout, opts));\\n+      return cb(null, module.exports.parse(path, stdout, opts));\\n   });\\n+}\\n };\\n \\n module.exports.cmd = function(path, opts) {\"}}",
            "message_norm":"fix: check path argument before processing (#10)\n\nhotfix to re mediate command injection",
            "language":"en",
            "entities":"[('#10', 'ISSUE', ''), ('hotfix', 'ACTION', ''), ('command injection', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":824,
            "vuln_id":"GHSA-6fc8-4gx4-v693",
            "cwe_id":"{'CWE-400', 'CWE-345'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/websockets\/ws\/commit\/00c425ec77993773d823f018f64a5c44e17023ff'}",
            "dataset":"osv",
            "summary":"ReDoS in Sec-Websocket-Protocol header ### Impact\n\nA specially crafted value of the `Sec-Websocket-Protocol` header can be used to significantly slow down a ws server.\n\n### Proof of concept\n\n```js\nfor (const length of [1000, 2000, 4000, 8000, 16000, 32000]) {\n  const value = 'b' + ' '.repeat(length) + 'x';\n  const start = process.hrtime.bigint();\n\n  value.trim().split(\/ *, *\/);\n\n  const end = process.hrtime.bigint();\n\n  console.log('length = %d, time = %f ns', length, end - start);\n}\n```\n\n### Patches\n\nThe vulnerability was fixed in ws@7.4.6 (https:\/\/github.com\/websockets\/ws\/commit\/00c425ec77993773d823f018f64a5c44e17023ff) and backported to ws@6.2.2 (https:\/\/github.com\/websockets\/ws\/commit\/78c676d2a1acefbc05292e9f7ea0a9457704bf1b) and ws@5.2.3 (https:\/\/github.com\/websockets\/ws\/commit\/76d47c1479002022a3e4357b3c9f0e23a68d4cd2).\n\n### Workarounds\n\nIn vulnerable versions of ws, the issue can be mitigated by reducing the maximum allowed length of the request headers using the [`--max-http-header-size=size`](https:\/\/nodejs.org\/api\/cli.html#cli_max_http_header_size_size) and\/or the [`maxHeaderSize`](https:\/\/nodejs.org\/api\/http.html#http_http_createserver_options_requestlistener) options.\n\n### Credits\n\nThe vulnerability was responsibly disclosed along with a fix in private by [Robert McLaughlin](https:\/\/github.com\/robmcl4) from University of California, Santa Barbara.",
            "published_date":"2021-05-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/websockets\/ws",
            "commit_href":"https:\/\/github.com\/websockets\/ws\/commit\/00c425ec77993773d823f018f64a5c44e17023ff",
            "commit_sha":"00c425ec77993773d823f018f64a5c44e17023ff",
            "patch":"SINGLE",
            "chain_ord":"['00c425ec77993773d823f018f64a5c44e17023ff']",
            "before_first_fix_commit":"{'990306d1446faf346c76452409a4c11455690514'}",
            "last_fix_commit":"00c425ec77993773d823f018f64a5c44e17023ff",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/25\/2021, 09:00:58",
            "message":"[security] Fix ReDoS vulnerability\n\nA specially crafted value of the `Sec-Websocket-Protocol` header could\nbe used to significantly slow down a ws server.\n\nPoC and fix were sent privately by Robert McLaughlin from University of\nCalifornia, Santa Barbara.",
            "author":"Luigi Pinca",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 1, 'total': 14}",
            "files":"{'lib\/websocket-server.js': {'additions': 13, 'deletions': 1, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/websockets\/ws\/raw\/00c425ec77993773d823f018f64a5c44e17023ff\/lib%2Fwebsocket-server.js', 'patch': \"@@ -286,7 +286,7 @@ class WebSocketServer extends EventEmitter {\\n     let protocol = req.headers['sec-websocket-protocol'];\\n \\n     if (protocol) {\\n-      protocol = protocol.trim().split(\/ *, *\/);\\n+      protocol = protocol.split(',').map(trim);\\n \\n       \/\/\\n       \/\/ Optionally call external protocol selection handler.\\n@@ -404,3 +404,15 @@ function abortHandshake(socket, code, message, headers) {\\n   socket.removeListener('error', socketOnError);\\n   socket.destroy();\\n }\\n+\\n+\/**\\n+ * Remove whitespace characters from both ends of a string.\\n+ *\\n+ * @param {String} str The string\\n+ * @return {String} A new string representing `str` stripped of whitespace\\n+ *     characters from both its beginning and end\\n+ * @private\\n+ *\/\\n+function trim(str) {\\n+  return str.trim();\\n+}\"}}",
            "message_norm":"[security] fix redos vulnerability\n\na specially crafted value of the `sec-websocket-protocol` header could\nbe used to significantly slow down a ws server.\n\npoc and fix were sent privately by robert mclaughlin from university of\ncalifornia, santa barbara.",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('protocol', 'SECWORD', ''), ('server', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/websocket-server.js'])",
            "num_files":1.0
        },
        {
            "index":3112,
            "vuln_id":"GHSA-vg44-fw64-cpjx",
            "cwe_id":"{'CWE-287'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/commit\/f32e529d13a53e55f558d903534d631846dc26ce'}",
            "dataset":"osv",
            "summary":"Incorrect Account Used for Signing ### Impact\n\nAnybody using this library to sign with a BIP44 account other than the first account may be affected. If a user is signing with the first account (i.e. the account at index `0`), or with the legacy MEW\/MyCrypto HD path, they are not affected.\n\nThe vulnerability impacts cases where the user signs a personal message or transaction without first adding the account. This includes cases where the user has already added the account in a previous session (i.e. they added the account, reset the application, then signed something). The serialization\/deserialization process does restore a previously added account, but it doesn&#39;t restore the index instructing the keyring to use that account for signing. As a result, after serializing then deserializing the keyring state, the account at index `0` is always used for signing even if it isn&#39;t the current account.\n\n### Patches\n\nThis has been patched ([#14](https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/pull\/14)) in version &gt;=0.2.1 of [`eth-ledger-bridge-keyring`](https:\/\/www.npmjs.com\/package\/eth-ledger-bridge-keyring), and in version &gt;=0.2.2 of [`@metamask\/eth-ledger-bridge-keyring`](https:\/\/www.npmjs.com\/package\/@metamask\/eth-ledger-bridge-keyring). Users are encouraged to migrate to the new package name.\n\n### Workarounds\n\nTo work around this problem without updating, you should remove then re-add the account before use. As long as the account was added during the lifetime of that process, signing with that account should work correctly.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [MetaMask\/eth-ledger-bridge-keyring on GitHub](https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring)\n* Email the MetaMask team at [hello@metamask.io](mailto:hello@metamask.io)",
            "published_date":"2020-03-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring",
            "commit_href":"https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/commit\/f32e529d13a53e55f558d903534d631846dc26ce",
            "commit_sha":"f32e529d13a53e55f558d903534d631846dc26ce",
            "patch":"SINGLE",
            "chain_ord":"['f32e529d13a53e55f558d903534d631846dc26ce']",
            "before_first_fix_commit":"{'25d96289bdffb369a70cbafd70b4ca1f1be47fcc'}",
            "last_fix_commit":"f32e529d13a53e55f558d903534d631846dc26ce",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/02\/2020, 22:58:21",
            "message":"Always sign transactions and messages with the correct account (#14)\n\nThe account used to sign transactions and messages should be the one\r\nthe transaction or message is from. Instead, the last connected account\r\nwas being used to sign any messages or transactions.\r\n\r\nThis was especially problematic considering the last connected account\r\nwas not persisted, meaning that signatures were being performed with\r\nthe wrong account after a reset (unless the last connected account\r\nhappened to be account 0, which was the default).\r\n\r\nA mapping of addresses to indexes as been added to the keyring state,\r\nand this mapping has been persisted. This should ensure the correct\r\naccount index is used, and thus the correct hd path, each time this\r\nkeyring is used for signing.",
            "author":"Mark Stacey",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 2, 'total': 17}",
            "files":"{'index.js': {'additions': 15, 'deletions': 2, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/raw\/f32e529d13a53e55f558d903534d631846dc26ce\/index.js', 'patch': \"@@ -18,6 +18,7 @@ const NETWORK_API_URLS = {\\n class LedgerBridgeKeyring extends EventEmitter {\\n   constructor (opts = {}) {\\n     super()\\n+    this.accountIndexes = {}\\n     this.bridgeUrl = null\\n     this.type = type\\n     this.page = 0\\n@@ -36,6 +37,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n     return Promise.resolve({\\n       hdPath: this.hdPath,\\n       accounts: this.accounts,\\n+      accountIndexes: this.accountIndexes,\\n       bridgeUrl: this.bridgeUrl,\\n       implementFullBIP44: false,\\n     })\\n@@ -45,6 +47,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n     this.hdPath = opts.hdPath || hdPathString\\n     this.bridgeUrl = opts.bridgeUrl || BRIDGE_URL\\n     this.accounts = opts.accounts || []\\n+    this.accountIndexes = opts.accountIndexes || {}\\n     this.implementFullBIP44 = opts.implementFullBIP44 || false\\n     return Promise.resolve()\\n   }\\n@@ -100,6 +103,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n             if (this._isBIP44()) {\\n               const path = this._getPathForIndex(i)\\n               address = await this.unlock(path)\\n+              this.accountIndexes[ethUtil.toChecksumAddress(address)] = i\\n             } else {\\n               address = this._addressFromIndex(pathBase, i)\\n             }\\n@@ -136,6 +140,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n       throw new Error(`Address ${address} not found in this keyring`)\\n     }\\n     this.accounts = this.accounts.filter(a => a.toLowerCase() !== address.toLowerCase())\\n+    delete this.accountIndexes[ethUtil.toChecksumAddress(address)]\\n   }\\n \\n   \/\/ tx is an instance of the ethereumjs-transaction class.\\n@@ -150,7 +155,11 @@ class LedgerBridgeKeyring extends EventEmitter {\\n \\n           let hdPath\\n           if (this._isBIP44()) {\\n-            hdPath = this._getPathForIndex(this.unlockedAccount)\\n+            const checksummedAddress = ethUtil.toChecksumAddress(address)\\n+            if (!this.accountIndexes[checksummedAddress]) {\\n+              reject(new Error(`Ledger: Index for address '${checksummedAddress}' not found`))\\n+            }\\n+            hdPath = this._getPathForIndex(this.accountIndexes[checksummedAddress])\\n           } else {\\n             hdPath = this._toLedgerPath(this._pathFromAddress(address))\\n           }\\n@@ -195,7 +204,11 @@ class LedgerBridgeKeyring extends EventEmitter {\\n         .then(_ => {\\n           let hdPath\\n           if (this._isBIP44()) {\\n-            hdPath = this._getPathForIndex(this.unlockedAccount)\\n+            const checksummedAddress = ethUtil.toChecksumAddress(withAccount)\\n+            if (!this.accountIndexes[checksummedAddress]) {\\n+              reject(new Error(`Ledger: Index for address '${checksummedAddress}' not found`))\\n+            }\\n+            hdPath = this._getPathForIndex(this.accountIndexes[checksummedAddress])\\n           } else {\\n             hdPath = this._toLedgerPath(this._pathFromAddress(withAccount))\\n           }\"}}",
            "message_norm":"always sign transactions and messages with the correct account (#14)\n\nthe account used to sign transactions and messages should be the one\r\nthe transaction or message is from. instead, the last connected account\r\nwas being used to sign any messages or transactions.\r\n\r\nthis was especially problematic considering the last connected account\r\nwas not persisted, meaning that signatures were being performed with\r\nthe wrong account after a reset (unless the last connected account\r\nhappened to be account 0, which was the default).\r\n\r\na mapping of addresses to indexes as been added to the keyring state,\r\nand this mapping has been persisted. this should ensure the correct\r\naccount index is used, and thus the correct hd path, each time this\r\nkeyring is used for signing.",
            "language":"en",
            "entities":"[('#14', 'ISSUE', ''), ('added', 'ACTION', ''), ('keyring', 'SECWORD', ''), ('ensure', 'ACTION', ''), ('keyring', 'SECWORD', ''), ('signing', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":20,
            "vuln_id":"GHSA-247x-2f9f-5wp7",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/448a16182065bd08a202d9057dd8ca541e67996c'}",
            "dataset":"osv",
            "summary":"Stack overflow in TensorFlow ### Impact\nThe `GraphDef` format in TensorFlow does not allow self recursive functions. The runtime assumes that this invariant is satisfied. However, a `GraphDef` containing a fragment such as the following can be consumed when loading a `SavedModel`:\n\n```\n  library {\n    function {\n      signature {\n        name: \"SomeOp\"\n        description: \"Self recursive op\"\n      }\n      node_def {\n        name: \"1\"\n        op: \"SomeOp\"\n      }\n      node_def {\n        name: \"2\"\n        op: \"SomeOp\"\n      }\n    }\n  } \n```\n\nThis would result in a stack overflow during execution as resolving each `NodeDef` means resolving the function itself and its nodes.\n\n### Patches\nWe have patched the issue in GitHub commit [448a16182065bd08a202d9057dd8ca541e67996c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/448a16182065bd08a202d9057dd8ca541e67996c).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/448a16182065bd08a202d9057dd8ca541e67996c",
            "commit_sha":"448a16182065bd08a202d9057dd8ca541e67996c",
            "patch":"SINGLE",
            "chain_ord":"['448a16182065bd08a202d9057dd8ca541e67996c']",
            "before_first_fix_commit":"{'7b1eba4193a389c7e92e01e585aeb71be97529cd'}",
            "last_fix_commit":"448a16182065bd08a202d9057dd8ca541e67996c",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/08\/2021, 00:49:32",
            "message":"Prevent stack overflow when FunctionLib in GraphDef has a self-recursive function.\n\nIt is likely that no recursivity is supported, but we should handle this separately.\n\nPiperOrigin-RevId: 414860329\nChange-Id: I02a2270e86282b37362ddd485eeef16fb986a9e0",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 18, 'deletions': 0, 'total': 18}",
            "files":"{'tensorflow\/cc\/saved_model\/loader.cc': {'additions': 18, 'deletions': 0, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/448a16182065bd08a202d9057dd8ca541e67996c\/tensorflow%2Fcc%2Fsaved_model%2Floader.cc', 'patch': '@@ -25,6 +25,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/attr_value.pb.h\"\\n #include \"tensorflow\/core\/framework\/function.pb.h\"\\n #include \"tensorflow\/core\/framework\/node_def.pb.h\"\\n+#include \"tensorflow\/core\/framework\/op_def.pb.h\"\\n #include \"tensorflow\/core\/framework\/tensor.pb.h\"\\n #include \"tensorflow\/core\/lib\/io\/path.h\"\\n #include \"tensorflow\/core\/lib\/monitoring\/counter.h\"\\n@@ -99,6 +100,19 @@ static Status ValidateNode(const NodeDef& node) {\\n   return Status::OK();\\n }\\n \\n+static Status ValidateFunctionNotRecursive(const FunctionDef& function) {\\n+  const auto& function_name = function.signature().name();\\n+  for (const auto& node : function.node_def()) {\\n+    if (node.op() == function_name) {\\n+      return errors::FailedPrecondition(\\n+          \"Function \", function_name,\\n+          \" is self recursive and TensorFlow does not support this scenario.\");\\n+    }\\n+  }\\n+\\n+  return Status::OK();\\n+}\\n+\\n static Status ValidateSavedTensors(const GraphDef& graph_def) {\\n   for (const auto& node : graph_def.node()) {\\n     TF_RETURN_IF_ERROR(ValidateNode(node));\\n@@ -110,6 +124,10 @@ static Status ValidateSavedTensors(const GraphDef& graph_def) {\\n       for (const auto& node : function.node_def()) {\\n         TF_RETURN_IF_ERROR(ValidateNode(node));\\n       }\\n+\\n+      \/\/ Also check that there is no recursivity in the library\\n+      \/\/ TODO(mihaimaruseac): Do more than self-recursivity\\n+      TF_RETURN_IF_ERROR(ValidateFunctionNotRecursive(function));\\n     }\\n   }'}}",
            "message_norm":"prevent stack overflow when functionlib in graphdef has a self-recursive function.\n\nit is likely that no recursivity is supported, but we should handle this separately.\n\npiperorigin-revid: 414860329\nchange-id: i02a2270e86282b37362ddd485eeef16fb986a9e0",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('414860329', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/cc\/saved_model\/loader.cc'])",
            "num_files":1.0
        },
        {
            "index":696,
            "vuln_id":"GHSA-5rwj-j5m3-3chj",
            "cwe_id":"{'CWE-401'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/sonicdoe\/detect-character-encoding\/commit\/d44356927b92e3b13e178071bf6d7c671766f588'}",
            "dataset":"osv",
            "summary":"Missing Release of Memory after Effective Lifetime in detect-character-encoding ### Impact\n\nIn detect-character-encoding v0.3.0 and earlier, allocated memory is not released.\n\n### Patches\n\nThe problem has been patched in [detect-character-encoding v0.3.1](https:\/\/github.com\/sonicdoe\/detect-character-encoding\/releases\/tag\/v0.3.1).\n\n### CVSS score\n\n[CVSS:3.1\/AV:N\/AC:L\/PR:N\/UI:N\/S:U\/C:N\/I:N\/A:H\/RL:O\/RC:C](https:\/\/www.first.org\/cvss\/calculator\/3.1#CVSS:3.1\/AV:N\/AC:L\/PR:N\/UI:N\/S:U\/C:N\/I:N\/A:H\/RL:O\/RC:C)\n\nBase Score: 7.5 (High)\nTemporal Score: 7.2 (High)\n\nSince detect-character-encoding is a library, the scoring is based on the \u201c[reasonable worst-case implementation scenario](https:\/\/www.first.org\/cvss\/v3.1\/user-guide#3-7-Scoring-Vulnerabilities-in-Software-Libraries-and-Similar)\u201d, namely, using detect-character-encoding in a program accessible over the internet which becomes unavailable when running out of memory. Depending on your specific implementation, the vulnerability\u2019s severity in your program may be different.\n\n### Proof of concept\n\n```js\nconst express = require(\"express\");\nconst detectCharacterEncoding = require(\"detect-character-encoding\");\n\nconst app = express();\n\napp.get(\"\/\", (req, res) => {\n  detectCharacterEncoding(Buffer.from(\"foo\"));\n\n  res.end();\n});\n\napp.listen(3000);\n```\n\n`hey -n 1000000 http:\/\/localhost:3000` ([`hey`](https:\/\/github.com\/rakyll\/hey)) causes the Node.js process to consume more and more memory.\n\n### References\n\n- https:\/\/github.com\/sonicdoe\/detect-character-encoding\/commit\/d44356927b92e3b13e178071bf6d7c671766f588\n- https:\/\/github.com\/sonicdoe\/detect-character-encoding\/pull\/6",
            "published_date":"2021-09-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/sonicdoe\/detect-character-encoding",
            "commit_href":"https:\/\/github.com\/sonicdoe\/detect-character-encoding\/commit\/d44356927b92e3b13e178071bf6d7c671766f588",
            "commit_sha":"d44356927b92e3b13e178071bf6d7c671766f588",
            "patch":"SINGLE",
            "chain_ord":"['d44356927b92e3b13e178071bf6d7c671766f588']",
            "before_first_fix_commit":"{'2e3aa333a573960edf2d782bca3b25a01e49678b'}",
            "last_fix_commit":"d44356927b92e3b13e178071bf6d7c671766f588",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/09\/2017, 18:19:58",
            "message":"Fix memory leak by properly closing `charsetDetector`",
            "author":"Michael Hertsch",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'icuWrapper.cpp': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sonicdoe\/detect-character-encoding\/raw\/d44356927b92e3b13e178071bf6d7c671766f588\/icuWrapper.cpp', 'patch': '@@ -28,27 +28,31 @@ NAN_METHOD(DetectCharacterEncoding) {\\n \\n \\tif(U_FAILURE(errorCode)) {\\n \\t\\tNan::ThrowError(\"Failed to set ICU charset detector\u2019s text.\");\\n+\\t\\tucsdet_close(charsetDetector);\\n \\t\\treturn;\\n \\t}\\n \\n \\tcharsetMatch = ucsdet_detect(charsetDetector, &errorCode);\\n \\n \\tif(U_FAILURE(errorCode)) {\\n \\t\\tNan::ThrowError(\"Failed to detect charset.\");\\n+\\t\\tucsdet_close(charsetDetector);\\n \\t\\treturn;\\n \\t}\\n \\n \\tconst char *charsetName = ucsdet_getName(charsetMatch, &errorCode);\\n \\n \\tif(U_FAILURE(errorCode)) {\\n \\t\\tNan::ThrowError(\"Failed to get name from charset match.\");\\n+\\t\\tucsdet_close(charsetDetector);\\n \\t\\treturn;\\n \\t}\\n \\n \\tint32_t confidence = ucsdet_getConfidence(charsetMatch, &errorCode);\\n \\n \\tif(U_FAILURE(errorCode)) {\\n \\t\\tNan::ThrowError(\"Failed to get confidence from charset match.\");\\n+\\t\\tucsdet_close(charsetDetector);\\n \\t\\treturn;\\n \\t}\\n \\n@@ -57,6 +61,7 @@ NAN_METHOD(DetectCharacterEncoding) {\\n \\tobj->Set(Nan::New<v8::String>(\"confidence\").ToLocalChecked(), Nan::New<v8::Number>(confidence));\\n \\n \\tinfo.GetReturnValue().Set(obj);\\n+\\tucsdet_close(charsetDetector);\\n }\\n \\n void Init(v8::Local<v8::Object> exports) {'}}",
            "message_norm":"fix memory leak by properly closing `charsetdetector`",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('memory leak', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['icuWrapper.cpp'])",
            "num_files":1.0
        },
        {
            "index":2613,
            "vuln_id":"GHSA-ppc3-fpvh-7396",
            "cwe_id":"{'CWE-362'}",
            "score":7.0,
            "chain":"{'https:\/\/github.com\/apache\/netbeans-html4j\/commit\/fa70e507e5555e1adb4f6518479fc408a7abd0e6'}",
            "dataset":"osv",
            "summary":"Improper synchronization in Apache Netbeans HTML\/Java API There exists a race condition between the deletion of the temporary file and the creation of the temporary directory in `webkit` subproject of HTML\/Java API version 1.7. A similar vulnerability has recently been disclosed in other Java projects and the fix in HTML\/Java API version 1.7.1 follows theirs: To avoid local privilege escalation version 1.7.1 creates the temporary directory atomically without dealing with the temporary file.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/netbeans-html4j",
            "commit_href":"https:\/\/github.com\/apache\/netbeans-html4j\/commit\/fa70e507e5555e1adb4f6518479fc408a7abd0e6",
            "commit_sha":"fa70e507e5555e1adb4f6518479fc408a7abd0e6",
            "patch":"SINGLE",
            "chain_ord":"['fa70e507e5555e1adb4f6518479fc408a7abd0e6']",
            "before_first_fix_commit":"{'d1dcd9c0542ac46d7764256a81057dfbe2d8805a'}",
            "last_fix_commit":"fa70e507e5555e1adb4f6518479fc408a7abd0e6",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/15\/2020, 08:56:27",
            "message":"createTempDirectory atomically",
            "author":"Jaroslav Tulach",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 3, 'total': 4}",
            "files":"{'webkit\/src\/main\/java\/org\/netbeans\/html\/presenters\/webkit\/UnJarResources.java': {'additions': 1, 'deletions': 3, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/netbeans-html4j\/raw\/fa70e507e5555e1adb4f6518479fc408a7abd0e6\/webkit%2Fsrc%2Fmain%2Fjava%2Forg%2Fnetbeans%2Fhtml%2Fpresenters%2Fwebkit%2FUnJarResources.java', 'patch': '@@ -39,9 +39,7 @@ static URL extract(URL url) throws IOException {\\n         if (jar == null) {\\n             return url;\\n         }\\n-        File dir = File.createTempFile(jar.getName(), \".dir\");\\n-        dir.delete();\\n-        dir.mkdirs();\\n+        File dir = Files.createTempDirectory(jar.getName() + \".dir\").toFile();\\n \\n         Enumeration<JarEntry> en = jar.entries();\\n         while (en.hasMoreElements()) {'}}",
            "message_norm":"createtempdirectory atomically",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['webkit\/src\/main\/java\/org\/netbeans\/html\/presenters\/webkit\/UnJarResources.java'])",
            "num_files":1.0
        },
        {
            "index":460,
            "vuln_id":"GHSA-4q2w-rw7m-xqw6",
            "cwe_id":"{'CWE-807'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/sony\/nnabla\/commit\/e87347648ab7210529a0e60f0849680de8e9b63a'}",
            "dataset":"osv",
            "summary":"Sony Neural Network Libraries reliance on untrusted inputs prior to v1.0.10 nbla\/logger.cpp in libnnabla.a in Sony Neural Network Libraries (aka nnabla) prior to v1.0.10 relies on the HOME environment variable, which might be untrusted.",
            "published_date":"2022-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/sony\/nnabla",
            "commit_href":"https:\/\/github.com\/sony\/nnabla\/commit\/e87347648ab7210529a0e60f0849680de8e9b63a",
            "commit_sha":"e87347648ab7210529a0e60f0849680de8e9b63a",
            "patch":"SINGLE",
            "chain_ord":"['e87347648ab7210529a0e60f0849680de8e9b63a']",
            "before_first_fix_commit":"{'b164980f08f3ed7740439b51d4e5ca79db0d149e', '05cd50648786cc044d3b131239299f91f399e3b8'}",
            "last_fix_commit":"e87347648ab7210529a0e60f0849680de8e9b63a",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/15\/2018, 08:24:39",
            "message":"Merge pull request #299 from sony\/feature\/20181107-fix-getenv-usage\n\nAvoid get HOME dir with getenv.",
            "author":"Takuya Narihira",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 6, 'total': 12}",
            "files":"{'src\/nbla\/logger.cpp': {'additions': 6, 'deletions': 6, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sony\/nnabla\/raw\/e87347648ab7210529a0e60f0849680de8e9b63a\/src%2Fnbla%2Flogger.cpp', 'patch': '@@ -48,21 +48,21 @@ std::shared_ptr<spdlog::logger> get_logger(void) {\\n       logfile = logpath + \"\\\\\\\\nbla_lib.log\";\\n     }\\n #else\\n-    const char *homedir = getenv(\"HOME\");\\n+    const char *homedir = nullptr;\\n     if (homedir == nullptr) {\\n       struct passwd *pw = getpwuid(getuid());\\n       if (pw != nullptr) {\\n         homedir = pw->pw_dir;\\n+        logpath = homedir;\\n+        logpath += \"\/nnabla_data\";\\n+        mkdir(logpath.c_str(), S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH);\\n       }\\n     }\\n     if (homedir == nullptr) {\\n-      logpath = \"\/tmp_\";\\n+      logpath = \"\/tmp\/nnabla_\";\\n       logpath += getuid();\\n-    } else {\\n-      logpath = homedir;\\n+      mkdir(logpath.c_str(), S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH);\\n     }\\n-    logpath += \"\/nnabla_data\";\\n-    mkdir(logpath.c_str(), S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH);\\n     logpath += \"\/log\";\\n     mkdir(logpath.c_str(), S_IRWXU | S_IRWXG | S_IROTH | S_IXOTH);\\n     logfile = logpath + \"\/nbla_lib.log\";'}}",
            "message_norm":"merge pull request #299 from sony\/feature\/20181107-fix-getenv-usage\n\navoid get home dir with getenv.",
            "language":"en",
            "entities":"[('#299', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/nbla\/logger.cpp'])",
            "num_files":1.0
        },
        {
            "index":1348,
            "vuln_id":"GHSA-9959-6p3m-wxpc",
            "cwe_id":"{'CWE-119'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/netty\/netty\/commit\/2fa9400a59d0563a66908aba55c41e7285a04994'}",
            "dataset":"osv",
            "summary":"Denial of service in Netty The SslHandler in Netty before 3.9.2 allows remote attackers to cause a denial of service (infinite loop and CPU consumption) via a crafted SSLv2Hello message.",
            "published_date":"2020-06-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/netty\/netty",
            "commit_href":"https:\/\/github.com\/netty\/netty\/commit\/2fa9400a59d0563a66908aba55c41e7285a04994",
            "commit_sha":"2fa9400a59d0563a66908aba55c41e7285a04994",
            "patch":"SINGLE",
            "chain_ord":"['2fa9400a59d0563a66908aba55c41e7285a04994']",
            "before_first_fix_commit":"{'129c17aaa4ac5c611519ef480c35a12e8282b807'}",
            "last_fix_commit":"2fa9400a59d0563a66908aba55c41e7285a04994",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/10\/2014, 08:55:19",
            "message":"Fix a bug where SslHandler does not handle SSLv2Hello correctly\n\nMotivation:\n\nWhen a SSLv2Hello message is received, SSLEngine expects the application buffer size to be more than 30KB which is larger than what SslBufferPool can provide.  SSLEngine will always return with BUFFER_OVERFLOW status, blocking the SSL session from continuing the handshake.\n\nModifications:\n\nWhen SSLEngine.getSession().getApplicationBufferSize() returns a value larger than what SslBufferPool provides, allocate a temporary heap buffer.\n\nResult:\n\nSSLv2Hello is handled correctly.",
            "author":"Trustin Lee",
            "comments":"{'com_1': {'author': 'normanmaurer', 'datetime': '06\/10\/2014, 10:12:19', 'body': \"shouldn't this check against remaining() ?\"}, 'com_2': {'author': 'trustin', 'datetime': '06\/10\/2014, 11:07:26', 'body': 'Not really because we always clear the buffer at the finally block below.'}}",
            "stats":"{'additions': 15, 'deletions': 5, 'total': 20}",
            "files":"{'src\/main\/java\/org\/jboss\/netty\/handler\/ssl\/SslHandler.java': {'additions': 15, 'deletions': 5, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/netty\/netty\/raw\/2fa9400a59d0563a66908aba55c41e7285a04994\/src%2Fmain%2Fjava%2Forg%2Fjboss%2Fnetty%2Fhandler%2Fssl%2FSslHandler.java', 'patch': '@@ -1268,8 +1268,18 @@ private ChannelBuffer unwrap(\\n                     \/\/ always contain at least one record in decode().  Therefore, if SSLEngine.unwrap() returns\\n                     \/\/ BUFFER_OVERFLOW, it is always resolved by retrying after emptying the application buffer.\\n                     for (;;) {\\n+                        final int outAppBufSize = engine.getSession().getApplicationBufferSize();\\n+                        final ByteBuffer outAppBuf;\\n+                        if (nioOutAppBuf.capacity() < outAppBufSize) {\\n+                            \/\/ SSLEngine wants a buffer larger than what the pool can provide.\\n+                            \/\/ Allocate a temporary heap buffer.\\n+                            outAppBuf = ByteBuffer.allocate(outAppBufSize);\\n+                        } else {\\n+                            outAppBuf = nioOutAppBuf;\\n+                        }\\n+\\n                         try {\\n-                            result = engine.unwrap(nioInNetBuf, nioOutAppBuf);\\n+                            result = engine.unwrap(nioInNetBuf, outAppBuf);\\n                             switch (result.getStatus()) {\\n                                 case CLOSED:\\n                                     \/\/ notify about the CLOSED state of the SSLEngine. See #137\\n@@ -1283,21 +1293,21 @@ private ChannelBuffer unwrap(\\n \\n                             break;\\n                         } finally {\\n-                            nioOutAppBuf.flip();\\n+                            outAppBuf.flip();\\n \\n                             \/\/ Sync the offset of the inbound buffer.\\n                             nettyInNetBuf.readerIndex(\\n                                     nettyInNetBufStartOffset + nioInNetBuf.position() - nioInNetBufStartOffset);\\n \\n                             \/\/ Copy the unwrapped data into a smaller buffer.\\n-                            if (nioOutAppBuf.hasRemaining()) {\\n+                            if (outAppBuf.hasRemaining()) {\\n                                 if (nettyOutAppBuf == null) {\\n                                     ChannelBufferFactory factory = ctx.getChannel().getConfig().getBufferFactory();\\n                                     nettyOutAppBuf = factory.getBuffer(initialNettyOutAppBufCapacity);\\n                                 }\\n-                                nettyOutAppBuf.writeBytes(nioOutAppBuf);\\n+                                nettyOutAppBuf.writeBytes(outAppBuf);\\n                             }\\n-                            nioOutAppBuf.clear();\\n+                            outAppBuf.clear();\\n                         }\\n                     }'}}",
            "message_norm":"fix a bug where sslhandler does not handle sslv2hello correctly\n\nmotivation:\n\nwhen a sslv2hello message is received, sslengine expects the application buffer size to be more than 30kb which is larger than what sslbufferpool can provide.  sslengine will always return with buffer_overflow status, blocking the ssl session from continuing the handshake.\n\nmodifications:\n\nwhen sslengine.getsession().getapplicationbuffersize() returns a value larger than what sslbufferpool provides, allocate a temporary heap buffer.\n\nresult:\n\nsslv2hello is handled correctly.",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('bug', 'FLAW', ''), ('buffer_overflow', 'SECWORD', ''), ('ssl', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/org\/jboss\/netty\/handler\/ssl\/SslHandler.java'])",
            "num_files":1.0
        },
        {
            "index":1271,
            "vuln_id":"GHSA-8w3x-r6x7-c5r5",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/3c2a14e676a57e5d77a16255965988eef48f9065'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in pimcore pimcore is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
            "published_date":"2021-12-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/3c2a14e676a57e5d77a16255965988eef48f9065",
            "commit_sha":"3c2a14e676a57e5d77a16255965988eef48f9065",
            "patch":"SINGLE",
            "chain_ord":"['3c2a14e676a57e5d77a16255965988eef48f9065']",
            "before_first_fix_commit":"{'a5e13bea6315b7bee8fb44f83a38029d065f97a3'}",
            "last_fix_commit":"3c2a14e676a57e5d77a16255965988eef48f9065",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/09\/2021, 11:53:00",
            "message":"[Admin UI] DataObject Class - escape general settings input values (#10991)\n\n* [Admin UI] DataObject Class - escape general settings input values\r\n\r\n* Update bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/object\/classes\/class.js\r\n\r\n* [Admin UI] DataObject Class - escape general settings input values\r\n\r\n* [Admin UI] DataObject Class - escape general settings input values",
            "author":"Divesh Pahuja",
            "comments":null,
            "stats":"{'additions': 20, 'deletions': 1, 'total': 21}",
            "files":"{'bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/object\/classes\/class.js': {'additions': 20, 'deletions': 1, 'changes': 21, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/3c2a14e676a57e5d77a16255965988eef48f9065\/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Fobject%2Fclasses%2Fclass.js', 'patch': '@@ -607,7 +607,12 @@ pimcore.object.classes.klass = Class.create({\\n                 for (var i = 0; i < items.length; i++) {\\n                     var item = items[i];\\n                     if (typeof item.getValue == \"function\") {\\n-                        this.data[item.name] = item.getValue();\\n+                        let value = item.getValue();\\n+                        if (typeof item.config.xtype !== \\'undefined\\' && item.config.xtype === \\'textfield\\') {\\n+                            value = Ext.util.Format.htmlEncode(value);\\n+                        }\\n+\\n+                        this.data[item.name] = value;\\n                     }\\n                 }\\n \\n@@ -705,6 +710,7 @@ pimcore.object.classes.klass = Class.create({\\n             id: \"iconfield-\" + this.getId(),\\n             name: \"icon\",\\n             width: 396,\\n+            renderer: Ext.util.Format.htmlEncode,\\n             value: this.data.icon,\\n             listeners: {\\n                 \"afterrender\": function (el) {\\n@@ -752,6 +758,7 @@ pimcore.object.classes.klass = Class.create({\\n                     width: 500,\\n                     enableKeyEvents: true,\\n                     value: this.data.name,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     listeners: {\\n                         keyup: function (el) {\\n                             this.rootPanel.getComponent(\"phpClassName\").setValue(getPhpClassName(el.getValue()))\\n@@ -763,12 +770,14 @@ pimcore.object.classes.klass = Class.create({\\n                     fieldLabel: t(\"description\"),\\n                     name: \"description\",\\n                     width: 500,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.description\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     fieldLabel: t(\"unique_identifier\"),\\n                     disabled: true,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.id,\\n                     width: 500\\n                 },\\n@@ -779,62 +788,71 @@ pimcore.object.classes.klass = Class.create({\\n                     itemId: \"phpClassName\",\\n                     width: 500,\\n                     disabled: true,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: getPhpClassName(this.data.name)\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     fieldLabel: t(\"parent_php_class\"),\\n                     name: \"parentClass\",\\n                     width: 600,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.parentClass\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     width: 600,\\n                     name: \"implementsInterfaces\",\\n                     fieldLabel: t(\"implements_interfaces\"),\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.implementsInterfaces\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     fieldLabel: t(\"use_traits\"),\\n                     name: \"useTraits\",\\n                     width: 600,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.useTraits\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     fieldLabel: t(\"listing_parent_php_class\"),\\n                     name: \"listingParentClass\",\\n                     width: 600,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.listingParentClass\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     fieldLabel: t(\"listing_use_traits\"),\\n                     name: \"listingUseTraits\",\\n                     width: 600,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.listingUseTraits\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     fieldLabel: t(\"link_generator_reference\"),\\n                     name: \"linkGeneratorReference\",\\n                     width: 600,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.linkGeneratorReference\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     fieldLabel: t(\"preview_generator_reference\"),\\n                     name: \"previewGeneratorReference\",\\n                     width: 600,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.previewGeneratorReference\\n                 },\\n                 {\\n                     xtype: \"textfield\",\\n                     fieldLabel: t(\"preview_url\"),\\n                     name: \"previewUrl\",\\n                     width: 600,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.previewUrl\\n                 },\\n                 {\\n@@ -885,6 +903,7 @@ pimcore.object.classes.klass = Class.create({\\n                     fieldLabel: t(\"group\"),\\n                     name: \"group\",\\n                     width: 600,\\n+                    renderer: Ext.util.Format.htmlEncode,\\n                     value: this.data.group\\n                 },\\n                 this.allowInheritance,'}}",
            "message_norm":"[admin ui] dataobject class - escape general settings input values (#10991)\n\n* [admin ui] dataobject class - escape general settings input values\r\n\r\n* update bundles\/adminbundle\/resources\/public\/js\/pimcore\/object\/classes\/class.js\r\n\r\n* [admin ui] dataobject class - escape general settings input values\r\n\r\n* [admin ui] dataobject class - escape general settings input values",
            "language":"ca",
            "entities":"[('admin', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('#10991', 'ISSUE', ''), ('admin', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('update', 'ACTION', ''), ('adminbundle', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/object\/classes\/class.js'])",
            "num_files":1.0
        },
        {
            "index":3124,
            "vuln_id":"GHSA-vhfp-9wvj-gwvg",
            "cwe_id":"{'CWE-611'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/modxcms\/revolution\/pull\/15238\/commits\/1b7ffe02df30f05dbf67dd15e4d8101687c1585a'}",
            "dataset":"osv",
            "summary":"XML External Entity vulnerability in MODX CMS A XML External Entity (XXE) vulnerability was discovered in the modRestServiceRequest component in MODX CMS 2.7.3 which can lead to an information disclosure or denial of service (DOS).",
            "published_date":"2021-11-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/modxcms\/revolution",
            "commit_href":"https:\/\/github.com\/modxcms\/revolution\/pull\/15238\/commits\/1b7ffe02df30f05dbf67dd15e4d8101687c1585a",
            "commit_sha":"1b7ffe02df30f05dbf67dd15e4d8101687c1585a",
            "patch":"SINGLE",
            "chain_ord":"['1b7ffe02df30f05dbf67dd15e4d8101687c1585a']",
            "before_first_fix_commit":"{'97b4e469500d54cf55a889b18f466a9cc6573983'}",
            "last_fix_commit":"1b7ffe02df30f05dbf67dd15e4d8101687c1585a",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/18\/2020, 09:14:28",
            "message":"Prevent potential XXE vulnerability in modRestService by disabling the libxml entity loader [#15237]\n\nThe libxml_disable_entity_loader function is deprecated in PHP8, and the entity loader is automatically enabled on v2.9.0+ of libxml which may have been used pre-PHP8 as well. PHP8 comes with at least v2.9.0+ of libxml bundled, so this conditional covers both scenarios.\n\nRef: https:\/\/github.com\/php\/php-src\/pull\/5867",
            "author":"Mark Hamstra",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 1, 'total': 10}",
            "files":"{'core\/model\/modx\/rest\/modrestservice.class.php': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/modxcms\/revolution\/raw\/1b7ffe02df30f05dbf67dd15e4d8101687c1585a\/core%2Fmodel%2Fmodx%2Frest%2Fmodrestservice.class.php', 'patch': \"@@ -59,6 +59,7 @@ public function __construct(modX &$modx,array $config = array()) {\\n             'responseSuccessKey' => 'success',\\n             'trimParameters' => false,\\n             'xmlRootNode' => 'response',\\n+            'xmlDisableEntityLoader' => true,\\n \\t\\t),$config);\\n \\t\\t$this->modx->getService('lexicon','modLexicon');\\n         if ($this->modx->lexicon) {\\n@@ -397,7 +398,14 @@ protected function _collectRequestParameters() {\\n             case 'text\/xml':\\n                 $data = stream_get_contents($filehandle);\\n                 fclose($filehandle);\\n-                $xml = simplexml_load_string($data);\\n+                if (LIBXML_VERSION < 20900 && $this->service->getOption('xmlDisableEntityLoader')) {\\n+                    $disableEntities = libxml_disable_entity_loader(true);\\n+                    $xml = simplexml_load_string($data);\\n+                    libxml_disable_entity_loader($disableEntities);\\n+                }\\n+                else {\\n+                    $xml = simplexml_load_string($data);\\n+                }\\n                 $params = $this->_xml2array($xml);\\n                 break;\\n             case 'application\/json':\"}}",
            "message_norm":"prevent potential xxe vulnerability in modrestservice by disabling the libxml entity loader [#15237]\n\nthe libxml_disable_entity_loader function is deprecated in php8, and the entity loader is automatically enabled on v2.9.0+ of libxml which may have been used pre-php8 as well. php8 comes with at least v2.9.0+ of libxml bundled, so this conditional covers both scenarios.\n\nref: https:\/\/github.com\/php\/php-src\/pull\/5867",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('xxe', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('#15237', 'ISSUE', ''), ('v2.9.0', 'VERSION', ''), ('v2.9.0', 'VERSION', ''), ('https:\/\/github.com\/php\/php-src\/pull\/5867', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/model\/modx\/rest\/modrestservice.class.php'])",
            "num_files":1.0
        },
        {
            "index":2314,
            "vuln_id":"GHSA-jwf9-w5xm-f437",
            "cwe_id":"{'CWE-125'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f'}",
            "dataset":"osv",
            "summary":"Heap OOB in TFLite's `Gather*` implementations ### Impact\nTFLite's [`GatherNd` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation.\n\nHence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`.\n\nSimilar issue exists in [`Gather` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/gather.cc).\n\n```python\nimport tensorflow as tf\nimport numpy as np\ntf.compat.v1.disable_v2_behavior()\n\nparams = tf.compat.v1.placeholder(name=\"params\", dtype=tf.int64, shape=(1,))\nindices = tf.compat.v1.placeholder(name=\"indices\", dtype=tf.int64, shape=())\n\nout = tf.gather(params, indices, name='out')\n\nwith tf.compat.v1.Session() as sess:\n   converter = tf.compat.v1.lite.TFLiteConverter.from_session(sess, [params, indices], [out])\n   tflite_model = converter.convert()\n\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nparams_data = np.reshape(np.array([1], dtype=np.int64), newshape=(1,))\nindices_data = np.reshape(np.array(-10, dtype=np.int64), newshape=())\ninterpreter.set_tensor(input_details[0]['index'], params_data)\ninterpreter.set_tensor(input_details[1]['index'], indices_data)\n\ninterpreter.invoke()\n```\n\n### Patches\nWe have patched the issue in GitHub commits [bb6a0383ed553c286f87ca88c207f6774d5c4a8f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f) and [eb921122119a6b6e470ee98b89e65d721663179d](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security  guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
            "commit_sha":"bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
            "patch":"MULTI",
            "chain_ord":"['bb6a0383ed553c286f87ca88c207f6774d5c4a8f', 'eb921122119a6b6e470ee98b89e65d721663179d']",
            "before_first_fix_commit":"{'ac72971cc6fbbfe4df7e67a8347ef1b6ab63b5fd'}",
            "last_fix_commit":"eb921122119a6b6e470ee98b89e65d721663179d",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 22:20:26",
            "message":"Prevent heap OOB read in TFLite's `gather_nd.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 0, 'total': 11}",
            "files":"{'tensorflow\/lite\/kernels\/gather_nd.cc': {'additions': 11, 'deletions': 0, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f\/tensorflow%2Flite%2Fkernels%2Fgather_nd.cc', 'patch': '@@ -123,6 +123,17 @@ TfLiteStatus GatherNdString(const TfLiteTensor* params,\\n template <typename IndicesT>\\n TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\\n                           const TfLiteTensor* indices, TfLiteTensor* output) {\\n+  bool indices_has_only_positive_elements = true;\\n+  const auto* indices_values = GetTensorData<IndicesT>(indices);\\n+  const size_t num_indices = indices->bytes \/ sizeof(IndicesT);\\n+  for (size_t i = 0; i < num_indices; i++) {\\n+    if (indices_values[i] < 0) {\\n+      indices_has_only_positive_elements = false;\\n+      break;\\n+    }\\n+  }\\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\\n+\\n   switch (params->type) {\\n     case kTfLiteFloat32:\\n       return GatherNd<float, IndicesT>(params, indices, output);'}}",
            "message_norm":"prevent heap oob read in tflite's `gather_nd.cc`.\n\npassing negative indices is illegal but there was a missing check so that resulted in oob accesses.\n\npiperorigin-revid: 387208551\nchange-id: i6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('missing check', 'SECWORD', ''), ('oob', 'SECWORD', ''), ('387208551', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/gather_nd.cc'])",
            "num_files":1.0
        },
        {
            "index":361,
            "vuln_id":"GHSA-455w-gv5p-wgg3",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/665976327ad3c2c87efa2a5a64d696032c0a8109'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in pimcore pimcore is vulnerable to Stored XSS at Name field in the setting tab of the Global Targeting Rules.",
            "published_date":"2022-01-26",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/665976327ad3c2c87efa2a5a64d696032c0a8109",
            "commit_sha":"665976327ad3c2c87efa2a5a64d696032c0a8109",
            "patch":"SINGLE",
            "chain_ord":"['665976327ad3c2c87efa2a5a64d696032c0a8109']",
            "before_first_fix_commit":"{'7f8855719f56c42ee3eda27a84b38ab57890e144'}",
            "last_fix_commit":"665976327ad3c2c87efa2a5a64d696032c0a8109",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/19\/2022, 10:36:40",
            "message":"[Targeting] Escape\/validate names of rules properly (#11205)\n\n* [Targeting] Escape\/validate names of rules properly\r\n\r\n* Update bundles\/AdminBundle\/Controller\/Admin\/TargetingController.php\r\n\r\nCo-authored-by: Jacob Dreesen <j.dreesen@neusta.de>\r\n\r\nCo-authored-by: Jacob Dreesen <j.dreesen@neusta.de>",
            "author":"Bernhard Rusch",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 4, 'total': 15}",
            "files":"{'bundles\/AdminBundle\/Controller\/Admin\/TargetingController.php': {'additions': 11, 'deletions': 4, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/665976327ad3c2c87efa2a5a64d696032c0a8109\/bundles%2FAdminBundle%2FController%2FAdmin%2FTargetingController.php', 'patch': '@@ -37,6 +37,11 @@ class TargetingController extends AdminController implements KernelControllerEve\\n {\\n     \/\/ RULES\\n \\n+    private function correctName(string $name): string\\n+    {\\n+        return preg_replace(\\'\/[#?*:\\\\\\\\\\\\\\\\<>|\"%&@=;+]\/\\', \\'-\\', $name);\\n+    }\\n+\\n     \/**\\n      * @Route(\"\/rule\/list\", name=\"pimcore_admin_targeting_rulelist\", methods={\"GET\"})\\n      *\\n@@ -55,7 +60,7 @@ public function ruleListAction(Request $request)\\n         foreach ($list->load() as $target) {\\n             $targets[] = [\\n                 \\'id\\' => $target->getId(),\\n-                \\'text\\' => $target->getName(),\\n+                \\'text\\' => htmlspecialchars($target->getName()),\\n                 \\'active\\' => $target->getActive(),\\n                 \\'qtip\\' => \\'ID: \\' . $target->getId(),\\n             ];\\n@@ -74,7 +79,7 @@ public function ruleListAction(Request $request)\\n     public function ruleAddAction(Request $request)\\n     {\\n         $target = new Targeting\\\\Rule();\\n-        $target->setName($request->get(\\'name\\'));\\n+        $target->setName($this->correctName($request->get(\\'name\\')));\\n         $target->save();\\n \\n         return $this->adminJson([\\'success\\' => true, \\'id\\' => $target->getId()]);\\n@@ -129,6 +134,7 @@ public function ruleSaveAction(Request $request)\\n         \/** @var Targeting\\\\Rule|Targeting\\\\Rule\\\\Dao $target *\/\\n         $target = Targeting\\\\Rule::getById($request->get(\\'id\\'));\\n         $target->setValues($data[\\'settings\\']);\\n+        $target->setName($this->correctName($target->getName()));\\n         $target->setConditions($data[\\'conditions\\']);\\n         $target->setActions($data[\\'actions\\']);\\n         $target->save();\\n@@ -208,7 +214,7 @@ public function targetGroupListAction(Request $request)\\n         foreach ($list->load() as $targetGroup) {\\n             $targetGroups[] = [\\n                 \\'id\\' => $targetGroup->getId(),\\n-                \\'text\\' => $targetGroup->getName(),\\n+                \\'text\\' => htmlspecialchars($targetGroup->getName()),\\n                 \\'active\\' => $targetGroup->getActive(),\\n                 \\'qtip\\' => $targetGroup->getId(),\\n             ];\\n@@ -230,7 +236,7 @@ public function targetGroupAddAction(Request $request, CoreCacheHandler $cache,\\n     {\\n         \/** @var TargetGroup|TargetGroup\\\\Dao $targetGroup *\/\\n         $targetGroup = new TargetGroup();\\n-        $targetGroup->setName($request->get(\\'name\\'));\\n+        $targetGroup->setName($this->correctName($request->get(\\'name\\')));\\n         $targetGroup->save();\\n \\n         $event = new TargetGroupEvent($targetGroup);\\n@@ -300,6 +306,7 @@ public function targetGroupSaveAction(Request $request, CoreCacheHandler $cache,\\n         \/** @var TargetGroup|TargetGroup\\\\Dao $targetGroup *\/\\n         $targetGroup = TargetGroup::getById($request->get(\\'id\\'));\\n         $targetGroup->setValues($data[\\'settings\\']);\\n+        $targetGroup->setName($this->correctName($targetGroup->getName()));\\n         $targetGroup->save();\\n \\n         $event = new TargetGroupEvent($targetGroup);'}}",
            "message_norm":"[targeting] escape\/validate names of rules properly (#11205)\n\n* [targeting] escape\/validate names of rules properly\r\n\r\n* update bundles\/adminbundle\/controller\/admin\/targetingcontroller.php\r\n\r\nco-authored-by: jacob dreesen <j.dreesen@neusta.de>\r\n\r\nco-authored-by: jacob dreesen <j.dreesen@neusta.de>",
            "language":"en",
            "entities":"[('escape', 'SECWORD', ''), ('validate', 'ACTION', ''), ('#11205', 'ISSUE', ''), ('escape', 'SECWORD', ''), ('validate', 'ACTION', ''), ('update', 'ACTION', ''), ('adminbundle', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('j.dreesen@neusta.de', 'EMAIL', ''), ('j.dreesen@neusta.de', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Controller\/Admin\/TargetingController.php'])",
            "num_files":1.0
        },
        {
            "index":2729,
            "vuln_id":"GHSA-q9p4-qfc8-fvpp",
            "cwe_id":"{'CWE-89'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/catfan\/Medoo\/commit\/659864b393961bf224bba1efc03b7dcbed7de533'}",
            "dataset":"osv",
            "summary":"SQL Injection in medoo columnQuote in medoo before 1.7.5 allows remote attackers to perform a SQL Injection due to improper escaping.",
            "published_date":"2021-10-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/catfan\/Medoo",
            "commit_href":"https:\/\/github.com\/catfan\/Medoo\/commit\/659864b393961bf224bba1efc03b7dcbed7de533",
            "commit_sha":"659864b393961bf224bba1efc03b7dcbed7de533",
            "patch":"SINGLE",
            "chain_ord":"['659864b393961bf224bba1efc03b7dcbed7de533']",
            "before_first_fix_commit":"{'b3f05edf256d63ec3cfd31d6a078c564daf9863d'}",
            "last_fix_commit":"659864b393961bf224bba1efc03b7dcbed7de533",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/11\/2019, 15:50:40",
            "message":"[fix] Fix columnQuote for \bsecurity issue reported by Snyk",
            "author":"Angel Lai",
            "comments":"{'com_1': {'author': 'jfcherng', 'datetime': '10\/12\/2019, 11:57:36', 'body': \"It's perfect valid to use `_` in a column name and I believe it's used quite often. This change would make `v1.7.4` literally unusable for most of people.\\r\\n\\r\\nNot sure about other SQL standard. For MySQL, it's valid to use some of UTF-8 chars as the column name.\\r\\nhttps:\/\/dev.mysql.com\/doc\/refman\/8.0\/en\/identifiers.html\"}, 'com_2': {'author': 'catfan', 'datetime': '10\/12\/2019, 13:18:09', 'body': \"Thanks for this great spot. The `_` should be added. Although it's possible to use UTF-8 chars for column name, it may have some problem for some databases. Using `a-zA-Z0-9_` is enough for most case.\"}}",
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'src\/Medoo.php': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/catfan\/Medoo\/raw\/659864b393961bf224bba1efc03b7dcbed7de533\/src%2FMedoo.php', 'patch': '@@ -500,6 +500,11 @@ protected function typeMap($value, $type)\\n \\n \\tprotected function columnQuote($string)\\n \\t{\\n+\\t\\tif (!preg_match(\\'\/^[a-zA-Z0-9]+(\\\\.?[a-zA-Z0-9]+)?$\/i\\', $string))\\n+\\t\\t{\\n+\\t\\t\\tthrow new InvalidArgumentException(\"Incorrect column name \\\\\"$string\\\\\"\");\\n+\\t\\t}\\n+\\n \\t\\tif (strpos($string, \\'.\\') !== false)\\n \\t\\t{\\n \\t\\t\\treturn \\'\"\\' . $this->prefix . str_replace(\\'.\\', \\'\".\"\\', $string) . \\'\"\\';'}}",
            "message_norm":"[fix] fix columnquote for \bsecurity issue reported by snyk",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('fix', 'ACTION', ''), ('\\x08security', 'SECWORD', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Medoo.php'])",
            "num_files":1.0
        },
        {
            "index":234,
            "vuln_id":"GHSA-3c33-3465-fhx2",
            "cwe_id":"{'CWE-668'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/librenms\/librenms\/commit\/e5bb6d80bc308fc56b9a01ffb76c34159995353c'}",
            "dataset":"osv",
            "summary":"Exposure of Resource to Wrong Sphere in LibreNMS An issue was discovered in LibreNMS before 1.65.1. It has insufficient access control for normal users because of \"'guard' => 'admin'\" instead of \"'middleware' => ['can:admin']\" in routes\/web.php.",
            "published_date":"2021-09-08",
            "chain_len":1,
            "project":"https:\/\/github.com\/librenms\/librenms",
            "commit_href":"https:\/\/github.com\/librenms\/librenms\/commit\/e5bb6d80bc308fc56b9a01ffb76c34159995353c",
            "commit_sha":"e5bb6d80bc308fc56b9a01ffb76c34159995353c",
            "patch":"SINGLE",
            "chain_ord":"['e5bb6d80bc308fc56b9a01ffb76c34159995353c']",
            "before_first_fix_commit":"{'a30fcbde0a0f8a2109cbd4edb2b27b118190b3ca'}",
            "last_fix_commit":"e5bb6d80bc308fc56b9a01ffb76c34159995353c",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/08\/2020, 23:04:48",
            "message":"Fix settings access (#11915)\n\nnormal users could access",
            "author":"Tony Murray",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'routes\/web.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/librenms\/librenms\/raw\/e5bb6d80bc308fc56b9a01ffb76c34159995353c\/routes%2Fweb.php', 'patch': \"@@ -43,7 +43,7 @@\\n     });\\n \\n     \/\/ admin pages\\n-    Route::group(['guard' => 'admin'], function () {\\n+    Route::group(['middleware' => ['can:admin']], function () {\\n         Route::get('settings\/{tab?}\/{section?}', 'SettingsController@index')->name('settings');\\n         Route::put('settings\/{name}', 'SettingsController@update')->name('settings.update');\\n         Route::delete('settings\/{name}', 'SettingsController@destroy')->name('settings.destroy');\"}}",
            "message_norm":"fix settings access (#11915)\n\nnormal users could access",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('#11915', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['routes\/web.php'])",
            "num_files":1.0
        },
        {
            "index":453,
            "vuln_id":"GHSA-4p55-xj37-fx7g",
            "cwe_id":"{'CWE-276'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/strapi\/strapi\/commit\/3cdd73987950d5c7976701047b38203e902007bb'}",
            "dataset":"osv",
            "summary":"Improper Authorization in Strapi In Strapi before 3.2.5, there is no admin::hasPermissions restriction for CTB (aka content-type-builder) routes.",
            "published_date":"2020-10-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/strapi\/strapi",
            "commit_href":"https:\/\/github.com\/strapi\/strapi\/commit\/3cdd73987950d5c7976701047b38203e902007bb",
            "commit_sha":"3cdd73987950d5c7976701047b38203e902007bb",
            "patch":"SINGLE",
            "chain_ord":"['3cdd73987950d5c7976701047b38203e902007bb']",
            "before_first_fix_commit":"{'15e8a76f11c7d86ee3746efff187cbf83e220424', '4d00bc09b8bd7c0938e2d54f480d503560fcb45e'}",
            "last_fix_commit":"3cdd73987950d5c7976701047b38203e902007bb",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/22\/2020, 14:30:20",
            "message":"Merge pull request #8439 from strapi\/fix\/ctb-permissions\n\nAdd permission to CTB routes",
            "author":"Alexandre BODIN",
            "comments":null,
            "stats":"{'additions': 42, 'deletions': 14, 'total': 56}",
            "files":"{'packages\/strapi-plugin-content-type-builder\/config\/routes.json': {'additions': 42, 'deletions': 14, 'changes': 56, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/strapi\/strapi\/raw\/3cdd73987950d5c7976701047b38203e902007bb\/packages%2Fstrapi-plugin-content-type-builder%2Fconfig%2Froutes.json', 'patch': '@@ -5,111 +5,139 @@\\n       \"path\": \"\/reserved-names\",\\n       \"handler\": \"Builder.getReservedNames\",\\n       \"config\": {\\n-        \"policies\": []\\n+        \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"GET\",\\n       \"path\": \"\/connections\",\\n       \"handler\": \"Connections.getConnections\",\\n       \"config\": {\\n-        \"policies\": []\\n+        \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"GET\",\\n       \"path\": \"\/content-types\",\\n       \"handler\": \"ContentTypes.getContentTypes\",\\n       \"config\": {\\n-        \"policies\": []\\n+        \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"GET\",\\n       \"path\": \"\/content-types\/:uid\",\\n       \"handler\": \"ContentTypes.getContentType\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"POST\",\\n       \"path\": \"\/content-types\",\\n       \"handler\": \"ContentTypes.createContentType\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"PUT\",\\n       \"path\": \"\/content-types\/:uid\",\\n       \"handler\": \"ContentTypes.updateContentType\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"DELETE\",\\n       \"path\": \"\/content-types\/:uid\",\\n       \"handler\": \"ContentTypes.deleteContentType\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"GET\",\\n       \"path\": \"\/components\",\\n       \"handler\": \"Components.getComponents\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"GET\",\\n       \"path\": \"\/components\/:uid\",\\n       \"handler\": \"Components.getComponent\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"POST\",\\n       \"path\": \"\/components\",\\n       \"handler\": \"Components.createComponent\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"PUT\",\\n       \"path\": \"\/components\/:uid\",\\n       \"handler\": \"Components.updateComponent\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"DELETE\",\\n       \"path\": \"\/components\/:uid\",\\n       \"handler\": \"Components.deleteComponent\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"PUT\",\\n       \"path\": \"\/component-categories\/:name\",\\n       \"handler\": \"ComponentCategories.editCategory\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     },\\n     {\\n       \"method\": \"DELETE\",\\n       \"path\": \"\/component-categories\/:name\",\\n       \"handler\": \"ComponentCategories.deleteCategory\",\\n       \"config\": {\\n-        \"policies\": []\\n+      \"policies\": [\\n+          [\"admin::hasPermissions\", [\"plugins::content-type-builder.read\"]]\\n+        ]\\n       }\\n     }\\n   ]'}}",
            "message_norm":"merge pull request #8439 from strapi\/fix\/ctb-permissions\n\nadd permission to ctb routes",
            "language":"fr",
            "entities":"[('#8439', 'ISSUE', ''), ('permissions', 'SECWORD', ''), ('add', 'ACTION', ''), ('permission', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['packages\/strapi-plugin-content-type-builder\/config\/routes.json'])",
            "num_files":1.0
        },
        {
            "index":568,
            "vuln_id":"GHSA-56wv-2wr9-3h9r",
            "cwe_id":"{'CWE-347'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/e592f106edd5acf6dacedfab2ad16fe6c735c9d1', 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/7b64e3efaa806b4daaf73bb5172af3581812f8de', 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/4a16daeaf139be20654ef58a9fe4c79dc030458c'}",
            "dataset":"osv",
            "summary":"Improper Verification of Cryptographic Signature in fastecdsa An issue was discovered in fastecdsa before 2.1.2. When using the NIST P-256 curve in the ECDSA implementation, the point at infinity is mishandled. This means that for an extreme value in k and s^-1, the signature verification fails even if the signature is correct. This behavior is not solely a usability problem. There are some threat models where an attacker can benefit by successfully guessing users for whom signature verification will fail.",
            "published_date":"2021-10-12",
            "chain_len":3,
            "project":"https:\/\/github.com\/AntonKueltz\/fastecdsa",
            "commit_href":"https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/4a16daeaf139be20654ef58a9fe4c79dc030458c",
            "commit_sha":"4a16daeaf139be20654ef58a9fe4c79dc030458c",
            "patch":"MULTI",
            "chain_ord":"['e592f106edd5acf6dacedfab2ad16fe6c735c9d1', '7b64e3efaa806b4daaf73bb5172af3581812f8de', '4a16daeaf139be20654ef58a9fe4c79dc030458c']",
            "before_first_fix_commit":"{'7b64e3efaa806b4daaf73bb5172af3581812f8de'}",
            "last_fix_commit":"4a16daeaf139be20654ef58a9fe4c79dc030458c",
            "chain_ord_pos":3.0,
            "commit_datetime":"04\/14\/2020, 09:52:44",
            "message":"Update CHANGELOG.md",
            "author":"AntonKueltz",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'CHANGELOG.md': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/raw\/4a16daeaf139be20654ef58a9fe4c79dc030458c\/CHANGELOG.md', 'patch': \"@@ -2,7 +2,7 @@\\n \\n ## [2.1.2]\\n ### Fixed\\n-- Point at infinity handling in C extensions\\n+- Point at infinity handling in C extensions (issue #52)\\n - DER signature decoding that assumed length was always encoded in one byte\\n \\n ## [2.1.1]\\n@@ -28,4 +28,4 @@\\n - Various unused imports\\n \\n ### Fixed\\n-- Issue with benchmark script when C extensions weren't built in place (issue #44)\\n\\\\ No newline at end of file\\n+- Issue with benchmark script when C extensions weren't built in place (issue #44)\"}}",
            "message_norm":"update changelog.md",
            "language":"nl",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['CHANGELOG.md'])",
            "num_files":1.0
        },
        {
            "index":2152,
            "vuln_id":"GHSA-hwv5-w8gm-fq9f",
            "cwe_id":"{'CWE-22'}",
            "score":3.5,
            "chain":"{'https:\/\/github.com\/horazont\/xmpp-http-upload\/commit\/82056540191e89f0cd697c81f57714c00962ed75'}",
            "dataset":"osv",
            "summary":"Directory Traversal vulnerability in GET\/PUT allows attackers to Disclose Information or Write Files via a crafted GET\/PUT request ### Impact\n\n#### Information Disclosure\n\nWhen the GET method is attacked, attackers can read files which have a `.data` suffix and which are accompanied by a JSON file with the `.meta` suffix. This can lead to Information Disclosure and in some shared-hosting scenarios also to circumvention of authentication or other limitations on the outbound (GET) traffic.\n\nFor example, in a scenario where a single server has multiple instances of the application running (with separate DATA_ROOT settings), an attacker who has knowledge about the directory structure is able to read files from any other instance to which the process has read access.\n\nIf instances have individual authentication (for example, HTTP authentication via a reverse proxy, source IP based filtering) or other restrictions (such as quotas), attackers may circumvent those limits in such a scenario by using the Directory Traversal to retrieve data from the other instances.\n\n#### File Write\n\nIf the associated XMPP server (or anyone knowing the SECRET_KEY) is malicious, they can write files outside the DATA_ROOT. The files which are written are constrained to have the `.meta` and the `.data` suffixes; the `.meta` file will contain the JSON with the Content-Type of the original request and the `.data` file will contain the payload.\n\n### Patches\n\nPR #12 fixes the issue. The PR has been merged into version 0.4.0 and 0.4.0 has been released and pushed to PyPI. Users are advised to upgrade immediately.\n\n### Workarounds\n\n- Apache can apparently be configured to filter such malicious paths when reverse-proxying. \n- There are no other workarounds known.\n\n### References\n\n- [Pull Request #12](https:\/\/github.com\/horazont\/xmpp-http-upload\/pull\/12)",
            "published_date":"2020-10-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/horazont\/xmpp-http-upload",
            "commit_href":"https:\/\/github.com\/horazont\/xmpp-http-upload\/commit\/82056540191e89f0cd697c81f57714c00962ed75",
            "commit_sha":"82056540191e89f0cd697c81f57714c00962ed75",
            "patch":"SINGLE",
            "chain_ord":"['82056540191e89f0cd697c81f57714c00962ed75']",
            "before_first_fix_commit":"{'f0fc7443c06a0e8aecb5696fc2bd513a2cc8b611'}",
            "last_fix_commit":"82056540191e89f0cd697c81f57714c00962ed75",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/05\/2020, 23:06:21",
            "message":"Simplify path handling, use safe_join\n\nThe current implementation of sanitized_join did not handle\n\"..\" properly. The problem is, that .absolute() does not do\nwhat .resolve() does, but .resolve() does not work on non\nexistant paths.\n\nAnyway, flask has a function exactly for this: safe_join.\n\nSo let's use that one.\n\nWhile at it, simplified the whole path handling a bit.",
            "author":"Christian Tacke",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 34, 'total': 49}",
            "files":"{'xhu.py': {'additions': 15, 'deletions': 34, 'changes': 49, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/horazont\/xmpp-http-upload\/raw\/82056540191e89f0cd697c81f57714c00962ed75\/xhu.py', 'patch': '@@ -29,6 +29,7 @@\\n import typing\\n \\n import flask\\n+import werkzeug.exceptions\\n \\n app = flask.Flask(\"xmpp-http-upload\")\\n app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")\\n@@ -39,16 +40,11 @@\\n     CORS(app)\\n \\n \\n-def sanitized_join(path: str, root: pathlib.Path) -> pathlib.Path:\\n-    result = (root \/ path).absolute()\\n-    if not str(result).startswith(str(root) + \"\/\"):\\n-        raise ValueError(\"resulting path is outside root\")\\n-    return result\\n-\\n-\\n-def get_paths(base_path: pathlib.Path):\\n-    data_file = pathlib.Path(str(base_path) + \".data\")\\n-    metadata_file = pathlib.Path(str(base_path) + \".meta\")\\n+def get_paths(root: str, sub_path: str) \\\\\\n+        -> typing.Tuple[pathlib.Path, pathlib.Path]:\\n+    base_path = flask.safe_join(root, sub_path)\\n+    data_file = pathlib.Path(base_path + \".data\")\\n+    metadata_file = pathlib.Path(base_path + \".meta\")\\n \\n     return data_file, metadata_file\\n \\n@@ -58,15 +54,10 @@ def load_metadata(metadata_file):\\n         return json.load(f)\\n \\n \\n-def get_info(path: str, root: pathlib.Path) -> typing.Tuple[\\n+def get_info(path: str) -> typing.Tuple[\\n         pathlib.Path,\\n         dict]:\\n-    dest_path = sanitized_join(\\n-        path,\\n-        pathlib.Path(app.config[\"DATA_ROOT\"]),\\n-    )\\n-\\n-    data_file, metadata_file = get_paths(dest_path)\\n+    data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\\n \\n     return data_file, load_metadata(metadata_file)\\n \\n@@ -104,11 +95,8 @@ def stream_file(src, dest, nbytes):\\n @app.route(\"\/<path:path>\", methods=[\"PUT\"])\\n def put_file(path):\\n     try:\\n-        dest_path = sanitized_join(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"]),\\n-        )\\n-    except ValueError:\\n+        data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\\n+    except werkzeug.exceptions.NotFound:\\n         return flask.Response(\\n             \"Not Found\",\\n             404,\\n@@ -134,8 +122,7 @@ def put_file(path):\\n         \"application\/octet-stream\",\\n     )\\n \\n-    dest_path.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\\n-    data_file, metadata_file = get_paths(dest_path)\\n+    data_file.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\\n \\n     try:\\n         with write_file(data_file) as fout:\\n@@ -189,13 +176,10 @@ def generate_headers(response_headers, metadata_headers):\\n @app.route(\"\/<path:path>\", methods=[\"HEAD\"])\\n def head_file(path):\\n     try:\\n-        data_file, metadata = get_info(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\\n-        )\\n+        data_file, metadata = get_info(path)\\n \\n         stat = data_file.stat()\\n-    except (OSError, ValueError):\\n+    except (OSError, werkzeug.exceptions.NotFound):\\n         return flask.Response(\\n             \"Not Found\",\\n             404,\\n@@ -214,11 +198,8 @@ def head_file(path):\\n @app.route(\"\/<path:path>\", methods=[\"GET\"])\\n def get_file(path):\\n     try:\\n-        data_file, metadata = get_info(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\\n-        )\\n-    except (OSError, ValueError):\\n+        data_file, metadata = get_info(path)\\n+    except (OSError, werkzeug.exceptions.NotFound):\\n         return flask.Response(\\n             \"Not Found\",\\n             404,'}}",
            "message_norm":"simplify path handling, use safe_join\n\nthe current implementation of sanitized_join did not handle\n\"..\" properly. the problem is, that .absolute() does not do\nwhat .resolve() does, but .resolve() does not work on non\nexistant paths.\n\nanyway, flask has a function exactly for this: safe_join.\n\nso let's use that one.\n\nwhile at it, simplified the whole path handling a bit.",
            "language":"en",
            "entities":"[('sanitized_join', 'SECWORD', ''), ('problem', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['xhu.py'])",
            "num_files":1.0
        },
        {
            "index":2630,
            "vuln_id":"GHSA-pr38-qpxm-g88x",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/apache\/activemq-artemis\/pull\/3871\/commits\/153d2e9a979aead8dff95fbc91d659ecc7d0fb82', 'https:\/\/github.com\/apache\/activemq-artemis\/pull\/3862\/commits\/1f92368240229b8f5db92a92a72c703faf83e9b7'}",
            "dataset":"osv",
            "summary":"Uncontrolled Resource Consumption in Apache ActiveMQ Artemis In Apache ActiveMQ Artemis prior to 2.20.0 or 2.19.1, an attacker could partially disrupt availability (DoS) through uncontrolled resource consumption of memory.",
            "published_date":"2022-02-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/apache\/activemq-artemis",
            "commit_href":"https:\/\/github.com\/apache\/activemq-artemis\/pull\/3862\/commits\/1f92368240229b8f5db92a92a72c703faf83e9b7",
            "commit_sha":"1f92368240229b8f5db92a92a72c703faf83e9b7",
            "patch":"MULTI",
            "chain_ord":"['1f92368240229b8f5db92a92a72c703faf83e9b7', '153d2e9a979aead8dff95fbc91d659ecc7d0fb82']",
            "before_first_fix_commit":"{'4196faf7ce56cb3676d46acb3b0684b5cdf804d7'}",
            "last_fix_commit":"153d2e9a979aead8dff95fbc91d659ecc7d0fb82",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/19\/2021, 12:02:45",
            "message":"Be defensive when reading data from `ActiveMQBuffer` and allocating memory.\n\nOr else, an adversary may handcraft the packet causing OOM situation for a running a JVM.",
            "author":"Viktor Kolomeyko",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 4, 'total': 20}",
            "files":"{'artemis-core-client\/src\/main\/java\/org\/apache\/activemq\/artemis\/utils\/XidCodecSupport.java': {'additions': 16, 'deletions': 4, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/activemq-artemis\/raw\/1f92368240229b8f5db92a92a72c703faf83e9b7\/artemis-core-client%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Factivemq%2Fartemis%2Futils%2FXidCodecSupport.java', 'patch': '@@ -32,12 +32,24 @@ public static void encodeXid(final Xid xid, final ActiveMQBuffer out) {\\n       out.writeBytes(xid.getGlobalTransactionId());\\n    }\\n \\n+   private static byte[] safeReadBytes(final ActiveMQBuffer in) {\\n+      int claimedSize = in.readInt();\\n+      int bufferCapacity = in.capacity();\\n+      \/\/ We have to be defensive here and not try to allocate byte buffer straight from information available in the\\n+      \/\/ stream. Or else, an adversary may handcraft the packet causing OOM situation for a running JVM.\\n+      if (claimedSize > bufferCapacity) {\\n+         throw new IllegalStateException(\"Buffer size: \" + claimedSize +\\n+                 \" exceeds overall buffer size of: \" + bufferCapacity);\\n+      }\\n+      byte[] byteBuffer = new byte[claimedSize];\\n+      in.readBytes(byteBuffer);\\n+      return byteBuffer;\\n+   }\\n+\\n    public static Xid decodeXid(final ActiveMQBuffer in) {\\n       int formatID = in.readInt();\\n-      byte[] bq = new byte[in.readInt()];\\n-      in.readBytes(bq);\\n-      byte[] gtxid = new byte[in.readInt()];\\n-      in.readBytes(gtxid);\\n+      byte[] bq = safeReadBytes(in);\\n+      byte[] gtxid = safeReadBytes(in);\\n       return new XidImpl(bq, formatID, gtxid);\\n    }'}}",
            "message_norm":"be defensive when reading data from `activemqbuffer` and allocating memory.\n\nor else, an adversary may handcraft the packet causing oom situation for a running a jvm.",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['artemis-core-client\/src\/main\/java\/org\/apache\/activemq\/artemis\/utils\/XidCodecSupport.java'])",
            "num_files":1.0
        },
        {
            "index":858,
            "vuln_id":"GHSA-6jp6-9rf9-gc66",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/9e19a8414337692cc90da2a91c9af5420f2952f1', 'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/f6753a1a1c63fade6ad418fbda827c6750ab0bda', 'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/22d577b1f1e88665a88b4569380148030e0f8389'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Weblate ### Impact\nDue to improper neutralization, it was possible to perform cross-site scripting via crafted user and language names.\n\n### Patches\n\nThe issues were fixed in the 4.11 release. The following commits are addressing it:\n\n* f6753a1a1c63fade6ad418fbda827c6750ab0bda\n* 9e19a8414337692cc90da2a91c9af5420f2952f1\n* 22d577b1f1e88665a88b4569380148030e0f8389\n\n### Workarounds\n\nYou can look for crafted user and language names to see if you were affected.\n\n### References\n* https:\/\/hackerone.com\/reports\/1486674\n* https:\/\/hackerone.com\/reports\/1486718\n* https:\/\/hackerone.com\/reports\/1485226\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open a topic in [discussions](https:\/\/github.com\/WeblateOrg\/weblate\/discussions)\n* Email us at [care@weblate.org](mailto:care@weblate.org)",
            "published_date":"2022-02-25",
            "chain_len":3,
            "project":"https:\/\/github.com\/WeblateOrg\/weblate",
            "commit_href":"https:\/\/github.com\/WeblateOrg\/weblate\/commit\/9e19a8414337692cc90da2a91c9af5420f2952f1",
            "commit_sha":"9e19a8414337692cc90da2a91c9af5420f2952f1",
            "patch":"MULTI",
            "chain_ord":"['22d577b1f1e88665a88b4569380148030e0f8389', '9e19a8414337692cc90da2a91c9af5420f2952f1', 'f6753a1a1c63fade6ad418fbda827c6750ab0bda']",
            "before_first_fix_commit":"{'572628cef60e9d839b79b2087960b606a5cca4d8'}",
            "last_fix_commit":"f6753a1a1c63fade6ad418fbda827c6750ab0bda",
            "chain_ord_pos":2.0,
            "commit_datetime":"02\/22\/2022, 20:00:41",
            "message":"js: Add missing escaping to username completion\n\nFixes https:\/\/hackerone.com\/reports\/1486674",
            "author":"Michal \u010ciha\u0159",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'weblate\/static\/loader-bootstrap.js': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/WeblateOrg\/weblate\/raw\/9e19a8414337692cc90da2a91c9af5420f2952f1\/weblate%2Fstatic%2Floader-bootstrap.js', 'patch': '@@ -1131,7 +1131,9 @@ $(function () {\\n       return \"\";\\n     },\\n     menuItemTemplate: function (item) {\\n-      return `<a>${item.string}<\/a>`;\\n+      let link = document.createElement(\"a\");\\n+      link.innerText = item.string;\\n+      return link.outerHTML;\\n     },\\n     values: (text, callback) => {\\n       $.ajax({'}}",
            "message_norm":"js: add missing escaping to username completion\n\nfixes https:\/\/hackerone.com\/reports\/1486674",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('escaping', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('https:\/\/hackerone.com\/reports\/1486674', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['weblate\/static\/loader-bootstrap.js'])",
            "num_files":1.0
        },
        {
            "index":3022,
            "vuln_id":"GHSA-rwv8-jvff-jq28",
            "cwe_id":"{'CWE-22'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/tnantoka\/public\/commit\/eae8ad8017b260f8667ded5e12801bd72b877af2'}",
            "dataset":"osv",
            "summary":"Path Traversal in public Versions of `public` before 0.1.3 are vulnerable to path traversal. This is due to lack of file path sanitization which could lead to any file the parent process has access to on the server to be read by malicious user.\n\n\n## Recommendation\n\nUpdate to version 0.1.3 or later.",
            "published_date":"2018-07-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/tnantoka\/public",
            "commit_href":"https:\/\/github.com\/tnantoka\/public\/commit\/eae8ad8017b260f8667ded5e12801bd72b877af2",
            "commit_sha":"eae8ad8017b260f8667ded5e12801bd72b877af2",
            "patch":"SINGLE",
            "chain_ord":"['eae8ad8017b260f8667ded5e12801bd72b877af2']",
            "before_first_fix_commit":"{'c5c14107c00eb37c677eabcc5566938a0dee685c'}",
            "last_fix_commit":"eae8ad8017b260f8667ded5e12801bd72b877af2",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/15\/2018, 05:13:37",
            "message":"Fix path traversal",
            "author":"tnantoka",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'bin\/public': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tnantoka\/public\/raw\/eae8ad8017b260f8667ded5e12801bd72b877af2\/bin%2Fpublic', 'patch': \"@@ -67,6 +67,7 @@ switch (args[0]) {\\n       }\\n     }\\n }\\n+var root = path.resolve(dir);\\n \\n if (path) {\\n   http.createServer(function(req, res) {\\n@@ -75,6 +76,13 @@ if (path) {\\n     var base = filePath.replace(dir, ''); \/\/ Base path for browser link\\n     var abs = path.resolve(filePath); \\n     console.log(new Date().toString(), abs);\\n+\\n+    if (abs.indexOf(root) !== 0) {\\n+      res.writeHead(403, { 'Content-Type': 'text\/plain' });\\n+      res.end('Forbidden\\\\n');\\n+      return;\\n+    }\\n+\\n     fs.readFile(filePath, function(err, data) {\\n       if (err) {\\n         res.writeHead(200, { 'Content-Type': 'text\/html' });\"}}",
            "message_norm":"fix path traversal",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('path traversal', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bin\/public'])",
            "num_files":1.0
        },
        {
            "index":1891,
            "vuln_id":"GHSA-gj85-pvp5-mvf9",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/ptrofimov\/beanstalk_console\/commit\/e351c8260ec1d3718d9e475ee57c7e12c47f19da'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Beanstalk console Beanstalk console prior to version 1.7.12 is vulnerable to cross-site scripting.",
            "published_date":"2022-02-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/ptrofimov\/beanstalk_console",
            "commit_href":"https:\/\/github.com\/ptrofimov\/beanstalk_console\/commit\/e351c8260ec1d3718d9e475ee57c7e12c47f19da",
            "commit_sha":"e351c8260ec1d3718d9e475ee57c7e12c47f19da",
            "patch":"SINGLE",
            "chain_ord":"['e351c8260ec1d3718d9e475ee57c7e12c47f19da']",
            "before_first_fix_commit":"{'95d5808836034835fc33500c6a82276277fabdf9'}",
            "last_fix_commit":"e351c8260ec1d3718d9e475ee57c7e12c47f19da",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/01\/2022, 15:43:02",
            "message":"Sanitize input",
            "author":"Nav-Prak",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/include.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ptrofimov\/beanstalk_console\/raw\/e351c8260ec1d3718d9e475ee57c7e12c47f19da\/lib%2Finclude.php', 'patch': \"@@ -19,7 +19,7 @@ function autoload_class($class) {\\n require_once dirname(__FILE__) . '\/..\/config.php';\\r\\n require_once dirname(__FILE__) . '\/..\/src\/Storage.php';\\r\\n \\r\\n-$GLOBALS['server'] = !empty($_GET['server']) ? $_GET['server'] : '';\\r\\n+$GLOBALS['server'] = !empty($_GET['server']) ? htmlspecialchars($_GET['server']) : '';\\r\\n $GLOBALS['action'] = !empty($_GET['action']) ? $_GET['action'] : '';\\r\\n $GLOBALS['state'] = !empty($_GET['state']) ? $_GET['state'] : '';\\r\\n $GLOBALS['count'] = !empty($_GET['count']) ? $_GET['count'] : '';\"}}",
            "message_norm":"sanitize input",
            "language":"ro",
            "entities":"[('sanitize', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/include.php'])",
            "num_files":1.0
        },
        {
            "index":2765,
            "vuln_id":"GHSA-qhxx-j73r-qpm2",
            "cwe_id":"{'CWE-908'}",
            "score":4.4,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2'}",
            "dataset":"osv",
            "summary":"Uninitialized memory access in TensorFlow ### Impact\nUnder certain cases, a saved model can trigger use of uninitialized values during code execution. This is caused by having tensor buffers be filled with the default value of the type but forgetting to [default initialize the quantized floating point types in Eigen](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f70160322a579144950dff1537dcbe3c7c09d6f5\/third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h#L61-L104):\n\n```cc\nstruct QUInt8 {\n  QUInt8() {}\n  \/\/ ...\n  uint8_t value;\n};\n\nstruct QInt16 {\n  QInt16() {}\n  \/\/ ...\n  int16_t value;\n};\n\nstruct QUInt16 {\n  QUInt16() {}\n  \/\/ ...\n  uint16_t value;\n};\n\nstruct QInt32 {\n  QInt32() {}\n  \/\/ ...\n  int32_t value;\n};\n```\n\n### Patches\nWe have patched the issue in GitHub commit [ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2) and will release TensorFlow 2.4.0 containing the patch. TensorFlow nightly packages after this commit will also have the issue resolved.\n\nSince this issue also impacts TF versions before 2.4, we will patch all releases between 1.15 and 2.3 inclusive.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2020-12-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
            "commit_sha":"ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
            "patch":"SINGLE",
            "chain_ord":"['ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2']",
            "before_first_fix_commit":"{'f70160322a579144950dff1537dcbe3c7c09d6f5'}",
            "last_fix_commit":"ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/24\/2020, 19:40:42",
            "message":"Default initialize fixed point Eigen types.\n\nIn certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.\n\nPiperOrigin-RevId: 344101137\nChange-Id: I14555fda74dca3b5f1582da9008901937e3f14e2",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 5, 'total': 10}",
            "files":"{'third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2\/third_party%2Feigen3%2Funsupported%2FEigen%2FCXX11%2Fsrc%2FFixedPoint%2FFixedPointTypes.h', 'patch': '@@ -49,7 +49,7 @@ struct scalar_product_traits<QInt32, double> {\\n \/\/ the compiler from silently type cast the mantissa into a bigger or a smaller\\n \/\/ representation.\\n struct QInt8 {\\n-  QInt8() {}\\n+  QInt8() : value(0) {}\\n   QInt8(const int8_t v) : value(v) {}\\n   QInt8(const QInt32 v);\\n \\n@@ -59,7 +59,7 @@ struct QInt8 {\\n };\\n \\n struct QUInt8 {\\n-  QUInt8() {}\\n+  QUInt8() : value(0) {}\\n   QUInt8(const uint8_t v) : value(v) {}\\n   QUInt8(const QInt32 v);\\n \\n@@ -69,7 +69,7 @@ struct QUInt8 {\\n };\\n \\n struct QInt16 {\\n-  QInt16() {}\\n+  QInt16() : value(0) {}\\n   QInt16(const int16_t v) : value(v) {}\\n   QInt16(const QInt32 v);\\n   operator int() const { return static_cast<int>(value); }\\n@@ -78,7 +78,7 @@ struct QInt16 {\\n };\\n \\n struct QUInt16 {\\n-  QUInt16() {}\\n+  QUInt16() : value(0) {}\\n   QUInt16(const uint16_t v) : value(v) {}\\n   QUInt16(const QInt32 v);\\n   operator int() const { return static_cast<int>(value); }\\n@@ -87,7 +87,7 @@ struct QUInt16 {\\n };\\n \\n struct QInt32 {\\n-  QInt32() {}\\n+  QInt32() : value(0) {}\\n   QInt32(const int8_t v) : value(v) {}\\n   QInt32(const int32_t v) : value(v) {}\\n   QInt32(const uint32_t v) : value(static_cast<int32_t>(v)) {}'}}",
            "message_norm":"default initialize fixed point eigen types.\n\nin certain cases, tensors are filled with default values of the type. but, for these fixed point types, these values were uninitialized. thus, we would have uninitialized memory access bugs, some of which were caught by msan.\n\npiperorigin-revid: 344101137\nchange-id: i14555fda74dca3b5f1582da9008901937e3f14e2",
            "language":"en",
            "entities":"[('initialize', 'SECWORD', ''), ('fixed', 'ACTION', ''), ('fixed', 'ACTION', ''), ('uninitialized', 'SECWORD', ''), ('uninitialized memory', 'SECWORD', ''), ('bugs', 'FLAW', ''), ('344101137', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h'])",
            "num_files":1.0
        },
        {
            "index":2853,
            "vuln_id":"GHSA-r4c4-5fpq-56wg",
            "cwe_id":"{'CWE-125'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378'}",
            "dataset":"osv",
            "summary":"Heap OOB in boosted trees ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `BoostedTreesSparseCalculateBestFeatureSplit`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(\n  node_id_range=[0,10],\n  stats_summary_indices=[[1, 2, 3, 0x1000000]],\n  stats_summary_values=[1.0],\n  stats_summary_shape=[1,1,1,1],\n  l1=l2=[1.0],\n  tree_complexity=[0.5],\n  min_node_weight=[1.0],\n  logits_dimension=3,\n  split_type='inequality')                                                                                                                                                                                                                                                                \n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc) needs to validate that each value in `stats_summary_indices` is in range.\n  \n### Patches\nWe have patched the issue in GitHub commit [e84c975313e8e8e38bb2ea118196369c45c51378](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378",
            "commit_sha":"e84c975313e8e8e38bb2ea118196369c45c51378",
            "patch":"SINGLE",
            "chain_ord":"['e84c975313e8e8e38bb2ea118196369c45c51378']",
            "before_first_fix_commit":"{'2e0ee46f1a47675152d3d865797a18358881d7a6'}",
            "last_fix_commit":"e84c975313e8e8e38bb2ea118196369c45c51378",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 19:35:03",
            "message":"In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaa",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e84c975313e8e8e38bb2ea118196369c45c51378\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\\n+      OP_REQUIRES(context, stat_dim < stats_dims,\\n+                  errors::InvalidArgument(\\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\\n+                      \"stats_summary_indices, cannot be greater than stats \"\\n+                      \"dims, the last value in stats_summary_shape, which was \",\\n+                      stats_dims, \". At index (\", idx,\\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\\n       auto& b_map = f_insert_result.first->second;'}}",
            "message_norm":"in tf.raw_ops.boostedtreessparsecalculatebestfeaturesplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\npiperorigin-revid: 387171191\nchange-id: i83ca8a75b22aa78c037e8b98779da6cced16bfaa",
            "language":"en",
            "entities":"[('387171191', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":2237,
            "vuln_id":"GHSA-jf9v-q8vh-3fmc",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/icecoder\/ICEcoder\/commit\/21d6ae0f2a3fce7d076ae430d48f5df56bd0f256'}",
            "dataset":"osv",
            "summary":"Cross-site scripting in ICEcoder In ICEcoder 8.0 allows, a reflected XSS vulnerability was identified in the multipe-results.php page due to insufficient sanitization of the _GET['replace'] variable. As a result, arbitrary Javascript code can get executed.",
            "published_date":"2021-09-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/icecoder\/ICEcoder",
            "commit_href":"https:\/\/github.com\/icecoder\/ICEcoder\/commit\/21d6ae0f2a3fce7d076ae430d48f5df56bd0f256",
            "commit_sha":"21d6ae0f2a3fce7d076ae430d48f5df56bd0f256",
            "patch":"SINGLE",
            "chain_ord":"['21d6ae0f2a3fce7d076ae430d48f5df56bd0f256']",
            "before_first_fix_commit":"{'54e4aff163d29edb13fe885219f82fca258c7e99'}",
            "last_fix_commit":"21d6ae0f2a3fce7d076ae430d48f5df56bd0f256",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/25\/2021, 20:22:25",
            "message":"XSS and usage fixes on multiple-results.php",
            "author":"mattpass",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 12, 'total': 27}",
            "files":"{'lib\/multiple-results.php': {'additions': 15, 'deletions': 12, 'changes': 27, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/icecoder\/ICEcoder\/raw\/21d6ae0f2a3fce7d076ae430d48f5df56bd0f256\/lib%2Fmultiple-results.php', 'patch': '@@ -1,4 +1,5 @@\\n <?php\\n+\/\/ TODO: The whole file needs a refactor and comments!\\n include \"headers.php\";\\n include \"settings.php\";\\n $t = $text[\\'multiple-results\\'];\\n@@ -101,16 +102,18 @@\\n             if (\\n                 \/\/ TODO: Find in filenames not working with regex, see all instances of findText and $findText below\\n                 true === haveMatch && -1 < targetURL.indexOf(\\'_perms\\')) {\\n-                if (-1 < userTarget.indexOf(\"selected\")) {\\n-                    for (let j = 0; j < parent.ICEcoder.selectedFiles.length; j++) {\\n-                        \/\/ TODO: This whole file needs comments - what does the below do?!\\n+                    if (-1 < userTarget.indexOf(\"selected\")) {\\n+                        for (let j = 0; j < parent.ICEcoder.selectedFiles.length; j++) {\\n                         if (\\n-                            0 === targetURL.replace(\/\\\\\/\/g, \"|\").indexOf(parent.ICEcoder.selectedFiles[j].replace(\/\\\\\/\/g, \"|\").replace(\/_perms\/g, \"\"))\\n+                            \/\/ If the pipe delimited targetURL starts with this pipe delimited, non _perms elem selectedFile\\n+                            0 === targetURL.replace(\/\\\\\/\/g, \"|\").indexOf(parent.ICEcoder.selectedFiles[j].replace(\/\\\\\/\/g, \"|\").replace(\/_perms\/g, \"\").toLowerCase())\\n                             && (\\n-                            targetURL.replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\") === parent.ICEcoder.selectedFiles[j].replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\")\\n+                            \/\/ If the slash delimited, non _perms elem matches the slasj delimited, non _perms elem\\n+                            targetURL.replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\") === parent.ICEcoder.selectedFiles[j].replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\").toLowerCase()\\n                             ||\\n+                            \/\/ Path length for targetURL is greater than path length for this selectedFile and targetURL char at selectedFiles length ends with a slash\\n                             (targetURL.replace(\/\\\\|\/g, \"\/\").split(\"\/\").length > parent.ICEcoder.selectedFiles[j].replace(\/\\\\|\/g, \"\/\").split(\"\/\").length && \"\/\" === targetURL.charAt(parent.ICEcoder.selectedFiles[j].length)))) {\\n-                            foundInSelected = true;\\n+                                foundInSelected = true;\\n                         }\\n                     }\\n                 }\\n@@ -124,8 +127,8 @@\\n                     \/\/ TODO: get this line working\\n                     resultsDisplay +=\\n                         targetURL.replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\").replace(\/<?php\\n-                            echo str_replace(\"\/\", \"\\\\\/\",strtolower($findText)); ?>\/g, \"<b>\" +\\n-                            findText.toLowerCase() + \"<\/b>\");\\n+                            echo str_replace(\"\/\", \"\\\\\/\",strtolower(preg_quote($findText))); ?>\/g, \"<b>\" +\\n+                            parent.ICEcoder.xssClean(findText).toLowerCase() + \"<\/b>\");\\n                         resultsDisplay += \\'<\/a><br>\\';\\n                     <?php if (false === isset($_GET[\\'replace\\'])) { ?>\\n                     resultsDisplay += \\'<div id=\"foundCount\\' + i +\\'\">\\' + spansArray[i].innerHTML + \\'<\/div>\\';\\n@@ -134,8 +137,8 @@\\n                     resultsDisplay +=\\n                         \\'<div id=\"foundCount\\' + i + \\'\">\\' + spansArray[i].innerHTML +\\n                         \\', <?php echo $t[\\'rename to\\'];?> \\' +\\n-                        targetURL.replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\").replace(\/<?php echo str_replace(\"\/\", \"\\\\\/\",strtolower($findText)); ?>\/g,\"<b><?php\\n-                            if (isset($_GET[\\'replace\\'])) {echo $_GET[\\'replace\\'];};\\n+                        targetURL.replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\").replace(\/<?php echo str_replace(\"\/\", \"\\\\\/\",strtolower(preg_quote($findText))); ?>\/g,\"<b><?php\\n+                            if (isset($_GET[\\'replace\\'])) {echo str_replace(\"&amp;\", \"&\", xssClean($_GET[\\'replace\\'], \\'script\\'));};\\n                         ?><\/b>\")+\\'<\/div>\\';\\n                         <?php\\n                         ;};\\n@@ -253,7 +256,7 @@ function phpGrep($q, $path, $base) {\\n \\n     const replaceInFileSingle = function(fileRef) {\\n         \/\/ TODO: findText in this line\\n-        parent.ICEcoder.replaceInFile(fileRef, true === parent.ICEcoder.findRegex ? findText : parent.ICEcoder.escapeRegex(findText), \\'<?php if (isset($_GET[\\'replace\\'])) {echo $_GET[\\'replace\\'];}; ?>\\');\\n+        parent.ICEcoder.replaceInFile(fileRef, true === parent.ICEcoder.findRegex ? findText : parent.ICEcoder.escapeRegex(findText), \\'<?php if (isset($_GET[\\'replace\\'])) {echo xssClean($_GET[\\'replace\\'], \\'script\\');}; ?>\\');\\n     };\\n \\n     const replaceInFilesAll = function() {\\n@@ -267,7 +270,7 @@ function phpGrep($q, $path, $base) {\\n         fileRef = spansArray[arrayRef].id.replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\");\\n         const rExp = new RegExp(true === parent.ICEcoder.findRegex ? findText : parent.ICEcoder.escapeRegex(findText), \"gi\");\\n         \/\/ TODO: get this working\\n-        newName = spansArray[arrayRef].id.replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\").replace(rExp, \"<?php if (isset($_GET[\\'replace\\'])) {echo $_GET[\\'replace\\'];}; ?>\");\\n+        newName = spansArray[arrayRef].id.replace(\/\\\\|\/g, \"\/\").replace(\/_perms\/g, \"\").replace(rExp, \"<?php if (isset($_GET[\\'replace\\'])) {echo xssClean($_GET[\\'replace\\'], \\'script\\');}; ?>\");\\n         parent.ICEcoder.renameFile(fileRef,newName);\\n     };'}}",
            "message_norm":"xss and usage fixes on multiple-results.php",
            "language":"en",
            "entities":"[('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/multiple-results.php'])",
            "num_files":1.0
        },
        {
            "index":1386,
            "vuln_id":"GHSA-9hx2-hgq2-2g4f",
            "cwe_id":"{'CWE-400'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/python-pillow\/Pillow\/commit\/6207b44ab1ff4a91d8ddc7579619876d0bb191a4', 'https:\/\/github.com\/python-pillow\/Pillow\/commit\/3bce145966374dd39ce58a6fc0083f8d1890719c'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service (ReDoS) in Pillow An issue was discovered in Pillow before 8.1.1. The PDF parser allows a regular expression DoS (ReDoS) attack via a crafted PDF file because of a catastrophic backtracking regex.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/python-pillow\/Pillow",
            "commit_href":"https:\/\/github.com\/python-pillow\/Pillow\/commit\/3bce145966374dd39ce58a6fc0083f8d1890719c",
            "commit_sha":"3bce145966374dd39ce58a6fc0083f8d1890719c",
            "patch":"MULTI",
            "chain_ord":"['6207b44ab1ff4a91d8ddc7579619876d0bb191a4', '3bce145966374dd39ce58a6fc0083f8d1890719c']",
            "before_first_fix_commit":"{'cbdce6c5d054fccaf4af34b47f212355c64ace7a'}",
            "last_fix_commit":"3bce145966374dd39ce58a6fc0083f8d1890719c",
            "chain_ord_pos":2.0,
            "commit_datetime":"01\/09\/2021, 13:53:09",
            "message":"Use more specific regex chars to prevent ReDoS\n\n* CVE-2021-25292",
            "author":"Hugo van Kemenade",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'src\/PIL\/PdfParser.py': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/python-pillow\/Pillow\/raw\/3bce145966374dd39ce58a6fc0083f8d1890719c\/src%2FPIL%2FPdfParser.py', 'patch': '@@ -580,8 +580,9 @@ def next_object_id(self, offset=None):\\n     whitespace_or_hex = br\"[\\\\000\\\\011\\\\012\\\\014\\\\015\\\\0400-9a-fA-F]\"\\n     whitespace_optional = whitespace + b\"*\"\\n     whitespace_mandatory = whitespace + b\"+\"\\n+    whitespace_optional_no_nl = br\"[\\\\000\\\\011\\\\014\\\\015\\\\040]*\"  # no \"\\\\012\" aka \"\\\\n\"\\n     newline_only = br\"[\\\\r\\\\n]+\"\\n-    newline = whitespace_optional + newline_only + whitespace_optional\\n+    newline = whitespace_optional_no_nl + newline_only + whitespace_optional_no_nl\\n     re_trailer_end = re.compile(\\n         whitespace_mandatory\\n         + br\"trailer\"'}}",
            "message_norm":"use more specific regex chars to prevent redos\n\n* cve-2021-25292",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('redos', 'SECWORD', ''), ('cve-2021-25292', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/PIL\/PdfParser.py'])",
            "num_files":1.0
        },
        {
            "index":1439,
            "vuln_id":"GHSA-9w2p-5mgw-p94c",
            "cwe_id":"{'CWE-681'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/96f364a1ca3009f98980021c4b32be5fdcca33a1'}",
            "dataset":"osv",
            "summary":"Integer overflow due to conversion to unsigned ### Impact\nThe implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=[1.0,2.0],\n  input=[1.0,1.0],\n  input_min=[0.0],\n  input_max=[10.0],\n  axis=-100)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc#L126) uses the `axis` value as the size argument to `absl::InlinedVector` constructor. But, the constructor uses an unsigned type for the argument, so the implicit conversion transforms the negative value to a large integer.\n\n### Patches\nWe have patched the issue in GitHub commit [96f364a1ca3009f98980021c4b32be5fdcca33a1](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/96f364a1ca3009f98980021c4b32be5fdcca33a1).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, and TensorFlow 2.4.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/96f364a1ca3009f98980021c4b32be5fdcca33a1",
            "commit_sha":"96f364a1ca3009f98980021c4b32be5fdcca33a1",
            "patch":"SINGLE",
            "chain_ord":"['96f364a1ca3009f98980021c4b32be5fdcca33a1']",
            "before_first_fix_commit":"{'10fe168385e67aca66427910ba6942eb14d31c5a'}",
            "last_fix_commit":"96f364a1ca3009f98980021c4b32be5fdcca33a1",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2021, 20:27:01",
            "message":"Validate axis input in tf.raw_ops.QuantizeAndDequantizeV4Grad\n\nPiperOrigin-RevId: 388291385\nChange-Id: I3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
            "files":"{'tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/96f364a1ca3009f98980021c4b32be5fdcca33a1\/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -158,6 +158,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\\n     Tensor* input_backprop = nullptr;\\n     OP_REQUIRES_OK(ctx,\\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\\n+    OP_REQUIRES(\\n+        ctx, axis_ >= -1,\\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\\n+                errors::InvalidArgument(\\n+                    \"Axis should be -1 or 0 or a positive value less than \",\\n+                    input.shape().dims(), \"but given axis value was \", axis_));\\n \\n     OP_REQUIRES(\\n         ctx, input.IsSameSize(gradient),'}}",
            "message_norm":"validate axis input in tf.raw_ops.quantizeanddequantizev4grad\n\npiperorigin-revid: 388291385\nchange-id: i3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
            "language":"ca",
            "entities":"[('validate', 'ACTION', ''), ('388291385', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc'])",
            "num_files":1.0
        },
        {
            "index":637,
            "vuln_id":"GHSA-5gqf-456p-4836",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in `SdcaOptimizer` ### Impact\nThe implementation of `tf.raw_ops.SdcaOptimizer` triggers undefined behavior due to dereferencing a null pointer:\n\n```python\nimport tensorflow as tf\n\nsparse_example_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_indices = [tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_values = []\n\ndense_features = []\ndense_weights = []\n\nexample_weights = tf.constant((0.0), dtype=tf.float32)\nexample_labels = tf.constant((0.0), dtype=tf.float32)\n\nsparse_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_weights = [tf.constant((0.0), dtype=tf.float32), tf.constant((0.0), dtype=tf.float32)]\n  \nexample_state_data = tf.constant([0.0, 0.0, 0.0, 0.0], shape=[1, 4], dtype=tf.float32)\n  \ntf.raw_ops.SdcaOptimizer(\n  sparse_example_indices=sparse_example_indices,\n  sparse_feature_indices=sparse_feature_indices,\n  sparse_feature_values=sparse_feature_values, dense_features=dense_features,\n  example_weights=example_weights, example_labels=example_labels, \n  sparse_indices=sparse_indices, sparse_weights=sparse_weights, \n  dense_weights=dense_weights, example_state_data=example_state_data,\n  loss_type=\"logistic_loss\", l1=0.0, l2=0.0, num_loss_partitions=1,\n  num_inner_iterations=1, adaptative=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/60a45c8b6192a4699f2e2709a2645a751d435cc3\/tensorflow\/core\/kernels\/sdca_internal.cc) does not validate that the user supplied arguments satisfy all [constraints expected by the op](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/raw_ops\/SdcaOptimizer).\n\n### Patches\nWe have patched the issue in GitHub commit [f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb",
            "commit_sha":"f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb",
            "patch":"SINGLE",
            "chain_ord":"['f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb']",
            "before_first_fix_commit":"{'60a45c8b6192a4699f2e2709a2645a751d435cc3'}",
            "last_fix_commit":"f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 18:40:50",
            "message":"Add several missing validations in SDCA\n\nPiperOrigin-RevId: 372172877\nChange-Id: Id366da962432e18dcbfac847d11e98488bebb70a",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 36, 'deletions': 0, 'total': 36}",
            "files":"{'tensorflow\/core\/kernels\/sdca_internal.cc': {'additions': 36, 'deletions': 0, 'changes': 36, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb\/tensorflow%2Fcore%2Fkernels%2Fsdca_internal.cc', 'patch': '@@ -99,17 +99,31 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\\n   OpInputList sparse_weights_inputs;\\n   TF_RETURN_IF_ERROR(\\n       context->input_list(\"sparse_weights\", &sparse_weights_inputs));\\n+  if (sparse_indices_inputs.size() != sparse_weights_inputs.size())\\n+    return errors::InvalidArgument(\\n+        \"sparse_indices and sparse_weights must have the same length, got \",\\n+        sparse_indices_inputs.size(), \" and \", sparse_weights_inputs.size());\\n   OpInputList dense_weights_inputs;\\n   TF_RETURN_IF_ERROR(\\n       context->input_list(\"dense_weights\", &dense_weights_inputs));\\n \\n   OpOutputList sparse_weights_outputs;\\n   TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",\\n                                           &sparse_weights_outputs));\\n+  if (sparse_weights_outputs.size() != sparse_weights_inputs.size())\\n+    return errors::InvalidArgument(\\n+        \"out_delta_sparse_weights and sparse_weights must have the same \"\\n+        \"length, got \",\\n+        sparse_weights_outputs.size(), \" and \", sparse_weights_inputs.size());\\n \\n   OpOutputList dense_weights_outputs;\\n   TF_RETURN_IF_ERROR(\\n       context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));\\n+  if (dense_weights_outputs.size() != dense_weights_inputs.size())\\n+    return errors::InvalidArgument(\\n+        \"out_delta_dense_weights and dense_weights must have the same length, \"\\n+        \"got \",\\n+        dense_weights_outputs.size(), \" and \", dense_weights_inputs.size());\\n \\n   for (int i = 0; i < sparse_weights_inputs.size(); ++i) {\\n     Tensor* delta_t;\\n@@ -327,13 +341,28 @@ Status Examples::Initialize(OpKernelContext* const context,\\n   OpInputList sparse_example_indices_inputs;\\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\\n                                          &sparse_example_indices_inputs));\\n+  if (sparse_example_indices_inputs.size() != num_sparse_features)\\n+    return errors::InvalidArgument(\\n+        \"Expected \", num_sparse_features,\\n+        \" tensors in sparse_example_indices but got \",\\n+        sparse_example_indices_inputs.size());\\n   OpInputList sparse_feature_indices_inputs;\\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\\n                                          &sparse_feature_indices_inputs));\\n+  if (sparse_feature_indices_inputs.size() != num_sparse_features)\\n+    return errors::InvalidArgument(\\n+        \"Expected \", num_sparse_features,\\n+        \" tensors in sparse_feature_indices but got \",\\n+        sparse_feature_indices_inputs.size());\\n   OpInputList sparse_feature_values_inputs;\\n   if (num_sparse_features_with_values > 0) {\\n     TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\\n                                            &sparse_feature_values_inputs));\\n+    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\\n+      return errors::InvalidArgument(\\n+          \"Expected \", num_sparse_features_with_values,\\n+          \" tensors in sparse_feature_values but got \",\\n+          sparse_feature_values_inputs.size());\\n   }\\n \\n   const Tensor* example_weights_t;\\n@@ -400,6 +429,13 @@ Status Examples::CreateSparseFeatureRepresentation(\\n           sparse_example_indices_inputs[i].template flat<int64>();\\n       auto feature_indices =\\n           sparse_feature_indices_inputs[i].template flat<int64>();\\n+      if (example_indices.size() != feature_indices.size()) {\\n+        mutex_lock l(mu);\\n+        result = errors::InvalidArgument(\\n+            \"Found mismatched example_indices and feature_indices [\",\\n+            example_indices, \"] vs [\", feature_indices, \"]\");\\n+        return;\\n+      }\\n \\n       \/\/ Parse features for each example. Features for a particular example\\n       \/\/ are at the offsets (start_id, end_id]'}}",
            "message_norm":"add several missing validations in sdca\n\npiperorigin-revid: 372172877\nchange-id: id366da962432e18dcbfac847d11e98488bebb70a",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validations', 'SECWORD', ''), ('372172877', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sdca_internal.cc'])",
            "num_files":1.0
        },
        {
            "index":930,
            "vuln_id":"GHSA-72wf-hwcq-65h9",
            "cwe_id":"{'CWE-352'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/filebrowser\/filebrowser\/commit\/74b7cd8e81840537a8206317344f118093153e8d'}",
            "dataset":"osv",
            "summary":"Cross-Site Request Forgery in Filebrowser A Cross-Site Request Forgery (CSRF) vulnerability exists in Filebrowser < 2.18.0 that allows attackers to create a backdoor user with admin privilege and get access to the filesystem via a malicious HTML webpage that is sent to the victim.",
            "published_date":"2022-02-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/filebrowser\/filebrowser",
            "commit_href":"https:\/\/github.com\/filebrowser\/filebrowser\/commit\/74b7cd8e81840537a8206317344f118093153e8d",
            "commit_sha":"74b7cd8e81840537a8206317344f118093153e8d",
            "patch":"SINGLE",
            "chain_ord":"['74b7cd8e81840537a8206317344f118093153e8d']",
            "before_first_fix_commit":"{'6cb51b4eb4751b49e7d3458c4a23589ccf16790b'}",
            "last_fix_commit":"74b7cd8e81840537a8206317344f118093153e8d",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/31\/2021, 16:13:16",
            "message":"fix: security issue in command runner (closes #1621)",
            "author":"Oleg Lobanov",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 6, 'total': 12}",
            "files":"{'http\/commands.go': {'additions': 6, 'deletions': 6, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/filebrowser\/filebrowser\/raw\/74b7cd8e81840537a8206317344f118093153e8d\/http%2Fcommands.go', 'patch': '@@ -59,19 +59,19 @@ var commandsHandler = withUser(func(w http.ResponseWriter, r *http.Request, d *d\\n \\t\\t}\\n \\t}\\n \\n-\\tif !d.server.EnableExec || !d.user.CanExecute(strings.Split(raw, \" \")[0]) {\\n-\\t\\tif err := conn.WriteMessage(websocket.TextMessage, cmdNotAllowed); err != nil { \/\/nolint:govet\\n+\\tcommand, err := runner.ParseCommand(d.settings, raw)\\n+\\tif err != nil {\\n+\\t\\tif err := conn.WriteMessage(websocket.TextMessage, []byte(err.Error())); err != nil { \/\/nolint:govet\\n \\t\\t\\twsErr(conn, r, http.StatusInternalServerError, err)\\n \\t\\t}\\n-\\n \\t\\treturn 0, nil\\n \\t}\\n \\n-\\tcommand, err := runner.ParseCommand(d.settings, raw)\\n-\\tif err != nil {\\n-\\t\\tif err := conn.WriteMessage(websocket.TextMessage, []byte(err.Error())); err != nil { \/\/nolint:govet\\n+\\tif !d.server.EnableExec || !d.user.CanExecute(command[0]) {\\n+\\t\\tif err := conn.WriteMessage(websocket.TextMessage, cmdNotAllowed); err != nil { \/\/nolint:govet\\n \\t\\t\\twsErr(conn, r, http.StatusInternalServerError, err)\\n \\t\\t}\\n+\\n \\t\\treturn 0, nil\\n \\t}'}}",
            "message_norm":"fix: security issue in command runner (closes #1621)",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('#1621', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['http\/commands.go'])",
            "num_files":1.0
        },
        {
            "index":309,
            "vuln_id":"GHSA-3r95-23jp-mhvg",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/TYPO3\/typo3\/commit\/6f2554dc4ea0b670fd5599c54fd788d4db96c4a0'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting in TYPO3's Form Framework > ### Meta\n> * CVSS: `CVSS:3.1\/AV:N\/AC:L\/PR:L\/UI:R\/S:C\/C:L\/I:L\/A:N\/E:F\/RL:O\/RC:C` (4.9)\n\n### Problem\nIt has been discovered that the Form Designer backend module of the Form Framework is vulnerable to cross-site scripting. A valid backend user account with access to the form module is needed to exploit this vulnerability.\n\n### Solution\nUpdate to TYPO3 versions 8.7.47 ELTS, 9.5.35 ELTS, 10.4.29, 11.5.11 that fix the problem described above.\n\n### Credits\nThanks to Gabe Troyan who reported and fixed the issue.\n\n### References\n* [TYPO3-CORE-SA-2022-003](https:\/\/typo3.org\/security\/advisory\/typo3-core-sa-2022-003)",
            "published_date":"2022-06-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/TYPO3\/typo3",
            "commit_href":"https:\/\/github.com\/TYPO3\/typo3\/commit\/6f2554dc4ea0b670fd5599c54fd788d4db96c4a0",
            "commit_sha":"6f2554dc4ea0b670fd5599c54fd788d4db96c4a0",
            "patch":"SINGLE",
            "chain_ord":"['6f2554dc4ea0b670fd5599c54fd788d4db96c4a0']",
            "before_first_fix_commit":"{'c93ea692e7dfef03b7c50fe5437487545bee4d6a'}",
            "last_fix_commit":"6f2554dc4ea0b670fd5599c54fd788d4db96c4a0",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/14\/2022, 07:17:30",
            "message":"[SECURITY] Ensure text preview of multivalue items in form editor\n\nMultivalue items in the form editor user interface were previewed\nas HTML, but should be treated as scalar text only.\n\nResolves: #96743\nReleases: main, 11.5, 10.4\nChange-Id: I5e8dab26119490ecf19ac5d48c2bc7a5a00daaad\nSecurity-Bulletin: TYPO3-CORE-SA-2022-003\nSecurity-References: CVE-2022-31048\nReviewed-on: https:\/\/review.typo3.org\/c\/Packages\/TYPO3.CMS\/+\/73297\nTested-by: Oliver Hader <oliver.hader@typo3.org>\nReviewed-by: Oliver Hader <oliver.hader@typo3.org>",
            "author":"Gabe Troyan",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 6, 'total': 12}",
            "files":"{'typo3\/sysext\/form\/Resources\/Public\/JavaScript\/backend\/form-editor\/stage-component.js': {'additions': 6, 'deletions': 6, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/TYPO3\/typo3\/raw\/6f2554dc4ea0b670fd5599c54fd788d4db96c4a0\/typo3%2Fsysext%2Fform%2FResources%2FPublic%2FJavaScript%2Fbackend%2Fform-editor%2Fstage-component.js', 'patch': \"@@ -513,10 +513,10 @@ function factory($, Helper, Icons) {\\n      *\/\\n     function setStageHeadline(title) {\\n       if (getUtility().isUndefinedOrNull(title)) {\\n-        title = buildTitleByFormElement();\\n+        title = buildTitleByFormElement().text();\\n       }\\n \\n-      $(getHelper().getDomElementDataIdentifierSelector('stageHeadline')).html(title);\\n+      $(getHelper().getDomElementDataIdentifierSelector('stageHeadline')).text(title);\\n     };\\n \\n     \/**\\n@@ -981,10 +981,10 @@ function factory($, Helper, Icons) {\\n \\n       getHelper()\\n         .getTemplatePropertyDomElement('_type', template)\\n-        .append(getFormElementDefinition(formElement, 'label'));\\n+        .append(document.createTextNode(getFormElementDefinition(formElement, 'label')));\\n       getHelper()\\n         .getTemplatePropertyDomElement('_identifier', template)\\n-        .append(formElement.get('identifier'));\\n+        .append(document.createTextNode(formElement.get('identifier')));\\n     };\\n \\n     \/**\\n@@ -1029,7 +1029,7 @@ function factory($, Helper, Icons) {\\n \\n             getHelper()\\n               .getTemplatePropertyDomElement('_label', rowTemplate)\\n-              .append(collectionElementConfiguration['label']);\\n+              .append(document.createTextNode(collectionElementConfiguration['label']));\\n             $(getHelper().getDomElementDataIdentifierSelector('validatorsContainer'), $(template))\\n               .append(rowTemplate.html());\\n           }\\n@@ -1089,7 +1089,7 @@ function factory($, Helper, Icons) {\\n           }\\n         }\\n \\n-        getHelper().getTemplatePropertyDomElement('_label', rowTemplate).append(label);\\n+        getHelper().getTemplatePropertyDomElement('_label', rowTemplate).append(document.createTextNode(label));\\n \\n         if (isPreselected) {\\n           getHelper().getTemplatePropertyDomElement('_label', rowTemplate).addClass(\"}}",
            "message_norm":"[security] ensure text preview of multivalue items in form editor\n\nmultivalue items in the form editor user interface were previewed\nas html, but should be treated as scalar text only.\n\nresolves: #96743\nreleases: main, 11.5, 10.4\nchange-id: i5e8dab26119490ecf19ac5d48c2bc7a5a00daaad\nsecurity-bulletin: typo3-core-sa-2022-003\nsecurity-references: cve-2022-31048\nreviewed-on: https:\/\/review.typo3.org\/c\/packages\/typo3.cms\/+\/73297\ntested-by: oliver hader <oliver.hader@typo3.org>\nreviewed-by: oliver hader <oliver.hader@typo3.org>",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('ensure', 'ACTION', ''), ('#96743', 'ISSUE', ''), ('security', 'SECWORD', ''), ('security', 'SECWORD', ''), ('cve-2022-31048', 'VULNID', 'CVE'), ('https:\/\/review.typo3.org\/c\/packages\/typo3.cms\/+\/73297', 'URL', ''), ('oliver.hader@typo3.org', 'EMAIL', ''), ('oliver.hader@typo3.org', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['typo3\/sysext\/form\/Resources\/Public\/JavaScript\/backend\/form-editor\/stage-component.js'])",
            "num_files":1.0
        },
        {
            "index":1436,
            "vuln_id":"GHSA-9vpm-rcf4-9wqw",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/376c352a37ce5a68b721406dc7e77ac4b6cf483d'}",
            "dataset":"osv",
            "summary":"Division by 0 in `MaxPoolGradWithArgmax` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGradWithArgmax` is vulnerable to a division by 0:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\ngrad = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nargmax = tf.constant([], shape=[0], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n\ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  padding='SAME', include_batch_in_index=False)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/279bab6efa22752a2827621b7edb56a730233bd8\/tensorflow\/core\/kernels\/maxpooling_op.cc#L1033-L1034) fails to validate that the batch dimension of the tensor is non-zero, before dividing by this quantity.\n\n### Patches\nWe have patched the issue in GitHub commit [376c352a37ce5a68b721406dc7e77ac4b6cf483d](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/376c352a37ce5a68b721406dc7e77ac4b6cf483d).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/376c352a37ce5a68b721406dc7e77ac4b6cf483d",
            "commit_sha":"376c352a37ce5a68b721406dc7e77ac4b6cf483d",
            "patch":"SINGLE",
            "chain_ord":"['376c352a37ce5a68b721406dc7e77ac4b6cf483d']",
            "before_first_fix_commit":"{'279bab6efa22752a2827621b7edb56a730233bd8'}",
            "last_fix_commit":"376c352a37ce5a68b721406dc7e77ac4b6cf483d",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 21:34:54",
            "message":"Don't do any work if output tensor is null (prevent div by 0)\n\nPiperOrigin-RevId: 372208700\nChange-Id: Iea6b6293e887ade8538facfdb50fb931e17f511e",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/maxpooling_op.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/376c352a37ce5a68b721406dc7e77ac4b6cf483d\/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc', 'patch': '@@ -1088,6 +1088,8 @@ class MaxPoolingGradWithArgmaxOp : public OpKernel {\\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\\n                                 {0}, 0, out_shape, &grad_out));\\n \\n+    if (out_shape.num_elements() == 0) return;  \/\/ nothing to be done\\n+\\n     LaunchMaxPoolingGradWithArgmax<Device, T>::launch(\\n         context, params, grad_in, argmax, grad_out, include_batch_in_index_);\\n   }'}}",
            "message_norm":"don't do any work if output tensor is null (prevent div by 0)\n\npiperorigin-revid: 372208700\nchange-id: iea6b6293e887ade8538facfdb50fb931e17f511e",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('div by 0', 'SECWORD', ''), ('372208700', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/maxpooling_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3069,
            "vuln_id":"GHSA-v768-w7m9-2vmm",
            "cwe_id":"{'CWE-824'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/578e634b4f1c1c684d4b4294f9e5281b2133b3ed'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in shape inference ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.SparseFillEmptyRows`:\n\n```python\nimport tensorflow as tf\n  \ntf.compat.v1.disable_v2_behavior()\ntf.raw_ops.SparseFillEmptyRows(\n  indices = tf.constant([], shape=[0, 0], dtype=tf.int64),\n  values = tf.constant([], shape=[0], dtype=tf.int64),\n  dense_shape = tf.constant([], shape=[0], dtype=tf.int64),\n  default_value = 0)\n```\n  \nThe shape inference [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/ops\/sparse_ops.cc#L608-L634) does not validate that the input arguments are not empty tensors.\n\n### Patches \nWe have patched the issue in GitHub commit [578e634b4f1c1c684d4b4294f9e5281b2133b3ed](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/578e634b4f1c1c684d4b4294f9e5281b2133b3ed).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/578e634b4f1c1c684d4b4294f9e5281b2133b3ed",
            "commit_sha":"578e634b4f1c1c684d4b4294f9e5281b2133b3ed",
            "patch":"SINGLE",
            "chain_ord":"['578e634b4f1c1c684d4b4294f9e5281b2133b3ed']",
            "before_first_fix_commit":"{'d7de67733925de196ec8863a33445b73f9562d1d'}",
            "last_fix_commit":"578e634b4f1c1c684d4b4294f9e5281b2133b3ed",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/30\/2021, 05:24:08",
            "message":"Prevent a segfault in shape inference due to bad inputs.\n\nPiperOrigin-RevId: 387737970\nChange-Id: Ibd1cf3dbdce1dd2ab47fd633d5c5a57f7d8fb6e9",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/ops\/sparse_ops.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/578e634b4f1c1c684d4b4294f9e5281b2133b3ed\/tensorflow%2Fcore%2Fops%2Fsparse_ops.cc', 'patch': '@@ -16,6 +16,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/common_shape_fns.h\"\\n #include \"tensorflow\/core\/framework\/op.h\"\\n #include \"tensorflow\/core\/framework\/shape_inference.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n \\n namespace tensorflow {\\n \\n@@ -619,6 +620,8 @@ REGISTER_OP(\"SparseFillEmptyRows\")\\n       DimensionHandle unused_dim;\\n       TF_RETURN_IF_ERROR(c->Merge(c->Dim(input_indices, 1),\\n                                   c->Dim(input_shape, 0), &unused_dim));\\n+      if (c->Value(c->NumElements(input_shape)) == 0)\\n+        return errors::InvalidArgument(\"dense_shape must not be empty\");\\n       ShapeHandle output_indices =\\n           c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\\n       ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);'}}",
            "message_norm":"prevent a segfault in shape inference due to bad inputs.\n\npiperorigin-revid: 387737970\nchange-id: ibd1cf3dbdce1dd2ab47fd633d5c5a57f7d8fb6e9",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('segfault', 'SECWORD', ''), ('387737970', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/ops\/sparse_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":1042,
            "vuln_id":"GHSA-7mpx-vg3c-cmr4",
            "cwe_id":"{'CWE-287'}",
            "score":8.2,
            "chain":"{'https:\/\/github.com\/salvoravida\/react-adal\/commit\/74158dba1647b12fe96fa401e306a6287fe9e2a9'}",
            "dataset":"osv",
            "summary":"Improper Authentication in react-adal This affects versions of react-adal < 0.5.1. It is possible for a specially crafted JWT token and request URL can cause the nonce, session and refresh values to be incorrectly validated, causing the application to treat an attacker-generated JWT token as authentic. The logical defect is caused by how the nonce, session and refresh values are stored in the browser local storage or session storage. Each key is automatically appended by ||. When the received nonce and session keys are generated, the list of values is stored in the browser storage, separated by ||, with || always appended to the end of the list. Since || will always be the last 2 characters of the stored values, an empty string (\"\") will always be in the list of the valid values. Therefore, if an empty session parameter is provided in the callback URL, and a specially-crafted JWT token contains an nonce value of \"\" (empty string), then adal.js will consider the JWT token as authentic.",
            "published_date":"2021-04-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/salvoravida\/react-adal",
            "commit_href":"https:\/\/github.com\/salvoravida\/react-adal\/commit\/74158dba1647b12fe96fa401e306a6287fe9e2a9",
            "commit_sha":"74158dba1647b12fe96fa401e306a6287fe9e2a9",
            "patch":"SINGLE",
            "chain_ord":"['74158dba1647b12fe96fa401e306a6287fe9e2a9']",
            "before_first_fix_commit":"{'e82bc421d70805ff308e11a1f0f1fcd7fb2b3186'}",
            "last_fix_commit":"74158dba1647b12fe96fa401e306a6287fe9e2a9",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/05\/2020, 20:19:06",
            "message":"ADAL.js update",
            "author":"Kris Hardy",
            "comments":null,
            "stats":"{'additions': 32, 'deletions': 51, 'total': 83}",
            "files":"{'src\/adal.js': {'additions': 32, 'deletions': 51, 'changes': 83, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/salvoravida\/react-adal\/raw\/74158dba1647b12fe96fa401e306a6287fe9e2a9\/src%2Fadal.js', 'patch': \"@@ -135,10 +135,6 @@ var AuthenticationContext = (function () {\\n         this._openedWindows = [];\\n         this._requestType = this.REQUEST_TYPE.LOGIN;\\n         window._adalInstance = this;\\n-        this._storageSupport = {\\n-            localStorage: null,\\n-            sessionStorage: null\\n-        };\\n \\n         \/\/ validate before constructor assignments\\n         if (config.displayCall && typeof config.displayCall !== 'function') {\\n@@ -813,7 +809,6 @@ var AuthenticationContext = (function () {\\n      * Clears cache items.\\n      *\/\\n     AuthenticationContext.prototype.clearCache = function () {\\n-        this._user = null;\\n         this._saveItem(this.CONSTANTS.STORAGE.LOGIN_REQUEST, '');\\n         this._saveItem(this.CONSTANTS.STORAGE.ANGULAR_LOGIN_REQUEST, '');\\n         this._saveItem(this.CONSTANTS.STORAGE.SESSION_STATE, '');\\n@@ -860,6 +855,7 @@ var AuthenticationContext = (function () {\\n      *\/\\n     AuthenticationContext.prototype.logOut = function () {\\n         this.clearCache();\\n+        this._user = null;\\n         var urlNavigate;\\n \\n         if (this.config.logOutUri) {\\n@@ -928,8 +924,7 @@ var AuthenticationContext = (function () {\\n      * @ignore\\n      *\/\\n     AuthenticationContext.prototype._addHintParameters = function (urlNavigate) {\\n-\\n-        \/\/If you don't use prompt=none, then if the session does not exist, there will be a failure.\\n+        \/\/If you don\ufffdt use prompt=none, then if the session does not exist, there will be a failure.\\n         \/\/If sid is sent alongside domain or login hints, there will be a failure since request is ambiguous.\\n         \/\/If sid is sent with a prompt value other than none or attempt_none, there will be a failure since the request is ambiguous.\\n \\n@@ -1103,7 +1098,7 @@ var AuthenticationContext = (function () {\\n         if (requestNonce) {\\n             requestNonce = requestNonce.split(this.CONSTANTS.CACHE_DELIMETER);\\n             for (var i = 0; i < requestNonce.length; i++) {\\n-                if (requestNonce[i] === user.profile.nonce) {\\n+                if (requestNonce[i] && requestNonce[i] === user.profile.nonce) {\\n                     return true;\\n                 }\\n             }\\n@@ -1122,7 +1117,7 @@ var AuthenticationContext = (function () {\\n         if (loginStates) {\\n             loginStates = loginStates.split(this.CONSTANTS.CACHE_DELIMETER);\\n             for (var i = 0; i < loginStates.length; i++) {\\n-                if (loginStates[i] === requestInfo.stateResponse) {\\n+                if (loginStates[i] && loginStates[i] === requestInfo.stateResponse) {\\n                     requestInfo.requestType = this.REQUEST_TYPE.LOGIN;\\n                     requestInfo.stateMatch = true;\\n                     return true;\\n@@ -1135,7 +1130,7 @@ var AuthenticationContext = (function () {\\n         if (acquireTokenStates) {\\n             acquireTokenStates = acquireTokenStates.split(this.CONSTANTS.CACHE_DELIMETER);\\n             for (var i = 0; i < acquireTokenStates.length; i++) {\\n-                if (acquireTokenStates[i] === requestInfo.stateResponse) {\\n+                if (acquireTokenStates[i] && acquireTokenStates[i] === requestInfo.stateResponse) {\\n                     requestInfo.requestType = this.REQUEST_TYPE.RENEW_TOKEN;\\n                     requestInfo.stateMatch = true;\\n                     return true;\\n@@ -1218,16 +1213,17 @@ var AuthenticationContext = (function () {\\n                             this._user = null;\\n                         } else {\\n                             this._saveItem(this.CONSTANTS.STORAGE.IDTOKEN, requestInfo.parameters[this.CONSTANTS.ID_TOKEN]);\\n+\\n                             \/\/ Save idtoken as access token for app itself\\n-                            var idTokenResource = this.config.loginResource ? this.config.loginResource : this.config.clientId;\\n+                            resource = this.config.loginResource ? this.config.loginResource : this.config.clientId;\\n \\n-                            if (!this._hasResource(idTokenResource)) {\\n+                            if (!this._hasResource(resource)) {\\n                                 keys = this._getItem(this.CONSTANTS.STORAGE.TOKEN_KEYS) || '';\\n-                                this._saveItem(this.CONSTANTS.STORAGE.TOKEN_KEYS, keys + idTokenResource + this.CONSTANTS.RESOURCE_DELIMETER);\\n+                                this._saveItem(this.CONSTANTS.STORAGE.TOKEN_KEYS, keys + resource + this.CONSTANTS.RESOURCE_DELIMETER);\\n                             }\\n \\n-                            this._saveItem(this.CONSTANTS.STORAGE.ACCESS_TOKEN_KEY + idTokenResource, requestInfo.parameters[this.CONSTANTS.ID_TOKEN]);\\n-                            this._saveItem(this.CONSTANTS.STORAGE.EXPIRATION_KEY + idTokenResource, this._user.profile.exp);\\n+                            this._saveItem(this.CONSTANTS.STORAGE.ACCESS_TOKEN_KEY + resource, requestInfo.parameters[this.CONSTANTS.ID_TOKEN]);\\n+                            this._saveItem(this.CONSTANTS.STORAGE.EXPIRATION_KEY + resource, this._user.profile.exp);\\n                         }\\n                     }\\n                     else {\\n@@ -1689,7 +1685,7 @@ var AuthenticationContext = (function () {\\n                 ifr.setAttribute('aria-hidden', 'true');\\n                 ifr.style.visibility = 'hidden';\\n                 ifr.style.position = 'absolute';\\n-                ifr.style.width = ifr.style.height = ifr.style.borderWidth = '0px';\\n+                ifr.style.width = ifr.style.height = ifr.borderWidth = '0px';\\n \\n                 adalFrame = document.getElementsByTagName('body')[0].appendChild(ifr);\\n             }\\n@@ -1764,52 +1760,37 @@ var AuthenticationContext = (function () {\\n     };\\n \\n     \/**\\n-     * Returns true if the browser supports given storage type\\n+     * Returns true if browser supports localStorage, false otherwise.\\n      * @ignore\\n      *\/\\n-    AuthenticationContext.prototype._supportsStorage = function(storageType) {\\n-        if (!(storageType in this._storageSupport)) {\\n-            return false;\\n-        }\\n-\\n-        if (this._storageSupport[storageType] !== null) {\\n-            return this._storageSupport[storageType];\\n-        }\\n-\\n+    AuthenticationContext.prototype._supportsLocalStorage = function () {\\n         try {\\n-            if (!(storageType in window) || window[storageType] === null) {\\n-                throw new Error();\\n-            }\\n-            var testKey = '__storageTest__';\\n-            window[storageType].setItem(testKey, 'A');\\n-            if (window[storageType].getItem(testKey) !== 'A') {\\n-                throw new Error();\\n-            }\\n-            window[storageType].removeItem(testKey);\\n-            if (window[storageType].getItem(testKey)) {\\n-                throw new Error();\\n-            }\\n-            this._storageSupport[storageType] = true;\\n+            if (!window.localStorage) return false; \/\/ Test availability\\n+            window.localStorage.setItem('storageTest', 'A'); \/\/ Try write\\n+            if (window.localStorage.getItem('storageTest') != 'A') return false; \/\/ Test read\/write\\n+            window.localStorage.removeItem('storageTest'); \/\/ Try delete\\n+            if (window.localStorage.getItem('storageTest')) return false; \/\/ Test delete\\n+            return true; \/\/ Success\\n         } catch (e) {\\n-            this._storageSupport[storageType] = false;\\n+            return false;\\n         }\\n-        return this._storageSupport[storageType];\\n-    }\\n-\\n-    \/**\\n-     * Returns true if browser supports localStorage, false otherwise.\\n-     * @ignore\\n-     *\/\\n-    AuthenticationContext.prototype._supportsLocalStorage = function () {        \\n-        return this._supportsStorage('localStorage');\\n     };\\n \\n     \/**\\n      * Returns true if browser supports sessionStorage, false otherwise.\\n      * @ignore\\n      *\/\\n     AuthenticationContext.prototype._supportsSessionStorage = function () {\\n-        return this._supportsStorage('sessionStorage');\\n+        try {\\n+            if (!window.sessionStorage) return false; \/\/ Test availability\\n+            window.sessionStorage.setItem('storageTest', 'A'); \/\/ Try write\\n+            if (window.sessionStorage.getItem('storageTest') != 'A') return false; \/\/ Test read\/write\\n+            window.sessionStorage.removeItem('storageTest'); \/\/ Try delete\\n+            if (window.sessionStorage.getItem('storageTest')) return false; \/\/ Test delete\\n+            return true; \/\/ Success\\n+        } catch (e) {\\n+            return false;\\n+        }\\n     };\\n \\n     \/**\\n@@ -1955,4 +1936,4 @@ var AuthenticationContext = (function () {\\n \\n     return AuthenticationContext;\\n \\n-}());\\n\\\\ No newline at end of file\\n+}());\"}}",
            "message_norm":"adal.js update",
            "language":"id",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"SUBMIT_CENTERED",
            "list_files":"dict_keys(['src\/adal.js'])",
            "num_files":1.0
        },
        {
            "index":72,
            "vuln_id":"GHSA-29mw-wpgm-hmr9",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/lodash\/lodash\/pull\/5065\/commits\/02906b8191d3c100c193fe6f7b27d1c40f200bb7'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service (ReDoS) in lodash All versions of package lodash prior to 4.17.21 are vulnerable to Regular Expression Denial of Service (ReDoS) via the toNumber, trim and trimEnd functions. Steps to reproduce (provided by reporter Liyuan Chen): var lo = require('lodash'); function build_blank (n) { var ret = \"1\" for (var i = 0; i < n; i++) { ret += \" \" } return ret + \"1\"; } var s = build_blank(50000) var time0 = Date.now(); lo.trim(s) var time_cost0 = Date.now() - time0; console.log(\"time_cost0: \" + time_cost0) var time1 = Date.now(); lo.toNumber(s) var time_cost1 = Date.now() - time1; console.log(\"time_cost1: \" + time_cost1) var time2 = Date.now(); lo.trimEnd(s) var time_cost2 = Date.now() - time2; console.log(\"time_cost2: \" + time_cost2)",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/lodash\/lodash",
            "commit_href":"https:\/\/github.com\/lodash\/lodash\/pull\/5065\/commits\/02906b8191d3c100c193fe6f7b27d1c40f200bb7",
            "commit_sha":"02906b8191d3c100c193fe6f7b27d1c40f200bb7",
            "patch":"SINGLE",
            "chain_ord":"['02906b8191d3c100c193fe6f7b27d1c40f200bb7']",
            "before_first_fix_commit":"{'ded9bc66583ed0b4e3b7dc906206d40757b4a90a'}",
            "last_fix_commit":"02906b8191d3c100c193fe6f7b27d1c40f200bb7",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/26\/2021, 22:17:05",
            "message":"perf: improve performance of `toNumber`, `trim` and `trimEnd` on large input strings",
            "author":"Micha\u0142 Lipi\u0144ski",
            "comments":null,
            "stats":"{'additions': 36, 'deletions': 7, 'total': 43}",
            "files":"{'lodash.js': {'additions': 36, 'deletions': 7, 'changes': 43, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/lodash\/lodash\/raw\/02906b8191d3c100c193fe6f7b27d1c40f200bb7\/lodash.js', 'patch': \"@@ -152,10 +152,11 @@\\n   var reRegExpChar = \/[\\\\\\\\^$.*+?()[\\\\]{}|]\/g,\\n       reHasRegExpChar = RegExp(reRegExpChar.source);\\n \\n-  \/** Used to match leading and trailing whitespace. *\/\\n-  var reTrim = \/^\\\\s+|\\\\s+$\/g,\\n-      reTrimStart = \/^\\\\s+\/,\\n-      reTrimEnd = \/\\\\s+$\/;\\n+  \/** Used to match leading whitespace. *\/\\n+  var reTrimStart = \/^\\\\s+\/;\\n+\\n+  \/** Used to match a single whitespace character. *\/\\n+  var reWhitespace = \/\\\\s\/;\\n \\n   \/** Used to match wrap detail comments. *\/\\n   var reWrapComment = \/\\\\{(?:\\\\n\\\\\/\\\\* \\\\[wrapped with .+\\\\] \\\\*\\\\\/)?\\\\n?\/,\\n@@ -993,6 +994,19 @@\\n     });\\n   }\\n \\n+  \/**\\n+   * The base implementation of `_.trim`.\\n+   *\\n+   * @private\\n+   * @param {string} string The string to trim.\\n+   * @returns {string} Returns the trimmed string.\\n+   *\/\\n+  function baseTrim(string) {\\n+    return string\\n+      ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\\n+      : string;\\n+  }\\n+\\n   \/**\\n    * The base implementation of `_.unary` without support for storing metadata.\\n    *\\n@@ -1326,6 +1340,21 @@\\n       : asciiToArray(string);\\n   }\\n \\n+  \/**\\n+   * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\\n+   * character of `string`.\\n+   *\\n+   * @private\\n+   * @param {string} string The string to inspect.\\n+   * @returns {number} Returns the index of the last non-whitespace character.\\n+   *\/\\n+  function trimmedEndIndex(string) {\\n+    var index = string.length;\\n+\\n+    while (index-- && reWhitespace.test(string.charAt(index))) {}\\n+    return index;\\n+  }\\n+\\n   \/**\\n    * Used by `_.unescape` to convert HTML entities to characters.\\n    *\\n@@ -12494,7 +12523,7 @@\\n       if (typeof value != 'string') {\\n         return value === 0 ? value : +value;\\n       }\\n-      value = value.replace(reTrim, '');\\n+      value = baseTrim(value);\\n       var isBinary = reIsBinary.test(value);\\n       return (isBinary || reIsOctal.test(value))\\n         ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\\n@@ -14979,7 +15008,7 @@\\n     function trim(string, chars, guard) {\\n       string = toString(string);\\n       if (string && (guard || chars === undefined)) {\\n-        return string.replace(reTrim, '');\\n+        return baseTrim(string);\\n       }\\n       if (!string || !(chars = baseToString(chars))) {\\n         return string;\\n@@ -15014,7 +15043,7 @@\\n     function trimEnd(string, chars, guard) {\\n       string = toString(string);\\n       if (string && (guard || chars === undefined)) {\\n-        return string.replace(reTrimEnd, '');\\n+        return string.slice(0, trimmedEndIndex(string) + 1);\\n       }\\n       if (!string || !(chars = baseToString(chars))) {\\n         return string;\"}}",
            "message_norm":"perf: improve performance of `tonumber`, `trim` and `trimend` on large input strings",
            "language":"en",
            "entities":"[('improve', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lodash.js'])",
            "num_files":1.0
        },
        {
            "index":223,
            "vuln_id":"GHSA-38m9-3vg4-rwvp",
            "cwe_id":"{'CWE-79'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/2b8fa5aac31e51e2aca83c7ef5d1281ba2e755f8'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in microweber microweber prior to version 1.2.11 is vulnerable to cross-site scripting.",
            "published_date":"2022-02-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/2b8fa5aac31e51e2aca83c7ef5d1281ba2e755f8",
            "commit_sha":"2b8fa5aac31e51e2aca83c7ef5d1281ba2e755f8",
            "patch":"SINGLE",
            "chain_ord":"['2b8fa5aac31e51e2aca83c7ef5d1281ba2e755f8']",
            "before_first_fix_commit":"{'93e1e59185d1fdf921d89a887887bca988b12085'}",
            "last_fix_commit":"2b8fa5aac31e51e2aca83c7ef5d1281ba2e755f8",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/18\/2022, 10:09:45",
            "message":"Update UrlManager.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'src\/MicroweberPackages\/Helper\/UrlManager.php': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/2b8fa5aac31e51e2aca83c7ef5d1281ba2e755f8\/src%2FMicroweberPackages%2FHelper%2FUrlManager.php', 'patch': '@@ -114,6 +114,9 @@ public function redirect($url)\\n         $redirectUrl = str_replace(\"\\\\r\", \"\", $redirectUrl);\\n         $redirectUrl = str_replace(\"\\\\n\", \"\", $redirectUrl);\\n \\n+        $clearInput = new HTMLClean();\\n+        $redirectUrl = $clearInput->clean($redirectUrl);\\n+\\n         if (headers_sent()) {\\n             echo \\'<meta http-equiv=\"refresh\" content=\"0;url=\\' . $redirectUrl . \\'\">\\';\\n         } else {'}}",
            "message_norm":"update urlmanager.php",
            "language":"sv",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"SUBMIT_CENTERED",
            "list_files":"dict_keys(['src\/MicroweberPackages\/Helper\/UrlManager.php'])",
            "num_files":1.0
        },
        {
            "index":1484,
            "vuln_id":"GHSA-c558-5gfm-p2r8",
            "cwe_id":"{'CWE-79'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a'}",
            "dataset":"osv",
            "summary":"JSPUI spellcheck and autocomplete tools vulnerable to Cross Site Scripting ### Impact\nThe JSPUI spellcheck \"Did you mean\" HTML escapes the data-spell attribute in the link, but not the actual displayed text.  Similarly, the JSPUI autocomplete HTML does not properly escape text passed to it. Both are vulnerable to XSS.  This vulnerability only impacts the JSPUI.\n\n_This vulnerability does NOT impact the XMLUI or 7.x._\n\n### Patches\n_DSpace 6.x:_\n* Fixed in 6.4 via two commits: \n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7\n* 6.x patch files available (may be applied manually if an immediate upgrade to 6.4 or above is not possible)\n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d.patch\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7.patch\n\n_DSpace 5.x:_\n* Fixed in 5.11 via two commits: \n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5\n* 5.x patch files available (may be applied manually if an immediate upgrade to 5.11 or 6.4 is not possible)\n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a.patch\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5.patch\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs \/ configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### References\nDiscovered & reported by Hassan Bhuiyan (Brunel University London)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
            "published_date":"2022-08-06",
            "chain_len":4,
            "project":"https:\/\/github.com\/DSpace\/DSpace",
            "commit_href":"https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5",
            "commit_sha":"6f75bb084ab1937d094208c55cd84340040bcbb5",
            "patch":"MULTI",
            "chain_ord":"['ebb83a75234d3de9be129464013e998dc929b68d', '35030a23e48b5946f5853332c797e1c4adea7bb7', 'c89e493e517b424dea6175caba54e91d3847fc3a', '6f75bb084ab1937d094208c55cd84340040bcbb5']",
            "before_first_fix_commit":"{'d1dd7d23329ef055069759df15cfa200c8e32e54'}",
            "last_fix_commit":"6f75bb084ab1937d094208c55cd84340040bcbb5",
            "chain_ord_pos":4.0,
            "commit_datetime":"07\/26\/2022, 21:12:22",
            "message":"[DS-4453] Discovery autocomplete HTML escaping (JSPUI)",
            "author":"Kim Shepherd",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 2, 'total': 9}",
            "files":"{'dspace-jspui\/src\/main\/webapp\/search\/discovery.jsp': {'additions': 7, 'deletions': 2, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DSpace\/DSpace\/raw\/6f75bb084ab1937d094208c55cd84340040bcbb5\/dspace-jspui%2Fsrc%2Fmain%2Fwebapp%2Fsearch%2Fdiscovery.jsp', 'patch': '@@ -141,7 +141,7 @@\\n \\t\\t\\t\\t\\t\\t\\t\\t\\ttmp_val = item.displayedValue;\\n \\t\\t\\t\\t\\t\\t\\t\\t}\\n \\t\\t\\t\\t\\t\\t\\t\\treturn {\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\tlabel: item.displayedValue + \" (\" + item.count + \")\",\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\tlabel: escapeHtml(item.displayedValue) + \" (\" + item.count + \")\",\\n \\t\\t\\t\\t\\t\\t\\t\\t\\tvalue: tmp_val\\n \\t\\t\\t\\t\\t\\t\\t\\t};\\n \\t\\t\\t\\t\\t\\t\\t}))\\t\\t\\t\\n@@ -153,7 +153,12 @@\\n \\tfunction validateFilters() {\\n \\t\\treturn document.getElementById(\"filterquery\").value.length > 0;\\n \\t}\\n-<\/script>\\t\\t\\n+\\t\/\/ Generic HTML escape utility\\n+\\tvar escapeHtml = s => (s + \\'\\').replace(\/[&<>\"\\']\/g, m => ({\\n+\\t\\t\\'&\\': \\'&amp;\\', \\'<\\': \\'&lt;\\', \\'>\\': \\'&gt;\\',\\n+\\t\\t\\'\"\\': \\'&quot;\\', \"\\'\": \\'&#39;\\'\\n+\\t})[m]);\\n+<\/script>\\n <\/c:set>\\n \\n <dspace:layout titlekey=\"jsp.search.title\">'}}",
            "message_norm":"[ds-4453] discovery autocomplete html escaping (jspui)",
            "language":"it",
            "entities":"[('escaping', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dspace-jspui\/src\/main\/webapp\/search\/discovery.jsp'])",
            "num_files":1.0
        },
        {
            "index":1149,
            "vuln_id":"GHSA-864j-6qpp-cmrr",
            "cwe_id":"{'CWE-89'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/alexreisner\/geocoder\/commit\/dcdc3d8675411edce3965941a2ca7c441ca48613'}",
            "dataset":"osv",
            "summary":"SQL Injection in Geocoder sql.rb in Geocoder before 1.6.1 allows Boolean-based SQL injection when within_bounding_box is used in conjunction with untrusted sw_lat, sw_lng, ne_lat, or ne_lng data.",
            "published_date":"2020-06-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/alexreisner\/geocoder",
            "commit_href":"https:\/\/github.com\/alexreisner\/geocoder\/commit\/dcdc3d8675411edce3965941a2ca7c441ca48613",
            "commit_sha":"dcdc3d8675411edce3965941a2ca7c441ca48613",
            "patch":"SINGLE",
            "chain_ord":"['dcdc3d8675411edce3965941a2ca7c441ca48613']",
            "before_first_fix_commit":"{'1ff64c47b6fc21d9c5ce30a6549d9eaa67c81a9e'}",
            "last_fix_commit":"dcdc3d8675411edce3965941a2ca7c441ca48613",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/23\/2020, 16:08:45",
            "message":"Sanitize lat\/lon for SQL query.",
            "author":"Alex Reisner",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'lib\/geocoder\/sql.rb': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/alexreisner\/geocoder\/raw\/dcdc3d8675411edce3965941a2ca7c441ca48613\/lib%2Fgeocoder%2Fsql.rb', 'patch': '@@ -44,13 +44,13 @@ def approx_distance(latitude, longitude, lat_attr, lon_attr, options = {})\\n     end\\n \\n     def within_bounding_box(sw_lat, sw_lng, ne_lat, ne_lng, lat_attr, lon_attr)\\n-      spans = \"#{lat_attr} BETWEEN #{sw_lat} AND #{ne_lat} AND \"\\n+      spans = \"#{lat_attr} BETWEEN #{sw_lat.to_f} AND #{ne_lat.to_f} AND \"\\n       # handle box that spans 180 longitude\\n       if sw_lng.to_f > ne_lng.to_f\\n-        spans + \"(#{lon_attr} BETWEEN #{sw_lng} AND 180 OR \" +\\n-        \"#{lon_attr} BETWEEN -180 AND #{ne_lng})\"\\n+        spans + \"(#{lon_attr} BETWEEN #{sw_lng.to_f} AND 180 OR \" +\\n+        \"#{lon_attr} BETWEEN -180 AND #{ne_lng.to_f})\"\\n       else\\n-        spans + \"#{lon_attr} BETWEEN #{sw_lng} AND #{ne_lng}\"\\n+        spans + \"#{lon_attr} BETWEEN #{sw_lng.to_f} AND #{ne_lng.to_f}\"\\n       end\\n     end'}}",
            "message_norm":"sanitize lat\/lon for sql query.",
            "language":"fr",
            "entities":"[('sanitize', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/geocoder\/sql.rb'])",
            "num_files":1.0
        },
        {
            "index":1032,
            "vuln_id":"GHSA-7ggw-h8pp-r95r",
            "cwe_id":"{'CWE-613'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/octobercms\/library\/commit\/642f597489e6f644d4bd9a0c267e864cabead024'}",
            "dataset":"osv",
            "summary":"Session ID not invalidated after logout ### Impact\nWhen logging out, the session ID was not invalidated. This is not a problem while the user is logged out, but as soon as the user logs back in the old session ID would be valid again; which means that anyone that gained access to the old session cookie would be able to act as the logged in user. This is not a major concern for the majority of cases, since it requires a malicious party gaining access to the session cookie in the first place, but nevertheless has been fixed.\n\n### Patches\nIssue has been patched in Build 472 (v1.0.472) and v1.1.2.\n\n### Workarounds\nApply https:\/\/github.com\/octobercms\/library\/commit\/642f597489e6f644d4bd9a0c267e864cabead024 to your installation manually if unable to upgrade to Build 472 or v1.1.2.\n\n### References\n- Reported by Anisio (Brazilian Information Security Analyst)\n- http:\/\/cve.circl.lu\/cve\/CVE-2021-3311\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at [hello@octobercms.com](mailto:hello@octobercms.com)\n\n### Threat assessment:\n<img width=\"699\" alt=\"Screen Shot 2021-02-07 at 11 50 35 PM\" src=\"https:\/\/user-images.githubusercontent.com\/7253840\/107180881-51eaf000-699f-11eb-8828-333128faf2a6.png\">",
            "published_date":"2021-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/octobercms\/library",
            "commit_href":"https:\/\/github.com\/octobercms\/library\/commit\/642f597489e6f644d4bd9a0c267e864cabead024",
            "commit_sha":"642f597489e6f644d4bd9a0c267e864cabead024",
            "patch":"SINGLE",
            "chain_ord":"['642f597489e6f644d4bd9a0c267e864cabead024']",
            "before_first_fix_commit":"{'e292d79ef2090f4d67a7d913d89c9d3597b0d334'}",
            "last_fix_commit":"642f597489e6f644d4bd9a0c267e864cabead024",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/30\/2021, 00:47:39",
            "message":"Invalidate the session ID to prevent reuse\n\n1. Good logs in\n2. Bad captures Good's session cookie\n3. Good logs out\n4. Session cookie no longer works\n5. Good logs in a second time\n6. ORIGINAL session cookie works (Bad is also signed in)",
            "author":"Samuel Georges",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/Auth\/Manager.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/octobercms\/library\/raw\/642f597489e6f644d4bd9a0c267e864cabead024\/src%2FAuth%2FManager.php', 'patch': '@@ -686,7 +686,7 @@ public function logout()\\n \\n         $this->user = null;\\n \\n-        Session::flush();\\n+        Session::invalidate();\\n         Cookie::queue(Cookie::forget($this->sessionKey));\\n     }'}}",
            "message_norm":"invalidate the session id to prevent reuse\n\n1. good logs in\n2. bad captures good's session cookie\n3. good logs out\n4. session cookie no longer works\n5. good logs in a second time\n6. original session cookie works (bad is also signed in)",
            "language":"en",
            "entities":"[('invalidate', 'ACTION', ''), ('prevent', 'ACTION', ''), ('cookie', 'SECWORD', ''), ('cookie', 'SECWORD', ''), ('cookie', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Auth\/Manager.php'])",
            "num_files":1.0
        },
        {
            "index":2158,
            "vuln_id":"GHSA-hx9q-2mx4-m4pg",
            "cwe_id":"{'CWE-191', 'CWE-20'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/20cb18724b0bf6c09071a3f53434c4eec53cc147', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/84563f265f28b3c36a15335c8b005d405260e943'}",
            "dataset":"osv",
            "summary":"Missing validation causes denial of service via `Conv3DBackpropFilterV2` ### Impact\nThe implementation of [`tf.raw_ops.UnsortedSegmentJoin`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f3b9bf4c3c0597563b289c0512e98d4ce81f886e\/tensorflow\/core\/kernels\/unsorted_segment_join_op.cc#L83-L148) does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack:\n\n```python\nimport tensorflow as tf\n\ntf.strings.unsorted_segment_join(\n  inputs=['123'],\n  segment_ids=[0],\n  num_segments=-1)\n```\n\nThe code assumes `num_segments` is a positive scalar but there is no validation:\n\n```cc\nconst Tensor& num_segments_tensor = context->input(2);\nauto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n\/\/ ...\nTensor* output_tensor = nullptr;\nTensorShape output_shape =\n    GetOutputShape(input_shape, segment_id_shape, num_segments);\n```\n\nSince this value is used to allocate the output tensor, a negative value would result in a `CHECK`-failure (assertion failure), as per [TFSA-2021-198](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/security\/advisory\/tfsa-2021-198.md).\n\n### Patches \nWe have patched the issue in GitHub commit [84563f265f28b3c36a15335c8b005d405260e943](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/84563f265f28b3c36a15335c8b005d405260e943) and GitHub commit [20cb18724b0bf6c09071a3f53434c4eec53cc147](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/20cb18724b0bf6c09071a3f53434c4eec53cc147).\n  \nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n      \n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n                       \n### Attribution \nThis vulnerability has been reported externally via a [GitHub issue](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/55305).",
            "published_date":"2022-05-24",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/84563f265f28b3c36a15335c8b005d405260e943",
            "commit_sha":"84563f265f28b3c36a15335c8b005d405260e943",
            "patch":"MULTI",
            "chain_ord":"['84563f265f28b3c36a15335c8b005d405260e943', '20cb18724b0bf6c09071a3f53434c4eec53cc147']",
            "before_first_fix_commit":"{'3f30e4965889b1b86b1d56392e437ccc08907f65'}",
            "last_fix_commit":"20cb18724b0bf6c09071a3f53434c4eec53cc147",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/15\/2022, 17:34:16",
            "message":"Validate `num_segments > 0` in `unsorted_segment_join`\n\nFixes #55305\n\nPiperOrigin-RevId: 442047005",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/unsorted_segment_join_op.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/84563f265f28b3c36a15335c8b005d405260e943\/tensorflow%2Fcore%2Fkernels%2Funsorted_segment_join_op.cc', 'patch': '@@ -94,6 +94,8 @@ class UnsortedSegmentJoinOp : public OpKernel {\\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\\n \\n+    OP_REQUIRES(context, num_segments > 0,\\n+                errors::InvalidArgument(\"Number of segments must be positive\"));\\n     OP_REQUIRES(context, segment_dims != 0,\\n                 errors::InvalidArgument(\"Segment_id cannot have rank 0\"));'}}",
            "message_norm":"validate `num_segments > 0` in `unsorted_segment_join`\n\nfixes #55305\n\npiperorigin-revid: 442047005",
            "language":"ca",
            "entities":"[('validate', 'ACTION', ''), ('fixes', 'ACTION', ''), ('#55305', 'ISSUE', ''), ('442047005', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/unsorted_segment_join_op.cc'])",
            "num_files":1.0
        },
        {
            "index":394,
            "vuln_id":"GHSA-49qr-xh3w-h436",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/jupyter\/notebook\/commit\/107a89fce5f413fb5728c1c5d2c7788e1fb17491'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects notebook Jupyter Notebook before 5.7.1 allows XSS via an untrusted notebook because nbconvert responses are considered to have the same origin as the notebook server. In other words, nbconvert endpoints can execute JavaScript with access to the server API. In notebook\/nbconvert\/handlers.py, NbconvertFileHandler and NbconvertPostHandler do not set a Content Security Policy to prevent this.",
            "published_date":"2018-11-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/jupyter\/notebook",
            "commit_href":"https:\/\/github.com\/jupyter\/notebook\/commit\/107a89fce5f413fb5728c1c5d2c7788e1fb17491",
            "commit_sha":"107a89fce5f413fb5728c1c5d2c7788e1fb17491",
            "patch":"SINGLE",
            "chain_ord":"['107a89fce5f413fb5728c1c5d2c7788e1fb17491']",
            "before_first_fix_commit":"{'04a686dbaf9dfe553324a03cb9e6f778cf1e3da1'}",
            "last_fix_commit":"107a89fce5f413fb5728c1c5d2c7788e1fb17491",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/22\/2018, 13:52:36",
            "message":"Apply CSP sandboxing for nbconvert responses\n\nThese may contain untrusted content, so they should be treated as being\nfrom a different domain to the notebook server.",
            "author":"Thomas Kluyver",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 0, 'total': 14}",
            "files":"{'notebook\/nbconvert\/handlers.py': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jupyter\/notebook\/raw\/107a89fce5f413fb5728c1c5d2c7788e1fb17491\/notebook%2Fnbconvert%2Fhandlers.py', 'patch': '@@ -78,6 +78,13 @@ class NbconvertFileHandler(IPythonHandler):\\n \\n     SUPPORTED_METHODS = (\\'GET\\',)\\n \\n+    @property\\n+    def content_security_policy(self):\\n+        # In case we\\'re serving HTML\/SVG, confine any Javascript to a unique\\n+        # origin so it can\\'t interact with the notebook server.\\n+        return super(NbconvertFileHandler, self).content_security_policy + \\\\\\n+               \"; sandbox allow-scripts\"\\n+\\n     @web.authenticated\\n     def get(self, format, path):\\n \\n@@ -145,6 +152,13 @@ def get(self, format, path):\\n class NbconvertPostHandler(IPythonHandler):\\n     SUPPORTED_METHODS = (\\'POST\\',)\\n \\n+    @property\\n+    def content_security_policy(self):\\n+        # In case we\\'re serving HTML\/SVG, confine any Javascript to a unique\\n+        # origin so it can\\'t interact with the notebook server.\\n+        return super(NbconvertPostHandler, self).content_security_policy + \\\\\\n+               \"; sandbox allow-scripts\"\\n+\\n     @web.authenticated\\n     def post(self, format):\\n         exporter = get_exporter(format, config=self.config)'}}",
            "message_norm":"apply csp sandboxing for nbconvert responses\n\nthese may contain untrusted content, so they should be treated as being\nfrom a different domain to the notebook server.",
            "language":"en",
            "entities":"[('untrusted', 'SECWORD', ''), ('server', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['notebook\/nbconvert\/handlers.py'])",
            "num_files":1.0
        },
        {
            "index":3452,
            "vuln_id":"GHSA-xjrf-8x4f-43h4",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/spring-projects\/spring-framework\/commit\/9982b4c01a8c7be0961e58b58ed83731c40449ff', 'https:\/\/github.com\/spring-projects\/spring-framework\/commit\/7a7df6637478607bef0277bf52a4e0a03e20a248', 'https:\/\/github.com\/spring-projects\/spring-framework\/commit\/f5c9fe69a444607af667911bd4c5074b5b073e7b'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Input During Web Page Generation in Spring Framework The JavaScriptUtils.javaScriptEscape method in web\/util\/JavaScriptUtils.java in Spring MVC in Spring Framework before 3.2.2 does not properly escape certain characters, which allows remote attackers to conduct cross-site scripting (XSS) attacks via a (1) line separator or (2) paragraph separator Unicode character or (3) left or (4) right angle bracket.",
            "published_date":"2022-05-05",
            "chain_len":3,
            "project":"https:\/\/github.com\/spring-projects\/spring-framework",
            "commit_href":"https:\/\/github.com\/spring-projects\/spring-framework\/commit\/9982b4c01a8c7be0961e58b58ed83731c40449ff",
            "commit_sha":"9982b4c01a8c7be0961e58b58ed83731c40449ff",
            "patch":"MULTI",
            "chain_ord":"['9982b4c01a8c7be0961e58b58ed83731c40449ff', 'f5c9fe69a444607af667911bd4c5074b5b073e7b', '7a7df6637478607bef0277bf52a4e0a03e20a248']",
            "before_first_fix_commit":"{'63bff1f068f0c749f938abacba1d38b7d0ca3cf9'}",
            "last_fix_commit":"7a7df6637478607bef0277bf52a4e0a03e20a248",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/23\/2013, 18:35:14",
            "message":"Add BS and VT char escape sequences to JavaScriptUtils\n\nIssue: SPR-9983",
            "author":"Rossen Stoyanchev",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 7, 'total': 21}",
            "files":"{'spring-web\/src\/main\/java\/org\/springframework\/web\/util\/JavaScriptUtils.java': {'additions': 14, 'deletions': 7, 'changes': 21, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/spring-projects\/spring-framework\/raw\/9982b4c01a8c7be0961e58b58ed83731c40449ff\/spring-web%2Fsrc%2Fmain%2Fjava%2Forg%2Fspringframework%2Fweb%2Futil%2FJavaScriptUtils.java', 'patch': '@@ -1,5 +1,5 @@\\n \/*\\n- * Copyright 2002-2008 the original author or authors.\\n+ * Copyright 2002-2013 the original author or authors.\\n  *\\n  * Licensed under the Apache License, Version 2.0 (the \"License\");\\n  * you may not use this file except in compliance with the License.\\n@@ -21,21 +21,21 @@\\n  * Escapes based on the JavaScript 1.5 recommendation.\\n  *\\n  * <p>Reference:\\n- * <a href=\"http:\/\/developer.mozilla.org\/en\/docs\/Core_JavaScript_1.5_Guide:Literals#String_Literals\">\\n- * Core JavaScript 1.5 Guide\\n- * <\/a>\\n+ * <a href=\"https:\/\/developer.mozilla.org\/en-US\/docs\/JavaScript\/Guide\/Values,_variables,_and_literals#String_literals\">\\n+ * JavaScript Guide<\/a> on Mozilla Developer Network.\\n  *\\n  * @author Juergen Hoeller\\n  * @author Rob Harrop\\n+ * @author Rossen Stoyanchev\\n  * @since 1.1.1\\n  *\/\\n public class JavaScriptUtils {\\n \\n \\t\/**\\n-\\t * Turn special characters into escaped characters conforming to JavaScript.\\n-\\t * Handles complete character set defined in HTML 4.01 recommendation.\\n+\\t * Turn JavaScript special characters into escaped characters.\\n+\\t *\\n \\t * @param input the input string\\n-\\t * @return the escaped string\\n+\\t * @return the string with escaped characters\\n \\t *\/\\n \\tpublic static String javaScriptEscape(String input) {\\n \\t\\tif (input == null) {\\n@@ -73,6 +73,13 @@ else if (c == \\'\\\\r\\') {\\n \\t\\t\\telse if (c == \\'\\\\f\\') {\\n \\t\\t\\t\\tfiltered.append(\"\\\\\\\\f\");\\n \\t\\t\\t}\\n+\\t\\t\\telse if (c == \\'\\\\b\\') {\\n+\\t\\t\\t\\tfiltered.append(\"\\\\\\\\b\");\\n+\\t\\t\\t}\\n+\\t\\t\\t\/\/ No \\'\\\\v\\' in Java, use octal value for VT ascii char\\n+\\t\\t\\telse if (c == \\'\\\\013\\') {\\n+\\t\\t\\t\\tfiltered.append(\"\\\\\\\\v\");\\n+\\t\\t\\t}\\n \\t\\t\\telse {\\n \\t\\t\\t\\tfiltered.append(c);\\n \\t\\t\\t}'}}",
            "message_norm":"add bs and vt char escape sequences to javascriptutils\n\nissue: spr-9983",
            "language":"ca",
            "entities":"[('add', 'ACTION', ''), ('escape', 'SECWORD', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['spring-web\/src\/main\/java\/org\/springframework\/web\/util\/JavaScriptUtils.java'])",
            "num_files":1.0
        },
        {
            "index":2144,
            "vuln_id":"GHSA-hwj3-m3p6-hj38",
            "cwe_id":"{'CWE-611'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/dom4j\/dom4j\/commit\/1707bf3d898a8ada3b213acb0e3b38f16eaae73d', 'https:\/\/github.com\/dom4j\/dom4j\/commit\/a8228522a99a02146106672a34c104adbda5c658'}",
            "dataset":"osv",
            "summary":"dom4j allows External Entities by default which might enable XXE attacks dom4j before 2.1.3 allows external DTDs and External Entities by default, which might enable XXE attacks. However, there is popular external documentation from OWASP showing how to enable the safe, non-default behavior in any application that uses dom4j.\n\nNote: This advisory applies to `dom4j:dom4j` version 1.x legacy artifacts.  To resolve this a change to the latest version of `org.dom4j:dom4j` is recommended.",
            "published_date":"2020-06-05",
            "chain_len":2,
            "project":"https:\/\/github.com\/dom4j\/dom4j",
            "commit_href":"https:\/\/github.com\/dom4j\/dom4j\/commit\/1707bf3d898a8ada3b213acb0e3b38f16eaae73d",
            "commit_sha":"1707bf3d898a8ada3b213acb0e3b38f16eaae73d",
            "patch":"MULTI",
            "chain_ord":"['a8228522a99a02146106672a34c104adbda5c658', '1707bf3d898a8ada3b213acb0e3b38f16eaae73d']",
            "before_first_fix_commit":"{'223ae0639d5d73a5a25fddec8b16c7071ee10e3d'}",
            "last_fix_commit":"1707bf3d898a8ada3b213acb0e3b38f16eaae73d",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/11\/2020, 17:27:36",
            "message":"#28 Disable downloading external resources with DocumentHelper.parseText() helper.\n\n(cherry picked from commit 8f6a7f6001d679176c1079ac65871d4e493360db)",
            "author":"Filip Jirs\u00e1k",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'src\/main\/java\/org\/dom4j\/DocumentHelper.java': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/dom4j\/dom4j\/raw\/1707bf3d898a8ada3b213acb0e3b38f16eaae73d\/src%2Fmain%2Fjava%2Forg%2Fdom4j%2FDocumentHelper.java', 'patch': '@@ -270,6 +270,14 @@ public static void sort(List<Node> list, String expression, boolean distinct) {\\n      *\/\\n     public static Document parseText(String text) throws DocumentException {\\n         SAXReader reader = new SAXReader();\\n+        try {\\n+            reader.setFeature(\"http:\/\/apache.org\/xml\/features\/nonvalidating\/load-external-dtd\", false);\\n+            reader.setFeature(\"http:\/\/xml.org\/sax\/features\/external-general-entities\", false);\\n+            reader.setFeature(\"http:\/\/xml.org\/sax\/features\/external-parameter-entities\", false);\\n+        } catch (SAXException e) {\\n+            \/\/Parse with external resources downloading allowed.\\n+        }\\n+\\n         String encoding = getEncoding(text);\\n \\n         InputSource source = new InputSource(new StringReader(text));'}}",
            "message_norm":"#28 disable downloading external resources with documenthelper.parsetext() helper.\n\n(cherry picked from commit 8f6a7f6001d679176c1079ac65871d4e493360db)",
            "language":"en",
            "entities":"[('#28', 'ISSUE', ''), ('commit 8f6a7f6001d679176c1079ac65871d4e493360db', 'SHA', 'prefix_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/org\/dom4j\/DocumentHelper.java'])",
            "num_files":1.0
        },
        {
            "index":1144,
            "vuln_id":"GHSA-85wq-pqhp-hmq6",
            "cwe_id":"{'CWE-352'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/3c5e5ca63d9a1ac1c4087682dc0d426625eafed8', 'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/e69c28e44dae41322112471e1c80f840bde314d4', 'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/23f4809e6c10a221e9d67f2e841536845387b42d'}",
            "dataset":"osv",
            "summary":"Cross-Site Request Forgery in Jenkins Jenkins versions 2.56 and earlier as well as 2.46.1 LTS and earlier are vulnerable to an issue in the Jenkins user database authentication realm: create an account if signup is enabled; or create an account if the victim is an administrator, possibly deleting the existing default admin user in the process and allowing a wide variety of impacts.",
            "published_date":"2022-05-14",
            "chain_len":3,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/23f4809e6c10a221e9d67f2e841536845387b42d",
            "commit_sha":"23f4809e6c10a221e9d67f2e841536845387b42d",
            "patch":"MULTI",
            "chain_ord":"['3c5e5ca63d9a1ac1c4087682dc0d426625eafed8', 'e69c28e44dae41322112471e1c80f840bde314d4', '23f4809e6c10a221e9d67f2e841536845387b42d']",
            "before_first_fix_commit":"{'eeb699ed8c2ce937f2b836692b36a98da7bb5622'}",
            "last_fix_commit":"23f4809e6c10a221e9d67f2e841536845387b42d",
            "chain_ord_pos":3.0,
            "commit_datetime":"04\/13\/2017, 13:01:32",
            "message":"[SECURITY-412] Simplify implementation as suggested by jglick",
            "author":"Daniel Beck",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 16, 'total': 20}",
            "files":"{'core\/src\/main\/java\/jenkins\/model\/Jenkins.java': {'additions': 4, 'deletions': 16, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/23f4809e6c10a221e9d67f2e841536845387b42d\/core%2Fsrc%2Fmain%2Fjava%2Fjenkins%2Fmodel%2FJenkins.java', 'patch': '@@ -3369,53 +3369,41 @@ public DirectoryBrowserSupport doUserContent() {\\n      *\\n      * This first replaces \"app\" to {@link HudsonIsRestarting}\\n      *\/\\n+    @CLIMethod(name=\"restart\")\\n     public void doRestart(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException, RestartNotSupportedException {\\n         checkPermission(ADMINISTER);\\n         if (req != null && req.getMethod().equals(\"GET\")) {\\n             req.getView(this,\"_restart.jelly\").forward(req,rsp);\\n             return;\\n         }\\n \\n-        if (req != null && req.getMethod().equals(\"POST\")) {\\n+        if (req == null || req.getMethod().equals(\"POST\")) {\\n             restart();\\n         }\\n \\n         rsp.sendRedirect2(\".\");\\n     }\\n \\n-    @CLIMethod(name=\"restart\")\\n-    @Restricted(NoExternalUse.class)\\n-    public void cliRestart() throws RestartNotSupportedException {\\n-        checkPermission(ADMINISTER);\\n-        restart();\\n-    }\\n-\\n     \/**\\n      * Queues up a restart of Jenkins for when there are no builds running, if we can.\\n      *\\n      * This first replaces \"app\" to {@link HudsonIsRestarting}\\n      *\\n      * @since 1.332\\n      *\/\\n+    @CLIMethod(name=\"safe-restart\")\\n     public HttpResponse doSafeRestart(StaplerRequest req) throws IOException, ServletException, RestartNotSupportedException {\\n         checkPermission(ADMINISTER);\\n         if (req != null && req.getMethod().equals(\"GET\"))\\n             return HttpResponses.forwardToView(this,\"_safeRestart.jelly\");\\n \\n-        if (req != null && req.getMethod().equals(\"POST\")) {\\n+        if (req == null || req.getMethod().equals(\"POST\")) {\\n             safeRestart();\\n         }\\n \\n         return HttpResponses.redirectToDot();\\n     }\\n \\n-    @CLIMethod(name=\"safe-restart\")\\n-    @Restricted(NoExternalUse.class)\\n-    public void cliSafeRestart() throws RestartNotSupportedException {\\n-        checkPermission(ADMINISTER);\\n-        safeRestart();\\n-    }\\n-\\n     \/**\\n      * Performs a restart.\\n      *\/'}}",
            "message_norm":"[security-412] simplify implementation as suggested by jglick",
            "language":"en",
            "entities":"[('security-412', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/src\/main\/java\/jenkins\/model\/Jenkins.java'])",
            "num_files":1.0
        },
        {
            "index":2669,
            "vuln_id":"GHSA-pxcf-v868-m492",
            "cwe_id":"{'CWE-74', 'CWE-79'}",
            "score":7.6,
            "chain":"{'https:\/\/github.com\/jperelli\/osm-static-maps\/commit\/97355d29e08753d1cfe99b1281dbaa06f4e651b0'}",
            "dataset":"osv",
            "summary":"Injection and Cross-site Scripting in osm-static-maps This affects all versions of package osm-static-maps under 3.9.0. User input given to the package is passed directly to a template without escaping ({{{ ... }}}). As such, it is possible for an attacker to inject arbitrary HTML\/JS code and depending on the context. It will be outputted as an HTML on the page which gives opportunity for XSS or rendered on the server (puppeteer) which also gives opportunity for SSRF and Local File Read.",
            "published_date":"2021-05-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/jperelli\/osm-static-maps",
            "commit_href":"https:\/\/github.com\/jperelli\/osm-static-maps\/commit\/97355d29e08753d1cfe99b1281dbaa06f4e651b0",
            "commit_sha":"97355d29e08753d1cfe99b1281dbaa06f4e651b0",
            "patch":"SINGLE",
            "chain_ord":"['97355d29e08753d1cfe99b1281dbaa06f4e651b0']",
            "before_first_fix_commit":"{'6bce2e2a8dd4cbbbbe083820e494ba858be74b16'}",
            "last_fix_commit":"97355d29e08753d1cfe99b1281dbaa06f4e651b0",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/11\/2020, 23:25:42",
            "message":"fix: escape special characters before insertion to template",
            "author":"snoopysecurity",
            "comments":null,
            "stats":"{'additions': 25, 'deletions': 6, 'total': 31}",
            "files":"{'src\/server.js': {'additions': 25, 'deletions': 6, 'changes': 31, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jperelli\/osm-static-maps\/raw\/97355d29e08753d1cfe99b1281dbaa06f4e651b0\/src%2Fserver.js', 'patch': '@@ -19,6 +19,23 @@ app.use((req, res, next) => {\\n   next();\\n });\\n \\n+\\n+function htmlEscape(text) {\\n+  return text.replace(\/&\/g, \\'&amp;\\').\\n+  replace(\/<\/g, \\'&lt;\\').\\n+  replace(\/\"\/g, \\'&quot;\\').\\n+  replace(\/\\'\/g, \\'&#039;\\');\\n+}\\n+\\n+\\n+function sanitize(params) {\\n+  result = {}\\n+  for (let [key, value] of Object.entries(params)) {\\n+      result[key] = htmlEscape(value)\\n+  }\\n+  return result;\\n+}\\n+\\n app.get(\"\/health\", (req, res) => res.sendStatus(200));\\n \\n const handler = (res, params) => {\\n@@ -40,12 +57,14 @@ const handler = (res, params) => {\\n app.get(\"\/\", (req, res) => handler(res, req.query));\\n app.post(\"\/\", (req, res) => handler(res, req.body));\\n \\n-app.get(\"\/dynamic\", (req, res) =>\\n-  handler(res, { ...req.query, renderToHtml: true })\\n-);\\n+app.get(\"\/dynamic\", (req, res) => {\\n+  var sanitized = sanitize(req.query)\\n+  handler(res, { ...sanitized, renderToHtml: true })\\n+})\\n \\n-app.post(\"\/dynamic\", (req, res) =>\\n-  handler(res, { ...req.body, renderToHtml: true })\\n-);\\n+app.post(\"\/dynamic\", (req, res) => {\\n+  var sanitized = sanitize(req.body)\\n+  handler(res, { ...sanitized, renderToHtml: true })\\n+})\\n \\n module.exports = http.createServer(app);'}}",
            "message_norm":"fix: escape special characters before insertion to template",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/server.js'])",
            "num_files":1.0
        },
        {
            "index":1233,
            "vuln_id":"GHSA-8p36-q63g-68qh",
            "cwe_id":"{'CWE-915'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/mitreid-connect\/OpenID-Connect-Java-Spring-Server\/commit\/7eba3c12fed82388f917e8dd9b73e86e3a311e4c'}",
            "dataset":"osv",
            "summary":"Autobinding vulnerability in MITREid Connect org\/mitre\/oauth2\/web\/OAuthConfirmationController.java in the OpenID Connect server implementation for MITREid Connect through 1.3.3 contains a Mass Assignment (aka Autobinding) vulnerability. This arises due to unsafe usage of the @ModelAttribute annotation during the OAuth authorization flow, in which HTTP request parameters affect an authorizationRequest.",
            "published_date":"2021-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/mitreid-connect\/OpenID-Connect-Java-Spring-Server",
            "commit_href":"https:\/\/github.com\/mitreid-connect\/OpenID-Connect-Java-Spring-Server\/commit\/7eba3c12fed82388f917e8dd9b73e86e3a311e4c",
            "commit_sha":"7eba3c12fed82388f917e8dd9b73e86e3a311e4c",
            "patch":"SINGLE",
            "chain_ord":"['7eba3c12fed82388f917e8dd9b73e86e3a311e4c']",
            "before_first_fix_commit":"{'0d4ef2cb4f77bea5df9e2d4f1cfff4dffb7045c0'}",
            "last_fix_commit":"7eba3c12fed82388f917e8dd9b73e86e3a311e4c",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/12\/2021, 15:22:12",
            "message":"Fix Spring Autobinding vulnerability\n\n1. Make authorizationRequest no longer affected by http request parameters due to @ModelAttribute. See http:\/\/agrrrdog.blogspot.com\/2017\/03\/autobinding-vulns-and-spring-mvc.html",
            "author":"Michael Stepankin",
            "comments":"{'com_1': {'author': 'abergmann', 'datetime': '02\/24\/2021, 07:32:35', 'body': '[CVE-2021-27582](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-27582) was assigned to this commit.'}}",
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'openid-connect-server\/src\/main\/java\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mitreid-connect\/OpenID-Connect-Java-Spring-Server\/raw\/7eba3c12fed82388f917e8dd9b73e86e3a311e4c\/openid-connect-server%2Fsrc%2Fmain%2Fjava%2Forg%2Fmitre%2Foauth2%2Fweb%2FOAuthConfirmationController.java', 'patch': '@@ -103,9 +103,9 @@ public OAuthConfirmationController(ClientDetailsEntityService clientService) {\\n \\n \\t@PreAuthorize(\"hasRole(\\'ROLE_USER\\')\")\\n \\t@RequestMapping(\"\/oauth\/confirm_access\")\\n-\\tpublic String confimAccess(Map<String, Object> model, @ModelAttribute(\"authorizationRequest\") AuthorizationRequest authRequest,\\n-\\t\\t\\tPrincipal p) {\\n+\\tpublic String confirmAccess(Map<String, Object> model, Principal p) {\\n \\n+\\t\\tAuthorizationRequest authRequest = (AuthorizationRequest) model.get(\"authorizationRequest\");\\n \\t\\t\/\/ Check the \"prompt\" parameter to see if we need to do special processing\\n \\n \\t\\tString prompt = (String)authRequest.getExtensions().get(PROMPT);'}}",
            "message_norm":"fix spring autobinding vulnerability\n\n1. make authorizationrequest no longer affected by http request parameters due to @modelattribute. see http:\/\/agrrrdog.blogspot.com\/2017\/03\/autobinding-vulns-and-spring-mvc.html",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('http:\/\/agrrrdog.blogspot.com\/2017\/03\/autobinding-vulns-and-spring-mvc.html', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['openid-connect-server\/src\/main\/java\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java'])",
            "num_files":1.0
        },
        {
            "index":1473,
            "vuln_id":"GHSA-c45w-2wxr-pp53",
            "cwe_id":"{'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b'}",
            "dataset":"osv",
            "summary":"Heap OOB read in `tf.raw_ops.Dequantize` ### Impact\nDue to lack of validation in `tf.raw_ops.Dequantize`, an attacker can trigger a read from outside of bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\ninput_tensor=tf.constant(\n  [75, 75, 75, 75, -6, -9, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10], shape=[5, 10], dtype=tf.int32)\ninput_tensor=tf.cast(input_tensor, dtype=tf.quint8)\nmin_range = tf.constant([-10], shape=[1], dtype=tf.float32)\nmax_range = tf.constant([24, 758, 758, 758, 758], shape=[5], dtype=tf.float32)\n  \ntf.raw_ops.Dequantize( \n  input=input_tensor, min_range=min_range, max_range=max_range, mode='SCALED',\n  narrow_range=True, axis=0, dtype=tf.dtypes.float32)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/26003593aa94b1742f34dc22ce88a1e17776a67d\/tensorflow\/core\/kernels\/dequantize_op.cc#L106-L131) accesses the `min_range` and `max_range` tensors in parallel but fails to check that they have the same shape:\n\n```cc\nif (num_slices == 1) {\n  const float min_range = input_min_tensor.flat<float>()(0);\n  const float max_range = input_max_tensor.flat<float>()(0);\n  DequantizeTensor(ctx, input, min_range, max_range, &float_output);\n} else {\n  ...\n  auto min_ranges = input_min_tensor.vec<float>();\n  auto max_ranges = input_max_tensor.vec<float>();\n  for (int i = 0; i < num_slices; ++i) {\n    DequantizeSlice(ctx->eigen_device<Device>(), ctx,\n                    input_tensor.template chip<1>(i), min_ranges(i),\n                    max_ranges(i), output_tensor.template chip<1>(i));\n    ...\n  }\n}\n```\n\n### Patches\nWe have patched the issue in GitHub commit [5899741d0421391ca878da47907b1452f06aaf1b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b",
            "commit_sha":"5899741d0421391ca878da47907b1452f06aaf1b",
            "patch":"SINGLE",
            "chain_ord":"['5899741d0421391ca878da47907b1452f06aaf1b']",
            "before_first_fix_commit":"{'26003593aa94b1742f34dc22ce88a1e17776a67d'}",
            "last_fix_commit":"5899741d0421391ca878da47907b1452f06aaf1b",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 22:31:05",
            "message":"Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'tensorflow\/core\/kernels\/dequantize_op.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/5899741d0421391ca878da47907b1452f06aaf1b\/tensorflow%2Fcore%2Fkernels%2Fdequantize_op.cc', 'patch': '@@ -98,6 +98,18 @@ class DequantizeOp : public OpKernel {\\n     if (axis_ > -1) {\\n       num_slices = input.dim_size(axis_);\\n     }\\n+    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\\n+                errors::InvalidArgument(\\n+                    \"input_min_tensor must have as many elements as input on \"\\n+                    \"the dequantization axis (\",\\n+                    axis_, \"), got \", input_min_tensor.NumElements(),\\n+                    \", expected \", num_slices));\\n+    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,\\n+                errors::InvalidArgument(\\n+                    \"input_max_tensor must have as many elements as input on \"\\n+                    \"the dequantization axis (\",\\n+                    axis_, \"), got \", input_max_tensor.NumElements(),\\n+                    \", expected \", num_slices));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));'}}",
            "message_norm":"fix heap oob read in dequantize op.\n\nalso fixes segv in same op\n\npiperorigin-revid: 372437896\nchange-id: i135e94d360c2a1ce374c10f7e0fed1af603dbc02",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('372437896', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/dequantize_op.cc'])",
            "num_files":1.0
        },
        {
            "index":2004,
            "vuln_id":"GHSA-h6jh-7gv5-28vg",
            "cwe_id":"{'CWE-681'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c283e542a3f422420cfdb332414543b62fc4e4a5'}",
            "dataset":"osv",
            "summary":"Bad alloc in `StringNGrams` caused by integer conversion ### Impact\nThe implementation of `tf.raw_ops.StringNGrams` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.StringNGrams(\n  data=['',''],\n  data_splits=[0,2],\n  separator=' '*100,\n  ngram_widths=[-80,0,0,-60],\n  left_pad=' ',\n  right_pad=' ',\n  pad_width=100,\n  preserve_short_sequences=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/string_ngrams_op.cc#L184) calls `reserve` on a `tstring` with a value that sometimes can be negative if user supplies negative `ngram_widths`. The `reserve` method calls `TF_TString_Reserve` which has an `unsigned long` argument for the size of the buffer. Hence, the implicit conversion transforms the negative value to a large integer.\n\n### Patches\nWe have patched the issue in GitHub commit [c283e542a3f422420cfdb332414543b62fc4e4a5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c283e542a3f422420cfdb332414543b62fc4e4a5).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c283e542a3f422420cfdb332414543b62fc4e4a5",
            "commit_sha":"c283e542a3f422420cfdb332414543b62fc4e4a5",
            "patch":"SINGLE",
            "chain_ord":"['c283e542a3f422420cfdb332414543b62fc4e4a5']",
            "before_first_fix_commit":"{'9659aea5b5e9de3b417413f69e58dab7a2907912'}",
            "last_fix_commit":"c283e542a3f422420cfdb332414543b62fc4e4a5",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 17:55:35",
            "message":"Disallow negative ngram_widths values in tf.raw_ops.StringNGrams\n\nPiperOrigin-RevId: 387148179\nChange-Id: I641395a09a208be72ef9b3ceb128cf8a83a0775b",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/string_ngrams_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c283e542a3f422420cfdb332414543b62fc4e4a5\/tensorflow%2Fcore%2Fkernels%2Fstring_ngrams_op.cc', 'patch': '@@ -53,6 +53,12 @@ class StringNGramsOp : public tensorflow::OpKernel {\\n   }\\n \\n   void Compute(tensorflow::OpKernelContext* context) override {\\n+    for (int ngram_width : ngram_widths_) {\\n+      OP_REQUIRES(\\n+          context, ngram_width > 0,\\n+          errors::InvalidArgument(\"ngram_widths must contain positive values\"));\\n+    }\\n+\\n     const tensorflow::Tensor* data;\\n     OP_REQUIRES_OK(context, context->input(\"data\", &data));\\n     const auto& input_data = data->flat<tstring>().data();'}}",
            "message_norm":"disallow negative ngram_widths values in tf.raw_ops.stringngrams\n\npiperorigin-revid: 387148179\nchange-id: i641395a09a208be72ef9b3ceb128cf8a83a0775b",
            "language":"en",
            "entities":"[('387148179', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/string_ngrams_op.cc'])",
            "num_files":1.0
        },
        {
            "index":360,
            "vuln_id":"GHSA-452g-f7fp-9jf7",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/030af767d357d1b4088c4a25c72cb3906abac489'}",
            "dataset":"osv",
            "summary":"Type confusion during tensor casts lead to dereferencing null pointers ### Impact\nCalling TF operations with tensors of non-numeric types when the operations expect numeric tensors result in null pointer dereferences.\n\nThere are multiple ways to reproduce this, listing a few examples here:\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata = tf.random.truncated_normal(shape=1,mean=np.float32(20.8739),stddev=779.973,dtype=20,seed=64)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata =\ntf.random.stateless_truncated_normal(shape=1,seed=[63,70],mean=np.float32(20.8739),stddev=779.973,dtype=20)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata = tf.one_hot(indices=[62,50],depth=136,on_value=np.int32(237),off_value=158,axis=856,dtype=20)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata = tf.range(start=np.int32(214),limit=660,delta=129,dtype=20)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata = tf.raw_ops.ResourceCountUpTo(resource=np.int32(30), limit=872, T=3)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nwriter_array = np.array([1,2],dtype=np.int32)\nwriter_tensor = tf.convert_to_tensor(writer_array,dtype=tf.resource)\n```\n\nAll these examples and similar ones have the same behavior: the [conversion from Python array to C++ array](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ff70c47a396ef1e3cb73c90513da4f5cb71bebba\/tensorflow\/python\/lib\/core\/ndarray_tensor.cc#L113-L169) is vulnerable to a type confusion:\n\n```cc\n  int pyarray_type = PyArray_TYPE(array);\n  PyArray_Descr* descr = PyArray_DESCR(array);\n  switch (pyarray_type) {\n    ...\n    case NPY_VOID:\n      \/\/ Quantized types are currently represented as custom struct types.\n      \/\/ PyArray_TYPE returns NPY_VOID for structs, and we should look into\n      \/\/ descr to derive the actual type.\n      \/\/ Direct feeds of certain types of ResourceHandles are represented as a\n      \/\/ custom struct type.\n      return PyArrayDescr_to_TF_DataType(descr, out_tf_datatype);\n    ...\n  }\n```\n\nFor the tensor types involved in the above example, the `pyarray_type` is `NPY_VOID` but the `descr` field is such that `descr->field = NULL`. Then [`PyArrayDescr_to_TF_DataType`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ff70c47a396ef1e3cb73c90513da4f5cb71bebba\/tensorflow\/python\/lib\/core\/ndarray_tensor.cc#L72-L77) will trigger a null dereference:\n\n```cc\nStatus PyArrayDescr_to_TF_DataType(PyArray_Descr* descr,\n                                   TF_DataType* out_tf_datatype) {\n  PyObject* key;\n  PyObject* value;\n  Py_ssize_t pos = 0;\n  if (PyDict_Next(descr->fields, &pos, &key, &value)) {\n    ...\n  }\n}\n```\n\nThis is because the Python's `PyDict_Next` implementation would dereference the first argument.\n\n### Patches\nWe have patched the issue in GitHub commit [030af767d357d1b4088c4a25c72cb3906abac489](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/030af767d357d1b4088c4a25c72cb3906abac489).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360 as well as Ye Zhang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/030af767d357d1b4088c4a25c72cb3906abac489",
            "commit_sha":"030af767d357d1b4088c4a25c72cb3906abac489",
            "patch":"SINGLE",
            "chain_ord":"['030af767d357d1b4088c4a25c72cb3906abac489']",
            "before_first_fix_commit":"{'ff70c47a396ef1e3cb73c90513da4f5cb71bebba'}",
            "last_fix_commit":"030af767d357d1b4088c4a25c72cb3906abac489",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2021, 21:25:01",
            "message":"Fix `tf.raw_ops.ResourceCountUpTo` null pointer dereference.\n\nPiperOrigin-RevId: 368294347\nChange-Id: I2c16fbfc9b4966c402c3d8e311f0d665a9c852d8",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'tensorflow\/python\/lib\/core\/ndarray_tensor.cc': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/030af767d357d1b4088c4a25c72cb3906abac489\/tensorflow%2Fpython%2Flib%2Fcore%2Fndarray_tensor.cc', 'patch': '@@ -16,6 +16,7 @@ limitations under the License.\\n #include \"tensorflow\/python\/lib\/core\/ndarray_tensor.h\"\\n \\n #include <cstring>\\n+#include <optional>\\n \\n #include \"tensorflow\/c\/eager\/tfe_context_internal.h\"\\n #include \"tensorflow\/c\/tf_tensor_internal.h\"\\n@@ -74,6 +75,13 @@ Status PyArrayDescr_to_TF_DataType(PyArray_Descr* descr,\\n   PyObject* key;\\n   PyObject* value;\\n   Py_ssize_t pos = 0;\\n+\\n+  \/\/ Return an error if the fields attribute is null.\\n+  \/\/ Occurs with an improper conversion attempt to resource.\\n+  if (descr->fields == nullptr) {\\n+    return errors::Internal(\"Unexpected numpy data type\");\\n+  }\\n+\\n   if (PyDict_Next(descr->fields, &pos, &key, &value)) {\\n     \/\/ In Python 3, the keys of numpy custom struct types are unicode, unlike\\n     \/\/ Python 2, where the keys are bytes.'}}",
            "message_norm":"fix `tf.raw_ops.resourcecountupto` null pointer dereference.\n\npiperorigin-revid: 368294347\nchange-id: i2c16fbfc9b4966c402c3d8e311f0d665a9c852d8",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('null pointer dereference', 'SECWORD', ''), ('368294347', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/python\/lib\/core\/ndarray_tensor.cc'])",
            "num_files":1.0
        },
        {
            "index":716,
            "vuln_id":"GHSA-5x33-h32w-6vr2",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/moodle\/moodle\/commit\/e8632a4ad0b4da3763cbbe5949594aa449b483bb'}",
            "dataset":"osv",
            "summary":"Cross site-scripting (XSS) moodle The filter in the tag manager required extra sanitizing to prevent a reflected XSS risk. This affects 3.9 to 3.9.1, 3.8 to 3.8.4, 3.7 to 3.7.7, 3.5 to 3.5.13 and earlier unsupported versions. Fixed in 3.9.2, 3.8.5, 3.7.8 and 3.5.14.",
            "published_date":"2021-03-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/moodle\/moodle",
            "commit_href":"https:\/\/github.com\/moodle\/moodle\/commit\/e8632a4ad0b4da3763cbbe5949594aa449b483bb",
            "commit_sha":"e8632a4ad0b4da3763cbbe5949594aa449b483bb",
            "patch":"SINGLE",
            "chain_ord":"['e8632a4ad0b4da3763cbbe5949594aa449b483bb']",
            "before_first_fix_commit":"{'630078eb4a189a17378ea6cf19be989da2114c1c'}",
            "last_fix_commit":"e8632a4ad0b4da3763cbbe5949594aa449b483bb",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/04\/2020, 10:04:27",
            "message":"MDL-69340 tag: Correct the filter input HTML in the tag manager",
            "author":"Michael Hawkins",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'tag\/manage.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/moodle\/moodle\/raw\/e8632a4ad0b4da3763cbbe5949594aa449b483bb\/tag%2Fmanage.php', 'patch': '@@ -211,7 +211,7 @@\\n print(\\'<div class=\"tag-management-form generalbox\"><label class=\"accesshide\" for=\"id_tagfilter\">\\'. get_string(\\'search\\') .\\'<\/label>\\'.\\n     \\'<input type=\"hidden\" name=\"tc\" value=\"\\'.$tagcollid.\\'\" \/>\\'.\\n     \\'<input type=\"hidden\" name=\"perpage\" value=\"\\'.$perpage.\\'\" \/>\\'.\\n-    \\'<input id=\"id_tagfilter\" name=\"filter\" type=\"text\" value=\\' . s($filter) . \\'>\\'.\\n+    \\'<input id=\"id_tagfilter\" name=\"filter\" type=\"text\" value=\"\\' . s($filter) . \\'\">\\'.\\n     \\'<input value=\"\\'. s(get_string(\\'search\\')) .\\'\" type=\"submit\" class=\"btn btn-secondary\"> \\'.\\n     ($filter !== \\'\\' ? html_writer::link(new moodle_url($PAGE->url, array(\\'filter\\' => null)),\\n         get_string(\\'resetfilter\\', \\'tag\\'), array(\\'class\\' => \\'resetfilterlink\\')) : \\'\\').'}}",
            "message_norm":"mdl-69340 tag: correct the filter input html in the tag manager",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tag\/manage.php'])",
            "num_files":1.0
        },
        {
            "index":2088,
            "vuln_id":"GHSA-hjxc-462x-x77j",
            "cwe_id":"{'CWE-367'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/yarnpkg\/yarn\/commit\/0474b8c66a8ea298f5e4dedc67b2de464297ad1c'}",
            "dataset":"osv",
            "summary":"TOCTOU Race Condition in Yarn The package integrity validation in yarn &lt; 1.19.0 contains a TOCTOU vulnerability where the hash is computed before writing a package to cache. It&#39;s not computed again when reading from the cache. This may lead to a cache pollution attack. This issue is fixed in 1.19.0.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/yarnpkg\/yarn",
            "commit_href":"https:\/\/github.com\/yarnpkg\/yarn\/commit\/0474b8c66a8ea298f5e4dedc67b2de464297ad1c",
            "commit_sha":"0474b8c66a8ea298f5e4dedc67b2de464297ad1c",
            "patch":"SINGLE",
            "chain_ord":"['0474b8c66a8ea298f5e4dedc67b2de464297ad1c']",
            "before_first_fix_commit":"{'7f606ec3a31b53873056d48840e8acc647dca879'}",
            "last_fix_commit":"0474b8c66a8ea298f5e4dedc67b2de464297ad1c",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/28\/2019, 12:16:15",
            "message":"Prevents loading the cache if the stored integrity doesnt match",
            "author":"Ma\u00ebl Nison",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 3, 'total': 15}",
            "files":"{'src\/package-fetcher.js': {'additions': 12, 'deletions': 3, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/yarnpkg\/yarn\/raw\/0474b8c66a8ea298f5e4dedc67b2de464297ad1c\/src%2Fpackage-fetcher.js', 'patch': \"@@ -9,8 +9,17 @@ import * as fetchers from '.\/fetchers\/index.js';\\n import * as fs from '.\/util\/fs.js';\\n import * as promise from '.\/util\/promise.js';\\n \\n-async function fetchCache(dest: string, fetcher: Fetchers, config: Config): Promise<FetchedMetadata> {\\n-  const {hash, package: pkg} = await config.readPackageMetadata(dest);\\n+const ssri = require('ssri');\\n+\\n+async function fetchCache(dest: string, fetcher: Fetchers, config: Config, integrity: ?string): Promise<FetchedMetadata> {\\n+  const {hash, package: pkg, remote} = await config.readPackageMetadata(dest);\\n+\\n+  if (integrity) {\\n+    if (!remote.integrity || !ssri.parse(integrity).match(remote.integrity)) {\\n+      throw new MessageError('Incorrect integrity when fetching from the cache');\\n+    }\\n+  }\\n+\\n   await fetcher.setupMirrorFromCache();\\n   return {\\n     package: pkg,\\n@@ -40,7 +49,7 @@ export async function fetchOneRemote(\\n \\n   const fetcher = new Fetcher(dest, remote, config);\\n   if (await config.isValidModuleDest(dest)) {\\n-    return fetchCache(dest, fetcher, config);\\n+      return fetchCache(dest, fetcher, config, remote.integrity);\\n   }\\n \\n   \/\/ remove as the module may be invalid\"}}",
            "message_norm":"prevents loading the cache if the stored integrity doesnt match",
            "language":"en",
            "entities":"[('prevents', 'ACTION', ''), ('integrity', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/package-fetcher.js'])",
            "num_files":1.0
        },
        {
            "index":1632,
            "vuln_id":"GHSA-cx2r-mf6x-55rx",
            "cwe_id":"{'CWE-79'}",
            "score":4.1,
            "chain":"{'https:\/\/github.com\/PrestaShop\/ps_linklist\/commit\/83e6e0bdda2287f4d6e64127cb90c41d26b5ad82'}",
            "dataset":"osv",
            "summary":"Stored XSS with custom URLs in PrestaShop module ps_linklist ### Impact\nStored XSS when using custom URLs.\n\n### Patches\nThe problem is fixed in 3.1.0\n\n### References\n[Cross-site Scripting (XSS) - Stored (CWE-79)](https:\/\/cwe.mitre.org\/data\/definitions\/79.html)",
            "published_date":"2021-10-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/PrestaShop\/ps_linklist",
            "commit_href":"https:\/\/github.com\/PrestaShop\/ps_linklist\/commit\/83e6e0bdda2287f4d6e64127cb90c41d26b5ad82",
            "commit_sha":"83e6e0bdda2287f4d6e64127cb90c41d26b5ad82",
            "patch":"SINGLE",
            "chain_ord":"['83e6e0bdda2287f4d6e64127cb90c41d26b5ad82']",
            "before_first_fix_commit":"{'b90005c2cfed949ab564228b277a728e0a62a876', '632e61961553a5cdd4c12ad7218e914455dbaa6b'}",
            "last_fix_commit":"83e6e0bdda2287f4d6e64127cb90c41d26b5ad82",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/15\/2020, 14:16:34",
            "message":"Merge pull request from GHSA-cx2r-mf6x-55rx\n\nThe custom url field must be a valid url",
            "author":"GoT",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'src\/Form\/Type\/CustomUrlType.php': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/PrestaShop\/ps_linklist\/raw\/83e6e0bdda2287f4d6e64127cb90c41d26b5ad82\/src%2FForm%2FType%2FCustomUrlType.php', 'patch': \"@@ -29,6 +29,7 @@\\n use PrestaShopBundle\\\\Form\\\\Admin\\\\Type\\\\TranslatorAwareType;\\n use Symfony\\\\Component\\\\Form\\\\Extension\\\\Core\\\\Type\\\\TextType;\\n use Symfony\\\\Component\\\\Form\\\\FormBuilderInterface;\\n+use Symfony\\\\Component\\\\Validator\\\\Constraints as Assert;\\n \\n class CustomUrlType extends TranslatorAwareType\\n {\\n@@ -45,6 +46,7 @@ public function buildForm(FormBuilderInterface $builder, array $options)\\n             ->add('url', TextType::class, [\\n                 'label' => $this->trans('URL', 'Modules.Linklist.Admin'),\\n                 'required' => true,\\n+                'constraints' => [new Assert\\\\Url()],\\n             ])\\n         ;\\n     }\"}}",
            "message_norm":"merge pull request from ghsa-cx2r-mf6x-55rx\n\nthe custom url field must be a valid url",
            "language":"en",
            "entities":"[('ghsa-cx2r-mf6x-55rx', 'VULNID', 'GHSA')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Form\/Type\/CustomUrlType.php'])",
            "num_files":1.0
        },
        {
            "index":688,
            "vuln_id":"GHSA-5rcr-q3rx-j7vr",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/75162b7f2d8ac2b37d17564e9c979ba1bae707e8', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/214dec9461f9acb9a4b9004368d2a81e0c125652'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1062, CVE-2019-1092, CVE-2019-1103, CVE-2019-1106.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/214dec9461f9acb9a4b9004368d2a81e0c125652",
            "commit_sha":"214dec9461f9acb9a4b9004368d2a81e0c125652",
            "patch":"MULTI",
            "chain_ord":"['214dec9461f9acb9a4b9004368d2a81e0c125652', '75162b7f2d8ac2b37d17564e9c979ba1bae707e8']",
            "before_first_fix_commit":"{'12c31f0e83ddc511e57b9aa1e78533899199eb32', 'ba1f4455f921ce5f12091ff8a11c8028c6a64b17'}",
            "last_fix_commit":"75162b7f2d8ac2b37d17564e9c979ba1bae707e8",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/06\/2019, 19:58:34",
            "message":"[CVE-2019-1107] Chakra JIT Type Confusion FinishOptPropOp",
            "author":"Paul Leathers",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'lib\/Backend\/GlobOptFields.cpp': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/214dec9461f9acb9a4b9004368d2a81e0c125652\/lib%2FBackend%2FGlobOptFields.cpp', 'patch': '@@ -410,6 +410,14 @@ GlobOpt::ProcessFieldKills(IR::Instr *instr, BVSparse<JitArenaAllocator> *bv, bo\\n         if (inGlobOpt)\\n         {\\n             KillObjectHeaderInlinedTypeSyms(this->currentBlock, false);\\n+            if (this->objectTypeSyms)\\n+            {\\n+                if (this->currentBlock->globOptData.maybeWrittenTypeSyms == nullptr)\\n+                {\\n+                    this->currentBlock->globOptData.maybeWrittenTypeSyms = JitAnew(this->alloc, BVSparse<JitArenaAllocator>, this->alloc);\\n+                }\\n+                this->currentBlock->globOptData.maybeWrittenTypeSyms->Or(this->objectTypeSyms);\\n+            }\\n         }\\n \\n         \/\/ fall through'}}",
            "message_norm":"[cve-2019-1107] chakra jit type confusion finishoptpropop",
            "language":"en",
            "entities":"[('cve-2019-1107', 'VULNID', 'CVE'), ('type confusion', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Backend\/GlobOptFields.cpp'])",
            "num_files":1.0
        },
        {
            "index":859,
            "vuln_id":"GHSA-6jp6-9rf9-gc66",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/9e19a8414337692cc90da2a91c9af5420f2952f1', 'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/f6753a1a1c63fade6ad418fbda827c6750ab0bda', 'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/22d577b1f1e88665a88b4569380148030e0f8389'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Weblate ### Impact\nDue to improper neutralization, it was possible to perform cross-site scripting via crafted user and language names.\n\n### Patches\n\nThe issues were fixed in the 4.11 release. The following commits are addressing it:\n\n* f6753a1a1c63fade6ad418fbda827c6750ab0bda\n* 9e19a8414337692cc90da2a91c9af5420f2952f1\n* 22d577b1f1e88665a88b4569380148030e0f8389\n\n### Workarounds\n\nYou can look for crafted user and language names to see if you were affected.\n\n### References\n* https:\/\/hackerone.com\/reports\/1486674\n* https:\/\/hackerone.com\/reports\/1486718\n* https:\/\/hackerone.com\/reports\/1485226\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open a topic in [discussions](https:\/\/github.com\/WeblateOrg\/weblate\/discussions)\n* Email us at [care@weblate.org](mailto:care@weblate.org)",
            "published_date":"2022-02-25",
            "chain_len":3,
            "project":"https:\/\/github.com\/WeblateOrg\/weblate",
            "commit_href":"https:\/\/github.com\/WeblateOrg\/weblate\/commit\/f6753a1a1c63fade6ad418fbda827c6750ab0bda",
            "commit_sha":"f6753a1a1c63fade6ad418fbda827c6750ab0bda",
            "patch":"MULTI",
            "chain_ord":"['22d577b1f1e88665a88b4569380148030e0f8389', '9e19a8414337692cc90da2a91c9af5420f2952f1', 'f6753a1a1c63fade6ad418fbda827c6750ab0bda']",
            "before_first_fix_commit":"{'572628cef60e9d839b79b2087960b606a5cca4d8'}",
            "last_fix_commit":"f6753a1a1c63fade6ad418fbda827c6750ab0bda",
            "chain_ord_pos":3.0,
            "commit_datetime":"02\/22\/2022, 20:10:41",
            "message":"translate: Add missing escaping to language name\n\nFixes https:\/\/hackerone.com\/reports\/1486674",
            "author":"Michal \u010ciha\u0159",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'weblate\/trans\/forms.py': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/WeblateOrg\/weblate\/raw\/f6753a1a1c63fade6ad418fbda827c6750ab0bda\/weblate%2Ftrans%2Fforms.py', 'patch': '@@ -37,6 +37,7 @@\\n from django.template.loader import render_to_string\\n from django.urls import reverse\\n from django.utils import timezone\\n+from django.utils.html import escape\\n from django.utils.http import urlencode\\n from django.utils.safestring import mark_safe\\n from django.utils.translation import gettext\\n@@ -318,7 +319,7 @@ def render(self, name, value, attrs=None, renderer=None, **kwargs):\\n             # Render textare\\n             textarea = super().render(fieldname, val, attrs, renderer, **kwargs)\\n             # Label for plural\\n-            label = str(unit.translation.language)\\n+            label = escape(unit.translation.language)\\n             if len(values) != 1:\\n                 label = f\"{label}, {plural.get_plural_label(idx)}\"\\n             ret.append('}}",
            "message_norm":"translate: add missing escaping to language name\n\nfixes https:\/\/hackerone.com\/reports\/1486674",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('escaping', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('https:\/\/hackerone.com\/reports\/1486674', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['weblate\/trans\/forms.py'])",
            "num_files":1.0
        }
    ]
}