{
    "schema":{
        "fields":[
            {
                "name":"index",
                "type":"integer"
            },
            {
                "name":"vuln_id",
                "type":"string"
            },
            {
                "name":"cwe_id",
                "type":"string"
            },
            {
                "name":"score",
                "type":"number"
            },
            {
                "name":"chain",
                "type":"string"
            },
            {
                "name":"dataset",
                "type":"string"
            },
            {
                "name":"summary",
                "type":"string"
            },
            {
                "name":"published_date",
                "type":"string"
            },
            {
                "name":"chain_len",
                "type":"integer"
            },
            {
                "name":"project",
                "type":"string"
            },
            {
                "name":"commit_href",
                "type":"string"
            },
            {
                "name":"commit_sha",
                "type":"string"
            },
            {
                "name":"patch",
                "type":"string"
            },
            {
                "name":"chain_ord",
                "type":"string"
            },
            {
                "name":"before_first_fix_commit",
                "type":"string"
            },
            {
                "name":"last_fix_commit",
                "type":"string"
            },
            {
                "name":"chain_ord_pos",
                "type":"number"
            },
            {
                "name":"commit_datetime",
                "type":"string"
            },
            {
                "name":"message",
                "type":"string"
            },
            {
                "name":"author",
                "type":"string"
            },
            {
                "name":"comments",
                "type":"string"
            },
            {
                "name":"stats",
                "type":"string"
            },
            {
                "name":"files",
                "type":"string"
            },
            {
                "name":"message_norm",
                "type":"string"
            },
            {
                "name":"language",
                "type":"string"
            },
            {
                "name":"entities",
                "type":"string"
            },
            {
                "name":"classification_level_1",
                "type":"string"
            },
            {
                "name":"classification_level_2",
                "type":"string"
            },
            {
                "name":"list_files",
                "type":"string"
            },
            {
                "name":"num_files",
                "type":"number"
            },
            {
                "name":"patch_content",
                "type":"string"
            }
        ],
        "primaryKey":[
            "index"
        ],
        "pandas_version":"1.4.0"
    },
    "data":[
        {
            "index":793,
            "vuln_id":"GHSA-6cf8-qhqj-vjqm",
            "cwe_id":"{'CWE-400'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/totaljs\/framework\/commit\/b3f901561d66ab799a4a99279893b94cad7ae4ff'}",
            "dataset":"osv",
            "summary":"Prototype pollution in total.js There is a prototype pollution vulnerability in the package total.js before version 3.4.7. The set function can be used to set a value into the object according to the path. However the keys of the path being set are not properly sanitized, leading to a prototype pollution vulnerability. The impact depends on the application. In some cases it is possible to achieve Denial of service (DoS), Remote Code Execution or Property Injection.",
            "published_date":"2021-02-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/totaljs\/framework",
            "commit_href":"https:\/\/github.com\/totaljs\/framework\/commit\/b3f901561d66ab799a4a99279893b94cad7ae4ff",
            "commit_sha":"b3f901561d66ab799a4a99279893b94cad7ae4ff",
            "patch":"SINGLE",
            "chain_ord":"['b3f901561d66ab799a4a99279893b94cad7ae4ff']",
            "before_first_fix_commit":"{'1e1faeb20d2291038e10b98f2046a4058135e767'}",
            "last_fix_commit":"b3f901561d66ab799a4a99279893b94cad7ae4ff",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/31\/2020, 10:41:21",
            "message":"Fixed `U.set()` by adding check for `Prototype pollution`.",
            "author":"Peter Sirka",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'utils.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/totaljs\/framework\/raw\/b3f901561d66ab799a4a99279893b94cad7ae4ff\/utils.js', 'patch': \"@@ -6621,6 +6621,10 @@ exports.set = function(obj, path, value) {\\n \\tvar v = arr[arr.length - 1];\\n \\tvar ispush = v.lastIndexOf('[]') !== -1;\\n \\tvar a = builder.join(';') + ';var v=typeof(a)===\\\\'function\\\\'?a(U.get(b)):a;w' + (v[0] === '[' ? '' : '.') + (ispush ? v.replace(REGREPLACEARR, '.push(v)') : (v + '=v')) + ';return v';\\n+\\n+\\tif ((\/__proto__|constructor|prototype\/).test(a))\\n+\\t\\tthrow new Error('Prototype pollution');\\n+\\n \\tvar fn = new Function('w', 'a', 'b', a);\\n \\tF.temporary.other[cachekey] = fn;\\n \\tfn(obj, value, path);\"}}",
            "message_norm":"fixed `u.set()` by adding check for `prototype pollution`.",
            "language":"en",
            "entities":"[('fixed', 'ACTION', ''), ('adding', 'ACTION', ''), ('prototype pollution', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['utils.js'])",
            "num_files":1.0,
            "patch_content":"From b3f901561d66ab799a4a99279893b94cad7ae4ff Mon Sep 17 00:00:00 2001\nFrom: Peter Sirka <petersirka@gmail.com>\nDate: Thu, 31 Dec 2020 11:41:21 +0100\nSubject: [PATCH] Fixed `U.set()` by adding check for `Prototype pollution`.\n\n---\n utils.js | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/utils.js b\/utils.js\nindex 2b2959dd7..916954343 100755\n--- a\/utils.js\n+++ b\/utils.js\n@@ -6621,6 +6621,10 @@ exports.set = function(obj, path, value) {\n \tvar v = arr[arr.length - 1];\n \tvar ispush = v.lastIndexOf('[]') !== -1;\n \tvar a = builder.join(';') + ';var v=typeof(a)===\\'function\\'?a(U.get(b)):a;w' + (v[0] === '[' ? '' : '.') + (ispush ? v.replace(REGREPLACEARR, '.push(v)') : (v + '=v')) + ';return v';\n+\n+\tif ((\/__proto__|constructor|prototype\/).test(a))\n+\t\tthrow new Error('Prototype pollution');\n+\n \tvar fn = new Function('w', 'a', 'b', a);\n \tF.temporary.other[cachekey] = fn;\n \tfn(obj, value, path);"
        },
        {
            "index":600,
            "vuln_id":"GHSA-vjxv-45g9-9296",
            "cwe_id":"{'CWE-347'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/sigstore\/cosign\/commit\/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94'}",
            "dataset":"osv",
            "summary":"cosign's `cosign verify-attestaton  --type` can report a false positive if any attestation exists `cosign verify-attestation` used with the `--type` flag will report a false positive verification when:\n\n- There is at least one attestation with a valid signature\n- There are NO attestations of the type being verified (--type defaults to \"custom\")\n\nThis can happen when signing with a standard keypair and with \"keyless\" signing with Fulcio. Users should upgrade to cosign version 1.10.1 or greater for a patch. Currently the only workaround is to upgrade.",
            "published_date":"2022-08-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/sigstore\/cosign",
            "commit_href":"https:\/\/github.com\/sigstore\/cosign\/commit\/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
            "commit_sha":"c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
            "patch":"SINGLE",
            "chain_ord":"['c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94']",
            "before_first_fix_commit":"{'641f02b146816da54f112e1c1227747da17e5020'}",
            "last_fix_commit":"c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/04\/2022, 16:05:27",
            "message":"Merge pull request from GHSA-vjxv-45g9-9296\n\nToday the verification logic:\n1. Verifies signatures on attestations (at least one must verify, or it errors),\n2. All attestations matching the specified `--type` must pass any specified Cue\/Rego policies,\n3. *All* signature-verified attestations are then printed.\n\nHowever, if NONE of the attestations match the specified `--type` then `2.` is considered satisfied and we proceed to `3.`\n\nThis changes the above logic to:\n1. Same.\n2. Same, but these are put into a `checked` list,\n3. `checked` must be non-empty (or an error is printed about no attestations matching `--type`),\n4. *Just* the `checked` attestations are printed.\n\n---\n\nThe bug at HEAD:\n```shell\n$ cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nVerification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - Any certificates were verified against the Fulcio roots.\nCertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\nCertificate issuer URL:  https:\/\/token.actions.githubusercontent.com\nCertificate extension GitHub Workflow Trigger: schedule\nCertificate extension GitHub Workflow SHA: 7e7572e578de7c51a2f1a1791f025cf315503aa2\nCertificate extension GitHub Workflow Name: Create Release\nCertificate extension GitHub Workflow Trigger distroless\/static\nCertificate extension GitHub Workflow Ref: refs\/heads\/main\n{\"payloadType\":\"application\/vnd.in-toto+json\",\"payload\":\"eyJfdHlwZSI6Imh0dHBzOi8vaW4tdG90by5pby9TdGF0ZW1lbnQvdjAuMSIsInByZWRpY2F0ZVR5cGUiOiJjb3NpZ24uc2lnc3RvcmUuZGV2L2F0dGVzdGF0aW9uL3Z1bG4vdjEiLCJzdWJqZWN0IjpbeyJuYW1lIjoiZ2hjci5pby9kaXN0cm9sZXNzL3N0YXRpYyIsImRpZ2VzdCI6eyJzaGEyNTYiOiJkZDc2MTRiNWExMmJjNGQ2MTdiMjIzYzU4OGI0ZTBjODMzNDAyYjhmNDk5MWZiNTcwMmVhODNhZmFkMTk4NmUyIn19XSwicHJlZGljYXRlIjp7Imludm9jYXRpb24iOnsicGFyYW1ldGVycyI6bnVsbCwidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2Rpc3Ryb2xlc3Mvc3RhdGljL2FjdGlvbnMvcnVucy8yNzc5MjEyNzA1IiwiZXZlbnRfaWQiOiIyNzc5MjEyNzA1IiwiYnVpbGRlci5pZCI6IkNyZWF0ZSBSZWxlYXNlIn0sInNjYW5uZXIiOnsidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2FxdWFzZWN1cml0eS90cml2eSIsInZlcnNpb24iOiIwLjI5LjIiLCJkYiI6eyJ1cmkiOiIiLCJ2ZXJzaW9uIjoiIn0sInJlc3VsdCI6eyIkc2NoZW1hIjoiaHR0cHM6Ly9qc29uLnNjaGVtYXN0b3JlLm9yZy9zYXJpZi0yLjEuMC1ydG0uNS5qc29uIiwicnVucyI6W3siY29sdW1uS2luZCI6InV0ZjE2Q29kZVVuaXRzIiwib3JpZ2luYWxVcmlCYXNlSWRzIjp7IlJPT1RQQVRIIjp7InVyaSI6ImZpbGU6Ly8vIn19LCJyZXN1bHRzIjpbXSwidG9vbCI6eyJkcml2ZXIiOnsiZnVsbE5hbWUiOiJUcml2eSBWdWxuZXJhYmlsaXR5IFNjYW5uZXIiLCJpbmZvcm1hdGlvblVyaSI6Imh0dHBzOi8vZ2l0aHViLmNvbS9hcXVhc2VjdXJpdHkvdHJpdnkiLCJuYW1lIjoiVHJpdnkiLCJydWxlcyI6W10sInZlcnNpb24iOiIwLjI5LjIifX19XSwidmVyc2lvbiI6IjIuMS4wIn19LCJtZXRhZGF0YSI6eyJzY2FuU3RhcnRlZE9uIjoiMjAyMi0wOC0wMlQwMjozMzo0N1oiLCJzY2FuRmluaXNoZWRPbiI6IjIwMjItMDgtMDJUMDI6MzM6NTNaIn19fQ==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"MEYCIQCovBtLOBXyB2zpvhp3j6QzqLtsH0\/RC7fRINSApySqxAIhAIKlzu1fXuKPPOIheNnsPmBOB6XfZbRs5sDW1yFSch1A\"}]}\n```\n\nThe same with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\nError: none of the attestations matched the predicate type: spdx\nmain.go:62: error during command execution: none of the attestations matched the predicate type: spdx\nexit status 1\n```\n\nA valid `--type` with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type vuln ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nVerification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - Any certificates were verified against the Fulcio roots.\nCertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\nCertificate issuer URL:  https:\/\/token.actions.githubusercontent.com\nCertificate extension GitHub Workflow Trigger: schedule\nCertificate extension GitHub Workflow SHA: 7e7572e578de7c51a2f1a1791f025cf315503aa2\nCertificate extension GitHub Workflow Name: Create Release\nCertificate extension GitHub Workflow Trigger distroless\/static\nCertificate extension GitHub Workflow Ref: refs\/heads\/main\n{\"payloadType\":\"application\/vnd.in-toto+json\",\"payload\":\"eyJfdHlwZSI6Imh0dHBzOi8vaW4tdG90by5pby9TdGF0ZW1lbnQvdjAuMSIsInByZWRpY2F0ZVR5cGUiOiJjb3NpZ24uc2lnc3RvcmUuZGV2L2F0dGVzdGF0aW9uL3Z1bG4vdjEiLCJzdWJqZWN0IjpbeyJuYW1lIjoiZ2hjci5pby9kaXN0cm9sZXNzL3N0YXRpYyIsImRpZ2VzdCI6eyJzaGEyNTYiOiJkZDc2MTRiNWExMmJjNGQ2MTdiMjIzYzU4OGI0ZTBjODMzNDAyYjhmNDk5MWZiNTcwMmVhODNhZmFkMTk4NmUyIn19XSwicHJlZGljYXRlIjp7Imludm9jYXRpb24iOnsicGFyYW1ldGVycyI6bnVsbCwidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2Rpc3Ryb2xlc3Mvc3RhdGljL2FjdGlvbnMvcnVucy8yNzc5MjEyNzA1IiwiZXZlbnRfaWQiOiIyNzc5MjEyNzA1IiwiYnVpbGRlci5pZCI6IkNyZWF0ZSBSZWxlYXNlIn0sInNjYW5uZXIiOnsidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2FxdWFzZWN1cml0eS90cml2eSIsInZlcnNpb24iOiIwLjI5LjIiLCJkYiI6eyJ1cmkiOiIiLCJ2ZXJzaW9uIjoiIn0sInJlc3VsdCI6eyIkc2NoZW1hIjoiaHR0cHM6Ly9qc29uLnNjaGVtYXN0b3JlLm9yZy9zYXJpZi0yLjEuMC1ydG0uNS5qc29uIiwicnVucyI6W3siY29sdW1uS2luZCI6InV0ZjE2Q29kZVVuaXRzIiwib3JpZ2luYWxVcmlCYXNlSWRzIjp7IlJPT1RQQVRIIjp7InVyaSI6ImZpbGU6Ly8vIn19LCJyZXN1bHRzIjpbXSwidG9vbCI6eyJkcml2ZXIiOnsiZnVsbE5hbWUiOiJUcml2eSBWdWxuZXJhYmlsaXR5IFNjYW5uZXIiLCJpbmZvcm1hdGlvblVyaSI6Imh0dHBzOi8vZ2l0aHViLmNvbS9hcXVhc2VjdXJpdHkvdHJpdnkiLCJuYW1lIjoiVHJpdnkiLCJydWxlcyI6W10sInZlcnNpb24iOiIwLjI5LjIifX19XSwidmVyc2lvbiI6IjIuMS4wIn19LCJtZXRhZGF0YSI6eyJzY2FuU3RhcnRlZE9uIjoiMjAyMi0wOC0wMlQwMjozMzo0N1oiLCJzY2FuRmluaXNoZWRPbiI6IjIwMjItMDgtMDJUMDI6MzM6NTNaIn19fQ==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"MEYCIQCovBtLOBXyB2zpvhp3j6QzqLtsH0\/RC7fRINSApySqxAIhAIKlzu1fXuKPPOIheNnsPmBOB6XfZbRs5sDW1yFSch1A\"}]}\n```\n\nSigned-off-by: Matt Moore <mattmoor@chainguard.dev>",
            "author":"Matt Moore",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 1, 'total': 11}",
            "files":"{'cmd\/cosign\/cli\/verify\/verify_attestation.go': {'additions': 10, 'deletions': 1, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sigstore\/cosign\/raw\/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94\/cmd%2Fcosign%2Fcli%2Fverify%2Fverify_attestation.go', 'patch': '@@ -201,6 +201,7 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t}\\n \\t\\t}\\n \\n+\\t\\tvar checked []oci.Signature\\n \\t\\tvar validationErrors []error\\n \\t\\tfor _, vp := range verified {\\n \\t\\t\\tpayload, err := policy.AttestationToPayloadJSON(ctx, c.PredicateType, vp)\\n@@ -217,6 +218,7 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t\\tcueValidationErr := cue.ValidateJSON(payload, cuePolicies)\\n \\t\\t\\t\\tif cueValidationErr != nil {\\n \\t\\t\\t\\t\\tvalidationErrors = append(validationErrors, cueValidationErr)\\n+\\t\\t\\t\\t\\tcontinue\\n \\t\\t\\t\\t}\\n \\t\\t\\t}\\n \\n@@ -225,8 +227,11 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t\\tregoValidationErrs := rego.ValidateJSON(payload, regoPolicies)\\n \\t\\t\\t\\tif len(regoValidationErrs) > 0 {\\n \\t\\t\\t\\t\\tvalidationErrors = append(validationErrors, regoValidationErrs...)\\n+\\t\\t\\t\\t\\tcontinue\\n \\t\\t\\t\\t}\\n \\t\\t\\t}\\n+\\n+\\t\\t\\tchecked = append(checked, vp)\\n \\t\\t}\\n \\n \\t\\tif len(validationErrors) > 0 {\\n@@ -237,10 +242,14 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\treturn fmt.Errorf(\"%d validation errors occurred\", len(validationErrors))\\n \\t\\t}\\n \\n+\\t\\tif len(checked) == 0 {\\n+\\t\\t\\treturn fmt.Errorf(\"none of the attestations matched the predicate type: %s\", c.PredicateType)\\n+\\t\\t}\\n+\\n \\t\\t\/\/ TODO: add CUE validation report to `PrintVerificationHeader`.\\n \\t\\tPrintVerificationHeader(imageRef, co, bundleVerified, fulcioVerified)\\n \\t\\t\/\/ The attestations are always JSON, so use the raw \"text\" mode for outputting them instead of conversion\\n-\\t\\tPrintVerification(imageRef, verified, \"text\")\\n+\\t\\tPrintVerification(imageRef, checked, \"text\")\\n \\t}\\n \\n \\treturn nil'}}",
            "message_norm":"merge pull request from ghsa-vjxv-45g9-9296\n\ntoday the verification logic:\n1. verifies signatures on attestations (at least one must verify, or it errors),\n2. all attestations matching the specified `--type` must pass any specified cue\/rego policies,\n3. *all* signature-verified attestations are then printed.\n\nhowever, if none of the attestations match the specified `--type` then `2.` is considered satisfied and we proceed to `3.`\n\nthis changes the above logic to:\n1. same.\n2. same, but these are put into a `checked` list,\n3. `checked` must be non-empty (or an error is printed about no attestations matching `--type`),\n4. *just* the `checked` attestations are printed.\n\n---\n\nthe bug at head:\n```shell\n$ cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nverification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nthe following checks were performed on each of these signatures:\n  - the cosign claims were validated\n  - existence of the claims in the transparency log was verified offline\n  - any certificates were verified against the fulcio roots.\ncertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\ncertificate issuer url:  https:\/\/token.actions.githubusercontent.com\ncertificate extension github workflow trigger: schedule\ncertificate extension github workflow sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2\ncertificate extension github workflow name: create release\ncertificate extension github workflow trigger distroless\/static\ncertificate extension github workflow ref: refs\/heads\/main\n{\"payloadtype\":\"application\/vnd.in-toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0\/rc7frinsapysqxaihaiklzu1fxukppoihennspmbob6xfzbrs5sdw1yfsch1a\"}]}\n```\n\nthe same with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\nerror: none of the attestations matched the predicate type: spdx\nmain.go:62: error during command execution: none of the attestations matched the predicate type: spdx\nexit status 1\n```\n\na valid `--type` with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type vuln ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nverification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nthe following checks were performed on each of these signatures:\n  - the cosign claims were validated\n  - existence of the claims in the transparency log was verified offline\n  - any certificates were verified against the fulcio roots.\ncertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\ncertificate issuer url:  https:\/\/token.actions.githubusercontent.com\ncertificate extension github workflow trigger: schedule\ncertificate extension github workflow sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2\ncertificate extension github workflow name: create release\ncertificate extension github workflow trigger distroless\/static\ncertificate extension github workflow ref: refs\/heads\/main\n{\"payloadtype\":\"application\/vnd.in-toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0\/rc7frinsapysqxaihaiklzu1fxukppoihennspmbob6xfzbrs5sdw1yfsch1a\"}]}\n```\n\nsigned-off-by: matt moore <mattmoor@chainguard.dev>",
            "language":"en",
            "entities":"[('ghsa-vjxv-45g9-9296', 'VULNID', 'GHSA'), ('verifies', 'ACTION', ''), ('verify', 'ACTION', ''), ('signature', 'SECWORD', ''), ('verified', 'ACTION', ''), ('changes', 'ACTION', ''), ('error', 'FLAW', ''), ('bug', 'FLAW', ''), ('validated', 'ACTION', ''), ('verified', 'ACTION', ''), ('verified', 'ACTION', ''), ('certificate', 'SECWORD', ''), ('https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main', 'URL', ''), ('certificate', 'SECWORD', ''), ('https:\/\/token.actions.githubusercontent.com', 'URL', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2', 'SHA', 'prefix_colon_sha'), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0', 'SECWORD', ''), ('error', 'FLAW', ''), ('error', 'FLAW', ''), ('command execution', 'SECWORD', ''), ('validated', 'ACTION', ''), ('verified', 'ACTION', ''), ('verified', 'ACTION', ''), ('certificate', 'SECWORD', ''), ('https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main', 'URL', ''), ('certificate', 'SECWORD', ''), ('https:\/\/token.actions.githubusercontent.com', 'URL', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2', 'SHA', 'prefix_colon_sha'), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0', 'SECWORD', ''), ('mattmoor@chainguard.dev', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['cmd\/cosign\/cli\/verify\/verify_attestation.go'])",
            "num_files":1.0,
            "patch_content":"From c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94 Mon Sep 17 00:00:00 2001\nFrom: Matt Moore <mattmoor@chainguard.dev>\nDate: Thu, 4 Aug 2022 09:05:27 -0700\nSubject: [PATCH] Merge pull request from GHSA-vjxv-45g9-9296\n\nToday the verification logic:\n1. Verifies signatures on attestations (at least one must verify, or it errors),\n2. All attestations matching the specified `--type` must pass any specified Cue\/Rego policies,\n3. *All* signature-verified attestations are then printed.\n\nHowever, if NONE of the attestations match the specified `--type` then `2.` is considered satisfied and we proceed to `3.`\n\nThis changes the above logic to:\n1. Same.\n2. Same, but these are put into a `checked` list,\n3. `checked` must be non-empty (or an error is printed about no attestations matching `--type`),\n4. *Just* the `checked` attestations are printed.\n\n---\n\nThe bug at HEAD:\n```shell\n$ cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nVerification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - Any certificates were verified against the Fulcio roots.\nCertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\nCertificate issuer URL:  https:\/\/token.actions.githubusercontent.com\nCertificate extension GitHub Workflow Trigger: schedule\nCertificate extension GitHub Workflow SHA: 7e7572e578de7c51a2f1a1791f025cf315503aa2\nCertificate extension GitHub Workflow Name: Create Release\nCertificate extension GitHub Workflow Trigger distroless\/static\nCertificate extension GitHub Workflow Ref: refs\/heads\/main\n{\"payloadType\":\"application\/vnd.in-toto+json\",\"payload\":\"eyJfdHlwZSI6Imh0dHBzOi8vaW4tdG90by5pby9TdGF0ZW1lbnQvdjAuMSIsInByZWRpY2F0ZVR5cGUiOiJjb3NpZ24uc2lnc3RvcmUuZGV2L2F0dGVzdGF0aW9uL3Z1bG4vdjEiLCJzdWJqZWN0IjpbeyJuYW1lIjoiZ2hjci5pby9kaXN0cm9sZXNzL3N0YXRpYyIsImRpZ2VzdCI6eyJzaGEyNTYiOiJkZDc2MTRiNWExMmJjNGQ2MTdiMjIzYzU4OGI0ZTBjODMzNDAyYjhmNDk5MWZiNTcwMmVhODNhZmFkMTk4NmUyIn19XSwicHJlZGljYXRlIjp7Imludm9jYXRpb24iOnsicGFyYW1ldGVycyI6bnVsbCwidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2Rpc3Ryb2xlc3Mvc3RhdGljL2FjdGlvbnMvcnVucy8yNzc5MjEyNzA1IiwiZXZlbnRfaWQiOiIyNzc5MjEyNzA1IiwiYnVpbGRlci5pZCI6IkNyZWF0ZSBSZWxlYXNlIn0sInNjYW5uZXIiOnsidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2FxdWFzZWN1cml0eS90cml2eSIsInZlcnNpb24iOiIwLjI5LjIiLCJkYiI6eyJ1cmkiOiIiLCJ2ZXJzaW9uIjoiIn0sInJlc3VsdCI6eyIkc2NoZW1hIjoiaHR0cHM6Ly9qc29uLnNjaGVtYXN0b3JlLm9yZy9zYXJpZi0yLjEuMC1ydG0uNS5qc29uIiwicnVucyI6W3siY29sdW1uS2luZCI6InV0ZjE2Q29kZVVuaXRzIiwib3JpZ2luYWxVcmlCYXNlSWRzIjp7IlJPT1RQQVRIIjp7InVyaSI6ImZpbGU6Ly8vIn19LCJyZXN1bHRzIjpbXSwidG9vbCI6eyJkcml2ZXIiOnsiZnVsbE5hbWUiOiJUcml2eSBWdWxuZXJhYmlsaXR5IFNjYW5uZXIiLCJpbmZvcm1hdGlvblVyaSI6Imh0dHBzOi8vZ2l0aHViLmNvbS9hcXVhc2VjdXJpdHkvdHJpdnkiLCJuYW1lIjoiVHJpdnkiLCJydWxlcyI6W10sInZlcnNpb24iOiIwLjI5LjIifX19XSwidmVyc2lvbiI6IjIuMS4wIn19LCJtZXRhZGF0YSI6eyJzY2FuU3RhcnRlZE9uIjoiMjAyMi0wOC0wMlQwMjozMzo0N1oiLCJzY2FuRmluaXNoZWRPbiI6IjIwMjItMDgtMDJUMDI6MzM6NTNaIn19fQ==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"MEYCIQCovBtLOBXyB2zpvhp3j6QzqLtsH0\/RC7fRINSApySqxAIhAIKlzu1fXuKPPOIheNnsPmBOB6XfZbRs5sDW1yFSch1A\"}]}\n```\n\nThe same with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type spdx ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\nError: none of the attestations matched the predicate type: spdx\nmain.go:62: error during command execution: none of the attestations matched the predicate type: spdx\nexit status 1\n```\n\nA valid `--type` with this change:\n```shell\n$ go run .\/cmd\/cosign verify-attestation --type vuln ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nVerification for ghcr.io\/distroless\/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - Any certificates were verified against the Fulcio roots.\nCertificate subject:  https:\/\/github.com\/distroless\/static\/.github\/workflows\/release.yaml@refs\/heads\/main\nCertificate issuer URL:  https:\/\/token.actions.githubusercontent.com\nCertificate extension GitHub Workflow Trigger: schedule\nCertificate extension GitHub Workflow SHA: 7e7572e578de7c51a2f1a1791f025cf315503aa2\nCertificate extension GitHub Workflow Name: Create Release\nCertificate extension GitHub Workflow Trigger distroless\/static\nCertificate extension GitHub Workflow Ref: refs\/heads\/main\n{\"payloadType\":\"application\/vnd.in-toto+json\",\"payload\":\"eyJfdHlwZSI6Imh0dHBzOi8vaW4tdG90by5pby9TdGF0ZW1lbnQvdjAuMSIsInByZWRpY2F0ZVR5cGUiOiJjb3NpZ24uc2lnc3RvcmUuZGV2L2F0dGVzdGF0aW9uL3Z1bG4vdjEiLCJzdWJqZWN0IjpbeyJuYW1lIjoiZ2hjci5pby9kaXN0cm9sZXNzL3N0YXRpYyIsImRpZ2VzdCI6eyJzaGEyNTYiOiJkZDc2MTRiNWExMmJjNGQ2MTdiMjIzYzU4OGI0ZTBjODMzNDAyYjhmNDk5MWZiNTcwMmVhODNhZmFkMTk4NmUyIn19XSwicHJlZGljYXRlIjp7Imludm9jYXRpb24iOnsicGFyYW1ldGVycyI6bnVsbCwidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2Rpc3Ryb2xlc3Mvc3RhdGljL2FjdGlvbnMvcnVucy8yNzc5MjEyNzA1IiwiZXZlbnRfaWQiOiIyNzc5MjEyNzA1IiwiYnVpbGRlci5pZCI6IkNyZWF0ZSBSZWxlYXNlIn0sInNjYW5uZXIiOnsidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2FxdWFzZWN1cml0eS90cml2eSIsInZlcnNpb24iOiIwLjI5LjIiLCJkYiI6eyJ1cmkiOiIiLCJ2ZXJzaW9uIjoiIn0sInJlc3VsdCI6eyIkc2NoZW1hIjoiaHR0cHM6Ly9qc29uLnNjaGVtYXN0b3JlLm9yZy9zYXJpZi0yLjEuMC1ydG0uNS5qc29uIiwicnVucyI6W3siY29sdW1uS2luZCI6InV0ZjE2Q29kZVVuaXRzIiwib3JpZ2luYWxVcmlCYXNlSWRzIjp7IlJPT1RQQVRIIjp7InVyaSI6ImZpbGU6Ly8vIn19LCJyZXN1bHRzIjpbXSwidG9vbCI6eyJkcml2ZXIiOnsiZnVsbE5hbWUiOiJUcml2eSBWdWxuZXJhYmlsaXR5IFNjYW5uZXIiLCJpbmZvcm1hdGlvblVyaSI6Imh0dHBzOi8vZ2l0aHViLmNvbS9hcXVhc2VjdXJpdHkvdHJpdnkiLCJuYW1lIjoiVHJpdnkiLCJydWxlcyI6W10sInZlcnNpb24iOiIwLjI5LjIifX19XSwidmVyc2lvbiI6IjIuMS4wIn19LCJtZXRhZGF0YSI6eyJzY2FuU3RhcnRlZE9uIjoiMjAyMi0wOC0wMlQwMjozMzo0N1oiLCJzY2FuRmluaXNoZWRPbiI6IjIwMjItMDgtMDJUMDI6MzM6NTNaIn19fQ==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"MEYCIQCovBtLOBXyB2zpvhp3j6QzqLtsH0\/RC7fRINSApySqxAIhAIKlzu1fXuKPPOIheNnsPmBOB6XfZbRs5sDW1yFSch1A\"}]}\n```\n\nSigned-off-by: Matt Moore <mattmoor@chainguard.dev>\n---\n cmd\/cosign\/cli\/verify\/verify_attestation.go | 11 ++++++++++-\n 1 file changed, 10 insertions(+), 1 deletion(-)\n\ndiff --git a\/cmd\/cosign\/cli\/verify\/verify_attestation.go b\/cmd\/cosign\/cli\/verify\/verify_attestation.go\nindex cde32f683cf..01ea6e044bd 100644\n--- a\/cmd\/cosign\/cli\/verify\/verify_attestation.go\n+++ b\/cmd\/cosign\/cli\/verify\/verify_attestation.go\n@@ -201,6 +201,7 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\n \t\t\t}\n \t\t}\n \n+\t\tvar checked []oci.Signature\n \t\tvar validationErrors []error\n \t\tfor _, vp := range verified {\n \t\t\tpayload, err := policy.AttestationToPayloadJSON(ctx, c.PredicateType, vp)\n@@ -217,6 +218,7 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\n \t\t\t\tcueValidationErr := cue.ValidateJSON(payload, cuePolicies)\n \t\t\t\tif cueValidationErr != nil {\n \t\t\t\t\tvalidationErrors = append(validationErrors, cueValidationErr)\n+\t\t\t\t\tcontinue\n \t\t\t\t}\n \t\t\t}\n \n@@ -225,8 +227,11 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\n \t\t\t\tregoValidationErrs := rego.ValidateJSON(payload, regoPolicies)\n \t\t\t\tif len(regoValidationErrs) > 0 {\n \t\t\t\t\tvalidationErrors = append(validationErrors, regoValidationErrs...)\n+\t\t\t\t\tcontinue\n \t\t\t\t}\n \t\t\t}\n+\n+\t\t\tchecked = append(checked, vp)\n \t\t}\n \n \t\tif len(validationErrors) > 0 {\n@@ -237,10 +242,14 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\n \t\t\treturn fmt.Errorf(\"%d validation errors occurred\", len(validationErrors))\n \t\t}\n \n+\t\tif len(checked) == 0 {\n+\t\t\treturn fmt.Errorf(\"none of the attestations matched the predicate type: %s\", c.PredicateType)\n+\t\t}\n+\n \t\t\/\/ TODO: add CUE validation report to `PrintVerificationHeader`.\n \t\tPrintVerificationHeader(imageRef, co, bundleVerified, fulcioVerified)\n \t\t\/\/ The attestations are always JSON, so use the raw \"text\" mode for outputting them instead of conversion\n-\t\tPrintVerification(imageRef, verified, \"text\")\n+\t\tPrintVerification(imageRef, checked, \"text\")\n \t}\n \n \treturn nil"
        },
        {
            "index":701,
            "vuln_id":"GHSA-wg6g-ppvx-927h",
            "cwe_id":"{'CWE-1321'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/ashaffer\/cached-path-relative\/commit\/40c73bf70c58add5aec7d11e4f36b93d144bb760'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in cached-path-relative The package cached-path-relative before 1.1.0 is vulnerable to Prototype Pollution via the cache variable that is set as {} instead of Object.create(null) in the cachedPathRelative function, which allows access to the parent prototype properties when the object is used to create the cached relative path. When using the origin path as __proto__, the attribute of the object is accessed instead of a path. **Note:** This vulnerability derives from an incomplete fix in https:\/\/security.snyk.io\/vuln\/SNYK-JS-CACHEDPATHRELATIVE-72573",
            "published_date":"2022-01-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/ashaffer\/cached-path-relative",
            "commit_href":"https:\/\/github.com\/ashaffer\/cached-path-relative\/commit\/40c73bf70c58add5aec7d11e4f36b93d144bb760",
            "commit_sha":"40c73bf70c58add5aec7d11e4f36b93d144bb760",
            "patch":"SINGLE",
            "chain_ord":"['40c73bf70c58add5aec7d11e4f36b93d144bb760']",
            "before_first_fix_commit":"{'dfc753a020508cf42cde98024c68bf16bed12edc'}",
            "last_fix_commit":"40c73bf70c58add5aec7d11e4f36b93d144bb760",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/19\/2022, 19:12:34",
            "message":"Fix other instances of prototype pollution vulnerability",
            "author":"Andrew",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'lib\/index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ashaffer\/cached-path-relative\/raw\/40c73bf70c58add5aec7d11e4f36b93d144bb760\/lib%2Findex.js', 'patch': '@@ -27,15 +27,15 @@ function cachedPathRelative (from, to) {\\n   \/\/ to invalidate the cache\\n   var cwd = process.cwd()\\n   if (cwd !== lastCwd) {\\n-    cache = {}\\n+    cache = Object.create(null)\\n     lastCwd = cwd\\n   }\\n \\n   if (cache[from] && cache[from][to]) return cache[from][to]\\n \\n   var result = relative.call(path, from, to)\\n \\n-  cache[from] = cache[from] || {}\\n+  cache[from] = cache[from] || Object.create(null)\\n   cache[from][to] = result\\n \\n   return result'}}",
            "message_norm":"fix other instances of prototype pollution vulnerability",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('prototype pollution', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/index.js'])",
            "num_files":1.0,
            "patch_content":"From 40c73bf70c58add5aec7d11e4f36b93d144bb760 Mon Sep 17 00:00:00 2001\nFrom: Andrew <darawk@gmail.com>\nDate: Wed, 19 Jan 2022 11:12:34 -0800\nSubject: [PATCH] Fix other instances of prototype pollution vulnerability\n\n---\n lib\/index.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/lib\/index.js b\/lib\/index.js\nindex 78346c3..cb74bec 100644\n--- a\/lib\/index.js\n+++ b\/lib\/index.js\n@@ -27,7 +27,7 @@ function cachedPathRelative (from, to) {\n   \/\/ to invalidate the cache\n   var cwd = process.cwd()\n   if (cwd !== lastCwd) {\n-    cache = {}\n+    cache = Object.create(null)\n     lastCwd = cwd\n   }\n \n@@ -35,7 +35,7 @@ function cachedPathRelative (from, to) {\n \n   var result = relative.call(path, from, to)\n \n-  cache[from] = cache[from] || {}\n+  cache[from] = cache[from] || Object.create(null)\n   cache[from][to] = result\n \n   return result"
        },
        {
            "index":846,
            "vuln_id":"GHSA-3mpr-hq3p-49h9",
            "cwe_id":"{'CWE-471'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/jonschlinkert\/mixin-deep\/commit\/578b0bc5e74e14de9ef4975f504dc698796bdf9c'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in mixin-deep Versions of `mixin-deep` before 1.3.1 are vulnerable to prototype pollution via merging functions.\n\n\n## Recommendation\n\nUpdate to version 1.3.1 or later.",
            "published_date":"2018-07-26",
            "chain_len":1,
            "project":"https:\/\/github.com\/jonschlinkert\/mixin-deep",
            "commit_href":"https:\/\/github.com\/jonschlinkert\/mixin-deep\/commit\/578b0bc5e74e14de9ef4975f504dc698796bdf9c",
            "commit_sha":"578b0bc5e74e14de9ef4975f504dc698796bdf9c",
            "patch":"SINGLE",
            "chain_ord":"['578b0bc5e74e14de9ef4975f504dc698796bdf9c']",
            "before_first_fix_commit":"{'7705bdf88ff0263242c07c824d20526203876668'}",
            "last_fix_commit":"578b0bc5e74e14de9ef4975f504dc698796bdf9c",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/07\/2018, 16:04:06",
            "message":"exclude __proto__",
            "author":"doowb",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'index.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jonschlinkert\/mixin-deep\/raw\/578b0bc5e74e14de9ef4975f504dc698796bdf9c\/index.js', 'patch': \"@@ -23,6 +23,10 @@ function mixinDeep(target, objects) {\\n  *\/\\n \\n function copy(val, key) {\\n+  if (key === '__proto__') {\\n+    return;\\n+  }\\n+\\n   var obj = this[key];\\n   if (isObject(val) && isObject(obj)) {\\n     mixinDeep(obj, val);\"}}",
            "message_norm":"exclude __proto__",
            "language":"pt",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From 578b0bc5e74e14de9ef4975f504dc698796bdf9c Mon Sep 17 00:00:00 2001\nFrom: doowb <brian.woodward@gmail.com>\nDate: Wed, 7 Feb 2018 11:04:06 -0500\nSubject: [PATCH] exclude __proto__\n\n---\n index.js | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/index.js b\/index.js\nindex 60f7049..909fbef 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -23,6 +23,10 @@ function mixinDeep(target, objects) {\n  *\/\n \n function copy(val, key) {\n+  if (key === '__proto__') {\n+    return;\n+  }\n+\n   var obj = this[key];\n   if (isObject(val) && isObject(obj)) {\n     mixinDeep(obj, val);"
        },
        {
            "index":25,
            "vuln_id":"GHSA-x8h6-xgqx-jqgp",
            "cwe_id":"{'CWE-908'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/32fdcbff9d06d010d908fcc4bd4b36eb3ce15925'}",
            "dataset":"osv",
            "summary":"Undefined behavior and `CHECK`-fail in `FractionalMaxPoolGrad` ### Impact\nThe implementation of `tf.raw_ops.FractionalMaxPoolGrad` triggers an undefined behavior if one of the input tensors is empty:\n\n```python\nimport tensorflow as tf\n\norig_input = tf.constant([2, 3], shape=[1, 1, 1, 2], dtype=tf.int64)\norig_output = tf.constant([], dtype=tf.int64) \nout_backprop = tf.zeros([2, 3, 6, 6], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([0], shape=[1], dtype=tf.int64)\ncol_pooling_sequence = tf.constant([0], shape=[1], dtype=tf.int64)\n\ntf.raw_ops.FractionalMaxPoolGrad(\n  orig_input=orig_input, orig_output=orig_output, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)\n```\n\nThe code is also vulnerable to a denial of service attack as a `CHECK` condition becomes false and aborts the process\n\n```python\nimport tensorflow as tf\n\norig_input = tf.constant([1], shape=[1], dtype=tf.int64)\norig_output = tf.constant([1], shape=[1], dtype=tf.int64)\nout_backprop = tf.constant([1, 1], shape=[2, 1, 1, 1], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64) \ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\n\ntf.raw_ops.FractionalMaxPoolGrad(\n  orig_input=orig_input, orig_output=orig_output, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)\n``` \n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/169054888d50ce488dfde9ca55d91d6325efbd5b\/tensorflow\/core\/kernels\/fractional_max_pool_op.cc#L215) fails to validate that input and output tensors are not empty and are of the same rank. Each of these unchecked assumptions is responsible for the above issues.\n\n### Patches\nWe have patched the issue in GitHub commit [32fdcbff9d06d010d908fcc4bd4b36eb3ce15925](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/32fdcbff9d06d010d908fcc4bd4b36eb3ce15925).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/32fdcbff9d06d010d908fcc4bd4b36eb3ce15925",
            "commit_sha":"32fdcbff9d06d010d908fcc4bd4b36eb3ce15925",
            "patch":"SINGLE",
            "chain_ord":"['32fdcbff9d06d010d908fcc4bd4b36eb3ce15925']",
            "before_first_fix_commit":"{'169054888d50ce488dfde9ca55d91d6325efbd5b'}",
            "last_fix_commit":"32fdcbff9d06d010d908fcc4bd4b36eb3ce15925",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 05:39:29",
            "message":"Validate arguments of `FractionalMaxPoolGrad`\n\nPiperOrigin-RevId: 372274982\nChange-Id: If46b0c442efa4eaef635ce6a476717060420122c",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 0, 'total': 14}",
            "files":"{'tensorflow\/core\/kernels\/fractional_max_pool_op.cc': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/32fdcbff9d06d010d908fcc4bd4b36eb3ce15925\/tensorflow%2Fcore%2Fkernels%2Ffractional_max_pool_op.cc', 'patch': '@@ -235,6 +235,20 @@ class FractionalMaxPoolGradOp : public OpKernel {\\n \\n     \/\/ Just to make it similar to FractionalMaxPoolOp.\\n     constexpr int tensor_in_and_out_dims = 4;\\n+    OP_REQUIRES(\\n+        context, tensor_in.dims() == tensor_in_and_out_dims,\\n+        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",\\n+                                tensor_in.DebugString()));\\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\\n+                errors::InvalidArgument(\"orig_input must not be empty, got \",\\n+                                        tensor_in.DebugString()));\\n+    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,\\n+                errors::InvalidArgument(\\n+                    \"orig_output should be a tensor of rank 4, got \",\\n+                    tensor_out.DebugString()));\\n+    OP_REQUIRES(context, tensor_out.NumElements() > 0,\\n+                errors::InvalidArgument(\"orig_output must not be empty, got \",\\n+                                        tensor_out.DebugString()));\\n     std::vector<int64> input_size(tensor_in_and_out_dims);\\n     std::vector<int64> output_size(tensor_in_and_out_dims);\\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {'}}",
            "message_norm":"validate arguments of `fractionalmaxpoolgrad`\n\npiperorigin-revid: 372274982\nchange-id: if46b0c442efa4eaef635ce6a476717060420122c",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('372274982', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/fractional_max_pool_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 32fdcbff9d06d010d908fcc4bd4b36eb3ce15925 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 5 May 2021 22:39:29 -0700\nSubject: [PATCH] Validate arguments of `FractionalMaxPoolGrad`\n\nPiperOrigin-RevId: 372274982\nChange-Id: If46b0c442efa4eaef635ce6a476717060420122c\n---\n tensorflow\/core\/kernels\/fractional_max_pool_op.cc | 14 ++++++++++++++\n 1 file changed, 14 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/fractional_max_pool_op.cc b\/tensorflow\/core\/kernels\/fractional_max_pool_op.cc\nindex 619a3507ce415f..1a2a783d135c54 100644\n--- a\/tensorflow\/core\/kernels\/fractional_max_pool_op.cc\n+++ b\/tensorflow\/core\/kernels\/fractional_max_pool_op.cc\n@@ -235,6 +235,20 @@ class FractionalMaxPoolGradOp : public OpKernel {\n \n     \/\/ Just to make it similar to FractionalMaxPoolOp.\n     constexpr int tensor_in_and_out_dims = 4;\n+    OP_REQUIRES(\n+        context, tensor_in.dims() == tensor_in_and_out_dims,\n+        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",\n+                                tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"orig_input must not be empty, got \",\n+                                        tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,\n+                errors::InvalidArgument(\n+                    \"orig_output should be a tensor of rank 4, got \",\n+                    tensor_out.DebugString()));\n+    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n+                errors::InvalidArgument(\"orig_output must not be empty, got \",\n+                                        tensor_out.DebugString()));\n     std::vector<int64> input_size(tensor_in_and_out_dims);\n     std::vector<int64> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {"
        },
        {
            "index":412,
            "vuln_id":"GHSA-49x3-8228-3w3m",
            "cwe_id":"{'CWE-1333'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/cdr\/code-server\/commit\/ca617df135e78833f93c8320cb2d2cf8bba809f5'}",
            "dataset":"osv",
            "summary":"Inefficient Regular Expression Complexity in code-server code-server is vulnerable to Inefficient Regular Expression Complexity",
            "published_date":"2021-09-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/cdr\/code-server",
            "commit_href":"https:\/\/github.com\/cdr\/code-server\/commit\/ca617df135e78833f93c8320cb2d2cf8bba809f5",
            "commit_sha":"ca617df135e78833f93c8320cb2d2cf8bba809f5",
            "patch":"SINGLE",
            "chain_ord":"['ca617df135e78833f93c8320cb2d2cf8bba809f5']",
            "before_first_fix_commit":"{'bc3acb071e5393944627e16b2b54dc296a17d2d6'}",
            "last_fix_commit":"ca617df135e78833f93c8320cb2d2cf8bba809f5",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/11\/2021, 13:10:47",
            "message":"[Security] Fix ReDoS\n\nFix potential ReDoS",
            "author":"ready-research",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/node\/util.ts': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/coder\/code-server\/raw\/ca617df135e78833f93c8320cb2d2cf8bba809f5\/src%2Fnode%2Futil.ts', 'patch': '@@ -20,7 +20,7 @@ export interface Paths {\\n \\n \/\/ From https:\/\/github.com\/chalk\/ansi-regex\\n const pattern = [\\n-  \"[\\\\\\\\u001B\\\\\\\\u009B][[\\\\\\\\]()#;?]*(?:(?:(?:[a-zA-Z\\\\\\\\d]*(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\\/#&.:=?%@~_]*)*)?\\\\\\\\u0007)\",\\n+  \"[\\\\\\\\u001B\\\\\\\\u009B][[\\\\\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\\\\\d]+(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\\/#&.:=?%@~_]*)*)?\\\\\\\\u0007)\",\\n   \"(?:(?:\\\\\\\\d{1,4}(?:;\\\\\\\\d{0,4})*)?[\\\\\\\\dA-PR-TZcf-ntqry=><~]))\",\\n ].join(\"|\")\\n const re = new RegExp(pattern, \"g\")'}}",
            "message_norm":"[security] fix redos\n\nfix potential redos",
            "language":"es",
            "entities":"[('security', 'SECWORD', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/node\/util.ts'])",
            "num_files":1.0,
            "patch_content":"From ca617df135e78833f93c8320cb2d2cf8bba809f5 Mon Sep 17 00:00:00 2001\nFrom: ready-research <72916209+ready-research@users.noreply.github.com>\nDate: Sat, 11 Sep 2021 18:40:47 +0530\nSubject: [PATCH] [Security] Fix ReDoS\n\nFix potential ReDoS\n---\n src\/node\/util.ts | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/node\/util.ts b\/src\/node\/util.ts\nindex 1216601efc95..61e410be5256 100644\n--- a\/src\/node\/util.ts\n+++ b\/src\/node\/util.ts\n@@ -20,7 +20,7 @@ export interface Paths {\n \n \/\/ From https:\/\/github.com\/chalk\/ansi-regex\n const pattern = [\n-  \"[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:(?:[a-zA-Z\\\\d]*(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]*)*)?\\\\u0007)\",\n+  \"[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]*)*)?\\\\u0007)\",\n   \"(?:(?:\\\\d{1,4}(?:;\\\\d{0,4})*)?[\\\\dA-PR-TZcf-ntqry=><~]))\",\n ].join(\"|\")\n const re = new RegExp(pattern, \"g\")"
        },
        {
            "index":442,
            "vuln_id":"GHSA-jxwx-85vp-gvwm",
            "cwe_id":"{'CWE-400'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/jquery-validation\/jquery-validation\/commit\/5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in jquery-validation The GitHub Security Lab team has identified potential security vulnerabilities in jquery.validation.\n\nThe project contains one or more regular expressions that are vulnerable to ReDoS (Regular Expression Denial of Service)\n\nThis issue was discovered and reported by GitHub team member @erik-krogh (Erik Krogh Kristensen).",
            "published_date":"2021-01-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/jquery-validation\/jquery-validation",
            "commit_href":"https:\/\/github.com\/jquery-validation\/jquery-validation\/commit\/5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d",
            "commit_sha":"5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d",
            "patch":"SINGLE",
            "chain_ord":"['5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d']",
            "before_first_fix_commit":"{'b8d6646ec67c73372dddfbc9aadff45571a96136'}",
            "last_fix_commit":"5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/09\/2021, 15:28:00",
            "message":"Core: fixed Regular Expression Denial of Service vulnerability (#2371)\n\nReDoS, or Regular Expression Denial of Service, is a vulnerability affecting\r\npoorly constructed and potentially inefficient regular expressions which can\r\nmake them perform extremely badly given a creatively constructed input string.\r\n\r\nGHSL-2020-294\r\n\r\ncredits to @erik-krogh for reporting the issue and providing a fix",
            "author":"Markus Staab",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/core.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jquery-validation\/jquery-validation\/raw\/5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d\/src%2Fcore.js', 'patch': '@@ -1412,7 +1412,7 @@ $.extend( $.validator, {\\n \\t\\t\\t\/\/ https:\/\/gist.github.com\/dperini\/729294\\n \\t\\t\\t\/\/ see also https:\/\/mathiasbynens.be\/demo\/url-regex\\n \\t\\t\\t\/\/ modified to allow protocol-relative URLs\\n-\\t\\t\\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:\\\\S+(?::\\\\S*)?@)?(?:(?!(?:10|127)(?:\\\\.\\\\d{1,3}){3})(?!(?:169\\\\.254|192\\\\.168)(?:\\\\.\\\\d{1,3}){2})(?!172\\\\.(?:1[6-9]|2\\\\d|3[0-1])(?:\\\\.\\\\d{1,3}){2})(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)*(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,})).?)(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i.test( value );\\n+\\t\\t\\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:\\\\S+(?::\\\\S*)?@)?(?:(?!(?:10|127)(?:\\\\.\\\\d{1,3}){3})(?!(?:169\\\\.254|192\\\\.168)(?:\\\\.\\\\d{1,3}){2})(?!172\\\\.(?:1[6-9]|2\\\\d|3[0-1])(?:\\\\.\\\\d{1,3}){2})(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z0-9\\\\u00a1-\\\\uffff][a-z0-9\\\\u00a1-\\\\uffff_-]{0,62})?[a-z0-9\\\\u00a1-\\\\uffff]\\\\.)+(?:[a-z\\\\u00a1-\\\\uffff]{2,}\\\\.?))(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i.test( value );\\n \\t\\t},\\n \\n \\t\\t\/\/ https:\/\/jqueryvalidation.org\/date-method\/'}}",
            "message_norm":"core: fixed regular expression denial of service vulnerability (#2371)\n\nredos, or regular expression denial of service, is a vulnerability affecting\r\npoorly constructed and potentially inefficient regular expressions which can\r\nmake them perform extremely badly given a creatively constructed input string.\r\n\r\nghsl-2020-294\r\n\r\ncredits to @erik-krogh for reporting the issue and providing a fix",
            "language":"en",
            "entities":"[('fixed', 'ACTION', ''), ('denial of service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('#2371', 'ISSUE', ''), ('redos', 'SECWORD', ''), ('denial of service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/core.js'])",
            "num_files":1.0,
            "patch_content":"From 5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d Mon Sep 17 00:00:00 2001\nFrom: Markus Staab <markus.staab@redaxo.de>\nDate: Sat, 9 Jan 2021 16:28:00 +0100\nSubject: [PATCH] Core: fixed Regular Expression Denial of Service\n vulnerability (#2371)\n\nReDoS, or Regular Expression Denial of Service, is a vulnerability affecting\npoorly constructed and potentially inefficient regular expressions which can\nmake them perform extremely badly given a creatively constructed input string.\n\nGHSL-2020-294\n\ncredits to @erik-krogh for reporting the issue and providing a fix\n---\n src\/core.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/core.js b\/src\/core.js\nindex 4674710f4..afcdbe820 100644\n--- a\/src\/core.js\n+++ b\/src\/core.js\n@@ -1412,7 +1412,7 @@ $.extend( $.validator, {\n \t\t\t\/\/ https:\/\/gist.github.com\/dperini\/729294\n \t\t\t\/\/ see also https:\/\/mathiasbynens.be\/demo\/url-regex\n \t\t\t\/\/ modified to allow protocol-relative URLs\n-\t\t\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:\\S+(?::\\S*)?@)?(?:(?!(?:10|127)(?:\\.\\d{1,3}){3})(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*(?:\\.(?:[a-z\\u00a1-\\uffff]{2,})).?)(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test( value );\n+\t\t\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:\\S+(?::\\S*)?@)?(?:(?!(?:10|127)(?:\\.\\d{1,3}){3})(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z0-9\\u00a1-\\uffff][a-z0-9\\u00a1-\\uffff_-]{0,62})?[a-z0-9\\u00a1-\\uffff]\\.)+(?:[a-z\\u00a1-\\uffff]{2,}\\.?))(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test( value );\n \t\t},\n \n \t\t\/\/ https:\/\/jqueryvalidation.org\/date-method\/"
        },
        {
            "index":287,
            "vuln_id":"GHSA-vxhc-c4qm-647p",
            "cwe_id":"{'CWE-284', 'CWE-863'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/Dolibarr\/dolibarr\/commit\/8cc100012d46282799fb19f735a53b7101569377'}",
            "dataset":"osv",
            "summary":"Improper Access Control in Dolibarr In \u201cDolibarr\u201d application, 2.8.1 to 13.0.4 don\u2019t restrict or incorrectly restricts access to a resource from an unauthorized actor. A low privileged attacker can modify the Private Note which only an administrator has rights to do, the affected field is at \u201c\/adherents\/note.php?id=1\u201d endpoint.",
            "published_date":"2021-08-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/Dolibarr\/dolibarr",
            "commit_href":"https:\/\/github.com\/Dolibarr\/dolibarr\/commit\/8cc100012d46282799fb19f735a53b7101569377",
            "commit_sha":"8cc100012d46282799fb19f735a53b7101569377",
            "patch":"SINGLE",
            "chain_ord":"['8cc100012d46282799fb19f735a53b7101569377']",
            "before_first_fix_commit":"{'0271645d8efd5815bbb2d8750c76e8b27ee974be'}",
            "last_fix_commit":"8cc100012d46282799fb19f735a53b7101569377",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/09\/2021, 10:50:46",
            "message":"Fix vulnerabiity: External users can set a public note",
            "author":"Laurent Destailleur",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 11, 'total': 24}",
            "files":"{'htdocs\/core\/actions_setnotes.inc.php': {'additions': 13, 'deletions': 11, 'changes': 24, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Dolibarr\/dolibarr\/raw\/8cc100012d46282799fb19f735a53b7101569377\/htdocs%2Fcore%2Factions_setnotes.inc.php', 'patch': \"@@ -67,16 +67,18 @@\\n \\t\\t\\t}\\n \\t\\t}\\n \\t}\\n-} elseif ($action == 'setnote_private' && !empty($permissionnote) && !GETPOST('cancel', 'alpha')) {\\n-\\t\/\/ Set public note\\n-\\tif (empty($action) || !is_object($object) || empty($id)) {\\n-\\t\\tdol_print_error('', 'Include of actions_setnotes.inc.php was done but required variable was not set before');\\n-\\t}\\n-\\tif (empty($object->id)) {\\n-\\t\\t$object->fetch($id); \/\/ Fetch may not be already done\\n-\\t}\\n-\\t$result = $object->update_note(dol_html_entity_decode(GETPOST('note_private', 'restricthtml'), ENT_QUOTES | ENT_HTML5), '_private');\\n-\\tif ($result < 0) {\\n-\\t\\tsetEventMessages($object->error, $object->errors, 'errors');\\n+} elseif ($action == 'setnote_private' && !empty($permissionnote) && !GETPOST('cancel', 'alpha')) {\\t\/\/ Set public note\\n+\\tif (empty($user->socid)) {\\n+\\t\\t\/\/ Private notes (always hidden to external users)\\n+\\t\\tif (empty($action) || !is_object($object) || empty($id)) {\\n+\\t\\t\\tdol_print_error('', 'Include of actions_setnotes.inc.php was done but required variable was not set before');\\n+\\t\\t}\\n+\\t\\tif (empty($object->id)) {\\n+\\t\\t\\t$object->fetch($id); \/\/ Fetch may not be already done\\n+\\t\\t}\\n+\\t\\t$result = $object->update_note(dol_html_entity_decode(GETPOST('note_private', 'restricthtml'), ENT_QUOTES | ENT_HTML5), '_private');\\n+\\t\\tif ($result < 0) {\\n+\\t\\t\\tsetEventMessages($object->error, $object->errors, 'errors');\\n+\\t\\t}\\n \\t}\\n }\"}}",
            "message_norm":"fix vulnerabiity: external users can set a public note",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('vulnerabiity', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['htdocs\/core\/actions_setnotes.inc.php'])",
            "num_files":1.0,
            "patch_content":"From 8cc100012d46282799fb19f735a53b7101569377 Mon Sep 17 00:00:00 2001\nFrom: Laurent Destailleur <eldy@destailleur.fr>\nDate: Sun, 9 May 2021 12:50:46 +0200\nSubject: [PATCH] Fix vulnerabiity: External users can set a public note\n\n---\n htdocs\/core\/actions_setnotes.inc.php | 24 +++++++++++++-----------\n 1 file changed, 13 insertions(+), 11 deletions(-)\n\ndiff --git a\/htdocs\/core\/actions_setnotes.inc.php b\/htdocs\/core\/actions_setnotes.inc.php\nindex f2426f6523f01..91e7f4a8aca2b 100644\n--- a\/htdocs\/core\/actions_setnotes.inc.php\n+++ b\/htdocs\/core\/actions_setnotes.inc.php\n@@ -67,16 +67,18 @@\n \t\t\t}\n \t\t}\n \t}\n-} elseif ($action == 'setnote_private' && !empty($permissionnote) && !GETPOST('cancel', 'alpha')) {\n-\t\/\/ Set public note\n-\tif (empty($action) || !is_object($object) || empty($id)) {\n-\t\tdol_print_error('', 'Include of actions_setnotes.inc.php was done but required variable was not set before');\n-\t}\n-\tif (empty($object->id)) {\n-\t\t$object->fetch($id); \/\/ Fetch may not be already done\n-\t}\n-\t$result = $object->update_note(dol_html_entity_decode(GETPOST('note_private', 'restricthtml'), ENT_QUOTES | ENT_HTML5), '_private');\n-\tif ($result < 0) {\n-\t\tsetEventMessages($object->error, $object->errors, 'errors');\n+} elseif ($action == 'setnote_private' && !empty($permissionnote) && !GETPOST('cancel', 'alpha')) {\t\/\/ Set public note\n+\tif (empty($user->socid)) {\n+\t\t\/\/ Private notes (always hidden to external users)\n+\t\tif (empty($action) || !is_object($object) || empty($id)) {\n+\t\t\tdol_print_error('', 'Include of actions_setnotes.inc.php was done but required variable was not set before');\n+\t\t}\n+\t\tif (empty($object->id)) {\n+\t\t\t$object->fetch($id); \/\/ Fetch may not be already done\n+\t\t}\n+\t\t$result = $object->update_note(dol_html_entity_decode(GETPOST('note_private', 'restricthtml'), ENT_QUOTES | ENT_HTML5), '_private');\n+\t\tif ($result < 0) {\n+\t\t\tsetEventMessages($object->error, $object->errors, 'errors');\n+\t\t}\n \t}\n }"
        },
        {
            "index":932,
            "vuln_id":"GHSA-mq5c-prh3-3f3h",
            "cwe_id":"{'CWE-665'}",
            "score":3.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9'}",
            "dataset":"osv",
            "summary":"Invalid validation in `QuantizeAndDequantizeV2` ### Impact\nThe validation in `tf.raw_ops.QuantizeAndDequantizeV2` allows invalid values for `axis` argument:\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([0.0], shape=[1], dtype=float)\ninput_min = tf.constant(-10.0)\ninput_max = tf.constant(-10.0)\n\ntf.raw_ops.QuantizeAndDequantizeV2(\n  input=input_tensor, input_min=input_min, input_max=input_max,\n  signed_input=False, num_bits=1, range_given=False, round_mode='HALF_TO_EVEN',\n  narrow_range=False, axis=-2)\n``` \n\nThe [validation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc#L74-L77) uses `||` to mix two different conditions:\n\n```cc\nOP_REQUIRES(ctx,\n  (axis_ == -1 || axis_ < input.shape().dims()),\n  errors::InvalidArgument(...));\n```\n\nIf `axis_ < -1` the condition in `OP_REQUIRES` will still be true, but this value of `axis_` results in heap underflow. This allows attackers to read\/write to other data on the heap.\n\n### Patches\nWe have patched the issue in GitHub commit [c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9",
            "commit_sha":"c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9",
            "patch":"SINGLE",
            "chain_ord":"['c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9']",
            "before_first_fix_commit":"{'ab6fafc1e32fb20855b7f3a642e36cb08aedbbbf'}",
            "last_fix_commit":"c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/30\/2021, 17:39:05",
            "message":"Fix the CHECK failure in tf.raw_ops.QuantizeAndDequantizeV2.\n\nPiperOrigin-RevId: 371361603\nChange-Id: Ia70e34d41adaadddf928e95e5e5c5c97d5bc60d0",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9\/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -72,6 +72,9 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& input = ctx->input(0);\\n+    OP_REQUIRES(\\n+        ctx, axis_ >= -1,\\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\\n     OP_REQUIRES(\\n         ctx, (axis_ == -1 || axis_ < input.shape().dims()),\\n         errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,'}}",
            "message_norm":"fix the check failure in tf.raw_ops.quantizeanddequantizev2.\n\npiperorigin-revid: 371361603\nchange-id: ia70e34d41adaadddf928e95e5e5c5c97d5bc60d0",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('371361603', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc'])",
            "num_files":1.0,
            "patch_content":"From c5b0d5f8ac19888e46ca14b0e27562e7fbbee9a9 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Fri, 30 Apr 2021 10:39:05 -0700\nSubject: [PATCH] Fix the CHECK failure in tf.raw_ops.QuantizeAndDequantizeV2.\n\nPiperOrigin-RevId: 371361603\nChange-Id: Ia70e34d41adaadddf928e95e5e5c5c97d5bc60d0\n---\n tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\nindex f01a70114591bf..540d900f9f8696 100644\n--- a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n@@ -72,6 +72,9 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(\n+        ctx, axis_ >= -1,\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n     OP_REQUIRES(\n         ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n         errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,"
        },
        {
            "index":551,
            "vuln_id":"GHSA-84mw-34w6-2q43",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b055b9c474cd376259dde8779908f9eeaf097d93'}",
            "dataset":"osv",
            "summary":"Null pointer dereference via invalid Ragged Tensors ### Impact\nCalling `tf.raw_ops.RaggedTensorToVariant` with arguments specifying an invalid ragged tensor results in a null pointer dereference:\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 56, 56, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 23, 1])\n```\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 39, 34, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])\n```\n\nThe implementation of [`RaggedTensorToVariant` operations](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/904b3926ed1c6c70380d5313d282d248a776baa1\/tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc#L39-L40) does not validate that the ragged tensor argument is non-empty:\n\n```cc\n  int ragged_rank = batched_ragged.ragged_rank();\n  auto batched_splits_top_vec = batched_ragged.splits(0).vec<SPLIT_TYPE>();\n```\n\nSince `batched_ragged` contains no elements, `batched_ragged.splits` is a null vector, thus `batched_ragged.splits(0)` will result in  dereferencing `nullptr`.\n\n### Patches\nWe have patched the issue in GitHub commit [b055b9c474cd376259dde8779908f9eeaf097d93](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b055b9c474cd376259dde8779908f9eeaf097d93).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b055b9c474cd376259dde8779908f9eeaf097d93",
            "commit_sha":"b055b9c474cd376259dde8779908f9eeaf097d93",
            "patch":"SINGLE",
            "chain_ord":"['b055b9c474cd376259dde8779908f9eeaf097d93']",
            "before_first_fix_commit":"{'904b3926ed1c6c70380d5313d282d248a776baa1'}",
            "last_fix_commit":"b055b9c474cd376259dde8779908f9eeaf097d93",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2021, 21:49:50",
            "message":"Fix `tf.raw_ops.RaggedTensorToVariant` invalid resize.\n\nPiperOrigin-RevId: 368299574\nChange-Id: I751c186325aa0bab397928845e790e60c2d90918",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b055b9c474cd376259dde8779908f9eeaf097d93\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_variant_op.cc', 'patch': '@@ -159,6 +159,11 @@ class RaggedTensorToVariantOp : public OpKernel {\\n \\n     \/\/ Unbatch the Ragged Tensor and encode the components.\\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\\n+    auto batched_splits_top_vec =\\n+        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\\n+    int num_components = batched_splits_top_vec.size() - 1;\\n+    OP_REQUIRES(context, num_components >= 0,\\n+                errors::Internal(\"Invalid split argument.\"));\\n     OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\\n                                 batched_ragged_input, &unbatched_ragged_input));'}}",
            "message_norm":"fix `tf.raw_ops.raggedtensortovariant` invalid resize.\n\npiperorigin-revid: 368299574\nchange-id: i751c186325aa0bab397928845e790e60c2d90918",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('368299574', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc'])",
            "num_files":1.0,
            "patch_content":"From b055b9c474cd376259dde8779908f9eeaf097d93 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Tue, 13 Apr 2021 14:49:50 -0700\nSubject: [PATCH] Fix `tf.raw_ops.RaggedTensorToVariant` invalid resize.\n\nPiperOrigin-RevId: 368299574\nChange-Id: I751c186325aa0bab397928845e790e60c2d90918\n---\n tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc b\/tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc\nindex 549dc68dfbf87c..687289cd38077a 100644\n--- a\/tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc\n+++ b\/tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc\n@@ -159,6 +159,11 @@ class RaggedTensorToVariantOp : public OpKernel {\n \n     \/\/ Unbatch the Ragged Tensor and encode the components.\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\n+    auto batched_splits_top_vec =\n+        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\n+    int num_components = batched_splits_top_vec.size() - 1;\n+    OP_REQUIRES(context, num_components >= 0,\n+                errors::Internal(\"Invalid split argument.\"));\n     OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\n                                 batched_ragged_input, &unbatched_ragged_input));"
        },
        {
            "index":65,
            "vuln_id":"GHSA-mq35-wqvf-r23c",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/sinatra\/sinatra\/commit\/12786867d6faaceaec62c7c2cb5b0e2dc074d71a'}",
            "dataset":"osv",
            "summary":"Sinatra has XSS via 400 Bad Request page via params parser exception Sinatra before 2.0.2 has XSS via the 400 Bad Request page that occurs upon a params parser exception.",
            "published_date":"2018-06-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/sinatra\/sinatra",
            "commit_href":"https:\/\/github.com\/sinatra\/sinatra\/commit\/12786867d6faaceaec62c7c2cb5b0e2dc074d71a",
            "commit_sha":"12786867d6faaceaec62c7c2cb5b0e2dc074d71a",
            "patch":"SINGLE",
            "chain_ord":"['12786867d6faaceaec62c7c2cb5b0e2dc074d71a']",
            "before_first_fix_commit":"{'5149dc9e0b0e281231b91223c6a414c905ad3a96'}",
            "last_fix_commit":"12786867d6faaceaec62c7c2cb5b0e2dc074d71a",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/30\/2018, 16:05:27",
            "message":"escape invalid query params, fixes #1428",
            "author":"Kunpei Sakai",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/sinatra\/base.rb': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sinatra\/sinatra\/raw\/12786867d6faaceaec62c7c2cb5b0e2dc074d71a\/lib%2Fsinatra%2Fbase.rb', 'patch': '@@ -78,7 +78,7 @@ def unlink?\\n     def params\\n       super\\n     rescue Rack::Utils::ParameterTypeError, Rack::Utils::InvalidParameterError => e\\n-      raise BadRequest, \"Invalid query parameters: #{e.message}\"\\n+      raise BadRequest, \"Invalid query parameters: #{Rack::Utils.escape_html(e.message)}\"\\n     end\\n \\n     private'}}",
            "message_norm":"escape invalid query params, fixes #1428",
            "language":"ca",
            "entities":"[('escape', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#1428', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/sinatra\/base.rb'])",
            "num_files":1.0,
            "patch_content":"From 12786867d6faaceaec62c7c2cb5b0e2dc074d71a Mon Sep 17 00:00:00 2001\nFrom: Kunpei Sakai <namusyaka@gmail.com>\nDate: Thu, 31 May 2018 01:05:27 +0900\nSubject: [PATCH] escape invalid query params, fixes #1428\n\n---\n lib\/sinatra\/base.rb | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/sinatra\/base.rb b\/lib\/sinatra\/base.rb\nindex 6843b4d375..727078d815 100644\n--- a\/lib\/sinatra\/base.rb\n+++ b\/lib\/sinatra\/base.rb\n@@ -78,7 +78,7 @@ def unlink?\n     def params\n       super\n     rescue Rack::Utils::ParameterTypeError, Rack::Utils::InvalidParameterError => e\n-      raise BadRequest, \"Invalid query parameters: #{e.message}\"\n+      raise BadRequest, \"Invalid query parameters: #{Rack::Utils.escape_html(e.message)}\"\n     end\n \n     private"
        },
        {
            "index":181,
            "vuln_id":"GHSA-mmhj-4w6j-76h7",
            "cwe_id":"{'CWE-913'}",
            "score":8.0,
            "chain":"{'https:\/\/github.com\/laverdet\/isolated-vm\/commit\/2646e6c1558bac66285daeab54c7d490ed332b15', 'https:\/\/github.com\/laverdet\/isolated-vm\/commit\/27151bfecc260e96714443613880e3b2e6596704'}",
            "dataset":"osv",
            "summary":"Misuse of `Reference` and other transferable APIs may lead to access to nodejs isolate Versions of `isolated-vm` before v4.0.0, and especially before v3.0.0, have API pitfalls which may make it easy for implementers to expose supposed secure isolates to the permissions of the main nodejs isolate.\n\n`Reference` objects allow access to the underlying reference's full prototype chain. In an environment where the implementer has exposed a `Reference` instance to an attacker they would be able to use it to acquire a `Reference` to the nodejs context's `Function` object.\n\nSimilar application-specific attacks could be possible by modifying the local prototype of other API objects.\n\nAccess to `NativeModule` objects could allow an attacker to load and run native code from anywhere on the filesystem. If combined with, for example, a file upload API this would allow for arbitrary code execution.\n\nTo address these issues the following changes were made in v4.0.0:\n- Documentation was updated with more explicit guidelines on building secure applications.\n- `Reference` instances will no longer follow prototype chains by default, nor will they invoke accessors or proxies.\n- All `isolated-vm` API prototypes are now immutable.\n- `NativeModule` constructor may only be invoked from a nodejs isolate.",
            "published_date":"2021-04-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/laverdet\/isolated-vm",
            "commit_href":"https:\/\/github.com\/laverdet\/isolated-vm\/commit\/27151bfecc260e96714443613880e3b2e6596704",
            "commit_sha":"27151bfecc260e96714443613880e3b2e6596704",
            "patch":"MULTI",
            "chain_ord":"['27151bfecc260e96714443613880e3b2e6596704', '2646e6c1558bac66285daeab54c7d490ed332b15']",
            "before_first_fix_commit":"{'3a2408a2b42ac51c64a6c10f9388a6f7cc311156'}",
            "last_fix_commit":"2646e6c1558bac66285daeab54c7d490ed332b15",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/18\/2021, 20:20:24",
            "message":"Disallow NativeModule creation unless main isolate",
            "author":"Marcel Laverdet",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'src\/module\/native_module_handle.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/laverdet\/isolated-vm\/raw\/27151bfecc260e96714443613880e3b2e6596704\/src%2Fmodule%2Fnative_module_handle.cc', 'patch': '@@ -15,6 +15,9 @@ namespace ivm {\\n  * RAII wrapper around libuv dlopen\\n  *\/\\n NativeModule::NativeModule(const std::string& filename) : init(nullptr) {\\n+\\tif (!IsolateEnvironment::GetCurrent()->IsDefault()) {\\n+\\t\\tthrow RuntimeGenericError(\"NativeModule may only be instantiated from default nodejs isolate\");\\n+\\t}\\n \\tif (uv_dlopen(filename.c_str(), &lib) != 0) {\\n \\t\\tthrow RuntimeGenericError(\"Failed to load module\");\\n \\t}'}}",
            "message_norm":"disallow nativemodule creation unless main isolate",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/module\/native_module_handle.cc'])",
            "num_files":1.0,
            "patch_content":"From 27151bfecc260e96714443613880e3b2e6596704 Mon Sep 17 00:00:00 2001\nFrom: Marcel Laverdet <marcel@laverdet.com>\nDate: Thu, 18 Mar 2021 15:20:24 -0500\nSubject: [PATCH] Disallow NativeModule creation unless main isolate\n\n---\n src\/module\/native_module_handle.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/src\/module\/native_module_handle.cc b\/src\/module\/native_module_handle.cc\nindex 895044ac..1802c49a 100644\n--- a\/src\/module\/native_module_handle.cc\n+++ b\/src\/module\/native_module_handle.cc\n@@ -15,6 +15,9 @@ namespace ivm {\n  * RAII wrapper around libuv dlopen\n  *\/\n NativeModule::NativeModule(const std::string& filename) : init(nullptr) {\n+\tif (!IsolateEnvironment::GetCurrent()->IsDefault()) {\n+\t\tthrow RuntimeGenericError(\"NativeModule may only be instantiated from default nodejs isolate\");\n+\t}\n \tif (uv_dlopen(filename.c_str(), &lib) != 0) {\n \t\tthrow RuntimeGenericError(\"Failed to load module\");\n \t}"
        },
        {
            "index":362,
            "vuln_id":"GHSA-8v99-48m9-c8pm",
            "cwe_id":"{'CWE-863'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/containerd\/imgcrypt\/commit\/6fdd9818a4d8142107b7ecd767d839c9707700d9'}",
            "dataset":"osv",
            "summary":"Incorrect Authorization in imgcrypt Imgcrypt implements a function `CheckAuthorization()` that is supposed to check whether a user is authorized to access an encrypted image given the keys that the user has provided on the command line that would enable decryption of the image. The check is to prevent that a user can start a container from an image that has previously been decrypted by another user on the same system and therefore a decrypted version of the image layers may be already available in the cache locally.\n\nThe failure occurs when an image with a ManifestList is used and the architecture of the local host is not the first one in the ManifestList. In the version prior to the fix, only the first architecture in the list was tested, which may not have its layers available locally (were not pulled) since it cannot be run on the host architecture. Therefore, the verdict on unavailable layers was that the image could be run anticipating that image run failure would occur later due to the layers not being available. However, this verdict to allow the image to run lead to other architectures in the ManifestList be able to run an image without providing keys if that image had previously been decrypted. The fixed version now skips over irrelevant architectures and tests the Manifest of the local architecture, if available.\n\nKnown projects that use the `CheckAuthorization()` of imgcrypt is for example the ctr-enc client tool provided by imgcrypt. In this implementation, the call to `CheckAuthorization()` is used on the client side and could therefore also be easily circumvented by a modified client tool not calling this function.\n\nIn relation to the vulnerability in ctr-enc, affected environments would have to allow different users to invoke ctr-enc indirectly using some sort of management stack that gives user indirect access to ctr-enc.\n\nThe patch has been applied to imgcrypt v1.1.4. Workarounds may include usage of different namespaces for each remote user.",
            "published_date":"2022-03-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/containerd\/imgcrypt",
            "commit_href":"https:\/\/github.com\/containerd\/imgcrypt\/commit\/6fdd9818a4d8142107b7ecd767d839c9707700d9",
            "commit_sha":"6fdd9818a4d8142107b7ecd767d839c9707700d9",
            "patch":"SINGLE",
            "chain_ord":"['6fdd9818a4d8142107b7ecd767d839c9707700d9']",
            "before_first_fix_commit":"{'f4400580b658c1fcb3cacc52dfb6104ea3c3aa82'}",
            "last_fix_commit":"6fdd9818a4d8142107b7ecd767d839c9707700d9",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/17\/2022, 19:52:56",
            "message":"images: Add list of Platforms to CheckAuthorization()\n\nTo be able to properly perform an authorization check on an image we need\nto know the platform to perform check when in cryptManifestList(). Extend\nthe logic for cryptoOp == cryptoOpUnwrapOnly to skip over manifests that\ndo not correspond to the local platform and return an error if no manifest\nwas found that matches the local platform.\n\nThe following projects seem NOT to be affect due to the change in the code\npath of CheckAuthorization() since they are not using it:\n\n- cri-o\n- nerdctl\n- skopeo\n- buildah\n- podman\n\nThe impact on imgcrypt via ctr-enc is not so clear either since\nCheckAuthorization() is not called on the server side but by the ctr-enc\nclient, thus can be modified easily.\n\nResolves: https:\/\/github.com\/containerd\/imgcrypt\/issues\/69\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
            "author":"Stefan Berger",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
            "files":"{'images\/encryption\/encryption.go': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/containerd\/imgcrypt\/raw\/6fdd9818a4d8142107b7ecd767d839c9707700d9\/images%2Fencryption%2Fencryption.go', 'patch': '@@ -50,6 +50,13 @@ const (\\n \/\/ LayerFilter allows to select Layers by certain criteria\\n type LayerFilter func(desc ocispec.Descriptor) bool\\n \\n+\/\/ isLocalPlatform determines whether the given platform matches the local one\\n+func isLocalPlatform(platform *ocispec.Platform) bool {\\n+\\tmatcher := platforms.NewMatcher(*platform)\\n+\\n+\\treturn matcher.Match(platforms.DefaultSpec())\\n+}\\n+\\n \/\/ IsEncryptedDiff returns true if mediaType is a known encrypted media type.\\n func IsEncryptedDiff(ctx context.Context, mediaType string) bool {\\n \\tswitch mediaType {\\n@@ -380,6 +387,9 @@ func cryptManifestList(ctx context.Context, cs content.Store, desc ocispec.Descr\\n \\tvar newManifests []ocispec.Descriptor\\n \\tmodified := false\\n \\tfor _, manifest := range index.Manifests {\\n+\\t\\tif cryptoOp == cryptoOpUnwrapOnly && !isLocalPlatform(manifest.Platform) {\\n+\\t\\t\\tcontinue\\n+\\t\\t}\\n \\t\\tnewManifest, m, err := cryptChildren(ctx, cs, manifest, cc, lf, cryptoOp, manifest.Platform)\\n \\t\\tif err != nil || cryptoOp == cryptoOpUnwrapOnly {\\n \\t\\t\\treturn ocispec.Descriptor{}, false, err\\n@@ -389,6 +399,9 @@ func cryptManifestList(ctx context.Context, cs content.Store, desc ocispec.Descr\\n \\t\\t}\\n \\t\\tnewManifests = append(newManifests, newManifest)\\n \\t}\\n+\\tif cryptoOp == cryptoOpUnwrapOnly {\\n+\\t\\treturn ocispec.Descriptor{}, false, fmt.Errorf(\"No manifest found for local platform\")\\n+\\t}\\n \\n \\tif modified {\\n \\t\\t\/\/ we need to update the index'}}",
            "message_norm":"images: add list of platforms to checkauthorization()\n\nto be able to properly perform an authorization check on an image we need\nto know the platform to perform check when in cryptmanifestlist(). extend\nthe logic for cryptoop == cryptoopunwraponly to skip over manifests that\ndo not correspond to the local platform and return an error if no manifest\nwas found that matches the local platform.\n\nthe following projects seem not to be affect due to the change in the code\npath of checkauthorization() since they are not using it:\n\n- cri-o\n- nerdctl\n- skopeo\n- buildah\n- podman\n\nthe impact on imgcrypt via ctr-enc is not so clear either since\ncheckauthorization() is not called on the server side but by the ctr-enc\nclient, thus can be modified easily.\n\nresolves: https:\/\/github.com\/containerd\/imgcrypt\/issues\/69\nsigned-off-by: stefan berger <stefanb@linux.ibm.com>",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('cryptoop', 'SECWORD', ''), ('cryptoopunwraponly', 'SECWORD', ''), ('error', 'FLAW', ''), ('found', 'ACTION', ''), ('server', 'SECWORD', ''), ('https:\/\/github.com\/containerd\/imgcrypt\/issues\/69', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['images\/encryption\/encryption.go'])",
            "num_files":1.0,
            "patch_content":"From 6fdd9818a4d8142107b7ecd767d839c9707700d9 Mon Sep 17 00:00:00 2001\nFrom: Stefan Berger <stefanb@linux.ibm.com>\nDate: Thu, 17 Mar 2022 15:52:56 -0400\nSubject: [PATCH] images: Add list of Platforms to CheckAuthorization()\n\nTo be able to properly perform an authorization check on an image we need\nto know the platform to perform check when in cryptManifestList(). Extend\nthe logic for cryptoOp == cryptoOpUnwrapOnly to skip over manifests that\ndo not correspond to the local platform and return an error if no manifest\nwas found that matches the local platform.\n\nThe following projects seem NOT to be affect due to the change in the code\npath of CheckAuthorization() since they are not using it:\n\n- cri-o\n- nerdctl\n- skopeo\n- buildah\n- podman\n\nThe impact on imgcrypt via ctr-enc is not so clear either since\nCheckAuthorization() is not called on the server side but by the ctr-enc\nclient, thus can be modified easily.\n\nResolves: https:\/\/github.com\/containerd\/imgcrypt\/issues\/69\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>\n---\n images\/encryption\/encryption.go | 13 +++++++++++++\n 1 file changed, 13 insertions(+)\n\ndiff --git a\/images\/encryption\/encryption.go b\/images\/encryption\/encryption.go\nindex 204d32c0..291424d1 100644\n--- a\/images\/encryption\/encryption.go\n+++ b\/images\/encryption\/encryption.go\n@@ -50,6 +50,13 @@ const (\n \/\/ LayerFilter allows to select Layers by certain criteria\n type LayerFilter func(desc ocispec.Descriptor) bool\n \n+\/\/ isLocalPlatform determines whether the given platform matches the local one\n+func isLocalPlatform(platform *ocispec.Platform) bool {\n+\tmatcher := platforms.NewMatcher(*platform)\n+\n+\treturn matcher.Match(platforms.DefaultSpec())\n+}\n+\n \/\/ IsEncryptedDiff returns true if mediaType is a known encrypted media type.\n func IsEncryptedDiff(ctx context.Context, mediaType string) bool {\n \tswitch mediaType {\n@@ -380,6 +387,9 @@ func cryptManifestList(ctx context.Context, cs content.Store, desc ocispec.Descr\n \tvar newManifests []ocispec.Descriptor\n \tmodified := false\n \tfor _, manifest := range index.Manifests {\n+\t\tif cryptoOp == cryptoOpUnwrapOnly && !isLocalPlatform(manifest.Platform) {\n+\t\t\tcontinue\n+\t\t}\n \t\tnewManifest, m, err := cryptChildren(ctx, cs, manifest, cc, lf, cryptoOp, manifest.Platform)\n \t\tif err != nil || cryptoOp == cryptoOpUnwrapOnly {\n \t\t\treturn ocispec.Descriptor{}, false, err\n@@ -389,6 +399,9 @@ func cryptManifestList(ctx context.Context, cs content.Store, desc ocispec.Descr\n \t\t}\n \t\tnewManifests = append(newManifests, newManifest)\n \t}\n+\tif cryptoOp == cryptoOpUnwrapOnly {\n+\t\treturn ocispec.Descriptor{}, false, fmt.Errorf(\"No manifest found for local platform\")\n+\t}\n \n \tif modified {\n \t\t\/\/ we need to update the index"
        },
        {
            "index":576,
            "vuln_id":"GHSA-p885-prv3-m4xv",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/f211c11034baf4281aa62e7b5e0347248d995ee9'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in snipe-it Stored Cross Site Scripting vulnerability in Item name parameter in GitHub repository snipe\/snipe-it prior to v5.4.3. The vulnerability is capable of stolen the user Cookie.",
            "published_date":"2022-04-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/f211c11034baf4281aa62e7b5e0347248d995ee9",
            "commit_sha":"f211c11034baf4281aa62e7b5e0347248d995ee9",
            "patch":"SINGLE",
            "chain_ord":"['f211c11034baf4281aa62e7b5e0347248d995ee9']",
            "before_first_fix_commit":"{'698c7f4904f8fd843c5b9761053c9c68819ec288', '7479f5f12d73f73d9bc8c479651e0e5602ad1791'}",
            "last_fix_commit":"f211c11034baf4281aa62e7b5e0347248d995ee9",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/15\/2022, 11:25:56",
            "message":"Merge pull request #10942 from snipe\/fixes\/xss_user_requested\n\nFixes potential XSS vuln in user requestable results",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 5, 'total': 10}",
            "files":"{'app\/Http\/Controllers\/Api\/ProfileController.php': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/f211c11034baf4281aa62e7b5e0347248d995ee9\/app%2FHttp%2FControllers%2FApi%2FProfileController.php', 'patch': \"@@ -30,11 +30,11 @@ public function requestedAssets()\\n             \/\/ Make sure the asset and request still exist\\n             if ($checkoutRequest && $checkoutRequest->itemRequested()) {\\n                 $results['rows'][] = [\\n-                    'image' => $checkoutRequest->itemRequested()->present()->getImageUrl(),\\n-                    'name' => $checkoutRequest->itemRequested()->present()->name(),\\n-                    'type' => $checkoutRequest->itemType(),\\n-                    'qty' => $checkoutRequest->quantity,\\n-                    'location' => ($checkoutRequest->location()) ? $checkoutRequest->location()->name : null,\\n+                    'image' => e($checkoutRequest->itemRequested()->present()->getImageUrl()),\\n+                    'name' => e($checkoutRequest->itemRequested()->present()->name()),\\n+                    'type' => e($checkoutRequest->itemType()),\\n+                    'qty' => (int) $checkoutRequest->quantity,\\n+                    'location' => ($checkoutRequest->location()) ? e($checkoutRequest->location()->name) : null,\\n                     'expected_checkin' => Helper::getFormattedDateObject($checkoutRequest->itemRequested()->expected_checkin, 'datetime'),\\n                     'request_date' => Helper::getFormattedDateObject($checkoutRequest->created_at, 'datetime'),\\n                 ];\"}}",
            "message_norm":"merge pull request #10942 from snipe\/fixes\/xss_user_requested\n\nfixes potential xss vuln in user requestable results",
            "language":"ca",
            "entities":"[('#10942', 'ISSUE', ''), ('xss_user_requested', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/Api\/ProfileController.php'])",
            "num_files":1.0,
            "patch_content":"From 698c7f4904f8fd843c5b9761053c9c68819ec288 Mon Sep 17 00:00:00 2001\nFrom: snipe <snipe@snipe.net>\nDate: Fri, 15 Apr 2022 12:22:20 +0100\nSubject: [PATCH] Fixes potential XSS vuln in user requestable results\n\nSigned-off-by: snipe <snipe@snipe.net>\n---\n app\/Http\/Controllers\/Api\/ProfileController.php | 10 +++++-----\n 1 file changed, 5 insertions(+), 5 deletions(-)\n\ndiff --git a\/app\/Http\/Controllers\/Api\/ProfileController.php b\/app\/Http\/Controllers\/Api\/ProfileController.php\nindex f6c31d5db15a..47e299e61516 100644\n--- a\/app\/Http\/Controllers\/Api\/ProfileController.php\n+++ b\/app\/Http\/Controllers\/Api\/ProfileController.php\n@@ -30,11 +30,11 @@ public function requestedAssets()\n             \/\/ Make sure the asset and request still exist\n             if ($checkoutRequest && $checkoutRequest->itemRequested()) {\n                 $results['rows'][] = [\n-                    'image' => $checkoutRequest->itemRequested()->present()->getImageUrl(),\n-                    'name' => $checkoutRequest->itemRequested()->present()->name(),\n-                    'type' => $checkoutRequest->itemType(),\n-                    'qty' => $checkoutRequest->quantity,\n-                    'location' => ($checkoutRequest->location()) ? $checkoutRequest->location()->name : null,\n+                    'image' => e($checkoutRequest->itemRequested()->present()->getImageUrl()),\n+                    'name' => e($checkoutRequest->itemRequested()->present()->name()),\n+                    'type' => e($checkoutRequest->itemType()),\n+                    'qty' => (int) $checkoutRequest->quantity,\n+                    'location' => ($checkoutRequest->location()) ? e($checkoutRequest->location()->name) : null,\n                     'expected_checkin' => Helper::getFormattedDateObject($checkoutRequest->itemRequested()->expected_checkin, 'datetime'),\n                     'request_date' => Helper::getFormattedDateObject($checkoutRequest->created_at, 'datetime'),\n                 ];"
        },
        {
            "index":878,
            "vuln_id":"GHSA-p8q8-jfcv-g2h2",
            "cwe_id":"{'CWE-59'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/pear\/Archive_Tar\/commit\/7789ebb2f34f9e4adb3a4152ad0d1548930a9755', 'https:\/\/github.com\/pear\/Archive_Tar\/commit\/b5832439b1f37331fb4f87e67fe4f61ca26bf7d4'}",
            "dataset":"osv",
            "summary":"Directory Traversal in Archive_Tar In Archive_Tar before 1.4.14, symlinks can refer to targets outside of the extracted archive, a different vulnerability than CVE-2020-36193.",
            "published_date":"2021-08-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/pear\/Archive_Tar",
            "commit_href":"https:\/\/github.com\/pear\/Archive_Tar\/commit\/b5832439b1f37331fb4f87e67fe4f61ca26bf7d4",
            "commit_sha":"b5832439b1f37331fb4f87e67fe4f61ca26bf7d4",
            "patch":"MULTI",
            "chain_ord":"['b5832439b1f37331fb4f87e67fe4f61ca26bf7d4', '7789ebb2f34f9e4adb3a4152ad0d1548930a9755']",
            "before_first_fix_commit":"{'8c00f3c220655961dc3f869f37005794ab3e3500', '4d761c5334c790e45ef3245f0864b8955c562caa'}",
            "last_fix_commit":"7789ebb2f34f9e4adb3a4152ad0d1548930a9755",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/18\/2021, 15:21:58",
            "message":"Properly fix symbolic link path traversal (CVE-2021-32610)",
            "author":"Michiel Rook",
            "comments":null,
            "stats":"{'additions': 29, 'deletions': 21, 'total': 50}",
            "files":"{'Archive\/Tar.php': {'additions': 29, 'deletions': 21, 'changes': 50, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pear\/Archive_Tar\/raw\/b5832439b1f37331fb4f87e67fe4f61ca26bf7d4\/Archive%2FTar.php', 'patch': '@@ -2124,39 +2124,47 @@ public function _extractList(\\n                             }\\n                         }\\n                     } elseif ($v_header[\\'typeflag\\'] == \"2\") {\\n+                        if (!$p_symlinks) {\\n+                            $this->_warning(\\'Symbolic links are not allowed. \\'\\n+                                . \\'Unable to extract {\\'\\n+                                . $v_header[\\'filename\\'] . \\'}\\'\\n+                            );\\n+                            return false;\\n+                        }\\n+                        $absolute_link = FALSE;\\n                         $link_depth = 0;\\n-                        foreach (explode(\"\/\", $v_header[\\'filename\\']) as $dir) {\\n-                            if ($dir === \"..\") {\\n-                                $link_depth--;\\n-                            } elseif ($dir !== \"\" && $dir !== \".\" ) {\\n-                                $link_depth++;\\n-                            }\\n+                        if (strpos($v_header[\\'link\\'], \"\/\") === 0 || strpos($v_header[\\'link\\'], \\':\\') !== FALSE) {\\n+                          $absolute_link = TRUE;\\n                         }\\n-                        foreach (explode(\"\/\", $v_header[\\'link\\']) as $dir){\\n-                            if ($link_depth <= 0) {\\n-                                break;\\n+                        else {\\n+                            $s_filename = preg_replace(\\'@^\\' . preg_quote($p_path) . \\'@\\', \"\", $v_header[\\'filename\\']);\\n+                            $s_linkname = str_replace(\\'\\\\\\\\\\', \\'\/\\', $v_header[\\'link\\']);\\n+                            foreach (explode(\"\/\", $s_filename) as $dir) {\\n+                                if ($dir === \"..\") {\\n+                                    $link_depth--;\\n+                                } elseif ($dir !== \"\" && $dir !== \".\" ) {\\n+                                    $link_depth++;\\n+                                }\\n                             }\\n-                            if ($dir === \"..\") {\\n-                                $link_depth--;\\n-                            } elseif ($dir !== \"\" && $dir !== \".\") {\\n-                                $link_depth++;\\n+                            foreach (explode(\"\/\", $s_linkname) as $dir){\\n+                                if ($link_depth <= 0) {\\n+                                    break;\\n+                                }\\n+                                if ($dir === \"..\") {\\n+                                    $link_depth--;\\n+                                } elseif ($dir !== \"\" && $dir !== \".\") {\\n+                                    $link_depth++;\\n+                                }\\n                             }\\n                         }\\n-                        if (strpos($v_header[\\'link\\'], \"\/\") === 0 or $link_depth <= 0) {\\n+                        if ($absolute_link || $link_depth <= 0) {\\n                             $this->_error(\\n                                  \\'Out-of-path file extraction {\\'\\n                                  . $v_header[\\'filename\\'] . \\' --> \\' .\\n                                  $v_header[\\'link\\'] . \\'}\\'\\n                             );\\n                             return false;\\n                         }\\n-                        if (!$p_symlinks) {\\n-                            $this->_warning(\\'Symbolic links are not allowed. \\'\\n-                                . \\'Unable to extract {\\'\\n-                                . $v_header[\\'filename\\'] . \\'}\\'\\n-                            );\\n-                            return false;\\n-                        }\\n                         if (@file_exists($v_header[\\'filename\\'])) {\\n                             @unlink($v_header[\\'filename\\']);\\n                         }'}}",
            "message_norm":"properly fix symbolic link path traversal (cve-2021-32610)",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('path traversal', 'SECWORD', ''), ('cve-2021-32610', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Archive\/Tar.php'])",
            "num_files":1.0,
            "patch_content":"From b5832439b1f37331fb4f87e67fe4f61ca26bf7d4 Mon Sep 17 00:00:00 2001\nFrom: Michiel Rook <mrook@php.net>\nDate: Sun, 18 Jul 2021 17:21:58 +0200\nSubject: [PATCH] Properly fix symbolic link path traversal (CVE-2021-32610)\n\n---\n Archive\/Tar.php | 50 ++++++++++++++++++++++++++++---------------------\n 1 file changed, 29 insertions(+), 21 deletions(-)\n\ndiff --git a\/Archive\/Tar.php b\/Archive\/Tar.php\nindex a8c9501..3356ad6 100644\n--- a\/Archive\/Tar.php\n+++ b\/Archive\/Tar.php\n@@ -2124,25 +2124,40 @@ public function _extractList(\n                             }\n                         }\n                     } elseif ($v_header['typeflag'] == \"2\") {\n+                        if (!$p_symlinks) {\n+                            $this->_warning('Symbolic links are not allowed. '\n+                                . 'Unable to extract {'\n+                                . $v_header['filename'] . '}'\n+                            );\n+                            return false;\n+                        }\n+                        $absolute_link = FALSE;\n                         $link_depth = 0;\n-                        foreach (explode(\"\/\", $v_header['filename']) as $dir) {\n-                            if ($dir === \"..\") {\n-                                $link_depth--;\n-                            } elseif ($dir !== \"\" && $dir !== \".\" ) {\n-                                $link_depth++;\n-                            }\n+                        if (strpos($v_header['link'], \"\/\") === 0 || strpos($v_header['link'], ':') !== FALSE) {\n+                          $absolute_link = TRUE;\n                         }\n-                        foreach (explode(\"\/\", $v_header['link']) as $dir){\n-                            if ($link_depth <= 0) {\n-                                break;\n+                        else {\n+                            $s_filename = preg_replace('@^' . preg_quote($p_path) . '@', \"\", $v_header['filename']);\n+                            $s_linkname = str_replace('\\\\', '\/', $v_header['link']);\n+                            foreach (explode(\"\/\", $s_filename) as $dir) {\n+                                if ($dir === \"..\") {\n+                                    $link_depth--;\n+                                } elseif ($dir !== \"\" && $dir !== \".\" ) {\n+                                    $link_depth++;\n+                                }\n                             }\n-                            if ($dir === \"..\") {\n-                                $link_depth--;\n-                            } elseif ($dir !== \"\" && $dir !== \".\") {\n-                                $link_depth++;\n+                            foreach (explode(\"\/\", $s_linkname) as $dir){\n+                                if ($link_depth <= 0) {\n+                                    break;\n+                                }\n+                                if ($dir === \"..\") {\n+                                    $link_depth--;\n+                                } elseif ($dir !== \"\" && $dir !== \".\") {\n+                                    $link_depth++;\n+                                }\n                             }\n                         }\n-                        if (strpos($v_header['link'], \"\/\") === 0 or $link_depth <= 0) {\n+                        if ($absolute_link || $link_depth <= 0) {\n                             $this->_error(\n                                  'Out-of-path file extraction {'\n                                  . $v_header['filename'] . ' --> ' .\n@@ -2150,13 +2165,6 @@ public function _extractList(\n                             );\n                             return false;\n                         }\n-                        if (!$p_symlinks) {\n-                            $this->_warning('Symbolic links are not allowed. '\n-                                . 'Unable to extract {'\n-                                . $v_header['filename'] . '}'\n-                            );\n-                            return false;\n-                        }\n                         if (@file_exists($v_header['filename'])) {\n                             @unlink($v_header['filename']);\n                         }"
        },
        {
            "index":519,
            "vuln_id":"GHSA-xw93-v57j-fcgh",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5'}",
            "dataset":"osv",
            "summary":"Division by 0 in `SparseMatMul` ### Impact\nAn attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.SparseMatMul`:\n\n```python\nimport tensorflow as tf\n\na = tf.constant([100.0, 100.0, 100.0, 100.0], shape=[2, 2], dtype=tf.float32)\nb = tf.constant([], shape=[0, 2], dtype=tf.float32)\n\ntf.raw_ops.SparseMatMul(\n    a=a, b=b, transpose_a=True, transpose_b=True,\n    a_is_sparse=True, b_is_sparse=True)\n``` \n    \nThe division by 0 occurs deep in Eigen code because the `b` tensor is empty.\n    \n### Patches\nWe have patched the issue in GitHub commit [7f283ff806b2031f407db64c4d3edcda8fb9f9f5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "commit_sha":"7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "patch":"SINGLE",
            "chain_ord":"['7f283ff806b2031f407db64c4d3edcda8fb9f9f5']",
            "before_first_fix_commit":"{'05a63e605a31e86c5dd96c5c8a763eda9ac7bb33'}",
            "last_fix_commit":"7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 22:00:39",
            "message":"Fix FPE issue in external Eigen source code issue with `tf.raw_ops.SparseMatMul`.\n\nPiperOrigin-RevId: 370992919\nChange-Id: Icfb276fef5fb40928b27c3e44608d2aca72c9fd7",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/sparse_matmul_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5\/tensorflow%2Fcore%2Fkernels%2Fsparse_matmul_op.cc', 'patch': '@@ -1039,6 +1039,10 @@ class SparseMatMulOp : public OpKernel {\\n     if (transpose_b) {\\n       \/\/ TODO(agarwal): avoid transposing the matrix here and directly handle\\n       \/\/ transpose in CreateDenseSlices.\\n+      OP_REQUIRES(ctx, right->dim_size(0) != 0,\\n+                  errors::InvalidArgument(\"b has an entry 0 in it\\'s shape.\"));\\n+      OP_REQUIRES(ctx, right->dim_size(1) != 0,\\n+                  errors::InvalidArgument(\"b has an entry 0 in it\\'s shape.\"));\\n       right_tr.reset(\\n           new Tensor(right->dtype(),\\n                      TensorShape({right->dim_size(1), right->dim_size(0)})));'}}",
            "message_norm":"fix fpe issue in external eigen source code issue with `tf.raw_ops.sparsematmul`.\n\npiperorigin-revid: 370992919\nchange-id: icfb276fef5fb40928b27c3e44608d2aca72c9fd7",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('issue', 'FLAW', ''), ('issue', 'FLAW', ''), ('370992919', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_matmul_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 7f283ff806b2031f407db64c4d3edcda8fb9f9f5 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Wed, 28 Apr 2021 15:00:39 -0700\nSubject: [PATCH] Fix FPE issue in external Eigen source code issue with\n `tf.raw_ops.SparseMatMul`.\n\nPiperOrigin-RevId: 370992919\nChange-Id: Icfb276fef5fb40928b27c3e44608d2aca72c9fd7\n---\n tensorflow\/core\/kernels\/sparse_matmul_op.cc | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_matmul_op.cc b\/tensorflow\/core\/kernels\/sparse_matmul_op.cc\nindex f5747854093c95..a02afafa33e3ad 100644\n--- a\/tensorflow\/core\/kernels\/sparse_matmul_op.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_matmul_op.cc\n@@ -1039,6 +1039,10 @@ class SparseMatMulOp : public OpKernel {\n     if (transpose_b) {\n       \/\/ TODO(agarwal): avoid transposing the matrix here and directly handle\n       \/\/ transpose in CreateDenseSlices.\n+      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n+                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n+      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n+                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n       right_tr.reset(\n           new Tensor(right->dtype(),\n                      TensorShape({right->dim_size(1), right->dim_size(0)})));"
        },
        {
            "index":39,
            "vuln_id":"GHSA-fqq2-xp7m-xvm8",
            "cwe_id":"{'CWE-362', 'CWE-119'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/RusPiRo\/ruspiro-singleton\/commit\/b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e'}",
            "dataset":"osv",
            "summary":"Data race in ruspiro-singleton `Singleton<T>` is meant to be a static object that can be initialized lazily. In\norder to satisfy the requirement that `static` items must implement `Sync`,\n`Singleton` implemented both `Sync` and `Send` unconditionally.\n\nThis allows for a bug where non-`Sync` types such as `Cell` can be used in\nsingletons and cause data races in concurrent programs.\n\nThe flaw was corrected in commit `b0d2bd20e` by adding trait bounds, requiring\nthe contaiend type to implement `Sync`.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/RusPiRo\/ruspiro-singleton",
            "commit_href":"https:\/\/github.com\/RusPiRo\/ruspiro-singleton\/commit\/b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e",
            "commit_sha":"b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e",
            "patch":"SINGLE",
            "chain_ord":"['b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e']",
            "before_first_fix_commit":"{'0565f8ef459bd336eda8a6a63d1d50cdb581c2b3'}",
            "last_fix_commit":"b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/16\/2020, 20:32:29",
            "message":"fix soundness",
            "author":"2ndTaleStudio",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'src\/lib.rs': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/RusPiRo\/ruspiro-singleton\/raw\/b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e\/src%2Flib.rs', 'patch': \"@@ -81,8 +81,10 @@ pub struct Singleton<T: 'static> {\\n \\n \/\/ The Singleton need to implement Send & Sync to ensure cross core compile check mechanics\\n \/\/ this is safe as the inner RWLock ensures cross core safety\\n-unsafe impl<T> Sync for Singleton<T> {}\\n-unsafe impl<T> Send for Singleton<T> {}\\n+\/\/ but we need to be conditional on the inner type to prevent interior mutable types beeing used\\n+\/\/ inside a singleton\\n+unsafe impl<T> Sync for Singleton<T> where T: Sync {}\\n+unsafe impl<T> Send for Singleton<T> where T: Send {}\\n \\n impl<T: 'static> Singleton<T> {\\n     \/\/\/ Create a new [Singleton] instance to be used in a static variable. Only ``const fn`` constructors are allowed\"}}",
            "message_norm":"fix soundness",
            "language":"en",
            "entities":"[('fix', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/lib.rs'])",
            "num_files":1.0,
            "patch_content":"From b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e Mon Sep 17 00:00:00 2001\nFrom: 2ndTaleStudio <43264484+2ndTaleStudio@users.noreply.github.com>\nDate: Mon, 16 Nov 2020 21:32:29 +0100\nSubject: [PATCH] fix soundness\n\n---\n src\/lib.rs | 6 ++++--\n 1 file changed, 4 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/lib.rs b\/src\/lib.rs\nindex d36df5d..82ce57a 100644\n--- a\/src\/lib.rs\n+++ b\/src\/lib.rs\n@@ -81,8 +81,10 @@ pub struct Singleton<T: 'static> {\n \n \/\/ The Singleton need to implement Send & Sync to ensure cross core compile check mechanics\n \/\/ this is safe as the inner RWLock ensures cross core safety\n-unsafe impl<T> Sync for Singleton<T> {}\n-unsafe impl<T> Send for Singleton<T> {}\n+\/\/ but we need to be conditional on the inner type to prevent interior mutable types beeing used\n+\/\/ inside a singleton\n+unsafe impl<T> Sync for Singleton<T> where T: Sync {}\n+unsafe impl<T> Send for Singleton<T> where T: Send {}\n \n impl<T: 'static> Singleton<T> {\n     \/\/\/ Create a new [Singleton] instance to be used in a static variable. Only ``const fn`` constructors are allowed"
        },
        {
            "index":218,
            "vuln_id":"GHSA-r4c4-5fpq-56wg",
            "cwe_id":"{'CWE-125'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378'}",
            "dataset":"osv",
            "summary":"Heap OOB in boosted trees ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `BoostedTreesSparseCalculateBestFeatureSplit`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(\n  node_id_range=[0,10],\n  stats_summary_indices=[[1, 2, 3, 0x1000000]],\n  stats_summary_values=[1.0],\n  stats_summary_shape=[1,1,1,1],\n  l1=l2=[1.0],\n  tree_complexity=[0.5],\n  min_node_weight=[1.0],\n  logits_dimension=3,\n  split_type='inequality')                                                                                                                                                                                                                                                                \n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc) needs to validate that each value in `stats_summary_indices` is in range.\n  \n### Patches\nWe have patched the issue in GitHub commit [e84c975313e8e8e38bb2ea118196369c45c51378](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378",
            "commit_sha":"e84c975313e8e8e38bb2ea118196369c45c51378",
            "patch":"SINGLE",
            "chain_ord":"['e84c975313e8e8e38bb2ea118196369c45c51378']",
            "before_first_fix_commit":"{'2e0ee46f1a47675152d3d865797a18358881d7a6'}",
            "last_fix_commit":"e84c975313e8e8e38bb2ea118196369c45c51378",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 19:35:03",
            "message":"In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaa",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e84c975313e8e8e38bb2ea118196369c45c51378\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\\n+      OP_REQUIRES(context, stat_dim < stats_dims,\\n+                  errors::InvalidArgument(\\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\\n+                      \"stats_summary_indices, cannot be greater than stats \"\\n+                      \"dims, the last value in stats_summary_shape, which was \",\\n+                      stats_dims, \". At index (\", idx,\\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\\n       auto& b_map = f_insert_result.first->second;'}}",
            "message_norm":"in tf.raw_ops.boostedtreessparsecalculatebestfeaturesplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\npiperorigin-revid: 387171191\nchange-id: i83ca8a75b22aa78c037e8b98779da6cced16bfaa",
            "language":"en",
            "entities":"[('387171191', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From e84c975313e8e8e38bb2ea118196369c45c51378 Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Tue, 27 Jul 2021 12:35:03 -0700\nSubject: [PATCH] In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit,\n limit stat_dim in stats_summary_indices to under stats_dims in\n stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaa\n---\n tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc | 7 +++++++\n 1 file changed, 7 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc b\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\nindex 014c2ec22c9cf6..2636909855a386 100644\n--- a\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\n+++ b\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\n@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\n+      OP_REQUIRES(context, stat_dim < stats_dims,\n+                  errors::InvalidArgument(\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\n+                      \"stats_summary_indices, cannot be greater than stats \"\n+                      \"dims, the last value in stats_summary_shape, which was \",\n+                      stats_dims, \". At index (\", idx,\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\n       auto& b_map = f_insert_result.first->second;"
        },
        {
            "index":448,
            "vuln_id":"GHSA-m34j-p8rj-wjxq",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67784700869470d65d5f2ef20aeb5e97c31673cb'}",
            "dataset":"osv",
            "summary":"Division by 0 in `QuantizedBiasAdd` ### Impact\nAn attacker can trigger an integer division by zero undefined behavior in `tf.raw_ops.QuantizedBiasAdd`:\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.quint8)\nbias = tf.constant([], shape=[0], dtype=tf.quint8)\nmin_input = tf.constant(-10.0, dtype=tf.float32)\nmax_input = tf.constant(-10.0, dtype=tf.float32)\nmin_bias = tf.constant(-10.0, dtype=tf.float32)\nmax_bias = tf.constant(-10.0, dtype=tf.float32)\n\ntf.raw_ops.QuantizedBiasAdd(input=input_tensor, bias=bias, min_input=min_input,\n                            max_input=max_input, min_bias=min_bias,\n                            max_bias=max_bias, out_type=tf.qint32)\n```\n\nThis is because the [implementation of the Eigen kernel](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/61bca8bd5ba8a68b2d97435ddfafcdf2b85672cd\/tensorflow\/core\/kernels\/quantization_utils.h#L812-L849) does a division by the number of elements of the smaller input (based on shape) without checking that this is not zero:\n\n```cc\ntemplate <typename T1, typename T2, typename T3>\nvoid QuantizedAddUsingEigen(const Eigen::ThreadPoolDevice& device,\n                            const Tensor& input, float input_min,\n                            float input_max, const Tensor& smaller_input,\n                            float smaller_input_min, float smaller_input_max,\n                            Tensor* output, float* output_min,\n                            float* output_max) {\n  ...\n  const int64 input_element_count = input.NumElements();\n  const int64 smaller_input_element_count = smaller_input.NumElements();\n  ...\n  bcast[0] = input_element_count \/ smaller_input_element_count;\n  ...\n}\n```\n\nThis integral division by 0 is undefined behavior.\n\n### Patches\nWe have patched the issue in GitHub commit [67784700869470d65d5f2ef20aeb5e97c31673cb](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67784700869470d65d5f2ef20aeb5e97c31673cb).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67784700869470d65d5f2ef20aeb5e97c31673cb",
            "commit_sha":"67784700869470d65d5f2ef20aeb5e97c31673cb",
            "patch":"SINGLE",
            "chain_ord":"['67784700869470d65d5f2ef20aeb5e97c31673cb']",
            "before_first_fix_commit":"{'61bca8bd5ba8a68b2d97435ddfafcdf2b85672cd'}",
            "last_fix_commit":"67784700869470d65d5f2ef20aeb5e97c31673cb",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2021, 18:11:39",
            "message":"Prevent division by 0 in `QuantizedBiasAdd`.\n\nPiperOrigin-RevId: 370117454\nChange-Id: I3804e2ac8dcc6d3afcc92e27853e2325a017ca4d",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/quantized_bias_add_op.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/67784700869470d65d5f2ef20aeb5e97c31673cb\/tensorflow%2Fcore%2Fkernels%2Fquantized_bias_add_op.cc', 'patch': '@@ -56,6 +56,8 @@ class QuantizedBiasAddOp : public OpKernel {\\n             \"Must provide as many biases as the last dimension \"\\n             \"of the input tensor: \",\\n             bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\\n+    OP_REQUIRES(context, bias.NumElements() > 0,\\n+                errors::InvalidArgument(\"Must provide at least 1 bias\"));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(context,'}}",
            "message_norm":"prevent division by 0 in `quantizedbiasadd`.\n\npiperorigin-revid: 370117454\nchange-id: i3804e2ac8dcc6d3afcc92e27853e2325a017ca4d",
            "language":"it",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('370117454', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_bias_add_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 67784700869470d65d5f2ef20aeb5e97c31673cb Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 23 Apr 2021 11:11:39 -0700\nSubject: [PATCH] Prevent division by 0 in `QuantizedBiasAdd`.\n\nPiperOrigin-RevId: 370117454\nChange-Id: I3804e2ac8dcc6d3afcc92e27853e2325a017ca4d\n---\n tensorflow\/core\/kernels\/quantized_bias_add_op.cc | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantized_bias_add_op.cc b\/tensorflow\/core\/kernels\/quantized_bias_add_op.cc\nindex 5457d290c2559c..db0e21a498011d 100644\n--- a\/tensorflow\/core\/kernels\/quantized_bias_add_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantized_bias_add_op.cc\n@@ -56,6 +56,8 @@ class QuantizedBiasAddOp : public OpKernel {\n             \"Must provide as many biases as the last dimension \"\n             \"of the input tensor: \",\n             bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\n+    OP_REQUIRES(context, bias.NumElements() > 0,\n+                errors::InvalidArgument(\"Must provide at least 1 bias\"));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,"
        },
        {
            "index":417,
            "vuln_id":"GHSA-pc5p-h8pf-mvwp",
            "cwe_id":"{'CWE-300'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/commit\/36d8cf509f877fa44f4404fce57ebaf9410fe51b'}",
            "dataset":"osv",
            "summary":"Machine-In-The-Middle in https-proxy-agent Versions of `https-proxy-agent` prior to 2.2.3 are vulnerable to Machine-In-The-Middle. The package fails to enforce TLS on the socket if the proxy server responds the to the request with a HTTP status different than 200. This allows an attacker with access to the proxy server to intercept unencrypted communications, which may include sensitive information such as credentials.\n\n\n## Recommendation\n\nUpgrade to version 3.0.0 or 2.2.3.",
            "published_date":"2020-04-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/TooTallNate\/node-https-proxy-agent",
            "commit_href":"https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/commit\/36d8cf509f877fa44f4404fce57ebaf9410fe51b",
            "commit_sha":"36d8cf509f877fa44f4404fce57ebaf9410fe51b",
            "patch":"SINGLE",
            "chain_ord":"['36d8cf509f877fa44f4404fce57ebaf9410fe51b']",
            "before_first_fix_commit":"{'5252bb9355ad12802d7e0846e5e7cf4ced54fc63'}",
            "last_fix_commit":"36d8cf509f877fa44f4404fce57ebaf9410fe51b",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/07\/2019, 19:53:24",
            "message":"Use an `EventEmitter` to replay failed proxy connect HTTP requests (#77)\n\n* Use an `EventEmitter` to replay failed proxy connect HTTP requests\r\n\r\nThis is a fix for https:\/\/hackerone.com\/reports\/541502.\r\n\r\nAborts the upstream proxy connection and instead uses a vanilla\r\n`EventEmitter` instance to replay the \"data\" events on to. This way,\r\nthe node core `http` Client doesn't attempt to write the HTTP request\r\nthat is intended to go to the destination server to the proxy server.\r\n\r\nCloses #76.\r\n\r\n* Adjust comment",
            "author":"Nathan Rajlich",
            "comments":"{'com_1': {'author': 'jaimeborjas', 'datetime': '04\/17\/2020, 01:17:19', 'body': 'Security fixes'}, 'com_2': {'author': 'donurukiran', 'datetime': '04\/17\/2020, 13:18:32', 'body': 'done with few security issues'}}",
            "stats":"{'additions': 15, 'deletions': 3, 'total': 18}",
            "files":"{'index.js': {'additions': 15, 'deletions': 3, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/raw\/36d8cf509f877fa44f4404fce57ebaf9410fe51b\/index.js', 'patch': '@@ -5,6 +5,7 @@\\n var net = require(\\'net\\');\\n var tls = require(\\'tls\\');\\n var url = require(\\'url\\');\\n+var events = require(\\'events\\');\\n var Agent = require(\\'agent-base\\');\\n var inherits = require(\\'util\\').inherits;\\n var debug = require(\\'debug\\')(\\'https-proxy-agent\\');\\n@@ -154,20 +155,32 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\\n       fn(null, sock);\\n     } else {\\n       \/\/ some other status code that\\'s not 200... need to re-play the HTTP header\\n-      \/\/ \"data\" events onto the socket once the HTTP machinery is attached so that\\n-      \/\/ the user can parse and handle the error status code\\n+      \/\/ \"data\" events onto the socket once the HTTP machinery is attached so\\n+      \/\/ that the node core `http` can parse and handle the error status code\\n       cleanup();\\n \\n+      \/\/ the original socket is closed, and a \"fake socket\" EventEmitter is\\n+      \/\/ returned instead, so that the proxy doesn\\'t get the HTTP request\\n+      \/\/ written to it (which may contain `Authorization` headers or other\\n+      \/\/ sensitive data).\\n+      \/\/\\n+      \/\/ See: https:\/\/hackerone.com\/reports\/541502\\n+      socket.destroy();\\n+      socket = new events.EventEmitter();\\n+\\n       \/\/ save a reference to the concat\\'d Buffer for the `onsocket` callback\\n       buffers = buffered;\\n \\n       \/\/ need to wait for the \"socket\" event to re-play the \"data\" events\\n       req.once(\\'socket\\', onsocket);\\n+\\n       fn(null, socket);\\n     }\\n   }\\n \\n   function onsocket(socket) {\\n+    debug(\\'replaying proxy buffer for failed request\\');\\n+\\n     \/\/ replay the \"buffers\" Buffer onto the `socket`, since at this point\\n     \/\/ the HTTP module machinery has been hooked up for the user\\n     if (socket.listenerCount(\\'data\\') > 0) {\\n@@ -177,7 +190,6 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\\n       throw new Error(\\'should not happen...\\');\\n     }\\n \\n-    socket.resume();\\n     \/\/ nullify the cached Buffer instance\\n     buffers = null;\\n   }'}}",
            "message_norm":"use an `eventemitter` to replay failed proxy connect http requests (#77)\n\n* use an `eventemitter` to replay failed proxy connect http requests\r\n\r\nthis is a fix for https:\/\/hackerone.com\/reports\/541502.\r\n\r\naborts the upstream proxy connection and instead uses a vanilla\r\n`eventemitter` instance to replay the \"data\" events on to. this way,\r\nthe node core `http` client doesn't attempt to write the http request\r\nthat is intended to go to the destination server to the proxy server.\r\n\r\ncloses #76.\r\n\r\n* adjust comment",
            "language":"en",
            "entities":"[('#77', 'ISSUE', ''), ('https:\/\/hackerone.com\/reports\/541502', 'URL', ''), ('server', 'SECWORD', ''), ('server', 'SECWORD', ''), ('#76', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From 36d8cf509f877fa44f4404fce57ebaf9410fe51b Mon Sep 17 00:00:00 2001\nFrom: Nathan Rajlich <n@n8.io>\nDate: Mon, 7 Oct 2019 12:53:24 -0700\nSubject: [PATCH] Use an `EventEmitter` to replay failed proxy connect HTTP\n requests (#77)\n\n* Use an `EventEmitter` to replay failed proxy connect HTTP requests\n\nThis is a fix for https:\/\/hackerone.com\/reports\/541502.\n\nAborts the upstream proxy connection and instead uses a vanilla\n`EventEmitter` instance to replay the \"data\" events on to. This way,\nthe node core `http` Client doesn't attempt to write the HTTP request\nthat is intended to go to the destination server to the proxy server.\n\nCloses #76.\n\n* Adjust comment\n---\n index.js | 18 +++++++++++++++---\n 1 file changed, 15 insertions(+), 3 deletions(-)\n\ndiff --git a\/index.js b\/index.js\nindex 64526639..2791aea8 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -5,6 +5,7 @@\n var net = require('net');\n var tls = require('tls');\n var url = require('url');\n+var events = require('events');\n var Agent = require('agent-base');\n var inherits = require('util').inherits;\n var debug = require('debug')('https-proxy-agent');\n@@ -154,20 +155,32 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\n       fn(null, sock);\n     } else {\n       \/\/ some other status code that's not 200... need to re-play the HTTP header\n-      \/\/ \"data\" events onto the socket once the HTTP machinery is attached so that\n-      \/\/ the user can parse and handle the error status code\n+      \/\/ \"data\" events onto the socket once the HTTP machinery is attached so\n+      \/\/ that the node core `http` can parse and handle the error status code\n       cleanup();\n \n+      \/\/ the original socket is closed, and a \"fake socket\" EventEmitter is\n+      \/\/ returned instead, so that the proxy doesn't get the HTTP request\n+      \/\/ written to it (which may contain `Authorization` headers or other\n+      \/\/ sensitive data).\n+      \/\/\n+      \/\/ See: https:\/\/hackerone.com\/reports\/541502\n+      socket.destroy();\n+      socket = new events.EventEmitter();\n+\n       \/\/ save a reference to the concat'd Buffer for the `onsocket` callback\n       buffers = buffered;\n \n       \/\/ need to wait for the \"socket\" event to re-play the \"data\" events\n       req.once('socket', onsocket);\n+\n       fn(null, socket);\n     }\n   }\n \n   function onsocket(socket) {\n+    debug('replaying proxy buffer for failed request');\n+\n     \/\/ replay the \"buffers\" Buffer onto the `socket`, since at this point\n     \/\/ the HTTP module machinery has been hooked up for the user\n     if (socket.listenerCount('data') > 0) {\n@@ -177,7 +190,6 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\n       throw new Error('should not happen...');\n     }\n \n-    socket.resume();\n     \/\/ nullify the cached Buffer instance\n     buffers = null;\n   }"
        },
        {
            "index":711,
            "vuln_id":"GHSA-2hjr-fg6c-v2h6",
            "cwe_id":"{'CWE-200'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/HubSpot\/jinjava\/pull\/435\/commits\/1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165', 'https:\/\/github.com\/HubSpot\/jinjava\/pull\/426\/commits\/5dfa5b87318744a4d020b66d5f7747acc36b213b'}",
            "dataset":"osv",
            "summary":"Unauthorized access to Class instance in Jinjava Jinjava before 2.5.4 allow access to arbitrary classes by calling Java methods on objects passed into a Jinjava context. This could allow for abuse of the application class loader, including Arbitrary File Disclosure.",
            "published_date":"2022-02-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/HubSpot\/jinjava",
            "commit_href":"https:\/\/github.com\/HubSpot\/jinjava\/pull\/426\/commits\/5dfa5b87318744a4d020b66d5f7747acc36b213b",
            "commit_sha":"5dfa5b87318744a4d020b66d5f7747acc36b213b",
            "patch":"MULTI",
            "chain_ord":"['5dfa5b87318744a4d020b66d5f7747acc36b213b', '1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165']",
            "before_first_fix_commit":"{'bfc6ecde3a98db02a00c87a3b905a0af907188f0'}",
            "last_fix_commit":"1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2020, 17:49:08",
            "message":"add method to blacklist",
            "author":"Matt Coley",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 1, 'total': 8}",
            "files":"{'src\/main\/java\/com\/hubspot\/jinjava\/el\/ext\/JinjavaBeanELResolver.java': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/HubSpot\/jinjava\/raw\/5dfa5b87318744a4d020b66d5f7747acc36b213b\/src%2Fmain%2Fjava%2Fcom%2Fhubspot%2Fjinjava%2Fel%2Fext%2FJinjavaBeanELResolver.java', 'patch': '@@ -2,6 +2,7 @@\\n \\n import com.google.common.base.CaseFormat;\\n import com.google.common.collect.ImmutableSet;\\n+import java.lang.reflect.Method;\\n import java.util.Set;\\n import javax.el.BeanELResolver;\\n import javax.el.ELContext;\\n@@ -111,7 +112,12 @@ private String transformPropertyName(Object property) {\\n   }\\n \\n   private void checkRestrictedClass(Object o, Object method) {\\n-    if (o instanceof Class || o instanceof ClassLoader || o instanceof Thread) {\\n+    if (\\n+      o instanceof Class ||\\n+      o instanceof ClassLoader ||\\n+      o instanceof Thread ||\\n+      o instanceof Method\\n+    ) {\\n       throw new MethodNotFoundException(\\n         \"Cannot find method \\'\" + method + \"\\' in \" + o.getClass()\\n       );'}}",
            "message_norm":"add method to blacklist",
            "language":"cy",
            "entities":"[('add', 'ACTION', ''), ('blacklist', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/com\/hubspot\/jinjava\/el\/ext\/JinjavaBeanELResolver.java'])",
            "num_files":1.0,
            "patch_content":"From 5dfa5b87318744a4d020b66d5f7747acc36b213b Mon Sep 17 00:00:00 2001\nFrom: Matt Coley <mcoley@hubspot.com>\nDate: Mon, 13 Apr 2020 13:49:08 -0400\nSubject: [PATCH] add method to blacklist\n\n---\n ...\/com\/hubspot\/jinjava\/el\/ext\/JinjavaBeanELResolver.java | 8 +++++++-\n 1 file changed, 7 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/main\/java\/com\/hubspot\/jinjava\/el\/ext\/JinjavaBeanELResolver.java b\/src\/main\/java\/com\/hubspot\/jinjava\/el\/ext\/JinjavaBeanELResolver.java\nindex a2f541af6..958f2b3bd 100644\n--- a\/src\/main\/java\/com\/hubspot\/jinjava\/el\/ext\/JinjavaBeanELResolver.java\n+++ b\/src\/main\/java\/com\/hubspot\/jinjava\/el\/ext\/JinjavaBeanELResolver.java\n@@ -2,6 +2,7 @@\n \n import com.google.common.base.CaseFormat;\n import com.google.common.collect.ImmutableSet;\n+import java.lang.reflect.Method;\n import java.util.Set;\n import javax.el.BeanELResolver;\n import javax.el.ELContext;\n@@ -111,7 +112,12 @@ private String transformPropertyName(Object property) {\n   }\n \n   private void checkRestrictedClass(Object o, Object method) {\n-    if (o instanceof Class || o instanceof ClassLoader || o instanceof Thread) {\n+    if (\n+      o instanceof Class ||\n+      o instanceof ClassLoader ||\n+      o instanceof Thread ||\n+      o instanceof Method\n+    ) {\n       throw new MethodNotFoundException(\n         \"Cannot find method '\" + method + \"' in \" + o.getClass()\n       );"
        },
        {
            "index":744,
            "vuln_id":"GHSA-98p5-x8x4-c9m5",
            "cwe_id":"{'CWE-190'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f19be71717c497723ba0cea0379e84f061a75e01', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1de49725a5fc4e48f1a3b902ec3599ee99283043', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e401da71458d253b05e41f28637b65baf64be4'}",
            "dataset":"osv",
            "summary":"Integer overflow in TFLite ### Impact \nAn attacker can craft a TFLite model that would cause an integer overflow [in embedding lookup operations](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ca6f96b62ad84207fbec580404eaa7dd7403a550\/tensorflow\/lite\/kernels\/embedding_lookup_sparse.cc#L179-L189):\n\n```cc\n  int embedding_size = 1;\n  int lookup_size = 1;\n  for (int i = 0; i < lookup_rank - 1; i++, k++) {\n    const int dim = dense_shape->data.i32[i];\n    lookup_size *= dim;\n    output_shape->data[k] = dim;\n  }\n  for (int i = 1; i < embedding_rank; i++, k++) {\n    const int dim = SizeOfDimension(value, i);\n    embedding_size *= dim;\n    output_shape->data[k] = dim;\n  } \n```\n\nBoth `embedding_size` and `lookup_size` are products of values provided by the user. Hence, a malicious user could trigger overflows in the multiplication.\n\nIn certain scenarios, this can then result in heap OOB read\/write.\n  \n### Patches\nWe have patched the issue in GitHub commits [f19be71717c497723ba0cea0379e84f061a75e01](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f19be71717c497723ba0cea0379e84f061a75e01), [1de49725a5fc4e48f1a3b902ec3599ee99283043](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1de49725a5fc4e48f1a3b902ec3599ee99283043) and [a4e401da71458d253b05e41f28637b65baf64be4](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e401da71458d253b05e41f28637b65baf64be4).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
            "published_date":"2022-02-09",
            "chain_len":3,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1de49725a5fc4e48f1a3b902ec3599ee99283043",
            "commit_sha":"1de49725a5fc4e48f1a3b902ec3599ee99283043",
            "patch":"MULTI",
            "chain_ord":"['f19be71717c497723ba0cea0379e84f061a75e01', '1de49725a5fc4e48f1a3b902ec3599ee99283043', 'a4e401da71458d253b05e41f28637b65baf64be4']",
            "before_first_fix_commit":"{'f435ae9dee673e83504618b77e1be8cddda73e74'}",
            "last_fix_commit":"a4e401da71458d253b05e41f28637b65baf64be4",
            "chain_ord_pos":2.0,
            "commit_datetime":"12\/21\/2021, 16:48:11",
            "message":"[lite] Check for overflow when creating required bytes.\n\nPiperOrigin-RevId: 417629001\nChange-Id: Ia7feb3ea8e988f4fd4b3c98c1a1fed4557d99fd7",
            "author":"Karim Nosir",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 7, 'total': 23}",
            "files":"{'tensorflow\/lite\/kernels\/embedding_lookup_sparse.cc': {'additions': 16, 'deletions': 7, 'changes': 23, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1de49725a5fc4e48f1a3b902ec3599ee99283043\/tensorflow%2Flite%2Fkernels%2Fembedding_lookup_sparse.cc', 'patch': '@@ -72,6 +72,7 @@ limitations under the License.\\n #include \"tensorflow\/lite\/kernels\/internal\/tensor_ctypes.h\"\\n #include \"tensorflow\/lite\/kernels\/internal\/tensor_utils.h\"\\n #include \"tensorflow\/lite\/kernels\/kernel_util.h\"\\n+#include \"tensorflow\/lite\/util.h\"\\n \\n namespace tflite {\\n namespace ops {\\n@@ -175,25 +176,33 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   TfLiteIntArray* output_shape = TfLiteIntArrayCreate(output_rank);\\n   TF_LITE_ENSURE(context, output_shape != nullptr);\\n   int k = 0;\\n-  int embedding_size = 1;\\n-  int lookup_size = 1;\\n+  size_t embedding_size = 1;\\n+  size_t lookup_size = 1;\\n   for (int i = 0; i < lookup_rank - 1; i++, k++) {\\n-    const int dim = dense_shape->data.i32[i];\\n-    lookup_size *= dim;\\n+    const size_t dim = dense_shape->data.i32[i];\\n+    TF_LITE_ENSURE_MSG(\\n+        context,\\n+        MultiplyAndCheckOverflow(lookup_size, dim, &lookup_size) == kTfLiteOk,\\n+        \"Lookup size overflowed.\");\\n     output_shape->data[k] = dim;\\n   }\\n   for (int i = 1; i < embedding_rank; i++, k++) {\\n-    const int dim = SizeOfDimension(value, i);\\n-    embedding_size *= dim;\\n+    const size_t dim = SizeOfDimension(value, i);\\n+    TF_LITE_ENSURE_MSG(context,\\n+                       MultiplyAndCheckOverflow(embedding_size, dim,\\n+                                                &embedding_size) == kTfLiteOk,\\n+                       \"Embedding size overflowed.\");\\n     output_shape->data[k] = dim;\\n   }\\n   TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_shape));\\n-  const int output_size = lookup_size * embedding_size;\\n+  const size_t output_size = lookup_size * embedding_size;\\n   TfLiteTensorRealloc(output_size * sizeof(float), output);\\n \\n   float* output_ptr = GetTensorData<float>(output);\\n   const float* weights_ptr = GetTensorData<float>(weights);\\n   const float* value_ptr = GetTensorData<float>(value);\\n+  \/\/ Makes sure reallocation was successful.\\n+  TF_LITE_ENSURE(context, output_ptr != nullptr);\\n \\n   std::fill_n(output_ptr, output_size, 0.0f);'}}",
            "message_norm":"[lite] check for overflow when creating required bytes.\n\npiperorigin-revid: 417629001\nchange-id: ia7feb3ea8e988f4fd4b3c98c1a1fed4557d99fd7",
            "language":"en",
            "entities":"[('overflow', 'SECWORD', ''), ('417629001', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/embedding_lookup_sparse.cc'])",
            "num_files":1.0,
            "patch_content":"From 1de49725a5fc4e48f1a3b902ec3599ee99283043 Mon Sep 17 00:00:00 2001\nFrom: Karim Nosir <karimnosseir@google.com>\nDate: Tue, 21 Dec 2021 08:48:11 -0800\nSubject: [PATCH] [lite] Check for overflow when creating required bytes.\n\nPiperOrigin-RevId: 417629001\nChange-Id: Ia7feb3ea8e988f4fd4b3c98c1a1fed4557d99fd7\n---\n ...\/lite\/kernels\/embedding_lookup_sparse.cc   | 23 +++++++++++++------\n 1 file changed, 16 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/embedding_lookup_sparse.cc b\/tensorflow\/lite\/kernels\/embedding_lookup_sparse.cc\nindex 4ad1054340c9c3..a0b9586203a93e 100644\n--- a\/tensorflow\/lite\/kernels\/embedding_lookup_sparse.cc\n+++ b\/tensorflow\/lite\/kernels\/embedding_lookup_sparse.cc\n@@ -72,6 +72,7 @@ limitations under the License.\n #include \"tensorflow\/lite\/kernels\/internal\/tensor_ctypes.h\"\n #include \"tensorflow\/lite\/kernels\/internal\/tensor_utils.h\"\n #include \"tensorflow\/lite\/kernels\/kernel_util.h\"\n+#include \"tensorflow\/lite\/util.h\"\n \n namespace tflite {\n namespace ops {\n@@ -175,25 +176,33 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   TfLiteIntArray* output_shape = TfLiteIntArrayCreate(output_rank);\n   TF_LITE_ENSURE(context, output_shape != nullptr);\n   int k = 0;\n-  int embedding_size = 1;\n-  int lookup_size = 1;\n+  size_t embedding_size = 1;\n+  size_t lookup_size = 1;\n   for (int i = 0; i < lookup_rank - 1; i++, k++) {\n-    const int dim = dense_shape->data.i32[i];\n-    lookup_size *= dim;\n+    const size_t dim = dense_shape->data.i32[i];\n+    TF_LITE_ENSURE_MSG(\n+        context,\n+        MultiplyAndCheckOverflow(lookup_size, dim, &lookup_size) == kTfLiteOk,\n+        \"Lookup size overflowed.\");\n     output_shape->data[k] = dim;\n   }\n   for (int i = 1; i < embedding_rank; i++, k++) {\n-    const int dim = SizeOfDimension(value, i);\n-    embedding_size *= dim;\n+    const size_t dim = SizeOfDimension(value, i);\n+    TF_LITE_ENSURE_MSG(context,\n+                       MultiplyAndCheckOverflow(embedding_size, dim,\n+                                                &embedding_size) == kTfLiteOk,\n+                       \"Embedding size overflowed.\");\n     output_shape->data[k] = dim;\n   }\n   TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_shape));\n-  const int output_size = lookup_size * embedding_size;\n+  const size_t output_size = lookup_size * embedding_size;\n   TfLiteTensorRealloc(output_size * sizeof(float), output);\n \n   float* output_ptr = GetTensorData<float>(output);\n   const float* weights_ptr = GetTensorData<float>(weights);\n   const float* value_ptr = GetTensorData<float>(value);\n+  \/\/ Makes sure reallocation was successful.\n+  TF_LITE_ENSURE(context, output_ptr != nullptr);\n \n   std::fill_n(output_ptr, output_size, 0.0f);"
        },
        {
            "index":337,
            "vuln_id":"GHSA-686h-j8r8-wmfm",
            "cwe_id":"{'CWE-362', 'CWE-77'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/Xudong-Huang\/rcu_cell\/pull\/4\/commits\/1faf18eee11f14969b77ae0f76dcd9ebd437d0c2'}",
            "dataset":"osv",
            "summary":"Data races in rcu_cell Affected versions of this crate unconditionally implement Send\/Sync for `RcuCell<T>`.\nThis allows users to send `T: !Send` to other threads (while `T` enclosed within `RcuCell<T>`), and allows users to concurrently access `T: !Sync` by using the APIs of `RcuCell<T>` that provide access to `&T`.\n\nThis can result in memory corruption caused by data races.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/Xudong-Huang\/rcu_cell",
            "commit_href":"https:\/\/github.com\/Xudong-Huang\/rcu_cell\/pull\/4\/commits\/1faf18eee11f14969b77ae0f76dcd9ebd437d0c2",
            "commit_sha":"1faf18eee11f14969b77ae0f76dcd9ebd437d0c2",
            "patch":"SINGLE",
            "chain_ord":"['1faf18eee11f14969b77ae0f76dcd9ebd437d0c2']",
            "before_first_fix_commit":"{'0e4dc8cd07002a583462994ab4bcfecdf3338fae'}",
            "last_fix_commit":"1faf18eee11f14969b77ae0f76dcd9ebd437d0c2",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/20\/2021, 03:33:02",
            "message":"Fix Send\/Sync impl of RcuCell<T>",
            "author":"JOE1994",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'src\/lib.rs': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Xudong-Huang\/rcu_cell\/raw\/1faf18eee11f14969b77ae0f76dcd9ebd437d0c2\/src%2Flib.rs', 'patch': '@@ -372,8 +372,8 @@ pub struct RcuCell<T> {\\n     link: LinkWrapper<T>,\\n }\\n \\n-unsafe impl<T> Send for RcuCell<T> {}\\n-unsafe impl<T> Sync for RcuCell<T> {}\\n+unsafe impl<T: Send> Send for RcuCell<T> {}\\n+unsafe impl<T: Sync> Sync for RcuCell<T> {}\\n \\n impl<T> Default for RcuCell<T> {\\n     fn default() -> Self {'}}",
            "message_norm":"fix send\/sync impl of rcucell<t>",
            "language":"en",
            "entities":"[('fix', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/lib.rs'])",
            "num_files":1.0,
            "patch_content":"From 1faf18eee11f14969b77ae0f76dcd9ebd437d0c2 Mon Sep 17 00:00:00 2001\nFrom: JOE1994 <joseph942010@gmail.com>\nDate: Tue, 19 Jan 2021 22:33:02 -0500\nSubject: [PATCH] Fix Send\/Sync impl of RcuCell<T>\n\n---\n src\/lib.rs | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/lib.rs b\/src\/lib.rs\nindex 860e5cf..641a153 100644\n--- a\/src\/lib.rs\n+++ b\/src\/lib.rs\n@@ -372,8 +372,8 @@ pub struct RcuCell<T> {\n     link: LinkWrapper<T>,\n }\n \n-unsafe impl<T> Send for RcuCell<T> {}\n-unsafe impl<T> Sync for RcuCell<T> {}\n+unsafe impl<T: Send> Send for RcuCell<T> {}\n+unsafe impl<T: Sync> Sync for RcuCell<T> {}\n \n impl<T> Default for RcuCell<T> {\n     fn default() -> Self {"
        },
        {
            "index":219,
            "vuln_id":"GHSA-24m3-w8g9-jwpq",
            "cwe_id":"{'CWE-178', 'CWE-200'}",
            "score":3.0,
            "chain":"{'https:\/\/github.com\/simplesamlphp\/simplesamlphp\/commit\/47968d26a2fd3ed52da70dc09210921d612ce44e'}",
            "dataset":"osv",
            "summary":"Information disclosure of source code in SimpleSAMLphp ### Background\n\nThe module controller in `SimpleSAML\\Module` that processes requests for pages\nhosted by modules, has code to identify paths ending with `.php` and process\nthose as PHP code. If no other suitable way of handling the given path exists it\npresents the file to the browser.\n\n### Description\n\nThe check to identify paths ending with `.php` does not account for uppercase\nletters. If someone requests a path ending with e.g. `.PHP` and the server is\nserving the code from a case-insensitive file system, such as on Windows, the\nprocessing of the PHP code does not occur, and the source code is instead\npresented to the browser.\n\n### Affected versions\n\nSimpleSAMLphp versions **1.18.5 and older**.\n\n### Impact\n\nAn attacker may use this issue to gain access to the source code in third-party\nmodules that is meant to be private, or even sensitive. However, the attack\nsurface is considered small, as the attack will only work when SimpleSAMLphp\nserves such content from a file system that is not case-sensitive, such as on\nWindows.\n\n### Resolution\n\nUpgrade the SimpleSAMLphp installation to version **1.18.6**.\n\n### Credit\n\nThis vulnerability was discovered and reported by S\u0142awek Naczy\u0144ski.",
            "published_date":"2020-04-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/simplesamlphp\/simplesamlphp",
            "commit_href":"https:\/\/github.com\/simplesamlphp\/simplesamlphp\/commit\/47968d26a2fd3ed52da70dc09210921d612ce44e",
            "commit_sha":"47968d26a2fd3ed52da70dc09210921d612ce44e",
            "patch":"SINGLE",
            "chain_ord":"['47968d26a2fd3ed52da70dc09210921d612ce44e']",
            "before_first_fix_commit":"{'228e4f2287fd5d73727178b87de7a9652bf1c5b0'}",
            "last_fix_commit":"47968d26a2fd3ed52da70dc09210921d612ce44e",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/16\/2020, 12:17:24",
            "message":"Fix source code disclosure on case-insensitive file systems\n\nIf the file system containing the PHP code is case-insensitive, a\nrequest containing an uppercase file extension will return the\ncontents of the PHP file to the browser instead of executing it.\n\nE.g. a request for this URL will return the source code:\n\n  https:\/sp.example.org\/simplesaml\/module.php\/core\/frontpage_welcome.PHP\n\nFix that by converting the path to lowercase before checking the file\nextension.\n\nSee the following page for details:\n\n  https:\/\/github.com\/simplesamlphp\/simplesamlphp\/security\/advisories\/GHSA-24m3-w8g9-jwpq",
            "author":"Olav Morken",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/SimpleSAML\/Module.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/simplesamlphp\/simplesamlphp\/raw\/47968d26a2fd3ed52da70dc09210921d612ce44e\/lib%2FSimpleSAML%2FModule.php', 'patch': \"@@ -259,7 +259,7 @@ function ($val) {\\n             throw new Error\\\\NotFound('The URL wasn\\\\'t found in the module.');\\n         }\\n \\n-        if (substr($path, -4) === '.php') {\\n+        if (mb_strtolower(substr($path, -4), 'UTF-8') === '.php') {\\n             \/\/ PHP file - attempt to run it\\n \\n             \/* In some environments, $_SERVER['SCRIPT_NAME'] is already set with $_SERVER['PATH_INFO']. Check for that\"}}",
            "message_norm":"fix source code disclosure on case-insensitive file systems\n\nif the file system containing the php code is case-insensitive, a\nrequest containing an uppercase file extension will return the\ncontents of the php file to the browser instead of executing it.\n\ne.g. a request for this url will return the source code:\n\n  https:\/sp.example.org\/simplesaml\/module.php\/core\/frontpage_welcome.php\n\nfix that by converting the path to lowercase before checking the file\nextension.\n\nsee the following page for details:\n\n  https:\/\/github.com\/simplesamlphp\/simplesamlphp\/security\/advisories\/ghsa-24m3-w8g9-jwpq",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('disclosure', 'SECWORD', ''), ('https:\/sp.example.org', 'URL', ''), ('https:\/\/github.com\/simplesamlphp\/simplesamlphp\/security\/advisories\/ghsa-24m3-w8g9-jwpq', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/SimpleSAML\/Module.php'])",
            "num_files":1.0,
            "patch_content":"From 47968d26a2fd3ed52da70dc09210921d612ce44e Mon Sep 17 00:00:00 2001\nFrom: Olav Morken <olav.morken@uninett.no>\nDate: Thu, 16 Apr 2020 14:17:24 +0200\nSubject: [PATCH] Fix source code disclosure on case-insensitive file systems\n\nIf the file system containing the PHP code is case-insensitive, a\nrequest containing an uppercase file extension will return the\ncontents of the PHP file to the browser instead of executing it.\n\nE.g. a request for this URL will return the source code:\n\n  https:\/sp.example.org\/simplesaml\/module.php\/core\/frontpage_welcome.PHP\n\nFix that by converting the path to lowercase before checking the file\nextension.\n\nSee the following page for details:\n\n  https:\/\/github.com\/simplesamlphp\/simplesamlphp\/security\/advisories\/GHSA-24m3-w8g9-jwpq\n---\n lib\/SimpleSAML\/Module.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/SimpleSAML\/Module.php b\/lib\/SimpleSAML\/Module.php\nindex d6f5c79cad..dfe056a38f 100644\n--- a\/lib\/SimpleSAML\/Module.php\n+++ b\/lib\/SimpleSAML\/Module.php\n@@ -259,7 +259,7 @@ function ($val) {\n             throw new Error\\NotFound('The URL wasn\\'t found in the module.');\n         }\n \n-        if (substr($path, -4) === '.php') {\n+        if (mb_strtolower(substr($path, -4), 'UTF-8') === '.php') {\n             \/\/ PHP file - attempt to run it\n \n             \/* In some environments, $_SERVER['SCRIPT_NAME'] is already set with $_SERVER['PATH_INFO']. Check for that"
        },
        {
            "index":161,
            "vuln_id":"GHSA-23hm-7w47-xw72",
            "cwe_id":"{'CWE-125'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/23968a8bf65b009120c43b5ebcceaf52dbc9e943'}",
            "dataset":"osv",
            "summary":"Out of bounds read in Tensorflow ### Impact \nThe [implementation of `Dequantize`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/dequantize_op.cc#L92-L153) does not fully validate the value of `axis` and can result in heap OOB accesses:\n\n```python\nimport tensorflow as tf\n\n@tf.function\ndef test():\n  y = tf.raw_ops.Dequantize(\n    input=tf.constant([1,1],dtype=tf.qint32),\n    min_range=[1.0],\n    max_range=[10.0],\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=2**31-1,\n    dtype=tf.bfloat16)\n  return y\n\ntest()\n```\n\nThe `axis` argument can be `-1` (the default value for the optional argument) or any other positive value at most the number of dimensions of the input. Unfortunately, the upper bound is not checked and this results in reading past the end of the array containing the dimensions of the input tensor:\n    \n```cc   \n  if (axis_ > -1) {\n    num_slices = input.dim_size(axis_);\n  }\n  \/\/ ...\n  int64_t pre_dim = 1, post_dim = 1;\n  for (int i = 0; i < axis_; ++i) {\n    pre_dim *= float_output.dim_size(i);\n  }\n  for (int i = axis_ + 1; i < float_output.dims(); ++i) {\n    post_dim *= float_output.dim_size(i);\n  }\n``` \n      \n### Patches\nWe have patched the issue in GitHub commit [23968a8bf65b009120c43b5ebcceaf52dbc9e943](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/23968a8bf65b009120c43b5ebcceaf52dbc9e943).\n  \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n      \n### Attribution\nThis vulnerability has been reported by Yu Tian of Qihoo 360 AIVul Team.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/23968a8bf65b009120c43b5ebcceaf52dbc9e943",
            "commit_sha":"23968a8bf65b009120c43b5ebcceaf52dbc9e943",
            "patch":"SINGLE",
            "chain_ord":"['23968a8bf65b009120c43b5ebcceaf52dbc9e943']",
            "before_first_fix_commit":"{'566576746f47ebf42c38ebe01cca6dbb8832a9ef'}",
            "last_fix_commit":"23968a8bf65b009120c43b5ebcceaf52dbc9e943",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/20\/2021, 07:16:11",
            "message":"Fix out of bound access in DequantizeOp by adding check for axis < input dimension\n\nPiperOrigin-RevId: 411214268\nChange-Id: I3249d2a69ddc82f182c589a3a5bbfb71543f4b29",
            "author":"Isha Arkatkar",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/dequantize_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/23968a8bf65b009120c43b5ebcceaf52dbc9e943\/tensorflow%2Fcore%2Fkernels%2Fdequantize_op.cc', 'patch': '@@ -94,6 +94,11 @@ class DequantizeOp : public OpKernel {\\n     const Tensor& input_min_tensor = ctx->input(1);\\n     const Tensor& input_max_tensor = ctx->input(2);\\n \\n+    OP_REQUIRES(\\n+        ctx, axis_ < input.dims(),\\n+        errors::InvalidArgument(\"Axis must be less than input dimension(\",\\n+                                input.dims(), \"), got \", axis_));\\n+\\n     int num_slices = 1;\\n     if (axis_ > -1) {\\n       num_slices = input.dim_size(axis_);'}}",
            "message_norm":"fix out of bound access in dequantizeop by adding check for axis < input dimension\n\npiperorigin-revid: 411214268\nchange-id: i3249d2a69ddc82f182c589a3a5bbfb71543f4b29",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('out of bound access', 'SECWORD', ''), ('adding', 'ACTION', ''), ('411214268', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/dequantize_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 23968a8bf65b009120c43b5ebcceaf52dbc9e943 Mon Sep 17 00:00:00 2001\nFrom: Isha Arkatkar <ishark@google.com>\nDate: Fri, 19 Nov 2021 23:16:11 -0800\nSubject: [PATCH] Fix out of bound access in DequantizeOp by adding check for\n axis < input dimension\n\nPiperOrigin-RevId: 411214268\nChange-Id: I3249d2a69ddc82f182c589a3a5bbfb71543f4b29\n---\n tensorflow\/core\/kernels\/dequantize_op.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/dequantize_op.cc b\/tensorflow\/core\/kernels\/dequantize_op.cc\nindex 31a7a7498cf0c8..0a466f1cf118e2 100644\n--- a\/tensorflow\/core\/kernels\/dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/dequantize_op.cc\n@@ -94,6 +94,11 @@ class DequantizeOp : public OpKernel {\n     const Tensor& input_min_tensor = ctx->input(1);\n     const Tensor& input_max_tensor = ctx->input(2);\n \n+    OP_REQUIRES(\n+        ctx, axis_ < input.dims(),\n+        errors::InvalidArgument(\"Axis must be less than input dimension(\",\n+                                input.dims(), \"), got \", axis_));\n+\n     int num_slices = 1;\n     if (axis_ > -1) {\n       num_slices = input.dim_size(axis_);"
        },
        {
            "index":182,
            "vuln_id":"GHSA-9hx2-hgq2-2g4f",
            "cwe_id":"{'CWE-400'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/python-pillow\/Pillow\/commit\/6207b44ab1ff4a91d8ddc7579619876d0bb191a4', 'https:\/\/github.com\/python-pillow\/Pillow\/commit\/3bce145966374dd39ce58a6fc0083f8d1890719c'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service (ReDoS) in Pillow An issue was discovered in Pillow before 8.1.1. The PDF parser allows a regular expression DoS (ReDoS) attack via a crafted PDF file because of a catastrophic backtracking regex.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/python-pillow\/Pillow",
            "commit_href":"https:\/\/github.com\/python-pillow\/Pillow\/commit\/3bce145966374dd39ce58a6fc0083f8d1890719c",
            "commit_sha":"3bce145966374dd39ce58a6fc0083f8d1890719c",
            "patch":"MULTI",
            "chain_ord":"['6207b44ab1ff4a91d8ddc7579619876d0bb191a4', '3bce145966374dd39ce58a6fc0083f8d1890719c']",
            "before_first_fix_commit":"{'cbdce6c5d054fccaf4af34b47f212355c64ace7a'}",
            "last_fix_commit":"3bce145966374dd39ce58a6fc0083f8d1890719c",
            "chain_ord_pos":2.0,
            "commit_datetime":"01\/09\/2021, 13:53:09",
            "message":"Use more specific regex chars to prevent ReDoS\n\n* CVE-2021-25292",
            "author":"Hugo van Kemenade",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'src\/PIL\/PdfParser.py': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/python-pillow\/Pillow\/raw\/3bce145966374dd39ce58a6fc0083f8d1890719c\/src%2FPIL%2FPdfParser.py', 'patch': '@@ -580,8 +580,9 @@ def next_object_id(self, offset=None):\\n     whitespace_or_hex = br\"[\\\\000\\\\011\\\\012\\\\014\\\\015\\\\0400-9a-fA-F]\"\\n     whitespace_optional = whitespace + b\"*\"\\n     whitespace_mandatory = whitespace + b\"+\"\\n+    whitespace_optional_no_nl = br\"[\\\\000\\\\011\\\\014\\\\015\\\\040]*\"  # no \"\\\\012\" aka \"\\\\n\"\\n     newline_only = br\"[\\\\r\\\\n]+\"\\n-    newline = whitespace_optional + newline_only + whitespace_optional\\n+    newline = whitespace_optional_no_nl + newline_only + whitespace_optional_no_nl\\n     re_trailer_end = re.compile(\\n         whitespace_mandatory\\n         + br\"trailer\"'}}",
            "message_norm":"use more specific regex chars to prevent redos\n\n* cve-2021-25292",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('redos', 'SECWORD', ''), ('cve-2021-25292', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/PIL\/PdfParser.py'])",
            "num_files":1.0,
            "patch_content":"From 3bce145966374dd39ce58a6fc0083f8d1890719c Mon Sep 17 00:00:00 2001\nFrom: Hugo van Kemenade <hugovk@users.noreply.github.com>\nDate: Sat, 9 Jan 2021 15:53:09 +0200\nSubject: [PATCH] Use more specific regex chars to prevent ReDoS\n\n* CVE-2021-25292\n---\n src\/PIL\/PdfParser.py | 3 ++-\n 1 file changed, 2 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/PIL\/PdfParser.py b\/src\/PIL\/PdfParser.py\nindex 975905f9693..86d78a95c2b 100644\n--- a\/src\/PIL\/PdfParser.py\n+++ b\/src\/PIL\/PdfParser.py\n@@ -580,8 +580,9 @@ def next_object_id(self, offset=None):\n     whitespace_or_hex = br\"[\\000\\011\\012\\014\\015\\0400-9a-fA-F]\"\n     whitespace_optional = whitespace + b\"*\"\n     whitespace_mandatory = whitespace + b\"+\"\n+    whitespace_optional_no_nl = br\"[\\000\\011\\014\\015\\040]*\"  # no \"\\012\" aka \"\\n\"\n     newline_only = br\"[\\r\\n]+\"\n-    newline = whitespace_optional + newline_only + whitespace_optional\n+    newline = whitespace_optional_no_nl + newline_only + whitespace_optional_no_nl\n     re_trailer_end = re.compile(\n         whitespace_mandatory\n         + br\"trailer\""
        },
        {
            "index":72,
            "vuln_id":"GHSA-86wf-436m-h424",
            "cwe_id":"{'CWE-665'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/TooTallNate\/node-http-proxy-agent\/commit\/b7b7cc793c3226aa83f820ce5c277e81862d32eb'}",
            "dataset":"osv",
            "summary":"Resource Exhaustion Denial of Service in http-proxy-agent  A flaw was found in http-proxy-agent, prior to version 2.1.0. It was discovered http-proxy-agent passes an auth option to the Buffer constructor without proper sanitization. This could result in a Denial of Service through the usage of all available CPU resources and data exposure through an uninitialized memory leak in setups where an attacker could submit typed input to the auth parameter.",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/TooTallNate\/node-http-proxy-agent",
            "commit_href":"https:\/\/github.com\/TooTallNate\/node-http-proxy-agent\/commit\/b7b7cc793c3226aa83f820ce5c277e81862d32eb",
            "commit_sha":"b7b7cc793c3226aa83f820ce5c277e81862d32eb",
            "patch":"SINGLE",
            "chain_ord":"['b7b7cc793c3226aa83f820ce5c277e81862d32eb']",
            "before_first_fix_commit":"{'687da671c075cde76be2d3e907d5384c970efadc'}",
            "last_fix_commit":"b7b7cc793c3226aa83f820ce5c277e81862d32eb",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/03\/2018, 23:47:26",
            "message":"Use `Buffer.from()`\n\n`new Buffer()` is deprecated and unsafe.",
            "author":"Nathan Rajlich",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 3, 'total': 8}",
            "files":"{'index.js': {'additions': 5, 'deletions': 3, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/TooTallNate\/node-http-proxy-agent\/raw\/b7b7cc793c3226aa83f820ce5c277e81862d32eb\/index.js', 'patch': \"@@ -75,9 +75,11 @@ HttpProxyAgent.prototype.callback = function connect (req, opts, fn) {\\n   req.path = absolute;\\n \\n   \/\/ inject the `Proxy-Authorization` header if necessary\\n-  var auth = proxy.auth;\\n-  if (auth) {\\n-    req.setHeader('Proxy-Authorization', 'Basic ' + new Buffer(auth).toString('base64'));\\n+  if (proxy.auth) {\\n+    req.setHeader(\\n+      'Proxy-Authorization',\\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64')\\n+    );\\n   }\\n \\n   \/\/ create a socket connection to the proxy server\"}}",
            "message_norm":"use `buffer.from()`\n\n`new buffer()` is deprecated and unsafe.",
            "language":"en",
            "entities":"[('unsafe', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From b7b7cc793c3226aa83f820ce5c277e81862d32eb Mon Sep 17 00:00:00 2001\nFrom: Nathan Rajlich <nathan@tootallnate.net>\nDate: Sat, 3 Mar 2018 15:47:26 -0800\nSubject: [PATCH] Use `Buffer.from()`\n\n`new Buffer()` is deprecated and unsafe.\n---\n index.js | 8 +++++---\n 1 file changed, 5 insertions(+), 3 deletions(-)\n\ndiff --git a\/index.js b\/index.js\nindex 4bc9704..f90a529 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -75,9 +75,11 @@ HttpProxyAgent.prototype.callback = function connect (req, opts, fn) {\n   req.path = absolute;\n \n   \/\/ inject the `Proxy-Authorization` header if necessary\n-  var auth = proxy.auth;\n-  if (auth) {\n-    req.setHeader('Proxy-Authorization', 'Basic ' + new Buffer(auth).toString('base64'));\n+  if (proxy.auth) {\n+    req.setHeader(\n+      'Proxy-Authorization',\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64')\n+    );\n   }\n \n   \/\/ create a socket connection to the proxy server"
        },
        {
            "index":56,
            "vuln_id":"GHSA-5rwj-j5m3-3chj",
            "cwe_id":"{'CWE-401'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/sonicdoe\/detect-character-encoding\/commit\/d44356927b92e3b13e178071bf6d7c671766f588'}",
            "dataset":"osv",
            "summary":"Missing Release of Memory after Effective Lifetime in detect-character-encoding ### Impact\n\nIn detect-character-encoding v0.3.0 and earlier, allocated memory is not released.\n\n### Patches\n\nThe problem has been patched in [detect-character-encoding v0.3.1](https:\/\/github.com\/sonicdoe\/detect-character-encoding\/releases\/tag\/v0.3.1).\n\n### CVSS score\n\n[CVSS:3.1\/AV:N\/AC:L\/PR:N\/UI:N\/S:U\/C:N\/I:N\/A:H\/RL:O\/RC:C](https:\/\/www.first.org\/cvss\/calculator\/3.1#CVSS:3.1\/AV:N\/AC:L\/PR:N\/UI:N\/S:U\/C:N\/I:N\/A:H\/RL:O\/RC:C)\n\nBase Score: 7.5 (High)\nTemporal Score: 7.2 (High)\n\nSince detect-character-encoding is a library, the scoring is based on the \u201c[reasonable worst-case implementation scenario](https:\/\/www.first.org\/cvss\/v3.1\/user-guide#3-7-Scoring-Vulnerabilities-in-Software-Libraries-and-Similar)\u201d, namely, using detect-character-encoding in a program accessible over the internet which becomes unavailable when running out of memory. Depending on your specific implementation, the vulnerability\u2019s severity in your program may be different.\n\n### Proof of concept\n\n```js\nconst express = require(\"express\");\nconst detectCharacterEncoding = require(\"detect-character-encoding\");\n\nconst app = express();\n\napp.get(\"\/\", (req, res) => {\n  detectCharacterEncoding(Buffer.from(\"foo\"));\n\n  res.end();\n});\n\napp.listen(3000);\n```\n\n`hey -n 1000000 http:\/\/localhost:3000` ([`hey`](https:\/\/github.com\/rakyll\/hey)) causes the Node.js process to consume more and more memory.\n\n### References\n\n- https:\/\/github.com\/sonicdoe\/detect-character-encoding\/commit\/d44356927b92e3b13e178071bf6d7c671766f588\n- https:\/\/github.com\/sonicdoe\/detect-character-encoding\/pull\/6",
            "published_date":"2021-09-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/sonicdoe\/detect-character-encoding",
            "commit_href":"https:\/\/github.com\/sonicdoe\/detect-character-encoding\/commit\/d44356927b92e3b13e178071bf6d7c671766f588",
            "commit_sha":"d44356927b92e3b13e178071bf6d7c671766f588",
            "patch":"SINGLE",
            "chain_ord":"['d44356927b92e3b13e178071bf6d7c671766f588']",
            "before_first_fix_commit":"{'2e3aa333a573960edf2d782bca3b25a01e49678b'}",
            "last_fix_commit":"d44356927b92e3b13e178071bf6d7c671766f588",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/09\/2017, 18:19:58",
            "message":"Fix memory leak by properly closing `charsetDetector`",
            "author":"Michael Hertsch",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'icuWrapper.cpp': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sonicdoe\/detect-character-encoding\/raw\/d44356927b92e3b13e178071bf6d7c671766f588\/icuWrapper.cpp', 'patch': '@@ -28,27 +28,31 @@ NAN_METHOD(DetectCharacterEncoding) {\\n \\n \\tif(U_FAILURE(errorCode)) {\\n \\t\\tNan::ThrowError(\"Failed to set ICU charset detector\u2019s text.\");\\n+\\t\\tucsdet_close(charsetDetector);\\n \\t\\treturn;\\n \\t}\\n \\n \\tcharsetMatch = ucsdet_detect(charsetDetector, &errorCode);\\n \\n \\tif(U_FAILURE(errorCode)) {\\n \\t\\tNan::ThrowError(\"Failed to detect charset.\");\\n+\\t\\tucsdet_close(charsetDetector);\\n \\t\\treturn;\\n \\t}\\n \\n \\tconst char *charsetName = ucsdet_getName(charsetMatch, &errorCode);\\n \\n \\tif(U_FAILURE(errorCode)) {\\n \\t\\tNan::ThrowError(\"Failed to get name from charset match.\");\\n+\\t\\tucsdet_close(charsetDetector);\\n \\t\\treturn;\\n \\t}\\n \\n \\tint32_t confidence = ucsdet_getConfidence(charsetMatch, &errorCode);\\n \\n \\tif(U_FAILURE(errorCode)) {\\n \\t\\tNan::ThrowError(\"Failed to get confidence from charset match.\");\\n+\\t\\tucsdet_close(charsetDetector);\\n \\t\\treturn;\\n \\t}\\n \\n@@ -57,6 +61,7 @@ NAN_METHOD(DetectCharacterEncoding) {\\n \\tobj->Set(Nan::New<v8::String>(\"confidence\").ToLocalChecked(), Nan::New<v8::Number>(confidence));\\n \\n \\tinfo.GetReturnValue().Set(obj);\\n+\\tucsdet_close(charsetDetector);\\n }\\n \\n void Init(v8::Local<v8::Object> exports) {'}}",
            "message_norm":"fix memory leak by properly closing `charsetdetector`",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('memory leak', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['icuWrapper.cpp'])",
            "num_files":1.0,
            "patch_content":"From d44356927b92e3b13e178071bf6d7c671766f588 Mon Sep 17 00:00:00 2001\nFrom: Michael Hertsch <mhertsch@t-online.de>\nDate: Thu, 9 Mar 2017 19:19:58 +0100\nSubject: [PATCH] Fix memory leak by properly closing `charsetDetector`\n\n---\n icuWrapper.cpp | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/icuWrapper.cpp b\/icuWrapper.cpp\nindex 440e01ea..a228fe06 100644\n--- a\/icuWrapper.cpp\n+++ b\/icuWrapper.cpp\n@@ -28,6 +28,7 @@ NAN_METHOD(DetectCharacterEncoding) {\n \n \tif(U_FAILURE(errorCode)) {\n \t\tNan::ThrowError(\"Failed to set ICU charset detector\u2019s text.\");\n+\t\tucsdet_close(charsetDetector);\n \t\treturn;\n \t}\n \n@@ -35,6 +36,7 @@ NAN_METHOD(DetectCharacterEncoding) {\n \n \tif(U_FAILURE(errorCode)) {\n \t\tNan::ThrowError(\"Failed to detect charset.\");\n+\t\tucsdet_close(charsetDetector);\n \t\treturn;\n \t}\n \n@@ -42,6 +44,7 @@ NAN_METHOD(DetectCharacterEncoding) {\n \n \tif(U_FAILURE(errorCode)) {\n \t\tNan::ThrowError(\"Failed to get name from charset match.\");\n+\t\tucsdet_close(charsetDetector);\n \t\treturn;\n \t}\n \n@@ -49,6 +52,7 @@ NAN_METHOD(DetectCharacterEncoding) {\n \n \tif(U_FAILURE(errorCode)) {\n \t\tNan::ThrowError(\"Failed to get confidence from charset match.\");\n+\t\tucsdet_close(charsetDetector);\n \t\treturn;\n \t}\n \n@@ -57,6 +61,7 @@ NAN_METHOD(DetectCharacterEncoding) {\n \tobj->Set(Nan::New<v8::String>(\"confidence\").ToLocalChecked(), Nan::New<v8::Number>(confidence));\n \n \tinfo.GetReturnValue().Set(obj);\n+\tucsdet_close(charsetDetector);\n }\n \n void Init(v8::Local<v8::Object> exports) {"
        },
        {
            "index":433,
            "vuln_id":"GHSA-72p8-v4hg-v45p",
            "cwe_id":"{'CWE-330', 'CWE-338'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/sshnet\/SSH.NET\/commit\/03c6d60736b8f7b42e44d6989a53f9b644a091fb', 'https:\/\/github.com\/sshnet\/SSH.NET\/commit\/f1f273cf349532b9d41c1de51d3b83a9accedc88'}",
            "dataset":"osv",
            "summary":"Weak private key generation in SSH.NET During an **X25519** key exchange, the client\u2019s private is generated with [**System.Random**](https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/system.random):\n\n```cs\nvar rnd = new Random();\n_privateKey = new byte[MontgomeryCurve25519.PrivateKeySizeInBytes];\nrnd.NextBytes(_privateKey);\n```\n\nSource: [KeyExchangeECCurve25519.cs](https:\/\/github.com\/sshnet\/SSH.NET\/blob\/bc99ada7da3f05f50d9379f2644941d91d5bf05a\/src\/Renci.SshNet\/Security\/KeyExchangeECCurve25519.cs#L51)  \nSource commit: https:\/\/github.com\/sshnet\/SSH.NET\/commit\/b58a11c0da55da1f5bad46faad2e9b71b7cb35b3\n\n[**System.Random**](https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/system.random) is not a cryptographically secure random number generator, it must therefore not be used for cryptographic purposes.\n\n### Impact\nWhen establishing an SSH connection to a remote host, during the X25519 key exchange, the private key is generated with\na weak random number generator whose seed can be bruteforced. This allows an attacker able to eavesdrop the\ncommunications to decrypt them.\n\n### Workarounds\nTo ensure you're not affected by this vulnerability, you can disable support for `curve25519-sha256` and `curve25519-sha256@libssh.org` key exchange algorithms by invoking the following method before a connection is established:\n```cs\nprivate static void RemoveUnsecureKEX(BaseClient client)\n{\n    client.ConnectionInfo.KeyExchangeAlgorithms.Remove(\"curve25519-sha256\");\n    client.ConnectionInfo.KeyExchangeAlgorithms.Remove(\"curve25519-sha256@libssh.org\");\n}\n```\n\n### Thanks\n\nThis issue was initially reported by **Siemens AG, Digital Industries**, shortly followed by @yaumn-synacktiv.",
            "published_date":"2022-06-01",
            "chain_len":2,
            "project":"https:\/\/github.com\/sshnet\/SSH.NET",
            "commit_href":"https:\/\/github.com\/sshnet\/SSH.NET\/commit\/03c6d60736b8f7b42e44d6989a53f9b644a091fb",
            "commit_sha":"03c6d60736b8f7b42e44d6989a53f9b644a091fb",
            "patch":"MULTI",
            "chain_ord":"['f1f273cf349532b9d41c1de51d3b83a9accedc88', '03c6d60736b8f7b42e44d6989a53f9b644a091fb']",
            "before_first_fix_commit":"{'cad943343b4c7ea55975a3033ef1cd0646b6b9d7'}",
            "last_fix_commit":"03c6d60736b8f7b42e44d6989a53f9b644a091fb",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/29\/2022, 14:58:07",
            "message":"Use cryptographically secure random number generator.\nFixes CVE-2022-29245.",
            "author":"drieseng",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 3, 'total': 4}",
            "files":"{'src\/Renci.SshNet\/Security\/KeyExchangeECCurve25519.cs': {'additions': 1, 'deletions': 3, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sshnet\/SSH.NET\/raw\/03c6d60736b8f7b42e44d6989a53f9b644a091fb\/src%2FRenci.SshNet%2FSecurity%2FKeyExchangeECCurve25519.cs', 'patch': '@@ -46,9 +46,7 @@ public override void Start(Session session, KeyExchangeInitMessage message)\\n             var basepoint = new byte[MontgomeryCurve25519.PublicKeySizeInBytes];\\n             basepoint[0] = 9;\\n \\n-            var rnd = new Random();\\n-            _privateKey = new byte[MontgomeryCurve25519.PrivateKeySizeInBytes];\\n-            rnd.NextBytes(_privateKey);\\n+            _privateKey = CryptoAbstraction.GenerateRandom(MontgomeryCurve25519.PrivateKeySizeInBytes);\\n \\n             _clientExchangeValue = new byte[MontgomeryCurve25519.PublicKeySizeInBytes];\\n             MontgomeryOperations.scalarmult(_clientExchangeValue, 0, _privateKey, 0, basepoint, 0);'}}",
            "message_norm":"use cryptographically secure random number generator.\nfixes cve-2022-29245.",
            "language":"en",
            "entities":"[('cryptographically', 'SECWORD', ''), ('secure', 'SECWORD', ''), ('cve-2022-29245', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Renci.SshNet\/Security\/KeyExchangeECCurve25519.cs'])",
            "num_files":1.0,
            "patch_content":"From 03c6d60736b8f7b42e44d6989a53f9b644a091fb Mon Sep 17 00:00:00 2001\nFrom: drieseng <gert.driesen@telenet.be>\nDate: Sun, 29 May 2022 16:58:07 +0200\nSubject: [PATCH] Use cryptographically secure random number generator. Fixes\n CVE-2022-29245.\n\n---\n src\/Renci.SshNet\/Security\/KeyExchangeECCurve25519.cs | 4 +---\n 1 file changed, 1 insertion(+), 3 deletions(-)\n\ndiff --git a\/src\/Renci.SshNet\/Security\/KeyExchangeECCurve25519.cs b\/src\/Renci.SshNet\/Security\/KeyExchangeECCurve25519.cs\nindex 9de7af8fb..1fba1c207 100644\n--- a\/src\/Renci.SshNet\/Security\/KeyExchangeECCurve25519.cs\n+++ b\/src\/Renci.SshNet\/Security\/KeyExchangeECCurve25519.cs\n@@ -46,9 +46,7 @@ public override void Start(Session session, KeyExchangeInitMessage message)\n             var basepoint = new byte[MontgomeryCurve25519.PublicKeySizeInBytes];\n             basepoint[0] = 9;\n \n-            var rnd = new Random();\n-            _privateKey = new byte[MontgomeryCurve25519.PrivateKeySizeInBytes];\n-            rnd.NextBytes(_privateKey);\n+            _privateKey = CryptoAbstraction.GenerateRandom(MontgomeryCurve25519.PrivateKeySizeInBytes);\n \n             _clientExchangeValue = new byte[MontgomeryCurve25519.PublicKeySizeInBytes];\n             MontgomeryOperations.scalarmult(_clientExchangeValue, 0, _privateKey, 0, basepoint, 0);"
        },
        {
            "index":679,
            "vuln_id":"GHSA-c45w-2wxr-pp53",
            "cwe_id":"{'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b'}",
            "dataset":"osv",
            "summary":"Heap OOB read in `tf.raw_ops.Dequantize` ### Impact\nDue to lack of validation in `tf.raw_ops.Dequantize`, an attacker can trigger a read from outside of bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\ninput_tensor=tf.constant(\n  [75, 75, 75, 75, -6, -9, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10], shape=[5, 10], dtype=tf.int32)\ninput_tensor=tf.cast(input_tensor, dtype=tf.quint8)\nmin_range = tf.constant([-10], shape=[1], dtype=tf.float32)\nmax_range = tf.constant([24, 758, 758, 758, 758], shape=[5], dtype=tf.float32)\n  \ntf.raw_ops.Dequantize( \n  input=input_tensor, min_range=min_range, max_range=max_range, mode='SCALED',\n  narrow_range=True, axis=0, dtype=tf.dtypes.float32)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/26003593aa94b1742f34dc22ce88a1e17776a67d\/tensorflow\/core\/kernels\/dequantize_op.cc#L106-L131) accesses the `min_range` and `max_range` tensors in parallel but fails to check that they have the same shape:\n\n```cc\nif (num_slices == 1) {\n  const float min_range = input_min_tensor.flat<float>()(0);\n  const float max_range = input_max_tensor.flat<float>()(0);\n  DequantizeTensor(ctx, input, min_range, max_range, &float_output);\n} else {\n  ...\n  auto min_ranges = input_min_tensor.vec<float>();\n  auto max_ranges = input_max_tensor.vec<float>();\n  for (int i = 0; i < num_slices; ++i) {\n    DequantizeSlice(ctx->eigen_device<Device>(), ctx,\n                    input_tensor.template chip<1>(i), min_ranges(i),\n                    max_ranges(i), output_tensor.template chip<1>(i));\n    ...\n  }\n}\n```\n\n### Patches\nWe have patched the issue in GitHub commit [5899741d0421391ca878da47907b1452f06aaf1b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b",
            "commit_sha":"5899741d0421391ca878da47907b1452f06aaf1b",
            "patch":"SINGLE",
            "chain_ord":"['5899741d0421391ca878da47907b1452f06aaf1b']",
            "before_first_fix_commit":"{'26003593aa94b1742f34dc22ce88a1e17776a67d'}",
            "last_fix_commit":"5899741d0421391ca878da47907b1452f06aaf1b",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 22:31:05",
            "message":"Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'tensorflow\/core\/kernels\/dequantize_op.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/5899741d0421391ca878da47907b1452f06aaf1b\/tensorflow%2Fcore%2Fkernels%2Fdequantize_op.cc', 'patch': '@@ -98,6 +98,18 @@ class DequantizeOp : public OpKernel {\\n     if (axis_ > -1) {\\n       num_slices = input.dim_size(axis_);\\n     }\\n+    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\\n+                errors::InvalidArgument(\\n+                    \"input_min_tensor must have as many elements as input on \"\\n+                    \"the dequantization axis (\",\\n+                    axis_, \"), got \", input_min_tensor.NumElements(),\\n+                    \", expected \", num_slices));\\n+    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,\\n+                errors::InvalidArgument(\\n+                    \"input_max_tensor must have as many elements as input on \"\\n+                    \"the dequantization axis (\",\\n+                    axis_, \"), got \", input_max_tensor.NumElements(),\\n+                    \", expected \", num_slices));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));'}}",
            "message_norm":"fix heap oob read in dequantize op.\n\nalso fixes segv in same op\n\npiperorigin-revid: 372437896\nchange-id: i135e94d360c2a1ce374c10f7e0fed1af603dbc02",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('372437896', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/dequantize_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 5899741d0421391ca878da47907b1452f06aaf1b Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 6 May 2021 15:31:05 -0700\nSubject: [PATCH] Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02\n---\n tensorflow\/core\/kernels\/dequantize_op.cc | 12 ++++++++++++\n 1 file changed, 12 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/dequantize_op.cc b\/tensorflow\/core\/kernels\/dequantize_op.cc\nindex 5393a677db242a..7a90e0c340b093 100644\n--- a\/tensorflow\/core\/kernels\/dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/dequantize_op.cc\n@@ -98,6 +98,18 @@ class DequantizeOp : public OpKernel {\n     if (axis_ > -1) {\n       num_slices = input.dim_size(axis_);\n     }\n+    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_min_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_min_tensor.NumElements(),\n+                    \", expected \", num_slices));\n+    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_max_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_max_tensor.NumElements(),\n+                    \", expected \", num_slices));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));"
        },
        {
            "index":351,
            "vuln_id":"GHSA-rrx2-r989-2c43",
            "cwe_id":"{'CWE-190'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1b54cadd19391b60b6fcccd8d076426f7221d5e8', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e952a89b7026b98fe8cbe626514a93ed68b7c510'}",
            "dataset":"osv",
            "summary":"Integer overflows in Tensorflow ### Impact \nThe [implementations of `Sparse*Cwise*` ops](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc) are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service):\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ntf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices=np.array([[9]]),\n    sp_values=np.array([5]),\n    sp_shape=np.array([92233720368., 92233720368]),\n    dense=np.array([4]))\n```\n\nWe are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The latter is an instance of [TFSA-2021-198](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/security\/advisory\/tfsa-2021-198.md) (CVE-2021-41197) and is easily fixed by replacing a call to `TensorShape` constructor with a call to `BuildTensorShape` static helper factory.\n\n### Patches\nWe have patched the issue in GitHub commits [1b54cadd19391b60b6fcccd8d076426f7221d5e8](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1b54cadd19391b60b6fcccd8d076426f7221d5e8) and [e952a89b7026b98fe8cbe626514a93ed68b7c510](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e952a89b7026b98fe8cbe626514a93ed68b7c510).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
            "published_date":"2022-02-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e952a89b7026b98fe8cbe626514a93ed68b7c510",
            "commit_sha":"e952a89b7026b98fe8cbe626514a93ed68b7c510",
            "patch":"MULTI",
            "chain_ord":"['1b54cadd19391b60b6fcccd8d076426f7221d5e8', 'e952a89b7026b98fe8cbe626514a93ed68b7c510']",
            "before_first_fix_commit":"{'1b54cadd19391b60b6fcccd8d076426f7221d5e8'}",
            "last_fix_commit":"e952a89b7026b98fe8cbe626514a93ed68b7c510",
            "chain_ord_pos":2.0,
            "commit_datetime":"12\/10\/2021, 17:46:48",
            "message":"Prevent overflow in sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543171\nChange-Id: I22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e952a89b7026b98fe8cbe626514a93ed68b7c510\/tensorflow%2Fcore%2Fkernels%2Fsparse_dense_binary_op_shared.cc', 'patch': '@@ -99,7 +99,9 @@ class SparseDenseBinaryOpShared : public OpKernel {\\n \\n     const auto indices_mat = indices_t->matrix<int64_t>();\\n     const auto shape_vec = shape_t->vec<int64_t>();\\n-    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\\n+    TensorShape lhs_shape;\\n+    OP_REQUIRES_OK(ctx, TensorShape::BuildTensorShape(shape_vec, &lhs_shape));\\n+    const auto lhs_dims = BCast::FromShape(lhs_shape);\\n     const auto rhs_dims = BCast::FromShape(dense_t->shape());\\n     BCast b(lhs_dims, rhs_dims, false);  \/\/ false for keeping the same num dims.'}}",
            "message_norm":"prevent overflow in sparse dense cwise ops.\n\npiperorigin-revid: 415543171\nchange-id: i22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('415543171', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc'])",
            "num_files":1.0,
            "patch_content":"From e952a89b7026b98fe8cbe626514a93ed68b7c510 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 10 Dec 2021 09:46:48 -0800\nSubject: [PATCH] Prevent overflow in sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543171\nChange-Id: I22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8\n---\n tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc | 4 +++-\n 1 file changed, 3 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc b\/tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc\nindex db27abfda7e537..29534bf0a2625c 100644\n--- a\/tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc\n@@ -99,7 +99,9 @@ class SparseDenseBinaryOpShared : public OpKernel {\n \n     const auto indices_mat = indices_t->matrix<int64_t>();\n     const auto shape_vec = shape_t->vec<int64_t>();\n-    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n+    TensorShape lhs_shape;\n+    OP_REQUIRES_OK(ctx, TensorShape::BuildTensorShape(shape_vec, &lhs_shape));\n+    const auto lhs_dims = BCast::FromShape(lhs_shape);\n     const auto rhs_dims = BCast::FromShape(dense_t->shape());\n     BCast b(lhs_dims, rhs_dims, false);  \/\/ false for keeping the same num dims."
        },
        {
            "index":754,
            "vuln_id":"GHSA-7vvq-7r29-5vg3",
            "cwe_id":"{'CWE-79'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/mrdoob\/three.js\/commit\/0c31bc605e21965aad8a6479bb1969351773f76d'}",
            "dataset":"osv",
            "summary":"Cross site scripting in three.js # CVE has been withdrawn\n\nVersions of three.js prior to 0.137.0 load untrusted iframes and allow for attackers to inject arbitrary javascript into a users browser.",
            "published_date":"2022-01-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/mrdoob\/three.js",
            "commit_href":"https:\/\/github.com\/mrdoob\/three.js\/commit\/0c31bc605e21965aad8a6479bb1969351773f76d",
            "commit_sha":"0c31bc605e21965aad8a6479bb1969351773f76d",
            "patch":"SINGLE",
            "chain_ord":"['0c31bc605e21965aad8a6479bb1969351773f76d']",
            "before_first_fix_commit":"{'55d4f24cb50e995b0dfee73979305e8237384a53'}",
            "last_fix_commit":"0c31bc605e21965aad8a6479bb1969351773f76d",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/24\/2022, 17:39:24",
            "message":"Only load trusted iframe (#23245)",
            "author":"Rohan Sharma",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'docs\/index.html': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mrdoob\/three.js\/raw\/0c31bc605e21965aad8a6479bb1969351773f76d\/docs%2Findex.html', 'patch': '@@ -498,7 +498,7 @@ <h1><a href=\"https:\/\/threejs.org\">three.js<\/a><\/h1>\\n \\t\\t\\tconst oldIframe = iframe;\\n \\t\\t\\tiframe = oldIframe.cloneNode();\\n \\n-\\t\\t\\tif ( hash ) {\\n+\\t\\t\\tif ( hash && titles[ splitHash[ 0 ] ] ) {\\n \\n \\t\\t\\t\\tiframe.src = splitHash[ 0 ] + \\'.html\\' + splitHash[ 1 ];\\n \\t\\t\\t\\tsubtitle = titles[ splitHash[ 0 ] ] + splitHash[ 1 ] + \\' \u2013 \\';'}}",
            "message_norm":"only load trusted iframe (#23245)",
            "language":"en",
            "entities":"[('#23245', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['docs\/index.html'])",
            "num_files":1.0,
            "patch_content":"From 0c31bc605e21965aad8a6479bb1969351773f76d Mon Sep 17 00:00:00 2001\nFrom: Rohan Sharma <i.am.lone.survivor@protonmail.com>\nDate: Mon, 24 Jan 2022 23:09:24 +0530\nSubject: [PATCH] Only load trusted iframe (#23245)\n\n---\n docs\/index.html | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/docs\/index.html b\/docs\/index.html\nindex a793da74a23b48..c8a41b4b2b1e73 100644\n--- a\/docs\/index.html\n+++ b\/docs\/index.html\n@@ -498,7 +498,7 @@ <h1><a href=\"https:\/\/threejs.org\">three.js<\/a><\/h1>\n \t\t\tconst oldIframe = iframe;\n \t\t\tiframe = oldIframe.cloneNode();\n \n-\t\t\tif ( hash ) {\n+\t\t\tif ( hash && titles[ splitHash[ 0 ] ] ) {\n \n \t\t\t\tiframe.src = splitHash[ 0 ] + '.html' + splitHash[ 1 ];\n \t\t\t\tsubtitle = titles[ splitHash[ 0 ] ] + splitHash[ 1 ] + ' \u2013 ';"
        },
        {
            "index":722,
            "vuln_id":"GHSA-cfpj-3q4c-jhvr",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/718721986aa137691ee23f03638867151f74935f'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite ### Impact\nThe implementation of fully connected layers in TFLite is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/lite\/kernels\/fully_connected.cc#L226):\n\n```cc\nconst int batch_size = input_size \/ filter->dims->data[1];\n```\n\nAn attacker can craft a model such that `filter->dims->data[1]` is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [718721986aa137691ee23f03638867151f74935f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/718721986aa137691ee23f03638867151f74935f).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360. Concurrently, it has also been reported by Yakun Zhang of Baidu Security.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/718721986aa137691ee23f03638867151f74935f",
            "commit_sha":"718721986aa137691ee23f03638867151f74935f",
            "patch":"SINGLE",
            "chain_ord":"['718721986aa137691ee23f03638867151f74935f']",
            "before_first_fix_commit":"{'985f07145a0cab0fd6018fdfc0b221b17e0c5a88'}",
            "last_fix_commit":"718721986aa137691ee23f03638867151f74935f",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/16\/2021, 13:49:45",
            "message":"Prevent division by 0 in `fully_connected.cc`\n\nPiperOrigin-RevId: 385137282\nChange-Id: If201e69b6e0048f0be001330b4b977e2b46db2cb",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/lite\/kernels\/fully_connected.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/718721986aa137691ee23f03638867151f74935f\/tensorflow%2Flite%2Fkernels%2Ffully_connected.cc', 'patch': '@@ -223,6 +223,7 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\\n   }\\n \\n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);\\n+  TF_LITE_ENSURE(context, filter->dims->data[1] != 0);\\n   const int batch_size = input_size \/ filter->dims->data[1];\\n   const int num_units = filter->dims->data[0];'}}",
            "message_norm":"prevent division by 0 in `fully_connected.cc`\n\npiperorigin-revid: 385137282\nchange-id: if201e69b6e0048f0be001330b4b977e2b46db2cb",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('385137282', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/fully_connected.cc'])",
            "num_files":1.0,
            "patch_content":"From 718721986aa137691ee23f03638867151f74935f Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 16 Jul 2021 06:49:45 -0700\nSubject: [PATCH] Prevent division by 0 in `fully_connected.cc`\n\nPiperOrigin-RevId: 385137282\nChange-Id: If201e69b6e0048f0be001330b4b977e2b46db2cb\n---\n tensorflow\/lite\/kernels\/fully_connected.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/fully_connected.cc b\/tensorflow\/lite\/kernels\/fully_connected.cc\nindex 4ebaa7877fa38c..d0010e302618dd 100644\n--- a\/tensorflow\/lite\/kernels\/fully_connected.cc\n+++ b\/tensorflow\/lite\/kernels\/fully_connected.cc\n@@ -223,6 +223,7 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);\n+  TF_LITE_ENSURE(context, filter->dims->data[1] != 0);\n   const int batch_size = input_size \/ filter->dims->data[1];\n   const int num_units = filter->dims->data[0];"
        },
        {
            "index":568,
            "vuln_id":"GHSA-vg44-fw64-cpjx",
            "cwe_id":"{'CWE-287'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/commit\/f32e529d13a53e55f558d903534d631846dc26ce'}",
            "dataset":"osv",
            "summary":"Incorrect Account Used for Signing ### Impact\n\nAnybody using this library to sign with a BIP44 account other than the first account may be affected. If a user is signing with the first account (i.e. the account at index `0`), or with the legacy MEW\/MyCrypto HD path, they are not affected.\n\nThe vulnerability impacts cases where the user signs a personal message or transaction without first adding the account. This includes cases where the user has already added the account in a previous session (i.e. they added the account, reset the application, then signed something). The serialization\/deserialization process does restore a previously added account, but it doesn&#39;t restore the index instructing the keyring to use that account for signing. As a result, after serializing then deserializing the keyring state, the account at index `0` is always used for signing even if it isn&#39;t the current account.\n\n### Patches\n\nThis has been patched ([#14](https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/pull\/14)) in version &gt;=0.2.1 of [`eth-ledger-bridge-keyring`](https:\/\/www.npmjs.com\/package\/eth-ledger-bridge-keyring), and in version &gt;=0.2.2 of [`@metamask\/eth-ledger-bridge-keyring`](https:\/\/www.npmjs.com\/package\/@metamask\/eth-ledger-bridge-keyring). Users are encouraged to migrate to the new package name.\n\n### Workarounds\n\nTo work around this problem without updating, you should remove then re-add the account before use. As long as the account was added during the lifetime of that process, signing with that account should work correctly.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [MetaMask\/eth-ledger-bridge-keyring on GitHub](https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring)\n* Email the MetaMask team at [hello@metamask.io](mailto:hello@metamask.io)",
            "published_date":"2020-03-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring",
            "commit_href":"https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/commit\/f32e529d13a53e55f558d903534d631846dc26ce",
            "commit_sha":"f32e529d13a53e55f558d903534d631846dc26ce",
            "patch":"SINGLE",
            "chain_ord":"['f32e529d13a53e55f558d903534d631846dc26ce']",
            "before_first_fix_commit":"{'25d96289bdffb369a70cbafd70b4ca1f1be47fcc'}",
            "last_fix_commit":"f32e529d13a53e55f558d903534d631846dc26ce",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/02\/2020, 22:58:21",
            "message":"Always sign transactions and messages with the correct account (#14)\n\nThe account used to sign transactions and messages should be the one\r\nthe transaction or message is from. Instead, the last connected account\r\nwas being used to sign any messages or transactions.\r\n\r\nThis was especially problematic considering the last connected account\r\nwas not persisted, meaning that signatures were being performed with\r\nthe wrong account after a reset (unless the last connected account\r\nhappened to be account 0, which was the default).\r\n\r\nA mapping of addresses to indexes as been added to the keyring state,\r\nand this mapping has been persisted. This should ensure the correct\r\naccount index is used, and thus the correct hd path, each time this\r\nkeyring is used for signing.",
            "author":"Mark Stacey",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 2, 'total': 17}",
            "files":"{'index.js': {'additions': 15, 'deletions': 2, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/raw\/f32e529d13a53e55f558d903534d631846dc26ce\/index.js', 'patch': \"@@ -18,6 +18,7 @@ const NETWORK_API_URLS = {\\n class LedgerBridgeKeyring extends EventEmitter {\\n   constructor (opts = {}) {\\n     super()\\n+    this.accountIndexes = {}\\n     this.bridgeUrl = null\\n     this.type = type\\n     this.page = 0\\n@@ -36,6 +37,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n     return Promise.resolve({\\n       hdPath: this.hdPath,\\n       accounts: this.accounts,\\n+      accountIndexes: this.accountIndexes,\\n       bridgeUrl: this.bridgeUrl,\\n       implementFullBIP44: false,\\n     })\\n@@ -45,6 +47,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n     this.hdPath = opts.hdPath || hdPathString\\n     this.bridgeUrl = opts.bridgeUrl || BRIDGE_URL\\n     this.accounts = opts.accounts || []\\n+    this.accountIndexes = opts.accountIndexes || {}\\n     this.implementFullBIP44 = opts.implementFullBIP44 || false\\n     return Promise.resolve()\\n   }\\n@@ -100,6 +103,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n             if (this._isBIP44()) {\\n               const path = this._getPathForIndex(i)\\n               address = await this.unlock(path)\\n+              this.accountIndexes[ethUtil.toChecksumAddress(address)] = i\\n             } else {\\n               address = this._addressFromIndex(pathBase, i)\\n             }\\n@@ -136,6 +140,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n       throw new Error(`Address ${address} not found in this keyring`)\\n     }\\n     this.accounts = this.accounts.filter(a => a.toLowerCase() !== address.toLowerCase())\\n+    delete this.accountIndexes[ethUtil.toChecksumAddress(address)]\\n   }\\n \\n   \/\/ tx is an instance of the ethereumjs-transaction class.\\n@@ -150,7 +155,11 @@ class LedgerBridgeKeyring extends EventEmitter {\\n \\n           let hdPath\\n           if (this._isBIP44()) {\\n-            hdPath = this._getPathForIndex(this.unlockedAccount)\\n+            const checksummedAddress = ethUtil.toChecksumAddress(address)\\n+            if (!this.accountIndexes[checksummedAddress]) {\\n+              reject(new Error(`Ledger: Index for address '${checksummedAddress}' not found`))\\n+            }\\n+            hdPath = this._getPathForIndex(this.accountIndexes[checksummedAddress])\\n           } else {\\n             hdPath = this._toLedgerPath(this._pathFromAddress(address))\\n           }\\n@@ -195,7 +204,11 @@ class LedgerBridgeKeyring extends EventEmitter {\\n         .then(_ => {\\n           let hdPath\\n           if (this._isBIP44()) {\\n-            hdPath = this._getPathForIndex(this.unlockedAccount)\\n+            const checksummedAddress = ethUtil.toChecksumAddress(withAccount)\\n+            if (!this.accountIndexes[checksummedAddress]) {\\n+              reject(new Error(`Ledger: Index for address '${checksummedAddress}' not found`))\\n+            }\\n+            hdPath = this._getPathForIndex(this.accountIndexes[checksummedAddress])\\n           } else {\\n             hdPath = this._toLedgerPath(this._pathFromAddress(withAccount))\\n           }\"}}",
            "message_norm":"always sign transactions and messages with the correct account (#14)\n\nthe account used to sign transactions and messages should be the one\r\nthe transaction or message is from. instead, the last connected account\r\nwas being used to sign any messages or transactions.\r\n\r\nthis was especially problematic considering the last connected account\r\nwas not persisted, meaning that signatures were being performed with\r\nthe wrong account after a reset (unless the last connected account\r\nhappened to be account 0, which was the default).\r\n\r\na mapping of addresses to indexes as been added to the keyring state,\r\nand this mapping has been persisted. this should ensure the correct\r\naccount index is used, and thus the correct hd path, each time this\r\nkeyring is used for signing.",
            "language":"en",
            "entities":"[('#14', 'ISSUE', ''), ('added', 'ACTION', ''), ('keyring', 'SECWORD', ''), ('ensure', 'ACTION', ''), ('keyring', 'SECWORD', ''), ('signing', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From f32e529d13a53e55f558d903534d631846dc26ce Mon Sep 17 00:00:00 2001\nFrom: Mark Stacey <markjstacey@gmail.com>\nDate: Mon, 2 Mar 2020 18:58:21 -0400\nSubject: [PATCH] Always sign transactions and messages with the correct\n account (#14)\n\nThe account used to sign transactions and messages should be the one\nthe transaction or message is from. Instead, the last connected account\nwas being used to sign any messages or transactions.\n\nThis was especially problematic considering the last connected account\nwas not persisted, meaning that signatures were being performed with\nthe wrong account after a reset (unless the last connected account\nhappened to be account 0, which was the default).\n\nA mapping of addresses to indexes as been added to the keyring state,\nand this mapping has been persisted. This should ensure the correct\naccount index is used, and thus the correct hd path, each time this\nkeyring is used for signing.\n---\n index.js | 17 +++++++++++++++--\n 1 file changed, 15 insertions(+), 2 deletions(-)\n\ndiff --git a\/index.js b\/index.js\nindex 7cb91a84..f9bc64c0 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -18,6 +18,7 @@ const NETWORK_API_URLS = {\n class LedgerBridgeKeyring extends EventEmitter {\n   constructor (opts = {}) {\n     super()\n+    this.accountIndexes = {}\n     this.bridgeUrl = null\n     this.type = type\n     this.page = 0\n@@ -36,6 +37,7 @@ class LedgerBridgeKeyring extends EventEmitter {\n     return Promise.resolve({\n       hdPath: this.hdPath,\n       accounts: this.accounts,\n+      accountIndexes: this.accountIndexes,\n       bridgeUrl: this.bridgeUrl,\n       implementFullBIP44: false,\n     })\n@@ -45,6 +47,7 @@ class LedgerBridgeKeyring extends EventEmitter {\n     this.hdPath = opts.hdPath || hdPathString\n     this.bridgeUrl = opts.bridgeUrl || BRIDGE_URL\n     this.accounts = opts.accounts || []\n+    this.accountIndexes = opts.accountIndexes || {}\n     this.implementFullBIP44 = opts.implementFullBIP44 || false\n     return Promise.resolve()\n   }\n@@ -100,6 +103,7 @@ class LedgerBridgeKeyring extends EventEmitter {\n             if (this._isBIP44()) {\n               const path = this._getPathForIndex(i)\n               address = await this.unlock(path)\n+              this.accountIndexes[ethUtil.toChecksumAddress(address)] = i\n             } else {\n               address = this._addressFromIndex(pathBase, i)\n             }\n@@ -136,6 +140,7 @@ class LedgerBridgeKeyring extends EventEmitter {\n       throw new Error(`Address ${address} not found in this keyring`)\n     }\n     this.accounts = this.accounts.filter(a => a.toLowerCase() !== address.toLowerCase())\n+    delete this.accountIndexes[ethUtil.toChecksumAddress(address)]\n   }\n \n   \/\/ tx is an instance of the ethereumjs-transaction class.\n@@ -150,7 +155,11 @@ class LedgerBridgeKeyring extends EventEmitter {\n \n           let hdPath\n           if (this._isBIP44()) {\n-            hdPath = this._getPathForIndex(this.unlockedAccount)\n+            const checksummedAddress = ethUtil.toChecksumAddress(address)\n+            if (!this.accountIndexes[checksummedAddress]) {\n+              reject(new Error(`Ledger: Index for address '${checksummedAddress}' not found`))\n+            }\n+            hdPath = this._getPathForIndex(this.accountIndexes[checksummedAddress])\n           } else {\n             hdPath = this._toLedgerPath(this._pathFromAddress(address))\n           }\n@@ -195,7 +204,11 @@ class LedgerBridgeKeyring extends EventEmitter {\n         .then(_ => {\n           let hdPath\n           if (this._isBIP44()) {\n-            hdPath = this._getPathForIndex(this.unlockedAccount)\n+            const checksummedAddress = ethUtil.toChecksumAddress(withAccount)\n+            if (!this.accountIndexes[checksummedAddress]) {\n+              reject(new Error(`Ledger: Index for address '${checksummedAddress}' not found`))\n+            }\n+            hdPath = this._getPathForIndex(this.accountIndexes[checksummedAddress])\n           } else {\n             hdPath = this._toLedgerPath(this._pathFromAddress(withAccount))\n           }"
        },
        {
            "index":883,
            "vuln_id":"GHSA-2rfj-2mwp-787v",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/3d6226cc2d1077537220361c82e34a362c6c76ee', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/36644ee0d4cc2bc97a3cd49c3540e6eea193182a'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-0989, CVE-2019-0991, CVE-2019-0992, CVE-2019-1002, CVE-2019-1003, CVE-2019-1024, CVE-2019-1051, CVE-2019-1052.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/36644ee0d4cc2bc97a3cd49c3540e6eea193182a",
            "commit_sha":"36644ee0d4cc2bc97a3cd49c3540e6eea193182a",
            "patch":"MULTI",
            "chain_ord":"['36644ee0d4cc2bc97a3cd49c3540e6eea193182a', '3d6226cc2d1077537220361c82e34a362c6c76ee']",
            "before_first_fix_commit":"{'d797e3f00e34c12c8c0ae52f56344325439dccd7', 'eabf77ad17010f220639e5261798da9ac14e43e3'}",
            "last_fix_commit":"3d6226cc2d1077537220361c82e34a362c6c76ee",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/15\/2019, 23:54:48",
            "message":"CVE-2019-0993",
            "author":"Paul Leathers",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'lib\/Runtime\/Language\/JavascriptOperators.cpp': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/36644ee0d4cc2bc97a3cd49c3540e6eea193182a\/lib%2FRuntime%2FLanguage%2FJavascriptOperators.cpp', 'patch': \"@@ -9655,6 +9655,10 @@ using namespace Js;\\n             Var result = CALL_ENTRYPOINT(threadContext, marshalledFunction->GetEntryPoint(), function, CallInfo(flags, 1), thisVar);\\n             result = CrossSite::MarshalVar(requestContext, result);\\n \\n+            \/\/ Set implicit call flags so we bail out if we're trying to propagate the value forward, e.g., from a compare. Subsequent calls\\n+            \/\/ to the getter may produce different results.\\n+            threadContext->AddImplicitCallFlags(ImplicitCall_Accessor);\\n+\\n             return result;\\n         });\\n     }\"}}",
            "message_norm":"cve-2019-0993",
            "language":"ro",
            "entities":"[('cve-2019-0993', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Runtime\/Language\/JavascriptOperators.cpp'])",
            "num_files":1.0,
            "patch_content":"From 36644ee0d4cc2bc97a3cd49c3540e6eea193182a Mon Sep 17 00:00:00 2001\nFrom: Paul Leathers <pleath@microsoft.com>\nDate: Wed, 15 May 2019 16:54:48 -0700\nSubject: [PATCH] CVE-2019-0993\n\n---\n lib\/Runtime\/Language\/JavascriptOperators.cpp | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/lib\/Runtime\/Language\/JavascriptOperators.cpp b\/lib\/Runtime\/Language\/JavascriptOperators.cpp\nindex ecfd7d86f4e..4d67ce2a0b7 100644\n--- a\/lib\/Runtime\/Language\/JavascriptOperators.cpp\n+++ b\/lib\/Runtime\/Language\/JavascriptOperators.cpp\n@@ -9655,6 +9655,10 @@ using namespace Js;\n             Var result = CALL_ENTRYPOINT(threadContext, marshalledFunction->GetEntryPoint(), function, CallInfo(flags, 1), thisVar);\n             result = CrossSite::MarshalVar(requestContext, result);\n \n+            \/\/ Set implicit call flags so we bail out if we're trying to propagate the value forward, e.g., from a compare. Subsequent calls\n+            \/\/ to the getter may produce different results.\n+            threadContext->AddImplicitCallFlags(ImplicitCall_Accessor);\n+\n             return result;\n         });\n     }"
        },
        {
            "index":912,
            "vuln_id":"GHSA-r9vm-rhmf-7hxx",
            "cwe_id":"{'CWE-78'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/Turistforeningen\/node-im-resize\/commit\/de624dacf6a50e39fe3472af1414d44937ce1f03'}",
            "dataset":"osv",
            "summary":"OS Command Injection in im-resize im-resize through 2.3.2 allows remote attackers to execute arbitrary commands via the \"exec\" argument. The cmd argument used within index.js, can be controlled by user without any sanitization.",
            "published_date":"2021-04-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/Turistforeningen\/node-im-resize",
            "commit_href":"https:\/\/github.com\/Turistforeningen\/node-im-resize\/commit\/de624dacf6a50e39fe3472af1414d44937ce1f03",
            "commit_sha":"de624dacf6a50e39fe3472af1414d44937ce1f03",
            "patch":"SINGLE",
            "chain_ord":"['de624dacf6a50e39fe3472af1414d44937ce1f03']",
            "before_first_fix_commit":"{'499fe82028337ae55cb61c24696c1ec16f0f9c9a'}",
            "last_fix_commit":"de624dacf6a50e39fe3472af1414d44937ce1f03",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/03\/2020, 21:25:54",
            "message":"fix: check image arguments before processing (#19)\n\nRegex hotfix to check for command injection",
            "author":"Sam Sanoop",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'index.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Turistforeningen\/node-im-resize\/raw\/de624dacf6a50e39fe3472af1414d44937ce1f03\/index.js', 'patch': \"@@ -7,13 +7,17 @@ var join = require('path').join;\\n var sprintf = require('util').format;\\n \\n module.exports = function(image, output, cb) {\\n+  if(\/;|&|`|\\\\$|\\\\(|\\\\)|\\\\|\\\\||\\\\||!|>|<|\\\\?|\\\\${\/g.test(JSON.stringify(image))) {\\n+    console.log('Input Validation failed, Suspicious Characters found');\\n+  } else {\\n   var cmd = module.exports.cmd(image, output);\\n   exec(cmd, {timeout: 30000}, function(e, stdout, stderr) {\\n     if (e) { return cb(e); }\\n     if (stderr) { return cb(new Error(stderr)); }\\n \\n     return cb(null, output.versions);\\n   });\\n+}\\n };\\n \\n \/**\"}}",
            "message_norm":"fix: check image arguments before processing (#19)\n\nregex hotfix to check for command injection",
            "language":"en",
            "entities":"[('#19', 'ISSUE', ''), ('hotfix', 'ACTION', ''), ('command injection', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From de624dacf6a50e39fe3472af1414d44937ce1f03 Mon Sep 17 00:00:00 2001\nFrom: Sam Sanoop <sams@snyk.io>\nDate: Mon, 3 Feb 2020 21:25:54 +0000\nSubject: [PATCH] fix: check image arguments before processing (#19)\n\nRegex hotfix to check for command injection\n---\n index.js | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/index.js b\/index.js\nindex 16654d1..4ca6998 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -7,6 +7,9 @@ var join = require('path').join;\n var sprintf = require('util').format;\n \n module.exports = function(image, output, cb) {\n+  if(\/;|&|`|\\$|\\(|\\)|\\|\\||\\||!|>|<|\\?|\\${\/g.test(JSON.stringify(image))) {\n+    console.log('Input Validation failed, Suspicious Characters found');\n+  } else {\n   var cmd = module.exports.cmd(image, output);\n   exec(cmd, {timeout: 30000}, function(e, stdout, stderr) {\n     if (e) { return cb(e); }\n@@ -14,6 +17,7 @@ module.exports = function(image, output, cb) {\n \n     return cb(null, output.versions);\n   });\n+}\n };\n \n \/**"
        },
        {
            "index":264,
            "vuln_id":"GHSA-f2rp-4rv7-fc95",
            "cwe_id":"{'CWE-200'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/theforeman\/foreman_fog_proxmox\/pull\/184\/commits\/b7e910bf61563f5d447c71b1b41e2a373a794d7b'}",
            "dataset":"osv",
            "summary":"Exposure of Sensitive Information to an Unauthorized Actor in foreman_fog_proxmox A flaw was found in the Foreman project. The Proxmox compute resource exposes the password through the API to an authenticated local attacker with view_hosts permission. The highest threat from this vulnerability is to data confidentiality and integrity as well as system availability. Versions before foreman_fog_proxmox 0.13.1 are affected",
            "published_date":"2021-06-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/theforeman\/foreman_fog_proxmox",
            "commit_href":"https:\/\/github.com\/theforeman\/foreman_fog_proxmox\/pull\/184\/commits\/b7e910bf61563f5d447c71b1b41e2a373a794d7b",
            "commit_sha":"b7e910bf61563f5d447c71b1b41e2a373a794d7b",
            "patch":"SINGLE",
            "chain_ord":"['b7e910bf61563f5d447c71b1b41e2a373a794d7b']",
            "before_first_fix_commit":"{'f131382d265944cda85bb5765a6dc5b0b2715f61'}",
            "last_fix_commit":"b7e910bf61563f5d447c71b1b41e2a373a794d7b",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/23\/2021, 21:00:19",
            "message":"Fix clean API result",
            "author":"Markus Bucher",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'app\/views\/api\/v2\/compute_resources\/proxmox.json.rabl': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/theforeman\/foreman_fog_proxmox\/raw\/b7e910bf61563f5d447c71b1b41e2a373a794d7b\/app%2Fviews%2Fapi%2Fv2%2Fcompute_resources%2Fproxmox.json.rabl', 'patch': '@@ -1,3 +1,3 @@\\n # frozen_string_literal: true\\n \\n-attributes :url, :user, :password, :ssl_verify_peer, :ssl_certs, :renew\\n+attributes :url, :user, :ssl_verify_peer, :ssl_certs, :renew'}}",
            "message_norm":"fix clean api result",
            "language":"ro",
            "entities":"[('fix', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/views\/api\/v2\/compute_resources\/proxmox.json.rabl'])",
            "num_files":1.0,
            "patch_content":"From b7e910bf61563f5d447c71b1b41e2a373a794d7b Mon Sep 17 00:00:00 2001\nFrom: Markus Bucher <bucher@atix.de>\nDate: Tue, 23 Feb 2021 22:00:19 +0100\nSubject: [PATCH] Fix clean API result\n\n---\n app\/views\/api\/v2\/compute_resources\/proxmox.json.rabl | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/app\/views\/api\/v2\/compute_resources\/proxmox.json.rabl b\/app\/views\/api\/v2\/compute_resources\/proxmox.json.rabl\nindex 9de2e523f..043421707 100644\n--- a\/app\/views\/api\/v2\/compute_resources\/proxmox.json.rabl\n+++ b\/app\/views\/api\/v2\/compute_resources\/proxmox.json.rabl\n@@ -1,3 +1,3 @@\n # frozen_string_literal: true\n \n-attributes :url, :user, :password, :ssl_verify_peer, :ssl_certs, :renew\n+attributes :url, :user, :ssl_verify_peer, :ssl_certs, :renew"
        },
        {
            "index":487,
            "vuln_id":"GHSA-mw6j-hh29-h379",
            "cwe_id":"{'CWE-190'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3796cc4fcd93ae55812a457abc96dcd55fbb854b'}",
            "dataset":"osv",
            "summary":"`CHECK` failure in depthwise ops via overflows ### Impact\nThe implementation of depthwise ops in TensorFlow is vulnerable to a denial of service via `CHECK`-failure (assertion failure) caused by overflowing the number of elements in a tensor:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant(1, shape=[1, 4, 4, 3], dtype=tf.float32)\nfilter_sizes = tf.constant(1879048192, shape=[13], dtype=tf.int32)\nout_backprop = tf.constant(1, shape=[1, 4, 4, 3], dtype=tf.float32)\ntf.raw_ops.DepthwiseConv2dNativeBackpropFilter(\n    input=input, filter_sizes=filter_sizes, out_backprop=out_backprop, strides=[1, 1, 1, 1], padding=\"SAME\")\n```\n  \nThis is another instance of [TFSA-2021-198](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/security\/advisory\/tfsa-2021-198.md) (CVE-2021-41197).\n  \n### Patches\nWe have patched the issue in GitHub commit [3796cc4fcd93ae55812a457abc96dcd55fbb854b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3796cc4fcd93ae55812a457abc96dcd55fbb854b).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Neophytos Christou from Secure Systems Lab at Brown University.",
            "published_date":"2022-05-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3796cc4fcd93ae55812a457abc96dcd55fbb854b",
            "commit_sha":"3796cc4fcd93ae55812a457abc96dcd55fbb854b",
            "patch":"SINGLE",
            "chain_ord":"['3796cc4fcd93ae55812a457abc96dcd55fbb854b']",
            "before_first_fix_commit":"{'8f704c59219243ee66bdeb93cb3471e8e6af7d86'}",
            "last_fix_commit":"3796cc4fcd93ae55812a457abc96dcd55fbb854b",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/27\/2022, 22:53:46",
            "message":"Fix tf.raw_ops.DepthwiseConv2dNativeBackpropInput vulnerability with large input sizes.\n\nUse AddDimWithStatus rather than AddDim in order to catch and report integer overflow gracefully.\n\nPiperOrigin-RevId: 444989983",
            "author":"Alan Liu",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 2, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/3796cc4fcd93ae55812a457abc96dcd55fbb854b\/tensorflow%2Fcore%2Fkernels%2Fdepthwise_conv_grad_op.cc', 'patch': '@@ -625,7 +625,7 @@ class DepthwiseConv2dNativeBackpropInputOp : public OpKernel {\\n       OP_REQUIRES(context, in_sizes_data[i] >= 0,\\n                   errors::InvalidArgument(\"Dimension \", i,\\n                                           \" of input_sizes must be >= 0\"));\\n-      input_shape.AddDim(in_sizes_data[i]);\\n+      OP_REQUIRES_OK(context, input_shape.AddDimWithStatus(in_sizes_data[i]));\\n     }\\n     const TensorShape& filter_shape = filter.shape();\\n     EXTRACT_AND_VERIFY_DIMENSIONS(\"DepthwiseConv2DBackpropInput\");\\n@@ -1131,7 +1131,8 @@ class DepthwiseConv2dNativeBackpropFilterOp : public OpKernel {\\n       OP_REQUIRES(context, filter_sizes_data[i] >= 0,\\n                   errors::InvalidArgument(\"Dimension \", i,\\n                                           \" of filter_sizes must be >= 0\"));\\n-      filter_shape.AddDim(filter_sizes_data[i]);\\n+      OP_REQUIRES_OK(context,\\n+                     filter_shape.AddDimWithStatus(filter_sizes_data[i]));\\n     }\\n     const TensorShape& input_shape = input.shape();'}}",
            "message_norm":"fix tf.raw_ops.depthwiseconv2dnativebackpropinput vulnerability with large input sizes.\n\nuse adddimwithstatus rather than adddim in order to catch and report integer overflow gracefully.\n\npiperorigin-revid: 444989983",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('integer overflow', 'SECWORD', ''), ('444989983', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 3796cc4fcd93ae55812a457abc96dcd55fbb854b Mon Sep 17 00:00:00 2001\nFrom: Alan Liu <liualan@google.com>\nDate: Wed, 27 Apr 2022 15:53:46 -0700\nSubject: [PATCH] Fix tf.raw_ops.DepthwiseConv2dNativeBackpropInput\n vulnerability with large input sizes.\n\nUse AddDimWithStatus rather than AddDim in order to catch and report integer overflow gracefully.\n\nPiperOrigin-RevId: 444989983\n---\n tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc | 5 +++--\n 1 file changed, 3 insertions(+), 2 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc b\/tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc\nindex e7dadd1ab12762..14372266d84aa3 100644\n--- a\/tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc\n+++ b\/tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc\n@@ -625,7 +625,7 @@ class DepthwiseConv2dNativeBackpropInputOp : public OpKernel {\n       OP_REQUIRES(context, in_sizes_data[i] >= 0,\n                   errors::InvalidArgument(\"Dimension \", i,\n                                           \" of input_sizes must be >= 0\"));\n-      input_shape.AddDim(in_sizes_data[i]);\n+      OP_REQUIRES_OK(context, input_shape.AddDimWithStatus(in_sizes_data[i]));\n     }\n     const TensorShape& filter_shape = filter.shape();\n     EXTRACT_AND_VERIFY_DIMENSIONS(\"DepthwiseConv2DBackpropInput\");\n@@ -1131,7 +1131,8 @@ class DepthwiseConv2dNativeBackpropFilterOp : public OpKernel {\n       OP_REQUIRES(context, filter_sizes_data[i] >= 0,\n                   errors::InvalidArgument(\"Dimension \", i,\n                                           \" of filter_sizes must be >= 0\"));\n-      filter_shape.AddDim(filter_sizes_data[i]);\n+      OP_REQUIRES_OK(context,\n+                     filter_shape.AddDimWithStatus(filter_sizes_data[i]));\n     }\n     const TensorShape& input_shape = input.shape();"
        },
        {
            "index":592,
            "vuln_id":"GHSA-8rm6-75mf-7r7r",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5117e0851348065ed59c991562c0ec80d9193db2'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite's implementation of hashtable lookup ### Impact\nThe TFLite implementation of hashtable lookup is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/1a8e885b864c818198a5b2c0cbbeca5a1e833bc8\/tensorflow\/lite\/kernels\/hashtable_lookup.cc#L114-L115):\n\n```cc\nconst int num_rows = SizeOfDimension(value, 0); \nconst int row_bytes = value->bytes \/ num_rows; \n```\n\nAn attacker can craft a model such that `values`'s first dimension would be 0.\n\n### Patches\nWe have patched the issue in GitHub commit [5117e0851348065ed59c991562c0ec80d9193db2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5117e0851348065ed59c991562c0ec80d9193db2).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5117e0851348065ed59c991562c0ec80d9193db2",
            "commit_sha":"5117e0851348065ed59c991562c0ec80d9193db2",
            "patch":"SINGLE",
            "chain_ord":"['5117e0851348065ed59c991562c0ec80d9193db2']",
            "before_first_fix_commit":"{'ba6822bd7b7324ba201a28b2f278c29a98edbef2'}",
            "last_fix_commit":"5117e0851348065ed59c991562c0ec80d9193db2",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 23:16:56",
            "message":"Prevent a division by 0\n\nPiperOrigin-RevId: 371007407\nChange-Id: Iecf2718de48d6bf5a69b02a9df9deda8ec1b19d3",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/lite\/kernels\/hashtable_lookup.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/5117e0851348065ed59c991562c0ec80d9193db2\/tensorflow%2Flite%2Fkernels%2Fhashtable_lookup.cc', 'patch': '@@ -112,6 +112,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\\n \\n   const int num_rows = SizeOfDimension(value, 0);\\n+  TF_LITE_ENSURE(context, num_rows != 0);\\n   const int row_bytes = value->bytes \/ num_rows;\\n   void* pointer = nullptr;\\n   DynamicBuffer buf;'}}",
            "message_norm":"prevent a division by 0\n\npiperorigin-revid: 371007407\nchange-id: iecf2718de48d6bf5a69b02a9df9deda8ec1b19d3",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('371007407', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/hashtable_lookup.cc'])",
            "num_files":1.0,
            "patch_content":"From 5117e0851348065ed59c991562c0ec80d9193db2 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 28 Apr 2021 16:16:56 -0700\nSubject: [PATCH] Prevent a division by 0\n\nPiperOrigin-RevId: 371007407\nChange-Id: Iecf2718de48d6bf5a69b02a9df9deda8ec1b19d3\n---\n tensorflow\/lite\/kernels\/hashtable_lookup.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/hashtable_lookup.cc b\/tensorflow\/lite\/kernels\/hashtable_lookup.cc\nindex 2563d8ade5f74e..0de24b11333c97 100644\n--- a\/tensorflow\/lite\/kernels\/hashtable_lookup.cc\n+++ b\/tensorflow\/lite\/kernels\/hashtable_lookup.cc\n@@ -112,6 +112,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\n \n   const int num_rows = SizeOfDimension(value, 0);\n+  TF_LITE_ENSURE(context, num_rows != 0);\n   const int row_bytes = value->bytes \/ num_rows;\n   void* pointer = nullptr;\n   DynamicBuffer buf;"
        },
        {
            "index":418,
            "vuln_id":"GHSA-vgmw-9cww-qq99",
            "cwe_id":"{'CWE-284', 'CWE-863'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/janeczku\/calibre-web\/commit\/0c0313f375bed7b035c8c0482bbb09599e16bfcf'}",
            "dataset":"osv",
            "summary":"Incorrect Authorization in calibreweb calibreweb prior to version 0.6.16 contains an Incorrect Authorization vulnerability.",
            "published_date":"2022-01-31",
            "chain_len":1,
            "project":"https:\/\/github.com\/janeczku\/calibre-web",
            "commit_href":"https:\/\/github.com\/janeczku\/calibre-web\/commit\/0c0313f375bed7b035c8c0482bbb09599e16bfcf",
            "commit_sha":"0c0313f375bed7b035c8c0482bbb09599e16bfcf",
            "patch":"SINGLE",
            "chain_ord":"['0c0313f375bed7b035c8c0482bbb09599e16bfcf']",
            "before_first_fix_commit":"{'6bf07539788004513c3692c074ebc7ba4ce005e1'}",
            "last_fix_commit":"0c0313f375bed7b035c8c0482bbb09599e16bfcf",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/18\/2022, 16:55:10",
            "message":"Prevent creating a public shelf without permission",
            "author":"Ozzie Isaacs",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'cps\/shelf.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/janeczku\/calibre-web\/raw\/0c0313f375bed7b035c8c0482bbb09599e16bfcf\/cps%2Fshelf.py', 'patch': '@@ -248,7 +248,7 @@ def create_edit_shelf(shelf, page_title, page, shelf_id=False):\\n         if not current_user.role_edit_shelfs() and to_save.get(\"is_public\") == \"on\":\\n             flash(_(u\"Sorry you are not allowed to create a public shelf\"), category=\"error\")\\n             return redirect(url_for(\\'web.index\\'))\\n-        is_public = 1 if to_save.get(\"is_public\") else 0\\n+        is_public = 1 if to_save.get(\"is_public\") == \"on\" else 0\\n         if config.config_kobo_sync:\\n             shelf.kobo_sync = True if to_save.get(\"kobo_sync\") else False\\n             if shelf.kobo_sync:'}}",
            "message_norm":"prevent creating a public shelf without permission",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('permission', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['cps\/shelf.py'])",
            "num_files":1.0,
            "patch_content":"From 0c0313f375bed7b035c8c0482bbb09599e16bfcf Mon Sep 17 00:00:00 2001\nFrom: Ozzie Isaacs <ozzie.fernandez.isaacs@googlemail.com>\nDate: Tue, 18 Jan 2022 17:55:10 +0100\nSubject: [PATCH] Prevent creating a public shelf without permission\n\n---\n cps\/shelf.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/cps\/shelf.py b\/cps\/shelf.py\nindex 29a4fe99d3..ad6a2665a2 100644\n--- a\/cps\/shelf.py\n+++ b\/cps\/shelf.py\n@@ -248,7 +248,7 @@ def create_edit_shelf(shelf, page_title, page, shelf_id=False):\n         if not current_user.role_edit_shelfs() and to_save.get(\"is_public\") == \"on\":\n             flash(_(u\"Sorry you are not allowed to create a public shelf\"), category=\"error\")\n             return redirect(url_for('web.index'))\n-        is_public = 1 if to_save.get(\"is_public\") else 0\n+        is_public = 1 if to_save.get(\"is_public\") == \"on\" else 0\n         if config.config_kobo_sync:\n             shelf.kobo_sync = True if to_save.get(\"kobo_sync\") else False\n             if shelf.kobo_sync:"
        },
        {
            "index":188,
            "vuln_id":"GHSA-cfx7-2xpc-8w4h",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/2c74674348a4708ced58ad6eb1b23354df8ee044'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite's implementation of `BatchToSpaceNd` ### Impact\nThe implementation of the `BatchToSpaceNd` TFLite operator is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/b5ed552fe55895aee8bd8b191f744a069957d18d\/tensorflow\/lite\/kernels\/batch_to_space_nd.cc#L81-L82):\n\n```cc\nTF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\noutput_batch_size = output_batch_size \/ block_shape[dim];\n```\n\nAn attacker can craft a model such that one dimension of the `block` input is 0. Hence, the corresponding value in `block_shape` is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [2c74674348a4708ced58ad6eb1b23354df8ee044](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/2c74674348a4708ced58ad6eb1b23354df8ee044).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/2c74674348a4708ced58ad6eb1b23354df8ee044",
            "commit_sha":"2c74674348a4708ced58ad6eb1b23354df8ee044",
            "patch":"SINGLE",
            "chain_ord":"['2c74674348a4708ced58ad6eb1b23354df8ee044']",
            "before_first_fix_commit":"{'b5ed552fe55895aee8bd8b191f744a069957d18d'}",
            "last_fix_commit":"2c74674348a4708ced58ad6eb1b23354df8ee044",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 20:57:37",
            "message":"Prevent division by 0\n\nPiperOrigin-RevId: 370979352\nChange-Id: Ic79191c316d986fc6072ecaebfec9d5f2b924d00",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/lite\/kernels\/batch_to_space_nd.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/2c74674348a4708ced58ad6eb1b23354df8ee044\/tensorflow%2Flite%2Fkernels%2Fbatch_to_space_nd.cc', 'patch': '@@ -78,6 +78,7 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\\n   int output_batch_size = input_size->data[0];\\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\\n     \/\/ Number of batch must be multiple of (block_shape[dim]).\\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\\n     TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\\n     output_batch_size = output_batch_size \/ block_shape[dim];\\n     output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -'}}",
            "message_norm":"prevent division by 0\n\npiperorigin-revid: 370979352\nchange-id: ic79191c316d986fc6072ecaebfec9d5f2b924d00",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('370979352', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/batch_to_space_nd.cc'])",
            "num_files":1.0,
            "patch_content":"From 2c74674348a4708ced58ad6eb1b23354df8ee044 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 28 Apr 2021 13:57:37 -0700\nSubject: [PATCH] Prevent division by 0\n\nPiperOrigin-RevId: 370979352\nChange-Id: Ic79191c316d986fc6072ecaebfec9d5f2b924d00\n---\n tensorflow\/lite\/kernels\/batch_to_space_nd.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/batch_to_space_nd.cc b\/tensorflow\/lite\/kernels\/batch_to_space_nd.cc\nindex 9d6492e0fcbf06..044ac1b3a5ee5d 100644\n--- a\/tensorflow\/lite\/kernels\/batch_to_space_nd.cc\n+++ b\/tensorflow\/lite\/kernels\/batch_to_space_nd.cc\n@@ -78,6 +78,7 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n   int output_batch_size = input_size->data[0];\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\n     \/\/ Number of batch must be multiple of (block_shape[dim]).\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n     TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\n     output_batch_size = output_batch_size \/ block_shape[dim];\n     output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -"
        },
        {
            "index":87,
            "vuln_id":"GHSA-72p5-2r6g-fm6v",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/totaljs\/cms\/commit\/75205f93009db3cf8c0b0f4f1fc8ab82d70da8ad', 'https:\/\/github.com\/totaljs\/cms\/commit\/8b9d7dada998c08d172481d9f0fc0397c4b3c78d'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects total.js Total.js CMS 12.0.0 has XSS related to themes\/admin\/views\/index.html (item.message) and themes\/admin\/public\/ui.js (column.format).",
            "published_date":"2019-04-02",
            "chain_len":2,
            "project":"https:\/\/github.com\/totaljs\/cms",
            "commit_href":"https:\/\/github.com\/totaljs\/cms\/commit\/75205f93009db3cf8c0b0f4f1fc8ab82d70da8ad",
            "commit_sha":"75205f93009db3cf8c0b0f4f1fc8ab82d70da8ad",
            "patch":"MULTI",
            "chain_ord":"['75205f93009db3cf8c0b0f4f1fc8ab82d70da8ad', '8b9d7dada998c08d172481d9f0fc0397c4b3c78d']",
            "before_first_fix_commit":"{'75205f93009db3cf8c0b0f4f1fc8ab82d70da8ad'}",
            "last_fix_commit":"8b9d7dada998c08d172481d9f0fc0397c4b3c78d",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/13\/2019, 19:29:24",
            "message":"Fixed XSS.",
            "author":"Peter S\u030cirka",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'themes\/admin\/public\/ui.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/totaljs\/cms\/raw\/75205f93009db3cf8c0b0f4f1fc8ab82d70da8ad\/themes%2Fadmin%2Fpublic%2Fui.js', 'patch': \"@@ -559,7 +559,7 @@ COMPONENT('grid', 'filter:true;external:false;fillcount:50;filterlabel:Filtering\\n \\t\\t\\tfor (var j = 0, jl = columns.length; j < jl; j++) {\\n \\t\\t\\t\\tvar column = columns[j];\\n \\t\\t\\t\\tvar val = items[i][column.name];\\n-\\t\\t\\t\\tm.value = column.template ? column.template(items[i], column) : column.render ? column.render(val, column, items[i]) : val == null ? '' : (column.format ? val.format(column.format) : val);\\n+\\t\\t\\t\\tm.value = column.template ? column.template(items[i], column) : column.render ? column.render(val, column, items[i]) : val == null ? '' : Thelpers.encode((column.format ? val.format(column.format) : val));\\n \\t\\t\\t\\tm.index = j;\\n \\t\\t\\t\\tm.align = column.align;\\n \\t\\t\\t\\tm.background = column.background;\"}}",
            "message_norm":"fixed xss.",
            "language":"en",
            "entities":"[('fixed', 'ACTION', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['themes\/admin\/public\/ui.js'])",
            "num_files":1.0,
            "patch_content":"From 75205f93009db3cf8c0b0f4f1fc8ab82d70da8ad Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Peter=20S=CC=8Cirka?= <petersirka@gmail.com>\nDate: Wed, 13 Feb 2019 20:29:24 +0100\nSubject: [PATCH] Fixed XSS.\n\n---\n themes\/admin\/public\/ui.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/themes\/admin\/public\/ui.js b\/themes\/admin\/public\/ui.js\nindex 2667788..a893966 100755\n--- a\/themes\/admin\/public\/ui.js\n+++ b\/themes\/admin\/public\/ui.js\n@@ -559,7 +559,7 @@ COMPONENT('grid', 'filter:true;external:false;fillcount:50;filterlabel:Filtering\n \t\t\tfor (var j = 0, jl = columns.length; j < jl; j++) {\n \t\t\t\tvar column = columns[j];\n \t\t\t\tvar val = items[i][column.name];\n-\t\t\t\tm.value = column.template ? column.template(items[i], column) : column.render ? column.render(val, column, items[i]) : val == null ? '' : (column.format ? val.format(column.format) : val);\n+\t\t\t\tm.value = column.template ? column.template(items[i], column) : column.render ? column.render(val, column, items[i]) : val == null ? '' : Thelpers.encode((column.format ? val.format(column.format) : val));\n \t\t\t\tm.index = j;\n \t\t\t\tm.align = column.align;\n \t\t\t\tm.background = column.background;"
        },
        {
            "index":276,
            "vuln_id":"GHSA-4xfp-4pfp-89wg",
            "cwe_id":"{'CWE-824'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1071f554dbd09f7e101324d366eec5f4fe5a3ece'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in `RaggedTensorToSparse` ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToSparse`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedTensorToSparse(\n  rt_nested_splits=[[0, 38, 0]],\n  rt_dense_values=[])\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc#L30) has an incomplete validation of the splits values: it does not check that they are in increasing order.\n\n### Patches\nWe have patched the issue in GitHub commit [1071f554dbd09f7e101324d366eec5f4fe5a3ece](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1071f554dbd09f7e101324d366eec5f4fe5a3ece).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1071f554dbd09f7e101324d366eec5f4fe5a3ece",
            "commit_sha":"1071f554dbd09f7e101324d366eec5f4fe5a3ece",
            "patch":"SINGLE",
            "chain_ord":"['1071f554dbd09f7e101324d366eec5f4fe5a3ece']",
            "before_first_fix_commit":"{'0f387ffa5cc7d30fa1574d12f875ffbb2d1826b4'}",
            "last_fix_commit":"1071f554dbd09f7e101324d366eec5f4fe5a3ece",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/30\/2021, 01:23:29",
            "message":"Add missing validation to `RaggedTensorToSparse`.\n\nThere needs to be a check that the splits allow for valid ragged tensors.\n\nPiperOrigin-RevId: 387712169\nChange-Id: I2499175324b82b65d159a260c7f83b98ceb5cc7d",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 1, 'total': 12}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc': {'additions': 11, 'deletions': 1, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1071f554dbd09f7e101324d366eec5f4fe5a3ece\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_sparse_kernel.cc', 'patch': '@@ -21,6 +21,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n \\n namespace tensorflow {\\n \\n@@ -38,7 +39,8 @@ class RaggedTensorToSparseOp : public OpKernel {\\n     OP_REQUIRES_OK(\\n         context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));\\n     const int rt_nested_splits_len = rt_nested_splits_in.size();\\n-    DCHECK_GT(rt_nested_splits_len, 0);  \/\/ Enforced by REGISTER_OP.\\n+    OP_REQUIRES(context, rt_nested_splits_len > 0,\\n+                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));\\n     std::vector<ConstFlatSplits> rt_nested_splits;\\n     rt_nested_splits.reserve(rt_nested_splits_len);\\n     for (int i = 0; i < rt_nested_splits_len; ++i) {\\n@@ -162,6 +164,14 @@ class RaggedTensorToSparseOp : public OpKernel {\\n       if (rt_nested_splits[i](0) != 0) {\\n         return InvalidArgument(\"First value of ragged splits must be 0.\");\\n       }\\n+      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {\\n+        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {\\n+          return InvalidArgument(\\n+              \"Ragged splits should be non decreasing, but we got \",\\n+              rt_nested_splits[i](j - 1), \" followed by \",\\n+              rt_nested_splits[i](j));\\n+        }\\n+      }\\n       if (i > 0) {\\n         SPLITS_TYPE last_split =\\n             rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);'}}",
            "message_norm":"add missing validation to `raggedtensortosparse`.\n\nthere needs to be a check that the splits allow for valid ragged tensors.\n\npiperorigin-revid: 387712169\nchange-id: i2499175324b82b65d159a260c7f83b98ceb5cc7d",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('387712169', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc'])",
            "num_files":1.0,
            "patch_content":"From 1071f554dbd09f7e101324d366eec5f4fe5a3ece Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 18:23:29 -0700\nSubject: [PATCH] Add missing validation to `RaggedTensorToSparse`.\n\nThere needs to be a check that the splits allow for valid ragged tensors.\n\nPiperOrigin-RevId: 387712169\nChange-Id: I2499175324b82b65d159a260c7f83b98ceb5cc7d\n---\n ...\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc   | 12 +++++++++++-\n 1 file changed, 11 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc b\/tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc\nindex a47ff372cf087a..639280a26b40d4 100644\n--- a\/tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc\n+++ b\/tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc\n@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/register_types.h\"\n #include \"tensorflow\/core\/framework\/tensor.h\"\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n \n namespace tensorflow {\n \n@@ -38,7 +39,8 @@ class RaggedTensorToSparseOp : public OpKernel {\n     OP_REQUIRES_OK(\n         context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));\n     const int rt_nested_splits_len = rt_nested_splits_in.size();\n-    DCHECK_GT(rt_nested_splits_len, 0);  \/\/ Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, rt_nested_splits_len > 0,\n+                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));\n     std::vector<ConstFlatSplits> rt_nested_splits;\n     rt_nested_splits.reserve(rt_nested_splits_len);\n     for (int i = 0; i < rt_nested_splits_len; ++i) {\n@@ -162,6 +164,14 @@ class RaggedTensorToSparseOp : public OpKernel {\n       if (rt_nested_splits[i](0) != 0) {\n         return InvalidArgument(\"First value of ragged splits must be 0.\");\n       }\n+      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {\n+        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {\n+          return InvalidArgument(\n+              \"Ragged splits should be non decreasing, but we got \",\n+              rt_nested_splits[i](j - 1), \" followed by \",\n+              rt_nested_splits[i](j));\n+        }\n+      }\n       if (i > 0) {\n         SPLITS_TYPE last_split =\n             rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);"
        },
        {
            "index":240,
            "vuln_id":"GHSA-6c8f-qphg-qjgp",
            "cwe_id":"{'CWE-668'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/jonschlinkert\/kind-of\/commit\/1df992ce6d5a1292048e5fe9c52c5382f941ee0b'}",
            "dataset":"osv",
            "summary":"Validation Bypass in kind-of Versions of `kind-of` 6.x prior to 6.0.3 are vulnerable to a Validation Bypass. A maliciously crafted object can alter the result of the type check, allowing attackers to bypass the type checking validation. \n\n\n## Recommendation\n\nUpgrade to versions 6.0.3 or later.",
            "published_date":"2020-03-31",
            "chain_len":1,
            "project":"https:\/\/github.com\/jonschlinkert\/kind-of",
            "commit_href":"https:\/\/github.com\/jonschlinkert\/kind-of\/commit\/1df992ce6d5a1292048e5fe9c52c5382f941ee0b",
            "commit_sha":"1df992ce6d5a1292048e5fe9c52c5382f941ee0b",
            "patch":"SINGLE",
            "chain_ord":"['1df992ce6d5a1292048e5fe9c52c5382f941ee0b']",
            "before_first_fix_commit":"{'975c13a7cfaf25d811475823824af3a9c04b0ba8', '4da96c0047906d22a4d6964a668d3abaca122e50'}",
            "last_fix_commit":"1df992ce6d5a1292048e5fe9c52c5382f941ee0b",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/16\/2020, 16:37:23",
            "message":"Merge pull request #31 from xiaofen9\/master\n\nfix type checking vul in ctorName",
            "author":"Brian Woodward",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jonschlinkert\/kind-of\/raw\/1df992ce6d5a1292048e5fe9c52c5382f941ee0b\/index.js', 'patch': \"@@ -66,7 +66,7 @@ module.exports = function kindOf(val) {\\n };\\n \\n function ctorName(val) {\\n-  return val.constructor ? val.constructor.name : null;\\n+  return val.constructor && typeof val.constructor === 'function' ? val.constructor.name : null;\\n }\\n \\n function isArray(val) {\"}}",
            "message_norm":"merge pull request #31 from xiaofen9\/master\n\nfix type checking vul in ctorname",
            "language":"en",
            "entities":"[('#31', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From 975c13a7cfaf25d811475823824af3a9c04b0ba8 Mon Sep 17 00:00:00 2001\nFrom: xiaofen9 <f3i@t00ls.net>\nDate: Mon, 30 Dec 2019 09:37:11 -0800\nSubject: [PATCH] fix type checking vul in ctorName\n\n---\n index.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/index.js b\/index.js\nindex aa2bb39..bdcfdc8 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -66,7 +66,7 @@ module.exports = function kindOf(val) {\n };\n \n function ctorName(val) {\n-  return val.constructor ? val.constructor.name : null;\n+  return val.constructor && typeof val.constructor === 'function' ? val.constructor.name : null;\n }\n \n function isArray(val) {"
        },
        {
            "index":825,
            "vuln_id":"GHSA-v82p-hv3v-p6qp",
            "cwe_id":"{'CWE-20'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/203214568f5bc237603dbab6e1fd389f1572f5c9', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9e62869465573cb2d9b5053f1fa02a81fce21d69'}",
            "dataset":"osv",
            "summary":"Incomplete validation in MKL requantization ### Impact\nDue to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RequantizationRangePerChannel(\n  input=[],\n  input_min=[0,0,0,0,0],\n  input_max=[1,1,1,1,1],\n  clip_value_max=1)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/mkl\/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor.\n\nA similar issue occurs in `MklRequantizePerChannelOp`:\n\n```python\nimport tensorflow as tf \nfrom tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  out_type=tf.int)\n``` \n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/mkl\/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments.\n\n### Patches\nWe have patched the issue in GitHub commit [9e62869465573cb2d9b5053f1fa02a81fce21d69](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9e62869465573cb2d9b5053f1fa02a81fce21d69) and in the Github commit [203214568f5bc237603dbab6e1fd389f1572f5c9](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/203214568f5bc237603dbab6e1fd389f1572f5c9).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9e62869465573cb2d9b5053f1fa02a81fce21d69",
            "commit_sha":"9e62869465573cb2d9b5053f1fa02a81fce21d69",
            "patch":"MULTI",
            "chain_ord":"['9e62869465573cb2d9b5053f1fa02a81fce21d69', '203214568f5bc237603dbab6e1fd389f1572f5c9']",
            "before_first_fix_commit":"{'aff0d5b2883ea3de9b52f9e7cd996a34b299bf06'}",
            "last_fix_commit":"203214568f5bc237603dbab6e1fd389f1572f5c9",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/29\/2021, 23:29:20",
            "message":"Add more validation to `RequantizationRangePerChannel`.\n\nPiperOrigin-RevId: 387693946\nChange-Id: Ife8dcbdb021bec4787eef6a4361dd08f17c14bd6",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 0, 'total': 14}",
            "files":"{'tensorflow\/core\/kernels\/mkl\/mkl_requantization_range_per_channel_op.cc': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/9e62869465573cb2d9b5053f1fa02a81fce21d69\/tensorflow%2Fcore%2Fkernels%2Fmkl%2Fmkl_requantization_range_per_channel_op.cc', 'patch': '@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\\n         ctx, input_max.dim_size(0) == depth,\\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\\n                                 depth, \" was \", input_max.dim_size(0)));\\n+    OP_REQUIRES(\\n+        ctx, input_min.NumElements() == depth,\\n+        errors::InvalidArgument(\"input_min must have the same number of \"\\n+                                \"elements as input_max, got \",\\n+                                input_min.NumElements(), \" and \", depth));\\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\\n+                errors::InvalidArgument(\"input must not be empty\"));\\n+    OP_REQUIRES(ctx, input.dims() == 4,\\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\\n+    OP_REQUIRES(\\n+        ctx, input.dim_size(3) == depth,\\n+        errors::InvalidArgument(\\n+            \"input must have same number of channels as length of input_min: \",\\n+            input.dim_size(3), \" vs \", depth));\\n \\n     const float* input_min_data = input_min.flat<float>().data();\\n     const float* input_max_data = input_max.flat<float>().data();'}}",
            "message_norm":"add more validation to `requantizationrangeperchannel`.\n\npiperorigin-revid: 387693946\nchange-id: ife8dcbdb021bec4787eef6a4361dd08f17c14bd6",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('387693946', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/mkl\/mkl_requantization_range_per_channel_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 9e62869465573cb2d9b5053f1fa02a81fce21d69 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 16:29:20 -0700\nSubject: [PATCH] Add more validation to `RequantizationRangePerChannel`.\n\nPiperOrigin-RevId: 387693946\nChange-Id: Ife8dcbdb021bec4787eef6a4361dd08f17c14bd6\n---\n ...\/mkl\/mkl_requantization_range_per_channel_op.cc | 14 ++++++++++++++\n 1 file changed, 14 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/mkl\/mkl_requantization_range_per_channel_op.cc b\/tensorflow\/core\/kernels\/mkl\/mkl_requantization_range_per_channel_op.cc\nindex 24dabb07ca067a..a38df2450d1942 100644\n--- a\/tensorflow\/core\/kernels\/mkl\/mkl_requantization_range_per_channel_op.cc\n+++ b\/tensorflow\/core\/kernels\/mkl\/mkl_requantization_range_per_channel_op.cc\n@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\n         ctx, input_max.dim_size(0) == depth,\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                 depth, \" was \", input_max.dim_size(0)));\n+    OP_REQUIRES(\n+        ctx, input_min.NumElements() == depth,\n+        errors::InvalidArgument(\"input_min must have the same number of \"\n+                                \"elements as input_max, got \",\n+                                input_min.NumElements(), \" and \", depth));\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\n+                errors::InvalidArgument(\"input must not be empty\"));\n+    OP_REQUIRES(ctx, input.dims() == 4,\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\n+    OP_REQUIRES(\n+        ctx, input.dim_size(3) == depth,\n+        errors::InvalidArgument(\n+            \"input must have same number of channels as length of input_min: \",\n+            input.dim_size(3), \" vs \", depth));\n \n     const float* input_min_data = input_min.flat<float>().data();\n     const float* input_max_data = input_max.flat<float>().data();"
        },
        {
            "index":205,
            "vuln_id":"GHSA-32wx-4gxx-h48f",
            "cwe_id":"{'CWE-639'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/flarum\/tags\/commit\/c8fcd000857493f1e4cc00b6f2771ce388b93e9d'}",
            "dataset":"osv",
            "summary":"Users can edit the tags of any discussion This advisory concerns a vulnerability which was patched and publicly released on October 5, 2020.\n\n### Impact\nThis vulnerability allowed any registered user to edit the tags of any discussion for which they have READ access using the REST API.\n\nUsers were able to remove any existing tag, and add any tag in which they are allowed to create discussions. The chosen tags still had to match the configured Tags minimums and maximums.\n\nBy moving the discussion to new tags, users were able to go around permissions applied to restricted tags. Depending on the setup, this can include publicly exposing content that was only visible to certain groups, or gain the ability to interact with content where such interaction was limited.\n\nThe full impact varies depending on the configuration of permissions and restricted tags, and which community extensions are being used. All tag-scoped permissions offered by extensions are impacted by this ability to go around them.\n\nForums that don't use restricted tags and don't use any extension that relies on tags for access control should not see any security impact. An update is still required to stop users from being able to change any discussion's tags.\n\nForums that don't use the Tags extension are unaffected.\n\n### Patches\nThe fix will be available in version v0.1.0-beta.14 with Flarum beta 14. The fix has already been back-ported to Flarum beta 13 as version v0.1.0-beta.13.2 of the Tags extension.\n\n### Workarounds\nVersion v0.1.0-beta.13.2 of the Tags extension allows existing Flarum beta 13 forums to fix the issue without the need to update to beta 14.\n\nForums that have not yet updated to Flarum beta 13 are encouraged to update as soon as possible.\n\n### References\n\n- [Release announcement](https:\/\/discuss.flarum.org\/d\/25059-security-update-to-flarum-tags-010-beta132)\n- [GitHub issue](https:\/\/github.com\/flarum\/core\/issues\/2355)\n\n### For more information\nIf you have any questions or comments about this advisory, please start a new discussion on our [support forum](https:\/\/discuss.flarum.org\/t\/support).\n\nIf you discover a security vulnerability within Flarum, please send an e-mail to [security@flarum.org](mailto:security@flarum.org). All security vulnerabilities will be promptly addressed. More details can be found in our [security policy](https:\/\/github.com\/flarum\/core\/security\/policy).",
            "published_date":"2021-01-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/flarum\/tags",
            "commit_href":"https:\/\/github.com\/flarum\/tags\/commit\/c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
            "commit_sha":"c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
            "patch":"SINGLE",
            "chain_ord":"['c8fcd000857493f1e4cc00b6f2771ce388b93e9d']",
            "before_first_fix_commit":"{'c207faa17ffc496d5ce0161923f19556a0ac4c5b'}",
            "last_fix_commit":"c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/03\/2020, 22:37:56",
            "message":"Fix Editing Discussion Tags Permission (#95)",
            "author":"Sami Mazouz",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'src\/Listener\/SaveTagsToDatabase.php': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/flarum\/tags\/raw\/c8fcd000857493f1e4cc00b6f2771ce388b93e9d\/src%2FListener%2FSaveTagsToDatabase.php', 'patch': \"@@ -59,6 +59,10 @@ public function handle(Saving $event)\\n \\n         \/\/ TODO: clean up, prevent discussion from being created without tags\\n         if (isset($event->data['relationships']['tags']['data'])) {\\n+            if ($discussion->exists) {\\n+                $actor->assertCan('tag', $discussion);\\n+            }\\n+\\n             $linkage = (array) $event->data['relationships']['tags']['data'];\\n \\n             $newTagIds = [];\"}}",
            "message_norm":"fix editing discussion tags permission (#95)",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('permission', 'SECWORD', ''), ('#95', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Listener\/SaveTagsToDatabase.php'])",
            "num_files":1.0,
            "patch_content":"From c8fcd000857493f1e4cc00b6f2771ce388b93e9d Mon Sep 17 00:00:00 2001\nFrom: Sami Mazouz <sychocouldy@gmail.com>\nDate: Sat, 3 Oct 2020 23:37:56 +0100\nSubject: [PATCH] Fix Editing Discussion Tags Permission (#95)\n\n---\n src\/Listener\/SaveTagsToDatabase.php | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/src\/Listener\/SaveTagsToDatabase.php b\/src\/Listener\/SaveTagsToDatabase.php\nindex 2d16fb5f..19e271db 100755\n--- a\/src\/Listener\/SaveTagsToDatabase.php\n+++ b\/src\/Listener\/SaveTagsToDatabase.php\n@@ -59,6 +59,10 @@ public function handle(Saving $event)\n \n         \/\/ TODO: clean up, prevent discussion from being created without tags\n         if (isset($event->data['relationships']['tags']['data'])) {\n+            if ($discussion->exists) {\n+                $actor->assertCan('tag', $discussion);\n+            }\n+\n             $linkage = (array) $event->data['relationships']['tags']['data'];\n \n             $newTagIds = [];"
        },
        {
            "index":8,
            "vuln_id":"GHSA-9c8h-2mv3-49ww",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4'}",
            "dataset":"osv",
            "summary":"Division by 0 in most convolution operators ### Impact\nMost implementations of convolution operators in TensorFlow are affected by a division by 0 vulnerability where an attacker can trigger a denial of service via a crash:\n\n```python\nimport tensorflow as tf\n\ntf.compat.v1.disable_v2_behavior()\ntf.raw_ops.Conv2D(\n  input = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  filter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32),\n  strides = [1, 1, 1, 1],\n  padding = \"SAME\")\n```\n\nThe shape inference [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/framework\/common_shape_fns.cc#L577) is missing several validations before doing divisions and modulo operations.\n\n### Patches\nWe have patched the issue in GitHub commit [8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4",
            "commit_sha":"8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4",
            "patch":"SINGLE",
            "chain_ord":"['8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4']",
            "before_first_fix_commit":"{'1071f554dbd09f7e101324d366eec5f4fe5a3ece'}",
            "last_fix_commit":"8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/30\/2021, 01:23:45",
            "message":"Prevent division by 0 in common shape functions.\n\nPiperOrigin-RevId: 387712197\nChange-Id: Id25c7460e35b68aeeeac23b9a88e455b443ee149",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 0, 'total': 11}",
            "files":"{'tensorflow\/core\/framework\/common_shape_fns.cc': {'additions': 11, 'deletions': 0, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4\/tensorflow%2Fcore%2Fframework%2Fcommon_shape_fns.cc', 'patch': '@@ -672,6 +672,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\\n     int64_t input_depth_value = c->Value(input_depth_dim),\\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\\n+    if (filter_input_depth_value == 0)\\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\\n     if (input_depth_value % filter_input_depth_value != 0)\\n       return errors::InvalidArgument(\\n           \"Depth of input (\", input_depth_value,\\n@@ -681,6 +683,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\\n       int64_t num_groups = input_depth_value \/ filter_input_depth_value;\\n       if (c->ValueKnown(output_depth_dim)) {\\n         int64_t output_depth_value = c->Value(output_depth_dim);\\n+        if (num_groups == 0)\\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\\n         if (output_depth_value % num_groups != 0)\\n           return errors::InvalidArgument(\\n               \"Depth of output (\", output_depth_value,\\n@@ -816,6 +820,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\\n     int64_t input_depth_value = c->Value(input_depth_dim),\\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\\n+    if (filter_input_depth_value == 0)\\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\\n     if (input_depth_value % filter_input_depth_value != 0)\\n       return errors::InvalidArgument(\\n           \"Depth of input (\", input_depth_value,\\n@@ -825,6 +831,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\\n       int64_t num_groups = input_depth_value \/ filter_input_depth_value;\\n       if (c->ValueKnown(output_depth_dim)) {\\n         int64_t output_depth_value = c->Value(output_depth_dim);\\n+        if (num_groups == 0)\\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\\n         if (output_depth_value % num_groups != 0)\\n           return errors::InvalidArgument(\\n               \"Depth of output (\", output_depth_value,\\n@@ -2456,6 +2464,9 @@ Status SparseReduceShapeFn(InferenceContext* c) {\\n \\n     int64_t ndims = shape_vec.size();\\n     absl::flat_hash_set<int64> axes;\\n+    if (ndims == 0)\\n+      return errors::InvalidArgument(\\n+          \"Number of dims in shape tensor must not be 0\");\\n     for (int i = 0; i < axes_vec.size(); i++) {\\n       axes.insert((axes_vec(i) + ndims) % ndims);\\n     }'}}",
            "message_norm":"prevent division by 0 in common shape functions.\n\npiperorigin-revid: 387712197\nchange-id: id25c7460e35b68aeeeac23b9a88e455b443ee149",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('387712197', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/common_shape_fns.cc'])",
            "num_files":1.0,
            "patch_content":"From 8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 18:23:45 -0700\nSubject: [PATCH] Prevent division by 0 in common shape functions.\n\nPiperOrigin-RevId: 387712197\nChange-Id: Id25c7460e35b68aeeeac23b9a88e455b443ee149\n---\n tensorflow\/core\/framework\/common_shape_fns.cc | 11 +++++++++++\n 1 file changed, 11 insertions(+)\n\ndiff --git a\/tensorflow\/core\/framework\/common_shape_fns.cc b\/tensorflow\/core\/framework\/common_shape_fns.cc\nindex e578e2016b8742..4806d70a1d337d 100644\n--- a\/tensorflow\/core\/framework\/common_shape_fns.cc\n+++ b\/tensorflow\/core\/framework\/common_shape_fns.cc\n@@ -672,6 +672,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -681,6 +683,8 @@ Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n       int64_t num_groups = input_depth_value \/ filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -816,6 +820,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -825,6 +831,8 @@ Status Conv3DShape(shape_inference::InferenceContext* c) {\n       int64_t num_groups = input_depth_value \/ filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,\n@@ -2456,6 +2464,9 @@ Status SparseReduceShapeFn(InferenceContext* c) {\n \n     int64_t ndims = shape_vec.size();\n     absl::flat_hash_set<int64> axes;\n+    if (ndims == 0)\n+      return errors::InvalidArgument(\n+          \"Number of dims in shape tensor must not be 0\");\n     for (int i = 0; i < axes_vec.size(); i++) {\n       axes.insert((axes_vec(i) + ndims) % ndims);\n     }"
        },
        {
            "index":506,
            "vuln_id":"GHSA-2gfx-95x2-5v3x",
            "cwe_id":"{'CWE-787'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a324ac84e573fba362a5e53d4e74d5de6729933e'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `QuantizedReshape` ### Impact\nAn attacker can cause a heap buffer overflow in `QuantizedReshape` by passing in invalid thresholds for the quantization:\n\n```python\nimport tensorflow as tf\n\ntensor = tf.constant([], dtype=tf.qint32)\nshape = tf.constant([], dtype=tf.int32)\ninput_min = tf.constant([], dtype=tf.float32)\ninput_max = tf.constant([], dtype=tf.float32)\n\ntf.raw_ops.QuantizedReshape(tensor=tensor, shape=shape, input_min=input_min, input_max=input_max)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a324ac84e573fba362a5e53d4e74d5de6729933e\/tensorflow\/core\/kernels\/quantized_reshape_op.cc#L38-L55) assumes that the 2 arguments are always valid scalars and tries to access the numeric value directly:\n\n```cc\nconst auto& input_min_float_tensor = ctx->input(2);\n...\nconst float input_min_float = input_min_float_tensor.flat<float>()(0);\nconst auto& input_max_float_tensor = ctx->input(3);\n...\nconst float input_max_float = input_max_float_tensor.flat<float>()(0);\n```\n\nHowever, if any of these tensors is empty, then `.flat<T>()` is an empty buffer and accessing the element at position 0 results in overflow.\n\n### Patches\nWe have patched the issue in GitHub commit [a324ac84e573fba362a5e53d4e74d5de6729933e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a324ac84e573fba362a5e53d4e74d5de6729933e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a324ac84e573fba362a5e53d4e74d5de6729933e",
            "commit_sha":"a324ac84e573fba362a5e53d4e74d5de6729933e",
            "patch":"SINGLE",
            "chain_ord":"['a324ac84e573fba362a5e53d4e74d5de6729933e']",
            "before_first_fix_commit":"{'2ec2ce48365486311e56b3503bb75ab9e72a813d'}",
            "last_fix_commit":"a324ac84e573fba362a5e53d4e74d5de6729933e",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/22\/2021, 01:11:15",
            "message":"Validate arguments to `QuantizedReshape`.\n\nEnsure that validations from `Reshape` also terminate `QuantizedReshape` on failure.\n\nPiperOrigin-RevId: 369775421\nChange-Id: If8c5342267aceea65b7cb83a4b183304886f1ce8",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 23, 'deletions': 2, 'total': 25}",
            "files":"{'tensorflow\/core\/kernels\/quantized_reshape_op.cc': {'additions': 23, 'deletions': 2, 'changes': 25, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a324ac84e573fba362a5e53d4e74d5de6729933e\/tensorflow%2Fcore%2Fkernels%2Fquantized_reshape_op.cc', 'patch': '@@ -17,6 +17,7 @@ limitations under the License.\\n \\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n+#include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n #include \"tensorflow\/core\/framework\/tensor_types.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/kernels\/reshape_op.h\"\\n@@ -30,9 +31,29 @@ class QuantizedReshapeOp : public ReshapeOp {\\n   void Compute(OpKernelContext* ctx) override {\\n     \/\/ This call processes inputs 1 and 2 to write output 0.\\n     ReshapeOp::Compute(ctx);\\n+    if (!ctx->status().ok()) {\\n+      return;\\n+    }\\n+\\n+    const auto& input_min_float_tensor = ctx->input(2);\\n+    const auto& input_min_float_shape = input_min_float_tensor.shape();\\n+    OP_REQUIRES(ctx,\\n+                TensorShapeUtils::IsScalar(input_min_float_shape) ||\\n+                    (TensorShapeUtils::IsVector(input_min_float_shape) &&\\n+                     (input_min_float_shape.dim_size(0) == 1)),\\n+                errors::InvalidArgument(\\n+                    \"input_min must be a scalar or a vector of 1 element\"));\\n+    const float input_min_float = input_min_float_tensor.flat<float>()(0);\\n+    const auto& input_max_float_tensor = ctx->input(3);\\n+    const auto& input_max_float_shape = input_max_float_tensor.shape();\\n+    OP_REQUIRES(ctx,\\n+                TensorShapeUtils::IsScalar(input_max_float_shape) ||\\n+                    (TensorShapeUtils::IsVector(input_max_float_shape) &&\\n+                     (input_max_float_shape.dim_size(0) == 1)),\\n+                errors::InvalidArgument(\\n+                    \"input_max must be a scalar or a vector of 1 element\"));\\n+    const float input_max_float = input_max_float_tensor.flat<float>()(0);\\n \\n-    const float input_min_float = ctx->input(2).flat<float>()(0);\\n-    const float input_max_float = ctx->input(3).flat<float>()(0);\\n     Tensor* output_min = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\\n     output_min->flat<float>()(0) = input_min_float;'}}",
            "message_norm":"validate arguments to `quantizedreshape`.\n\nensure that validations from `reshape` also terminate `quantizedreshape` on failure.\n\npiperorigin-revid: 369775421\nchange-id: if8c5342267aceea65b7cb83a4b183304886f1ce8",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('ensure', 'ACTION', ''), ('369775421', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_reshape_op.cc'])",
            "num_files":1.0,
            "patch_content":"From a324ac84e573fba362a5e53d4e74d5de6729933e Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 21 Apr 2021 18:11:15 -0700\nSubject: [PATCH] Validate arguments to `QuantizedReshape`.\n\nEnsure that validations from `Reshape` also terminate `QuantizedReshape` on failure.\n\nPiperOrigin-RevId: 369775421\nChange-Id: If8c5342267aceea65b7cb83a4b183304886f1ce8\n---\n ...\/core\/kernels\/quantized_reshape_op.cc      | 25 +++++++++++++++++--\n 1 file changed, 23 insertions(+), 2 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantized_reshape_op.cc b\/tensorflow\/core\/kernels\/quantized_reshape_op.cc\nindex bd76c94edeea7a..682f4aaa1f79e7 100644\n--- a\/tensorflow\/core\/kernels\/quantized_reshape_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantized_reshape_op.cc\n@@ -17,6 +17,7 @@ limitations under the License.\n \n #include \"tensorflow\/core\/framework\/op_kernel.h\"\n #include \"tensorflow\/core\/framework\/register_types.h\"\n+#include \"tensorflow\/core\/framework\/tensor_shape.h\"\n #include \"tensorflow\/core\/framework\/tensor_types.h\"\n #include \"tensorflow\/core\/framework\/types.h\"\n #include \"tensorflow\/core\/kernels\/reshape_op.h\"\n@@ -30,9 +31,29 @@ class QuantizedReshapeOp : public ReshapeOp {\n   void Compute(OpKernelContext* ctx) override {\n     \/\/ This call processes inputs 1 and 2 to write output 0.\n     ReshapeOp::Compute(ctx);\n+    if (!ctx->status().ok()) {\n+      return;\n+    }\n+\n+    const auto& input_min_float_tensor = ctx->input(2);\n+    const auto& input_min_float_shape = input_min_float_tensor.shape();\n+    OP_REQUIRES(ctx,\n+                TensorShapeUtils::IsScalar(input_min_float_shape) ||\n+                    (TensorShapeUtils::IsVector(input_min_float_shape) &&\n+                     (input_min_float_shape.dim_size(0) == 1)),\n+                errors::InvalidArgument(\n+                    \"input_min must be a scalar or a vector of 1 element\"));\n+    const float input_min_float = input_min_float_tensor.flat<float>()(0);\n+    const auto& input_max_float_tensor = ctx->input(3);\n+    const auto& input_max_float_shape = input_max_float_tensor.shape();\n+    OP_REQUIRES(ctx,\n+                TensorShapeUtils::IsScalar(input_max_float_shape) ||\n+                    (TensorShapeUtils::IsVector(input_max_float_shape) &&\n+                     (input_max_float_shape.dim_size(0) == 1)),\n+                errors::InvalidArgument(\n+                    \"input_max must be a scalar or a vector of 1 element\"));\n+    const float input_max_float = input_max_float_tensor.flat<float>()(0);\n \n-    const float input_min_float = ctx->input(2).flat<float>()(0);\n-    const float input_max_float = ctx->input(3).flat<float>()(0);\n     Tensor* output_min = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\n     output_min->flat<float>()(0) = input_min_float;"
        },
        {
            "index":445,
            "vuln_id":"GHSA-jmgf-p46x-982h",
            "cwe_id":"{'CWE-352'}",
            "score":0.0,
            "chain":"{'http:\/\/github.com\/rails\/rails\/commit\/7282ed863ca7e6f928bae9162c9a63a98775a19d'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects rails CRLF injection vulnerability in Ruby on Rails before 2.0.5 allows remote attackers to inject arbitrary HTTP headers and conduct HTTP response splitting attacks via a crafted URL to the redirect_to function.",
            "published_date":"2017-10-24",
            "chain_len":1,
            "project":"http:\/\/github.com\/rails\/rails",
            "commit_href":"http:\/\/github.com\/rails\/rails\/commit\/7282ed863ca7e6f928bae9162c9a63a98775a19d",
            "commit_sha":"7282ed863ca7e6f928bae9162c9a63a98775a19d",
            "patch":"SINGLE",
            "chain_ord":"['7282ed863ca7e6f928bae9162c9a63a98775a19d']",
            "before_first_fix_commit":"{'e8577991dcc47bcb11f99fd6582ee2a3f8270498'}",
            "last_fix_commit":"7282ed863ca7e6f928bae9162c9a63a98775a19d",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/14\/2008, 09:47:27",
            "message":"Sanitize the URLs passed to redirect_to to prevent a potential response spli\n\nCGI.rb and mongrel don't do any sanitization of the contents of HTTP headers",
            "author":"Michael Koziarski",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'actionpack\/lib\/action_controller\/response.rb': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/rails\/rails\/raw\/7282ed863ca7e6f928bae9162c9a63a98775a19d\/actionpack%2Flib%2Faction_controller%2Fresponse.rb', 'patch': '@@ -30,9 +30,9 @@ def charset\\n \\n     def redirect(to_url, response_status)\\n       self.headers[\"Status\"] = response_status\\n-      self.headers[\"Location\"] = to_url\\n+      self.headers[\"Location\"] = to_url.gsub(\/[\\\\r\\\\n]\/, \\'\\')\\n \\n-      self.body = \"<html><body>You are being <a href=\\\\\"#{to_url}\\\\\">redirected<\/a>.<\/body><\/html>\"\\n+      self.body = \"<html><body>You are being <a href=\\\\\"#{CGI.escapeHTML(to_url)}\\\\\">redirected<\/a>.<\/body><\/html>\"\\n     end\\n \\n     def prepare!'}}",
            "message_norm":"sanitize the urls passed to redirect_to to prevent a potential response spli\n\ncgi.rb and mongrel don't do any sanitization of the contents of http headers",
            "language":"en",
            "entities":"[('sanitize', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('sanitization', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['actionpack\/lib\/action_controller\/response.rb'])",
            "num_files":1.0,
            "patch_content":"From 7282ed863ca7e6f928bae9162c9a63a98775a19d Mon Sep 17 00:00:00 2001\nFrom: Michael Koziarski <michael@koziarski.com>\nDate: Tue, 14 Oct 2008 11:47:27 +0200\nSubject: [PATCH] Sanitize the URLs passed to redirect_to to prevent a\n potential response spli\n\nCGI.rb and mongrel don't do any sanitization of the contents of HTTP headers\n---\n actionpack\/lib\/action_controller\/response.rb | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/actionpack\/lib\/action_controller\/response.rb b\/actionpack\/lib\/action_controller\/response.rb\nindex 1d9f6676ba49d..56dace08af68c 100755\n--- a\/actionpack\/lib\/action_controller\/response.rb\n+++ b\/actionpack\/lib\/action_controller\/response.rb\n@@ -30,9 +30,9 @@ def charset\n \n     def redirect(to_url, response_status)\n       self.headers[\"Status\"] = response_status\n-      self.headers[\"Location\"] = to_url\n+      self.headers[\"Location\"] = to_url.gsub(\/[\\r\\n]\/, '')\n \n-      self.body = \"<html><body>You are being <a href=\\\"#{to_url}\\\">redirected<\/a>.<\/body><\/html>\"\n+      self.body = \"<html><body>You are being <a href=\\\"#{CGI.escapeHTML(to_url)}\\\">redirected<\/a>.<\/body><\/html>\"\n     end\n \n     def prepare!"
        },
        {
            "index":502,
            "vuln_id":"GHSA-q67f-3jq4-mww2",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/e786fd44aac46febdbf916ed6c328fbe645d80bf'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Pimcore Pimcore version 10.3.2 and prior is vulnerable to stored cross-site scripting. A patch is available and anticipated to be part of version 10.3.3.",
            "published_date":"2022-03-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/e786fd44aac46febdbf916ed6c328fbe645d80bf",
            "commit_sha":"e786fd44aac46febdbf916ed6c328fbe645d80bf",
            "patch":"SINGLE",
            "chain_ord":"['e786fd44aac46febdbf916ed6c328fbe645d80bf']",
            "before_first_fix_commit":"{'ce5c01f4c9f477444aeceb640b60f3b6199e7c22'}",
            "last_fix_commit":"e786fd44aac46febdbf916ed6c328fbe645d80bf",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/02\/2022, 20:15:07",
            "message":"escaping 'key' custom property field in elements",
            "author":"JiaJia Ji",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 2, 'total': 5}",
            "files":"{'bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/element\/properties.js': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/e786fd44aac46febdbf916ed6c328fbe645d80bf\/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Felement%2Fproperties.js', 'patch': '@@ -568,10 +568,11 @@ pimcore.element.properties = Class.create({\\n \\n     addSetFromUserDefined: function (customKey, customType) {\\n         try {\\n-            if (in_array(customKey.getValue(), this.disallowedKeys)) {\\n+            let key = htmlspecialchars(customKey.getValue());\\n+            if (in_array(key, this.disallowedKeys)) {\\n                 Ext.MessageBox.alert(t(\"error\"), t(\"name_is_not_allowed\"));\\n             }\\n-            this.add(customKey.getValue(), customType.getValue(), false, false, false, true);\\n+            this.add(key, customType.getValue(), false, false, false, true);\\n         } catch (e) {\\n             console.log(e);\\n         }'}}",
            "message_norm":"escaping 'key' custom property field in elements",
            "language":"en",
            "entities":"[('escaping', 'SECWORD', ''), ('key', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/element\/properties.js'])",
            "num_files":1.0,
            "patch_content":"From e786fd44aac46febdbf916ed6c328fbe645d80bf Mon Sep 17 00:00:00 2001\nFrom: JiaJia Ji <kingjia90@gmail.com>\nDate: Wed, 2 Mar 2022 21:15:07 +0100\nSubject: [PATCH] escaping 'key' custom property field in elements\n\n---\n ...\/Resources\/public\/js\/pimcore\/element\/properties.js        | 5 +++--\n 1 file changed, 3 insertions(+), 2 deletions(-)\n\ndiff --git a\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/element\/properties.js b\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/element\/properties.js\nindex 16466f0a5ad..0517e3163ee 100644\n--- a\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/element\/properties.js\n+++ b\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/element\/properties.js\n@@ -568,10 +568,11 @@ pimcore.element.properties = Class.create({\n \n     addSetFromUserDefined: function (customKey, customType) {\n         try {\n-            if (in_array(customKey.getValue(), this.disallowedKeys)) {\n+            let key = htmlspecialchars(customKey.getValue());\n+            if (in_array(key, this.disallowedKeys)) {\n                 Ext.MessageBox.alert(t(\"error\"), t(\"name_is_not_allowed\"));\n             }\n-            this.add(customKey.getValue(), customType.getValue(), false, false, false, true);\n+            this.add(key, customType.getValue(), false, false, false, true);\n         } catch (e) {\n             console.log(e);\n         }"
        },
        {
            "index":504,
            "vuln_id":"GHSA-rc8h-3fv6-pxv8",
            "cwe_id":"{'CWE-400'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/hapijs\/hapi\/commit\/aab2496e930dce5ee1ab28eecec94e0e45f03580'}",
            "dataset":"osv",
            "summary":"Denial of Service in hapi Versions of `hapi` prior to 11.1.3 are affected by a denial of service vulnerability.\n\nThe vulnerability is triggered when certain input is passed into the If-Modified-Since or Last-Modified headers.\n\nThis causes an 'illegal access' exception to be raised, and instead of sending a HTTP 500 error back to the sender, hapi will continue to hold the socket open until timed out (default node timeout is 2 minutes).\n\n\n\n\n\n## Recommendation\n\nUpdate to v11.1.3 or later",
            "published_date":"2018-06-07",
            "chain_len":1,
            "project":"https:\/\/github.com\/hapijs\/hapi",
            "commit_href":"https:\/\/github.com\/hapijs\/hapi\/commit\/aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "commit_sha":"aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "patch":"SINGLE",
            "chain_ord":"['aab2496e930dce5ee1ab28eecec94e0e45f03580']",
            "before_first_fix_commit":"{'1ad65ba793377928aa5a2dfc819888c5c9793394', 'ef2a0f85d558eeb102c512fac45386b2145cb903'}",
            "last_fix_commit":"aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/23\/2015, 21:54:47",
            "message":"Merge pull request #2988 from hapijs\/v11.1.x\n\nHandle invalid date exceptions",
            "author":"Eran Hammer",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 2, 'total': 13}",
            "files":"{'lib\/transmit.js': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hapijs\/hapi\/raw\/aab2496e930dce5ee1ab28eecec94e0e45f03580\/lib%2Ftransmit.js', 'patch': '@@ -82,8 +82,8 @@ internals.marshal = function (request, next) {\\n \\n                 \/\/ Weak verifier\\n \\n-                const ifModifiedSince = Date.parse(ifModifiedSinceHeader);\\n-                const lastModified = Date.parse(lastModifiedHeader);\\n+                const ifModifiedSince = internals.parseDate(ifModifiedSinceHeader);\\n+                const lastModified = internals.parseDate(lastModifiedHeader);\\n \\n                 if (ifModifiedSince &&\\n                     lastModified &&\\n@@ -147,6 +147,15 @@ internals.marshal = function (request, next) {\\n };\\n \\n \\n+internals.parseDate = function (string) {\\n+\\n+    try {\\n+        return Date.parse(string);\\n+    }\\n+    catch (errIgnore) { }\\n+};\\n+\\n+\\n internals.fail = function (request, boom, callback) {\\n \\n     const error = boom.output;'}}",
            "message_norm":"merge pull request #2988 from hapijs\/v11.1.x\n\nhandle invalid date exceptions",
            "language":"en",
            "entities":"[('#2988', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/transmit.js'])",
            "num_files":1.0,
            "patch_content":"From 14ca827cb6501b88a5452054f429a92ee3fe0b6e Mon Sep 17 00:00:00 2001\nFrom: Eran Hammer <eran@hammer.io>\nDate: Wed, 23 Dec 2015 13:51:44 -0800\nSubject: [PATCH 1\/3] Handle invalid date exceptions. Closes #2987\n\n---\n lib\/transmit.js     | 13 +++++++++++--\n npm-shrinkwrap.json |  2 +-\n package.json        |  2 +-\n 3 files changed, 13 insertions(+), 4 deletions(-)\n\ndiff --git a\/lib\/transmit.js b\/lib\/transmit.js\nindex 5ab2d0d48..d4ee1f5fd 100755\n--- a\/lib\/transmit.js\n+++ b\/lib\/transmit.js\n@@ -82,8 +82,8 @@ internals.marshal = function (request, next) {\n \n                 \/\/ Weak verifier\n \n-                const ifModifiedSince = Date.parse(ifModifiedSinceHeader);\n-                const lastModified = Date.parse(lastModifiedHeader);\n+                const ifModifiedSince = internals.parseDate(ifModifiedSinceHeader);\n+                const lastModified = internals.parseDate(lastModifiedHeader);\n \n                 if (ifModifiedSince &&\n                     lastModified &&\n@@ -147,6 +147,15 @@ internals.marshal = function (request, next) {\n };\n \n \n+internals.parseDate = function (string) {\n+\n+    try {\n+        return Date.parse(string);\n+    }\n+    catch (errIgnore) { }\n+};\n+\n+\n internals.fail = function (request, boom, callback) {\n \n     const error = boom.output;\ndiff --git a\/npm-shrinkwrap.json b\/npm-shrinkwrap.json\nindex 1e611ff2d..fa06071ff 100755\n--- a\/npm-shrinkwrap.json\n+++ b\/npm-shrinkwrap.json\n@@ -1,6 +1,6 @@\n {\n     \"name\": \"hapi\",\n-    \"version\": \"11.1.1\",\n+    \"version\": \"11.1.3\",\n     \"dependencies\": {\n         \"accept\": {\n             \"version\": \"2.0.0\"\ndiff --git a\/package.json b\/package.json\nindex a67947141..776b696b5 100755\n--- a\/package.json\n+++ b\/package.json\n@@ -2,7 +2,7 @@\n   \"name\": \"hapi\",\n   \"description\": \"HTTP Server framework\",\n   \"homepage\": \"http:\/\/hapijs.com\",\n-  \"version\": \"11.1.2\",\n+  \"version\": \"11.1.3\",\n   \"repository\": {\n     \"type\": \"git\",\n     \"url\": \"git:\/\/github.com\/hapijs\/hapi\"\n\nFrom 9f328465611dd81f7dc40b065eb34d5f04f9c8e1 Mon Sep 17 00:00:00 2001\nFrom: Eran Hammer <eran@hammer.io>\nDate: Wed, 23 Dec 2015 13:54:29 -0800\nSubject: [PATCH 2\/3] Update npm-shrinkwrap.json\n\n---\n npm-shrinkwrap.json | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/npm-shrinkwrap.json b\/npm-shrinkwrap.json\nindex fa06071ff..1e611ff2d 100755\n--- a\/npm-shrinkwrap.json\n+++ b\/npm-shrinkwrap.json\n@@ -1,6 +1,6 @@\n {\n     \"name\": \"hapi\",\n-    \"version\": \"11.1.3\",\n+    \"version\": \"11.1.1\",\n     \"dependencies\": {\n         \"accept\": {\n             \"version\": \"2.0.0\"\n\nFrom ef2a0f85d558eeb102c512fac45386b2145cb903 Mon Sep 17 00:00:00 2001\nFrom: Eran Hammer <eran@hammer.io>\nDate: Wed, 23 Dec 2015 13:54:39 -0800\nSubject: [PATCH 3\/3] Update package.json\n\n---\n package.json | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/package.json b\/package.json\nindex 776b696b5..a67947141 100755\n--- a\/package.json\n+++ b\/package.json\n@@ -2,7 +2,7 @@\n   \"name\": \"hapi\",\n   \"description\": \"HTTP Server framework\",\n   \"homepage\": \"http:\/\/hapijs.com\",\n-  \"version\": \"11.1.3\",\n+  \"version\": \"11.1.2\",\n   \"repository\": {\n     \"type\": \"git\",\n     \"url\": \"git:\/\/github.com\/hapijs\/hapi\""
        },
        {
            "index":765,
            "vuln_id":"GHSA-jr37-66pj-36v7",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/Bottelet\/DaybydayCRM\/commit\/002dc75f400cf307bd00b71a5a93f1e26e52cee2'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in DayByDay CRM In Daybyday CRM, version 2.2.0 is vulnerable to Stored Cross-Site Scripting (XSS) vulnerability that allows low privileged application users to store malicious scripts in the title field of new tasks. These scripts are executed in a victim\u2019s browser when they open the \u201c\/tasks\u201d page to view all the tasks.",
            "published_date":"2022-01-08",
            "chain_len":1,
            "project":"https:\/\/github.com\/Bottelet\/DaybydayCRM",
            "commit_href":"https:\/\/github.com\/Bottelet\/DaybydayCRM\/commit\/002dc75f400cf307bd00b71a5a93f1e26e52cee2",
            "commit_sha":"002dc75f400cf307bd00b71a5a93f1e26e52cee2",
            "patch":"SINGLE",
            "chain_ord":"['002dc75f400cf307bd00b71a5a93f1e26e52cee2']",
            "before_first_fix_commit":"{'fe842ea5ede237443f1f45a99aeb839133115d8b'}",
            "last_fix_commit":"002dc75f400cf307bd00b71a5a93f1e26e52cee2",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/25\/2021, 19:53:06",
            "message":"fix xss for tasks index",
            "author":"Casper Bottelet",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'app\/Http\/Controllers\/TasksController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Bottelet\/DaybydayCRM\/raw\/002dc75f400cf307bd00b71a5a93f1e26e52cee2\/app%2FHttp%2FControllers%2FTasksController.php', 'patch': '@@ -82,7 +82,7 @@ public function anyData()\\n             })\\n             ->addColumn(\\'view\\', function ($tasks) {\\n                 return \\'<a href=\"\\' . route(\"tasks.show\", $tasks->external_id) . \\'\" class=\"btn btn-link\">\\' . __(\\'View\\') .\\'<\/a>\\'\\n-                . \\'<a data-toggle=\"modal\" data-id=\"\\'. route(\\'tasks.destroy\\',$tasks->external_id) . \\'\" data-title=\"\\'. $tasks->title . \\'\" data-target=\"#deletion\" class=\"btn btn-link\">\\' . __(\\'Delete\\') .\\'<\/a>\\'\\n+                . \\'<a data-toggle=\"modal\" data-id=\"\\'. route(\\'tasks.destroy\\',$tasks->external_id) . \\'\" data-target=\"#deletion\" class=\"btn btn-link\">\\' . __(\\'Delete\\') .\\'<\/a>\\'\\n                 ;\\n             })\\n             ->rawColumns([\\'titlelink\\',\\'view\\', \\'status_id\\'])'}}",
            "message_norm":"fix xss for tasks index",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/TasksController.php'])",
            "num_files":1.0,
            "patch_content":"From 002dc75f400cf307bd00b71a5a93f1e26e52cee2 Mon Sep 17 00:00:00 2001\nFrom: Casper Bottelet <cbottelet@gmail.com>\nDate: Fri, 25 Jun 2021 21:53:06 +0200\nSubject: [PATCH] fix xss for tasks index\n\n---\n app\/Http\/Controllers\/TasksController.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/app\/Http\/Controllers\/TasksController.php b\/app\/Http\/Controllers\/TasksController.php\nindex 629437d21..831cd76dd 100644\n--- a\/app\/Http\/Controllers\/TasksController.php\n+++ b\/app\/Http\/Controllers\/TasksController.php\n@@ -82,7 +82,7 @@ public function anyData()\n             })\n             ->addColumn('view', function ($tasks) {\n                 return '<a href=\"' . route(\"tasks.show\", $tasks->external_id) . '\" class=\"btn btn-link\">' . __('View') .'<\/a>'\n-                . '<a data-toggle=\"modal\" data-id=\"'. route('tasks.destroy',$tasks->external_id) . '\" data-title=\"'. $tasks->title . '\" data-target=\"#deletion\" class=\"btn btn-link\">' . __('Delete') .'<\/a>'\n+                . '<a data-toggle=\"modal\" data-id=\"'. route('tasks.destroy',$tasks->external_id) . '\" data-target=\"#deletion\" class=\"btn btn-link\">' . __('Delete') .'<\/a>'\n                 ;\n             })\n             ->rawColumns(['titlelink','view', 'status_id'])"
        },
        {
            "index":100,
            "vuln_id":"GHSA-9w7h-3wwh-6m5q",
            "cwe_id":"{'CWE-79'}",
            "score":6.3,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/ad3928f67b2cd4443f4323d858b666d35a919ba8'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Microweber Microweber prior to 1.2.15 is vulnerable to reflected cross-site scripting on demo.microweber.org\/demo\/module\/. This allows the execution of arbitrary JavaScript as the attacked user.",
            "published_date":"2022-04-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/ad3928f67b2cd4443f4323d858b666d35a919ba8",
            "commit_sha":"ad3928f67b2cd4443f4323d858b666d35a919ba8",
            "patch":"SINGLE",
            "chain_ord":"['ad3928f67b2cd4443f4323d858b666d35a919ba8']",
            "before_first_fix_commit":"{'3e47c4f1933aa3ffd0975e24e34b7af35de947b4'}",
            "last_fix_commit":"ad3928f67b2cd4443f4323d858b666d35a919ba8",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/22\/2022, 16:26:41",
            "message":"update",
            "author":"Peter Ivanov",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 2, 'total': 9}",
            "files":"{'src\/MicroweberPackages\/App\/Http\/Controllers\/ApiController.php': {'additions': 7, 'deletions': 2, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/ad3928f67b2cd4443f4323d858b666d35a919ba8\/src%2FMicroweberPackages%2FApp%2FHttp%2FControllers%2FApiController.php', 'patch': \"@@ -611,18 +611,23 @@ public function module()\\n             $request_data_new = [];\\n             $antixss = new AntiXSS();\\n             foreach ($request_data as $k=>$v){\\n-\\n+                if(is_string($v)) {\\n+                    $v = str_replace('<', '-', $v);\\n+                    $v = str_replace('>', '-', $v);\\n+                }\\n                 $v = $antixss->xss_clean($v);\\n \\n                 if(is_string($k)){\\n+                    $k = str_replace('<', '-', $k);\\n+                    $k = str_replace('>', '-', $k);\\n                     $k = $antixss->xss_clean($k);\\n                     if($k){\\n                         $request_data_new[$k] = $v;\\n                     }\\n                 } else {\\n                     $request_data_new[$k] = $v;\\n                 }\\n-                \\n+\\n             }\\n             $request_data = $request_data_new;\\n         }\"}}",
            "message_norm":"update",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/App\/Http\/Controllers\/ApiController.php'])",
            "num_files":1.0,
            "patch_content":"From ad3928f67b2cd4443f4323d858b666d35a919ba8 Mon Sep 17 00:00:00 2001\nFrom: Peter Ivanov <peter@microweber.com>\nDate: Fri, 22 Apr 2022 19:26:41 +0300\nSubject: [PATCH] update\n\n---\n ...\/App\/Http\/Controllers\/ApiController.php               | 9 +++++++--\n 1 file changed, 7 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/MicroweberPackages\/App\/Http\/Controllers\/ApiController.php b\/src\/MicroweberPackages\/App\/Http\/Controllers\/ApiController.php\nindex 6d628263d5b..9e72121a9e6 100644\n--- a\/src\/MicroweberPackages\/App\/Http\/Controllers\/ApiController.php\n+++ b\/src\/MicroweberPackages\/App\/Http\/Controllers\/ApiController.php\n@@ -611,10 +611,15 @@ public function module()\n             $request_data_new = [];\n             $antixss = new AntiXSS();\n             foreach ($request_data as $k=>$v){\n-\n+                if(is_string($v)) {\n+                    $v = str_replace('<', '-', $v);\n+                    $v = str_replace('>', '-', $v);\n+                }\n                 $v = $antixss->xss_clean($v);\n \n                 if(is_string($k)){\n+                    $k = str_replace('<', '-', $k);\n+                    $k = str_replace('>', '-', $k);\n                     $k = $antixss->xss_clean($k);\n                     if($k){\n                         $request_data_new[$k] = $v;\n@@ -622,7 +627,7 @@ public function module()\n                 } else {\n                     $request_data_new[$k] = $v;\n                 }\n-                \n+\n             }\n             $request_data = $request_data_new;\n         }"
        },
        {
            "index":827,
            "vuln_id":"GHSA-gg6x-xx78-448c",
            "cwe_id":"{'CWE-87'}",
            "score":4.0,
            "chain":"{'https:\/\/github.com\/octobercms\/october\/commit\/cd0b6a791f995d86071a024464c1702efc50f46c'}",
            "dataset":"osv",
            "summary":"Reflected XSS when importing CSV in OctoberCMS ### Impact\nA user with the ability to use the import functionality of the `ImportExportController` behavior could be socially engineered by an attacker to upload a maliciously crafted CSV file which could result in a reflected XSS attack on the user in question\n\n### Patches\nIssue has been patched in Build 466 (v1.0.466).\n\n### Workarounds\nApply https:\/\/github.com\/octobercms\/october\/commit\/cd0b6a791f995d86071a024464c1702efc50f46c to your installation manually if unable to upgrade to Build 466.\n\n### References\nReported by [Sivanesh Ashok](https:\/\/stazot.com\/)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at [hello@octobercms.com](mailto:hello@octobercms.com)\n\n### Threat assessment:\n<img width=\"1100\" alt=\"Screen Shot 2020-03-31 at 2 01 52 PM\" src=\"https:\/\/user-images.githubusercontent.com\/7253840\/78070158-8f7ef580-7358-11ea-950c-226533f6a0a3.png\">",
            "published_date":"2020-06-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/octobercms\/october",
            "commit_href":"https:\/\/github.com\/octobercms\/october\/commit\/cd0b6a791f995d86071a024464c1702efc50f46c",
            "commit_sha":"cd0b6a791f995d86071a024464c1702efc50f46c",
            "patch":"SINGLE",
            "chain_ord":"['cd0b6a791f995d86071a024464c1702efc50f46c']",
            "before_first_fix_commit":"{'6711dae8ef70caf0e94cec434498012a2ccd86b8'}",
            "last_fix_commit":"cd0b6a791f995d86071a024464c1702efc50f46c",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/31\/2020, 10:17:41",
            "message":"escape import CSV column names",
            "author":"Luke Towers",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'modules\/backend\/behaviors\/importexportcontroller\/partials\/_import_file_columns.htm': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/octobercms\/october\/raw\/cd0b6a791f995d86071a024464c1702efc50f46c\/modules%2Fbackend%2Fbehaviors%2Fimportexportcontroller%2Fpartials%2F_import_file_columns.htm', 'patch': '@@ -22,7 +22,7 @@\\n                                 class=\"column-label\"\\n                                 onclick=\"$.oc.importBehavior.loadFileColumnSample(this)\"\\n                             >\\n-                                <?= $column ?>\\n+                                <?= e($column) ?>\\n                             <\/a>\\n                         <\/span>\\n                     <\/div>'}}",
            "message_norm":"escape import csv column names",
            "language":"ro",
            "entities":"[('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/backend\/behaviors\/importexportcontroller\/partials\/_import_file_columns.htm'])",
            "num_files":1.0,
            "patch_content":"From cd0b6a791f995d86071a024464c1702efc50f46c Mon Sep 17 00:00:00 2001\nFrom: Luke Towers <github@luketowers.ca>\nDate: Tue, 31 Mar 2020 04:17:41 -0600\nSubject: [PATCH] escape import CSV column names\n\n---\n ...\/importexportcontroller\/partials\/_import_file_columns.htm    | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/modules\/backend\/behaviors\/importexportcontroller\/partials\/_import_file_columns.htm b\/modules\/backend\/behaviors\/importexportcontroller\/partials\/_import_file_columns.htm\nindex 8677699774..b221e54879 100644\n--- a\/modules\/backend\/behaviors\/importexportcontroller\/partials\/_import_file_columns.htm\n+++ b\/modules\/backend\/behaviors\/importexportcontroller\/partials\/_import_file_columns.htm\n@@ -22,7 +22,7 @@\n                                 class=\"column-label\"\n                                 onclick=\"$.oc.importBehavior.loadFileColumnSample(this)\"\n                             >\n-                                <?= $column ?>\n+                                <?= e($column) ?>\n                             <\/a>\n                         <\/span>\n                     <\/div>"
        },
        {
            "index":634,
            "vuln_id":"GHSA-hj8g-cw8x-2c6m",
            "cwe_id":"{'CWE-79'}",
            "score":7.6,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/a5925f74d39775771d4c37c8d4c1acbb762fda0a'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Microweber Microweber prior to version 1.3 is vulnerable to reflected cross-site scripting.",
            "published_date":"2022-02-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/a5925f74d39775771d4c37c8d4c1acbb762fda0a",
            "commit_sha":"a5925f74d39775771d4c37c8d4c1acbb762fda0a",
            "patch":"SINGLE",
            "chain_ord":"['a5925f74d39775771d4c37c8d4c1acbb762fda0a']",
            "before_first_fix_commit":"{'0b6b1eb5ba85ffc8f74e6f5f5be9dc9f9f7e9d8f'}",
            "last_fix_commit":"a5925f74d39775771d4c37c8d4c1acbb762fda0a",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/22\/2022, 10:18:26",
            "message":"Update UrlManager.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'src\/MicroweberPackages\/Helper\/UrlManager.php': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/a5925f74d39775771d4c37c8d4c1acbb762fda0a\/src%2FMicroweberPackages%2FHelper%2FUrlManager.php', 'patch': '@@ -276,7 +276,8 @@ public function string($skip_ajax = false)\\n \\n         \/\/ clear request params\\n         $cleanParam = new HTMLClean();\\n-        $u1 = $cleanParam->cleanArray($u1);\\n+        $u1 = $cleanParam->clean($u1);\\n+\\n \\n         return $u1;\\n     }'}}",
            "message_norm":"update urlmanager.php",
            "language":"sv",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"SUBMIT_CENTERED",
            "list_files":"dict_keys(['src\/MicroweberPackages\/Helper\/UrlManager.php'])",
            "num_files":1.0,
            "patch_content":"From a5925f74d39775771d4c37c8d4c1acbb762fda0a Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Tue, 22 Feb 2022 12:18:26 +0200\nSubject: [PATCH] Update UrlManager.php\n\n---\n src\/MicroweberPackages\/Helper\/UrlManager.php | 3 ++-\n 1 file changed, 2 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/MicroweberPackages\/Helper\/UrlManager.php b\/src\/MicroweberPackages\/Helper\/UrlManager.php\nindex 4e277892b04..74996d7aa52 100644\n--- a\/src\/MicroweberPackages\/Helper\/UrlManager.php\n+++ b\/src\/MicroweberPackages\/Helper\/UrlManager.php\n@@ -276,7 +276,8 @@ public function string($skip_ajax = false)\n \n         \/\/ clear request params\n         $cleanParam = new HTMLClean();\n-        $u1 = $cleanParam->cleanArray($u1);\n+        $u1 = $cleanParam->clean($u1);\n+\n \n         return $u1;\n     }"
        },
        {
            "index":170,
            "vuln_id":"GHSA-pxcf-v868-m492",
            "cwe_id":"{'CWE-74', 'CWE-79'}",
            "score":7.6,
            "chain":"{'https:\/\/github.com\/jperelli\/osm-static-maps\/commit\/97355d29e08753d1cfe99b1281dbaa06f4e651b0'}",
            "dataset":"osv",
            "summary":"Injection and Cross-site Scripting in osm-static-maps This affects all versions of package osm-static-maps under 3.9.0. User input given to the package is passed directly to a template without escaping ({{{ ... }}}). As such, it is possible for an attacker to inject arbitrary HTML\/JS code and depending on the context. It will be outputted as an HTML on the page which gives opportunity for XSS or rendered on the server (puppeteer) which also gives opportunity for SSRF and Local File Read.",
            "published_date":"2021-05-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/jperelli\/osm-static-maps",
            "commit_href":"https:\/\/github.com\/jperelli\/osm-static-maps\/commit\/97355d29e08753d1cfe99b1281dbaa06f4e651b0",
            "commit_sha":"97355d29e08753d1cfe99b1281dbaa06f4e651b0",
            "patch":"SINGLE",
            "chain_ord":"['97355d29e08753d1cfe99b1281dbaa06f4e651b0']",
            "before_first_fix_commit":"{'6bce2e2a8dd4cbbbbe083820e494ba858be74b16'}",
            "last_fix_commit":"97355d29e08753d1cfe99b1281dbaa06f4e651b0",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/11\/2020, 23:25:42",
            "message":"fix: escape special characters before insertion to template",
            "author":"snoopysecurity",
            "comments":null,
            "stats":"{'additions': 25, 'deletions': 6, 'total': 31}",
            "files":"{'src\/server.js': {'additions': 25, 'deletions': 6, 'changes': 31, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jperelli\/osm-static-maps\/raw\/97355d29e08753d1cfe99b1281dbaa06f4e651b0\/src%2Fserver.js', 'patch': '@@ -19,6 +19,23 @@ app.use((req, res, next) => {\\n   next();\\n });\\n \\n+\\n+function htmlEscape(text) {\\n+  return text.replace(\/&\/g, \\'&amp;\\').\\n+  replace(\/<\/g, \\'&lt;\\').\\n+  replace(\/\"\/g, \\'&quot;\\').\\n+  replace(\/\\'\/g, \\'&#039;\\');\\n+}\\n+\\n+\\n+function sanitize(params) {\\n+  result = {}\\n+  for (let [key, value] of Object.entries(params)) {\\n+      result[key] = htmlEscape(value)\\n+  }\\n+  return result;\\n+}\\n+\\n app.get(\"\/health\", (req, res) => res.sendStatus(200));\\n \\n const handler = (res, params) => {\\n@@ -40,12 +57,14 @@ const handler = (res, params) => {\\n app.get(\"\/\", (req, res) => handler(res, req.query));\\n app.post(\"\/\", (req, res) => handler(res, req.body));\\n \\n-app.get(\"\/dynamic\", (req, res) =>\\n-  handler(res, { ...req.query, renderToHtml: true })\\n-);\\n+app.get(\"\/dynamic\", (req, res) => {\\n+  var sanitized = sanitize(req.query)\\n+  handler(res, { ...sanitized, renderToHtml: true })\\n+})\\n \\n-app.post(\"\/dynamic\", (req, res) =>\\n-  handler(res, { ...req.body, renderToHtml: true })\\n-);\\n+app.post(\"\/dynamic\", (req, res) => {\\n+  var sanitized = sanitize(req.body)\\n+  handler(res, { ...sanitized, renderToHtml: true })\\n+})\\n \\n module.exports = http.createServer(app);'}}",
            "message_norm":"fix: escape special characters before insertion to template",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/server.js'])",
            "num_files":1.0,
            "patch_content":"From 97355d29e08753d1cfe99b1281dbaa06f4e651b0 Mon Sep 17 00:00:00 2001\nFrom: snoopysecurity <sams@snyk.io>\nDate: Mon, 12 Oct 2020 00:25:42 +0100\nSubject: [PATCH] fix: escape special characters before insertion to template\n\n---\n src\/server.js | 31 +++++++++++++++++++++++++------\n 1 file changed, 25 insertions(+), 6 deletions(-)\n\ndiff --git a\/src\/server.js b\/src\/server.js\nindex 2485f49..4944708 100644\n--- a\/src\/server.js\n+++ b\/src\/server.js\n@@ -19,6 +19,23 @@ app.use((req, res, next) => {\n   next();\n });\n \n+\n+function htmlEscape(text) {\n+  return text.replace(\/&\/g, '&amp;').\n+  replace(\/<\/g, '&lt;').\n+  replace(\/\"\/g, '&quot;').\n+  replace(\/'\/g, '&#039;');\n+}\n+\n+\n+function sanitize(params) {\n+  result = {}\n+  for (let [key, value] of Object.entries(params)) {\n+      result[key] = htmlEscape(value)\n+  }\n+  return result;\n+}\n+\n app.get(\"\/health\", (req, res) => res.sendStatus(200));\n \n const handler = (res, params) => {\n@@ -40,12 +57,14 @@ const handler = (res, params) => {\n app.get(\"\/\", (req, res) => handler(res, req.query));\n app.post(\"\/\", (req, res) => handler(res, req.body));\n \n-app.get(\"\/dynamic\", (req, res) =>\n-  handler(res, { ...req.query, renderToHtml: true })\n-);\n+app.get(\"\/dynamic\", (req, res) => {\n+  var sanitized = sanitize(req.query)\n+  handler(res, { ...sanitized, renderToHtml: true })\n+})\n \n-app.post(\"\/dynamic\", (req, res) =>\n-  handler(res, { ...req.body, renderToHtml: true })\n-);\n+app.post(\"\/dynamic\", (req, res) => {\n+  var sanitized = sanitize(req.body)\n+  handler(res, { ...sanitized, renderToHtml: true })\n+})\n \n module.exports = http.createServer(app);"
        },
        {
            "index":268,
            "vuln_id":"GHSA-rf66-hmqf-q3fc",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/pull\/6831\/commits\/5848d9a10c7d62c73ff6a3858edfae96a429402a'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Input During Web Page Generation in Select2 In Select2 through 4.0.5, as used in Snipe-IT and other products, rich selectlists allow XSS. This affects use cases with Ajax remote data loading when HTML templates are used to display listbox data.",
            "published_date":"2022-05-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/pull\/6831\/commits\/5848d9a10c7d62c73ff6a3858edfae96a429402a",
            "commit_sha":"5848d9a10c7d62c73ff6a3858edfae96a429402a",
            "patch":"SINGLE",
            "chain_ord":"['5848d9a10c7d62c73ff6a3858edfae96a429402a']",
            "before_first_fix_commit":"{'bd8548325d6b4210015bd0ddeb144c61ae8949be'}",
            "last_fix_commit":"5848d9a10c7d62c73ff6a3858edfae96a429402a",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/19\/2019, 02:29:30",
            "message":"Janky fix for Select2 bug",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 1, 'total': 13}",
            "files":"{'resources\/assets\/js\/snipeit.js': {'additions': 12, 'deletions': 1, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/5848d9a10c7d62c73ff6a3858edfae96a429402a\/resources%2Fassets%2Fjs%2Fsnipeit.js', 'patch': '@@ -260,7 +260,18 @@ $(document).ready(function () {\\n     }\\n \\n     function formatDataSelection (datalist) {\\n-        return datalist.text;\\n+        \/\/ This a heinous workaround for a known bug in Select2.\\n+        \/\/ Without this, the rich selectlists are vulnerable to XSS.\\n+        \/\/ Many thanks to @uberbrady for this fix. It ain\\'t pretty,\\n+        \/\/ but it resolves the issue until Select2 addresses it on their end.\\n+        \/\/\\n+        \/\/ Bug was reported in 2016 :{\\n+        \/\/ https:\/\/github.com\/select2\/select2\/issues\/4587\\n+\\n+        return datalist.text.replace(\/>\/g, \\'&gt;\\')\\n+            .replace(\/<\/g, \\'&lt;\\')\\n+            .replace(\/\"\/g, \\'&quot;\\')\\n+            .replace(\/\\'\/g, \\'&#039;\\');\\n     }\\n \\n     \/\/ This handles the radio button selectors for the checkout-to-foo options'}}",
            "message_norm":"janky fix for select2 bug",
            "language":"en",
            "entities":"[('bug', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['resources\/assets\/js\/snipeit.js'])",
            "num_files":1.0,
            "patch_content":"From 5848d9a10c7d62c73ff6a3858edfae96a429402a Mon Sep 17 00:00:00 2001\nFrom: snipe <snipe@snipe.net>\nDate: Mon, 18 Mar 2019 19:29:30 -0700\nSubject: [PATCH] Janky fix for Select2 bug\n\n---\n resources\/assets\/js\/snipeit.js | 13 ++++++++++++-\n 1 file changed, 12 insertions(+), 1 deletion(-)\n\ndiff --git a\/resources\/assets\/js\/snipeit.js b\/resources\/assets\/js\/snipeit.js\nindex 4e3cb24b4ab5..e2e1dde39cc8 100755\n--- a\/resources\/assets\/js\/snipeit.js\n+++ b\/resources\/assets\/js\/snipeit.js\n@@ -260,7 +260,18 @@ $(document).ready(function () {\n     }\n \n     function formatDataSelection (datalist) {\n-        return datalist.text;\n+        \/\/ This a heinous workaround for a known bug in Select2.\n+        \/\/ Without this, the rich selectlists are vulnerable to XSS.\n+        \/\/ Many thanks to @uberbrady for this fix. It ain't pretty,\n+        \/\/ but it resolves the issue until Select2 addresses it on their end.\n+        \/\/\n+        \/\/ Bug was reported in 2016 :{\n+        \/\/ https:\/\/github.com\/select2\/select2\/issues\/4587\n+\n+        return datalist.text.replace(\/>\/g, '&gt;')\n+            .replace(\/<\/g, '&lt;')\n+            .replace(\/\"\/g, '&quot;')\n+            .replace(\/'\/g, '&#039;');\n     }\n \n     \/\/ This handles the radio button selectors for the checkout-to-foo options"
        },
        {
            "index":293,
            "vuln_id":"GHSA-85r7-w5mv-c849",
            "cwe_id":"{'CWE-22'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/rack\/rack\/commit\/6f237e4c9fab649d3750482514f0fde76c56ab30'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects rack rack\/file.rb (Rack::File) in Rack 1.5.x before 1.5.2 and 1.4.x before 1.4.5 allows attackers to access arbitrary files outside the intended root directory via a crafted PATH_INFO environment variable, probably a directory traversal vulnerability that is remotely exploitable, aka \"symlink path traversals.\"",
            "published_date":"2017-10-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/rack\/rack",
            "commit_href":"https:\/\/github.com\/rack\/rack\/commit\/6f237e4c9fab649d3750482514f0fde76c56ab30",
            "commit_sha":"6f237e4c9fab649d3750482514f0fde76c56ab30",
            "patch":"SINGLE",
            "chain_ord":"['6f237e4c9fab649d3750482514f0fde76c56ab30']",
            "before_first_fix_commit":"{'0cd7e9aa397f8ebb3b8481d67dbac8b4863a7f07'}",
            "last_fix_commit":"6f237e4c9fab649d3750482514f0fde76c56ab30",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/07\/2013, 00:25:22",
            "message":"Prevent symlink path traversals\n\n * Closes CVE-2013-0262",
            "author":"James Tucker",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 11, 'total': 17}",
            "files":"{'lib\/rack\/file.rb': {'additions': 6, 'deletions': 11, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/rack\/rack\/raw\/6f237e4c9fab649d3750482514f0fde76c56ab30\/lib%2Frack%2Ffile.rb', 'patch': '@@ -41,19 +41,14 @@ def _call(env)\\n       path_info = Utils.unescape(env[\"PATH_INFO\"])\\n       parts = path_info.split SEPS\\n \\n-      parts.inject(0) do |depth, part|\\n-        case part\\n-        when \\'\\', \\'.\\'\\n-          depth\\n-        when \\'..\\'\\n-          return fail(404, \"Not Found\") if depth - 1 < 0\\n-          depth - 1\\n-        else\\n-          depth + 1\\n-        end\\n+      clean = []\\n+\\n+      parts.each do |part|\\n+        next if part.empty? || part == \\'.\\'\\n+        part == \\'..\\' ? clean.pop : clean << part\\n       end\\n \\n-      @path = F.join(@root, *parts)\\n+      @path = F.join(@root, *clean)\\n \\n       available = begin\\n         F.file?(@path) && F.readable?(@path)'}}",
            "message_norm":"prevent symlink path traversals\n\n * closes cve-2013-0262",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('symlink', 'SECWORD', ''), ('path traversals', 'SECWORD', ''), ('cve-2013-0262', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/rack\/file.rb'])",
            "num_files":1.0,
            "patch_content":"From 6f237e4c9fab649d3750482514f0fde76c56ab30 Mon Sep 17 00:00:00 2001\nFrom: James Tucker <jftucker@gmail.com>\nDate: Wed, 6 Feb 2013 16:25:22 -0800\nSubject: [PATCH] Prevent symlink path traversals\n\n * Closes CVE-2013-0262\n---\n lib\/rack\/file.rb | 17 ++++++-----------\n 1 file changed, 6 insertions(+), 11 deletions(-)\n\ndiff --git a\/lib\/rack\/file.rb b\/lib\/rack\/file.rb\nindex 090a00151..ee58a1a71 100644\n--- a\/lib\/rack\/file.rb\n+++ b\/lib\/rack\/file.rb\n@@ -41,19 +41,14 @@ def _call(env)\n       path_info = Utils.unescape(env[\"PATH_INFO\"])\n       parts = path_info.split SEPS\n \n-      parts.inject(0) do |depth, part|\n-        case part\n-        when '', '.'\n-          depth\n-        when '..'\n-          return fail(404, \"Not Found\") if depth - 1 < 0\n-          depth - 1\n-        else\n-          depth + 1\n-        end\n+      clean = []\n+\n+      parts.each do |part|\n+        next if part.empty? || part == '.'\n+        part == '..' ? clean.pop : clean << part\n       end\n \n-      @path = F.join(@root, *parts)\n+      @path = F.join(@root, *clean)\n \n       available = begin\n         F.file?(@path) && F.readable?(@path)"
        },
        {
            "index":751,
            "vuln_id":"GHSA-c9qf-r67m-p7cg",
            "cwe_id":"{'CWE-476'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5dc7f6981fdaf74c8c5be41f393df705841fb7c5'}",
            "dataset":"osv",
            "summary":"Null pointer dereference in `CompressElement` ### Impact\nIt is possible to trigger a null pointer dereference in TensorFlow by passing an invalid input to `tf.raw_ops.CompressElement`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.CompressElement(components=[[]])\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/47a06f40411a69c99f381495f490536972152ac0\/tensorflow\/core\/data\/compression_utils.cc#L34) was accessing the size of a buffer obtained from the return of a separate function call before validating that said buffer is valid.\n\n### Patches\nWe have patched the issue in GitHub commit [5dc7f6981fdaf74c8c5be41f393df705841fb7c5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5dc7f6981fdaf74c8c5be41f393df705841fb7c5).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for  more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360. Concurrently, it was resolved in `master` branch as it was also discovered internally and fixed before the report was handled.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5dc7f6981fdaf74c8c5be41f393df705841fb7c5",
            "commit_sha":"5dc7f6981fdaf74c8c5be41f393df705841fb7c5",
            "patch":"SINGLE",
            "chain_ord":"['5dc7f6981fdaf74c8c5be41f393df705841fb7c5']",
            "before_first_fix_commit":"{'de9a4335c96bec8fa69abb89618b1daa4b2459fa'}",
            "last_fix_commit":"5dc7f6981fdaf74c8c5be41f393df705841fb7c5",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/15\/2021, 05:07:07",
            "message":"Fix accessing possible nullptr in tensorflow::data::CompressElement and UncompressElement which are used in tf.data.service.\n\nPiperOrigin-RevId: 373920841\nChange-Id: Ia88d78aee09fa19bb53a0f163fd19620d0c68743",
            "author":"A. Unique TensorFlower",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 7, 'total': 22}",
            "files":"{'tensorflow\/core\/data\/compression_utils.cc': {'additions': 15, 'deletions': 7, 'changes': 22, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/5dc7f6981fdaf74c8c5be41f393df705841fb7c5\/tensorflow%2Fcore%2Fdata%2Fcompression_utils.cc', 'patch': '@@ -29,9 +29,10 @@ Status CompressElement(const std::vector<Tensor>& element,\\n   int64 total_size = 0;\\n   for (auto& component : element) {\\n     if (DataTypeCanUseMemcpy(component.dtype())) {\\n-      \/\/ Some datatypes can be memcopied, allowing us to save two copies\\n-      \/\/ (AsProtoTensorContent and SerializeToArray).\\n-      total_size += DMAHelper::buffer(&component)->size();\\n+      const TensorBuffer* buffer = DMAHelper::buffer(&component);\\n+      if (buffer) {\\n+        total_size += buffer->size();\\n+      }\\n     } else {\\n       non_memcpy_components.emplace_back();\\n       component.AsProtoTensorContent(&non_memcpy_components.back());\\n@@ -53,8 +54,10 @@ Status CompressElement(const std::vector<Tensor>& element,\\n     component.shape().AsProto(metadata->mutable_tensor_shape());\\n     if (DataTypeCanUseMemcpy(component.dtype())) {\\n       const TensorBuffer* buffer = DMAHelper::buffer(&component);\\n-      memcpy(position, buffer->data(), buffer->size());\\n-      metadata->set_tensor_size_bytes(buffer->size());\\n+      if (buffer) {\\n+        memcpy(position, buffer->data(), buffer->size());\\n+        metadata->set_tensor_size_bytes(buffer->size());\\n+      }\\n     } else {\\n       TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\\n       proto.SerializeToArray(position, proto.ByteSizeLong());\\n@@ -94,8 +97,13 @@ Status UncompressElement(const CompressedElement& compressed,\\n     if (DataTypeCanUseMemcpy(metadata.dtype())) {\\n       out->emplace_back(metadata.dtype(), metadata.tensor_shape());\\n       TensorBuffer* buffer = DMAHelper::buffer(&out->back());\\n-      iov[i].iov_base = buffer->data();\\n-      iov[i].iov_len = buffer->size();\\n+      if (buffer) {\\n+        iov[i].iov_base = buffer->data();\\n+        iov[i].iov_len = buffer->size();\\n+      } else {\\n+        iov[i].iov_base = nullptr;\\n+        iov[i].iov_len = 0;\\n+      }\\n     } else {\\n       \/\/ Allocate an empty Tensor. We will fill it out later after\\n       \/\/ uncompressing into the tensor_proto_str.'}}",
            "message_norm":"fix accessing possible nullptr in tensorflow::data::compresselement and uncompresselement which are used in tf.data.service.\n\npiperorigin-revid: 373920841\nchange-id: ia88d78aee09fa19bb53a0f163fd19620d0c68743",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('tensorflow::data::compresselement', 'SECWORD', ''), ('uncompresselement', 'SECWORD', ''), ('373920841', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/data\/compression_utils.cc'])",
            "num_files":1.0,
            "patch_content":"From 5dc7f6981fdaf74c8c5be41f393df705841fb7c5 Mon Sep 17 00:00:00 2001\nFrom: \"A. Unique TensorFlower\" <gardener@tensorflow.org>\nDate: Fri, 14 May 2021 22:07:07 -0700\nSubject: [PATCH] Fix accessing possible nullptr in\n tensorflow::data::CompressElement and UncompressElement which are used in\n tf.data.service.\n\nPiperOrigin-RevId: 373920841\nChange-Id: Ia88d78aee09fa19bb53a0f163fd19620d0c68743\n---\n tensorflow\/core\/data\/compression_utils.cc | 22 +++++++++++++++-------\n 1 file changed, 15 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/core\/data\/compression_utils.cc b\/tensorflow\/core\/data\/compression_utils.cc\nindex bbff3a96667d13..40238a05a2614b 100644\n--- a\/tensorflow\/core\/data\/compression_utils.cc\n+++ b\/tensorflow\/core\/data\/compression_utils.cc\n@@ -29,9 +29,10 @@ Status CompressElement(const std::vector<Tensor>& element,\n   int64 total_size = 0;\n   for (auto& component : element) {\n     if (DataTypeCanUseMemcpy(component.dtype())) {\n-      \/\/ Some datatypes can be memcopied, allowing us to save two copies\n-      \/\/ (AsProtoTensorContent and SerializeToArray).\n-      total_size += DMAHelper::buffer(&component)->size();\n+      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n+      if (buffer) {\n+        total_size += buffer->size();\n+      }\n     } else {\n       non_memcpy_components.emplace_back();\n       component.AsProtoTensorContent(&non_memcpy_components.back());\n@@ -53,8 +54,10 @@ Status CompressElement(const std::vector<Tensor>& element,\n     component.shape().AsProto(metadata->mutable_tensor_shape());\n     if (DataTypeCanUseMemcpy(component.dtype())) {\n       const TensorBuffer* buffer = DMAHelper::buffer(&component);\n-      memcpy(position, buffer->data(), buffer->size());\n-      metadata->set_tensor_size_bytes(buffer->size());\n+      if (buffer) {\n+        memcpy(position, buffer->data(), buffer->size());\n+        metadata->set_tensor_size_bytes(buffer->size());\n+      }\n     } else {\n       TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\n       proto.SerializeToArray(position, proto.ByteSizeLong());\n@@ -94,8 +97,13 @@ Status UncompressElement(const CompressedElement& compressed,\n     if (DataTypeCanUseMemcpy(metadata.dtype())) {\n       out->emplace_back(metadata.dtype(), metadata.tensor_shape());\n       TensorBuffer* buffer = DMAHelper::buffer(&out->back());\n-      iov[i].iov_base = buffer->data();\n-      iov[i].iov_len = buffer->size();\n+      if (buffer) {\n+        iov[i].iov_base = buffer->data();\n+        iov[i].iov_len = buffer->size();\n+      } else {\n+        iov[i].iov_base = nullptr;\n+        iov[i].iov_len = 0;\n+      }\n     } else {\n       \/\/ Allocate an empty Tensor. We will fill it out later after\n       \/\/ uncompressing into the tensor_proto_str."
        },
        {
            "index":774,
            "vuln_id":"GHSA-f7r3-p866-q9qr",
            "cwe_id":"{'CWE-400'}",
            "score":3.7,
            "chain":"{'https:\/\/github.com\/Twipped\/ircdkit\/pull\/2\/commits\/595ed02cde517fad57854d2ac2855a09a626e665', 'https:\/\/github.com\/Twipped\/ircdkit\/commit\/f0cc6dc913ec17b499fa33a676bb72c624456f2c'}",
            "dataset":"osv",
            "summary":"ircdkit vulnerable to Denial of Service due to unhandled connection end event Versions of `ircdkit` 1.0.3 and prior are vulnerable to a remote denial of service.\n\n\n## Recommendation\n\nUpgrade to version 1.0.4.",
            "published_date":"2019-06-03",
            "chain_len":2,
            "project":"https:\/\/github.com\/Twipped\/ircdkit",
            "commit_href":"https:\/\/github.com\/Twipped\/ircdkit\/commit\/f0cc6dc913ec17b499fa33a676bb72c624456f2c",
            "commit_sha":"f0cc6dc913ec17b499fa33a676bb72c624456f2c",
            "patch":"MULTI",
            "chain_ord":"['f0cc6dc913ec17b499fa33a676bb72c624456f2c', '595ed02cde517fad57854d2ac2855a09a626e665']",
            "before_first_fix_commit":"{'74aa751e75a90af34ef63377fcbd41285d155380'}",
            "last_fix_commit":"595ed02cde517fad57854d2ac2855a09a626e665",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/30\/2019, 03:09:45",
            "message":"DOS fix\n\ncorrected unhandled connection 'end' event, fixes issue #1",
            "author":"Trinity Fox",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Twipped\/ircdkit\/raw\/f0cc6dc913ec17b499fa33a676bb72c624456f2c\/lib%2Findex.js', 'patch': \"@@ -47,7 +47,7 @@ function create (options) {\\n \\n \\t\\tclient.on('end', function () {\\n \\t\\t\\tdebug('connection ended');\\n-\\t\\t\\tremoveClient(client);\\n+\\t\\t\\tclient.close();\\n \\t\\t\\tapp.emit('connection:end', client);\\n \\t\\t});\"}}",
            "message_norm":"dos fix\n\ncorrected unhandled connection 'end' event, fixes issue #1",
            "language":"en",
            "entities":"[('dos', 'SECWORD', ''), ('fix', 'ACTION', ''), ('#1', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/index.js'])",
            "num_files":1.0,
            "patch_content":"From f0cc6dc913ec17b499fa33a676bb72c624456f2c Mon Sep 17 00:00:00 2001\nFrom: Trinity Fox <671259+cottonflop@users.noreply.github.com>\nDate: Wed, 29 May 2019 20:09:45 -0700\nSubject: [PATCH] DOS fix\n\ncorrected unhandled connection 'end' event, fixes issue #1\n---\n lib\/index.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/index.js b\/lib\/index.js\nindex 5088eca..6349746 100644\n--- a\/lib\/index.js\n+++ b\/lib\/index.js\n@@ -47,7 +47,7 @@ function create (options) {\n \n \t\tclient.on('end', function () {\n \t\t\tdebug('connection ended');\n-\t\t\tremoveClient(client);\n+\t\t\tclient.close();\n \t\t\tapp.emit('connection:end', client);\n \t\t});"
        },
        {
            "index":283,
            "vuln_id":"GHSA-5rcr-q3rx-j7vr",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/75162b7f2d8ac2b37d17564e9c979ba1bae707e8', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/214dec9461f9acb9a4b9004368d2a81e0c125652'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1062, CVE-2019-1092, CVE-2019-1103, CVE-2019-1106.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/214dec9461f9acb9a4b9004368d2a81e0c125652",
            "commit_sha":"214dec9461f9acb9a4b9004368d2a81e0c125652",
            "patch":"MULTI",
            "chain_ord":"['214dec9461f9acb9a4b9004368d2a81e0c125652', '75162b7f2d8ac2b37d17564e9c979ba1bae707e8']",
            "before_first_fix_commit":"{'12c31f0e83ddc511e57b9aa1e78533899199eb32', 'ba1f4455f921ce5f12091ff8a11c8028c6a64b17'}",
            "last_fix_commit":"75162b7f2d8ac2b37d17564e9c979ba1bae707e8",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/06\/2019, 19:58:34",
            "message":"[CVE-2019-1107] Chakra JIT Type Confusion FinishOptPropOp",
            "author":"Paul Leathers",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'lib\/Backend\/GlobOptFields.cpp': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/214dec9461f9acb9a4b9004368d2a81e0c125652\/lib%2FBackend%2FGlobOptFields.cpp', 'patch': '@@ -410,6 +410,14 @@ GlobOpt::ProcessFieldKills(IR::Instr *instr, BVSparse<JitArenaAllocator> *bv, bo\\n         if (inGlobOpt)\\n         {\\n             KillObjectHeaderInlinedTypeSyms(this->currentBlock, false);\\n+            if (this->objectTypeSyms)\\n+            {\\n+                if (this->currentBlock->globOptData.maybeWrittenTypeSyms == nullptr)\\n+                {\\n+                    this->currentBlock->globOptData.maybeWrittenTypeSyms = JitAnew(this->alloc, BVSparse<JitArenaAllocator>, this->alloc);\\n+                }\\n+                this->currentBlock->globOptData.maybeWrittenTypeSyms->Or(this->objectTypeSyms);\\n+            }\\n         }\\n \\n         \/\/ fall through'}}",
            "message_norm":"[cve-2019-1107] chakra jit type confusion finishoptpropop",
            "language":"en",
            "entities":"[('cve-2019-1107', 'VULNID', 'CVE'), ('type confusion', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Backend\/GlobOptFields.cpp'])",
            "num_files":1.0,
            "patch_content":"From 214dec9461f9acb9a4b9004368d2a81e0c125652 Mon Sep 17 00:00:00 2001\nFrom: Paul Leathers <pleath@microsoft.com>\nDate: Thu, 6 Jun 2019 12:58:34 -0700\nSubject: [PATCH] [CVE-2019-1107] Chakra JIT Type Confusion FinishOptPropOp\n\n---\n lib\/Backend\/GlobOptFields.cpp | 8 ++++++++\n 1 file changed, 8 insertions(+)\n\ndiff --git a\/lib\/Backend\/GlobOptFields.cpp b\/lib\/Backend\/GlobOptFields.cpp\nindex 92a7e9ec108..59e19b71f6d 100644\n--- a\/lib\/Backend\/GlobOptFields.cpp\n+++ b\/lib\/Backend\/GlobOptFields.cpp\n@@ -410,6 +410,14 @@ GlobOpt::ProcessFieldKills(IR::Instr *instr, BVSparse<JitArenaAllocator> *bv, bo\n         if (inGlobOpt)\n         {\n             KillObjectHeaderInlinedTypeSyms(this->currentBlock, false);\n+            if (this->objectTypeSyms)\n+            {\n+                if (this->currentBlock->globOptData.maybeWrittenTypeSyms == nullptr)\n+                {\n+                    this->currentBlock->globOptData.maybeWrittenTypeSyms = JitAnew(this->alloc, BVSparse<JitArenaAllocator>, this->alloc);\n+                }\n+                this->currentBlock->globOptData.maybeWrittenTypeSyms->Or(this->objectTypeSyms);\n+            }\n         }\n \n         \/\/ fall through"
        },
        {
            "index":858,
            "vuln_id":"GHSA-hxmr-5gv9-6p8v",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/librenms\/librenms\/commit\/4f86915866703e2fcd1e34b3fc1181ec2ad78e54'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in librenms Cross-site Scripting (XSS) - Stored in Packagist librenms\/librenms prior to 22.2.0.",
            "published_date":"2022-02-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/librenms\/librenms",
            "commit_href":"https:\/\/github.com\/librenms\/librenms\/commit\/4f86915866703e2fcd1e34b3fc1181ec2ad78e54",
            "commit_sha":"4f86915866703e2fcd1e34b3fc1181ec2ad78e54",
            "patch":"SINGLE",
            "chain_ord":"['4f86915866703e2fcd1e34b3fc1181ec2ad78e54']",
            "before_first_fix_commit":"{'3ac0de16b2767d4d4df25b89aa9439daf070b24c'}",
            "last_fix_commit":"4f86915866703e2fcd1e34b3fc1181ec2ad78e54",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/13\/2022, 18:07:37",
            "message":"XSS fix, cont. (#13776)\n\nhttps:\/\/huntr.dev\/bounties\/13951f51-deed-4a3d-8275-52306cc5a87d\/",
            "author":"PipoCanaja",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 3, 'total': 6}",
            "files":"{'includes\/html\/pages\/addhost.inc.php': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/librenms\/librenms\/raw\/4f86915866703e2fcd1e34b3fc1181ec2ad78e54\/includes%2Fhtml%2Fpages%2Faddhost.inc.php', 'patch': \"@@ -45,9 +45,9 @@\\n             $snmpver = 'v2c';\\n             $additional = [\\n                 'snmp_disable' => 1,\\n-                'os'           => $_POST['os'] ? $_POST['os_id'] : 'ping',\\n-                'hardware'     => $_POST['hardware'],\\n-                'sysName'      => $_POST['sysName'],\\n+                'os'           => $_POST['os'] ? strip_tags($_POST['os_id']) : 'ping',\\n+                'hardware'     => strip_tags($_POST['hardware']),\\n+                'sysName'      => strip_tags($_POST['sysName']),\\n             ];\\n         } elseif ($_POST['snmpver'] === 'v2c' || $_POST['snmpver'] === 'v1') {\\n             if ($_POST['community']) {\"}}",
            "message_norm":"xss fix, cont. (#13776)\n\nhttps:\/\/huntr.dev\/bounties\/13951f51-deed-4a3d-8275-52306cc5a87d\/",
            "language":"ca",
            "entities":"[('xss', 'SECWORD', ''), ('#13776', 'ISSUE', ''), ('https:\/\/huntr.dev\/bounties\/13951f51-deed-4a3d-8275-52306cc5a87d\/', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['includes\/html\/pages\/addhost.inc.php'])",
            "num_files":1.0,
            "patch_content":"From 4f86915866703e2fcd1e34b3fc1181ec2ad78e54 Mon Sep 17 00:00:00 2001\nFrom: PipoCanaja <38363551+PipoCanaja@users.noreply.github.com>\nDate: Sun, 13 Feb 2022 19:07:37 +0100\nSubject: [PATCH] XSS fix, cont. (#13776)\n\nhttps:\/\/huntr.dev\/bounties\/13951f51-deed-4a3d-8275-52306cc5a87d\/\n---\n includes\/html\/pages\/addhost.inc.php | 6 +++---\n 1 file changed, 3 insertions(+), 3 deletions(-)\n\ndiff --git a\/includes\/html\/pages\/addhost.inc.php b\/includes\/html\/pages\/addhost.inc.php\nindex 07dc9e44ade5..c95135673560 100644\n--- a\/includes\/html\/pages\/addhost.inc.php\n+++ b\/includes\/html\/pages\/addhost.inc.php\n@@ -45,9 +45,9 @@\n             $snmpver = 'v2c';\n             $additional = [\n                 'snmp_disable' => 1,\n-                'os'           => $_POST['os'] ? $_POST['os_id'] : 'ping',\n-                'hardware'     => $_POST['hardware'],\n-                'sysName'      => $_POST['sysName'],\n+                'os'           => $_POST['os'] ? strip_tags($_POST['os_id']) : 'ping',\n+                'hardware'     => strip_tags($_POST['hardware']),\n+                'sysName'      => strip_tags($_POST['sysName']),\n             ];\n         } elseif ($_POST['snmpver'] === 'v2c' || $_POST['snmpver'] === 'v1') {\n             if ($_POST['community']) {"
        },
        {
            "index":852,
            "vuln_id":"GHSA-jc8m-cxhj-668x",
            "cwe_id":"{'CWE-307'}",
            "score":8.3,
            "chain":"{'https:\/\/github.com\/Sorcery\/sorcery\/commit\/0f116d223826895a73b12492f17486e5d54ab7a7'}",
            "dataset":"osv",
            "summary":"Improper Restriction of Excessive Authentication Attempts in Sorcery ### Impact\nBrute force vulnerability when using password authentication via Sorcery. The brute force protection submodule will prevent a brute force attack for the defined lockout period, but once expired protection will not be re-enabled until a user or malicious actor logs in successfully. This does not affect users that do not use the built-in brute force protection submodule, nor users that use permanent account lockout.\n\n### Patches\nPatched as of version `0.15.0`.\n\n### Workarounds\nCurrently no workarounds, other than monkey patching the authenticate method provided by Sorcery or upgrading to version `0.15.0`.",
            "published_date":"2020-05-07",
            "chain_len":1,
            "project":"https:\/\/github.com\/Sorcery\/sorcery",
            "commit_href":"https:\/\/github.com\/Sorcery\/sorcery\/commit\/0f116d223826895a73b12492f17486e5d54ab7a7",
            "commit_sha":"0f116d223826895a73b12492f17486e5d54ab7a7",
            "patch":"SINGLE",
            "chain_ord":"['0f116d223826895a73b12492f17486e5d54ab7a7']",
            "before_first_fix_commit":"{'6b72ca36cf389804963e2553ccbb3da000518e51'}",
            "last_fix_commit":"0f116d223826895a73b12492f17486e5d54ab7a7",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/02\/2020, 20:56:58",
            "message":"Fix brute force vuln due to callbacks not being ran (#235)\n\nThe authenticate method previously would return before callbacks executed if an\r\ninvalid password was provided, which causes the brute force protection to only\r\nwork for the first lockout period, and only resets after a successful login.\r\n\r\nFixes #231",
            "author":"Josh Buker",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'lib\/sorcery\/model.rb': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Sorcery\/sorcery\/raw\/0f116d223826895a73b12492f17486e5d54ab7a7\/lib%2Fsorcery%2Fmodel.rb', 'patch': '@@ -102,10 +102,6 @@ def authenticate(*credentials, &block)\\n \\n         set_encryption_attributes\\n \\n-        unless user.valid_password?(credentials[1])\\n-          return authentication_response(user: user, failure: :invalid_password, &block)\\n-        end\\n-\\n         if user.respond_to?(:active_for_authentication?) && !user.active_for_authentication?\\n           return authentication_response(user: user, failure: :inactive, &block)\\n         end\\n@@ -118,6 +114,10 @@ def authenticate(*credentials, &block)\\n           end\\n         end\\n \\n+        unless user.valid_password?(credentials[1])\\n+          return authentication_response(user: user, failure: :invalid_password, &block)\\n+        end\\n+\\n         authentication_response(user: user, return_value: user, &block)\\n       end'}}",
            "message_norm":"fix brute force vuln due to callbacks not being ran (#235)\n\nthe authenticate method previously would return before callbacks executed if an\r\ninvalid password was provided, which causes the brute force protection to only\r\nwork for the first lockout period, and only resets after a successful login.\r\n\r\nfixes #231",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('#235', 'ISSUE', ''), ('password', 'SECWORD', ''), ('protection', 'SECWORD', ''), ('login', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#231', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/sorcery\/model.rb'])",
            "num_files":1.0,
            "patch_content":"From 0f116d223826895a73b12492f17486e5d54ab7a7 Mon Sep 17 00:00:00 2001\nFrom: Josh Buker <buker.joshua@gmail.com>\nDate: Sat, 2 May 2020 20:56:58 +0000\nSubject: [PATCH] Fix brute force vuln due to callbacks not being ran (#235)\n\nThe authenticate method previously would return before callbacks executed if an\ninvalid password was provided, which causes the brute force protection to only\nwork for the first lockout period, and only resets after a successful login.\n\nFixes #231\n---\n lib\/sorcery\/model.rb | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/lib\/sorcery\/model.rb b\/lib\/sorcery\/model.rb\nindex 395710cf..6a500fc4 100644\n--- a\/lib\/sorcery\/model.rb\n+++ b\/lib\/sorcery\/model.rb\n@@ -102,10 +102,6 @@ def authenticate(*credentials, &block)\n \n         set_encryption_attributes\n \n-        unless user.valid_password?(credentials[1])\n-          return authentication_response(user: user, failure: :invalid_password, &block)\n-        end\n-\n         if user.respond_to?(:active_for_authentication?) && !user.active_for_authentication?\n           return authentication_response(user: user, failure: :inactive, &block)\n         end\n@@ -118,6 +114,10 @@ def authenticate(*credentials, &block)\n           end\n         end\n \n+        unless user.valid_password?(credentials[1])\n+          return authentication_response(user: user, failure: :invalid_password, &block)\n+        end\n+\n         authentication_response(user: user, return_value: user, &block)\n       end"
        },
        {
            "index":530,
            "vuln_id":"GHSA-mxh3-2699-98g9",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/b5a9ad65e5a4dde1916f02019f8686ad835681ce'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting pimcore pimcore version 10.3.0 and prior is vulnerable to cross-site scripting.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/b5a9ad65e5a4dde1916f02019f8686ad835681ce",
            "commit_sha":"b5a9ad65e5a4dde1916f02019f8686ad835681ce",
            "patch":"SINGLE",
            "chain_ord":"['b5a9ad65e5a4dde1916f02019f8686ad835681ce']",
            "before_first_fix_commit":"{'6ccb5c12fc1be065ebce9c89c4677ee939b88597'}",
            "last_fix_commit":"b5a9ad65e5a4dde1916f02019f8686ad835681ce",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/07\/2022, 14:23:39",
            "message":"[Admin] DataObject - Escape class definitions group properly",
            "author":"dpahuja",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassController.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/b5a9ad65e5a4dde1916f02019f8686ad835681ce\/bundles%2FAdminBundle%2FController%2FAdmin%2FDataObject%2FClassController.php', 'patch': \"@@ -861,7 +861,7 @@ public function fieldcollectionTreeAction(Request $request, EventDispatcherInter\\n                 if (!isset($groups[$item->getGroup()])) {\\n                     $groups[$item->getGroup()] = [\\n                         'id' => 'group_' . $item->getKey(),\\n-                        'text' => $item->getGroup(),\\n+                        'text' => htmlspecialchars($item->getGroup()),\\n                         'expandable' => true,\\n                         'leaf' => false,\\n                         'allowChildren' => true,\\n@@ -1266,7 +1266,7 @@ public function objectbrickTreeAction(Request $request, EventDispatcherInterface\\n                 if (!isset($groups[$item->getGroup()])) {\\n                     $groups[$item->getGroup()] = [\\n                         'id' => 'group_' . $item->getKey(),\\n-                        'text' => $item->getGroup(),\\n+                        'text' => htmlspecialchars($item->getGroup()),\\n                         'expandable' => true,\\n                         'leaf' => false,\\n                         'allowChildren' => true,\"}}",
            "message_norm":"[admin] dataobject - escape class definitions group properly",
            "language":"fr",
            "entities":"[('admin', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassController.php'])",
            "num_files":1.0,
            "patch_content":"From b5a9ad65e5a4dde1916f02019f8686ad835681ce Mon Sep 17 00:00:00 2001\nFrom: dpahuja <divesh.pahuja@pimcore.com>\nDate: Mon, 7 Feb 2022 15:23:39 +0100\nSubject: [PATCH] [Admin] DataObject - Escape class definitions group properly\n\n---\n ...\/Controller\/Admin\/DataObject\/ClassController.php           | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassController.php b\/bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassController.php\nindex ac818bca628..a041274b7b3 100644\n--- a\/bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassController.php\n+++ b\/bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassController.php\n@@ -861,7 +861,7 @@ public function fieldcollectionTreeAction(Request $request, EventDispatcherInter\n                 if (!isset($groups[$item->getGroup()])) {\n                     $groups[$item->getGroup()] = [\n                         'id' => 'group_' . $item->getKey(),\n-                        'text' => $item->getGroup(),\n+                        'text' => htmlspecialchars($item->getGroup()),\n                         'expandable' => true,\n                         'leaf' => false,\n                         'allowChildren' => true,\n@@ -1266,7 +1266,7 @@ public function objectbrickTreeAction(Request $request, EventDispatcherInterface\n                 if (!isset($groups[$item->getGroup()])) {\n                     $groups[$item->getGroup()] = [\n                         'id' => 'group_' . $item->getKey(),\n-                        'text' => $item->getGroup(),\n+                        'text' => htmlspecialchars($item->getGroup()),\n                         'expandable' => true,\n                         'leaf' => false,\n                         'allowChildren' => true,"
        },
        {
            "index":291,
            "vuln_id":"GHSA-338v-3958-8v8r",
            "cwe_id":"{'CWE-362'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/weld\/core\/commit\/6808b11cd6d97c71a2eed754ed4f955acd789086', 'https:\/\/github.com\/weld\/core\/commit\/29fd1107fd30579ad9bb23fae4dc3ba464205745', 'https:\/\/github.com\/weld\/core\/commit\/8e413202fa1af08c09c580f444e4fd16874f9c65'}",
            "dataset":"osv",
            "summary":"Information disclosure in JBoss Weld Race condition in JBoss Weld before 2.2.8 and 3.x before 3.0.0 Alpha3 allows remote attackers to obtain information from a previous conversation via vectors related to a stale thread state.",
            "published_date":"2020-06-10",
            "chain_len":3,
            "project":"https:\/\/github.com\/weld\/core",
            "commit_href":"https:\/\/github.com\/weld\/core\/commit\/6808b11cd6d97c71a2eed754ed4f955acd789086",
            "commit_sha":"6808b11cd6d97c71a2eed754ed4f955acd789086",
            "patch":"MULTI",
            "chain_ord":"['29fd1107fd30579ad9bb23fae4dc3ba464205745', '6808b11cd6d97c71a2eed754ed4f955acd789086', '8e413202fa1af08c09c580f444e4fd16874f9c65']",
            "before_first_fix_commit":"{'6808b11cd6d97c71a2eed754ed4f955acd789086'}",
            "last_fix_commit":"8e413202fa1af08c09c580f444e4fd16874f9c65",
            "chain_ord_pos":2.0,
            "commit_datetime":"12\/01\/2014, 16:48:56",
            "message":"WELD-1802 RequestScopedCache - Make sure each request is ended before a new one is started",
            "author":"Jozef Hartinger",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'impl\/src\/main\/java\/org\/jboss\/weld\/context\/cache\/RequestScopedCache.java': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/weld\/core\/raw\/6808b11cd6d97c71a2eed754ed4f955acd789086\/impl%2Fsrc%2Fmain%2Fjava%2Forg%2Fjboss%2Fweld%2Fcontext%2Fcache%2FRequestScopedCache.java', 'patch': '@@ -71,6 +71,8 @@ public void invalidate() {\\n     }\\n \\n     public static void beginRequest() {\\n+        \/\/ if the previous request was not ended properly for some reason, make sure it is ended now\\n+        endRequest();\\n         CACHE.set(new LinkedList<RequestScopedItem>());\\n     }\\n \\n@@ -80,8 +82,8 @@ public static void beginRequest() {\\n      *\/\\n     public static void endRequest() {\\n         final List<RequestScopedItem> result = CACHE.get();\\n-        CACHE.remove();\\n         if (result != null) {\\n+            CACHE.remove();\\n             for (final RequestScopedItem item : result) {\\n                 item.invalidate();\\n             }'}}",
            "message_norm":"weld-1802 requestscopedcache - make sure each request is ended before a new one is started",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['impl\/src\/main\/java\/org\/jboss\/weld\/context\/cache\/RequestScopedCache.java'])",
            "num_files":1.0,
            "patch_content":"From 6808b11cd6d97c71a2eed754ed4f955acd789086 Mon Sep 17 00:00:00 2001\nFrom: Jozef Hartinger <jharting@redhat.com>\nDate: Mon, 1 Dec 2014 17:48:56 +0100\nSubject: [PATCH] WELD-1802 RequestScopedCache - Make sure each request is\n ended before a new one is started\n\n---\n ...\/java\/org\/jboss\/weld\/context\/cache\/RequestScopedCache.java | 4 +++-\n 1 file changed, 3 insertions(+), 1 deletion(-)\n\ndiff --git a\/impl\/src\/main\/java\/org\/jboss\/weld\/context\/cache\/RequestScopedCache.java b\/impl\/src\/main\/java\/org\/jboss\/weld\/context\/cache\/RequestScopedCache.java\nindex 27d6664f27f..3eae118ab30 100644\n--- a\/impl\/src\/main\/java\/org\/jboss\/weld\/context\/cache\/RequestScopedCache.java\n+++ b\/impl\/src\/main\/java\/org\/jboss\/weld\/context\/cache\/RequestScopedCache.java\n@@ -71,6 +71,8 @@ public void invalidate() {\n     }\n \n     public static void beginRequest() {\n+        \/\/ if the previous request was not ended properly for some reason, make sure it is ended now\n+        endRequest();\n         CACHE.set(new LinkedList<RequestScopedItem>());\n     }\n \n@@ -80,8 +82,8 @@ public static void beginRequest() {\n      *\/\n     public static void endRequest() {\n         final List<RequestScopedItem> result = CACHE.get();\n-        CACHE.remove();\n         if (result != null) {\n+            CACHE.remove();\n             for (final RequestScopedItem item : result) {\n                 item.invalidate();\n             }"
        },
        {
            "index":485,
            "vuln_id":"GHSA-5jgj-h9wp-53fr",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/idno\/known\/commit\/80b716a8392fb71cfce84d03aaf7c045c62f6350'}",
            "dataset":"osv",
            "summary":"Known vulnerable to code execution via SVG file in v1.3.1 An issue in the isSVG() function of Known v1.3.1 allows attackers to execute arbitrary code via a crafted SVG file.\n\nThe researcher report indicates that versions 1.3.1 and prior are vulnerable. Version 1.2.2 is the last version tagged on GitHub and in Packagist, and development related to the 1.3.x branch is currently on the `dev` branch of the idno\/known repository.",
            "published_date":"2022-07-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/idno\/known",
            "commit_href":"https:\/\/github.com\/idno\/known\/commit\/80b716a8392fb71cfce84d03aaf7c045c62f6350",
            "commit_sha":"80b716a8392fb71cfce84d03aaf7c045c62f6350",
            "patch":"SINGLE",
            "chain_ord":"['80b716a8392fb71cfce84d03aaf7c045c62f6350']",
            "before_first_fix_commit":"{'e86e779cf1db93cd488ee578e92a16008132a114'}",
            "last_fix_commit":"80b716a8392fb71cfce84d03aaf7c045c62f6350",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/18\/2021, 15:44:26",
            "message":"Checking for script tags in GIFs etc (#3017)",
            "author":"Ben Werdmuller",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 0, 'total': 14}",
            "files":"{'Idno\/Entities\/File.php': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/idno\/known\/raw\/80b716a8392fb71cfce84d03aaf7c045c62f6350\/Idno%2FEntities%2FFile.php', 'patch': \"@@ -285,6 +285,20 @@ public static function isImage($file_path)\\n             return false;\\n         }\\n \\n+        \/**\\n+         * Detects whether the file contains PHP or script tags, eg to check for embedded code in GIFs\\n+         * @param $file_path\\n+         * @return bool\\n+         *\/\\n+        public static function isFileFreeFromScriptTags($file_path)\\n+        {\\n+            if ($contents = file_get_contents($file_path)) {\\n+                if (stripos($contents, '<script') || strpos($contents, '<?')) return false;\\n+                return true;\\n+            }\\n+            return false;\\n+        }\\n+\\n         \/**\\n          * Retrieve a file by ID\\n          *\"}}",
            "message_norm":"checking for script tags in gifs etc (#3017)",
            "language":"en",
            "entities":"[('#3017', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Idno\/Entities\/File.php'])",
            "num_files":1.0,
            "patch_content":"From 80b716a8392fb71cfce84d03aaf7c045c62f6350 Mon Sep 17 00:00:00 2001\nFrom: Ben Werdmuller <ben@benwerd.com>\nDate: Thu, 18 Nov 2021 10:44:26 -0500\nSubject: [PATCH] Checking for script tags in GIFs etc (#3017)\n\n---\n Idno\/Entities\/File.php | 14 ++++++++++++++\n 1 file changed, 14 insertions(+)\n\ndiff --git a\/Idno\/Entities\/File.php b\/Idno\/Entities\/File.php\nindex 568a3b2e48..fffa8301c3 100644\n--- a\/Idno\/Entities\/File.php\n+++ b\/Idno\/Entities\/File.php\n@@ -285,6 +285,20 @@ public static function isImage($file_path)\n             return false;\n         }\n \n+        \/**\n+         * Detects whether the file contains PHP or script tags, eg to check for embedded code in GIFs\n+         * @param $file_path\n+         * @return bool\n+         *\/\n+        public static function isFileFreeFromScriptTags($file_path)\n+        {\n+            if ($contents = file_get_contents($file_path)) {\n+                if (stripos($contents, '<script') || strpos($contents, '<?')) return false;\n+                return true;\n+            }\n+            return false;\n+        }\n+\n         \/**\n          * Retrieve a file by ID\n          *"
        },
        {
            "index":411,
            "vuln_id":"GHSA-p55x-7x9v-q8m4",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/miekg\/dns\/commit\/43913f2f4fbd7dcff930b8a809e709591e4dd79e'}",
            "dataset":"osv",
            "summary":"Denial of Service in miekg-dns A denial of service flaw was found in miekg-dns before 1.0.4. A remote attacker could use carefully timed TCP packets to block the DNS server from accepting new connections.",
            "published_date":"2021-06-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/miekg\/dns",
            "commit_href":"https:\/\/github.com\/miekg\/dns\/commit\/43913f2f4fbd7dcff930b8a809e709591e4dd79e",
            "commit_sha":"43913f2f4fbd7dcff930b8a809e709591e4dd79e",
            "patch":"SINGLE",
            "chain_ord":"['43913f2f4fbd7dcff930b8a809e709591e4dd79e']",
            "before_first_fix_commit":"{'862243b3b1e77ca9f73771fc95a7148d11cebb55'}",
            "last_fix_commit":"43913f2f4fbd7dcff930b8a809e709591e4dd79e",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/25\/2018, 10:36:19",
            "message":"Fix for CVE-2017-15133 TCP DOS (#631)\n\nserveTCP calls reader.ReadTCP in the accept loop rather than in\r\nthe per-connection goroutine. If an attacker opens a connection\r\nand leaves it idle, this will block the accept loop until the\r\nconnection times out (2s by default). During this time no other\r\nincoming connections will succeed, preventing legitimate queries\r\nfrom being answered.\r\n\r\nThis commit moves the call to reader.ReadTCP into the per-connection\r\ngoroutine. It also adds a missing call to Close whose absence allowed\r\nfile-descirptors to leak in select cases.\r\n\r\nThis attack and fix have no impact on serving UDP queries.",
            "author":"Miek Gieben",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 5, 'total': 13}",
            "files":"{'server.go': {'additions': 8, 'deletions': 5, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/miekg\/dns\/raw\/43913f2f4fbd7dcff930b8a809e709591e4dd79e\/server.go', 'patch': '@@ -472,11 +472,14 @@ func (srv *Server) serveTCP(l net.Listener) error {\\n \\t\\t\\t}\\n \\t\\t\\treturn err\\n \\t\\t}\\n-\\t\\tm, err := reader.ReadTCP(rw, rtimeout)\\n-\\t\\tif err != nil {\\n-\\t\\t\\tcontinue\\n-\\t\\t}\\n-\\t\\tgo srv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\\n+\\t\\tgo func() {\\n+\\t\\t\\tm, err := reader.ReadTCP(rw, rtimeout)\\n+\\t\\t\\tif err != nil {\\n+\\t\\t\\t\\trw.Close()\\n+\\t\\t\\t\\treturn\\n+\\t\\t\\t}\\n+\\t\\t\\tsrv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\\n+\\t\\t}()\\n \\t}\\n }'}}",
            "message_norm":"fix for cve-2017-15133 tcp dos (#631)\n\nservetcp calls reader.readtcp in the accept loop rather than in\r\nthe per-connection goroutine. if an attacker opens a connection\r\nand leaves it idle, this will block the accept loop until the\r\nconnection times out (2s by default). during this time no other\r\nincoming connections will succeed, preventing legitimate queries\r\nfrom being answered.\r\n\r\nthis commit moves the call to reader.readtcp into the per-connection\r\ngoroutine. it also adds a missing call to close whose absence allowed\r\nfile-descirptors to leak in select cases.\r\n\r\nthis attack and fix have no impact on serving udp queries.",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('cve-2017-15133', 'VULNID', 'CVE'), ('dos', 'SECWORD', ''), ('#631', 'ISSUE', ''), ('attacker', 'SECWORD', ''), ('preventing', 'ACTION', ''), ('adds', 'ACTION', ''), ('leak', 'SECWORD', ''), ('attack', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server.go'])",
            "num_files":1.0,
            "patch_content":"From 43913f2f4fbd7dcff930b8a809e709591e4dd79e Mon Sep 17 00:00:00 2001\nFrom: Miek Gieben <miek@miek.nl>\nDate: Thu, 25 Jan 2018 10:36:19 +0000\nSubject: [PATCH] Fix for CVE-2017-15133 TCP DOS (#631)\n\nserveTCP calls reader.ReadTCP in the accept loop rather than in\nthe per-connection goroutine. If an attacker opens a connection\nand leaves it idle, this will block the accept loop until the\nconnection times out (2s by default). During this time no other\nincoming connections will succeed, preventing legitimate queries\nfrom being answered.\n\nThis commit moves the call to reader.ReadTCP into the per-connection\ngoroutine. It also adds a missing call to Close whose absence allowed\nfile-descirptors to leak in select cases.\n\nThis attack and fix have no impact on serving UDP queries.\n---\n server.go | 13 ++++++++-----\n 1 file changed, 8 insertions(+), 5 deletions(-)\n\ndiff --git a\/server.go b\/server.go\nindex b6ce5b5f6..685753f43 100644\n--- a\/server.go\n+++ b\/server.go\n@@ -472,11 +472,14 @@ func (srv *Server) serveTCP(l net.Listener) error {\n \t\t\t}\n \t\t\treturn err\n \t\t}\n-\t\tm, err := reader.ReadTCP(rw, rtimeout)\n-\t\tif err != nil {\n-\t\t\tcontinue\n-\t\t}\n-\t\tgo srv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\n+\t\tgo func() {\n+\t\t\tm, err := reader.ReadTCP(rw, rtimeout)\n+\t\t\tif err != nil {\n+\t\t\t\trw.Close()\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\tsrv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\n+\t\t}()\n \t}\n }"
        },
        {
            "index":637,
            "vuln_id":"GHSA-r24h-634p-m72x",
            "cwe_id":"{'CWE-668'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/Atinux\/schema-inspector\/commit\/345a7b2eed11bb6128421150d65f4f83fdbb737d'}",
            "dataset":"osv",
            "summary":"Validation Bypass in schema-inspector In schema-inspector before 1.6.9, a maliciously crafted JavaScript object can bypass the `sanitize()` and the `validate()` function used within schema-inspector.",
            "published_date":"2020-06-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/Atinux\/schema-inspector",
            "commit_href":"https:\/\/github.com\/Atinux\/schema-inspector\/commit\/345a7b2eed11bb6128421150d65f4f83fdbb737d",
            "commit_sha":"345a7b2eed11bb6128421150d65f4f83fdbb737d",
            "patch":"SINGLE",
            "chain_ord":"['345a7b2eed11bb6128421150d65f4f83fdbb737d']",
            "before_first_fix_commit":"{'7f67b2a95f85ecb76d0dc5326d76d082a2b99e1f'}",
            "last_fix_commit":"345a7b2eed11bb6128421150d65f4f83fdbb737d",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/20\/2020, 15:01:42",
            "message":"fix: Issue #75",
            "author":"S\u00e9bastien Chopin",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'lib\/schema-inspector.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/schema-inspector\/schema-inspector\/raw\/345a7b2eed11bb6128421150d65f4f83fdbb737d\/lib%2Fschema-inspector.js', 'patch': \"@@ -80,7 +80,7 @@\\n \\t\\tthis._custom = {};\\n \\t\\tif (custom != null) {\\n \\t\\t\\tfor (var key in custom) {\\n-\\t\\t\\t\\tif (custom.hasOwnProperty(key)){\\n+\\t\\t\\t\\tif (Object.prototype.hasOwnProperty.call(custom, key)) {\\n \\t\\t\\t\\t\\tthis._custom['$' + key] = custom[key];\\n \\t\\t\\t\\t}\\n \\t\\t\\t}\\n@@ -480,7 +480,7 @@\\n \\t\\t\\t}\\n \\t\\t\\telse {\\n \\t\\t\\t\\tfor (var key in candidate) {\\n-\\t\\t\\t\\t\\tif (candidate.hasOwnProperty(key)){\\n+\\t\\t\\t\\t\\tif (Object.prototype.hasOwnProperty.call(candidate, key)) {\\n \\t\\t\\t\\t\\t\\tthis._deeperArray(key);\\n \\t\\t\\t\\t\\t\\tthis._validate(items, candidate[key]);\\n \\t\\t\\t\\t\\t\\tthis._back();\\n@@ -1011,7 +1011,7 @@\\n \\t\\t\\t}\\n \\t\\t\\telse {\\n \\t\\t\\t\\tfor (i in post) {\\n-\\t\\t\\t\\t\\tif(post.hasOwnProperty(i)){\\n+\\t\\t\\t\\t\\tif (Object.prototype.hasOwnProperty.call(post, i)) {\\n \\t\\t\\t\\t\\t\\tthis._deeperArray(i);\\n \\t\\t\\t\\t\\t\\tpost[i] = this._sanitize(schema.items, post[i]);\\n \\t\\t\\t\\t\\t\\tthis._back();\\n@@ -1430,7 +1430,7 @@\\n \\t\\t\\tvar prop = schema.properties || {};\\n \\n \\t\\t\\tfor (var key in prop) {\\n-\\t\\t\\t\\tif (prop.hasOwnProperty(key)){\\n+\\t\\t\\t\\tif (Object.prototype.hasOwnProperty.call(prop, key)) {\\n \\t\\t\\t\\t\\tif (prop[key].optional === true && _rand.bool() === true) {\\n \\t\\t\\t\\t\\t\\tcontinue;\\n \\t\\t\\t\\t\\t}\"}}",
            "message_norm":"fix: issue #75",
            "language":"fr",
            "entities":"[('#75', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/schema-inspector.js'])",
            "num_files":1.0,
            "patch_content":"From 345a7b2eed11bb6128421150d65f4f83fdbb737d Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?S=C3=A9bastien=20Chopin?= <seb@nuxtjs.com>\nDate: Mon, 20 Jan 2020 16:01:42 +0100\nSubject: [PATCH] fix: Issue #75\n\n---\n lib\/schema-inspector.js | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/lib\/schema-inspector.js b\/lib\/schema-inspector.js\nindex 2bf9d64..3113a61 100644\n--- a\/lib\/schema-inspector.js\n+++ b\/lib\/schema-inspector.js\n@@ -80,7 +80,7 @@\n \t\tthis._custom = {};\n \t\tif (custom != null) {\n \t\t\tfor (var key in custom) {\n-\t\t\t\tif (custom.hasOwnProperty(key)){\n+\t\t\t\tif (Object.prototype.hasOwnProperty.call(custom, key)) {\n \t\t\t\t\tthis._custom['$' + key] = custom[key];\n \t\t\t\t}\n \t\t\t}\n@@ -480,7 +480,7 @@\n \t\t\t}\n \t\t\telse {\n \t\t\t\tfor (var key in candidate) {\n-\t\t\t\t\tif (candidate.hasOwnProperty(key)){\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(candidate, key)) {\n \t\t\t\t\t\tthis._deeperArray(key);\n \t\t\t\t\t\tthis._validate(items, candidate[key]);\n \t\t\t\t\t\tthis._back();\n@@ -1011,7 +1011,7 @@\n \t\t\t}\n \t\t\telse {\n \t\t\t\tfor (i in post) {\n-\t\t\t\t\tif(post.hasOwnProperty(i)){\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(post, i)) {\n \t\t\t\t\t\tthis._deeperArray(i);\n \t\t\t\t\t\tpost[i] = this._sanitize(schema.items, post[i]);\n \t\t\t\t\t\tthis._back();\n@@ -1430,7 +1430,7 @@\n \t\t\tvar prop = schema.properties || {};\n \n \t\t\tfor (var key in prop) {\n-\t\t\t\tif (prop.hasOwnProperty(key)){\n+\t\t\t\tif (Object.prototype.hasOwnProperty.call(prop, key)) {\n \t\t\t\t\tif (prop[key].optional === true && _rand.bool() === true) {\n \t\t\t\t\t\tcontinue;\n \t\t\t\t\t}"
        },
        {
            "index":464,
            "vuln_id":"GHSA-pm9p-9926-w68m",
            "cwe_id":"{'CWE-20'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/jfhbrook\/node-ecstatic\/commit\/71ce93988ead4b561a8592168c72143907189f01'}",
            "dataset":"osv",
            "summary":"Denial of Service in ecstatic `ecstatic`, a simple static file server middleware, is vulnerable to denial of service. If a payload with a large number of null bytes (`%00`) is provided by an attacker it can crash ecstatic by running it out of memory.\n\n\n[Results from the original advisory](https:\/\/www.checkmarx.com\/advisories\/denial-of-service-dos-vulnerability-in-ecstatic-npm-package\/)\n\n```\nA payload of 22kB caused a lag of 1 second,\nA payload of 35kB caused a lag of 3 seconds,\nA payload of 86kB caused the server to crash\n```\n\n\n## Recommendation\n\nUpdate to version 2.0.0 or later.",
            "published_date":"2017-12-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/jfhbrook\/node-ecstatic",
            "commit_href":"https:\/\/github.com\/jfhbrook\/node-ecstatic\/commit\/71ce93988ead4b561a8592168c72143907189f01",
            "commit_sha":"71ce93988ead4b561a8592168c72143907189f01",
            "patch":"SINGLE",
            "chain_ord":"['71ce93988ead4b561a8592168c72143907189f01']",
            "before_first_fix_commit":"{'2fceb40fb9eeaaba29f5d2c3b63583fefb04a130'}",
            "last_fix_commit":"71ce93988ead4b561a8592168c72143907189f01",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/09\/2016, 16:37:39",
            "message":"Remove stripping of null bytes\n\nThis was at one point necessary because of an old bug in url.parse\n\nSee: https:\/\/github.com\/jfhbrook\/node-ecstatic\/issues\/16#issuecomment-3039914\nSee: https:\/\/github.com\/jfhbrook\/node-ecstatic\/commit\/43f7e72a31524f88f47e367c3cc3af710e67c9f4\n\nBut this opens up a regex dos attack vector! D:\n\nBased on some research (ie asking #node-dev if this is still an issue),\nit's *probably* not an issue. :)",
            "author":"Joshua Holbrook",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'lib\/ecstatic.js': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jfhbrook\/node-ecstatic\/raw\/71ce93988ead4b561a8592168c72143907189f01\/lib%2Fecstatic.js', 'patch': \"@@ -52,9 +52,21 @@ var ecstatic = module.exports = function (dir, options) {\\n   return function middleware (req, res, next) {\\n \\n     \/\/ Strip any null bytes from the url\\n+    \/\/ This was at one point necessary because of an old bug in url.parse\\n+    \/\/\\n+    \/\/ See: https:\/\/github.com\/jfhbrook\/node-ecstatic\/issues\/16#issuecomment-3039914\\n+    \/\/ See: https:\/\/github.com\/jfhbrook\/node-ecstatic\/commit\/43f7e72a31524f88f47e367c3cc3af710e67c9f4\\n+    \/\/\\n+    \/\/ But this opens up a regex dos attack vector! D:\\n+    \/\/\\n+    \/\/ Based on some research (ie asking #node-dev if this is still an issue),\\n+    \/\/ it's *probably* not an issue. :)\\n+    \/*\\n     while(req.url.indexOf('%00') !== -1) {\\n       req.url = req.url.replace(\/\\\\%00\/g, '');\\n     }\\n+    *\/\\n+\\n     \/\/ Figure out the path for the file from the given url\\n     var parsed = url.parse(req.url);\\n     try {\"}}",
            "message_norm":"remove stripping of null bytes\n\nthis was at one point necessary because of an old bug in url.parse\n\nsee: https:\/\/github.com\/jfhbrook\/node-ecstatic\/issues\/16#issuecomment-3039914\nsee: https:\/\/github.com\/jfhbrook\/node-ecstatic\/commit\/43f7e72a31524f88f47e367c3cc3af710e67c9f4\n\nbut this opens up a regex dos attack vector! d:\n\nbased on some research (ie asking #node-dev if this is still an issue),\nit's *probably* not an issue. :)",
            "language":"en",
            "entities":"[('remove', 'ACTION', ''), ('bug', 'FLAW', ''), ('https:\/\/github.com\/jfhbrook\/node-ecstatic\/issues\/16#issuecomment-3039914', 'FLAW', ''), ('https:\/\/github.com\/jfhbrook\/node-ecstatic\/commit\/43f7e72a31524f88f47e367c3cc3af710e67c9f4', 'SHA', 'github_url_sha'), ('dos', 'SECWORD', ''), ('attack vector', 'SECWORD', ''), ('issue', 'FLAW', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/ecstatic.js'])",
            "num_files":1.0,
            "patch_content":"From 71ce93988ead4b561a8592168c72143907189f01 Mon Sep 17 00:00:00 2001\nFrom: Joshua Holbrook <josh.holbrook@gmail.com>\nDate: Tue, 9 Aug 2016 12:37:39 -0400\nSubject: [PATCH] Remove stripping of null bytes\n\nThis was at one point necessary because of an old bug in url.parse\n\nSee: https:\/\/github.com\/jfhbrook\/node-ecstatic\/issues\/16#issuecomment-3039914\nSee: https:\/\/github.com\/jfhbrook\/node-ecstatic\/commit\/43f7e72a31524f88f47e367c3cc3af710e67c9f4\n\nBut this opens up a regex dos attack vector! D:\n\nBased on some research (ie asking #node-dev if this is still an issue),\nit's *probably* not an issue. :)\n---\n lib\/ecstatic.js | 12 ++++++++++++\n 1 file changed, 12 insertions(+)\n\ndiff --git a\/lib\/ecstatic.js b\/lib\/ecstatic.js\nindex 115de99..efc333e 100755\n--- a\/lib\/ecstatic.js\n+++ b\/lib\/ecstatic.js\n@@ -52,9 +52,21 @@ var ecstatic = module.exports = function (dir, options) {\n   return function middleware (req, res, next) {\n \n     \/\/ Strip any null bytes from the url\n+    \/\/ This was at one point necessary because of an old bug in url.parse\n+    \/\/\n+    \/\/ See: https:\/\/github.com\/jfhbrook\/node-ecstatic\/issues\/16#issuecomment-3039914\n+    \/\/ See: https:\/\/github.com\/jfhbrook\/node-ecstatic\/commit\/43f7e72a31524f88f47e367c3cc3af710e67c9f4\n+    \/\/\n+    \/\/ But this opens up a regex dos attack vector! D:\n+    \/\/\n+    \/\/ Based on some research (ie asking #node-dev if this is still an issue),\n+    \/\/ it's *probably* not an issue. :)\n+    \/*\n     while(req.url.indexOf('%00') !== -1) {\n       req.url = req.url.replace(\/\\%00\/g, '');\n     }\n+    *\/\n+\n     \/\/ Figure out the path for the file from the given url\n     var parsed = url.parse(req.url);\n     try {"
        },
        {
            "index":815,
            "vuln_id":"GHSA-fq6p-x6j3-cmmq",
            "cwe_id":"{'CWE-400'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/mrdoob\/three.js\/pull\/21143\/commits\/4a582355216b620176a291ff319d740e619d583e'}",
            "dataset":"osv",
            "summary":"Denial of service in three This affects the package three before 0.125.0. This can happen when handling rgb or hsl colors. PoC: var three = require('three') function build_blank (n) { var ret = \"rgb(\" for (var i = 0; i < n; i++) { ret += \" \" } return ret + \"\"; } var Color = three.Color var time = Date.now(); new Color(build_blank(50000)) var time_cost = Date.now() - time; console.log(time_cost+\" ms\")",
            "published_date":"2021-03-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/mrdoob\/three.js",
            "commit_href":"https:\/\/github.com\/mrdoob\/three.js\/pull\/21143\/commits\/4a582355216b620176a291ff319d740e619d583e",
            "commit_sha":"4a582355216b620176a291ff319d740e619d583e",
            "patch":"SINGLE",
            "chain_ord":"['4a582355216b620176a291ff319d740e619d583e']",
            "before_first_fix_commit":"{'0f5de4f5da1014f81c00d309f93b1a1e709341e4'}",
            "last_fix_commit":"4a582355216b620176a291ff319d740e619d583e",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/25\/2021, 11:45:42",
            "message":"Fix ReDoS",
            "author":"Yeting Li",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'src\/math\/Color.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mrdoob\/three.js\/raw\/4a582355216b620176a291ff319d740e619d583e\/src%2Fmath%2FColor.js', 'patch': \"@@ -169,14 +169,14 @@ class Color {\\n \\n \\t\\t\\tlet color;\\n \\t\\t\\tconst name = m[ 1 ];\\n-\\t\\t\\tconst components = m[ 2 ].replace(\/^\\\\s*\/, '');\\n+\\t\\t\\tconst components = m[ 2 ];\\n \\n \\t\\t\\tswitch ( name ) {\\n \\n \\t\\t\\t\\tcase 'rgb':\\n \\t\\t\\t\\tcase 'rgba':\\n \\n-\\t\\t\\t\\t\\tif ( color = \/^(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = \/^\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t\/\/ rgb(255,0,0) rgba(255,0,0,0.5)\\n \\t\\t\\t\\t\\t\\tthis.r = Math.min( 255, parseInt( color[ 1 ], 10 ) ) \/ 255;\\n@@ -189,7 +189,7 @@ class Color {\\n \\n \\t\\t\\t\\t\\t}\\n \\n-\\t\\t\\t\\t\\tif ( color = \/^(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = \/^\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t\/\/ rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\\n \\t\\t\\t\\t\\t\\tthis.r = Math.min( 100, parseInt( color[ 1 ], 10 ) ) \/ 100;\\n@@ -207,7 +207,7 @@ class Color {\\n \\t\\t\\t\\tcase 'hsl':\\n \\t\\t\\t\\tcase 'hsla':\\n \\n-\\t\\t\\t\\t\\tif ( color = \/^(\\\\d*\\\\.?\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = \/^\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t\/\/ hsl(120,50%,50%) hsla(120,50%,50%,0.5)\\n \\t\\t\\t\\t\\t\\tconst h = parseFloat( color[ 1 ] ) \/ 360;\"}}",
            "message_norm":"fix redos",
            "language":"pt",
            "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/math\/Color.js'])",
            "num_files":1.0,
            "patch_content":"From 4a582355216b620176a291ff319d740e619d583e Mon Sep 17 00:00:00 2001\nFrom: Yeting Li <liyt@ios.ac.cn>\nDate: Mon, 25 Jan 2021 19:45:42 +0800\nSubject: [PATCH] Fix ReDoS\n\n---\n src\/math\/Color.js | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/math\/Color.js b\/src\/math\/Color.js\nindex 7bc9a11405157b..f2ea4f82edac0b 100644\n--- a\/src\/math\/Color.js\n+++ b\/src\/math\/Color.js\n@@ -169,14 +169,14 @@ class Color {\n \n \t\t\tlet color;\n \t\t\tconst name = m[ 1 ];\n-\t\t\tconst components = m[ 2 ].replace(\/^\\s*\/, '');\n+\t\t\tconst components = m[ 2 ];\n \n \t\t\tswitch ( name ) {\n \n \t\t\t\tcase 'rgb':\n \t\t\t\tcase 'rgba':\n \n-\t\t\t\t\tif ( color = \/^(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ rgb(255,0,0) rgba(255,0,0,0.5)\n \t\t\t\t\t\tthis.r = Math.min( 255, parseInt( color[ 1 ], 10 ) ) \/ 255;\n@@ -189,7 +189,7 @@ class Color {\n \n \t\t\t\t\t}\n \n-\t\t\t\t\tif ( color = \/^(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\n \t\t\t\t\t\tthis.r = Math.min( 100, parseInt( color[ 1 ], 10 ) ) \/ 100;\n@@ -207,7 +207,7 @@ class Color {\n \t\t\t\tcase 'hsl':\n \t\t\t\tcase 'hsla':\n \n-\t\t\t\t\tif ( color = \/^(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ hsl(120,50%,50%) hsla(120,50%,50%,0.5)\n \t\t\t\t\t\tconst h = parseFloat( color[ 1 ] ) \/ 360;"
        },
        {
            "index":929,
            "vuln_id":"GHSA-c5hf-mc85-2hx4",
            "cwe_id":"{'CWE-863'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/moodle\/moodle\/commit\/cdc78a16a5da95a17fb10bf1c66689237f5a3f7d'}",
            "dataset":"osv",
            "summary":"Missing authorization in Moodle Users with the capability to configure badge criteria (teachers and managers by default) were able to configure course badges with profile field criteria, which should only be available for site badges.",
            "published_date":"2022-04-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/moodle\/moodle",
            "commit_href":"https:\/\/github.com\/moodle\/moodle\/commit\/cdc78a16a5da95a17fb10bf1c66689237f5a3f7d",
            "commit_sha":"cdc78a16a5da95a17fb10bf1c66689237f5a3f7d",
            "patch":"SINGLE",
            "chain_ord":"['cdc78a16a5da95a17fb10bf1c66689237f5a3f7d']",
            "before_first_fix_commit":"{'4c00836de97bea26a0c5ba6068a55a8c1b16f260'}",
            "last_fix_commit":"cdc78a16a5da95a17fb10bf1c66689237f5a3f7d",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/07\/2022, 12:39:16",
            "message":"MDL-74075 core_badges: Check accepted criterias",
            "author":"Amaia Anabitarte",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'badges\/criteria_settings.php': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/moodle\/moodle\/raw\/cdc78a16a5da95a17fb10bf1c66689237f5a3f7d\/badges%2Fcriteria_settings.php', 'patch': \"@@ -55,6 +55,12 @@\\n     redirect($return);\\n }\\n \\n+\/\/ Make sure the criteria type is accepted.\\n+$accepted = $badge->get_accepted_criteria();\\n+if (!in_array($type, $accepted)) {\\n+    redirect($return);\\n+}\\n+\\n if ($badge->type == BADGE_TYPE_COURSE) {\\n     require_login($badge->courseid);\\n     $navurl = new moodle_url('\/badges\/index.php', array('type' => $badge->type, 'id' => $badge->courseid));\"}}",
            "message_norm":"mdl-74075 core_badges: check accepted criterias",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['badges\/criteria_settings.php'])",
            "num_files":1.0,
            "patch_content":"From cdc78a16a5da95a17fb10bf1c66689237f5a3f7d Mon Sep 17 00:00:00 2001\nFrom: Amaia Anabitarte <amaia@moodle.com>\nDate: Mon, 7 Mar 2022 13:39:16 +0100\nSubject: [PATCH] MDL-74075 core_badges: Check accepted criterias\n\n---\n badges\/criteria_settings.php | 6 ++++++\n 1 file changed, 6 insertions(+)\n\ndiff --git a\/badges\/criteria_settings.php b\/badges\/criteria_settings.php\nindex cd2cb213b975f..46dcd168ab2c8 100644\n--- a\/badges\/criteria_settings.php\n+++ b\/badges\/criteria_settings.php\n@@ -55,6 +55,12 @@\n     redirect($return);\n }\n \n+\/\/ Make sure the criteria type is accepted.\n+$accepted = $badge->get_accepted_criteria();\n+if (!in_array($type, $accepted)) {\n+    redirect($return);\n+}\n+\n if ($badge->type == BADGE_TYPE_COURSE) {\n     require_login($badge->courseid);\n     $navurl = new moodle_url('\/badges\/index.php', array('type' => $badge->type, 'id' => $badge->courseid));"
        },
        {
            "index":599,
            "vuln_id":"GHSA-7f53-fmmv-mfjv",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/facebook\/react-native\/commit\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7'}",
            "dataset":"osv",
            "summary":"Regular expression denial of service in react-native A regular expression denial of service (ReDoS) vulnerability in the validateBaseUrl function can cause the application to use excessive resources, become unresponsive, or crash. This was introduced in react-native version 0.59.0 and fixed in version 0.64.1.",
            "published_date":"2021-07-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/facebook\/react-native",
            "commit_href":"https:\/\/github.com\/facebook\/react-native\/commit\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
            "commit_sha":"ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
            "patch":"SINGLE",
            "chain_ord":"['ca09ae82715e33c9ac77b3fa55495cf84ba891c7']",
            "before_first_fix_commit":"{'166a5ddf88aca0d0235e48c624681eec095e9ef8'}",
            "last_fix_commit":"ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/29\/2021, 21:51:29",
            "message":"Update validateBaseUrl to use latest regex\n\nSummary:\nUpdating the regex to avoid a potential regular expression denial-of-service vulnerability.\n\nChangelog: Update validateBaseUrl to use a more robust regular expression. Fixes CVE-2020-1920, GHSL-2020-293\n\nReviewed By: lunaleaps\n\nDifferential Revision: D25507604\n\nfbshipit-source-id: c36a03c456881bc655c861e1a2c5cd41a7127c9d",
            "author":"Neal Poole",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'Libraries\/Blob\/URL.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/facebook\/react-native\/raw\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7\/Libraries%2FBlob%2FURL.js', 'patch': '@@ -107,7 +107,7 @@ export class URLSearchParams {\\n \\n function validateBaseUrl(url: string) {\\n   \/\/ from this MIT-licensed gist: https:\/\/gist.github.com\/dperini\/729294\\n-  return \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)*(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,}))?)(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i.test(\\n+  return \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z0-9\\\\u00a1-\\\\uffff][a-z0-9\\\\u00a1-\\\\uffff_-]{0,62})?[a-z0-9\\\\u00a1-\\\\uffff]\\\\.)*(?:[a-z\\\\u00a1-\\\\uffff]{2,}\\\\.?))(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/.test(\\n     url,\\n   );\\n }'}}",
            "message_norm":"update validatebaseurl to use latest regex\n\nsummary:\nupdating the regex to avoid a potential regular expression denial-of-service vulnerability.\n\nchangelog: update validatebaseurl to use a more robust regular expression. fixes cve-2020-1920, ghsl-2020-293\n\nreviewed by: lunaleaps\n\ndifferential revision: d25507604\n\nfbshipit-source-id: c36a03c456881bc655c861e1a2c5cd41a7127c9d",
            "language":"en",
            "entities":"[('update', 'ACTION', ''), ('updating', 'ACTION', ''), ('denial-of-service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('update', 'ACTION', ''), ('cve-2020-1920', 'VULNID', 'CVE'), ('d25507604', 'SHA', 'generic_sha'), ('c36a03c456881bc655c861e1a2c5cd41a7127c9d', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Libraries\/Blob\/URL.js'])",
            "num_files":1.0,
            "patch_content":"From ca09ae82715e33c9ac77b3fa55495cf84ba891c7 Mon Sep 17 00:00:00 2001\nFrom: Neal Poole <neal@fb.com>\nDate: Thu, 29 Apr 2021 14:51:29 -0700\nSubject: [PATCH] Update validateBaseUrl to use latest regex\n\nSummary:\nUpdating the regex to avoid a potential regular expression denial-of-service vulnerability.\n\nChangelog: Update validateBaseUrl to use a more robust regular expression. Fixes CVE-2020-1920, GHSL-2020-293\n\nReviewed By: lunaleaps\n\nDifferential Revision: D25507604\n\nfbshipit-source-id: c36a03c456881bc655c861e1a2c5cd41a7127c9d\n---\n Libraries\/Blob\/URL.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/Libraries\/Blob\/URL.js b\/Libraries\/Blob\/URL.js\nindex f2b6f7f277cb7e..df186f36de1ac4 100644\n--- a\/Libraries\/Blob\/URL.js\n+++ b\/Libraries\/Blob\/URL.js\n@@ -107,7 +107,7 @@ export class URLSearchParams {\n \n function validateBaseUrl(url: string) {\n   \/\/ from this MIT-licensed gist: https:\/\/gist.github.com\/dperini\/729294\n-  return \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*(?:\\.(?:[a-z\\u00a1-\\uffff]{2,}))?)(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test(\n+  return \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z0-9\\u00a1-\\uffff][a-z0-9\\u00a1-\\uffff_-]{0,62})?[a-z0-9\\u00a1-\\uffff]\\.)*(?:[a-z\\u00a1-\\uffff]{2,}\\.?))(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/.test(\n     url,\n   );\n }"
        },
        {
            "index":902,
            "vuln_id":"GHSA-29vr-79w7-p649",
            "cwe_id":"{'CWE-863'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/Gerapy\/Gerapy\/commit\/49bcb19be5e0320e7e1535f34fe00f16a3cf3b28'}",
            "dataset":"osv",
            "summary":"Incorrect Authorization in Gerapy An Access Control vunerabiity exists in Gerapy v 0.9.7 via the spider parameter in project_configure function.",
            "published_date":"2022-03-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/Gerapy\/Gerapy",
            "commit_href":"https:\/\/github.com\/Gerapy\/Gerapy\/commit\/49bcb19be5e0320e7e1535f34fe00f16a3cf3b28",
            "commit_sha":"49bcb19be5e0320e7e1535f34fe00f16a3cf3b28",
            "patch":"SINGLE",
            "chain_ord":"['49bcb19be5e0320e7e1535f34fe00f16a3cf3b28']",
            "before_first_fix_commit":"{'f1cd46d80328497c016fbac12c9239b9dcaef047'}",
            "last_fix_commit":"49bcb19be5e0320e7e1535f34fe00f16a3cf3b28",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/26\/2021, 09:50:00",
            "message":"fix remote execute",
            "author":"Germey",
            "comments":null,
            "stats":"{'additions': 56, 'deletions': 40, 'total': 96}",
            "files":"{'gerapy\/server\/core\/views.py': {'additions': 56, 'deletions': 40, 'changes': 96, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Gerapy\/Gerapy\/raw\/49bcb19be5e0320e7e1535f34fe00f16a3cf3b28\/gerapy%2Fserver%2Fcore%2Fviews.py', 'patch': '@@ -2,7 +2,12 @@\\n from pathlib import Path\\n from urllib.parse import unquote\\n import base64\\n-import json, os, requests, time, pytz, pymongo\\n+import json\\n+import os\\n+import requests\\n+import time\\n+import pytz\\n+import pymongo\\n from shutil import rmtree\\n from requests.exceptions import ConnectionError\\n from os.path import join, exists\\n@@ -173,7 +178,8 @@ def spider_list(request, client_id, project_name):\\n         client = Client.objects.get(id=client_id)\\n         scrapyd = get_scrapyd(client)\\n         spiders = scrapyd.list_spiders(project_name)\\n-        spiders = [{\\'name\\': spider, \\'id\\': index + 1} for index, spider in enumerate(spiders)]\\n+        spiders = [{\\'name\\': spider, \\'id\\': index + 1}\\n+                   for index, spider in enumerate(spiders)]\\n         return JsonResponse(spiders)\\n \\n \\n@@ -242,23 +248,25 @@ def project_configure(request, project_name):\\n     if request.method == \\'GET\\':\\n         project = Project.objects.get(name=project_name)\\n         project = model_to_dict(project)\\n-        project[\\'configuration\\'] = json.loads(project[\\'configuration\\']) if project[\\'configuration\\'] else None\\n+        project[\\'configuration\\'] = json.loads(\\n+            project[\\'configuration\\']) if project[\\'configuration\\'] else None\\n         return JsonResponse(project)\\n-    \\n+\\n     # update configuration\\n     elif request.method == \\'POST\\':\\n         project = Project.objects.filter(name=project_name)\\n         data = json.loads(request.body)\\n-        configuration = json.dumps(data.get(\\'configuration\\'), ensure_ascii=False)\\n+        configuration = json.dumps(\\n+            data.get(\\'configuration\\'), ensure_ascii=False)\\n         project.update(**{\\'configuration\\': configuration})\\n-        \\n         # for safe protection\\n-        project_name = re.sub(\\'[\\\\!\\\\@\\\\#\\\\$\\\\;\\\\&\\\\*\\\\~\\\\\"\\\\\\'\\\\{\\\\}\\\\]\\\\[\\\\-\\\\+\\\\%\\\\^]+\\', \\'\\', project_name)\\n+        project_name = re.sub(\\n+            \\'[\\\\s\\\\!\\\\@\\\\#\\\\$\\\\;\\\\&\\\\*\\\\~\\\\\"\\\\\\'\\\\{\\\\}\\\\]\\\\[\\\\-\\\\+\\\\%\\\\^]+\\', \\'\\', project_name)\\n         # execute generate cmd\\n-        cmd = \\' \\'.join([\\'gerapy\\', \\'generate\\', project_name])\\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n+        cmd = [\\'gerapy\\', \\'generate\\', project_name]\\n+        p = Popen(cmd, shell=False, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\\n-        \\n+\\n         if not stderr:\\n             return JsonResponse({\\'status\\': \\'1\\'})\\n         else:\\n@@ -294,7 +302,8 @@ def project_create(request):\\n         data[\\'configurable\\'] = 1\\n         project, result = Project.objects.update_or_create(**data)\\n         # generate a single project folder\\n-        path = join(os.path.abspath(join(os.getcwd(), PROJECTS_FOLDER)), data[\\'name\\'])\\n+        path = join(os.path.abspath(\\n+            join(os.getcwd(), PROJECTS_FOLDER)), data[\\'name\\'])\\n         os.mkdir(path)\\n         return JsonResponse(model_to_dict(project))\\n \\n@@ -334,12 +343,13 @@ def project_clone(request):\\n         if not address.startswith(\\'http\\'):\\n             return JsonResponse({\\'status\\': False})\\n         address = address + \\'.git\\' if not address.endswith(\\'.git\\') else address\\n-        cmd = \\'git clone {address} {target}\\'.format(address=address, target=join(PROJECTS_FOLDER, Path(address).stem))\\n+        cmd = [\\'git\\', \\'clone\\', \\'address\\', join(PROJECTS_FOLDER, Path(address).stem)]\\n         logger.debug(\\'clone cmd %s\\', cmd)\\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n+        p = Popen(cmd, shell=False, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\\n         logger.debug(\\'clone run result %s\\', stdout)\\n-        if stderr: logger.error(stderr)\\n+        if stderr:\\n+            logger.error(stderr)\\n         return JsonResponse({\\'status\\': True}) if not stderr else JsonResponse({\\'status\\': False})\\n \\n \\n@@ -393,10 +403,12 @@ def project_version(request, client_id, project_name):\\n                 return JsonResponse({\\'message\\': \\'Connect Error\\'}, status=500)\\n             if len(versions) > 0:\\n                 version = versions[-1]\\n-                deployed_at = timezone.datetime.fromtimestamp(int(version), tz=pytz.timezone(TIME_ZONE))\\n+                deployed_at = timezone.datetime.fromtimestamp(\\n+                    int(version), tz=pytz.timezone(TIME_ZONE))\\n             else:\\n                 deployed_at = None\\n-            deploy, result = Deploy.objects.update_or_create(client=client, project=project, deployed_at=deployed_at)\\n+            deploy, result = Deploy.objects.update_or_create(\\n+                client=client, project=project, deployed_at=deployed_at)\\n         # return deploy json info\\n         return JsonResponse(model_to_dict(deploy))\\n \\n@@ -446,7 +458,7 @@ def project_build(request, project_name):\\n     # get project folder\\n     path = os.path.abspath(join(os.getcwd(), PROJECTS_FOLDER))\\n     project_path = join(path, project_name)\\n-    \\n+\\n     # get build version\\n     if request.method == \\'GET\\':\\n         egg = find_egg(project_path)\\n@@ -470,7 +482,7 @@ def project_build(request, project_name):\\n         # transfer model to dict then dumps it to json\\n         data = model_to_dict(model)\\n         return JsonResponse(data)\\n-    \\n+\\n     # build operation manually by clicking button\\n     elif request.method == \\'POST\\':\\n         data = json.loads(request.body)\\n@@ -483,7 +495,8 @@ def project_build(request, project_name):\\n         built_at = timezone.now()\\n         # if project does not exists in db, create it\\n         if not Project.objects.filter(name=project_name):\\n-            Project(name=project_name, description=description, built_at=built_at, egg=egg).save()\\n+            Project(name=project_name, description=description,\\n+                    built_at=built_at, egg=egg).save()\\n             model = Project.objects.get(name=project_name)\\n         # if project exists, update egg, description, built_at info\\n         else:\\n@@ -526,17 +539,16 @@ def project_parse(request, project_name):\\n         body = data.get(\\'body\\', \\'\\')\\n         if args.get(\\'method\\').lower() != \\'get\\':\\n             args[\\'body\\'] = \"\\'\" + json.dumps(body, ensure_ascii=False) + \"\\'\"\\n-        \\n-        args_cmd = \\' \\'.join(\\n-            [\\'--{arg} {value}\\'.format(arg=arg, value=value) for arg, value in args.items()])\\n-        logger.debug(\\'args cmd %s\\', args_cmd)\\n-        cmd = \\'gerapy parse {args_cmd} {project_path} {spider_name}\\'.format(\\n-            args_cmd=args_cmd,\\n-            project_path=project_path,\\n-            spider_name=spider_name\\n-        )\\n+\\n+        args_array = []\\n+        for arg, value in args.items():\\n+            args_array.append(f\\'--{arg}\\')\\n+            args_array.append(f\\'{value}\\')\\n+        cmd = [\\'gerapy\\', \\'parse\\'] + args_array + [project_path] + [spider_name]\\n+        print(\\'cmd\\', cmd)\\n         logger.debug(\\'parse cmd %s\\', cmd)\\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)\\n+        p = Popen(cmd, shell=False, stdin=PIPE,\\n+                         stdout=PIPE, stderr=PIPE, close_fds=True)\\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\\n         logger.debug(\\'stdout %s, stderr %s\\', stdout, stderr)\\n         if not stderr:\\n@@ -645,7 +657,6 @@ def job_list(request, client_id, project_name):\\n                 job[\\'status\\'] = status\\n                 jobs.append(job)\\n         return JsonResponse(jobs)\\n-    \\n \\n \\n @api_view([\\'GET\\'])\\n@@ -663,7 +674,8 @@ def job_log(request, client_id, project_name, spider_name, job_id):\\n     if request.method == \\'GET\\':\\n         client = Client.objects.get(id=client_id)\\n         # get log url\\n-        url = log_url(client.ip, client.port, project_name, spider_name, job_id)\\n+        url = log_url(client.ip, client.port,\\n+                      project_name, spider_name, job_id)\\n         # get last 1000 bytes of log\\n         response = requests.get(url, timeout=5, headers={\\n             \\'Range\\': \\'bytes=-1000\\'\\n@@ -765,7 +777,8 @@ def monitor_create(request):\\n     if request.method == \\'POST\\':\\n         data = json.loads(request.body)\\n         data = data[\\'form\\']\\n-        data[\\'configuration\\'] = json.dumps(data[\\'configuration\\'], ensure_ascii=False)\\n+        data[\\'configuration\\'] = json.dumps(\\n+            data[\\'configuration\\'], ensure_ascii=False)\\n         monitor = Monitor.objects.create(**data)\\n         return JsonResponse(model_to_dict(monitor))\\n \\n@@ -785,7 +798,8 @@ def task_create(request):\\n                                    name=data.get(\\'name\\'),\\n                                    spider=data.get(\\'spider\\'),\\n                                    trigger=data.get(\\'trigger\\'),\\n-                                   configuration=json.dumps(data.get(\\'configuration\\'), ensure_ascii=False),\\n+                                   configuration=json.dumps(\\n+                                       data.get(\\'configuration\\'), ensure_ascii=False),\\n                                    modified=1)\\n         return JsonResponse({\\'result\\': \\'1\\', \\'data\\': model_to_dict(task)})\\n \\n@@ -803,7 +817,8 @@ def task_update(request, task_id):\\n         task = Task.objects.filter(id=task_id)\\n         data = json.loads(request.body)\\n         data[\\'clients\\'] = json.dumps(data.get(\\'clients\\'), ensure_ascii=False)\\n-        data[\\'configuration\\'] = json.dumps(data.get(\\'configuration\\'), ensure_ascii=False)\\n+        data[\\'configuration\\'] = json.dumps(\\n+            data.get(\\'configuration\\'), ensure_ascii=False)\\n         data[\\'modified\\'] = 1\\n         task.update(**data)\\n         return JsonResponse(model_to_dict(Task.objects.get(id=task_id)))\\n@@ -823,11 +838,10 @@ def task_remove(request, task_id):\\n         clients = clients_of_task(task)\\n         for client in clients:\\n             job_id = get_job_id(client, task)\\n-            DjangoJob.objects.filter(name=job_id).delete()\\n+            DjangoJob.objects.filter(id=job_id).delete()\\n         # delete task\\n         Task.objects.filter(id=task_id).delete()\\n         return JsonResponse({\\'result\\': \\'1\\'})\\n-    \\n \\n \\n @api_view([\\'GET\\'])\\n@@ -875,12 +889,14 @@ def task_status(request, task_id):\\n         clients = clients_of_task(task)\\n         for client in clients:\\n             job_id = get_job_id(client, task)\\n-            jobs = DjangoJob.objects.filter(name=job_id)\\n+            jobs = DjangoJob.objects.filter(id=job_id)\\n             logger.debug(\\'jobs from djangojob %s\\', jobs)\\n             # if job does not exist, for date mode exceed time\\n-            if not jobs: continue\\n-            job = DjangoJob.objects.get(name=job_id)\\n-            executions = serialize(\\'json\\', DjangoJobExecution.objects.filter(job=job))\\n+            if not jobs:\\n+                continue\\n+            job = DjangoJob.objects.get(id=job_id)\\n+            executions = serialize(\\n+                \\'json\\', DjangoJobExecution.objects.filter(job=job))\\n             result.append({\\n                 \\'client\\': model_to_dict(client),\\n                 \\'next\\': job.next_run_time,'}}",
            "message_norm":"fix remote execute",
            "language":"ro",
            "entities":"[('fix', 'ACTION', ''), ('remote execute', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['gerapy\/server\/core\/views.py'])",
            "num_files":1.0,
            "patch_content":"From 49bcb19be5e0320e7e1535f34fe00f16a3cf3b28 Mon Sep 17 00:00:00 2001\nFrom: Germey <cqc@cuiqingcai.com>\nDate: Sun, 26 Dec 2021 17:50:00 +0800\nSubject: [PATCH] fix remote execute\n\n---\n gerapy\/server\/core\/views.py | 96 +++++++++++++++++++++----------------\n 1 file changed, 56 insertions(+), 40 deletions(-)\n\ndiff --git a\/gerapy\/server\/core\/views.py b\/gerapy\/server\/core\/views.py\nindex bcbddea4..3404f574 100755\n--- a\/gerapy\/server\/core\/views.py\n+++ b\/gerapy\/server\/core\/views.py\n@@ -2,7 +2,12 @@\n from pathlib import Path\n from urllib.parse import unquote\n import base64\n-import json, os, requests, time, pytz, pymongo\n+import json\n+import os\n+import requests\n+import time\n+import pytz\n+import pymongo\n from shutil import rmtree\n from requests.exceptions import ConnectionError\n from os.path import join, exists\n@@ -173,7 +178,8 @@ def spider_list(request, client_id, project_name):\n         client = Client.objects.get(id=client_id)\n         scrapyd = get_scrapyd(client)\n         spiders = scrapyd.list_spiders(project_name)\n-        spiders = [{'name': spider, 'id': index + 1} for index, spider in enumerate(spiders)]\n+        spiders = [{'name': spider, 'id': index + 1}\n+                   for index, spider in enumerate(spiders)]\n         return JsonResponse(spiders)\n \n \n@@ -242,23 +248,25 @@ def project_configure(request, project_name):\n     if request.method == 'GET':\n         project = Project.objects.get(name=project_name)\n         project = model_to_dict(project)\n-        project['configuration'] = json.loads(project['configuration']) if project['configuration'] else None\n+        project['configuration'] = json.loads(\n+            project['configuration']) if project['configuration'] else None\n         return JsonResponse(project)\n-    \n+\n     # update configuration\n     elif request.method == 'POST':\n         project = Project.objects.filter(name=project_name)\n         data = json.loads(request.body)\n-        configuration = json.dumps(data.get('configuration'), ensure_ascii=False)\n+        configuration = json.dumps(\n+            data.get('configuration'), ensure_ascii=False)\n         project.update(**{'configuration': configuration})\n-        \n         # for safe protection\n-        project_name = re.sub('[\\!\\@\\#\\$\\;\\&\\*\\~\\\"\\'\\{\\}\\]\\[\\-\\+\\%\\^]+', '', project_name)\n+        project_name = re.sub(\n+            '[\\s\\!\\@\\#\\$\\;\\&\\*\\~\\\"\\'\\{\\}\\]\\[\\-\\+\\%\\^]+', '', project_name)\n         # execute generate cmd\n-        cmd = ' '.join(['gerapy', 'generate', project_name])\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n+        cmd = ['gerapy', 'generate', project_name]\n+        p = Popen(cmd, shell=False, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\n-        \n+\n         if not stderr:\n             return JsonResponse({'status': '1'})\n         else:\n@@ -294,7 +302,8 @@ def project_create(request):\n         data['configurable'] = 1\n         project, result = Project.objects.update_or_create(**data)\n         # generate a single project folder\n-        path = join(os.path.abspath(join(os.getcwd(), PROJECTS_FOLDER)), data['name'])\n+        path = join(os.path.abspath(\n+            join(os.getcwd(), PROJECTS_FOLDER)), data['name'])\n         os.mkdir(path)\n         return JsonResponse(model_to_dict(project))\n \n@@ -334,12 +343,13 @@ def project_clone(request):\n         if not address.startswith('http'):\n             return JsonResponse({'status': False})\n         address = address + '.git' if not address.endswith('.git') else address\n-        cmd = 'git clone {address} {target}'.format(address=address, target=join(PROJECTS_FOLDER, Path(address).stem))\n+        cmd = ['git', 'clone', 'address', join(PROJECTS_FOLDER, Path(address).stem)]\n         logger.debug('clone cmd %s', cmd)\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n+        p = Popen(cmd, shell=False, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\n         logger.debug('clone run result %s', stdout)\n-        if stderr: logger.error(stderr)\n+        if stderr:\n+            logger.error(stderr)\n         return JsonResponse({'status': True}) if not stderr else JsonResponse({'status': False})\n \n \n@@ -393,10 +403,12 @@ def project_version(request, client_id, project_name):\n                 return JsonResponse({'message': 'Connect Error'}, status=500)\n             if len(versions) > 0:\n                 version = versions[-1]\n-                deployed_at = timezone.datetime.fromtimestamp(int(version), tz=pytz.timezone(TIME_ZONE))\n+                deployed_at = timezone.datetime.fromtimestamp(\n+                    int(version), tz=pytz.timezone(TIME_ZONE))\n             else:\n                 deployed_at = None\n-            deploy, result = Deploy.objects.update_or_create(client=client, project=project, deployed_at=deployed_at)\n+            deploy, result = Deploy.objects.update_or_create(\n+                client=client, project=project, deployed_at=deployed_at)\n         # return deploy json info\n         return JsonResponse(model_to_dict(deploy))\n \n@@ -446,7 +458,7 @@ def project_build(request, project_name):\n     # get project folder\n     path = os.path.abspath(join(os.getcwd(), PROJECTS_FOLDER))\n     project_path = join(path, project_name)\n-    \n+\n     # get build version\n     if request.method == 'GET':\n         egg = find_egg(project_path)\n@@ -470,7 +482,7 @@ def project_build(request, project_name):\n         # transfer model to dict then dumps it to json\n         data = model_to_dict(model)\n         return JsonResponse(data)\n-    \n+\n     # build operation manually by clicking button\n     elif request.method == 'POST':\n         data = json.loads(request.body)\n@@ -483,7 +495,8 @@ def project_build(request, project_name):\n         built_at = timezone.now()\n         # if project does not exists in db, create it\n         if not Project.objects.filter(name=project_name):\n-            Project(name=project_name, description=description, built_at=built_at, egg=egg).save()\n+            Project(name=project_name, description=description,\n+                    built_at=built_at, egg=egg).save()\n             model = Project.objects.get(name=project_name)\n         # if project exists, update egg, description, built_at info\n         else:\n@@ -526,17 +539,16 @@ def project_parse(request, project_name):\n         body = data.get('body', '')\n         if args.get('method').lower() != 'get':\n             args['body'] = \"'\" + json.dumps(body, ensure_ascii=False) + \"'\"\n-        \n-        args_cmd = ' '.join(\n-            ['--{arg} {value}'.format(arg=arg, value=value) for arg, value in args.items()])\n-        logger.debug('args cmd %s', args_cmd)\n-        cmd = 'gerapy parse {args_cmd} {project_path} {spider_name}'.format(\n-            args_cmd=args_cmd,\n-            project_path=project_path,\n-            spider_name=spider_name\n-        )\n+\n+        args_array = []\n+        for arg, value in args.items():\n+            args_array.append(f'--{arg}')\n+            args_array.append(f'{value}')\n+        cmd = ['gerapy', 'parse'] + args_array + [project_path] + [spider_name]\n+        print('cmd', cmd)\n         logger.debug('parse cmd %s', cmd)\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)\n+        p = Popen(cmd, shell=False, stdin=PIPE,\n+                         stdout=PIPE, stderr=PIPE, close_fds=True)\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\n         logger.debug('stdout %s, stderr %s', stdout, stderr)\n         if not stderr:\n@@ -645,7 +657,6 @@ def job_list(request, client_id, project_name):\n                 job['status'] = status\n                 jobs.append(job)\n         return JsonResponse(jobs)\n-    \n \n \n @api_view(['GET'])\n@@ -663,7 +674,8 @@ def job_log(request, client_id, project_name, spider_name, job_id):\n     if request.method == 'GET':\n         client = Client.objects.get(id=client_id)\n         # get log url\n-        url = log_url(client.ip, client.port, project_name, spider_name, job_id)\n+        url = log_url(client.ip, client.port,\n+                      project_name, spider_name, job_id)\n         # get last 1000 bytes of log\n         response = requests.get(url, timeout=5, headers={\n             'Range': 'bytes=-1000'\n@@ -765,7 +777,8 @@ def monitor_create(request):\n     if request.method == 'POST':\n         data = json.loads(request.body)\n         data = data['form']\n-        data['configuration'] = json.dumps(data['configuration'], ensure_ascii=False)\n+        data['configuration'] = json.dumps(\n+            data['configuration'], ensure_ascii=False)\n         monitor = Monitor.objects.create(**data)\n         return JsonResponse(model_to_dict(monitor))\n \n@@ -785,7 +798,8 @@ def task_create(request):\n                                    name=data.get('name'),\n                                    spider=data.get('spider'),\n                                    trigger=data.get('trigger'),\n-                                   configuration=json.dumps(data.get('configuration'), ensure_ascii=False),\n+                                   configuration=json.dumps(\n+                                       data.get('configuration'), ensure_ascii=False),\n                                    modified=1)\n         return JsonResponse({'result': '1', 'data': model_to_dict(task)})\n \n@@ -803,7 +817,8 @@ def task_update(request, task_id):\n         task = Task.objects.filter(id=task_id)\n         data = json.loads(request.body)\n         data['clients'] = json.dumps(data.get('clients'), ensure_ascii=False)\n-        data['configuration'] = json.dumps(data.get('configuration'), ensure_ascii=False)\n+        data['configuration'] = json.dumps(\n+            data.get('configuration'), ensure_ascii=False)\n         data['modified'] = 1\n         task.update(**data)\n         return JsonResponse(model_to_dict(Task.objects.get(id=task_id)))\n@@ -823,11 +838,10 @@ def task_remove(request, task_id):\n         clients = clients_of_task(task)\n         for client in clients:\n             job_id = get_job_id(client, task)\n-            DjangoJob.objects.filter(name=job_id).delete()\n+            DjangoJob.objects.filter(id=job_id).delete()\n         # delete task\n         Task.objects.filter(id=task_id).delete()\n         return JsonResponse({'result': '1'})\n-    \n \n \n @api_view(['GET'])\n@@ -875,12 +889,14 @@ def task_status(request, task_id):\n         clients = clients_of_task(task)\n         for client in clients:\n             job_id = get_job_id(client, task)\n-            jobs = DjangoJob.objects.filter(name=job_id)\n+            jobs = DjangoJob.objects.filter(id=job_id)\n             logger.debug('jobs from djangojob %s', jobs)\n             # if job does not exist, for date mode exceed time\n-            if not jobs: continue\n-            job = DjangoJob.objects.get(name=job_id)\n-            executions = serialize('json', DjangoJobExecution.objects.filter(job=job))\n+            if not jobs:\n+                continue\n+            job = DjangoJob.objects.get(id=job_id)\n+            executions = serialize(\n+                'json', DjangoJobExecution.objects.filter(job=job))\n             result.append({\n                 'client': model_to_dict(client),\n                 'next': job.next_run_time,"
        },
        {
            "index":646,
            "vuln_id":"GHSA-cg3h-rc9q-g8v9",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/6ccb5c12fc1be065ebce9c89c4677ee939b88597'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in pimcore pimcore version 10.3.0 and prior is vulnerable to cross-site scripting.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/6ccb5c12fc1be065ebce9c89c4677ee939b88597",
            "commit_sha":"6ccb5c12fc1be065ebce9c89c4677ee939b88597",
            "patch":"SINGLE",
            "chain_ord":"['6ccb5c12fc1be065ebce9c89c4677ee939b88597']",
            "before_first_fix_commit":"{'7b6b2229ed3f19da1632afcbf9b8fec6d768faad'}",
            "last_fix_commit":"6ccb5c12fc1be065ebce9c89c4677ee939b88597",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/07\/2022, 12:03:58",
            "message":"[Admin] Website Settings - Escape grid values properly",
            "author":"dpahuja",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 7, 'total': 26}",
            "files":"{'bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/settings\/website.js': {'additions': 19, 'deletions': 7, 'changes': 26, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/6ccb5c12fc1be065ebce9c89c4677ee939b88597\/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Fsettings%2Fwebsite.js', 'patch': '@@ -36,7 +36,7 @@ pimcore.settings.website = Class.create({\\n                 border:false,\\n                 layout:\"fit\",\\n                 closable:true,\\n-                items:[this.getRowEditor()]\\n+                items:[this.getRowEditor()],\\n             });\\n \\n             var tabPanel = Ext.getCmp(\"pimcore_panel_tabs\");\\n@@ -133,6 +133,7 @@ pimcore.settings.website = Class.create({\\n                 dataIndex: \\'data\\',\\n                 flex: 300,\\n                 editable: true,\\n+                editor: new Ext.form.TextField({}),\\n                 renderer: this.getCellRenderer.bind(this),\\n             },\\n             {text: t(\"site\"), flex: 100, sortable:true, dataIndex: \"siteId\",\\n@@ -303,7 +304,10 @@ pimcore.settings.website = Class.create({\\n             bodyCls: \"pimcore_editable_grid\",\\n             stripeRows:true,\\n             columns : {\\n-                items: typesColumns\\n+                items: typesColumns,\\n+                defaults: {\\n+                    renderer: Ext.util.Format.htmlEncode\\n+                },\\n             },\\n             sm:  Ext.create(\\'Ext.selection.RowModel\\', {}),\\n             bbar:this.pagingtoolbar,\\n@@ -359,15 +363,23 @@ pimcore.settings.website = Class.create({\\n     },\\n \\n     getCellEditor: function (record) {\\n-        var data = record.data;\\n+        let data = record.data;\\n \\n-        var type = data.type;\\n-        var property;\\n+        let type = data.type;\\n+        let property;\\n \\n         if (type === \"text\") {\\n-            property = Ext.create(\\'Ext.form.TextField\\');\\n+            property = {\\n+                xtype: \\'textfield\\',\\n+                flex: 1,\\n+                value: data.data\\n+            }\\n         } else if (type == \"textarea\") {\\n-            property = Ext.create(\\'Ext.form.TextArea\\');\\n+            property = {\\n+                xtype: \"textarea\",\\n+                flex: 1,\\n+                value: data.data\\n+            }\\n         } else if (type == \"document\" || type == \"asset\" || type == \"object\") {\\n             property = {\\n                 xtype: \\'textfield\\','}}",
            "message_norm":"[admin] website settings - escape grid values properly",
            "language":"af",
            "entities":"[('admin', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/settings\/website.js'])",
            "num_files":1.0,
            "patch_content":"From 6ccb5c12fc1be065ebce9c89c4677ee939b88597 Mon Sep 17 00:00:00 2001\nFrom: dpahuja <divesh.pahuja@pimcore.com>\nDate: Mon, 7 Feb 2022 13:03:58 +0100\nSubject: [PATCH] [Admin] Website Settings - Escape grid values properly\n\n---\n ...\/public\/js\/pimcore\/settings\/website.js     | 26 ++++++++++++++-----\n 1 file changed, 19 insertions(+), 7 deletions(-)\n\ndiff --git a\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/settings\/website.js b\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/settings\/website.js\nindex b522d6fd2d3..f19115b0e41 100644\n--- a\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/settings\/website.js\n+++ b\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/settings\/website.js\n@@ -36,7 +36,7 @@ pimcore.settings.website = Class.create({\n                 border:false,\n                 layout:\"fit\",\n                 closable:true,\n-                items:[this.getRowEditor()]\n+                items:[this.getRowEditor()],\n             });\n \n             var tabPanel = Ext.getCmp(\"pimcore_panel_tabs\");\n@@ -133,6 +133,7 @@ pimcore.settings.website = Class.create({\n                 dataIndex: 'data',\n                 flex: 300,\n                 editable: true,\n+                editor: new Ext.form.TextField({}),\n                 renderer: this.getCellRenderer.bind(this),\n             },\n             {text: t(\"site\"), flex: 100, sortable:true, dataIndex: \"siteId\",\n@@ -303,7 +304,10 @@ pimcore.settings.website = Class.create({\n             bodyCls: \"pimcore_editable_grid\",\n             stripeRows:true,\n             columns : {\n-                items: typesColumns\n+                items: typesColumns,\n+                defaults: {\n+                    renderer: Ext.util.Format.htmlEncode\n+                },\n             },\n             sm:  Ext.create('Ext.selection.RowModel', {}),\n             bbar:this.pagingtoolbar,\n@@ -359,15 +363,23 @@ pimcore.settings.website = Class.create({\n     },\n \n     getCellEditor: function (record) {\n-        var data = record.data;\n+        let data = record.data;\n \n-        var type = data.type;\n-        var property;\n+        let type = data.type;\n+        let property;\n \n         if (type === \"text\") {\n-            property = Ext.create('Ext.form.TextField');\n+            property = {\n+                xtype: 'textfield',\n+                flex: 1,\n+                value: data.data\n+            }\n         } else if (type == \"textarea\") {\n-            property = Ext.create('Ext.form.TextArea');\n+            property = {\n+                xtype: \"textarea\",\n+                flex: 1,\n+                value: data.data\n+            }\n         } else if (type == \"document\" || type == \"asset\" || type == \"object\") {\n             property = {\n                 xtype: 'textfield',"
        },
        {
            "index":769,
            "vuln_id":"GHSA-73q9-7pwj-gm46",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/icecoder\/icecoder\/commit\/51cf24b2a39138e6a7b5739ef59eb38cd7c39763'}",
            "dataset":"osv",
            "summary":"icecoder is vulnerable to Cross-site Scripting icecoder is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
            "published_date":"2022-01-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/icecoder\/icecoder",
            "commit_href":"https:\/\/github.com\/icecoder\/icecoder\/commit\/51cf24b2a39138e6a7b5739ef59eb38cd7c39763",
            "commit_sha":"51cf24b2a39138e6a7b5739ef59eb38cd7c39763",
            "patch":"SINGLE",
            "chain_ord":"['51cf24b2a39138e6a7b5739ef59eb38cd7c39763']",
            "before_first_fix_commit":"{'cd964f816f31828011593405e024ee3b4c0f6ed3'}",
            "last_fix_commit":"51cf24b2a39138e6a7b5739ef59eb38cd7c39763",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/17\/2022, 12:38:29",
            "message":"rXSS cleaned username in editor info display",
            "author":"Matt Pass",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'editor.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/icecoder\/ICEcoder\/raw\/51cf24b2a39138e6a7b5739ef59eb38cd7c39763\/editor.php', 'patch': '@@ -150,7 +150,7 @@\\n             ?>\\n             <h2><?php echo $t[\\'multi-user\\']; ?><\/h2>\\n             <span class=\"heading\"><?php echo $t[\\'Username\\']; ?><\/span><br>\\n-            <?php echo $_SESSION[\\'username\\'];?><br><br>\\n+            <?php echo xssClean($_SESSION[\\'username\\'], \"html\");?><br><br>\\n             <?php\\n         }\\n         ?>'}}",
            "message_norm":"rxss cleaned username in editor info display",
            "language":"en",
            "entities":"[('rxss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['editor.php'])",
            "num_files":1.0,
            "patch_content":"From 51cf24b2a39138e6a7b5739ef59eb38cd7c39763 Mon Sep 17 00:00:00 2001\nFrom: Matt Pass <matt@mattpass.com>\nDate: Mon, 17 Jan 2022 12:38:29 +0000\nSubject: [PATCH] rXSS cleaned username in editor info display\n\n---\n editor.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/editor.php b\/editor.php\nindex 417ba43f..7b7fa26f 100644\n--- a\/editor.php\n+++ b\/editor.php\n@@ -150,7 +150,7 @@\n             ?>\n             <h2><?php echo $t['multi-user']; ?><\/h2>\n             <span class=\"heading\"><?php echo $t['Username']; ?><\/span><br>\n-            <?php echo $_SESSION['username'];?><br><br>\n+            <?php echo xssClean($_SESSION['username'], \"html\");?><br><br>\n             <?php\n         }\n         ?>"
        },
        {
            "index":262,
            "vuln_id":"GHSA-fc38-mxwr-pfhx",
            "cwe_id":"{'CWE-79'}",
            "score":8.0,
            "chain":"{'https:\/\/github.com\/shopware\/platform\/commit\/abe9f69e1f667800f974acccd3047b4930e4b423'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting via SVG media files ### Impact\nCross-Site Scripting via SVG media files\n\n### Patches\nWe recommend updating to the current version 6.4.3.1. You can get the update to 6.4.3.1 regularly via the Auto-Updater or directly via the download overview.\n\nhttps:\/\/www.shopware.com\/en\/download\/#shopware-6\n\n### Workarounds\nFor older versions of 6.1, 6.2, and 6.3, corresponding security measures are also available via a plugin. For the full range of functions, we recommend updating to the latest Shopware version.",
            "published_date":"2021-08-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/shopware\/platform",
            "commit_href":"https:\/\/github.com\/shopware\/platform\/commit\/abe9f69e1f667800f974acccd3047b4930e4b423",
            "commit_sha":"abe9f69e1f667800f974acccd3047b4930e4b423",
            "patch":"SINGLE",
            "chain_ord":"['abe9f69e1f667800f974acccd3047b4930e4b423']",
            "before_first_fix_commit":"{'912b96de3b839c6c5525c98cbb58f537c2d838be'}",
            "last_fix_commit":"abe9f69e1f667800f974acccd3047b4930e4b423",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 13:31:10",
            "message":"NEXT-15677 - Fix XSS for SVG files",
            "author":"Jonas Elfering",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'public\/.htaccess.dist': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/shopware\/platform\/raw\/abe9f69e1f667800f974acccd3047b4930e4b423\/public%2F.htaccess.dist', 'patch': '@@ -36,7 +36,7 @@ DirectoryIndex index.php\\n <\/IfModule>\\n \\n <IfModule mod_headers.c>\\n-    <FilesMatch \"\\\\.svg$\">\\n+    <FilesMatch \"\\\\.(?i:svg)$\">\\n         Header set Content-Security-Policy \"script-src \\'none\\'\"\\n     <\/FilesMatch>\\n <\/IfModule>'}}",
            "message_norm":"next-15677 - fix xss for svg files",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['public\/.htaccess.dist'])",
            "num_files":1.0,
            "patch_content":"From abe9f69e1f667800f974acccd3047b4930e4b423 Mon Sep 17 00:00:00 2001\nFrom: Jonas Elfering <j.elfering@shopware.com>\nDate: Tue, 27 Jul 2021 15:31:10 +0200\nSubject: [PATCH] NEXT-15677 - Fix XSS for SVG files\n\n---\n public\/.htaccess.dist | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/public\/.htaccess.dist b\/public\/.htaccess.dist\nindex c81ffef81e5..62601e581c2 100644\n--- a\/public\/.htaccess.dist\n+++ b\/public\/.htaccess.dist\n@@ -36,7 +36,7 @@ DirectoryIndex index.php\n <\/IfModule>\n \n <IfModule mod_headers.c>\n-    <FilesMatch \"\\.svg$\">\n+    <FilesMatch \"\\.(?i:svg)$\">\n         Header set Content-Security-Policy \"script-src 'none'\"\n     <\/FilesMatch>\n <\/IfModule>"
        },
        {
            "index":598,
            "vuln_id":"GHSA-6cpj-3g83-q2j4",
            "cwe_id":"{'CWE-611'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/apache\/lucene-solr\/commit\/f230486ce6707762c1a6e81655d0fac52887906d', 'https:\/\/github.com\/apache\/lucene-solr\/commit\/0d21b900975b7048d2e925d852aeacb9bdc6766c'}",
            "dataset":"osv",
            "summary":"Improper Restriction of XML External Entity Reference in Apache Solr The (1) UpdateRequestHandler for XSLT or (2) XPathEntityProcessor in Apache Solr before 4.1 allows remote attackers to have an unspecified impact via XML data containing an external entity declaration in conjunction with an entity reference, related to an XML External Entity (XXE) issue, different vectors than CVE-2013-6407.",
            "published_date":"2022-05-17",
            "chain_len":2,
            "project":"https:\/\/github.com\/apache\/lucene-solr",
            "commit_href":"https:\/\/github.com\/apache\/lucene-solr\/commit\/0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "commit_sha":"0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "patch":"MULTI",
            "chain_ord":"['f230486ce6707762c1a6e81655d0fac52887906d', '0d21b900975b7048d2e925d852aeacb9bdc6766c']",
            "before_first_fix_commit":"{'f230486ce6707762c1a6e81655d0fac52887906d'}",
            "last_fix_commit":"0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "chain_ord_pos":2.0,
            "commit_datetime":"09\/27\/2012, 13:15:24",
            "message":"SOLR-3895, SOLR-3614: Fix javadocs\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991 13f79535-47bb-0310-9956-ffa450edef68",
            "author":"Uwe Schindler",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/lucene-solr\/raw\/0d21b900975b7048d2e925d852aeacb9bdc6766c\/solr%2Fcore%2Fsrc%2Fjava%2Forg%2Fapache%2Fsolr%2Futil%2FEmptyEntityResolver.java', 'patch': '@@ -67,7 +67,7 @@ private static void trySetSAXFeature(SAXParserFactory saxFactory, String feature\\n   }\\n   \\n   \/** Configures the given {@link SAXParserFactory} to do secure XML processing of untrusted sources.\\n-   * It is required to also set {@link #SAX_INSTANCE} on the created {@link XMLReader}.\\n+   * It is required to also set {@link #SAX_INSTANCE} on the created {@link org.xml.sax.XMLReader}.\\n    * @see #SAX_INSTANCE\\n    *\/\\n   public static void configureSAXParserFactory(SAXParserFactory saxFactory) {'}}",
            "message_norm":"solr-3895, solr-3614: fix javadocs\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991 13f79535-47bb-0310-9956-ffa450edef68",
            "language":"sv",
            "entities":"[('fix', 'ACTION', ''), ('https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991', 'URL', ''), ('13f79535', 'SHA', 'generic_sha'), ('ffa450edef68', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java'])",
            "num_files":1.0,
            "patch_content":"From 0d21b900975b7048d2e925d852aeacb9bdc6766c Mon Sep 17 00:00:00 2001\nFrom: Uwe Schindler <uschindler@apache.org>\nDate: Thu, 27 Sep 2012 13:15:24 +0000\nSubject: [PATCH] SOLR-3895, SOLR-3614: Fix javadocs\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991 13f79535-47bb-0310-9956-ffa450edef68\n---\n ...\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java b\/solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java\nindex c9ff143c2feb..86e27a4bb763 100644\n--- a\/solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java\n+++ b\/solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java\n@@ -67,7 +67,7 @@ private static void trySetSAXFeature(SAXParserFactory saxFactory, String feature\n   }\n   \n   \/** Configures the given {@link SAXParserFactory} to do secure XML processing of untrusted sources.\n-   * It is required to also set {@link #SAX_INSTANCE} on the created {@link XMLReader}.\n+   * It is required to also set {@link #SAX_INSTANCE} on the created {@link org.xml.sax.XMLReader}.\n    * @see #SAX_INSTANCE\n    *\/\n   public static void configureSAXParserFactory(SAXParserFactory saxFactory) {"
        },
        {
            "index":243,
            "vuln_id":"GHSA-2v5j-q74q-r53f",
            "cwe_id":"{'CWE-79'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/django-helpdesk\/django-helpdesk\/commit\/a22eb0673fe0b7784f99c6b5fd343b64a6700f06'}",
            "dataset":"osv",
            "summary":"django-helpdesk is vulnerable to Cross-site Scripting django-helpdesk is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting').",
            "published_date":"2021-12-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/django-helpdesk\/django-helpdesk",
            "commit_href":"https:\/\/github.com\/django-helpdesk\/django-helpdesk\/commit\/a22eb0673fe0b7784f99c6b5fd343b64a6700f06",
            "commit_sha":"a22eb0673fe0b7784f99c6b5fd343b64a6700f06",
            "patch":"SINGLE",
            "chain_ord":"['a22eb0673fe0b7784f99c6b5fd343b64a6700f06']",
            "before_first_fix_commit":"{'7097c9c4c0b255ec1f10f3ea14fa2b9c47f6c706'}",
            "last_fix_commit":"a22eb0673fe0b7784f99c6b5fd343b64a6700f06",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/19\/2021, 16:11:33",
            "message":"Update pattern",
            "author":"noobpk",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'helpdesk\/models.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/django-helpdesk\/django-helpdesk\/raw\/a22eb0673fe0b7784f99c6b5fd343b64a6700f06\/helpdesk%2Fmodels.py', 'patch': '@@ -56,7 +56,7 @@ def get_markdown(text):\\n     if not text:\\n         return \"\"\\n \\n-    pattern = fr\\'([\\\\[\\\\s\\\\S\\\\]]*?)\\\\(([\\\\s\\\\S]*?):([\\\\[\\\\s\\\\S\\\\]]*?)\\\\)\\'\\n+    pattern = fr\\'([\\\\[\\\\s\\\\S\\\\]]*?)\\\\(([\\\\s\\\\S]*?):([\\\\s\\\\S]*?)\\\\)\\'\\n     # Regex check\\n     if re.match(pattern, text):\\n         # get get value of group regex'}}",
            "message_norm":"update pattern",
            "language":"it",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"REDUNDANT_MESSAGE",
            "list_files":"dict_keys(['helpdesk\/models.py'])",
            "num_files":1.0,
            "patch_content":"From a22eb0673fe0b7784f99c6b5fd343b64a6700f06 Mon Sep 17 00:00:00 2001\nFrom: noobpk <ltp.noobpk@gmail.com>\nDate: Fri, 19 Nov 2021 23:11:33 +0700\nSubject: [PATCH] Update pattern\n\n---\n helpdesk\/models.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/helpdesk\/models.py b\/helpdesk\/models.py\nindex 31bed5df6..f8ffb8b11 100644\n--- a\/helpdesk\/models.py\n+++ b\/helpdesk\/models.py\n@@ -56,7 +56,7 @@ def get_markdown(text):\n     if not text:\n         return \"\"\n \n-    pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\[\\s\\S\\]]*?)\\)'\n+    pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\s\\S]*?)\\)'\n     # Regex check\n     if re.match(pattern, text):\n         # get get value of group regex"
        },
        {
            "index":651,
            "vuln_id":"GHSA-6m8p-4fxj-pgc2",
            "cwe_id":"{'CWE-78'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/mikaelbr\/mversion\/commit\/b7a8b32600e60759a7ad3921ec4a2750bf173482'}",
            "dataset":"osv",
            "summary":"OS Command Injection in mversion The issue occurs because tagName user input is formatted inside the exec function is executed without any checks.",
            "published_date":"2021-05-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/mikaelbr\/mversion",
            "commit_href":"https:\/\/github.com\/mikaelbr\/mversion\/commit\/b7a8b32600e60759a7ad3921ec4a2750bf173482",
            "commit_sha":"b7a8b32600e60759a7ad3921ec4a2750bf173482",
            "patch":"SINGLE",
            "chain_ord":"['b7a8b32600e60759a7ad3921ec4a2750bf173482']",
            "before_first_fix_commit":"{'a9ddbc2bc86eb48f6976b85d195b6a94e81ffb22'}",
            "last_fix_commit":"b7a8b32600e60759a7ad3921ec4a2750bf173482",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/23\/2020, 22:02:33",
            "message":"Fix Remote Command Execution",
            "author":"hbkhan",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/git.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mikaelbr\/mversion\/raw\/b7a8b32600e60759a7ad3921ec4a2750bf173482\/lib%2Fgit.js', 'patch': '@@ -61,7 +61,7 @@ module.exports.commit = function (files, message, newVer, tagName, callback) {\\n \\n     function (done) {\\n       cp.exec(\\n-        [gitApp, \"tag\", \"-a\", tagName, \"-m\", message].join(\" \"),\\n+        [gitApp, \"tag\", \"-a\", escapeQuotes(tagName), \"-m\", message].join(\" \"),\\n         gitExtra,\\n         done\\n       );'}}",
            "message_norm":"fix remote command execution",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('command execution', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/git.js'])",
            "num_files":1.0,
            "patch_content":"From b7a8b32600e60759a7ad3921ec4a2750bf173482 Mon Sep 17 00:00:00 2001\nFrom: hbkhan <hbkhan@github.com>\nDate: Tue, 23 Jun 2020 17:02:33 -0500\nSubject: [PATCH] Fix Remote Command Execution\n\n---\n lib\/git.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/git.js b\/lib\/git.js\nindex acf6297..2a488ff 100644\n--- a\/lib\/git.js\n+++ b\/lib\/git.js\n@@ -61,7 +61,7 @@ module.exports.commit = function (files, message, newVer, tagName, callback) {\n \n     function (done) {\n       cp.exec(\n-        [gitApp, \"tag\", \"-a\", tagName, \"-m\", message].join(\" \"),\n+        [gitApp, \"tag\", \"-a\", escapeQuotes(tagName), \"-m\", message].join(\" \"),\n         gitExtra,\n         done\n       );"
        },
        {
            "index":550,
            "vuln_id":"GHSA-rfw2-x9f8-2f6m",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/linkedin\/oncall\/commit\/843bc106a1c1b1699e9e52b6b0d01c7efe1d6225'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting LinkedIn Oncall through 1.4.0 allows reflected XSS via \/query because of mishandling of the \"No results found for\" message in the search bar.",
            "published_date":"2021-04-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/linkedin\/oncall",
            "commit_href":"https:\/\/github.com\/linkedin\/oncall\/commit\/843bc106a1c1b1699e9e52b6b0d01c7efe1d6225",
            "commit_sha":"843bc106a1c1b1699e9e52b6b0d01c7efe1d6225",
            "patch":"SINGLE",
            "chain_ord":"['843bc106a1c1b1699e9e52b6b0d01c7efe1d6225']",
            "before_first_fix_commit":"{'605d10ef5d68181b2c516dc857fdc3c8575539cd'}",
            "last_fix_commit":"843bc106a1c1b1699e9e52b6b0d01c7efe1d6225",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/05\/2021, 23:30:43",
            "message":"prevent potential XSS from searchbar results (#342)\n\n* prevent potential XSS from searchbar results\r\n\r\n* use built in handlebars expression escaping\r\n\r\n* use handlebars encodeURIComponent",
            "author":"Diego Cepeda",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'src\/oncall\/ui\/static\/js\/oncall.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/linkedin\/oncall\/raw\/843bc106a1c1b1699e9e52b6b0d01c7efe1d6225\/src%2Foncall%2Fui%2Fstatic%2Fjs%2Foncall.js', 'patch': '@@ -579,11 +579,11 @@ var oncall = {\\n               },\\n               footer: function(resp){\\n                 if (teamsCt > typeaheadLimit) {\\n-                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + resp.query + \\'\/teams\" data-navigo> See all \\' + teamsCt + \\' results for teams \u00bb<\/a><\/div>\\';\\n+                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + \\'\/teams\" data-navigo> See all \\' + teamsCt + \\' results for teams \u00bb<\/a><\/div>\\';\\n                 }\\n               },\\n               empty: function(resp){\\n-                return \\'<h4> No results found for \"\\' + resp.query + \\'\" <\/h4>\\';\\n+                return \\'<h4> No results found for \"\\' + Handlebars.escapeExpression(resp.query) + \\'\" <\/h4>\\';\\n               }\\n             }\\n           },\\n@@ -604,7 +604,7 @@ var oncall = {\\n               },\\n               footer: function(resp){\\n                 if (servicesCt > typeaheadLimit) {\\n-                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + resp.query + \\'\/services\" data-navigo> See all \\' + servicesCt + \\' results for services \u00bb<\/a><\/div>\\';\\n+                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + \\'\/services\" data-navigo> See all \\' + servicesCt + \\' results for services \u00bb<\/a><\/div>\\';\\n                 }\\n               }\\n             }\\n@@ -626,7 +626,7 @@ var oncall = {\\n               },\\n               footer: function(resp){\\n                 if (usersCt > typeaheadLimit) {\\n-                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + resp.query + \\'\/users\" data-navigo> See all \\' + usersCt + \\' results for users \u00bb<\/a><\/div>\\';\\n+                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + \\'\/users\" data-navigo> See all \\' + usersCt + \\' results for users \u00bb<\/a><\/div>\\';\\n                 }\\n               }\\n             }'}}",
            "message_norm":"prevent potential xss from searchbar results (#342)\n\n* prevent potential xss from searchbar results\r\n\r\n* use built in handlebars expression escaping\r\n\r\n* use handlebars encodeuricomponent",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('xss', 'SECWORD', ''), ('#342', 'ISSUE', ''), ('prevent', 'ACTION', ''), ('xss', 'SECWORD', ''), ('escaping', 'SECWORD', ''), ('encodeuricomponent', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/oncall\/ui\/static\/js\/oncall.js'])",
            "num_files":1.0,
            "patch_content":"From 843bc106a1c1b1699e9e52b6b0d01c7efe1d6225 Mon Sep 17 00:00:00 2001\nFrom: Diego Cepeda <dcepeda@linkedin.com>\nDate: Fri, 5 Feb 2021 15:30:43 -0800\nSubject: [PATCH] prevent potential XSS from searchbar results (#342)\n\n* prevent potential XSS from searchbar results\n\n* use built in handlebars expression escaping\n\n* use handlebars encodeURIComponent\n---\n src\/oncall\/ui\/static\/js\/oncall.js | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/oncall\/ui\/static\/js\/oncall.js b\/src\/oncall\/ui\/static\/js\/oncall.js\nindex 9189bd8d..022985e2 100644\n--- a\/src\/oncall\/ui\/static\/js\/oncall.js\n+++ b\/src\/oncall\/ui\/static\/js\/oncall.js\n@@ -579,11 +579,11 @@ var oncall = {\n               },\n               footer: function(resp){\n                 if (teamsCt > typeaheadLimit) {\n-                  return '<div class=\"tt-see-all\"><a href=\"\/query\/' + resp.query + '\/teams\" data-navigo> See all ' + teamsCt + ' results for teams \u00bb<\/a><\/div>';\n+                  return '<div class=\"tt-see-all\"><a href=\"\/query\/' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + '\/teams\" data-navigo> See all ' + teamsCt + ' results for teams \u00bb<\/a><\/div>';\n                 }\n               },\n               empty: function(resp){\n-                return '<h4> No results found for \"' + resp.query + '\" <\/h4>';\n+                return '<h4> No results found for \"' + Handlebars.escapeExpression(resp.query) + '\" <\/h4>';\n               }\n             }\n           },\n@@ -604,7 +604,7 @@ var oncall = {\n               },\n               footer: function(resp){\n                 if (servicesCt > typeaheadLimit) {\n-                  return '<div class=\"tt-see-all\"><a href=\"\/query\/' + resp.query + '\/services\" data-navigo> See all ' + servicesCt + ' results for services \u00bb<\/a><\/div>';\n+                  return '<div class=\"tt-see-all\"><a href=\"\/query\/' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + '\/services\" data-navigo> See all ' + servicesCt + ' results for services \u00bb<\/a><\/div>';\n                 }\n               }\n             }\n@@ -626,7 +626,7 @@ var oncall = {\n               },\n               footer: function(resp){\n                 if (usersCt > typeaheadLimit) {\n-                  return '<div class=\"tt-see-all\"><a href=\"\/query\/' + resp.query + '\/users\" data-navigo> See all ' + usersCt + ' results for users \u00bb<\/a><\/div>';\n+                  return '<div class=\"tt-see-all\"><a href=\"\/query\/' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + '\/users\" data-navigo> See all ' + usersCt + ' results for users \u00bb<\/a><\/div>';\n                 }\n               }\n             }"
        },
        {
            "index":708,
            "vuln_id":"GHSA-8v7h-cpc2-r8jp",
            "cwe_id":"{'CWE-362'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/octobercms\/library\/commit\/fe569f3babf3f593be2b1e0a4ae0283506127a83'}",
            "dataset":"osv",
            "summary":"October CMS upload process vulnerable to RCE via Race Condition ### Impact\n\nThis advisory affects plugins that expose the `October\\Rain\\Database\\Attach\\File::fromData` as a public interface. This vulnerability does not affect vanilla installations of October CMS since this method is not exposed or used by the system internally or externally.\n\nWhen the developer allows the user to specify their own filename in the `fromData` method, an unauthenticated user can perform remote code execution (RCE) by exploiting a race condition in the temporary storage directory.\n\n### Patches\n\nThe issue has been patched in Build 476 (v1.0.476) and v1.1.12 and v2.2.15.\n\n### Workarounds\n\nApply https:\/\/github.com\/octobercms\/library\/commit\/fe569f3babf3f593be2b1e0a4ae0283506127a83 to your installation manually if unable to upgrade to Build 476 (v1.0.476) or v1.1.12 or v2.2.15.\n\n### References\n\nCredits to:\n- DucNT, HungTD and GiangVQ from RedTeam@VNG Security Response Center.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n- Email us at [hello@octobercms.com](mailto:hello@octobercms.com)",
            "published_date":"2022-07-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/octobercms\/library",
            "commit_href":"https:\/\/github.com\/octobercms\/library\/commit\/fe569f3babf3f593be2b1e0a4ae0283506127a83",
            "commit_sha":"fe569f3babf3f593be2b1e0a4ae0283506127a83",
            "patch":"SINGLE",
            "chain_ord":"['fe569f3babf3f593be2b1e0a4ae0283506127a83']",
            "before_first_fix_commit":"{'95ce496038c104571362c92418783b81889a8b9d'}",
            "last_fix_commit":"fe569f3babf3f593be2b1e0a4ae0283506127a83",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/29\/2022, 01:51:19",
            "message":"Refactor",
            "author":"Sam Georges",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 4, 'total': 9}",
            "files":"{'src\/Database\/Attach\/File.php': {'additions': 5, 'deletions': 4, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/octobercms\/library\/raw\/fe569f3babf3f593be2b1e0a4ae0283506127a83\/src%2FDatabase%2FAttach%2FFile.php', 'patch': \"@@ -124,14 +124,14 @@ public function fromPost($uploadedFile)\\n     \/**\\n      * fromFile creates a file object from a file on the disk\\n      *\/\\n-    public function fromFile($filePath)\\n+    public function fromFile($filePath, $filename = null)\\n     {\\n         if ($filePath === null) {\\n             return;\\n         }\\n \\n         $file = new FileObj($filePath);\\n-        $this->file_name = $file->getFilename();\\n+        $this->file_name = empty($filename) ? $file->getFilename() : $filename;\\n         $this->file_size = $file->getSize();\\n         $this->content_type = $file->getMimeType();\\n         $this->disk_name = $this->getDiskName();\\n@@ -152,10 +152,11 @@ public function fromData($data, $filename)\\n             return;\\n         }\\n \\n-        $tempPath = temp_path(basename($filename));\\n+        $tempName = str_replace('.', '', uniqid('', true)) . '.tmp';\\n+        $tempPath = temp_path($tempName);\\n         FileHelper::put($tempPath, $data);\\n \\n-        $file = $this->fromFile($tempPath);\\n+        $file = $this->fromFile($tempPath, basename($filename));\\n         FileHelper::delete($tempPath);\\n \\n         return $file;\"}}",
            "message_norm":"refactor",
            "language":"ro",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"SINGLE_WORD",
            "list_files":"dict_keys(['src\/Database\/Attach\/File.php'])",
            "num_files":1.0,
            "patch_content":"From fe569f3babf3f593be2b1e0a4ae0283506127a83 Mon Sep 17 00:00:00 2001\nFrom: Sam Georges <sam@daftspunk.com>\nDate: Tue, 29 Mar 2022 12:51:19 +1100\nSubject: [PATCH] Refactor\n\n---\n src\/Database\/Attach\/File.php | 9 +++++----\n 1 file changed, 5 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/Database\/Attach\/File.php b\/src\/Database\/Attach\/File.php\nindex 221be9a69..92f673413 100644\n--- a\/src\/Database\/Attach\/File.php\n+++ b\/src\/Database\/Attach\/File.php\n@@ -124,14 +124,14 @@ public function fromPost($uploadedFile)\n     \/**\n      * fromFile creates a file object from a file on the disk\n      *\/\n-    public function fromFile($filePath)\n+    public function fromFile($filePath, $filename = null)\n     {\n         if ($filePath === null) {\n             return;\n         }\n \n         $file = new FileObj($filePath);\n-        $this->file_name = $file->getFilename();\n+        $this->file_name = empty($filename) ? $file->getFilename() : $filename;\n         $this->file_size = $file->getSize();\n         $this->content_type = $file->getMimeType();\n         $this->disk_name = $this->getDiskName();\n@@ -152,10 +152,11 @@ public function fromData($data, $filename)\n             return;\n         }\n \n-        $tempPath = temp_path(basename($filename));\n+        $tempName = str_replace('.', '', uniqid('', true)) . '.tmp';\n+        $tempPath = temp_path($tempName);\n         FileHelper::put($tempPath, $data);\n \n-        $file = $this->fromFile($tempPath);\n+        $file = $this->fromFile($tempPath, basename($filename));\n         FileHelper::delete($tempPath);\n \n         return $file;"
        },
        {
            "index":817,
            "vuln_id":"GHSA-v7m9-9497-p9gr",
            "cwe_id":"{'CWE-863'}",
            "score":6.8,
            "chain":"{'https:\/\/github.com\/jupyterhub\/kubespawner\/commit\/3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0'}",
            "dataset":"osv",
            "summary":"Possible pod name collisions in jupyterhub-kubespawner ### Impact\n_What kind of vulnerability is it? Who is impacted?_\n\nJupyterHub deployments using:\n\n- KubeSpawner <= 0.11.1 (e.g. zero-to-jupyterhub 0.9.0) and\n- enabled named_servers (not default), and\n- an Authenticator that allows:\n  - usernames with hyphens or other characters that require escape (e.g. `user-hyphen` or `user@email`), and\n  - usernames which may match other usernames up to but not including the escaped character (e.g. `user` in the above cases)\n\nIn this circumstance, certain usernames will be able to craft particular server names which will grant them access to the default server of other users who have matching usernames.\n\n### Patches\n_Has the problem been patched? What versions should users upgrade to?_\n\nPatch will be released in kubespawner 0.12 and zero-to-jupyterhub 0.9.1\n\n### Workarounds\n_Is there a way for users to fix or remediate the vulnerability without upgrading?_\n\n#### KubeSpawner\n\nSpecify configuration:\n\nfor KubeSpawner\n```python\nfrom traitlets import default\nfrom kubespawner import KubeSpawner\n\nclass PatchedKubeSpawner(KubeSpawner):\n    @default(\"pod_name_template\")\n    def _default_pod_name_template(self):\n        if self.name:\n            return \"jupyter-{username}-{servername}\"\n        else:\n            return \"jupyter-{username}\"\n\n    @default(\"pvc_name_template\")\n    def _default_pvc_name_template(self):\n        if self.name:\n            return \"claim-{username}-{servername}\"\n        else:\n            return \"claim-{username}\"\n\nc.JupyterHub.spawner_class = PatchedKubeSpawner\n```\n\n**Note for KubeSpawner:** this configuration will behave differently before and after the upgrade, so will need to be removed when upgrading. Only apply this configuration while still using KubeSpawner \u2264 0.11.1 and remove it after upgrade to ensure consistent pod and pvc naming.\n\nChanging the name template means pvcs for named servers will have different names. This will result in orphaned PVCs for named servers across Hub upgrade! This may appear as data loss for users, depending on configuration, but the orphaned PVCs will still be around and data can be migrated manually (or new PVCs created manually to reference existing PVs) before deleting the old PVCs and\/or PVs.\n\n### References\n_Are there any links users can visit to find out more?_\n\n### For more information\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [kubespawner](https:\/\/github.com\/jupyterhub\/kubespawner)\n* Email us at [security@ipython.org](mailto:security@ipython.org)\n\nCredit: Jining Huang",
            "published_date":"2020-07-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/jupyterhub\/kubespawner",
            "commit_href":"https:\/\/github.com\/jupyterhub\/kubespawner\/commit\/3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0",
            "commit_sha":"3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0",
            "patch":"SINGLE",
            "chain_ord":"['3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0']",
            "before_first_fix_commit":"{'b7f55eae3d5afb6ac9f2facf76f46239e2f2a38a'}",
            "last_fix_commit":"3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/03\/2020, 07:48:42",
            "message":"move delimiter to pvc\/pod name templates\n\nand note version change",
            "author":"Min RK",
            "comments":null,
            "stats":"{'additions': 28, 'deletions': 16, 'total': 44}",
            "files":"{'kubespawner\/spawner.py': {'additions': 28, 'deletions': 16, 'changes': 44, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jupyterhub\/kubespawner\/raw\/3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0\/kubespawner%2Fspawner.py', 'patch': '@@ -307,16 +307,25 @@ def _namespace_default(self):\\n     )\\n \\n     pod_name_template = Unicode(\\n-        \\'jupyter-{username}{servername}\\',\\n+        \\'jupyter-{username}--{servername}\\',\\n         config=True,\\n         help=\"\"\"\\n         Template to use to form the name of user\\'s pods.\\n \\n-        `{username}` is expanded to the escaped, dns-label safe username.\\n+        `{username}` is expanded to the escaped, dns-label-safe username.\\n+        `{servername}` is expanded to the escaped, dns-label-safe server name, if any.\\n+\\n+        Trailing `-` characters are stripped for safe handling of empty server names (user default servers).\\n \\n         This must be unique within the namespace the pods are being spawned\\n         in, so if you are running multiple jupyterhubs spawning in the\\n         same namespace, consider setting this to be something more unique.\\n+\\n+        .. versionchanged:: 0.12\\n+            `--` delimiter added to the template,\\n+            where it was implicitly added to the `servername` field before.\\n+            Additionally, `username--servername` delimiter was `-` instead of `--`,\\n+            allowing collisions in certain circumstances.\\n         \"\"\"\\n     )\\n \\n@@ -332,16 +341,25 @@ def _namespace_default(self):\\n     )\\n \\n     pvc_name_template = Unicode(\\n-        \\'claim-{username}{servername}\\',\\n+        \\'claim-{username}--{servername}\\',\\n         config=True,\\n         help=\"\"\"\\n         Template to use to form the name of user\\'s pvc.\\n \\n         `{username}` is expanded to the escaped, dns-label safe username.\\n+        `{servername}` is expanded to the escaped, dns-label-safe server name, if any.\\n+\\n+        Trailing `-` characters are stripped for safe handling of empty server names (user default servers).\\n \\n         This must be unique within the namespace the pvc are being spawned\\n         in, so if you are running multiple jupyterhubs spawning in the\\n         same namespace, consider setting this to be something more unique.\\n+\\n+        .. versionchanged:: 0.12\\n+            `--` delimiter added to the template,\\n+            where it was implicitly added to the `servername` field before.\\n+            Additionally, `username--servername` delimiter was `-` instead of `--`,\\n+            allowing collisions in certain circumstances.\\n         \"\"\"\\n     )\\n \\n@@ -1313,28 +1331,22 @@ def _expand_user_properties(self, template):\\n         # Note: \\'-\\' is not in safe_chars, as it is being used as escape character\\n         safe_chars = set(string.ascii_lowercase + string.digits)\\n \\n-        # Set servername based on whether named-server initialised\\n-        if self.name:\\n-            # use two -- to ensure no collision possibilities\\n-            # are created by an ambiguous boundary between username and\\n-            # servername.\\n-            # -- cannot occur in a string where - is the escape char.\\n-            servername = \\'--{}\\'.format(self.name)\\n-            safe_servername = \\'--{}\\'.format(escapism.escape(self.name, safe=safe_chars, escape_char=\\'-\\').lower())\\n-        else:\\n-            servername = \\'\\'\\n-            safe_servername = \\'\\'\\n+        raw_servername = self.name or \\'\\'\\n+        safe_servername = escapism.escape(raw_servername, safe=safe_chars, escape_char=\\'-\\').lower()\\n \\n         legacy_escaped_username = \\'\\'.join([s if s in safe_chars else \\'-\\' for s in self.user.name.lower()])\\n         safe_username = escapism.escape(self.user.name, safe=safe_chars, escape_char=\\'-\\').lower()\\n-        return template.format(\\n+        rendered = template.format(\\n             userid=self.user.id,\\n             username=safe_username,\\n             unescaped_username=self.user.name,\\n             legacy_escape_username=legacy_escaped_username,\\n             servername=safe_servername,\\n-            unescaped_servername=servername,\\n+            unescaped_servername=raw_servername,\\n         )\\n+        # strip trailing - delimiter in case of empty servername.\\n+        # k8s object names cannot have trailing -\\n+        return rendered.rstrip(\"-\")\\n \\n     def _expand_all(self, src):\\n         if isinstance(src, list):'}}",
            "message_norm":"move delimiter to pvc\/pod name templates\n\nand note version change",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['kubespawner\/spawner.py'])",
            "num_files":1.0,
            "patch_content":"From 3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0 Mon Sep 17 00:00:00 2001\nFrom: Min RK <benjaminrk@gmail.com>\nDate: Fri, 3 Jul 2020 09:48:42 +0200\nSubject: [PATCH] move delimiter to pvc\/pod name templates\n\nand note version change\n---\n kubespawner\/spawner.py | 44 +++++++++++++++++++++++++++---------------\n 1 file changed, 28 insertions(+), 16 deletions(-)\n\ndiff --git a\/kubespawner\/spawner.py b\/kubespawner\/spawner.py\nindex f171ec6f..2106cd31 100644\n--- a\/kubespawner\/spawner.py\n+++ b\/kubespawner\/spawner.py\n@@ -307,16 +307,25 @@ def _namespace_default(self):\n     )\n \n     pod_name_template = Unicode(\n-        'jupyter-{username}{servername}',\n+        'jupyter-{username}--{servername}',\n         config=True,\n         help=\"\"\"\n         Template to use to form the name of user's pods.\n \n-        `{username}` is expanded to the escaped, dns-label safe username.\n+        `{username}` is expanded to the escaped, dns-label-safe username.\n+        `{servername}` is expanded to the escaped, dns-label-safe server name, if any.\n+\n+        Trailing `-` characters are stripped for safe handling of empty server names (user default servers).\n \n         This must be unique within the namespace the pods are being spawned\n         in, so if you are running multiple jupyterhubs spawning in the\n         same namespace, consider setting this to be something more unique.\n+\n+        .. versionchanged:: 0.12\n+            `--` delimiter added to the template,\n+            where it was implicitly added to the `servername` field before.\n+            Additionally, `username--servername` delimiter was `-` instead of `--`,\n+            allowing collisions in certain circumstances.\n         \"\"\"\n     )\n \n@@ -332,16 +341,25 @@ def _namespace_default(self):\n     )\n \n     pvc_name_template = Unicode(\n-        'claim-{username}{servername}',\n+        'claim-{username}--{servername}',\n         config=True,\n         help=\"\"\"\n         Template to use to form the name of user's pvc.\n \n         `{username}` is expanded to the escaped, dns-label safe username.\n+        `{servername}` is expanded to the escaped, dns-label-safe server name, if any.\n+\n+        Trailing `-` characters are stripped for safe handling of empty server names (user default servers).\n \n         This must be unique within the namespace the pvc are being spawned\n         in, so if you are running multiple jupyterhubs spawning in the\n         same namespace, consider setting this to be something more unique.\n+\n+        .. versionchanged:: 0.12\n+            `--` delimiter added to the template,\n+            where it was implicitly added to the `servername` field before.\n+            Additionally, `username--servername` delimiter was `-` instead of `--`,\n+            allowing collisions in certain circumstances.\n         \"\"\"\n     )\n \n@@ -1313,28 +1331,22 @@ def _expand_user_properties(self, template):\n         # Note: '-' is not in safe_chars, as it is being used as escape character\n         safe_chars = set(string.ascii_lowercase + string.digits)\n \n-        # Set servername based on whether named-server initialised\n-        if self.name:\n-            # use two -- to ensure no collision possibilities\n-            # are created by an ambiguous boundary between username and\n-            # servername.\n-            # -- cannot occur in a string where - is the escape char.\n-            servername = '--{}'.format(self.name)\n-            safe_servername = '--{}'.format(escapism.escape(self.name, safe=safe_chars, escape_char='-').lower())\n-        else:\n-            servername = ''\n-            safe_servername = ''\n+        raw_servername = self.name or ''\n+        safe_servername = escapism.escape(raw_servername, safe=safe_chars, escape_char='-').lower()\n \n         legacy_escaped_username = ''.join([s if s in safe_chars else '-' for s in self.user.name.lower()])\n         safe_username = escapism.escape(self.user.name, safe=safe_chars, escape_char='-').lower()\n-        return template.format(\n+        rendered = template.format(\n             userid=self.user.id,\n             username=safe_username,\n             unescaped_username=self.user.name,\n             legacy_escape_username=legacy_escaped_username,\n             servername=safe_servername,\n-            unescaped_servername=servername,\n+            unescaped_servername=raw_servername,\n         )\n+        # strip trailing - delimiter in case of empty servername.\n+        # k8s object names cannot have trailing -\n+        return rendered.rstrip(\"-\")\n \n     def _expand_all(self, src):\n         if isinstance(src, list):"
        },
        {
            "index":34,
            "vuln_id":"GHSA-9w2p-5mgw-p94c",
            "cwe_id":"{'CWE-681'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/96f364a1ca3009f98980021c4b32be5fdcca33a1'}",
            "dataset":"osv",
            "summary":"Integer overflow due to conversion to unsigned ### Impact\nThe implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=[1.0,2.0],\n  input=[1.0,1.0],\n  input_min=[0.0],\n  input_max=[10.0],\n  axis=-100)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc#L126) uses the `axis` value as the size argument to `absl::InlinedVector` constructor. But, the constructor uses an unsigned type for the argument, so the implicit conversion transforms the negative value to a large integer.\n\n### Patches\nWe have patched the issue in GitHub commit [96f364a1ca3009f98980021c4b32be5fdcca33a1](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/96f364a1ca3009f98980021c4b32be5fdcca33a1).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, and TensorFlow 2.4.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/96f364a1ca3009f98980021c4b32be5fdcca33a1",
            "commit_sha":"96f364a1ca3009f98980021c4b32be5fdcca33a1",
            "patch":"SINGLE",
            "chain_ord":"['96f364a1ca3009f98980021c4b32be5fdcca33a1']",
            "before_first_fix_commit":"{'10fe168385e67aca66427910ba6942eb14d31c5a'}",
            "last_fix_commit":"96f364a1ca3009f98980021c4b32be5fdcca33a1",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2021, 20:27:01",
            "message":"Validate axis input in tf.raw_ops.QuantizeAndDequantizeV4Grad\n\nPiperOrigin-RevId: 388291385\nChange-Id: I3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
            "files":"{'tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/96f364a1ca3009f98980021c4b32be5fdcca33a1\/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -158,6 +158,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\\n     Tensor* input_backprop = nullptr;\\n     OP_REQUIRES_OK(ctx,\\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\\n+    OP_REQUIRES(\\n+        ctx, axis_ >= -1,\\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\\n+                errors::InvalidArgument(\\n+                    \"Axis should be -1 or 0 or a positive value less than \",\\n+                    input.shape().dims(), \"but given axis value was \", axis_));\\n \\n     OP_REQUIRES(\\n         ctx, input.IsSameSize(gradient),'}}",
            "message_norm":"validate axis input in tf.raw_ops.quantizeanddequantizev4grad\n\npiperorigin-revid: 388291385\nchange-id: i3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
            "language":"ca",
            "entities":"[('validate', 'ACTION', ''), ('388291385', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 96f364a1ca3009f98980021c4b32be5fdcca33a1 Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Mon, 2 Aug 2021 13:27:01 -0700\nSubject: [PATCH] Validate axis input in tf.raw_ops.QuantizeAndDequantizeV4Grad\n\nPiperOrigin-RevId: 388291385\nChange-Id: I3bab68dc61d935afa96c0da021a7b722c6dc8dc8\n---\n tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc | 7 +++++++\n 1 file changed, 7 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\nindex 540d900f9f8696..d63a49a04be621 100644\n--- a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n@@ -158,6 +158,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n     Tensor* input_backprop = nullptr;\n     OP_REQUIRES_OK(ctx,\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\n+    OP_REQUIRES(\n+        ctx, axis_ >= -1,\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n+                errors::InvalidArgument(\n+                    \"Axis should be -1 or 0 or a positive value less than \",\n+                    input.shape().dims(), \"but given axis value was \", axis_));\n \n     OP_REQUIRES(\n         ctx, input.IsSameSize(gradient),"
        },
        {
            "index":905,
            "vuln_id":"GHSA-772j-h9xw-ffp5",
            "cwe_id":"{'CWE-843'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025'}",
            "dataset":"osv",
            "summary":"CHECK-fail in SparseCross due to type confusion ### Impact\nThe API of `tf.raw_ops.SparseCross` allows combinations which would result in a `CHECK`-failure and denial of service:\n\n```python\nimport tensorflow as tf\n\nhashed_output = False\nnum_buckets = 1949315406\nhash_key = 1869835877\nout_type = tf.string \ninternal_type = tf.string\n\nindices_1 = tf.constant([0, 6], shape=[1, 2], dtype=tf.int64)\nindices_2 = tf.constant([0, 0], shape=[1, 2], dtype=tf.int64)\nindices = [indices_1, indices_2]\n\nvalues_1 = tf.constant([0], dtype=tf.int64)\nvalues_2 = tf.constant([72], dtype=tf.int64)\nvalues = [values_1, values_2]\n\nbatch_size = 4\nshape_1 = tf.constant([4, 122], dtype=tf.int64)\nshape_2 = tf.constant([4, 188], dtype=tf.int64)\nshapes = [shape_1, shape_2]\n\ndense_1 = tf.constant([188, 127, 336, 0], shape=[4, 1], dtype=tf.int64)\ndense_2 = tf.constant([341, 470, 470, 470], shape=[4, 1], dtype=tf.int64)\ndense_3 = tf.constant([188, 188, 341, 922], shape=[4, 1], dtype=tf.int64)\ndenses = [dense_1, dense_2, dense_3]\n\ntf.raw_ops.SparseCross(indices=indices, values=values, shapes=shapes, dense_inputs=denses, hashed_output=hashed_output,\n                       num_buckets=num_buckets, hash_key=hash_key, out_type=out_type, internal_type=internal_type)\n```\n\nThe above code will result in a `CHECK` fail in [`tensor.cc`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/3d782b7d47b1bf2ed32bd4a246d6d6cadc4c903d\/tensorflow\/core\/framework\/tensor.cc#L670-L675):\n\n```cc\nvoid Tensor::CheckTypeAndIsAligned(DataType expected_dtype) const {\n  CHECK_EQ(dtype(), expected_dtype)\n      << \" \" << DataTypeString(expected_dtype) << \" expected, got \"\n      << DataTypeString(dtype());\n  ...\n}\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/3d782b7d47b1bf2ed32bd4a246d6d6cadc4c903d\/tensorflow\/core\/kernels\/sparse_cross_op.cc#L114-L116) is tricked to consider a tensor of type `tstring` which in fact contains integral elements:\n\n```cc\n  if (DT_STRING == values_.dtype())\n      return Fingerprint64(values_.vec<tstring>().data()[start + n]);\n  return values_.vec<int64>().data()[start + n];\n```\n\nFixing the type confusion by preventing mixing `DT_STRING` and `DT_INT64` types solves this issue.\n\n### Patches\nWe have patched the issue in GitHub commit [b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025",
            "commit_sha":"b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025",
            "patch":"SINGLE",
            "chain_ord":"['b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025']",
            "before_first_fix_commit":"{'3d782b7d47b1bf2ed32bd4a246d6d6cadc4c903d'}",
            "last_fix_commit":"b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/15\/2021, 20:03:19",
            "message":"Fix `tf.raw_ops.SparseCross` failing CHECK.\n\nPiperOrigin-RevId: 368701671\nChange-Id: Id805729dd9ba0bda36e4bb309408129b55fb649d",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 48, 'deletions': 7, 'total': 55}",
            "files":"{'tensorflow\/core\/kernels\/sparse_cross_op.cc': {'additions': 48, 'deletions': 7, 'changes': 55, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025\/tensorflow%2Fcore%2Fkernels%2Fsparse_cross_op.cc', 'patch': '@@ -27,6 +27,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n+#include \"tensorflow\/core\/framework\/types.pb.h\"\\n #include \"tensorflow\/core\/lib\/core\/stringpiece.h\"\\n #include \"tensorflow\/core\/lib\/strings\/str_util.h\"\\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\\n@@ -460,10 +461,19 @@ int64 CalculateBatchSize(const OpInputList& shapes_list_in,\\n Status ValidateInput(const OpInputList& indices_list_in,\\n                      const OpInputList& values_list_in,\\n                      const OpInputList& shapes_list_in,\\n-                     const OpInputList& dense_list_in) {\\n+                     const OpInputList& dense_list_in,\\n+                     const DataType& internal_type) {\\n   const auto size = indices_list_in.size();\\n+  \/\/ Only perform internal_type check for SparseCrossOp.\\n+  \/\/ Check if the internal_type is not invalid before doing so.\\n+  bool check_type = internal_type != DT_INVALID;\\n   \/\/ Validates indices_list_in OpInputList.\\n   for (int i = 0; i < size; i++) {\\n+    if (check_type && indices_list_in[i].dtype() != DT_INT64) {\\n+      return errors::InvalidArgument(\"Input indices should be of type \",\\n+                                     DT_INT64, \" but received \",\\n+                                     indices_list_in[i].dtype());\\n+    }\\n     if (!TensorShapeUtils::IsMatrix(indices_list_in[i].shape())) {\\n       return errors::InvalidArgument(\\n           \"Input indices should be a matrix but received shape \",\\n@@ -482,6 +492,14 @@ Status ValidateInput(const OpInputList& indices_list_in,\\n                                    values_list_in.size());\\n   }\\n   for (int i = 0; i < size; i++) {\\n+    \/\/ Make sure to avoid the expected type to be string, but input values to be\\n+    \/\/ int64.\\n+    if (check_type && internal_type == DT_STRING &&\\n+        values_list_in[i].dtype() == DT_INT64) {\\n+      return errors::InvalidArgument(\"Input values should be of internal type \",\\n+                                     internal_type, \" but received \",\\n+                                     values_list_in[i].dtype());\\n+    }\\n     if (!TensorShapeUtils::IsVector(values_list_in[i].shape())) {\\n       return errors::InvalidArgument(\\n           \"Input values should be a vector but received shape \",\\n@@ -502,6 +520,11 @@ Status ValidateInput(const OpInputList& indices_list_in,\\n                                    shapes_list_in.size());\\n   }\\n   for (int i = 0; i < size; i++) {\\n+    if (check_type && shapes_list_in[i].dtype() != DT_INT64) {\\n+      return errors::InvalidArgument(\"Input shape should be of type \", DT_INT64,\\n+                                     \" but received \",\\n+                                     shapes_list_in[i].dtype());\\n+    }\\n     if (!TensorShapeUtils::IsVector(shapes_list_in[i].shape())) {\\n       return errors::InvalidArgument(\\n           \"Input shapes should be a vector but received shape \",\\n@@ -517,6 +540,14 @@ Status ValidateInput(const OpInputList& indices_list_in,\\n \\n   \/\/ Validates dense_list_in OpInputList\\n   for (int i = 0; i < dense_list_in.size(); ++i) {\\n+    \/\/ Make sure to avoid the expected type to be string, but input values to be\\n+    \/\/ int64.\\n+    if (check_type && internal_type == DT_STRING &&\\n+        dense_list_in[i].dtype() == DT_INT64) {\\n+      return errors::InvalidArgument(\"Dense inputs should be of internal type \",\\n+                                     internal_type, \" but received \",\\n+                                     dense_list_in[i].dtype());\\n+    }\\n     if (!TensorShapeUtils::IsMatrix(dense_list_in[i].shape())) {\\n       return errors::InvalidArgument(\\n           \"Dense inputs should be a matrix but received shape \",\\n@@ -698,6 +729,7 @@ class SparseCrossOp : public OpKernel {\\n     int64 signed_hash_key_;\\n     OP_REQUIRES_OK(context, context->GetAttr(\"hash_key\", &signed_hash_key_));\\n     hash_key_ = static_cast<uint64>(signed_hash_key_);\\n+    OP_REQUIRES_OK(context, context->GetAttr(\"internal_type\", &internal_type_));\\n   }\\n \\n   void Compute(OpKernelContext* context) override {\\n@@ -711,8 +743,10 @@ class SparseCrossOp : public OpKernel {\\n     OP_REQUIRES_OK(context,\\n                    context->input_list(\"dense_inputs\", &dense_list_in));\\n \\n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\\n-                                          shapes_list_in, dense_list_in));\\n+    DataType internal_type = internal_type_;\\n+    OP_REQUIRES_OK(\\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\\n+                               dense_list_in, internal_type));\\n \\n     std::vector<std::unique_ptr<ColumnInterface<InternalType>>> columns =\\n         GenerateColumnsFromInput<InternalType>(indices_list_in, values_list_in,\\n@@ -756,6 +790,7 @@ class SparseCrossOp : public OpKernel {\\n  private:\\n   int64 num_buckets_;\\n   uint64 hash_key_;\\n+  DataType internal_type_;\\n };\\n \\n class SparseCrossV2Op : public OpKernel {\\n@@ -773,8 +808,11 @@ class SparseCrossV2Op : public OpKernel {\\n     OP_REQUIRES_OK(context,\\n                    context->input_list(\"dense_inputs\", &dense_list_in));\\n \\n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\\n-                                          shapes_list_in, dense_list_in));\\n+    \/\/ Set internal_type to invalid_type so that the check will be ignored.\\n+    DataType internal_type = DT_INVALID;\\n+    OP_REQUIRES_OK(\\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\\n+                               dense_list_in, internal_type));\\n \\n     const Tensor* sep_t;\\n     OP_REQUIRES_OK(context, context->input(\"sep\", &sep_t));\\n@@ -832,8 +870,11 @@ class SparseCrossHashedOp : public OpKernel {\\n     OP_REQUIRES_OK(context,\\n                    context->input_list(\"dense_inputs\", &dense_list_in));\\n \\n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\\n-                                          shapes_list_in, dense_list_in));\\n+    \/\/ Set internal_type to invalid_type so that the check will be ignored.\\n+    DataType internal_type = DT_INVALID;\\n+    OP_REQUIRES_OK(\\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\\n+                               dense_list_in, internal_type));\\n \\n     const Tensor* num_buckets_t;\\n     OP_REQUIRES_OK(context, context->input(\"num_buckets\", &num_buckets_t));'}}",
            "message_norm":"fix `tf.raw_ops.sparsecross` failing check.\n\npiperorigin-revid: 368701671\nchange-id: id805729dd9ba0bda36e4bb309408129b55fb649d",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('368701671', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_cross_op.cc'])",
            "num_files":1.0,
            "patch_content":"From b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Thu, 15 Apr 2021 13:03:19 -0700\nSubject: [PATCH] Fix `tf.raw_ops.SparseCross` failing CHECK.\n\nPiperOrigin-RevId: 368701671\nChange-Id: Id805729dd9ba0bda36e4bb309408129b55fb649d\n---\n tensorflow\/core\/kernels\/sparse_cross_op.cc | 55 +++++++++++++++++++---\n 1 file changed, 48 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_cross_op.cc b\/tensorflow\/core\/kernels\/sparse_cross_op.cc\nindex 583235b4a309b8..43b3bedc745032 100644\n--- a\/tensorflow\/core\/kernels\/sparse_cross_op.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_cross_op.cc\n@@ -27,6 +27,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/tensor.h\"\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\n #include \"tensorflow\/core\/framework\/types.h\"\n+#include \"tensorflow\/core\/framework\/types.pb.h\"\n #include \"tensorflow\/core\/lib\/core\/stringpiece.h\"\n #include \"tensorflow\/core\/lib\/strings\/str_util.h\"\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\n@@ -460,10 +461,19 @@ int64 CalculateBatchSize(const OpInputList& shapes_list_in,\n Status ValidateInput(const OpInputList& indices_list_in,\n                      const OpInputList& values_list_in,\n                      const OpInputList& shapes_list_in,\n-                     const OpInputList& dense_list_in) {\n+                     const OpInputList& dense_list_in,\n+                     const DataType& internal_type) {\n   const auto size = indices_list_in.size();\n+  \/\/ Only perform internal_type check for SparseCrossOp.\n+  \/\/ Check if the internal_type is not invalid before doing so.\n+  bool check_type = internal_type != DT_INVALID;\n   \/\/ Validates indices_list_in OpInputList.\n   for (int i = 0; i < size; i++) {\n+    if (check_type && indices_list_in[i].dtype() != DT_INT64) {\n+      return errors::InvalidArgument(\"Input indices should be of type \",\n+                                     DT_INT64, \" but received \",\n+                                     indices_list_in[i].dtype());\n+    }\n     if (!TensorShapeUtils::IsMatrix(indices_list_in[i].shape())) {\n       return errors::InvalidArgument(\n           \"Input indices should be a matrix but received shape \",\n@@ -482,6 +492,14 @@ Status ValidateInput(const OpInputList& indices_list_in,\n                                    values_list_in.size());\n   }\n   for (int i = 0; i < size; i++) {\n+    \/\/ Make sure to avoid the expected type to be string, but input values to be\n+    \/\/ int64.\n+    if (check_type && internal_type == DT_STRING &&\n+        values_list_in[i].dtype() == DT_INT64) {\n+      return errors::InvalidArgument(\"Input values should be of internal type \",\n+                                     internal_type, \" but received \",\n+                                     values_list_in[i].dtype());\n+    }\n     if (!TensorShapeUtils::IsVector(values_list_in[i].shape())) {\n       return errors::InvalidArgument(\n           \"Input values should be a vector but received shape \",\n@@ -502,6 +520,11 @@ Status ValidateInput(const OpInputList& indices_list_in,\n                                    shapes_list_in.size());\n   }\n   for (int i = 0; i < size; i++) {\n+    if (check_type && shapes_list_in[i].dtype() != DT_INT64) {\n+      return errors::InvalidArgument(\"Input shape should be of type \", DT_INT64,\n+                                     \" but received \",\n+                                     shapes_list_in[i].dtype());\n+    }\n     if (!TensorShapeUtils::IsVector(shapes_list_in[i].shape())) {\n       return errors::InvalidArgument(\n           \"Input shapes should be a vector but received shape \",\n@@ -517,6 +540,14 @@ Status ValidateInput(const OpInputList& indices_list_in,\n \n   \/\/ Validates dense_list_in OpInputList\n   for (int i = 0; i < dense_list_in.size(); ++i) {\n+    \/\/ Make sure to avoid the expected type to be string, but input values to be\n+    \/\/ int64.\n+    if (check_type && internal_type == DT_STRING &&\n+        dense_list_in[i].dtype() == DT_INT64) {\n+      return errors::InvalidArgument(\"Dense inputs should be of internal type \",\n+                                     internal_type, \" but received \",\n+                                     dense_list_in[i].dtype());\n+    }\n     if (!TensorShapeUtils::IsMatrix(dense_list_in[i].shape())) {\n       return errors::InvalidArgument(\n           \"Dense inputs should be a matrix but received shape \",\n@@ -698,6 +729,7 @@ class SparseCrossOp : public OpKernel {\n     int64 signed_hash_key_;\n     OP_REQUIRES_OK(context, context->GetAttr(\"hash_key\", &signed_hash_key_));\n     hash_key_ = static_cast<uint64>(signed_hash_key_);\n+    OP_REQUIRES_OK(context, context->GetAttr(\"internal_type\", &internal_type_));\n   }\n \n   void Compute(OpKernelContext* context) override {\n@@ -711,8 +743,10 @@ class SparseCrossOp : public OpKernel {\n     OP_REQUIRES_OK(context,\n                    context->input_list(\"dense_inputs\", &dense_list_in));\n \n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\n-                                          shapes_list_in, dense_list_in));\n+    DataType internal_type = internal_type_;\n+    OP_REQUIRES_OK(\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\n+                               dense_list_in, internal_type));\n \n     std::vector<std::unique_ptr<ColumnInterface<InternalType>>> columns =\n         GenerateColumnsFromInput<InternalType>(indices_list_in, values_list_in,\n@@ -756,6 +790,7 @@ class SparseCrossOp : public OpKernel {\n  private:\n   int64 num_buckets_;\n   uint64 hash_key_;\n+  DataType internal_type_;\n };\n \n class SparseCrossV2Op : public OpKernel {\n@@ -773,8 +808,11 @@ class SparseCrossV2Op : public OpKernel {\n     OP_REQUIRES_OK(context,\n                    context->input_list(\"dense_inputs\", &dense_list_in));\n \n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\n-                                          shapes_list_in, dense_list_in));\n+    \/\/ Set internal_type to invalid_type so that the check will be ignored.\n+    DataType internal_type = DT_INVALID;\n+    OP_REQUIRES_OK(\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\n+                               dense_list_in, internal_type));\n \n     const Tensor* sep_t;\n     OP_REQUIRES_OK(context, context->input(\"sep\", &sep_t));\n@@ -832,8 +870,11 @@ class SparseCrossHashedOp : public OpKernel {\n     OP_REQUIRES_OK(context,\n                    context->input_list(\"dense_inputs\", &dense_list_in));\n \n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\n-                                          shapes_list_in, dense_list_in));\n+    \/\/ Set internal_type to invalid_type so that the check will be ignored.\n+    DataType internal_type = DT_INVALID;\n+    OP_REQUIRES_OK(\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\n+                               dense_list_in, internal_type));\n \n     const Tensor* num_buckets_t;\n     OP_REQUIRES_OK(context, context->input(\"num_buckets\", &num_buckets_t));"
        },
        {
            "index":539,
            "vuln_id":"GHSA-jff5-55xj-4jcq",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/307ed31caba68a46426b8c73a787a05add2c7489'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Input During Web Page Generation in Jenkins jenkins before versions 2.44, 2.32.2 is vulnerable to a persisted cross-site scripting in search suggestions due to improperly escaping users with less-than and greater-than characters in their names (SECURITY-388).",
            "published_date":"2022-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/307ed31caba68a46426b8c73a787a05add2c7489",
            "commit_sha":"307ed31caba68a46426b8c73a787a05add2c7489",
            "patch":"SINGLE",
            "chain_ord":"['307ed31caba68a46426b8c73a787a05add2c7489']",
            "before_first_fix_commit":"{'97a61a9fe55f4c16168c123f98301a5173b9fa86', '7ae469770fd10c79bebc07511cd0ab1cafd33292'}",
            "last_fix_commit":"307ed31caba68a46426b8c73a787a05add2c7489",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/10\/2017, 22:21:40",
            "message":"Merge pull request #98 from jenkinsci-cert\/SECURITY-388\n\n[SECURITY-388] Escape metacharacters in the search box",
            "author":"Jesse Glick",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'war\/src\/main\/webapp\/scripts\/hudson-behavior.js': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/307ed31caba68a46426b8c73a787a05add2c7489\/war%2Fsrc%2Fmain%2Fwebapp%2Fscripts%2Fhudson-behavior.js', 'patch': '@@ -2168,6 +2168,7 @@ function createSearchBox(searchURL) {\\n     var ac = new YAHOO.widget.AutoComplete(\"search-box\",\"search-box-completion\",ds);\\n     ac.typeAhead = false;\\n     ac.autoHighlight = false;\\n+    ac.formatResult = ac.formatEscapedResult;\\n \\n     var box   = $(\"search-box\");\\n     var sizer = $(\"search-box-sizer\");'}}",
            "message_norm":"merge pull request #98 from jenkinsci-cert\/security-388\n\n[security-388] escape metacharacters in the search box",
            "language":"en",
            "entities":"[('#98', 'ISSUE', ''), ('security-388', 'SECWORD', ''), ('security-388', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['war\/src\/main\/webapp\/scripts\/hudson-behavior.js'])",
            "num_files":1.0,
            "patch_content":"From 7ae469770fd10c79bebc07511cd0ab1cafd33292 Mon Sep 17 00:00:00 2001\nFrom: Jesse Glick <jglick@cloudbees.com>\nDate: Fri, 6 Jan 2017 14:26:57 -0500\nSubject: [PATCH] [SECURITY-388] Escape metacharacters in the search box.\n\n---\n war\/src\/main\/webapp\/scripts\/hudson-behavior.js | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/war\/src\/main\/webapp\/scripts\/hudson-behavior.js b\/war\/src\/main\/webapp\/scripts\/hudson-behavior.js\nindex 22d85fd27ed9..77a4c41b34e3 100644\n--- a\/war\/src\/main\/webapp\/scripts\/hudson-behavior.js\n+++ b\/war\/src\/main\/webapp\/scripts\/hudson-behavior.js\n@@ -2168,6 +2168,7 @@ function createSearchBox(searchURL) {\n     var ac = new YAHOO.widget.AutoComplete(\"search-box\",\"search-box-completion\",ds);\n     ac.typeAhead = false;\n     ac.autoHighlight = false;\n+    ac.formatResult = ac.formatEscapedResult;\n \n     var box   = $(\"search-box\");\n     var sizer = $(\"search-box-sizer\");"
        },
        {
            "index":352,
            "vuln_id":"GHSA-wvh5-78h5-gmgr",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/moodle\/moodle\/commit\/6abe964bbac41b5e40a81b40962f7044b0dc201e'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in moodle A flaw was found in moodle where ID numbers displayed when bulk allocating markers to assignments required additional sanitizing to prevent a stored XSS risk.",
            "published_date":"2022-05-19",
            "chain_len":1,
            "project":"https:\/\/github.com\/moodle\/moodle",
            "commit_href":"https:\/\/github.com\/moodle\/moodle\/commit\/6abe964bbac41b5e40a81b40962f7044b0dc201e",
            "commit_sha":"6abe964bbac41b5e40a81b40962f7044b0dc201e",
            "patch":"SINGLE",
            "chain_ord":"['6abe964bbac41b5e40a81b40962f7044b0dc201e']",
            "before_first_fix_commit":"{'11b2cc4cb5cf0693414f0e84cb790e487ae33a24'}",
            "last_fix_commit":"6abe964bbac41b5e40a81b40962f7044b0dc201e",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/15\/2022, 00:10:25",
            "message":"MDL-74204 mod_assign: escape identity fields in allocate marker form.",
            "author":"Paul Holden",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'mod\/assign\/classes\/output\/renderer.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/moodle\/moodle\/raw\/6abe964bbac41b5e40a81b40962f7044b0dc201e\/mod%2Fassign%2Fclasses%2Foutput%2Frenderer.php', 'patch': \"@@ -168,7 +168,7 @@ public function render_assign_user_summary(\\\\assign_user_summary $summary) {\\n             $fullname = fullname($summary->user, $summary->viewfullnames);\\n             $extrainfo = array();\\n             foreach ($summary->extrauserfields as $extrafield) {\\n-                $extrainfo[] = $summary->user->$extrafield;\\n+                $extrainfo[] = s($summary->user->$extrafield);\\n             }\\n             if (count($extrainfo)) {\\n                 $fullname .= ' (' . implode(', ', $extrainfo) . ')';\"}}",
            "message_norm":"mdl-74204 mod_assign: escape identity fields in allocate marker form.",
            "language":"en",
            "entities":"[('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['mod\/assign\/classes\/output\/renderer.php'])",
            "num_files":1.0,
            "patch_content":"From 6abe964bbac41b5e40a81b40962f7044b0dc201e Mon Sep 17 00:00:00 2001\nFrom: Paul Holden <paulh@moodle.com>\nDate: Tue, 15 Mar 2022 00:10:25 +0000\nSubject: [PATCH] MDL-74204 mod_assign: escape identity fields in allocate\n marker form.\n\n---\n mod\/assign\/classes\/output\/renderer.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/mod\/assign\/classes\/output\/renderer.php b\/mod\/assign\/classes\/output\/renderer.php\nindex 45e60caf347a6..098fd15c4193e 100644\n--- a\/mod\/assign\/classes\/output\/renderer.php\n+++ b\/mod\/assign\/classes\/output\/renderer.php\n@@ -168,7 +168,7 @@ public function render_assign_user_summary(\\assign_user_summary $summary) {\n             $fullname = fullname($summary->user, $summary->viewfullnames);\n             $extrainfo = array();\n             foreach ($summary->extrauserfields as $extrafield) {\n-                $extrainfo[] = $summary->user->$extrafield;\n+                $extrainfo[] = s($summary->user->$extrafield);\n             }\n             if (count($extrainfo)) {\n                 $fullname .= ' (' . implode(', ', $extrainfo) . ')';"
        },
        {
            "index":425,
            "vuln_id":"GHSA-98gj-wwxm-cj3h",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/lepture\/mistune\/commit\/5f06d724bc05580e7f203db2d4a4905fc1127f98'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects mistune Cross-site scripting (XSS) vulnerability in the _keyify function in mistune.py in Mistune before 0.8.1 allows remote attackers to inject arbitrary web script or HTML by leveraging failure to escape the \"key\" argument.",
            "published_date":"2019-01-04",
            "chain_len":1,
            "project":"https:\/\/github.com\/lepture\/mistune",
            "commit_href":"https:\/\/github.com\/lepture\/mistune\/commit\/5f06d724bc05580e7f203db2d4a4905fc1127f98",
            "commit_sha":"5f06d724bc05580e7f203db2d4a4905fc1127f98",
            "patch":"SINGLE",
            "chain_ord":"['5f06d724bc05580e7f203db2d4a4905fc1127f98']",
            "before_first_fix_commit":"{'7f7f106a717e6cf58012304e56b41d6fb2b98e5f'}",
            "last_fix_commit":"5f06d724bc05580e7f203db2d4a4905fc1127f98",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/20\/2017, 15:15:09",
            "message":"Fix CVE-2017-16876",
            "author":"Hsiaoming Yang",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 3, 'total': 8}",
            "files":"{'mistune.py': {'additions': 5, 'deletions': 3, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/lepture\/mistune\/raw\/5f06d724bc05580e7f203db2d4a4905fc1127f98\/mistune.py', 'patch': \"@@ -11,7 +11,7 @@\\n import re\\n import inspect\\n \\n-__version__ = '0.8'\\n+__version__ = '0.8.1'\\n __author__ = 'Hsiaoming Yang <me@lepture.com>'\\n __all__ = [\\n     'BlockGrammar', 'BlockLexer',\\n@@ -48,7 +48,8 @@ def _pure_pattern(regex):\\n \\n \\n def _keyify(key):\\n-    return _key_pattern.sub(' ', key.lower())\\n+    key = escape(key.lower(), quote=True)\\n+    return _key_pattern.sub(' ', key)\\n \\n \\n def escape(text, quote=False, smart_amp=True):\\n@@ -445,7 +446,8 @@ class InlineGrammar(object):\\n     inline_html = re.compile(\\n         r'^(?:%s|%s|%s)' % (\\n             r'<!--[\\\\s\\\\S]*?-->',\\n-            r'<(\\\\w+%s)((?:%s)*?)\\\\s*>([\\\\s\\\\S]*?)<\\\\\/\\\\1>' % (_valid_end, _valid_attr),\\n+            r'<(\\\\w+%s)((?:%s)*?)\\\\s*>([\\\\s\\\\S]*?)<\\\\\/\\\\1>' % (\\n+                _valid_end, _valid_attr),\\n             r'<\\\\w+%s(?:%s)*?\\\\s*\\\\\/?>' % (_valid_end, _valid_attr),\\n         )\\n     )\"}}",
            "message_norm":"fix cve-2017-16876",
            "language":"fr",
            "entities":"[('fix', 'ACTION', ''), ('cve-2017-16876', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['mistune.py'])",
            "num_files":1.0,
            "patch_content":"From 5f06d724bc05580e7f203db2d4a4905fc1127f98 Mon Sep 17 00:00:00 2001\nFrom: Hsiaoming Yang <me@lepture.com>\nDate: Tue, 21 Nov 2017 00:15:09 +0900\nSubject: [PATCH] Fix CVE-2017-16876\n\n---\n mistune.py | 8 +++++---\n 1 file changed, 5 insertions(+), 3 deletions(-)\n\ndiff --git a\/mistune.py b\/mistune.py\nindex d6ecf7e..5b05fcb 100644\n--- a\/mistune.py\n+++ b\/mistune.py\n@@ -11,7 +11,7 @@\n import re\n import inspect\n \n-__version__ = '0.8'\n+__version__ = '0.8.1'\n __author__ = 'Hsiaoming Yang <me@lepture.com>'\n __all__ = [\n     'BlockGrammar', 'BlockLexer',\n@@ -48,7 +48,8 @@ def _pure_pattern(regex):\n \n \n def _keyify(key):\n-    return _key_pattern.sub(' ', key.lower())\n+    key = escape(key.lower(), quote=True)\n+    return _key_pattern.sub(' ', key)\n \n \n def escape(text, quote=False, smart_amp=True):\n@@ -445,7 +446,8 @@ class InlineGrammar(object):\n     inline_html = re.compile(\n         r'^(?:%s|%s|%s)' % (\n             r'<!--[\\s\\S]*?-->',\n-            r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\\/\\1>' % (_valid_end, _valid_attr),\n+            r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\\/\\1>' % (\n+                _valid_end, _valid_attr),\n             r'<\\w+%s(?:%s)*?\\s*\\\/?>' % (_valid_end, _valid_attr),\n         )\n     )"
        },
        {
            "index":659,
            "vuln_id":"GHSA-5ppx-rgw2-xg23",
            "cwe_id":"{'CWE-79'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/f67068170b55633571e5462e52b6124b23d7cb84'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Input During Web Page Generation in Jenkins Jenkins 2.88 and earlier; 2.73.2 and earlier Autocompletion suggestions for text fields were not escaped, resulting in a persisted cross-site scripting vulnerability if the source for the suggestions allowed specifying text that includes HTML metacharacters like less-than and greater-than characters.",
            "published_date":"2022-05-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/f67068170b55633571e5462e52b6124b23d7cb84",
            "commit_sha":"f67068170b55633571e5462e52b6124b23d7cb84",
            "patch":"SINGLE",
            "chain_ord":"['f67068170b55633571e5462e52b6124b23d7cb84']",
            "before_first_fix_commit":"{'566a8ddb885f0bef9bc848e60455c0aabbf0c1d3'}",
            "last_fix_commit":"f67068170b55633571e5462e52b6124b23d7cb84",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/24\/2017, 16:01:03",
            "message":"[SECURITY-641] Escape autocompletion suggestions",
            "author":"Daniel Beck",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'war\/src\/main\/webapp\/scripts\/hudson-behavior.js': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/f67068170b55633571e5462e52b6124b23d7cb84\/war%2Fsrc%2Fmain%2Fwebapp%2Fscripts%2Fhudson-behavior.js', 'patch': '@@ -712,6 +712,7 @@ var jenkinsRules = {\\n         };\\n         ac.prehighlightClassName = \"yui-ac-prehighlight\";\\n         ac.animSpeed = 0;\\n+        ac.formatResult = ac.formatEscapedResult;\\n         ac.useShadow = true;\\n         ac.autoSnapContainer = true;\\n         ac.delimChar = e.getAttribute(\"autoCompleteDelimChar\");'}}",
            "message_norm":"[security-641] escape autocompletion suggestions",
            "language":"fr",
            "entities":"[('security-641', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['war\/src\/main\/webapp\/scripts\/hudson-behavior.js'])",
            "num_files":1.0,
            "patch_content":"From f67068170b55633571e5462e52b6124b23d7cb84 Mon Sep 17 00:00:00 2001\nFrom: Daniel Beck <daniel-beck@users.noreply.github.com>\nDate: Tue, 24 Oct 2017 12:01:03 -0400\nSubject: [PATCH] [SECURITY-641] Escape autocompletion suggestions\n\n---\n war\/src\/main\/webapp\/scripts\/hudson-behavior.js | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/war\/src\/main\/webapp\/scripts\/hudson-behavior.js b\/war\/src\/main\/webapp\/scripts\/hudson-behavior.js\nindex 5e39b3491125..c63e5782cf76 100644\n--- a\/war\/src\/main\/webapp\/scripts\/hudson-behavior.js\n+++ b\/war\/src\/main\/webapp\/scripts\/hudson-behavior.js\n@@ -712,6 +712,7 @@ var jenkinsRules = {\n         };\n         ac.prehighlightClassName = \"yui-ac-prehighlight\";\n         ac.animSpeed = 0;\n+        ac.formatResult = ac.formatEscapedResult;\n         ac.useShadow = true;\n         ac.autoSnapContainer = true;\n         ac.delimChar = e.getAttribute(\"autoCompleteDelimChar\");"
        },
        {
            "index":17,
            "vuln_id":"GHSA-x28w-hvwc-mp75",
            "cwe_id":"{'CWE-94', 'CWE-96'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/b2baab6e582b2efe63788d367a2bb61a2fa26470'}",
            "dataset":"osv",
            "summary":"Static Code Injection in Microweber Microweber is a new generation CMS with drag and drop. Prior to version 1.3, Microweber is vulnerable to static code injection.",
            "published_date":"2022-03-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/b2baab6e582b2efe63788d367a2bb61a2fa26470",
            "commit_sha":"b2baab6e582b2efe63788d367a2bb61a2fa26470",
            "patch":"SINGLE",
            "chain_ord":"['b2baab6e582b2efe63788d367a2bb61a2fa26470']",
            "before_first_fix_commit":"{'a15da374af81c3cd312ee1639e4c6f56c4839f7e'}",
            "last_fix_commit":"b2baab6e582b2efe63788d367a2bb61a2fa26470",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/09\/2022, 11:13:43",
            "message":"Update ContactInformationTrait.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 4, 'total': 13}",
            "files":"{'src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ContactInformationTrait.php': {'additions': 9, 'deletions': 4, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/b2baab6e582b2efe63788d367a2bb61a2fa26470\/src%2FMicroweberPackages%2FCheckout%2FHttp%2FControllers%2FTraits%2FContactInformationTrait.php', 'patch': \"@@ -36,11 +36,16 @@ public function contactInformation() {\\n \\n     public function contactInformationSave(Request $request) {\\n \\n+        $firstName = strip_tags($request->get('first_name'));\\n+        $lastName = strip_tags($request->get('last_name'));\\n+        $email = strip_tags($request->get('email'));\\n+        $phone = strip_tags($request->get('phone'));\\n+\\n         session_append_array('checkout_v2', [\\n-            'first_name'=> $request->get('first_name'),\\n-            'last_name'=> $request->get('last_name'),\\n-            'email'=> $request->get('email'),\\n-            'phone'=> $request->get('phone')\\n+            'first_name'=> $firstName,\\n+            'last_name'=> $lastName,\\n+            'email'=> $email,\\n+            'phone'=> $phone\\n         ]);\\n \\n         $validate = $this->_validateContactInformation($request->all());\"}}",
            "message_norm":"update contactinformationtrait.php",
            "language":"fr",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ContactInformationTrait.php'])",
            "num_files":1.0,
            "patch_content":"From b2baab6e582b2efe63788d367a2bb61a2fa26470 Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Wed, 9 Mar 2022 13:13:43 +0200\nSubject: [PATCH] Update ContactInformationTrait.php\n\n---\n ...\/Controllers\/Traits\/ContactInformationTrait.php  | 13 +++++++++----\n 1 file changed, 9 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ContactInformationTrait.php b\/src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ContactInformationTrait.php\nindex 626328e59db..c7d679495df 100644\n--- a\/src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ContactInformationTrait.php\n+++ b\/src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ContactInformationTrait.php\n@@ -36,11 +36,16 @@ public function contactInformation() {\n \n     public function contactInformationSave(Request $request) {\n \n+        $firstName = strip_tags($request->get('first_name'));\n+        $lastName = strip_tags($request->get('last_name'));\n+        $email = strip_tags($request->get('email'));\n+        $phone = strip_tags($request->get('phone'));\n+\n         session_append_array('checkout_v2', [\n-            'first_name'=> $request->get('first_name'),\n-            'last_name'=> $request->get('last_name'),\n-            'email'=> $request->get('email'),\n-            'phone'=> $request->get('phone')\n+            'first_name'=> $firstName,\n+            'last_name'=> $lastName,\n+            'email'=> $email,\n+            'phone'=> $phone\n         ]);\n \n         $validate = $this->_validateContactInformation($request->all());"
        },
        {
            "index":805,
            "vuln_id":"GHSA-8434-v7xw-8m9x",
            "cwe_id":"{'CWE-88', 'CWE-78'}",
            "score":9.3,
            "chain":"{'https:\/\/github.com\/dwisiswant0\/apkleaks\/commit\/a966e781499ff6fd4eea66876d7532301b13a382'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Argument Delimiters in a Decompiling Package Process in APKLeaks APKLeaks prior to v2.0.4 allows remote authenticated attackers to execute arbitrary OS commands via package name inside the application manifest.\n\n### Impact\n\nAn authenticated attacker could include arguments that allow unintended commands or code to be executed, allow sensitive data to be read or modified, or could cause other unintended behavior through malicious package names.\n\n\n### References\n\n- a966e781499ff6fd4eea66876d7532301b13a382\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Email me at [me@dw1.io](mailto:me@dw1.io)",
            "published_date":"2022-01-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/dwisiswant0\/apkleaks",
            "commit_href":"https:\/\/github.com\/dwisiswant0\/apkleaks\/commit\/a966e781499ff6fd4eea66876d7532301b13a382",
            "commit_sha":"a966e781499ff6fd4eea66876d7532301b13a382",
            "patch":"SINGLE",
            "chain_ord":"['a966e781499ff6fd4eea66876d7532301b13a382']",
            "before_first_fix_commit":"{'8577b7af6224bf0a5455b552963c46721308d2ff'}",
            "last_fix_commit":"a966e781499ff6fd4eea66876d7532301b13a382",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2021, 15:25:42",
            "message":"Escapes decompiling arguments",
            "author":"Dwi Siswanto",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'apkleaks\/apkleaks.py': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/dwisiswant0\/apkleaks\/raw\/a966e781499ff6fd4eea66876d7532301b13a382\/apkleaks%2Fapkleaks.py', 'patch': '@@ -2,6 +2,7 @@\\n from apkleaks.colors import clr\\n from contextlib import closing\\n from distutils.spawn import find_executable\\n+from pipes import quote\\n from pyaxmlparser import APK\\n from urllib.request import urlopen\\n from zipfile import ZipFile\\n@@ -84,8 +85,9 @@ def decompile(self):\\n \\t\\t\\t\\t\\tclasses.write(zipped.read(\"classes.dex\"))\\n \\t\\t\\texcept Exception as e:\\n \\t\\t\\t\\tsys.exit(self.writeln(str(e), clr.WARNING))\\n-\\t\\tdec = \"%s %s -d %s --deobf\" % (self.jadx, dex, self.tempdir)\\n-\\t\\tos.system(dec)\\n+\\t\\targs = [self.jadx, dex, \"-d\", self.tempdir, \"--deobf\"]\\n+\\t\\tcomm = \"%s\" % (\" \".join(quote(arg) for arg in args))\\n+\\t\\tos.system(comm)\\n \\t\\treturn self.tempdir\\n \\n \\tdef unique(self, list):'}}",
            "message_norm":"escapes decompiling arguments",
            "language":"ca",
            "entities":"[('escapes', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['apkleaks\/apkleaks.py'])",
            "num_files":1.0,
            "patch_content":"From a966e781499ff6fd4eea66876d7532301b13a382 Mon Sep 17 00:00:00 2001\nFrom: Dwi Siswanto <dwi.siswanto98@gmail.com>\nDate: Sun, 14 Mar 2021 22:25:42 +0700\nSubject: [PATCH] Escapes decompiling arguments\n\n---\n apkleaks\/apkleaks.py | 6 ++++--\n 1 file changed, 4 insertions(+), 2 deletions(-)\n\ndiff --git a\/apkleaks\/apkleaks.py b\/apkleaks\/apkleaks.py\nindex c51c75e..e1e084f 100644\n--- a\/apkleaks\/apkleaks.py\n+++ b\/apkleaks\/apkleaks.py\n@@ -2,6 +2,7 @@\n from apkleaks.colors import clr\n from contextlib import closing\n from distutils.spawn import find_executable\n+from pipes import quote\n from pyaxmlparser import APK\n from urllib.request import urlopen\n from zipfile import ZipFile\n@@ -84,8 +85,9 @@ def decompile(self):\n \t\t\t\t\tclasses.write(zipped.read(\"classes.dex\"))\n \t\t\texcept Exception as e:\n \t\t\t\tsys.exit(self.writeln(str(e), clr.WARNING))\n-\t\tdec = \"%s %s -d %s --deobf\" % (self.jadx, dex, self.tempdir)\n-\t\tos.system(dec)\n+\t\targs = [self.jadx, dex, \"-d\", self.tempdir, \"--deobf\"]\n+\t\tcomm = \"%s\" % (\" \".join(quote(arg) for arg in args))\n+\t\tos.system(comm)\n \t\treturn self.tempdir\n \n \tdef unique(self, list):"
        },
        {
            "index":688,
            "vuln_id":"GHSA-cwpm-f78v-7m5c",
            "cwe_id":"{'CWE-400', 'CWE-20'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bd4d5583ff9c8df26d47a23e508208844297310e'}",
            "dataset":"osv",
            "summary":"Denial of service in `tf.ragged.constant` due to lack of validation ### Impact\nThe implementation of [`tf.ragged.constant`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f3b9bf4c3c0597563b289c0512e98d4ce81f886e\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py#L146-L239) does not fully validate the input arguments. This results in a denial of service by consuming all available memory:\n\n```python\nimport tensorflow as tf\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [bd4d5583ff9c8df26d47a23e508208844297310e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bd4d5583ff9c8df26d47a23e508208844297310e).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [GitHub issue](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/55199).",
            "published_date":"2022-05-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bd4d5583ff9c8df26d47a23e508208844297310e",
            "commit_sha":"bd4d5583ff9c8df26d47a23e508208844297310e",
            "patch":"SINGLE",
            "chain_ord":"['bd4d5583ff9c8df26d47a23e508208844297310e']",
            "before_first_fix_commit":"{'e74ef072ecd54ca54f3940ce9b98af796ded2a1a'}",
            "last_fix_commit":"bd4d5583ff9c8df26d47a23e508208844297310e",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/15\/2022, 16:11:43",
            "message":"Prevent denial of service in `tf.ragged.constant`\n\nFixes #55199\n\nPiperOrigin-RevId: 442029525",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/bd4d5583ff9c8df26d47a23e508208844297310e\/tensorflow%2Fpython%2Fops%2Fragged%2Fragged_factory_ops.py', 'patch': '@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\\n     if max_depth > scalar_depth:\\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\\n                        \"than scalar value nesting\" % pylist)\\n+    if ragged_rank is not None and max_depth < ragged_rank:\\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\\n+                       f\"ragged_rank={ragged_rank}\")\\n \\n   # If both inner_shape and ragged_rank were specified, then check that\\n   # they are compatible with pylist.'}}",
            "message_norm":"prevent denial of service in `tf.ragged.constant`\n\nfixes #55199\n\npiperorigin-revid: 442029525",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('denial of service', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#55199', 'ISSUE', ''), ('442029525', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py'])",
            "num_files":1.0,
            "patch_content":"From bd4d5583ff9c8df26d47a23e508208844297310e Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 15 Apr 2022 09:11:43 -0700\nSubject: [PATCH] Prevent denial of service in `tf.ragged.constant`\n\nFixes #55199\n\nPiperOrigin-RevId: 442029525\n---\n tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py b\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py\nindex a1906c469beb46..457b3a04618a81 100644\n--- a\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py\n+++ b\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py\n@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist."
        },
        {
            "index":462,
            "vuln_id":"GHSA-h6rj-8r3c-9gpj",
            "cwe_id":"{'CWE-400'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/mongodb\/bson-ruby\/commit\/976da329ff03ecdfca3030eb6efe3c85e6db9999'}",
            "dataset":"osv",
            "summary":"bson is vulnerable to denial of service due to incorrect regex validation BSON injection vulnerability in the legal? function in BSON (bson-ruby) gem before 3.0.4 for Ruby allows remote attackers to cause a denial of service (resource consumption) or inject arbitrary data via a crafted string.",
            "published_date":"2018-03-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/mongodb\/bson-ruby",
            "commit_href":"https:\/\/github.com\/mongodb\/bson-ruby\/commit\/976da329ff03ecdfca3030eb6efe3c85e6db9999",
            "commit_sha":"976da329ff03ecdfca3030eb6efe3c85e6db9999",
            "patch":"SINGLE",
            "chain_ord":"['976da329ff03ecdfca3030eb6efe3c85e6db9999']",
            "before_first_fix_commit":"{'7446d7c6764dfda8dc4480ce16d5c023e74be5ca'}",
            "last_fix_commit":"976da329ff03ecdfca3030eb6efe3c85e6db9999",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/04\/2015, 04:19:42",
            "message":"Use \\A \\z for checking regex on legal",
            "author":"Durran Jordan",
            "comments":"{'com_1': {'author': 'judofyr', 'datetime': '06\/04\/2015, 16:53:06', 'body': 'Yay! Thanks for a quick patch.'}, 'com_2': {'author': 'cheald', 'datetime': '06\/04\/2015, 19:17:08', 'body': \"Is the 1.x series going to see a patch? Users who aren't using bson_ext (such as users on JRuby) are still vulnerable.\"}, 'com_3': {'author': 'estolfo', 'datetime': '06\/04\/2015, 19:19:06', 'body': 'Yes, it will be released this afternoon.'}, 'com_4': {'author': 'estolfo', 'datetime': '06\/04\/2015, 19:20:30', 'body': \"It's in master already.\"}, 'com_5': {'author': 'cheald', 'datetime': '06\/04\/2015, 19:21:58', 'body': 'Perfect, thanks. https:\/\/github.com\/mongodb\/mongo-ruby-driver\/blob\/1.x-stable\/lib\/bson\/types\/object_id.rb for anyone else who ends up here looking for it, like me. :)'}, 'com_6': {'author': 'estolfo', 'datetime': '06\/04\/2015, 20:44:37', 'body': 'mongo 1.12.3 and bson 1.12.3 are released with this fix.'}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/bson\/object_id.rb': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mongodb\/bson-ruby\/raw\/976da329ff03ecdfca3030eb6efe3c85e6db9999\/lib%2Fbson%2Fobject_id.rb', 'patch': '@@ -282,7 +282,7 @@ def from_time(time, options = {})\\n       #\\n       # @since 2.0.0\\n       def legal?(string)\\n-        string.to_s =~ \/^[0-9a-f]{24}$\/i ? true : false\\n+        string.to_s =~ \/\\\\A[0-9a-f]{24}\\\\z\/i ? true : false\\n       end\\n \\n       # Executes the provided block only if the size of the provided object is'}}",
            "message_norm":"use \\a \\z for checking regex on legal",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/bson\/object_id.rb'])",
            "num_files":1.0,
            "patch_content":"From 976da329ff03ecdfca3030eb6efe3c85e6db9999 Mon Sep 17 00:00:00 2001\nFrom: Durran Jordan <durran@gmail.com>\nDate: Thu, 4 Jun 2015 00:19:42 -0400\nSubject: [PATCH] Use \\A \\z for checking regex on legal\n\n---\n lib\/bson\/object_id.rb | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/bson\/object_id.rb b\/lib\/bson\/object_id.rb\nindex d39314465..b8503f3b4 100644\n--- a\/lib\/bson\/object_id.rb\n+++ b\/lib\/bson\/object_id.rb\n@@ -282,7 +282,7 @@ def from_time(time, options = {})\n       #\n       # @since 2.0.0\n       def legal?(string)\n-        string.to_s =~ \/^[0-9a-f]{24}$\/i ? true : false\n+        string.to_s =~ \/\\A[0-9a-f]{24}\\z\/i ? true : false\n       end\n \n       # Executes the provided block only if the size of the provided object is"
        },
        {
            "index":435,
            "vuln_id":"GHSA-94qw-r73x-j7hg",
            "cwe_id":"{'CWE-285'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/opencast\/opencast\/commit\/72fad0031d8a82c860e2bde0b27570c5042320ee'}",
            "dataset":"osv",
            "summary":"Users with ROLE_COURSE_ADMIN can create new users in Opencast ### Impact\n\nUsers with the role `ROLE_COURSE_ADMIN` can use the user-utils endpoint to create new users not including the role `ROLE_ADMIN`. For example:\n\n```bash\n# Use the admin to create a new user with ROLE_COURSE_ADMIN using the admin user.\n# We expect this to work.\n% curl -i -u admin:opencast 'https:\/\/example.opencast.org\/user-utils\/xy.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n\n# Use the new user to create more new users.\n# We don't exp\u00fcect a user with just role ROLE_COURSE_ADMIN to succeed.\n# But it does work\n% curl -i -u xy:f 'https:\/\/example.opencast.org\/user-utils\/ab.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n```\n`ROLE_COURSE_ADMIN` is a non-standard role in Opencast which is referenced neither in the documentation nor in any code (except for tests) but only in the security configuration. From the name \u2013 implying an admin for a specific course \u2013 users would never expect that this role allows user creation.\n\n### Patches\n\nThis issue is fixed in 7.6 and 8.1 which both ship a new default security configuration.\n\n### Workarounds\n\nYou can fix this issue by removing all instances of `ROLE_COURSE_ADMIN` in your organization's security configuration (`etc\/security\/mh_default_org.xml` by default).\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n- Open an issue in [opencast\/opencast](https:\/\/github.com\/opencast\/opencast\/issues)\n- For security-relevant information, email us at security@opencast.org",
            "published_date":"2020-01-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/opencast\/opencast",
            "commit_href":"https:\/\/github.com\/opencast\/opencast\/commit\/72fad0031d8a82c860e2bde0b27570c5042320ee",
            "commit_sha":"72fad0031d8a82c860e2bde0b27570c5042320ee",
            "patch":"SINGLE",
            "chain_ord":"['72fad0031d8a82c860e2bde0b27570c5042320ee']",
            "before_first_fix_commit":"{'b157e1fb3b35991ca7bf59f0730329fbe7ce82e8'}",
            "last_fix_commit":"72fad0031d8a82c860e2bde0b27570c5042320ee",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/16\/2020, 15:40:23",
            "message":"Remove ROLE_COURSE_ADMIN\n\nUsers with the role `ROLE_COURSE_ADMIN` can use the user-utils endpoint\nto create new users not including the role ROLE_ADMIN. For example:\n\n```sh\n% curl -i -u admin:opencast 'https:\/\/example.opencast.org\/user-utils\/xy.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n\n% curl -i -u xy:f 'https:\/\/example.opencast.org\/user-utils\/ab.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n```\n\n`ROLE_COURSE_ADMIN` is a non-standard role in Opencast which is\nreferenced neither in the documentation nor in any code (except for\ntests) but only in the security configuration. From the name \u2013 implying\nan admin for a specific course \u2013 users would never expect that this role\nallows user creation.\n\nThis patch fixes the problem by dropping the default access rules for\n`ROLE_COURSE_ADMIN`. Users which use and need this custom role can\neasily configure this specific to their needs. There is no reason to\nship this by default.",
            "author":"Lars Kiesow",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 5, 'total': 10}",
            "files":"{'etc\/security\/mh_default_org.xml': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencast\/opencast\/raw\/72fad0031d8a82c860e2bde0b27570c5042320ee\/etc%2Fsecurity%2Fmh_default_org.xml', 'patch': '@@ -297,11 +297,11 @@\\n     <sec:intercept-url pattern=\"\/transcripts\/watson\/results*\" method=\"POST\" access=\"ROLE_ANONYMOUS\" \/>\\n \\n     <!-- Everything else is for the admin users -->\\n-    <sec:intercept-url pattern=\"\/admin-ng\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\\n-    <sec:intercept-url pattern=\"\/admin-ng\/\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\\n-    <sec:intercept-url pattern=\"\/admin-ng\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\\n-    <sec:intercept-url pattern=\"\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\\n-    <sec:intercept-url pattern=\"\/**\" access=\"ROLE_ADMIN, ROLE_COURSE_ADMIN\" \/>\\n+    <sec:intercept-url pattern=\"\/admin-ng\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\\n+    <sec:intercept-url pattern=\"\/admin-ng\/\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\\n+    <sec:intercept-url pattern=\"\/admin-ng\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\\n+    <sec:intercept-url pattern=\"\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\\n+    <sec:intercept-url pattern=\"\/**\" access=\"ROLE_ADMIN\" \/>\\n \\n     <!-- ############################# -->\\n     <!-- # LOGIN \/ LOGOUT MECHANISMS # -->'}}",
            "message_norm":"remove role_course_admin\n\nusers with the role `role_course_admin` can use the user-utils endpoint\nto create new users not including the role role_admin. for example:\n\n```sh\n% curl -i -u admin:opencast 'https:\/\/example.opencast.org\/user-utils\/xy.json' -x put \\\n  --data 'password=f&roles=%5b%22role_course_admin%22%5d'\nhttp\/2 201\n\n% curl -i -u xy:f 'https:\/\/example.opencast.org\/user-utils\/ab.json' -x put \\\n  --data 'password=f&roles=%5b%22role_course_admin%22%5d'\nhttp\/2 201\n```\n\n`role_course_admin` is a non-standard role in opencast which is\nreferenced neither in the documentation nor in any code (except for\ntests) but only in the security configuration. from the name \u2013 implying\nan admin for a specific course \u2013 users would never expect that this role\nallows user creation.\n\nthis patch fixes the problem by dropping the default access rules for\n`role_course_admin`. users which use and need this custom role can\neasily configure this specific to their needs. there is no reason to\nship this by default.",
            "language":"en",
            "entities":"[('remove', 'ACTION', ''), ('role_course_admin', 'SECWORD', ''), ('role_course_admin', 'SECWORD', ''), ('role_admin', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('https:\/\/example.opencast.org\/user-utils\/xy.json', 'URL', ''), ('password', 'SECWORD', ''), ('f&roles=%5b%22role_course_admin%22%5d', 'SECWORD', ''), ('https:\/\/example.opencast.org\/user-utils\/ab.json', 'URL', ''), ('password', 'SECWORD', ''), ('f&roles=%5b%22role_course_admin%22%5d', 'SECWORD', ''), ('role_course_admin', 'SECWORD', ''), ('security', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('problem', 'FLAW', ''), ('role_course_admin', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['etc\/security\/mh_default_org.xml'])",
            "num_files":1.0,
            "patch_content":"From 72fad0031d8a82c860e2bde0b27570c5042320ee Mon Sep 17 00:00:00 2001\nFrom: Lars Kiesow <lkiesow@uos.de>\nDate: Thu, 16 Jan 2020 16:40:23 +0100\nSubject: [PATCH] Remove ROLE_COURSE_ADMIN\nMIME-Version: 1.0\nContent-Type: text\/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\n\nUsers with the role `ROLE_COURSE_ADMIN` can use the user-utils endpoint\nto create new users not including the role ROLE_ADMIN. For example:\n\n```sh\n% curl -i -u admin:opencast 'https:\/\/example.opencast.org\/user-utils\/xy.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n\n% curl -i -u xy:f 'https:\/\/example.opencast.org\/user-utils\/ab.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n```\n\n`ROLE_COURSE_ADMIN` is a non-standard role in Opencast which is\nreferenced neither in the documentation nor in any code (except for\ntests) but only in the security configuration. From the name \u2013 implying\nan admin for a specific course \u2013 users would never expect that this role\nallows user creation.\n\nThis patch fixes the problem by dropping the default access rules for\n`ROLE_COURSE_ADMIN`. Users which use and need this custom role can\neasily configure this specific to their needs. There is no reason to\nship this by default.\n---\n etc\/security\/mh_default_org.xml | 10 +++++-----\n 1 file changed, 5 insertions(+), 5 deletions(-)\n\ndiff --git a\/etc\/security\/mh_default_org.xml b\/etc\/security\/mh_default_org.xml\nindex e1f03ad938f..9364ee605db 100644\n--- a\/etc\/security\/mh_default_org.xml\n+++ b\/etc\/security\/mh_default_org.xml\n@@ -297,11 +297,11 @@\n     <sec:intercept-url pattern=\"\/transcripts\/watson\/results*\" method=\"POST\" access=\"ROLE_ANONYMOUS\" \/>\n \n     <!-- Everything else is for the admin users -->\n-    <sec:intercept-url pattern=\"\/admin-ng\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\n-    <sec:intercept-url pattern=\"\/admin-ng\/\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\n-    <sec:intercept-url pattern=\"\/admin-ng\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\n-    <sec:intercept-url pattern=\"\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\n-    <sec:intercept-url pattern=\"\/**\" access=\"ROLE_ADMIN, ROLE_COURSE_ADMIN\" \/>\n+    <sec:intercept-url pattern=\"\/admin-ng\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\n+    <sec:intercept-url pattern=\"\/admin-ng\/\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\n+    <sec:intercept-url pattern=\"\/admin-ng\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\n+    <sec:intercept-url pattern=\"\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\n+    <sec:intercept-url pattern=\"\/**\" access=\"ROLE_ADMIN\" \/>\n \n     <!-- ############################# -->\n     <!-- # LOGIN \/ LOGOUT MECHANISMS # -->"
        },
        {
            "index":107,
            "vuln_id":"GHSA-hwj9-h5mp-3pm3",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734', 'https:\/\/github.com\/postcss\/postcss\/commit\/b6f3e4d5a8d7504d553267f80384373af3a3dec5', 'https:\/\/github.com\/postcss\/postcss\/commit\/8682b1e4e328432ba692bed52326e84439cec9e4'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in postcss The npm package `postcss` from 7.0.0 and before versions 7.0.36 and 8.2.10 is vulnerable to Regular Expression Denial of Service (ReDoS) during source map parsing.",
            "published_date":"2021-05-10",
            "chain_len":3,
            "project":"https:\/\/github.com\/postcss\/postcss",
            "commit_href":"https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734",
            "commit_sha":"54cbf3c4847eb0fb1501b9d2337465439e849734",
            "patch":"MULTI",
            "chain_ord":"['8682b1e4e328432ba692bed52326e84439cec9e4', 'b6f3e4d5a8d7504d553267f80384373af3a3dec5', '54cbf3c4847eb0fb1501b9d2337465439e849734']",
            "before_first_fix_commit":"{'12832f3d203474bd273bd06bd3b2407567bfe09e'}",
            "last_fix_commit":"54cbf3c4847eb0fb1501b9d2337465439e849734",
            "chain_ord_pos":3.0,
            "commit_datetime":"06\/11\/2021, 02:38:48",
            "message":"Backport ReDoS vulnerabilities from PostCSS 8",
            "author":"Andrey Sitnik",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'lib\/previous-map.es6': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/postcss\/postcss\/raw\/54cbf3c4847eb0fb1501b9d2337465439e849734\/lib%2Fprevious-map.es6', 'patch': '@@ -73,12 +73,14 @@ class PreviousMap {\\n \\n   getAnnotationURL (sourceMapString) {\\n     return sourceMapString\\n-      .match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\s*\\\\*\\\\\/\/)[1]\\n+      .match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\\\*\\\\\/\/)[1]\\n       .trim()\\n   }\\n \\n   loadAnnotation (css) {\\n-    let annotations = css.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\s*\\\\*\\\\\/\/mg)\\n+    let annotations = css.match(\\n+      \/\\\\\/\\\\*\\\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\\\*\\\\\/\/gm\\n+    )\\n \\n     if (annotations && annotations.length > 0) {\\n       \/\/ Locate the last sourceMappingURL to avoid picking up'}}",
            "message_norm":"backport redos vulnerabilities from postcss 8",
            "language":"en",
            "entities":"[('redos', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/previous-map.es6'])",
            "num_files":1.0,
            "patch_content":"From 54cbf3c4847eb0fb1501b9d2337465439e849734 Mon Sep 17 00:00:00 2001\nFrom: Andrey Sitnik <andrey@sitnik.ru>\nDate: Thu, 10 Jun 2021 22:38:48 -0400\nSubject: [PATCH] Backport ReDoS vulnerabilities from PostCSS 8\n\n---\n lib\/previous-map.es6 | 6 ++++--\n 1 file changed, 4 insertions(+), 2 deletions(-)\n\ndiff --git a\/lib\/previous-map.es6 b\/lib\/previous-map.es6\nindex 2f36f0aef..d2c44b814 100644\n--- a\/lib\/previous-map.es6\n+++ b\/lib\/previous-map.es6\n@@ -73,12 +73,14 @@ class PreviousMap {\n \n   getAnnotationURL (sourceMapString) {\n     return sourceMapString\n-      .match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\s*\\*\\\/\/)[1]\n+      .match(\/\\\/\\*\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\*\\\/\/)[1]\n       .trim()\n   }\n \n   loadAnnotation (css) {\n-    let annotations = css.match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\s*\\*\\\/\/mg)\n+    let annotations = css.match(\n+      \/\\\/\\*\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\*\\\/\/gm\n+    )\n \n     if (annotations && annotations.length > 0) {\n       \/\/ Locate the last sourceMappingURL to avoid picking up"
        },
        {
            "index":796,
            "vuln_id":"GHSA-gmh3-x5w7-jg5m",
            "cwe_id":"{'CWE-79'}",
            "score":6.3,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/79c6914bab8c9da07ac950fda17648d08c68b130'}",
            "dataset":"osv",
            "summary":"Microweber before v1.2.20 vulnerable to cross-site scripting Prior to Microweber v1.2.20, due to improper neutralization of input, an attacker can steal tokens to perform cross-site request forgery (CSRF), fetch contents from same-site and redirect a user.",
            "published_date":"2022-07-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/79c6914bab8c9da07ac950fda17648d08c68b130",
            "commit_sha":"79c6914bab8c9da07ac950fda17648d08c68b130",
            "patch":"SINGLE",
            "chain_ord":"['79c6914bab8c9da07ac950fda17648d08c68b130']",
            "before_first_fix_commit":"{'d35e691e72d358430abc8e99f5ba9eb374423b9f'}",
            "last_fix_commit":"79c6914bab8c9da07ac950fda17648d08c68b130",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/08\/2022, 17:31:13",
            "message":"update",
            "author":"Peter Ivanov",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 2, 'total': 16}",
            "files":"{'userfiles\/modules\/microweber\/toolbar\/editor_tools\/module_settings\/index.php': {'additions': 14, 'deletions': 2, 'changes': 16, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/79c6914bab8c9da07ac950fda17648d08c68b130\/userfiles%2Fmodules%2Fmicroweber%2Ftoolbar%2Feditor_tools%2Fmodule_settings%2Findex.php', 'patch': '@@ -87,14 +87,24 @@\\n     if (isset($_GET[\\'autosize\\'])) {\\n         $autoSize = $_GET[\\'autosize\\'];\\n     }\\n-    $autoSize = xss_clean($autoSize);\\n+    $autoSize = intval($autoSize);\\n \\n     $type = \\'\\';\\n     if (isset($_GET[\\'type\\'])) {\\n         $type = $_GET[\\'type\\'];\\n     }\\n     $type = xss_clean($type);\\n \\n+            $other = [\\n+                \\';\\',\\n+                \\'\\\\\\'\\',\\n+                \\'\/\/\\',\\n+                \\'`\\',\\n+                \\'\\\\\\\\\\',\\n+\\n+            ];\\n+    $type = str_replace($other, \\'\\', $type);\\n+\\n     $mod_id = $mod_orig_id = false;\\n     $is_linked_mod = false;\\n \\n@@ -108,6 +118,8 @@\\n     if ($mod_id != $mod_orig_id) {\\n         $is_linked_mod = true;\\n     }\\n+\\n+\\n     ?>\\n \\n     <script type=\"text\/javascript\">\\n@@ -124,7 +136,7 @@\\n         addIcon();\\n \\n         autoSize = <?php  print $autoSize; ?>;\\n-        settingsType = \\'<?php print $type; ?>\\';\\n+        settingsType = \\'<?php print htmlentities($type); ?>\\';\\n \\n         window.onbeforeunload = function () {\\n             $(document.body).addClass(\"mw-external-loading\")'}}",
            "message_norm":"update",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['userfiles\/modules\/microweber\/toolbar\/editor_tools\/module_settings\/index.php'])",
            "num_files":1.0,
            "patch_content":"From 79c6914bab8c9da07ac950fda17648d08c68b130 Mon Sep 17 00:00:00 2001\nFrom: Peter Ivanov <peter@microweber.com>\nDate: Fri, 8 Jul 2022 20:31:13 +0300\nSubject: [PATCH] update\n\n---\n ...\/editor_tools\/module_settings\/index.php       | 16 ++++++++++++++--\n 1 file changed, 14 insertions(+), 2 deletions(-)\n\ndiff --git a\/userfiles\/modules\/microweber\/toolbar\/editor_tools\/module_settings\/index.php b\/userfiles\/modules\/microweber\/toolbar\/editor_tools\/module_settings\/index.php\nindex a6bc6821ccd..b8a55eed45d 100644\n--- a\/userfiles\/modules\/microweber\/toolbar\/editor_tools\/module_settings\/index.php\n+++ b\/userfiles\/modules\/microweber\/toolbar\/editor_tools\/module_settings\/index.php\n@@ -87,7 +87,7 @@\n     if (isset($_GET['autosize'])) {\n         $autoSize = $_GET['autosize'];\n     }\n-    $autoSize = xss_clean($autoSize);\n+    $autoSize = intval($autoSize);\n \n     $type = '';\n     if (isset($_GET['type'])) {\n@@ -95,6 +95,16 @@\n     }\n     $type = xss_clean($type);\n \n+            $other = [\n+                ';',\n+                '\\'',\n+                '\/\/',\n+                '`',\n+                '\\\\',\n+\n+            ];\n+    $type = str_replace($other, '', $type);\n+\n     $mod_id = $mod_orig_id = false;\n     $is_linked_mod = false;\n \n@@ -108,6 +118,8 @@\n     if ($mod_id != $mod_orig_id) {\n         $is_linked_mod = true;\n     }\n+\n+\n     ?>\n \n     <script type=\"text\/javascript\">\n@@ -124,7 +136,7 @@\n         addIcon();\n \n         autoSize = <?php  print $autoSize; ?>;\n-        settingsType = '<?php print $type; ?>';\n+        settingsType = '<?php print htmlentities($type); ?>';\n \n         window.onbeforeunload = function () {\n             $(document.body).addClass(\"mw-external-loading\")"
        },
        {
            "index":625,
            "vuln_id":"GHSA-f655-xhvm-cwp4",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/jenkinsci\/gitlab-plugin\/commit\/24e9a99d8151b5345109ef12cddc1ab323baa4ee'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Jenkins GitLab Plugin Jenkins GitLab Plugin 1.5.34 and earlier does not escape multiple fields inserted into the description of webhook-triggered builds, resulting in a stored cross-site scripting (XSS) vulnerability exploitable by attackers with Item\/Configure permission.",
            "published_date":"2022-07-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/gitlab-plugin",
            "commit_href":"https:\/\/github.com\/jenkinsci\/gitlab-plugin\/commit\/24e9a99d8151b5345109ef12cddc1ab323baa4ee",
            "commit_sha":"24e9a99d8151b5345109ef12cddc1ab323baa4ee",
            "patch":"SINGLE",
            "chain_ord":"['24e9a99d8151b5345109ef12cddc1ab323baa4ee']",
            "before_first_fix_commit":"{'316f8aa1190c646e0cddf6614e3d881d1490be7f'}",
            "last_fix_commit":"24e9a99d8151b5345109ef12cddc1ab323baa4ee",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/29\/2022, 15:15:16",
            "message":"[SECURITY-2316]",
            "author":"Daniel Beck",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'src\/main\/resources\/com\/dabsquared\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/gitlab-plugin\/raw\/24e9a99d8151b5345109ef12cddc1ab323baa4ee\/src%2Fmain%2Fresources%2Fcom%2Fdabsquared%2Fgitlabjenkins%2Fcause%2FGitLabWebHookCause%2Fdescription.jelly', 'patch': '@@ -1,4 +1,5 @@\\n <?jelly escape-by-default=\\'true\\'?>\\n <j:jelly xmlns:j=\"jelly:core\">\\n-  <span><j:out value=\"${it.shortDescription}\" \/><\/span>\\n+  <!-- SECURITY-2316: This used to show the HTML-formatted it.shortDescription, but that does not properly neutralize user-provided input -->\\n+  <span>Triggered by GitLab Webhook<\/span>\\n <\/j:jelly>'}}",
            "message_norm":"[security-2316]",
            "language":"en",
            "entities":"[('security-2316', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/resources\/com\/dabsquared\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly'])",
            "num_files":1.0,
            "patch_content":"From 24e9a99d8151b5345109ef12cddc1ab323baa4ee Mon Sep 17 00:00:00 2001\nFrom: Daniel Beck <daniel-beck@users.noreply.github.com>\nDate: Wed, 29 Jun 2022 17:15:16 +0200\nSubject: [PATCH] [SECURITY-2316]\n\n---\n ...\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly   | 3 ++-\n 1 file changed, 2 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/main\/resources\/com\/dabsquared\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly b\/src\/main\/resources\/com\/dabsquared\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly\nindex 37e85ef37..1c0244b0d 100644\n--- a\/src\/main\/resources\/com\/dabsquared\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly\n+++ b\/src\/main\/resources\/com\/dabsquared\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly\n@@ -1,4 +1,5 @@\n <?jelly escape-by-default='true'?>\n <j:jelly xmlns:j=\"jelly:core\">\n-  <span><j:out value=\"${it.shortDescription}\" \/><\/span>\n+  <!-- SECURITY-2316: This used to show the HTML-formatted it.shortDescription, but that does not properly neutralize user-provided input -->\n+  <span>Triggered by GitLab Webhook<\/span>\n <\/j:jelly>"
        },
        {
            "index":145,
            "vuln_id":"GHSA-85wq-pqhp-hmq6",
            "cwe_id":"{'CWE-352'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/3c5e5ca63d9a1ac1c4087682dc0d426625eafed8', 'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/e69c28e44dae41322112471e1c80f840bde314d4', 'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/23f4809e6c10a221e9d67f2e841536845387b42d'}",
            "dataset":"osv",
            "summary":"Cross-Site Request Forgery in Jenkins Jenkins versions 2.56 and earlier as well as 2.46.1 LTS and earlier are vulnerable to an issue in the Jenkins user database authentication realm: create an account if signup is enabled; or create an account if the victim is an administrator, possibly deleting the existing default admin user in the process and allowing a wide variety of impacts.",
            "published_date":"2022-05-14",
            "chain_len":3,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/23f4809e6c10a221e9d67f2e841536845387b42d",
            "commit_sha":"23f4809e6c10a221e9d67f2e841536845387b42d",
            "patch":"MULTI",
            "chain_ord":"['3c5e5ca63d9a1ac1c4087682dc0d426625eafed8', 'e69c28e44dae41322112471e1c80f840bde314d4', '23f4809e6c10a221e9d67f2e841536845387b42d']",
            "before_first_fix_commit":"{'eeb699ed8c2ce937f2b836692b36a98da7bb5622'}",
            "last_fix_commit":"23f4809e6c10a221e9d67f2e841536845387b42d",
            "chain_ord_pos":3.0,
            "commit_datetime":"04\/13\/2017, 13:01:32",
            "message":"[SECURITY-412] Simplify implementation as suggested by jglick",
            "author":"Daniel Beck",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 16, 'total': 20}",
            "files":"{'core\/src\/main\/java\/jenkins\/model\/Jenkins.java': {'additions': 4, 'deletions': 16, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/23f4809e6c10a221e9d67f2e841536845387b42d\/core%2Fsrc%2Fmain%2Fjava%2Fjenkins%2Fmodel%2FJenkins.java', 'patch': '@@ -3369,53 +3369,41 @@ public DirectoryBrowserSupport doUserContent() {\\n      *\\n      * This first replaces \"app\" to {@link HudsonIsRestarting}\\n      *\/\\n+    @CLIMethod(name=\"restart\")\\n     public void doRestart(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException, RestartNotSupportedException {\\n         checkPermission(ADMINISTER);\\n         if (req != null && req.getMethod().equals(\"GET\")) {\\n             req.getView(this,\"_restart.jelly\").forward(req,rsp);\\n             return;\\n         }\\n \\n-        if (req != null && req.getMethod().equals(\"POST\")) {\\n+        if (req == null || req.getMethod().equals(\"POST\")) {\\n             restart();\\n         }\\n \\n         rsp.sendRedirect2(\".\");\\n     }\\n \\n-    @CLIMethod(name=\"restart\")\\n-    @Restricted(NoExternalUse.class)\\n-    public void cliRestart() throws RestartNotSupportedException {\\n-        checkPermission(ADMINISTER);\\n-        restart();\\n-    }\\n-\\n     \/**\\n      * Queues up a restart of Jenkins for when there are no builds running, if we can.\\n      *\\n      * This first replaces \"app\" to {@link HudsonIsRestarting}\\n      *\\n      * @since 1.332\\n      *\/\\n+    @CLIMethod(name=\"safe-restart\")\\n     public HttpResponse doSafeRestart(StaplerRequest req) throws IOException, ServletException, RestartNotSupportedException {\\n         checkPermission(ADMINISTER);\\n         if (req != null && req.getMethod().equals(\"GET\"))\\n             return HttpResponses.forwardToView(this,\"_safeRestart.jelly\");\\n \\n-        if (req != null && req.getMethod().equals(\"POST\")) {\\n+        if (req == null || req.getMethod().equals(\"POST\")) {\\n             safeRestart();\\n         }\\n \\n         return HttpResponses.redirectToDot();\\n     }\\n \\n-    @CLIMethod(name=\"safe-restart\")\\n-    @Restricted(NoExternalUse.class)\\n-    public void cliSafeRestart() throws RestartNotSupportedException {\\n-        checkPermission(ADMINISTER);\\n-        safeRestart();\\n-    }\\n-\\n     \/**\\n      * Performs a restart.\\n      *\/'}}",
            "message_norm":"[security-412] simplify implementation as suggested by jglick",
            "language":"en",
            "entities":"[('security-412', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/src\/main\/java\/jenkins\/model\/Jenkins.java'])",
            "num_files":1.0,
            "patch_content":"From 23f4809e6c10a221e9d67f2e841536845387b42d Mon Sep 17 00:00:00 2001\nFrom: Daniel Beck <daniel-beck@users.noreply.github.com>\nDate: Thu, 13 Apr 2017 15:01:32 +0200\nSubject: [PATCH] [SECURITY-412] Simplify implementation as suggested by jglick\n\n---\n core\/src\/main\/java\/jenkins\/model\/Jenkins.java | 20 ++++---------------\n 1 file changed, 4 insertions(+), 16 deletions(-)\n\ndiff --git a\/core\/src\/main\/java\/jenkins\/model\/Jenkins.java b\/core\/src\/main\/java\/jenkins\/model\/Jenkins.java\nindex 58ead664a596..eff060916bb8 100644\n--- a\/core\/src\/main\/java\/jenkins\/model\/Jenkins.java\n+++ b\/core\/src\/main\/java\/jenkins\/model\/Jenkins.java\n@@ -3369,6 +3369,7 @@ public DirectoryBrowserSupport doUserContent() {\n      *\n      * This first replaces \"app\" to {@link HudsonIsRestarting}\n      *\/\n+    @CLIMethod(name=\"restart\")\n     public void doRestart(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException, RestartNotSupportedException {\n         checkPermission(ADMINISTER);\n         if (req != null && req.getMethod().equals(\"GET\")) {\n@@ -3376,20 +3377,13 @@ public void doRestart(StaplerRequest req, StaplerResponse rsp) throws IOExceptio\n             return;\n         }\n \n-        if (req != null && req.getMethod().equals(\"POST\")) {\n+        if (req == null || req.getMethod().equals(\"POST\")) {\n             restart();\n         }\n \n         rsp.sendRedirect2(\".\");\n     }\n \n-    @CLIMethod(name=\"restart\")\n-    @Restricted(NoExternalUse.class)\n-    public void cliRestart() throws RestartNotSupportedException {\n-        checkPermission(ADMINISTER);\n-        restart();\n-    }\n-\n     \/**\n      * Queues up a restart of Jenkins for when there are no builds running, if we can.\n      *\n@@ -3397,25 +3391,19 @@ public void cliRestart() throws RestartNotSupportedException {\n      *\n      * @since 1.332\n      *\/\n+    @CLIMethod(name=\"safe-restart\")\n     public HttpResponse doSafeRestart(StaplerRequest req) throws IOException, ServletException, RestartNotSupportedException {\n         checkPermission(ADMINISTER);\n         if (req != null && req.getMethod().equals(\"GET\"))\n             return HttpResponses.forwardToView(this,\"_safeRestart.jelly\");\n \n-        if (req != null && req.getMethod().equals(\"POST\")) {\n+        if (req == null || req.getMethod().equals(\"POST\")) {\n             safeRestart();\n         }\n \n         return HttpResponses.redirectToDot();\n     }\n \n-    @CLIMethod(name=\"safe-restart\")\n-    @Restricted(NoExternalUse.class)\n-    public void cliSafeRestart() throws RestartNotSupportedException {\n-        checkPermission(ADMINISTER);\n-        safeRestart();\n-    }\n-\n     \/**\n      * Performs a restart.\n      *\/"
        },
        {
            "index":95,
            "vuln_id":"GHSA-f5cx-5wr3-5qrc",
            "cwe_id":"{'CWE-824'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in boosted trees ### Impact\nAn attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesCalculateBestGainsPerFeature(\n  node_id_range=[],\n  stats_summary_list=[[1,2,3]],\n  l1=[1.0],\n  l2=[1.0],\n  tree_complexity =[1.0],\n  min_node_weight =[1.17],\n  max_splits=5)\n```\n\nA similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`:\n\n```python\nimport tensorflow as tf\n                                                                                                                                                                                                                                                                                          \ntf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2(\n  node_id_range=[],\n  stats_summaries_list=[[1,2,3]],\n  split_types=[''],\n  candidate_feature_ids=[1,2,3,4],\n  l1=[1],     \n  l2=[1],\n  tree_complexity=[1.0],\n  min_node_weight=[1.17],\n  logits_dimension=5)\n```     \n    \nThe  [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc) does not validate the input values.\n\n### Patches\nWe have patched the issue in GitHub commit [9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad) and in commit. [429f009d2b2c09028647dd4bb7b3f6f414bbaad7](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad",
            "commit_sha":"9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad",
            "patch":"MULTI",
            "chain_ord":"['9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', '429f009d2b2c09028647dd4bb7b3f6f414bbaad7']",
            "before_first_fix_commit":"{'4f8db85aa9ab71a71e95d5acce7de52a0b195661'}",
            "last_fix_commit":"429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 19:11:33",
            "message":"Disallow empty node_id_range in tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2 and tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature\n\nPiperOrigin-RevId: 387165936\nChange-Id: I2f70341af96236b2776c2a592c917d549c1fc1e2",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 20, 'deletions': 0, 'total': 20}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc': {'additions': 20, 'deletions': 0, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -51,6 +51,16 @@ class BoostedTreesCalculateBestGainsPerFeatureOp : public OpKernel {\\n     \/\/ node_id_range\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->dims() == 1,\\n+        errors::InvalidArgument(\"node_id_range must be a rank 1 tensor, but \"\\n+                                \"given node_id_range has dims of \",\\n+                                node_id_range_t->dims()));\\n+    OP_REQUIRES(context, node_id_range_t->dim_size(0) == 2,\\n+                errors::InvalidArgument(\\n+                    \"node_id_range must be a rank 1 tensor with shape=[2], but \"\\n+                    \"given node_id_range has shape \",\\n+                    node_id_range_t->dim_size(0), \" on its first dim\"));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n     const int32_t node_id_first = node_id_range(0);  \/\/ inclusive\\n     const int32_t node_id_last = node_id_range(1);   \/\/ exclusive\\n@@ -570,6 +580,16 @@ class BoostedTreesCalculateBestFeatureSplitV2 : public OpKernel {\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->dims() == 1,\\n+        errors::InvalidArgument(\"node_id_range must be a rank 1 tensor, but \"\\n+                                \"given node_id_range has dims of \",\\n+                                node_id_range_t->dims()));\\n+    OP_REQUIRES(context, node_id_range_t->dim_size(0) == 2,\\n+                errors::InvalidArgument(\\n+                    \"node_id_range must be a rank 1 tensor with shape=[2], but \"\\n+                    \"given node_id_range has shape \",\\n+                    node_id_range_t->dim_size(0), \" on its first dim\"));\\n     const int32_t node_id_first = node_id_range(0);  \/\/ Inclusive.\\n     const int32_t node_id_last = node_id_range(1);   \/\/ Exclusive.'}}",
            "message_norm":"disallow empty node_id_range in tf.raw_ops.boostedtreescalculatebestfeaturesplitv2 and tf.raw_ops.boostedtreescalculatebestgainsperfeature\n\npiperorigin-revid: 387165936\nchange-id: i2f70341af96236b2776c2a592c917d549c1fc1e2",
            "language":"en",
            "entities":"[('387165936', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Tue, 27 Jul 2021 12:11:33 -0700\nSubject: [PATCH] Disallow empty node_id_range in\n tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2 and\n tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature\n\nPiperOrigin-RevId: 387165936\nChange-Id: I2f70341af96236b2776c2a592c917d549c1fc1e2\n---\n ...\/core\/kernels\/boosted_trees\/stats_ops.cc   | 20 +++++++++++++++++++\n 1 file changed, 20 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc b\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\nindex f3449daef78385..014c2ec22c9cf6 100644\n--- a\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\n+++ b\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\n@@ -51,6 +51,16 @@ class BoostedTreesCalculateBestGainsPerFeatureOp : public OpKernel {\n     \/\/ node_id_range\n     const Tensor* node_id_range_t;\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n+    OP_REQUIRES(\n+        context, node_id_range_t->dims() == 1,\n+        errors::InvalidArgument(\"node_id_range must be a rank 1 tensor, but \"\n+                                \"given node_id_range has dims of \",\n+                                node_id_range_t->dims()));\n+    OP_REQUIRES(context, node_id_range_t->dim_size(0) == 2,\n+                errors::InvalidArgument(\n+                    \"node_id_range must be a rank 1 tensor with shape=[2], but \"\n+                    \"given node_id_range has shape \",\n+                    node_id_range_t->dim_size(0), \" on its first dim\"));\n     const auto node_id_range = node_id_range_t->vec<int32>();\n     const int32_t node_id_first = node_id_range(0);  \/\/ inclusive\n     const int32_t node_id_last = node_id_range(1);   \/\/ exclusive\n@@ -570,6 +580,16 @@ class BoostedTreesCalculateBestFeatureSplitV2 : public OpKernel {\n     const Tensor* node_id_range_t;\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n     const auto node_id_range = node_id_range_t->vec<int32>();\n+    OP_REQUIRES(\n+        context, node_id_range_t->dims() == 1,\n+        errors::InvalidArgument(\"node_id_range must be a rank 1 tensor, but \"\n+                                \"given node_id_range has dims of \",\n+                                node_id_range_t->dims()));\n+    OP_REQUIRES(context, node_id_range_t->dim_size(0) == 2,\n+                errors::InvalidArgument(\n+                    \"node_id_range must be a rank 1 tensor with shape=[2], but \"\n+                    \"given node_id_range has shape \",\n+                    node_id_range_t->dim_size(0), \" on its first dim\"));\n     const int32_t node_id_first = node_id_range(0);  \/\/ Inclusive.\n     const int32_t node_id_last = node_id_range(1);   \/\/ Exclusive."
        },
        {
            "index":885,
            "vuln_id":"GHSA-rcxc-3w2m-mp8h",
            "cwe_id":"{'CWE-502'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/NVIDIA\/NVFlare\/commit\/fd018eea9dff925a765079a94c2f017920fcda67'}",
            "dataset":"osv",
            "summary":"Unsafe deserialisation in the PKI implementation scheme of NVFlare ### Impact\nNVFLARE contains a vulnerability in its PKI implementation module, where The CA credentials are transported via pickle and no safe deserialization. The deserialization of Untrusted Data may allow an unprivileged network attacker to cause Remote Code Execution, Denial Of Service, and Impact to both Confidentiality and Integrity.\nAll versions before 2.1.2 are affected.\n\nCVSS Score = 9.8\n[AV:N\/AC:L\/PR:N\/UI:N\/S:U\/C:H\/I:H\/A:H](https:\/\/nam11.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fnvd.nist.gov%2Fvuln-metrics%2Fcvss%2Fv3-calculator%3Fvector%3DAV%3AN%2FAC%3AL%2FPR%3AN%2FUI%3AN%2FS%3AU%2FC%3AH%2FI%3AH%2FA%3AH&data=05%7C01%7Cchesterc%40nvidia.com%7Ce9600bde16854b0b380008da4fc544f7%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C637910005925574215%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=5kBrXEmAbqp8R31JCH%2FG95MUly72UPVihnBwiRFmvBY%3D&reserved=0)\n\n\n\n### Patches\nThe patch will be included in nvflare==2.1.2\n\n### Workarounds\nReplace pickle serialization with JSON and change the code accordingly\n\nAdditional information\nIssue Found by: Oliver Sellwood (@Nintorac)",
            "published_date":"2022-06-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/NVIDIA\/NVFlare",
            "commit_href":"https:\/\/github.com\/NVIDIA\/NVFlare\/commit\/fd018eea9dff925a765079a94c2f017920fcda67",
            "commit_sha":"fd018eea9dff925a765079a94c2f017920fcda67",
            "patch":"SINGLE",
            "chain_ord":"['fd018eea9dff925a765079a94c2f017920fcda67']",
            "before_first_fix_commit":"{'f0a005982122277a1ac22cb04f977186393d8ab2'}",
            "last_fix_commit":"fd018eea9dff925a765079a94c2f017920fcda67",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/19\/2022, 15:30:59",
            "message":"Replace pickle in state persistence in provision cert with json (#412)",
            "author":"Isaac Yang",
            "comments":null,
            "stats":"{'additions': 17, 'deletions': 13, 'total': 30}",
            "files":"{'nvflare\/lighter\/impl\/cert.py': {'additions': 17, 'deletions': 13, 'changes': 30, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NVIDIA\/NVFlare\/raw\/fd018eea9dff925a765079a94c2f017920fcda67\/nvflare%2Flighter%2Fimpl%2Fcert.py', 'patch': '@@ -13,8 +13,8 @@\\n # limitations under the License.\\n \\n import datetime\\n+import json\\n import os\\n-import pickle\\n \\n from cryptography import x509\\n from cryptography.hazmat.backends import default_backend\\n@@ -50,13 +50,13 @@ def __init__(self):\\n \\n     def initialize(self, ctx):\\n         state_dir = self.get_state_dir(ctx)\\n-        cert_file = os.path.join(state_dir, \"cert.pkl\")\\n+        cert_file = os.path.join(state_dir, \"cert.json\")\\n         if os.path.exists(cert_file):\\n-            self.persistent_state = pickle.load(open(cert_file, \"rb\"))\\n-            self.serialized_cert = self.persistent_state[\"root_cert\"]\\n+            self.persistent_state = json.load(open(cert_file, \"rt\"))\\n+            self.serialized_cert = self.persistent_state[\"root_cert\"].encode(\"ascii\")\\n             self.root_cert = x509.load_pem_x509_certificate(self.serialized_cert, default_backend())\\n             self.pri_key = serialization.load_pem_private_key(\\n-                self.persistent_state[\"root_pri_key\"], password=None, backend=default_backend()\\n+                self.persistent_state[\"root_pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\\n             )\\n             self.pub_key = self.pri_key.public_key()\\n             self.subject = self.root_cert.subject\\n@@ -69,26 +69,30 @@ def _build_root(self, subject):\\n             self.pri_key = pri_key\\n             self.pub_key = pub_key\\n             self.serialized_cert = serialize_cert(self.root_cert)\\n-            self.persistent_state[\"root_cert\"] = self.serialized_cert\\n-            self.persistent_state[\"root_pri_key\"] = serialize_pri_key(self.pri_key)\\n+            self.persistent_state[\"root_cert\"] = self.serialized_cert.decode(\"ascii\")\\n+            self.persistent_state[\"root_pri_key\"] = serialize_pri_key(self.pri_key).decode(\"ascii\")\\n \\n     def _build_write_cert_pair(self, participant, base_name, ctx):\\n         subject = participant.subject\\n         if self.persistent_state and subject in self.persistent_state:\\n-            cert = x509.load_pem_x509_certificate(self.persistent_state[subject][\"cert\"], default_backend())\\n+            cert = x509.load_pem_x509_certificate(\\n+                self.persistent_state[subject][\"cert\"].encode(\"ascii\"), default_backend()\\n+            )\\n             pri_key = serialization.load_pem_private_key(\\n-                self.persistent_state[subject][\"pri_key\"], password=None, backend=default_backend()\\n+                self.persistent_state[subject][\"pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\\n             )\\n         else:\\n             pri_key, cert = self.get_pri_key_cert(participant)\\n-            self.persistent_state[subject] = dict(cert=serialize_cert(cert), pri_key=serialize_pri_key(pri_key))\\n+            self.persistent_state[subject] = dict(\\n+                cert=serialize_cert(cert).decode(\"ascii\"), pri_key=serialize_pri_key(pri_key).decode(\"ascii\")\\n+            )\\n         dest_dir = self.get_kit_dir(participant, ctx)\\n         with open(os.path.join(dest_dir, f\"{base_name}.crt\"), \"wb\") as f:\\n             f.write(serialize_cert(cert))\\n         with open(os.path.join(dest_dir, f\"{base_name}.key\"), \"wb\") as f:\\n             f.write(serialize_pri_key(pri_key))\\n         pkcs12 = serialization.pkcs12.serialize_key_and_certificates(\\n-            subject.encode(\"utf-8\"), pri_key, cert, None, serialization.BestAvailableEncryption(subject.encode(\"utf-8\"))\\n+            subject.encode(\"ascii\"), pri_key, cert, None, serialization.BestAvailableEncryption(subject.encode(\"ascii\"))\\n         )\\n         with open(os.path.join(dest_dir, f\"{base_name}.pfx\"), \"wb\") as f:\\n             f.write(pkcs12)\\n@@ -163,5 +167,5 @@ def _x509_name(self, cn_name, org_name=None):\\n \\n     def finalize(self, ctx):\\n         state_dir = self.get_state_dir(ctx)\\n-        cert_file = os.path.join(state_dir, \"cert.pkl\")\\n-        pickle.dump(self.persistent_state, open(cert_file, \"wb\"))\\n+        cert_file = os.path.join(state_dir, \"cert.json\")\\n+        json.dump(self.persistent_state, open(cert_file, \"wt\"))'}}",
            "message_norm":"replace pickle in state persistence in provision cert with json (#412)",
            "language":"en",
            "entities":"[('#412', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['nvflare\/lighter\/impl\/cert.py'])",
            "num_files":1.0,
            "patch_content":"From fd018eea9dff925a765079a94c2f017920fcda67 Mon Sep 17 00:00:00 2001\nFrom: Isaac Yang <isaacy@nvidia.com>\nDate: Tue, 19 Apr 2022 08:30:59 -0700\nSubject: [PATCH] Replace pickle in state persistence in provision cert with\n json (#412)\n\n---\n nvflare\/lighter\/impl\/cert.py | 30 +++++++++++++++++-------------\n 1 file changed, 17 insertions(+), 13 deletions(-)\n\ndiff --git a\/nvflare\/lighter\/impl\/cert.py b\/nvflare\/lighter\/impl\/cert.py\nindex 5522aa224c..84b9888a5e 100644\n--- a\/nvflare\/lighter\/impl\/cert.py\n+++ b\/nvflare\/lighter\/impl\/cert.py\n@@ -13,8 +13,8 @@\n # limitations under the License.\n \n import datetime\n+import json\n import os\n-import pickle\n \n from cryptography import x509\n from cryptography.hazmat.backends import default_backend\n@@ -50,13 +50,13 @@ def __init__(self):\n \n     def initialize(self, ctx):\n         state_dir = self.get_state_dir(ctx)\n-        cert_file = os.path.join(state_dir, \"cert.pkl\")\n+        cert_file = os.path.join(state_dir, \"cert.json\")\n         if os.path.exists(cert_file):\n-            self.persistent_state = pickle.load(open(cert_file, \"rb\"))\n-            self.serialized_cert = self.persistent_state[\"root_cert\"]\n+            self.persistent_state = json.load(open(cert_file, \"rt\"))\n+            self.serialized_cert = self.persistent_state[\"root_cert\"].encode(\"ascii\")\n             self.root_cert = x509.load_pem_x509_certificate(self.serialized_cert, default_backend())\n             self.pri_key = serialization.load_pem_private_key(\n-                self.persistent_state[\"root_pri_key\"], password=None, backend=default_backend()\n+                self.persistent_state[\"root_pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\n             )\n             self.pub_key = self.pri_key.public_key()\n             self.subject = self.root_cert.subject\n@@ -69,26 +69,30 @@ def _build_root(self, subject):\n             self.pri_key = pri_key\n             self.pub_key = pub_key\n             self.serialized_cert = serialize_cert(self.root_cert)\n-            self.persistent_state[\"root_cert\"] = self.serialized_cert\n-            self.persistent_state[\"root_pri_key\"] = serialize_pri_key(self.pri_key)\n+            self.persistent_state[\"root_cert\"] = self.serialized_cert.decode(\"ascii\")\n+            self.persistent_state[\"root_pri_key\"] = serialize_pri_key(self.pri_key).decode(\"ascii\")\n \n     def _build_write_cert_pair(self, participant, base_name, ctx):\n         subject = participant.subject\n         if self.persistent_state and subject in self.persistent_state:\n-            cert = x509.load_pem_x509_certificate(self.persistent_state[subject][\"cert\"], default_backend())\n+            cert = x509.load_pem_x509_certificate(\n+                self.persistent_state[subject][\"cert\"].encode(\"ascii\"), default_backend()\n+            )\n             pri_key = serialization.load_pem_private_key(\n-                self.persistent_state[subject][\"pri_key\"], password=None, backend=default_backend()\n+                self.persistent_state[subject][\"pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\n             )\n         else:\n             pri_key, cert = self.get_pri_key_cert(participant)\n-            self.persistent_state[subject] = dict(cert=serialize_cert(cert), pri_key=serialize_pri_key(pri_key))\n+            self.persistent_state[subject] = dict(\n+                cert=serialize_cert(cert).decode(\"ascii\"), pri_key=serialize_pri_key(pri_key).decode(\"ascii\")\n+            )\n         dest_dir = self.get_kit_dir(participant, ctx)\n         with open(os.path.join(dest_dir, f\"{base_name}.crt\"), \"wb\") as f:\n             f.write(serialize_cert(cert))\n         with open(os.path.join(dest_dir, f\"{base_name}.key\"), \"wb\") as f:\n             f.write(serialize_pri_key(pri_key))\n         pkcs12 = serialization.pkcs12.serialize_key_and_certificates(\n-            subject.encode(\"utf-8\"), pri_key, cert, None, serialization.BestAvailableEncryption(subject.encode(\"utf-8\"))\n+            subject.encode(\"ascii\"), pri_key, cert, None, serialization.BestAvailableEncryption(subject.encode(\"ascii\"))\n         )\n         with open(os.path.join(dest_dir, f\"{base_name}.pfx\"), \"wb\") as f:\n             f.write(pkcs12)\n@@ -163,5 +167,5 @@ def _x509_name(self, cn_name, org_name=None):\n \n     def finalize(self, ctx):\n         state_dir = self.get_state_dir(ctx)\n-        cert_file = os.path.join(state_dir, \"cert.pkl\")\n-        pickle.dump(self.persistent_state, open(cert_file, \"wb\"))\n+        cert_file = os.path.join(state_dir, \"cert.json\")\n+        json.dump(self.persistent_state, open(cert_file, \"wt\"))"
        },
        {
            "index":674,
            "vuln_id":"GHSA-65mj-7c86-79jf",
            "cwe_id":"{'CWE-305', 'CWE-287'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/ADOdb\/ADOdb\/commit\/952de6c4273d9b1e91c2b838044f8c2111150c29', 'https:\/\/github.com\/ADOdb\/ADOdb\/commit\/b4d5ce70034c5aac3a1d51d317d93c037a0938d2'}",
            "dataset":"osv",
            "summary":"Authentication Bypass in ADOdb\/ADOdb ### Impact\n\nAn attacker can inject values into a PostgreSQL connection string by providing a parameter surrounded by single quotes.\n\nDepending on how the library is used in the client software, this may allow an attacker to bypass the login process, gain access to the server's IP address, etc.\n\n### Patches\n\nThe vulnerability is fixed in ADOdb versions 5.20.21 (952de6c4273d9b1e91c2b838044f8c2111150c29) and 5.21.4 or later (b4d5ce70034c5aac3a1d51d317d93c037a0938d2).\n\nThe simplest patch is to delete line 29 in `drivers\/adodb-postgres64.inc.php`:\n\n```php\ndiff --git a\/drivers\/adodb-postgres64.inc.php b\/drivers\/adodb-postgres64.inc.php\nindex d04b7f67..729d7141 100644\n--- a\/drivers\/adodb-postgres64.inc.php\n+++ b\/drivers\/adodb-postgres64.inc.php\n@@ -26,7 +26,6 @@ function adodb_addslashes($s)\n {\n    $len = strlen($s);\n    if ($len == 0) return \"''\";\n-   if (strncmp($s,\"'\",1) === 0 && substr($s,$len-1) == \"'\") return $s; \/\/ already quoted\n \n    return \"'\".addslashes($s).\"'\";\n }\n```\n\n### Workarounds\n\nEnsure the parameters passed to *ADOConnection::connect()* or related functions (_nConnect()_, _pConnect()_) are not surrounded by single quotes.\n\n### Credits\n\nThanks to **Emmet Leahy** (@meme-lord) of Sorcery Ltd for reporting this vulnerability, and to the [huntr](https:\/\/huntr.dev\/) team for their support.\n\n### References\n\n- Original issue report https:\/\/huntr.dev\/bounties\/bdf5f216-4499-4225-a737-b28bc6f5801c\/\n- ADOdb reference issue #793 \n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Add a note in issue #793\n* Contact the maintainers on [Gitter](https:\/\/gitter.im\/adodb\/adodb)",
            "published_date":"2022-01-27",
            "chain_len":2,
            "project":"https:\/\/github.com\/ADOdb\/ADOdb",
            "commit_href":"https:\/\/github.com\/ADOdb\/ADOdb\/commit\/b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
            "commit_sha":"b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
            "patch":"MULTI",
            "chain_ord":"['952de6c4273d9b1e91c2b838044f8c2111150c29', 'b4d5ce70034c5aac3a1d51d317d93c037a0938d2']",
            "before_first_fix_commit":"{'c5415722049f36c446a4034d15f1d17943f11458'}",
            "last_fix_commit":"b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
            "chain_ord_pos":2.0,
            "commit_datetime":"01\/10\/2022, 09:00:33",
            "message":"Prevent auth bypass with PostgreSQL connections\n\nThanks to Emmet Leahy of Sorcery Ltd for reporting this vulnerability\n(CVE-2021-3850).\n\nRefactoring ADODB_postgres64::_connect():\n- Remove adodb_addslashes() function, which did not escape the\n  connection parameters when they are wrapped in single quotes\n  (root cause for the identified security issue).\n- Use addcslashes() instead of addslashes() to only escape `'` and `\\`,\n  to strictly follow pg_connect() documentation (addslashes() also\n  escapes `\"`)\n- Use an array and a foreach loop to build the connection string when\n  given individual parameters for host:port, user, password and dbname\n\nFixes #793",
            "author":"Damien Regad",
            "comments":null,
            "stats":"{'additions': 25, 'deletions': 22, 'total': 47}",
            "files":"{'drivers\/adodb-postgres64.inc.php': {'additions': 25, 'deletions': 22, 'changes': 47, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ADOdb\/ADOdb\/raw\/b4d5ce70034c5aac3a1d51d317d93c037a0938d2\/drivers%2Fadodb-postgres64.inc.php', 'patch': '@@ -22,15 +22,6 @@\\n \/\/ security - hide paths\\n if (!defined(\\'ADODB_DIR\\')) die();\\n \\n-function adodb_addslashes($s)\\n-{\\n-\\t$len = strlen($s);\\n-\\tif ($len == 0) return \"\\'\\'\";\\n-\\tif (strncmp($s,\"\\'\",1) === 0 && substr($s,$len-1) == \"\\'\") return $s; \/\/ already quoted\\n-\\n-\\treturn \"\\'\".addslashes($s).\"\\'\";\\n-}\\n-\\n class ADODB_postgres64 extends ADOConnection{\\n \\tvar $databaseType = \\'postgres64\\';\\n \\tvar $dataProvider = \\'postgres\\';\\n@@ -693,21 +684,33 @@ function _connect($str,$user=\\'\\',$pwd=\\'\\',$db=\\'\\',$ctype=0)\\n \\n \\t\\t$this->_errorMsg = false;\\n \\n+\\t\\t\/\/ If $user, $pwd and $db are all null, then $str is a pg_connect()\\n+\\t\\t\/\/ connection string. Otherwise we expect it to be a hostname,\\n+\\t\\t\/\/ with optional port separated by \\':\\'\\n \\t\\tif ($user || $pwd || $db) {\\n-\\t\\t\\t$user = adodb_addslashes($user);\\n-\\t\\t\\t$pwd = adodb_addslashes($pwd);\\n-\\t\\t\\tif (strlen($db) == 0) $db = \\'template1\\';\\n-\\t\\t\\t$db = adodb_addslashes($db);\\n-\\t\\t\\tif ($str)  {\\n-\\t\\t\\t\\t$host = explode(\":\", $str);\\n-\\t\\t\\t\\tif ($host[0]) $str = \"host=\".adodb_addslashes($host[0]);\\n-\\t\\t\\t\\telse $str = \\'\\';\\n-\\t\\t\\t\\tif (isset($host[1])) $str .= \" port=$host[1]\";\\n-\\t\\t\\t\\telse if (!empty($this->port)) $str .= \" port=\".$this->port;\\n+\\t\\t\\t\/\/ Hostname & port\\n+\\t\\t\\tif ($str) {\\n+\\t\\t\\t\\t$host = explode(\\':\\', $str);\\n+\\t\\t\\t\\tif ($host[0]) {\\n+\\t\\t\\t\\t\\t$conn[\\'host\\'] = $host[0];\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t\\tif (isset($host[1])) {\\n+\\t\\t\\t\\t\\t$conn[\\'port\\'] = (int)$host[1];\\n+\\t\\t\\t\\t} elseif (!empty($this->port)) {\\n+\\t\\t\\t\\t\\t$conn[\\'port\\'] = $this->port;\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t}\\n+\\t\\t\\t$conn[\\'user\\'] = $user;\\n+\\t\\t\\t$conn[\\'password\\'] = $pwd;\\n+\\t\\t\\t\/\/ @TODO not sure why we default to \\'template1\\', pg_connect() uses the username when dbname is empty\\n+\\t\\t\\t$conn[\\'dbname\\'] = $db ?: \\'template1\\';\\n+\\n+\\t\\t\\t\/\/ Generate connection string\\n+\\t\\t\\t$str = \\'\\';\\n+\\t\\t\\tforeach ($conn as $param => $value) {\\n+\\t\\t\\t\\t\/\/ Escaping single quotes and backslashes per pg_connect() documentation\\n+\\t\\t\\t\\t$str .= $param . \"=\\'\" . addcslashes($value, \"\\'\\\\\\\\\") . \"\\' \";\\n \\t\\t\\t}\\n-\\t\\t\\tif ($user) $str .= \" user=\".$user;\\n-\\t\\t\\tif ($pwd)  $str .= \" password=\".$pwd;\\n-\\t\\t\\tif ($db)   $str .= \" dbname=\".$db;\\n \\t\\t}\\n \\n \\t\\t\/\/if ($user) $linea = \"user=$user host=$linea password=$pwd dbname=$db port=5432\";'}}",
            "message_norm":"prevent auth bypass with postgresql connections\n\nthanks to emmet leahy of sorcery ltd for reporting this vulnerability\n(cve-2021-3850).\n\nrefactoring adodb_postgres64::_connect():\n- remove adodb_addslashes() function, which did not escape the\n  connection parameters when they are wrapped in single quotes\n  (root cause for the identified security issue).\n- use addcslashes() instead of addslashes() to only escape `'` and `\\`,\n  to strictly follow pg_connect() documentation (addslashes() also\n  escapes `\"`)\n- use an array and a foreach loop to build the connection string when\n  given individual parameters for host:port, user, password and dbname\n\nfixes #793",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('auth', 'SECWORD', ''), ('bypass', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('cve-2021-3850', 'VULNID', 'CVE'), ('remove', 'ACTION', ''), ('escape', 'SECWORD', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('escape', 'SECWORD', ''), ('escapes', 'SECWORD', ''), ('password', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#793', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['drivers\/adodb-postgres64.inc.php'])",
            "num_files":1.0,
            "patch_content":"From b4d5ce70034c5aac3a1d51d317d93c037a0938d2 Mon Sep 17 00:00:00 2001\nFrom: Damien Regad <dregad@mantisbt.org>\nDate: Mon, 10 Jan 2022 10:00:33 +0100\nSubject: [PATCH] Prevent auth bypass with PostgreSQL connections\n\nThanks to Emmet Leahy of Sorcery Ltd for reporting this vulnerability\n(CVE-2021-3850).\n\nRefactoring ADODB_postgres64::_connect():\n- Remove adodb_addslashes() function, which did not escape the\n  connection parameters when they are wrapped in single quotes\n  (root cause for the identified security issue).\n- Use addcslashes() instead of addslashes() to only escape `'` and `\\`,\n  to strictly follow pg_connect() documentation (addslashes() also\n  escapes `\"`)\n- Use an array and a foreach loop to build the connection string when\n  given individual parameters for host:port, user, password and dbname\n\nFixes #793\n---\n drivers\/adodb-postgres64.inc.php | 47 +++++++++++++++++---------------\n 1 file changed, 25 insertions(+), 22 deletions(-)\n\ndiff --git a\/drivers\/adodb-postgres64.inc.php b\/drivers\/adodb-postgres64.inc.php\nindex 9128467be..2f2e4584d 100644\n--- a\/drivers\/adodb-postgres64.inc.php\n+++ b\/drivers\/adodb-postgres64.inc.php\n@@ -22,15 +22,6 @@\n \/\/ security - hide paths\n if (!defined('ADODB_DIR')) die();\n \n-function adodb_addslashes($s)\n-{\n-\t$len = strlen($s);\n-\tif ($len == 0) return \"''\";\n-\tif (strncmp($s,\"'\",1) === 0 && substr($s,$len-1) == \"'\") return $s; \/\/ already quoted\n-\n-\treturn \"'\".addslashes($s).\"'\";\n-}\n-\n class ADODB_postgres64 extends ADOConnection{\n \tvar $databaseType = 'postgres64';\n \tvar $dataProvider = 'postgres';\n@@ -693,21 +684,33 @@ function _connect($str,$user='',$pwd='',$db='',$ctype=0)\n \n \t\t$this->_errorMsg = false;\n \n+\t\t\/\/ If $user, $pwd and $db are all null, then $str is a pg_connect()\n+\t\t\/\/ connection string. Otherwise we expect it to be a hostname,\n+\t\t\/\/ with optional port separated by ':'\n \t\tif ($user || $pwd || $db) {\n-\t\t\t$user = adodb_addslashes($user);\n-\t\t\t$pwd = adodb_addslashes($pwd);\n-\t\t\tif (strlen($db) == 0) $db = 'template1';\n-\t\t\t$db = adodb_addslashes($db);\n-\t\t\tif ($str)  {\n-\t\t\t\t$host = explode(\":\", $str);\n-\t\t\t\tif ($host[0]) $str = \"host=\".adodb_addslashes($host[0]);\n-\t\t\t\telse $str = '';\n-\t\t\t\tif (isset($host[1])) $str .= \" port=$host[1]\";\n-\t\t\t\telse if (!empty($this->port)) $str .= \" port=\".$this->port;\n+\t\t\t\/\/ Hostname & port\n+\t\t\tif ($str) {\n+\t\t\t\t$host = explode(':', $str);\n+\t\t\t\tif ($host[0]) {\n+\t\t\t\t\t$conn['host'] = $host[0];\n+\t\t\t\t}\n+\t\t\t\tif (isset($host[1])) {\n+\t\t\t\t\t$conn['port'] = (int)$host[1];\n+\t\t\t\t} elseif (!empty($this->port)) {\n+\t\t\t\t\t$conn['port'] = $this->port;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\t$conn['user'] = $user;\n+\t\t\t$conn['password'] = $pwd;\n+\t\t\t\/\/ @TODO not sure why we default to 'template1', pg_connect() uses the username when dbname is empty\n+\t\t\t$conn['dbname'] = $db ?: 'template1';\n+\n+\t\t\t\/\/ Generate connection string\n+\t\t\t$str = '';\n+\t\t\tforeach ($conn as $param => $value) {\n+\t\t\t\t\/\/ Escaping single quotes and backslashes per pg_connect() documentation\n+\t\t\t\t$str .= $param . \"='\" . addcslashes($value, \"'\\\\\") . \"' \";\n \t\t\t}\n-\t\t\tif ($user) $str .= \" user=\".$user;\n-\t\t\tif ($pwd)  $str .= \" password=\".$pwd;\n-\t\t\tif ($db)   $str .= \" dbname=\".$db;\n \t\t}\n \n \t\t\/\/if ($user) $linea = \"user=$user host=$linea password=$pwd dbname=$db port=5432\";"
        }
    ]
}