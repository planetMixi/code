{
    "schema":{
        "fields":[
            {
                "name":"index",
                "type":"integer"
            },
            {
                "name":"vuln_id",
                "type":"string"
            },
            {
                "name":"cwe_id",
                "type":"string"
            },
            {
                "name":"score",
                "type":"number"
            },
            {
                "name":"chain",
                "type":"string"
            },
            {
                "name":"dataset",
                "type":"string"
            },
            {
                "name":"summary",
                "type":"string"
            },
            {
                "name":"published_date",
                "type":"string"
            },
            {
                "name":"chain_len",
                "type":"integer"
            },
            {
                "name":"project",
                "type":"string"
            },
            {
                "name":"commit_href",
                "type":"string"
            },
            {
                "name":"commit_sha",
                "type":"string"
            },
            {
                "name":"patch",
                "type":"string"
            },
            {
                "name":"chain_ord",
                "type":"string"
            },
            {
                "name":"before_first_fix_commit",
                "type":"string"
            },
            {
                "name":"last_fix_commit",
                "type":"string"
            },
            {
                "name":"chain_ord_pos",
                "type":"number"
            },
            {
                "name":"commit_datetime",
                "type":"string"
            },
            {
                "name":"message",
                "type":"string"
            },
            {
                "name":"author",
                "type":"string"
            },
            {
                "name":"comments",
                "type":"string"
            },
            {
                "name":"stats",
                "type":"string"
            },
            {
                "name":"files",
                "type":"string"
            },
            {
                "name":"message_norm",
                "type":"string"
            },
            {
                "name":"language",
                "type":"string"
            },
            {
                "name":"entities",
                "type":"string"
            },
            {
                "name":"classification_level_1",
                "type":"string"
            },
            {
                "name":"classification_level_2",
                "type":"string"
            },
            {
                "name":"list_files",
                "type":"string"
            },
            {
                "name":"num_files",
                "type":"number"
            },
            {
                "name":"patch_content",
                "type":"string"
            }
        ],
        "primaryKey":[
            "index"
        ],
        "pandas_version":"1.4.0"
    },
    "data":[
        {
            "index":813,
            "vuln_id":"GHSA-j6p2-cx3w-6jcp",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/jashkenas\/backbone\/commit\/0cdc525961d3fa98e810ffae6bcc8e3838e36d93'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting in backbone Affected versions of `backbone` are vulnerable to cross-site scripting when users are allowed to supply input to the `Model#Escape` function, and the output is then written to the DOM. \n\nThe vulnerability occurs as a result of the regular expression used to encode metacharacters failing to take HTML Entities such as `&#60;` into account.\n\n\n## Recommendation\n\nUpdate to version 0.5.0 or later.",
            "published_date":"2019-02-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/jashkenas\/backbone",
            "commit_href":"https:\/\/github.com\/jashkenas\/backbone\/commit\/0cdc525961d3fa98e810ffae6bcc8e3838e36d93",
            "commit_sha":"0cdc525961d3fa98e810ffae6bcc8e3838e36d93",
            "patch":"SINGLE",
            "chain_ord":"['0cdc525961d3fa98e810ffae6bcc8e3838e36d93']",
            "before_first_fix_commit":"{'7216d993502da2e312fc53f4e8edc8b534c25042'}",
            "last_fix_commit":"0cdc525961d3fa98e810ffae6bcc8e3838e36d93",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/01\/2011, 21:12:24",
            "message":"Fixed escapeHTML function\nto skip not only &***;, but also &#***; and &x***;",
            "author":"Dmitry Baranovskiy",
            "comments":"{'com_1': {'author': 'alanhogan', 'datetime': '03\/06\/2011, 02:31:15', 'body': 'What are your thoughts on escaping single quotes?\\n\\nUsing single quotes around attribute values is less common than double quotes, but is certainly done:\\n\\n```\\n<p id=\\'foo\\'>\u2026<\/p>\\n```\\n\\nThis can lead to XSS just as unescaped double-quotes can:\\n\\n```\\nvar attack = \" \\' onmouseover=\\'alert(1);\\' foo=\\' \";\\nvar html = \"<p data-user-input=\\'\"+escapeHTML(attack)+\"\\'>Foo<\/p>\";\\ndocument.write(html);\\n```\\n\\nIMO, single quotes really ought to be escaped, as well.'}, 'com_2': {'author': 'alanhogan', 'datetime': '03\/06\/2011, 02:37:31', 'body': 'Demo of attack on jsfiddle: http:\/\/jsfiddle.net\/wEzNJ\/'}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'backbone.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jashkenas\/backbone\/raw\/0cdc525961d3fa98e810ffae6bcc8e3838e36d93\/backbone.js', 'patch': '@@ -1079,7 +1079,7 @@\\n \\n   \/\/ Helper function to escape a string for HTML rendering.\\n   var escapeHTML = function(string) {\\n-    return string.replace(\/&(?!\\\\w+;)\/g, \\'&amp;\\').replace(\/<\/g, \\'&lt;\\').replace(\/>\/g, \\'&gt;\\').replace(\/\"\/g, \\'&quot;\\');\\n+    return string.replace(\/&(?!\\\\w+;|#\\\\d+;|#x[\\\\da-f]+;)\/gi, \\'&amp;\\').replace(\/<\/g, \\'&lt;\\').replace(\/>\/g, \\'&gt;\\').replace(\/\"\/g, \\'&quot;\\');\\n   };\\n \\n }).call(this);'}}",
            "message_norm":"fixed escapehtml function\nto skip not only &***;, but also &#***; and &x***;",
            "language":"en",
            "entities":"[('fixed', 'ACTION', ''), ('escapehtml', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['backbone.js'])",
            "num_files":1.0,
            "patch_content":"From 0cdc525961d3fa98e810ffae6bcc8e3838e36d93 Mon Sep 17 00:00:00 2001\nFrom: Dmitry Baranovskiy <Dmitry@Baranovskiy.com>\nDate: Wed, 2 Mar 2011 08:12:24 +1100\nSubject: [PATCH] Fixed escapeHTML function to skip not only &***;, but also\n &#***; and &x***;\n\n---\n backbone.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/backbone.js b\/backbone.js\nindex 98ba0ddc0..47e85aeb8 100644\n--- a\/backbone.js\n+++ b\/backbone.js\n@@ -1079,7 +1079,7 @@\n \n   \/\/ Helper function to escape a string for HTML rendering.\n   var escapeHTML = function(string) {\n-    return string.replace(\/&(?!\\w+;)\/g, '&amp;').replace(\/<\/g, '&lt;').replace(\/>\/g, '&gt;').replace(\/\"\/g, '&quot;');\n+    return string.replace(\/&(?!\\w+;|#\\d+;|#x[\\da-f]+;)\/gi, '&amp;').replace(\/<\/g, '&lt;').replace(\/>\/g, '&gt;').replace(\/\"\/g, '&quot;');\n   };\n \n }).call(this);"
        },
        {
            "index":901,
            "vuln_id":"GHSA-h5g4-ppwx-48q2",
            "cwe_id":"{'CWE-20'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cff267650c6a1b266e4b4500f69fbc49cdd773c5'}",
            "dataset":"osv",
            "summary":"Missing validation causes denial of service via `DeleteSessionTensor` ### Impact\nThe implementation of [`tf.raw_ops.DeleteSessionTensor`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f3b9bf4c3c0597563b289c0512e98d4ce81f886e\/tensorflow\/core\/kernels\/session_ops.cc#L128-L144) does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack:\n\n```python\nimport tensorflow as tf\n\nhandle = tf.constant(\"[]\", shape=[0], dtype=tf.string)\ntf.raw_ops.DeleteSessionTensor(handle=handle)\n```\n  \nThe code assumes `handle` is a scalar but there is no validation for this:\n  \n```cc\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n```\n\n### Patches\nWe have patched the issue in GitHub commit [cff267650c6a1b266e4b4500f69fbc49cdd773c5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cff267650c6a1b266e4b4500f69fbc49cdd773c5).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Neophytos Christou from Secure Systems Lab at Brown University.",
            "published_date":"2022-05-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cff267650c6a1b266e4b4500f69fbc49cdd773c5",
            "commit_sha":"cff267650c6a1b266e4b4500f69fbc49cdd773c5",
            "patch":"SINGLE",
            "chain_ord":"['cff267650c6a1b266e4b4500f69fbc49cdd773c5']",
            "before_first_fix_commit":"{'339d5de981acaa8580da62c5de8c0da64ae88ad4'}",
            "last_fix_commit":"cff267650c6a1b266e4b4500f69fbc49cdd773c5",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 20:08:57",
            "message":"Fix tf.raw_ops.DeleteSessionTensor vulnerability with invalid `handle`.\n\nCheck that `handle` input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445228994",
            "author":"Alan Liu",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/session_ops.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/cff267650c6a1b266e4b4500f69fbc49cdd773c5\/tensorflow%2Fcore%2Fkernels%2Fsession_ops.cc', 'patch': '@@ -134,6 +134,8 @@ class DeleteSessionTensorOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& handle = ctx->input(0);\\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\\n+                errors::InvalidArgument(\"`handle` must be scalar\"));\\n     const string& name = handle.scalar<tstring>()();\\n     auto session_state = ctx->session_state();\\n     OP_REQUIRES(ctx, session_state != nullptr,'}}",
            "message_norm":"fix tf.raw_ops.deletesessiontensor vulnerability with invalid `handle`.\n\ncheck that `handle` input is actually a scalar before treating it as such.\n\npiperorigin-revid: 445228994",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('445228994', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/session_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From cff267650c6a1b266e4b4500f69fbc49cdd773c5 Mon Sep 17 00:00:00 2001\nFrom: Alan Liu <liualan@google.com>\nDate: Thu, 28 Apr 2022 13:08:57 -0700\nSubject: [PATCH] Fix tf.raw_ops.DeleteSessionTensor vulnerability with invalid\n `handle`.\n\nCheck that `handle` input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445228994\n---\n tensorflow\/core\/kernels\/session_ops.cc | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/session_ops.cc b\/tensorflow\/core\/kernels\/session_ops.cc\nindex bb47288b1575ad..2feb79a24e329e 100644\n--- a\/tensorflow\/core\/kernels\/session_ops.cc\n+++ b\/tensorflow\/core\/kernels\/session_ops.cc\n@@ -134,6 +134,8 @@ class DeleteSessionTensorOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& handle = ctx->input(0);\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\n+                errors::InvalidArgument(\"`handle` must be scalar\"));\n     const string& name = handle.scalar<tstring>()();\n     auto session_state = ctx->session_state();\n     OP_REQUIRES(ctx, session_state != nullptr,"
        },
        {
            "index":863,
            "vuln_id":"GHSA-jff2-qjw8-5476",
            "cwe_id":"{'CWE-77', 'CWE-78'}",
            "score":8.9,
            "chain":"{'https:\/\/github.com\/sebhildebrandt\/systeminformation\/commit\/01ef56cd5824ed6da1c11b37013a027fdef67524', 'https:\/\/github.com\/sebhildebrandt\/systeminformation\/commit\/0be6fcd575c05687d1076d5cd6d75af2ebae5a46', 'https:\/\/github.com\/sebhildebrandt\/systeminformation\/commit\/7922366d707de7f20995fc8e30ac3153636bf35f'}",
            "dataset":"osv",
            "summary":"Command Injection Vulnerability in systeminformation ### Impact\ncommand injection vulnerability\n\n### Patches\nProblem was fixed with a parameter check. Please upgrade to version >= 5.6.4\n\n### Workarounds\nIf you cannot upgrade, be sure to check or sanitize service parameters that are passed to si.inetLatency(), si.inetChecksite(), si.services(), si.processLoad() ... do only allow strings, reject any arrays. String sanitation works as expected.",
            "published_date":"2021-04-06",
            "chain_len":3,
            "project":"https:\/\/github.com\/sebhildebrandt\/systeminformation",
            "commit_href":"https:\/\/github.com\/sebhildebrandt\/systeminformation\/commit\/01ef56cd5824ed6da1c11b37013a027fdef67524",
            "commit_sha":"01ef56cd5824ed6da1c11b37013a027fdef67524",
            "patch":"MULTI",
            "chain_ord":"['7922366d707de7f20995fc8e30ac3153636bf35f', '0be6fcd575c05687d1076d5cd6d75af2ebae5a46', '01ef56cd5824ed6da1c11b37013a027fdef67524']",
            "before_first_fix_commit":"{'0be6fcd575c05687d1076d5cd6d75af2ebae5a46'}",
            "last_fix_commit":"01ef56cd5824ed6da1c11b37013a027fdef67524",
            "chain_ord_pos":3.0,
            "commit_datetime":"03\/15\/2021, 10:51:30",
            "message":"sanitizeShellString() and other security improvements",
            "author":"Sebastian Hildebrandt",
            "comments":"{'com_1': {'author': 'Aaisui', 'datetime': '06\/24\/2021, 03:57:58', 'body': \"In fact,I think the previous version is also safe,i try to do something bad but can't bypass  sanitizeShellString !! :( @sebhildebrandt\"}, 'com_2': {'author': 'Aaisui', 'datetime': '06\/24\/2021, 04:01:11', 'body': \"> In fact, I think the previous version is also safe, I try to do something bad but can't bypass sanitizeShellString !! :( @sebhildebrandt\\r\\n\\r\\nI hope you can give some trick for me XDDDD\"}}",
            "stats":"{'additions': 3, 'deletions': 4, 'total': 7}",
            "files":"{'lib\/internet.js': {'additions': 3, 'deletions': 4, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sebhildebrandt\/systeminformation\/raw\/01ef56cd5824ed6da1c11b37013a027fdef67524\/lib%2Finternet.js', 'patch': \"@@ -14,7 +14,6 @@\\n \/\/ ----------------------------------------------------------------------------------\\n \\n \/\/ const exec = require('child_process').exec;\\n-const execFile = require('child_process').execFile;\\n const util = require('.\/util');\\n \\n let _platform = process.platform;\\n@@ -213,9 +212,9 @@ function inetLatency(host, callback) {\\n         let result = null;\\n         try {\\n           const params = hostSanitized + ' -n 1';\\n-          execFile('ping', params.split(' '), util.execOptsWin, function (error, stdout) {\\n-            if (!error) {\\n-              let lines = stdout.toString().split('\\\\r\\\\n');\\n+          util.execSave('ping', params.split(' '), util.execOptsWin).then((stdout) => {\\n+            if (stdout) {\\n+              let lines = stdout.split('\\\\r\\\\n');\\n               lines.shift();\\n               lines.forEach(function (line) {\\n                 if ((line.toLowerCase().match(\/ms\/g) || []).length === 3) {\"}}",
            "message_norm":"sanitizeshellstring() and other security improvements",
            "language":"en",
            "entities":"[('sanitizeshellstring', 'SECWORD', ''), ('security', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/internet.js'])",
            "num_files":1.0,
            "patch_content":"From 01ef56cd5824ed6da1c11b37013a027fdef67524 Mon Sep 17 00:00:00 2001\nFrom: Sebastian Hildebrandt <hildebrandt@plus-innovations.com>\nDate: Mon, 15 Mar 2021 11:51:30 +0100\nSubject: [PATCH] sanitizeShellString() and other security improvements\n\n---\n lib\/internet.js | 7 +++----\n 1 file changed, 3 insertions(+), 4 deletions(-)\n\ndiff --git a\/lib\/internet.js b\/lib\/internet.js\nindex 1f75a712..2dc0d5a0 100644\n--- a\/lib\/internet.js\n+++ b\/lib\/internet.js\n@@ -14,7 +14,6 @@\n \/\/ ----------------------------------------------------------------------------------\n \n \/\/ const exec = require('child_process').exec;\n-const execFile = require('child_process').execFile;\n const util = require('.\/util');\n \n let _platform = process.platform;\n@@ -213,9 +212,9 @@ function inetLatency(host, callback) {\n         let result = null;\n         try {\n           const params = hostSanitized + ' -n 1';\n-          execFile('ping', params.split(' '), util.execOptsWin, function (error, stdout) {\n-            if (!error) {\n-              let lines = stdout.toString().split('\\r\\n');\n+          util.execSave('ping', params.split(' '), util.execOptsWin).then((stdout) => {\n+            if (stdout) {\n+              let lines = stdout.split('\\r\\n');\n               lines.shift();\n               lines.forEach(function (line) {\n                 if ((line.toLowerCase().match(\/ms\/g) || []).length === 3) {"
        },
        {
            "index":536,
            "vuln_id":"GHSA-qw5h-7f53-xrp6",
            "cwe_id":"{'CWE-674'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e07e1c3d26492c06f078c7e5bf2d138043e199c1'}",
            "dataset":"osv",
            "summary":"Stack overflow in `ParseAttrValue` with nested tensors ### Impact\nThe implementation of [`ParseAttrValue`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/c22d88d6ff33031aa113e48aa3fc9aa74ed79595\/tensorflow\/core\/framework\/attr_value_util.cc#L397-L453) can be tricked into stack overflow due to recursion by giving in a specially crafted input.\n\n### Patches\nWe have patched the issue in GitHub commit [e07e1c3d26492c06f078c7e5bf2d138043e199c1](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e07e1c3d26492c06f078c7e5bf2d138043e199c1).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e07e1c3d26492c06f078c7e5bf2d138043e199c1",
            "commit_sha":"e07e1c3d26492c06f078c7e5bf2d138043e199c1",
            "patch":"SINGLE",
            "chain_ord":"['e07e1c3d26492c06f078c7e5bf2d138043e199c1']",
            "before_first_fix_commit":"{'c22d88d6ff33031aa113e48aa3fc9aa74ed79595'}",
            "last_fix_commit":"e07e1c3d26492c06f078c7e5bf2d138043e199c1",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2021, 17:33:00",
            "message":"Prevent memory overflow in ParseAttrValue from nested tensors.\n\nPiperOrigin-RevId: 370108442\nChange-Id: I84d64a5e8895a6aeffbf4749841b4c54d51b5889",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 57, 'deletions': 1, 'total': 58}",
            "files":"{'tensorflow\/core\/framework\/attr_value_util.cc': {'additions': 57, 'deletions': 1, 'changes': 58, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e07e1c3d26492c06f078c7e5bf2d138043e199c1\/tensorflow%2Fcore%2Fframework%2Fattr_value_util.cc', 'patch': '@@ -38,6 +38,9 @@ namespace {\\n \/\/ Do not construct large tensors to compute their hash or compare for equality.\\n constexpr int kMaxAttrValueTensorByteSize = 32 * 1024 * 1024;  \/\/ 32mb\\n \\n+\/\/ Limit nesting of tensors to 100 deep to prevent memory overflow.\\n+constexpr int kMaxTensorNestDepth = 100;\\n+\\n \/\/ Return the size of the tensor represented by this TensorProto. If shape is\\n \/\/ not fully defined return -1.\\n int64 TensorByteSize(const TensorProto& t) {\\n@@ -224,6 +227,54 @@ string SummarizeFunc(const NameAttrList& func) {\\n   return strings::StrCat(func.name(), \"[\", absl::StrJoin(entries, \", \"), \"]\");\\n }\\n \\n+bool ParseAttrValueHelper_TensorNestsUnderLimit(int limit, string to_parse) {\\n+  int nests = 0;\\n+  int maxed_out = to_parse.length();\\n+  int open_curly = to_parse.find(\\'{\\');\\n+  int open_bracket = to_parse.find(\\'<\\');\\n+  int close_curly = to_parse.find(\\'}\\');\\n+  int close_bracket = to_parse.find(\\'>\\');\\n+  if (open_curly == -1) {\\n+    open_curly = maxed_out;\\n+  }\\n+  if (open_bracket == -1) {\\n+    open_bracket = maxed_out;\\n+  }\\n+  int min = std::min(open_curly, open_bracket);\\n+  do {\\n+    if (open_curly == maxed_out && open_bracket == maxed_out) {\\n+      return true;\\n+    }\\n+    if (min == open_curly) {\\n+      nests += 1;\\n+      open_curly = to_parse.find(\\'{\\', open_curly + 1);\\n+      if (open_curly == -1) {\\n+        open_curly = maxed_out;\\n+      }\\n+    } else if (min == open_bracket) {\\n+      nests += 1;\\n+      open_bracket = to_parse.find(\\'<\\', open_bracket + 1);\\n+      if (open_bracket == -1) {\\n+        open_bracket = maxed_out;\\n+      }\\n+    } else if (min == close_curly) {\\n+      nests -= 1;\\n+      close_curly = to_parse.find(\\'}\\', close_curly + 1);\\n+      if (close_curly == -1) {\\n+        close_curly = maxed_out;\\n+      }\\n+    } else if (min == close_bracket) {\\n+      nests -= 1;\\n+      close_bracket = to_parse.find(\\'>\\', close_bracket + 1);\\n+      if (close_bracket == -1) {\\n+        close_bracket = maxed_out;\\n+      }\\n+    }\\n+    min = std::min({open_curly, open_bracket, close_curly, close_bracket});\\n+  } while (nests < 100);\\n+  return false;\\n+}\\n+\\n }  \/\/ namespace\\n \\n string SummarizeAttrValue(const AttrValue& attr_value) {\\n@@ -448,7 +499,12 @@ bool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\\n   } else {\\n     to_parse = strings::StrCat(field_name, \": \", text);\\n   }\\n-\\n+  if (field_name == \"tensor\") {\\n+    if (!ParseAttrValueHelper_TensorNestsUnderLimit(kMaxTensorNestDepth,\\n+                                                    to_parse)) {\\n+      return false;\\n+    }\\n+  }\\n   return ProtoParseFromString(to_parse, out);\\n }'}}",
            "message_norm":"prevent memory overflow in parseattrvalue from nested tensors.\n\npiperorigin-revid: 370108442\nchange-id: i84d64a5e8895a6aeffbf4749841b4c54d51b5889",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('370108442', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/attr_value_util.cc'])",
            "num_files":1.0,
            "patch_content":"From e07e1c3d26492c06f078c7e5bf2d138043e199c1 Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Fri, 23 Apr 2021 10:33:00 -0700\nSubject: [PATCH] Prevent memory overflow in ParseAttrValue from nested\n tensors.\n\nPiperOrigin-RevId: 370108442\nChange-Id: I84d64a5e8895a6aeffbf4749841b4c54d51b5889\n---\n tensorflow\/core\/framework\/attr_value_util.cc | 58 +++++++++++++++++++-\n 1 file changed, 57 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/framework\/attr_value_util.cc b\/tensorflow\/core\/framework\/attr_value_util.cc\nindex 712e205c587c84..76fe36e7f1e2a6 100644\n--- a\/tensorflow\/core\/framework\/attr_value_util.cc\n+++ b\/tensorflow\/core\/framework\/attr_value_util.cc\n@@ -38,6 +38,9 @@ namespace {\n \/\/ Do not construct large tensors to compute their hash or compare for equality.\n constexpr int kMaxAttrValueTensorByteSize = 32 * 1024 * 1024;  \/\/ 32mb\n \n+\/\/ Limit nesting of tensors to 100 deep to prevent memory overflow.\n+constexpr int kMaxTensorNestDepth = 100;\n+\n \/\/ Return the size of the tensor represented by this TensorProto. If shape is\n \/\/ not fully defined return -1.\n int64 TensorByteSize(const TensorProto& t) {\n@@ -224,6 +227,54 @@ string SummarizeFunc(const NameAttrList& func) {\n   return strings::StrCat(func.name(), \"[\", absl::StrJoin(entries, \", \"), \"]\");\n }\n \n+bool ParseAttrValueHelper_TensorNestsUnderLimit(int limit, string to_parse) {\n+  int nests = 0;\n+  int maxed_out = to_parse.length();\n+  int open_curly = to_parse.find('{');\n+  int open_bracket = to_parse.find('<');\n+  int close_curly = to_parse.find('}');\n+  int close_bracket = to_parse.find('>');\n+  if (open_curly == -1) {\n+    open_curly = maxed_out;\n+  }\n+  if (open_bracket == -1) {\n+    open_bracket = maxed_out;\n+  }\n+  int min = std::min(open_curly, open_bracket);\n+  do {\n+    if (open_curly == maxed_out && open_bracket == maxed_out) {\n+      return true;\n+    }\n+    if (min == open_curly) {\n+      nests += 1;\n+      open_curly = to_parse.find('{', open_curly + 1);\n+      if (open_curly == -1) {\n+        open_curly = maxed_out;\n+      }\n+    } else if (min == open_bracket) {\n+      nests += 1;\n+      open_bracket = to_parse.find('<', open_bracket + 1);\n+      if (open_bracket == -1) {\n+        open_bracket = maxed_out;\n+      }\n+    } else if (min == close_curly) {\n+      nests -= 1;\n+      close_curly = to_parse.find('}', close_curly + 1);\n+      if (close_curly == -1) {\n+        close_curly = maxed_out;\n+      }\n+    } else if (min == close_bracket) {\n+      nests -= 1;\n+      close_bracket = to_parse.find('>', close_bracket + 1);\n+      if (close_bracket == -1) {\n+        close_bracket = maxed_out;\n+      }\n+    }\n+    min = std::min({open_curly, open_bracket, close_curly, close_bracket});\n+  } while (nests < 100);\n+  return false;\n+}\n+\n }  \/\/ namespace\n \n string SummarizeAttrValue(const AttrValue& attr_value) {\n@@ -448,7 +499,12 @@ bool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\n   } else {\n     to_parse = strings::StrCat(field_name, \": \", text);\n   }\n-\n+  if (field_name == \"tensor\") {\n+    if (!ParseAttrValueHelper_TensorNestsUnderLimit(kMaxTensorNestDepth,\n+                                                    to_parse)) {\n+      return false;\n+    }\n+  }\n   return ProtoParseFromString(to_parse, out);\n }"
        },
        {
            "index":279,
            "vuln_id":"GHSA-4hvf-hxvg-f67v",
            "cwe_id":"{'CWE-787', 'CWE-125'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038'}",
            "dataset":"osv",
            "summary":"Read and Write outside of bounds in TensorFlow ### Impact\nAn attacker can craft a TFLite model that would allow limited reads and writes outside of arrays in TFLite. This exploits missing validation in [the conversion from sparse tensors to dense tensors](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ca6f96b62ad84207fbec580404eaa7dd7403a550\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc#L252-L293).\n\n### Patches\nWe have patched the issue in GitHub commit [6364463d6f5b6254cac3d6aedf999b6a96225038](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038",
            "commit_sha":"6364463d6f5b6254cac3d6aedf999b6a96225038",
            "patch":"SINGLE",
            "chain_ord":"['6364463d6f5b6254cac3d6aedf999b6a96225038']",
            "before_first_fix_commit":"{'3e49ff637ad4f05c133d235a568943d19216fa9a'}",
            "last_fix_commit":"6364463d6f5b6254cac3d6aedf999b6a96225038",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/16\/2021, 23:37:14",
            "message":"[lite] Add some safety checks to avoid out of bound access for sparsity format\n\nPiperOrigin-RevId: 416910386\nChange-Id: Ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
            "author":"Karim Nosir",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 7, 'total': 18}",
            "files":"{'tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc': {'additions': 11, 'deletions': 7, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6364463d6f5b6254cac3d6aedf999b6a96225038\/tensorflow%2Flite%2Fkernels%2Finternal%2Futils%2Fsparsity_format_converter.cc', 'patch': '@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\\n   block_size_.resize(block_map_.size());\\n   for (int i = 0; i < original_rank; i++) {\\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\\n-      int orig_dim = traversal_order_[original_rank + block_dim];\\n-      block_size_[block_dim] = dense_size[orig_dim];\\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\\n-      block_dim++;\\n+      if (original_rank + block_dim < traversal_order_.size()) {\\n+        int orig_dim = traversal_order_[original_rank + block_dim];\\n+        block_size_[block_dim] = dense_size[orig_dim];\\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\\n+        block_dim++;\\n+      }\\n     } else {\\n       blocked_shape_[i] = dense_shape_[i];\\n     }\\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\\n                src_data_ptr, dest_data);\\n     }\\n-  } else {\\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\\n     const auto& array_segments = dim_metadata_[metadata_idx];\\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\\n          i++) {\\n-      indices[level] = array_indices[i];\\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      if (i < array_indices.size() && level < indices.size()) {\\n+        indices[level] = array_indices[i];\\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      }\\n     }\\n   }\\n }'}}",
            "message_norm":"[lite] add some safety checks to avoid out of bound access for sparsity format\n\npiperorigin-revid: 416910386\nchange-id: ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('safety checks', 'SECWORD', ''), ('out of bound access', 'SECWORD', ''), ('416910386', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc'])",
            "num_files":1.0,
            "patch_content":"From 6364463d6f5b6254cac3d6aedf999b6a96225038 Mon Sep 17 00:00:00 2001\nFrom: Karim Nosir <karimnosseir@google.com>\nDate: Thu, 16 Dec 2021 15:37:14 -0800\nSubject: [PATCH] [lite] Add some safety checks to avoid out of bound access\n for sparsity format\n\nPiperOrigin-RevId: 416910386\nChange-Id: Ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a\n---\n ...\/utils\/sparsity_format_converter.cc         | 18 +++++++++++-------\n 1 file changed, 11 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc b\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\nindex 22aa5d019e7395..0595d49365c387 100644\n--- a\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\n+++ b\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\n@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\n   block_size_.resize(block_map_.size());\n   for (int i = 0; i < original_rank; i++) {\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\n-      int orig_dim = traversal_order_[original_rank + block_dim];\n-      block_size_[block_dim] = dense_size[orig_dim];\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n-      block_dim++;\n+      if (original_rank + block_dim < traversal_order_.size()) {\n+        int orig_dim = traversal_order_[original_rank + block_dim];\n+        block_size_[block_dim] = dense_size[orig_dim];\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n+        block_dim++;\n+      }\n     } else {\n       blocked_shape_[i] = dense_shape_[i];\n     }\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\n                src_data_ptr, dest_data);\n     }\n-  } else {\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\n     const auto& array_segments = dim_metadata_[metadata_idx];\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\n          i++) {\n-      indices[level] = array_indices[i];\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      if (i < array_indices.size() && level < indices.size()) {\n+        indices[level] = array_indices[i];\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      }\n     }\n   }\n }"
        },
        {
            "index":244,
            "vuln_id":"GHSA-wqwf-x5cj-rg56",
            "cwe_id":"{'CWE-78'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/kubernetes\/kubernetes\/commit\/d65039c56ce4de5f2efdc38aa1284eeb95f89169'}",
            "dataset":"osv",
            "summary":"Arbitrary Command Injection In Kubernetes versions 1.9.0-1.9.9, 1.10.0-1.10.5, and 1.11.0-1.11.1, user input was handled insecurely while setting up volume mounts on Windows nodes, which could lead to command line argument injection.",
            "published_date":"2022-02-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/kubernetes\/kubernetes",
            "commit_href":"https:\/\/github.com\/kubernetes\/kubernetes\/commit\/d65039c56ce4de5f2efdc38aa1284eeb95f89169",
            "commit_sha":"d65039c56ce4de5f2efdc38aa1284eeb95f89169",
            "patch":"SINGLE",
            "chain_ord":"['d65039c56ce4de5f2efdc38aa1284eeb95f89169']",
            "before_first_fix_commit":"{'dc0afb24d138220cb53d9be3298f1539b0be4f7a', '27bc865cc1bffb97d4dff38492aa9f830f859e45'}",
            "last_fix_commit":"d65039c56ce4de5f2efdc38aa1284eeb95f89169",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/03\/2018, 13:16:06",
            "message":"Merge pull request #65751 from andyzhangx\/mount-windows-fix\n\nAutomatic merge from submit-queue (batch tested with PRs 65381, 65751). If you want to cherry-pick this change to another branch, please follow the instructions <a href=\"https:\/\/github.com\/kubernetes\/community\/blob\/master\/contributors\/devel\/cherry-picks.md\">here<\/a>.\n\nfix smb mount security issue\n\n**What this PR does \/ why we need it**:\r\nfix smb mount security issue:\r\nuser PowerShell Environment Variables to store user input string to prevent command line injection, the env var in PowerShell would be taken as literal values and not as executable vulnerable code, this kind of fix is common for command line injection issue (called: parameterized way)\r\n\r\nOriginally use go sdk for `New-SmbGlobalMapping` is best solution, while after discussion with Windows team, go API for `New-SmbGlobalMapping` is not ready yet and the new functionality of basic win32 API [NetUseAdd](https:\/\/msdn.microsoft.com\/en-us\/library\/windows\/desktop\/aa370645(v=vs.85).aspx) is not public yet, use [PowerShell with Environment Variables](https:\/\/docs.microsoft.com\/en-us\/powershell\/module\/microsoft.powershell.core\/about\/about_environment_variables?view=powershell-5.1) is also their recommended way.\r\n\r\n**Which issue(s) this PR fixes** *(optional, in `fixes #<issue number>(, fixes #<issue_number>, ...)` format, will close the issue(s) when PR gets merged)*:\r\nFixes #65750 \r\n\r\n**Special notes for your reviewer**:\r\n - This is a security issue fix, no behavior change, E2E test of smb mount passes.\r\n - Original logging as `azureMount` is incorrect since this mount_windows is for mount disk & smb, it's a common feature on Windows, not specific to Azure, I will send another PR to fixing all the logging naming issue, anyway it's not related to this security issue. Let's keep this PR simple.\r\n\r\n**Release note**:\r\n\r\n```\r\nfix smb mount security issue\r\n```\r\n\r\n\/sig windows\r\n\/sig storage\r\n\/kind bug\r\n\r\n@jessfraz \r\n\/assign @jsafrane @msau42",
            "author":"Kubernetes Submit Queue",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 6, 'total': 18}",
            "files":"{'pkg\/util\/mount\/mount_windows.go': {'additions': 12, 'deletions': 6, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/kubernetes\/kubernetes\/raw\/d65039c56ce4de5f2efdc38aa1284eeb95f89169\/pkg%2Futil%2Fmount%2Fmount_windows.go', 'patch': '@@ -83,14 +83,20 @@ func (mounter *Mounter) Mount(source string, target string, fstype string, optio\\n \\t\\t\\treturn fmt.Errorf(\"azureMount: only cifs mount is supported now, fstype: %q, mounting source (%q), target (%q), with options (%q)\", fstype, source, target, options)\\n \\t\\t}\\n \\n-\\t\\tcmdLine := fmt.Sprintf(`$User = \"%s\";$PWord = ConvertTo-SecureString -String \"%s\" -AsPlainText -Force;`+\\n-\\t\\t\\t`$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $User, $PWord`,\\n-\\t\\t\\toptions[0], options[1])\\n-\\n \\t\\tbindSource = source\\n-\\t\\tcmdLine += fmt.Sprintf(\";New-SmbGlobalMapping -RemotePath %s -Credential $Credential\", source)\\n \\n-\\t\\tif output, err := exec.Command(\"powershell\", \"\/c\", cmdLine).CombinedOutput(); err != nil {\\n+\\t\\t\/\/ use PowerShell Environment Variables to store user input string to prevent command line injection\\n+\\t\\t\/\/ https:\/\/docs.microsoft.com\/en-us\/powershell\/module\/microsoft.powershell.core\/about\/about_environment_variables?view=powershell-5.1\\n+\\t\\tcmdLine := fmt.Sprintf(`$PWord = ConvertTo-SecureString -String $Env:smbpassword -AsPlainText -Force` +\\n+\\t\\t\\t`;$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $Env:smbuser, $PWord` +\\n+\\t\\t\\t`;New-SmbGlobalMapping -RemotePath $Env:smbremotepath -Credential $Credential`)\\n+\\n+\\t\\tcmd := exec.Command(\"powershell\", \"\/c\", cmdLine)\\n+\\t\\tcmd.Env = append(os.Environ(),\\n+\\t\\t\\tfmt.Sprintf(\"smbuser=%s\", options[0]),\\n+\\t\\t\\tfmt.Sprintf(\"smbpassword=%s\", options[1]),\\n+\\t\\t\\tfmt.Sprintf(\"smbremotepath=%s\", source))\\n+\\t\\tif output, err := cmd.CombinedOutput(); err != nil {\\n \\t\\t\\treturn fmt.Errorf(\"azureMount: SmbGlobalMapping failed: %v, only SMB mount is supported now, output: %q\", err, string(output))\\n \\t\\t}\\n \\t}'}}",
            "message_norm":"merge pull request #65751 from andyzhangx\/mount-windows-fix\n\nautomatic merge from submit-queue (batch tested with prs 65381, 65751). if you want to cherry-pick this change to another branch, please follow the instructions <a href=\"https:\/\/github.com\/kubernetes\/community\/blob\/master\/contributors\/devel\/cherry-picks.md\">here<\/a>.\n\nfix smb mount security issue\n\n**what this pr does \/ why we need it**:\r\nfix smb mount security issue:\r\nuser powershell environment variables to store user input string to prevent command line injection, the env var in powershell would be taken as literal values and not as executable vulnerable code, this kind of fix is common for command line injection issue (called: parameterized way)\r\n\r\noriginally use go sdk for `new-smbglobalmapping` is best solution, while after discussion with windows team, go api for `new-smbglobalmapping` is not ready yet and the new functionality of basic win32 api [netuseadd](https:\/\/msdn.microsoft.com\/en-us\/library\/windows\/desktop\/aa370645(v=vs.85).aspx) is not public yet, use [powershell with environment variables](https:\/\/docs.microsoft.com\/en-us\/powershell\/module\/microsoft.powershell.core\/about\/about_environment_variables?view=powershell-5.1) is also their recommended way.\r\n\r\n**which issue(s) this pr fixes** *(optional, in `fixes #<issue number>(, fixes #<issue_number>, ...)` format, will close the issue(s) when pr gets merged)*:\r\nfixes #65750 \r\n\r\n**special notes for your reviewer**:\r\n - this is a security issue fix, no behavior change, e2e test of smb mount passes.\r\n - original logging as `azuremount` is incorrect since this mount_windows is for mount disk & smb, it's a common feature on windows, not specific to azure, i will send another pr to fixing all the logging naming issue, anyway it's not related to this security issue. let's keep this pr simple.\r\n\r\n**release note**:\r\n\r\n```\r\nfix smb mount security issue\r\n```\r\n\r\n\/sig windows\r\n\/sig storage\r\n\/kind bug\r\n\r\n@jessfraz \r\n\/assign @jsafrane @msau42",
            "language":"en",
            "entities":"[('#65751', 'ISSUE', ''), ('href=\"https:\/\/github.com', 'URL', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('prevent', 'ACTION', ''), ('injection', 'SECWORD', ''), ('vulnerable', 'SECWORD', ''), ('injection', 'SECWORD', ''), ('issue', 'FLAW', ''), ('netuseadd](https:\/\/msdn.microsoft.com', 'URL', ''), ('variables](https:\/\/docs.microsoft.com', 'URL', ''), ('issue(s', 'FLAW', ''), ('fixes', 'ACTION', ''), ('fixes', 'ACTION', ''), ('issue', 'FLAW', ''), ('fixes', 'ACTION', ''), ('issue(s', 'FLAW', ''), ('fixes', 'ACTION', ''), ('#65750', 'ISSUE', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('fixing', 'ACTION', ''), ('issue', 'FLAW', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('bug', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['pkg\/util\/mount\/mount_windows.go'])",
            "num_files":1.0,
            "patch_content":"From 27bc865cc1bffb97d4dff38492aa9f830f859e45 Mon Sep 17 00:00:00 2001\nFrom: andyzhangx <xiazhang@microsoft.com>\nDate: Tue, 3 Jul 2018 08:03:31 +0000\nSubject: [PATCH] fix smb mount security issue\n\n---\n pkg\/util\/mount\/mount_windows.go | 18 ++++++++++++------\n 1 file changed, 12 insertions(+), 6 deletions(-)\n\ndiff --git a\/pkg\/util\/mount\/mount_windows.go b\/pkg\/util\/mount\/mount_windows.go\nindex 2aa92ca1df24e..a690167a99828 100644\n--- a\/pkg\/util\/mount\/mount_windows.go\n+++ b\/pkg\/util\/mount\/mount_windows.go\n@@ -83,14 +83,20 @@ func (mounter *Mounter) Mount(source string, target string, fstype string, optio\n \t\t\treturn fmt.Errorf(\"azureMount: only cifs mount is supported now, fstype: %q, mounting source (%q), target (%q), with options (%q)\", fstype, source, target, options)\n \t\t}\n \n-\t\tcmdLine := fmt.Sprintf(`$User = \"%s\";$PWord = ConvertTo-SecureString -String \"%s\" -AsPlainText -Force;`+\n-\t\t\t`$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $User, $PWord`,\n-\t\t\toptions[0], options[1])\n-\n \t\tbindSource = source\n-\t\tcmdLine += fmt.Sprintf(\";New-SmbGlobalMapping -RemotePath %s -Credential $Credential\", source)\n \n-\t\tif output, err := exec.Command(\"powershell\", \"\/c\", cmdLine).CombinedOutput(); err != nil {\n+\t\t\/\/ use PowerShell Environment Variables to store user input string to prevent command line injection\n+\t\t\/\/ https:\/\/docs.microsoft.com\/en-us\/powershell\/module\/microsoft.powershell.core\/about\/about_environment_variables?view=powershell-5.1\n+\t\tcmdLine := fmt.Sprintf(`$PWord = ConvertTo-SecureString -String $Env:smbpassword -AsPlainText -Force` +\n+\t\t\t`;$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $Env:smbuser, $PWord` +\n+\t\t\t`;New-SmbGlobalMapping -RemotePath $Env:smbremotepath -Credential $Credential`)\n+\n+\t\tcmd := exec.Command(\"powershell\", \"\/c\", cmdLine)\n+\t\tcmd.Env = append(os.Environ(),\n+\t\t\tfmt.Sprintf(\"smbuser=%s\", options[0]),\n+\t\t\tfmt.Sprintf(\"smbpassword=%s\", options[1]),\n+\t\t\tfmt.Sprintf(\"smbremotepath=%s\", source))\n+\t\tif output, err := cmd.CombinedOutput(); err != nil {\n \t\t\treturn fmt.Errorf(\"azureMount: SmbGlobalMapping failed: %v, only SMB mount is supported now, output: %q\", err, string(output))\n \t\t}\n \t}"
        },
        {
            "index":621,
            "vuln_id":"GHSA-j8qc-5fqr-52fp",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c570e2ecfc822941335ad48f6e10df4e21f11c96'}",
            "dataset":"osv",
            "summary":"Division by zero in `Conv2DBackpropFilter` ### Impact\nAn attacker can cause a division by zero to occur in `Conv2DBackpropFilter`:\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nfilter_sizes = tf.constant([0, 0, 0, 0], shape=[4], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropFilter(\n  input=input_tensor,\n  filter_sizes=filter_sizes,\n  out_backprop=out_backprop,\n  strides=[1, 1, 1, 1],\n  use_cudnn_on_gpu=False,\n  padding='SAME',\n  explicit_paddings=[],\n  data_format='NHWC',\n  dilations=[1, 1, 1, 1]\n)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/1b0296c3b8dd9bd948f924aa8cd62f87dbb7c3da\/tensorflow\/core\/kernels\/conv_grad_filter_ops.cc#L513-L522) computes a divisor based on user provided data (i.e., the shape of the tensors given as arguments):\n\n```cc\nconst size_t size_A = output_image_size * filter_total_size; \nconst size_t size_B = output_image_size * dims.out_depth;\nconst size_t size_C = filter_total_size * dims.out_depth;\nconst size_t work_unit_size = size_A + size_B + size_C;\nconst size_t shard_size = (target_working_set_size + work_unit_size - 1) \/ work_unit_size;\n```\n\nIf all shapes are empty then `work_unit_size` is 0. Since there is no check for this case before division, this results in a runtime exception, with potential to be abused for a denial of service. \n\n### Patches\nWe have patched the issue in GitHub commit [c570e2ecfc822941335ad48f6e10df4e21f11c96](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c570e2ecfc822941335ad48f6e10df4e21f11c96).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c570e2ecfc822941335ad48f6e10df4e21f11c96",
            "commit_sha":"c570e2ecfc822941335ad48f6e10df4e21f11c96",
            "patch":"SINGLE",
            "chain_ord":"['c570e2ecfc822941335ad48f6e10df4e21f11c96']",
            "before_first_fix_commit":"{'1b0296c3b8dd9bd948f924aa8cd62f87dbb7c3da'}",
            "last_fix_commit":"c570e2ecfc822941335ad48f6e10df4e21f11c96",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/22\/2021, 00:50:10",
            "message":"Fix issues in Conv2DBackpropFilter.\n\nPiperOrigin-RevId: 369772454\nChange-Id: I49b465f2ae2ce91def61b56cea8000197d5177d8",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
            "files":"{'tensorflow\/core\/kernels\/conv_grad_filter_ops.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c570e2ecfc822941335ad48f6e10df4e21f11c96\/tensorflow%2Fcore%2Fkernels%2Fconv_grad_filter_ops.cc', 'patch': '@@ -495,6 +495,14 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\\n     const int filter_total_size = dims.spatial_dims[0].filter_size *\\n                                   dims.spatial_dims[1].filter_size *\\n                                   dims.in_depth;\\n+    OP_REQUIRES(\\n+        context,\\n+        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\\n+        errors::InvalidArgument(\\n+            \"filter_size does not have enough elements, requested \",\\n+            filter_total_size * dims.out_depth, \", got \",\\n+            filter_backprop->NumElements()));\\n+\\n     \/\/ The output image size is the spatial size of the output.\\n     const int output_image_size =\\n         dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\\n@@ -518,6 +526,11 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\\n \\n     const size_t work_unit_size = size_A + size_B + size_C;\\n \\n+    OP_REQUIRES(\\n+        context, work_unit_size != 0,\\n+        errors::InvalidArgument(\\n+            \"Work size for convolution would be 0, which is not acceptable\"));\\n+\\n     const size_t shard_size =\\n         (target_working_set_size + work_unit_size - 1) \/ work_unit_size;'}}",
            "message_norm":"fix issues in conv2dbackpropfilter.\n\npiperorigin-revid: 369772454\nchange-id: i49b465f2ae2ce91def61b56cea8000197d5177d8",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('issues', 'FLAW', ''), ('369772454', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/conv_grad_filter_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From c570e2ecfc822941335ad48f6e10df4e21f11c96 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 21 Apr 2021 17:50:10 -0700\nSubject: [PATCH] Fix issues in Conv2DBackpropFilter.\n\nPiperOrigin-RevId: 369772454\nChange-Id: I49b465f2ae2ce91def61b56cea8000197d5177d8\n---\n tensorflow\/core\/kernels\/conv_grad_filter_ops.cc | 13 +++++++++++++\n 1 file changed, 13 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/conv_grad_filter_ops.cc b\/tensorflow\/core\/kernels\/conv_grad_filter_ops.cc\nindex fb48e3e285a27c..2645d850ab7cfb 100644\n--- a\/tensorflow\/core\/kernels\/conv_grad_filter_ops.cc\n+++ b\/tensorflow\/core\/kernels\/conv_grad_filter_ops.cc\n@@ -495,6 +495,14 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n     const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                   dims.spatial_dims[1].filter_size *\n                                   dims.in_depth;\n+    OP_REQUIRES(\n+        context,\n+        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\n+        errors::InvalidArgument(\n+            \"filter_size does not have enough elements, requested \",\n+            filter_total_size * dims.out_depth, \", got \",\n+            filter_backprop->NumElements()));\n+\n     \/\/ The output image size is the spatial size of the output.\n     const int output_image_size =\n         dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n@@ -518,6 +526,11 @@ class Conv2DCustomBackpropFilterOp : public OpKernel {\n \n     const size_t work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size != 0,\n+        errors::InvalidArgument(\n+            \"Work size for convolution would be 0, which is not acceptable\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) \/ work_unit_size;"
        },
        {
            "index":534,
            "vuln_id":"GHSA-wf5x-cr3r-xr77",
            "cwe_id":"{'CWE-674'}",
            "score":8.3,
            "chain":"{'https:\/\/github.com\/patriksimek\/vm2\/commit\/4b22d704e4794af63a5a2d633385fd20948f6f90'}",
            "dataset":"osv",
            "summary":"vm2 before 3.6.11 vulnerable to sandbox escape This affects the package vm2 before 3.6.11. It is possible to trigger a RangeError exception from the host rather than the \"sandboxed\" context by reaching the stack call limit with an infinite recursion. The returned object is then used to reference the mainModule property of the host code running the script allowing it to spawn a child_process and execute arbitrary code.",
            "published_date":"2022-07-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/patriksimek\/vm2",
            "commit_href":"https:\/\/github.com\/patriksimek\/vm2\/commit\/4b22d704e4794af63a5a2d633385fd20948f6f90",
            "commit_sha":"4b22d704e4794af63a5a2d633385fd20948f6f90",
            "patch":"SINGLE",
            "chain_ord":"['4b22d704e4794af63a5a2d633385fd20948f6f90']",
            "before_first_fix_commit":"{'2ac8ff254a71e516e83f6496635fa61420447fa9'}",
            "last_fix_commit":"4b22d704e4794af63a5a2d633385fd20948f6f90",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/07\/2019, 23:46:03",
            "message":"Fixes sandbox escape (#197)",
            "author":"Patrik Simek",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 16, 'total': 32}",
            "files":"{'lib\/contextify.js': {'additions': 16, 'deletions': 16, 'changes': 32, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/patriksimek\/vm2\/raw\/4b22d704e4794af63a5a2d633385fd20948f6f90\/lib%2Fcontextify.js', 'patch': \"@@ -327,15 +327,15 @@ Decontextify.object = (object, traps, deepTraps, flags, mock) => {\\n \\treturn proxy;\\n };\\n Decontextify.value = (value, traps, deepTraps, flags, mock) => {\\n-\\tif (Contextified.has(value)) {\\n-\\t\\t\/\/ Contextified object has returned back from vm\\n-\\t\\treturn Contextified.get(value);\\n-\\t} else if (Decontextify.proxies.has(value)) {\\n-\\t\\t\/\/ Decontextified proxy already exists, reuse\\n-\\t\\treturn Decontextify.proxies.get(value);\\n-\\t}\\n-\\n \\ttry {\\n+\\t\\tif (Contextified.has(value)) {\\n+\\t\\t\\t\/\/ Contextified object has returned back from vm\\n+\\t\\t\\treturn Contextified.get(value);\\n+\\t\\t} else if (Decontextify.proxies.has(value)) {\\n+\\t\\t\\t\/\/ Decontextified proxy already exists, reuse\\n+\\t\\t\\treturn Decontextify.proxies.get(value);\\n+\\t\\t}\\n+\\n \\t\\tswitch (typeof value) {\\n \\t\\t\\tcase 'object':\\n \\t\\t\\t\\tif (value === null) {\\n@@ -621,15 +621,15 @@ Contextify.object = (object, traps, deepTraps, flags, mock) => {\\n \\treturn proxy;\\n };\\n Contextify.value = (value, traps, deepTraps, flags, mock) => {\\n-\\tif (Decontextified.has(value)) {\\n-\\t\\t\/\/ Decontextified object has returned back to vm\\n-\\t\\treturn Decontextified.get(value);\\n-\\t} else if (Contextify.proxies.has(value)) {\\n-\\t\\t\/\/ Contextified proxy already exists, reuse\\n-\\t\\treturn Contextify.proxies.get(value);\\n-\\t}\\n-\\n \\ttry {\\n+\\t\\tif (Decontextified.has(value)) {\\n+\\t\\t\\t\/\/ Decontextified object has returned back to vm\\n+\\t\\t\\treturn Decontextified.get(value);\\n+\\t\\t} else if (Contextify.proxies.has(value)) {\\n+\\t\\t\\t\/\/ Contextified proxy already exists, reuse\\n+\\t\\t\\treturn Contextify.proxies.get(value);\\n+\\t\\t}\\n+\\n \\t\\tswitch (typeof value) {\\n \\t\\t\\tcase 'object':\\n \\t\\t\\t\\tif (value === null) {\"}}",
            "message_norm":"fixes sandbox escape (#197)",
            "language":"ca",
            "entities":"[('fixes', 'ACTION', ''), ('sandbox', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('#197', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/contextify.js'])",
            "num_files":1.0,
            "patch_content":"From 4b22d704e4794af63a5a2d633385fd20948f6f90 Mon Sep 17 00:00:00 2001\nFrom: Patrik Simek <patrik@patriksimek.cz>\nDate: Mon, 8 Apr 2019 01:46:03 +0200\nSubject: [PATCH] Fixes sandbox escape (#197)\n\n---\n lib\/contextify.js | 32 ++++++++++++++++----------------\n 1 file changed, 16 insertions(+), 16 deletions(-)\n\ndiff --git a\/lib\/contextify.js b\/lib\/contextify.js\nindex 361fb8a..97acccf 100644\n--- a\/lib\/contextify.js\n+++ b\/lib\/contextify.js\n@@ -327,15 +327,15 @@ Decontextify.object = (object, traps, deepTraps, flags, mock) => {\n \treturn proxy;\n };\n Decontextify.value = (value, traps, deepTraps, flags, mock) => {\n-\tif (Contextified.has(value)) {\n-\t\t\/\/ Contextified object has returned back from vm\n-\t\treturn Contextified.get(value);\n-\t} else if (Decontextify.proxies.has(value)) {\n-\t\t\/\/ Decontextified proxy already exists, reuse\n-\t\treturn Decontextify.proxies.get(value);\n-\t}\n-\n \ttry {\n+\t\tif (Contextified.has(value)) {\n+\t\t\t\/\/ Contextified object has returned back from vm\n+\t\t\treturn Contextified.get(value);\n+\t\t} else if (Decontextify.proxies.has(value)) {\n+\t\t\t\/\/ Decontextified proxy already exists, reuse\n+\t\t\treturn Decontextify.proxies.get(value);\n+\t\t}\n+\n \t\tswitch (typeof value) {\n \t\t\tcase 'object':\n \t\t\t\tif (value === null) {\n@@ -621,15 +621,15 @@ Contextify.object = (object, traps, deepTraps, flags, mock) => {\n \treturn proxy;\n };\n Contextify.value = (value, traps, deepTraps, flags, mock) => {\n-\tif (Decontextified.has(value)) {\n-\t\t\/\/ Decontextified object has returned back to vm\n-\t\treturn Decontextified.get(value);\n-\t} else if (Contextify.proxies.has(value)) {\n-\t\t\/\/ Contextified proxy already exists, reuse\n-\t\treturn Contextify.proxies.get(value);\n-\t}\n-\n \ttry {\n+\t\tif (Decontextified.has(value)) {\n+\t\t\t\/\/ Decontextified object has returned back to vm\n+\t\t\treturn Decontextified.get(value);\n+\t\t} else if (Contextify.proxies.has(value)) {\n+\t\t\t\/\/ Contextified proxy already exists, reuse\n+\t\t\treturn Contextify.proxies.get(value);\n+\t\t}\n+\n \t\tswitch (typeof value) {\n \t\t\tcase 'object':\n \t\t\t\tif (value === null) {"
        },
        {
            "index":823,
            "vuln_id":"GHSA-wf5p-c75w-w3wh",
            "cwe_id":"{'CWE-476'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6b57f461b39fd1aa8c1b870f1b974aac3554955'}",
            "dataset":"osv",
            "summary":"Null pointer dereference in TFLite MLIR optimizations ### Impact\nAn attacker can craft a TFLite model that would trigger a null pointer dereference, which would result in a crash and denial of service:\n\nThis is caused by the MLIR optimization of `L2NormalizeReduceAxis` operator. The [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/compiler\/mlir\/lite\/transforms\/optimize.cc#L67-L70) unconditionally dereferences a pointer to an iterator to a vector without checking that the vector has elements:\n\n```cc\nbool L2NormalizeReduceAxis(Value sq_op, DenseElementsAttr axis) {\n  if (sq_op.getType().cast<ShapedType>().getRank() - 1 ==\n          *axis.getValues<int>().begin() ||\n      *axis.getValues<int>().begin() == -1) {\n      \/\/ ...\n  }\n  \/\/ ...\n}\n```\n\n### Patches\nWe have patched the issue in GitHub commit [d6b57f461b39fd1aa8c1b870f1b974aac3554955](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6b57f461b39fd1aa8c1b870f1b974aac3554955).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n          \n### Attribution              \nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6b57f461b39fd1aa8c1b870f1b974aac3554955",
            "commit_sha":"d6b57f461b39fd1aa8c1b870f1b974aac3554955",
            "patch":"SINGLE",
            "chain_ord":"['d6b57f461b39fd1aa8c1b870f1b974aac3554955']",
            "before_first_fix_commit":"{'c26b15e7565e4f50ad6ea25b09127a019ad77c14'}",
            "last_fix_commit":"d6b57f461b39fd1aa8c1b870f1b974aac3554955",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 23:20:45",
            "message":"Prevent nullptr dereference in MLIR TFLite dialect\/optimizer.\n\nPiperOrigin-RevId: 387220762\nChange-Id: Id136ef04bb3d36123b4685d316ae81a9ec924d6b",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/compiler\/mlir\/lite\/transforms\/optimize.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/d6b57f461b39fd1aa8c1b870f1b974aac3554955\/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize.cc', 'patch': '@@ -68,6 +68,9 @@ constexpr char kRelu6[] = \"RELU6\";\\n constexpr char kRelu1[] = \"RELU_N1_TO_1\";\\n \\n bool L2NormalizeReduceAxis(Value sq_op, DenseElementsAttr axis) {\\n+  if (axis.getNumElements() == 0) {\\n+    return false;\\n+  }\\n   if (sq_op.getType().cast<ShapedType>().getRank() - 1 ==\\n           *axis.getValues<int>().begin() ||\\n       *axis.getValues<int>().begin() == -1) {'}}",
            "message_norm":"prevent nullptr dereference in mlir tflite dialect\/optimizer.\n\npiperorigin-revid: 387220762\nchange-id: id136ef04bb3d36123b4685d316ae81a9ec924d6b",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('387220762', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/compiler\/mlir\/lite\/transforms\/optimize.cc'])",
            "num_files":1.0,
            "patch_content":"From d6b57f461b39fd1aa8c1b870f1b974aac3554955 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 27 Jul 2021 16:20:45 -0700\nSubject: [PATCH] Prevent nullptr dereference in MLIR TFLite dialect\/optimizer.\n\nPiperOrigin-RevId: 387220762\nChange-Id: Id136ef04bb3d36123b4685d316ae81a9ec924d6b\n---\n tensorflow\/compiler\/mlir\/lite\/transforms\/optimize.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/compiler\/mlir\/lite\/transforms\/optimize.cc b\/tensorflow\/compiler\/mlir\/lite\/transforms\/optimize.cc\nindex d457612bf70eed..6a8803d2461594 100644\n--- a\/tensorflow\/compiler\/mlir\/lite\/transforms\/optimize.cc\n+++ b\/tensorflow\/compiler\/mlir\/lite\/transforms\/optimize.cc\n@@ -68,6 +68,9 @@ constexpr char kRelu6[] = \"RELU6\";\n constexpr char kRelu1[] = \"RELU_N1_TO_1\";\n \n bool L2NormalizeReduceAxis(Value sq_op, DenseElementsAttr axis) {\n+  if (axis.getNumElements() == 0) {\n+    return false;\n+  }\n   if (sq_op.getType().cast<ShapedType>().getRank() - 1 ==\n           *axis.getValues<int>().begin() ||\n       *axis.getValues<int>().begin() == -1) {"
        },
        {
            "index":101,
            "vuln_id":"GHSA-m7fm-4jfh-jrg6",
            "cwe_id":"{'CWE-416'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5ecec9c6fbdbc6be03295685190a45e7eee726ab'}",
            "dataset":"osv",
            "summary":"Use after free in boosted trees creation ### Impact\nThe implementation for `tf.raw_ops.BoostedTreesCreateEnsemble` can result in a use after free error if an attacker supplies specially crafted arguments:\n\n```python\nimport tensorflow as tf\n\nv= tf.Variable([0.0])\ntf.raw_ops.BoostedTreesCreateEnsemble(\n  tree_ensemble_handle=v.handle,\n  stamp_token=[0],\n  tree_ensemble_serialized=['0']) \n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/boosted_trees\/resource_ops.cc#L55) uses a reference counted resource and decrements the refcount if the initialization fails, as it should. However, when the code was written, the  resource was represented as a naked pointer but later refactoring has changed it to be a smart pointer. Thus, when the pointer leaves the scope, a subsequent `free`-ing of the resource occurs, but this fails to take into account that the refcount has already reached 0, thus the resource has been already freed. During this double-free process, members of the resource object are accessed for cleanup but they are invalid as the entire resource has been freed.\n\n### Patches\nWe have patched the issue in GitHub commit [5ecec9c6fbdbc6be03295685190a45e7eee726ab](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5ecec9c6fbdbc6be03295685190a45e7eee726ab).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5ecec9c6fbdbc6be03295685190a45e7eee726ab",
            "commit_sha":"5ecec9c6fbdbc6be03295685190a45e7eee726ab",
            "patch":"SINGLE",
            "chain_ord":"['5ecec9c6fbdbc6be03295685190a45e7eee726ab']",
            "before_first_fix_commit":"{'d8a39f2dc1cba935ba153092a09e7d4bb2ce5ee2'}",
            "last_fix_commit":"5ecec9c6fbdbc6be03295685190a45e7eee726ab",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/31\/2021, 02:13:19",
            "message":"Prevent use after free.\n\nA very old version of the code used `result` as a simple pointer to a resource. Two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `Unref`. Three years after that, we finally uncover the UAF.\n\nPiperOrigin-RevId: 387924872\nChange-Id: I70fb6f199164de49fac20c168132a07b84903f9b",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/resource_ops.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/5ecec9c6fbdbc6be03295685190a45e7eee726ab\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fresource_ops.cc', 'patch': '@@ -53,6 +53,7 @@ class BoostedTreesCreateEnsembleOp : public OpKernel {\\n     if (!result->InitFromSerialized(\\n             tree_ensemble_serialized_t->scalar<tstring>()(), stamp_token)) {\\n       result->Unref();\\n+      result.release();  \/\/ Needed due to the `->Unref` above, to prevent UAF\\n       OP_REQUIRES(\\n           context, false,\\n           errors::InvalidArgument(\"Unable to parse tree ensemble proto.\"));'}}",
            "message_norm":"prevent use after free.\n\na very old version of the code used `result` as a simple pointer to a resource. two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `unref`. three years after that, we finally uncover the uaf.\n\npiperorigin-revid: 387924872\nchange-id: i70fb6f199164de49fac20c168132a07b84903f9b",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('use after free', 'SECWORD', ''), ('changed', 'ACTION', ''), ('remove', 'ACTION', ''), ('387924872', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/resource_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 5ecec9c6fbdbc6be03295685190a45e7eee726ab Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 19:13:19 -0700\nSubject: [PATCH] Prevent use after free.\n\nA very old version of the code used `result` as a simple pointer to a resource. Two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `Unref`. Three years after that, we finally uncover the UAF.\n\nPiperOrigin-RevId: 387924872\nChange-Id: I70fb6f199164de49fac20c168132a07b84903f9b\n---\n tensorflow\/core\/kernels\/boosted_trees\/resource_ops.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/boosted_trees\/resource_ops.cc b\/tensorflow\/core\/kernels\/boosted_trees\/resource_ops.cc\nindex d50885fa3f5113..f2c60b9b4511de 100644\n--- a\/tensorflow\/core\/kernels\/boosted_trees\/resource_ops.cc\n+++ b\/tensorflow\/core\/kernels\/boosted_trees\/resource_ops.cc\n@@ -53,6 +53,7 @@ class BoostedTreesCreateEnsembleOp : public OpKernel {\n     if (!result->InitFromSerialized(\n             tree_ensemble_serialized_t->scalar<tstring>()(), stamp_token)) {\n       result->Unref();\n+      result.release();  \/\/ Needed due to the `->Unref` above, to prevent UAF\n       OP_REQUIRES(\n           context, false,\n           errors::InvalidArgument(\"Unable to parse tree ensemble proto.\"));"
        },
        {
            "index":733,
            "vuln_id":"GHSA-55j9-849x-26h4",
            "cwe_id":"{'CWE-74'}",
            "score":8.2,
            "chain":"{'https:\/\/github.com\/Cog-Creators\/Red-DiscordBot\/pull\/4175\/commits\/9ab536235bafc2b42c3c17d7ce26f1cc64482a81'}",
            "dataset":"osv",
            "summary":"Remote Code Execution in Red Discord Bot ### Impact\nA RCE exploit has been discovered in the Trivia module: this exploit allows Discord users with specifically crafted usernames to inject code into the Trivia module's leaderboard command. By abusing this exploit, it's possible to perform destructive actions and\/or access sensitive information.\n\n### Patches\nThis critical exploit has been fixed on version 3.3.11.\n\n### Workarounds\nUnloading the Trivia module with ``unload trivia`` can render this exploit not accessible. We still highly recommend updating to 3.3.11 to completely patch this issue.\n\n### References\nhttps:\/\/github.com\/Cog-Creators\/Red-DiscordBot\/pull\/4175\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Cog-Creators\/Red-DiscordBot](https:\/\/github.com\/Cog-Creators\/Red-DiscordBot)\n* Over on our [Discord server](https:\/\/discord.gg\/red)",
            "published_date":"2020-08-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/Cog-Creators\/Red-DiscordBot",
            "commit_href":"https:\/\/github.com\/Cog-Creators\/Red-DiscordBot\/pull\/4175\/commits\/9ab536235bafc2b42c3c17d7ce26f1cc64482a81",
            "commit_sha":"9ab536235bafc2b42c3c17d7ce26f1cc64482a81",
            "patch":"SINGLE",
            "chain_ord":"['9ab536235bafc2b42c3c17d7ce26f1cc64482a81']",
            "before_first_fix_commit":"{'c8526d42b4299d50b0c69f86204723cc82754453'}",
            "last_fix_commit":"9ab536235bafc2b42c3c17d7ce26f1cc64482a81",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/09\/2020, 23:11:15",
            "message":"Remove an unnecessary `.format`",
            "author":"Flame442",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'redbot\/cogs\/trivia\/trivia.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Cog-Creators\/Red-DiscordBot\/raw\/9ab536235bafc2b42c3c17d7ce26f1cc64482a81\/redbot%2Fcogs%2Ftrivia%2Ftrivia.py', 'patch': '@@ -539,7 +539,7 @@ def _get_leaderboard(data: dict, key: str, top: int):\\n             )\\n             padding = [\" \" * (len(h) - len(f)) for h, f in zip(headers, fields)]\\n             fields = tuple(f + padding[i] for i, f in enumerate(fields))\\n-            lines.append(\" | \".join(fields).format(member=member, **m_data))\\n+            lines.append(\" | \".join(fields))\\n             if rank == top:\\n                 break\\n         return \"\\\\n\".join(lines)'}}",
            "message_norm":"remove an unnecessary `.format`",
            "language":"en",
            "entities":"[('remove', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['redbot\/cogs\/trivia\/trivia.py'])",
            "num_files":1.0,
            "patch_content":"From 9ab536235bafc2b42c3c17d7ce26f1cc64482a81 Mon Sep 17 00:00:00 2001\nFrom: Flame442 <34169552+Flame442@users.noreply.github.com>\nDate: Sun, 9 Aug 2020 19:11:15 -0400\nSubject: [PATCH] Remove an unnecessary `.format`\n\n---\n redbot\/cogs\/trivia\/trivia.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/redbot\/cogs\/trivia\/trivia.py b\/redbot\/cogs\/trivia\/trivia.py\nindex b428605fd6d..4f80edd6e01 100644\n--- a\/redbot\/cogs\/trivia\/trivia.py\n+++ b\/redbot\/cogs\/trivia\/trivia.py\n@@ -539,7 +539,7 @@ def _get_leaderboard(data: dict, key: str, top: int):\n             )\n             padding = [\" \" * (len(h) - len(f)) for h, f in zip(headers, fields)]\n             fields = tuple(f + padding[i] for i, f in enumerate(fields))\n-            lines.append(\" | \".join(fields).format(member=member, **m_data))\n+            lines.append(\" | \".join(fields))\n             if rank == top:\n                 break\n         return \"\\n\".join(lines)"
        },
        {
            "index":640,
            "vuln_id":"GHSA-xrr4-74mc-rpjc",
            "cwe_id":"{'CWE-59'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/irmen\/Pyro3\/commit\/554e095a62c4412c91f981e72fd34a936ac2bf1e'}",
            "dataset":"osv",
            "summary":"Pyro mishandles pid files in temporary directory locations and opening the pid file as root pyro before 3.15 unsafely handles pid files in temporary directory locations and opening the pid file as root. An attacker can use this flaw to overwrite arbitrary files via symlinks.",
            "published_date":"2018-08-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/irmen\/Pyro3",
            "commit_href":"https:\/\/github.com\/irmen\/Pyro3\/commit\/554e095a62c4412c91f981e72fd34a936ac2bf1e",
            "commit_sha":"554e095a62c4412c91f981e72fd34a936ac2bf1e",
            "patch":"SINGLE",
            "chain_ord":"['554e095a62c4412c91f981e72fd34a936ac2bf1e']",
            "before_first_fix_commit":"{'1df908f8e8bd3eaf0fd2f1b80d38405f6a10328d'}",
            "last_fix_commit":"554e095a62c4412c91f981e72fd34a936ac2bf1e",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/01\/2011, 13:32:40",
            "message":"changed pidfile location because of security vulnerability, debian bug #631912",
            "author":"irmen",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 1, 'total': 8}",
            "files":"{'Pyro\/ext\/daemonizer.py': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/irmen\/Pyro3\/raw\/554e095a62c4412c91f981e72fd34a936ac2bf1e\/Pyro%2Fext%2Fdaemonizer.py', 'patch': '@@ -47,7 +47,9 @@ class Daemonizer:\\n     \"\"\"\\n     def __init__(self, pidfile=None):\\n         if not pidfile:\\n-            self.pidfile = \"\/tmp\/%s.pid\" % self.__class__.__name__.lower()\\n+            # PID file moved out of \/tmp to avoid security vulnerability\\n+            # changed by Debian maintainer per Debian bug #631912\\n+            self.pidfile = \"\/var\/run\/pyro-%s.pid\" % self.__class__.__name__.lower()\\n         else:\\n             self.pidfile = pidfile\\n \\n@@ -121,12 +123,16 @@ def main_loop(self):\\n \\n     def process_command_line(self, argv, verbose=1):\\n         usage = \"usage:  %s  start | stop | restart | status | debug \" \\\\\\n+                \"[--pidfile=...] \" \\\\\\n                 \"(run as non-daemon)\" % os.path.basename(argv[0])\\n         if len(argv) < 2:\\n             print usage\\n             raise SystemExit\\n         else:\\n             operation = argv[1]\\n+            if len(argv) > 2 and argv[2].startswith(\\'--pidfile=\\') and \\\\\\n+                len(argv[2]) > len(\\'--pidfile=\\'):\\n+                self.pidfile = argv[2][len(\\'--pidfile=\\'):]\\n         pid = self.get_pid()\\n         if operation == \\'status\\':\\n             if self.is_process_running():'}}",
            "message_norm":"changed pidfile location because of security vulnerability, debian bug #631912",
            "language":"en",
            "entities":"[('changed', 'ACTION', ''), ('security', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('bug', 'FLAW', ''), ('#631912', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Pyro\/ext\/daemonizer.py'])",
            "num_files":1.0,
            "patch_content":"From 554e095a62c4412c91f981e72fd34a936ac2bf1e Mon Sep 17 00:00:00 2001\nFrom: irmen <irmen@08cfa0ad-1c00-4aa0-9110-f4b10de7e716>\nDate: Thu, 1 Sep 2011 13:32:40 +0000\nSubject: [PATCH] changed pidfile location because of security vulnerability,\n debian bug #631912\n\n---\n Pyro\/ext\/daemonizer.py | 8 +++++++-\n 1 file changed, 7 insertions(+), 1 deletion(-)\n\ndiff --git a\/Pyro\/ext\/daemonizer.py b\/Pyro\/ext\/daemonizer.py\nindex e481877..11b5061 100644\n--- a\/Pyro\/ext\/daemonizer.py\n+++ b\/Pyro\/ext\/daemonizer.py\n@@ -47,7 +47,9 @@ class Daemonizer:\n     \"\"\"\n     def __init__(self, pidfile=None):\n         if not pidfile:\n-            self.pidfile = \"\/tmp\/%s.pid\" % self.__class__.__name__.lower()\n+            # PID file moved out of \/tmp to avoid security vulnerability\n+            # changed by Debian maintainer per Debian bug #631912\n+            self.pidfile = \"\/var\/run\/pyro-%s.pid\" % self.__class__.__name__.lower()\n         else:\n             self.pidfile = pidfile\n \n@@ -121,12 +123,16 @@ def main_loop(self):\n \n     def process_command_line(self, argv, verbose=1):\n         usage = \"usage:  %s  start | stop | restart | status | debug \" \\\n+                \"[--pidfile=...] \" \\\n                 \"(run as non-daemon)\" % os.path.basename(argv[0])\n         if len(argv) < 2:\n             print usage\n             raise SystemExit\n         else:\n             operation = argv[1]\n+            if len(argv) > 2 and argv[2].startswith('--pidfile=') and \\\n+                len(argv[2]) > len('--pidfile='):\n+                self.pidfile = argv[2][len('--pidfile='):]\n         pid = self.get_pid()\n         if operation == 'status':\n             if self.is_process_running():"
        },
        {
            "index":913,
            "vuln_id":"GHSA-q5wr-fvpq-p67g",
            "cwe_id":"{'CWE-787', 'CWE-190'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/gemini-testing\/png-img\/commit\/14ac462a32ca4b3b78f56502ac976d5b0222ce3d'}",
            "dataset":"osv",
            "summary":"Integer Overflow in png-img An integer overflow in the PngImg::InitStorage_() function of png-img before 3.1.0 leads to an under-allocation of heap memory and subsequently an exploitable heap-based buffer overflow when loading a crafted PNG file.",
            "published_date":"2021-12-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/gemini-testing\/png-img",
            "commit_href":"https:\/\/github.com\/gemini-testing\/png-img\/commit\/14ac462a32ca4b3b78f56502ac976d5b0222ce3d",
            "commit_sha":"14ac462a32ca4b3b78f56502ac976d5b0222ce3d",
            "patch":"SINGLE",
            "chain_ord":"['14ac462a32ca4b3b78f56502ac976d5b0222ce3d']",
            "before_first_fix_commit":"{'9fedfccb9ab2d1ccee4d7d544f3e03d505317352'}",
            "last_fix_commit":"14ac462a32ca4b3b78f56502ac976d5b0222ce3d",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/06\/2020, 00:45:40",
            "message":"Handle image size overflow",
            "author":"Mikhail Cheshkov",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 2, 'total': 14}",
            "files":"{'src\/PngImg.cc': {'additions': 12, 'deletions': 2, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/gemini-testing\/png-img\/raw\/14ac462a32ca4b3b78f56502ac976d5b0222ce3d\/src%2FPngImg.cc', 'patch': '@@ -60,10 +60,20 @@ void PngImg::ReadInfo_(PngReadStruct& rs) {\\n \/\/\/\\n void PngImg::InitStorage_() {\\n     rowPtrs_.resize(info_.height, nullptr);\\n-    data_ = new png_byte[info_.height * info_.rowbytes];\\n+    \/\/ Extend height and rowbytes from uint32_t to size_t to avoid multiplication overflow when size_t is larger\\n+    size_t h = info_.height;\\n+    size_t rb = info_.rowbytes;\\n+    \/\/ We need to make sure that info_.height * info_.rowbytes will not overflow size_t\\n+    \/\/ Unfotunately, there\\'s no simple and portable way to do this in C++\\n+    \/\/ For integer division of positive numbers a * b > c <==> a > c \/ b holds\\n+    if (h > std::numeric_limits<size_t>::max() \/ rb) {\\n+        \/\/ TODO Propagate this exception to JS, and test it\\n+        throw std::runtime_error(\"Image is too large to allocate single buffer\");\\n+    }\\n+    data_ = new png_byte[h * rb];\\n \\n     for(size_t i = 0; i < info_.height; ++i) {\\n-        rowPtrs_[i] = data_ + i * info_.rowbytes;\\n+        rowPtrs_[i] = data_ + i * rb;\\n     }\\n }'}}",
            "message_norm":"handle image size overflow",
            "language":"en",
            "entities":"[('overflow', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/PngImg.cc'])",
            "num_files":1.0,
            "patch_content":"From 14ac462a32ca4b3b78f56502ac976d5b0222ce3d Mon Sep 17 00:00:00 2001\nFrom: Mikhail Cheshkov <mcheshkov@gmail.com>\nDate: Thu, 6 Aug 2020 03:45:40 +0300\nSubject: [PATCH] Handle image size overflow\n\n---\n src\/PngImg.cc | 14 ++++++++++++--\n 1 file changed, 12 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/PngImg.cc b\/src\/PngImg.cc\nindex 17968ae..5a554a7 100644\n--- a\/src\/PngImg.cc\n+++ b\/src\/PngImg.cc\n@@ -60,10 +60,20 @@ void PngImg::ReadInfo_(PngReadStruct& rs) {\n \/\/\/\n void PngImg::InitStorage_() {\n     rowPtrs_.resize(info_.height, nullptr);\n-    data_ = new png_byte[info_.height * info_.rowbytes];\n+    \/\/ Extend height and rowbytes from uint32_t to size_t to avoid multiplication overflow when size_t is larger\n+    size_t h = info_.height;\n+    size_t rb = info_.rowbytes;\n+    \/\/ We need to make sure that info_.height * info_.rowbytes will not overflow size_t\n+    \/\/ Unfotunately, there's no simple and portable way to do this in C++\n+    \/\/ For integer division of positive numbers a * b > c <==> a > c \/ b holds\n+    if (h > std::numeric_limits<size_t>::max() \/ rb) {\n+        \/\/ TODO Propagate this exception to JS, and test it\n+        throw std::runtime_error(\"Image is too large to allocate single buffer\");\n+    }\n+    data_ = new png_byte[h * rb];\n \n     for(size_t i = 0; i < info_.height; ++i) {\n-        rowPtrs_[i] = data_ + i * info_.rowbytes;\n+        rowPtrs_[i] = data_ + i * rb;\n     }\n }"
        },
        {
            "index":111,
            "vuln_id":"GHSA-j3mj-fhpq-qqjj",
            "cwe_id":"{'CWE-617'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5b491cd5e41ad63735161cec9c2a568172c8b6a3'}",
            "dataset":"osv",
            "summary":"Reachable Assertion in Tensorflow ### Impact\nWhen decoding a tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments, if the tensors have an invalid `dtype` and 0 elements or an invalid shape. This allows attackers to cause denial of services in TensorFlow processes.\n\n### Patches\nWe have patched the issue in GitHub commit [5b491cd5e41ad63735161cec9c2a568172c8b6a3](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5b491cd5e41ad63735161cec9c2a568172c8b6a3).\n  \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range. \n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5b491cd5e41ad63735161cec9c2a568172c8b6a3",
            "commit_sha":"5b491cd5e41ad63735161cec9c2a568172c8b6a3",
            "patch":"SINGLE",
            "chain_ord":"['5b491cd5e41ad63735161cec9c2a568172c8b6a3']",
            "before_first_fix_commit":"{'9f3eb61a8033efa4ef45b1f291ef67d5beef8b0e'}",
            "last_fix_commit":"5b491cd5e41ad63735161cec9c2a568172c8b6a3",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/08\/2021, 17:51:28",
            "message":"Validate `proto.dtype()` before calling `set_dtype()`.\n\nThis prevents a `DCHECK`-fail when the proto contains an invalid dtype for a tensor shape with 0 elements or for an incomplete tensor shape.\n\nPiperOrigin-RevId: 408369083\nChange-Id: Ia21a3e3d62a90d642a4561f08f3b543e5ad00c46",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 0, 'total': 9}",
            "files":"{'tensorflow\/core\/framework\/tensor.cc': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/5b491cd5e41ad63735161cec9c2a568172c8b6a3\/tensorflow%2Fcore%2Fframework%2Ftensor.cc', 'patch': '@@ -983,6 +983,15 @@ bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\\n                          dtype_error = true, dtype_error = true);\\n     }\\n     if (dtype_error || p == nullptr) return false;\\n+  } else {\\n+    \/\/ Handle the case of empty tensors (N = 0) or tensors with incomplete shape\\n+    \/\/ (N = -1). All other values of `shape.num_elements()` should be invalid by\\n+    \/\/ construction.\\n+    \/\/ Here, we just need to validate that the `proto.dtype()` value is valid.\\n+    bool dtype_error = false;\\n+    CASES_WITH_DEFAULT(proto.dtype(), break, dtype_error = true,\\n+                       dtype_error = true);\\n+    if (dtype_error) return false;\\n   }\\n   shape_ = shape;\\n   set_dtype(proto.dtype());'}}",
            "message_norm":"validate `proto.dtype()` before calling `set_dtype()`.\n\nthis prevents a `dcheck`-fail when the proto contains an invalid dtype for a tensor shape with 0 elements or for an incomplete tensor shape.\n\npiperorigin-revid: 408369083\nchange-id: ia21a3e3d62a90d642a4561f08f3b543e5ad00c46",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('prevents', 'ACTION', ''), ('408369083', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/tensor.cc'])",
            "num_files":1.0,
            "patch_content":"From 5b491cd5e41ad63735161cec9c2a568172c8b6a3 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Mon, 8 Nov 2021 09:51:28 -0800\nSubject: [PATCH] Validate `proto.dtype()` before calling `set_dtype()`.\n\nThis prevents a `DCHECK`-fail when the proto contains an invalid dtype for a tensor shape with 0 elements or for an incomplete tensor shape.\n\nPiperOrigin-RevId: 408369083\nChange-Id: Ia21a3e3d62a90d642a4561f08f3b543e5ad00c46\n---\n tensorflow\/core\/framework\/tensor.cc | 9 +++++++++\n 1 file changed, 9 insertions(+)\n\ndiff --git a\/tensorflow\/core\/framework\/tensor.cc b\/tensorflow\/core\/framework\/tensor.cc\nindex 8ae9fd0051652c..c7a08ee0808043 100644\n--- a\/tensorflow\/core\/framework\/tensor.cc\n+++ b\/tensorflow\/core\/framework\/tensor.cc\n@@ -983,6 +983,15 @@ bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n                          dtype_error = true, dtype_error = true);\n     }\n     if (dtype_error || p == nullptr) return false;\n+  } else {\n+    \/\/ Handle the case of empty tensors (N = 0) or tensors with incomplete shape\n+    \/\/ (N = -1). All other values of `shape.num_elements()` should be invalid by\n+    \/\/ construction.\n+    \/\/ Here, we just need to validate that the `proto.dtype()` value is valid.\n+    bool dtype_error = false;\n+    CASES_WITH_DEFAULT(proto.dtype(), break, dtype_error = true,\n+                       dtype_error = true);\n+    if (dtype_error) return false;\n   }\n   shape_ = shape;\n   set_dtype(proto.dtype());"
        },
        {
            "index":907,
            "vuln_id":"GHSA-69q2-p9xp-739v",
            "cwe_id":"{'CWE-91'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/petl-developers\/petl\/pull\/527\/commits\/1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8'}",
            "dataset":"osv",
            "summary":"XML Injection in petl petl before 1.68, in some configurations, allows resolution of entities in an XML document.",
            "published_date":"2021-04-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/petl-developers\/petl",
            "commit_href":"https:\/\/github.com\/petl-developers\/petl\/pull\/527\/commits\/1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8",
            "commit_sha":"1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8",
            "patch":"SINGLE",
            "chain_ord":"['1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8']",
            "before_first_fix_commit":"{'364c3e5d0263a99dffebcd9df70b17bce57b3b06'}",
            "last_fix_commit":"1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/05\/2020, 22:42:56",
            "message":"allow using a custom\/restricted xml parser",
            "author":"Juarez Rudsatz",
            "comments":null,
            "stats":"{'additions': 20, 'deletions': 2, 'total': 22}",
            "files":"{'petl\/io\/xml.py': {'additions': 20, 'deletions': 2, 'changes': 22, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/petl-developers\/petl\/raw\/1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8\/petl%2Fio%2Fxml.py', 'patch': '@@ -133,6 +133,9 @@ def fromxml(source, *args, **kwargs):\\n     or list of paths can be provided, e.g.,\\n     ``fromxml(\\'example.html\\', \\'.\/\/tr\\', (\\'th\\', \\'td\\'))``.\\n \\n+    Optionally a custom parser can be provided, e.g.,\\n+    ``etl.fromxml(\\'example1.xml\\', \\'tr\\', \\'td\\', parser=my_parser)``.\\n+\\n     \"\"\"\\n \\n     source = read_source_from_arg(source)\\n@@ -162,14 +165,15 @@ def __init__(self, source, *args, **kwargs):\\n         else:\\n             assert False, \\'bad parameters\\'\\n         self.missing = kwargs.get(\\'missing\\', None)\\n+        self.user_parser = kwargs.get(\\'parser\\', None)\\n \\n     def __iter__(self):\\n         vmatch = self.vmatch\\n         vdict = self.vdict\\n \\n         with self.source.open(\\'rb\\') as xmlf:\\n-\\n-            tree = etree.parse(xmlf)\\n+            parser2 = _create_xml_parser(self.user_parser)\\n+            tree = etree.parse(xmlf, parser=parser2)\\n             if not hasattr(tree, \\'iterfind\\'):\\n                 # Python 2.6 compatibility\\n                 tree.iterfind = tree.findall\\n@@ -219,6 +223,20 @@ def __iter__(self):\\n                                 for f in flds)\\n \\n \\n+def _create_xml_parser(user_parser):\\n+    if user_parser is not None:\\n+        return user_parser\\n+    try:\\n+        # Default lxml parser.\\n+        # This will throw an error if parser is not set and lxml could not be imported\\n+        # because Python\\'s built XML parser doesn\\'t like the `resolve_entities` kwarg.\\n+        # return etree.XMLParser(resolve_entities=False)\\n+        return etree.XMLParser(resolve_entities=False)\\n+    except TypeError:\\n+        # lxml not available\\n+        return None\\n+\\n+\\n def element_text_getter(missing):\\n     def _get(v):\\n         if len(v) > 1:'}}",
            "message_norm":"allow using a custom\/restricted xml parser",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['petl\/io\/xml.py'])",
            "num_files":1.0,
            "patch_content":"From 1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8 Mon Sep 17 00:00:00 2001\nFrom: Juarez Rudsatz <juarezr@gmail.com>\nDate: Mon, 5 Oct 2020 19:42:56 -0300\nSubject: [PATCH] allow using a custom\/restricted xml parser\n\n---\n petl\/io\/xml.py | 22 ++++++++++++++++++++--\n 1 file changed, 20 insertions(+), 2 deletions(-)\n\ndiff --git a\/petl\/io\/xml.py b\/petl\/io\/xml.py\nindex 983d9f6d..b63287c9 100644\n--- a\/petl\/io\/xml.py\n+++ b\/petl\/io\/xml.py\n@@ -133,6 +133,9 @@ def fromxml(source, *args, **kwargs):\n     or list of paths can be provided, e.g.,\n     ``fromxml('example.html', '.\/\/tr', ('th', 'td'))``.\n \n+    Optionally a custom parser can be provided, e.g.,\n+    ``etl.fromxml('example1.xml', 'tr', 'td', parser=my_parser)``.\n+\n     \"\"\"\n \n     source = read_source_from_arg(source)\n@@ -162,14 +165,15 @@ def __init__(self, source, *args, **kwargs):\n         else:\n             assert False, 'bad parameters'\n         self.missing = kwargs.get('missing', None)\n+        self.user_parser = kwargs.get('parser', None)\n \n     def __iter__(self):\n         vmatch = self.vmatch\n         vdict = self.vdict\n \n         with self.source.open('rb') as xmlf:\n-\n-            tree = etree.parse(xmlf)\n+            parser2 = _create_xml_parser(self.user_parser)\n+            tree = etree.parse(xmlf, parser=parser2)\n             if not hasattr(tree, 'iterfind'):\n                 # Python 2.6 compatibility\n                 tree.iterfind = tree.findall\n@@ -219,6 +223,20 @@ def __iter__(self):\n                                 for f in flds)\n \n \n+def _create_xml_parser(user_parser):\n+    if user_parser is not None:\n+        return user_parser\n+    try:\n+        # Default lxml parser.\n+        # This will throw an error if parser is not set and lxml could not be imported\n+        # because Python's built XML parser doesn't like the `resolve_entities` kwarg.\n+        # return etree.XMLParser(resolve_entities=False)\n+        return etree.XMLParser(resolve_entities=False)\n+    except TypeError:\n+        # lxml not available\n+        return None\n+\n+\n def element_text_getter(missing):\n     def _get(v):\n         if len(v) > 1:"
        },
        {
            "index":572,
            "vuln_id":"GHSA-5875-p652-2ppm",
            "cwe_id":"{'CWE-668'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/76361264d9fdfff38a1af79c63141455cc4d36e3'}",
            "dataset":"osv",
            "summary":"Exposure of Resource to Wrong Sphere in microweber Exposure of Resource to Wrong Sphere in microweber prior to 1.3 allows users to add deleted products to a cart and buy it.",
            "published_date":"2022-02-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/76361264d9fdfff38a1af79c63141455cc4d36e3",
            "commit_sha":"76361264d9fdfff38a1af79c63141455cc4d36e3",
            "patch":"SINGLE",
            "chain_ord":"['76361264d9fdfff38a1af79c63141455cc4d36e3']",
            "before_first_fix_commit":"{'cc5947c83f05f5490c9190d4a68dc199461b34e3'}",
            "last_fix_commit":"76361264d9fdfff38a1af79c63141455cc4d36e3",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/25\/2022, 09:43:45",
            "message":"check product is deleted before add to cart",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 0, 'total': 14}",
            "files":"{'src\/MicroweberPackages\/Cart\/CartManager.php': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/76361264d9fdfff38a1af79c63141455cc4d36e3\/src%2FMicroweberPackages%2FCart%2FCartManager.php', 'patch': \"@@ -565,7 +565,21 @@ public function update_cart($data)\\n         }\\n \\n         if ($data['for'] == 'content') {\\n+\\n             $cont = $this->app->content_manager->get_by_id($for_id);\\n+\\n+            if (isset($cont['is_active'])) {\\n+                if ($cont['is_active'] != 1) {\\n+                    $cont = false;\\n+                }\\n+            }\\n+\\n+            if (isset($cont['is_deleted'])) {\\n+                if ($cont['is_deleted'] > 0) {\\n+                    $cont = false;\\n+                }\\n+            }\\n+\\n             $cont_data = $this->app->content_manager->data($for_id);\\n             if ($cont == false) {\\n                 return array('error' => 'Invalid product?');\"}}",
            "message_norm":"check product is deleted before add to cart",
            "language":"en",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"REDUNDANT_MESSAGE",
            "list_files":"dict_keys(['src\/MicroweberPackages\/Cart\/CartManager.php'])",
            "num_files":1.0,
            "patch_content":"From 76361264d9fdfff38a1af79c63141455cc4d36e3 Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Fri, 25 Feb 2022 11:43:45 +0200\nSubject: [PATCH] check product is deleted before add to cart\n\n---\n src\/MicroweberPackages\/Cart\/CartManager.php | 14 ++++++++++++++\n 1 file changed, 14 insertions(+)\n\ndiff --git a\/src\/MicroweberPackages\/Cart\/CartManager.php b\/src\/MicroweberPackages\/Cart\/CartManager.php\nindex 2b2ff36eab9..3addd09d354 100644\n--- a\/src\/MicroweberPackages\/Cart\/CartManager.php\n+++ b\/src\/MicroweberPackages\/Cart\/CartManager.php\n@@ -565,7 +565,21 @@ public function update_cart($data)\n         }\n \n         if ($data['for'] == 'content') {\n+\n             $cont = $this->app->content_manager->get_by_id($for_id);\n+\n+            if (isset($cont['is_active'])) {\n+                if ($cont['is_active'] != 1) {\n+                    $cont = false;\n+                }\n+            }\n+\n+            if (isset($cont['is_deleted'])) {\n+                if ($cont['is_deleted'] > 0) {\n+                    $cont = false;\n+                }\n+            }\n+\n             $cont_data = $this->app->content_manager->data($for_id);\n             if ($cont == false) {\n                 return array('error' => 'Invalid product?');"
        },
        {
            "index":719,
            "vuln_id":"GHSA-h4mx-xv96-2jgm",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/TYPO3\/typo3\/commit\/da611775f92102d7602713003f4c79606c8a445d'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting in TYPO3's Frontend Login Mailer > ### Meta\n> * CVSS: `CVSS:3.1\/AV:N\/AC:L\/PR:L\/UI:R\/S:C\/C:L\/I:L\/A:N\/E:F\/RL:O\/RC:C` (4.9)\n\n### Problem\nUser submitted content was used without being properly encoded in HTML emails sent to users. The actually affected components were mail clients used to view those messages.\n\n### Solution\nUpdate to TYPO3 versions 9.5.35 ELTS, 10.4.29, 11.5.11 that fix the problem described above.\n\n### Credits\nThanks to Christian Seifert who reported this issue and to TYPO3 framework merger Andreas Fernandez who fixed the issue.\n\n### References\n* [TYPO3-CORE-SA-2022-004](https:\/\/typo3.org\/security\/advisory\/typo3-core-sa-2022-004)",
            "published_date":"2022-06-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/TYPO3\/typo3",
            "commit_href":"https:\/\/github.com\/TYPO3\/typo3\/commit\/da611775f92102d7602713003f4c79606c8a445d",
            "commit_sha":"da611775f92102d7602713003f4c79606c8a445d",
            "patch":"SINGLE",
            "chain_ord":"['da611775f92102d7602713003f4c79606c8a445d']",
            "before_first_fix_commit":"{'6f2554dc4ea0b670fd5599c54fd788d4db96c4a0'}",
            "last_fix_commit":"da611775f92102d7602713003f4c79606c8a445d",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/14\/2022, 07:18:04",
            "message":"[SECURITY] Avoid HTML injection in password recovery mail\n\nThe `receiverName` variable used in the password recovery mail of the\nExtbase felogin plugin was susceptible to HTML injection due to\nmissing sanitization. The variable is now passed thru the\n`f:format.htmlspecialchars` ViewHelper.\n\nResolves: #96559\nReleases: main, 11.5, 10.4\nChange-Id: I60e23c161f7f2fcc87b8870345b10a4c31d7b8db\nSecurity-Bulletin: TYPO3-CORE-SA-2022-004\nSecurity-References: CVE-2022-31049\nReviewed-on: https:\/\/review.typo3.org\/c\/Packages\/TYPO3.CMS\/+\/74904\nTested-by: Oliver Hader <oliver.hader@typo3.org>\nReviewed-by: Oliver Hader <oliver.hader@typo3.org>",
            "author":"Andreas Fernandez",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'typo3\/sysext\/felogin\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/TYPO3\/typo3\/raw\/da611775f92102d7602713003f4c79606c8a445d\/typo3%2Fsysext%2Ffelogin%2FResources%2FPrivate%2FEmail%2FTemplates%2FPasswordRecovery.html', 'patch': '@@ -9,7 +9,7 @@\\n         {f:translate(\\n         key: \\'forgot_validate_reset_password_html\\',\\n         extensionName: \\'felogin\\',\\n-        arguments: \\'{ 0: receiverName, 1: recoveryLink, 2: validUntil }\\'\\n+        arguments: \\'{ 0: \"{receiverName -> f:format.htmlspecialchars()}\", 1: recoveryLink, 2: validUntil }\\'\\n         ) -> f:format.html()}\\n     <\/f:spaceless>\\n <\/f:section>'}}",
            "message_norm":"[security] avoid html injection in password recovery mail\n\nthe `receivername` variable used in the password recovery mail of the\nextbase felogin plugin was susceptible to html injection due to\nmissing sanitization. the variable is now passed thru the\n`f:format.htmlspecialchars` viewhelper.\n\nresolves: #96559\nreleases: main, 11.5, 10.4\nchange-id: i60e23c161f7f2fcc87b8870345b10a4c31d7b8db\nsecurity-bulletin: typo3-core-sa-2022-004\nsecurity-references: cve-2022-31049\nreviewed-on: https:\/\/review.typo3.org\/c\/packages\/typo3.cms\/+\/74904\ntested-by: oliver hader <oliver.hader@typo3.org>\nreviewed-by: oliver hader <oliver.hader@typo3.org>",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('injection', 'SECWORD', ''), ('password', 'SECWORD', ''), ('password', 'SECWORD', ''), ('injection', 'SECWORD', ''), ('sanitization', 'SECWORD', ''), ('format.htmlspecialchars', 'SECWORD', ''), ('#96559', 'ISSUE', ''), ('security', 'SECWORD', ''), ('security', 'SECWORD', ''), ('cve-2022-31049', 'VULNID', 'CVE'), ('https:\/\/review.typo3.org\/c\/packages\/typo3.cms\/+\/74904', 'URL', ''), ('oliver.hader@typo3.org', 'EMAIL', ''), ('oliver.hader@typo3.org', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['typo3\/sysext\/felogin\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html'])",
            "num_files":1.0,
            "patch_content":"From da611775f92102d7602713003f4c79606c8a445d Mon Sep 17 00:00:00 2001\nFrom: Andreas Fernandez <a.fernandez@scripting-base.de>\nDate: Tue, 14 Jun 2022 09:18:04 +0200\nSubject: [PATCH] [SECURITY] Avoid HTML injection in password recovery mail\n\nThe `receiverName` variable used in the password recovery mail of the\nExtbase felogin plugin was susceptible to HTML injection due to\nmissing sanitization. The variable is now passed thru the\n`f:format.htmlspecialchars` ViewHelper.\n\nResolves: #96559\nReleases: main, 11.5, 10.4\nChange-Id: I60e23c161f7f2fcc87b8870345b10a4c31d7b8db\nSecurity-Bulletin: TYPO3-CORE-SA-2022-004\nSecurity-References: CVE-2022-31049\nReviewed-on: https:\/\/review.typo3.org\/c\/Packages\/TYPO3.CMS\/+\/74904\nTested-by: Oliver Hader <oliver.hader@typo3.org>\nReviewed-by: Oliver Hader <oliver.hader@typo3.org>\n---\n ...\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html     | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/typo3\/sysext\/felogin\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html b\/typo3\/sysext\/felogin\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html\nindex b6eb95d7f04c..9ce5344654b4 100644\n--- a\/typo3\/sysext\/felogin\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html\n+++ b\/typo3\/sysext\/felogin\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html\n@@ -9,7 +9,7 @@\n         {f:translate(\n         key: 'forgot_validate_reset_password_html',\n         extensionName: 'felogin',\n-        arguments: '{ 0: receiverName, 1: recoveryLink, 2: validUntil }'\n+        arguments: '{ 0: \"{receiverName -> f:format.htmlspecialchars()}\", 1: recoveryLink, 2: validUntil }'\n         ) -> f:format.html()}\n     <\/f:spaceless>\n <\/f:section>"
        },
        {
            "index":341,
            "vuln_id":"GHSA-43m5-c88r-cjvv",
            "cwe_id":"{'CWE-352'}",
            "score":6.8,
            "chain":"{'https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/commit\/cf43beedb05131937ef46f365ab0a0c6fa6ac618'}",
            "dataset":"osv",
            "summary":"XSS due to lack of CSRF validation for replying\/publishing ### Impact\nDue to lack of CSRF validation, a logged in user is potentially vulnerable to an XSS attack which could allow a third party to post on their behalf on the forum.\n\n### Patches\nUpgrade to the latest version v0.7.0\n\n### Workarounds\nYou can cherry-pick the following commit: [https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/commit\/cf43beedb05131937ef46f365ab0a0c6fa6ac618](https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/commit\/cf43beedb05131937ef46f365ab0a0c6fa6ac618)\n\n### References\nVisit https:\/\/community.nodebb.org if you have any questions about this issue or on how to patch \/ upgrade your instance.",
            "published_date":"2020-08-26",
            "chain_len":1,
            "project":"https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments",
            "commit_href":"https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/commit\/cf43beedb05131937ef46f365ab0a0c6fa6ac618",
            "commit_sha":"cf43beedb05131937ef46f365ab0a0c6fa6ac618",
            "patch":"SINGLE",
            "chain_ord":"['cf43beedb05131937ef46f365ab0a0c6fa6ac618']",
            "before_first_fix_commit":"{'ed0156594a44c6429743e314e9b5a313fad60730'}",
            "last_fix_commit":"cf43beedb05131937ef46f365ab0a0c6fa6ac618",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/20\/2020, 05:11:57",
            "message":"fix: CSRF issues",
            "author":"psychobunny",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'library.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/raw\/cf43beedb05131937ef46f365ab0a0c6fa6ac618\/library.js', 'patch': \"@@ -248,8 +248,8 @@\\n \\t\\t});\\n \\n \\t\\tapp.get('\/comments\/get\/:id\/:pagination?', middleware.applyCSRF, Comments.getCommentData);\\n-\\t\\tapp.post('\/comments\/reply', Comments.replyToComment);\\n-\\t\\tapp.post('\/comments\/publish', Comments.publishArticle);\\n+\\t\\tapp.post('\/comments\/reply', middleware.applyCSRF, Comments.replyToComment);\\n+\\t\\tapp.post('\/comments\/publish', middleware.applyCSRF, Comments.publishArticle);\\n \\n \\t\\tapp.get('\/admin\/blog-comments', middleware.admin.buildHeader, renderAdmin);\\n \\t\\tapp.get('\/api\/admin\/blog-comments', renderAdmin);\"}}",
            "message_norm":"fix: csrf issues",
            "language":"en",
            "entities":"[('csrf', 'SECWORD', ''), ('issues', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['library.js'])",
            "num_files":1.0,
            "patch_content":"From cf43beedb05131937ef46f365ab0a0c6fa6ac618 Mon Sep 17 00:00:00 2001\nFrom: psychobunny <psycho.bunny@hotmail.com>\nDate: Thu, 20 Aug 2020 01:11:57 -0400\nSubject: [PATCH] fix: CSRF issues\n\n---\n library.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/library.js b\/library.js\nindex 7786830a..7960b486 100644\n--- a\/library.js\n+++ b\/library.js\n@@ -248,8 +248,8 @@\n \t\t});\n \n \t\tapp.get('\/comments\/get\/:id\/:pagination?', middleware.applyCSRF, Comments.getCommentData);\n-\t\tapp.post('\/comments\/reply', Comments.replyToComment);\n-\t\tapp.post('\/comments\/publish', Comments.publishArticle);\n+\t\tapp.post('\/comments\/reply', middleware.applyCSRF, Comments.replyToComment);\n+\t\tapp.post('\/comments\/publish', middleware.applyCSRF, Comments.publishArticle);\n \n \t\tapp.get('\/admin\/blog-comments', middleware.admin.buildHeader, renderAdmin);\n \t\tapp.get('\/api\/admin\/blog-comments', renderAdmin);"
        },
        {
            "index":208,
            "vuln_id":"GHSA-wx69-rvg3-x7fc",
            "cwe_id":"{'CWE-79'}",
            "score":9.0,
            "chain":"{'https:\/\/github.com\/NodeBB\/NodeBB\/commit\/1783f918bc19568f421473824461ff2ed7755e4c'}",
            "dataset":"osv",
            "summary":"XSS via prototype pollution in NodeBB  ### Impact\nA prototype pollution vulnerability in the uploader module allowed a malicious user to inject arbitrary data (i.e. javascript) into the DOM, theoretically allowing for an account takeover when used in conjunction with a path traversal vulnerability disclosed at the same time as this report.\n\n### Patches\nThe vulnerability has been patched as of v1.18.5.\n\n### Workarounds\nCherry-pick commit hash 1783f918bc19568f421473824461ff2ed7755e4c to receive this patch in lieu of a full upgrade.\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at [security@nodebb.org](mailto:security@nodebb.org)",
            "published_date":"2021-11-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/NodeBB\/NodeBB",
            "commit_href":"https:\/\/github.com\/NodeBB\/NodeBB\/commit\/1783f918bc19568f421473824461ff2ed7755e4c",
            "commit_sha":"1783f918bc19568f421473824461ff2ed7755e4c",
            "patch":"SINGLE",
            "chain_ord":"['1783f918bc19568f421473824461ff2ed7755e4c']",
            "before_first_fix_commit":"{'c8b2fc46dc698db687379106b3f01c71b80f495f'}",
            "last_fix_commit":"1783f918bc19568f421473824461ff2ed7755e4c",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/25\/2021, 17:17:33",
            "message":"fix: guard against prototype pollution",
            "author":"Bar\u0131\u015f Soner U\u015fakl\u0131",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 2, 'total': 5}",
            "files":"{'src\/socket.io\/uploads.js': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NodeBB\/NodeBB\/raw\/1783f918bc19568f421473824461ff2ed7755e4c\/src%2Fsocket.io%2Fuploads.js', 'patch': \"@@ -15,11 +15,12 @@ uploads.upload = async function (socket, data) {\\n \\t\\t'user.updateCover': socketUser.updateCover,\\n \\t\\t'groups.cover.update': socketGroup.cover.update,\\n \\t};\\n-\\tif (!socket.uid || !data || !data.chunk || !data.params || !data.params.method || !methodToFunc[data.params.method]) {\\n+\\tif (!socket.uid || !data || !data.chunk ||\\n+\\t\\t!data.params || !data.params.method || !methodToFunc.hasOwnProperty(data.params.method)) {\\n \\t\\tthrow new Error('[[error:invalid-data]]');\\n \\t}\\n \\n-\\tinProgress[socket.id] = inProgress[socket.id] || {};\\n+\\tinProgress[socket.id] = inProgress[socket.id] || Object.create(null);\\n \\tconst socketUploads = inProgress[socket.id];\\n \\tconst { method } = data.params;\"}}",
            "message_norm":"fix: guard against prototype pollution",
            "language":"en",
            "entities":"[('prototype pollution', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/socket.io\/uploads.js'])",
            "num_files":1.0,
            "patch_content":"From 1783f918bc19568f421473824461ff2ed7755e4c Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Bar=C4=B1=C5=9F=20Soner=20U=C5=9Fakl=C4=B1?=\n <barisusakli@gmail.com>\nDate: Mon, 25 Oct 2021 13:17:33 -0400\nSubject: [PATCH] fix: guard against prototype pollution\n\n---\n src\/socket.io\/uploads.js | 5 +++--\n 1 file changed, 3 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/socket.io\/uploads.js b\/src\/socket.io\/uploads.js\nindex c3fd025e0da5..66b7266b0124 100644\n--- a\/src\/socket.io\/uploads.js\n+++ b\/src\/socket.io\/uploads.js\n@@ -15,11 +15,12 @@ uploads.upload = async function (socket, data) {\n \t\t'user.updateCover': socketUser.updateCover,\n \t\t'groups.cover.update': socketGroup.cover.update,\n \t};\n-\tif (!socket.uid || !data || !data.chunk || !data.params || !data.params.method || !methodToFunc[data.params.method]) {\n+\tif (!socket.uid || !data || !data.chunk ||\n+\t\t!data.params || !data.params.method || !methodToFunc.hasOwnProperty(data.params.method)) {\n \t\tthrow new Error('[[error:invalid-data]]');\n \t}\n \n-\tinProgress[socket.id] = inProgress[socket.id] || {};\n+\tinProgress[socket.id] = inProgress[socket.id] || Object.create(null);\n \tconst socketUploads = inProgress[socket.id];\n \tconst { method } = data.params;"
        },
        {
            "index":476,
            "vuln_id":"GHSA-gv26-jpj9-c8gq",
            "cwe_id":"{'CWE-754'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f6fde895ef9c77d848061c0517f19d0ec2682f3a'}",
            "dataset":"osv",
            "summary":"Incomplete validation in `SparseSparseMinimum` ### Impact\nIncomplete validation in `SparseAdd` results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:\n\n```python \nimport tensorflow as tf\n\na_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    b_shape=b_shape)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/656e7673b14acd7835dc778867f84916c6d1cac2\/tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc) has a large set of validation for the two sparse tensor inputs (6 tensors in total), but does not validate that the tensors are not empty or that the second dimension of `*_indices` matches the size of corresponding `*_shape`. This allows attackers to send tensor triples that represent invalid sparse tensors to abuse code assumptions that are not protected by validation.\n\n### Patches \nWe have patched the issue in GitHub commit [ba6822bd7b7324ba201a28b2f278c29a98edbef2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2) followed by GitHub commit [f6fde895ef9c77d848061c0517f19d0ec2682f3a](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f6fde895ef9c77d848061c0517f19d0ec2682f3a).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2022-03-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f6fde895ef9c77d848061c0517f19d0ec2682f3a",
            "commit_sha":"f6fde895ef9c77d848061c0517f19d0ec2682f3a",
            "patch":"MULTI",
            "chain_ord":"['ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'f6fde895ef9c77d848061c0517f19d0ec2682f3a']",
            "before_first_fix_commit":"{'cae81a7ae3ca6207396d5c893e8163f4acb34037'}",
            "last_fix_commit":"f6fde895ef9c77d848061c0517f19d0ec2682f3a",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/12\/2021, 01:32:03",
            "message":"Validate that a and b are proper sparse tensors\n\nPiperOrigin-RevId: 373274848\nChange-Id: I3a665ac3a29dee9fb69bdf408a939330cb93ea75",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 6, 'total': 15}",
            "files":"{'tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc': {'additions': 9, 'deletions': 6, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f6fde895ef9c77d848061c0517f19d0ec2682f3a\/tensorflow%2Fcore%2Fkernels%2Fsparse_sparse_binary_op_shared.cc', 'patch': '@@ -150,6 +150,7 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n \\n     const int64 a_nnz = a_indices_t->dim_size(0);\\n     const int64 b_nnz = b_indices_t->dim_size(0);\\n+\\n     const auto a_values = a_values_t->vec<T>();\\n     const auto b_values = b_values_t->vec<T>();\\n \\n@@ -166,6 +167,14 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n                     \"Input shapes should be a vector but received shapes \",\\n                     a_shape_t->shape().DebugString(), \" and \",\\n                     b_shape_t->shape().DebugString()));\\n+    const int num_dims = a_indices_t->dim_size(1);\\n+    OP_REQUIRES(\\n+        ctx, a_shape_t->NumElements() == num_dims,\\n+        errors::InvalidArgument(\"Second dimension of a_indices and length of \"\\n+                                \"a_shape must match, got \",\\n+                                num_dims, \" and \", a_shape_t->NumElements()));\\n+    OP_REQUIRES(ctx, num_dims > 0,\\n+                errors::InvalidArgument(\"Tensors must not be empty\"));\\n     OP_REQUIRES(ctx, a_shape_t->IsSameSize(*b_shape_t),\\n                 errors::InvalidArgument(\\n                     \"Operands do not have the same ranks; got shapes: \",\\n@@ -180,12 +189,6 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n                                           \" for dimension \", i));\\n     }\\n \\n-    OP_REQUIRES(\\n-        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\\n-        errors::InvalidArgument(\\n-            \"Indices\\' dimensions do not match: got \", a_indices_t->dim_size(1),\\n-            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\\n-    const int num_dims = a_indices_t->dim_size(1);\\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\\n     std::vector<T> a_augmented_values, b_augmented_values;'}}",
            "message_norm":"validate that a and b are proper sparse tensors\n\npiperorigin-revid: 373274848\nchange-id: i3a665ac3a29dee9fb69bdf408a939330cb93ea75",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('373274848', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc'])",
            "num_files":1.0,
            "patch_content":"From f6fde895ef9c77d848061c0517f19d0ec2682f3a Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 11 May 2021 18:32:03 -0700\nSubject: [PATCH] Validate that a and b are proper sparse tensors\n\nPiperOrigin-RevId: 373274848\nChange-Id: I3a665ac3a29dee9fb69bdf408a939330cb93ea75\n---\n ...\/kernels\/sparse_sparse_binary_op_shared.cc     | 15 +++++++++------\n 1 file changed, 9 insertions(+), 6 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc b\/tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc\nindex 9fe42e05d879ee..eb993a5965043b 100644\n--- a\/tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc\n@@ -150,6 +150,7 @@ class SparseSparseBinaryOpShared : public OpKernel {\n \n     const int64 a_nnz = a_indices_t->dim_size(0);\n     const int64 b_nnz = b_indices_t->dim_size(0);\n+\n     const auto a_values = a_values_t->vec<T>();\n     const auto b_values = b_values_t->vec<T>();\n \n@@ -166,6 +167,14 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                     \"Input shapes should be a vector but received shapes \",\n                     a_shape_t->shape().DebugString(), \" and \",\n                     b_shape_t->shape().DebugString()));\n+    const int num_dims = a_indices_t->dim_size(1);\n+    OP_REQUIRES(\n+        ctx, a_shape_t->NumElements() == num_dims,\n+        errors::InvalidArgument(\"Second dimension of a_indices and length of \"\n+                                \"a_shape must match, got \",\n+                                num_dims, \" and \", a_shape_t->NumElements()));\n+    OP_REQUIRES(ctx, num_dims > 0,\n+                errors::InvalidArgument(\"Tensors must not be empty\"));\n     OP_REQUIRES(ctx, a_shape_t->IsSameSize(*b_shape_t),\n                 errors::InvalidArgument(\n                     \"Operands do not have the same ranks; got shapes: \",\n@@ -180,12 +189,6 @@ class SparseSparseBinaryOpShared : public OpKernel {\n                                           \" for dimension \", i));\n     }\n \n-    OP_REQUIRES(\n-        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n-        errors::InvalidArgument(\n-            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n-            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n-    const int num_dims = a_indices_t->dim_size(1);\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\n     std::vector<T> a_augmented_values, b_augmented_values;"
        },
        {
            "index":628,
            "vuln_id":"GHSA-xf7w-r453-m56c",
            "cwe_id":"{'CWE-59'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/npm\/fstream\/commit\/6a77d2fa6e1462693cf8e46f930da96ec1b0bb22'}",
            "dataset":"osv",
            "summary":"Arbitrary File Overwrite in fstream Versions of `fstream` prior to 1.0.12 are vulnerable to Arbitrary File Overwrite. Extracting tarballs containing a hardlink to a file that already exists in the system and a file that matches the hardlink will overwrite the system's file with the contents of the extracted file. The `fstream.DirWriter()` function is vulnerable.\n\n\n## Recommendation\n\nUpgrade to version 1.0.12 or later.",
            "published_date":"2019-05-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/npm\/fstream",
            "commit_href":"https:\/\/github.com\/npm\/fstream\/commit\/6a77d2fa6e1462693cf8e46f930da96ec1b0bb22",
            "commit_sha":"6a77d2fa6e1462693cf8e46f930da96ec1b0bb22",
            "patch":"SINGLE",
            "chain_ord":"['6a77d2fa6e1462693cf8e46f930da96ec1b0bb22']",
            "before_first_fix_commit":"{'1e4527ffe8688d4f5325283d7cf2cf2d61f14c6b'}",
            "last_fix_commit":"6a77d2fa6e1462693cf8e46f930da96ec1b0bb22",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/15\/2019, 00:37:57",
            "message":"Clobber a Link if it's in the way of a File\n\nFixes https:\/\/github.com\/npm\/node-tar\/issues\/212",
            "author":"isaacs",
            "comments":"{'com_1': {'author': 'ret2libc', 'datetime': '06\/24\/2019, 10:41:00', 'body': \"Does this fix really solve the issue? Doesn't it make it just racy? (e.g. if at the time of check the file is a regular one and it is switched to an hardlink just before the `create()` function is called)\"}, 'com_2': {'author': 'mssalvatore', 'datetime': '08\/29\/2019, 11:35:42', 'body': 'I don\\'t believe this patch is attempting to resolve a TOCTOU condition. The context of the original issue (https:\/\/hackerone.com\/reports\/344595) is that arbitrary files on the filesystem could be overwritten if a crafted **tar archive** were extracted.\\r\\n\\r\\nWithin that context, I don\\'t believe this fix is has a race condition. It is not trying to prevent general TOCTOU issues. Rather, it\\'s preventing the condition where you\\'re in the process of iterating through the entries in a tar archive and you:\\r\\n\\r\\n1) Extract a hardlink named \"LINK\" that points to some arbitrary location (like \/etc\/passwd)\\r\\n2) Extract a regular file that also has the name \"LINK\"\\r\\n\\r\\nWithout this fix, this scenario would result in \/etc\/passwd being overwritten with the contents of the regular file \"LINK\".\\r\\n\\r\\nAll that being said, I am *really* not a javascript\/node.js developer, so:\\r\\n\\r\\n1) Since node.js handles I\/O asynchronously, are there concurrency concerns while looping through and extracting the entries of a tarball? \\r\\n2) Why would someone use fstream at all in this capacity when they could use the tar package instead? I\\'m curious as to why this fix was really necessary in the first place.'}, 'com_3': {'author': 'ret2libc', 'datetime': '09\/10\/2019, 15:20:25', 'body': \"> I don't believe this patch is attempting to resolve a TOCTOU condition. The context of the original issue (https:\/\/hackerone.com\/reports\/344595) is that arbitrary files on the filesystem could be overwritten if a crafted **tar archive** were extracted.\\r\\n\\r\\nTrue, though I was not able to trigger the issue while extracting a tar. Maybe I'm just missing something, but I ended up analyzing the issue in the context of a copy from one directory to another. Also, from reading various comments around this seemed more like a security fix to make npm-audit happy.\"}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/writer.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/npm\/fstream\/raw\/6a77d2fa6e1462693cf8e46f930da96ec1b0bb22\/lib%2Fwriter.js', 'patch': \"@@ -147,7 +147,7 @@ Writer.prototype._stat = function (current) {\\n \\n     \/\/ if it's a type change, then we need to clobber or error.\\n     \/\/ if it's not a type change, then let the impl take care of it.\\n-    if (currentType !== self.type) {\\n+    if (currentType !== self.type || self.type === 'File' && current.nlink > 1) {\\n       return rimraf(self._path, function (er) {\\n         if (er) return self.error(er)\\n         self._old = null\"}}",
            "message_norm":"clobber a link if it's in the way of a file\n\nfixes https:\/\/github.com\/npm\/node-tar\/issues\/212",
            "language":"en",
            "entities":"[('https:\/\/github.com\/npm\/node-tar\/issues\/212', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/writer.js'])",
            "num_files":1.0,
            "patch_content":"From 6a77d2fa6e1462693cf8e46f930da96ec1b0bb22 Mon Sep 17 00:00:00 2001\nFrom: isaacs <i@izs.me>\nDate: Tue, 14 May 2019 17:37:57 -0700\nSubject: [PATCH] Clobber a Link if it's in the way of a File\n\nFixes https:\/\/github.com\/npm\/node-tar\/issues\/212\n---\n lib\/writer.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/writer.js b\/lib\/writer.js\nindex 140e449..3f10547 100644\n--- a\/lib\/writer.js\n+++ b\/lib\/writer.js\n@@ -147,7 +147,7 @@ Writer.prototype._stat = function (current) {\n \n     \/\/ if it's a type change, then we need to clobber or error.\n     \/\/ if it's not a type change, then let the impl take care of it.\n-    if (currentType !== self.type) {\n+    if (currentType !== self.type || self.type === 'File' && current.nlink > 1) {\n       return rimraf(self._path, function (er) {\n         if (er) return self.error(er)\n         self._old = null"
        },
        {
            "index":555,
            "vuln_id":"GHSA-g25h-jr74-qp5j",
            "cwe_id":"{'CWE-20'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6da6620efad397c85493b8f8667b821403516708'}",
            "dataset":"osv",
            "summary":"Incomplete validation in `QuantizeV2` ### Impact                                                                                                                                                                                                                                                                                \nDue to incomplete validation in `tf.raw_ops.QuantizeV2`, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeV2(\n  input=[1,2,3],\n  min_range=[1,2],\n  max_range=[],\n  T=tf.qint32,\n  mode='SCALED',\n  round_mode='HALF_AWAY_FROM_ZERO',\n  narrow_range=False,\n  axis=1,\n  ensure_minimum_range=3)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/quantize_op.cc#L59) has some validation but does not check that `min_range` and `max_range` both have the same non-zero number of elements. If `axis` is provided (i.e., not `-1`), then validation should check that it is a value in range for the rank of `input` tensor and then the lengths of `min_range` and `max_range` inputs match the `axis` dimension of the `input` tensor.\n  \n### Patches\nWe have patched the issue in GitHub commit [6da6620efad397c85493b8f8667b821403516708](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6da6620efad397c85493b8f8667b821403516708).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6da6620efad397c85493b8f8667b821403516708",
            "commit_sha":"6da6620efad397c85493b8f8667b821403516708",
            "patch":"SINGLE",
            "chain_ord":"['6da6620efad397c85493b8f8667b821403516708']",
            "before_first_fix_commit":"{'eb921122119a6b6e470ee98b89e65d721663179d'}",
            "last_fix_commit":"6da6620efad397c85493b8f8667b821403516708",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/28\/2021, 00:19:57",
            "message":"Secure tf.raw_ops.QuantizeV2\n\nValidate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 43, 'deletions': 0, 'total': 43}",
            "files":"{'tensorflow\/core\/kernels\/quantize_op.cc': {'additions': 43, 'deletions': 0, 'changes': 43, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6da6620efad397c85493b8f8667b821403516708\/tensorflow%2Fcore%2Fkernels%2Fquantize_op.cc', 'patch': '@@ -113,7 +113,50 @@ class QuantizeV2Op : public OpKernel {\\n \\n     int num_slices = 1;\\n     if (axis_ > -1) {\\n+      OP_REQUIRES(\\n+          ctx, input.dims() > axis_,\\n+          errors::InvalidArgument(\\n+              \"Axis is on a zero-based index, so its value must always be less \"\\n+              \"than number of input\\'s dims, but given axis value was \",\\n+              axis_, \" and input\\'s dims was \", input.dims()));\\n       num_slices = input.dim_size(axis_);\\n+      OP_REQUIRES(ctx, input_min_range.dims() == 1,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\\n+                      \"whose size matches the axis dimension of the input and \"\\n+                      \"output tensors, but min_range dims are \",\\n+                      input_min_range.dims()));\\n+      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\\n+                      \"whose size matches the axis dimension of the input and \"\\n+                      \"output tensors, but min_range is a 1-D tensor of size \",\\n+                      input_min_range.dim_size(0),\\n+                      \" and input\\'s axis dimension is of size \", num_slices));\\n+      OP_REQUIRES(ctx, input_max_range.dims() == 1,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\\n+                      \"whose size matches the axis dimension of the input and \"\\n+                      \"output tensors, but max_range dims are \",\\n+                      input_max_range.dims()));\\n+      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\\n+                      \"whose size matches the axis dimension of the input and \"\\n+                      \"output tensors, but max_range is a 1-D tensor of size \",\\n+                      input_max_range.dim_size(0),\\n+                      \" and input\\'s axis dimension is of size \", num_slices));\\n+    } else {\\n+      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is not specified, min_range must contain a \"\\n+                      \"single float element, but it contains \",\\n+                      input_min_range.NumElements(), \" elements\"));\\n+      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is not specified, max_range must contain a \"\\n+                      \"single float element, but it contains \",\\n+                      input_max_range.NumElements(), \" elements\"));\\n     }\\n \\n     const TensorShape& minmax_shape = ctx->input(1).shape();'}}",
            "message_norm":"secure tf.raw_ops.quantizev2\n\nvalidate size and shape of min_range and max_range\nensure axis is within input dims limits\n\npiperorigin-revid: 387232799\nchange-id: i36975281f7b5758e9e31a8dcc73fe610ef456318",
            "language":"en",
            "entities":"[('secure', 'SECWORD', ''), ('validate', 'ACTION', ''), ('ensure', 'ACTION', ''), ('387232799', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 6da6620efad397c85493b8f8667b821403516708 Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Tue, 27 Jul 2021 17:19:57 -0700\nSubject: [PATCH] Secure tf.raw_ops.QuantizeV2\n\nValidate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318\n---\n tensorflow\/core\/kernels\/quantize_op.cc | 43 ++++++++++++++++++++++++++\n 1 file changed, 43 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantize_op.cc b\/tensorflow\/core\/kernels\/quantize_op.cc\nindex f64a2188fa9547..be73d4f8291f7b 100644\n--- a\/tensorflow\/core\/kernels\/quantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantize_op.cc\n@@ -113,7 +113,50 @@ class QuantizeV2Op : public OpKernel {\n \n     int num_slices = 1;\n     if (axis_ > -1) {\n+      OP_REQUIRES(\n+          ctx, input.dims() > axis_,\n+          errors::InvalidArgument(\n+              \"Axis is on a zero-based index, so its value must always be less \"\n+              \"than number of input's dims, but given axis value was \",\n+              axis_, \" and input's dims was \", input.dims()));\n       num_slices = input.dim_size(axis_);\n+      OP_REQUIRES(ctx, input_min_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range dims are \",\n+                      input_min_range.dims()));\n+      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but min_range is a 1-D tensor of size \",\n+                      input_min_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+      OP_REQUIRES(ctx, input_max_range.dims() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range dims are \",\n+                      input_max_range.dims()));\n+      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,\n+                  errors::InvalidArgument(\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\n+                      \"whose size matches the axis dimension of the input and \"\n+                      \"output tensors, but max_range is a 1-D tensor of size \",\n+                      input_max_range.dim_size(0),\n+                      \" and input's axis dimension is of size \", num_slices));\n+    } else {\n+      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, min_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_min_range.NumElements(), \" elements\"));\n+      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"If axis is not specified, max_range must contain a \"\n+                      \"single float element, but it contains \",\n+                      input_max_range.NumElements(), \" elements\"));\n     }\n \n     const TensorShape& minmax_shape = ctx->input(1).shape();"
        },
        {
            "index":180,
            "vuln_id":"GHSA-p9m8-27x8-rg87",
            "cwe_id":"{'CWE-94'}",
            "score":10.0,
            "chain":"{'https:\/\/github.com\/jmrozanec\/cron-utils\/commit\/cfd2880f80e62ea74b92fa83474c2aabdb9899da', 'https:\/\/github.com\/jmrozanec\/cron-utils\/commit\/d6707503ec2f20947f79e38f861dba93b39df9da'}",
            "dataset":"osv",
            "summary":"Critical vulnerability found in cron-utils ### Impact\nA Template Injection was identified in cron-utils enabling attackers to inject arbitrary Java EL expressions, leading to unauthenticated Remote Code Execution (RCE) vulnerability. Versions up to 9.1.2 are susceptible to this vulnerability. Please note, that only projects using the @Cron annotation to validate untrusted Cron expressions are affected.\n\n### Patches\nThe issue was patched and a new version was released. Please upgrade to version 9.1.6.\n\n### Workarounds\nThere are no known workarounds up to this moment.\n\n### References\nA description of the issue is provided in [issue 461](https:\/\/github.com\/jmrozanec\/cron-utils\/issues\/461)\n\n### For more information\nIf you have any questions or comments about this advisory:\n\nOpen an issue in the [cron-utils Github repository](https:\/\/github.com\/jmrozanec\/cron-utils)",
            "published_date":"2021-11-15",
            "chain_len":2,
            "project":"https:\/\/github.com\/jmrozanec\/cron-utils",
            "commit_href":"https:\/\/github.com\/jmrozanec\/cron-utils\/commit\/d6707503ec2f20947f79e38f861dba93b39df9da",
            "commit_sha":"d6707503ec2f20947f79e38f861dba93b39df9da",
            "patch":"MULTI",
            "chain_ord":"['d6707503ec2f20947f79e38f861dba93b39df9da', 'cfd2880f80e62ea74b92fa83474c2aabdb9899da']",
            "before_first_fix_commit":"{'9c93c17b8107e58073443a045e22274467b88aae', 'd6707503ec2f20947f79e38f861dba93b39df9da'}",
            "last_fix_commit":"cfd2880f80e62ea74b92fa83474c2aabdb9899da",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/30\/2021, 13:11:58",
            "message":"Merge pull request #493 from pwntester\/patch-1\n\nPrevent arbitrary EL expression evaluation",
            "author":"jmrozanec",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/main\/java\/com\/cronutils\/validation\/CronValidator.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jmrozanec\/cron-utils\/raw\/d6707503ec2f20947f79e38f861dba93b39df9da\/src%2Fmain%2Fjava%2Fcom%2Fcronutils%2Fvalidation%2FCronValidator.java', 'patch': '@@ -30,7 +30,7 @@ public boolean isValid(String value, ConstraintValidatorContext context) {\\n             return true;\\n         } catch (IllegalArgumentException e) {\\n             context.disableDefaultConstraintViolation();\\n-            context.buildConstraintViolationWithTemplate(e.getMessage()).addConstraintViolation();\\n+            context.buildConstraintViolationWithTemplate(\"Error parsing the Cron expression\").addConstraintViolation();\\n             return false;\\n         }\\n     }'}}",
            "message_norm":"merge pull request #493 from pwntester\/patch-1\n\nprevent arbitrary el expression evaluation",
            "language":"en",
            "entities":"[('#493', 'ISSUE', ''), ('prevent', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/com\/cronutils\/validation\/CronValidator.java'])",
            "num_files":1.0,
            "patch_content":"From d7c6e3cd8c8c7732330b00c01fc881845b4a6fbe Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Alvaro=20Mu=C3=B1oz?= <pwntester@github.com>\nDate: Fri, 22 Oct 2021 12:06:00 +0200\nSubject: [PATCH] Update CronValidator.java\n\n---\n src\/main\/java\/com\/cronutils\/validation\/CronValidator.java | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/main\/java\/com\/cronutils\/validation\/CronValidator.java b\/src\/main\/java\/com\/cronutils\/validation\/CronValidator.java\nindex bf7350c8..62a26e53 100644\n--- a\/src\/main\/java\/com\/cronutils\/validation\/CronValidator.java\n+++ b\/src\/main\/java\/com\/cronutils\/validation\/CronValidator.java\n@@ -30,7 +30,7 @@ public boolean isValid(String value, ConstraintValidatorContext context) {\n             return true;\n         } catch (IllegalArgumentException e) {\n             context.disableDefaultConstraintViolation();\n-            context.buildConstraintViolationWithTemplate(e.getMessage()).addConstraintViolation();\n+            context.buildConstraintViolationWithTemplate(\"Error parsing the Cron expression\").addConstraintViolation();\n             return false;\n         }\n     }"
        },
        {
            "index":83,
            "vuln_id":"GHSA-73qw-ww62-m54x",
            "cwe_id":"{'CWE-77'}",
            "score":10.0,
            "chain":"{'https:\/\/github.com\/quadule\/colorscore\/commit\/570b5e854cecddd44d2047c44126aed951b61718'}",
            "dataset":"osv",
            "summary":"Critical severity vulnerability that affects colorscore The initialize method in the Histogram class in lib\/colorscore\/histogram.rb in the colorscore gem before 0.0.5 for Ruby allows context-dependent attackers to execute arbitrary code via shell metacharacters in the (1) image_path, (2) colors, or (3) depth variable.",
            "published_date":"2017-10-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/quadule\/colorscore",
            "commit_href":"https:\/\/github.com\/quadule\/colorscore\/commit\/570b5e854cecddd44d2047c44126aed951b61718",
            "commit_sha":"570b5e854cecddd44d2047c44126aed951b61718",
            "patch":"SINGLE",
            "chain_ord":"['570b5e854cecddd44d2047c44126aed951b61718']",
            "before_first_fix_commit":"{'d589ce05be678c87174adae013ca5ac79f567828'}",
            "last_fix_commit":"570b5e854cecddd44d2047c44126aed951b61718",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/05\/2016, 10:53:22",
            "message":"Fix CVE-2015-7541\n\nAvoid passsing possible user input directly into the shell. Instead\nquote the `image_path` value before calling the `convert` command.\n\nSee here http:\/\/rubysec.com\/advisories\/CVE-2015-7541\/ for more\ninformation.",
            "author":"Florian Frank",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'lib\/colorscore\/histogram.rb': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/quadule\/colorscore\/raw\/570b5e854cecddd44d2047c44126aed951b61718\/lib%2Fcolorscore%2Fhistogram.rb', 'patch': '@@ -1,7 +1,9 @@\\n+require \"shellwords\"\\n+\\n module Colorscore\\n   class Histogram\\n     def initialize(image_path, colors=16, depth=8)\\n-      output = `convert #{image_path} -resize 400x400 -format %c -dither None -quantize YIQ -colors #{colors} -depth #{depth} histogram:info:-`\\n+      output = `convert #{image_path.shellescape} -resize 400x400 -format %c -dither None -quantize YIQ -colors #{colors.to_i} -depth #{depth.to_i} histogram:info:-`\\n       @lines = output.lines.sort.reverse.map(&:strip).reject(&:empty?)\\n     end'}}",
            "message_norm":"fix cve-2015-7541\n\navoid passsing possible user input directly into the shell. instead\nquote the `image_path` value before calling the `convert` command.\n\nsee here http:\/\/rubysec.com\/advisories\/cve-2015-7541\/ for more\ninformation.",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('cve-2015-7541', 'VULNID', 'CVE'), ('http:\/\/rubysec.com\/advisories\/cve-2015-7541\/', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/colorscore\/histogram.rb'])",
            "num_files":1.0,
            "patch_content":"From 570b5e854cecddd44d2047c44126aed951b61718 Mon Sep 17 00:00:00 2001\nFrom: Florian Frank <flori@ping.de>\nDate: Tue, 5 Jan 2016 11:53:22 +0100\nSubject: [PATCH] Fix CVE-2015-7541\n\nAvoid passsing possible user input directly into the shell. Instead\nquote the `image_path` value before calling the `convert` command.\n\nSee here http:\/\/rubysec.com\/advisories\/CVE-2015-7541\/ for more\ninformation.\n---\n lib\/colorscore\/histogram.rb | 4 +++-\n 1 file changed, 3 insertions(+), 1 deletion(-)\n\ndiff --git a\/lib\/colorscore\/histogram.rb b\/lib\/colorscore\/histogram.rb\nindex 3c2d1b1..4debcd5 100644\n--- a\/lib\/colorscore\/histogram.rb\n+++ b\/lib\/colorscore\/histogram.rb\n@@ -1,7 +1,9 @@\n+require \"shellwords\"\n+\n module Colorscore\n   class Histogram\n     def initialize(image_path, colors=16, depth=8)\n-      output = `convert #{image_path} -resize 400x400 -format %c -dither None -quantize YIQ -colors #{colors} -depth #{depth} histogram:info:-`\n+      output = `convert #{image_path.shellescape} -resize 400x400 -format %c -dither None -quantize YIQ -colors #{colors.to_i} -depth #{depth.to_i} histogram:info:-`\n       @lines = output.lines.sort.reverse.map(&:strip).reject(&:empty?)\n     end"
        },
        {
            "index":212,
            "vuln_id":"GHSA-8p5c-f328-9fvv",
            "cwe_id":"{'CWE-22'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/anthraxx\/diffoscope\/commit\/632a40828a54b399787c25e7fa243f732aef7e05'}",
            "dataset":"osv",
            "summary":"Diffoscope may write to arbitrary locations due to an untrusted archive diffoscope before 76 writes to arbitrary locations on disk based on the contents of an untrusted archive.",
            "published_date":"2018-07-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/anthraxx\/diffoscope",
            "commit_href":"https:\/\/github.com\/anthraxx\/diffoscope\/commit\/632a40828a54b399787c25e7fa243f732aef7e05",
            "commit_sha":"632a40828a54b399787c25e7fa243f732aef7e05",
            "patch":"SINGLE",
            "chain_ord":"['632a40828a54b399787c25e7fa243f732aef7e05']",
            "before_first_fix_commit":"{'b468a2840a097f4b2f7719929d690d5738dbcae4'}",
            "last_fix_commit":"632a40828a54b399787c25e7fa243f732aef7e05",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/09\/2017, 21:47:05",
            "message":"Extract archive members using an auto-incrementing integer, avoiding the need to sanitise filenames. (Closes: #854723)\n\nSigned-off-by: Chris Lamb <lamby@debian.org>",
            "author":"Chris Lamb",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 27, 'total': 41}",
            "files":"{'diffoscope\/comparators\/utils\/libarchive.py': {'additions': 14, 'deletions': 27, 'changes': 41, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/anthraxx\/diffoscope\/raw\/632a40828a54b399787c25e7fa243f732aef7e05\/diffoscope%2Fcomparators%2Futils%2Flibarchive.py', 'patch': '@@ -23,6 +23,7 @@\\n import ctypes\\n import logging\\n import libarchive\\n+import collections\\n \\n from diffoscope.tempfiles import get_temporary_directory\\n \\n@@ -168,11 +169,11 @@ def close_archive(self):\\n \\n     def get_member_names(self):\\n         self.ensure_unpacked()\\n-        return self._member_names\\n+        return self._members.keys()\\n \\n     def extract(self, member_name, dest_dir):\\n         self.ensure_unpacked()\\n-        return os.path.join(self._unpacked, member_name)\\n+        return self._members[member_name]\\n \\n     def get_member(self, member_name):\\n         with libarchive.file_reader(self.source.path) as archive:\\n@@ -197,45 +198,31 @@ def get_subclass(self, entry):\\n         return LibarchiveMember(self, entry)\\n \\n     def ensure_unpacked(self):\\n-        if hasattr(self, \\'_unpacked\\'):\\n+        if hasattr(self, \\'_members\\'):\\n             return\\n \\n-        self._unpacked = get_temporary_directory().name\\n-        self._member_names = []\\n+        tmpdir = get_temporary_directory().name\\n+        self._members = collections.OrderedDict()\\n \\n-        logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)\\n+        logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)\\n \\n         with libarchive.file_reader(self.source.path) as archive:\\n-            for entry in archive:\\n-                self._member_names.append(entry.pathname)\\n+            for idx, entry in enumerate(archive):\\n+                # Maintain a mapping of archive path to the extracted path,\\n+                # avoiding the need to sanitise filenames.\\n+                dst = os.path.join(tmpdir, \\'{}\\'.format(idx))\\n+                self._members[entry.pathname] = dst\\n \\n                 if entry.isdir:\\n                     continue\\n \\n-                # All extracted locations must be underneath self._unpacked\\n-                force_prefix = os.path.join(self._unpacked, \"\")\\n-\\n-                # Try to pick a safe and reasonable candidate name\\n-                candidate_name = os.path.normpath(entry.pathname.rstrip(\\'\/\\' + os.sep))\\n-                if os.path.isabs(candidate_name):\\n-                    candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))\\n-\\n-                dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))\\n-                if not dst.startswith(force_prefix):\\n-                    logger.warn(\"Skipping member because we could not make a safe name to extract it to: \\'%s\\'\",\\n-                                entry.pathname)\\n-                    continue\\n-\\n-                # TODO: need to fix reading these cleaned members. currently\\n-                # reading will still try to use the uncleaned name.\\n-                #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)\\n-                os.makedirs(os.path.dirname(dst), exist_ok=True)\\n+                logger.debug(\"Extracting %s to %s\", entry.pathname, dst)\\n \\n                 with open(dst, \\'wb\\') as f:\\n                     for block in entry.get_blocks():\\n                         f.write(block)\\n \\n         logger.debug(\\n             \"Extracted %d entries from %s to %s\",\\n-            len(self._member_names), self.source.path, self._unpacked,\\n+            len(self._members), self.source.path, tmpdir,\\n         )'}}",
            "message_norm":"extract archive members using an auto-incrementing integer, avoiding the need to sanitise filenames. (closes: #854723)\n\nsigned-off-by: chris lamb <lamby@debian.org>",
            "language":"en",
            "entities":"[('sanitise', 'SECWORD', ''), ('#854723', 'ISSUE', ''), ('lamby@debian.org', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['diffoscope\/comparators\/utils\/libarchive.py'])",
            "num_files":1.0,
            "patch_content":"From 632a40828a54b399787c25e7fa243f732aef7e05 Mon Sep 17 00:00:00 2001\nFrom: Chris Lamb <lamby@debian.org>\nDate: Fri, 10 Feb 2017 10:47:05 +1300\nSubject: [PATCH] Extract archive members using an auto-incrementing integer,\n avoiding the need to sanitise filenames. (Closes: #854723)\n\nSigned-off-by: Chris Lamb <lamby@debian.org>\n---\n diffoscope\/comparators\/utils\/libarchive.py | 41 ++++++++--------------\n 1 file changed, 14 insertions(+), 27 deletions(-)\n\ndiff --git a\/diffoscope\/comparators\/utils\/libarchive.py b\/diffoscope\/comparators\/utils\/libarchive.py\nindex 2acbb74..70160a0 100644\n--- a\/diffoscope\/comparators\/utils\/libarchive.py\n+++ b\/diffoscope\/comparators\/utils\/libarchive.py\n@@ -23,6 +23,7 @@\n import ctypes\n import logging\n import libarchive\n+import collections\n \n from diffoscope.tempfiles import get_temporary_directory\n \n@@ -168,11 +169,11 @@ def close_archive(self):\n \n     def get_member_names(self):\n         self.ensure_unpacked()\n-        return self._member_names\n+        return self._members.keys()\n \n     def extract(self, member_name, dest_dir):\n         self.ensure_unpacked()\n-        return os.path.join(self._unpacked, member_name)\n+        return self._members[member_name]\n \n     def get_member(self, member_name):\n         with libarchive.file_reader(self.source.path) as archive:\n@@ -197,39 +198,25 @@ def get_subclass(self, entry):\n         return LibarchiveMember(self, entry)\n \n     def ensure_unpacked(self):\n-        if hasattr(self, '_unpacked'):\n+        if hasattr(self, '_members'):\n             return\n \n-        self._unpacked = get_temporary_directory().name\n-        self._member_names = []\n+        tmpdir = get_temporary_directory().name\n+        self._members = collections.OrderedDict()\n \n-        logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)\n+        logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)\n \n         with libarchive.file_reader(self.source.path) as archive:\n-            for entry in archive:\n-                self._member_names.append(entry.pathname)\n+            for idx, entry in enumerate(archive):\n+                # Maintain a mapping of archive path to the extracted path,\n+                # avoiding the need to sanitise filenames.\n+                dst = os.path.join(tmpdir, '{}'.format(idx))\n+                self._members[entry.pathname] = dst\n \n                 if entry.isdir:\n                     continue\n \n-                # All extracted locations must be underneath self._unpacked\n-                force_prefix = os.path.join(self._unpacked, \"\")\n-\n-                # Try to pick a safe and reasonable candidate name\n-                candidate_name = os.path.normpath(entry.pathname.rstrip('\/' + os.sep))\n-                if os.path.isabs(candidate_name):\n-                    candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))\n-\n-                dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))\n-                if not dst.startswith(force_prefix):\n-                    logger.warn(\"Skipping member because we could not make a safe name to extract it to: '%s'\",\n-                                entry.pathname)\n-                    continue\n-\n-                # TODO: need to fix reading these cleaned members. currently\n-                # reading will still try to use the uncleaned name.\n-                #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)\n-                os.makedirs(os.path.dirname(dst), exist_ok=True)\n+                logger.debug(\"Extracting %s to %s\", entry.pathname, dst)\n \n                 with open(dst, 'wb') as f:\n                     for block in entry.get_blocks():\n@@ -237,5 +224,5 @@ def ensure_unpacked(self):\n \n         logger.debug(\n             \"Extracted %d entries from %s to %s\",\n-            len(self._member_names), self.source.path, self._unpacked,\n+            len(self._members), self.source.path, tmpdir,\n         )"
        },
        {
            "index":522,
            "vuln_id":"GHSA-hf44-3mx6-vhhw",
            "cwe_id":"{'CWE-400'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/graphhopper\/graphhopper\/commit\/eb189be1fa7443ebf4ae881e737a18f818c95f41'}",
            "dataset":"osv",
            "summary":"Navigate endpoint is vulnerable to regex injection that may lead to Denial of Service. ### Impact\nThe regex injection that may lead to Denial of Service.\n\n### Patches\nWill be patched in 2.4 and 3.0\n\n### Workarounds\nVersions lower than 2.x are only affected if the navigation module is added\n\n### References\nSee this pull request for the fix: https:\/\/github.com\/graphhopper\/graphhopper\/pull\/2304\n\nIf you have any questions or comments about this advisory please [send us an Email](https:\/\/www.graphhopper.com\/contact-form\/) or create a topic [here](https:\/\/discuss.graphhopper.com\/).",
            "published_date":"2021-05-19",
            "chain_len":1,
            "project":"https:\/\/github.com\/graphhopper\/graphhopper",
            "commit_href":"https:\/\/github.com\/graphhopper\/graphhopper\/commit\/eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "commit_sha":"eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "patch":"SINGLE",
            "chain_ord":"['eb189be1fa7443ebf4ae881e737a18f818c95f41']",
            "before_first_fix_commit":"{'744f0e2535355e67aefbb6906303332b8aff0a7f'}",
            "last_fix_commit":"eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/04\/2021, 18:03:31",
            "message":"avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexOf\r\n\r\n* make check stricter\r\n\r\n* use @easbar's suggestion",
            "author":"Peter",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 5, 'total': 8}",
            "files":"{'navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java': {'additions': 3, 'deletions': 5, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/graphhopper\/graphhopper\/raw\/eb189be1fa7443ebf4ae881e737a18f818c95f41\/navigation%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgraphhopper%2Fnavigation%2FNavigateResource.java', 'patch': '@@ -188,13 +188,11 @@ private GHResponse calcRoute(List<Double> favoredHeadings, List<GHPoint> request\\n      * The url looks like: \"...\/{profile}\/1.522438,42.504606;1.527209,42.504776;1.526113,42.505144;1.527218,42.50529?..\"\\n      *\/\\n     private List<GHPoint> getPointsFromRequest(HttpServletRequest httpServletRequest, String profile) {\\n-\\n         String url = httpServletRequest.getRequestURI();\\n-        url = url.replaceFirst(\"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\", \"\");\\n-        url = url.replaceAll(\"\\\\\\\\?[*]\", \"\");\\n-\\n+        String urlStart = \"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\";\\n+        if (!url.startsWith(urlStart)) throw new IllegalArgumentException(\"Incorrect URL \" + url);\\n+        url = url.substring(urlStart.length());\\n         String[] pointStrings = url.split(\";\");\\n-\\n         List<GHPoint> points = new ArrayList<>(pointStrings.length);\\n         for (int i = 0; i < pointStrings.length; i++) {\\n             points.add(GHPoint.fromStringLonLat(pointStrings[i]));'}}",
            "message_norm":"avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexof\r\n\r\n* make check stricter\r\n\r\n* use @easbar's suggestion",
            "language":"en",
            "entities":"[('#2304', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java'])",
            "num_files":1.0,
            "patch_content":"From eb189be1fa7443ebf4ae881e737a18f818c95f41 Mon Sep 17 00:00:00 2001\nFrom: Peter <graphhopper@gmx.de>\nDate: Tue, 4 May 2021 20:03:31 +0200\nSubject: [PATCH] avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexOf\n\n* make check stricter\n\n* use @easbar's suggestion\n---\n ...\/java\/com\/graphhopper\/navigation\/NavigateResource.java | 8 +++-----\n 1 file changed, 3 insertions(+), 5 deletions(-)\n\ndiff --git a\/navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java b\/navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java\nindex 75c61c5f3b8..66880307cba 100644\n--- a\/navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java\n+++ b\/navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java\n@@ -188,13 +188,11 @@ private GHResponse calcRoute(List<Double> favoredHeadings, List<GHPoint> request\n      * The url looks like: \"...\/{profile}\/1.522438,42.504606;1.527209,42.504776;1.526113,42.505144;1.527218,42.50529?..\"\n      *\/\n     private List<GHPoint> getPointsFromRequest(HttpServletRequest httpServletRequest, String profile) {\n-\n         String url = httpServletRequest.getRequestURI();\n-        url = url.replaceFirst(\"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\", \"\");\n-        url = url.replaceAll(\"\\\\?[*]\", \"\");\n-\n+        String urlStart = \"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\";\n+        if (!url.startsWith(urlStart)) throw new IllegalArgumentException(\"Incorrect URL \" + url);\n+        url = url.substring(urlStart.length());\n         String[] pointStrings = url.split(\";\");\n-\n         List<GHPoint> points = new ArrayList<>(pointStrings.length);\n         for (int i = 0; i < pointStrings.length; i++) {\n             points.add(GHPoint.fromStringLonLat(pointStrings[i]));"
        },
        {
            "index":491,
            "vuln_id":"GHSA-hp68-xhvj-x6j6",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/yhatt\/jsx-slack\/commit\/46bc88391d89d5fda4ce689e18ca080bcdd29ecc'}",
            "dataset":"osv",
            "summary":"jsx-slack insufficient patch for CVE-2021-43838 ReDoS We found the patch for CVE-2021-43838 in jsx-slack v4.5.1 is insufficient to save from Regular Expression Denial of Service (ReDoS) attack.\n\nThis vulnerability affects to jsx-slack v4.5.1 and earlier versions.\n\n### Impact\n\nIf attacker can put a lot of JSX elements into `<blockquote>` tag _with including multibyte characters_, an internal regular expression for escaping characters may consume an excessive amount of computing resources.\n\n```javascript\n\/** @jsxImportSource jsx-slack *\/\nimport { Section } from 'jsx-slack'\n\nconsole.log(\n  <Section>\n    <blockquote>\n      {[...Array(40)].map(() => (\n        <p>\u4e9c<\/p>\n      ))}\n    <\/blockquote>\n  <\/Section>\n)\n```\n\nv4.5.1 has released by passing the test against ASCII characters but missed the case of multibyte characters.\nhttps:\/\/github.com\/yhatt\/jsx-slack\/security\/advisories\/GHSA-55xv-f85c-248q\n\n### Patches\n\njsx-slack v4.5.2 has updated regular expressions for escaping blockquote characters to prevent catastrophic backtracking. It is also including an updated test case to confirm rendering multiple tags in `<blockquote>` with multibyte characters.\n\n### References\n\n- https:\/\/github.com\/yhatt\/jsx-slack\/commit\/46bc88391d89d5fda4ce689e18ca080bcdd29ecc\n\n### Credits\n\nThanks to @hieki for finding out this vulnerability.",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/yhatt\/jsx-slack",
            "commit_href":"https:\/\/github.com\/yhatt\/jsx-slack\/commit\/46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
            "commit_sha":"46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
            "patch":"SINGLE",
            "chain_ord":"['46bc88391d89d5fda4ce689e18ca080bcdd29ecc']",
            "before_first_fix_commit":"{'c3722705c8aadf544f922a974883578aa27dbea3'}",
            "last_fix_commit":"46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/18\/2021, 07:03:24",
            "message":"Prevent catastrophic backtracking in blockquote escape replacer",
            "author":"Yuki Hattori",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 6, 'total': 13}",
            "files":"{'src\/mrkdwn\/escape.ts': {'additions': 7, 'deletions': 6, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/yhatt\/jsx-slack\/raw\/46bc88391d89d5fda4ce689e18ca080bcdd29ecc\/src%2Fmrkdwn%2Fescape.ts', 'patch': '@@ -1,20 +1,21 @@\\n \/\/ An internal HTML tag and emoji shorthand should not escape\\n const preventEscapeRegex =\\n-  \/(<.*?>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b\\'\\\\u1100-\\\\u11ff\\\\u2e80-\\\\u2fd5\\\\u3005\\\\u3041-\\\\u3096\\\\u30a0-\\\\u30ff\\\\u3130-\\\\u318f\\\\u3400-\\\\u4db5\\\\u4e00-\\\\u9fcb\\\\ua960-\\\\ua97f\\\\uac00-\\\\ud7ff\\\\uff10-\\\\uff19\\\\uff41-\\\\uff5a\\\\uff61-\\\\uff9f]+:)\/\\n+  \/(<[^>]*>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b\\'\\\\u1100-\\\\u11ff\\\\u2e80-\\\\u2fd5\\\\u3005\\\\u3041-\\\\u3096\\\\u30a0-\\\\u30ff\\\\u3130-\\\\u318f\\\\u3400-\\\\u4db5\\\\u4e00-\\\\u9fcb\\\\ua960-\\\\ua97f\\\\uac00-\\\\ud7ff\\\\uff10-\\\\uff19\\\\uff41-\\\\uff5a\\\\uff61-\\\\uff9f]+:)\/\\n \\n const generateReplacerForEscape = (fallback: string) => (matched: string) =>\\n   `<span data-escape=\"${fallback.repeat(matched.length)}\">${matched}<\/span>`\\n \\n export const escapeReplacers = {\\n   blockquote: (partial: string) =>\\n     partial\\n-      .replace(\/^((?:<.*?>)*)(.{4})\/gm, (matched, leading, character) =>\\n-        character === \\'&gt;\\' ? `${leading}\\\\u00ad&gt;` : matched\\n+      .replace(\\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(&gt;)\/gm,\\n+        (_, leadingTags, character) => `${leadingTags}\\\\u00ad${character}`\\n       )\\n       .replace(\\n-        \/^((?:<.*?>)*)(\uff1e)\/gm,\\n-        (_, leading, character) =>\\n-          `${leading}${generateReplacerForEscape(\\'\\\\u00ad\uff1e\\')(character)}`\\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(\uff1e)\/gm,\\n+        (_, leadingTags, character) =>\\n+          `${leadingTags}${generateReplacerForEscape(\\'\\\\u00ad\uff1e\\')(character)}`\\n       ),\\n   bold: (partial: string) =>\\n     partial'}}",
            "message_norm":"prevent catastrophic backtracking in blockquote escape replacer",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/mrkdwn\/escape.ts'])",
            "num_files":1.0,
            "patch_content":"From 46bc88391d89d5fda4ce689e18ca080bcdd29ecc Mon Sep 17 00:00:00 2001\nFrom: Yuki Hattori <yukihattori1116@gmail.com>\nDate: Sat, 18 Dec 2021 16:03:24 +0900\nSubject: [PATCH] Prevent catastrophic backtracking in blockquote escape\n replacer\n\n---\n src\/mrkdwn\/escape.ts | 13 +++++++------\n 1 file changed, 7 insertions(+), 6 deletions(-)\n\ndiff --git a\/src\/mrkdwn\/escape.ts b\/src\/mrkdwn\/escape.ts\nindex 5702c5f..abb2491 100644\n--- a\/src\/mrkdwn\/escape.ts\n+++ b\/src\/mrkdwn\/escape.ts\n@@ -1,6 +1,6 @@\n \/\/ An internal HTML tag and emoji shorthand should not escape\n const preventEscapeRegex =\n-  \/(<.*?>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b'\\u1100-\\u11ff\\u2e80-\\u2fd5\\u3005\\u3041-\\u3096\\u30a0-\\u30ff\\u3130-\\u318f\\u3400-\\u4db5\\u4e00-\\u9fcb\\ua960-\\ua97f\\uac00-\\ud7ff\\uff10-\\uff19\\uff41-\\uff5a\\uff61-\\uff9f]+:)\/\n+  \/(<[^>]*>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b'\\u1100-\\u11ff\\u2e80-\\u2fd5\\u3005\\u3041-\\u3096\\u30a0-\\u30ff\\u3130-\\u318f\\u3400-\\u4db5\\u4e00-\\u9fcb\\ua960-\\ua97f\\uac00-\\ud7ff\\uff10-\\uff19\\uff41-\\uff5a\\uff61-\\uff9f]+:)\/\n \n const generateReplacerForEscape = (fallback: string) => (matched: string) =>\n   `<span data-escape=\"${fallback.repeat(matched.length)}\">${matched}<\/span>`\n@@ -8,13 +8,14 @@ const generateReplacerForEscape = (fallback: string) => (matched: string) =>\n export const escapeReplacers = {\n   blockquote: (partial: string) =>\n     partial\n-      .replace(\/^((?:<.*?>)*)(.{4})\/gm, (matched, leading, character) =>\n-        character === '&gt;' ? `${leading}\\u00ad&gt;` : matched\n+      .replace(\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(&gt;)\/gm,\n+        (_, leadingTags, character) => `${leadingTags}\\u00ad${character}`\n       )\n       .replace(\n-        \/^((?:<.*?>)*)(\uff1e)\/gm,\n-        (_, leading, character) =>\n-          `${leading}${generateReplacerForEscape('\\u00ad\uff1e')(character)}`\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(\uff1e)\/gm,\n+        (_, leadingTags, character) =>\n+          `${leadingTags}${generateReplacerForEscape('\\u00ad\uff1e')(character)}`\n       ),\n   bold: (partial: string) =>\n     partial"
        },
        {
            "index":696,
            "vuln_id":"GHSA-fh37-cx83-q542",
            "cwe_id":"{'CWE-306', 'CWE-269', 'CWE-287'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/apache\/airflow\/commit\/21cedff205e7d62675949fda2aa4616d77232b76'}",
            "dataset":"osv",
            "summary":"Improper Authentication in Apache Airflow The lineage endpoint of the deprecated Experimental API was not protected by authentication in Airflow 2.0.0. This allowed unauthenticated users to hit that endpoint. This is low-severity issue as the attacker needs to be aware of certain parameters to pass to that endpoint and even after can just get some metadata about a DAG and a Task. This issue only affects Apache Airflow 2.0.0.",
            "published_date":"2021-06-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/airflow",
            "commit_href":"https:\/\/github.com\/apache\/airflow\/commit\/21cedff205e7d62675949fda2aa4616d77232b76",
            "commit_sha":"21cedff205e7d62675949fda2aa4616d77232b76",
            "patch":"SINGLE",
            "chain_ord":"['21cedff205e7d62675949fda2aa4616d77232b76']",
            "before_first_fix_commit":"{'4b1a6f78d132e42f1c946f53eca89789d21bdc1d'}",
            "last_fix_commit":"21cedff205e7d62675949fda2aa4616d77232b76",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/27\/2021, 21:47:45",
            "message":"Add authentication to lineage endpoint for experimental API (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)",
            "author":"Ian Carroll",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'airflow\/www\/api\/experimental\/endpoints.py': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/airflow\/raw\/21cedff205e7d62675949fda2aa4616d77232b76\/airflow%2Fwww%2Fapi%2Fexperimental%2Fendpoints.py', 'patch': '@@ -389,6 +389,7 @@ def delete_pool(name):\\n \\n \\n @api_experimental.route(\\'\/lineage\/<string:dag_id>\/<string:execution_date>\\', methods=[\\'GET\\'])\\n+@requires_authentication\\n def get_lineage(dag_id: str, execution_date: str):\\n     \"\"\"Get Lineage details for a DagRun\"\"\"\\n     # Convert string datetime into actual datetime'}}",
            "message_norm":"add authentication to lineage endpoint for experimental api (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('authentication', 'SECWORD', ''), ('#13870', 'ISSUE', ''), ('commit 24a54242d56058846c7978130b3f37ca045d5142', 'SHA', 'prefix_colon_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['airflow\/www\/api\/experimental\/endpoints.py'])",
            "num_files":1.0,
            "patch_content":"From 21cedff205e7d62675949fda2aa4616d77232b76 Mon Sep 17 00:00:00 2001\nFrom: Ian Carroll <iangcarroll+spam-only@icloud.com>\nDate: Wed, 27 Jan 2021 13:47:45 -0800\nSubject: [PATCH] Add authentication to lineage endpoint for experimental API\n (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)\n---\n airflow\/www\/api\/experimental\/endpoints.py | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/airflow\/www\/api\/experimental\/endpoints.py b\/airflow\/www\/api\/experimental\/endpoints.py\nindex ada059b8575ef..e24ed5ef7be61 100644\n--- a\/airflow\/www\/api\/experimental\/endpoints.py\n+++ b\/airflow\/www\/api\/experimental\/endpoints.py\n@@ -389,6 +389,7 @@ def delete_pool(name):\n \n \n @api_experimental.route('\/lineage\/<string:dag_id>\/<string:execution_date>', methods=['GET'])\n+@requires_authentication\n def get_lineage(dag_id: str, execution_date: str):\n     \"\"\"Get Lineage details for a DagRun\"\"\"\n     # Convert string datetime into actual datetime"
        },
        {
            "index":123,
            "vuln_id":"GHSA-7488-6x3r-23w5",
            "cwe_id":"{'CWE-22'}",
            "score":9.3,
            "chain":"{'https:\/\/github.com\/ganga-devs\/ganga\/commit\/730e7aba192407d35eb37dd7938d49071124be8c'}",
            "dataset":"osv",
            "summary":"ganga before 8.5.10 allows absolute path traversal because the Flask send_file function is used unsafely The ganga-devs\/ganga repository before 8.5.10 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.",
            "published_date":"2022-07-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/ganga-devs\/ganga",
            "commit_href":"https:\/\/github.com\/ganga-devs\/ganga\/commit\/730e7aba192407d35eb37dd7938d49071124be8c",
            "commit_sha":"730e7aba192407d35eb37dd7938d49071124be8c",
            "patch":"SINGLE",
            "chain_ord":"['730e7aba192407d35eb37dd7938d49071124be8c']",
            "before_first_fix_commit":"{'0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc'}",
            "last_fix_commit":"730e7aba192407d35eb37dd7938d49071124be8c",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/09\/2022, 23:19:28",
            "message":"# Absolute Path Traversal due to incorrect use of `send_file` call (#2025)\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (..\/)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## Common Weakness Enumeration category\r\nCWE - 36\r\n\r\n## Root Cause Analysis\r\n\r\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path\/to\/mySafeStaticDir\"\r\n>>> malicious = \"\/..\/..\/..\/..\/..\/etc\/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'\/..\/..\/..\/..\/..\/etc\/passwd'\r\n```\r\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nIn this case, the problems occurs due to the following code :\r\nhttps:\/\/github.com\/ganga-devs\/ganga\/blob\/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc\/ganga\/GangaGUI\/gui\/routes.py#L671\r\n\r\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\r\n\r\n## Proof of Concept\r\n\r\nThe bug can be verified using a proof of concept similar to the one shown below.\r\n\r\n```\r\ncurl --path-as-is 'http:\/\/<domain>\/job\/<int:job_id>\/browse\/\/\/..\/..\/..\/..\/etc\/passwd\"'\r\n```\r\n## Remediation\r\n\r\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## Common Vulnerability Scoring System Vector\r\n\r\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\r\n\r\n(AV:N\/AC:L\/PR:N\/UI:N\/S:C\/C:H\/I:N\/A:L)[https:\/\/nvd.nist.gov\/vuln-metrics\/cvss\/v3-calculator?vector=AV:N\/AC:L\/PR:N\/UI:N\/S:C\/C:H\/I:N\/A:L&version=3.1]\r\n\r\nThis gives it a base score of 9.3\/10 and a severity rating of critical.\r\n\r\n## References\r\n* [OWASP Path Traversal](https:\/\/owasp.org\/www-community\/attacks\/Path_Traversal)\r\n* github\/securitylab#669\r\n\r\n### This bug was found using *[CodeQL by Github](https:\/\/codeql.github.com\/)*\r\n\r\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>",
            "author":"porcupineyhairs",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'ganga\/GangaGUI\/gui\/routes.py': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ganga-devs\/ganga\/raw\/730e7aba192407d35eb37dd7938d49071124be8c\/ganga%2FGangaGUI%2Fgui%2Froutes.py', 'patch': '@@ -12,7 +12,7 @@\\n import sys\\n import datetime\\n from functools import wraps\\n-from werkzeug.utils import secure_filename\\n+from werkzeug.utils import secure_filename, safe_join\\n from werkzeug.security import generate_password_hash, check_password_hash\\n from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, session, send_file, make_response\\n from flask_login import login_user, login_required, logout_user, current_user, UserMixin\\n@@ -656,7 +656,7 @@ def job_browse(job_id: int, path):\\n         return redirect(url_for(\"job_page\", job_id=job_id))\\n \\n     # Join the base and the requested path\\n-    abs_path = os.path.join(job_base_dir, path)\\n+    abs_path = safe_join(job_base_dir, path)\\n \\n     # URL path variable for going back\\n     back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")'}}",
            "message_norm":"# absolute path traversal due to incorrect use of `send_file` call (#2025)\n\na path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. by manipulating variables that reference files with \u201cdot-dot-slash (..\/)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. this attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## common weakness enumeration category\r\ncwe - 36\r\n\r\n## root cause analysis\r\n\r\nthe `os.path.join` call is unsafe for use with untrusted input. when the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path\/to\/mysafestaticdir\"\r\n>>> malicious = \"\/..\/..\/..\/..\/..\/etc\/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'\/..\/..\/..\/..\/..\/etc\/passwd'\r\n```\r\nsince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nin this case, the problems occurs due to the following code :\r\nhttps:\/\/github.com\/ganga-devs\/ganga\/blob\/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc\/ganga\/gangagui\/gui\/routes.py#l671\r\n\r\nhere, the `path` parameter is attacker controlled. this parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. this leads to a path traversal attack.\r\n\r\n## proof of concept\r\n\r\nthe bug can be verified using a proof of concept similar to the one shown below.\r\n\r\n```\r\ncurl --path-as-is 'http:\/\/<domain>\/job\/<int:job_id>\/browse\/\/\/..\/..\/..\/..\/etc\/passwd\"'\r\n```\r\n## remediation\r\n\r\nthis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. in case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## common vulnerability scoring system vector\r\n\r\nthe attack can be carried over the network. a complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. there is no user interaction required for successful execution. the attack can affect components outside the scope of the target module. the attack can be used to gain access to confidential files like passwords, login credentials and other secrets. it cannot be directly used to affect a change on a system resource. hence has limited to no impact on integrity. using this attack vector a attacker may make multiple requests for accessing huge files such as a database. this can lead to a partial system denial service. however, the impact on availability is quite low in this case. taking this account an appropriate cvss v3.1 vector would be\r\n\r\n(av:n\/ac:l\/pr:n\/ui:n\/s:c\/c:h\/i:n\/a:l)[https:\/\/nvd.nist.gov\/vuln-metrics\/cvss\/v3-calculator?vector=av:n\/ac:l\/pr:n\/ui:n\/s:c\/c:h\/i:n\/a:l&version=3.1]\r\n\r\nthis gives it a base score of 9.3\/10 and a severity rating of critical.\r\n\r\n## references\r\n* [owasp path traversal](https:\/\/owasp.org\/www-community\/attacks\/path_traversal)\r\n* github\/securitylab#669\r\n\r\n### this bug was found using *[codeql by github](https:\/\/codeql.github.com\/)*\r\n\r\nco-authored-by: porcupiney hairs <porucpiney.hairs@protonmail.com>",
            "language":"en",
            "entities":"[('absolute path traversal', 'SECWORD', ''), ('incorrect use', 'SECWORD', ''), ('#2025', 'ISSUE', ''), ('path traversal', 'SECWORD', ''), ('attack', 'SECWORD', ''), ('directory traversal', 'SECWORD', ''), ('manipulating', 'ACTION', ''), ('critical', 'SEVERITY', ''), ('attack', 'SECWORD', ''), ('directory traversal', 'SECWORD', ''), ('common weakness enumeration', 'SECWORD', ''), ('cwe - 36', 'CWEID', 'CWE_flexible'), ('unsafe', 'SECWORD', ''), ('untrusted', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('untrusted', 'SECWORD', ''), ('path traversal', 'SECWORD', ''), ('attacks', 'FLAW', ''), ('problems', 'FLAW', ''), ('https:\/\/github.com\/ganga-devs\/ganga\/blob\/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc\/ganga\/gangagui\/gui\/routes.py#l671', 'URL', ''), ('attacker', 'SECWORD', ''), ('unsafe', 'SECWORD', ''), ('attacker', 'SECWORD', ''), ('path traversal', 'SECWORD', ''), ('attack', 'FLAW', ''), ('bug', 'FLAW', ''), ('verified', 'ACTION', ''), ('http:\/\/<domain>\/job\/<int', 'URL', ''), ('fixed', 'ACTION', ''), ('preventing', 'ACTION', ''), ('untrusted data', 'SECWORD', ''), ('vulnerable', 'SECWORD', ''), ('untrusted', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('attack', 'SECWORD', ''), ('attack', 'SECWORD', ''), ('attack', 'SECWORD', ''), ('attack', 'FLAW', ''), ('confidential', 'SECWORD', ''), ('passwords', 'SECWORD', ''), ('login', 'SECWORD', ''), ('integrity', 'SECWORD', ''), ('attack vector', 'SECWORD', ''), ('attacker', 'FLAW', ''), ('availability', 'SECWORD', ''), ('low', 'SEVERITY', ''), ('v3.1', 'VERSION', ''), ('l)[https:\/\/nvd.nist.gov', 'URL', ''), ('critical', 'SEVERITY', ''), ('owasp', 'SECWORD', ''), ('path traversal](https:\/\/owasp.org', 'SECWORD', ''), ('attacks', 'SECWORD', ''), ('securitylab#669', 'SECWORD', ''), ('bug', 'FLAW', ''), ('found', 'ACTION', ''), ('codeql', 'DETECTION', ''), ('github](https:\/\/codeql.github.com\/', 'URL', ''), ('porucpiney.hairs@protonmail.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['ganga\/GangaGUI\/gui\/routes.py'])",
            "num_files":1.0,
            "patch_content":"From 730e7aba192407d35eb37dd7938d49071124be8c Mon Sep 17 00:00:00 2001\nFrom: porcupineyhairs <61983466+porcupineyhairs@users.noreply.github.com>\nDate: Mon, 9 May 2022 23:19:28 +0000\nSubject: [PATCH] # Absolute Path Traversal due to incorrect use of `send_file`\n call (#2025)\nMIME-Version: 1.0\nContent-Type: text\/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (..\/)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\n\n## Common Weakness Enumeration category\nCWE - 36\n\n## Root Cause Analysis\n\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\n```\n>>> import os.path\n>>> static = \"path\/to\/mySafeStaticDir\"\n>>> malicious = \"\/..\/..\/..\/..\/..\/etc\/passwd\"\n>>> os.path.join(t,malicious)\n'\/..\/..\/..\/..\/..\/etc\/passwd'\n```\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\n\nIn this case, the problems occurs due to the following code :\nhttps:\/\/github.com\/ganga-devs\/ganga\/blob\/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc\/ganga\/GangaGUI\/gui\/routes.py#L671\n\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\n\n## Proof of Concept\n\nThe bug can be verified using a proof of concept similar to the one shown below.\n\n```\ncurl --path-as-is 'http:\/\/<domain>\/job\/<int:job_id>\/browse\/\/\/..\/..\/..\/..\/etc\/passwd\"'\n```\n## Remediation\n\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\n\n## Common Vulnerability Scoring System Vector\n\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\n\n(AV:N\/AC:L\/PR:N\/UI:N\/S:C\/C:H\/I:N\/A:L)[https:\/\/nvd.nist.gov\/vuln-metrics\/cvss\/v3-calculator?vector=AV:N\/AC:L\/PR:N\/UI:N\/S:C\/C:H\/I:N\/A:L&version=3.1]\n\nThis gives it a base score of 9.3\/10 and a severity rating of critical.\n\n## References\n* [OWASP Path Traversal](https:\/\/owasp.org\/www-community\/attacks\/Path_Traversal)\n* github\/securitylab#669\n\n### This bug was found using *[CodeQL by Github](https:\/\/codeql.github.com\/)*\n\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>\n---\n ganga\/GangaGUI\/gui\/routes.py | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/ganga\/GangaGUI\/gui\/routes.py b\/ganga\/GangaGUI\/gui\/routes.py\nindex 5e1fd9ea69..51cb98266c 100644\n--- a\/ganga\/GangaGUI\/gui\/routes.py\n+++ b\/ganga\/GangaGUI\/gui\/routes.py\n@@ -12,7 +12,7 @@\n import sys\n import datetime\n from functools import wraps\n-from werkzeug.utils import secure_filename\n+from werkzeug.utils import secure_filename, safe_join\n from werkzeug.security import generate_password_hash, check_password_hash\n from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, session, send_file, make_response\n from flask_login import login_user, login_required, logout_user, current_user, UserMixin\n@@ -656,7 +656,7 @@ def job_browse(job_id: int, path):\n         return redirect(url_for(\"job_page\", job_id=job_id))\n \n     # Join the base and the requested path\n-    abs_path = os.path.join(job_base_dir, path)\n+    abs_path = safe_join(job_base_dir, path)\n \n     # URL path variable for going back\n     back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")"
        },
        {
            "index":594,
            "vuln_id":"GHSA-f5fj-7265-jxhj",
            "cwe_id":"{'CWE-200'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/go-gitea\/gitea\/commit\/194a11eb110cd98fc2ba52861abf7770db6885a3'}",
            "dataset":"osv",
            "summary":"Information Exposure Gitea version prior to version 1.5.1 contains a CWE-200 vulnerability that can result in Exposure of users private email addresses. This attack appear to be exploitable via Watch a repository to receive email notifications. Emails received contain the other recipients even if they have the email set as private. This vulnerability appears to have been fixed in 1.5.1.",
            "published_date":"2022-02-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/go-gitea\/gitea",
            "commit_href":"https:\/\/github.com\/go-gitea\/gitea\/commit\/194a11eb110cd98fc2ba52861abf7770db6885a3",
            "commit_sha":"194a11eb110cd98fc2ba52861abf7770db6885a3",
            "patch":"SINGLE",
            "chain_ord":"['194a11eb110cd98fc2ba52861abf7770db6885a3']",
            "before_first_fix_commit":"{'912953e82a851492c7fd1f2e9c10d3a1955b625c'}",
            "last_fix_commit":"194a11eb110cd98fc2ba52861abf7770db6885a3",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/24\/2018, 04:41:26",
            "message":"Don't disclose emails of all users when sending out emails (#4664)",
            "author":"techknowlogick",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 2, 'total': 12}",
            "files":"{'models\/issue_mail.go': {'additions': 10, 'deletions': 2, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/go-gitea\/gitea\/raw\/194a11eb110cd98fc2ba52861abf7770db6885a3\/models%2Fissue_mail.go', 'patch': '@@ -1,4 +1,5 @@\\n \/\/ Copyright 2016 The Gogs Authors. All rights reserved.\\n+\/\/ Copyright 2018 The Gitea Authors. All rights reserved.\\n \/\/ Use of this source code is governed by a MIT-style\\n \/\/ license that can be found in the LICENSE file.\\n \\n@@ -87,7 +88,9 @@ func mailIssueCommentToParticipants(e Engine, issue *Issue, doer *User, content\\n \\t\\tnames = append(names, participants[i].Name)\\n \\t}\\n \\n-\\tSendIssueCommentMail(issue, doer, content, comment, tos)\\n+\\tfor _, to := range tos {\\n+\\t\\tSendIssueCommentMail(issue, doer, content, comment, []string{to})\\n+\\t}\\n \\n \\t\/\/ Mail mentioned people and exclude watchers.\\n \\tnames = append(names, doer.Name)\\n@@ -99,7 +102,12 @@ func mailIssueCommentToParticipants(e Engine, issue *Issue, doer *User, content\\n \\n \\t\\ttos = append(tos, mentions[i])\\n \\t}\\n-\\tSendIssueMentionMail(issue, doer, content, comment, getUserEmailsByNames(e, tos))\\n+\\n+\\temails := getUserEmailsByNames(e, tos)\\n+\\n+\\tfor _, to := range emails {\\n+\\t\\tSendIssueMentionMail(issue, doer, content, comment, []string{to})\\n+\\t}\\n \\n \\treturn nil\\n }'}}",
            "message_norm":"don't disclose emails of all users when sending out emails (#4664)",
            "language":"en",
            "entities":"[('disclose', 'SECWORD', ''), ('#4664', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['models\/issue_mail.go'])",
            "num_files":1.0,
            "patch_content":"From 194a11eb110cd98fc2ba52861abf7770db6885a3 Mon Sep 17 00:00:00 2001\nFrom: techknowlogick <techknowlogick@users.noreply.github.com>\nDate: Fri, 24 Aug 2018 00:41:26 -0400\nSubject: [PATCH] Don't disclose emails of all users when sending out emails\n (#4664)\n\n---\n models\/issue_mail.go | 12 ++++++++++--\n 1 file changed, 10 insertions(+), 2 deletions(-)\n\ndiff --git a\/models\/issue_mail.go b\/models\/issue_mail.go\nindex 179bb6527b549..b78da6d79a5bd 100644\n--- a\/models\/issue_mail.go\n+++ b\/models\/issue_mail.go\n@@ -1,4 +1,5 @@\n \/\/ Copyright 2016 The Gogs Authors. All rights reserved.\n+\/\/ Copyright 2018 The Gitea Authors. All rights reserved.\n \/\/ Use of this source code is governed by a MIT-style\n \/\/ license that can be found in the LICENSE file.\n \n@@ -87,7 +88,9 @@ func mailIssueCommentToParticipants(e Engine, issue *Issue, doer *User, content\n \t\tnames = append(names, participants[i].Name)\n \t}\n \n-\tSendIssueCommentMail(issue, doer, content, comment, tos)\n+\tfor _, to := range tos {\n+\t\tSendIssueCommentMail(issue, doer, content, comment, []string{to})\n+\t}\n \n \t\/\/ Mail mentioned people and exclude watchers.\n \tnames = append(names, doer.Name)\n@@ -99,7 +102,12 @@ func mailIssueCommentToParticipants(e Engine, issue *Issue, doer *User, content\n \n \t\ttos = append(tos, mentions[i])\n \t}\n-\tSendIssueMentionMail(issue, doer, content, comment, getUserEmailsByNames(e, tos))\n+\n+\temails := getUserEmailsByNames(e, tos)\n+\n+\tfor _, to := range emails {\n+\t\tSendIssueMentionMail(issue, doer, content, comment, []string{to})\n+\t}\n \n \treturn nil\n }"
        },
        {
            "index":830,
            "vuln_id":"GHSA-29q4-gxjq-rx5c",
            "cwe_id":"{'CWE-59', 'CWE-690', 'CWE-917', 'CWE-74', 'CWE-62', 'CWE-77'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/SAP\/scimono\/commit\/413b5d75fa94e77876af0e47be76475a23745b80'}",
            "dataset":"osv",
            "summary":"Remote Code Execution in SCIMono ### Impact\nIt is possible for attacker to inject and execute java expression and compromising the availability and integrity of the system.\n\n### Patches\nThe issue was fixed on  [0.0.19 version](https:\/\/mvnrepository.com\/artifact\/com.sap.scimono\/scimono-server\/0.0.19)",
            "published_date":"2021-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/SAP\/scimono",
            "commit_href":"https:\/\/github.com\/SAP\/scimono\/commit\/413b5d75fa94e77876af0e47be76475a23745b80",
            "commit_sha":"413b5d75fa94e77876af0e47be76475a23745b80",
            "patch":"SINGLE",
            "chain_ord":"['413b5d75fa94e77876af0e47be76475a23745b80']",
            "before_first_fix_commit":"{'8a09b8cfbb4cb797efac745c7ec3924569513844'}",
            "last_fix_commit":"413b5d75fa94e77876af0e47be76475a23745b80",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/30\/2020, 14:35:19",
            "message":"Escape Java EL in validation message before interpolation (#117)",
            "author":"Aleydin Karaimin",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 1, 'total': 9}",
            "files":"{'scimono-server\/src\/main\/java\/com\/sap\/scimono\/entity\/schema\/validation\/ValidationUtil.java': {'additions': 8, 'deletions': 1, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/SAP\/scimono\/raw\/413b5d75fa94e77876af0e47be76475a23745b80\/scimono-server%2Fsrc%2Fmain%2Fjava%2Fcom%2Fsap%2Fscimono%2Fentity%2Fschema%2Fvalidation%2FValidationUtil.java', 'patch': '@@ -1,13 +1,20 @@\\n \\n package com.sap.scimono.entity.schema.validation;\\n \\n+import java.util.regex.Pattern;\\n+\\n import javax.validation.ConstraintValidatorContext;\\n \\n class ValidationUtil {\\n+  private static final Pattern EXPRESSION_LANGUAGE_CHARACTERS = Pattern.compile(\"([${}])\");\\n \\n   public static void interpolateErrorMessage(ConstraintValidatorContext context, String errorMessage) {\\n     context.disableDefaultConstraintViolation();\\n-    context.buildConstraintViolationWithTemplate(errorMessage).addConstraintViolation();\\n+    context.buildConstraintViolationWithTemplate(escapeExpressionLanguage(errorMessage)).addConstraintViolation();\\n+  }\\n+\\n+  private static String escapeExpressionLanguage(String text) {\\n+    return EXPRESSION_LANGUAGE_CHARACTERS.matcher(text).replaceAll( \"\\\\\\\\\\\\\\\\$1\" );\\n   }\\n \\n }'}}",
            "message_norm":"escape java el in validation message before interpolation (#117)",
            "language":"it",
            "entities":"[('escape', 'SECWORD', ''), ('#117', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['scimono-server\/src\/main\/java\/com\/sap\/scimono\/entity\/schema\/validation\/ValidationUtil.java'])",
            "num_files":1.0,
            "patch_content":"From 413b5d75fa94e77876af0e47be76475a23745b80 Mon Sep 17 00:00:00 2001\nFrom: Aleydin Karaimin <aleyidin.karaimin@sap.com>\nDate: Mon, 30 Nov 2020 16:35:19 +0200\nSubject: [PATCH] Escape Java EL in validation message before interpolation\n (#117)\n\n---\n ...\/scimono\/entity\/schema\/validation\/ValidationUtil.java | 9 ++++++++-\n 1 file changed, 8 insertions(+), 1 deletion(-)\n\ndiff --git a\/scimono-server\/src\/main\/java\/com\/sap\/scimono\/entity\/schema\/validation\/ValidationUtil.java b\/scimono-server\/src\/main\/java\/com\/sap\/scimono\/entity\/schema\/validation\/ValidationUtil.java\nindex 58ca9bc9..9e546b10 100644\n--- a\/scimono-server\/src\/main\/java\/com\/sap\/scimono\/entity\/schema\/validation\/ValidationUtil.java\n+++ b\/scimono-server\/src\/main\/java\/com\/sap\/scimono\/entity\/schema\/validation\/ValidationUtil.java\n@@ -1,13 +1,20 @@\n \n package com.sap.scimono.entity.schema.validation;\n \n+import java.util.regex.Pattern;\n+\n import javax.validation.ConstraintValidatorContext;\n \n class ValidationUtil {\n+  private static final Pattern EXPRESSION_LANGUAGE_CHARACTERS = Pattern.compile(\"([${}])\");\n \n   public static void interpolateErrorMessage(ConstraintValidatorContext context, String errorMessage) {\n     context.disableDefaultConstraintViolation();\n-    context.buildConstraintViolationWithTemplate(errorMessage).addConstraintViolation();\n+    context.buildConstraintViolationWithTemplate(escapeExpressionLanguage(errorMessage)).addConstraintViolation();\n+  }\n+\n+  private static String escapeExpressionLanguage(String text) {\n+    return EXPRESSION_LANGUAGE_CHARACTERS.matcher(text).replaceAll( \"\\\\\\\\$1\" );\n   }\n \n }"
        },
        {
            "index":321,
            "vuln_id":"GHSA-f6g6-54hm-fhxv",
            "cwe_id":"{'CWE-362', 'CWE-119'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/mvertescher\/libsbc-rs\/commit\/a34d6e10f6f5654ed01a35288cf683d014ebc9c4'}",
            "dataset":"osv",
            "summary":"Data races in libsbc Affected versions of this crate implements `Send` for `Decoder<R>` for any `R: Read`. This allows `Decoder<R>` to contain `R: !Send` and carry (move) it to another thread.\n\nThis can result in undefined behavior such as memory corruption from data race on `R`, or dropping `R = MutexGuard<_>` from a thread that didn't lock the mutex.\n\nThe flaw was corrected in commit a34d6e1 by adding trait bound `R: Send` to the `Send` impl for `Decoder<R>`.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/mvertescher\/libsbc-rs",
            "commit_href":"https:\/\/github.com\/mvertescher\/libsbc-rs\/commit\/a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
            "commit_sha":"a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
            "patch":"SINGLE",
            "chain_ord":"['a34d6e10f6f5654ed01a35288cf683d014ebc9c4']",
            "before_first_fix_commit":"{'7278b23901f93d956d9739fdfc4ced147cc3f242'}",
            "last_fix_commit":"a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/23\/2021, 02:06:34",
            "message":"Add R: Send bound to Send impl of Decoder<R>\nfixes issue #4",
            "author":"JOE1994",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/lib.rs': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mvertescher\/libsbc-rs\/raw\/a34d6e10f6f5654ed01a35288cf683d014ebc9c4\/src%2Flib.rs', 'patch': '@@ -33,7 +33,7 @@ where\\n \\n unsafe impl<R> Send for Decoder<R>\\n where\\n-        R: Read,\\n+        R: Read + Send,\\n {\\n }'}}",
            "message_norm":"add r: send bound to send impl of decoder<r>\nfixes issue #4",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('decoder', 'SECWORD', ''), ('#4', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/lib.rs'])",
            "num_files":1.0,
            "patch_content":"From a34d6e10f6f5654ed01a35288cf683d014ebc9c4 Mon Sep 17 00:00:00 2001\nFrom: JOE1994 <joseph942010@gmail.com>\nDate: Fri, 22 Jan 2021 21:06:34 -0500\nSubject: [PATCH] Add R: Send bound to Send impl of Decoder<R> fixes issue #4\n\n---\n src\/lib.rs | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/lib.rs b\/src\/lib.rs\nindex fcfc4d1..58aa8df 100644\n--- a\/src\/lib.rs\n+++ b\/src\/lib.rs\n@@ -33,7 +33,7 @@ where\n \n unsafe impl<R> Send for Decoder<R>\n where\n-        R: Read,\n+        R: Read + Send,\n {\n }"
        },
        {
            "index":748,
            "vuln_id":"GHSA-hrf4-hcpc-3345",
            "cwe_id":"{'CWE-190'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/f7acbd075dff4825b35b597b74958de9edce67fc'}",
            "dataset":"osv",
            "summary":"Denial of service in microweber Microweber is drag and drop website builder and CMS with E-commerce. The microweber prior 1.2.12 application allows large characters to insert in the input field \"post title\" which can allow attackers to cause a Denial of Service (DoS) via a crafted HTTP request. The post title input can be limited to 500 characters or max 1000 characters as a workaround.",
            "published_date":"2022-03-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/f7acbd075dff4825b35b597b74958de9edce67fc",
            "commit_sha":"f7acbd075dff4825b35b597b74958de9edce67fc",
            "patch":"SINGLE",
            "chain_ord":"['f7acbd075dff4825b35b597b74958de9edce67fc']",
            "before_first_fix_commit":"{'14e960d184e681507f5293be86446d18d1c125b5'}",
            "last_fix_commit":"f7acbd075dff4825b35b597b74958de9edce67fc",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2022, 15:00:22",
            "message":"Update PostRequest.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 1, 'total': 9}",
            "files":"{'src\/MicroweberPackages\/Post\/Http\/Requests\/PostRequest.php': {'additions': 8, 'deletions': 1, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/f7acbd075dff4825b35b597b74958de9edce67fc\/src%2FMicroweberPackages%2FPost%2FHttp%2FRequests%2FPostRequest.php', 'patch': \"@@ -22,8 +22,15 @@ public function authorize()\\n      *\/\\n     public function rules()\\n     {\\n+        \/\/ todo with multilanguage\\n+\\n         $rules = [\\n-           \/\/ 'title' => 'required', \/\/ todo with multilanguage\\n+            'title' => 'required|max:500',\\n+            'url' => 'max:500',\\n+            'description' => 'max:500',\\n+            'content_meta_title' => 'max:500',\\n+            'content_meta_keywords' => 'max:500',\\n+            'original_link' => 'max:500',\\n         ];\\n \\n         return $rules;\"}}",
            "message_norm":"update postrequest.php",
            "language":"fr",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/Post\/Http\/Requests\/PostRequest.php'])",
            "num_files":1.0,
            "patch_content":"From f7acbd075dff4825b35b597b74958de9edce67fc Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Mon, 14 Mar 2022 17:00:22 +0200\nSubject: [PATCH] Update PostRequest.php\n\n---\n ...\/Post\/Http\/Requests\/PostRequest.php                   | 9 ++++++++-\n 1 file changed, 8 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/MicroweberPackages\/Post\/Http\/Requests\/PostRequest.php b\/src\/MicroweberPackages\/Post\/Http\/Requests\/PostRequest.php\nindex 597a68a2f9c..f76f0810468 100644\n--- a\/src\/MicroweberPackages\/Post\/Http\/Requests\/PostRequest.php\n+++ b\/src\/MicroweberPackages\/Post\/Http\/Requests\/PostRequest.php\n@@ -22,8 +22,15 @@ public function authorize()\n      *\/\n     public function rules()\n     {\n+        \/\/ todo with multilanguage\n+\n         $rules = [\n-           \/\/ 'title' => 'required', \/\/ todo with multilanguage\n+            'title' => 'required|max:500',\n+            'url' => 'max:500',\n+            'description' => 'max:500',\n+            'content_meta_title' => 'max:500',\n+            'content_meta_keywords' => 'max:500',\n+            'original_link' => 'max:500',\n         ];\n \n         return $rules;"
        },
        {
            "index":16,
            "vuln_id":"GHSA-x2p8-rgfm-qw3v",
            "cwe_id":"{'CWE-863'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/stanfordnlp\/CoreNLP\/commit\/5ee097dbede547023e88f60ed3f430ff09398b87'}",
            "dataset":"osv",
            "summary":"Access Control vulnerability within CoreNLP An Incorrect Access Control vulnerability exists in CoreNLP 4.3.2 via the classifier in NERServlet.java (lines 158 and 159).",
            "published_date":"2022-02-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/stanfordnlp\/CoreNLP",
            "commit_href":"https:\/\/github.com\/stanfordnlp\/CoreNLP\/commit\/5ee097dbede547023e88f60ed3f430ff09398b87",
            "commit_sha":"5ee097dbede547023e88f60ed3f430ff09398b87",
            "patch":"SINGLE",
            "chain_ord":"['5ee097dbede547023e88f60ed3f430ff09398b87']",
            "before_first_fix_commit":"{'85e305bf63b3954e6266801175579a8b81769709'}",
            "last_fix_commit":"5ee097dbede547023e88f60ed3f430ff09398b87",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/26\/2021, 22:07:33",
            "message":"Address issue #1222: verify that classifier and outputFormat are valid values before returning them in headers.  Should sanitize malicious output",
            "author":"John Bauer",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 7, 'total': 22}",
            "files":"{'src\/edu\/stanford\/nlp\/ie\/ner\/webapp\/NERServlet.java': {'additions': 15, 'deletions': 7, 'changes': 22, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/stanfordnlp\/CoreNLP\/raw\/5ee097dbede547023e88f60ed3f430ff09398b87\/src%2Fedu%2Fstanford%2Fnlp%2Fie%2Fner%2Fwebapp%2FNERServlet.java', 'patch': '@@ -63,9 +63,9 @@ public void init() throws ServletException {\\n       log(classifier);\\n     }\\n \\n-    ners = Generics.newHashMap();\\n+    ners = new HashMap<>();\\n     for (String classifier : classifiers) {\\n-      CRFClassifier model = null;\\n+      CRFClassifier<CoreMap> model = null;\\n       String filename = \"\/WEB-INF\/data\/models\/\" + classifier;\\n       InputStream is = getServletConfig().getServletContext().getResourceAsStream(filename);\\n \\n@@ -154,15 +154,23 @@ private void addResults(HttpServletRequest request,\\n       classifier = this.defaultClassifier;\\n     }\\n \\n-    response.addHeader(\"classifier\", classifier);\\n-    response.addHeader(\"outputFormat\", outputFormat);\\n-    response.addHeader(\"preserveSpacing\", String.valueOf(preserveSpacing));\\n+    CRFClassifier<CoreMap> nerModel = ners.get(classifier);\\n+    \/\/ check that we weren\\'t asked for a classifier that doesn\\'t exist\\n+    if (nerModel == null) {\\n+      out.print(StringEscapeUtils.escapeHtml4(\"Unknown model \" + classifier));\\n+      return;\\n+    }\\n \\n     if (outputFormat.equals(\"highlighted\")) {\\n-      outputHighlighting(out, ners.get(classifier), input);\\n+      outputHighlighting(out, nerModel, input);\\n     } else {\\n-      out.print(StringEscapeUtils.escapeHtml4(ners.get(classifier).classifyToString(input, outputFormat, preserveSpacing)));\\n+      out.print(StringEscapeUtils.escapeHtml4(nerModel.classifyToString(input, outputFormat, preserveSpacing)));\\n     }\\n+\\n+    response.addHeader(\"classifier\", classifier);\\n+    \/\/ a non-existent outputFormat would have just thrown an exception\\n+    response.addHeader(\"outputFormat\", outputFormat);\\n+    response.addHeader(\"preserveSpacing\", String.valueOf(preserveSpacing));\\n   }\\n \\n   private static void outputHighlighting(PrintWriter out,'}}",
            "message_norm":"address issue #1222: verify that classifier and outputformat are valid values before returning them in headers.  should sanitize malicious output",
            "language":"en",
            "entities":"[('issue', 'FLAW', ''), ('#1222', 'ISSUE', ''), ('verify', 'ACTION', ''), ('sanitize', 'SECWORD', ''), ('malicious', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/edu\/stanford\/nlp\/ie\/ner\/webapp\/NERServlet.java'])",
            "num_files":1.0,
            "patch_content":"From 5ee097dbede547023e88f60ed3f430ff09398b87 Mon Sep 17 00:00:00 2001\nFrom: John Bauer <horatio@gmail.com>\nDate: Fri, 26 Nov 2021 14:07:33 -0800\nSubject: [PATCH] Address issue #1222: verify that classifier and outputFormat\n are valid values before returning them in headers.  Should sanitize malicious\n output\n\n---\n ...\/nlp\/ie\/ner\/webapp\/NERServlet.java         | 22 +++++++++++++------\n 1 file changed, 15 insertions(+), 7 deletions(-)\n\ndiff --git a\/src\/edu\/stanford\/nlp\/ie\/ner\/webapp\/NERServlet.java b\/src\/edu\/stanford\/nlp\/ie\/ner\/webapp\/NERServlet.java\nindex 4236f14ea2..f67edb4103 100644\n--- a\/src\/edu\/stanford\/nlp\/ie\/ner\/webapp\/NERServlet.java\n+++ b\/src\/edu\/stanford\/nlp\/ie\/ner\/webapp\/NERServlet.java\n@@ -63,9 +63,9 @@ public void init() throws ServletException {\n       log(classifier);\n     }\n \n-    ners = Generics.newHashMap();\n+    ners = new HashMap<>();\n     for (String classifier : classifiers) {\n-      CRFClassifier model = null;\n+      CRFClassifier<CoreMap> model = null;\n       String filename = \"\/WEB-INF\/data\/models\/\" + classifier;\n       InputStream is = getServletConfig().getServletContext().getResourceAsStream(filename);\n \n@@ -154,15 +154,23 @@ private void addResults(HttpServletRequest request,\n       classifier = this.defaultClassifier;\n     }\n \n-    response.addHeader(\"classifier\", classifier);\n-    response.addHeader(\"outputFormat\", outputFormat);\n-    response.addHeader(\"preserveSpacing\", String.valueOf(preserveSpacing));\n+    CRFClassifier<CoreMap> nerModel = ners.get(classifier);\n+    \/\/ check that we weren't asked for a classifier that doesn't exist\n+    if (nerModel == null) {\n+      out.print(StringEscapeUtils.escapeHtml4(\"Unknown model \" + classifier));\n+      return;\n+    }\n \n     if (outputFormat.equals(\"highlighted\")) {\n-      outputHighlighting(out, ners.get(classifier), input);\n+      outputHighlighting(out, nerModel, input);\n     } else {\n-      out.print(StringEscapeUtils.escapeHtml4(ners.get(classifier).classifyToString(input, outputFormat, preserveSpacing)));\n+      out.print(StringEscapeUtils.escapeHtml4(nerModel.classifyToString(input, outputFormat, preserveSpacing)));\n     }\n+\n+    response.addHeader(\"classifier\", classifier);\n+    \/\/ a non-existent outputFormat would have just thrown an exception\n+    response.addHeader(\"outputFormat\", outputFormat);\n+    response.addHeader(\"preserveSpacing\", String.valueOf(preserveSpacing));\n   }\n \n   private static void outputHighlighting(PrintWriter out,"
        },
        {
            "index":884,
            "vuln_id":"GHSA-qc36-q22q-cjw3",
            "cwe_id":"{'CWE-147'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/lettre\/lettre\/pull\/627\/commits\/93458d01fed0ec81c0e7b4e98e6f35961356fae2', 'https:\/\/github.com\/lettre\/lettre\/commit\/8bfc20506cc5e098fe6eb3d1cafe3bea791215ce'}",
            "dataset":"osv",
            "summary":"SMTP command injection in lettre ### Impact\n\nAffected versions of lettre allowed SMTP command injection through an attacker's controlled message body. The module for escaping lines starting with a period wouldn't catch a period that was placed after a double CRLF sequence, allowing the attacker to end the current message and write arbitrary SMTP commands after it.\n\n### Fix\n\nThe flaw is fixed by correctly handling consecutive CRLF sequences.\n\n### References\n\n* [RUSTSEC-2021-0069](https:\/\/rustsec.org\/advisories\/RUSTSEC-2021-0069.html)",
            "published_date":"2021-07-12",
            "chain_len":2,
            "project":"https:\/\/github.com\/lettre\/lettre",
            "commit_href":"https:\/\/github.com\/lettre\/lettre\/pull\/627\/commits\/93458d01fed0ec81c0e7b4e98e6f35961356fae2",
            "commit_sha":"93458d01fed0ec81c0e7b4e98e6f35961356fae2",
            "patch":"MULTI",
            "chain_ord":"['93458d01fed0ec81c0e7b4e98e6f35961356fae2', '8bfc20506cc5e098fe6eb3d1cafe3bea791215ce']",
            "before_first_fix_commit":"{'d930c42d5069e344a9dfa84ebe4b60bf3b11ac64'}",
            "last_fix_commit":"8bfc20506cc5e098fe6eb3d1cafe3bea791215ce",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/22\/2021, 17:31:36",
            "message":"fix(transport-smtp): Fix transparency codec\n\nIt fails to add transparency when a period is preceded by two\nsuccessive CRLF.",
            "author":"Paolo Barbolini",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 2, 'total': 13}",
            "files":"{'src\/transport\/smtp\/client\/mod.rs': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/lettre\/lettre\/raw\/93458d01fed0ec81c0e7b4e98e6f35961356fae2\/src%2Ftransport%2Fsmtp%2Fclient%2Fmod.rs', 'patch': '@@ -78,7 +78,15 @@ impl ClientCodec {\\n                     match self.escape_count {\\n                         0 => self.escape_count = if *byte == b\\'\\\\r\\' { 1 } else { 0 },\\n                         1 => self.escape_count = if *byte == b\\'\\\\n\\' { 2 } else { 0 },\\n-                        2 => self.escape_count = if *byte == b\\'.\\' { 3 } else { 0 },\\n+                        2 => {\\n+                            self.escape_count = if *byte == b\\'.\\' {\\n+                                3\\n+                            } else if *byte == b\\'\\\\r\\' {\\n+                                1\\n+                            } else {\\n+                                0\\n+                            }\\n+                        }\\n                         _ => unreachable!(),\\n                     }\\n                     if self.escape_count == 3 {\\n@@ -111,6 +119,7 @@ mod test {\\n         let mut buf: Vec<u8> = vec![];\\n \\n         codec.encode(b\"test\\\\r\\\\n\", &mut buf);\\n+        codec.encode(b\"test\\\\r\\\\n\\\\r\\\\n\", &mut buf);\\n         codec.encode(b\".\\\\r\\\\n\", &mut buf);\\n         codec.encode(b\"\\\\r\\\\ntest\", &mut buf);\\n         codec.encode(b\"te\\\\r\\\\n.\\\\r\\\\nst\", &mut buf);\\n@@ -121,7 +130,7 @@ mod test {\\n         codec.encode(b\"test\", &mut buf);\\n         assert_eq!(\\n             String::from_utf8(buf).unwrap(),\\n-            \"test\\\\r\\\\n..\\\\r\\\\n\\\\r\\\\ntestte\\\\r\\\\n..\\\\r\\\\nsttesttest.test\\\\n.test\\\\ntest\"\\n+            \"test\\\\r\\\\ntest\\\\r\\\\n\\\\r\\\\n..\\\\r\\\\n\\\\r\\\\ntestte\\\\r\\\\n..\\\\r\\\\nsttesttest.test\\\\n.test\\\\ntest\"\\n         );\\n     }'}}",
            "message_norm":"fix(transport-smtp): fix transparency codec\n\nit fails to add transparency when a period is preceded by two\nsuccessive crlf.",
            "language":"en",
            "entities":"[('fix(transport', 'ACTION', ''), ('fix', 'ACTION', ''), ('add', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/transport\/smtp\/client\/mod.rs'])",
            "num_files":1.0,
            "patch_content":"From 93458d01fed0ec81c0e7b4e98e6f35961356fae2 Mon Sep 17 00:00:00 2001\nFrom: Paolo Barbolini <paolo@paolo565.org>\nDate: Sat, 22 May 2021 19:31:36 +0200\nSubject: [PATCH] fix(transport-smtp): Fix transparency codec\n\nIt fails to add transparency when a period is preceded by two\nsuccessive CRLF.\n---\n src\/transport\/smtp\/client\/mod.rs | 13 +++++++++++--\n 1 file changed, 11 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/transport\/smtp\/client\/mod.rs b\/src\/transport\/smtp\/client\/mod.rs\nindex 795f389af..ce4b5da12 100644\n--- a\/src\/transport\/smtp\/client\/mod.rs\n+++ b\/src\/transport\/smtp\/client\/mod.rs\n@@ -78,7 +78,15 @@ impl ClientCodec {\n                     match self.escape_count {\n                         0 => self.escape_count = if *byte == b'\\r' { 1 } else { 0 },\n                         1 => self.escape_count = if *byte == b'\\n' { 2 } else { 0 },\n-                        2 => self.escape_count = if *byte == b'.' { 3 } else { 0 },\n+                        2 => {\n+                            self.escape_count = if *byte == b'.' {\n+                                3\n+                            } else if *byte == b'\\r' {\n+                                1\n+                            } else {\n+                                0\n+                            }\n+                        }\n                         _ => unreachable!(),\n                     }\n                     if self.escape_count == 3 {\n@@ -111,6 +119,7 @@ mod test {\n         let mut buf: Vec<u8> = vec![];\n \n         codec.encode(b\"test\\r\\n\", &mut buf);\n+        codec.encode(b\"test\\r\\n\\r\\n\", &mut buf);\n         codec.encode(b\".\\r\\n\", &mut buf);\n         codec.encode(b\"\\r\\ntest\", &mut buf);\n         codec.encode(b\"te\\r\\n.\\r\\nst\", &mut buf);\n@@ -121,7 +130,7 @@ mod test {\n         codec.encode(b\"test\", &mut buf);\n         assert_eq!(\n             String::from_utf8(buf).unwrap(),\n-            \"test\\r\\n..\\r\\n\\r\\ntestte\\r\\n..\\r\\nsttesttest.test\\n.test\\ntest\"\n+            \"test\\r\\ntest\\r\\n\\r\\n..\\r\\n\\r\\ntestte\\r\\n..\\r\\nsttesttest.test\\n.test\\ntest\"\n         );\n     }"
        },
        {
            "index":923,
            "vuln_id":"GHSA-j8cx-j9j2-f29w",
            "cwe_id":"{'CWE-922'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/b592c86d2b927c0cae5b73b87fb541f25e777aa3'}",
            "dataset":"osv",
            "summary":"Insecure Storage of Sensitive Information in Microweber Microweber prior to version 1.3 does not strip images of EXIF data, exposing information about users' locations, device hardware, and device software.",
            "published_date":"2022-02-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/b592c86d2b927c0cae5b73b87fb541f25e777aa3",
            "commit_sha":"b592c86d2b927c0cae5b73b87fb541f25e777aa3",
            "patch":"SINGLE",
            "chain_ord":"['b592c86d2b927c0cae5b73b87fb541f25e777aa3']",
            "before_first_fix_commit":"{'bfb86241bbb8cffe8291822091c6411498ac2a3e'}",
            "last_fix_commit":"b592c86d2b927c0cae5b73b87fb541f25e777aa3",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/22\/2022, 11:07:12",
            "message":"Update plupload.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 3, 'total': 6}",
            "files":"{'src\/MicroweberPackages\/App\/functions\/plupload.php': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/b592c86d2b927c0cae5b73b87fb541f25e777aa3\/src%2FMicroweberPackages%2FApp%2Ffunctions%2Fplupload.php', 'patch': \"@@ -522,22 +522,22 @@\\n                 \/\/ This will clear exif data - security issue\\n                 $imgCreatedFromJpeg = @imagecreatefromjpeg($filePath);\\n                 if ($imgCreatedFromJpeg) {\\n-                    imagejpeg($imgCreatedFromJpeg, $filePath,100);\\n+                    imagejpeg($imgCreatedFromJpeg, $filePath,100);  \/\/ this will create fresh new image without exif sensitive data\\n                     $valid = true;\\n                 }\\n             } else if ($ext === 'png') {\\n \\n                 $imgCreatedFromPng = @imagecreatefrompng($filePath);\\n                 if ($imgCreatedFromPng) {\\n-                    imagepng($imgCreatedFromPng, $filePath,100);\\n+                    imagepng($imgCreatedFromPng, $filePath,100);  \/\/ this will create fresh new image without exif sensitive data\\n                     $valid = true;\\n                 }\\n \\n             } else if ($ext === 'gif') {\\n \\n                 $imgCreatedFromGif = @imagecreatefromgif($filePath);\\n                 if ($imgCreatedFromGif) {\\n-                    imagegif($imgCreatedFromGif, $filePath,100);\\n+                    imagegif($imgCreatedFromGif, $filePath,100); \/\/ this will create fresh new image without exif sensitive data\\n                     $valid = true;\\n                 }\"}}",
            "message_norm":"update plupload.php",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/App\/functions\/plupload.php'])",
            "num_files":1.0,
            "patch_content":"From b592c86d2b927c0cae5b73b87fb541f25e777aa3 Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Tue, 22 Feb 2022 13:07:12 +0200\nSubject: [PATCH] Update plupload.php\n\n---\n src\/MicroweberPackages\/App\/functions\/plupload.php | 6 +++---\n 1 file changed, 3 insertions(+), 3 deletions(-)\n\ndiff --git a\/src\/MicroweberPackages\/App\/functions\/plupload.php b\/src\/MicroweberPackages\/App\/functions\/plupload.php\nindex 07de3dbfadf..d19e56c404b 100644\n--- a\/src\/MicroweberPackages\/App\/functions\/plupload.php\n+++ b\/src\/MicroweberPackages\/App\/functions\/plupload.php\n@@ -522,14 +522,14 @@\n                 \/\/ This will clear exif data - security issue\n                 $imgCreatedFromJpeg = @imagecreatefromjpeg($filePath);\n                 if ($imgCreatedFromJpeg) {\n-                    imagejpeg($imgCreatedFromJpeg, $filePath,100);\n+                    imagejpeg($imgCreatedFromJpeg, $filePath,100);  \/\/ this will create fresh new image without exif sensitive data\n                     $valid = true;\n                 }\n             } else if ($ext === 'png') {\n \n                 $imgCreatedFromPng = @imagecreatefrompng($filePath);\n                 if ($imgCreatedFromPng) {\n-                    imagepng($imgCreatedFromPng, $filePath,100);\n+                    imagepng($imgCreatedFromPng, $filePath,100);  \/\/ this will create fresh new image without exif sensitive data\n                     $valid = true;\n                 }\n \n@@ -537,7 +537,7 @@\n \n                 $imgCreatedFromGif = @imagecreatefromgif($filePath);\n                 if ($imgCreatedFromGif) {\n-                    imagegif($imgCreatedFromGif, $filePath,100);\n+                    imagegif($imgCreatedFromGif, $filePath,100); \/\/ this will create fresh new image without exif sensitive data\n                     $valid = true;\n                 }"
        },
        {
            "index":413,
            "vuln_id":"GHSA-95hx-62rh-gg96",
            "cwe_id":"{'CWE-79'}",
            "score":8.0,
            "chain":"{'https:\/\/github.com\/PrestaShop\/contactform\/commit\/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09'}",
            "dataset":"osv",
            "summary":"Potential XSS injection In PrestaShop contactform ### Impact\nAn attacker is able to inject javascript while using the contact form. \n\n### Patches\nThe problem is fixed in v4.3.0\n\n### References\n[Cross-site Scripting (XSS) - Stored (CWE-79)](https:\/\/cwe.mitre.org\/data\/definitions\/79.html)",
            "published_date":"2020-09-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/PrestaShop\/contactform",
            "commit_href":"https:\/\/github.com\/PrestaShop\/contactform\/commit\/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
            "commit_sha":"ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
            "patch":"SINGLE",
            "chain_ord":"['ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09']",
            "before_first_fix_commit":"{'a883e56240357b4aaaf594ade573bb596e518078', 'aa3c77923734854bb7168f30db43544e42638202'}",
            "last_fix_commit":"ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/15\/2020, 08:03:00",
            "message":"Merge pull request from GHSA-95hx-62rh-gg96\n\nDo not unescape form message data",
            "author":"GoT",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 8, 'total': 17}",
            "files":"{'contactform.php': {'additions': 9, 'deletions': 8, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/PrestaShop\/contactform\/raw\/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09\/contactform.php', 'patch': \"@@ -317,7 +317,7 @@ public function getWidgetVariables($hookName = null, array $configuration = [])\\n             }\\n         }\\n         $this->contact['contacts'] = $this->getTemplateVarContact();\\n-        $this->contact['message'] = html_entity_decode(Tools::getValue('message'));\\n+        $this->contact['message'] = Tools::getValue('message');\\n         $this->contact['allow_file_upload'] = (bool) Configuration::get('PS_CUSTOMER_SERVICE_FILE_UPLOAD');\\n \\n         if (!(bool)Configuration::isCatalogMode()) {\\n@@ -388,9 +388,10 @@ public function getTemplateVarOrders()\\n     {\\n         $orders = [];\\n \\n-        if (!isset($this->customer_thread['id_order'])\\n+        if (empty($this->customer_thread['id_order'])\\n             && isset($this->context->customer)\\n-            && $this->context->customer->isLogged()) {\\n+            && $this->context->customer->isLogged()\\n+        ) {\\n             $customer_orders = Order::getCustomerOrders($this->context->customer->id);\\n \\n             foreach ($customer_orders as $customer_order) {\\n@@ -401,7 +402,7 @@ public function getTemplateVarOrders()\\n                     $orders[$customer_order['id_order']]['products'] = $myOrder->getProducts();\\n                 }\\n             }\\n-        } elseif (isset($this->customer_thread['id_order']) && (int)$this->customer_thread['id_order'] > 0) {\\n+        } elseif (isset($this->customer_thread['id_order']) && (int) $this->customer_thread['id_order'] > 0) {\\n             $myOrder = new Order($this->customer_thread['id_order']);\\n \\n             if (Validate::isLoadedObject($myOrder)) {\\n@@ -411,13 +412,13 @@ public function getTemplateVarOrders()\\n             }\\n         }\\n \\n-        if (isset($this->customer_thread['id_product'])) {\\n+        if (!empty($this->customer_thread['id_product'])) {\\n             $id_order = isset($this->customer_thread['id_order']) ?\\n-                      (int)$this->customer_thread['id_order'] :\\n+                      (int) $this->customer_thread['id_order'] :\\n                       0;\\n \\n             $orders[$id_order]['products'][(int)$this->customer_thread['id_product']] = $this->context->controller->objectPresenter->present(\\n-                new Product((int)$this->customer_thread['id_product'])\\n+                new Product((int) $this->customer_thread['id_product'])\\n             );\\n         }\\n \\n@@ -586,7 +587,7 @@ public function sendMessage()\\n                     '{lastname}' => '',\\n                     '{order_name}' => '-',\\n                     '{attached_file}' => '-',\\n-                    '{message}' => Tools::nl2br(Tools::stripslashes($message)),\\n+                    '{message}' => Tools::nl2br(Tools::htmlentitiesUTF8(Tools::stripslashes($message))),\\n                     '{email}' =>  $from,\\n                     '{product_name}' => '',\\n                 ];\"}}",
            "message_norm":"merge pull request from ghsa-95hx-62rh-gg96\n\ndo not unescape form message data",
            "language":"fr",
            "entities":"[('ghsa-95hx-62rh-gg96', 'VULNID', 'GHSA'), ('unescape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['contactform.php'])",
            "num_files":1.0,
            "patch_content":"From aa3c77923734854bb7168f30db43544e42638202 Mon Sep 17 00:00:00 2001\nFrom: Pierre RAMBAUD <pierre.rambaud86@gmail.com>\nDate: Mon, 10 Aug 2020 17:09:40 +0200\nSubject: [PATCH] Do not unescape form message data\n\n---\n contactform.php | 17 +++++++++--------\n 1 file changed, 9 insertions(+), 8 deletions(-)\n\ndiff --git a\/contactform.php b\/contactform.php\nindex 0f94633..3135a3f 100644\n--- a\/contactform.php\n+++ b\/contactform.php\n@@ -317,7 +317,7 @@ public function getWidgetVariables($hookName = null, array $configuration = [])\n             }\n         }\n         $this->contact['contacts'] = $this->getTemplateVarContact();\n-        $this->contact['message'] = html_entity_decode(Tools::getValue('message'));\n+        $this->contact['message'] = Tools::getValue('message');\n         $this->contact['allow_file_upload'] = (bool) Configuration::get('PS_CUSTOMER_SERVICE_FILE_UPLOAD');\n \n         if (!(bool)Configuration::isCatalogMode()) {\n@@ -388,9 +388,10 @@ public function getTemplateVarOrders()\n     {\n         $orders = [];\n \n-        if (!isset($this->customer_thread['id_order'])\n+        if (empty($this->customer_thread['id_order'])\n             && isset($this->context->customer)\n-            && $this->context->customer->isLogged()) {\n+            && $this->context->customer->isLogged()\n+        ) {\n             $customer_orders = Order::getCustomerOrders($this->context->customer->id);\n \n             foreach ($customer_orders as $customer_order) {\n@@ -401,7 +402,7 @@ public function getTemplateVarOrders()\n                     $orders[$customer_order['id_order']]['products'] = $myOrder->getProducts();\n                 }\n             }\n-        } elseif (isset($this->customer_thread['id_order']) && (int)$this->customer_thread['id_order'] > 0) {\n+        } elseif (isset($this->customer_thread['id_order']) && (int) $this->customer_thread['id_order'] > 0) {\n             $myOrder = new Order($this->customer_thread['id_order']);\n \n             if (Validate::isLoadedObject($myOrder)) {\n@@ -411,13 +412,13 @@ public function getTemplateVarOrders()\n             }\n         }\n \n-        if (isset($this->customer_thread['id_product'])) {\n+        if (!empty($this->customer_thread['id_product'])) {\n             $id_order = isset($this->customer_thread['id_order']) ?\n-                      (int)$this->customer_thread['id_order'] :\n+                      (int) $this->customer_thread['id_order'] :\n                       0;\n \n             $orders[$id_order]['products'][(int)$this->customer_thread['id_product']] = $this->context->controller->objectPresenter->present(\n-                new Product((int)$this->customer_thread['id_product'])\n+                new Product((int) $this->customer_thread['id_product'])\n             );\n         }\n \n@@ -584,7 +585,7 @@ public function sendMessage()\n                 $var_list = [\n                     '{order_name}' => '-',\n                     '{attached_file}' => '-',\n-                    '{message}' => Tools::nl2br(Tools::stripslashes($message)),\n+                    '{message}' => Tools::nl2br(Tools::htmlentitiesUTF8(Tools::stripslashes($message))),\n                     '{email}' =>  $from,\n                     '{product_name}' => '',\n                 ];"
        },
        {
            "index":165,
            "vuln_id":"GHSA-mj63-64x7-57xf",
            "cwe_id":"{'CWE-22'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/49c643bf66620646884ed141c94e5fdd85bcdd2f', 'https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/99bd29e3995c254e2d6f6c2e3454e4271665955a'}",
            "dataset":"osv",
            "summary":"Path traversal in impacket Multiple path traversal vulnerabilities exist in smbserver.py in Impacket before 0.9.23. An attacker that connects to a running smbserver instance can list and write to arbitrary files via ..\/ directory traversal. This could potentially be abused to achieve arbitrary code execution by replacing \/etc\/shadow or an SSH authorized key.",
            "published_date":"2021-06-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/SecureAuthCorp\/impacket",
            "commit_href":"https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/49c643bf66620646884ed141c94e5fdd85bcdd2f",
            "commit_sha":"49c643bf66620646884ed141c94e5fdd85bcdd2f",
            "patch":"MULTI",
            "chain_ord":"['99bd29e3995c254e2d6f6c2e3454e4271665955a', '49c643bf66620646884ed141c94e5fdd85bcdd2f']",
            "before_first_fix_commit":"{'6688da5d97592269aae72b3a00dc1ab186c0b33d', '91902eafb68fea932cf2350cab329f15afa554e5'}",
            "last_fix_commit":"49c643bf66620646884ed141c94e5fdd85bcdd2f",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/03\/2021, 15:43:02",
            "message":"Merge pull request #1066 from omriinbar\/master\n\nFix Path Traversal vulnerabilities by checking path prefix against in\u2026",
            "author":"0xdeaddood",
            "comments":null,
            "stats":"{'additions': 2012, 'deletions': 1937, 'total': 3949}",
            "files":"{'impacket\/smbserver.py': {'additions': 2012, 'deletions': 1937, 'changes': 3949, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/SecureAuthCorp\/impacket\/raw\/49c643bf66620646884ed141c94e5fdd85bcdd2f\/impacket%2Fsmbserver.py', 'patch': None}}",
            "message_norm":"merge pull request #1066 from omriinbar\/master\n\nfix path traversal vulnerabilities by checking path prefix against in\u2026",
            "language":"en",
            "entities":"[('#1066', 'ISSUE', ''), ('path traversal', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['impacket\/smbserver.py'])",
            "num_files":1.0,
            "patch_content":"From 99bd29e3995c254e2d6f6c2e3454e4271665955a Mon Sep 17 00:00:00 2001\nFrom: OmriI <omri.inbar@checkmarx.com>\nDate: Sun, 25 Apr 2021 14:06:02 +0300\nSubject: [PATCH 1\/2] Fix Path Traversal vulnerabilities by checking path\n prefix against incoming filename\n\n---\n impacket\/smbserver.py | 3947 +++++++++++++++++++++--------------------\n 1 file changed, 2011 insertions(+), 1936 deletions(-)\n\ndiff --git a\/impacket\/smbserver.py b\/impacket\/smbserver.py\nindex d51704d126..a10b79fecd 100644\n--- a\/impacket\/smbserver.py\n+++ b\/impacket\/smbserver.py\n@@ -46,7 +46,8 @@\n # For signing\n from impacket import smb, nmb, ntlm, uuid\n from impacket import smb3structs as smb2\n-from impacket.spnego import SPNEGO_NegTokenInit, TypesMech, MechTypes, SPNEGO_NegTokenResp, ASN1_AID, ASN1_SUPPORTED_MECH\n+from impacket.spnego import SPNEGO_NegTokenInit, TypesMech, MechTypes, SPNEGO_NegTokenResp, ASN1_AID, \\\n+    ASN1_SUPPORTED_MECH\n from impacket.nt_errors import STATUS_NO_MORE_FILES, STATUS_NETWORK_NAME_DELETED, STATUS_INVALID_PARAMETER, \\\n     STATUS_FILE_CLOSED, STATUS_MORE_PROCESSING_REQUIRED, STATUS_OBJECT_PATH_NOT_FOUND, STATUS_DIRECTORY_NOT_EMPTY, \\\n     STATUS_FILE_IS_A_DIRECTORY, STATUS_NOT_IMPLEMENTED, STATUS_INVALID_HANDLE, STATUS_OBJECT_NAME_COLLISION, \\\n@@ -61,16 +62,16 @@\n STATUS_SMB_BAD_UID = 0x005B0002\n STATUS_SMB_BAD_TID = 0x00050002\n \n+\n # Utility functions\n-# and general functions. \n-# There are some common functions that can be accessed from more than one SMB \n+# and general functions.\n+# There are some common functions that can be accessed from more than one SMB\n # command (or either TRANSACTION). That's why I'm putting them here\n # TODO: Return NT ERROR Codes\n \n def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage, ntlmChallenge, type1):\n     # Let's calculate the NTLMv2 Response\n \n-\n     responseKeyNT = ntlm.NTOWFv2(identity, '', authenticateMessage['domain_name'].decode('utf-16le'), nthash)\n     responseKeyLM = ntlm.LMOWFv2(identity, '', authenticateMessage['domain_name'].decode('utf-16le'), lmhash)\n \n@@ -103,8 +104,8 @@ def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage\n         responseFlags &= 0xffffffff ^ ntlm.NTLMSSP_NEGOTIATE_ALWAYS_SIGN\n \n     keyExchangeKey = ntlm.KXKEY(ntlmChallenge['flags'], sessionBaseKey, lmChallengeResponse,\n-                           ntlmChallenge['challenge'], '',\n-                           lmhash, nthash, True)\n+                                ntlmChallenge['challenge'], '',\n+                                lmhash, nthash, True)\n \n     # If we set up key exchange, let's fill the right variables\n     if ntlmChallenge['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:\n@@ -124,9 +125,9 @@ def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage\n \n \n def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):\n-# We don't want to add a possible failure here, since this is an\n-# extra bonus. We try, if it fails, returns nothing\n-# ToDo: Document the parameter's types (bytes \/ string) and check all the places where it's called\n+    # We don't want to add a possible failure here, since this is an\n+    # extra bonus. We try, if it fails, returns nothing\n+    # ToDo: Document the parameter's types (bytes \/ string) and check all the places where it's called\n     ret_value = ''\n     if type(challenge) is not bytes:\n         challenge = challenge.decode('latin-1')\n@@ -137,13 +138,13 @@ def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):\n             ret_value = {'hash_string': '%s::%s:%s:%s:%s' % (\n                 username.decode('utf-16le'), domain.decode('utf-16le'), hexlify(challenge).decode('latin-1'),\n                 hexlify(ntresponse).decode('latin-1')[:32],\n-            hexlify(ntresponse).decode()[32:]), 'hash_version': 'ntlmv2'}\n+                hexlify(ntresponse).decode()[32:]), 'hash_version': 'ntlmv2'}\n         else:\n             # NTLMv1\n             ret_value = {'hash_string': '%s::%s:%s:%s:%s' % (\n                 username.decode('utf-16le'), domain.decode('utf-16le'), hexlify(lmresponse).decode('latin-1'),\n                 hexlify(ntresponse).decode('latin-1'),\n-            hexlify(challenge).decode()), 'hash_version': 'ntlm'}\n+                hexlify(challenge).decode()), 'hash_version': 'ntlm'}\n     except:\n         # Let's try w\/o decoding Unicode\n         try:\n@@ -166,6 +167,7 @@ def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):\n \n     return ret_value\n \n+\n def writeJohnOutputToFile(hash_string, hash_version, file_name):\n     fn_data = os.path.splitext(file_name)\n     if hash_version == \"ntlmv2\":\n@@ -173,33 +175,37 @@ def writeJohnOutputToFile(hash_string, hash_version, file_name):\n     else:\n         output_filename = fn_data[0] + \"_ntlm\" + fn_data[1]\n \n-    with open(output_filename,\"a\") as f:\n-            f.write(hash_string)\n-            f.write('\\n')\t\t        \n+    with open(output_filename, \"a\") as f:\n+        f.write(hash_string)\n+        f.write('\\n')\n \n \n-def decodeSMBString( flags, text ):\n+def decodeSMBString(flags, text):\n     if flags & smb.SMB.FLAGS2_UNICODE:\n         return text.decode('utf-16le')\n     else:\n         return text\n \n-def encodeSMBString( flags, text ):\n+\n+def encodeSMBString(flags, text):\n     if flags & smb.SMB.FLAGS2_UNICODE:\n         return (text).encode('utf-16le')\n     else:\n         return text.encode('ascii')\n-    \n+\n+\n def getFileTime(t):\n     t *= 10000000\n     t += 116444736000000000\n     return t\n \n+\n def getUnixTime(t):\n     t -= 116444736000000000\n     t \/\/= 10000000\n     return t\n \n+\n def getSMBDate(t):\n     # TODO: Fix this :P\n     d = datetime.date.fromtimestamp(t)\n@@ -207,35 +213,39 @@ def getSMBDate(t):\n     ret = (year << 8) + (d.month << 4) + d.day\n     return ret\n \n+\n def getSMBTime(t):\n     # TODO: Fix this :P\n     d = datetime.datetime.fromtimestamp(t)\n-    return (d.hour << 8) + (d.minute << 4) + d.second \n+    return (d.hour << 8) + (d.minute << 4) + d.second\n+\n \n def getShares(connId, smbServer):\n     config = smbServer.getServerConfig()\n     sections = config.sections()\n     # Remove the global one\n-    del(sections[sections.index('global')])\n+    del (sections[sections.index('global')])\n     shares = {}\n     for i in sections:\n         shares[i] = dict(config.items(i))\n     return shares\n \n+\n def searchShare(connId, share, smbServer):\n     config = smbServer.getServerConfig()\n     if config.has_section(share):\n-       return dict(config.items(share))\n+        return dict(config.items(share))\n     else:\n-       return None\n+        return None\n+\n \n-def openFile(path,fileName, accessMode, fileAttributes, openMode):\n-    fileName = os.path.normpath(fileName.replace('\\\\','\/'))\n+def openFile(path, fileName, accessMode, fileAttributes, openMode):\n+    fileName = os.path.normpath(fileName.replace('\\\\', '\/'))\n     errorCode = 0\n     if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n-       # strip leading '\/'\n-       fileName = fileName[1:]\n-    pathName = os.path.join(path,fileName)\n+        # strip leading '\/'\n+        fileName = fileName[1:]\n+    pathName = os.path.join(path, fileName)\n     mode = 0\n     # Check the Open Mode\n     if openMode & 0x10:\n@@ -245,61 +255,61 @@ def openFile(path,fileName, accessMode, fileAttributes, openMode):\n         # If file does not exist, return an error\n         if os.path.exists(pathName) is not True:\n             errorCode = STATUS_NO_SUCH_FILE\n-            return 0,mode, pathName, errorCode\n+            return 0, mode, pathName, errorCode\n \n     if os.path.isdir(pathName) and (fileAttributes & smb.ATTR_DIRECTORY) == 0:\n         # Request to open a normal file and this is actually a directory\n-            errorCode = STATUS_FILE_IS_A_DIRECTORY\n-            return 0, mode, pathName, errorCode\n+        errorCode = STATUS_FILE_IS_A_DIRECTORY\n+        return 0, mode, pathName, errorCode\n     # Check the Access Mode\n     if accessMode & 0x7 == 1:\n-       mode |= os.O_WRONLY\n+        mode |= os.O_WRONLY\n     elif accessMode & 0x7 == 2:\n-       mode |= os.O_RDWR\n+        mode |= os.O_RDWR\n     else:\n-       mode = os.O_RDONLY\n+        mode = os.O_RDONLY\n \n     try:\n         if sys.platform == 'win32':\n             mode |= os.O_BINARY\n         fid = os.open(pathName, mode)\n     except Exception as e:\n-        LOG.error(\"openFile: %s,%s\" % (pathName, mode) ,e)\n+        LOG.error(\"openFile: %s,%s\" % (pathName, mode), e)\n         fid = 0\n         errorCode = STATUS_ACCESS_DENIED\n \n     return fid, mode, pathName, errorCode\n \n-def queryFsInformation(path, filename, level=0, pktFlags = smb.SMB.FLAGS2_UNICODE):\n \n+def queryFsInformation(path, filename, level=0, pktFlags=smb.SMB.FLAGS2_UNICODE):\n     if pktFlags & smb.SMB.FLAGS2_UNICODE:\n-         encoding = 'utf-16le'\n+        encoding = 'utf-16le'\n     else:\n-         encoding = 'ascii'\n+        encoding = 'ascii'\n \n-    fileName = os.path.normpath(filename.replace('\\\\','\/'))\n+    fileName = os.path.normpath(filename.replace('\\\\', '\/'))\n     if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n-       # strip leading '\/'\n-       fileName = fileName[1:]\n-    pathName = os.path.join(path,fileName)\n+        # strip leading '\/'\n+        fileName = fileName[1:]\n+    pathName = os.path.join(path, fileName)\n     fileSize = os.path.getsize(pathName)\n     (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n     if level == smb.SMB_QUERY_FS_ATTRIBUTE_INFO or level == smb2.SMB2_FILESYSTEM_ATTRIBUTE_INFO:\n         data = smb.SMBQueryFsAttributeInfo()\n-        data['FileSystemAttributes']      = smb.FILE_CASE_SENSITIVE_SEARCH | smb.FILE_CASE_PRESERVED_NAMES\n+        data['FileSystemAttributes'] = smb.FILE_CASE_SENSITIVE_SEARCH | smb.FILE_CASE_PRESERVED_NAMES\n         data['MaxFilenNameLengthInBytes'] = 255\n-        data['LengthOfFileSystemName']    = len('XTFS')*2\n-        data['FileSystemName']            = 'XTFS'.encode('utf-16le')\n+        data['LengthOfFileSystemName'] = len('XTFS') * 2\n+        data['FileSystemName'] = 'XTFS'.encode('utf-16le')\n         return data.getData()\n     elif level == smb.SMB_INFO_VOLUME:\n-        data = smb.SMBQueryFsInfoVolume( flags = pktFlags )\n-        data['VolumeLabel']               = 'SHARE'.encode(encoding)\n+        data = smb.SMBQueryFsInfoVolume(flags=pktFlags)\n+        data['VolumeLabel'] = 'SHARE'.encode(encoding)\n         return data.getData()\n     elif level == smb.SMB_QUERY_FS_VOLUME_INFO or level == smb2.SMB2_FILESYSTEM_VOLUME_INFO:\n         data = smb.SMBQueryFsVolumeInfo()\n-        data['VolumeLabel']               = ''\n-        data['VolumeCreationTime']        = getFileTime(ctime)\n-        return data.getData() \n+        data['VolumeLabel'] = ''\n+        data['VolumeCreationTime'] = getFileTime(ctime)\n+        return data.getData()\n     elif level == smb.SMB_QUERY_FS_SIZE_INFO:\n         data = smb.SMBQueryFsSizeInfo()\n         return data.getData()\n@@ -319,225 +329,241 @@ def queryFsInformation(path, filename, level=0, pktFlags = smb.SMB.FLAGS2_UNICOD\n         fileAttributes = attribs\n         return fileSize, lastWriteTime, fileAttributes\n \n-def findFirst2(path, fileName, level, searchAttributes, pktFlags = smb.SMB.FLAGS2_UNICODE, isSMB2 = False):\n-     # TODO: Depending on the level, this could be done much simpler\n-     \n-     #print \"FindFirs2 path:%s, filename:%s\" % (path, fileName)\n-     fileName = os.path.normpath(fileName.replace('\\\\','\/'))\n-     # Let's choose the right encoding depending on the request\n-     if pktFlags & smb.SMB.FLAGS2_UNICODE:\n-         encoding = 'utf-16le'\n-     else:\n-         encoding = 'ascii'\n-\n-     if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+\n+def findFirst2(path, fileName, level, searchAttributes, pktFlags=smb.SMB.FLAGS2_UNICODE, isSMB2=False):\n+    # TODO: Depending on the level, this could be done much simpler\n+\n+    # print \"FindFirs2 path:%s, filename:%s\" % (path, fileName)\n+    fileName = os.path.normpath(fileName.replace('\\\\', '\/'))\n+    # Let's choose the right encoding depending on the request\n+    if pktFlags & smb.SMB.FLAGS2_UNICODE:\n+        encoding = 'utf-16le'\n+    else:\n+        encoding = 'ascii'\n+\n+    if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n         # strip leading '\/'\n         fileName = fileName[1:]\n \n-     pathName = os.path.join(path,fileName)\n-     files = []\n-\n-     if pathName.find('*') == -1 and pathName.find('?') == -1:\n-         # No search patterns\n-         pattern = ''\n-     else:\n-         pattern = os.path.basename(pathName)\n-         dirName = os.path.dirname(pathName)\n-\n-     # Always add . and .. Not that important for Windows, but Samba whines if \n-     # not present (for * search only)\n-     if pattern == '*':\n-         files.append(os.path.join(dirName,'.'))\n-         files.append(os.path.join(dirName,'..'))\n-\n-     if pattern != '':\n-         for file in os.listdir(dirName):\n-             if fnmatch.fnmatch(file.lower(),pattern.lower()):\n+    if not isInFileJail(path, fileName):\n+        LOG.error(\"Path not in current working directory\")\n+        return [], 0, STATUS_NOT_SUPPORTED\n+\n+    pathName = os.path.join(path, fileName)\n+    files = []\n+\n+    if pathName.find('*') == -1 and pathName.find('?') == -1:\n+        # No search patterns\n+        pattern = ''\n+    else:\n+        pattern = os.path.basename(pathName)\n+        dirName = os.path.dirname(pathName)\n+\n+    # Always add . and .. Not that important for Windows, but Samba whines if\n+    # not present (for * search only)\n+    if pattern == '*':\n+        files.append(os.path.join(dirName, '.'))\n+        files.append(os.path.join(dirName, '..'))\n+\n+    if pattern != '':\n+        for file in os.listdir(dirName):\n+            if fnmatch.fnmatch(file.lower(), pattern.lower()):\n                 entry = os.path.join(dirName, file)\n                 if os.path.isdir(entry):\n                     if searchAttributes & smb.ATTR_DIRECTORY:\n                         files.append(entry)\n                 else:\n                     files.append(entry)\n-     else:\n-         if os.path.exists(pathName):\n-             files.append(pathName)\n+    else:\n+        if os.path.exists(pathName):\n+            files.append(pathName)\n \n-     searchResult = []\n-     searchCount = len(files)\n-     errorCode = STATUS_SUCCESS\n+    searchResult = []\n+    searchCount = len(files)\n+    errorCode = STATUS_SUCCESS\n \n-     for i in files:\n+    for i in files:\n         if level == smb.SMB_FIND_FILE_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_BOTH_DIRECTORY_INFO:\n-            item = smb.SMBFindFileBothDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileBothDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_DIRECTORY_INFO or level == smb2.SMB2_FILE_DIRECTORY_INFO:\n-            item = smb.SMBFindFileDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_FULL_DIRECTORY_INFO or level == smb2.SMB2_FULL_DIRECTORY_INFO:\n-            item = smb.SMBFindFileFullDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileFullDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_INFO_STANDARD:\n-            item = smb.SMBFindInfoStandard( flags = pktFlags )\n+            item = smb.SMBFindInfoStandard(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_ID_FULL_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_FULL_DIRECTORY_INFO:\n-            item = smb.SMBFindFileIdFullDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileIdFullDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_BOTH_DIRECTORY_INFO:\n-            item = smb.SMBFindFileIdBothDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileIdBothDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_NAMES_INFO or level == smb2.SMB2_FILE_NAMES_INFO:\n-            item = smb.SMBFindFileNamesInfo( flags = pktFlags )\n+            item = smb.SMBFindFileNamesInfo(flags=pktFlags)\n         else:\n             LOG.error(\"Wrong level %d!\" % level)\n-            return  searchResult, searchCount, STATUS_NOT_SUPPORTED\n-            \n+            return searchResult, searchCount, STATUS_NOT_SUPPORTED\n+\n         (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(i)\n         if os.path.isdir(i):\n-           item['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n+            item['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n         else:\n-           item['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n+            item['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n \n         item['FileName'] = os.path.basename(i).encode(encoding)\n \n         if level == smb.SMB_FIND_FILE_BOTH_DIRECTORY_INFO or level == smb.SMB_FIND_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_BOTH_DIRECTORY_INFO:\n-           item['EaSize']            = 0\n-           item['EndOfFile']         = size\n-           item['AllocationSize']    = size\n-           item['CreationTime']      = getFileTime(ctime)\n-           item['LastAccessTime']    = getFileTime(atime)\n-           item['LastWriteTime']     = getFileTime(mtime)\n-           item['LastChangeTime']    = getFileTime(mtime)\n-           item['ShortName']         = '\\x00'*24\n-           item['FileName']          = os.path.basename(i).encode(encoding)\n-           padLen = (8-(len(item) % 8)) % 8\n-           item['NextEntryOffset']   = len(item) + padLen\n+            item['EaSize'] = 0\n+            item['EndOfFile'] = size\n+            item['AllocationSize'] = size\n+            item['CreationTime'] = getFileTime(ctime)\n+            item['LastAccessTime'] = getFileTime(atime)\n+            item['LastWriteTime'] = getFileTime(mtime)\n+            item['LastChangeTime'] = getFileTime(mtime)\n+            item['ShortName'] = '\\x00' * 24\n+            item['FileName'] = os.path.basename(i).encode(encoding)\n+            padLen = (8 - (len(item) % 8)) % 8\n+            item['NextEntryOffset'] = len(item) + padLen\n         elif level == smb.SMB_FIND_FILE_DIRECTORY_INFO:\n-           item['EndOfFile']         = size\n-           item['AllocationSize']    = size\n-           item['CreationTime']      = getFileTime(ctime)\n-           item['LastAccessTime']    = getFileTime(atime)\n-           item['LastWriteTime']     = getFileTime(mtime)\n-           item['LastChangeTime']    = getFileTime(mtime)\n-           item['FileName']          = os.path.basename(i).encode(encoding)\n-           padLen = (8-(len(item) % 8)) % 8\n-           item['NextEntryOffset']   = len(item) + padLen\n+            item['EndOfFile'] = size\n+            item['AllocationSize'] = size\n+            item['CreationTime'] = getFileTime(ctime)\n+            item['LastAccessTime'] = getFileTime(atime)\n+            item['LastWriteTime'] = getFileTime(mtime)\n+            item['LastChangeTime'] = getFileTime(mtime)\n+            item['FileName'] = os.path.basename(i).encode(encoding)\n+            padLen = (8 - (len(item) % 8)) % 8\n+            item['NextEntryOffset'] = len(item) + padLen\n         elif level == smb.SMB_FIND_FILE_FULL_DIRECTORY_INFO or level == smb.SMB_FIND_FILE_ID_FULL_DIRECTORY_INFO or level == smb2.SMB2_FULL_DIRECTORY_INFO:\n-           item['EaSize']            = 0\n-           item['EndOfFile']         = size\n-           item['AllocationSize']    = size\n-           item['CreationTime']      = getFileTime(ctime)\n-           item['LastAccessTime']    = getFileTime(atime)\n-           item['LastWriteTime']     = getFileTime(mtime)\n-           item['LastChangeTime']    = getFileTime(mtime)\n-           padLen = (8-(len(item) % 8)) % 8\n-           item['NextEntryOffset']   = len(item) + padLen\n+            item['EaSize'] = 0\n+            item['EndOfFile'] = size\n+            item['AllocationSize'] = size\n+            item['CreationTime'] = getFileTime(ctime)\n+            item['LastAccessTime'] = getFileTime(atime)\n+            item['LastWriteTime'] = getFileTime(mtime)\n+            item['LastChangeTime'] = getFileTime(mtime)\n+            padLen = (8 - (len(item) % 8)) % 8\n+            item['NextEntryOffset'] = len(item) + padLen\n         elif level == smb.SMB_FIND_INFO_STANDARD:\n-           item['EaSize']            = size\n-           item['CreationDate']      = getSMBDate(ctime)\n-           item['CreationTime']      = getSMBTime(ctime)\n-           item['LastAccessDate']    = getSMBDate(atime)\n-           item['LastAccessTime']    = getSMBTime(atime)\n-           item['LastWriteDate']     = getSMBDate(mtime)\n-           item['LastWriteTime']     = getSMBTime(mtime)\n+            item['EaSize'] = size\n+            item['CreationDate'] = getSMBDate(ctime)\n+            item['CreationTime'] = getSMBTime(ctime)\n+            item['LastAccessDate'] = getSMBDate(atime)\n+            item['LastAccessTime'] = getSMBTime(atime)\n+            item['LastWriteDate'] = getSMBDate(mtime)\n+            item['LastWriteTime'] = getSMBTime(mtime)\n         searchResult.append(item)\n \n-     # No more files\n-     if (level >= smb.SMB_FIND_FILE_DIRECTORY_INFO or isSMB2 is True) and searchCount > 0:\n-         searchResult[-1]['NextEntryOffset'] = 0\n+    # No more files\n+    if (level >= smb.SMB_FIND_FILE_DIRECTORY_INFO or isSMB2 is True) and searchCount > 0:\n+        searchResult[-1]['NextEntryOffset'] = 0\n+\n+    return searchResult, searchCount, errorCode\n \n-     return searchResult, searchCount, errorCode\n \n def queryFileInformation(path, filename, level):\n-    #print \"queryFileInfo path: %s, filename: %s, level:0x%x\" % (path,filename,level)\n-    return queryPathInformation(path,filename, level)\n+    # print \"queryFileInfo path: %s, filename: %s, level:0x%x\" % (path,filename,level)\n+    return queryPathInformation(path, filename, level)\n+\n \n def queryPathInformation(path, filename, level):\n     # TODO: Depending on the level, this could be done much simpler\n-  #print(\"queryPathInfo path: %s, filename: %s, level:0x%x\" % (path,filename,level))\n-  try:\n-    errorCode = 0\n-    fileName = os.path.normpath(filename.replace('\\\\','\/'))\n-    if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\') and path != '':\n-       # strip leading '\/'\n-       fileName = fileName[1:]\n-    pathName = os.path.join(path,fileName)\n-    if os.path.exists(pathName):\n-        (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n-        if level == smb.SMB_QUERY_FILE_BASIC_INFO:\n-            infoRecord = smb.SMBQueryFileBasicInfo()\n-            infoRecord['CreationTime']         = getFileTime(ctime)\n-            infoRecord['LastAccessTime']       = getFileTime(atime)\n-            infoRecord['LastWriteTime']        = getFileTime(mtime)\n-            infoRecord['LastChangeTime']       = getFileTime(mtime)\n-            if os.path.isdir(pathName):\n-               infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n-            else:\n-               infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n-        elif level == smb.SMB_QUERY_FILE_STANDARD_INFO:\n-            infoRecord = smb.SMBQueryFileStandardInfo()\n-            infoRecord['AllocationSize']       = size\n-            infoRecord['EndOfFile']            = size\n-            if os.path.isdir(pathName):\n-               infoRecord['Directory']         = 1\n-            else:\n-               infoRecord['Directory']         = 0\n-        elif level == smb.SMB_QUERY_FILE_ALL_INFO or level == smb2.SMB2_FILE_ALL_INFO:\n-            infoRecord = smb.SMBQueryFileAllInfo()\n-            infoRecord['CreationTime']         = getFileTime(ctime)\n-            infoRecord['LastAccessTime']       = getFileTime(atime)\n-            infoRecord['LastWriteTime']        = getFileTime(mtime)\n-            infoRecord['LastChangeTime']       = getFileTime(mtime)\n-            if os.path.isdir(pathName):\n-               infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n-            else:\n-               infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n-            infoRecord['AllocationSize']       = size\n-            infoRecord['EndOfFile']            = size\n-            if os.path.isdir(pathName):\n-               infoRecord['Directory']         = 1\n-            else:\n-               infoRecord['Directory']         = 0\n-            infoRecord['FileName']             = filename.encode('utf-16le')\n-        elif level == smb2.SMB2_FILE_NETWORK_OPEN_INFO:\n-            infoRecord = smb.SMBFileNetworkOpenInfo()\n-            infoRecord['CreationTime']         = getFileTime(ctime)\n-            infoRecord['LastAccessTime']       = getFileTime(atime)\n-            infoRecord['LastWriteTime']        = getFileTime(mtime)\n-            infoRecord['ChangeTime']           = getFileTime(mtime)\n-            infoRecord['AllocationSize']       = size\n-            infoRecord['EndOfFile']            = size\n-            if os.path.isdir(pathName):\n-               infoRecord['FileAttributes'] = smb.ATTR_DIRECTORY\n+    # print(\"queryPathInfo path: %s, filename: %s, level:0x%x\" % (path,filename,level))\n+    try:\n+        errorCode = 0\n+        fileName = os.path.normpath(filename.replace('\\\\', '\/'))\n+        if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\') and path != '':\n+            # strip leading '\/'\n+            fileName = fileName[1:]\n+        pathName = os.path.join(path, fileName)\n+        if os.path.exists(pathName):\n+            (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n+            if level == smb.SMB_QUERY_FILE_BASIC_INFO:\n+                infoRecord = smb.SMBQueryFileBasicInfo()\n+                infoRecord['CreationTime'] = getFileTime(ctime)\n+                infoRecord['LastAccessTime'] = getFileTime(atime)\n+                infoRecord['LastWriteTime'] = getFileTime(mtime)\n+                infoRecord['LastChangeTime'] = getFileTime(mtime)\n+                if os.path.isdir(pathName):\n+                    infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n+                else:\n+                    infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n+            elif level == smb.SMB_QUERY_FILE_STANDARD_INFO:\n+                infoRecord = smb.SMBQueryFileStandardInfo()\n+                infoRecord['AllocationSize'] = size\n+                infoRecord['EndOfFile'] = size\n+                if os.path.isdir(pathName):\n+                    infoRecord['Directory'] = 1\n+                else:\n+                    infoRecord['Directory'] = 0\n+            elif level == smb.SMB_QUERY_FILE_ALL_INFO or level == smb2.SMB2_FILE_ALL_INFO:\n+                infoRecord = smb.SMBQueryFileAllInfo()\n+                infoRecord['CreationTime'] = getFileTime(ctime)\n+                infoRecord['LastAccessTime'] = getFileTime(atime)\n+                infoRecord['LastWriteTime'] = getFileTime(mtime)\n+                infoRecord['LastChangeTime'] = getFileTime(mtime)\n+                if os.path.isdir(pathName):\n+                    infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n+                else:\n+                    infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n+                infoRecord['AllocationSize'] = size\n+                infoRecord['EndOfFile'] = size\n+                if os.path.isdir(pathName):\n+                    infoRecord['Directory'] = 1\n+                else:\n+                    infoRecord['Directory'] = 0\n+                infoRecord['FileName'] = filename.encode('utf-16le')\n+            elif level == smb2.SMB2_FILE_NETWORK_OPEN_INFO:\n+                infoRecord = smb.SMBFileNetworkOpenInfo()\n+                infoRecord['CreationTime'] = getFileTime(ctime)\n+                infoRecord['LastAccessTime'] = getFileTime(atime)\n+                infoRecord['LastWriteTime'] = getFileTime(mtime)\n+                infoRecord['ChangeTime'] = getFileTime(mtime)\n+                infoRecord['AllocationSize'] = size\n+                infoRecord['EndOfFile'] = size\n+                if os.path.isdir(pathName):\n+                    infoRecord['FileAttributes'] = smb.ATTR_DIRECTORY\n+                else:\n+                    infoRecord['FileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n+            elif level == smb.SMB_QUERY_FILE_EA_INFO or level == smb2.SMB2_FILE_EA_INFO:\n+                infoRecord = smb.SMBQueryFileEaInfo()\n+            elif level == smb2.SMB2_FILE_STREAM_INFO:\n+                infoRecord = smb.SMBFileStreamInformation()\n             else:\n-               infoRecord['FileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n-        elif level == smb.SMB_QUERY_FILE_EA_INFO or level == smb2.SMB2_FILE_EA_INFO: \n-            infoRecord = smb.SMBQueryFileEaInfo()\n-        elif level == smb2.SMB2_FILE_STREAM_INFO:\n-            infoRecord = smb.SMBFileStreamInformation()\n+                LOG.error('Unknown level for query path info! 0x%x' % level)\n+                # UNSUPPORTED\n+                return None, STATUS_NOT_SUPPORTED\n+\n+            return infoRecord, errorCode\n         else:\n-            LOG.error('Unknown level for query path info! 0x%x' % level)\n-            # UNSUPPORTED\n-            return None, STATUS_NOT_SUPPORTED\n+            # NOT FOUND\n+            return None, STATUS_OBJECT_NAME_NOT_FOUND\n+    except Exception as e:\n+        LOG.error('queryPathInfo: %s' % e)\n+        raise\n \n-        return infoRecord, errorCode\n-    else:\n-        # NOT FOUND\n-        return None, STATUS_OBJECT_NAME_NOT_FOUND\n-  except Exception as e:\n-      LOG.error('queryPathInfo: %s' % e)\n-      raise\n \n def queryDiskInformation(path):\n-# TODO: Do something useful here :)\n-# For now we just return fake values\n-   totalUnits = 65535\n-   freeUnits = 65535\n-   return totalUnits, freeUnits\n+    # TODO: Do something useful here :)\n+    # For now we just return fake values\n+    totalUnits = 65535\n+    freeUnits = 65535\n+    return totalUnits, freeUnits\n+\n+\n+def isInFileJail(path, fileName):\n+    pathName = os.path.join(path, fileName)\n+    share_real_path = os.path.realpath(path)\n+    return os.path.commonprefix((os.path.realpath(pathName), share_real_path)) == share_real_path\n+\n \n # Here we implement the NT transaction handlers\n class NTTRANSCommands:\n-    def default(self, connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def default(self, connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         pass\n \n+\n # Here we implement the NT transaction handlers\n class TRANSCommands:\n     @staticmethod\n-    def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         # Minimal [MS-RAP] implementation, just to return the shares\n         connData = smbServer.getConnectionData(connId)\n \n@@ -545,20 +571,20 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n         respParameters = b''\n         respData = b''\n         errorCode = STATUS_SUCCESS\n-        if struct.unpack('<H',parameters[:2])[0] == 0:\n+        if struct.unpack('<H', parameters[:2])[0] == 0:\n             # NetShareEnum Request\n             netShareEnum = smb.SMBNetShareEnum(parameters)\n             if netShareEnum['InfoLevel'] == 1:\n                 shares = getShares(connId, smbServer)\n                 respParameters = smb.SMBNetShareEnumResponse()\n-                respParameters['EntriesReturned']  = len(shares)\n+                respParameters['EntriesReturned'] = len(shares)\n                 respParameters['EntriesAvailable'] = len(shares)\n                 tailData = ''\n                 for i in shares:\n                     # NetShareInfo1 len == 20\n                     entry = smb.NetShareInfo1()\n-                    entry['NetworkName'] = i + '\\x00'*(13-len(i))\n-                    entry['Type']        = int(shares[i]['share type'])\n+                    entry['NetworkName'] = i + '\\x00' * (13 - len(i))\n+                    entry['Type'] = int(shares[i]['share type'])\n                     # (beto) If offset == 0 it crashes explorer.exe on windows 7\n                     entry['RemarkOffsetLow'] = 20 * len(shares) + len(tailData)\n                     respData += entry.getData()\n@@ -570,28 +596,28 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n             else:\n                 # We don't support other info levels\n                 errorCode = STATUS_NOT_SUPPORTED\n-        elif struct.unpack('<H',parameters[:2])[0] == 13:\n+        elif struct.unpack('<H', parameters[:2])[0] == 13:\n             # NetrServerGetInfo Request\n             respParameters = smb.SMBNetServerGetInfoResponse()\n             netServerInfo = smb.SMBNetServerInfo1()\n             netServerInfo['ServerName'] = smbServer.getServerName()\n             respData = netServerInfo.getData()\n             respParameters['TotalBytesAvailable'] = len(respData)\n-        elif struct.unpack('<H',parameters[:2])[0] == 1:\n+        elif struct.unpack('<H', parameters[:2])[0] == 1:\n             # NetrShareGetInfo Request\n             request = smb.SMBNetShareGetInfo(parameters)\n             respParameters = smb.SMBNetShareGetInfoResponse()\n             shares = getShares(connId, smbServer)\n             share = shares[request['ShareName'].upper()]\n-            shareInfo = smb.NetShareInfo1() \n+            shareInfo = smb.NetShareInfo1()\n             shareInfo['NetworkName'] = request['ShareName'].upper() + '\\x00'\n-            shareInfo['Type']        = int(share['share type'])\n+            shareInfo['Type'] = int(share['share type'])\n             respData = shareInfo.getData()\n             if 'comment' in share:\n                 shareInfo['RemarkOffsetLow'] = len(respData)\n                 respData += share['comment'] + '\\x00'\n             respParameters['TotalBytesAvailable'] = len(respData)\n-     \n+\n         else:\n             # We don't know how to handle anything else\n             errorCode = STATUS_NOT_SUPPORTED\n@@ -601,15 +627,15 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n         return respSetup, respParameters, respData, errorCode\n \n     @staticmethod\n-    def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n         respParameters = b''\n         respData = b''\n         errorCode = STATUS_SUCCESS\n-        SMBCommand  = smb.SMBCommand(recvPacket['Data'][0])\n-        transParameters= smb.SMBTransaction_Parameters(SMBCommand['Parameters'])\n+        SMBCommand = smb.SMBCommand(recvPacket['Data'][0])\n+        transParameters = smb.SMBTransaction_Parameters(SMBCommand['Parameters'])\n \n         # Extract the FID\n         fid = struct.unpack('<H', transParameters['Setup'][2:])[0]\n@@ -617,8 +643,8 @@ def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCo\n         if fid in connData['OpenedFiles']:\n             fileHandle = connData['OpenedFiles'][fid]['FileHandle']\n             if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                os.write(fileHandle,data)\n-                respData = os.read(fileHandle,data)\n+                os.write(fileHandle, data)\n+                respData = os.read(fileHandle, data)\n             else:\n                 sock = connData['OpenedFiles'][fid]['Socket']\n                 sock.send(data)\n@@ -630,26 +656,27 @@ def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCo\n \n         return respSetup, respParameters, respData, errorCode\n \n+\n # Here we implement the transaction2 handlers\n class TRANS2Commands:\n     # All these commands return setup, parameters, data, errorCode\n     @staticmethod\n-    def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n         respParameters = b''\n         respData = b''\n         errorCode = STATUS_SUCCESS\n-        setPathInfoParameters = smb.SMBSetPathInformation_Parameters(flags = recvPacket['Flags2'], data = parameters)\n+        setPathInfoParameters = smb.SMBSetPathInformation_Parameters(flags=recvPacket['Flags2'], data=parameters)\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-            path     = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n             fileName = decodeSMBString(recvPacket['Flags2'], setPathInfoParameters['FileName'])\n-            fileName = os.path.normpath(fileName.replace('\\\\','\/'))\n+            fileName = os.path.normpath(fileName.replace('\\\\', '\/'))\n             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\') and path != '':\n-               # strip leading '\/'\n-               fileName = fileName[1:]\n-            pathName = os.path.join(path,fileName)\n+                # strip leading '\/'\n+                fileName = fileName[1:]\n+            pathName = os.path.join(path, fileName)\n             if os.path.exists(pathName):\n                 informationLevel = setPathInfoParameters['InformationLevel']\n                 if informationLevel == smb.SMB_SET_FILE_BASIC_INFO:\n@@ -666,11 +693,12 @@ def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n                     else:\n                         mtime = getUnixTime(mtime)\n                     if mtime != -1 or atime != -1:\n-                        os.utime(pathName,(atime,mtime))\n+                        os.utime(pathName, (atime, mtime))\n                 else:\n-                    smbServer.log('Unknown level for set path info! 0x%x' % setPathInfoParameters['InformationLevel'], logging.ERROR)\n+                    smbServer.log('Unknown level for set path info! 0x%x' % setPathInfoParameters['InformationLevel'],\n+                                  logging.ERROR)\n                     # UNSUPPORTED\n-                    errorCode =  STATUS_NOT_SUPPORTED\n+                    errorCode = STATUS_NOT_SUPPORTED\n             else:\n                 errorCode = STATUS_OBJECT_NAME_NOT_FOUND\n \n@@ -684,9 +712,8 @@ def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n \n         return respSetup, respParameters, respData, errorCode\n \n-\n     @staticmethod\n-    def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n@@ -702,9 +729,9 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n                 if informationLevel == smb.SMB_SET_FILE_DISPOSITION_INFO:\n                     infoRecord = smb.SMBSetFileDispositionInfo(parameters)\n                     if infoRecord['DeletePending'] > 0:\n-                       # Mark this file for removal after closed\n-                       connData['OpenedFiles'][setFileInfoParameters['FID']]['DeleteOnClose'] = True\n-                       respParameters = smb.SMBSetFileInformationResponse_Parameters()\n+                        # Mark this file for removal after closed\n+                        connData['OpenedFiles'][setFileInfoParameters['FID']]['DeleteOnClose'] = True\n+                        respParameters = smb.SMBSetFileInformationResponse_Parameters()\n                 elif informationLevel == smb.SMB_SET_FILE_BASIC_INFO:\n                     infoRecord = smb.SMBSetFileBasicInfo(data)\n                     # Creation time won't be set,  the other ones we play with.\n@@ -718,17 +745,18 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n                         mtime = -1\n                     else:\n                         mtime = getUnixTime(mtime)\n-                    os.utime(fileName,(atime,mtime))\n+                    os.utime(fileName, (atime, mtime))\n                 elif informationLevel == smb.SMB_SET_FILE_END_OF_FILE_INFO:\n                     fileHandle = connData['OpenedFiles'][setFileInfoParameters['FID']]['FileHandle']\n                     infoRecord = smb.SMBSetFileEndOfFileInfo(data)\n                     if infoRecord['EndOfFile'] > 0:\n-                        os.lseek(fileHandle, infoRecord['EndOfFile']-1, 0)\n+                        os.lseek(fileHandle, infoRecord['EndOfFile'] - 1, 0)\n                         os.write(fileHandle, b'\\x00')\n                 else:\n-                    smbServer.log('Unknown level for set file info! 0x%x' % setFileInfoParameters['InformationLevel'], logging.ERROR)\n+                    smbServer.log('Unknown level for set file info! 0x%x' % setFileInfoParameters['InformationLevel'],\n+                                  logging.ERROR)\n                     # UNSUPPORTED\n-                    errorCode =  STATUS_NOT_SUPPORTED\n+                    errorCode = STATUS_NOT_SUPPORTED\n             else:\n                 errorCode = STATUS_NO_SUCH_FILE\n \n@@ -742,7 +770,7 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n         return respSetup, respParameters, respData, errorCode\n \n     @staticmethod\n-    def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n@@ -770,7 +798,7 @@ def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDat\n         return respSetup, respParameters, respData, errorCode\n \n     @staticmethod\n-    def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n@@ -778,7 +806,7 @@ def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDat\n         respData = b''\n         errorCode = 0\n \n-        queryPathInfoParameters = smb.SMBQueryPathInformation_Parameters(flags = recvPacket['Flags2'], data = parameters)\n+        queryPathInfoParameters = smb.SMBQueryPathInformation_Parameters(flags=recvPacket['Flags2'], data=parameters)\n \n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n@@ -787,30 +815,30 @@ def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDat\n                                                                                    queryPathInfoParameters['FileName']),\n                                                              queryPathInfoParameters['InformationLevel'])\n             except Exception as e:\n-               smbServer.log(\"queryPathInformation: %s\" % e,logging.ERROR)\n+                smbServer.log(\"queryPathInformation: %s\" % e, logging.ERROR)\n \n             if infoRecord is not None:\n                 respParameters = smb.SMBQueryPathInformationResponse_Parameters()\n                 respData = infoRecord\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n-           \n+\n         smbServer.setConnectionData(connId, connData)\n \n         return respSetup, respParameters, respData, errorCode\n \n     @staticmethod\n-    def queryFsInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def queryFsInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n         errorCode = 0\n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             data = queryFsInformation(connData['ConnectedShares'][recvPacket['Tid']]['path'], '',\n-                                      struct.unpack('<H',parameters)[0], pktFlags = recvPacket['Flags2'])\n+                                      struct.unpack('<H', parameters)[0], pktFlags=recvPacket['Flags2'])\n \n         smbServer.setConnectionData(connId, connData)\n \n-        return b'',b'', data, errorCode\n+        return b'', b'', data, errorCode\n \n     @staticmethod\n     def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):\n@@ -820,7 +848,7 @@ def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):\n         respParameters = b''\n         respData = b''\n         errorCode = STATUS_SUCCESS\n-        findNext2Parameters = smb.SMBFindNext2_Parameters(flags = recvPacket['Flags2'], data = parameters)\n+        findNext2Parameters = smb.SMBFindNext2_Parameters(flags=recvPacket['Flags2'], data=parameters)\n \n         sid = findNext2Parameters['SID']\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n@@ -833,28 +861,28 @@ def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):\n                 for i in enumerate(searchResult):\n                     data = i[1].getData()\n                     lenData = len(data)\n-                    if (totalData+lenData) >= maxDataCount or (i[0]+1) >= findNext2Parameters['SearchCount']:\n+                    if (totalData + lenData) >= maxDataCount or (i[0] + 1) >= findNext2Parameters['SearchCount']:\n                         # We gotta stop here and continue on a find_next2\n                         endOfSearch = 0\n                         connData['SIDs'][sid] = searchResult[i[0]:]\n                         respParameters['LastNameOffset'] = totalData\n                         break\n                     else:\n-                        searchCount +=1\n+                        searchCount += 1\n                         respData += data\n                         totalData += lenData\n-                    \n+\n                 # Have we reached the end of the search or still stuff to send?\n                 if endOfSearch > 0:\n                     # Let's remove the SID from our ConnData\n-                    del(connData['SIDs'][sid])\n+                    del (connData['SIDs'][sid])\n \n                 respParameters['EndOfSearch'] = endOfSearch\n                 respParameters['SearchCount'] = searchCount\n-            else: \n+            else:\n                 errorCode = STATUS_INVALID_HANDLE\n         else:\n-            errorCode = STATUS_SMB_BAD_TID   \n+            errorCode = STATUS_SMB_BAD_TID\n \n         smbServer.setConnectionData(connId, connData)\n \n@@ -867,55 +895,58 @@ def findFirst2(connId, smbServer, recvPacket, parameters, data, maxDataCount):\n         respSetup = b''\n         respParameters = b''\n         respData = b''\n-        findFirst2Parameters = smb.SMBFindFirst2_Parameters( recvPacket['Flags2'], data = parameters)\n+        findFirst2Parameters = smb.SMBFindFirst2_Parameters(recvPacket['Flags2'], data=parameters)\n \n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n \n-            searchResult, searchCount, errorCode = findFirst2(path, \n-                          decodeSMBString( recvPacket['Flags2'], findFirst2Parameters['FileName'] ), \n-                          findFirst2Parameters['InformationLevel'], \n-                          findFirst2Parameters['SearchAttributes'] , pktFlags = recvPacket['Flags2'])\n+            searchResult, searchCount, errorCode = findFirst2(path,\n+                                                              decodeSMBString(recvPacket['Flags2'],\n+                                                                              findFirst2Parameters['FileName']),\n+                                                              findFirst2Parameters['InformationLevel'],\n+                                                              findFirst2Parameters['SearchAttributes'],\n+                                                              pktFlags=recvPacket['Flags2'])\n \n             respParameters = smb.SMBFindFirst2Response_Parameters()\n             endOfSearch = 1\n-            sid = 0x80 # default SID\n+            sid = 0x80  # default SID\n             searchCount = 0\n             totalData = 0\n             for i in enumerate(searchResult):\n-                #i[1].dump()\n+                # i[1].dump()\n                 data = i[1].getData()\n                 lenData = len(data)\n-                if (totalData+lenData) >= maxDataCount or (i[0]+1) > findFirst2Parameters['SearchCount']:\n+                if (totalData + lenData) >= maxDataCount or (i[0] + 1) > findFirst2Parameters['SearchCount']:\n                     # We gotta stop here and continue on a find_next2\n                     endOfSearch = 0\n                     # Simple way to generate a fid\n                     if len(connData['SIDs']) == 0:\n-                       sid = 1\n+                        sid = 1\n                     else:\n-                       sid = list(connData['SIDs'].keys())[-1] + 1\n+                        sid = list(connData['SIDs'].keys())[-1] + 1\n                     # Store the remaining search results in the ConnData SID\n                     connData['SIDs'][sid] = searchResult[i[0]:]\n                     respParameters['LastNameOffset'] = totalData\n                     break\n                 else:\n-                    searchCount +=1\n+                    searchCount += 1\n                     respData += data\n \n-                    padLen = (8-(lenData % 8)) %8\n-                    respData += b'\\xaa'*padLen\n+                    padLen = (8 - (lenData % 8)) % 8\n+                    respData += b'\\xaa' * padLen\n                     totalData += lenData + padLen\n \n             respParameters['SID'] = sid\n             respParameters['EndOfSearch'] = endOfSearch\n             respParameters['SearchCount'] = searchCount\n         else:\n-            errorCode = STATUS_SMB_BAD_TID   \n+            errorCode = STATUS_SMB_BAD_TID\n \n         smbServer.setConnectionData(connId, connData)\n \n         return respSetup, respParameters, respData, errorCode\n \n+\n # Here we implement the commands handlers\n class SMBCommands:\n \n@@ -925,16 +956,16 @@ def smbTransaction(connId, smbServer, SMBCommand, recvPacket, transCommands):\n \n         respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n \n-        transParameters= smb.SMBTransaction_Parameters(SMBCommand['Parameters'])\n+        transParameters = smb.SMBTransaction_Parameters(SMBCommand['Parameters'])\n \n         # Do the stuff\n         if transParameters['ParameterCount'] != transParameters['TotalParameterCount']:\n-            # TODO: Handle partial parameters \n+            # TODO: Handle partial parameters\n             raise Exception(\"Unsupported partial parameters in TRANSACT2!\")\n         else:\n-            transData = smb.SMBTransaction_SData(flags = recvPacket['Flags2'])\n-            # Standard says servers shouldn't trust Parameters and Data comes \n-            # in order, so we have to parse the offsets, ugly   \n+            transData = smb.SMBTransaction_SData(flags=recvPacket['Flags2'])\n+            # Standard says servers shouldn't trust Parameters and Data comes\n+            # in order, so we have to parse the offsets, ugly\n \n             paramCount = transParameters['ParameterCount']\n             transData['Trans_ParametersLength'] = paramCount\n@@ -943,142 +974,141 @@ def smbTransaction(connId, smbServer, SMBCommand, recvPacket, transCommands):\n             transData.fromString(SMBCommand['Data'])\n             if transParameters['ParameterOffset'] > 0:\n                 paramOffset = transParameters['ParameterOffset'] - 63 - transParameters['SetupLength']\n-                transData['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]\n+                transData['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]\n             else:\n                 transData['Trans_Parameters'] = b''\n \n             if transParameters['DataOffset'] > 0:\n                 dataOffset = transParameters['DataOffset'] - 63 - transParameters['SetupLength']\n                 transData['Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]\n-            else: \n+            else:\n                 transData['Trans_Data'] = b''\n-            \n+\n             # Call the handler for this TRANSACTION\n             if transParameters['SetupCount'] == 0:\n                 # No subcommand, let's play with the Name\n-                command = decodeSMBString(recvPacket['Flags2'],transData['Name'])\n+                command = decodeSMBString(recvPacket['Flags2'], transData['Name'])\n             else:\n                 command = struct.unpack('<H', transParameters['Setup'][:2])[0]\n-            \n+\n             if command in transCommands:\n-               # Call the TRANS subcommand\n-               setup = b''\n-               parameters = b''\n-               data = b''\n-               try: \n-                   setup, parameters, data, errorCode = transCommands[command](connId,\n-                                smbServer, \n-                                recvPacket, \n-                                transData['Trans_Parameters'], \n-                                transData['Trans_Data'],\n-                                transParameters['MaxDataCount'])\n-               except Exception as e:\n-                   #print 'Transaction: %s' % e,e\n-                   smbServer.log('Transaction: (%r,%s)' % (command, e), logging.ERROR)\n-                   errorCode = STATUS_ACCESS_DENIED\n-                   #raise\n-\n-               if setup == b'' and parameters == b'' and data == b'':\n-                   # Something wen't wrong\n-                   respParameters = b''\n-                   respData = b''\n-               else:\n-                   # Build the answer\n-                   if hasattr(data, 'getData'):\n-                       data = data.getData()\n-                   remainingData = len(data)\n-                   if hasattr(parameters, 'getData'):\n-                       parameters = parameters.getData()\n-                   remainingParameters = len(parameters)\n-                   commands = []\n-                   dataDisplacement = 0\n-                   while remainingData > 0 or remainingParameters > 0: \n-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n-                       respParameters = smb.SMBTransactionResponse_Parameters()\n-                       respData       = smb.SMBTransaction2Response_Data()\n-\n-                       respParameters['TotalParameterCount'] = len(parameters)\n-                       respParameters['ParameterCount']      = len(parameters)\n-                       respData['Trans_ParametersLength']    = len(parameters)\n-                       respParameters['TotalDataCount']      = len(data)\n-                       respParameters['DataDisplacement']    = dataDisplacement\n-\n-                       # TODO: Do the same for parameters\n-                       if len(data) >  transParameters['MaxDataCount']:\n-                           # Answer doesn't fit in this packet\n-                           LOG.debug(\"Lowering answer from %d to %d\" % (len(data),transParameters['MaxDataCount']) )\n-                           respParameters['DataCount'] = transParameters['MaxDataCount']\n-                       else:\n-                           respParameters['DataCount'] = len(data)\n-\n-                       respData['Trans_DataLength']          = respParameters['DataCount']\n-                       respParameters['SetupCount']          = len(setup)\n-                       respParameters['Setup']               = setup\n-                       # TODO: Make sure we're calculating the pad right\n-                       if len(parameters) > 0:\n-                           #padLen = 4 - (55 + len(setup)) % 4 \n-                           padLen = (4 - (55 + len(setup)) % 4 ) % 4\n-                           padBytes = b'\\xFF' * padLen\n-                           respData['Pad1'] = padBytes\n-                           respParameters['ParameterOffset'] = 55 + len(setup) + padLen \n-                       else:\n-                           padLen = 0\n-                           respParameters['ParameterOffset'] = 0\n-                           respData['Pad1']                  = b''\n-\n-                       if len(data) > 0:\n-                           #pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4\n-                           pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4\n-                           respData['Pad2'] = b'\\xFF' * pad2Len\n-                           respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len\n-                       else:\n-                           respParameters['DataOffset'] = 0\n-                           respData['Pad2']             = b''\n-\n-                       respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n-                       respData['Trans_Data']       = data[:respParameters['DataCount']] \n-                       respSMBCommand['Parameters'] = respParameters\n-                       respSMBCommand['Data']       = respData \n-\n-                       data = data[respParameters['DataCount']:]\n-                       remainingData -= respParameters['DataCount']\n-                       dataDisplacement += respParameters['DataCount'] + 1\n-\n-                       parameters = parameters[respParameters['ParameterCount']:]\n-                       remainingParameters -= respParameters['ParameterCount']\n-                       commands.append(respSMBCommand)\n-\n-                   smbServer.setConnectionData(connId, connData)\n-                   return commands, None, errorCode\n+                # Call the TRANS subcommand\n+                setup = b''\n+                parameters = b''\n+                data = b''\n+                try:\n+                    setup, parameters, data, errorCode = transCommands[command](connId,\n+                                                                                smbServer,\n+                                                                                recvPacket,\n+                                                                                transData['Trans_Parameters'],\n+                                                                                transData['Trans_Data'],\n+                                                                                transParameters['MaxDataCount'])\n+                except Exception as e:\n+                    # print 'Transaction: %s' % e,e\n+                    smbServer.log('Transaction: (%r,%s)' % (command, e), logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n+                    # raise\n+\n+                if setup == b'' and parameters == b'' and data == b'':\n+                    # Something wen't wrong\n+                    respParameters = b''\n+                    respData = b''\n+                else:\n+                    # Build the answer\n+                    if hasattr(data, 'getData'):\n+                        data = data.getData()\n+                    remainingData = len(data)\n+                    if hasattr(parameters, 'getData'):\n+                        parameters = parameters.getData()\n+                    remainingParameters = len(parameters)\n+                    commands = []\n+                    dataDisplacement = 0\n+                    while remainingData > 0 or remainingParameters > 0:\n+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n+                        respParameters = smb.SMBTransactionResponse_Parameters()\n+                        respData = smb.SMBTransaction2Response_Data()\n+\n+                        respParameters['TotalParameterCount'] = len(parameters)\n+                        respParameters['ParameterCount'] = len(parameters)\n+                        respData['Trans_ParametersLength'] = len(parameters)\n+                        respParameters['TotalDataCount'] = len(data)\n+                        respParameters['DataDisplacement'] = dataDisplacement\n+\n+                        # TODO: Do the same for parameters\n+                        if len(data) > transParameters['MaxDataCount']:\n+                            # Answer doesn't fit in this packet\n+                            LOG.debug(\"Lowering answer from %d to %d\" % (len(data), transParameters['MaxDataCount']))\n+                            respParameters['DataCount'] = transParameters['MaxDataCount']\n+                        else:\n+                            respParameters['DataCount'] = len(data)\n+\n+                        respData['Trans_DataLength'] = respParameters['DataCount']\n+                        respParameters['SetupCount'] = len(setup)\n+                        respParameters['Setup'] = setup\n+                        # TODO: Make sure we're calculating the pad right\n+                        if len(parameters) > 0:\n+                            # padLen = 4 - (55 + len(setup)) % 4\n+                            padLen = (4 - (55 + len(setup)) % 4) % 4\n+                            padBytes = b'\\xFF' * padLen\n+                            respData['Pad1'] = padBytes\n+                            respParameters['ParameterOffset'] = 55 + len(setup) + padLen\n+                        else:\n+                            padLen = 0\n+                            respParameters['ParameterOffset'] = 0\n+                            respData['Pad1'] = b''\n+\n+                        if len(data) > 0:\n+                            # pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4\n+                            pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4\n+                            respData['Pad2'] = b'\\xFF' * pad2Len\n+                            respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len\n+                        else:\n+                            respParameters['DataOffset'] = 0\n+                            respData['Pad2'] = b''\n+\n+                        respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n+                        respData['Trans_Data'] = data[:respParameters['DataCount']]\n+                        respSMBCommand['Parameters'] = respParameters\n+                        respSMBCommand['Data'] = respData\n+\n+                        data = data[respParameters['DataCount']:]\n+                        remainingData -= respParameters['DataCount']\n+                        dataDisplacement += respParameters['DataCount'] + 1\n+\n+                        parameters = parameters[respParameters['ParameterCount']:]\n+                        remainingParameters -= respParameters['ParameterCount']\n+                        commands.append(respSMBCommand)\n+\n+                    smbServer.setConnectionData(connId, connData)\n+                    return commands, None, errorCode\n \n             else:\n-               smbServer.log(\"Unsupported Transact command %r\" % command, logging.ERROR)\n-               respParameters = b''\n-               respData = b''\n-               errorCode = STATUS_NOT_IMPLEMENTED\n+                smbServer.log(\"Unsupported Transact command %r\" % command, logging.ERROR)\n+                respParameters = b''\n+                respData = b''\n+                errorCode = STATUS_NOT_IMPLEMENTED\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smbNTTransact(connId, smbServer, SMBCommand, recvPacket, transCommands):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n \n-        NTTransParameters= smb.SMBNTTransaction_Parameters(SMBCommand['Parameters'])\n+        NTTransParameters = smb.SMBNTTransaction_Parameters(SMBCommand['Parameters'])\n         # Do the stuff\n         if NTTransParameters['ParameterCount'] != NTTransParameters['TotalParameterCount']:\n-            # TODO: Handle partial parameters \n+            # TODO: Handle partial parameters\n             raise Exception(\"Unsupported partial parameters in NTTrans!\")\n         else:\n             NTTransData = smb.SMBNTTransaction_Data()\n-            # Standard says servers shouldn't trust Parameters and Data comes \n-            # in order, so we have to parse the offsets, ugly   \n+            # Standard says servers shouldn't trust Parameters and Data comes\n+            # in order, so we have to parse the offsets, ugly\n \n             paramCount = NTTransParameters['ParameterCount']\n             NTTransData['NT_Trans_ParametersLength'] = paramCount\n@@ -1087,139 +1117,138 @@ def smbNTTransact(connId, smbServer, SMBCommand, recvPacket, transCommands):\n \n             if NTTransParameters['ParameterOffset'] > 0:\n                 paramOffset = NTTransParameters['ParameterOffset'] - 73 - NTTransParameters['SetupLength']\n-                NTTransData['NT_Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]\n+                NTTransData['NT_Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]\n             else:\n                 NTTransData['NT_Trans_Parameters'] = b''\n \n             if NTTransParameters['DataOffset'] > 0:\n                 dataOffset = NTTransParameters['DataOffset'] - 73 - NTTransParameters['SetupLength']\n                 NTTransData['NT_Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]\n-            else: \n+            else:\n                 NTTransData['NT_Trans_Data'] = b''\n \n             # Call the handler for this TRANSACTION\n             command = NTTransParameters['Function']\n             if command in transCommands:\n-               # Call the NT TRANS subcommand\n-               setup = b''\n-               parameters = b''\n-               data = b''\n-               try: \n-                   setup, parameters, data, errorCode = transCommands[command](connId,\n-                                smbServer, \n-                                recvPacket, \n-                                NTTransData['NT_Trans_Parameters'], \n-                                NTTransData['NT_Trans_Data'],\n-                                NTTransParameters['MaxDataCount'])\n-               except Exception as e:\n-                   smbServer.log('NTTransaction: (0x%x,%s)' % (command, e), logging.ERROR)\n-                   errorCode = STATUS_ACCESS_DENIED\n-                   #raise\n-\n-               if setup == b'' and parameters == b'' and data == b'':\n-                   # Something wen't wrong\n-                   respParameters = b''\n-                   respData = b''\n-                   if errorCode == STATUS_SUCCESS:\n-                       errorCode = STATUS_ACCESS_DENIED \n-               else:\n-                   # Build the answer\n-                   if hasattr(data, 'getData'):\n-                       data = data.getData()\n-                   remainingData = len(data)\n-                   if hasattr(parameters, 'getData'):\n-                       parameters = parameters.getData()\n-                   remainingParameters = len(parameters)\n-                   commands = []\n-                   dataDisplacement = 0\n-                   while remainingData > 0 or remainingParameters > 0: \n-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n-                       respParameters = smb.SMBNTTransactionResponse_Parameters()\n-                       respData       = smb.SMBNTTransactionResponse_Data()\n-\n-                       respParameters['TotalParameterCount'] = len(parameters)\n-                       respParameters['ParameterCount']      = len(parameters)\n-                       respData['Trans_ParametersLength']    = len(parameters)\n-                       respParameters['TotalDataCount']      = len(data)\n-                       respParameters['DataDisplacement']    = dataDisplacement\n-                       # TODO: Do the same for parameters\n-                       if len(data) >  NTTransParameters['MaxDataCount']:\n-                           # Answer doesn't fit in this packet\n-                           LOG.debug(\"Lowering answer from %d to %d\" % (len(data),NTTransParameters['MaxDataCount']) )\n-                           respParameters['DataCount'] = NTTransParameters['MaxDataCount']\n-                       else:\n-                           respParameters['DataCount'] = len(data)\n-\n-                       respData['NT_Trans_DataLength']          = respParameters['DataCount']\n-                       respParameters['SetupCount']          = len(setup)\n-                       respParameters['Setup']               = setup\n-                       # TODO: Make sure we're calculating the pad right\n-                       if len(parameters) > 0:\n-                           #padLen = 4 - (71 + len(setup)) % 4 \n-                           padLen = (4 - (73 + len(setup)) % 4 ) % 4\n-                           padBytes = b'\\xFF' * padLen\n-                           respData['Pad1'] = padBytes\n-                           respParameters['ParameterOffset'] = 73 + len(setup) + padLen \n-                       else:\n-                           padLen = 0\n-                           respParameters['ParameterOffset'] = 0\n-                           respData['Pad1']                  = b''\n-\n-                       if len(data) > 0:\n-                           #pad2Len = 4 - (71 + len(setup) + padLen + len(parameters)) % 4\n-                           pad2Len = (4 - (73 + len(setup) + padLen + len(parameters)) % 4) % 4\n-                           respData['Pad2'] = b'\\xFF' * pad2Len\n-                           respParameters['DataOffset'] = 73 + len(setup) + padLen + len(parameters) + pad2Len\n-                       else:\n-                           respParameters['DataOffset'] = 0\n-                           respData['Pad2']             = b''\n-\n-                       respData['NT_Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n-                       respData['NT_Trans_Data']       = data[:respParameters['DataCount']] \n-                       respSMBCommand['Parameters'] = respParameters\n-                       respSMBCommand['Data']       = respData \n-\n-                       data = data[respParameters['DataCount']:]\n-                       remainingData -= respParameters['DataCount']\n-                       dataDisplacement += respParameters['DataCount'] + 1\n-\n-                       parameters = parameters[respParameters['ParameterCount']:]\n-                       remainingParameters -= respParameters['ParameterCount']\n-                       commands.append(respSMBCommand)\n-\n-                   smbServer.setConnectionData(connId, connData)\n-                   return commands, None, errorCode\n+                # Call the NT TRANS subcommand\n+                setup = b''\n+                parameters = b''\n+                data = b''\n+                try:\n+                    setup, parameters, data, errorCode = transCommands[command](connId,\n+                                                                                smbServer,\n+                                                                                recvPacket,\n+                                                                                NTTransData['NT_Trans_Parameters'],\n+                                                                                NTTransData['NT_Trans_Data'],\n+                                                                                NTTransParameters['MaxDataCount'])\n+                except Exception as e:\n+                    smbServer.log('NTTransaction: (0x%x,%s)' % (command, e), logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n+                    # raise\n+\n+                if setup == b'' and parameters == b'' and data == b'':\n+                    # Something wen't wrong\n+                    respParameters = b''\n+                    respData = b''\n+                    if errorCode == STATUS_SUCCESS:\n+                        errorCode = STATUS_ACCESS_DENIED\n+                else:\n+                    # Build the answer\n+                    if hasattr(data, 'getData'):\n+                        data = data.getData()\n+                    remainingData = len(data)\n+                    if hasattr(parameters, 'getData'):\n+                        parameters = parameters.getData()\n+                    remainingParameters = len(parameters)\n+                    commands = []\n+                    dataDisplacement = 0\n+                    while remainingData > 0 or remainingParameters > 0:\n+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n+                        respParameters = smb.SMBNTTransactionResponse_Parameters()\n+                        respData = smb.SMBNTTransactionResponse_Data()\n+\n+                        respParameters['TotalParameterCount'] = len(parameters)\n+                        respParameters['ParameterCount'] = len(parameters)\n+                        respData['Trans_ParametersLength'] = len(parameters)\n+                        respParameters['TotalDataCount'] = len(data)\n+                        respParameters['DataDisplacement'] = dataDisplacement\n+                        # TODO: Do the same for parameters\n+                        if len(data) > NTTransParameters['MaxDataCount']:\n+                            # Answer doesn't fit in this packet\n+                            LOG.debug(\"Lowering answer from %d to %d\" % (len(data), NTTransParameters['MaxDataCount']))\n+                            respParameters['DataCount'] = NTTransParameters['MaxDataCount']\n+                        else:\n+                            respParameters['DataCount'] = len(data)\n+\n+                        respData['NT_Trans_DataLength'] = respParameters['DataCount']\n+                        respParameters['SetupCount'] = len(setup)\n+                        respParameters['Setup'] = setup\n+                        # TODO: Make sure we're calculating the pad right\n+                        if len(parameters) > 0:\n+                            # padLen = 4 - (71 + len(setup)) % 4\n+                            padLen = (4 - (73 + len(setup)) % 4) % 4\n+                            padBytes = b'\\xFF' * padLen\n+                            respData['Pad1'] = padBytes\n+                            respParameters['ParameterOffset'] = 73 + len(setup) + padLen\n+                        else:\n+                            padLen = 0\n+                            respParameters['ParameterOffset'] = 0\n+                            respData['Pad1'] = b''\n+\n+                        if len(data) > 0:\n+                            # pad2Len = 4 - (71 + len(setup) + padLen + len(parameters)) % 4\n+                            pad2Len = (4 - (73 + len(setup) + padLen + len(parameters)) % 4) % 4\n+                            respData['Pad2'] = b'\\xFF' * pad2Len\n+                            respParameters['DataOffset'] = 73 + len(setup) + padLen + len(parameters) + pad2Len\n+                        else:\n+                            respParameters['DataOffset'] = 0\n+                            respData['Pad2'] = b''\n+\n+                        respData['NT_Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n+                        respData['NT_Trans_Data'] = data[:respParameters['DataCount']]\n+                        respSMBCommand['Parameters'] = respParameters\n+                        respSMBCommand['Data'] = respData\n+\n+                        data = data[respParameters['DataCount']:]\n+                        remainingData -= respParameters['DataCount']\n+                        dataDisplacement += respParameters['DataCount'] + 1\n+\n+                        parameters = parameters[respParameters['ParameterCount']:]\n+                        remainingParameters -= respParameters['ParameterCount']\n+                        commands.append(respSMBCommand)\n+\n+                    smbServer.setConnectionData(connId, connData)\n+                    return commands, None, errorCode\n \n             else:\n-               #smbServer.log(\"Unsupported NTTransact command 0x%x\" % command, logging.ERROR)\n-               respParameters = b''\n-               respData = b''\n-               errorCode = STATUS_NOT_IMPLEMENTED\n+                # smbServer.log(\"Unsupported NTTransact command 0x%x\" % command, logging.ERROR)\n+                respParameters = b''\n+                respData = b''\n+                errorCode = STATUS_NOT_IMPLEMENTED\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n \n-        trans2Parameters= smb.SMBTransaction2_Parameters(SMBCommand['Parameters'])\n+        trans2Parameters = smb.SMBTransaction2_Parameters(SMBCommand['Parameters'])\n \n         # Do the stuff\n         if trans2Parameters['ParameterCount'] != trans2Parameters['TotalParameterCount']:\n-            # TODO: Handle partial parameters \n-            #print \"Unsupported partial parameters in TRANSACT2!\"\n+            # TODO: Handle partial parameters\n+            # print \"Unsupported partial parameters in TRANSACT2!\"\n             raise Exception(\"Unsupported partial parameters in TRANSACT2!\")\n         else:\n             trans2Data = smb.SMBTransaction2_Data()\n-            # Standard says servers shouldn't trust Parameters and Data comes \n-            # in order, so we have to parse the offsets, ugly   \n+            # Standard says servers shouldn't trust Parameters and Data comes\n+            # in order, so we have to parse the offsets, ugly\n \n             paramCount = trans2Parameters['ParameterCount']\n             trans2Data['Trans_ParametersLength'] = paramCount\n@@ -1228,113 +1257,113 @@ def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):\n \n             if trans2Parameters['ParameterOffset'] > 0:\n                 paramOffset = trans2Parameters['ParameterOffset'] - 63 - trans2Parameters['SetupLength']\n-                trans2Data['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]\n+                trans2Data['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]\n             else:\n                 trans2Data['Trans_Parameters'] = b''\n \n             if trans2Parameters['DataOffset'] > 0:\n                 dataOffset = trans2Parameters['DataOffset'] - 63 - trans2Parameters['SetupLength']\n                 trans2Data['Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]\n-            else: \n+            else:\n                 trans2Data['Trans_Data'] = b''\n \n             # Call the handler for this TRANSACTION\n             command = struct.unpack('<H', trans2Parameters['Setup'])[0]\n             if command in transCommands:\n-               # Call the TRANS2 subcommand\n-               try:\n-                   setup, parameters, data, errorCode = transCommands[command](connId,\n-                                smbServer, \n-                                recvPacket, \n-                                trans2Data['Trans_Parameters'], \n-                                trans2Data['Trans_Data'],\n-                                trans2Parameters['MaxDataCount'])\n-               except Exception as e:\n-                   smbServer.log('Transaction2: (0x%x,%s)' % (command, e), logging.ERROR)\n-                   #import traceback\n-                   #traceback.print_exc()\n-                   raise\n-\n-               if setup == b'' and parameters == b'' and data == b'':\n-                   # Something wen't wrong\n-                   respParameters = b''\n-                   respData = b''\n-               else:\n-                   # Build the answer\n-                   if hasattr(data, 'getData'):\n-                       data = data.getData()\n-                   remainingData = len(data)\n-                   if hasattr(parameters, 'getData'):\n-                       parameters = parameters.getData()\n-                   remainingParameters = len(parameters)\n-                   commands = []\n-                   dataDisplacement = 0\n-                   while remainingData > 0 or remainingParameters > 0: \n-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n-                       respParameters = smb.SMBTransaction2Response_Parameters()\n-                       respData       = smb.SMBTransaction2Response_Data()\n-\n-                       respParameters['TotalParameterCount'] = len(parameters)\n-                       respParameters['ParameterCount']      = len(parameters)\n-                       respData['Trans_ParametersLength']    = len(parameters)\n-                       respParameters['TotalDataCount']      = len(data)\n-                       respParameters['DataDisplacement']    = dataDisplacement\n-                       # TODO: Do the same for parameters\n-                       if len(data) >  trans2Parameters['MaxDataCount']:\n-                           # Answer doesn't fit in this packet\n-                           LOG.debug(\"Lowering answer from %d to %d\" % (len(data),trans2Parameters['MaxDataCount']) )\n-                           respParameters['DataCount'] = trans2Parameters['MaxDataCount']\n-                       else:\n-                           respParameters['DataCount'] = len(data)\n-\n-                       respData['Trans_DataLength']          = respParameters['DataCount']\n-                       respParameters['SetupCount']          = len(setup)\n-                       respParameters['Setup']               = setup\n-                       # TODO: Make sure we're calculating the pad right\n-                       if len(parameters) > 0:\n-                           #padLen = 4 - (55 + len(setup)) % 4 \n-                           padLen = (4 - (55 + len(setup)) % 4 ) % 4\n-                           padBytes = b'\\xFF' * padLen\n-                           respData['Pad1'] = padBytes\n-                           respParameters['ParameterOffset'] = 55 + len(setup) + padLen \n-                       else:\n-                           padLen = 0\n-                           respParameters['ParameterOffset'] = 0\n-                           respData['Pad1']                  = b''\n-\n-                       if len(data) > 0:\n-                           #pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4\n-                           pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4\n-                           respData['Pad2'] = b'\\xFF' * pad2Len\n-                           respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len\n-                       else:\n-                           respParameters['DataOffset'] = 0\n-                           respData['Pad2']             = b''\n-\n-                       respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n-                       respData['Trans_Data']       = data[:respParameters['DataCount']] \n-                       respSMBCommand['Parameters'] = respParameters\n-                       respSMBCommand['Data']       = respData \n-\n-                       data = data[respParameters['DataCount']:]\n-                       remainingData -= respParameters['DataCount']\n-                       dataDisplacement += respParameters['DataCount'] + 1\n-\n-                       parameters = parameters[respParameters['ParameterCount']:]\n-                       remainingParameters -= respParameters['ParameterCount']\n-                       commands.append(respSMBCommand)\n-\n-                   smbServer.setConnectionData(connId, connData)\n-                   return commands, None, errorCode\n+                # Call the TRANS2 subcommand\n+                try:\n+                    setup, parameters, data, errorCode = transCommands[command](connId,\n+                                                                                smbServer,\n+                                                                                recvPacket,\n+                                                                                trans2Data['Trans_Parameters'],\n+                                                                                trans2Data['Trans_Data'],\n+                                                                                trans2Parameters['MaxDataCount'])\n+                except Exception as e:\n+                    smbServer.log('Transaction2: (0x%x,%s)' % (command, e), logging.ERROR)\n+                    # import traceback\n+                    # traceback.print_exc()\n+                    raise\n+\n+                if setup == b'' and parameters == b'' and data == b'':\n+                    # Something wen't wrong\n+                    respParameters = b''\n+                    respData = b''\n+                else:\n+                    # Build the answer\n+                    if hasattr(data, 'getData'):\n+                        data = data.getData()\n+                    remainingData = len(data)\n+                    if hasattr(parameters, 'getData'):\n+                        parameters = parameters.getData()\n+                    remainingParameters = len(parameters)\n+                    commands = []\n+                    dataDisplacement = 0\n+                    while remainingData > 0 or remainingParameters > 0:\n+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n+                        respParameters = smb.SMBTransaction2Response_Parameters()\n+                        respData = smb.SMBTransaction2Response_Data()\n+\n+                        respParameters['TotalParameterCount'] = len(parameters)\n+                        respParameters['ParameterCount'] = len(parameters)\n+                        respData['Trans_ParametersLength'] = len(parameters)\n+                        respParameters['TotalDataCount'] = len(data)\n+                        respParameters['DataDisplacement'] = dataDisplacement\n+                        # TODO: Do the same for parameters\n+                        if len(data) > trans2Parameters['MaxDataCount']:\n+                            # Answer doesn't fit in this packet\n+                            LOG.debug(\"Lowering answer from %d to %d\" % (len(data), trans2Parameters['MaxDataCount']))\n+                            respParameters['DataCount'] = trans2Parameters['MaxDataCount']\n+                        else:\n+                            respParameters['DataCount'] = len(data)\n+\n+                        respData['Trans_DataLength'] = respParameters['DataCount']\n+                        respParameters['SetupCount'] = len(setup)\n+                        respParameters['Setup'] = setup\n+                        # TODO: Make sure we're calculating the pad right\n+                        if len(parameters) > 0:\n+                            # padLen = 4 - (55 + len(setup)) % 4\n+                            padLen = (4 - (55 + len(setup)) % 4) % 4\n+                            padBytes = b'\\xFF' * padLen\n+                            respData['Pad1'] = padBytes\n+                            respParameters['ParameterOffset'] = 55 + len(setup) + padLen\n+                        else:\n+                            padLen = 0\n+                            respParameters['ParameterOffset'] = 0\n+                            respData['Pad1'] = b''\n+\n+                        if len(data) > 0:\n+                            # pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4\n+                            pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4\n+                            respData['Pad2'] = b'\\xFF' * pad2Len\n+                            respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len\n+                        else:\n+                            respParameters['DataOffset'] = 0\n+                            respData['Pad2'] = b''\n+\n+                        respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n+                        respData['Trans_Data'] = data[:respParameters['DataCount']]\n+                        respSMBCommand['Parameters'] = respParameters\n+                        respSMBCommand['Data'] = respData\n+\n+                        data = data[respParameters['DataCount']:]\n+                        remainingData -= respParameters['DataCount']\n+                        dataDisplacement += respParameters['DataCount'] + 1\n+\n+                        parameters = parameters[respParameters['ParameterCount']:]\n+                        remainingParameters -= respParameters['ParameterCount']\n+                        commands.append(respSMBCommand)\n+\n+                    smbServer.setConnectionData(connId, connData)\n+                    return commands, None, errorCode\n \n             else:\n-               smbServer.log(\"Unsupported Transact\/2 command 0x%x\" % command, logging.ERROR)\n-               respParameters = b''\n-               respData = b''\n-               errorCode = STATUS_NOT_IMPLEMENTED\n+                smbServer.log(\"Unsupported Transact\/2 command 0x%x\" % command, logging.ERROR)\n+                respParameters = b''\n+                respData = b''\n+                errorCode = STATUS_NOT_IMPLEMENTED\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n@@ -1343,59 +1372,58 @@ def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):\n     def smbComLockingAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_LOCKING_ANDX)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_LOCKING_ANDX)\n+        respParameters = b''\n+        respData = b''\n \n         # I'm actually doing nothing.. just make MacOS happy ;)\n         errorCode = STATUS_SUCCESS\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smbComClose(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_CLOSE)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_CLOSE)\n+        respParameters = b''\n+        respData = b''\n \n-        comClose =  smb.SMBClose_Parameters(SMBCommand['Parameters'])\n+        comClose = smb.SMBClose_Parameters(SMBCommand['Parameters'])\n \n         if comClose['FID'] in connData['OpenedFiles']:\n-             errorCode = STATUS_SUCCESS\n-             fileHandle = connData['OpenedFiles'][comClose['FID']]['FileHandle']\n-             try:\n-                 if fileHandle == PIPE_FILE_DESCRIPTOR:\n-                     connData['OpenedFiles'][comClose['FID']]['Socket'].close()\n-                 elif fileHandle != VOID_FILE_DESCRIPTOR:\n-                     os.close(fileHandle)\n-             except Exception as e:\n-                 smbServer.log(\"comClose %s\" % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n-             else:\n-                 # Check if the file was marked for removal\n-                 if connData['OpenedFiles'][comClose['FID']]['DeleteOnClose'] is True:\n-                     try:\n-                         os.remove(connData['OpenedFiles'][comClose['FID']]['FileName'])\n-                     except Exception as e:\n-                         smbServer.log(\"comClose %s\" % e, logging.ERROR)\n-                         errorCode = STATUS_ACCESS_DENIED\n-                 del(connData['OpenedFiles'][comClose['FID']])\n+            errorCode = STATUS_SUCCESS\n+            fileHandle = connData['OpenedFiles'][comClose['FID']]['FileHandle']\n+            try:\n+                if fileHandle == PIPE_FILE_DESCRIPTOR:\n+                    connData['OpenedFiles'][comClose['FID']]['Socket'].close()\n+                elif fileHandle != VOID_FILE_DESCRIPTOR:\n+                    os.close(fileHandle)\n+            except Exception as e:\n+                smbServer.log(\"comClose %s\" % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n+            else:\n+                # Check if the file was marked for removal\n+                if connData['OpenedFiles'][comClose['FID']]['DeleteOnClose'] is True:\n+                    try:\n+                        os.remove(connData['OpenedFiles'][comClose['FID']]['FileName'])\n+                    except Exception as e:\n+                        smbServer.log(\"comClose %s\" % e, logging.ERROR)\n+                        errorCode = STATUS_ACCESS_DENIED\n+                del (connData['OpenedFiles'][comClose['FID']])\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1404,310 +1432,308 @@ def smbComClose(connId, smbServer, SMBCommand, recvPacket):\n     def smbComWrite(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_WRITE)\n-        respParameters        = smb.SMBWriteResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_WRITE)\n+        respParameters = smb.SMBWriteResponse_Parameters()\n+        respData = b''\n \n-        comWriteParameters =  smb.SMBWrite_Parameters(SMBCommand['Parameters'])\n+        comWriteParameters = smb.SMBWrite_Parameters(SMBCommand['Parameters'])\n         comWriteData = smb.SMBWrite_Data(SMBCommand['Data'])\n \n         if comWriteParameters['Fid'] in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][comWriteParameters['Fid']]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     # TODO: Handle big size files\n-                     # If we're trying to write past the file end we just skip the write call (Vista does this)\n-                     if os.lseek(fileHandle, 0, 2) >= comWriteParameters['Offset']: \n-                         os.lseek(fileHandle,comWriteParameters['Offset'],0)\n-                         os.write(fileHandle,comWriteData['Data'])\n-                 else:\n-                     sock = connData['OpenedFiles'][comWriteParameters['Fid']]['Socket']\n-                     sock.send(comWriteData['Data'])\n-                 respParameters['Count']    = comWriteParameters['Count']\n-             except Exception as e:\n-                 smbServer.log('smbComWrite: %s' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][comWriteParameters['Fid']]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    # TODO: Handle big size files\n+                    # If we're trying to write past the file end we just skip the write call (Vista does this)\n+                    if os.lseek(fileHandle, 0, 2) >= comWriteParameters['Offset']:\n+                        os.lseek(fileHandle, comWriteParameters['Offset'], 0)\n+                        os.write(fileHandle, comWriteData['Data'])\n+                else:\n+                    sock = connData['OpenedFiles'][comWriteParameters['Fid']]['Socket']\n+                    sock.send(comWriteData['Data'])\n+                respParameters['Count'] = comWriteParameters['Count']\n+            except Exception as e:\n+                smbServer.log('smbComWrite: %s' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n-\n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n     @staticmethod\n-    def smbComFlush(connId, smbServer, SMBCommand,recvPacket ):\n+    def smbComFlush(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_FLUSH)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_FLUSH)\n+        respParameters = b''\n+        respData = b''\n \n-        comFlush =  smb.SMBFlush_Parameters(SMBCommand['Parameters'])\n+        comFlush = smb.SMBFlush_Parameters(SMBCommand['Parameters'])\n \n         if comFlush['FID'] in connData['OpenedFiles']:\n-             errorCode = STATUS_SUCCESS\n-             fileHandle = connData['OpenedFiles'][comFlush['FID']]['FileHandle']\n-             try:\n-                 os.fsync(fileHandle)\n-             except Exception as e:\n-                 smbServer.log(\"comFlush %s\" % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            errorCode = STATUS_SUCCESS\n+            fileHandle = connData['OpenedFiles'][comFlush['FID']]['FileHandle']\n+            try:\n+                os.fsync(fileHandle)\n+            except Exception as e:\n+                smbServer.log(\"comFlush %s\" % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n-    def smbComCreateDirectory(connId, smbServer, SMBCommand,recvPacket ):\n+    def smbComCreateDirectory(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_CREATE_DIRECTORY)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_CREATE_DIRECTORY)\n+        respParameters = b''\n+        respData = b''\n \n-        comCreateDirectoryData=  smb.SMBCreateDirectory_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        comCreateDirectoryData = smb.SMBCreateDirectory_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             errorCode = STATUS_SUCCESS\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comCreateDirectoryData['DirectoryName']).replace('\\\\','\/'))\n-             if len(fileName) > 0:\n+            errorCode = STATUS_SUCCESS\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            fileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comCreateDirectoryData['DirectoryName']).replace('\\\\', '\/'))\n+            if len(fileName) > 0:\n                 if fileName[0] == '\/' or fileName[0] == '\\\\':\n                     # strip leading '\/'\n                     fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             if os.path.exists(pathName):\n+            pathName = os.path.join(path, fileName)\n+            if os.path.exists(pathName):\n                 errorCode = STATUS_OBJECT_NAME_COLLISION\n \n-             # TODO: More checks here in the future.. Specially when we support\n-             # user access\n-             else:\n-                 try:\n-                     os.mkdir(pathName)\n-                 except Exception as e:\n-                     smbServer.log(\"smbComCreateDirectory: %s\" % e, logging.ERROR)\n-                     errorCode = STATUS_ACCESS_DENIED\n+            # TODO: More checks here in the future.. Specially when we support\n+            # user access\n+            else:\n+                try:\n+                    os.mkdir(pathName)\n+                except Exception as e:\n+                    smbServer.log(\"smbComCreateDirectory: %s\" % e, logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n     @staticmethod\n-    def smbComRename(connId, smbServer, SMBCommand, recvPacket ):\n+    def smbComRename(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_RENAME)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_RENAME)\n+        respParameters = b''\n+        respData = b''\n \n-        comRenameData      =  smb.SMBRename_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        comRenameData = smb.SMBRename_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             errorCode = STATUS_SUCCESS\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             oldFileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comRenameData['OldFileName']).replace('\\\\','\/'))\n-             newFileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comRenameData['NewFileName']).replace('\\\\','\/'))\n-             if len(oldFileName) > 0 and (oldFileName[0] == '\/' or oldFileName[0] == '\\\\'):\n+            errorCode = STATUS_SUCCESS\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            oldFileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comRenameData['OldFileName']).replace('\\\\', '\/'))\n+            newFileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comRenameData['NewFileName']).replace('\\\\', '\/'))\n+            if len(oldFileName) > 0 and (oldFileName[0] == '\/' or oldFileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 oldFileName = oldFileName[1:]\n-             oldPathName = os.path.join(path,oldFileName)\n-             if len(newFileName) > 0 and (newFileName[0] == '\/' or newFileName[0] == '\\\\'):\n+            oldPathName = os.path.join(path, oldFileName)\n+            if len(newFileName) > 0 and (newFileName[0] == '\/' or newFileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 newFileName = newFileName[1:]\n-             newPathName = os.path.join(path,newFileName)\n+            newPathName = os.path.join(path, newFileName)\n \n-             if os.path.exists(oldPathName) is not True:\n+            if os.path.exists(oldPathName) is not True:\n                 errorCode = STATUS_NO_SUCH_FILE\n \n-             # TODO: More checks here in the future.. Specially when we support\n-             # user access\n-             else:\n-                 try:\n-                     os.rename(oldPathName,newPathName)\n-                 except OSError as e:\n-                     smbServer.log(\"smbComRename: %s\" % e, logging.ERROR)\n-                     errorCode = STATUS_ACCESS_DENIED\n+            # TODO: More checks here in the future.. Specially when we support\n+            # user access\n+            else:\n+                try:\n+                    os.rename(oldPathName, newPathName)\n+                except OSError as e:\n+                    smbServer.log(\"smbComRename: %s\" % e, logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n     @staticmethod\n-    def smbComDelete(connId, smbServer, SMBCommand, recvPacket ):\n+    def smbComDelete(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_DELETE)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_DELETE)\n+        respParameters = b''\n+        respData = b''\n \n-        comDeleteData         =  smb.SMBDelete_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        comDeleteData = smb.SMBDelete_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             errorCode = STATUS_SUCCESS\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comDeleteData['FileName']).replace('\\\\','\/'))\n-             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+            errorCode = STATUS_SUCCESS\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            fileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comDeleteData['FileName']).replace('\\\\', '\/'))\n+            if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             if os.path.exists(pathName) is not True:\n+            pathName = os.path.join(path, fileName)\n+            if os.path.exists(pathName) is not True:\n                 errorCode = STATUS_NO_SUCH_FILE\n \n-             # TODO: More checks here in the future.. Specially when we support\n-             # user access\n-             else:\n-                 try:\n-                     os.remove(pathName)\n-                 except OSError as e:\n-                     smbServer.log(\"smbComDelete: %s\" % e, logging.ERROR)\n-                     errorCode = STATUS_ACCESS_DENIED\n+            # TODO: More checks here in the future.. Specially when we support\n+            # user access\n+            else:\n+                try:\n+                    os.remove(pathName)\n+                except OSError as e:\n+                    smbServer.log(\"smbComDelete: %s\" % e, logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n-    def smbComDeleteDirectory(connId, smbServer, SMBCommand, recvPacket ):\n+    def smbComDeleteDirectory(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_DELETE_DIRECTORY)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_DELETE_DIRECTORY)\n+        respParameters = b''\n+        respData = b''\n \n-        comDeleteDirectoryData=  smb.SMBDeleteDirectory_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        comDeleteDirectoryData = smb.SMBDeleteDirectory_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             errorCode = STATUS_SUCCESS\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comDeleteDirectoryData['DirectoryName']).replace('\\\\','\/'))\n-             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+            errorCode = STATUS_SUCCESS\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            fileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comDeleteDirectoryData['DirectoryName']).replace('\\\\', '\/'))\n+            if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             if os.path.exists(pathName) is not True:\n+            pathName = os.path.join(path, fileName)\n+            if os.path.exists(pathName) is not True:\n                 errorCode = STATUS_NO_SUCH_FILE\n \n-             # TODO: More checks here in the future.. Specially when we support\n-             # user access\n-             else:\n-                 try:\n-                     os.rmdir(pathName)\n-                 except OSError as e:\n-                     smbServer.log(\"smbComDeleteDirectory: %s\" % e,logging.ERROR)\n-                     if e.errno == errno.ENOTEMPTY:\n-                         errorCode = STATUS_DIRECTORY_NOT_EMPTY\n-                     else:\n-                         errorCode = STATUS_ACCESS_DENIED\n+            # TODO: More checks here in the future.. Specially when we support\n+            # user access\n+            else:\n+                try:\n+                    os.rmdir(pathName)\n+                except OSError as e:\n+                    smbServer.log(\"smbComDeleteDirectory: %s\" % e, logging.ERROR)\n+                    if e.errno == errno.ENOTEMPTY:\n+                        errorCode = STATUS_DIRECTORY_NOT_EMPTY\n+                    else:\n+                        errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smbComWriteAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_WRITE_ANDX)\n-        respParameters        = smb.SMBWriteAndXResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_WRITE_ANDX)\n+        respParameters = smb.SMBWriteAndXResponse_Parameters()\n+        respData = b''\n \n         if SMBCommand['WordCount'] == 0x0C:\n-            writeAndX =  smb.SMBWriteAndX_Parameters_Short(SMBCommand['Parameters'])\n+            writeAndX = smb.SMBWriteAndX_Parameters_Short(SMBCommand['Parameters'])\n             writeAndXData = smb.SMBWriteAndX_Data_Short()\n         else:\n-            writeAndX =  smb.SMBWriteAndX_Parameters(SMBCommand['Parameters'])\n+            writeAndX = smb.SMBWriteAndX_Parameters(SMBCommand['Parameters'])\n             writeAndXData = smb.SMBWriteAndX_Data()\n         writeAndXData['DataLength'] = writeAndX['DataLength']\n         writeAndXData['DataOffset'] = writeAndX['DataOffset']\n         writeAndXData.fromString(SMBCommand['Data'])\n-        \n \n         if writeAndX['Fid'] in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][writeAndX['Fid']]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     offset = writeAndX['Offset']\n-                     if 'HighOffset' in writeAndX.fields:\n-                         offset += (writeAndX['HighOffset'] << 32)\n-                     # If we're trying to write past the file end we just skip the write call (Vista does this)\n-                     if os.lseek(fileHandle, 0, 2) >= offset:\n-                         os.lseek(fileHandle,offset,0)\n-                         os.write(fileHandle,writeAndXData['Data'])\n-                 else:\n-                     sock = connData['OpenedFiles'][writeAndX['Fid']]['Socket']\n-                     sock.send(writeAndXData['Data'])\n-\n-                 respParameters['Count']    = writeAndX['DataLength']\n-                 respParameters['Available']= 0xff\n-             except Exception as e:\n-                 smbServer.log('smbComWriteAndx: %s' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][writeAndX['Fid']]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    offset = writeAndX['Offset']\n+                    if 'HighOffset' in writeAndX.fields:\n+                        offset += (writeAndX['HighOffset'] << 32)\n+                    # If we're trying to write past the file end we just skip the write call (Vista does this)\n+                    if os.lseek(fileHandle, 0, 2) >= offset:\n+                        os.lseek(fileHandle, offset, 0)\n+                        os.write(fileHandle, writeAndXData['Data'])\n+                else:\n+                    sock = connData['OpenedFiles'][writeAndX['Fid']]['Socket']\n+                    sock.send(writeAndXData['Data'])\n+\n+                respParameters['Count'] = writeAndX['DataLength']\n+                respParameters['Available'] = 0xff\n+            except Exception as e:\n+                smbServer.log('smbComWriteAndx: %s' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1716,38 +1742,38 @@ def smbComWriteAndX(connId, smbServer, SMBCommand, recvPacket):\n     def smbComRead(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_READ)\n-        respParameters        = smb.SMBReadResponse_Parameters()\n-        respData              = smb.SMBReadResponse_Data()\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_READ)\n+        respParameters = smb.SMBReadResponse_Parameters()\n+        respData = smb.SMBReadResponse_Data()\n \n-        comReadParameters =  smb.SMBRead_Parameters(SMBCommand['Parameters'])\n+        comReadParameters = smb.SMBRead_Parameters(SMBCommand['Parameters'])\n \n         if comReadParameters['Fid'] in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][comReadParameters['Fid']]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     # TODO: Handle big size files\n-                     os.lseek(fileHandle,comReadParameters['Offset'],0)\n-                     content = os.read(fileHandle,comReadParameters['Count'])\n-                 else:\n-                     sock = connData['OpenedFiles'][comReadParameters['Fid']]['Socket']\n-                     content = sock.recv(comReadParameters['Count'])\n-                 respParameters['Count']    = len(content)\n-                 respData['DataLength']     = len(content)\n-                 respData['Data']           = content\n-             except Exception as e:\n-                 smbServer.log('smbComRead: %s ' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][comReadParameters['Fid']]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    # TODO: Handle big size files\n+                    os.lseek(fileHandle, comReadParameters['Offset'], 0)\n+                    content = os.read(fileHandle, comReadParameters['Count'])\n+                else:\n+                    sock = connData['OpenedFiles'][comReadParameters['Fid']]['Socket']\n+                    content = sock.recv(comReadParameters['Count'])\n+                respParameters['Count'] = len(content)\n+                respData['DataLength'] = len(content)\n+                respData['Data'] = content\n+            except Exception as e:\n+                smbServer.log('smbComRead: %s ' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1756,45 +1782,45 @@ def smbComRead(connId, smbServer, SMBCommand, recvPacket):\n     def smbComReadAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_READ_ANDX)\n-        respParameters        = smb.SMBReadAndXResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_READ_ANDX)\n+        respParameters = smb.SMBReadAndXResponse_Parameters()\n+        respData = b''\n \n         if SMBCommand['WordCount'] == 0x0A:\n-            readAndX =  smb.SMBReadAndX_Parameters2(SMBCommand['Parameters'])\n+            readAndX = smb.SMBReadAndX_Parameters2(SMBCommand['Parameters'])\n         else:\n-            readAndX =  smb.SMBReadAndX_Parameters(SMBCommand['Parameters'])\n+            readAndX = smb.SMBReadAndX_Parameters(SMBCommand['Parameters'])\n \n         if readAndX['Fid'] in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][readAndX['Fid']]['FileHandle']\n-             errorCode = 0\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     offset = readAndX['Offset']\n-                     if 'HighOffset' in readAndX.fields:\n-                         offset += (readAndX['HighOffset'] << 32)\n-                     os.lseek(fileHandle,offset,0)\n-                     content = os.read(fileHandle,readAndX['MaxCount'])\n-                 else:\n-                     sock = connData['OpenedFiles'][readAndX['Fid']]['Socket']\n-                     content = sock.recv(readAndX['MaxCount'])\n-                 respParameters['Remaining']    = 0xffff\n-                 respParameters['DataCount']    = len(content)\n-                 respParameters['DataOffset']   = 59\n-                 respParameters['DataCount_Hi'] = 0\n-                 respData = content\n-             except Exception as e:\n-                 smbServer.log('smbComReadAndX: %s ' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][readAndX['Fid']]['FileHandle']\n+            errorCode = 0\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    offset = readAndX['Offset']\n+                    if 'HighOffset' in readAndX.fields:\n+                        offset += (readAndX['HighOffset'] << 32)\n+                    os.lseek(fileHandle, offset, 0)\n+                    content = os.read(fileHandle, readAndX['MaxCount'])\n+                else:\n+                    sock = connData['OpenedFiles'][readAndX['Fid']]['Socket']\n+                    content = sock.recv(readAndX['MaxCount'])\n+                respParameters['Remaining'] = 0xffff\n+                respParameters['DataCount'] = len(content)\n+                respParameters['DataOffset'] = 59\n+                respParameters['DataCount_Hi'] = 0\n+                respData = content\n+            except Exception as e:\n+                smbServer.log('smbComReadAndX: %s ' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1805,28 +1831,28 @@ def smbQueryInformation(connId, smbServer, SMBCommand, recvPacket):\n \n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION)\n         respParameters = smb.SMBQueryInformationResponse_Parameters()\n-        respData       = b''\n+        respData = b''\n \n-        queryInformation= smb.SMBQueryInformation_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        queryInformation = smb.SMBQueryInformation_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             fileSize, lastWriteTime, fileAttributes = queryFsInformation(\n-                connData['ConnectedShares'][recvPacket['Tid']]['path'], \n-                decodeSMBString(recvPacket['Flags2'],queryInformation['FileName']), pktFlags = recvPacket['Flags2'])\n+                connData['ConnectedShares'][recvPacket['Tid']]['path'],\n+                decodeSMBString(recvPacket['Flags2'], queryInformation['FileName']), pktFlags=recvPacket['Flags2'])\n \n-            respParameters['FileSize']       = fileSize\n-            respParameters['LastWriteTime']  = lastWriteTime\n+            respParameters['FileSize'] = fileSize\n+            respParameters['LastWriteTime'] = lastWriteTime\n             respParameters['FileAttributes'] = fileAttributes\n             errorCode = STATUS_SUCCESS\n         else:\n             # STATUS_SMB_BAD_TID\n             errorCode = STATUS_SMB_BAD_TID\n-            respParameters  = b''\n-            respData        = b''\n+            respParameters = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n@@ -1837,27 +1863,26 @@ def smbQueryInformationDisk(connId, smbServer, SMBCommand, recvPacket):\n \n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION_DISK)\n         respParameters = smb.SMBQueryInformationDiskResponse_Parameters()\n-        respData       = b''\n+        respData = b''\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             totalUnits, freeUnits = queryDiskInformation(\n-                        connData['ConnectedShares'][recvPacket['Tid']]['path'])\n+                connData['ConnectedShares'][recvPacket['Tid']]['path'])\n \n-            respParameters['TotalUnits']    = totalUnits\n+            respParameters['TotalUnits'] = totalUnits\n             respParameters['BlocksPerUnit'] = 1\n-            respParameters['BlockSize']     = 1\n-            respParameters['FreeUnits']     = freeUnits\n+            respParameters['BlockSize'] = 1\n+            respParameters['FreeUnits'] = freeUnits\n             errorCode = STATUS_SUCCESS\n         else:\n             # STATUS_SMB_BAD_TID\n-            respData  = b''\n+            respData = b''\n             respParameters = b''\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n@@ -1868,15 +1893,15 @@ def smbComEcho(connId, smbServer, SMBCommand, recvPacket):\n \n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_ECHO)\n         respParameters = smb.SMBEchoResponse_Parameters()\n-        respData       = smb.SMBEchoResponse_Data()\n+        respData = smb.SMBEchoResponse_Data()\n \n-        echoData       = smb.SMBEcho_Data(SMBCommand['Data'])\n+        echoData = smb.SMBEcho_Data(SMBCommand['Data'])\n \n         respParameters['SequenceNumber'] = 1\n-        respData['Data']                 = echoData['Data']\n+        respData['Data'] = echoData['Data']\n \n-        respSMBCommand['Parameters']     = respParameters\n-        respSMBCommand['Data']           = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         errorCode = STATUS_SUCCESS\n         smbServer.setConnectionData(connId, connData)\n@@ -1893,15 +1918,16 @@ def smbComTreeDisconnect(connId, smbServer, SMBCommand, recvPacket):\n         respData = b''\n \n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-            smbServer.log(\"Disconnecting Share(%d:%s)\" % (recvPacket['Tid'],connData['ConnectedShares'][recvPacket['Tid']]['shareName']))\n-            del(connData['ConnectedShares'][recvPacket['Tid']])\n+            smbServer.log(\"Disconnecting Share(%d:%s)\" % (\n+            recvPacket['Tid'], connData['ConnectedShares'][recvPacket['Tid']]['shareName']))\n+            del (connData['ConnectedShares'][recvPacket['Tid']])\n             errorCode = STATUS_SUCCESS\n         else:\n             # STATUS_SMB_BAD_TID\n             errorCode = STATUS_SMB_BAD_TID\n \n         respSMBCommand['Parameters'] = respParameters\n-        respSMBCommand['Data']       = respData \n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n@@ -1910,7 +1936,7 @@ def smbComTreeDisconnect(connId, smbServer, SMBCommand, recvPacket):\n     def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_LOGOFF_ANDX)\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_LOGOFF_ANDX)\n \n         # Check if the Uid matches the user trying to logoff\n         respParameters = b''\n@@ -1921,8 +1947,8 @@ def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):\n         else:\n             errorCode = STATUS_SUCCESS\n \n-        respSMBCommand['Parameters']   = respParameters\n-        respSMBCommand['Data']         = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         connData['Uid'] = 0\n         connData['Authenticated'] = False\n \n@@ -1934,41 +1960,41 @@ def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):\n     def smbComQueryInformation2(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION2)\n-        respParameters        = smb.SMBQueryInformation2Response_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION2)\n+        respParameters = smb.SMBQueryInformation2Response_Parameters()\n+        respData = b''\n \n         queryInformation2 = smb.SMBQueryInformation2_Parameters(SMBCommand['Parameters'])\n         errorCode = 0xFF\n         if queryInformation2['Fid'] in connData['OpenedFiles']:\n-             errorCode = STATUS_SUCCESS\n-             pathName = connData['OpenedFiles'][queryInformation2['Fid']]['FileName']\n-             try:\n-                 (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n-                 respParameters['CreateDate']         = getSMBDate(ctime)\n-                 respParameters['CreationTime']       = getSMBTime(ctime)\n-                 respParameters['LastAccessDate']     = getSMBDate(atime)\n-                 respParameters['LastAccessTime']     = getSMBTime(atime)\n-                 respParameters['LastWriteDate']      = getSMBDate(mtime)\n-                 respParameters['LastWriteTime']      = getSMBTime(mtime)\n-                 respParameters['FileDataSize']       = size\n-                 respParameters['FileAllocationSize'] = size\n-                 attribs = 0\n-                 if os.path.isdir(pathName):\n-                     attribs = smb.SMB_FILE_ATTRIBUTE_DIRECTORY\n-                 if os.path.isfile(pathName):\n-                     attribs = smb.SMB_FILE_ATTRIBUTE_NORMAL\n-                 respParameters['FileAttributes'] = attribs\n-             except Exception as e:\n-                 smbServer.log('smbComQueryInformation2 %s' % e,logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            errorCode = STATUS_SUCCESS\n+            pathName = connData['OpenedFiles'][queryInformation2['Fid']]['FileName']\n+            try:\n+                (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n+                respParameters['CreateDate'] = getSMBDate(ctime)\n+                respParameters['CreationTime'] = getSMBTime(ctime)\n+                respParameters['LastAccessDate'] = getSMBDate(atime)\n+                respParameters['LastAccessTime'] = getSMBTime(atime)\n+                respParameters['LastWriteDate'] = getSMBDate(mtime)\n+                respParameters['LastWriteTime'] = getSMBTime(mtime)\n+                respParameters['FileDataSize'] = size\n+                respParameters['FileAllocationSize'] = size\n+                attribs = 0\n+                if os.path.isdir(pathName):\n+                    attribs = smb.SMB_FILE_ATTRIBUTE_DIRECTORY\n+                if os.path.isfile(pathName):\n+                    attribs = smb.SMB_FILE_ATTRIBUTE_NORMAL\n+                respParameters['FileAttributes'] = attribs\n+            except Exception as e:\n+                smbServer.log('smbComQueryInformation2 %s' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1978,136 +2004,145 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n         # TODO: Fully implement this\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_NT_CREATE_ANDX)\n-        respParameters        = smb.SMBNtCreateAndXResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_NT_CREATE_ANDX)\n+        respParameters = smb.SMBNtCreateAndXResponse_Parameters()\n+        respData = b''\n \n         ntCreateAndXParameters = smb.SMBNtCreateAndX_Parameters(SMBCommand['Parameters'])\n-        ntCreateAndXData       = smb.SMBNtCreateAndX_Data( flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        ntCreateAndXData = smb.SMBNtCreateAndX_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n-        #if ntCreateAndXParameters['CreateFlags'] & 0x10:  # NT_CREATE_REQUEST_EXTENDED_RESPONSE\n+        # if ntCreateAndXParameters['CreateFlags'] & 0x10:  # NT_CREATE_REQUEST_EXTENDED_RESPONSE\n         #    respParameters        = smb.SMBNtCreateAndXExtendedResponse_Parameters()\n         #    respParameters['VolumeGUID'] = '\\x00'\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             # If we have a rootFid, the path is relative to that fid\n-             errorCode = STATUS_SUCCESS\n-             if ntCreateAndXParameters['RootFid'] > 0:\n-                 path = connData['OpenedFiles'][ntCreateAndXParameters['RootFid']]['FileName']\n-                 LOG.debug(\"RootFid present %s!\" % path)\n-             else:\n-                 if 'path' in connData['ConnectedShares'][recvPacket['Tid']]:\n-                     path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-                 else:\n-                     path = 'NONE'\n-                     errorCode = STATUS_ACCESS_DENIED\n-\n-             deleteOnClose = False\n-\n-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],ntCreateAndXData['FileName']).replace('\\\\','\/'))\n-             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+            # If we have a rootFid, the path is relative to that fid\n+            errorCode = STATUS_SUCCESS\n+            if ntCreateAndXParameters['RootFid'] > 0:\n+                path = connData['OpenedFiles'][ntCreateAndXParameters['RootFid']]['FileName']\n+                LOG.debug(\"RootFid present %s!\" % path)\n+            else:\n+                if 'path' in connData['ConnectedShares'][recvPacket['Tid']]:\n+                    path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+                else:\n+                    path = 'NONE'\n+                    errorCode = STATUS_ACCESS_DENIED\n+\n+            deleteOnClose = False\n+\n+            fileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], ntCreateAndXData['FileName']).replace('\\\\', '\/'))\n+            if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             createDisposition = ntCreateAndXParameters['Disposition']\n-             mode = 0\n-\n-             if createDisposition == smb.FILE_SUPERSEDE:\n-                 mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb.FILE_OVERWRITE_IF == smb.FILE_OVERWRITE_IF:\n-                 mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb.FILE_OVERWRITE == smb.FILE_OVERWRITE:\n-                 if os.path.exists(pathName) is True:\n-                     mode |= os.O_TRUNC \n-                 else:\n-                     errorCode = STATUS_NO_SUCH_FILE\n-             elif createDisposition & smb.FILE_OPEN_IF == smb.FILE_OPEN_IF:\n-                 if os.path.exists(pathName) is True:\n-                     mode |= os.O_TRUNC \n-                 else:\n-                     mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb.FILE_CREATE == smb.FILE_CREATE:\n-                 if os.path.exists(pathName) is True:\n-                     errorCode = STATUS_OBJECT_NAME_COLLISION\n-                 else:\n-                     mode |= os.O_CREAT\n-             elif createDisposition & smb.FILE_OPEN == smb.FILE_OPEN:\n-                 if os.path.exists(pathName) is not True and (str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:\n-                     errorCode = STATUS_NO_SUCH_FILE\n-\n-             if errorCode == STATUS_SUCCESS:\n-                 desiredAccess = ntCreateAndXParameters['AccessMask']\n-                 if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):\n-                     mode |= os.O_RDONLY\n-                 if (desiredAccess & smb.FILE_WRITE_DATA) or (desiredAccess & smb.GENERIC_WRITE):\n-                     if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):\n-                         mode |= os.O_RDWR #| os.O_APPEND\n-                     else: \n-                         mode |= os.O_WRONLY #| os.O_APPEND\n-                 if desiredAccess & smb.GENERIC_ALL:\n-                     mode |= os.O_RDWR #| os.O_APPEND\n-\n-                 createOptions =  ntCreateAndXParameters['CreateOptions']\n-                 if mode & os.O_CREAT == os.O_CREAT:\n-                     if createOptions & smb.FILE_DIRECTORY_FILE == smb.FILE_DIRECTORY_FILE: \n-                         try:\n-                             # Let's create the directory\n-                             os.mkdir(pathName)\n-                             mode = os.O_RDONLY\n-                         except Exception as e:\n-                             smbServer.log(\"NTCreateAndX: %s,%s,%s\" % (pathName,mode,e),logging.ERROR)\n-                             errorCode = STATUS_ACCESS_DENIED\n-                 if createOptions & smb.FILE_NON_DIRECTORY_FILE == smb.FILE_NON_DIRECTORY_FILE:\n-                     # If the file being opened is a directory, the server MUST fail the request with\n-                     # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server\n-                     # response.\n-                     if os.path.isdir(pathName) is True:\n+\n+            if not isInFileJail(path, fileName):\n+                LOG.error(\"Path not in current working directory\")\n+                respSMBCommand['Parameters'] = b''\n+                respSMBCommand['Data'] = b''\n+                return [respSMBCommand], None, STATUS_ACCESS_DENIED\n+\n+            pathName = os.path.join(path, fileName)\n+            createDisposition = ntCreateAndXParameters['Disposition']\n+            mode = 0\n+\n+            if createDisposition == smb.FILE_SUPERSEDE:\n+                mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb.FILE_OVERWRITE_IF == smb.FILE_OVERWRITE_IF:\n+                mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb.FILE_OVERWRITE == smb.FILE_OVERWRITE:\n+                if os.path.exists(pathName) is True:\n+                    mode |= os.O_TRUNC\n+                else:\n+                    errorCode = STATUS_NO_SUCH_FILE\n+            elif createDisposition & smb.FILE_OPEN_IF == smb.FILE_OPEN_IF:\n+                if os.path.exists(pathName) is True:\n+                    mode |= os.O_TRUNC\n+                else:\n+                    mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb.FILE_CREATE == smb.FILE_CREATE:\n+                if os.path.exists(pathName) is True:\n+                    errorCode = STATUS_OBJECT_NAME_COLLISION\n+                else:\n+                    mode |= os.O_CREAT\n+            elif createDisposition & smb.FILE_OPEN == smb.FILE_OPEN:\n+                if os.path.exists(pathName) is not True and (\n+                        str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:\n+                    errorCode = STATUS_NO_SUCH_FILE\n+\n+            if errorCode == STATUS_SUCCESS:\n+                desiredAccess = ntCreateAndXParameters['AccessMask']\n+                if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):\n+                    mode |= os.O_RDONLY\n+                if (desiredAccess & smb.FILE_WRITE_DATA) or (desiredAccess & smb.GENERIC_WRITE):\n+                    if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):\n+                        mode |= os.O_RDWR  # | os.O_APPEND\n+                    else:\n+                        mode |= os.O_WRONLY  # | os.O_APPEND\n+                if desiredAccess & smb.GENERIC_ALL:\n+                    mode |= os.O_RDWR  # | os.O_APPEND\n+\n+                createOptions = ntCreateAndXParameters['CreateOptions']\n+                if mode & os.O_CREAT == os.O_CREAT:\n+                    if createOptions & smb.FILE_DIRECTORY_FILE == smb.FILE_DIRECTORY_FILE:\n+                        try:\n+                            # Let's create the directory\n+                            os.mkdir(pathName)\n+                            mode = os.O_RDONLY\n+                        except Exception as e:\n+                            smbServer.log(\"NTCreateAndX: %s,%s,%s\" % (pathName, mode, e), logging.ERROR)\n+                            errorCode = STATUS_ACCESS_DENIED\n+                if createOptions & smb.FILE_NON_DIRECTORY_FILE == smb.FILE_NON_DIRECTORY_FILE:\n+                    # If the file being opened is a directory, the server MUST fail the request with\n+                    # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server\n+                    # response.\n+                    if os.path.isdir(pathName) is True:\n                         errorCode = STATUS_FILE_IS_A_DIRECTORY\n \n-                 if createOptions & smb.FILE_DELETE_ON_CLOSE == smb.FILE_DELETE_ON_CLOSE:\n-                     deleteOnClose = True\n-                 \n-                 if errorCode == STATUS_SUCCESS:\n-                     try:\n-                         if os.path.isdir(pathName) and sys.platform == 'win32':\n+                if createOptions & smb.FILE_DELETE_ON_CLOSE == smb.FILE_DELETE_ON_CLOSE:\n+                    deleteOnClose = True\n+\n+                if errorCode == STATUS_SUCCESS:\n+                    try:\n+                        if os.path.isdir(pathName) and sys.platform == 'win32':\n                             fid = VOID_FILE_DESCRIPTOR\n-                         else:\n+                        else:\n                             if sys.platform == 'win32':\n-                               mode |= os.O_BINARY\n+                                mode |= os.O_BINARY\n                             if str(pathName) in smbServer.getRegisteredNamedPipes():\n                                 fid = PIPE_FILE_DESCRIPTOR\n                                 sock = socket.socket()\n                                 sock.connect(smbServer.getRegisteredNamedPipes()[str(pathName)])\n                             else:\n                                 fid = os.open(pathName, mode)\n-                     except Exception as e:\n-                         smbServer.log(\"NTCreateAndX: %s,%s,%s\" % (pathName,mode,e),logging.ERROR)\n-                         #print e\n-                         fid = 0\n-                         errorCode = STATUS_ACCESS_DENIED\n+                    except Exception as e:\n+                        smbServer.log(\"NTCreateAndX: %s,%s,%s\" % (pathName, mode, e), logging.ERROR)\n+                        # print e\n+                        fid = 0\n+                        errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n         if errorCode == STATUS_SUCCESS:\n             # Simple way to generate a fid\n             if len(connData['OpenedFiles']) == 0:\n-               fakefid = 1\n+                fakefid = 1\n             else:\n-               fakefid = list(connData['OpenedFiles'].keys())[-1] + 1\n+                fakefid = list(connData['OpenedFiles'].keys())[-1] + 1\n             respParameters['Fid'] = fakefid\n             respParameters['CreateAction'] = createDisposition\n             if fid == PIPE_FILE_DESCRIPTOR:\n                 respParameters['FileAttributes'] = 0x80\n                 respParameters['IsDirectory'] = 0\n-                respParameters['CreateTime']     = 0\n+                respParameters['CreateTime'] = 0\n                 respParameters['LastAccessTime'] = 0\n-                respParameters['LastWriteTime']  = 0\n+                respParameters['LastWriteTime'] = 0\n                 respParameters['LastChangeTime'] = 0\n                 respParameters['AllocationSize'] = 4096\n-                respParameters['EndOfFile']      = 0\n-                respParameters['FileType']       = 2\n-                respParameters['IPCState']       = 0x5ff\n+                respParameters['EndOfFile'] = 0\n+                respParameters['FileType'] = 2\n+                respParameters['IPCState'] = 0x5ff\n             else:\n                 if os.path.isdir(pathName):\n                     respParameters['FileAttributes'] = smb.SMB_FILE_ATTRIBUTE_DIRECTORY\n@@ -2116,18 +2151,18 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n                     respParameters['IsDirectory'] = 0\n                     respParameters['FileAttributes'] = ntCreateAndXParameters['FileAttributes']\n                 # Let's get this file's information\n-                respInfo, errorCode = queryPathInformation('',pathName,level= smb.SMB_QUERY_FILE_ALL_INFO)\n+                respInfo, errorCode = queryPathInformation('', pathName, level=smb.SMB_QUERY_FILE_ALL_INFO)\n                 if errorCode == STATUS_SUCCESS:\n-                    respParameters['CreateTime']     = respInfo['CreationTime']\n+                    respParameters['CreateTime'] = respInfo['CreationTime']\n                     respParameters['LastAccessTime'] = respInfo['LastAccessTime']\n-                    respParameters['LastWriteTime']  = respInfo['LastWriteTime']\n+                    respParameters['LastWriteTime'] = respInfo['LastWriteTime']\n                     respParameters['LastChangeTime'] = respInfo['LastChangeTime']\n                     respParameters['FileAttributes'] = respInfo['ExtFileAttributes']\n                     respParameters['AllocationSize'] = respInfo['AllocationSize']\n-                    respParameters['EndOfFile']      = respInfo['EndOfFile']\n+                    respParameters['EndOfFile'] = respInfo['EndOfFile']\n                 else:\n                     respParameters = b''\n-                    respData       = b''\n+                    respData = b''\n \n             if errorCode == STATUS_SUCCESS:\n                 # Let's store the fid for the connection\n@@ -2135,15 +2170,15 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n                 connData['OpenedFiles'][fakefid] = {}\n                 connData['OpenedFiles'][fakefid]['FileHandle'] = fid\n                 connData['OpenedFiles'][fakefid]['FileName'] = pathName\n-                connData['OpenedFiles'][fakefid]['DeleteOnClose']  = deleteOnClose\n+                connData['OpenedFiles'][fakefid]['DeleteOnClose'] = deleteOnClose\n                 if fid == PIPE_FILE_DESCRIPTOR:\n                     connData['OpenedFiles'][fakefid]['Socket'] = sock\n         else:\n             respParameters = b''\n-            respData       = b''\n-        \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+            respData = b''\n+\n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -2152,31 +2187,32 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n     def smbComOpenAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_OPEN_ANDX)\n-        respParameters        = smb.SMBOpenAndXResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_OPEN_ANDX)\n+        respParameters = smb.SMBOpenAndXResponse_Parameters()\n+        respData = b''\n \n         openAndXParameters = smb.SMBOpenAndX_Parameters(SMBCommand['Parameters'])\n-        openAndXData       = smb.SMBOpenAndX_Data( flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        openAndXData = smb.SMBOpenAndX_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             openedFile, mode, pathName, errorCode = openFile(path,\n-                     decodeSMBString(recvPacket['Flags2'],openAndXData['FileName']), \n-                     openAndXParameters['DesiredAccess'], \n-                     openAndXParameters['FileAttributes'], \n-                     openAndXParameters['OpenMode'])\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            openedFile, mode, pathName, errorCode = openFile(path,\n+                                                             decodeSMBString(recvPacket['Flags2'],\n+                                                                             openAndXData['FileName']),\n+                                                             openAndXParameters['DesiredAccess'],\n+                                                             openAndXParameters['FileAttributes'],\n+                                                             openAndXParameters['OpenMode'])\n         else:\n-           errorCode = STATUS_SMB_BAD_TID\n+            errorCode = STATUS_SMB_BAD_TID\n \n         if errorCode == STATUS_SUCCESS:\n             # Simple way to generate a fid\n-            fid = len(connData['OpenedFiles']) + 1 \n+            fid = len(connData['OpenedFiles']) + 1\n             if len(connData['OpenedFiles']) == 0:\n-               fid = 1\n+                fid = 1\n             else:\n-               fid = list(connData['OpenedFiles'].keys())[-1] + 1\n+                fid = list(connData['OpenedFiles'].keys())[-1] + 1\n             respParameters['Fid'] = fid\n             if mode & os.O_CREAT:\n                 # File did not exist and was created\n@@ -2190,19 +2226,19 @@ def smbComOpenAndX(connId, smbServer, SMBCommand, recvPacket):\n             else:\n                 # File existed and was truncated\n                 respParameters['Action'] = 0x3\n-            \n+\n             # Let's store the fid for the connection\n-            #smbServer.log('Opening file %s' % pathName)\n+            # smbServer.log('Opening file %s' % pathName)\n             connData['OpenedFiles'][fid] = {}\n             connData['OpenedFiles'][fid]['FileHandle'] = openedFile\n             connData['OpenedFiles'][fid]['FileName'] = pathName\n-            connData['OpenedFiles'][fid]['DeleteOnClose']  = False\n+            connData['OpenedFiles'][fid]['DeleteOnClose'] = False\n         else:\n             respParameters = b''\n-            respData       = b''\n-        \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+            respData = b''\n+\n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -2213,22 +2249,23 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):\n \n         resp = smb.NewSMBPacket()\n         resp['Flags1'] = smb.SMB.FLAGS1_REPLY\n-        resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | recvPacket['Flags2'] & smb.SMB.FLAGS2_UNICODE\n+        resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | \\\n+                         recvPacket['Flags2'] & smb.SMB.FLAGS2_UNICODE\n \n         resp['Tid'] = recvPacket['Tid']\n         resp['Mid'] = recvPacket['Mid']\n         resp['Pid'] = connData['Pid']\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_TREE_CONNECT_ANDX)\n-        respParameters        = smb.SMBTreeConnectAndXResponse_Parameters()\n-        respData              = smb.SMBTreeConnectAndXResponse_Data()\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_TREE_CONNECT_ANDX)\n+        respParameters = smb.SMBTreeConnectAndXResponse_Parameters()\n+        respData = smb.SMBTreeConnectAndXResponse_Data()\n \n         treeConnectAndXParameters = smb.SMBTreeConnectAndX_Parameters(SMBCommand['Parameters'])\n \n         if treeConnectAndXParameters['Flags'] & 0x8:\n-            respParameters        = smb.SMBTreeConnectAndXExtendedResponse_Parameters()\n+            respParameters = smb.SMBTreeConnectAndXExtendedResponse_Parameters()\n \n-        treeConnectAndXData                    = smb.SMBTreeConnectAndX_Data( flags = recvPacket['Flags2'] )\n+        treeConnectAndXData = smb.SMBTreeConnectAndX_Data(flags=recvPacket['Flags2'])\n         treeConnectAndXData['_PasswordLength'] = treeConnectAndXParameters['PasswordLength']\n         treeConnectAndXData.fromString(SMBCommand['Data'])\n \n@@ -2243,34 +2280,34 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):\n         else:\n             path = ntpath.basename(UNCOrShare)\n \n-        share = searchShare(connId, path, smbServer) \n+        share = searchShare(connId, path, smbServer)\n         if share is not None:\n             # Simple way to generate a Tid\n             if len(connData['ConnectedShares']) == 0:\n-               tid = 1\n+                tid = 1\n             else:\n-               tid = list(connData['ConnectedShares'].keys())[-1] + 1\n+                tid = list(connData['ConnectedShares'].keys())[-1] + 1\n             connData['ConnectedShares'][tid] = share\n             connData['ConnectedShares'][tid]['shareName'] = path\n             resp['Tid'] = tid\n-            #smbServer.log(\"Connecting Share(%d:%s)\" % (tid,path))\n+            # smbServer.log(\"Connecting Share(%d:%s)\" % (tid,path))\n         else:\n             smbServer.log(\"TreeConnectAndX not found %s\" % path, logging.ERROR)\n             errorCode = STATUS_OBJECT_PATH_NOT_FOUND\n-            resp['ErrorCode']   = errorCode >> 16\n-            resp['ErrorClass']  = errorCode & 0xff\n+            resp['ErrorCode'] = errorCode >> 16\n+            resp['ErrorClass'] = errorCode & 0xff\n         ##\n         respParameters['OptionalSupport'] = smb.SMB.SMB_SUPPORT_SEARCH_BITS\n \n         if path == 'IPC$':\n-            respData['Service']               = 'IPC'\n+            respData['Service'] = 'IPC'\n         else:\n-            respData['Service']               = path\n-        respData['PadLen']                = 0\n-        respData['NativeFileSystem']      = encodeSMBString(recvPacket['Flags2'], 'NTFS' ).decode()\n+            respData['Service'] = path\n+        respData['PadLen'] = 0\n+        respData['NativeFileSystem'] = encodeSMBString(recvPacket['Flags2'], 'NTFS').decode()\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         resp['Uid'] = connData['Uid']\n         resp.addCommand(respSMBCommand)\n@@ -2284,19 +2321,19 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):\n \n     @staticmethod\n     def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n-        connData = smbServer.getConnectionData(connId, checkStatus = False)\n+        connData = smbServer.getConnectionData(connId, checkStatus=False)\n \n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_SESSION_SETUP_ANDX)\n \n         # From [MS-SMB]\n-        # When extended security is being used (see section 3.2.4.2.4), the \n+        # When extended security is being used (see section 3.2.4.2.4), the\n         # request MUST take the following form\n         # [..]\n         # WordCount (1 byte): The value of this field MUST be 0x0C.\n         if SMBCommand['WordCount'] == 12:\n             # Extended security. Here we deal with all SPNEGO stuff\n             respParameters = smb.SMBSessionSetupAndX_Extended_Response_Parameters()\n-            respData       = smb.SMBSessionSetupAndX_Extended_Response_Data(flags = recvPacket['Flags2'])\n+            respData = smb.SMBSessionSetupAndX_Extended_Response_Data(flags=recvPacket['Flags2'])\n             sessionSetupParameters = smb.SMBSessionSetupAndX_Extended_Parameters(SMBCommand['Parameters'])\n             sessionSetupData = smb.SMBSessionSetupAndX_Extended_Data()\n             sessionSetupData['SecurityBlobLength'] = sessionSetupParameters['SecurityBlobLength']\n@@ -2304,45 +2341,45 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n             connData['Capabilities'] = sessionSetupParameters['Capabilities']\n \n             rawNTLM = False\n-            if struct.unpack('B',sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_AID:\n-               # NEGOTIATE packet\n-               blob =  SPNEGO_NegTokenInit(sessionSetupData['SecurityBlob'])\n-               token = blob['MechToken']\n-               if len(blob['MechTypes'][0]) > 0:\n-                   # Is this GSSAPI NTLM or something else we don't support?\n-                   mechType = blob['MechTypes'][0]\n-                   if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:\n-                       # Nope, do we know it?\n-                       if mechType in MechTypes:\n-                           mechStr = MechTypes[mechType]\n-                       else:\n-                           mechStr = hexlify(mechType)\n-                       smbServer.log(\"Unsupported MechType '%s'\" % mechStr, logging.CRITICAL)\n-                       # We don't know the token, we answer back again saying \n-                       # we just support NTLM.\n-                       # ToDo: Build this into a SPNEGO_NegTokenResp()\n-                       respToken = b'\\xa1\\x15\\x30\\x13\\xa0\\x03\\x0a\\x01\\x03\\xa1\\x0c\\x06\\x0a\\x2b\\x06\\x01\\x04\\x01\\x82\\x37\\x02\\x02\\x0a'\n-                       respParameters['SecurityBlobLength'] = len(respToken)\n-                       respData['SecurityBlobLength'] = respParameters['SecurityBlobLength'] \n-                       respData['SecurityBlob']       = respToken\n-                       respData['NativeOS']     = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n-                       respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n-                       respSMBCommand['Parameters'] = respParameters\n-                       respSMBCommand['Data']       = respData \n-                       return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED\n-\n-            elif struct.unpack('B',sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_SUPPORTED_MECH:\n-               # AUTH packet\n-               blob = SPNEGO_NegTokenResp(sessionSetupData['SecurityBlob'])\n-               token = blob['ResponseToken']\n+            if struct.unpack('B', sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_AID:\n+                # NEGOTIATE packet\n+                blob = SPNEGO_NegTokenInit(sessionSetupData['SecurityBlob'])\n+                token = blob['MechToken']\n+                if len(blob['MechTypes'][0]) > 0:\n+                    # Is this GSSAPI NTLM or something else we don't support?\n+                    mechType = blob['MechTypes'][0]\n+                    if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:\n+                        # Nope, do we know it?\n+                        if mechType in MechTypes:\n+                            mechStr = MechTypes[mechType]\n+                        else:\n+                            mechStr = hexlify(mechType)\n+                        smbServer.log(\"Unsupported MechType '%s'\" % mechStr, logging.CRITICAL)\n+                        # We don't know the token, we answer back again saying\n+                        # we just support NTLM.\n+                        # ToDo: Build this into a SPNEGO_NegTokenResp()\n+                        respToken = b'\\xa1\\x15\\x30\\x13\\xa0\\x03\\x0a\\x01\\x03\\xa1\\x0c\\x06\\x0a\\x2b\\x06\\x01\\x04\\x01\\x82\\x37\\x02\\x02\\x0a'\n+                        respParameters['SecurityBlobLength'] = len(respToken)\n+                        respData['SecurityBlobLength'] = respParameters['SecurityBlobLength']\n+                        respData['SecurityBlob'] = respToken\n+                        respData['NativeOS'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n+                        respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n+                        respSMBCommand['Parameters'] = respParameters\n+                        respSMBCommand['Data'] = respData\n+                        return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED\n+\n+            elif struct.unpack('B', sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_SUPPORTED_MECH:\n+                # AUTH packet\n+                blob = SPNEGO_NegTokenResp(sessionSetupData['SecurityBlob'])\n+                token = blob['ResponseToken']\n             else:\n-               # No GSSAPI stuff, raw NTLMSSP\n-               rawNTLM = True\n-               token = sessionSetupData['SecurityBlob']\n+                # No GSSAPI stuff, raw NTLMSSP\n+                rawNTLM = True\n+                token = sessionSetupData['SecurityBlob']\n \n-            # Here we only handle NTLMSSP, depending on what stage of the \n+            # Here we only handle NTLMSSP, depending on what stage of the\n             # authentication we are, we act on it\n-            messageType = struct.unpack('<L',token[len('NTLMSSP\\x00'):len('NTLMSSP\\x00')+4])[0]\n+            messageType = struct.unpack('<L', token[len('NTLMSSP\\x00'):len('NTLMSSP\\x00') + 4])[0]\n \n             if messageType == 0x01:\n                 # NEGOTIATE_MESSAGE\n@@ -2351,45 +2388,48 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                 # Let's store it in the connection data\n                 connData['NEGOTIATE_MESSAGE'] = negotiateMessage\n                 # Let's build the answer flags\n-                # TODO: Parse all the flags. With this we're leaving some clients out \n+                # TODO: Parse all the flags. With this we're leaving some clients out\n \n                 ansFlags = 0\n \n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_56:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56\n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_128:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128\n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH\n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_UNICODE:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE\n                 if negotiateMessage['flags'] & ntlm.NTLM_NEGOTIATE_OEM:\n-                   ansFlags |= ntlm.NTLM_NEGOTIATE_OEM\n+                    ansFlags |= ntlm.NTLM_NEGOTIATE_OEM\n \n                 ansFlags |= ntlm.NTLMSSP_NEGOTIATE_VERSION | ntlm.NTLMSSP_NEGOTIATE_TARGET_INFO | ntlm.NTLMSSP_TARGET_TYPE_SERVER | ntlm.NTLMSSP_NEGOTIATE_NTLM | ntlm.NTLMSSP_REQUEST_TARGET\n \n                 # Generate the AV_PAIRS\n                 av_pairs = ntlm.AV_PAIRS()\n                 # TODO: Put the proper data from SMBSERVER config\n-                av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')\n-                av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')\n-                av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (116444736000000000 + calendar.timegm(time.gmtime()) * 10000000) )\n+                av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[\n+                    ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')\n+                av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[\n+                    ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')\n+                av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (\n+                            116444736000000000 + calendar.timegm(time.gmtime()) * 10000000))\n \n                 challengeMessage = ntlm.NTLMAuthChallenge()\n-                challengeMessage['flags']            = ansFlags\n-                challengeMessage['domain_len']       = len(smbServer.getServerDomain().encode('utf-16le'))\n-                challengeMessage['domain_max_len']   = challengeMessage['domain_len']\n-                challengeMessage['domain_offset']    = 40 + 16\n-                challengeMessage['challenge']        = smbServer.getSMBChallenge()\n-                challengeMessage['domain_name']      = smbServer.getServerDomain().encode('utf-16le')\n-                challengeMessage['TargetInfoFields_len']     = len(av_pairs)\n+                challengeMessage['flags'] = ansFlags\n+                challengeMessage['domain_len'] = len(smbServer.getServerDomain().encode('utf-16le'))\n+                challengeMessage['domain_max_len'] = challengeMessage['domain_len']\n+                challengeMessage['domain_offset'] = 40 + 16\n+                challengeMessage['challenge'] = smbServer.getSMBChallenge()\n+                challengeMessage['domain_name'] = smbServer.getServerDomain().encode('utf-16le')\n+                challengeMessage['TargetInfoFields_len'] = len(av_pairs)\n                 challengeMessage['TargetInfoFields_max_len'] = len(av_pairs)\n                 challengeMessage['TargetInfoFields'] = av_pairs\n-                challengeMessage['TargetInfoFields_offset']  = 40 + 16 + len(challengeMessage['domain_name'])\n-                challengeMessage['Version']          = b'\\xff'*8\n-                challengeMessage['VersionLen']       = 8\n+                challengeMessage['TargetInfoFields_offset'] = 40 + 16 + len(challengeMessage['domain_name'])\n+                challengeMessage['Version'] = b'\\xff' * 8\n+                challengeMessage['VersionLen'] = 8\n \n                 if rawNTLM is False:\n                     respToken = SPNEGO_NegTokenResp()\n@@ -2403,7 +2443,7 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n \n                 # Setting the packet to STATUS_MORE_PROCESSING\n                 errorCode = STATUS_MORE_PROCESSING_REQUIRED\n-                # Let's set up an UID for this connection and store it \n+                # Let's set up an UID for this connection and store it\n                 # in the connection's data\n                 # Picking a fixed value\n                 # TODO: Manage more UIDs for the same session\n@@ -2419,9 +2459,9 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                 authenticateMessage = ntlm.NTLMAuthChallengeResponse()\n                 authenticateMessage.fromString(token)\n                 smbServer.log(\"AUTHENTICATE_MESSAGE (%s\\\\%s,%s)\" % (\n-                authenticateMessage['domain_name'].decode('utf-16le'),\n-                authenticateMessage['user_name'].decode('utf-16le'),\n-                authenticateMessage['host_name'].decode('utf-16le')))\n+                    authenticateMessage['domain_name'].decode('utf-16le'),\n+                    authenticateMessage['user_name'].decode('utf-16le'),\n+                    authenticateMessage['host_name'].decode('utf-16le')))\n                 # Do we have credentials to check?\n                 if len(smbServer.getCredentials()) > 0:\n                     identity = authenticateMessage['user_name'].decode('utf-16le').lower()\n@@ -2432,7 +2472,8 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                         uid, lmhash, nthash = smbServer.getCredentials()[identity]\n \n                         errorCode, sessionKey = computeNTLMv2(identity, lmhash, nthash, smbServer.getSMBChallenge(),\n-                                             authenticateMessage, connData['CHALLENGE_MESSAGE'], connData['NEGOTIATE_MESSAGE'])\n+                                                              authenticateMessage, connData['CHALLENGE_MESSAGE'],\n+                                                              connData['NEGOTIATE_MESSAGE'])\n \n                         if sessionKey is not None:\n                             connData['SignatureEnabled'] = False\n@@ -2450,8 +2491,10 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                     # accept-completed\n                     respToken['NegState'] = b'\\x00'\n \n-                    smbServer.log('User %s\\\\%s authenticated successfully' % (authenticateMessage['host_name'].decode('utf-16le'),\n-                                                                              authenticateMessage['user_name'].decode('utf-16le')))\n+                    smbServer.log(\n+                        'User %s\\\\%s authenticated successfully' % (authenticateMessage['host_name'].decode('utf-16le'),\n+                                                                    authenticateMessage['user_name'].decode(\n+                                                                        'utf-16le')))\n                     # Let's store it in the connection data\n                     connData['AUTHENTICATE_MESSAGE'] = authenticateMessage\n                     try:\n@@ -2462,7 +2505,8 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                                                             authenticateMessage['lanman'], authenticateMessage['ntlm'])\n                         smbServer.log(ntlm_hash_data['hash_string'])\n                         if jtr_dump_path != '':\n-                            writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'], jtr_dump_path)\n+                            writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'],\n+                                                  jtr_dump_path)\n                     except:\n                         smbServer.log(\"Could not write NTLM Hashes to the specified JTR_Dump_Path %s\" % jtr_dump_path)\n                 else:\n@@ -2473,13 +2517,13 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                 raise Exception(\"Unknown NTLMSSP MessageType %d\" % messageType)\n \n             respParameters['SecurityBlobLength'] = len(respToken)\n-            respData['SecurityBlobLength'] = respParameters['SecurityBlobLength'] \n-            respData['SecurityBlob']       = respToken.getData()\n+            respData['SecurityBlobLength'] = respParameters['SecurityBlobLength']\n+            respData['SecurityBlob'] = respToken.getData()\n \n         else:\n             # Process Standard Security\n             respParameters = smb.SMBSessionSetupAndXResponse_Parameters()\n-            respData       = smb.SMBSessionSetupAndXResponse_Data()\n+            respData = smb.SMBSessionSetupAndXResponse_Data()\n             sessionSetupParameters = smb.SMBSessionSetupAndX_Parameters(SMBCommand['Parameters'])\n             sessionSetupData = smb.SMBSessionSetupAndX_Data()\n             sessionSetupData['AnsiPwdLength'] = sessionSetupParameters['AnsiPwdLength']\n@@ -2492,38 +2536,41 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n             connData['Uid'] = 10\n             connData['Authenticated'] = True\n             respParameters['Action'] = 0\n-            smbServer.log('User %s\\\\%s authenticated successfully (basic)' % (sessionSetupData['PrimaryDomain'], sessionSetupData['Account']))\n+            smbServer.log('User %s\\\\%s authenticated successfully (basic)' % (\n+            sessionSetupData['PrimaryDomain'], sessionSetupData['Account']))\n             try:\n                 jtr_dump_path = smbServer.getJTRdumpPath()\n-                ntlm_hash_data = outputToJohnFormat( b'', b(sessionSetupData['Account']), b(sessionSetupData['PrimaryDomain']), sessionSetupData['AnsiPwd'], sessionSetupData['UnicodePwd'] )\n+                ntlm_hash_data = outputToJohnFormat(b'', b(sessionSetupData['Account']),\n+                                                    b(sessionSetupData['PrimaryDomain']), sessionSetupData['AnsiPwd'],\n+                                                    sessionSetupData['UnicodePwd'])\n                 smbServer.log(ntlm_hash_data['hash_string'])\n                 if jtr_dump_path != '':\n                     writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'], jtr_dump_path)\n             except:\n                 smbServer.log(\"Could not write NTLM Hashes to the specified JTR_Dump_Path %s\" % jtr_dump_path)\n \n-        respData['NativeOS']     = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n+        respData['NativeOS'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n         respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n         respSMBCommand['Parameters'] = respParameters\n-        respSMBCommand['Data']       = respData \n+        respSMBCommand['Data'] = respData\n \n         # From now on, the client can ask for other commands\n         connData['Authenticated'] = True\n         # For now, just switching to nobody\n-        #os.setregid(65534,65534)\n-        #os.setreuid(65534,65534)\n+        # os.setregid(65534,65534)\n+        # os.setreuid(65534,65534)\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n     @staticmethod\n-    def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket ):\n-        connData = smbServer.getConnectionData(connId, checkStatus = False)\n+    def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket):\n+        connData = smbServer.getConnectionData(connId, checkStatus=False)\n         connData['Pid'] = recvPacket['Pid']\n \n         SMBCommand = smb.SMBCommand(recvPacket['Data'][0])\n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_NEGOTIATE)\n-        \n+\n         resp = smb.NewSMBPacket()\n         resp['Flags1'] = smb.SMB.FLAGS1_REPLY\n         resp['Pid'] = connData['Pid']\n@@ -2532,108 +2579,107 @@ def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket ):\n \n         # TODO: We support more dialects, and parse them accordingly\n         dialects = SMBCommand['Data'].split(b'\\x02')\n-        try: \n-           index = dialects.index(b'NT LM 0.12\\x00') - 1\n-           # Let's fill the data for NTLM\n-           if recvPacket['Flags2'] & smb.SMB.FLAGS2_EXTENDED_SECURITY:\n-                    resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE\n-                    #resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS \n-                    _dialects_data = smb.SMBExtended_Security_Data()\n-                    _dialects_data['ServerGUID'] = b'A'*16\n-                    blob = SPNEGO_NegTokenInit()\n-                    blob['MechTypes'] = [TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']]\n-                    _dialects_data['SecurityBlob'] = blob.getData()\n-        \n-                    _dialects_parameters = smb.SMBExtended_Security_Parameters()\n-                    _dialects_parameters['Capabilities']    = smb.SMB.CAP_EXTENDED_SECURITY | smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS | smb.SMB.CAP_UNICODE \n-                    _dialects_parameters['ChallengeLength'] = 0\n-\n-           else:\n-                    resp['Flags2'] = smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE\n-                    _dialects_parameters = smb.SMBNTLMDialect_Parameters()\n-                    _dialects_data= smb.SMBNTLMDialect_Data()\n-                    _dialects_data['Payload'] = ''\n-                    if 'EncryptionKey' in connData:\n-                        _dialects_data['Challenge'] = connData['EncryptionKey']\n-                        _dialects_parameters['ChallengeLength'] = len(_dialects_data.getData())\n-                    else:\n-                        # TODO: Handle random challenges, now one that can be used with rainbow tables\n-                        _dialects_data['Challenge'] = b'\\x11\\x22\\x33\\x44\\x55\\x66\\x77\\x88'\n-                        _dialects_parameters['ChallengeLength'] = 8\n-                    _dialects_parameters['Capabilities']    = smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS \n-\n-           # Let's see if we need to support RPC_REMOTE_APIS\n-           config = smbServer.getServerConfig()\n-           if config.has_option('global','rpc_apis'):\n-               if config.getboolean('global', 'rpc_apis') is True:\n-                  _dialects_parameters['Capabilities'] |= smb.SMB.CAP_RPC_REMOTE_APIS\n-\n-           _dialects_parameters['DialectIndex']    = index\n-           #_dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER | smb.SMB.SECURITY_SIGNATURES_REQUIRED\n-           _dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER\n-           _dialects_parameters['MaxMpxCount']     = 1\n-           _dialects_parameters['MaxNumberVcs']    = 1\n-           _dialects_parameters['MaxBufferSize']   = 64000\n-           _dialects_parameters['MaxRawSize']      = 65536\n-           _dialects_parameters['SessionKey']      = 0\n-           _dialects_parameters['LowDateTime']     = 0\n-           _dialects_parameters['HighDateTime']    = 0\n-           _dialects_parameters['ServerTimeZone']  = 0 \n-\n-\n-           respSMBCommand['Data']           = _dialects_data\n-           respSMBCommand['Parameters']     = _dialects_parameters\n-           connData['_dialects_data']       = _dialects_data\n-           connData['_dialects_parameters'] = _dialects_parameters\n+        try:\n+            index = dialects.index(b'NT LM 0.12\\x00') - 1\n+            # Let's fill the data for NTLM\n+            if recvPacket['Flags2'] & smb.SMB.FLAGS2_EXTENDED_SECURITY:\n+                resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE\n+                # resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS\n+                _dialects_data = smb.SMBExtended_Security_Data()\n+                _dialects_data['ServerGUID'] = b'A' * 16\n+                blob = SPNEGO_NegTokenInit()\n+                blob['MechTypes'] = [TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']]\n+                _dialects_data['SecurityBlob'] = blob.getData()\n+\n+                _dialects_parameters = smb.SMBExtended_Security_Parameters()\n+                _dialects_parameters[\n+                    'Capabilities'] = smb.SMB.CAP_EXTENDED_SECURITY | smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS | smb.SMB.CAP_UNICODE\n+                _dialects_parameters['ChallengeLength'] = 0\n+\n+            else:\n+                resp['Flags2'] = smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE\n+                _dialects_parameters = smb.SMBNTLMDialect_Parameters()\n+                _dialects_data = smb.SMBNTLMDialect_Data()\n+                _dialects_data['Payload'] = ''\n+                if 'EncryptionKey' in connData:\n+                    _dialects_data['Challenge'] = connData['EncryptionKey']\n+                    _dialects_parameters['ChallengeLength'] = len(_dialects_data.getData())\n+                else:\n+                    # TODO: Handle random challenges, now one that can be used with rainbow tables\n+                    _dialects_data['Challenge'] = b'\\x11\\x22\\x33\\x44\\x55\\x66\\x77\\x88'\n+                    _dialects_parameters['ChallengeLength'] = 8\n+                _dialects_parameters['Capabilities'] = smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS\n+\n+                # Let's see if we need to support RPC_REMOTE_APIS\n+            config = smbServer.getServerConfig()\n+            if config.has_option('global', 'rpc_apis'):\n+                if config.getboolean('global', 'rpc_apis') is True:\n+                    _dialects_parameters['Capabilities'] |= smb.SMB.CAP_RPC_REMOTE_APIS\n+\n+            _dialects_parameters['DialectIndex'] = index\n+            # _dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER | smb.SMB.SECURITY_SIGNATURES_REQUIRED\n+            _dialects_parameters['SecurityMode'] = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER\n+            _dialects_parameters['MaxMpxCount'] = 1\n+            _dialects_parameters['MaxNumberVcs'] = 1\n+            _dialects_parameters['MaxBufferSize'] = 64000\n+            _dialects_parameters['MaxRawSize'] = 65536\n+            _dialects_parameters['SessionKey'] = 0\n+            _dialects_parameters['LowDateTime'] = 0\n+            _dialects_parameters['HighDateTime'] = 0\n+            _dialects_parameters['ServerTimeZone'] = 0\n+\n+            respSMBCommand['Data'] = _dialects_data\n+            respSMBCommand['Parameters'] = _dialects_parameters\n+            connData['_dialects_data'] = _dialects_data\n+            connData['_dialects_parameters'] = _dialects_parameters\n \n         except Exception as e:\n-           # No NTLM throw an error\n-           smbServer.log('smbComNegotiate: %s' % e, logging.ERROR)\n-           respSMBCommand['Data'] = struct.pack('<H',0xffff) \n+            # No NTLM throw an error\n+            smbServer.log('smbComNegotiate: %s' % e, logging.ERROR)\n+            respSMBCommand['Data'] = struct.pack('<H', 0xffff)\n \n-       \n         smbServer.setConnectionData(connId, connData)\n \n         resp.addCommand(respSMBCommand)\n-        \n+\n         return None, [resp], STATUS_SUCCESS\n \n     @staticmethod\n     def default(connId, smbServer, SMBCommand, recvPacket):\n         # By default we return an SMB Packet with error not implemented\n-        smbServer.log(\"Not implemented command: 0x%x\" % recvPacket['Command'],logging.DEBUG)\n+        smbServer.log(\"Not implemented command: 0x%x\" % recvPacket['Command'], logging.DEBUG)\n         packet = smb.NewSMBPacket()\n-        packet['Flags1']  = smb.SMB.FLAGS1_REPLY\n-        packet['Flags2']  = smb.SMB.FLAGS2_NT_STATUS \n+        packet['Flags1'] = smb.SMB.FLAGS1_REPLY\n+        packet['Flags2'] = smb.SMB.FLAGS2_NT_STATUS\n         packet['Command'] = recvPacket['Command']\n-        packet['Pid']     = recvPacket['Pid']\n-        packet['Tid']     = recvPacket['Tid']\n-        packet['Mid']     = recvPacket['Mid']\n-        packet['Uid']     = recvPacket['Uid']\n-        packet['Data']    = b'\\x00\\x00\\x00'\n+        packet['Pid'] = recvPacket['Pid']\n+        packet['Tid'] = recvPacket['Tid']\n+        packet['Mid'] = recvPacket['Mid']\n+        packet['Uid'] = recvPacket['Uid']\n+        packet['Data'] = b'\\x00\\x00\\x00'\n         errorCode = STATUS_NOT_IMPLEMENTED\n-        packet['ErrorCode']   = errorCode >> 16\n-        packet['ErrorClass']  = errorCode & 0xff\n+        packet['ErrorCode'] = errorCode >> 16\n+        packet['ErrorClass'] = errorCode & 0xff\n \n         return None, [packet], errorCode\n \n+\n class SMB2Commands:\n     @staticmethod\n-    def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n-        connData = smbServer.getConnectionData(connId, checkStatus = False)\n+    def smb2Negotiate(connId, smbServer, recvPacket, isSMB1=False):\n+        connData = smbServer.getConnectionData(connId, checkStatus=False)\n \n         respPacket = smb2.SMB2Packet()\n-        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n-        respPacket['Status']    = STATUS_SUCCESS\n+        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n+        respPacket['Status'] = STATUS_SUCCESS\n         respPacket['CreditRequestResponse'] = 1\n-        respPacket['Command']   = smb2.SMB2_NEGOTIATE\n+        respPacket['Command'] = smb2.SMB2_NEGOTIATE\n         respPacket['SessionID'] = 0\n         if isSMB1 is False:\n             respPacket['MessageID'] = recvPacket['MessageID']\n         else:\n             respPacket['MessageID'] = 0\n-        respPacket['TreeID']    = 0\n-\n+        respPacket['TreeID'] = 0\n \n         respSMBCommand = smb2.SMB2Negotiate_Response()\n \n@@ -2641,7 +2687,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n         if isSMB1 is True:\n             # Let's first parse the packet to see if the client supports SMB2\n             SMBCommand = smb.SMBCommand(recvPacket['Data'][0])\n-        \n+\n             dialects = SMBCommand['Data'].split(b'\\x02')\n             if b'SMB 2.002\\x00' in dialects or b'SMB 2.???\\x00' in dialects:\n                 respSMBCommand['DialectRevision'] = smb2.SMB2_DIALECT_002\n@@ -2650,7 +2696,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n                 raise Exception('SMB2 not supported, fallbacking')\n         else:\n             respSMBCommand['DialectRevision'] = smb2.SMB2_DIALECT_002\n-        respSMBCommand['ServerGuid'] = b'A'*16\n+        respSMBCommand['ServerGuid'] = b'A' * 16\n         respSMBCommand['Capabilities'] = 0\n         respSMBCommand['MaxTransactSize'] = 65536\n         respSMBCommand['MaxReadSize'] = 65536\n@@ -2665,7 +2711,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n         respSMBCommand['Buffer'] = blob.getData()\n         respSMBCommand['SecurityBufferLength'] = len(respSMBCommand['Buffer'])\n \n-        respPacket['Data']      = respSMBCommand\n+        respPacket['Data'] = respSMBCommand\n \n         smbServer.setConnectionData(connId, connData)\n \n@@ -2673,7 +2719,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n \n     @staticmethod\n     def smb2SessionSetup(connId, smbServer, recvPacket):\n-        connData = smbServer.getConnectionData(connId, checkStatus = False)\n+        connData = smbServer.getConnectionData(connId, checkStatus=False)\n \n         respSMBCommand = smb2.SMB2SessionSetup_Response()\n \n@@ -2684,41 +2730,41 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n         securityBlob = sessionSetupData['Buffer']\n \n         rawNTLM = False\n-        if struct.unpack('B',securityBlob[0:1])[0] == ASN1_AID:\n-           # NEGOTIATE packet\n-           blob =  SPNEGO_NegTokenInit(securityBlob)\n-           token = blob['MechToken']\n-           if len(blob['MechTypes'][0]) > 0:\n-               # Is this GSSAPI NTLM or something else we don't support?\n-               mechType = blob['MechTypes'][0]\n-               if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:\n-                   # Nope, do we know it?\n-                   if mechType in MechTypes:\n-                       mechStr = MechTypes[mechType]\n-                   else:\n-                       mechStr = hexlify(mechType)\n-                   smbServer.log(\"Unsupported MechType '%s'\" % mechStr, logging.CRITICAL)\n-                   # We don't know the token, we answer back again saying \n-                   # we just support NTLM.\n-                   # ToDo: Build this into a SPNEGO_NegTokenResp()\n-                   respToken = b'\\xa1\\x15\\x30\\x13\\xa0\\x03\\x0a\\x01\\x03\\xa1\\x0c\\x06\\x0a\\x2b\\x06\\x01\\x04\\x01\\x82\\x37\\x02\\x02\\x0a'\n-                   respSMBCommand['SecurityBufferOffset'] = 0x48\n-                   respSMBCommand['SecurityBufferLength'] = len(respToken)\n-                   respSMBCommand['Buffer'] = respToken\n-\n-                   return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED\n-        elif struct.unpack('B',securityBlob[0:1])[0] == ASN1_SUPPORTED_MECH:\n-           # AUTH packet\n-           blob = SPNEGO_NegTokenResp(securityBlob)\n-           token = blob['ResponseToken']\n+        if struct.unpack('B', securityBlob[0:1])[0] == ASN1_AID:\n+            # NEGOTIATE packet\n+            blob = SPNEGO_NegTokenInit(securityBlob)\n+            token = blob['MechToken']\n+            if len(blob['MechTypes'][0]) > 0:\n+                # Is this GSSAPI NTLM or something else we don't support?\n+                mechType = blob['MechTypes'][0]\n+                if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:\n+                    # Nope, do we know it?\n+                    if mechType in MechTypes:\n+                        mechStr = MechTypes[mechType]\n+                    else:\n+                        mechStr = hexlify(mechType)\n+                    smbServer.log(\"Unsupported MechType '%s'\" % mechStr, logging.CRITICAL)\n+                    # We don't know the token, we answer back again saying\n+                    # we just support NTLM.\n+                    # ToDo: Build this into a SPNEGO_NegTokenResp()\n+                    respToken = b'\\xa1\\x15\\x30\\x13\\xa0\\x03\\x0a\\x01\\x03\\xa1\\x0c\\x06\\x0a\\x2b\\x06\\x01\\x04\\x01\\x82\\x37\\x02\\x02\\x0a'\n+                    respSMBCommand['SecurityBufferOffset'] = 0x48\n+                    respSMBCommand['SecurityBufferLength'] = len(respToken)\n+                    respSMBCommand['Buffer'] = respToken\n+\n+                    return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED\n+        elif struct.unpack('B', securityBlob[0:1])[0] == ASN1_SUPPORTED_MECH:\n+            # AUTH packet\n+            blob = SPNEGO_NegTokenResp(securityBlob)\n+            token = blob['ResponseToken']\n         else:\n-           # No GSSAPI stuff, raw NTLMSSP\n-           rawNTLM = True\n-           token = securityBlob\n+            # No GSSAPI stuff, raw NTLMSSP\n+            rawNTLM = True\n+            token = securityBlob\n \n-        # Here we only handle NTLMSSP, depending on what stage of the \n+        # Here we only handle NTLMSSP, depending on what stage of the\n         # authentication we are, we act on it\n-        messageType = struct.unpack('<L',token[len('NTLMSSP\\x00'):len('NTLMSSP\\x00')+4])[0]\n+        messageType = struct.unpack('<L', token[len('NTLMSSP\\x00'):len('NTLMSSP\\x00') + 4])[0]\n \n         if messageType == 0x01:\n             # NEGOTIATE_MESSAGE\n@@ -2727,45 +2773,48 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n             # Let's store it in the connection data\n             connData['NEGOTIATE_MESSAGE'] = negotiateMessage\n             # Let's build the answer flags\n-            # TODO: Parse all the flags. With this we're leaving some clients out \n+            # TODO: Parse all the flags. With this we're leaving some clients out\n \n             ansFlags = 0\n \n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_56:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56\n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_128:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128\n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH\n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_UNICODE:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE\n             if negotiateMessage['flags'] & ntlm.NTLM_NEGOTIATE_OEM:\n-               ansFlags |= ntlm.NTLM_NEGOTIATE_OEM\n+                ansFlags |= ntlm.NTLM_NEGOTIATE_OEM\n \n             ansFlags |= ntlm.NTLMSSP_NEGOTIATE_VERSION | ntlm.NTLMSSP_NEGOTIATE_TARGET_INFO | ntlm.NTLMSSP_TARGET_TYPE_SERVER | ntlm.NTLMSSP_NEGOTIATE_NTLM | ntlm.NTLMSSP_REQUEST_TARGET\n \n             # Generate the AV_PAIRS\n             av_pairs = ntlm.AV_PAIRS()\n             # TODO: Put the proper data from SMBSERVER config\n-            av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')\n-            av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')\n-            av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (116444736000000000 + calendar.timegm(time.gmtime()) * 10000000) )\n+            av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[\n+                ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')\n+            av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[\n+                ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')\n+            av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (\n+                        116444736000000000 + calendar.timegm(time.gmtime()) * 10000000))\n \n             challengeMessage = ntlm.NTLMAuthChallenge()\n-            challengeMessage['flags']            = ansFlags\n-            challengeMessage['domain_len']       = len(smbServer.getServerDomain().encode('utf-16le'))\n-            challengeMessage['domain_max_len']   = challengeMessage['domain_len']\n-            challengeMessage['domain_offset']    = 40 + 16\n-            challengeMessage['challenge']        = smbServer.getSMBChallenge()\n-            challengeMessage['domain_name']      = smbServer.getServerDomain().encode('utf-16le')\n-            challengeMessage['TargetInfoFields_len']     = len(av_pairs)\n+            challengeMessage['flags'] = ansFlags\n+            challengeMessage['domain_len'] = len(smbServer.getServerDomain().encode('utf-16le'))\n+            challengeMessage['domain_max_len'] = challengeMessage['domain_len']\n+            challengeMessage['domain_offset'] = 40 + 16\n+            challengeMessage['challenge'] = smbServer.getSMBChallenge()\n+            challengeMessage['domain_name'] = smbServer.getServerDomain().encode('utf-16le')\n+            challengeMessage['TargetInfoFields_len'] = len(av_pairs)\n             challengeMessage['TargetInfoFields_max_len'] = len(av_pairs)\n             challengeMessage['TargetInfoFields'] = av_pairs\n-            challengeMessage['TargetInfoFields_offset']  = 40 + 16 + len(challengeMessage['domain_name'])\n-            challengeMessage['Version']          = b'\\xff'*8\n-            challengeMessage['VersionLen']       = 8\n+            challengeMessage['TargetInfoFields_offset'] = 40 + 16 + len(challengeMessage['domain_name'])\n+            challengeMessage['Version'] = b'\\xff' * 8\n+            challengeMessage['VersionLen'] = 8\n \n             if rawNTLM is False:\n                 respToken = SPNEGO_NegTokenResp()\n@@ -2779,11 +2828,11 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n \n             # Setting the packet to STATUS_MORE_PROCESSING\n             errorCode = STATUS_MORE_PROCESSING_REQUIRED\n-            # Let's set up an UID for this connection and store it \n+            # Let's set up an UID for this connection and store it\n             # in the connection's data\n             # Picking a fixed value\n             # TODO: Manage more UIDs for the same session\n-            connData['Uid'] = random.randint(1,0xffffffff)\n+            connData['Uid'] = random.randint(1, 0xffffffff)\n             # Let's store it in the connection data\n             connData['CHALLENGE_MESSAGE'] = challengeMessage\n \n@@ -2795,8 +2844,9 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n             authenticateMessage = ntlm.NTLMAuthChallengeResponse()\n             authenticateMessage.fromString(token)\n             smbServer.log(\"AUTHENTICATE_MESSAGE (%s\\\\%s,%s)\" % (\n-            authenticateMessage['domain_name'].decode('utf-16le'), authenticateMessage['user_name'].decode('utf-16le'),\n-            authenticateMessage['host_name'].decode('utf-16le')))\n+                authenticateMessage['domain_name'].decode('utf-16le'),\n+                authenticateMessage['user_name'].decode('utf-16le'),\n+                authenticateMessage['host_name'].decode('utf-16le')))\n             # TODO: Check the credentials! Now granting permissions\n             # Do we have credentials to check?\n             if len(smbServer.getCredentials()) > 0:\n@@ -2829,7 +2879,8 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n                 # accept-completed\n                 respToken['NegState'] = b'\\x00'\n                 smbServer.log('User %s\\\\%s authenticated successfully' % (\n-                authenticateMessage['host_name'].decode('utf-16le'), authenticateMessage['user_name'].decode('utf-16le')))\n+                    authenticateMessage['host_name'].decode('utf-16le'),\n+                    authenticateMessage['user_name'].decode('utf-16le')))\n                 # Let's store it in the connection data\n                 connData['AUTHENTICATE_MESSAGE'] = authenticateMessage\n                 try:\n@@ -2862,8 +2913,8 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n         # From now on, the client can ask for other commands\n         connData['Authenticated'] = True\n         # For now, just switching to nobody\n-        #os.setregid(65534,65534)\n-        #os.setreuid(65534,65534)\n+        # os.setregid(65534,65534)\n+        # os.setreuid(65534,65534)\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -2873,16 +2924,16 @@ def smb2TreeConnect(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respPacket = smb2.SMB2Packet()\n-        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n-        respPacket['Status']    = STATUS_SUCCESS\n+        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n+        respPacket['Status'] = STATUS_SUCCESS\n         respPacket['CreditRequestResponse'] = 1\n-        respPacket['Command']   = recvPacket['Command']\n+        respPacket['Command'] = recvPacket['Command']\n         respPacket['SessionID'] = connData['Uid']\n-        respPacket['Reserved']  = recvPacket['Reserved']\n+        respPacket['Reserved'] = recvPacket['Reserved']\n         respPacket['MessageID'] = recvPacket['MessageID']\n-        respPacket['TreeID']    = recvPacket['TreeID']\n+        respPacket['TreeID'] = recvPacket['TreeID']\n \n-        respSMBCommand        = smb2.SMB2TreeConnect_Response()\n+        respSMBCommand = smb2.SMB2TreeConnect_Response()\n \n         treeConnectRequest = smb2.SMB2TreeConnect(recvPacket['Data'])\n \n@@ -2902,13 +2953,13 @@ def smb2TreeConnect(connId, smbServer, recvPacket):\n         if share is not None:\n             # Simple way to generate a Tid\n             if len(connData['ConnectedShares']) == 0:\n-               tid = 1\n+                tid = 1\n             else:\n-               tid = list(connData['ConnectedShares'].keys())[-1] + 1\n+                tid = list(connData['ConnectedShares'].keys())[-1] + 1\n             connData['ConnectedShares'][tid] = share\n             connData['ConnectedShares'][tid]['shareName'] = path\n-            respPacket['TreeID']    = tid\n-            smbServer.log(\"Connecting Share(%d:%s)\" % (tid,path))\n+            respPacket['TreeID'] = tid\n+            smbServer.log(\"Connecting Share(%d:%s)\" % (tid, path))\n         else:\n             smbServer.log(\"SMB2_TREE_CONNECT not found %s\" % path, logging.ERROR)\n             errorCode = STATUS_OBJECT_PATH_NOT_FOUND\n@@ -2938,104 +2989,111 @@ def smb2TreeConnect(connId, smbServer, recvPacket):\n     def smb2Create(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb2.SMB2Create_Response()\n+        respSMBCommand = smb2.SMB2Create_Response()\n \n-        ntCreateRequest       = smb2.SMB2Create(recvPacket['Data'])\n+        ntCreateRequest = smb2.SMB2Create(recvPacket['Data'])\n \n         respSMBCommand['Buffer'] = b'\\x00'\n         # Get the Tid associated\n         if recvPacket['TreeID'] in connData['ConnectedShares']:\n-             # If we have a rootFid, the path is relative to that fid\n-             errorCode = STATUS_SUCCESS\n-             if 'path' in connData['ConnectedShares'][recvPacket['TreeID']]:\n-                 path = connData['ConnectedShares'][recvPacket['TreeID']]['path']\n-             else:\n-                 path = 'NONE'\n-                 errorCode = STATUS_ACCESS_DENIED\n-\n-             deleteOnClose = False\n-\n-             fileName = os.path.normpath(ntCreateRequest['Buffer'][:ntCreateRequest['NameLength']].decode('utf-16le').replace('\\\\','\/'))\n-             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+            # If we have a rootFid, the path is relative to that fid\n+            errorCode = STATUS_SUCCESS\n+            if 'path' in connData['ConnectedShares'][recvPacket['TreeID']]:\n+                path = connData['ConnectedShares'][recvPacket['TreeID']]['path']\n+            else:\n+                path = 'NONE'\n+                errorCode = STATUS_ACCESS_DENIED\n+\n+            deleteOnClose = False\n+\n+            fileName = os.path.normpath(\n+                ntCreateRequest['Buffer'][:ntCreateRequest['NameLength']].decode('utf-16le').replace('\\\\', '\/'))\n+            if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             createDisposition = ntCreateRequest['CreateDisposition']\n-             mode = 0\n-\n-             if createDisposition == smb2.FILE_SUPERSEDE:\n-                 mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb2.FILE_OVERWRITE_IF == smb2.FILE_OVERWRITE_IF:\n-                 mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb2.FILE_OVERWRITE == smb2.FILE_OVERWRITE:\n-                 if os.path.exists(pathName) is True:\n-                     mode |= os.O_TRUNC \n-                 else:\n-                     errorCode = STATUS_NO_SUCH_FILE\n-             elif createDisposition & smb2.FILE_OPEN_IF == smb2.FILE_OPEN_IF:\n-                 if os.path.exists(pathName) is True:\n-                     mode |= os.O_TRUNC \n-                 else:\n-                     mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb2.FILE_CREATE == smb2.FILE_CREATE:\n-                 if os.path.exists(pathName) is True:\n-                     errorCode = STATUS_OBJECT_NAME_COLLISION\n-                 else:\n-                     mode |= os.O_CREAT\n-             elif createDisposition & smb2.FILE_OPEN == smb2.FILE_OPEN:\n-                 if os.path.exists(pathName) is not True and (str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:\n-                     errorCode = STATUS_NO_SUCH_FILE\n-\n-             if errorCode == STATUS_SUCCESS:\n-                 desiredAccess = ntCreateRequest['DesiredAccess']\n-                 if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):\n-                     mode |= os.O_RDONLY\n-                 if (desiredAccess & smb2.FILE_WRITE_DATA) or (desiredAccess & smb2.GENERIC_WRITE):\n-                     if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):\n-                         mode |= os.O_RDWR #| os.O_APPEND\n-                     else: \n-                         mode |= os.O_WRONLY #| os.O_APPEND\n-                 if desiredAccess & smb2.GENERIC_ALL:\n-                     mode |= os.O_RDWR #| os.O_APPEND\n-\n-                 createOptions =  ntCreateRequest['CreateOptions']\n-                 if mode & os.O_CREAT == os.O_CREAT:\n-                     if createOptions & smb2.FILE_DIRECTORY_FILE == smb2.FILE_DIRECTORY_FILE: \n-                         try:\n-                             # Let's create the directory\n-                             os.mkdir(pathName)\n-                             mode = os.O_RDONLY\n-                         except Exception as e:\n-                             smbServer.log(\"SMB2_CREATE: %s,%s,%s\" % (pathName,mode,e),logging.ERROR)\n-                             errorCode = STATUS_ACCESS_DENIED\n-                 if createOptions & smb2.FILE_NON_DIRECTORY_FILE == smb2.FILE_NON_DIRECTORY_FILE:\n-                     # If the file being opened is a directory, the server MUST fail the request with\n-                     # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server\n-                     # response.\n-                     if os.path.isdir(pathName) is True:\n+\n+            if not isInFileJail(path, fileName):\n+                LOG.error(\"Path not in current working directory\")\n+                return [smb2.SMB2Error()], None, STATUS_ACCESS_DENIED\n+\n+            pathName = os.path.join(path, fileName)\n+            createDisposition = ntCreateRequest['CreateDisposition']\n+            mode = 0\n+\n+            if createDisposition == smb2.FILE_SUPERSEDE:\n+                mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb2.FILE_OVERWRITE_IF == smb2.FILE_OVERWRITE_IF:\n+                mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb2.FILE_OVERWRITE == smb2.FILE_OVERWRITE:\n+                if os.path.exists(pathName) is True:\n+                    mode |= os.O_TRUNC\n+                else:\n+                    errorCode = STATUS_NO_SUCH_FILE\n+            elif createDisposition & smb2.FILE_OPEN_IF == smb2.FILE_OPEN_IF:\n+                if os.path.exists(pathName) is True:\n+                    mode |= os.O_TRUNC\n+                else:\n+                    mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb2.FILE_CREATE == smb2.FILE_CREATE:\n+                if os.path.exists(pathName) is True:\n+                    errorCode = STATUS_OBJECT_NAME_COLLISION\n+                else:\n+                    mode |= os.O_CREAT\n+            elif createDisposition & smb2.FILE_OPEN == smb2.FILE_OPEN:\n+                if os.path.exists(pathName) is not True and (\n+                        str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:\n+                    errorCode = STATUS_NO_SUCH_FILE\n+\n+            if errorCode == STATUS_SUCCESS:\n+                desiredAccess = ntCreateRequest['DesiredAccess']\n+                if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):\n+                    mode |= os.O_RDONLY\n+                if (desiredAccess & smb2.FILE_WRITE_DATA) or (desiredAccess & smb2.GENERIC_WRITE):\n+                    if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):\n+                        mode |= os.O_RDWR  # | os.O_APPEND\n+                    else:\n+                        mode |= os.O_WRONLY  # | os.O_APPEND\n+                if desiredAccess & smb2.GENERIC_ALL:\n+                    mode |= os.O_RDWR  # | os.O_APPEND\n+\n+                createOptions = ntCreateRequest['CreateOptions']\n+                if mode & os.O_CREAT == os.O_CREAT:\n+                    if createOptions & smb2.FILE_DIRECTORY_FILE == smb2.FILE_DIRECTORY_FILE:\n+                        try:\n+                            # Let's create the directory\n+                            os.mkdir(pathName)\n+                            mode = os.O_RDONLY\n+                        except Exception as e:\n+                            smbServer.log(\"SMB2_CREATE: %s,%s,%s\" % (pathName, mode, e), logging.ERROR)\n+                            errorCode = STATUS_ACCESS_DENIED\n+                if createOptions & smb2.FILE_NON_DIRECTORY_FILE == smb2.FILE_NON_DIRECTORY_FILE:\n+                    # If the file being opened is a directory, the server MUST fail the request with\n+                    # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server\n+                    # response.\n+                    if os.path.isdir(pathName) is True:\n                         errorCode = STATUS_FILE_IS_A_DIRECTORY\n \n-                 if createOptions & smb2.FILE_DELETE_ON_CLOSE == smb2.FILE_DELETE_ON_CLOSE:\n-                     deleteOnClose = True\n-                 \n-                 if errorCode == STATUS_SUCCESS:\n-                     try:\n-                         if os.path.isdir(pathName) and sys.platform == 'win32':\n+                if createOptions & smb2.FILE_DELETE_ON_CLOSE == smb2.FILE_DELETE_ON_CLOSE:\n+                    deleteOnClose = True\n+\n+                if errorCode == STATUS_SUCCESS:\n+                    try:\n+                        if os.path.isdir(pathName) and sys.platform == 'win32':\n                             fid = VOID_FILE_DESCRIPTOR\n-                         else:\n+                        else:\n                             if sys.platform == 'win32':\n-                               mode |= os.O_BINARY\n+                                mode |= os.O_BINARY\n                             if str(pathName) in smbServer.getRegisteredNamedPipes():\n                                 fid = PIPE_FILE_DESCRIPTOR\n                                 sock = socket.socket()\n                                 sock.connect(smbServer.getRegisteredNamedPipes()[str(pathName)])\n                             else:\n                                 fid = os.open(pathName, mode)\n-                     except Exception as e:\n-                         smbServer.log(\"SMB2_CREATE: %s,%s,%s\" % (pathName,mode,e),logging.ERROR)\n-                         #print e\n-                         fid = 0\n-                         errorCode = STATUS_ACCESS_DENIED\n+                    except Exception as e:\n+                        smbServer.log(\"SMB2_CREATE: %s,%s,%s\" % (pathName, mode, e), logging.ERROR)\n+                        # print e\n+                        fid = 0\n+                        errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n@@ -3047,12 +3105,12 @@ def smb2Create(connId, smbServer, recvPacket):\n             respSMBCommand['CreateAction'] = createDisposition\n \n             if fid == PIPE_FILE_DESCRIPTOR:\n-                respSMBCommand['CreationTime']   = 0\n+                respSMBCommand['CreationTime'] = 0\n                 respSMBCommand['LastAccessTime'] = 0\n-                respSMBCommand['LastWriteTime']  = 0\n-                respSMBCommand['ChangeTime']     = 0\n+                respSMBCommand['LastWriteTime'] = 0\n+                respSMBCommand['ChangeTime'] = 0\n                 respSMBCommand['AllocationSize'] = 4096\n-                respSMBCommand['EndOfFile']      = 0\n+                respSMBCommand['EndOfFile'] = 0\n                 respSMBCommand['FileAttributes'] = 0x80\n \n             else:\n@@ -3061,15 +3119,15 @@ def smb2Create(connId, smbServer, recvPacket):\n                 else:\n                     respSMBCommand['FileAttributes'] = ntCreateRequest['FileAttributes']\n                 # Let's get this file's information\n-                respInfo, errorCode = queryPathInformation('',pathName,level= smb.SMB_QUERY_FILE_ALL_INFO)\n+                respInfo, errorCode = queryPathInformation('', pathName, level=smb.SMB_QUERY_FILE_ALL_INFO)\n                 if errorCode == STATUS_SUCCESS:\n-                    respSMBCommand['CreationTime']   = respInfo['CreationTime']\n+                    respSMBCommand['CreationTime'] = respInfo['CreationTime']\n                     respSMBCommand['LastAccessTime'] = respInfo['LastAccessTime']\n-                    respSMBCommand['LastWriteTime']  = respInfo['LastWriteTime']\n+                    respSMBCommand['LastWriteTime'] = respInfo['LastWriteTime']\n                     respSMBCommand['LastChangeTime'] = respInfo['LastChangeTime']\n                     respSMBCommand['FileAttributes'] = respInfo['ExtFileAttributes']\n                     respSMBCommand['AllocationSize'] = respInfo['AllocationSize']\n-                    respSMBCommand['EndOfFile']      = respInfo['EndOfFile']\n+                    respSMBCommand['EndOfFile'] = respInfo['EndOfFile']\n \n             if errorCode == STATUS_SUCCESS:\n                 # Let's store the fid for the connection\n@@ -3077,15 +3135,15 @@ def smb2Create(connId, smbServer, recvPacket):\n                 connData['OpenedFiles'][fakefid] = {}\n                 connData['OpenedFiles'][fakefid]['FileHandle'] = fid\n                 connData['OpenedFiles'][fakefid]['FileName'] = pathName\n-                connData['OpenedFiles'][fakefid]['DeleteOnClose']  = deleteOnClose\n-                connData['OpenedFiles'][fakefid]['Open']  = {}\n+                connData['OpenedFiles'][fakefid]['DeleteOnClose'] = deleteOnClose\n+                connData['OpenedFiles'][fakefid]['Open'] = {}\n                 connData['OpenedFiles'][fakefid]['Open']['EnumerationLocation'] = 0\n                 connData['OpenedFiles'][fakefid]['Open']['EnumerationSearchPattern'] = ''\n                 if fid == PIPE_FILE_DESCRIPTOR:\n                     connData['OpenedFiles'][fakefid]['Socket'] = sock\n         else:\n             respSMBCommand = smb2.SMB2Error()\n-        \n+\n         if errorCode == STATUS_SUCCESS:\n             connData['LastRequest']['SMB2_CREATE'] = respSMBCommand\n         smbServer.setConnectionData(connId, connData)\n@@ -3096,13 +3154,13 @@ def smb2Create(connId, smbServer, recvPacket):\n     def smb2Close(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb2.SMB2Close_Response()\n+        respSMBCommand = smb2.SMB2Close_Response()\n \n         closeRequest = smb2.SMB2Close(recvPacket['Data'])\n \n-        if closeRequest['FileID'].getData() == b'\\xff'*16:\n+        if closeRequest['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = closeRequest['FileID'].getData()\n@@ -3110,42 +3168,43 @@ def smb2Close(connId, smbServer, recvPacket):\n             fileID = closeRequest['FileID'].getData()\n \n         if fileID in connData['OpenedFiles']:\n-             errorCode = STATUS_SUCCESS\n-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n-             pathName = connData['OpenedFiles'][fileID]['FileName']\n-             infoRecord = None\n-             try:\n-                 if fileHandle == PIPE_FILE_DESCRIPTOR:\n-                     connData['OpenedFiles'][fileID]['Socket'].close()\n-                 elif fileHandle != VOID_FILE_DESCRIPTOR:\n-                     os.close(fileHandle)\n-                     infoRecord, errorCode = queryFileInformation(os.path.dirname(pathName), os.path.basename(pathName), smb2.SMB2_FILE_NETWORK_OPEN_INFO)\n-             except Exception as e:\n-                 smbServer.log(\"SMB2_CLOSE %s\" % e, logging.ERROR)\n-                 errorCode = STATUS_INVALID_HANDLE\n-             else:\n-                 # Check if the file was marked for removal\n-                 if connData['OpenedFiles'][fileID]['DeleteOnClose'] is True:\n-                     try:\n-                         if os.path.isdir(pathName):\n-                             shutil.rmtree(connData['OpenedFiles'][fileID]['FileName'])\n-                         else:\n-                             os.remove(connData['OpenedFiles'][fileID]['FileName'])\n-                     except Exception as e:\n-                         smbServer.log(\"SMB2_CLOSE %s\" % e, logging.ERROR)\n-                         errorCode = STATUS_ACCESS_DENIED\n-    \n-                 # Now fill out the response\n-                 if infoRecord is not None:\n-                     respSMBCommand['CreationTime']   = infoRecord['CreationTime']\n-                     respSMBCommand['LastAccessTime'] = infoRecord['LastAccessTime']\n-                     respSMBCommand['LastWriteTime']  = infoRecord['LastWriteTime']\n-                     respSMBCommand['ChangeTime']     = infoRecord['ChangeTime']\n-                     respSMBCommand['AllocationSize'] = infoRecord['AllocationSize']\n-                     respSMBCommand['EndofFile']      = infoRecord['EndOfFile']\n-                     respSMBCommand['FileAttributes'] = infoRecord['FileAttributes']\n-                 if errorCode == STATUS_SUCCESS:\n-                     del(connData['OpenedFiles'][fileID])\n+            errorCode = STATUS_SUCCESS\n+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n+            pathName = connData['OpenedFiles'][fileID]['FileName']\n+            infoRecord = None\n+            try:\n+                if fileHandle == PIPE_FILE_DESCRIPTOR:\n+                    connData['OpenedFiles'][fileID]['Socket'].close()\n+                elif fileHandle != VOID_FILE_DESCRIPTOR:\n+                    os.close(fileHandle)\n+                    infoRecord, errorCode = queryFileInformation(os.path.dirname(pathName), os.path.basename(pathName),\n+                                                                 smb2.SMB2_FILE_NETWORK_OPEN_INFO)\n+            except Exception as e:\n+                smbServer.log(\"SMB2_CLOSE %s\" % e, logging.ERROR)\n+                errorCode = STATUS_INVALID_HANDLE\n+            else:\n+                # Check if the file was marked for removal\n+                if connData['OpenedFiles'][fileID]['DeleteOnClose'] is True:\n+                    try:\n+                        if os.path.isdir(pathName):\n+                            shutil.rmtree(connData['OpenedFiles'][fileID]['FileName'])\n+                        else:\n+                            os.remove(connData['OpenedFiles'][fileID]['FileName'])\n+                    except Exception as e:\n+                        smbServer.log(\"SMB2_CLOSE %s\" % e, logging.ERROR)\n+                        errorCode = STATUS_ACCESS_DENIED\n+\n+                # Now fill out the response\n+                if infoRecord is not None:\n+                    respSMBCommand['CreationTime'] = infoRecord['CreationTime']\n+                    respSMBCommand['LastAccessTime'] = infoRecord['LastAccessTime']\n+                    respSMBCommand['LastWriteTime'] = infoRecord['LastWriteTime']\n+                    respSMBCommand['ChangeTime'] = infoRecord['ChangeTime']\n+                    respSMBCommand['AllocationSize'] = infoRecord['AllocationSize']\n+                    respSMBCommand['EndofFile'] = infoRecord['EndOfFile']\n+                    respSMBCommand['FileAttributes'] = infoRecord['FileAttributes']\n+                if errorCode == STATUS_SUCCESS:\n+                    del (connData['OpenedFiles'][fileID])\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n@@ -3156,18 +3215,18 @@ def smb2Close(connId, smbServer, recvPacket):\n     def smb2QueryInfo(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb2.SMB2QueryInfo_Response()\n+        respSMBCommand = smb2.SMB2QueryInfo_Response()\n \n         queryInfo = smb2.SMB2QueryInfo(recvPacket['Data'])\n-       \n-        errorCode = STATUS_SUCCESS \n+\n+        errorCode = STATUS_SUCCESS\n \n         respSMBCommand['OutputBufferOffset'] = 0x48\n         respSMBCommand['Buffer'] = b'\\x00'\n \n-        if queryInfo['FileID'].getData() == b'\\xff'*16:\n+        if queryInfo['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = queryInfo['FileID'].getData()\n@@ -3189,15 +3248,16 @@ def smb2QueryInfo(connId, smbServer, recvPacket):\n                                                                      queryInfo['FileInfoClass'])\n                 elif queryInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:\n                     if queryInfo['FileInfoClass'] == smb2.SMB2_FILE_EA_INFO:\n-                        infoRecord = b'\\x00'*4\n+                        infoRecord = b'\\x00' * 4\n                     else:\n-                        infoRecord = queryFsInformation(os.path.dirname(fileName), os.path.basename(fileName), queryInfo['FileInfoClass'])\n+                        infoRecord = queryFsInformation(os.path.dirname(fileName), os.path.basename(fileName),\n+                                                        queryInfo['FileInfoClass'])\n                 elif queryInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:\n                     # Failing for now, until we support it\n                     infoRecord = None\n                     errorCode = STATUS_ACCESS_DENIED\n                 else:\n-                    smbServer.log(\"queryInfo not supported (%x)\" %  queryInfo['InfoType'], logging.ERROR)\n+                    smbServer.log(\"queryInfo not supported (%x)\" % queryInfo['InfoType'], logging.ERROR)\n \n                 if infoRecord is not None:\n                     respSMBCommand['OutputBufferLength'] = len(infoRecord)\n@@ -3207,7 +3267,6 @@ def smb2QueryInfo(connId, smbServer, recvPacket):\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n@@ -3215,15 +3274,15 @@ def smb2QueryInfo(connId, smbServer, recvPacket):\n     def smb2SetInfo(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb2.SMB2SetInfo_Response()\n+        respSMBCommand = smb2.SMB2SetInfo_Response()\n \n         setInfo = smb2.SMB2SetInfo(recvPacket['Data'])\n-       \n-        errorCode = STATUS_SUCCESS \n \n-        if setInfo['FileID'].getData() == b'\\xff'*16:\n+        errorCode = STATUS_SUCCESS\n+\n+        if setInfo['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = setInfo['FileID'].getData()\n@@ -3231,7 +3290,7 @@ def smb2SetInfo(connId, smbServer, recvPacket):\n             fileID = setInfo['FileID'].getData()\n \n         if recvPacket['TreeID'] in connData['ConnectedShares']:\n-            path     = connData['ConnectedShares'][recvPacket['TreeID']]['path']\n+            path = connData['ConnectedShares'][recvPacket['TreeID']]['path']\n             if fileID in connData['OpenedFiles']:\n                 pathName = connData['OpenedFiles'][fileID]['FileName']\n \n@@ -3241,8 +3300,8 @@ def smb2SetInfo(connId, smbServer, recvPacket):\n                     if informationLevel == smb2.SMB2_FILE_DISPOSITION_INFO:\n                         infoRecord = smb.SMBSetFileDispositionInfo(setInfo['Buffer'])\n                         if infoRecord['DeletePending'] > 0:\n-                           # Mark this file for removal after closed\n-                           connData['OpenedFiles'][fileID]['DeleteOnClose'] = True\n+                            # Mark this file for removal after closed\n+                            connData['OpenedFiles'][fileID]['DeleteOnClose'] = True\n                     elif informationLevel == smb2.SMB2_FILE_BASIC_INFO:\n                         infoRecord = smb.SMBSetFileBasicInfo(setInfo['Buffer'])\n                         # Creation time won't be set,  the other ones we play with.\n@@ -3257,48 +3316,47 @@ def smb2SetInfo(connId, smbServer, recvPacket):\n                         else:\n                             mtime = getUnixTime(mtime)\n                         if atime > 0 and mtime > 0:\n-                            os.utime(pathName,(atime,mtime))\n+                            os.utime(pathName, (atime, mtime))\n                     elif informationLevel == smb2.SMB2_FILE_END_OF_FILE_INFO:\n                         fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n                         infoRecord = smb.SMBSetFileEndOfFileInfo(setInfo['Buffer'])\n                         if infoRecord['EndOfFile'] > 0:\n-                            os.lseek(fileHandle, infoRecord['EndOfFile']-1, 0)\n+                            os.lseek(fileHandle, infoRecord['EndOfFile'] - 1, 0)\n                             os.write(fileHandle, b'\\x00')\n                     elif informationLevel == smb2.SMB2_FILE_RENAME_INFO:\n                         renameInfo = smb2.FILE_RENAME_INFORMATION_TYPE_2(setInfo['Buffer'])\n-                        newPathName = os.path.join(path,renameInfo['FileName'].decode('utf-16le').replace('\\\\', '\/')) \n+                        newPathName = os.path.join(path, renameInfo['FileName'].decode('utf-16le').replace('\\\\', '\/'))\n                         if renameInfo['ReplaceIfExists'] == 0 and os.path.exists(newPathName):\n                             return [smb2.SMB2Error()], None, STATUS_OBJECT_NAME_COLLISION\n                         try:\n-                             os.rename(pathName,newPathName)\n-                             connData['OpenedFiles'][fileID]['FileName'] = newPathName\n+                            os.rename(pathName, newPathName)\n+                            connData['OpenedFiles'][fileID]['FileName'] = newPathName\n                         except Exception as e:\n-                             smbServer.log(\"smb2SetInfo: %s\" % e, logging.ERROR)\n-                             errorCode = STATUS_ACCESS_DENIED\n+                            smbServer.log(\"smb2SetInfo: %s\" % e, logging.ERROR)\n+                            errorCode = STATUS_ACCESS_DENIED\n                     else:\n                         smbServer.log('Unknown level for set file info! 0x%x' % informationLevel, logging.ERROR)\n                         # UNSUPPORTED\n-                        errorCode =  STATUS_NOT_SUPPORTED\n-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:\n+                        errorCode = STATUS_NOT_SUPPORTED\n+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:\n                 #    # The underlying object store information is being set.\n                 #    setInfo = queryFsInformation('\/', fileName, queryInfo['FileInfoClass'])\n-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:\n+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:\n                 #    # The security information is being set.\n                 #    # Failing for now, until we support it\n                 #    infoRecord = None\n                 #    errorCode = STATUS_ACCESS_DENIED\n-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_QUOTA:\n+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_QUOTA:\n                 #    # The underlying object store quota information is being set.\n                 #    setInfo = queryFsInformation('\/', fileName, queryInfo['FileInfoClass'])\n                 else:\n-                    smbServer.log(\"setInfo not supported (%x)\" %  setInfo['InfoType'], logging.ERROR)\n+                    smbServer.log(\"setInfo not supported (%x)\" % setInfo['InfoType'], logging.ERROR)\n \n             else:\n                 errorCode = STATUS_INVALID_HANDLE\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n@@ -3307,13 +3365,13 @@ def smb2Write(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb2.SMB2Write_Response()\n-        writeRequest   = smb2.SMB2Write(recvPacket['Data'])\n+        writeRequest = smb2.SMB2Write(recvPacket['Data'])\n \n         respSMBCommand['Buffer'] = b'\\x00'\n \n-        if writeRequest['FileID'].getData() == b'\\xff'*16:\n+        if writeRequest['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = writeRequest['FileID'].getData()\n@@ -3321,24 +3379,24 @@ def smb2Write(connId, smbServer, recvPacket):\n             fileID = writeRequest['FileID'].getData()\n \n         if fileID in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     offset = writeRequest['Offset']\n-                     # If we're trying to write past the file end we just skip the write call (Vista does this)\n-                     if os.lseek(fileHandle, 0, 2) >= offset:\n-                         os.lseek(fileHandle,offset,0)\n-                         os.write(fileHandle,writeRequest['Buffer'])\n-                 else:\n-                     sock = connData['OpenedFiles'][fileID]['Socket']\n-                     sock.send(writeRequest['Buffer'])\n-\n-                 respSMBCommand['Count']    = writeRequest['Length']\n-                 respSMBCommand['Remaining']= 0xff\n-             except Exception as e:\n-                 smbServer.log('SMB2_WRITE: %s' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    offset = writeRequest['Offset']\n+                    # If we're trying to write past the file end we just skip the write call (Vista does this)\n+                    if os.lseek(fileHandle, 0, 2) >= offset:\n+                        os.lseek(fileHandle, offset, 0)\n+                        os.write(fileHandle, writeRequest['Buffer'])\n+                else:\n+                    sock = connData['OpenedFiles'][fileID]['Socket']\n+                    sock.send(writeRequest['Buffer'])\n+\n+                respSMBCommand['Count'] = writeRequest['Length']\n+                respSMBCommand['Remaining'] = 0xff\n+            except Exception as e:\n+                smbServer.log('SMB2_WRITE: %s' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n@@ -3350,13 +3408,13 @@ def smb2Read(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb2.SMB2Read_Response()\n-        readRequest   = smb2.SMB2Read(recvPacket['Data'])\n+        readRequest = smb2.SMB2Read(recvPacket['Data'])\n \n         respSMBCommand['Buffer'] = b'\\x00'\n \n-        if readRequest['FileID'].getData() == b'\\xff'*16:\n+        if readRequest['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = readRequest['FileID'].getData()\n@@ -3364,24 +3422,24 @@ def smb2Read(connId, smbServer, recvPacket):\n             fileID = readRequest['FileID'].getData()\n \n         if fileID in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n-             errorCode = 0\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     offset = readRequest['Offset']\n-                     os.lseek(fileHandle,offset,0)\n-                     content = os.read(fileHandle,readRequest['Length'])\n-                 else:\n-                     sock = connData['OpenedFiles'][fileID]['Socket']\n-                     content = sock.recv(readRequest['Length'])\n-\n-                 respSMBCommand['DataOffset']   = 0x50\n-                 respSMBCommand['DataLength']   = len(content)\n-                 respSMBCommand['DataRemaining']= 0\n-                 respSMBCommand['Buffer']       = content\n-             except Exception as e:\n-                 smbServer.log('SMB2_READ: %s ' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n+            errorCode = 0\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    offset = readRequest['Offset']\n+                    os.lseek(fileHandle, offset, 0)\n+                    content = os.read(fileHandle, readRequest['Length'])\n+                else:\n+                    sock = connData['OpenedFiles'][fileID]['Socket']\n+                    content = sock.recv(readRequest['Length'])\n+\n+                respSMBCommand['DataOffset'] = 0x50\n+                respSMBCommand['DataLength'] = len(content)\n+                respSMBCommand['DataRemaining'] = 0\n+                respSMBCommand['Buffer'] = content\n+            except Exception as e:\n+                smbServer.log('SMB2_READ: %s ' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n@@ -3393,40 +3451,39 @@ def smb2Flush(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb2.SMB2Flush_Response()\n-        flushRequest   = smb2.SMB2Flush(recvPacket['Data'])\n+        flushRequest = smb2.SMB2Flush(recvPacket['Data'])\n \n         if flushRequest['FileID'].getData() in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][flushRequest['FileID'].getData()]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 os.fsync(fileHandle)\n-             except Exception as e:\n-                 smbServer.log(\"SMB2_FLUSH %s\" % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][flushRequest['FileID'].getData()]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                os.fsync(fileHandle)\n+            except Exception as e:\n+                smbServer.log(\"SMB2_FLUSH %s\" % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smb2QueryDirectory(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n         respSMBCommand = smb2.SMB2QueryDirectory_Response()\n-        queryDirectoryRequest   = smb2.SMB2QueryDirectory(recvPacket['Data'])\n+        queryDirectoryRequest = smb2.SMB2QueryDirectory(recvPacket['Data'])\n \n         respSMBCommand['Buffer'] = b'\\x00'\n \n         # The server MUST locate the tree connection, as specified in section 3.3.5.2.11.\n         if (recvPacket['TreeID'] in connData['ConnectedShares']) is False:\n             return [smb2.SMB2Error()], None, STATUS_NETWORK_NAME_DELETED\n-       \n-        # Next, the server MUST locate the open for the directory to be queried \n+\n+        # Next, the server MUST locate the open for the directory to be queried\n         # If no open is found, the server MUST fail the request with STATUS_FILE_CLOSED\n-        if queryDirectoryRequest['FileID'].getData() == b'\\xff'*16:\n+        if queryDirectoryRequest['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = queryDirectoryRequest['FileID'].getData()\n@@ -3436,57 +3493,59 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):\n         if (fileID in connData['OpenedFiles']) is False:\n             return [smb2.SMB2Error()], None, STATUS_FILE_CLOSED\n \n-        # If the open is not an open to a directory, the request MUST be failed \n+        # If the open is not an open to a directory, the request MUST be failed\n         # with STATUS_INVALID_PARAMETER.\n         if os.path.isdir(connData['OpenedFiles'][fileID]['FileName']) is False:\n             return [smb2.SMB2Error()], None, STATUS_INVALID_PARAMETER\n \n-        # If any other information class is specified in the FileInformationClass \n-        # field of the SMB2 QUERY_DIRECTORY Request, the server MUST fail the \n-        # operation with STATUS_INVALID_INFO_CLASS. \n+        # If any other information class is specified in the FileInformationClass\n+        # field of the SMB2 QUERY_DIRECTORY Request, the server MUST fail the\n+        # operation with STATUS_INVALID_INFO_CLASS.\n         if queryDirectoryRequest['FileInformationClass'] not in (\n-        smb2.FILE_DIRECTORY_INFORMATION, smb2.FILE_FULL_DIRECTORY_INFORMATION, smb2.FILEID_FULL_DIRECTORY_INFORMATION,\n-        smb2.FILE_BOTH_DIRECTORY_INFORMATION, smb2.FILEID_BOTH_DIRECTORY_INFORMATION, smb2.FILENAMES_INFORMATION):\n+                smb2.FILE_DIRECTORY_INFORMATION, smb2.FILE_FULL_DIRECTORY_INFORMATION,\n+                smb2.FILEID_FULL_DIRECTORY_INFORMATION,\n+                smb2.FILE_BOTH_DIRECTORY_INFORMATION, smb2.FILEID_BOTH_DIRECTORY_INFORMATION,\n+                smb2.FILENAMES_INFORMATION):\n             return [smb2.SMB2Error()], None, STATUS_INVALID_INFO_CLASS\n \n-        # If SMB2_REOPEN is set in the Flags field of the SMB2 QUERY_DIRECTORY \n-        # Request, the server SHOULD<326> set Open.EnumerationLocation to 0 \n+        # If SMB2_REOPEN is set in the Flags field of the SMB2 QUERY_DIRECTORY\n+        # Request, the server SHOULD<326> set Open.EnumerationLocation to 0\n         # and Open.EnumerationSearchPattern to an empty string.\n         if queryDirectoryRequest['Flags'] & smb2.SMB2_REOPEN:\n             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = 0\n             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = ''\n-        \n-        # If SMB2_RESTART_SCANS is set in the Flags field of the SMB2 \n-        # QUERY_DIRECTORY Request, the server MUST set \n+\n+        # If SMB2_RESTART_SCANS is set in the Flags field of the SMB2\n+        # QUERY_DIRECTORY Request, the server MUST set\n         # Open.EnumerationLocation to 0.\n         if queryDirectoryRequest['Flags'] & smb2.SMB2_RESTART_SCANS:\n             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = 0\n \n-        # If Open.EnumerationLocation is 0 and Open.EnumerationSearchPattern \n-        # is an empty string, then Open.EnumerationSearchPattern MUST be set \n-        # to the search pattern specified in the SMB2 QUERY_DIRECTORY by \n-        # FileNameOffset and FileNameLength. If FileNameLength is 0, the server \n+        # If Open.EnumerationLocation is 0 and Open.EnumerationSearchPattern\n+        # is an empty string, then Open.EnumerationSearchPattern MUST be set\n+        # to the search pattern specified in the SMB2 QUERY_DIRECTORY by\n+        # FileNameOffset and FileNameLength. If FileNameLength is 0, the server\n         # SHOULD<327> set Open.EnumerationSearchPattern as \"*\" to search all entries.\n \n         pattern = queryDirectoryRequest['Buffer'].decode('utf-16le')\n-        if  connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0 and \\\n-            connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] == '':\n+        if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0 and \\\n+                connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] == '':\n             if pattern == '':\n                 pattern = '*'\n             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = pattern\n \n-        # If SMB2_INDEX_SPECIFIED is set and FileNameLength is not zero, \n-        # the server MUST set Open.EnumerationSearchPattern to the search pattern \n+        # If SMB2_INDEX_SPECIFIED is set and FileNameLength is not zero,\n+        # the server MUST set Open.EnumerationSearchPattern to the search pattern\n         # specified in the request by FileNameOffset and FileNameLength.\n         if queryDirectoryRequest['Flags'] & smb2.SMB2_INDEX_SPECIFIED and \\\n-           queryDirectoryRequest['FileNameLength'] > 0:\n+                queryDirectoryRequest['FileNameLength'] > 0:\n             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = pattern\n \n-        pathName = os.path.join(os.path.normpath(connData['OpenedFiles'][fileID]['FileName']),pattern)\n+        pathName = os.path.join(os.path.normpath(connData['OpenedFiles'][fileID]['FileName']), pattern)\n         searchResult, searchCount, errorCode = findFirst2(os.path.dirname(pathName),\n-                  os.path.basename(pathName),\n-                  queryDirectoryRequest['FileInformationClass'], \n-                  smb.ATTR_DIRECTORY, isSMB2 = True )\n+                                                          os.path.basename(pathName),\n+                                                          queryDirectoryRequest['FileInformationClass'],\n+                                                          smb.ATTR_DIRECTORY, isSMB2=True)\n \n         if errorCode != STATUS_SUCCESS:\n             return [smb2.SMB2Error()], None, errorCode\n@@ -3499,7 +3558,7 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):\n         if searchCount == 0 and connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0:\n             return [smb2.SMB2Error()], None, STATUS_NO_SUCH_FILE\n \n-        if  connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] < 0:\n+        if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] < 0:\n             return [smb2.SMB2Error()], None, STATUS_NO_MORE_FILES\n \n         totalData = 0\n@@ -3511,20 +3570,20 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):\n                 searchResult[nItem]['NextEntryOffset'] = 0\n             data = searchResult[nItem].getData()\n             lenData = len(data)\n-            padLen = (8-(lenData % 8)) %8\n- \n-            if (totalData+lenData) >= queryDirectoryRequest['OutputBufferLength']:\n+            padLen = (8 - (lenData % 8)) % 8\n+\n+            if (totalData + lenData) >= queryDirectoryRequest['OutputBufferLength']:\n                 connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] -= 1\n                 break\n             else:\n-                respData += data + b'\\x00'*padLen\n+                respData += data + b'\\x00' * padLen\n                 totalData += lenData + padLen\n \n             if queryDirectoryRequest['Flags'] & smb2.SL_RETURN_SINGLE_ENTRY:\n                 break\n \n         if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] >= searchCount:\n-             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = -1\n+            connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = -1\n \n         respSMBCommand['OutputBufferOffset'] = 0x48\n         respSMBCommand['OutputBufferLength'] = totalData\n@@ -3553,14 +3612,13 @@ def smb2TreeDisconnect(connId, smbServer, recvPacket):\n \n         if recvPacket['TreeID'] in connData['ConnectedShares']:\n             smbServer.log(\"Disconnecting Share(%d:%s)\" % (\n-            recvPacket['TreeID'], connData['ConnectedShares'][recvPacket['TreeID']]['shareName']))\n-            del(connData['ConnectedShares'][recvPacket['TreeID']])\n+                recvPacket['TreeID'], connData['ConnectedShares'][recvPacket['TreeID']]['shareName']))\n+            del (connData['ConnectedShares'][recvPacket['TreeID']])\n             errorCode = STATUS_SUCCESS\n         else:\n             # STATUS_SMB_BAD_TID\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n@@ -3587,24 +3645,24 @@ def smb2Ioctl(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb2.SMB2Ioctl_Response()\n-        ioctlRequest   = smb2.SMB2Ioctl(recvPacket['Data'])\n+        ioctlRequest = smb2.SMB2Ioctl(recvPacket['Data'])\n \n         ioctls = smbServer.getIoctls()\n         if ioctlRequest['CtlCode'] in ioctls:\n             outputData, errorCode = ioctls[ioctlRequest['CtlCode']](connId, smbServer, ioctlRequest)\n             if errorCode == STATUS_SUCCESS:\n-                respSMBCommand['CtlCode']      = ioctlRequest['CtlCode']\n-                respSMBCommand['FileID']       = ioctlRequest['FileID']\n-                respSMBCommand['InputOffset']  = 0\n-                respSMBCommand['InputCount']   = 0\n+                respSMBCommand['CtlCode'] = ioctlRequest['CtlCode']\n+                respSMBCommand['FileID'] = ioctlRequest['FileID']\n+                respSMBCommand['InputOffset'] = 0\n+                respSMBCommand['InputCount'] = 0\n                 respSMBCommand['OutputOffset'] = 0x70\n-                respSMBCommand['OutputCount']  = len(outputData)\n-                respSMBCommand['Flags']        = 0\n-                respSMBCommand['Buffer']       = outputData\n+                respSMBCommand['OutputCount'] = len(outputData)\n+                respSMBCommand['Flags'] = 0\n+                respSMBCommand['Buffer'] = outputData\n             else:\n                 respSMBCommand = outputData\n         else:\n-            smbServer.log(\"Ioctl not implemented command: 0x%x\" % ioctlRequest['CtlCode'],logging.DEBUG)\n+            smbServer.log(\"Ioctl not implemented command: 0x%x\" % ioctlRequest['CtlCode'], logging.DEBUG)\n             errorCode = STATUS_INVALID_DEVICE_REQUEST\n             respSMBCommand = smb2.SMB2Error()\n \n@@ -3631,49 +3689,50 @@ def smb2Cancel(connId, smbServer, recvPacket):\n     @staticmethod\n     def default(connId, smbServer, recvPacket):\n         # By default we return an SMB Packet with error not implemented\n-        smbServer.log(\"Not implemented command: 0x%x\" % recvPacket['Command'],logging.DEBUG)\n+        smbServer.log(\"Not implemented command: 0x%x\" % recvPacket['Command'], logging.DEBUG)\n         return [smb2.SMB2Error()], None, STATUS_NOT_SUPPORTED\n \n+\n class Ioctls:\n-   @staticmethod\n-   def fsctlDfsGetReferrals(connId, smbServer, ioctlRequest):\n+    @staticmethod\n+    def fsctlDfsGetReferrals(connId, smbServer, ioctlRequest):\n         return smb2.SMB2Error(), STATUS_FS_DRIVER_REQUIRED\n \n-   @staticmethod\n-   def fsctlPipeTransceive(connId, smbServer, ioctlRequest):\n+    @staticmethod\n+    def fsctlPipeTransceive(connId, smbServer, ioctlRequest):\n         connData = smbServer.getConnectionData(connId)\n-        \n+\n         ioctlResponse = ''\n \n         if ioctlRequest['FileID'].getData() in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     errorCode = STATUS_INVALID_DEVICE_REQUEST\n-                 else:\n-                     sock = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['Socket']\n-                     sock.sendall(ioctlRequest['Buffer'])\n-                     ioctlResponse = sock.recv(ioctlRequest['MaxOutputResponse'])\n-             except Exception as e:\n-                 smbServer.log('fsctlPipeTransceive: %s ' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    errorCode = STATUS_INVALID_DEVICE_REQUEST\n+                else:\n+                    sock = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['Socket']\n+                    sock.sendall(ioctlRequest['Buffer'])\n+                    ioctlResponse = sock.recv(ioctlRequest['MaxOutputResponse'])\n+            except Exception as e:\n+                smbServer.log('fsctlPipeTransceive: %s ' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_DEVICE_REQUEST\n \n         smbServer.setConnectionData(connId, connData)\n         return ioctlResponse, errorCode\n \n-   @staticmethod\n-   def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):\n+    @staticmethod\n+    def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):\n         connData = smbServer.getConnectionData(connId)\n-        \n+\n         errorCode = STATUS_SUCCESS\n \n         validateNegotiateInfo = smb2.VALIDATE_NEGOTIATE_INFO(ioctlRequest['Buffer'])\n         validateNegotiateInfoResponse = smb2.VALIDATE_NEGOTIATE_INFO_RESPONSE()\n         validateNegotiateInfoResponse['Capabilities'] = 0\n-        validateNegotiateInfoResponse['Guid'] = b'A'*16\n+        validateNegotiateInfoResponse['Guid'] = b'A' * 16\n         validateNegotiateInfoResponse['SecurityMode'] = 1\n         validateNegotiateInfoResponse['Dialect'] = smb2.SMB2_DIALECT_002\n \n@@ -3682,15 +3741,15 @@ def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):\n \n \n class SMBSERVERHandler(socketserver.BaseRequestHandler):\n-    def __init__(self, request, client_address, server, select_poll = False):\n+    def __init__(self, request, client_address, server, select_poll=False):\n         self.__SMB = server\n         # In case of AF_INET6 the client_address contains 4 items, ignore the last 2\n         self.__ip, self.__port = client_address[:2]\n         self.__request = request\n         self.__connId = threading.currentThread().getName()\n-        self.__timeOut = 60*5\n+        self.__timeOut = 60 * 5\n         self.__select_poll = select_poll\n-        #self.__connId = os.getpid()\n+        # self.__connId = os.getpid()\n         socketserver.BaseRequestHandler.__init__(self, request, client_address, server)\n \n     def handle(self):\n@@ -3706,31 +3765,32 @@ def handle(self):\n                 except nmb.NetBIOSTimeout:\n                     raise\n                 except nmb.NetBIOSError:\n-                    break                 \n+                    break\n \n                 if p.get_type() == nmb.NETBIOS_SESSION_REQUEST:\n-                   # Someone is requesting a session, we're gonna accept them all :)\n-                   _, rn, my = p.get_trailer().split(b' ')\n-                   remote_name = nmb.decode_name(b'\\x20'+rn)\n-                   myname = nmb.decode_name(b'\\x20'+my)\n-                   self.__SMB.log(\"NetBIOS Session request (%s,%s,%s)\" % (self.__ip, remote_name[1].strip(), myname[1])) \n-                   r = nmb.NetBIOSSessionPacket()\n-                   r.set_type(nmb.NETBIOS_SESSION_POSITIVE_RESPONSE)\n-                   r.set_trailer(p.get_trailer())\n-                   self.__request.send(r.rawData())\n+                    # Someone is requesting a session, we're gonna accept them all :)\n+                    _, rn, my = p.get_trailer().split(b' ')\n+                    remote_name = nmb.decode_name(b'\\x20' + rn)\n+                    myname = nmb.decode_name(b'\\x20' + my)\n+                    self.__SMB.log(\n+                        \"NetBIOS Session request (%s,%s,%s)\" % (self.__ip, remote_name[1].strip(), myname[1]))\n+                    r = nmb.NetBIOSSessionPacket()\n+                    r.set_type(nmb.NETBIOS_SESSION_POSITIVE_RESPONSE)\n+                    r.set_trailer(p.get_trailer())\n+                    self.__request.send(r.rawData())\n                 else:\n-                   resp = self.__SMB.processRequest(self.__connId, p.get_trailer())\n-                   # Send all the packets received. Except for big transactions this should be\n-                   # a single packet\n-                   for i in resp:\n-                       if hasattr(i, 'getData'):\n-                           session.send_packet(i.getData())\n-                       else:\n-                           session.send_packet(i)\n+                    resp = self.__SMB.processRequest(self.__connId, p.get_trailer())\n+                    # Send all the packets received. Except for big transactions this should be\n+                    # a single packet\n+                    for i in resp:\n+                        if hasattr(i, 'getData'):\n+                            session.send_packet(i.getData())\n+                        else:\n+                            session.send_packet(i)\n             except Exception as e:\n                 self.__SMB.log(\"Handle: %s\" % e)\n-                #import traceback\n-                #traceback.print_exc()\n+                # import traceback\n+                # traceback.print_exc()\n                 break\n \n     def finish(self):\n@@ -3739,18 +3799,19 @@ def finish(self):\n         self.__SMB.removeConnection(self.__connId)\n         return socketserver.BaseRequestHandler.finish(self)\n \n+\n class SMBSERVER(socketserver.ThreadingMixIn, socketserver.TCPServer):\n-#class SMBSERVER(socketserver.ForkingMixIn, socketserver.TCPServer):\n-    def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser = None):\n+    # class SMBSERVER(socketserver.ForkingMixIn, socketserver.TCPServer):\n+    def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser=None):\n         socketserver.TCPServer.allow_reuse_address = True\n         socketserver.TCPServer.__init__(self, server_address, handler_class)\n \n         # Server name and OS to be presented whenever is necessary\n-        self.__serverName   = ''\n-        self.__serverOS     = ''\n+        self.__serverName = ''\n+        self.__serverOS = ''\n         self.__serverDomain = ''\n-        self.__challenge    = ''\n-        self.__log          = None\n+        self.__challenge = ''\n+        self.__log = None\n \n         # Our ConfigParser data\n         self.__serverConfig = config_parser\n@@ -3769,108 +3830,108 @@ def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser\n \n         # SMB2 Support flag = default not active\n         self.__SMB2Support = False\n- \n+\n         # Our list of commands we will answer, by default the NOT IMPLEMENTED one\n         self.__smbCommandsHandler = SMBCommands()\n-        self.__smbTrans2Handler   = TRANS2Commands()\n-        self.__smbTransHandler    = TRANSCommands()\n-        self.__smbNTTransHandler  = NTTRANSCommands()\n+        self.__smbTrans2Handler = TRANS2Commands()\n+        self.__smbTransHandler = TRANSCommands()\n+        self.__smbNTTransHandler = NTTRANSCommands()\n         self.__smb2CommandsHandler = SMB2Commands()\n-        self.__IoctlHandler       = Ioctls()\n+        self.__IoctlHandler = Ioctls()\n \n         self.__smbNTTransCommands = {\n-        # NT IOCTL, can't find doc for this\n-        0xff                               :self.__smbNTTransHandler.default\n+            # NT IOCTL, can't find doc for this\n+            0xff: self.__smbNTTransHandler.default\n         }\n \n-        self.__smbTransCommands  = {\n-'\\\\PIPE\\\\LANMAN'                       :self.__smbTransHandler.lanMan,\n-smb.SMB.TRANS_TRANSACT_NMPIPE          :self.__smbTransHandler.transactNamedPipe,\n+        self.__smbTransCommands = {\n+            '\\\\PIPE\\\\LANMAN': self.__smbTransHandler.lanMan,\n+            smb.SMB.TRANS_TRANSACT_NMPIPE: self.__smbTransHandler.transactNamedPipe,\n         }\n         self.__smbTrans2Commands = {\n- smb.SMB.TRANS2_FIND_FIRST2            :self.__smbTrans2Handler.findFirst2,\n- smb.SMB.TRANS2_FIND_NEXT2             :self.__smbTrans2Handler.findNext2,\n- smb.SMB.TRANS2_QUERY_FS_INFORMATION   :self.__smbTrans2Handler.queryFsInformation,\n- smb.SMB.TRANS2_QUERY_PATH_INFORMATION :self.__smbTrans2Handler.queryPathInformation,\n- smb.SMB.TRANS2_QUERY_FILE_INFORMATION :self.__smbTrans2Handler.queryFileInformation,\n- smb.SMB.TRANS2_SET_FILE_INFORMATION   :self.__smbTrans2Handler.setFileInformation,\n- smb.SMB.TRANS2_SET_PATH_INFORMATION   :self.__smbTrans2Handler.setPathInformation\n+            smb.SMB.TRANS2_FIND_FIRST2: self.__smbTrans2Handler.findFirst2,\n+            smb.SMB.TRANS2_FIND_NEXT2: self.__smbTrans2Handler.findNext2,\n+            smb.SMB.TRANS2_QUERY_FS_INFORMATION: self.__smbTrans2Handler.queryFsInformation,\n+            smb.SMB.TRANS2_QUERY_PATH_INFORMATION: self.__smbTrans2Handler.queryPathInformation,\n+            smb.SMB.TRANS2_QUERY_FILE_INFORMATION: self.__smbTrans2Handler.queryFileInformation,\n+            smb.SMB.TRANS2_SET_FILE_INFORMATION: self.__smbTrans2Handler.setFileInformation,\n+            smb.SMB.TRANS2_SET_PATH_INFORMATION: self.__smbTrans2Handler.setPathInformation\n         }\n \n-        self.__smbCommands = { \n- #smb.SMB.SMB_COM_FLUSH:              self.__smbCommandsHandler.smbComFlush, \n- smb.SMB.SMB_COM_CREATE_DIRECTORY:   self.__smbCommandsHandler.smbComCreateDirectory, \n- smb.SMB.SMB_COM_DELETE_DIRECTORY:   self.__smbCommandsHandler.smbComDeleteDirectory, \n- smb.SMB.SMB_COM_RENAME:             self.__smbCommandsHandler.smbComRename, \n- smb.SMB.SMB_COM_DELETE:             self.__smbCommandsHandler.smbComDelete, \n- smb.SMB.SMB_COM_NEGOTIATE:          self.__smbCommandsHandler.smbComNegotiate, \n- smb.SMB.SMB_COM_SESSION_SETUP_ANDX: self.__smbCommandsHandler.smbComSessionSetupAndX,\n- smb.SMB.SMB_COM_LOGOFF_ANDX:        self.__smbCommandsHandler.smbComLogOffAndX,\n- smb.SMB.SMB_COM_TREE_CONNECT_ANDX:  self.__smbCommandsHandler.smbComTreeConnectAndX,\n- smb.SMB.SMB_COM_TREE_DISCONNECT:    self.__smbCommandsHandler.smbComTreeDisconnect,\n- smb.SMB.SMB_COM_ECHO:               self.__smbCommandsHandler.smbComEcho,\n- smb.SMB.SMB_COM_QUERY_INFORMATION:  self.__smbCommandsHandler.smbQueryInformation,\n- smb.SMB.SMB_COM_TRANSACTION2:       self.__smbCommandsHandler.smbTransaction2,\n- smb.SMB.SMB_COM_TRANSACTION:        self.__smbCommandsHandler.smbTransaction,\n- # Not needed for now\n- smb.SMB.SMB_COM_NT_TRANSACT:        self.__smbCommandsHandler.smbNTTransact,\n- smb.SMB.SMB_COM_QUERY_INFORMATION_DISK: self.__smbCommandsHandler.smbQueryInformationDisk,\n- smb.SMB.SMB_COM_OPEN_ANDX:          self.__smbCommandsHandler.smbComOpenAndX,\n- smb.SMB.SMB_COM_QUERY_INFORMATION2: self.__smbCommandsHandler.smbComQueryInformation2,\n- smb.SMB.SMB_COM_READ_ANDX:          self.__smbCommandsHandler.smbComReadAndX,\n- smb.SMB.SMB_COM_READ:               self.__smbCommandsHandler.smbComRead,\n- smb.SMB.SMB_COM_WRITE_ANDX:         self.__smbCommandsHandler.smbComWriteAndX,\n- smb.SMB.SMB_COM_WRITE:              self.__smbCommandsHandler.smbComWrite,\n- smb.SMB.SMB_COM_CLOSE:              self.__smbCommandsHandler.smbComClose,\n- smb.SMB.SMB_COM_LOCKING_ANDX:       self.__smbCommandsHandler.smbComLockingAndX,\n- smb.SMB.SMB_COM_NT_CREATE_ANDX:     self.__smbCommandsHandler.smbComNtCreateAndX,\n- 0xFF:                               self.__smbCommandsHandler.default\n-}\n-\n-        self.__smb2Ioctls = { \n- smb2.FSCTL_DFS_GET_REFERRALS:            self.__IoctlHandler.fsctlDfsGetReferrals, \n-# smb2.FSCTL_PIPE_PEEK:                    self.__IoctlHandler.fsctlPipePeek, \n-# smb2.FSCTL_PIPE_WAIT:                    self.__IoctlHandler.fsctlPipeWait, \n- smb2.FSCTL_PIPE_TRANSCEIVE:              self.__IoctlHandler.fsctlPipeTransceive, \n-# smb2.FSCTL_SRV_COPYCHUNK:                self.__IoctlHandler.fsctlSrvCopyChunk, \n-# smb2.FSCTL_SRV_ENUMERATE_SNAPSHOTS:      self.__IoctlHandler.fsctlSrvEnumerateSnapshots, \n-# smb2.FSCTL_SRV_REQUEST_RESUME_KEY:       self.__IoctlHandler.fsctlSrvRequestResumeKey, \n-# smb2.FSCTL_SRV_READ_HASH:                self.__IoctlHandler.fsctlSrvReadHash, \n-# smb2.FSCTL_SRV_COPYCHUNK_WRITE:          self.__IoctlHandler.fsctlSrvCopyChunkWrite, \n-# smb2.FSCTL_LMR_REQUEST_RESILIENCY:       self.__IoctlHandler.fsctlLmrRequestResiliency, \n-# smb2.FSCTL_QUERY_NETWORK_INTERFACE_INFO: self.__IoctlHandler.fsctlQueryNetworkInterfaceInfo, \n-# smb2.FSCTL_SET_REPARSE_POINT:            self.__IoctlHandler.fsctlSetReparsePoint, \n-# smb2.FSCTL_DFS_GET_REFERRALS_EX:         self.__IoctlHandler.fsctlDfsGetReferralsEx, \n-# smb2.FSCTL_FILE_LEVEL_TRIM:              self.__IoctlHandler.fsctlFileLevelTrim, \n- smb2.FSCTL_VALIDATE_NEGOTIATE_INFO:      self.__IoctlHandler.fsctlValidateNegotiateInfo, \n-}\n-\n-        self.__smb2Commands = { \n- smb2.SMB2_NEGOTIATE:       self.__smb2CommandsHandler.smb2Negotiate, \n- smb2.SMB2_SESSION_SETUP:   self.__smb2CommandsHandler.smb2SessionSetup, \n- smb2.SMB2_LOGOFF:          self.__smb2CommandsHandler.smb2Logoff, \n- smb2.SMB2_TREE_CONNECT:    self.__smb2CommandsHandler.smb2TreeConnect, \n- smb2.SMB2_TREE_DISCONNECT: self.__smb2CommandsHandler.smb2TreeDisconnect, \n- smb2.SMB2_CREATE:          self.__smb2CommandsHandler.smb2Create, \n- smb2.SMB2_CLOSE:           self.__smb2CommandsHandler.smb2Close, \n- smb2.SMB2_FLUSH:           self.__smb2CommandsHandler.smb2Flush, \n- smb2.SMB2_READ:            self.__smb2CommandsHandler.smb2Read, \n- smb2.SMB2_WRITE:           self.__smb2CommandsHandler.smb2Write, \n- smb2.SMB2_LOCK:            self.__smb2CommandsHandler.smb2Lock, \n- smb2.SMB2_IOCTL:           self.__smb2CommandsHandler.smb2Ioctl, \n- smb2.SMB2_CANCEL:          self.__smb2CommandsHandler.smb2Cancel, \n- smb2.SMB2_ECHO:            self.__smb2CommandsHandler.smb2Echo, \n- smb2.SMB2_QUERY_DIRECTORY: self.__smb2CommandsHandler.smb2QueryDirectory, \n- smb2.SMB2_CHANGE_NOTIFY:   self.__smb2CommandsHandler.smb2ChangeNotify, \n- smb2.SMB2_QUERY_INFO:      self.__smb2CommandsHandler.smb2QueryInfo, \n- smb2.SMB2_SET_INFO:        self.__smb2CommandsHandler.smb2SetInfo, \n-# smb2.SMB2_OPLOCK_BREAK:    self.__smb2CommandsHandler.smb2SessionSetup, \n- 0xFF:                      self.__smb2CommandsHandler.default\n-}\n+        self.__smbCommands = {\n+            # smb.SMB.SMB_COM_FLUSH:              self.__smbCommandsHandler.smbComFlush,\n+            smb.SMB.SMB_COM_CREATE_DIRECTORY: self.__smbCommandsHandler.smbComCreateDirectory,\n+            smb.SMB.SMB_COM_DELETE_DIRECTORY: self.__smbCommandsHandler.smbComDeleteDirectory,\n+            smb.SMB.SMB_COM_RENAME: self.__smbCommandsHandler.smbComRename,\n+            smb.SMB.SMB_COM_DELETE: self.__smbCommandsHandler.smbComDelete,\n+            smb.SMB.SMB_COM_NEGOTIATE: self.__smbCommandsHandler.smbComNegotiate,\n+            smb.SMB.SMB_COM_SESSION_SETUP_ANDX: self.__smbCommandsHandler.smbComSessionSetupAndX,\n+            smb.SMB.SMB_COM_LOGOFF_ANDX: self.__smbCommandsHandler.smbComLogOffAndX,\n+            smb.SMB.SMB_COM_TREE_CONNECT_ANDX: self.__smbCommandsHandler.smbComTreeConnectAndX,\n+            smb.SMB.SMB_COM_TREE_DISCONNECT: self.__smbCommandsHandler.smbComTreeDisconnect,\n+            smb.SMB.SMB_COM_ECHO: self.__smbCommandsHandler.smbComEcho,\n+            smb.SMB.SMB_COM_QUERY_INFORMATION: self.__smbCommandsHandler.smbQueryInformation,\n+            smb.SMB.SMB_COM_TRANSACTION2: self.__smbCommandsHandler.smbTransaction2,\n+            smb.SMB.SMB_COM_TRANSACTION: self.__smbCommandsHandler.smbTransaction,\n+            # Not needed for now\n+            smb.SMB.SMB_COM_NT_TRANSACT: self.__smbCommandsHandler.smbNTTransact,\n+            smb.SMB.SMB_COM_QUERY_INFORMATION_DISK: self.__smbCommandsHandler.smbQueryInformationDisk,\n+            smb.SMB.SMB_COM_OPEN_ANDX: self.__smbCommandsHandler.smbComOpenAndX,\n+            smb.SMB.SMB_COM_QUERY_INFORMATION2: self.__smbCommandsHandler.smbComQueryInformation2,\n+            smb.SMB.SMB_COM_READ_ANDX: self.__smbCommandsHandler.smbComReadAndX,\n+            smb.SMB.SMB_COM_READ: self.__smbCommandsHandler.smbComRead,\n+            smb.SMB.SMB_COM_WRITE_ANDX: self.__smbCommandsHandler.smbComWriteAndX,\n+            smb.SMB.SMB_COM_WRITE: self.__smbCommandsHandler.smbComWrite,\n+            smb.SMB.SMB_COM_CLOSE: self.__smbCommandsHandler.smbComClose,\n+            smb.SMB.SMB_COM_LOCKING_ANDX: self.__smbCommandsHandler.smbComLockingAndX,\n+            smb.SMB.SMB_COM_NT_CREATE_ANDX: self.__smbCommandsHandler.smbComNtCreateAndX,\n+            0xFF: self.__smbCommandsHandler.default\n+        }\n+\n+        self.__smb2Ioctls = {\n+            smb2.FSCTL_DFS_GET_REFERRALS: self.__IoctlHandler.fsctlDfsGetReferrals,\n+            # smb2.FSCTL_PIPE_PEEK:                    self.__IoctlHandler.fsctlPipePeek,\n+            # smb2.FSCTL_PIPE_WAIT:                    self.__IoctlHandler.fsctlPipeWait,\n+            smb2.FSCTL_PIPE_TRANSCEIVE: self.__IoctlHandler.fsctlPipeTransceive,\n+            # smb2.FSCTL_SRV_COPYCHUNK:                self.__IoctlHandler.fsctlSrvCopyChunk,\n+            # smb2.FSCTL_SRV_ENUMERATE_SNAPSHOTS:      self.__IoctlHandler.fsctlSrvEnumerateSnapshots,\n+            # smb2.FSCTL_SRV_REQUEST_RESUME_KEY:       self.__IoctlHandler.fsctlSrvRequestResumeKey,\n+            # smb2.FSCTL_SRV_READ_HASH:                self.__IoctlHandler.fsctlSrvReadHash,\n+            # smb2.FSCTL_SRV_COPYCHUNK_WRITE:          self.__IoctlHandler.fsctlSrvCopyChunkWrite,\n+            # smb2.FSCTL_LMR_REQUEST_RESILIENCY:       self.__IoctlHandler.fsctlLmrRequestResiliency,\n+            # smb2.FSCTL_QUERY_NETWORK_INTERFACE_INFO: self.__IoctlHandler.fsctlQueryNetworkInterfaceInfo,\n+            # smb2.FSCTL_SET_REPARSE_POINT:            self.__IoctlHandler.fsctlSetReparsePoint,\n+            # smb2.FSCTL_DFS_GET_REFERRALS_EX:         self.__IoctlHandler.fsctlDfsGetReferralsEx,\n+            # smb2.FSCTL_FILE_LEVEL_TRIM:              self.__IoctlHandler.fsctlFileLevelTrim,\n+            smb2.FSCTL_VALIDATE_NEGOTIATE_INFO: self.__IoctlHandler.fsctlValidateNegotiateInfo,\n+        }\n+\n+        self.__smb2Commands = {\n+            smb2.SMB2_NEGOTIATE: self.__smb2CommandsHandler.smb2Negotiate,\n+            smb2.SMB2_SESSION_SETUP: self.__smb2CommandsHandler.smb2SessionSetup,\n+            smb2.SMB2_LOGOFF: self.__smb2CommandsHandler.smb2Logoff,\n+            smb2.SMB2_TREE_CONNECT: self.__smb2CommandsHandler.smb2TreeConnect,\n+            smb2.SMB2_TREE_DISCONNECT: self.__smb2CommandsHandler.smb2TreeDisconnect,\n+            smb2.SMB2_CREATE: self.__smb2CommandsHandler.smb2Create,\n+            smb2.SMB2_CLOSE: self.__smb2CommandsHandler.smb2Close,\n+            smb2.SMB2_FLUSH: self.__smb2CommandsHandler.smb2Flush,\n+            smb2.SMB2_READ: self.__smb2CommandsHandler.smb2Read,\n+            smb2.SMB2_WRITE: self.__smb2CommandsHandler.smb2Write,\n+            smb2.SMB2_LOCK: self.__smb2CommandsHandler.smb2Lock,\n+            smb2.SMB2_IOCTL: self.__smb2CommandsHandler.smb2Ioctl,\n+            smb2.SMB2_CANCEL: self.__smb2CommandsHandler.smb2Cancel,\n+            smb2.SMB2_ECHO: self.__smb2CommandsHandler.smb2Echo,\n+            smb2.SMB2_QUERY_DIRECTORY: self.__smb2CommandsHandler.smb2QueryDirectory,\n+            smb2.SMB2_CHANGE_NOTIFY: self.__smb2CommandsHandler.smb2ChangeNotify,\n+            smb2.SMB2_QUERY_INFO: self.__smb2CommandsHandler.smb2QueryInfo,\n+            smb2.SMB2_SET_INFO: self.__smb2CommandsHandler.smb2SetInfo,\n+            # smb2.SMB2_OPLOCK_BREAK:    self.__smb2CommandsHandler.smb2SessionSetup,\n+            0xFF: self.__smb2CommandsHandler.default\n+        }\n \n         # List of active connections\n         self.__activeConnections = {}\n-  \n+\n     def getIoctls(self):\n         return self.__smb2Ioctls\n \n@@ -3879,39 +3940,39 @@ def getCredentials(self):\n \n     def removeConnection(self, name):\n         try:\n-           del(self.__activeConnections[name])\n+            del (self.__activeConnections[name])\n         except:\n-           pass\n+            pass\n         self.log(\"Remaining connections %s\" % list(self.__activeConnections.keys()))\n \n     def addConnection(self, name, ip, port):\n         self.__activeConnections[name] = {}\n         # Let's init with some know stuff we will need to have\n         # TODO: Document what's in there\n-        #print \"Current Connections\", self.__activeConnections.keys()\n-        self.__activeConnections[name]['PacketNum']       = 0\n-        self.__activeConnections[name]['ClientIP']        = ip\n-        self.__activeConnections[name]['ClientPort']      = port\n-        self.__activeConnections[name]['Uid']             = 0\n+        # print \"Current Connections\", self.__activeConnections.keys()\n+        self.__activeConnections[name]['PacketNum'] = 0\n+        self.__activeConnections[name]['ClientIP'] = ip\n+        self.__activeConnections[name]['ClientPort'] = port\n+        self.__activeConnections[name]['Uid'] = 0\n         self.__activeConnections[name]['ConnectedShares'] = {}\n-        self.__activeConnections[name]['OpenedFiles']     = {}\n+        self.__activeConnections[name]['OpenedFiles'] = {}\n         # SID results for findfirst2\n-        self.__activeConnections[name]['SIDs']            = {}\n-        self.__activeConnections[name]['LastRequest']     = {}\n-        self.__activeConnections[name]['SignatureEnabled']= False\n-        self.__activeConnections[name]['SigningChallengeResponse']= ''\n-        self.__activeConnections[name]['SigningSessionKey']= b''\n-        self.__activeConnections[name]['Authenticated']= False\n+        self.__activeConnections[name]['SIDs'] = {}\n+        self.__activeConnections[name]['LastRequest'] = {}\n+        self.__activeConnections[name]['SignatureEnabled'] = False\n+        self.__activeConnections[name]['SigningChallengeResponse'] = ''\n+        self.__activeConnections[name]['SigningSessionKey'] = b''\n+        self.__activeConnections[name]['Authenticated'] = False\n \n     def getActiveConnections(self):\n         return self.__activeConnections\n \n     def setConnectionData(self, connId, data):\n         self.__activeConnections[connId] = data\n-        #print \"setConnectionData\" \n-        #print self.__activeConnections\n+        # print \"setConnectionData\"\n+        # print self.__activeConnections\n \n-    def getConnectionData(self, connId, checkStatus = True):\n+    def getConnectionData(self, connId, checkStatus=True):\n         conn = self.__activeConnections[connId]\n         if checkStatus is True:\n             if ('Authenticated' in conn) is not True:\n@@ -3928,16 +3989,16 @@ def registerNamedPipe(self, pipeName, address):\n \n     def unregisterNamedPipe(self, pipeName):\n         if pipeName in self.__registeredNamedPipes:\n-            del(self.__registeredNamedPipes[str(pipeName)])\n+            del (self.__registeredNamedPipes[str(pipeName)])\n             return True\n         return False\n \n     def unregisterTransaction(self, transCommand):\n         if transCommand in self.__smbTransCommands:\n-           del(self.__smbTransCommands[transCommand])\n+            del (self.__smbTransCommands[transCommand])\n \n     def hookTransaction(self, transCommand, callback):\n-        # If you call this function, callback will replace \n+        # If you call this function, callback will replace\n         # the current Transaction sub command.\n         # (don't get confused with the Transaction smbCommand)\n         # If the transaction sub command doesn't not exist, it is added\n@@ -3948,14 +4009,14 @@ def hookTransaction(self, transCommand, callback):\n         #\n         # WHERE:\n         #\n-        # connId      : the connection Id, used to grab\/update information about \n+        # connId      : the connection Id, used to grab\/update information about\n         #               the current connection\n-        # smbServer   : the SMBServer instance available for you to ask \n+        # smbServer   : the SMBServer instance available for you to ask\n         #               configuration data\n         # recvPacket  : the full SMBPacket that triggered this command\n         # parameters  : the transaction parameters\n         # data        : the transaction data\n-        # maxDataCount: the max amount of data that can be transferred agreed \n+        # maxDataCount: the max amount of data that can be transferred agreed\n         #               with the client\n         #\n         # and MUST return:\n@@ -3966,53 +4027,53 @@ def hookTransaction(self, transCommand, callback):\n         # respSetup: the setup response of the transaction\n         # respParameters: the parameters response of the transaction\n         # respData: the data response of the transaction\n-        # errorCode: the NT error code \n+        # errorCode: the NT error code\n \n         if transCommand in self.__smbTransCommands:\n-           originalCommand = self.__smbTransCommands[transCommand]\n+            originalCommand = self.__smbTransCommands[transCommand]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smbTransCommands[transCommand] = callback\n         return originalCommand\n \n     def unregisterTransaction2(self, transCommand):\n         if transCommand in self.__smbTrans2Commands:\n-           del(self.__smbTrans2Commands[transCommand])\n+            del (self.__smbTrans2Commands[transCommand])\n \n     def hookTransaction2(self, transCommand, callback):\n         # Here we should add to __smbTrans2Commands\n         # Same description as Transaction\n         if transCommand in self.__smbTrans2Commands:\n-           originalCommand = self.__smbTrans2Commands[transCommand]\n+            originalCommand = self.__smbTrans2Commands[transCommand]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smbTrans2Commands[transCommand] = callback\n         return originalCommand\n \n     def unregisterNTTransaction(self, transCommand):\n         if transCommand in self.__smbNTTransCommands:\n-           del(self.__smbNTTransCommands[transCommand])\n+            del (self.__smbNTTransCommands[transCommand])\n \n     def hookNTTransaction(self, transCommand, callback):\n         # Here we should add to __smbNTTransCommands\n         # Same description as Transaction\n         if transCommand in self.__smbNTTransCommands:\n-           originalCommand = self.__smbNTTransCommands[transCommand]\n+            originalCommand = self.__smbNTTransCommands[transCommand]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smbNTTransCommands[transCommand] = callback\n         return originalCommand\n \n     def unregisterSmbCommand(self, smbCommand):\n         if smbCommand in self.__smbCommands:\n-           del(self.__smbCommands[smbCommand])\n+            del (self.__smbCommands[smbCommand])\n \n     def hookSmbCommand(self, smbCommand, callback):\n         # Here we should add to self.__smbCommands\n-        # If you call this function, callback will replace \n+        # If you call this function, callback will replace\n         # the current smbCommand.\n         # If smbCommand doesn't not exist, it is added\n         # If SMB command exists, it returns the original function replaced\n@@ -4022,19 +4083,19 @@ def hookSmbCommand(self, smbCommand, callback):\n         #\n         # WHERE:\n         #\n-        # connId    : the connection Id, used to grab\/update information about \n+        # connId    : the connection Id, used to grab\/update information about\n         #             the current connection\n-        # smbServer : the SMBServer instance available for you to ask \n+        # smbServer : the SMBServer instance available for you to ask\n         #             configuration data\n-        # SMBCommand: the SMBCommand itself, with its data and parameters. \n+        # SMBCommand: the SMBCommand itself, with its data and parameters.\n         #             Check smb.py:SMBCommand() for a reference\n         # recvPacket: the full SMBPacket that triggered this command\n         #\n         # and MUST return:\n         # <list of respSMBCommands>, <list of packets>, errorCode\n-        # <list of packets> has higher preference over commands, in case you \n-        # want to change the whole packet \n-        # errorCode: the NT error code \n+        # <list of packets> has higher preference over commands, in case you\n+        # want to change the whole packet\n+        # errorCode: the NT error code\n         #\n         # For SMB_COM_TRANSACTION2, SMB_COM_TRANSACTION and SMB_COM_NT_TRANSACT\n         # the callback function is slightly different:\n@@ -4042,46 +4103,46 @@ def hookSmbCommand(self, smbCommand, callback):\n         # callback(connId, smbServer, SMBCommand, recvPacket, transCommands)\n         #\n         # WHERE:\n-        # \n+        #\n         # transCommands: a list of transaction subcommands already registered\n         #\n \n         if smbCommand in self.__smbCommands:\n-           originalCommand = self.__smbCommands[smbCommand]\n+            originalCommand = self.__smbCommands[smbCommand]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smbCommands[smbCommand] = callback\n         return originalCommand\n-  \n+\n     def unregisterSmb2Command(self, smb2Command):\n         if smb2Command in self.__smb2Commands:\n-           del(self.__smb2Commands[smb2Command])\n+            del (self.__smb2Commands[smb2Command])\n \n     def hookSmb2Command(self, smb2Command, callback):\n         if smb2Command in self.__smb2Commands:\n-           originalCommand = self.__smb2Commands[smb2Command]\n+            originalCommand = self.__smb2Commands[smb2Command]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smb2Commands[smb2Command] = callback\n         return originalCommand\n \n     def log(self, msg, level=logging.INFO):\n-        self.__log.log(level,msg)\n+        self.__log.log(level, msg)\n \n     def getServerName(self):\n         return self.__serverName\n \n     def getServerOS(self):\n         return self.__serverOS\n-  \n+\n     def getServerDomain(self):\n         return self.__serverDomain\n \n     def getSMBChallenge(self):\n         return self.__challenge\n-  \n+\n     def getServerConfig(self):\n         return self.__serverConfig\n \n@@ -4116,47 +4177,47 @@ def signSMBv1(self, connData, packet, signingSessionKey, signingChallengeRespons\n         # The resulting 8-byte signature MUST be copied into the SecuritySignature field of the SMB Header,\n         # after which the message can be transmitted.\n \n-        #print \"seq(%d) signingSessionKey %r, signingChallengeResponse %r\" % (connData['SignSequenceNumber'], signingSessionKey, signingChallengeResponse)\n-        packet['SecurityFeatures'] = struct.pack('<q',connData['SignSequenceNumber'])\n+        # print \"seq(%d) signingSessionKey %r, signingChallengeResponse %r\" % (connData['SignSequenceNumber'], signingSessionKey, signingChallengeResponse)\n+        packet['SecurityFeatures'] = struct.pack('<q', connData['SignSequenceNumber'])\n         # Sign with the sequence\n         m = hashlib.md5()\n-        m.update( signingSessionKey )\n-        m.update( signingChallengeResponse )\n+        m.update(signingSessionKey)\n+        m.update(signingChallengeResponse)\n         if hasattr(packet, 'getData'):\n-            m.update( packet.getData() )\n+            m.update(packet.getData())\n         else:\n-            m.update( packet )\n+            m.update(packet)\n         # Replace sequence with acual hash\n         packet['SecurityFeatures'] = m.digest()[:8]\n-        connData['SignSequenceNumber'] +=2\n+        connData['SignSequenceNumber'] += 2\n \n     def signSMBv2(self, packet, signingSessionKey):\n-        packet['Signature'] = b'\\x00'*16\n+        packet['Signature'] = b'\\x00' * 16\n         packet['Flags'] |= smb2.SMB2_FLAGS_SIGNED\n         signature = hmac.new(signingSessionKey, packet.getData(), hashlib.sha256).digest()\n         packet['Signature'] = signature[:16]\n-        #print \"%s\" % packet['Signature'].encode('hex')\n+        # print \"%s\" % packet['Signature'].encode('hex')\n \n     def processRequest(self, connId, data):\n \n         # TODO: Process batched commands.\n-        isSMB2      = False\n-        SMBCommand  = None\n+        isSMB2 = False\n+        SMBCommand = None\n         try:\n-            packet = smb.NewSMBPacket(data = data)\n-            SMBCommand  = smb.SMBCommand(packet['Data'][0])\n+            packet = smb.NewSMBPacket(data=data)\n+            SMBCommand = smb.SMBCommand(packet['Data'][0])\n         except:\n             # Maybe a SMB2 packet?\n-            packet = smb2.SMB2Packet(data = data)\n+            packet = smb2.SMB2Packet(data=data)\n             connData = self.getConnectionData(connId, False)\n             self.signSMBv2(packet, connData['SigningSessionKey'])\n             isSMB2 = True\n \n-        connData    = self.getConnectionData(connId, False)\n+        connData = self.getConnectionData(connId, False)\n \n         # We might have compound requests\n         compoundedPacketsResponse = []\n-        compoundedPackets         = []\n+        compoundedPackets = []\n         try:\n             # Search out list of implemented commands\n             # We provide them with:\n@@ -4173,7 +4234,8 @@ def processRequest(self, connId, data):\n             # errorCode   : self explanatory\n             if isSMB2 is False:\n                 # Is the client authenticated already?\n-                if connData['Authenticated'] is False and packet['Command'] not in (smb.SMB.SMB_COM_NEGOTIATE, smb.SMB.SMB_COM_SESSION_SETUP_ANDX):\n+                if connData['Authenticated'] is False and packet['Command'] not in (\n+                smb.SMB.SMB_COM_NEGOTIATE, smb.SMB.SMB_COM_SESSION_SETUP_ANDX):\n                     # Nope.. in that case he should only ask for a few commands, if not throw him out.\n                     errorCode = STATUS_ACCESS_DENIED\n                     respPackets = None\n@@ -4181,65 +4243,68 @@ def processRequest(self, connId, data):\n                 else:\n                     if packet['Command'] == smb.SMB.SMB_COM_TRANSACTION2:\n                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                      connId,\n-                                      self,\n-                                      SMBCommand,\n-                                      packet,\n-                                      self.__smbTrans2Commands)\n+                            connId,\n+                            self,\n+                            SMBCommand,\n+                            packet,\n+                            self.__smbTrans2Commands)\n                     elif packet['Command'] == smb.SMB.SMB_COM_NT_TRANSACT:\n                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                      connId,\n-                                      self,\n-                                      SMBCommand,\n-                                      packet,\n-                                      self.__smbNTTransCommands)\n+                            connId,\n+                            self,\n+                            SMBCommand,\n+                            packet,\n+                            self.__smbNTTransCommands)\n                     elif packet['Command'] == smb.SMB.SMB_COM_TRANSACTION:\n                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                      connId,\n-                                      self,\n-                                      SMBCommand,\n-                                      packet,\n-                                      self.__smbTransCommands)\n+                            connId,\n+                            self,\n+                            SMBCommand,\n+                            packet,\n+                            self.__smbTransCommands)\n                     else:\n                         if packet['Command'] in self.__smbCommands:\n-                           if self.__SMB2Support is True:\n-                               if packet['Command'] == smb.SMB.SMB_COM_NEGOTIATE:\n-                                   try:\n-                                       respCommands, respPackets, errorCode = self.__smb2Commands[smb2.SMB2_NEGOTIATE](connId, self, packet, True)\n-                                       isSMB2 = True\n-                                   except Exception as e:\n-                                       import traceback\n-                                       traceback.print_exc()\n-                                       self.log('SMB2_NEGOTIATE: %s' % e, logging.ERROR)\n-                                       # If something went wrong, let's fallback to SMB1\n-                                       respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                           connId,\n-                                           self,\n-                                           SMBCommand,\n-                                           packet)\n-                                       #self.__SMB2Support = False\n-                                       pass\n-                               else:\n-                                   respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                           connId,\n-                                           self,\n-                                           SMBCommand,\n-                                           packet)\n-                           else:\n-                               respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                           connId,\n-                                           self,\n-                                           SMBCommand,\n-                                           packet)\n+                            if self.__SMB2Support is True:\n+                                if packet['Command'] == smb.SMB.SMB_COM_NEGOTIATE:\n+                                    try:\n+                                        respCommands, respPackets, errorCode = self.__smb2Commands[smb2.SMB2_NEGOTIATE](\n+                                            connId, self, packet, True)\n+                                        isSMB2 = True\n+                                    except Exception as e:\n+                                        import traceback\n+                                        traceback.print_exc()\n+                                        self.log('SMB2_NEGOTIATE: %s' % e, logging.ERROR)\n+                                        # If something went wrong, let's fallback to SMB1\n+                                        respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n+                                            connId,\n+                                            self,\n+                                            SMBCommand,\n+                                            packet)\n+                                        # self.__SMB2Support = False\n+                                        pass\n+                                else:\n+                                    respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n+                                        connId,\n+                                        self,\n+                                        SMBCommand,\n+                                        packet)\n+                            else:\n+                                respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n+                                    connId,\n+                                    self,\n+                                    SMBCommand,\n+                                    packet)\n                         else:\n-                           respCommands, respPackets, errorCode = self.__smbCommands[255](connId, self, SMBCommand, packet)\n+                            respCommands, respPackets, errorCode = self.__smbCommands[255](connId, self, SMBCommand,\n+                                                                                           packet)\n \n                 compoundedPacketsResponse.append((respCommands, respPackets, errorCode))\n                 compoundedPackets.append(packet)\n \n             else:\n                 # Is the client authenticated already?\n-                if connData['Authenticated'] is False and packet['Command'] not in (smb2.SMB2_NEGOTIATE, smb2.SMB2_SESSION_SETUP):\n+                if connData['Authenticated'] is False and packet['Command'] not in (\n+                smb2.SMB2_NEGOTIATE, smb2.SMB2_SESSION_SETUP):\n                     # Nope.. in that case he should only ask for a few commands, if not throw him out.\n                     errorCode = STATUS_ACCESS_DENIED\n                     respPackets = None\n@@ -4250,37 +4315,37 @@ def processRequest(self, connId, data):\n                     done = False\n                     while not done:\n                         if packet['Command'] in self.__smb2Commands:\n-                           if self.__SMB2Support is True:\n-                               respCommands, respPackets, errorCode = self.__smb2Commands[packet['Command']](\n-                                       connId,\n-                                       self,\n-                                       packet)\n-                           else:\n-                               respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)\n+                            if self.__SMB2Support is True:\n+                                respCommands, respPackets, errorCode = self.__smb2Commands[packet['Command']](\n+                                    connId,\n+                                    self,\n+                                    packet)\n+                            else:\n+                                respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)\n                         else:\n-                           respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)\n+                            respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)\n                         # Let's store the result for this compounded packet\n                         compoundedPacketsResponse.append((respCommands, respPackets, errorCode))\n                         compoundedPackets.append(packet)\n                         if packet['NextCommand'] != 0:\n                             data = data[packet['NextCommand']:]\n-                            packet = smb2.SMB2Packet(data = data)\n+                            packet = smb2.SMB2Packet(data=data)\n                         else:\n                             done = True\n \n         except Exception as e:\n-            #import traceback\n-            #traceback.print_exc()\n+            # import traceback\n+            # traceback.print_exc()\n             # Something wen't wrong, defaulting to Bad user ID\n-            self.log('processRequest (0x%x,%s)' % (packet['Command'],e), logging.ERROR)\n+            self.log('processRequest (0x%x,%s)' % (packet['Command'], e), logging.ERROR)\n             raise\n \n         # We prepare the response packet to commands don't need to bother about that.\n-        connData    = self.getConnectionData(connId, False)\n+        connData = self.getConnectionData(connId, False)\n \n         # Force reconnection loop.. This is just a test.. client will send me back credentials :)\n-        #connData['PacketNum'] += 1\n-        #if connData['PacketNum'] == 15:\n+        # connData['PacketNum'] += 1\n+        # if connData['PacketNum'] == 15:\n         #    connData['PacketNum'] = 0\n         #    # Something wen't wrong, defaulting to Bad user ID\n         #    self.log('Sending BAD USER ID!', logging.ERROR)\n@@ -4292,7 +4357,7 @@ def processRequest(self, connId, data):\n         #    packet['ErrorClass']  = errorCode & 0xff\n         #    return [packet]\n \n-        self.setConnectionData(connId, connData)    \n+        self.setConnectionData(connId, connData)\n \n         packetsToSend = []\n         for packetNum in range(len(compoundedPacketsResponse)):\n@@ -4301,49 +4366,51 @@ def processRequest(self, connId, data):\n             if respPackets is None:\n                 for respCommand in respCommands:\n                     if isSMB2 is False:\n-                        respPacket           = smb.NewSMBPacket()\n+                        respPacket = smb.NewSMBPacket()\n                         respPacket['Flags1'] = smb.SMB.FLAGS1_REPLY\n \n                         # TODO this should come from a per session configuration\n-                        respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | packet['Flags2'] & smb.SMB.FLAGS2_UNICODE\n-                        #respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES \n-                        #respPacket['Flags1'] = 0x98\n-                        #respPacket['Flags2'] = 0xc807\n-                \n-\n-                        respPacket['Tid']    = packet['Tid']\n-                        respPacket['Mid']    = packet['Mid']\n-                        respPacket['Pid']    = packet['Pid']\n-                        respPacket['Uid']    = connData['Uid']\n-        \n-                        respPacket['ErrorCode']   = errorCode >> 16\n-                        respPacket['_reserved']   = errorCode >> 8 & 0xff\n-                        respPacket['ErrorClass']  = errorCode & 0xff\n+                        respPacket[\n+                            'Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | \\\n+                                        packet['Flags2'] & smb.SMB.FLAGS2_UNICODE\n+                        # respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES\n+                        # respPacket['Flags1'] = 0x98\n+                        # respPacket['Flags2'] = 0xc807\n+\n+                        respPacket['Tid'] = packet['Tid']\n+                        respPacket['Mid'] = packet['Mid']\n+                        respPacket['Pid'] = packet['Pid']\n+                        respPacket['Uid'] = connData['Uid']\n+\n+                        respPacket['ErrorCode'] = errorCode >> 16\n+                        respPacket['_reserved'] = errorCode >> 8 & 0xff\n+                        respPacket['ErrorClass'] = errorCode & 0xff\n                         respPacket.addCommand(respCommand)\n \n                         if connData['SignatureEnabled']:\n                             respPacket['Flags2'] |= smb.SMB.FLAGS2_SMB_SECURITY_SIGNATURE\n-                            self.signSMBv1(connData, respPacket, connData['SigningSessionKey'], connData['SigningChallengeResponse'])\n-            \n+                            self.signSMBv1(connData, respPacket, connData['SigningSessionKey'],\n+                                           connData['SigningChallengeResponse'])\n+\n                         packetsToSend.append(respPacket)\n                     else:\n                         respPacket = smb2.SMB2Packet()\n-                        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n+                        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n                         if packetNum > 0:\n                             respPacket['Flags'] |= smb2.SMB2_FLAGS_RELATED_OPERATIONS\n-                        respPacket['Status']    = errorCode\n+                        respPacket['Status'] = errorCode\n                         respPacket['CreditRequestResponse'] = packet['CreditRequestResponse']\n-                        respPacket['Command']   = packet['Command']\n+                        respPacket['Command'] = packet['Command']\n                         respPacket['CreditCharge'] = packet['CreditCharge']\n-                        #respPacket['CreditCharge'] = 0\n-                        respPacket['Reserved']  = packet['Reserved']\n+                        # respPacket['CreditCharge'] = 0\n+                        respPacket['Reserved'] = packet['Reserved']\n                         respPacket['SessionID'] = connData['Uid']\n                         respPacket['MessageID'] = packet['MessageID']\n-                        respPacket['TreeID']    = packet['TreeID']\n+                        respPacket['TreeID'] = packet['TreeID']\n                         if hasattr(respCommand, 'getData'):\n-                            respPacket['Data']      = respCommand.getData()\n+                            respPacket['Data'] = respCommand.getData()\n                         else:\n-                            respPacket['Data']      = str(respCommand)\n+                            respPacket['Data'] = str(respCommand)\n \n                         if connData['SignatureEnabled']:\n                             self.signSMBv2(respPacket, connData['SigningSessionKey'])\n@@ -4357,21 +4424,21 @@ def processRequest(self, connId, data):\n             # Let's build a compound answer\n             finalData = b''\n             i = 0\n-            for i in range(len(packetsToSend)-1):\n+            for i in range(len(packetsToSend) - 1):\n                 packet = packetsToSend[i]\n                 # Align to 8-bytes\n-                padLen = (8 - (len(packet) % 8) ) % 8\n+                padLen = (8 - (len(packet) % 8)) % 8\n                 packet['NextCommand'] = len(packet) + padLen\n                 if hasattr(packet, 'getData'):\n-                    finalData += packet.getData() + padLen*b'\\x00'\n+                    finalData += packet.getData() + padLen * b'\\x00'\n                 else:\n-                    finalData += packet + padLen*b'\\x00'\n+                    finalData += packet + padLen * b'\\x00'\n \n             # Last one\n-            if hasattr(packetsToSend[len(packetsToSend)-1], 'getData'):\n-                finalData += packetsToSend[len(packetsToSend)-1].getData()\n+            if hasattr(packetsToSend[len(packetsToSend) - 1], 'getData'):\n+                finalData += packetsToSend[len(packetsToSend) - 1].getData()\n             else:\n-                finalData += packetsToSend[len(packetsToSend)-1]\n+                finalData += packetsToSend[len(packetsToSend) - 1]\n             packetsToSend = [finalData]\n \n         # We clear the compound requests\n@@ -4379,7 +4446,7 @@ def processRequest(self, connId, data):\n \n         return packetsToSend\n \n-    def processConfigFile(self, configFile = None):\n+    def processConfigFile(self, configFile=None):\n         # TODO: Do a real config parser\n         if self.__serverConfig is None:\n             if configFile is None:\n@@ -4387,32 +4454,32 @@ def processConfigFile(self, configFile = None):\n             self.__serverConfig = configparser.ConfigParser()\n             self.__serverConfig.read(configFile)\n \n-        self.__serverName   = self.__serverConfig.get('global','server_name')\n-        self.__serverOS     = self.__serverConfig.get('global','server_os')\n-        self.__serverDomain = self.__serverConfig.get('global','server_domain')\n-        self.__logFile      = self.__serverConfig.get('global','log_file')\n+        self.__serverName = self.__serverConfig.get('global', 'server_name')\n+        self.__serverOS = self.__serverConfig.get('global', 'server_os')\n+        self.__serverDomain = self.__serverConfig.get('global', 'server_domain')\n+        self.__logFile = self.__serverConfig.get('global', 'log_file')\n         if self.__serverConfig.has_option('global', 'challenge'):\n-            self.__challenge    = unhexlify(self.__serverConfig.get('global', 'challenge'))\n+            self.__challenge = unhexlify(self.__serverConfig.get('global', 'challenge'))\n         else:\n-            self.__challenge    = b'A'*16\n+            self.__challenge = b'A' * 16\n \n         if self.__serverConfig.has_option(\"global\", \"jtr_dump_path\"):\n             self.__jtr_dump_path = self.__serverConfig.get(\"global\", \"jtr_dump_path\")\n \n         if self.__serverConfig.has_option(\"global\", \"SMB2Support\"):\n-            self.__SMB2Support = self.__serverConfig.getboolean(\"global\",\"SMB2Support\")\n+            self.__SMB2Support = self.__serverConfig.getboolean(\"global\", \"SMB2Support\")\n         else:\n             self.__SMB2Support = False\n \n         if self.__logFile != 'None':\n-            logging.basicConfig(filename = self.__logFile, \n-                             level = logging.DEBUG, \n-                             format=\"%(asctime)s: %(levelname)s: %(message)s\", \n-                             datefmt = '%m\/%d\/%Y %I:%M:%S %p')\n-        self.__log        = LOG\n+            logging.basicConfig(filename=self.__logFile,\n+                                level=logging.DEBUG,\n+                                format=\"%(asctime)s: %(levelname)s: %(message)s\",\n+                                datefmt='%m\/%d\/%Y %I:%M:%S %p')\n+        self.__log = LOG\n \n         # Process the credentials\n-        credentials_fname = self.__serverConfig.get('global','credentials_file')\n+        credentials_fname = self.__serverConfig.get('global', 'credentials_file')\n         if credentials_fname != \"\":\n             cred = open(credentials_fname)\n             line = cred.readline()\n@@ -4430,13 +4497,14 @@ def addCredential(self, name, uid, lmhash, nthash):\n                 lmhash = '0%s' % lmhash\n             if len(nthash) % 2:\n                 nthash = '0%s' % nthash\n-            try: # just in case they were converted already\n+            try:  # just in case they were converted already\n                 lmhash = a2b_hex(lmhash)\n                 nthash = a2b_hex(nthash)\n             except:\n                 pass\n         self.__credentials[name.lower()] = (uid, lmhash, nthash)\n \n+\n # For windows platforms, opening a directory is not an option, so we set a void FD\n VOID_FILE_DESCRIPTOR = -1\n PIPE_FILE_DESCRIPTOR = -2\n@@ -4447,19 +4515,21 @@ def addCredential(self, name, uid, lmhash, nthash):\n \n from impacket.dcerpc.v5.rpcrt import DCERPCServer\n from impacket.dcerpc.v5.dtypes import NULL\n-from impacket.dcerpc.v5.srvs import NetrShareEnum, NetrShareEnumResponse, SHARE_INFO_1, NetrServerGetInfo, NetrServerGetInfoResponse, NetrShareGetInfo, NetrShareGetInfoResponse\n+from impacket.dcerpc.v5.srvs import NetrShareEnum, NetrShareEnumResponse, SHARE_INFO_1, NetrServerGetInfo, \\\n+    NetrServerGetInfoResponse, NetrShareGetInfo, NetrShareGetInfoResponse\n from impacket.dcerpc.v5.wkst import NetrWkstaGetInfo, NetrWkstaGetInfoResponse\n from impacket.system_errors import ERROR_INVALID_LEVEL\n \n+\n class WKSTServer(DCERPCServer):\n     def __init__(self):\n         DCERPCServer.__init__(self)\n         self.wkssvcCallBacks = {\n             0: self.NetrWkstaGetInfo,\n         }\n-        self.addCallbacks(('6BFFD098-A112-3610-9833-46C3F87E345A', '1.0'),'\\\\PIPE\\\\wkssvc', self.wkssvcCallBacks)\n+        self.addCallbacks(('6BFFD098-A112-3610-9833-46C3F87E345A', '1.0'), '\\\\PIPE\\\\wkssvc', self.wkssvcCallBacks)\n \n-    def NetrWkstaGetInfo(self,data):\n+    def NetrWkstaGetInfo(self, data):\n         request = NetrWkstaGetInfo(data)\n         self.log(\"NetrWkstaGetInfo Level: %d\" % request['Level'])\n \n@@ -4489,6 +4559,7 @@ def NetrWkstaGetInfo(self,data):\n \n         return answer\n \n+\n class SRVSServer(DCERPCServer):\n     def __init__(self):\n         DCERPCServer.__init__(self)\n@@ -4503,86 +4574,87 @@ def __init__(self):\n             21: self.NetrServerGetInfo,\n         }\n \n-        self.addCallbacks(('4B324FC8-1670-01D3-1278-5A47BF6EE188', '3.0'),'\\\\PIPE\\\\srvsvc', self.srvsvcCallBacks)\n+        self.addCallbacks(('4B324FC8-1670-01D3-1278-5A47BF6EE188', '3.0'), '\\\\PIPE\\\\srvsvc', self.srvsvcCallBacks)\n \n     def setServerConfig(self, config):\n         self.__serverConfig = config\n \n     def processConfigFile(self, configFile=None):\n-       if configFile is not None:\n-           self.__serverConfig = configparser.ConfigParser()\n-           self.__serverConfig.read(configFile)\n-       sections = self.__serverConfig.sections()\n-       # Let's check the log file\n-       self.__logFile      = self.__serverConfig.get('global','log_file')\n-       if self.__logFile != 'None':\n-            logging.basicConfig(filename = self.__logFile, \n-                             level = logging.DEBUG, \n-                             format=\"%(asctime)s: %(levelname)s: %(message)s\", \n-                             datefmt = '%m\/%d\/%Y %I:%M:%S %p')\n-\n-       # Remove the global one\n-       del(sections[sections.index('global')])\n-       self._shares = {}\n-       for i in sections:\n-           self._shares[i] = dict(self.__serverConfig.items(i))\n-\n-    def NetrShareGetInfo(self,data):\n-       request = NetrShareGetInfo(data)\n-       self.log(\"NetrGetShareInfo Level: %d\" % request['Level'])\n-\n-       s = request['NetName'][:-1].upper()\n-       answer = NetrShareGetInfoResponse()\n-       if s in self._shares:\n-           share  = self._shares[s]\n-\n-           answer['InfoStruct']['tag'] = 1\n-           answer['InfoStruct']['ShareInfo1']['shi1_netname']= s+'\\x00'\n-           answer['InfoStruct']['ShareInfo1']['shi1_type']   = share['share type']\n-           answer['InfoStruct']['ShareInfo1']['shi1_remark'] = share['comment']+'\\x00' \n-           answer['ErrorCode'] = 0\n-       else:\n-           answer['InfoStruct']['tag'] = 1\n-           answer['InfoStruct']['ShareInfo1']= NULL\n-           answer['ErrorCode'] = 0x0906 #WERR_NET_NAME_NOT_FOUND\n-\n-       return answer\n-\n-    def NetrServerGetInfo(self,data):\n-       request = NetrServerGetInfo(data)\n-       self.log(\"NetrServerGetInfo Level: %d\" % request['Level'])\n-       answer = NetrServerGetInfoResponse()\n-       answer['InfoStruct']['tag'] = 101\n-       # PLATFORM_ID_NT = 500\n-       answer['InfoStruct']['ServerInfo101']['sv101_platform_id'] = 500\n-       answer['InfoStruct']['ServerInfo101']['sv101_name'] = request['ServerName']\n-       # Windows 7 = 6.1\n-       answer['InfoStruct']['ServerInfo101']['sv101_version_major'] = 6\n-       answer['InfoStruct']['ServerInfo101']['sv101_version_minor'] = 1\n-       # Workstation = 1\n-       answer['InfoStruct']['ServerInfo101']['sv101_type'] = 1\n-       answer['InfoStruct']['ServerInfo101']['sv101_comment'] = NULL\n-       answer['ErrorCode'] = 0\n-       return answer\n+        if configFile is not None:\n+            self.__serverConfig = configparser.ConfigParser()\n+            self.__serverConfig.read(configFile)\n+        sections = self.__serverConfig.sections()\n+        # Let's check the log file\n+        self.__logFile = self.__serverConfig.get('global', 'log_file')\n+        if self.__logFile != 'None':\n+            logging.basicConfig(filename=self.__logFile,\n+                                level=logging.DEBUG,\n+                                format=\"%(asctime)s: %(levelname)s: %(message)s\",\n+                                datefmt='%m\/%d\/%Y %I:%M:%S %p')\n+\n+        # Remove the global one\n+        del (sections[sections.index('global')])\n+        self._shares = {}\n+        for i in sections:\n+            self._shares[i] = dict(self.__serverConfig.items(i))\n+\n+    def NetrShareGetInfo(self, data):\n+        request = NetrShareGetInfo(data)\n+        self.log(\"NetrGetShareInfo Level: %d\" % request['Level'])\n+\n+        s = request['NetName'][:-1].upper()\n+        answer = NetrShareGetInfoResponse()\n+        if s in self._shares:\n+            share = self._shares[s]\n+\n+            answer['InfoStruct']['tag'] = 1\n+            answer['InfoStruct']['ShareInfo1']['shi1_netname'] = s + '\\x00'\n+            answer['InfoStruct']['ShareInfo1']['shi1_type'] = share['share type']\n+            answer['InfoStruct']['ShareInfo1']['shi1_remark'] = share['comment'] + '\\x00'\n+            answer['ErrorCode'] = 0\n+        else:\n+            answer['InfoStruct']['tag'] = 1\n+            answer['InfoStruct']['ShareInfo1'] = NULL\n+            answer['ErrorCode'] = 0x0906  # WERR_NET_NAME_NOT_FOUND\n+\n+        return answer\n+\n+    def NetrServerGetInfo(self, data):\n+        request = NetrServerGetInfo(data)\n+        self.log(\"NetrServerGetInfo Level: %d\" % request['Level'])\n+        answer = NetrServerGetInfoResponse()\n+        answer['InfoStruct']['tag'] = 101\n+        # PLATFORM_ID_NT = 500\n+        answer['InfoStruct']['ServerInfo101']['sv101_platform_id'] = 500\n+        answer['InfoStruct']['ServerInfo101']['sv101_name'] = request['ServerName']\n+        # Windows 7 = 6.1\n+        answer['InfoStruct']['ServerInfo101']['sv101_version_major'] = 6\n+        answer['InfoStruct']['ServerInfo101']['sv101_version_minor'] = 1\n+        # Workstation = 1\n+        answer['InfoStruct']['ServerInfo101']['sv101_type'] = 1\n+        answer['InfoStruct']['ServerInfo101']['sv101_comment'] = NULL\n+        answer['ErrorCode'] = 0\n+        return answer\n \n     def NetrShareEnum(self, data):\n-       request = NetrShareEnum(data)\n-       self.log(\"NetrShareEnum Level: %d\" % request['InfoStruct']['Level'])\n-       shareEnum = NetrShareEnumResponse()\n-       shareEnum['InfoStruct']['Level'] = 1\n-       shareEnum['InfoStruct']['ShareInfo']['tag'] = 1\n-       shareEnum['TotalEntries'] = len(self._shares)\n-       shareEnum['InfoStruct']['ShareInfo']['Level1']['EntriesRead'] = len(self._shares)\n-       shareEnum['ErrorCode'] = 0\n-\n-       for i in self._shares:\n-           shareInfo = SHARE_INFO_1()\n-           shareInfo['shi1_netname'] = i+'\\x00'\n-           shareInfo['shi1_type'] = self._shares[i]['share type']\n-           shareInfo['shi1_remark'] = self._shares[i]['comment']+'\\x00'\n-           shareEnum['InfoStruct']['ShareInfo']['Level1']['Buffer'].append(shareInfo)\n-\n-       return shareEnum\n+        request = NetrShareEnum(data)\n+        self.log(\"NetrShareEnum Level: %d\" % request['InfoStruct']['Level'])\n+        shareEnum = NetrShareEnumResponse()\n+        shareEnum['InfoStruct']['Level'] = 1\n+        shareEnum['InfoStruct']['ShareInfo']['tag'] = 1\n+        shareEnum['TotalEntries'] = len(self._shares)\n+        shareEnum['InfoStruct']['ShareInfo']['Level1']['EntriesRead'] = len(self._shares)\n+        shareEnum['ErrorCode'] = 0\n+\n+        for i in self._shares:\n+            shareInfo = SHARE_INFO_1()\n+            shareInfo['shi1_netname'] = i + '\\x00'\n+            shareInfo['shi1_type'] = self._shares[i]['share type']\n+            shareInfo['shi1_remark'] = self._shares[i]['comment'] + '\\x00'\n+            shareEnum['InfoStruct']['ShareInfo']['Level1']['Buffer'].append(shareInfo)\n+\n+        return shareEnum\n+\n \n class SimpleSMBServer:\n     \"\"\"\n@@ -4592,44 +4664,47 @@ class SimpleSMBServer:\n     :param integer listenPort: the port number you want the server to listen on\n     :param string configFile: a file with all the servers' configuration. If no file specified, this class will create the basic parameters needed to run. You will need to add your shares manually tho. See addShare() method\n     \"\"\"\n-    def __init__(self, listenAddress = '0.0.0.0', listenPort=445, configFile=''):\n+\n+    def __init__(self, listenAddress='0.0.0.0', listenPort=445, configFile=''):\n         if configFile != '':\n-            self.__server = SMBSERVER((listenAddress,listenPort))\n+            self.__server = SMBSERVER((listenAddress, listenPort))\n             self.__server.processConfigFile(configFile)\n             self.__smbConfig = None\n         else:\n             # Here we write a mini config for the server\n             self.__smbConfig = configparser.ConfigParser()\n             self.__smbConfig.add_section('global')\n-            self.__smbConfig.set('global','server_name',''.join([random.choice(string.ascii_letters) for _ in range(8)]))\n-            self.__smbConfig.set('global','server_os',''.join([random.choice(string.ascii_letters) for _ in range(8)])\n-)\n-            self.__smbConfig.set('global','server_domain',''.join([random.choice(string.ascii_letters) for _ in range(8)])\n-)\n-            self.__smbConfig.set('global','log_file','None')\n-            self.__smbConfig.set('global','rpc_apis','yes')\n-            self.__smbConfig.set('global','credentials_file','')\n-            self.__smbConfig.set('global', 'challenge', \"A\"*16)\n+            self.__smbConfig.set('global', 'server_name',\n+                                 ''.join([random.choice(string.ascii_letters) for _ in range(8)]))\n+            self.__smbConfig.set('global', 'server_os', ''.join([random.choice(string.ascii_letters) for _ in range(8)])\n+                                 )\n+            self.__smbConfig.set('global', 'server_domain',\n+                                 ''.join([random.choice(string.ascii_letters) for _ in range(8)])\n+                                 )\n+            self.__smbConfig.set('global', 'log_file', 'None')\n+            self.__smbConfig.set('global', 'rpc_apis', 'yes')\n+            self.__smbConfig.set('global', 'credentials_file', '')\n+            self.__smbConfig.set('global', 'challenge', \"A\" * 16)\n \n             # IPC always needed\n             self.__smbConfig.add_section('IPC$')\n-            self.__smbConfig.set('IPC$','comment','')\n-            self.__smbConfig.set('IPC$','read only','yes')\n-            self.__smbConfig.set('IPC$','share type','3')\n-            self.__smbConfig.set('IPC$','path','')\n-            self.__server = SMBSERVER((listenAddress,listenPort), config_parser = self.__smbConfig)\n+            self.__smbConfig.set('IPC$', 'comment', '')\n+            self.__smbConfig.set('IPC$', 'read only', 'yes')\n+            self.__smbConfig.set('IPC$', 'share type', '3')\n+            self.__smbConfig.set('IPC$', 'path', '')\n+            self.__server = SMBSERVER((listenAddress, listenPort), config_parser=self.__smbConfig)\n             self.__server.processConfigFile()\n \n-        # Now we have to register the MS-SRVS server. This specially important for \n-        # Windows 7+ and Mavericks clients since they WON'T (specially OSX) \n+        # Now we have to register the MS-SRVS server. This specially important for\n+        # Windows 7+ and Mavericks clients since they WON'T (specially OSX)\n         # ask for shares using MS-RAP.\n \n         self.__srvsServer = SRVSServer()\n         self.__srvsServer.daemon = True\n         self.__wkstServer = WKSTServer()\n         self.__wkstServer.daemon = True\n-        self.__server.registerNamedPipe('srvsvc',('127.0.0.1',self.__srvsServer.getListenPort()))\n-        self.__server.registerNamedPipe('wkssvc',('127.0.0.1',self.__wkstServer.getListenPort()))\n+        self.__server.registerNamedPipe('srvsvc', ('127.0.0.1', self.__srvsServer.getListenPort()))\n+        self.__server.registerNamedPipe('wkssvc', ('127.0.0.1', self.__wkstServer.getListenPort()))\n \n     def start(self):\n         self.__srvsServer.start()\n@@ -4645,7 +4720,7 @@ def unregisterNamedPipe(self, pipeName):\n     def getRegisteredNamedPipes(self):\n         return self.__server.getRegisteredNamedPipes()\n \n-    def addShare(self, shareName, sharePath, shareComment='', shareType = '0', readOnly = 'no'):\n+    def addShare(self, shareName, sharePath, shareComment='', shareType='0', readOnly='no'):\n         share = shareName.upper()\n         self.__smbConfig.add_section(share)\n         self.__smbConfig.set(share, 'comment', shareComment)\n@@ -4669,14 +4744,14 @@ def setSMBChallenge(self, challenge):\n             self.__smbConfig.set('global', 'challenge', challenge)\n             self.__server.setServerConfig(self.__smbConfig)\n             self.__server.processConfigFile()\n-        \n+\n     def setLogFile(self, logFile):\n-        self.__smbConfig.set('global','log_file',logFile)\n+        self.__smbConfig.set('global', 'log_file', logFile)\n         self.__server.setServerConfig(self.__smbConfig)\n         self.__server.processConfigFile()\n \n     def setCredentialsFile(self, logFile):\n-        self.__smbConfig.set('global','credentials_file',logFile)\n+        self.__smbConfig.set('global', 'credentials_file', logFile)\n         self.__server.setServerConfig(self.__smbConfig)\n         self.__server.processConfigFile()\n \n\nFrom 6688da5d97592269aae72b3a00dc1ab186c0b33d Mon Sep 17 00:00:00 2001\nFrom: OmriI <omri.inbar@checkmarx.com>\nDate: Mon, 26 Apr 2021 20:02:57 +0300\nSubject: [PATCH 2\/2] Changed STATUS_ACCESS_DENIED and STATUS_NOT_SUPPORTED to\n STATUS_OBJECT_PATH_SYNTAX_BAD\n\n---\n impacket\/smbserver.py | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/impacket\/smbserver.py b\/impacket\/smbserver.py\nindex a10b79fecd..d60e3e6cb9 100644\n--- a\/impacket\/smbserver.py\n+++ b\/impacket\/smbserver.py\n@@ -53,7 +53,7 @@\n     STATUS_FILE_IS_A_DIRECTORY, STATUS_NOT_IMPLEMENTED, STATUS_INVALID_HANDLE, STATUS_OBJECT_NAME_COLLISION, \\\n     STATUS_NO_SUCH_FILE, STATUS_CANCELLED, STATUS_OBJECT_NAME_NOT_FOUND, STATUS_SUCCESS, STATUS_ACCESS_DENIED, \\\n     STATUS_NOT_SUPPORTED, STATUS_INVALID_DEVICE_REQUEST, STATUS_FS_DRIVER_REQUIRED, STATUS_INVALID_INFO_CLASS, \\\n-    STATUS_LOGON_FAILURE\n+    STATUS_LOGON_FAILURE, STATUS_OBJECT_PATH_SYNTAX_BAD\n \n # Setting LOG to current's module name\n LOG = logging.getLogger(__name__)\n@@ -347,7 +347,7 @@ def findFirst2(path, fileName, level, searchAttributes, pktFlags=smb.SMB.FLAGS2_\n \n     if not isInFileJail(path, fileName):\n         LOG.error(\"Path not in current working directory\")\n-        return [], 0, STATUS_NOT_SUPPORTED\n+        return [], 0, STATUS_OBJECT_PATH_SYNTAX_BAD\n \n     pathName = os.path.join(path, fileName)\n     files = []\n@@ -2041,7 +2041,7 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n                 LOG.error(\"Path not in current working directory\")\n                 respSMBCommand['Parameters'] = b''\n                 respSMBCommand['Data'] = b''\n-                return [respSMBCommand], None, STATUS_ACCESS_DENIED\n+                return [respSMBCommand], None, STATUS_OBJECT_PATH_SYNTAX_BAD\n \n             pathName = os.path.join(path, fileName)\n             createDisposition = ntCreateAndXParameters['Disposition']\n@@ -3014,7 +3014,7 @@ def smb2Create(connId, smbServer, recvPacket):\n \n             if not isInFileJail(path, fileName):\n                 LOG.error(\"Path not in current working directory\")\n-                return [smb2.SMB2Error()], None, STATUS_ACCESS_DENIED\n+                return [smb2.SMB2Error()], None, STATUS_OBJECT_PATH_SYNTAX_BAD\n \n             pathName = os.path.join(path, fileName)\n             createDisposition = ntCreateRequest['CreateDisposition']"
        },
        {
            "index":426,
            "vuln_id":"GHSA-4c4g-crqm-xrxw",
            "cwe_id":"{'CWE-908'}",
            "score":4.4,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8933b8a21280696ab119b63263babdb54c298538', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/537bc7c723439b9194a358f64d871dd326c18887'}",
            "dataset":"osv",
            "summary":"Use of unitialized value in TFLite ### Impact\nAll TFLite operations that use quantization can be made to use unitialized values. [For example](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/lite\/kernels\/depthwise_conv.cc#L198-L200):\n\n```cc\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n```\n\nThe issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code.\n\n### Patches\nWe have patched the issue in GitHub commits [537bc7c723439b9194a358f64d871dd326c18887](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/537bc7c723439b9194a358f64d871dd326c18887),\n[4a91f2069f7145aab6ba2d8cfe41be8a110c18a5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5) and [8933b8a21280696ab119b63263babdb54c298538](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8933b8a21280696ab119b63263babdb54c298538).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":3,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8933b8a21280696ab119b63263babdb54c298538",
            "commit_sha":"8933b8a21280696ab119b63263babdb54c298538",
            "patch":"MULTI",
            "chain_ord":"['537bc7c723439b9194a358f64d871dd326c18887', '4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', '8933b8a21280696ab119b63263babdb54c298538']",
            "before_first_fix_commit":"{'e35be978351a8578549d30b6f483825d36dc0f8b'}",
            "last_fix_commit":"8933b8a21280696ab119b63263babdb54c298538",
            "chain_ord_pos":3.0,
            "commit_datetime":"07\/16\/2021, 17:22:37",
            "message":"Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/lite\/kernels\/depthwise_conv.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/8933b8a21280696ab119b63263babdb54c298538\/tensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc', 'patch': '@@ -176,6 +176,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   if (data_type != kTfLiteFloat32) {\\n     TF_LITE_ENSURE_EQ(context, filter->quantization.type,\\n                       kTfLiteAffineQuantization);\\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n     const auto* affine_quantization =\\n         reinterpret_cast<TfLiteAffineQuantization*>(\\n             filter->quantization.params);\\n@@ -195,6 +196,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   }\\n \\n   if (is_hybrid) {\\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n     const auto* affine_quantization =\\n         reinterpret_cast<TfLiteAffineQuantization*>(\\n             filter->quantization.params);\\n@@ -495,6 +497,7 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\\n   op_params.weights_offset = 0;\\n   op_params.float_activation_min = output_activation_min;\\n   op_params.float_activation_max = output_activation_max;\\n+  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n   const auto* affine_quantization =\\n       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\\n   if (kernel_type == kReference) {'}}",
            "message_norm":"fix a null pointer exception caused by branching on uninitialized data.\n\nthis is due to not checking that the params for the quantization exists. if there is no quantization, we should not access the `.params` field.\n\npiperorigin-revid: 385173491\nchange-id: i8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('null pointer exception', 'SECWORD', ''), ('uninitialized', 'SECWORD', ''), ('385173491', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/depthwise_conv.cc'])",
            "num_files":1.0,
            "patch_content":"From 8933b8a21280696ab119b63263babdb54c298538 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 16 Jul 2021 10:22:37 -0700\nSubject: [PATCH] Fix a null pointer exception caused by branching on\n uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663\n---\n tensorflow\/lite\/kernels\/depthwise_conv.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/depthwise_conv.cc b\/tensorflow\/lite\/kernels\/depthwise_conv.cc\nindex c19e01cf33bca7..060b0827dafa74 100644\n--- a\/tensorflow\/lite\/kernels\/depthwise_conv.cc\n+++ b\/tensorflow\/lite\/kernels\/depthwise_conv.cc\n@@ -176,6 +176,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   if (data_type != kTfLiteFloat32) {\n     TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                       kTfLiteAffineQuantization);\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n     const auto* affine_quantization =\n         reinterpret_cast<TfLiteAffineQuantization*>(\n             filter->quantization.params);\n@@ -195,6 +196,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   if (is_hybrid) {\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n     const auto* affine_quantization =\n         reinterpret_cast<TfLiteAffineQuantization*>(\n             filter->quantization.params);\n@@ -495,6 +497,7 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n   op_params.weights_offset = 0;\n   op_params.float_activation_min = output_activation_min;\n   op_params.float_activation_max = output_activation_max;\n+  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n   const auto* affine_quantization =\n       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n   if (kernel_type == kReference) {"
        },
        {
            "index":310,
            "vuln_id":"GHSA-9xh4-23q4-v6wr",
            "cwe_id":"{'CWE-476', 'CWE-787', 'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow and undefined behavior in `FusedBatchNorm` ### Impact\nThe implementation of `tf.raw_ops.FusedBatchNorm` is vulnerable to a heap buffer overflow:\n      \n```python\nimport tensorflow as tf\n\nx = tf.zeros([10, 10, 10, 6], dtype=tf.float32)\nscale = tf.constant([0.0], shape=[1], dtype=tf.float32)\noffset = tf.constant([0.0], shape=[1], dtype=tf.float32)\nmean = tf.constant([0.0], shape=[1], dtype=tf.float32)\nvariance = tf.constant([0.0], shape=[1], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n    \ntf.raw_ops.FusedBatchNorm(\n  x=x, scale=scale, offset=offset, mean=mean, variance=variance,\n  epsilon=epsilon, exponential_avg_factor=exponential_avg_factor,\n  data_format=data_format, is_training=is_training)\n```\n  \nIf the tensors are empty, the same implementation can trigger undefined behavior by dereferencing null pointers:\n\n```python \nimport tensorflow as tf\nimport numpy as np\n\nx = tf.zeros([10, 10, 10, 1], dtype=tf.float32)\nscale = tf.constant([], shape=[0], dtype=tf.float32)\noffset = tf.constant([], shape=[0], dtype=tf.float32)\nmean = tf.constant([], shape=[0], dtype=tf.float32)\nvariance = tf.constant([], shape=[0], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n\ntf.raw_ops.FusedBatchNorm(\n  x=x, scale=scale, offset=offset, mean=mean, variance=variance, \n  epsilon=epsilon, exponential_avg_factor=exponential_avg_factor,\n  data_format=data_format, is_training=is_training)\n``` \n\nThe  [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/57d86e0db5d1365f19adcce848dfc1bf89fdd4c7\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc) fails to validate that `scale`, `offset`, `mean` and `variance` (the last two only when required) all have the same number of elements as the number of channels of `x`. This results in heap out of bounds reads when the buffers backing these tensors are indexed past their boundary.\n\nIf the tensors are empty, the validation mentioned in the above paragraph would also trigger and prevent the undefined behavior.\n\n### Patches\nWe have patched the issue in GitHub commit [6972f9dfe325636b3db4e0bc517ee22a159365c0](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0",
            "commit_sha":"6972f9dfe325636b3db4e0bc517ee22a159365c0",
            "patch":"SINGLE",
            "chain_ord":"['6972f9dfe325636b3db4e0bc517ee22a159365c0']",
            "before_first_fix_commit":"{'57d86e0db5d1365f19adcce848dfc1bf89fdd4c7'}",
            "last_fix_commit":"6972f9dfe325636b3db4e0bc517ee22a159365c0",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/07\/2021, 00:45:51",
            "message":"Add missing valuidation to FusedBatchNorm.\n\nPiperOrigin-RevId: 372460336\nChange-Id: Ic8c4e4de67c58a741bd87f2e182bed07247d1126",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 27, 'deletions': 1, 'total': 28}",
            "files":"{'tensorflow\/core\/kernels\/fused_batch_norm_op.cc': {'additions': 27, 'deletions': 1, 'changes': 28, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6972f9dfe325636b3db4e0bc517ee22a159365c0\/tensorflow%2Fcore%2Fkernels%2Ffused_batch_norm_op.cc', 'patch': '@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\\n     }\\n \\n+    const auto num_channels = GetTensorDim(x, tensor_format_, \\'C\\');\\n+    OP_REQUIRES(\\n+        context, scale.NumElements() == num_channels,\\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\\n+                                \"as the channels of x, got \",\\n+                                scale.NumElements(), \" and \", num_channels));\\n+    OP_REQUIRES(\\n+        context, offset.NumElements() == num_channels,\\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\\n+                                \"as the channels of x, got \",\\n+                                offset.NumElements(), \" and \", num_channels));\\n+    if (estimated_mean.NumElements() != 0) {\\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\\n+                  errors::InvalidArgument(\\n+                      \"mean must be empty or have the same number of \"\\n+                      \"elements as the channels of x, got \",\\n+                      estimated_mean.NumElements(), \" and \", num_channels));\\n+    }\\n+    if (estimated_variance.NumElements() != 0) {\\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\\n+                  errors::InvalidArgument(\\n+                      \"variance must be empty or have the same number of \"\\n+                      \"elements as the channels of x, got \",\\n+                      estimated_variance.NumElements(), \" and \", num_channels));\\n+    }\\n+\\n     if (has_side_input_) {\\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\\n                   errors::InvalidArgument(\\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\\n       \/\/ NOTE(ezhulenev): This requirement is coming from implementation\\n       \/\/ details of cudnnBatchNormalizationForwardTrainingEx.\\n       OP_REQUIRES(\\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\\n+          context, !is_training_ || num_channels % 4 == 0,\\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\\n                                   \"channel dimension to be a multiple of 4.\"));\\n     }'}}",
            "message_norm":"add missing valuidation to fusedbatchnorm.\n\npiperorigin-revid: 372460336\nchange-id: ic8c4e4de67c58a741bd87f2e182bed07247d1126",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('372460336', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/fused_batch_norm_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 6972f9dfe325636b3db4e0bc517ee22a159365c0 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 6 May 2021 17:45:51 -0700\nSubject: [PATCH] Add missing valuidation to FusedBatchNorm.\n\nPiperOrigin-RevId: 372460336\nChange-Id: Ic8c4e4de67c58a741bd87f2e182bed07247d1126\n---\n ...\/core\/kernels\/fused_batch_norm_op.cc       | 28 ++++++++++++++++++-\n 1 file changed, 27 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc b\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\nindex e564b19857c383..7b0932d953261c 100644\n--- a\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\n+++ b\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\n@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\n     }\n \n+    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n+    OP_REQUIRES(\n+        context, scale.NumElements() == num_channels,\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                scale.NumElements(), \" and \", num_channels));\n+    OP_REQUIRES(\n+        context, offset.NumElements() == num_channels,\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                offset.NumElements(), \" and \", num_channels));\n+    if (estimated_mean.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"mean must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_mean.NumElements(), \" and \", num_channels));\n+    }\n+    if (estimated_variance.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"variance must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_variance.NumElements(), \" and \", num_channels));\n+    }\n+\n     if (has_side_input_) {\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\n                   errors::InvalidArgument(\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\n       \/\/ NOTE(ezhulenev): This requirement is coming from implementation\n       \/\/ details of cudnnBatchNormalizationForwardTrainingEx.\n       OP_REQUIRES(\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\n+          context, !is_training_ || num_channels % 4 == 0,\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                   \"channel dimension to be a multiple of 4.\"));\n     }"
        },
        {
            "index":231,
            "vuln_id":"GHSA-66rh-8fw6-59q6",
            "cwe_id":"{'CWE-915', 'CWE-20'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/jonschlinkert\/assign-deep\/commit\/8e3cc4a34246733672c71e96532105384937e56c', 'https:\/\/github.com\/jonschlinkert\/assign-deep\/commit\/90bf1c551d05940898168d04066bbf15060f50cc'}",
            "dataset":"osv",
            "summary":"assign-deep Vulnerable to Prototype Pollution Versions of `assign-deep` prior to 1.0.1 and 0.4.8 are vulnerable to Prototype Pollution. The `assign` function fails to validate which Object properties it updates. This allows attackers to modify the prototype of Object, causing the addition or modification of an existing property on all objects.\n\n## Recommendation\n\nUpgrade to versions 1.0.1, 0.4.8, or later.",
            "published_date":"2019-08-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/jonschlinkert\/assign-deep",
            "commit_href":"https:\/\/github.com\/jonschlinkert\/assign-deep\/commit\/8e3cc4a34246733672c71e96532105384937e56c",
            "commit_sha":"8e3cc4a34246733672c71e96532105384937e56c",
            "patch":"MULTI",
            "chain_ord":"['90bf1c551d05940898168d04066bbf15060f50cc', '8e3cc4a34246733672c71e96532105384937e56c']",
            "before_first_fix_commit":"{'24412bd2b59bc128437819c4a4518a7b7148d81a'}",
            "last_fix_commit":"8e3cc4a34246733672c71e96532105384937e56c",
            "chain_ord_pos":2.0,
            "commit_datetime":"06\/25\/2019, 17:46:37",
            "message":"ensure keys are valid",
            "author":"doowb",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 1, 'total': 10}",
            "files":"{'index.js': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jonschlinkert\/assign-deep\/raw\/8e3cc4a34246733672c71e96532105384937e56c\/index.js', 'patch': \"@@ -37,7 +37,7 @@ function extend(target, obj) {\\n   assignSymbols(target, obj);\\n \\n   for (var key in obj) {\\n-    if (key !== '__proto__' && hasOwn(obj, key)) {\\n+    if (isValidKey(key) && hasOwn(obj, key)) {\\n       var val = obj[key];\\n       if (isObject(val)) {\\n         if (typeOf(target[key]) === 'undefined' && typeOf(val) === 'function') {\\n@@ -68,6 +68,14 @@ function hasOwn(obj, key) {\\n   return Object.prototype.hasOwnProperty.call(obj, key);\\n }\\n \\n+\/**\\n+ * Returns true if the given `key` is a valid key that can be used for assigning properties.\\n+ *\/\\n+\\n+function isValidKey(key) {\\n+  return key !== '__proto__' && key !== 'constructor' && key !== 'prototype';\\n+}\\n+\\n \/**\\n  * Expose `assign`\\n  *\/\"}}",
            "message_norm":"ensure keys are valid",
            "language":"af",
            "entities":"[('ensure', 'ACTION', ''), ('keys', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From 8e3cc4a34246733672c71e96532105384937e56c Mon Sep 17 00:00:00 2001\nFrom: doowb <brian.woodward@gmail.com>\nDate: Tue, 25 Jun 2019 13:46:37 -0400\nSubject: [PATCH] ensure keys are valid\n\n---\n index.js | 10 +++++++++-\n 1 file changed, 9 insertions(+), 1 deletion(-)\n\ndiff --git a\/index.js b\/index.js\nindex c5dc494..7b45f0c 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -37,7 +37,7 @@ function extend(target, obj) {\n   assignSymbols(target, obj);\n \n   for (var key in obj) {\n-    if (key !== '__proto__' && hasOwn(obj, key)) {\n+    if (isValidKey(key) && hasOwn(obj, key)) {\n       var val = obj[key];\n       if (isObject(val)) {\n         if (typeOf(target[key]) === 'undefined' && typeOf(val) === 'function') {\n@@ -68,6 +68,14 @@ function hasOwn(obj, key) {\n   return Object.prototype.hasOwnProperty.call(obj, key);\n }\n \n+\/**\n+ * Returns true if the given `key` is a valid key that can be used for assigning properties.\n+ *\/\n+\n+function isValidKey(key) {\n+  return key !== '__proto__' && key !== 'constructor' && key !== 'prototype';\n+}\n+\n \/**\n  * Expose `assign`\n  *\/"
        },
        {
            "index":632,
            "vuln_id":"GHSA-82j4-vr25-x394",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/78522520892d4e29cc94148c6ec84a204a607b73'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in ShowDoc ShowDoc is vulnerable to stored cross-site scripting due to unrestricted file upload in versions 2.10.3 and prior. A patch is available and anticipated to be part of version 2.10.4.",
            "published_date":"2022-03-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/78522520892d4e29cc94148c6ec84a204a607b73",
            "commit_sha":"78522520892d4e29cc94148c6ec84a204a607b73",
            "patch":"SINGLE",
            "chain_ord":"['78522520892d4e29cc94148c6ec84a204a607b73']",
            "before_first_fix_commit":"{'52d1d902084387bec22a64e6027f100e939733c8', '830c89a4c2c5fd0dd491422bf8e97b4eb5713f55'}",
            "last_fix_commit":"78522520892d4e29cc94148c6ec84a204a607b73",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/13\/2022, 10:39:59",
            "message":"Merge pull request #1629 from ajaysenr\/master\n\nUpdate AttachmentModel.class.php",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'server\/Application\/Api\/Model\/AttachmentModel.class.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/78522520892d4e29cc94148c6ec84a204a607b73\/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': '@@ -304,6 +304,7 @@ public function isDangerFilename($filename){\\n \\t\\t\\t|| $isDangerStr($filename , \"%\")\\n \\t\\t\\t|| $isDangerStr($filename , \".xml\")\\n \\t\\t\\t|| $isDangerStr($filename , \".xxhtml\")\\n+\\t\\t\\t|| $isDangerStr($filename , \".aspx\")\\t\\t\\t\\n \\t\\t) {\\n \\t\\t\\treturn true;\\n \\t\\t}'}}",
            "message_norm":"merge pull request #1629 from ajaysenr\/master\n\nupdate attachmentmodel.class.php",
            "language":"en",
            "entities":"[('#1629', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Model\/AttachmentModel.class.php'])",
            "num_files":1.0,
            "patch_content":"From 52d1d902084387bec22a64e6027f100e939733c8 Mon Sep 17 00:00:00 2001\nFrom: Ajaysen R <40132420+ajaysenr@users.noreply.github.com>\nDate: Sun, 13 Mar 2022 09:55:17 +0000\nSubject: [PATCH] Update AttachmentModel.class.php\n\n---\n server\/Application\/Api\/Model\/AttachmentModel.class.php | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/server\/Application\/Api\/Model\/AttachmentModel.class.php b\/server\/Application\/Api\/Model\/AttachmentModel.class.php\nindex 3dac201f4..ee9fd9f9c 100644\n--- a\/server\/Application\/Api\/Model\/AttachmentModel.class.php\n+++ b\/server\/Application\/Api\/Model\/AttachmentModel.class.php\n@@ -304,6 +304,7 @@ public function isDangerFilename($filename){\n \t\t\t|| $isDangerStr($filename , \"%\")\n \t\t\t|| $isDangerStr($filename , \".xml\")\n \t\t\t|| $isDangerStr($filename , \".xxhtml\")\n+\t\t\t|| $isDangerStr($filename , \".aspx\")\t\t\t\n \t\t) {\n \t\t\treturn true;\n \t\t}"
        },
        {
            "index":392,
            "vuln_id":"GHSA-wvjw-p9f5-vq28",
            "cwe_id":"{'CWE-755'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/82e6203221865de4008445b13c69b6826d2b28d9'}",
            "dataset":"osv",
            "summary":"Segfault in `tf.raw_ops.SparseCountSparseOutput` ### Impact\nPassing invalid arguments (e.g., discovered via fuzzing) to `tf.raw_ops.SparseCountSparseOutput` results in segfault.\n\n### Patches\nWe have patched the issue in GitHub commit [82e6203221865de4008445b13c69b6826d2b28d9](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/82e6203221865de4008445b13c69b6826d2b28d9).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/82e6203221865de4008445b13c69b6826d2b28d9",
            "commit_sha":"82e6203221865de4008445b13c69b6826d2b28d9",
            "patch":"SINGLE",
            "chain_ord":"['82e6203221865de4008445b13c69b6826d2b28d9']",
            "before_first_fix_commit":"{'0e182ba66c18db83668c05d26ee0c84ca9e2dbff'}",
            "last_fix_commit":"82e6203221865de4008445b13c69b6826d2b28d9",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/03\/2021, 01:02:03",
            "message":"Fix segfaults in `tf.raw_ops.SparseCountSparseOutput`.\n\nPiperOrigin-RevId: 360547563\nChange-Id: I781c7af4b54a63d867c6e18d43a44d64a5c4e7c9",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'tensorflow\/core\/kernels\/count_ops.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/82e6203221865de4008445b13c69b6826d2b28d9\/tensorflow%2Fcore%2Fkernels%2Fcount_ops.cc', 'patch': '@@ -192,6 +192,10 @@ class SparseCount : public OpKernel {\\n               \"; values shape: \", values.shape().DebugString()));\\n     }\\n \\n+    OP_REQUIRES(context, shape.NumElements() != 0,\\n+                errors::InvalidArgument(\\n+                    \"The shape argument requires at least one element.\"));\\n+\\n     bool is_1d = shape.NumElements() == 1;\\n     int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\\n     int num_values = values.NumElements();\\n@@ -212,6 +216,14 @@ class SparseCount : public OpKernel {\\n \\n     for (int idx = 0; idx < num_values; ++idx) {\\n       int batch = is_1d ? 0 : indices_values(idx, 0);\\n+      if (batch >= num_batches) {\\n+        OP_REQUIRES(context, batch < num_batches,\\n+                    errors::InvalidArgument(\\n+                        \"Indices value along the first dimension must be \",\\n+                        \"lower than the first index of the shape.\", \"Got \",\\n+                        batch, \" as batch and \", num_batches,\\n+                        \" as the first dimension of the shape.\"));\\n+      }\\n       const auto& value = values_values(idx);\\n       if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\\n         if (binary_output_) {'}}",
            "message_norm":"fix segfaults in `tf.raw_ops.sparsecountsparseoutput`.\n\npiperorigin-revid: 360547563\nchange-id: i781c7af4b54a63d867c6e18d43a44d64a5c4e7c9",
            "language":"en",
            "entities":"[('segfaults', 'SECWORD', ''), ('360547563', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/count_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 82e6203221865de4008445b13c69b6826d2b28d9 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Tue, 2 Mar 2021 17:02:03 -0800\nSubject: [PATCH] Fix segfaults in `tf.raw_ops.SparseCountSparseOutput`.\n\nPiperOrigin-RevId: 360547563\nChange-Id: I781c7af4b54a63d867c6e18d43a44d64a5c4e7c9\n---\n tensorflow\/core\/kernels\/count_ops.cc | 12 ++++++++++++\n 1 file changed, 12 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/count_ops.cc b\/tensorflow\/core\/kernels\/count_ops.cc\nindex 087deef0812f00..d6ab68c2c70bd3 100644\n--- a\/tensorflow\/core\/kernels\/count_ops.cc\n+++ b\/tensorflow\/core\/kernels\/count_ops.cc\n@@ -192,6 +192,10 @@ class SparseCount : public OpKernel {\n               \"; values shape: \", values.shape().DebugString()));\n     }\n \n+    OP_REQUIRES(context, shape.NumElements() != 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n+\n     bool is_1d = shape.NumElements() == 1;\n     int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\n     int num_values = values.NumElements();\n@@ -212,6 +216,14 @@ class SparseCount : public OpKernel {\n \n     for (int idx = 0; idx < num_values; ++idx) {\n       int batch = is_1d ? 0 : indices_values(idx, 0);\n+      if (batch >= num_batches) {\n+        OP_REQUIRES(context, batch < num_batches,\n+                    errors::InvalidArgument(\n+                        \"Indices value along the first dimension must be \",\n+                        \"lower than the first index of the shape.\", \"Got \",\n+                        batch, \" as batch and \", num_batches,\n+                        \" as the first dimension of the shape.\"));\n+      }\n       const auto& value = values_values(idx);\n       if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n         if (binary_output_) {"
        },
        {
            "index":780,
            "vuln_id":"GHSA-m52x-29pq-w3vv",
            "cwe_id":"{'CWE-79'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/mpetroff\/pannellum\/commit\/cc2f3d99953de59db908e0c6efd1c2c17f7c6914'}",
            "dataset":"osv",
            "summary":"Pannellum Cross-Site Scripting due to data not being sanitized for URIs or vbscript Versions of `pannellum` prior to 2.5.6 are vulnerable to Cross-Site Scripting (XSS). The package fails to sanitize URLs for data URIs, which may allow attackers to execute arbitrary code in a victim's browser. \n\n\n## Recommendation\n\nUpgrade to version 2.5.6 or later.",
            "published_date":"2019-11-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/mpetroff\/pannellum",
            "commit_href":"https:\/\/github.com\/mpetroff\/pannellum\/commit\/cc2f3d99953de59db908e0c6efd1c2c17f7c6914",
            "commit_sha":"cc2f3d99953de59db908e0c6efd1c2c17f7c6914",
            "patch":"SINGLE",
            "chain_ord":"['cc2f3d99953de59db908e0c6efd1c2c17f7c6914']",
            "before_first_fix_commit":"{'40111b237e763821437f501c94d8511022274dc3', 'f42e80facb41bb97321a0e2056d9ef5a4779e627'}",
            "last_fix_commit":"cc2f3d99953de59db908e0c6efd1c2c17f7c6914",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/22\/2019, 01:35:45",
            "message":"Merge pull request from GHSA-m52x-29pq-w3vv\n\nFix potential XSS vulnerability",
            "author":"Matthew Petroff",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 6, 'total': 19}",
            "files":"{'src\/js\/pannellum.js': {'additions': 13, 'deletions': 6, 'changes': 19, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mpetroff\/pannellum\/raw\/cc2f3d99953de59db908e0c6efd1c2c17f7c6914\/src%2Fjs%2Fpannellum.js', 'patch': \"@@ -1719,7 +1719,7 @@ function createHotSpot(hs) {\\n         if (config.basePath && !absoluteURL(imgp))\\n             imgp = config.basePath + imgp;\\n         a = document.createElement('a');\\n-        a.href = sanitizeURL(hs.URL ? hs.URL : imgp);\\n+        a.href = sanitizeURL(hs.URL ? hs.URL : imgp, true);\\n         a.target = '_blank';\\n         span.appendChild(a);\\n         var image = document.createElement('img');\\n@@ -1731,7 +1731,7 @@ function createHotSpot(hs) {\\n         span.style.maxWidth = 'initial';\\n     } else if (hs.URL) {\\n         a = document.createElement('a');\\n-        a.href = sanitizeURL(hs.URL);\\n+        a.href = sanitizeURL(hs.URL, true);\\n         if (hs.attributes) {\\n             for (var key in hs.attributes) {\\n                 a.setAttribute(key, hs.attributes[key]);\\n@@ -2005,7 +2005,7 @@ function processOptions(isPreview) {\\n                 var authorText = escapeHTML(config[key]);\\n                 if (config.authorURL) {\\n                     var authorLink = document.createElement('a');\\n-                    authorLink.href = sanitizeURL(config['authorURL']);\\n+                    authorLink.href = sanitizeURL(config['authorURL'], true);\\n                     authorLink.target = '_blank';\\n                     authorLink.innerHTML = escapeHTML(config[key]);\\n                     authorText = authorLink.outerHTML;\\n@@ -2016,7 +2016,7 @@ function processOptions(isPreview) {\\n             \\n             case 'fallback':\\n                 var link = document.createElement('a');\\n-                link.href = sanitizeURL(config[key]);\\n+                link.href = sanitizeURL(config[key], true);\\n                 link.target = '_blank';\\n                 link.textContent = 'Click here to view this panorama in an alternative viewer.';\\n                 var message = document.createElement('p');\\n@@ -2378,10 +2378,17 @@ function escapeHTML(s) {\\n  * The URL cannot be of protocol 'javascript'.\\n  * @private\\n  * @param {string} url - URL to sanitize\\n+ * @param {boolean} href - True if URL is for link (blocks data URIs)\\n  * @returns {string} Sanitized URL\\n  *\/\\n-function sanitizeURL(url) {\\n-    if (url.trim().toLowerCase().indexOf('javascript:') === 0) {\\n+function sanitizeURL(url, href) {\\n+    if (url.trim().toLowerCase().indexOf('javascript:') === 0 ||\\n+        url.trim().toLowerCase().indexOf('vbscript:') === 0) {\\n+        console.log('Script URL removed.');\\n+        return 'about:blank';\\n+    }\\n+    if (href && url.trim().toLowerCase().indexOf('data:') === 0) {\\n+        console.log('Data URI removed from link.');\\n         return 'about:blank';\\n     }\\n     return url;\"}}",
            "message_norm":"merge pull request from ghsa-m52x-29pq-w3vv\n\nfix potential xss vulnerability",
            "language":"ca",
            "entities":"[('ghsa-m52x-29pq-w3vv', 'VULNID', 'GHSA'), ('fix', 'ACTION', ''), ('xss', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/js\/pannellum.js'])",
            "num_files":1.0,
            "patch_content":"From 40111b237e763821437f501c94d8511022274dc3 Mon Sep 17 00:00:00 2001\nFrom: Matthew Petroff <matthew@mpetroff.net>\nDate: Fri, 15 Nov 2019 11:03:49 -0500\nSubject: [PATCH] Fix potential XSS vulnerability.\n\n---\n src\/js\/pannellum.js | 19 +++++++++++++------\n 1 file changed, 13 insertions(+), 6 deletions(-)\n\ndiff --git a\/src\/js\/pannellum.js b\/src\/js\/pannellum.js\nindex 5f29c0f7..f295dfd2 100644\n--- a\/src\/js\/pannellum.js\n+++ b\/src\/js\/pannellum.js\n@@ -1726,7 +1726,7 @@ function createHotSpot(hs) {\n         if (config.basePath && !absoluteURL(imgp))\n             imgp = config.basePath + imgp;\n         a = document.createElement('a');\n-        a.href = sanitizeURL(hs.URL ? hs.URL : imgp);\n+        a.href = sanitizeURL(hs.URL ? hs.URL : imgp, true);\n         a.target = '_blank';\n         span.appendChild(a);\n         var image = document.createElement('img');\n@@ -1738,7 +1738,7 @@ function createHotSpot(hs) {\n         span.style.maxWidth = 'initial';\n     } else if (hs.URL) {\n         a = document.createElement('a');\n-        a.href = sanitizeURL(hs.URL);\n+        a.href = sanitizeURL(hs.URL, true);\n         if (hs.attributes) {\n             for (var key in hs.attributes) {\n                 a.setAttribute(key, hs.attributes[key]);\n@@ -2012,7 +2012,7 @@ function processOptions(isPreview) {\n                 var authorText = escapeHTML(config[key]);\n                 if (config.authorURL) {\n                     var authorLink = document.createElement('a');\n-                    authorLink.href = sanitizeURL(config['authorURL']);\n+                    authorLink.href = sanitizeURL(config['authorURL'], true);\n                     authorLink.target = '_blank';\n                     authorLink.innerHTML = escapeHTML(config[key]);\n                     authorText = authorLink.outerHTML;\n@@ -2023,7 +2023,7 @@ function processOptions(isPreview) {\n             \n             case 'fallback':\n                 var link = document.createElement('a');\n-                link.href = sanitizeURL(config[key]);\n+                link.href = sanitizeURL(config[key], true);\n                 link.target = '_blank';\n                 link.textContent = 'Click here to view this panorama in an alternative viewer.';\n                 var message = document.createElement('p');\n@@ -2389,10 +2389,17 @@ function escapeHTML(s) {\n  * The URL cannot be of protocol 'javascript'.\n  * @private\n  * @param {string} url - URL to sanitize\n+ * @param {boolean} href - True if URL is for link (blocks data URIs)\n  * @returns {string} Sanitized URL\n  *\/\n-function sanitizeURL(url) {\n-    if (url.trim().toLowerCase().indexOf('javascript:') === 0) {\n+function sanitizeURL(url, href) {\n+    if (url.trim().toLowerCase().indexOf('javascript:') === 0 ||\n+        url.trim().toLowerCase().indexOf('vbscript:') === 0) {\n+        console.log('Script URL removed.');\n+        return 'about:blank';\n+    }\n+    if (href && url.trim().toLowerCase().indexOf('data:') === 0) {\n+        console.log('Data URI removed from link.');\n         return 'about:blank';\n     }\n     return url;"
        },
        {
            "index":601,
            "vuln_id":"GHSA-g7xr-v82w-qggq",
            "cwe_id":"{'CWE-94'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d'}",
            "dataset":"osv",
            "summary":"Code Injection in SEOmatic In the SEOmatic plugin up to 3.4.11 for Craft CMS 3, it is possible for unauthenticated attackers to perform a Server-Side Template Injection, allowing for remote code execution.",
            "published_date":"2022-06-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/nystudio107\/craft-seomatic",
            "commit_href":"https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d",
            "commit_sha":"3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d",
            "patch":"SINGLE",
            "chain_ord":"['3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d']",
            "before_first_fix_commit":"{'4e46b792ce973ac0c652fb330055f41aca1981c8'}",
            "last_fix_commit":"3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/24\/2021, 18:08:04",
            "message":"Sanitize the canonical URL after the absolute URL has been returned, to mitigate poisoned `X-Forwarded-Host` headers",
            "author":"Andrew Welch",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 2, 'total': 3}",
            "files":"{'src\/services\/Helper.php': {'additions': 1, 'deletions': 2, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nystudio107\/craft-seomatic\/raw\/3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d\/src%2Fservices%2FHelper.php', 'patch': '@@ -148,9 +148,8 @@ public static function safeCanonicalUrl(): string\\n         } catch (InvalidConfigException $e) {\\n             Craft::error($e->getMessage(), __METHOD__);\\n         }\\n-        $url = DynamicMetaHelper::sanitizeUrl($url);\\n \\n-        return UrlHelper::absoluteUrlWithProtocol($url);\\n+        return DynamicMetaHelper::sanitizeUrl(UrlHelper::absoluteUrlWithProtocol($url));\\n     }\\n \\n     \/**'}}",
            "message_norm":"sanitize the canonical url after the absolute url has been returned, to mitigate poisoned `x-forwarded-host` headers",
            "language":"en",
            "entities":"[('sanitize', 'SECWORD', ''), ('mitigate', 'ACTION', ''), ('poisoned', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/services\/Helper.php'])",
            "num_files":1.0,
            "patch_content":"From 3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d Mon Sep 17 00:00:00 2001\nFrom: Andrew Welch <andrew@keluli.local>\nDate: Fri, 24 Sep 2021 14:08:04 -0400\nSubject: [PATCH] Sanitize the canonical URL after the absolute URL has been\n returned, to mitigate poisoned `X-Forwarded-Host` headers\n\n---\n src\/services\/Helper.php | 3 +--\n 1 file changed, 1 insertion(+), 2 deletions(-)\n\ndiff --git a\/src\/services\/Helper.php b\/src\/services\/Helper.php\nindex 8cac2428f..c1aded868 100644\n--- a\/src\/services\/Helper.php\n+++ b\/src\/services\/Helper.php\n@@ -148,9 +148,8 @@ public static function safeCanonicalUrl(): string\n         } catch (InvalidConfigException $e) {\n             Craft::error($e->getMessage(), __METHOD__);\n         }\n-        $url = DynamicMetaHelper::sanitizeUrl($url);\n \n-        return UrlHelper::absoluteUrlWithProtocol($url);\n+        return DynamicMetaHelper::sanitizeUrl(UrlHelper::absoluteUrlWithProtocol($url));\n     }\n \n     \/**"
        },
        {
            "index":928,
            "vuln_id":"GHSA-xg72-6c83-ghh4",
            "cwe_id":"{'CWE-79'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/d35e691e72d358430abc8e99f5ba9eb374423b9f'}",
            "dataset":"osv",
            "summary":"Microweber Stored Cross-site Scripting before v1.2.20 Microwerber prior to version 1.2.20 is vulnerable to stored Cross-site Scripting (XSS).",
            "published_date":"2022-07-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/d35e691e72d358430abc8e99f5ba9eb374423b9f",
            "commit_sha":"d35e691e72d358430abc8e99f5ba9eb374423b9f",
            "patch":"SINGLE",
            "chain_ord":"['d35e691e72d358430abc8e99f5ba9eb374423b9f']",
            "before_first_fix_commit":"{'b39736f1191589e89eb4e54f5f6f05b6349626e3'}",
            "last_fix_commit":"d35e691e72d358430abc8e99f5ba9eb374423b9f",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/08\/2022, 13:41:01",
            "message":"update",
            "author":"Peter Ivanov",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 4, 'total': 16}",
            "files":"{'src\/MicroweberPackages\/App\/functions\/plupload.php': {'additions': 12, 'deletions': 4, 'changes': 16, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/d35e691e72d358430abc8e99f5ba9eb374423b9f\/src%2FMicroweberPackages%2FApp%2Ffunctions%2Fplupload.php', 'patch': \"@@ -563,17 +563,25 @@\\n                 }\\n \\n             } else if ($ext === 'svg') {\\n-\\n+                $valid = false;\\n                 if (is_file($filePath)) {\\n                     $sanitizer = new \\\\enshrined\\\\svgSanitize\\\\Sanitizer();\\n                     \/\/ Load the dirty svg\\n                     $dirtySVG = file_get_contents($filePath);\\n                      \/\/ Pass it to the sanitizer and get it back clean\\n-                    $cleanSVG = $sanitizer->sanitize($dirtySVG);\\n-                    file_put_contents($filePath, $cleanSVG);\\n+                    try {\\n+                        $cleanSVG = $sanitizer->sanitize($dirtySVG);\\n+                        $valid = true;\\n+                    } catch (\\\\Exception $e) {\\n+                        $valid = false;\\n+                    }\\n+\\n+                    if ($valid) {\\n+                        file_put_contents($filePath, $cleanSVG);\\n+                    }\\n \\n                 }\\n-               $valid = true;\\n+\\n \\n             } else {\\n                 $valid = false;\"}}",
            "message_norm":"update",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/App\/functions\/plupload.php'])",
            "num_files":1.0,
            "patch_content":"From d35e691e72d358430abc8e99f5ba9eb374423b9f Mon Sep 17 00:00:00 2001\nFrom: Peter Ivanov <peter@microweber.com>\nDate: Fri, 8 Jul 2022 16:41:01 +0300\nSubject: [PATCH] update\n\n---\n ...\/App\/functions\/plupload.php                   | 16 ++++++++++++----\n 1 file changed, 12 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/MicroweberPackages\/App\/functions\/plupload.php b\/src\/MicroweberPackages\/App\/functions\/plupload.php\nindex 244980968ce..5890b2ae9ff 100644\n--- a\/src\/MicroweberPackages\/App\/functions\/plupload.php\n+++ b\/src\/MicroweberPackages\/App\/functions\/plupload.php\n@@ -563,17 +563,25 @@\n                 }\n \n             } else if ($ext === 'svg') {\n-\n+                $valid = false;\n                 if (is_file($filePath)) {\n                     $sanitizer = new \\enshrined\\svgSanitize\\Sanitizer();\n                     \/\/ Load the dirty svg\n                     $dirtySVG = file_get_contents($filePath);\n                      \/\/ Pass it to the sanitizer and get it back clean\n-                    $cleanSVG = $sanitizer->sanitize($dirtySVG);\n-                    file_put_contents($filePath, $cleanSVG);\n+                    try {\n+                        $cleanSVG = $sanitizer->sanitize($dirtySVG);\n+                        $valid = true;\n+                    } catch (\\Exception $e) {\n+                        $valid = false;\n+                    }\n+\n+                    if ($valid) {\n+                        file_put_contents($filePath, $cleanSVG);\n+                    }\n \n                 }\n-               $valid = true;\n+\n \n             } else {\n                 $valid = false;"
        },
        {
            "index":602,
            "vuln_id":"GHSA-gm9x-q798-hmr4",
            "cwe_id":"{'CWE-78'}",
            "score":7.2,
            "chain":"{'https:\/\/github.com\/sh0ji\/git-tags-remote\/commit\/a20488960cbd2c98455386108253094897ebfc1c'}",
            "dataset":"osv",
            "summary":"Command Injection in git-tags-remote All versions of `git-tags-remote ` are vulnerable to Command Injection. The package fails to sanitize the repository input and passes it directly to an `exec` call on the `get` function . This may allow attackers to execute arbitrary code in the system if the `repo` value passed to the function is user-controlled.  \n\nThe following proof-of-concept creates a file in `\/tmp`:  \n```\nconst gitTagsRemote = require('git-tags-remote');\n\ngitTagsRemote.get('https:\/\/github.com\/sh0ji\/git-tags-remote.git; echo \"Injection Success\" > \/tmp\/command-injection.test')\n.then(tags => console.log(tags));\n```",
            "published_date":"2020-07-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/sh0ji\/git-tags-remote",
            "commit_href":"https:\/\/github.com\/sh0ji\/git-tags-remote\/commit\/a20488960cbd2c98455386108253094897ebfc1c",
            "commit_sha":"a20488960cbd2c98455386108253094897ebfc1c",
            "patch":"SINGLE",
            "chain_ord":"['a20488960cbd2c98455386108253094897ebfc1c']",
            "before_first_fix_commit":"{'c43558b77312a13f69ca25ed965cf4792c239458'}",
            "last_fix_commit":"a20488960cbd2c98455386108253094897ebfc1c",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/21\/2021, 20:02:24",
            "message":"fix: use spawn for more secure input\n\nresolves #58",
            "author":"Evan Yamanishi",
            "comments":null,
            "stats":"{'additions': 23, 'deletions': 10, 'total': 33}",
            "files":"{'src\/index.ts': {'additions': 23, 'deletions': 10, 'changes': 33, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sh0ji\/git-tags-remote\/raw\/a20488960cbd2c98455386108253094897ebfc1c\/src%2Findex.ts', 'patch': \"@@ -1,17 +1,30 @@\\n import { valid, compare } from 'semver';\\n-import { exec } from 'child_process';\\n+import { spawn } from 'child_process';\\n \\n-const lsRemoteTags = (repo: string): Promise<string> => new Promise(\\n-\\t(resolve, reject) => {\\n-\\t\\texec(`git ls-remote --tags ${repo}`, (_, stdout, stderr) => {\\n-\\t\\t\\tif (stderr) reject(new Error(stderr));\\n-\\t\\t\\tresolve(stdout.toString().trim());\\n-\\t\\t});\\n-\\t},\\n-);\\n+const lsRemoteTags = (repoPath: string): Promise<string> => new Promise((resolve, reject) => {\\n+\\tlet stderr = '';\\n+\\tlet stdout = '';\\n+\\n+\\tconst child = spawn('git', ['ls-remote', '--tags', repoPath]);\\n+\\n+\\tchild.stdout.on('data', (data) => {\\n+\\t\\tstdout += data;\\n+\\t});\\n+\\n+\\tchild.stderr.on('data', (data) => {\\n+\\t\\tstderr += data;\\n+\\t});\\n+\\n+\\tchild.on('error', reject);\\n+\\n+\\tchild.on('close', (exitCode) => {\\n+\\t\\tif (exitCode !== 0 || stderr.length) reject(new Error(stderr));\\n+\\t\\tresolve(stdout.toString().trim());\\n+\\t});\\n+});\\n \\n const parseTags = (tags: string): Map<string, string> => {\\n-\\tconst tagMap = new Map();\\n+\\tconst tagMap = new Map<string, string>();\\n \\ttags.split('\\\\n')\\n \\t\\t.forEach((str) => {\\n \\t\\t\\tconst ref = str.split(\/\\\\t\/);\"}}",
            "message_norm":"fix: use spawn for more secure input\n\nresolves #58",
            "language":"en",
            "entities":"[('secure', 'SECWORD', ''), ('#58', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/index.ts'])",
            "num_files":1.0,
            "patch_content":"From a20488960cbd2c98455386108253094897ebfc1c Mon Sep 17 00:00:00 2001\nFrom: Evan Yamanishi <yamanishi1@gmail.com>\nDate: Mon, 21 Jun 2021 16:02:24 -0400\nSubject: [PATCH] fix: use spawn for more secure input\n\nresolves #58\n---\n src\/index.ts | 33 +++++++++++++++++++++++----------\n 1 file changed, 23 insertions(+), 10 deletions(-)\n\ndiff --git a\/src\/index.ts b\/src\/index.ts\nindex 06ebcd3..fe98700 100644\n--- a\/src\/index.ts\n+++ b\/src\/index.ts\n@@ -1,17 +1,30 @@\n import { valid, compare } from 'semver';\n-import { exec } from 'child_process';\n+import { spawn } from 'child_process';\n \n-const lsRemoteTags = (repo: string): Promise<string> => new Promise(\n-\t(resolve, reject) => {\n-\t\texec(`git ls-remote --tags ${repo}`, (_, stdout, stderr) => {\n-\t\t\tif (stderr) reject(new Error(stderr));\n-\t\t\tresolve(stdout.toString().trim());\n-\t\t});\n-\t},\n-);\n+const lsRemoteTags = (repoPath: string): Promise<string> => new Promise((resolve, reject) => {\n+\tlet stderr = '';\n+\tlet stdout = '';\n+\n+\tconst child = spawn('git', ['ls-remote', '--tags', repoPath]);\n+\n+\tchild.stdout.on('data', (data) => {\n+\t\tstdout += data;\n+\t});\n+\n+\tchild.stderr.on('data', (data) => {\n+\t\tstderr += data;\n+\t});\n+\n+\tchild.on('error', reject);\n+\n+\tchild.on('close', (exitCode) => {\n+\t\tif (exitCode !== 0 || stderr.length) reject(new Error(stderr));\n+\t\tresolve(stdout.toString().trim());\n+\t});\n+});\n \n const parseTags = (tags: string): Map<string, string> => {\n-\tconst tagMap = new Map();\n+\tconst tagMap = new Map<string, string>();\n \ttags.split('\\n')\n \t\t.forEach((str) => {\n \t\t\tconst ref = str.split(\/\\t\/);"
        },
        {
            "index":554,
            "vuln_id":"GHSA-hc72-vj3g-5g2g",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/SeriaWei\/ZKEACMS\/commit\/833c5460dc5c6152092f6ad54b8b832870a59903'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in ZKEACMS A cross-site scripting (XSS) vulnerability in \/navigation\/create?ParentID=%23 of ZKEACMS v3.5.2 allows attackers to execute arbitrary web scripts or HTML via a crafted payload injected into the ParentID parameter.",
            "published_date":"2022-05-26",
            "chain_len":1,
            "project":"https:\/\/github.com\/SeriaWei\/ZKEACMS",
            "commit_href":"https:\/\/github.com\/SeriaWei\/ZKEACMS\/commit\/833c5460dc5c6152092f6ad54b8b832870a59903",
            "commit_sha":"833c5460dc5c6152092f6ad54b8b832870a59903",
            "patch":"SINGLE",
            "chain_ord":"['833c5460dc5c6152092f6ad54b8b832870a59903']",
            "before_first_fix_commit":"{'53109ba58bbeac75074583ec261732772ed1ecc5'}",
            "last_fix_commit":"833c5460dc5c6152092f6ad54b8b832870a59903",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/14\/2022, 14:55:34",
            "message":"Sanitize Html\n\n#457",
            "author":"wayne",
            "comments":null,
            "stats":"{'additions': 36, 'deletions': 1, 'total': 37}",
            "files":"{'src\/ZKEACMS\/Common\/Service\/NavigationService.cs': {'additions': 36, 'deletions': 1, 'changes': 37, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/SeriaWei\/ZKEACMS\/raw\/833c5460dc5c6152092f6ad54b8b832870a59903\/src%2FZKEACMS%2FCommon%2FService%2FNavigationService.cs', 'patch': '@@ -11,13 +11,16 @@\\n using ZKEACMS.Common.Models;\\n using Easy;\\n using Microsoft.EntityFrameworkCore;\\n+using ZKEACMS.Safety;\\n \\n namespace ZKEACMS.Common.Service\\n {\\n     public class NavigationService : ServiceBase<NavigationEntity, CMSDbContext>, INavigationService\\n     {\\n-        public NavigationService(IApplicationContext applicationContext, CMSDbContext dbContext) : base(applicationContext, dbContext)\\n+        private readonly IHtmlSanitizer _htmlSanitizer;\\n+        public NavigationService(IApplicationContext applicationContext, CMSDbContext dbContext, IHtmlSanitizer htmlSanitizer) : base(applicationContext, dbContext)\\n         {\\n+            _htmlSanitizer = htmlSanitizer;\\n         }\\n         public override DbSet<NavigationEntity> CurrentDbSet => DbContext.Navigation;\\n         public override ServiceResult<NavigationEntity> Add(NavigationEntity item)\\n@@ -27,8 +30,34 @@ public override ServiceResult<NavigationEntity> Add(NavigationEntity item)\\n                 item.ParentId = \"#\";\\n             }\\n             item.ID = Guid.NewGuid().ToString(\"N\");\\n+            Santize(item);\\n             return base.Add(item);\\n         }\\n+\\n+        public override ServiceResult<NavigationEntity> AddRange(params NavigationEntity[] items)\\n+        {\\n+            foreach (var item in items)\\n+            {\\n+                Santize(item);\\n+            }\\n+            return base.AddRange(items);\\n+        }\\n+\\n+        public override ServiceResult<NavigationEntity> Update(NavigationEntity item)\\n+        {\\n+            Santize(item);\\n+            return base.Update(item);\\n+        }\\n+\\n+        public override ServiceResult<NavigationEntity> UpdateRange(params NavigationEntity[] items)\\n+        {\\n+            foreach (var item in items)\\n+            {\\n+                Santize(item);\\n+            }\\n+            return base.UpdateRange(items);\\n+        }\\n+\\n         public override void Remove(NavigationEntity item)\\n         {\\n             Remove(m => m.ParentId == item.ID);\\n@@ -73,5 +102,11 @@ public void Move(string id, string parentId, int position, int oldPosition)\\n             }\\n             Update(nav);\\n         }\\n+\\n+        private void Santize(NavigationEntity item)\\n+        {\\n+            item.Title = _htmlSanitizer.Sanitize(item.Title);\\n+            item.Html = _htmlSanitizer.Sanitize(item.Html);\\n+        }\\n     }\\n }\\n\\\\ No newline at end of file'}}",
            "message_norm":"sanitize html\n\n#457",
            "language":"sq",
            "entities":"[('sanitize', 'SECWORD', ''), ('#457', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/ZKEACMS\/Common\/Service\/NavigationService.cs'])",
            "num_files":1.0,
            "patch_content":"From 833c5460dc5c6152092f6ad54b8b832870a59903 Mon Sep 17 00:00:00 2001\nFrom: wayne <seriawei@outlook.com>\nDate: Thu, 14 Apr 2022 22:55:34 +0800\nSubject: [PATCH] Sanitize Html\n\n#457\n---\n ...\/Common\/Service\/NavigationService.cs       | 37 ++++++++++++++++++-\n 1 file changed, 36 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/ZKEACMS\/Common\/Service\/NavigationService.cs b\/src\/ZKEACMS\/Common\/Service\/NavigationService.cs\nindex c6fafc72..66ed8921 100644\n--- a\/src\/ZKEACMS\/Common\/Service\/NavigationService.cs\n+++ b\/src\/ZKEACMS\/Common\/Service\/NavigationService.cs\n@@ -11,13 +11,16 @@\n using ZKEACMS.Common.Models;\n using Easy;\n using Microsoft.EntityFrameworkCore;\n+using ZKEACMS.Safety;\n \n namespace ZKEACMS.Common.Service\n {\n     public class NavigationService : ServiceBase<NavigationEntity, CMSDbContext>, INavigationService\n     {\n-        public NavigationService(IApplicationContext applicationContext, CMSDbContext dbContext) : base(applicationContext, dbContext)\n+        private readonly IHtmlSanitizer _htmlSanitizer;\n+        public NavigationService(IApplicationContext applicationContext, CMSDbContext dbContext, IHtmlSanitizer htmlSanitizer) : base(applicationContext, dbContext)\n         {\n+            _htmlSanitizer = htmlSanitizer;\n         }\n         public override DbSet<NavigationEntity> CurrentDbSet => DbContext.Navigation;\n         public override ServiceResult<NavigationEntity> Add(NavigationEntity item)\n@@ -27,8 +30,34 @@ public override ServiceResult<NavigationEntity> Add(NavigationEntity item)\n                 item.ParentId = \"#\";\n             }\n             item.ID = Guid.NewGuid().ToString(\"N\");\n+            Santize(item);\n             return base.Add(item);\n         }\n+\n+        public override ServiceResult<NavigationEntity> AddRange(params NavigationEntity[] items)\n+        {\n+            foreach (var item in items)\n+            {\n+                Santize(item);\n+            }\n+            return base.AddRange(items);\n+        }\n+\n+        public override ServiceResult<NavigationEntity> Update(NavigationEntity item)\n+        {\n+            Santize(item);\n+            return base.Update(item);\n+        }\n+\n+        public override ServiceResult<NavigationEntity> UpdateRange(params NavigationEntity[] items)\n+        {\n+            foreach (var item in items)\n+            {\n+                Santize(item);\n+            }\n+            return base.UpdateRange(items);\n+        }\n+\n         public override void Remove(NavigationEntity item)\n         {\n             Remove(m => m.ParentId == item.ID);\n@@ -73,5 +102,11 @@ public void Move(string id, string parentId, int position, int oldPosition)\n             }\n             Update(nav);\n         }\n+\n+        private void Santize(NavigationEntity item)\n+        {\n+            item.Title = _htmlSanitizer.Sanitize(item.Title);\n+            item.Html = _htmlSanitizer.Sanitize(item.Html);\n+        }\n     }\n }\n\\ No newline at end of file"
        },
        {
            "index":887,
            "vuln_id":"GHSA-q97v-764g-r2rp",
            "cwe_id":"{'CWE-284'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/gollum\/grit_adapter\/commit\/4520d973c81fecfebbeacd2ef2f1849d763951c7'}",
            "dataset":"osv",
            "summary":"High severity vulnerability that affects gollum and gollum-lib The gollum-grit_adapter Ruby gem dependency in gollum before 3.1.1 and the gollum-lib gem dependency in gollum-lib before 4.0.1 when the string \"master\" is in any of the wiki documents, allows remote authenticated users to execute arbitrary code via the -O or --open-files-in-pager flags.",
            "published_date":"2017-11-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/gollum\/grit_adapter",
            "commit_href":"https:\/\/github.com\/gollum\/grit_adapter\/commit\/4520d973c81fecfebbeacd2ef2f1849d763951c7",
            "commit_sha":"4520d973c81fecfebbeacd2ef2f1849d763951c7",
            "patch":"SINGLE",
            "chain_ord":"['4520d973c81fecfebbeacd2ef2f1849d763951c7']",
            "before_first_fix_commit":"{'1b04ba5a1e822a990d6bde99b7332eef56a9998c'}",
            "last_fix_commit":"4520d973c81fecfebbeacd2ef2f1849d763951c7",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/04\/2014, 12:45:17",
            "message":"Fix security issue with git grep -O",
            "author":"Dawa Ometto",
            "comments":"{'com_1': {'author': 'dometto', 'datetime': '12\/04\/2014, 13:53:01', 'body': 'Escape the `ls_files` query for good measure.'}}",
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'lib\/grit_adapter\/git_layer_grit.rb': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/gollum\/grit_adapter\/raw\/4520d973c81fecfebbeacd2ef2f1849d763951c7\/lib%2Fgrit_adapter%2Fgit_layer_grit.rb', 'patch': '@@ -136,6 +136,8 @@ def exist?\\n       \\n       def grep(query, options={})\\n         ref = options[:ref] ? options[:ref] : \"HEAD\"\\n+        query = Shellwords.split(query).select {|q| !(q =~ \/^(-O)|(--open-files-in-pager)\/) }\\n+        query = Shellwords.join(query)\\n         args = [{}, \\'-I\\', \\'-i\\', \\'-c\\', query, ref, \\'--\\']\\n         args << options[:path] if options[:path]\\n         result = @git.grep(*args).split(\"\\\\n\")\\n@@ -165,6 +167,7 @@ def rev_list(options, *refs)\\n       \\n       def ls_files(query, options = {})\\n         options[:ref] = options[:ref] ? options[:ref] : \"HEAD\"\\n+        query = Shellwords.shellescape(query)\\n         @git.ls_files({}, \"*#{query}*\").split(\"\\\\n\")\\n       end'}}",
            "message_norm":"fix security issue with git grep -o",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/grit_adapter\/git_layer_grit.rb'])",
            "num_files":1.0,
            "patch_content":"From 4520d973c81fecfebbeacd2ef2f1849d763951c7 Mon Sep 17 00:00:00 2001\nFrom: Dawa Ometto <dawa.ometto@phil.uu.nl>\nDate: Thu, 4 Dec 2014 13:45:17 +0100\nSubject: [PATCH] Fix security issue with git grep -O\n\n---\n lib\/grit_adapter\/git_layer_grit.rb | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/lib\/grit_adapter\/git_layer_grit.rb b\/lib\/grit_adapter\/git_layer_grit.rb\nindex f607a7a..e677ca6 100644\n--- a\/lib\/grit_adapter\/git_layer_grit.rb\n+++ b\/lib\/grit_adapter\/git_layer_grit.rb\n@@ -136,6 +136,8 @@ def exist?\n       \n       def grep(query, options={})\n         ref = options[:ref] ? options[:ref] : \"HEAD\"\n+        query = Shellwords.split(query).select {|q| !(q =~ \/^(-O)|(--open-files-in-pager)\/) }\n+        query = Shellwords.join(query)\n         args = [{}, '-I', '-i', '-c', query, ref, '--']\n         args << options[:path] if options[:path]\n         result = @git.grep(*args).split(\"\\n\")\n@@ -165,6 +167,7 @@ def rev_list(options, *refs)\n       \n       def ls_files(query, options = {})\n         options[:ref] = options[:ref] ? options[:ref] : \"HEAD\"\n+        query = Shellwords.shellescape(query)\n         @git.ls_files({}, \"*#{query}*\").split(\"\\n\")\n       end"
        },
        {
            "index":680,
            "vuln_id":"GHSA-xqj7-j8j5-f2xr",
            "cwe_id":"{'CWE-327'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/bcgit\/bc-java\/commit\/73780ac522b7795fc165630aba8d5f5729acc839', 'https:\/\/github.com\/bcgit\/bc-java\/commit\/22467b6e8fe19717ecdf201c0cf91bacf04a55ad'}",
            "dataset":"osv",
            "summary":"Bouncy Castle has a flaw in the Low-level interface to RSA key pair generator Bouncy Castle BC 1.54 - 1.59, BC-FJA 1.0.0, BC-FJA 1.0.1 and earlier have a flaw in the Low-level interface to RSA key pair generator, specifically RSA Key Pairs generated in low-level API with added certainty may have less M-R tests than expected. This appears to be fixed in versions BC 1.60 beta 4 and later, BC-FJA 1.0.2 and later.",
            "published_date":"2018-10-16",
            "chain_len":2,
            "project":"https:\/\/github.com\/bcgit\/bc-java",
            "commit_href":"https:\/\/github.com\/bcgit\/bc-java\/commit\/22467b6e8fe19717ecdf201c0cf91bacf04a55ad",
            "commit_sha":"22467b6e8fe19717ecdf201c0cf91bacf04a55ad",
            "patch":"MULTI",
            "chain_ord":"['73780ac522b7795fc165630aba8d5f5729acc839', '22467b6e8fe19717ecdf201c0cf91bacf04a55ad']",
            "before_first_fix_commit":"{'73780ac522b7795fc165630aba8d5f5729acc839'}",
            "last_fix_commit":"22467b6e8fe19717ecdf201c0cf91bacf04a55ad",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/22\/2018, 22:14:24",
            "message":"BJA-694 minor tweak to avoid method signature change",
            "author":"David Hook",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'core\/src\/main\/java\/org\/bouncycastle\/crypto\/generators\/RSAKeyPairGenerator.java': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/bcgit\/bc-java\/raw\/22467b6e8fe19717ecdf201c0cf91bacf04a55ad\/core%2Fsrc%2Fmain%2Fjava%2Forg%2Fbouncycastle%2Fcrypto%2Fgenerators%2FRSAKeyPairGenerator.java', 'patch': '@@ -157,8 +157,6 @@ public AsymmetricCipherKeyPair generateKeyPair()\\n      *\/\\n     protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger sqrdBound)\\n     {\\n-        int iterations = getNumberOfIterations(bitlength, param.getCertainty());\\n-\\n         for (int i = 0; i != 5 * bitlength; i++)\\n         {\\n             BigInteger p = new BigInteger(bitlength, 1, param.getRandom());\\n@@ -173,7 +171,7 @@ protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger s\\n                 continue;\\n             }\\n \\n-            if (!isProbablePrime(p, iterations))\\n+            if (!isProbablePrime(p))\\n             {\\n                 continue;\\n             }\\n@@ -189,8 +187,10 @@ protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger s\\n         throw new IllegalStateException(\"unable to generate prime number for RSA key\");\\n     }\\n \\n-    protected boolean isProbablePrime(BigInteger x, int iterations)\\n+    protected boolean isProbablePrime(BigInteger x)\\n     {\\n+        int iterations = getNumberOfIterations(x.bitLength(), param.getCertainty());\\n+\\n         \/*\\n          * Primes class for FIPS 186-4 C.3 primality checking\\n          *\/'}}",
            "message_norm":"bja-694 minor tweak to avoid method signature change",
            "language":"en",
            "entities":"[('tweak', 'FLAW', ''), ('signature', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/src\/main\/java\/org\/bouncycastle\/crypto\/generators\/RSAKeyPairGenerator.java'])",
            "num_files":1.0,
            "patch_content":"From 22467b6e8fe19717ecdf201c0cf91bacf04a55ad Mon Sep 17 00:00:00 2001\nFrom: David Hook <dgh@cryptoworkshop.com>\nDate: Mon, 23 Apr 2018 08:14:24 +1000\nSubject: [PATCH] BJA-694 minor tweak to avoid method signature change\n\n---\n ...\/crypto\/generators\/RSAKeyPairGenerator.java            | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/core\/src\/main\/java\/org\/bouncycastle\/crypto\/generators\/RSAKeyPairGenerator.java b\/core\/src\/main\/java\/org\/bouncycastle\/crypto\/generators\/RSAKeyPairGenerator.java\nindex 3dafea9485..beb1aee2ed 100644\n--- a\/core\/src\/main\/java\/org\/bouncycastle\/crypto\/generators\/RSAKeyPairGenerator.java\n+++ b\/core\/src\/main\/java\/org\/bouncycastle\/crypto\/generators\/RSAKeyPairGenerator.java\n@@ -157,8 +157,6 @@ public AsymmetricCipherKeyPair generateKeyPair()\n      *\/\n     protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger sqrdBound)\n     {\n-        int iterations = getNumberOfIterations(bitlength, param.getCertainty());\n-\n         for (int i = 0; i != 5 * bitlength; i++)\n         {\n             BigInteger p = new BigInteger(bitlength, 1, param.getRandom());\n@@ -173,7 +171,7 @@ protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger s\n                 continue;\n             }\n \n-            if (!isProbablePrime(p, iterations))\n+            if (!isProbablePrime(p))\n             {\n                 continue;\n             }\n@@ -189,8 +187,10 @@ protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger s\n         throw new IllegalStateException(\"unable to generate prime number for RSA key\");\n     }\n \n-    protected boolean isProbablePrime(BigInteger x, int iterations)\n+    protected boolean isProbablePrime(BigInteger x)\n     {\n+        int iterations = getNumberOfIterations(x.bitLength(), param.getCertainty());\n+\n         \/*\n          * Primes class for FIPS 186-4 C.3 primality checking\n          *\/"
        },
        {
            "index":184,
            "vuln_id":"GHSA-8xqr-4cpm-wx7g",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/tanem\/react-svg\/pull\/57\/commits\/ec7de5d678f53a085cee1348cb1aa069c9fc42fb'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting in react-svg Versions of `react-svg` before 2.2.18 are vulnerable to cross-site scripting (xss). This is due to the fact that scripts found in SVG files are run by default.\n\n\n## Recommendation\n\nUpdate to version 2.2.18 or later.",
            "published_date":"2019-05-31",
            "chain_len":1,
            "project":"https:\/\/github.com\/tanem\/react-svg",
            "commit_href":"https:\/\/github.com\/tanem\/react-svg\/pull\/57\/commits\/ec7de5d678f53a085cee1348cb1aa069c9fc42fb",
            "commit_sha":"ec7de5d678f53a085cee1348cb1aa069c9fc42fb",
            "patch":"SINGLE",
            "chain_ord":"['ec7de5d678f53a085cee1348cb1aa069c9fc42fb']",
            "before_first_fix_commit":"{'9fa13da92cc4c44a10b6e2aced023d3199e8c6bb'}",
            "last_fix_commit":"ec7de5d678f53a085cee1348cb1aa069c9fc42fb",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/21\/2018, 18:37:51",
            "message":"Changed default evalScripts prop to match documentation.",
            "author":"Ron Perris",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tanem\/react-svg\/raw\/ec7de5d678f53a085cee1348cb1aa069c9fc42fb\/src%2Findex.js', 'patch': \"@@ -10,7 +10,7 @@ export default class ReactSVG extends React.Component {\\n   static defaultProps = {\\n     callback: () => {},\\n     className: null,\\n-    evalScripts: 'once',\\n+    evalScripts: 'never',\\n     style: {},\\n     wrapperClassName: null\\n   }\"}}",
            "message_norm":"changed default evalscripts prop to match documentation.",
            "language":"en",
            "entities":"[('changed', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/index.js'])",
            "num_files":1.0,
            "patch_content":"From ec7de5d678f53a085cee1348cb1aa069c9fc42fb Mon Sep 17 00:00:00 2001\nFrom: Ron Perris <ronperris@gmail.com>\nDate: Sat, 21 Apr 2018 11:37:51 -0700\nSubject: [PATCH] Changed default evalScripts prop to match documentation.\n\n---\n src\/index.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/index.js b\/src\/index.js\nindex ce4742173..9f04da8bc 100644\n--- a\/src\/index.js\n+++ b\/src\/index.js\n@@ -10,7 +10,7 @@ export default class ReactSVG extends React.Component {\n   static defaultProps = {\n     callback: () => {},\n     className: null,\n-    evalScripts: 'once',\n+    evalScripts: 'never',\n     style: {},\n     wrapperClassName: null\n   }"
        },
        {
            "index":692,
            "vuln_id":"GHSA-c265-37vj-cwcc",
            "cwe_id":"{'CWE-502'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/99001cdb6807b5c7b170ec6a9092ecbb618ae79c'}",
            "dataset":"osv",
            "summary":"Deserialization of untrusted data in Jackson Databind FasterXML jackson-databind 2.x before 2.9.10.5 mishandles the interaction between serialization gadgets and typing, related to com.sun.org.apache.xalan.internal.lib.sql.JNDIConnectionPool (aka xalan2).",
            "published_date":"2020-06-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/FasterXML\/jackson-databind",
            "commit_href":"https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
            "commit_sha":"99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
            "patch":"SINGLE",
            "chain_ord":"['99001cdb6807b5c7b170ec6a9092ecbb618ae79c']",
            "before_first_fix_commit":"{'716f3f95fb82c686cc20d7255665de54c5330fa7'}",
            "last_fix_commit":"99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/02\/2020, 02:17:39",
            "message":"Fix #2704",
            "author":"Tatu Saloranta",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'release-notes\/VERSION-2.x': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/FasterXML\/jackson-databind\/raw\/99001cdb6807b5c7b170ec6a9092ecbb618ae79c\/release-notes%2FVERSION-2.x', 'patch': '@@ -10,6 +10,8 @@ Project: jackson-databind\\n  (reported by Topsec(tcc))\\n #2698: Block one more gadget type (weblogic\/oracle-aqjms)\\n  (reported by Fangrun Li)\\n+#2704: Block one more gadget type (weblogic\/oracle-aqjms)\\n+ (reported by XuYuanzhen)\\n \\n 2.9.10.4 (11-Apr-2020)'}}",
            "message_norm":"fix #2704",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('#2704', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['release-notes\/VERSION-2.x'])",
            "num_files":1.0,
            "patch_content":"From 99001cdb6807b5c7b170ec6a9092ecbb618ae79c Mon Sep 17 00:00:00 2001\nFrom: Tatu Saloranta <tatu.saloranta@iki.fi>\nDate: Fri, 1 May 2020 19:17:39 -0700\nSubject: [PATCH] Fix #2704\n\n---\n release-notes\/VERSION-2.x | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/release-notes\/VERSION-2.x b\/release-notes\/VERSION-2.x\nindex dff1317057..0bc7e01ef3 100644\n--- a\/release-notes\/VERSION-2.x\n+++ b\/release-notes\/VERSION-2.x\n@@ -10,6 +10,8 @@ Project: jackson-databind\n  (reported by Topsec(tcc))\n #2698: Block one more gadget type (weblogic\/oracle-aqjms)\n  (reported by Fangrun Li)\n+#2704: Block one more gadget type (weblogic\/oracle-aqjms)\n+ (reported by XuYuanzhen)\n \n 2.9.10.4 (11-Apr-2020)"
        },
        {
            "index":771,
            "vuln_id":"GHSA-9m95-8hx6-7p9v",
            "cwe_id":"{'CWE-20'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/opencontainers\/umoci\/commit\/d9efc31daf2206f7d3fdb839863cf7a576a2eb57'}",
            "dataset":"osv",
            "summary":"Improper input validation in umoci ### Impact\n\numoci 0.4.6 and earlier can be tricked into modifying host files by\ncreating a malicious layer that has a symlink with the name \".\" (or\n\"\/\"). Because umoci deletes inodes if they change types, this results in\nthe rootfs directory being replaced with an attacker-controlled symlink.\nSubsequent image layers will then be applied on top of the target of the\nsymlink (which could be any directory on the host filesystem the user\nrunning umoci has access to).\n\nWhile umoci does have defences against symlink-based attacks, they are\nall implemented by resolving things relative to the rootfs directory --\nif the rootfs itself is a symlink, umoci resolves it first.\n\nThis vulnerability affects both \"umoci unpack\" and \"umoci raw unpack\".\n\n### Patches\nThis issue has been patched in umoci 0.4.7, see the references section\nfor the specific commit which fixed this vulnerability.\n\n### Workarounds\nNote that if you use umoci as an unprivileged user (using the --rootless\nflag) then umoci will not be able to overwrite any files that your user\ndoesn't have access to. Other possible mitigations are to run umoci\nunder an LSM profile such as AppArmor or SELinux to restrict the level\nof access it has outside of container image directories.\n\n### References\n* [oss-security public disclosure](https:\/\/www.openwall.com\/lists\/oss-security\/2021\/04\/06\/2)\n* [patch](https:\/\/github.com\/opencontainers\/umoci\/commit\/d9efc31daf2206f7d3fdb839863cf7a576a2eb57)\n\n### Credits\nThanks to Robin Peraglie from Cure53 for discovering and reporting this\nvulnerability.\n\n### For more information\n\nIf you have any questions or comments about this advisory\n* Open an issue in <https:\/\/github.com\/opencontainers\/umoci>.\n* Email us at <security@opencontainers.org>.",
            "published_date":"2022-02-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/opencontainers\/umoci",
            "commit_href":"https:\/\/github.com\/opencontainers\/umoci\/commit\/d9efc31daf2206f7d3fdb839863cf7a576a2eb57",
            "commit_sha":"d9efc31daf2206f7d3fdb839863cf7a576a2eb57",
            "patch":"SINGLE",
            "chain_ord":"['d9efc31daf2206f7d3fdb839863cf7a576a2eb57']",
            "before_first_fix_commit":"{'07fa845e5b068dee64dcbf391b456a564a6fcfa6'}",
            "last_fix_commit":"d9efc31daf2206f7d3fdb839863cf7a576a2eb57",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/23\/2021, 13:17:06",
            "message":"layer: don't permit \/ type to be changed on extraction\n\nIf users can change the type of \/ to a symlink, they can cause umoci to\noverwrite host files. This is obviously bad, and is not caught by the\nrest of our directory escape detection code because the root itself has\nbeen changed to a different directory.\n\nFixes: CVE-2021-29136\nReported-by: Robin Peraglie <robin@cure53.de>\nTested-by: Daniel Dao <dqminh89@gmail.com>\nReviewed-by: Tycho Andersen <tycho@tycho.pizza>\nSigned-off-by: Aleksa Sarai <cyphar@cyphar.com>",
            "author":"Aleksa Sarai",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'oci\/layer\/tar_extract.go': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencontainers\/umoci\/raw\/d9efc31daf2206f7d3fdb839863cf7a576a2eb57\/oci%2Flayer%2Ftar_extract.go', 'patch': '@@ -404,6 +404,11 @@ func (te *TarExtractor) UnpackEntry(root string, hdr *tar.Header, r io.Reader) (\\n \\tif filepath.Join(\"\/\", hdr.Name) == \"\/\" {\\n \\t\\t\/\/ If we got an entry for the root, then unsafeDir is the full path.\\n \\t\\tunsafeDir, file = hdr.Name, \".\"\\n+\\t\\t\/\/ If we\\'re being asked to change the root type, bail because they may\\n+\\t\\t\/\/ change it to a symlink which we could inadvertently follow.\\n+\\t\\tif hdr.Typeflag != tar.TypeDir {\\n+\\t\\t\\treturn errors.New(\"malicious tar entry -- refusing to change type of root directory\")\\n+\\t\\t}\\n \\t}\\n \\tdir, err := securejoin.SecureJoinVFS(root, unsafeDir, te.fsEval)\\n \\tif err != nil {'}}",
            "message_norm":"layer: don't permit \/ type to be changed on extraction\n\nif users can change the type of \/ to a symlink, they can cause umoci to\noverwrite host files. this is obviously bad, and is not caught by the\nrest of our directory escape detection code because the root itself has\nbeen changed to a different directory.\n\nfixes: cve-2021-29136\nreported-by: robin peraglie <robin@cure53.de>\ntested-by: daniel dao <dqminh89@gmail.com>\nreviewed-by: tycho andersen <tycho@tycho.pizza>\nsigned-off-by: aleksa sarai <cyphar@cyphar.com>",
            "language":"en",
            "entities":"[('changed', 'ACTION', ''), ('change', 'ACTION', ''), ('symlink', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('changed', 'ACTION', ''), ('fixes', 'ACTION', ''), ('cve-2021-29136', 'VULNID', 'CVE'), ('robin@cure53.de', 'EMAIL', ''), ('dqminh89@gmail.com', 'EMAIL', ''), ('cyphar@cyphar.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['oci\/layer\/tar_extract.go'])",
            "num_files":1.0,
            "patch_content":"From d9efc31daf2206f7d3fdb839863cf7a576a2eb57 Mon Sep 17 00:00:00 2001\nFrom: Aleksa Sarai <cyphar@cyphar.com>\nDate: Wed, 24 Mar 2021 00:17:06 +1100\nSubject: [PATCH] layer: don't permit \/ type to be changed on extraction\n\nIf users can change the type of \/ to a symlink, they can cause umoci to\noverwrite host files. This is obviously bad, and is not caught by the\nrest of our directory escape detection code because the root itself has\nbeen changed to a different directory.\n\nFixes: CVE-2021-29136\nReported-by: Robin Peraglie <robin@cure53.de>\nTested-by: Daniel Dao <dqminh89@gmail.com>\nReviewed-by: Tycho Andersen <tycho@tycho.pizza>\nSigned-off-by: Aleksa Sarai <cyphar@cyphar.com>\n---\n oci\/layer\/tar_extract.go | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/oci\/layer\/tar_extract.go b\/oci\/layer\/tar_extract.go\nindex 1b8c3d67c..d74141051 100644\n--- a\/oci\/layer\/tar_extract.go\n+++ b\/oci\/layer\/tar_extract.go\n@@ -404,6 +404,11 @@ func (te *TarExtractor) UnpackEntry(root string, hdr *tar.Header, r io.Reader) (\n \tif filepath.Join(\"\/\", hdr.Name) == \"\/\" {\n \t\t\/\/ If we got an entry for the root, then unsafeDir is the full path.\n \t\tunsafeDir, file = hdr.Name, \".\"\n+\t\t\/\/ If we're being asked to change the root type, bail because they may\n+\t\t\/\/ change it to a symlink which we could inadvertently follow.\n+\t\tif hdr.Typeflag != tar.TypeDir {\n+\t\t\treturn errors.New(\"malicious tar entry -- refusing to change type of root directory\")\n+\t\t}\n \t}\n \tdir, err := securejoin.SecureJoinVFS(root, unsafeDir, te.fsEval)\n \tif err != nil {"
        },
        {
            "index":872,
            "vuln_id":"GHSA-w3v3-cxq5-9vr4",
            "cwe_id":"{'CWE-276', 'CWE-284'}",
            "score":6.3,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/cf14a0222c67472086cd08b2155f045edaf75f2e'}",
            "dataset":"osv",
            "summary":"Incorrect Default Permissions and Improper Access Control in snipe-it snipe-it is vulnerable to Improper Access Control\/Incorrect Default Permissions.",
            "published_date":"2022-01-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/cf14a0222c67472086cd08b2155f045edaf75f2e",
            "commit_sha":"cf14a0222c67472086cd08b2155f045edaf75f2e",
            "patch":"SINGLE",
            "chain_ord":"['cf14a0222c67472086cd08b2155f045edaf75f2e']",
            "before_first_fix_commit":"{'b78e610ce3b4295fb4c56659976a5d5d26eeb6da', 'bb095641c2f421f744796d184287c46fc9303591'}",
            "last_fix_commit":"cf14a0222c67472086cd08b2155f045edaf75f2e",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/11\/2022, 03:24:31",
            "message":"Merge pull request #10498 from Haxatron\/master\n\nFix access control",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 2, 'total': 8}",
            "files":"{'app\/Http\/Controllers\/BulkAssetModelsController.php': {'additions': 6, 'deletions': 2, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/cf14a0222c67472086cd08b2155f045edaf75f2e\/app%2FHttp%2FControllers%2FBulkAssetModelsController.php', 'patch': \"@@ -32,6 +32,7 @@ public function edit(Request $request)\\n \\n             \/\/ If deleting....\\n             if ($request->input('bulk_actions')=='delete') {\\n+                $this->authorize('delete', AssetModel::class);\\n                 $valid_count = 0;\\n                 foreach ($models as $model) {\\n                     if ($model->assets_count == 0) {\\n@@ -42,7 +43,7 @@ public function edit(Request $request)\\n \\n             \/\/ Otherwise display the bulk edit screen\\n             }\\n-\\n+            $this->authorize('update', AssetModel::class);\\n             $nochange = ['NC' => 'No Change'];\\n             return view('models\/bulk-edit', compact('models'))\\n                 ->with('fieldset_list', $nochange + Helper::customFieldsetList())\\n@@ -63,7 +64,8 @@ public function edit(Request $request)\\n      *\/\\n     public function update(Request $request)\\n     {\\n-\\n+        $this->authorize('update', AssetModel::class);\\n+      \\n         $models_raw_array = $request->input('ids');\\n         $update_array = array();\\n \\n@@ -103,6 +105,8 @@ public function update(Request $request)\\n      *\/\\n     public function destroy(Request $request)\\n     {\\n+        $this->authorize('delete', AssetModel::class);\\n+      \\n         $models_raw_array = $request->input('ids');\\n \\n         if ((is_array($models_raw_array)) && (count($models_raw_array) > 0)) {\"}}",
            "message_norm":"merge pull request #10498 from haxatron\/master\n\nfix access control",
            "language":"en",
            "entities":"[('#10498', 'ISSUE', ''), ('access control', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/BulkAssetModelsController.php'])",
            "num_files":1.0,
            "patch_content":"From bb095641c2f421f744796d184287c46fc9303591 Mon Sep 17 00:00:00 2001\nFrom: Haxatron <76475453+Haxatron@users.noreply.github.com>\nDate: Thu, 6 Jan 2022 09:50:11 +0800\nSubject: [PATCH] Update BulkAssetModelsController.php\n\nhttps:\/\/huntr.dev\/bounties\/efdf2ead-f9d1-4767-9f02-d11f762d15e7\n---\n app\/Http\/Controllers\/BulkAssetModelsController.php | 8 ++++++--\n 1 file changed, 6 insertions(+), 2 deletions(-)\n\ndiff --git a\/app\/Http\/Controllers\/BulkAssetModelsController.php b\/app\/Http\/Controllers\/BulkAssetModelsController.php\nindex 088e8da509ac..38dd65c76baf 100644\n--- a\/app\/Http\/Controllers\/BulkAssetModelsController.php\n+++ b\/app\/Http\/Controllers\/BulkAssetModelsController.php\n@@ -32,6 +32,7 @@ public function edit(Request $request)\n \n             \/\/ If deleting....\n             if ($request->input('bulk_actions')=='delete') {\n+                $this->authorize('delete', AssetModel::class);\n                 $valid_count = 0;\n                 foreach ($models as $model) {\n                     if ($model->assets_count == 0) {\n@@ -42,7 +43,7 @@ public function edit(Request $request)\n \n             \/\/ Otherwise display the bulk edit screen\n             }\n-\n+            $this->authorize('update', AssetModel::class);\n             $nochange = ['NC' => 'No Change'];\n             return view('models\/bulk-edit', compact('models'))\n                 ->with('fieldset_list', $nochange + Helper::customFieldsetList())\n@@ -63,7 +64,8 @@ public function edit(Request $request)\n      *\/\n     public function update(Request $request)\n     {\n-\n+        $this->authorize('update', AssetModel::class);\n+      \n         $models_raw_array = $request->input('ids');\n         $update_array = array();\n \n@@ -103,6 +105,8 @@ public function update(Request $request)\n      *\/\n     public function destroy(Request $request)\n     {\n+        $this->authorize('delete', AssetModel::class);\n+      \n         $models_raw_array = $request->input('ids');\n \n         if ((is_array($models_raw_array)) && (count($models_raw_array) > 0)) {"
        },
        {
            "index":12,
            "vuln_id":"GHSA-qgmg-gppg-76g5",
            "cwe_id":"{'CWE-1333'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/validatorjs\/validator.js\/commit\/496fc8b2a7f5997acaaec33cc44d0b8dba5fb5e1'}",
            "dataset":"osv",
            "summary":"Inefficient Regular Expression Complexity in validator.js validator.js prior to 13.7.0 is vulnerable to Inefficient Regular Expression Complexity",
            "published_date":"2021-11-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/validatorjs\/validator.js",
            "commit_href":"https:\/\/github.com\/validatorjs\/validator.js\/commit\/496fc8b2a7f5997acaaec33cc44d0b8dba5fb5e1",
            "commit_sha":"496fc8b2a7f5997acaaec33cc44d0b8dba5fb5e1",
            "patch":"SINGLE",
            "chain_ord":"['496fc8b2a7f5997acaaec33cc44d0b8dba5fb5e1']",
            "before_first_fix_commit":"{'45901ec4f1276d192da6d0eb10a60b64722356c1'}",
            "last_fix_commit":"496fc8b2a7f5997acaaec33cc44d0b8dba5fb5e1",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/01\/2021, 20:30:39",
            "message":"fix(rtrim): remove regex to prevent ReDOS attack (#1738)",
            "author":"Sarhan Aissi",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 3, 'total': 15}",
            "files":"{'src\/lib\/rtrim.js': {'additions': 12, 'deletions': 3, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/validatorjs\/validator.js\/raw\/496fc8b2a7f5997acaaec33cc44d0b8dba5fb5e1\/src%2Flib%2Frtrim.js', 'patch': \"@@ -2,7 +2,16 @@ import assertString from '.\/util\/assertString';\\n \\n export default function rtrim(str, chars) {\\n   assertString(str);\\n-  \/\/ https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/JavaScript\/Guide\/Regular_Expressions#Escaping\\n-  const pattern = chars ? new RegExp(`[${chars.replace(\/[.*+?^${}()|[\\\\]\\\\\\\\]\/g, '\\\\\\\\$&')}]+$`, 'g') : \/(\\\\s)+$\/g;\\n-  return str.replace(pattern, '');\\n+  if (chars) {\\n+    \/\/ https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/JavaScript\/Guide\/Regular_Expressions#Escaping\\n+    const pattern = new RegExp(`[${chars.replace(\/[.*+?^${}()|[\\\\]\\\\\\\\]\/g, '\\\\\\\\$&')}]+$`, 'g');\\n+    return str.replace(pattern, '');\\n+  }\\n+  \/\/ Use a faster and more safe than regex trim method https:\/\/blog.stevenlevithan.com\/archives\/faster-trim-javascript\\n+  let strIndex = str.length - 1;\\n+  while (\/\\\\s\/.test(str.charAt(strIndex))) {\\n+    strIndex -= 1;\\n+  }\\n+\\n+  return str.slice(0, strIndex + 1);\\n }\"}}",
            "message_norm":"fix(rtrim): remove regex to prevent redos attack (#1738)",
            "language":"en",
            "entities":"[('fix(rtrim', 'ACTION', ''), ('remove', 'ACTION', ''), ('prevent', 'ACTION', ''), ('redos', 'SECWORD', ''), ('attack', 'FLAW', ''), ('#1738', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/lib\/rtrim.js'])",
            "num_files":1.0,
            "patch_content":"From 496fc8b2a7f5997acaaec33cc44d0b8dba5fb5e1 Mon Sep 17 00:00:00 2001\nFrom: Sarhan Aissi <tux-tn@users.noreply.github.com>\nDate: Mon, 1 Nov 2021 21:30:39 +0100\nSubject: [PATCH] fix(rtrim): remove regex to prevent ReDOS attack (#1738)\n\n---\n src\/lib\/rtrim.js | 15 ++++++++++++---\n 1 file changed, 12 insertions(+), 3 deletions(-)\n\ndiff --git a\/src\/lib\/rtrim.js b\/src\/lib\/rtrim.js\nindex d10aaa9de..2d311574b 100644\n--- a\/src\/lib\/rtrim.js\n+++ b\/src\/lib\/rtrim.js\n@@ -2,7 +2,16 @@ import assertString from '.\/util\/assertString';\n \n export default function rtrim(str, chars) {\n   assertString(str);\n-  \/\/ https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/JavaScript\/Guide\/Regular_Expressions#Escaping\n-  const pattern = chars ? new RegExp(`[${chars.replace(\/[.*+?^${}()|[\\]\\\\]\/g, '\\\\$&')}]+$`, 'g') : \/(\\s)+$\/g;\n-  return str.replace(pattern, '');\n+  if (chars) {\n+    \/\/ https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/JavaScript\/Guide\/Regular_Expressions#Escaping\n+    const pattern = new RegExp(`[${chars.replace(\/[.*+?^${}()|[\\]\\\\]\/g, '\\\\$&')}]+$`, 'g');\n+    return str.replace(pattern, '');\n+  }\n+  \/\/ Use a faster and more safe than regex trim method https:\/\/blog.stevenlevithan.com\/archives\/faster-trim-javascript\n+  let strIndex = str.length - 1;\n+  while (\/\\s\/.test(str.charAt(strIndex))) {\n+    strIndex -= 1;\n+  }\n+\n+  return str.slice(0, strIndex + 1);\n }"
        },
        {
            "index":809,
            "vuln_id":"GHSA-pvrc-hg3f-58r6",
            "cwe_id":"{'CWE-787'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3f6fe4dfef6f57e768260b48166c27d148f3015f'}",
            "dataset":"osv",
            "summary":"Heap OOB access in `Dilation2DBackpropInput` ### Impact\nAn attacker can write outside the bounds of heap allocated arrays by passing invalid arguments to `tf.raw_ops.Dilation2DBackpropInput`:\n\n```python\nimport tensorflow as tf\n    \ninput_tensor = tf.constant([1.1] * 81, shape=[3, 3, 3, 3], dtype=tf.float32)\nfilter = tf.constant([], shape=[0, 0, 3], dtype=tf.float32)\nout_backprop = tf.constant([1.1] * 1062, shape=[3, 2, 59, 3], dtype=tf.float32)\n\ntf.raw_ops.Dilation2DBackpropInput(\n  input=input_tensor, filter=filter, out_backprop=out_backprop, \n  strides=[1, 40, 1, 1], rates=[1, 56, 56, 1], padding='VALID')\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/afd954e65f15aea4d438d0a219136fc4a63a573d\/tensorflow\/core\/kernels\/dilation_ops.cc#L321-L322) does not validate before writing to the output array.\n  \n```cc               \nin_backprop(b, h_in_max, w_in_max, d) += out_backprop(b, h_out, w_out, d);\n```                 \n    \nThe values for `h_out` and `w_out` are guaranteed to be in range for `out_backprop` (as they are loop indices bounded by the size of the array). However, there are no similar guarantees relating `h_in_max`\/`w_in_max` and `in_backprop`.\n\n### Patches\nWe have patched the issue in GitHub commit [3f6fe4dfef6f57e768260b48166c27d148f3015f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3f6fe4dfef6f57e768260b48166c27d148f3015f).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3f6fe4dfef6f57e768260b48166c27d148f3015f",
            "commit_sha":"3f6fe4dfef6f57e768260b48166c27d148f3015f",
            "patch":"SINGLE",
            "chain_ord":"['3f6fe4dfef6f57e768260b48166c27d148f3015f']",
            "before_first_fix_commit":"{'afd954e65f15aea4d438d0a219136fc4a63a573d'}",
            "last_fix_commit":"3f6fe4dfef6f57e768260b48166c27d148f3015f",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 01:33:28",
            "message":"Add missing validations in dillation ops.\n\nPiperOrigin-RevId: 372037158\nChange-Id: I4ee304c84a02550c030288a6534000b934fc1599",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 4, 'total': 15}",
            "files":"{'tensorflow\/core\/kernels\/dilation_ops.cc': {'additions': 11, 'deletions': 4, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/3f6fe4dfef6f57e768260b48166c27d148f3015f\/tensorflow%2Fcore%2Fkernels%2Fdilation_ops.cc', 'patch': '@@ -130,6 +130,7 @@ class DilationOp : public OpKernel {\\n     ParseSizes(context, strides_, rates_, padding_, &stride_rows, &stride_cols,\\n                &rate_rows, &rate_cols, &pad_top, &pad_left, &out_rows,\\n                &out_cols);\\n+    if (!context->status().ok()) return;\\n \\n     \/\/ Output tensor is of the following dimensions:\\n     \/\/ [ batch, out_rows, out_cols, depth ]\\n@@ -229,6 +230,7 @@ class DilationBackpropInputOp : public OpKernel {\\n     ParseSizes(context, strides_, rates_, padding_, &stride_rows, &stride_cols,\\n                &rate_rows, &rate_cols, &pad_top, &pad_left, &out_rows,\\n                &out_cols);\\n+    if (!context->status().ok()) return;\\n \\n     \/\/ Verify that the incoming gradient tensor has the expected size\\n     \/\/ [ batch, out_rows, out_cols, depth ]\\n@@ -318,8 +320,10 @@ struct DilationBackpropInput<CPUDevice, T> {\\n                 }\\n               }\\n             }\\n-            in_backprop(b, h_in_max, w_in_max, d) +=\\n-                out_backprop(b, h_out, w_out, d);\\n+            if (h_in_max < input_rows && w_in_max < input_cols) {\\n+              in_backprop(b, h_in_max, w_in_max, d) +=\\n+                  out_backprop(b, h_out, w_out, d);\\n+            }\\n           }\\n         }\\n       }\\n@@ -349,6 +353,7 @@ class DilationBackpropFilterOp : public OpKernel {\\n     ParseSizes(context, strides_, rates_, padding_, &stride_rows, &stride_cols,\\n                &rate_rows, &rate_cols, &pad_top, &pad_left, &out_rows,\\n                &out_cols);\\n+    if (!context->status().ok()) return;\\n \\n     \/\/ Verify that the incoming gradient tensor has the expected size\\n     \/\/ [ batch, out_rows, out_cols, depth ]\\n@@ -438,8 +443,10 @@ struct DilationBackpropFilter<CPUDevice, T> {\\n                 }\\n               }\\n             }\\n-            filter_backprop(h_max, w_max, d) +=\\n-                out_backprop(b, h_out, w_out, d);\\n+            if (h_max < filter_rows && w_max < filter_cols) {\\n+              filter_backprop(h_max, w_max, d) +=\\n+                  out_backprop(b, h_out, w_out, d);\\n+            }\\n           }\\n         }\\n       }'}}",
            "message_norm":"add missing validations in dillation ops.\n\npiperorigin-revid: 372037158\nchange-id: i4ee304c84a02550c030288a6534000b934fc1599",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validations', 'SECWORD', ''), ('372037158', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/dilation_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 3f6fe4dfef6f57e768260b48166c27d148f3015f Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 4 May 2021 18:33:28 -0700\nSubject: [PATCH] Add missing validations in dillation ops.\n\nPiperOrigin-RevId: 372037158\nChange-Id: I4ee304c84a02550c030288a6534000b934fc1599\n---\n tensorflow\/core\/kernels\/dilation_ops.cc | 15 +++++++++++----\n 1 file changed, 11 insertions(+), 4 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/dilation_ops.cc b\/tensorflow\/core\/kernels\/dilation_ops.cc\nindex 738ea31d555d5f..996ddb62bfefeb 100644\n--- a\/tensorflow\/core\/kernels\/dilation_ops.cc\n+++ b\/tensorflow\/core\/kernels\/dilation_ops.cc\n@@ -130,6 +130,7 @@ class DilationOp : public OpKernel {\n     ParseSizes(context, strides_, rates_, padding_, &stride_rows, &stride_cols,\n                &rate_rows, &rate_cols, &pad_top, &pad_left, &out_rows,\n                &out_cols);\n+    if (!context->status().ok()) return;\n \n     \/\/ Output tensor is of the following dimensions:\n     \/\/ [ batch, out_rows, out_cols, depth ]\n@@ -229,6 +230,7 @@ class DilationBackpropInputOp : public OpKernel {\n     ParseSizes(context, strides_, rates_, padding_, &stride_rows, &stride_cols,\n                &rate_rows, &rate_cols, &pad_top, &pad_left, &out_rows,\n                &out_cols);\n+    if (!context->status().ok()) return;\n \n     \/\/ Verify that the incoming gradient tensor has the expected size\n     \/\/ [ batch, out_rows, out_cols, depth ]\n@@ -318,8 +320,10 @@ struct DilationBackpropInput<CPUDevice, T> {\n                 }\n               }\n             }\n-            in_backprop(b, h_in_max, w_in_max, d) +=\n-                out_backprop(b, h_out, w_out, d);\n+            if (h_in_max < input_rows && w_in_max < input_cols) {\n+              in_backprop(b, h_in_max, w_in_max, d) +=\n+                  out_backprop(b, h_out, w_out, d);\n+            }\n           }\n         }\n       }\n@@ -349,6 +353,7 @@ class DilationBackpropFilterOp : public OpKernel {\n     ParseSizes(context, strides_, rates_, padding_, &stride_rows, &stride_cols,\n                &rate_rows, &rate_cols, &pad_top, &pad_left, &out_rows,\n                &out_cols);\n+    if (!context->status().ok()) return;\n \n     \/\/ Verify that the incoming gradient tensor has the expected size\n     \/\/ [ batch, out_rows, out_cols, depth ]\n@@ -438,8 +443,10 @@ struct DilationBackpropFilter<CPUDevice, T> {\n                 }\n               }\n             }\n-            filter_backprop(h_max, w_max, d) +=\n-                out_backprop(b, h_out, w_out, d);\n+            if (h_max < filter_rows && w_max < filter_cols) {\n+              filter_backprop(h_max, w_max, d) +=\n+                  out_backprop(b, h_out, w_out, d);\n+            }\n           }\n         }\n       }"
        },
        {
            "index":298,
            "vuln_id":"GHSA-8278-88vv-x98r",
            "cwe_id":"{'CWE-502'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/tenable\/integration-jira-cloud\/commit\/f8c2095fd529e664e7fa25403a0a4a85bb3907d0'}",
            "dataset":"osv",
            "summary":"Execution of untrusted code through config file ### Impact\nIt is possible to run arbitrary commands through the yaml.load() method.  This could allow an attacker with local access to the host to run arbitrary code by running the application with a specially crafted YAML configuration file.\n\n### Workarounds\nManually adjust yaml.load() to yaml.safe_load()\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [tenable\/integration-jira-cloud](https:\/\/github.com\/tenable\/integration-jira-cloud\/issues)\n* Email us at [vulnreport@tenable.com](mailto:vulnreport@tenable.com)",
            "published_date":"2021-03-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tenable\/integration-jira-cloud",
            "commit_href":"https:\/\/github.com\/tenable\/integration-jira-cloud\/commit\/f8c2095fd529e664e7fa25403a0a4a85bb3907d0",
            "commit_sha":"f8c2095fd529e664e7fa25403a0a4a85bb3907d0",
            "patch":"SINGLE",
            "chain_ord":"['f8c2095fd529e664e7fa25403a0a4a85bb3907d0']",
            "before_first_fix_commit":"{'fa838db45f1ae5581a47e1965f74919c12488cf5'}",
            "last_fix_commit":"f8c2095fd529e664e7fa25403a0a4a85bb3907d0",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/04\/2021, 14:58:38",
            "message":"switched yaml.load() to yaml.safe_load() to not load serialized python objects.",
            "author":"Steve McGrath",
            "comments":"{'com_1': {'author': 'rabby28698869', 'datetime': '03\/11\/2021, 03:07:50', 'body': 'f8c2095'}, 'com_2': {'author': 'SteveMcGrath', 'datetime': '03\/11\/2021, 15:23:59', 'body': '?'}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'tenable_jira\/cli.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tenable\/integration-jira-cloud\/raw\/f8c2095fd529e664e7fa25403a0a4a85bb3907d0\/tenable_jira%2Fcli.py', 'patch': \"@@ -62,7 +62,7 @@ def cli(configfile, observed_since, setup_only=False, troubleshoot=False):\\n     '''\\n     # Load the config, but ensure that any additional fields are additive to the\\n     # basic field set.\\n-    config_from_file = yaml.load(configfile, Loader=yaml.Loader)\\n+    config_from_file = yaml.safe_load(configfile)\\n     fields = config_from_file.pop('custom_fields', list())\\n     config = dict_merge(base_config(), config_from_file)\\n     config['fields'] = config['fields'] + fields\"}}",
            "message_norm":"switched yaml.load() to yaml.safe_load() to not load serialized python objects.",
            "language":"en",
            "entities":"[('serialized', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tenable_jira\/cli.py'])",
            "num_files":1.0,
            "patch_content":"From f8c2095fd529e664e7fa25403a0a4a85bb3907d0 Mon Sep 17 00:00:00 2001\nFrom: Steve McGrath <smcgrath@tenable.com>\nDate: Thu, 4 Mar 2021 08:58:38 -0600\nSubject: [PATCH] switched yaml.load() to yaml.safe_load() to not load\n serialized python objects.\n\n---\n tenable_jira\/cli.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/tenable_jira\/cli.py b\/tenable_jira\/cli.py\nindex 17bb76b..1f16571 100644\n--- a\/tenable_jira\/cli.py\n+++ b\/tenable_jira\/cli.py\n@@ -62,7 +62,7 @@ def cli(configfile, observed_since, setup_only=False, troubleshoot=False):\n     '''\n     # Load the config, but ensure that any additional fields are additive to the\n     # basic field set.\n-    config_from_file = yaml.load(configfile, Loader=yaml.Loader)\n+    config_from_file = yaml.safe_load(configfile)\n     fields = config_from_file.pop('custom_fields', list())\n     config = dict_merge(base_config(), config_from_file)\n     config['fields'] = config['fields'] + fields"
        },
        {
            "index":297,
            "vuln_id":"GHSA-5r2v-6gm6-vpvh",
            "cwe_id":"{'CWE-200'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/gogs\/gogs\/commit\/c3af3ff1d0484de3bd789ee6c6e47f35d590e945'}",
            "dataset":"osv",
            "summary":"Insecure Permissions in Gogs routes\/api\/v1\/api.go in Gogs 0.11.86 lacks permission checks for routes: deploy keys, collaborators, and hooks.",
            "published_date":"2021-05-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/gogs\/gogs",
            "commit_href":"https:\/\/github.com\/gogs\/gogs\/commit\/c3af3ff1d0484de3bd789ee6c6e47f35d590e945",
            "commit_sha":"c3af3ff1d0484de3bd789ee6c6e47f35d590e945",
            "patch":"SINGLE",
            "chain_ord":"['c3af3ff1d0484de3bd789ee6c6e47f35d590e945']",
            "before_first_fix_commit":"{'1592e578ed3ac7190baed6165b093002b931520c'}",
            "last_fix_commit":"c3af3ff1d0484de3bd789ee6c6e47f35d590e945",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2019, 01:36:05",
            "message":"routes\/api: fix permission checks for routes\n\nReported by @ManassehZhou #5764",
            "author":"unknwon",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 5, 'total': 19}",
            "files":"{'routes\/api\/v1\/api.go': {'additions': 14, 'deletions': 5, 'changes': 19, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/gogs\/gogs\/raw\/c3af3ff1d0484de3bd789ee6c6e47f35d590e945\/routes%2Fapi%2Fv1%2Fapi.go', 'patch': '@@ -112,6 +112,15 @@ func reqRepoWriter() macaron.Handler {\\n \\t}\\n }\\n \\n+func reqRepoAdmin() macaron.Handler {\\n+\\treturn func(c *context.Context) {\\n+\\t\\tif !c.Repo.IsAdmin() {\\n+\\t\\t\\tc.Error(http.StatusForbidden)\\n+\\t\\t\\treturn\\n+\\t\\t}\\n+\\t}\\n+}\\n+\\n func orgAssignment(args ...bool) macaron.Handler {\\n \\tvar (\\n \\t\\tassignOrg  bool\\n@@ -236,12 +245,12 @@ func RegisterRoutes(m *macaron.Macaron) {\\n \\t\\t\\t\\t\\t\\tPost(bind(api.CreateHookOption{}), repo.CreateHook)\\n \\t\\t\\t\\t\\tm.Combo(\"\/:id\").Patch(bind(api.EditHookOption{}), repo.EditHook).\\n \\t\\t\\t\\t\\t\\tDelete(repo.DeleteHook)\\n-\\t\\t\\t\\t}, reqAdmin())\\n+\\t\\t\\t\\t}, reqRepoAdmin())\\n \\t\\t\\t\\tm.Group(\"\/collaborators\", func() {\\n \\t\\t\\t\\t\\tm.Get(\"\", repo.ListCollaborators)\\n \\t\\t\\t\\t\\tm.Combo(\"\/:collaborator\").Get(repo.IsCollaborator).Put(bind(api.AddCollaboratorOption{}), repo.AddCollaborator).\\n \\t\\t\\t\\t\\t\\tDelete(repo.DeleteCollaborator)\\n-\\t\\t\\t\\t}, reqAdmin())\\n+\\t\\t\\t\\t}, reqRepoAdmin())\\n \\t\\t\\t\\tm.Get(\"\/raw\/*\", context.RepoRef(), repo.GetRawFile)\\n \\t\\t\\t\\tm.Get(\"\/archive\/*\", repo.GetArchive)\\n \\t\\t\\t\\tm.Get(\"\/forks\", repo.ListForks)\\n@@ -260,7 +269,7 @@ func RegisterRoutes(m *macaron.Macaron) {\\n \\t\\t\\t\\t\\t\\tPost(bind(api.CreateKeyOption{}), repo.CreateDeployKey)\\n \\t\\t\\t\\t\\tm.Combo(\"\/:id\").Get(repo.GetDeployKey).\\n \\t\\t\\t\\t\\t\\tDelete(repo.DeleteDeploykey)\\n-\\t\\t\\t\\t}, reqAdmin())\\n+\\t\\t\\t\\t}, reqRepoAdmin())\\n \\t\\t\\t\\tm.Group(\"\/issues\", func() {\\n \\t\\t\\t\\t\\tm.Combo(\"\").Get(repo.ListIssues).Post(bind(api.CreateIssueOption{}), repo.CreateIssue)\\n \\t\\t\\t\\t\\tm.Group(\"\/comments\", func() {\\n@@ -300,8 +309,8 @@ func RegisterRoutes(m *macaron.Macaron) {\\n \\t\\t\\t\\t\\t\\tDelete(reqRepoWriter(), repo.DeleteMilestone)\\n \\t\\t\\t\\t})\\n \\n-\\t\\t\\t\\tm.Patch(\"\/issue-tracker\", bind(api.EditIssueTrackerOption{}), repo.IssueTracker)\\n-\\t\\t\\t\\tm.Post(\"\/mirror-sync\", repo.MirrorSync)\\n+\\t\\t\\t\\tm.Patch(\"\/issue-tracker\", reqRepoWriter(), bind(api.EditIssueTrackerOption{}), repo.IssueTracker)\\n+\\t\\t\\t\\tm.Post(\"\/mirror-sync\", reqRepoWriter(), repo.MirrorSync)\\n \\t\\t\\t\\tm.Get(\"\/editorconfig\/:filename\", context.RepoRef(), repo.GetEditorconfig)\\n \\t\\t\\t}, repoAssignment())\\n \\t\\t}, reqToken())'}}",
            "message_norm":"routes\/api: fix permission checks for routes\n\nreported by @manassehzhou #5764",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('permission', 'SECWORD', ''), ('#5764', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['routes\/api\/v1\/api.go'])",
            "num_files":1.0,
            "patch_content":"From c3af3ff1d0484de3bd789ee6c6e47f35d590e945 Mon Sep 17 00:00:00 2001\nFrom: unknwon <u@gogs.io>\nDate: Thu, 1 Aug 2019 18:36:05 -0700\nSubject: [PATCH] routes\/api: fix permission checks for routes\n\nReported by @ManassehZhou #5764\n---\n routes\/api\/v1\/api.go | 19 ++++++++++++++-----\n 1 file changed, 14 insertions(+), 5 deletions(-)\n\ndiff --git a\/routes\/api\/v1\/api.go b\/routes\/api\/v1\/api.go\nindex 54f7e7efe7b..7b58b4eb14b 100644\n--- a\/routes\/api\/v1\/api.go\n+++ b\/routes\/api\/v1\/api.go\n@@ -112,6 +112,15 @@ func reqRepoWriter() macaron.Handler {\n \t}\n }\n \n+func reqRepoAdmin() macaron.Handler {\n+\treturn func(c *context.Context) {\n+\t\tif !c.Repo.IsAdmin() {\n+\t\t\tc.Error(http.StatusForbidden)\n+\t\t\treturn\n+\t\t}\n+\t}\n+}\n+\n func orgAssignment(args ...bool) macaron.Handler {\n \tvar (\n \t\tassignOrg  bool\n@@ -236,12 +245,12 @@ func RegisterRoutes(m *macaron.Macaron) {\n \t\t\t\t\t\tPost(bind(api.CreateHookOption{}), repo.CreateHook)\n \t\t\t\t\tm.Combo(\"\/:id\").Patch(bind(api.EditHookOption{}), repo.EditHook).\n \t\t\t\t\t\tDelete(repo.DeleteHook)\n-\t\t\t\t}, reqAdmin())\n+\t\t\t\t}, reqRepoAdmin())\n \t\t\t\tm.Group(\"\/collaborators\", func() {\n \t\t\t\t\tm.Get(\"\", repo.ListCollaborators)\n \t\t\t\t\tm.Combo(\"\/:collaborator\").Get(repo.IsCollaborator).Put(bind(api.AddCollaboratorOption{}), repo.AddCollaborator).\n \t\t\t\t\t\tDelete(repo.DeleteCollaborator)\n-\t\t\t\t}, reqAdmin())\n+\t\t\t\t}, reqRepoAdmin())\n \t\t\t\tm.Get(\"\/raw\/*\", context.RepoRef(), repo.GetRawFile)\n \t\t\t\tm.Get(\"\/archive\/*\", repo.GetArchive)\n \t\t\t\tm.Get(\"\/forks\", repo.ListForks)\n@@ -260,7 +269,7 @@ func RegisterRoutes(m *macaron.Macaron) {\n \t\t\t\t\t\tPost(bind(api.CreateKeyOption{}), repo.CreateDeployKey)\n \t\t\t\t\tm.Combo(\"\/:id\").Get(repo.GetDeployKey).\n \t\t\t\t\t\tDelete(repo.DeleteDeploykey)\n-\t\t\t\t}, reqAdmin())\n+\t\t\t\t}, reqRepoAdmin())\n \t\t\t\tm.Group(\"\/issues\", func() {\n \t\t\t\t\tm.Combo(\"\").Get(repo.ListIssues).Post(bind(api.CreateIssueOption{}), repo.CreateIssue)\n \t\t\t\t\tm.Group(\"\/comments\", func() {\n@@ -300,8 +309,8 @@ func RegisterRoutes(m *macaron.Macaron) {\n \t\t\t\t\t\tDelete(reqRepoWriter(), repo.DeleteMilestone)\n \t\t\t\t})\n \n-\t\t\t\tm.Patch(\"\/issue-tracker\", bind(api.EditIssueTrackerOption{}), repo.IssueTracker)\n-\t\t\t\tm.Post(\"\/mirror-sync\", repo.MirrorSync)\n+\t\t\t\tm.Patch(\"\/issue-tracker\", reqRepoWriter(), bind(api.EditIssueTrackerOption{}), repo.IssueTracker)\n+\t\t\t\tm.Post(\"\/mirror-sync\", reqRepoWriter(), repo.MirrorSync)\n \t\t\t\tm.Get(\"\/editorconfig\/:filename\", context.RepoRef(), repo.GetEditorconfig)\n \t\t\t}, repoAssignment())\n \t\t}, reqToken())"
        },
        {
            "index":86,
            "vuln_id":"GHSA-874w-m2v2-mj64",
            "cwe_id":"{'CWE-415'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/adplug\/adplug\/commit\/1a282a486a8e33fef3e15998bf6408d3515dc07e', 'https:\/\/github.com\/miller-alex\/adplug\/commit\/8abb9328bf27dcbdafc67ade3e75af0ffd8f7633'}",
            "dataset":"osv",
            "summary":"Double Free in Adplug AdPlug 2.3.1 has a double free in the Cu6mPlayer class in u6m.h.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/adplug\/adplug",
            "commit_href":"https:\/\/github.com\/adplug\/adplug\/commit\/1a282a486a8e33fef3e15998bf6408d3515dc07e",
            "commit_sha":"1a282a486a8e33fef3e15998bf6408d3515dc07e",
            "patch":"MULTI",
            "chain_ord":"['8abb9328bf27dcbdafc67ade3e75af0ffd8f7633', '1a282a486a8e33fef3e15998bf6408d3515dc07e']",
            "before_first_fix_commit":"{'a8903d884e2c900e77af5c70ef440e72626646ad'}",
            "last_fix_commit":"1a282a486a8e33fef3e15998bf6408d3515dc07e",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/11\/2020, 11:48:45",
            "message":"Update NEWS with a list of CVEs now fixed",
            "author":"Adam Nielsen",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 0, 'total': 10}",
            "files":"{'NEWS': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/adplug\/adplug\/raw\/1a282a486a8e33fef3e15998bf6408d3515dc07e\/NEWS', 'patch': '@@ -2,6 +2,16 @@ This is a brief overview of user-visible changes in AdPlug.\\n \\n Changes for version 2.3.3:\\n --------------------------\\n+- Bug fixes: (huge thanks to Alexander Miller for these)\\n+  - CVE-2019-14690 - buffer overflow in .bmf\\n+  - CVE-2019-14691 - buffer overflow in .dtm\\n+  - CVE-2019-14692 - buffer overflow in .mkj\\n+  - CVE-2019-14732 - buffer overflow in .a2m\\n+  - CVE-2019-14733 - buffer overflow in .rad\\n+  - CVE-2019-14734 - buffer overflow in .mtk\\n+  - CVE-2019-15151 - double free and OOB reads in .u6m\\n+  - OOB reads in .xad\\n+  - OOB reads in .rix\\n \\n Changes for version 2.3.2:\\n --------------------------'}}",
            "message_norm":"update news with a list of cves now fixed",
            "language":"en",
            "entities":"[('update', 'ACTION', ''), ('fixed', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['NEWS'])",
            "num_files":1.0,
            "patch_content":"From 1a282a486a8e33fef3e15998bf6408d3515dc07e Mon Sep 17 00:00:00 2001\nFrom: Adam Nielsen <malvineous@shikadi.net>\nDate: Mon, 11 May 2020 21:48:45 +1000\nSubject: [PATCH] Update NEWS with a list of CVEs now fixed\n\n---\n NEWS | 10 ++++++++++\n 1 file changed, 10 insertions(+)\n\ndiff --git a\/NEWS b\/NEWS\nindex 52d4fc40..130146b5 100644\n--- a\/NEWS\n+++ b\/NEWS\n@@ -2,6 +2,16 @@ This is a brief overview of user-visible changes in AdPlug.\n \n Changes for version 2.3.3:\n --------------------------\n+- Bug fixes: (huge thanks to Alexander Miller for these)\n+  - CVE-2019-14690 - buffer overflow in .bmf\n+  - CVE-2019-14691 - buffer overflow in .dtm\n+  - CVE-2019-14692 - buffer overflow in .mkj\n+  - CVE-2019-14732 - buffer overflow in .a2m\n+  - CVE-2019-14733 - buffer overflow in .rad\n+  - CVE-2019-14734 - buffer overflow in .mtk\n+  - CVE-2019-15151 - double free and OOB reads in .u6m\n+  - OOB reads in .xad\n+  - OOB reads in .rix\n \n Changes for version 2.3.2:\n --------------------------"
        },
        {
            "index":277,
            "vuln_id":"GHSA-v768-w7m9-2vmm",
            "cwe_id":"{'CWE-824'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/578e634b4f1c1c684d4b4294f9e5281b2133b3ed'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in shape inference ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.SparseFillEmptyRows`:\n\n```python\nimport tensorflow as tf\n  \ntf.compat.v1.disable_v2_behavior()\ntf.raw_ops.SparseFillEmptyRows(\n  indices = tf.constant([], shape=[0, 0], dtype=tf.int64),\n  values = tf.constant([], shape=[0], dtype=tf.int64),\n  dense_shape = tf.constant([], shape=[0], dtype=tf.int64),\n  default_value = 0)\n```\n  \nThe shape inference [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/ops\/sparse_ops.cc#L608-L634) does not validate that the input arguments are not empty tensors.\n\n### Patches \nWe have patched the issue in GitHub commit [578e634b4f1c1c684d4b4294f9e5281b2133b3ed](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/578e634b4f1c1c684d4b4294f9e5281b2133b3ed).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/578e634b4f1c1c684d4b4294f9e5281b2133b3ed",
            "commit_sha":"578e634b4f1c1c684d4b4294f9e5281b2133b3ed",
            "patch":"SINGLE",
            "chain_ord":"['578e634b4f1c1c684d4b4294f9e5281b2133b3ed']",
            "before_first_fix_commit":"{'d7de67733925de196ec8863a33445b73f9562d1d'}",
            "last_fix_commit":"578e634b4f1c1c684d4b4294f9e5281b2133b3ed",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/30\/2021, 05:24:08",
            "message":"Prevent a segfault in shape inference due to bad inputs.\n\nPiperOrigin-RevId: 387737970\nChange-Id: Ibd1cf3dbdce1dd2ab47fd633d5c5a57f7d8fb6e9",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/ops\/sparse_ops.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/578e634b4f1c1c684d4b4294f9e5281b2133b3ed\/tensorflow%2Fcore%2Fops%2Fsparse_ops.cc', 'patch': '@@ -16,6 +16,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/common_shape_fns.h\"\\n #include \"tensorflow\/core\/framework\/op.h\"\\n #include \"tensorflow\/core\/framework\/shape_inference.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n \\n namespace tensorflow {\\n \\n@@ -619,6 +620,8 @@ REGISTER_OP(\"SparseFillEmptyRows\")\\n       DimensionHandle unused_dim;\\n       TF_RETURN_IF_ERROR(c->Merge(c->Dim(input_indices, 1),\\n                                   c->Dim(input_shape, 0), &unused_dim));\\n+      if (c->Value(c->NumElements(input_shape)) == 0)\\n+        return errors::InvalidArgument(\"dense_shape must not be empty\");\\n       ShapeHandle output_indices =\\n           c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\\n       ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);'}}",
            "message_norm":"prevent a segfault in shape inference due to bad inputs.\n\npiperorigin-revid: 387737970\nchange-id: ibd1cf3dbdce1dd2ab47fd633d5c5a57f7d8fb6e9",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('segfault', 'SECWORD', ''), ('387737970', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/ops\/sparse_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 578e634b4f1c1c684d4b4294f9e5281b2133b3ed Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 22:24:08 -0700\nSubject: [PATCH] Prevent a segfault in shape inference due to bad inputs.\n\nPiperOrigin-RevId: 387737970\nChange-Id: Ibd1cf3dbdce1dd2ab47fd633d5c5a57f7d8fb6e9\n---\n tensorflow\/core\/ops\/sparse_ops.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/core\/ops\/sparse_ops.cc b\/tensorflow\/core\/ops\/sparse_ops.cc\nindex 906cef1f5ecafe..b1e40e66af8929 100644\n--- a\/tensorflow\/core\/ops\/sparse_ops.cc\n+++ b\/tensorflow\/core\/ops\/sparse_ops.cc\n@@ -16,6 +16,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/common_shape_fns.h\"\n #include \"tensorflow\/core\/framework\/op.h\"\n #include \"tensorflow\/core\/framework\/shape_inference.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n \n namespace tensorflow {\n \n@@ -619,6 +620,8 @@ REGISTER_OP(\"SparseFillEmptyRows\")\n       DimensionHandle unused_dim;\n       TF_RETURN_IF_ERROR(c->Merge(c->Dim(input_indices, 1),\n                                   c->Dim(input_shape, 0), &unused_dim));\n+      if (c->Value(c->NumElements(input_shape)) == 0)\n+        return errors::InvalidArgument(\"dense_shape must not be empty\");\n       ShapeHandle output_indices =\n           c->Matrix(InferenceContext::kUnknownDim, c->NumElements(input_shape));\n       ShapeHandle output_values = c->Vector(InferenceContext::kUnknownDim);"
        },
        {
            "index":415,
            "vuln_id":"GHSA-465w-gg5p-85c9",
            "cwe_id":"{'CWE-613', 'CWE-384', 'CWE-295'}",
            "score":8.6,
            "chain":"{'https:\/\/github.com\/kiali\/kiali\/commit\/93f5cd0b6698e8fe8772afb8f35816f6c086aef1', 'https:\/\/github.com\/kiali\/kiali\/commit\/c91a0949683976f621cca213c1193831d63b381c'}",
            "dataset":"osv",
            "summary":"Insufficient Session Expiration in Kiali An insufficient JWT validation vulnerability was found in Kiali versions 0.4.0 to 1.15.0 and was fixed in Kiali version 1.15.1, wherein a remote attacker could abuse this flaw by stealing a valid JWT cookie and using that to spoof a user session, possibly gaining privileges to view and alter the Istio configuration.",
            "published_date":"2021-05-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/kiali\/kiali",
            "commit_href":"https:\/\/github.com\/kiali\/kiali\/commit\/c91a0949683976f621cca213c1193831d63b381c",
            "commit_sha":"c91a0949683976f621cca213c1193831d63b381c",
            "patch":"MULTI",
            "chain_ord":"['c91a0949683976f621cca213c1193831d63b381c', '93f5cd0b6698e8fe8772afb8f35816f6c086aef1']",
            "before_first_fix_commit":"{'a660a80b2add1fd2fcfb5662c63824ca1dff95b9'}",
            "last_fix_commit":"93f5cd0b6698e8fe8772afb8f35816f6c086aef1",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/17\/2020, 18:05:17",
            "message":"Fix security issues around 'token' strategy\n\n* Require presence of sid claim",
            "author":"Edgar Hern\u00e1ndez",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'handlers\/authentication.go': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/kiali\/kiali\/raw\/c91a0949683976f621cca213c1193831d63b381c\/handlers%2Fauthentication.go', 'patch': '@@ -425,6 +425,12 @@ func checkTokenSession(w http.ResponseWriter, r *http.Request) (int, string) {\\n \\tif claims, err := config.GetTokenClaimsIfValid(tokenString); err != nil {\\n \\t\\tlog.Warningf(\"Token is invalid: %s\", err.Error())\\n \\t} else {\\n+\\t\\t\/\/ Session ID claim must be present\\n+\\t\\tif len(claims.SessionId) == 0 {\\n+\\t\\t\\tlog.Warning(\"Token is invalid: sid claim is required\")\\n+\\t\\t\\treturn http.StatusUnauthorized, \"\"\\n+\\t\\t}\\n+\\n \\t\\tbusiness, err := business.Get(claims.SessionId)\\n \\t\\tif err != nil {\\n \\t\\t\\tlog.Warning(\"Could not get the business layer : \", err)'}}",
            "message_norm":"fix security issues around 'token' strategy\n\n* require presence of sid claim",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issues', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['handlers\/authentication.go'])",
            "num_files":1.0,
            "patch_content":"From c91a0949683976f621cca213c1193831d63b381c Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Edgar=20Hern=C3=A1ndez?= <ehernand@redhat.com>\nDate: Tue, 17 Mar 2020 12:05:17 -0600\nSubject: [PATCH] Fix security issues around 'token' strategy\n\n* Require presence of sid claim\n---\n handlers\/authentication.go | 6 ++++++\n 1 file changed, 6 insertions(+)\n\ndiff --git a\/handlers\/authentication.go b\/handlers\/authentication.go\nindex 12bcf36835..f2d1ee490c 100644\n--- a\/handlers\/authentication.go\n+++ b\/handlers\/authentication.go\n@@ -425,6 +425,12 @@ func checkTokenSession(w http.ResponseWriter, r *http.Request) (int, string) {\n \tif claims, err := config.GetTokenClaimsIfValid(tokenString); err != nil {\n \t\tlog.Warningf(\"Token is invalid: %s\", err.Error())\n \t} else {\n+\t\t\/\/ Session ID claim must be present\n+\t\tif len(claims.SessionId) == 0 {\n+\t\t\tlog.Warning(\"Token is invalid: sid claim is required\")\n+\t\t\treturn http.StatusUnauthorized, \"\"\n+\t\t}\n+\n \t\tbusiness, err := business.Get(claims.SessionId)\n \t\tif err != nil {\n \t\t\tlog.Warning(\"Could not get the business layer : \", err)"
        },
        {
            "index":870,
            "vuln_id":"GHSA-hwj3-m3p6-hj38",
            "cwe_id":"{'CWE-611'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/dom4j\/dom4j\/commit\/1707bf3d898a8ada3b213acb0e3b38f16eaae73d', 'https:\/\/github.com\/dom4j\/dom4j\/commit\/a8228522a99a02146106672a34c104adbda5c658'}",
            "dataset":"osv",
            "summary":"dom4j allows External Entities by default which might enable XXE attacks dom4j before 2.1.3 allows external DTDs and External Entities by default, which might enable XXE attacks. However, there is popular external documentation from OWASP showing how to enable the safe, non-default behavior in any application that uses dom4j.\n\nNote: This advisory applies to `dom4j:dom4j` version 1.x legacy artifacts.  To resolve this a change to the latest version of `org.dom4j:dom4j` is recommended.",
            "published_date":"2020-06-05",
            "chain_len":2,
            "project":"https:\/\/github.com\/dom4j\/dom4j",
            "commit_href":"https:\/\/github.com\/dom4j\/dom4j\/commit\/1707bf3d898a8ada3b213acb0e3b38f16eaae73d",
            "commit_sha":"1707bf3d898a8ada3b213acb0e3b38f16eaae73d",
            "patch":"MULTI",
            "chain_ord":"['a8228522a99a02146106672a34c104adbda5c658', '1707bf3d898a8ada3b213acb0e3b38f16eaae73d']",
            "before_first_fix_commit":"{'223ae0639d5d73a5a25fddec8b16c7071ee10e3d'}",
            "last_fix_commit":"1707bf3d898a8ada3b213acb0e3b38f16eaae73d",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/11\/2020, 17:27:36",
            "message":"#28 Disable downloading external resources with DocumentHelper.parseText() helper.\n\n(cherry picked from commit 8f6a7f6001d679176c1079ac65871d4e493360db)",
            "author":"Filip Jirs\u00e1k",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'src\/main\/java\/org\/dom4j\/DocumentHelper.java': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/dom4j\/dom4j\/raw\/1707bf3d898a8ada3b213acb0e3b38f16eaae73d\/src%2Fmain%2Fjava%2Forg%2Fdom4j%2FDocumentHelper.java', 'patch': '@@ -270,6 +270,14 @@ public static void sort(List<Node> list, String expression, boolean distinct) {\\n      *\/\\n     public static Document parseText(String text) throws DocumentException {\\n         SAXReader reader = new SAXReader();\\n+        try {\\n+            reader.setFeature(\"http:\/\/apache.org\/xml\/features\/nonvalidating\/load-external-dtd\", false);\\n+            reader.setFeature(\"http:\/\/xml.org\/sax\/features\/external-general-entities\", false);\\n+            reader.setFeature(\"http:\/\/xml.org\/sax\/features\/external-parameter-entities\", false);\\n+        } catch (SAXException e) {\\n+            \/\/Parse with external resources downloading allowed.\\n+        }\\n+\\n         String encoding = getEncoding(text);\\n \\n         InputSource source = new InputSource(new StringReader(text));'}}",
            "message_norm":"#28 disable downloading external resources with documenthelper.parsetext() helper.\n\n(cherry picked from commit 8f6a7f6001d679176c1079ac65871d4e493360db)",
            "language":"en",
            "entities":"[('#28', 'ISSUE', ''), ('commit 8f6a7f6001d679176c1079ac65871d4e493360db', 'SHA', 'prefix_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/org\/dom4j\/DocumentHelper.java'])",
            "num_files":1.0,
            "patch_content":"From 1707bf3d898a8ada3b213acb0e3b38f16eaae73d Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Filip=20Jirs=C3=A1k?= <filip@jirsak.org>\nDate: Sat, 11 Apr 2020 19:27:36 +0200\nSubject: [PATCH] #28 Disable downloading external resources with\n DocumentHelper.parseText() helper.\n\n(cherry picked from commit 8f6a7f6001d679176c1079ac65871d4e493360db)\n---\n src\/main\/java\/org\/dom4j\/DocumentHelper.java | 8 ++++++++\n 1 file changed, 8 insertions(+)\n\ndiff --git a\/src\/main\/java\/org\/dom4j\/DocumentHelper.java b\/src\/main\/java\/org\/dom4j\/DocumentHelper.java\nindex a3a69dca..6ceed9a3 100644\n--- a\/src\/main\/java\/org\/dom4j\/DocumentHelper.java\n+++ b\/src\/main\/java\/org\/dom4j\/DocumentHelper.java\n@@ -270,6 +270,14 @@ public static void sort(List<Node> list, String expression, boolean distinct) {\n      *\/\n     public static Document parseText(String text) throws DocumentException {\n         SAXReader reader = new SAXReader();\n+        try {\n+            reader.setFeature(\"http:\/\/apache.org\/xml\/features\/nonvalidating\/load-external-dtd\", false);\n+            reader.setFeature(\"http:\/\/xml.org\/sax\/features\/external-general-entities\", false);\n+            reader.setFeature(\"http:\/\/xml.org\/sax\/features\/external-parameter-entities\", false);\n+        } catch (SAXException e) {\n+            \/\/Parse with external resources downloading allowed.\n+        }\n+\n         String encoding = getEncoding(text);\n \n         InputSource source = new InputSource(new StringReader(text));"
        },
        {
            "index":605,
            "vuln_id":"GHSA-hrgx-p36p-89q4",
            "cwe_id":"{'CWE-89', 'CWE-95'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/PrestaShop\/PrestaShop\/commit\/b6d96e7c2a4e35a44e96ffbcdfd34439b56af804'}",
            "dataset":"osv",
            "summary":"PrestaShop eval injection possible if shop vulnerable to SQL injection ### Impact\nEval injection possible if the shop is vulnerable to an SQL injection.\n\n### Patches\nThe problem is fixed in version 1.7.8.7\n\n### Workarounds\nDelete the MySQL Smarty cache feature by removing these lines in the file `config\/smarty.config.inc.php` lines 43-46 (PrestaShop 1.7) or 40-43 (PrestaShop 1.6):\n```php\nif (Configuration::get('PS_SMARTY_CACHING_TYPE') == 'mysql') {\n    include _PS_CLASS_DIR_.'Smarty\/SmartyCacheResourceMysql.php';\n    $smarty->caching_type = 'mysql';\n}\n```",
            "published_date":"2022-07-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/PrestaShop\/PrestaShop",
            "commit_href":"https:\/\/github.com\/PrestaShop\/PrestaShop\/commit\/b6d96e7c2a4e35a44e96ffbcdfd34439b56af804",
            "commit_sha":"b6d96e7c2a4e35a44e96ffbcdfd34439b56af804",
            "patch":"SINGLE",
            "chain_ord":"['b6d96e7c2a4e35a44e96ffbcdfd34439b56af804']",
            "before_first_fix_commit":"{'dc8dc1faef7185ad30fc8dcb0653524d9bfb7c82', 'f342765697f5f980e4c6bb537f6575bf5e657077'}",
            "last_fix_commit":"b6d96e7c2a4e35a44e96ffbcdfd34439b56af804",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/25\/2022, 08:51:31",
            "message":"Merge pull request from GHSA-hrgx-p36p-89q4\n\nCrypt\/decrypt smarty cache in DB",
            "author":"atomiix",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 2, 'total': 12}",
            "files":"{'classes\/Smarty\/SmartyCacheResourceMysql.php': {'additions': 10, 'deletions': 2, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/PrestaShop\/PrestaShop\/raw\/b6d96e7c2a4e35a44e96ffbcdfd34439b56af804\/classes%2FSmarty%2FSmartyCacheResourceMysql.php', 'patch': '@@ -25,6 +25,14 @@\\n  *\/\\n class Smarty_CacheResource_Mysql extends Smarty_CacheResource_Custom\\n {\\n+    \/** @var PhpEncryption *\/\\n+    private $phpEncryption;\\n+\\n+    public function __construct()\\n+    {\\n+        $this->phpEncryption = new PhpEncryption(_NEW_COOKIE_KEY_);\\n+    }\\n+\\n     \/**\\n      * fetch cached content and its modification time from data source.\\n      *\\n@@ -39,7 +47,7 @@ protected function fetch($id, $name, $cache_id, $compile_id, &$content, &$mtime)\\n     {\\n         $row = Db::getInstance()->getRow(\\'SELECT modified, content FROM \\' . _DB_PREFIX_ . \\'smarty_cache WHERE id_smarty_cache = \"\\' . pSQL($id, true) . \\'\"\\');\\n         if ($row) {\\n-            $content = $row[\\'content\\'];\\n+            $content = $this->phpEncryption->decrypt($row[\\'content\\']);\\n             $mtime = strtotime($row[\\'modified\\']);\\n         } else {\\n             $content = null;\\n@@ -87,7 +95,7 @@ protected function save($id, $name, $cache_id, $compile_id, $exp_time, $content)\\n \\t\\t\\t\"\\' . pSQL($id, true) . \\'\",\\n \\t\\t\\t\"\\' . pSQL(sha1($name)) . \\'\",\\n \\t\\t\\t\"\\' . pSQL($cache_id, true) . \\'\",\\n-\\t\\t\\t\"\\' . pSQL($content, true) . \\'\"\\n+\\t\\t\\t\"\\' . $this->phpEncryption->encrypt($content) . \\'\"\\n \\t\\t)\\');\\n \\n         return (bool) Db::getInstance()->Affected_Rows();'}}",
            "message_norm":"merge pull request from ghsa-hrgx-p36p-89q4\n\ncrypt\/decrypt smarty cache in db",
            "language":"en",
            "entities":"[('ghsa-hrgx-p36p-89q4', 'VULNID', 'GHSA'), ('crypt', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['classes\/Smarty\/SmartyCacheResourceMysql.php'])",
            "num_files":1.0,
            "patch_content":"From f342765697f5f980e4c6bb537f6575bf5e657077 Mon Sep 17 00:00:00 2001\nFrom: atomiix <thomas.baccelli@prestashop.com>\nDate: Wed, 20 Jul 2022 12:44:20 +0200\nSubject: [PATCH] Crypt\/decrypt smarty cache in DB\n\n---\n classes\/Smarty\/SmartyCacheResourceMysql.php | 12 ++++++++++--\n 1 file changed, 10 insertions(+), 2 deletions(-)\n\ndiff --git a\/classes\/Smarty\/SmartyCacheResourceMysql.php b\/classes\/Smarty\/SmartyCacheResourceMysql.php\nindex d3f684624649b..b4f928d485109 100644\n--- a\/classes\/Smarty\/SmartyCacheResourceMysql.php\n+++ b\/classes\/Smarty\/SmartyCacheResourceMysql.php\n@@ -25,6 +25,14 @@\n  *\/\n class Smarty_CacheResource_Mysql extends Smarty_CacheResource_Custom\n {\n+    \/** @var PhpEncryption *\/\n+    private $phpEncryption;\n+\n+    public function __construct()\n+    {\n+        $this->phpEncryption = new PhpEncryption(_NEW_COOKIE_KEY_);\n+    }\n+\n     \/**\n      * fetch cached content and its modification time from data source.\n      *\n@@ -39,7 +47,7 @@ protected function fetch($id, $name, $cache_id, $compile_id, &$content, &$mtime)\n     {\n         $row = Db::getInstance()->getRow('SELECT modified, content FROM ' . _DB_PREFIX_ . 'smarty_cache WHERE id_smarty_cache = \"' . pSQL($id, true) . '\"');\n         if ($row) {\n-            $content = $row['content'];\n+            $content = $this->phpEncryption->decrypt($row['content']);\n             $mtime = strtotime($row['modified']);\n         } else {\n             $content = null;\n@@ -87,7 +95,7 @@ protected function save($id, $name, $cache_id, $compile_id, $exp_time, $content)\n \t\t\t\"' . pSQL($id, true) . '\",\n \t\t\t\"' . pSQL(sha1($name)) . '\",\n \t\t\t\"' . pSQL($cache_id, true) . '\",\n-\t\t\t\"' . pSQL($content, true) . '\"\n+\t\t\t\"' . $this->phpEncryption->encrypt($content) . '\"\n \t\t)');\n \n         return (bool) Db::getInstance()->Affected_Rows();"
        },
        {
            "index":169,
            "vuln_id":"GHSA-44qp-9wwf-734r",
            "cwe_id":"{'CWE-787', 'CWE-120'}",
            "score":7.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/2b7100d6cdff36aa21010a82269bc05a6d1cc74a', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/adbbabdb0d3abb3cdeac69e38a96de1d678b24b3'}",
            "dataset":"osv",
            "summary":"Heap overflow in Tensorflow ### Impact \nThe [implementation of `SparseCountSparseOutput`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/count_ops.cc#L168-L273) is vulnerable to a heap overflow:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ntf.raw_ops.SparseCountSparseOutput(\n  indices=[[-1,-1]],\n  values=[2],\n  dense_shape=[1, 1],\n  weights=[1],\n  binary_output=True,\n  minlength=-1,\n  maxlength=-1,\n  name=None)\n```\n\n### Patches\nWe have patched the issue in GitHub commits [2b7100d6cdff36aa21010a82269bc05a6d1cc74a](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/2b7100d6cdff36aa21010a82269bc05a6d1cc74a) and [adbbabdb0d3abb3cdeac69e38a96de1d678b24b3](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/adbbabdb0d3abb3cdeac69e38a96de1d678b24b3).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
            "published_date":"2022-02-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/2b7100d6cdff36aa21010a82269bc05a6d1cc74a",
            "commit_sha":"2b7100d6cdff36aa21010a82269bc05a6d1cc74a",
            "patch":"MULTI",
            "chain_ord":"['2b7100d6cdff36aa21010a82269bc05a6d1cc74a', 'adbbabdb0d3abb3cdeac69e38a96de1d678b24b3']",
            "before_first_fix_commit":"{'2b7100d6cdff36aa21010a82269bc05a6d1cc74a'}",
            "last_fix_commit":"adbbabdb0d3abb3cdeac69e38a96de1d678b24b3",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/08\/2021, 03:36:18",
            "message":"Cleanup and remove duplicate validation in `SparseCount`.\n\nWe have valdiation that is duplicated, checking different conditions, in different formats and failing to capture all cases. This should fix all the previous bugs.\n\nPiperOrigin-RevId: 414886981\nChange-Id: Ibf0bba0beb057b76d505324bb9487565daf95f01",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 21, 'deletions': 27, 'total': 48}",
            "files":"{'tensorflow\/core\/kernels\/count_ops.cc': {'additions': 21, 'deletions': 27, 'changes': 48, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/2b7100d6cdff36aa21010a82269bc05a6d1cc74a\/tensorflow%2Fcore%2Fkernels%2Fcount_ops.cc', 'patch': '@@ -185,6 +185,27 @@ class SparseCount : public OpKernel {\\n                 errors::InvalidArgument(\\n                     \"Input indices must be a 2-dimensional tensor. Got: \",\\n                     indices.shape().DebugString()));\\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(values.shape()),\\n+                errors::InvalidArgument(\"Input values must be a vector. Got: \",\\n+                                        values.shape().DebugString()));\\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(shape.shape()),\\n+                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\\n+                                        shape.shape().DebugString()));\\n+    OP_REQUIRES(context,\\n+                values.shape().dim_size(0) == indices.shape().dim_size(0),\\n+                errors::InvalidArgument(\\n+                    \"Number of values must match first dimension of indices.\",\\n+                    \"Got \", values.shape().dim_size(0),\\n+                    \" values, indices shape: \", indices.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, shape.shape().dim_size(0) == indices.shape().dim_size(1),\\n+        errors::InvalidArgument(\\n+            \"Number of dimensions must match second dimension of indices.\",\\n+            \"Got \", shape.shape().dim_size(0),\\n+            \" dimensions, indices shape: \", indices.shape().DebugString()));\\n+    OP_REQUIRES(context, shape.NumElements() > 0,\\n+                errors::InvalidArgument(\\n+                    \"The shape argument requires at least one element.\"));\\n \\n     if (use_weights) {\\n       OP_REQUIRES(\\n@@ -195,28 +216,11 @@ class SparseCount : public OpKernel {\\n               \"; values shape: \", values.shape().DebugString()));\\n     }\\n \\n-    OP_REQUIRES(context, shape.NumElements() != 0,\\n-                errors::InvalidArgument(\\n-                    \"The shape argument requires at least one element.\"));\\n-\\n     bool is_1d = shape.NumElements() == 1;\\n     auto shape_vector = shape.flat<int64_t>();\\n     int num_batches = is_1d ? 1 : shape_vector(0);\\n     int num_values = values.NumElements();\\n \\n-    for (int b = 0; b < shape_vector.size(); b++) {\\n-      OP_REQUIRES(context, shape_vector(b) >= 0,\\n-                  errors::InvalidArgument(\\n-                      \"Elements in dense_shape must be >= 0. Instead got:\",\\n-                      shape.DebugString()));\\n-    }\\n-\\n-    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\\n-                errors::InvalidArgument(\\n-                    \"Number of values must match first dimension of indices.\",\\n-                    \"Got \", num_values,\\n-                    \" values, indices shape: \", indices.shape().DebugString()));\\n-\\n     const auto indices_values = indices.matrix<int64_t>();\\n     const auto values_values = values.flat<T>();\\n     const auto weight_values = weights.flat<W>();\\n@@ -225,16 +229,6 @@ class SparseCount : public OpKernel {\\n \\n     T max_value = 0;\\n \\n-    OP_REQUIRES(context, num_values <= indices.shape().dim_size(0),\\n-                errors::InvalidArgument(\\n-                    \"The first dimension of indices must be equal to or \"\\n-                    \"greather than number of values. ( \",\\n-                    indices.shape().dim_size(0), \" vs. \", num_values, \" )\"));\\n-    OP_REQUIRES(context, indices.shape().dim_size(1) > 0,\\n-                errors::InvalidArgument(\"The second dimension of indices must \"\\n-                                        \"be greater than 0. Received: \",\\n-                                        indices.shape().dim_size(1)));\\n-\\n     for (int idx = 0; idx < num_values; ++idx) {\\n       int batch = is_1d ? 0 : indices_values(idx, 0);\\n       if (batch >= num_batches) {'}}",
            "message_norm":"cleanup and remove duplicate validation in `sparsecount`.\n\nwe have valdiation that is duplicated, checking different conditions, in different formats and failing to capture all cases. this should fix all the previous bugs.\n\npiperorigin-revid: 414886981\nchange-id: ibf0bba0beb057b76d505324bb9487565daf95f01",
            "language":"en",
            "entities":"[('remove', 'ACTION', ''), ('duplicate validation', 'SECWORD', ''), ('fix', 'ACTION', ''), ('bugs', 'FLAW', ''), ('414886981', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/count_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 2b7100d6cdff36aa21010a82269bc05a6d1cc74a Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 7 Dec 2021 19:36:18 -0800\nSubject: [PATCH] Cleanup and remove duplicate validation in `SparseCount`.\n\nWe have valdiation that is duplicated, checking different conditions, in different formats and failing to capture all cases. This should fix all the previous bugs.\n\nPiperOrigin-RevId: 414886981\nChange-Id: Ibf0bba0beb057b76d505324bb9487565daf95f01\n---\n tensorflow\/core\/kernels\/count_ops.cc | 48 ++++++++++++----------------\n 1 file changed, 21 insertions(+), 27 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/count_ops.cc b\/tensorflow\/core\/kernels\/count_ops.cc\nindex 5330c36361e5e6..1f99e0783e26f6 100644\n--- a\/tensorflow\/core\/kernels\/count_ops.cc\n+++ b\/tensorflow\/core\/kernels\/count_ops.cc\n@@ -185,6 +185,27 @@ class SparseCount : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Input indices must be a 2-dimensional tensor. Got: \",\n                     indices.shape().DebugString()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(values.shape()),\n+                errors::InvalidArgument(\"Input values must be a vector. Got: \",\n+                                        values.shape().DebugString()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(shape.shape()),\n+                errors::InvalidArgument(\"Input shape must be a vector. Got: \",\n+                                        shape.shape().DebugString()));\n+    OP_REQUIRES(context,\n+                values.shape().dim_size(0) == indices.shape().dim_size(0),\n+                errors::InvalidArgument(\n+                    \"Number of values must match first dimension of indices.\",\n+                    \"Got \", values.shape().dim_size(0),\n+                    \" values, indices shape: \", indices.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, shape.shape().dim_size(0) == indices.shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices.\",\n+            \"Got \", shape.shape().dim_size(0),\n+            \" dimensions, indices shape: \", indices.shape().DebugString()));\n+    OP_REQUIRES(context, shape.NumElements() > 0,\n+                errors::InvalidArgument(\n+                    \"The shape argument requires at least one element.\"));\n \n     if (use_weights) {\n       OP_REQUIRES(\n@@ -195,28 +216,11 @@ class SparseCount : public OpKernel {\n               \"; values shape: \", values.shape().DebugString()));\n     }\n \n-    OP_REQUIRES(context, shape.NumElements() != 0,\n-                errors::InvalidArgument(\n-                    \"The shape argument requires at least one element.\"));\n-\n     bool is_1d = shape.NumElements() == 1;\n     auto shape_vector = shape.flat<int64_t>();\n     int num_batches = is_1d ? 1 : shape_vector(0);\n     int num_values = values.NumElements();\n \n-    for (int b = 0; b < shape_vector.size(); b++) {\n-      OP_REQUIRES(context, shape_vector(b) >= 0,\n-                  errors::InvalidArgument(\n-                      \"Elements in dense_shape must be >= 0. Instead got:\",\n-                      shape.DebugString()));\n-    }\n-\n-    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\n-                errors::InvalidArgument(\n-                    \"Number of values must match first dimension of indices.\",\n-                    \"Got \", num_values,\n-                    \" values, indices shape: \", indices.shape().DebugString()));\n-\n     const auto indices_values = indices.matrix<int64_t>();\n     const auto values_values = values.flat<T>();\n     const auto weight_values = weights.flat<W>();\n@@ -225,16 +229,6 @@ class SparseCount : public OpKernel {\n \n     T max_value = 0;\n \n-    OP_REQUIRES(context, num_values <= indices.shape().dim_size(0),\n-                errors::InvalidArgument(\n-                    \"The first dimension of indices must be equal to or \"\n-                    \"greather than number of values. ( \",\n-                    indices.shape().dim_size(0), \" vs. \", num_values, \" )\"));\n-    OP_REQUIRES(context, indices.shape().dim_size(1) > 0,\n-                errors::InvalidArgument(\"The second dimension of indices must \"\n-                                        \"be greater than 0. Received: \",\n-                                        indices.shape().dim_size(1)));\n-\n     for (int idx = 0; idx < num_values; ++idx) {\n       int batch = is_1d ? 0 : indices_values(idx, 0);\n       if (batch >= num_batches) {"
        },
        {
            "index":641,
            "vuln_id":"GHSA-f55g-x8qq-2569",
            "cwe_id":"{'CWE-1236'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/d9e136ff228e3760fd6dd7572869ac38e9a81809'}",
            "dataset":"osv",
            "summary":"CSV-Safe improperly filters special characters potentially leading to CSV injection CSV-Safe gem < 3.0.0 doesn't filter out special characters which could trigger CSV Injection.",
            "published_date":"2022-05-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/WeblateOrg\/weblate",
            "commit_href":"https:\/\/github.com\/WeblateOrg\/weblate\/commit\/d9e136ff228e3760fd6dd7572869ac38e9a81809",
            "commit_sha":"d9e136ff228e3760fd6dd7572869ac38e9a81809",
            "patch":"SINGLE",
            "chain_ord":"['d9e136ff228e3760fd6dd7572869ac38e9a81809']",
            "before_first_fix_commit":"{'66f55341916de8a9e9125bb4af661373fb5c525b'}",
            "last_fix_commit":"d9e136ff228e3760fd6dd7572869ac38e9a81809",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/26\/2017, 15:19:46",
            "message":"Improve filter on CSV formulas\n\nIt seems that Excel is interpreting way more than I originally thought.\n\nFixes https:\/\/hackerone.com\/reports\/223999\n\nSigned-off-by: Michal \u010ciha\u0159 <michal@cihar.com>",
            "author":"Michal \u010ciha\u0159",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'weblate\/trans\/exporters.py': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/WeblateOrg\/weblate\/raw\/d9e136ff228e3760fd6dd7572869ac38e9a81809\/weblate%2Ftrans%2Fexporters.py', 'patch': '@@ -279,6 +279,6 @@ def string_filter(self, text):\\n         used at first position of translatable strings, so the harm is not\\n         that big.\\n         \"\"\"\\n-        if text and text[0] in (\\'=\\', \\'+\\', \\'-\\', \\'@\\'):\\n-            return \"\\'\" + text\\n+        if text and text[0] in (\\'=\\', \\'+\\', \\'-\\', \\'@\\', \\'|\\', \\'%\\'):\\n+            return \"\\'{0}\\'\".format(text.replace(\\'|\\', \\'\\\\|\\'))\\n         return text'}}",
            "message_norm":"improve filter on csv formulas\n\nit seems that excel is interpreting way more than i originally thought.\n\nfixes https:\/\/hackerone.com\/reports\/223999\n\nsigned-off-by: michal \u010diha\u0159 <michal@cihar.com>",
            "language":"en",
            "entities":"[('improve', 'ACTION', ''), ('fixes', 'ACTION', ''), ('https:\/\/hackerone.com\/reports\/223999', 'URL', ''), ('michal@cihar.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['weblate\/trans\/exporters.py'])",
            "num_files":1.0,
            "patch_content":"From d9e136ff228e3760fd6dd7572869ac38e9a81809 Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Michal=20=C4=8Ciha=C5=99?= <michal@cihar.com>\nDate: Wed, 26 Apr 2017 17:19:46 +0200\nSubject: [PATCH] Improve filter on CSV formulas\nMIME-Version: 1.0\nContent-Type: text\/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\n\nIt seems that Excel is interpreting way more than I originally thought.\n\nFixes https:\/\/hackerone.com\/reports\/223999\n\nSigned-off-by: Michal \u010ciha\u0159 <michal@cihar.com>\n---\n weblate\/trans\/exporters.py | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/weblate\/trans\/exporters.py b\/weblate\/trans\/exporters.py\nindex 56aef00c52ec..36396f4d816a 100644\n--- a\/weblate\/trans\/exporters.py\n+++ b\/weblate\/trans\/exporters.py\n@@ -279,6 +279,6 @@ def string_filter(self, text):\n         used at first position of translatable strings, so the harm is not\n         that big.\n         \"\"\"\n-        if text and text[0] in ('=', '+', '-', '@'):\n-            return \"'\" + text\n+        if text and text[0] in ('=', '+', '-', '@', '|', '%'):\n+            return \"'{0}'\".format(text.replace('|', '\\|'))\n         return text"
        },
        {
            "index":523,
            "vuln_id":"GHSA-h3gg-7wx2-cq3h",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/flarum\/sticky\/commit\/7ebd30462bd405c4c0570b93a6d48710e6c3db19'}",
            "dataset":"osv",
            "summary":"XSS in Flarum Sticky extension ### Impact\nA change in release beta 14 of the Sticky extension caused the plain text content of the first post of a pinned discussion to be injected as HTML on the discussion list. The issue was discovered following an internal audit.\n\nAny HTML would be injected through Mithril's `m.trust()` helper. This resulted in an HTML injection where `<script>` tags would not be executed. However it was possible to run javascript from other HTML attributes, enabling a cross-site scripting (XSS) attack to be performed.\n\nSince the exploit only happens with the first post of a pinned discussion, an attacker would need the ability to pin their own discussion, or be able to edit a discussion that was previously pinned.\n\nOn forums where all pinned posts are authored by your staff, you can be relatively certain the vulnerability has not been exploited.\n\nForums where some user-created discussions were pinned can look at the first post edit date to find whether the vulnerability might have been exploited. Because Flarum doesn't store the post content history, you cannot be certain if a malicious edit was reverted.\n\n### Patches\nThe fix will be available in version v0.1.0-beta.16 with Flarum beta 16. The fix has already been back-ported to Flarum beta 15 as version v0.1.0-beta.15.1 of the Sticky extension.\n\n### Workarounds\nForum administrators can disable the Sticky extension until they are able to apply the update. The vulnerability cannot be exploited while the extension is disabled.\n\n### References\n\n- [Release announcement](https:\/\/discuss.flarum.org\/d\/26042-security-update-to-flarum-sticky-010-beta151)\n- [Pull Request](https:\/\/github.com\/flarum\/sticky\/pull\/24)\n\n### For more information\nIf you have any questions or comments about this advisory, please start a new discussion on our [support forum](https:\/\/discuss.flarum.org\/t\/support).\n\nIf you discover a security vulnerability within Flarum, please send an e-mail to [security@flarum.org](mailto:security@flarum.org). All security vulnerabilities will be promptly addressed. More details can be found in our [security policy](https:\/\/github.com\/flarum\/core\/security\/policy).",
            "published_date":"2021-01-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/flarum\/sticky",
            "commit_href":"https:\/\/github.com\/flarum\/sticky\/commit\/7ebd30462bd405c4c0570b93a6d48710e6c3db19",
            "commit_sha":"7ebd30462bd405c4c0570b93a6d48710e6c3db19",
            "patch":"SINGLE",
            "chain_ord":"['7ebd30462bd405c4c0570b93a6d48710e6c3db19']",
            "before_first_fix_commit":"{'62a74d25ab3f84f69d1c4b5920080963788a8360'}",
            "last_fix_commit":"7ebd30462bd405c4c0570b93a6d48710e6c3db19",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/22\/2021, 18:53:11",
            "message":"Fix evaluation of post content by m.trust() (#24)",
            "author":"Sami Mazouz",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'js\/src\/forum\/addStickyExcerpt.js': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/flarum\/sticky\/raw\/7ebd30462bd405c4c0570b93a6d48710e6c3db19\/js%2Fsrc%2Fforum%2FaddStickyExcerpt.js', 'patch': \"@@ -21,7 +21,8 @@ export default function addStickyControl() {\\n       if (firstPost) {\\n         const excerpt = truncate(firstPost.contentPlain(), 175);\\n \\n-        items.add('excerpt', m.trust(excerpt), -100);\\n+        \/\/ Wrapping in <div> because ItemList entries need to be vnodes\\n+        items.add('excerpt', <div>{excerpt}<\/div>, -100);\\n       }\\n     }\\n   });\"}}",
            "message_norm":"fix evaluation of post content by m.trust() (#24)",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('#24', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['js\/src\/forum\/addStickyExcerpt.js'])",
            "num_files":1.0,
            "patch_content":"From 7ebd30462bd405c4c0570b93a6d48710e6c3db19 Mon Sep 17 00:00:00 2001\nFrom: Sami Mazouz <sychocouldy@gmail.com>\nDate: Fri, 22 Jan 2021 19:53:11 +0100\nSubject: [PATCH] Fix evaluation of post content by m.trust() (#24)\n\n---\n js\/src\/forum\/addStickyExcerpt.js | 3 ++-\n 1 file changed, 2 insertions(+), 1 deletion(-)\n\ndiff --git a\/js\/src\/forum\/addStickyExcerpt.js b\/js\/src\/forum\/addStickyExcerpt.js\nindex 817e626..05e6954 100644\n--- a\/js\/src\/forum\/addStickyExcerpt.js\n+++ b\/js\/src\/forum\/addStickyExcerpt.js\n@@ -21,7 +21,8 @@ export default function addStickyControl() {\n       if (firstPost) {\n         const excerpt = truncate(firstPost.contentPlain(), 175);\n \n-        items.add('excerpt', m.trust(excerpt), -100);\n+        \/\/ Wrapping in <div> because ItemList entries need to be vnodes\n+        items.add('excerpt', <div>{excerpt}<\/div>, -100);\n       }\n     }\n   });"
        },
        {
            "index":781,
            "vuln_id":"GHSA-v82p-hv3v-p6qp",
            "cwe_id":"{'CWE-20'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/203214568f5bc237603dbab6e1fd389f1572f5c9', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9e62869465573cb2d9b5053f1fa02a81fce21d69'}",
            "dataset":"osv",
            "summary":"Incomplete validation in MKL requantization ### Impact\nDue to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RequantizationRangePerChannel(\n  input=[],\n  input_min=[0,0,0,0,0],\n  input_max=[1,1,1,1,1],\n  clip_value_max=1)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/mkl\/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor.\n\nA similar issue occurs in `MklRequantizePerChannelOp`:\n\n```python\nimport tensorflow as tf \nfrom tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  out_type=tf.int)\n``` \n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/mkl\/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments.\n\n### Patches\nWe have patched the issue in GitHub commit [9e62869465573cb2d9b5053f1fa02a81fce21d69](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9e62869465573cb2d9b5053f1fa02a81fce21d69) and in the Github commit [203214568f5bc237603dbab6e1fd389f1572f5c9](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/203214568f5bc237603dbab6e1fd389f1572f5c9).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/203214568f5bc237603dbab6e1fd389f1572f5c9",
            "commit_sha":"203214568f5bc237603dbab6e1fd389f1572f5c9",
            "patch":"MULTI",
            "chain_ord":"['9e62869465573cb2d9b5053f1fa02a81fce21d69', '203214568f5bc237603dbab6e1fd389f1572f5c9']",
            "before_first_fix_commit":"{'aff0d5b2883ea3de9b52f9e7cd996a34b299bf06'}",
            "last_fix_commit":"203214568f5bc237603dbab6e1fd389f1572f5c9",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/30\/2021, 23:06:23",
            "message":"Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 25, 'deletions': 15, 'total': 40}",
            "files":"{'tensorflow\/core\/kernels\/mkl\/mkl_requantize_per_channel_op.cc': {'additions': 25, 'deletions': 15, 'changes': 40, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/203214568f5bc237603dbab6e1fd389f1572f5c9\/tensorflow%2Fcore%2Fkernels%2Fmkl%2Fmkl_requantize_per_channel_op.cc', 'patch': '@@ -49,35 +49,45 @@ class MklRequantizePerChannelOp : public OpKernel {\\n   void Compute(OpKernelContext* ctx) override {\\n     try {\\n       const Tensor& input = ctx->input(kInputTensorIndex);\\n+      OP_REQUIRES(\\n+          ctx, input.dims() == 4,\\n+          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\\n+                                  \"supports 4D tensors only.\"));\\n+\\n       const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\\n+      size_t depth = input_min_vec.NumElements();\\n       float* input_min_vec_data = (float*)const_cast<void*>(\\n           static_cast<const void*>(input_min_vec.flat<float>().data()));\\n+\\n       const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\\n+      OP_REQUIRES(\\n+          ctx, input_max_vec.NumElements() == depth,\\n+          errors::InvalidArgument(\"input_max has incorrect size, expected \",\\n+                                  depth, \" was \", input_max_vec.NumElements()));\\n       float* input_max_vec_data = (float*)const_cast<void*>(\\n           static_cast<const void*>(input_max_vec.flat<float>().data()));\\n \\n       const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\\n+      OP_REQUIRES(\\n+          ctx, input_requested_min.NumElements() == 1,\\n+          errors::InvalidArgument(\"requested_output_min must be a scalar\"));\\n       const float input_requested_min_float =\\n           input_requested_min.flat<float>()(0);\\n+\\n       const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\\n+      OP_REQUIRES(\\n+          ctx, input_requested_min.NumElements() == 1,\\n+          errors::InvalidArgument(\"requested_output_max must be a scalar\"));\\n       const float input_requested_max_float =\\n           input_requested_max.flat<float>()(0);\\n \\n-      size_t depth = input_min_vec.NumElements();\\n-      OP_REQUIRES(\\n-          ctx, input.dims() == 4,\\n-          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\\n-                                  \"supports 4D tensors only.\"));\\n-      OP_REQUIRES(\\n-          ctx, input_min_vec.dim_size(0) == depth,\\n-          errors::InvalidArgument(\"input_min has incorrect size, expected \",\\n-                                  depth, \" was \", input_min_vec.dim_size(0)));\\n-      OP_REQUIRES(\\n-          ctx, input_max_vec.dim_size(0) == depth,\\n-          errors::InvalidArgument(\"input_max has incorrect size, expected \",\\n-                                  depth, \" was \", input_max_vec.dim_size(0)));\\n-\\n-      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\\n+      if (out_type_ == DT_QINT8) {\\n+        OP_REQUIRES(ctx, input_requested_min_float < 0.0f,\\n+                    errors::InvalidArgument(\\n+                        \"If out_type is QINT8, requested_output_max must be \"\\n+                        \"non negative, got \",\\n+                        input_requested_min_float));\\n+      }\\n \\n       const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\\n       const float requested_min_max ='}}",
            "message_norm":"reorganize and add more validation to mkl requantization\n\npiperorigin-revid: 387901341\nchange-id: i2515b9034c64e113db0bcec8337d30643ab0a0f1",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('387901341', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/mkl\/mkl_requantize_per_channel_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 203214568f5bc237603dbab6e1fd389f1572f5c9 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 16:06:23 -0700\nSubject: [PATCH] Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1\n---\n ...\/mkl\/mkl_requantize_per_channel_op.cc      | 40 ++++++++++++-------\n 1 file changed, 25 insertions(+), 15 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/mkl\/mkl_requantize_per_channel_op.cc b\/tensorflow\/core\/kernels\/mkl\/mkl_requantize_per_channel_op.cc\nindex c0f9845cd4b084..6ffbd09b44f543 100644\n--- a\/tensorflow\/core\/kernels\/mkl\/mkl_requantize_per_channel_op.cc\n+++ b\/tensorflow\/core\/kernels\/mkl\/mkl_requantize_per_channel_op.cc\n@@ -49,35 +49,45 @@ class MklRequantizePerChannelOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     try {\n       const Tensor& input = ctx->input(kInputTensorIndex);\n+      OP_REQUIRES(\n+          ctx, input.dims() == 4,\n+          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n+                                  \"supports 4D tensors only.\"));\n+\n       const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n+      size_t depth = input_min_vec.NumElements();\n       float* input_min_vec_data = (float*)const_cast<void*>(\n           static_cast<const void*>(input_min_vec.flat<float>().data()));\n+\n       const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n+      OP_REQUIRES(\n+          ctx, input_max_vec.NumElements() == depth,\n+          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n+                                  depth, \" was \", input_max_vec.NumElements()));\n       float* input_max_vec_data = (float*)const_cast<void*>(\n           static_cast<const void*>(input_max_vec.flat<float>().data()));\n \n       const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n+      OP_REQUIRES(\n+          ctx, input_requested_min.NumElements() == 1,\n+          errors::InvalidArgument(\"requested_output_min must be a scalar\"));\n       const float input_requested_min_float =\n           input_requested_min.flat<float>()(0);\n+\n       const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n+      OP_REQUIRES(\n+          ctx, input_requested_min.NumElements() == 1,\n+          errors::InvalidArgument(\"requested_output_max must be a scalar\"));\n       const float input_requested_max_float =\n           input_requested_max.flat<float>()(0);\n \n-      size_t depth = input_min_vec.NumElements();\n-      OP_REQUIRES(\n-          ctx, input.dims() == 4,\n-          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n-                                  \"supports 4D tensors only.\"));\n-      OP_REQUIRES(\n-          ctx, input_min_vec.dim_size(0) == depth,\n-          errors::InvalidArgument(\"input_min has incorrect size, expected \",\n-                                  depth, \" was \", input_min_vec.dim_size(0)));\n-      OP_REQUIRES(\n-          ctx, input_max_vec.dim_size(0) == depth,\n-          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n-                                  depth, \" was \", input_max_vec.dim_size(0)));\n-\n-      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\n+      if (out_type_ == DT_QINT8) {\n+        OP_REQUIRES(ctx, input_requested_min_float < 0.0f,\n+                    errors::InvalidArgument(\n+                        \"If out_type is QINT8, requested_output_max must be \"\n+                        \"non negative, got \",\n+                        input_requested_min_float));\n+      }\n \n       const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n       const float requested_min_max ="
        },
        {
            "index":214,
            "vuln_id":"GHSA-gwrj-88fp-5m36",
            "cwe_id":"{'CWE-94'}",
            "score":8.5,
            "chain":"{'https:\/\/github.com\/whiteleaf7\/narou\/commit\/d07720e855293182563b749431dfbf6c2d1cdb42'}",
            "dataset":"osv",
            "summary":"Code injection in Narou Narou (aka Narou.rb) before 3.8.0 allows Ruby Code Injection via the title name or author name of a novel.",
            "published_date":"2021-07-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/whiteleaf7\/narou",
            "commit_href":"https:\/\/github.com\/whiteleaf7\/narou\/commit\/d07720e855293182563b749431dfbf6c2d1cdb42",
            "commit_sha":"d07720e855293182563b749431dfbf6c2d1cdb42",
            "patch":"SINGLE",
            "chain_ord":"['d07720e855293182563b749431dfbf6c2d1cdb42']",
            "before_first_fix_commit":"{'21f8d1b4cbfa42a80eae09d74bb5124fd6cde3f2'}",
            "last_fix_commit":"d07720e855293182563b749431dfbf6c2d1cdb42",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/27\/2021, 13:49:19",
            "message":"prohibit embedding of novel information",
            "author":"whiteleaf7",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 8, 'total': 9}",
            "files":"{'template\/converter.rb.erb': {'additions': 1, 'deletions': 8, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/whiteleaf7\/narou\/raw\/d07720e855293182563b749431dfbf6c2d1cdb42\/template%2Fconverter.rb.erb', 'patch': '@@ -1,14 +1,7 @@\\n # -*- coding: utf-8 -*-\\n <% Template.target_binary_version(1.0) -%>\\n \\n-=begin\\n-\u5bfe\u8c61\u5c0f\u8aac\u60c5\u5831\\n-\u30bf\u30a4\u30c8\u30eb: <%= @setting[\"title\"] %>\\n-\u4f5c\u8005: <%= @setting[\"author\"] %>\\n-URL: <%= @setting[\"toc_url\"] %>\\n-\\n-\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f http:\/\/bit.ly\/1vTEH04 \u3092\u53c2\u7167\u3057\u3066\u4e0b\u3055\u3044\\n-=end\\n+# \u8a73\u7d30\u306b\u3064\u3044\u3066\u306f http:\/\/bit.ly\/1vTEH04 \u3092\u53c2\u7167\u3057\u3066\u4e0b\u3055\u3044\\n converter do\\n   # \u5404\u7a2e\u5909\u63db\u51e6\u7406\u304c\u3055\u308c\u308b\u300c\u524d\u300d\u306e\u751f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u306e\u5909\u63db\u51e6\u7406\u3092\u8a18\u8ff0\\n   def before(io, text_type)'}}",
            "message_norm":"prohibit embedding of novel information",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['template\/converter.rb.erb'])",
            "num_files":1.0,
            "patch_content":"From d07720e855293182563b749431dfbf6c2d1cdb42 Mon Sep 17 00:00:00 2001\nFrom: whiteleaf7 <2nd.leaf@gmail.com>\nDate: Sun, 27 Jun 2021 22:49:19 +0900\nSubject: [PATCH] prohibit embedding of novel information\n\n---\n template\/converter.rb.erb | 9 +--------\n 1 file changed, 1 insertion(+), 8 deletions(-)\n\ndiff --git a\/template\/converter.rb.erb b\/template\/converter.rb.erb\nindex a714c30c..07af4897 100644\n--- a\/template\/converter.rb.erb\n+++ b\/template\/converter.rb.erb\n@@ -1,14 +1,7 @@\n # -*- coding: utf-8 -*-\n <% Template.target_binary_version(1.0) -%>\n \n-=begin\n-\u5bfe\u8c61\u5c0f\u8aac\u60c5\u5831\n-\u30bf\u30a4\u30c8\u30eb: <%= @setting[\"title\"] %>\n-\u4f5c\u8005: <%= @setting[\"author\"] %>\n-URL: <%= @setting[\"toc_url\"] %>\n-\n-\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f http:\/\/bit.ly\/1vTEH04 \u3092\u53c2\u7167\u3057\u3066\u4e0b\u3055\u3044\n-=end\n+# \u8a73\u7d30\u306b\u3064\u3044\u3066\u306f http:\/\/bit.ly\/1vTEH04 \u3092\u53c2\u7167\u3057\u3066\u4e0b\u3055\u3044\n converter do\n   # \u5404\u7a2e\u5909\u63db\u51e6\u7406\u304c\u3055\u308c\u308b\u300c\u524d\u300d\u306e\u751f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u306e\u5909\u63db\u51e6\u7406\u3092\u8a18\u8ff0\n   def before(io, text_type)"
        },
        {
            "index":516,
            "vuln_id":"GHSA-h6wm-mr85-4h9g",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/neorazorx\/facturascripts\/commit\/73a6595ca85984d65f656c6356fabb23d1936c54'}",
            "dataset":"osv",
            "summary":"Cross site scripting in facturascripts A Cross-site Scripting (XSS) vulnerability exists in the fsNick parameter in facturascripts prior to version 2022.06",
            "published_date":"2022-06-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/neorazorx\/facturascripts",
            "commit_href":"https:\/\/github.com\/neorazorx\/facturascripts\/commit\/73a6595ca85984d65f656c6356fabb23d1936c54",
            "commit_sha":"73a6595ca85984d65f656c6356fabb23d1936c54",
            "patch":"SINGLE",
            "chain_ord":"['73a6595ca85984d65f656c6356fabb23d1936c54']",
            "before_first_fix_commit":"{'298eb4b1a94c5898fde5a21e412955fc77a3ef93'}",
            "last_fix_commit":"73a6595ca85984d65f656c6356fabb23d1936c54",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 09:29:31",
            "message":"Sanitized username when showing user not found message.\n------\nSaneado nombre de usuario al mostrar el mensaje de usuario no encontrado.",
            "author":"Carlos Garcia Gomez",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'Core\/App\/AppController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NeoRazorX\/facturascripts\/raw\/73a6595ca85984d65f656c6356fabb23d1936c54\/Core%2FApp%2FAppController.php', 'patch': \"@@ -287,7 +287,7 @@ private function userAuth()\\n         }\\n \\n         $this->ipWarning();\\n-        ToolBox::i18nLog()->warning('login-user-not-found', ['%nick%' => $nick]);\\n+        ToolBox::i18nLog()->warning('login-user-not-found', ['%nick%' => htmlspecialchars($nick)]);\\n         return false;\\n     }\"}}",
            "message_norm":"sanitized username when showing user not found message.\n------\nsaneado nombre de usuario al mostrar el mensaje de usuario no encontrado.",
            "language":"en",
            "entities":"[('sanitized', 'SECWORD', ''), ('found', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Core\/App\/AppController.php'])",
            "num_files":1.0,
            "patch_content":"From 73a6595ca85984d65f656c6356fabb23d1936c54 Mon Sep 17 00:00:00 2001\nFrom: Carlos Garcia Gomez <neorazorx@gmail.com>\nDate: Thu, 28 Apr 2022 11:29:31 +0200\nSubject: [PATCH] Sanitized username when showing user not found message.\n ------ Saneado nombre de usuario al mostrar el mensaje de usuario no\n encontrado.\n\n---\n Core\/App\/AppController.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/Core\/App\/AppController.php b\/Core\/App\/AppController.php\nindex 83c42b7241..0dd563c518 100644\n--- a\/Core\/App\/AppController.php\n+++ b\/Core\/App\/AppController.php\n@@ -287,7 +287,7 @@ private function userAuth()\n         }\n \n         $this->ipWarning();\n-        ToolBox::i18nLog()->warning('login-user-not-found', ['%nick%' => $nick]);\n+        ToolBox::i18nLog()->warning('login-user-not-found', ['%nick%' => htmlspecialchars($nick)]);\n         return false;\n     }"
        },
        {
            "index":58,
            "vuln_id":"GHSA-7gfg-6934-mqq2",
            "cwe_id":"{'CWE-287'}",
            "score":5.6,
            "chain":"{'https:\/\/github.com\/pion\/dtls\/commit\/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0'}",
            "dataset":"osv",
            "summary":"Improper Authenication in Pion DTLS handleIncomingPacket in conn.go in Pion DTLS before 1.5.2 lacks a check for application data with epoch 0, which allows remote attackers to inject arbitrary unencrypted data after handshake completion.",
            "published_date":"2021-06-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/pion\/dtls",
            "commit_href":"https:\/\/github.com\/pion\/dtls\/commit\/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
            "commit_sha":"fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
            "patch":"SINGLE",
            "chain_ord":"['fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0']",
            "before_first_fix_commit":"{'82948855ecb86a9e0b86c8dd43d010cbc545dc94'}",
            "last_fix_commit":"fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/11\/2019, 09:12:16",
            "message":"Assert that ApplicationData has epoch != 0\n\nOtherwise we may accept unencrypted\/unauthenticated ApplicationData\nfrom a remote",
            "author":"Sean DuBois",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'conn.go': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pion\/dtls\/raw\/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0\/conn.go', 'patch': '@@ -559,6 +559,10 @@ func (c *Conn) handleIncomingPacket(buf []byte) (*alert, error) {\\n \\t\\tc.log.Trace(\"<- ChangeCipherSpec\")\\n \\t\\tc.setRemoteEpoch(c.getRemoteEpoch() + 1)\\n \\tcase *applicationData:\\n+\\t\\tif h.epoch == 0 {\\n+\\t\\t\\treturn &alert{alertLevelFatal, alertUnexpectedMessage}, fmt.Errorf(\"ApplicationData with epoch of 0\")\\n+\\t\\t}\\n+\\n \\t\\tc.decrypted <- content.data\\n \\tdefault:\\n \\t\\treturn &alert{alertLevelFatal, alertUnexpectedMessage}, fmt.Errorf(\"unhandled contentType %d\", content.contentType())'}}",
            "message_norm":"assert that applicationdata has epoch != 0\n\notherwise we may accept unencrypted\/unauthenticated applicationdata\nfrom a remote",
            "language":"en",
            "entities":"[('unencrypted', 'SECWORD', ''), ('unauthenticated', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['conn.go'])",
            "num_files":1.0,
            "patch_content":"From fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0 Mon Sep 17 00:00:00 2001\nFrom: Sean DuBois <seaduboi@amazon.com>\nDate: Fri, 11 Oct 2019 02:12:16 -0700\nSubject: [PATCH] Assert that ApplicationData has epoch != 0\n\nOtherwise we may accept unencrypted\/unauthenticated ApplicationData\nfrom a remote\n---\n conn.go | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/conn.go b\/conn.go\nindex 441db8644..bf5a88e03 100644\n--- a\/conn.go\n+++ b\/conn.go\n@@ -559,6 +559,10 @@ func (c *Conn) handleIncomingPacket(buf []byte) (*alert, error) {\n \t\tc.log.Trace(\"<- ChangeCipherSpec\")\n \t\tc.setRemoteEpoch(c.getRemoteEpoch() + 1)\n \tcase *applicationData:\n+\t\tif h.epoch == 0 {\n+\t\t\treturn &alert{alertLevelFatal, alertUnexpectedMessage}, fmt.Errorf(\"ApplicationData with epoch of 0\")\n+\t\t}\n+\n \t\tc.decrypted <- content.data\n \tdefault:\n \t\treturn &alert{alertLevelFatal, alertUnexpectedMessage}, fmt.Errorf(\"unhandled contentType %d\", content.contentType())"
        },
        {
            "index":664,
            "vuln_id":"GHSA-43f8-2h32-f4cj",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/npm\/hosted-git-info\/commit\/bede0dc38e1785e732bf0a48ba6f81a4a908eba3', 'https:\/\/github.com\/npm\/hosted-git-info\/commit\/8d4b3697d79bcd89cdb36d1db165e3696c783a01', 'https:\/\/github.com\/npm\/hosted-git-info\/commit\/29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in hosted-git-info The npm package `hosted-git-info` before 3.0.8 are vulnerable to Regular Expression Denial of Service (ReDoS) via regular expression shortcutMatch in the fromUrl function in index.js. The affected regular expression exhibits polynomial worst-case time complexity",
            "published_date":"2021-05-06",
            "chain_len":3,
            "project":"https:\/\/github.com\/npm\/hosted-git-info",
            "commit_href":"https:\/\/github.com\/npm\/hosted-git-info\/commit\/29adfe5ef789784c861b2cdeb15051ec2ba651a7",
            "commit_sha":"29adfe5ef789784c861b2cdeb15051ec2ba651a7",
            "patch":"MULTI",
            "chain_ord":"['bede0dc38e1785e732bf0a48ba6f81a4a908eba3', '29adfe5ef789784c861b2cdeb15051ec2ba651a7', '8d4b3697d79bcd89cdb36d1db165e3696c783a01']",
            "before_first_fix_commit":"{'29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
            "last_fix_commit":"8d4b3697d79bcd89cdb36d1db165e3696c783a01",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/07\/2021, 19:31:52",
            "message":"fix: backport regex fix from #76\n\nPR-URL: https:\/\/github.com\/npm\/hosted-git-info\/pull\/84\nCredit: @nlf\nClose: #84\nReviewed-by: @wraithgar",
            "author":"nlf",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/npm\/hosted-git-info\/raw\/29adfe5ef789784c861b2cdeb15051ec2ba651a7\/index.js', 'patch': \"@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\\n   )\\n   var parsed = parseGitUrl(url)\\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\\\/)?([^#]+)\/)\\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\\n     try {\\n       var gitHostInfo = gitHosts[gitHostName]\\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\\n       var defaultRepresentation = null\\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\\n-        project = decodeURIComponent(shortcutMatch[3])\\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\\\.git$\/, ''))\\n         defaultRepresentation = 'shortcut'\\n       } else {\\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return\"}}",
            "message_norm":"fix: backport regex fix from #76\n\npr-url: https:\/\/github.com\/npm\/hosted-git-info\/pull\/84\ncredit: @nlf\nclose: #84\nreviewed-by: @wraithgar",
            "language":"en",
            "entities":"[('#76', 'ISSUE', ''), ('https:\/\/github.com\/npm\/hosted-git-info\/pull\/84', 'URL', ''), ('#84', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From 29adfe5ef789784c861b2cdeb15051ec2ba651a7 Mon Sep 17 00:00:00 2001\nFrom: nlf <quitlahok@gmail.com>\nDate: Wed, 7 Apr 2021 12:31:52 -0700\nSubject: [PATCH] fix: backport regex fix from #76\n\nPR-URL: https:\/\/github.com\/npm\/hosted-git-info\/pull\/84\nCredit: @nlf\nClose: #84\nReviewed-by: @wraithgar\n---\n index.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/index.js b\/index.js\nindex 21e53fe..0885772 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\n   )\n   var parsed = parseGitUrl(url)\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\/)?([^#]+)\/)\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\n     try {\n       var gitHostInfo = gitHosts[gitHostName]\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\n       var defaultRepresentation = null\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\n-        project = decodeURIComponent(shortcutMatch[3])\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\.git$\/, ''))\n         defaultRepresentation = 'shortcut'\n       } else {\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return"
        },
        {
            "index":377,
            "vuln_id":"GHSA-pxpf-v376-7xx5",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/yairEO\/tagify\/commit\/198c0451fad188390390395ccfc84ab371def4c7'}",
            "dataset":"osv",
            "summary":"tagify can pass a malicious placeholder to initiate the cross-site scripting (XSS) payload This affects the package @yaireo\/tagify before 4.9.8. The package is used for rendering UI components inside the input or text fields, and an attacker can pass a malicious placeholder value to it to fire the cross-site scripting (XSS) payload.",
            "published_date":"2022-04-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/yairEO\/tagify",
            "commit_href":"https:\/\/github.com\/yairEO\/tagify\/commit\/198c0451fad188390390395ccfc84ab371def4c7",
            "commit_sha":"198c0451fad188390390395ccfc84ab371def4c7",
            "patch":"SINGLE",
            "chain_ord":"['198c0451fad188390390395ccfc84ab371def4c7']",
            "before_first_fix_commit":"{'93f729c6d1bf45666a1dc21d5cae3aefe1b18043'}",
            "last_fix_commit":"198c0451fad188390390395ccfc84ab371def4c7",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/17\/2022, 08:16:09",
            "message":"fixes #989 - fix XSS",
            "author":"Yair Even Or",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/tagify.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/yairEO\/tagify\/raw\/198c0451fad188390390395ccfc84ab371def4c7\/src%2Ftagify.js', 'patch': '@@ -101,7 +101,7 @@ Tagify.prototype = {\\n \\n         _s.disabled = input.hasAttribute(\\'disabled\\')\\n         _s.readonly = _s.readonly || input.hasAttribute(\\'readonly\\')\\n-        _s.placeholder = input.getAttribute(\\'placeholder\\') || _s.placeholder || \"\"\\n+        _s.placeholder = escapeHTML(input.getAttribute(\\'placeholder\\') || _s.placeholder || \"\")\\n         _s.required = input.hasAttribute(\\'required\\')\\n \\n         for( let name in _s.classNames )'}}",
            "message_norm":"fixes #989 - fix xss",
            "language":"ca",
            "entities":"[('fixes', 'ACTION', ''), ('#989', 'ISSUE', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/tagify.js'])",
            "num_files":1.0,
            "patch_content":"From 198c0451fad188390390395ccfc84ab371def4c7 Mon Sep 17 00:00:00 2001\nFrom: Yair Even Or <Yair.Even-Or@amdocs.com>\nDate: Thu, 17 Feb 2022 10:16:09 +0200\nSubject: [PATCH] fixes #989 - fix XSS\n\n---\n src\/tagify.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/tagify.js b\/src\/tagify.js\nindex 2929ae27..63d5d93f 100644\n--- a\/src\/tagify.js\n+++ b\/src\/tagify.js\n@@ -101,7 +101,7 @@ Tagify.prototype = {\n \n         _s.disabled = input.hasAttribute('disabled')\n         _s.readonly = _s.readonly || input.hasAttribute('readonly')\n-        _s.placeholder = input.getAttribute('placeholder') || _s.placeholder || \"\"\n+        _s.placeholder = escapeHTML(input.getAttribute('placeholder') || _s.placeholder || \"\")\n         _s.required = input.hasAttribute('required')\n \n         for( let name in _s.classNames )"
        },
        {
            "index":589,
            "vuln_id":"GHSA-qhh5-9738-g9mx",
            "cwe_id":"{'CWE-276'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/apache\/incubator-dolphinscheduler\/commit\/b8a9e2e00f2f207ae60c913a7173b59405ff95f1'}",
            "dataset":"osv",
            "summary":"Incorrect Default Permissions in Apache DolphinScheduler Versions of Apache DolphinScheduler prior to 1.3.2 allowed an ordinary user under any tenant to override another users password through the API interface.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/incubator-dolphinscheduler",
            "commit_href":"https:\/\/github.com\/apache\/incubator-dolphinscheduler\/commit\/b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
            "commit_sha":"b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
            "patch":"SINGLE",
            "chain_ord":"['b8a9e2e00f2f207ae60c913a7173b59405ff95f1']",
            "before_first_fix_commit":"{'0505ebf45d93fc1518386804ceffa6b36595f9c5'}",
            "last_fix_commit":"b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/18\/2020, 06:07:47",
            "message":"modify general user can't create,delete,update token (#3538)\n\nCo-authored-by: qiaozhanwei <qiaozhanwei@analysys.com.cn>",
            "author":"qiaozhanwei",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 8, 'total': 15}",
            "files":"{'dolphinscheduler-api\/src\/main\/java\/org\/apache\/dolphinscheduler\/api\/service\/AccessTokenService.java': {'additions': 7, 'deletions': 8, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/dolphinscheduler\/raw\/b8a9e2e00f2f207ae60c913a7173b59405ff95f1\/dolphinscheduler-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fdolphinscheduler%2Fapi%2Fservice%2FAccessTokenService.java', 'patch': '@@ -84,7 +84,9 @@ public Map<String, Object> queryAccessTokenList(User loginUser, String searchVal\\n      *\/\\n     public Map<String, Object> createToken(User loginUser, int userId, String expireTime, String token) {\\n         Map<String, Object> result = new HashMap<>(5);\\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n+\\n+        if (!hasPerm(loginUser,userId)){\\n+            putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n \\n@@ -140,10 +142,6 @@ public Map<String, Object> generateToken(User loginUser, int userId, String expi\\n     public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n         Map<String, Object> result = new HashMap<>(5);\\n \\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n-            return result;\\n-        }\\n-\\n         AccessToken accessToken = accessTokenMapper.selectById(id);\\n \\n         if (accessToken == null) {\\n@@ -152,8 +150,7 @@ public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n             return result;\\n         }\\n \\n-        if (loginUser.getId() != accessToken.getUserId() &&\\n-                loginUser.getUserType() != UserType.ADMIN_USER) {\\n+        if (!hasPerm(loginUser,accessToken.getUserId())){\\n             putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n@@ -176,9 +173,11 @@ public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n     public Map<String, Object> updateToken(User loginUser, int id, int userId, String expireTime, String token) {\\n         Map<String, Object> result = new HashMap<>(5);\\n \\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n+        if (!hasPerm(loginUser,userId)){\\n+            putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n+\\n         AccessToken accessToken = accessTokenMapper.selectById(id);\\n         if (accessToken == null) {\\n             logger.error(\"access token not exist,  access token id {}\", id);'}}",
            "message_norm":"modify general user can't create,delete,update token (#3538)\n\nco-authored-by: qiaozhanwei <qiaozhanwei@analysys.com.cn>",
            "language":"en",
            "entities":"[('update', 'ACTION', ''), ('#3538', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dolphinscheduler-api\/src\/main\/java\/org\/apache\/dolphinscheduler\/api\/service\/AccessTokenService.java'])",
            "num_files":1.0,
            "patch_content":"From b8a9e2e00f2f207ae60c913a7173b59405ff95f1 Mon Sep 17 00:00:00 2001\nFrom: qiaozhanwei <qiaozhanwei@outlook.com>\nDate: Tue, 18 Aug 2020 14:07:47 +0800\nSubject: [PATCH] modify general user can't create,delete,update token (#3538)\n\nCo-authored-by: qiaozhanwei <qiaozhanwei@analysys.com.cn>\n---\n ...\/api\/service\/AccessTokenService.java           | 15 +++++++--------\n 1 file changed, 7 insertions(+), 8 deletions(-)\n\ndiff --git a\/dolphinscheduler-api\/src\/main\/java\/org\/apache\/dolphinscheduler\/api\/service\/AccessTokenService.java b\/dolphinscheduler-api\/src\/main\/java\/org\/apache\/dolphinscheduler\/api\/service\/AccessTokenService.java\nindex 8ccbff1e2f50..c663842bc8aa 100644\n--- a\/dolphinscheduler-api\/src\/main\/java\/org\/apache\/dolphinscheduler\/api\/service\/AccessTokenService.java\n+++ b\/dolphinscheduler-api\/src\/main\/java\/org\/apache\/dolphinscheduler\/api\/service\/AccessTokenService.java\n@@ -84,7 +84,9 @@ public Map<String, Object> queryAccessTokenList(User loginUser, String searchVal\n      *\/\n     public Map<String, Object> createToken(User loginUser, int userId, String expireTime, String token) {\n         Map<String, Object> result = new HashMap<>(5);\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\n+\n+        if (!hasPerm(loginUser,userId)){\n+            putMsg(result, Status.USER_NO_OPERATION_PERM);\n             return result;\n         }\n \n@@ -140,10 +142,6 @@ public Map<String, Object> generateToken(User loginUser, int userId, String expi\n     public Map<String, Object> delAccessTokenById(User loginUser, int id) {\n         Map<String, Object> result = new HashMap<>(5);\n \n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\n-            return result;\n-        }\n-\n         AccessToken accessToken = accessTokenMapper.selectById(id);\n \n         if (accessToken == null) {\n@@ -152,8 +150,7 @@ public Map<String, Object> delAccessTokenById(User loginUser, int id) {\n             return result;\n         }\n \n-        if (loginUser.getId() != accessToken.getUserId() &&\n-                loginUser.getUserType() != UserType.ADMIN_USER) {\n+        if (!hasPerm(loginUser,accessToken.getUserId())){\n             putMsg(result, Status.USER_NO_OPERATION_PERM);\n             return result;\n         }\n@@ -176,9 +173,11 @@ public Map<String, Object> delAccessTokenById(User loginUser, int id) {\n     public Map<String, Object> updateToken(User loginUser, int id, int userId, String expireTime, String token) {\n         Map<String, Object> result = new HashMap<>(5);\n \n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\n+        if (!hasPerm(loginUser,userId)){\n+            putMsg(result, Status.USER_NO_OPERATION_PERM);\n             return result;\n         }\n+\n         AccessToken accessToken = accessTokenMapper.selectById(id);\n         if (accessToken == null) {\n             logger.error(\"access token not exist,  access token id {}\", id);"
        },
        {
            "index":661,
            "vuln_id":"GHSA-8p36-q63g-68qh",
            "cwe_id":"{'CWE-915'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/mitreid-connect\/OpenID-Connect-Java-Spring-Server\/commit\/7eba3c12fed82388f917e8dd9b73e86e3a311e4c'}",
            "dataset":"osv",
            "summary":"Autobinding vulnerability in MITREid Connect org\/mitre\/oauth2\/web\/OAuthConfirmationController.java in the OpenID Connect server implementation for MITREid Connect through 1.3.3 contains a Mass Assignment (aka Autobinding) vulnerability. This arises due to unsafe usage of the @ModelAttribute annotation during the OAuth authorization flow, in which HTTP request parameters affect an authorizationRequest.",
            "published_date":"2021-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/mitreid-connect\/OpenID-Connect-Java-Spring-Server",
            "commit_href":"https:\/\/github.com\/mitreid-connect\/OpenID-Connect-Java-Spring-Server\/commit\/7eba3c12fed82388f917e8dd9b73e86e3a311e4c",
            "commit_sha":"7eba3c12fed82388f917e8dd9b73e86e3a311e4c",
            "patch":"SINGLE",
            "chain_ord":"['7eba3c12fed82388f917e8dd9b73e86e3a311e4c']",
            "before_first_fix_commit":"{'0d4ef2cb4f77bea5df9e2d4f1cfff4dffb7045c0'}",
            "last_fix_commit":"7eba3c12fed82388f917e8dd9b73e86e3a311e4c",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/12\/2021, 15:22:12",
            "message":"Fix Spring Autobinding vulnerability\n\n1. Make authorizationRequest no longer affected by http request parameters due to @ModelAttribute. See http:\/\/agrrrdog.blogspot.com\/2017\/03\/autobinding-vulns-and-spring-mvc.html",
            "author":"Michael Stepankin",
            "comments":"{'com_1': {'author': 'abergmann', 'datetime': '02\/24\/2021, 07:32:35', 'body': '[CVE-2021-27582](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-27582) was assigned to this commit.'}}",
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'openid-connect-server\/src\/main\/java\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mitreid-connect\/OpenID-Connect-Java-Spring-Server\/raw\/7eba3c12fed82388f917e8dd9b73e86e3a311e4c\/openid-connect-server%2Fsrc%2Fmain%2Fjava%2Forg%2Fmitre%2Foauth2%2Fweb%2FOAuthConfirmationController.java', 'patch': '@@ -103,9 +103,9 @@ public OAuthConfirmationController(ClientDetailsEntityService clientService) {\\n \\n \\t@PreAuthorize(\"hasRole(\\'ROLE_USER\\')\")\\n \\t@RequestMapping(\"\/oauth\/confirm_access\")\\n-\\tpublic String confimAccess(Map<String, Object> model, @ModelAttribute(\"authorizationRequest\") AuthorizationRequest authRequest,\\n-\\t\\t\\tPrincipal p) {\\n+\\tpublic String confirmAccess(Map<String, Object> model, Principal p) {\\n \\n+\\t\\tAuthorizationRequest authRequest = (AuthorizationRequest) model.get(\"authorizationRequest\");\\n \\t\\t\/\/ Check the \"prompt\" parameter to see if we need to do special processing\\n \\n \\t\\tString prompt = (String)authRequest.getExtensions().get(PROMPT);'}}",
            "message_norm":"fix spring autobinding vulnerability\n\n1. make authorizationrequest no longer affected by http request parameters due to @modelattribute. see http:\/\/agrrrdog.blogspot.com\/2017\/03\/autobinding-vulns-and-spring-mvc.html",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('http:\/\/agrrrdog.blogspot.com\/2017\/03\/autobinding-vulns-and-spring-mvc.html', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['openid-connect-server\/src\/main\/java\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java'])",
            "num_files":1.0,
            "patch_content":"From 7eba3c12fed82388f917e8dd9b73e86e3a311e4c Mon Sep 17 00:00:00 2001\nFrom: Michael Stepankin <artsploit@gmail.com>\nDate: Fri, 12 Feb 2021 15:22:12 +0000\nSubject: [PATCH] Fix Spring Autobinding vulnerability\n\n1. Make authorizationRequest no longer affected by http request parameters due to @ModelAttribute. See http:\/\/agrrrdog.blogspot.com\/2017\/03\/autobinding-vulns-and-spring-mvc.html\n---\n ...\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java     | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/openid-connect-server\/src\/main\/java\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java b\/openid-connect-server\/src\/main\/java\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java\nindex d89464690c..29c9a1419e 100644\n--- a\/openid-connect-server\/src\/main\/java\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java\n+++ b\/openid-connect-server\/src\/main\/java\/org\/mitre\/oauth2\/web\/OAuthConfirmationController.java\n@@ -103,9 +103,9 @@ public OAuthConfirmationController(ClientDetailsEntityService clientService) {\n \n \t@PreAuthorize(\"hasRole('ROLE_USER')\")\n \t@RequestMapping(\"\/oauth\/confirm_access\")\n-\tpublic String confimAccess(Map<String, Object> model, @ModelAttribute(\"authorizationRequest\") AuthorizationRequest authRequest,\n-\t\t\tPrincipal p) {\n+\tpublic String confirmAccess(Map<String, Object> model, Principal p) {\n \n+\t\tAuthorizationRequest authRequest = (AuthorizationRequest) model.get(\"authorizationRequest\");\n \t\t\/\/ Check the \"prompt\" parameter to see if we need to do special processing\n \n \t\tString prompt = (String)authRequest.getExtensions().get(PROMPT);"
        },
        {
            "index":113,
            "vuln_id":"GHSA-cgfm-62j4-v4rf",
            "cwe_id":"{'CWE-125'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750'}",
            "dataset":"osv",
            "summary":"Heap out of bounds access in sparse reduction operations ### Impact\nThe implementation of sparse reduction operations in TensorFlow can trigger accesses outside of bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\nx = tf.SparseTensor(\n      indices=[[773, 773, 773], [773, 773, 773]],\n      values=[1, 1],\n      dense_shape=[337, 337, 337])\ntf.sparse.reduce_sum(x, 1)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1bc56203f21a5a4995311825ffaba7a670d7747\/tensorflow\/core\/kernels\/sparse_reduce_op.cc#L217-L228) fails to validate that each reduction group does not overflow and that each corresponding index does not point to outside the bounds of the input tensor.\n\n### Patches\nWe have patched the issue in GitHub commit [87158f43f05f2720a374f3e6d22a7aaa3a33f750](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750). \n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750",
            "commit_sha":"87158f43f05f2720a374f3e6d22a7aaa3a33f750",
            "patch":"SINGLE",
            "chain_ord":"['87158f43f05f2720a374f3e6d22a7aaa3a33f750']",
            "before_first_fix_commit":"{'9c7f40e5f1b5b74156ad4d7bc20b8d69bdedbe29'}",
            "last_fix_commit":"87158f43f05f2720a374f3e6d22a7aaa3a33f750",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/31\/2021, 04:11:18",
            "message":"Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
            "files":"{'tensorflow\/core\/kernels\/sparse_reduce_op.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/87158f43f05f2720a374f3e6d22a7aaa3a33f750\/tensorflow%2Fcore%2Fkernels%2Fsparse_reduce_op.cc', 'patch': '@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\\n     sp.Reorder<T>(reduction.reorder_dims);\\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\\n+      OP_REQUIRES(ctx,\\n+                  output_strides.empty() ||\\n+                  (g.group().size() == output_strides.size()),\\n+                  errors::Internal(\\n+                      \"Expected group size and output_strides size to match\",\\n+                      \", but got \", g.group().size(), \" and \",\\n+                      output_strides.size()));\\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\\n+      OP_REQUIRES(ctx,\\n+                  idx >= 0 && idx < out_flat.size(),\\n+                  errors::Internal(\\n+                      \"Obtained a write index of \", idx,\\n+                      \" which is outside of bounds of [0, \",\\n+                      out_flat.size(), \")\"));\\n       out_flat(idx) = reduced_val();\\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"'}}",
            "message_norm":"prevent heap oob in sparse reduction ops.\n\npiperorigin-revid: 387934524\nchange-id: i894aa30f1e454f09b471d565b4a325da49322c1a",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('387934524', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_reduce_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 87158f43f05f2720a374f3e6d22a7aaa3a33f750 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 21:11:18 -0700\nSubject: [PATCH] Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a\n---\n tensorflow\/core\/kernels\/sparse_reduce_op.cc | 13 +++++++++++++\n 1 file changed, 13 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_reduce_op.cc b\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\nindex 668ea5ae54084c..430be0a271742e 100644\n--- a\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\n@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\n     sp.Reorder<T>(reduction.reorder_dims);\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n+      OP_REQUIRES(ctx,\n+                  output_strides.empty() ||\n+                  (g.group().size() == output_strides.size()),\n+                  errors::Internal(\n+                      \"Expected group size and output_strides size to match\",\n+                      \", but got \", g.group().size(), \" and \",\n+                      output_strides.size()));\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n+      OP_REQUIRES(ctx,\n+                  idx >= 0 && idx < out_flat.size(),\n+                  errors::Internal(\n+                      \"Obtained a write index of \", idx,\n+                      \" which is outside of bounds of [0, \",\n+                      out_flat.size(), \")\"));\n       out_flat(idx) = reduced_val();\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \""
        },
        {
            "index":339,
            "vuln_id":"GHSA-2p9q-h29j-3f5v",
            "cwe_id":"{'CWE-20'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/290bb05c80c327ed74fae1d089f1001b1e2a4ef7'}",
            "dataset":"osv",
            "summary":"Missing validation causes `TensorSummaryV2` to crash ### Impact\nThe implementation of [`tf.raw_ops.TensorSummaryV2`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f3b9bf4c3c0597563b289c0512e98d4ce81f886e\/tensorflow\/core\/kernels\/summary_tensor_op.cc#L33-L58) does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack:\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\ntf.raw_ops.TensorSummaryV2(\n  tag=np.array('test'),\n  tensor=np.array(3),\n  serialized_summary_metadata=tf.io.encode_base64(np.empty((0))))\n```\n\nThe code assumes `axis` is a scalar but there is no validation for this.\n\n```cc\n    const Tensor& serialized_summary_metadata_tensor = c->input(2);\n    \/\/ ...\n    ParseFromTString(serialized_summary_metadata_tensor.scalar<tstring>()(),\n                     v->mutable_metadata());\n``` \n\n### Patches\nWe have patched the issue in GitHub commit [290bb05c80c327ed74fae1d089f1001b1e2a4ef7](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/290bb05c80c327ed74fae1d089f1001b1e2a4ef7).\n    \nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n    \n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by Neophytos Christou from Secure Systems Lab at Brown University and Hong Jin from Singapore Management University.",
            "published_date":"2022-05-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/290bb05c80c327ed74fae1d089f1001b1e2a4ef7",
            "commit_sha":"290bb05c80c327ed74fae1d089f1001b1e2a4ef7",
            "patch":"SINGLE",
            "chain_ord":"['290bb05c80c327ed74fae1d089f1001b1e2a4ef7']",
            "before_first_fix_commit":"{'263ad6ad211921b34c5fa5c3460e177d855d1101'}",
            "last_fix_commit":"290bb05c80c327ed74fae1d089f1001b1e2a4ef7",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 18:02:25",
            "message":"Fix tf.raw_ops.TensorSummaryV2 vulnerability with invalid serialized_summary_metadata.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445197183",
            "author":"Alan Liu",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/summary_tensor_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/290bb05c80c327ed74fae1d089f1001b1e2a4ef7\/tensorflow%2Fcore%2Fkernels%2Fsummary_tensor_op.cc', 'patch': '@@ -36,6 +36,10 @@ class SummaryTensorOpV2 : public OpKernel {\\n                 errors::InvalidArgument(\"tag must be scalar\"));\\n     const Tensor& tensor = c->input(1);\\n     const Tensor& serialized_summary_metadata_tensor = c->input(2);\\n+    OP_REQUIRES(\\n+        c,\\n+        TensorShapeUtils::IsScalar(serialized_summary_metadata_tensor.shape()),\\n+        errors::InvalidArgument(\"serialized_summary_metadata must be scalar\"));\\n \\n     Summary s;\\n     Summary::Value* v = s.add_value();'}}",
            "message_norm":"fix tf.raw_ops.tensorsummaryv2 vulnerability with invalid serialized_summary_metadata.\n\ncheck that input is actually a scalar before treating it as such.\n\npiperorigin-revid: 445197183",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('serialized_summary_metadata', 'SECWORD', ''), ('445197183', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/summary_tensor_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 290bb05c80c327ed74fae1d089f1001b1e2a4ef7 Mon Sep 17 00:00:00 2001\nFrom: Alan Liu <liualan@google.com>\nDate: Thu, 28 Apr 2022 11:02:25 -0700\nSubject: [PATCH] Fix tf.raw_ops.TensorSummaryV2 vulnerability with invalid\n serialized_summary_metadata.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445197183\n---\n tensorflow\/core\/kernels\/summary_tensor_op.cc | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/summary_tensor_op.cc b\/tensorflow\/core\/kernels\/summary_tensor_op.cc\nindex e367045b02ab48..730ef6f38e5d62 100644\n--- a\/tensorflow\/core\/kernels\/summary_tensor_op.cc\n+++ b\/tensorflow\/core\/kernels\/summary_tensor_op.cc\n@@ -36,6 +36,10 @@ class SummaryTensorOpV2 : public OpKernel {\n                 errors::InvalidArgument(\"tag must be scalar\"));\n     const Tensor& tensor = c->input(1);\n     const Tensor& serialized_summary_metadata_tensor = c->input(2);\n+    OP_REQUIRES(\n+        c,\n+        TensorShapeUtils::IsScalar(serialized_summary_metadata_tensor.shape()),\n+        errors::InvalidArgument(\"serialized_summary_metadata must be scalar\"));\n \n     Summary s;\n     Summary::Value* v = s.add_value();"
        },
        {
            "index":924,
            "vuln_id":"GHSA-5f2r-qp73-37mr",
            "cwe_id":"{'CWE-617'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/92dba16749fae36c246bec3f9ba474d9ddeb7662'}",
            "dataset":"osv",
            "summary":"`CHECK`-failures during Grappler's `SafeToRemoveIdentity` in Tensorflow ### Impact\nThe Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that [`SafeToRemoveIdentity`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc#L59-L98) would trigger `CHECK` failures.\n\n### Patches\nWe have patched the issue in GitHub commit [92dba16749fae36c246bec3f9ba474d9ddeb7662](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/92dba16749fae36c246bec3f9ba474d9ddeb7662).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/92dba16749fae36c246bec3f9ba474d9ddeb7662",
            "commit_sha":"92dba16749fae36c246bec3f9ba474d9ddeb7662",
            "patch":"SINGLE",
            "chain_ord":"['92dba16749fae36c246bec3f9ba474d9ddeb7662']",
            "before_first_fix_commit":"{'1cda4d4a26acea3814d06e7d9525772ab357fc1c'}",
            "last_fix_commit":"92dba16749fae36c246bec3f9ba474d9ddeb7662",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/11\/2021, 18:43:29",
            "message":"Prevent a null-pointer dereference \/ `CHECK`-fail in grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/92dba16749fae36c246bec3f9ba474d9ddeb7662\/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdependency_optimizer.cc', 'patch': '@@ -75,8 +75,10 @@ bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\\n   }\\n \\n   const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\\n-  CHECK(input != nullptr) << \"node = \" << node.name()\\n-                          << \" input = \" << node.input(0);\\n+  if (input == nullptr) {\\n+    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\\n+    return false;\\n+  }\\n   \/\/ Don\\'t remove Identity nodes corresponding to Variable reads or following\\n   \/\/ Recv.\\n   if (IsVariable(*input) || IsRecv(*input)) {'}}",
            "message_norm":"prevent a null-pointer dereference \/ `check`-fail in grappler.\n\npiperorigin-revid: 409187354\nchange-id: i369c249cca32e6c56ec193f0ebbf2f2768fc7d43",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('null-pointer dereference', 'SECWORD', ''), ('409187354', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc'])",
            "num_files":1.0,
            "patch_content":"From 92dba16749fae36c246bec3f9ba474d9ddeb7662 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 11 Nov 2021 10:43:29 -0800\nSubject: [PATCH] Prevent a null-pointer dereference \/ `CHECK`-fail in\n grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43\n---\n tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc | 6 ++++--\n 1 file changed, 4 insertions(+), 2 deletions(-)\n\ndiff --git a\/tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc b\/tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc\nindex aadea833a4fc48..bfd98a58a77718 100644\n--- a\/tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc\n+++ b\/tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc\n@@ -75,8 +75,10 @@ bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n   }\n \n   const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n-  CHECK(input != nullptr) << \"node = \" << node.name()\n-                          << \" input = \" << node.input(0);\n+  if (input == nullptr) {\n+    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\n+    return false;\n+  }\n   \/\/ Don't remove Identity nodes corresponding to Variable reads or following\n   \/\/ Recv.\n   if (IsVariable(*input) || IsRecv(*input)) {"
        },
        {
            "index":236,
            "vuln_id":"GHSA-6fvx-r7hx-3vh6",
            "cwe_id":"{'CWE-611'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/javamelody\/javamelody\/commit\/ef111822562d0b9365bd3e671a75b65bd0613353'}",
            "dataset":"osv",
            "summary":"JavaMelody has XXE via parseSoapMethodName in bull\/javamelody\/PayloadNameRequestWrapper.java. JavaMelody before 1.74.0 has XXE via parseSoapMethodName in bull\/javamelody\/PayloadNameRequestWrapper.java.",
            "published_date":"2018-10-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/javamelody\/javamelody",
            "commit_href":"https:\/\/github.com\/javamelody\/javamelody\/commit\/ef111822562d0b9365bd3e671a75b65bd0613353",
            "commit_sha":"ef111822562d0b9365bd3e671a75b65bd0613353",
            "patch":"SINGLE",
            "chain_ord":"['ef111822562d0b9365bd3e671a75b65bd0613353']",
            "before_first_fix_commit":"{'00dd8d51a6483cb3a5b4c8ae9c24197028401c58'}",
            "last_fix_commit":"ef111822562d0b9365bd3e671a75b65bd0613353",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/04\/2018, 06:31:29",
            "message":"fix for security",
            "author":"evernat",
            "comments":"{'com_1': {'author': 'abergmann', 'datetime': '10\/12\/2018, 08:21:37', 'body': '[CVE-2018-15531](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2018-15531) was assigned to this issue.'}}",
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'javamelody-core\/src\/main\/java\/net\/bull\/javamelody\/PayloadNameRequestWrapper.java': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/javamelody\/javamelody\/raw\/ef111822562d0b9365bd3e671a75b65bd0613353\/javamelody-core%2Fsrc%2Fmain%2Fjava%2Fnet%2Fbull%2Fjavamelody%2FPayloadNameRequestWrapper.java', 'patch': '@@ -235,6 +235,8 @@ private static String parseSoapMethodName(InputStream stream, String charEncodin\\n \\t\\ttry {\\r\\n \\t\\t\\t\/\/ newInstance() et pas newFactory() pour java 1.5 (issue 367)\\r\\n \\t\\t\\tfinal XMLInputFactory factory = XMLInputFactory.newInstance();\\r\\n+\\t\\t\\tfactory.setProperty(XMLInputFactory.SUPPORT_DTD, false); \/\/ disable DTDs entirely for that factory\\r\\n+\\t\\t\\tfactory.setProperty(XMLInputFactory.IS_SUPPORTING_EXTERNAL_ENTITIES, false); \/\/ disable external entities\\r\\n \\t\\t\\tfinal XMLStreamReader xmlReader;\\r\\n \\t\\t\\tif (charEncoding != null) {\\r\\n \\t\\t\\t\\txmlReader = factory.createXMLStreamReader(stream, charEncoding);'}}",
            "message_norm":"fix for security",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('security', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['javamelody-core\/src\/main\/java\/net\/bull\/javamelody\/PayloadNameRequestWrapper.java'])",
            "num_files":1.0,
            "patch_content":"From ef111822562d0b9365bd3e671a75b65bd0613353 Mon Sep 17 00:00:00 2001\nFrom: evernat <evernat@free.fr>\nDate: Tue, 4 Sep 2018 08:31:29 +0200\nSubject: [PATCH] fix for security\n\n---\n ...\/java\/net\/bull\/javamelody\/PayloadNameRequestWrapper.java     | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/javamelody-core\/src\/main\/java\/net\/bull\/javamelody\/PayloadNameRequestWrapper.java b\/javamelody-core\/src\/main\/java\/net\/bull\/javamelody\/PayloadNameRequestWrapper.java\nindex c2affb3bc..f03c1419f 100644\n--- a\/javamelody-core\/src\/main\/java\/net\/bull\/javamelody\/PayloadNameRequestWrapper.java\n+++ b\/javamelody-core\/src\/main\/java\/net\/bull\/javamelody\/PayloadNameRequestWrapper.java\n@@ -235,6 +235,8 @@ private static String parseSoapMethodName(InputStream stream, String charEncodin\n \t\ttry {\r\n \t\t\t\/\/ newInstance() et pas newFactory() pour java 1.5 (issue 367)\r\n \t\t\tfinal XMLInputFactory factory = XMLInputFactory.newInstance();\r\n+\t\t\tfactory.setProperty(XMLInputFactory.SUPPORT_DTD, false); \/\/ disable DTDs entirely for that factory\r\n+\t\t\tfactory.setProperty(XMLInputFactory.IS_SUPPORTING_EXTERNAL_ENTITIES, false); \/\/ disable external entities\r\n \t\t\tfinal XMLStreamReader xmlReader;\r\n \t\t\tif (charEncoding != null) {\r\n \t\t\t\txmlReader = factory.createXMLStreamReader(stream, charEncoding);"
        },
        {
            "index":76,
            "vuln_id":"GHSA-6hjc-m38h-7jhh",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/4e46b792ce973ac0c652fb330055f41aca1981c8', 'https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in SEOmatic plugin A cross-site scripting (XSS) vulnerability in the SEOmatic plugin 3.4.10 for Craft CMS 3 allows remote attackers to inject arbitrary web script via a GET to \/index.php?action=seomatic\/file\/seo-file-link with url parameter containing the base64 encoded URL of a malicious web page \/ file and fileName parameter containing an arbitrary filename with the intended content-type to be rendered in the user's browser as the extension.",
            "published_date":"2022-06-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/nystudio107\/craft-seomatic",
            "commit_href":"https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/4e46b792ce973ac0c652fb330055f41aca1981c8",
            "commit_sha":"4e46b792ce973ac0c652fb330055f41aca1981c8",
            "patch":"MULTI",
            "chain_ord":"['5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873', '4e46b792ce973ac0c652fb330055f41aca1981c8']",
            "before_first_fix_commit":"{'8c0dc48d026fd076cd0a8fae917bdadc8d67cfa6'}",
            "last_fix_commit":"4e46b792ce973ac0c652fb330055f41aca1981c8",
            "chain_ord_pos":2.0,
            "commit_datetime":"09\/24\/2021, 15:01:54",
            "message":"Disallow SVGs",
            "author":"Andrew Welch",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/controllers\/FileController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nystudio107\/craft-seomatic\/raw\/4e46b792ce973ac0c652fb330055f41aca1981c8\/src%2Fcontrollers%2FFileController.php', 'patch': \"@@ -96,7 +96,7 @@ public function actionSeoFileLink($url, $robots = '', $canonical = '', $inline =\\n             if (($ext = pathinfo($fileName, PATHINFO_EXTENSION)) !== '') {\\n                 $ext = strtolower($ext);\\n             }\\n-            if ($ext === '' || !in_array($ext, $allowedExtensions, true)) {\\n+            if ($ext === '' || $ext === 'svg' || !in_array($ext, $allowedExtensions, true)) {\\n                 throw new ServerErrorHttpException(Craft::t('seomatic', 'File format not allowed.'));\\n             }\\n             \/\/ Send the file as a stream, so it can exist anywhere\"}}",
            "message_norm":"disallow svgs",
            "language":"it",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/controllers\/FileController.php'])",
            "num_files":1.0,
            "patch_content":"From 4e46b792ce973ac0c652fb330055f41aca1981c8 Mon Sep 17 00:00:00 2001\nFrom: Andrew Welch <andrew@keluli.local>\nDate: Fri, 24 Sep 2021 11:01:54 -0400\nSubject: [PATCH] Disallow SVGs\n\n---\n src\/controllers\/FileController.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/controllers\/FileController.php b\/src\/controllers\/FileController.php\nindex 33d7f0582..43315dfa6 100644\n--- a\/src\/controllers\/FileController.php\n+++ b\/src\/controllers\/FileController.php\n@@ -96,7 +96,7 @@ public function actionSeoFileLink($url, $robots = '', $canonical = '', $inline =\n             if (($ext = pathinfo($fileName, PATHINFO_EXTENSION)) !== '') {\n                 $ext = strtolower($ext);\n             }\n-            if ($ext === '' || !in_array($ext, $allowedExtensions, true)) {\n+            if ($ext === '' || $ext === 'svg' || !in_array($ext, $allowedExtensions, true)) {\n                 throw new ServerErrorHttpException(Craft::t('seomatic', 'File format not allowed.'));\n             }\n             \/\/ Send the file as a stream, so it can exist anywhere"
        },
        {
            "index":152,
            "vuln_id":"GHSA-q3g3-h9r4-prrc",
            "cwe_id":"{'CWE-125'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr and heap OOB in binary cwise ops ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations):\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.SqrtGrad(y=[4, 16],dy=[])\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/cwise_ops_common.h#L264) assumes that the two inputs have exactly the same number of elements but does not check that. Hence, when the eigen functor executes it triggers heap OOB reads and undefined behavior due to binding to nullptr.\n\n### Patches\nWe have patched the issue in GitHub commit [93f428fd1768df147171ed674fee1fc5ab8309ec](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo  360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec",
            "commit_sha":"93f428fd1768df147171ed674fee1fc5ab8309ec",
            "patch":"SINGLE",
            "chain_ord":"['93f428fd1768df147171ed674fee1fc5ab8309ec']",
            "before_first_fix_commit":"{'bc9c546ce7015c57c2f15c168b3d9201de679a1d'}",
            "last_fix_commit":"93f428fd1768df147171ed674fee1fc5ab8309ec",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/31\/2021, 04:42:36",
            "message":"Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/cwise_ops_common.h': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/93f428fd1768df147171ed674fee1fc5ab8309ec\/tensorflow%2Fcore%2Fkernels%2Fcwise_ops_common.h', 'patch': '@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& in0 = ctx->input(0);\\n     const Tensor& in1 = ctx->input(1);\\n+    OP_REQUIRES(\\n+        ctx, in0.NumElements() == in1.NumElements(),\\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\\n+                                \"same number of elements, got \",\\n+                                in0.NumElements(), \" and \", in1.NumElements()));\\n     auto in0_flat = in0.flat<Tin>();\\n     auto in1_flat = in1.flat<Tin>();\\n     const Device& eigen_device = ctx->eigen_device<Device>();'}}",
            "message_norm":"fix nullptr deref and heap oob access in binary cwise ops.\n\npiperorigin-revid: 387936777\nchange-id: i608b8074cec36a982cca622b7144cb2c43e6e19f",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('heap oob', 'SECWORD', ''), ('387936777', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/cwise_ops_common.h'])",
            "num_files":1.0,
            "patch_content":"From 93f428fd1768df147171ed674fee1fc5ab8309ec Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 21:42:36 -0700\nSubject: [PATCH] Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f\n---\n tensorflow\/core\/kernels\/cwise_ops_common.h | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/cwise_ops_common.h b\/tensorflow\/core\/kernels\/cwise_ops_common.h\nindex 9adc628421d046..4f2c83322ba00f 100644\n--- a\/tensorflow\/core\/kernels\/cwise_ops_common.h\n+++ b\/tensorflow\/core\/kernels\/cwise_ops_common.h\n@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();"
        },
        {
            "index":380,
            "vuln_id":"GHSA-hm37-9xh2-q499",
            "cwe_id":"{'CWE-209'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/scottcwang\/openssh_key_parser\/commit\/d5b53b4b7e76c5b666fc657019dbf864fb04076c', 'https:\/\/github.com\/scottcwang\/openssh_key_parser\/commit\/26e0a471e9fdb23e635bc3014cf4cbd2323a08d3', 'https:\/\/github.com\/scottcwang\/openssh_key_parser\/commit\/274447f91b4037b7050ae634879b657554523b39'}",
            "dataset":"osv",
            "summary":"Possible leak of key's raw field if declared length is incorrect ### Impact\nIf a field of a key is shorter than it is declared to be, the parser raises an error with a message containing the raw field value. An attacker able to modify the declared length of a key's sensitive field can thus expose the raw value of that field.\n\n### Patches\nUpgrade to version 0.0.6, which no longer includes the raw field value in the error message.\n\n### Workarounds\nN\/A\n\n### References\nN\/A\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [openssh_key_parser](https:\/\/github.com\/scottcwang\/openssh_key_parser)",
            "published_date":"2022-07-06",
            "chain_len":3,
            "project":"https:\/\/github.com\/scottcwang\/openssh_key_parser",
            "commit_href":"https:\/\/github.com\/scottcwang\/openssh_key_parser\/commit\/d5b53b4b7e76c5b666fc657019dbf864fb04076c",
            "commit_sha":"d5b53b4b7e76c5b666fc657019dbf864fb04076c",
            "patch":"MULTI",
            "chain_ord":"['26e0a471e9fdb23e635bc3014cf4cbd2323a08d3', 'd5b53b4b7e76c5b666fc657019dbf864fb04076c', '274447f91b4037b7050ae634879b657554523b39']",
            "before_first_fix_commit":"{'ae4d131d1cd8fe06325bfd6b749305aca60873bf', '69fe5b7addc21d3f39626ae93c6961811aea9d4c'}",
            "last_fix_commit":"274447f91b4037b7050ae634879b657554523b39",
            "chain_ord_pos":2.0,
            "commit_datetime":"06\/22\/2022, 14:59:49",
            "message":"Improved error handling to prevent unhandled exceptions in calling code.",
            "author":"Michael Doyle",
            "comments":null,
            "stats":"{'additions': 95, 'deletions': 86, 'total': 181}",
            "files":"{'openssh_key\/private_key_list.py': {'additions': 95, 'deletions': 86, 'changes': 181, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/scottcwang\/openssh_key_parser\/raw\/d5b53b4b7e76c5b666fc657019dbf864fb04076c\/openssh_key%2Fprivate_key_list.py', 'patch': '@@ -221,118 +221,127 @@ def from_bytes(\\n \\n         Raises:\\n             ValueError: The provided byte string is not an ``openssh-key-v1``\\n-                key list or the declared key count is negative.\\n+                key list, when the declared key count is negative, or when an\\n+                EOF is found while parsing the key.\\n+\\n             UserWarning: The check numbers in the decrypted private byte string\\n                 do not match (likely due to an incorrect passphrase), the key\\n                 type or parameter values of a private key do not match that of\\n                 the corresponding public key in the list, or the padding bytes\\n                 at the end of the decrypted private byte string are not as\\n                 expected.\\n         \"\"\"\\n-        byte_stream = PascalStyleByteStream(byte_string)\\n+        try:\\n+            byte_stream = PascalStyleByteStream(byte_string)\\n \\n-        header = byte_stream.read_from_format_instructions_dict(\\n-            cls.HEADER_FORMAT_INSTRUCTIONS_DICT\\n-        )\\n+            header = byte_stream.read_from_format_instructions_dict(\\n+                cls.HEADER_FORMAT_INSTRUCTIONS_DICT\\n+            )\\n+\\n+            if header[\\'auth_magic\\'] != b\\'openssh-key-v1\\\\x00\\':\\n+                raise ValueError(\\'Not an openssh-key-v1 key\\')\\n \\n-        if header[\\'auth_magic\\'] != b\\'openssh-key-v1\\\\x00\\':\\n-            raise ValueError(\\'Not an openssh-key-v1 key\\')\\n+            num_keys = header[\\'num_keys\\']\\n \\n-        num_keys = header[\\'num_keys\\']\\n+            if num_keys < 0:\\n+                raise ValueError(\\'Cannot parse negative number of keys\\')\\n \\n-        if num_keys < 0:\\n-            raise ValueError(\\'Cannot parse negative number of keys\\')\\n+            public_key_list = []\\n+            for i in range(num_keys):\\n+                public_key_bytes = byte_stream.read_from_format_instruction(\\n+                    PascalStyleFormatInstruction.BYTES\\n+                )\\n+                public_key_list.append(\\n+                    PublicKey.from_bytes(public_key_bytes)\\n+                )\\n \\n-        public_key_list = []\\n-        for i in range(num_keys):\\n-            public_key_bytes = byte_stream.read_from_format_instruction(\\n+            cipher_bytes = byte_stream.read_from_format_instruction(\\n                 PascalStyleFormatInstruction.BYTES\\n             )\\n-            public_key_list.append(\\n-                PublicKey.from_bytes(public_key_bytes)\\n-            )\\n \\n-        cipher_bytes = byte_stream.read_from_format_instruction(\\n-            PascalStyleFormatInstruction.BYTES\\n-        )\\n-\\n-        kdf_class = get_kdf_options_class(header[\\'kdf\\'])\\n-        kdf_options = kdf_class(\\n-            PascalStyleByteStream(\\n-                header[\\'kdf_options\\']\\n-            ).read_from_format_instructions_dict(\\n-                kdf_class.FORMAT_INSTRUCTIONS_DICT\\n+            kdf_class = get_kdf_options_class(header[\\'kdf\\'])\\n+            kdf_options = kdf_class(\\n+                PascalStyleByteStream(\\n+                    header[\\'kdf_options\\']\\n+                ).read_from_format_instructions_dict(\\n+                    kdf_class.FORMAT_INSTRUCTIONS_DICT\\n+                )\\n             )\\n-        )\\n \\n-        cipher_class = get_cipher_class(header[\\'cipher\\'])\\n+            cipher_class = get_cipher_class(header[\\'cipher\\'])\\n \\n-        if kdf_class == NoneKDFOptions:\\n-            passphrase = \\'\\'\\n-        elif passphrase is None:\\n-            passphrase = getpass.getpass(\\'Key passphrase: \\')\\n+            if kdf_class == NoneKDFOptions:\\n+                passphrase = \\'\\'\\n+            elif passphrase is None:\\n+                passphrase = getpass.getpass(\\'Key passphrase: \\')\\n \\n-        if issubclass(cipher_class, ConfidentialityIntegrityCipher):\\n-            cipher_bytes += byte_stream.read_fixed_bytes(\\n-                cipher_class.TAG_LENGTH\\n-            )\\n-\\n-        decipher_bytes = cipher_class.decrypt(\\n-            kdf_class(kdf_options),\\n-            passphrase,\\n-            cipher_bytes\\n-        )\\n-\\n-        decipher_byte_stream = PascalStyleByteStream(decipher_bytes)\\n+            if issubclass(cipher_class, ConfidentialityIntegrityCipher):\\n+                cipher_bytes += byte_stream.read_fixed_bytes(\\n+                    cipher_class.TAG_LENGTH\\n+                )\\n \\n-        decipher_bytes_header = \\\\\\n-            decipher_byte_stream.read_from_format_instructions_dict(\\n-                cls.DECIPHER_BYTES_HEADER_FORMAT_INSTRUCTIONS_DICT\\n+            decipher_bytes = cipher_class.decrypt(\\n+                kdf_class(kdf_options),\\n+                passphrase,\\n+                cipher_bytes\\n             )\\n \\n-        if decipher_bytes_header[\\'check_int_1\\'] \\\\\\n-                != decipher_bytes_header[\\'check_int_2\\']:\\n-            warnings.warn(\\'Cipher header check numbers do not match\\')\\n+            decipher_byte_stream = PascalStyleByteStream(decipher_bytes)\\n \\n-        initlist = []\\n-        for i in range(num_keys):\\n-            initlist.append(\\n-                PublicPrivateKeyPair(\\n-                    public_key_list[i],\\n-                    PrivateKey.from_byte_stream(decipher_byte_stream)\\n-                )\\n-            )\\n-            if initlist[i].public.header[\\'key_type\\'] \\\\\\n-                    != initlist[i].private.header[\\'key_type\\']:\\n-                warnings.warn(\\n-                    f\\'Inconsistency between private and public \\'\\n-                    f\\'key types for key {i}\\'\\n+            decipher_bytes_header = \\\\\\n+                decipher_byte_stream.read_from_format_instructions_dict(\\n+                    cls.DECIPHER_BYTES_HEADER_FORMAT_INSTRUCTIONS_DICT\\n                 )\\n-            if not all(\\n-                (\\n-                    initlist[i].public.params[k] ==\\n-                    initlist[i].private.params[k]\\n-                ) for k in (\\n-                    initlist[i].public.params.keys() &\\n-                    initlist[i].private.params.keys()\\n+\\n+            if decipher_bytes_header[\\'check_int_1\\'] \\\\\\n+                    != decipher_bytes_header[\\'check_int_2\\']:\\n+                warnings.warn(\\'Cipher header check numbers do not match\\')\\n+\\n+            initlist = []\\n+            for i in range(num_keys):\\n+                initlist.append(\\n+                    PublicPrivateKeyPair(\\n+                        public_key_list[i],\\n+                        PrivateKey.from_byte_stream(decipher_byte_stream)\\n+                    )\\n                 )\\n+                if initlist[i].public.header[\\'key_type\\'] \\\\\\n+                        != initlist[i].private.header[\\'key_type\\']:\\n+                    warnings.warn(\\n+                        f\\'Inconsistency between private and public \\'\\n+                        f\\'key types for key {i}\\'\\n+                    )\\n+                if not all(\\n+                    (\\n+                        initlist[i].public.params[k] ==\\n+                        initlist[i].private.params[k]\\n+                    ) for k in (\\n+                        initlist[i].public.params.keys() &\\n+                        initlist[i].private.params.keys()\\n+                    )\\n+                ):\\n+                    warnings.warn(\\n+                        f\\'Inconsistency between private and public \\'\\n+                        f\\'values for key {i}\\'\\n+                    )\\n+\\n+            decipher_padding = decipher_byte_stream.read()\\n+\\n+            if (\\n+                len(decipher_byte_stream.getvalue()) %\\n+                    cipher_class.BLOCK_SIZE != 0\\n+            ) or not (\\n+                bytes(\\n+                    range(1, 1 + cipher_class.BLOCK_SIZE)\\n+                ).startswith(decipher_padding)\\n             ):\\n-                warnings.warn(\\n-                    f\\'Inconsistency between private and public \\'\\n-                    f\\'values for key {i}\\'\\n-                )\\n-\\n-        decipher_padding = decipher_byte_stream.read()\\n-\\n-        if (\\n-            len(decipher_byte_stream.getvalue()) %\\n-                cipher_class.BLOCK_SIZE != 0\\n-        ) or not (\\n-            bytes(\\n-                range(1, 1 + cipher_class.BLOCK_SIZE)\\n-            ).startswith(decipher_padding)\\n-        ):\\n-            warnings.warn(\\'Incorrect padding at end of ciphertext\\')\\n+                warnings.warn(\\'Incorrect padding at end of ciphertext\\')\\n+        except ValueError as e:\\n+            raise e\\n+        except EOFError as e:\\n+            raise ValueError(\\'Premature EOF detected while parsing key.\\')\\n+        except e:\\n+            raise ValueError(\\'Unexpected error condition reached.\\')\\n \\n         return cls(\\n             initlist,'}}",
            "message_norm":"improved error handling to prevent unhandled exceptions in calling code.",
            "language":"en",
            "entities":"[('improved', 'ACTION', ''), ('error handling', 'SECWORD', ''), ('prevent', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['openssh_key\/private_key_list.py'])",
            "num_files":1.0,
            "patch_content":"From d5b53b4b7e76c5b666fc657019dbf864fb04076c Mon Sep 17 00:00:00 2001\nFrom: Michael Doyle <mike@arnica.io>\nDate: Wed, 22 Jun 2022 10:59:49 -0400\nSubject: [PATCH] Improved error handling to prevent unhandled exceptions in\n calling code.\n\n---\n openssh_key\/private_key_list.py | 181 +++++++++++++++++---------------\n 1 file changed, 95 insertions(+), 86 deletions(-)\n\ndiff --git a\/openssh_key\/private_key_list.py b\/openssh_key\/private_key_list.py\nindex 72613ae..0899378 100644\n--- a\/openssh_key\/private_key_list.py\n+++ b\/openssh_key\/private_key_list.py\n@@ -221,7 +221,9 @@ def from_bytes(\n \n         Raises:\n             ValueError: The provided byte string is not an ``openssh-key-v1``\n-                key list or the declared key count is negative.\n+                key list, when the declared key count is negative, or when an\n+                EOF is found while parsing the key.\n+\n             UserWarning: The check numbers in the decrypted private byte string\n                 do not match (likely due to an incorrect passphrase), the key\n                 type or parameter values of a private key do not match that of\n@@ -229,110 +231,117 @@ def from_bytes(\n                 at the end of the decrypted private byte string are not as\n                 expected.\n         \"\"\"\n-        byte_stream = PascalStyleByteStream(byte_string)\n+        try:\n+            byte_stream = PascalStyleByteStream(byte_string)\n \n-        header = byte_stream.read_from_format_instructions_dict(\n-            cls.HEADER_FORMAT_INSTRUCTIONS_DICT\n-        )\n+            header = byte_stream.read_from_format_instructions_dict(\n+                cls.HEADER_FORMAT_INSTRUCTIONS_DICT\n+            )\n+\n+            if header['auth_magic'] != b'openssh-key-v1\\x00':\n+                raise ValueError('Not an openssh-key-v1 key')\n \n-        if header['auth_magic'] != b'openssh-key-v1\\x00':\n-            raise ValueError('Not an openssh-key-v1 key')\n+            num_keys = header['num_keys']\n \n-        num_keys = header['num_keys']\n+            if num_keys < 0:\n+                raise ValueError('Cannot parse negative number of keys')\n \n-        if num_keys < 0:\n-            raise ValueError('Cannot parse negative number of keys')\n+            public_key_list = []\n+            for i in range(num_keys):\n+                public_key_bytes = byte_stream.read_from_format_instruction(\n+                    PascalStyleFormatInstruction.BYTES\n+                )\n+                public_key_list.append(\n+                    PublicKey.from_bytes(public_key_bytes)\n+                )\n \n-        public_key_list = []\n-        for i in range(num_keys):\n-            public_key_bytes = byte_stream.read_from_format_instruction(\n+            cipher_bytes = byte_stream.read_from_format_instruction(\n                 PascalStyleFormatInstruction.BYTES\n             )\n-            public_key_list.append(\n-                PublicKey.from_bytes(public_key_bytes)\n-            )\n \n-        cipher_bytes = byte_stream.read_from_format_instruction(\n-            PascalStyleFormatInstruction.BYTES\n-        )\n-\n-        kdf_class = get_kdf_options_class(header['kdf'])\n-        kdf_options = kdf_class(\n-            PascalStyleByteStream(\n-                header['kdf_options']\n-            ).read_from_format_instructions_dict(\n-                kdf_class.FORMAT_INSTRUCTIONS_DICT\n+            kdf_class = get_kdf_options_class(header['kdf'])\n+            kdf_options = kdf_class(\n+                PascalStyleByteStream(\n+                    header['kdf_options']\n+                ).read_from_format_instructions_dict(\n+                    kdf_class.FORMAT_INSTRUCTIONS_DICT\n+                )\n             )\n-        )\n \n-        cipher_class = get_cipher_class(header['cipher'])\n+            cipher_class = get_cipher_class(header['cipher'])\n \n-        if kdf_class == NoneKDFOptions:\n-            passphrase = ''\n-        elif passphrase is None:\n-            passphrase = getpass.getpass('Key passphrase: ')\n+            if kdf_class == NoneKDFOptions:\n+                passphrase = ''\n+            elif passphrase is None:\n+                passphrase = getpass.getpass('Key passphrase: ')\n \n-        if issubclass(cipher_class, ConfidentialityIntegrityCipher):\n-            cipher_bytes += byte_stream.read_fixed_bytes(\n-                cipher_class.TAG_LENGTH\n-            )\n-\n-        decipher_bytes = cipher_class.decrypt(\n-            kdf_class(kdf_options),\n-            passphrase,\n-            cipher_bytes\n-        )\n-\n-        decipher_byte_stream = PascalStyleByteStream(decipher_bytes)\n+            if issubclass(cipher_class, ConfidentialityIntegrityCipher):\n+                cipher_bytes += byte_stream.read_fixed_bytes(\n+                    cipher_class.TAG_LENGTH\n+                )\n \n-        decipher_bytes_header = \\\n-            decipher_byte_stream.read_from_format_instructions_dict(\n-                cls.DECIPHER_BYTES_HEADER_FORMAT_INSTRUCTIONS_DICT\n+            decipher_bytes = cipher_class.decrypt(\n+                kdf_class(kdf_options),\n+                passphrase,\n+                cipher_bytes\n             )\n \n-        if decipher_bytes_header['check_int_1'] \\\n-                != decipher_bytes_header['check_int_2']:\n-            warnings.warn('Cipher header check numbers do not match')\n+            decipher_byte_stream = PascalStyleByteStream(decipher_bytes)\n \n-        initlist = []\n-        for i in range(num_keys):\n-            initlist.append(\n-                PublicPrivateKeyPair(\n-                    public_key_list[i],\n-                    PrivateKey.from_byte_stream(decipher_byte_stream)\n-                )\n-            )\n-            if initlist[i].public.header['key_type'] \\\n-                    != initlist[i].private.header['key_type']:\n-                warnings.warn(\n-                    f'Inconsistency between private and public '\n-                    f'key types for key {i}'\n+            decipher_bytes_header = \\\n+                decipher_byte_stream.read_from_format_instructions_dict(\n+                    cls.DECIPHER_BYTES_HEADER_FORMAT_INSTRUCTIONS_DICT\n                 )\n-            if not all(\n-                (\n-                    initlist[i].public.params[k] ==\n-                    initlist[i].private.params[k]\n-                ) for k in (\n-                    initlist[i].public.params.keys() &\n-                    initlist[i].private.params.keys()\n+\n+            if decipher_bytes_header['check_int_1'] \\\n+                    != decipher_bytes_header['check_int_2']:\n+                warnings.warn('Cipher header check numbers do not match')\n+\n+            initlist = []\n+            for i in range(num_keys):\n+                initlist.append(\n+                    PublicPrivateKeyPair(\n+                        public_key_list[i],\n+                        PrivateKey.from_byte_stream(decipher_byte_stream)\n+                    )\n                 )\n+                if initlist[i].public.header['key_type'] \\\n+                        != initlist[i].private.header['key_type']:\n+                    warnings.warn(\n+                        f'Inconsistency between private and public '\n+                        f'key types for key {i}'\n+                    )\n+                if not all(\n+                    (\n+                        initlist[i].public.params[k] ==\n+                        initlist[i].private.params[k]\n+                    ) for k in (\n+                        initlist[i].public.params.keys() &\n+                        initlist[i].private.params.keys()\n+                    )\n+                ):\n+                    warnings.warn(\n+                        f'Inconsistency between private and public '\n+                        f'values for key {i}'\n+                    )\n+\n+            decipher_padding = decipher_byte_stream.read()\n+\n+            if (\n+                len(decipher_byte_stream.getvalue()) %\n+                    cipher_class.BLOCK_SIZE != 0\n+            ) or not (\n+                bytes(\n+                    range(1, 1 + cipher_class.BLOCK_SIZE)\n+                ).startswith(decipher_padding)\n             ):\n-                warnings.warn(\n-                    f'Inconsistency between private and public '\n-                    f'values for key {i}'\n-                )\n-\n-        decipher_padding = decipher_byte_stream.read()\n-\n-        if (\n-            len(decipher_byte_stream.getvalue()) %\n-                cipher_class.BLOCK_SIZE != 0\n-        ) or not (\n-            bytes(\n-                range(1, 1 + cipher_class.BLOCK_SIZE)\n-            ).startswith(decipher_padding)\n-        ):\n-            warnings.warn('Incorrect padding at end of ciphertext')\n+                warnings.warn('Incorrect padding at end of ciphertext')\n+        except ValueError as e:\n+            raise e\n+        except EOFError as e:\n+            raise ValueError('Premature EOF detected while parsing key.')\n+        except e:\n+            raise ValueError('Unexpected error condition reached.')\n \n         return cls(\n             initlist,"
        },
        {
            "index":441,
            "vuln_id":"GHSA-9g3v-j3cr-6fc6",
            "cwe_id":"{'CWE-79'}",
            "score":6.8,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/bda23bb1e66fd7ce42c75c69cf5eea4e80865c1c'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in snipe-it snipe-it is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
            "published_date":"2021-10-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/bda23bb1e66fd7ce42c75c69cf5eea4e80865c1c",
            "commit_sha":"bda23bb1e66fd7ce42c75c69cf5eea4e80865c1c",
            "patch":"SINGLE",
            "chain_ord":"['bda23bb1e66fd7ce42c75c69cf5eea4e80865c1c']",
            "before_first_fix_commit":"{'5d94b99035317cd23059c7af91ff5f38177f5968'}",
            "last_fix_commit":"bda23bb1e66fd7ce42c75c69cf5eea4e80865c1c",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/15\/2021, 16:50:52",
            "message":"Fixes possible XSS on all-file-types export\n\nSigned-off-by: snipe <snipe@snipe.net>",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'resources\/views\/partials\/bootstrap-table.blade.php': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/bda23bb1e66fd7ce42c75c69cf5eea4e80865c1c\/resources%2Fviews%2Fpartials%2Fbootstrap-table.blade.php', 'patch': '@@ -75,6 +75,10 @@ classes: \\'table table-responsive table-no-bordered\\',\\n                 export: \\'fa-download\\',\\n                 clearSearch: \\'fa-times\\'\\n             },\\n+            exportOptions: {\\n+                htmlContent: true,\\n+            },\\n+\\n             exportTypes: [\\'csv\\', \\'excel\\', \\'doc\\', \\'txt\\',\\'json\\', \\'xml\\', \\'pdf\\'],\\n             onLoadSuccess: function () {\\n                 $(\\'[data-toggle=\"tooltip\"]\\').tooltip(); \/\/ Needed to attach tooltips after ajax call'}}",
            "message_norm":"fixes possible xss on all-file-types export\n\nsigned-off-by: snipe <snipe@snipe.net>",
            "language":"en",
            "entities":"[('xss', 'SECWORD', ''), ('snipe@snipe.net', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['resources\/views\/partials\/bootstrap-table.blade.php'])",
            "num_files":1.0,
            "patch_content":"From bda23bb1e66fd7ce42c75c69cf5eea4e80865c1c Mon Sep 17 00:00:00 2001\nFrom: snipe <snipe@snipe.net>\nDate: Fri, 15 Oct 2021 11:50:52 -0500\nSubject: [PATCH] Fixes possible XSS on all-file-types export\n\nSigned-off-by: snipe <snipe@snipe.net>\n---\n resources\/views\/partials\/bootstrap-table.blade.php | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/resources\/views\/partials\/bootstrap-table.blade.php b\/resources\/views\/partials\/bootstrap-table.blade.php\nindex 7ad14bf9059f..130bc9c2d3e1 100644\n--- a\/resources\/views\/partials\/bootstrap-table.blade.php\n+++ b\/resources\/views\/partials\/bootstrap-table.blade.php\n@@ -75,6 +75,10 @@ classes: 'table table-responsive table-no-bordered',\n                 export: 'fa-download',\n                 clearSearch: 'fa-times'\n             },\n+            exportOptions: {\n+                htmlContent: true,\n+            },\n+\n             exportTypes: ['csv', 'excel', 'doc', 'txt','json', 'xml', 'pdf'],\n             onLoadSuccess: function () {\n                 $('[data-toggle=\"tooltip\"]').tooltip(); \/\/ Needed to attach tooltips after ajax call"
        },
        {
            "index":185,
            "vuln_id":"GHSA-fm67-cv37-96ff",
            "cwe_id":"{'CWE-415'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/ultrajson\/ultrajson\/commit\/9c20de0f77b391093967e25d01fb48671104b15b'}",
            "dataset":"osv",
            "summary":"Potential double free of buffer during string decoding ### Impact\n_What kind of vulnerability is it? Who is impacted?_\n\nWhen an error occurs while reallocating the buffer for string decoding, the buffer gets freed twice.\n\nDue to how UltraJSON uses the internal decoder, this double free is impossible to trigger from Python.\n\n### Patches\n_Has the problem been patched? What versions should users upgrade to?_\n\nUsers should upgrade to UltraJSON 5.4.0.\n\n### Workarounds\n_Is there a way for users to fix or remediate the vulnerability without upgrading?_\n\nThere is no workaround.\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [UltraJSON](http:\/\/github.com\/ultrajson\/ultrajson\/issues)",
            "published_date":"2022-07-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/ultrajson\/ultrajson",
            "commit_href":"https:\/\/github.com\/ultrajson\/ultrajson\/commit\/9c20de0f77b391093967e25d01fb48671104b15b",
            "commit_sha":"9c20de0f77b391093967e25d01fb48671104b15b",
            "patch":"SINGLE",
            "chain_ord":"['9c20de0f77b391093967e25d01fb48671104b15b']",
            "before_first_fix_commit":"{'b21da40ead640b6153783dad506e68b4024056ef', '67ec07183342589d602e0fcf7bb1ff3e19272687'}",
            "last_fix_commit":"9c20de0f77b391093967e25d01fb48671104b15b",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/02\/2022, 05:11:59",
            "message":"Merge pull request from GHSA-fm67-cv37-96ff\n\nFix double free on string decoding if realloc fails",
            "author":"Hugo van Kemenade",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/ultrajsondec.c': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ultrajson\/ultrajson\/raw\/9c20de0f77b391093967e25d01fb48671104b15b\/lib%2Fultrajsondec.c', 'patch': '@@ -384,7 +384,7 @@ static FASTCALL_ATTR JSOBJ FASTCALL_MSVC decode_string ( struct DecoderState *ds\\n       escStart = (JSUINT32 *)ds->dec->realloc(ds->escStart, newSize * sizeof(JSUINT32));\\n       if (!escStart)\\n       {\\n-        ds->dec->free(ds->escStart);\\n+        \/\/ Don\\'t free ds->escStart here; it gets handled in JSON_DecodeObject.\\n         return SetError(ds, -1, \"Could not reserve memory block\");\\n       }\\n       ds->escStart = escStart;'}}",
            "message_norm":"merge pull request from ghsa-fm67-cv37-96ff\n\nfix double free on string decoding if realloc fails",
            "language":"en",
            "entities":"[('ghsa-fm67-cv37-96ff', 'VULNID', 'GHSA'), ('double free', 'SECWORD', ''), ('decoding', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/ultrajsondec.c'])",
            "num_files":1.0,
            "patch_content":"From b21da40ead640b6153783dad506e68b4024056ef Mon Sep 17 00:00:00 2001\nFrom: JustAnotherArchivist <JustAnotherArchivist@users.noreply.github.com>\nDate: Mon, 27 Jun 2022 22:26:31 +0000\nSubject: [PATCH] Fix double free on string decoding if realloc fails\n\n---\n lib\/ultrajsondec.c | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/ultrajsondec.c b\/lib\/ultrajsondec.c\nindex 47485a6b..eb4567ed 100644\n--- a\/lib\/ultrajsondec.c\n+++ b\/lib\/ultrajsondec.c\n@@ -384,7 +384,7 @@ static FASTCALL_ATTR JSOBJ FASTCALL_MSVC decode_string ( struct DecoderState *ds\n       escStart = (JSUINT32 *)ds->dec->realloc(ds->escStart, newSize * sizeof(JSUINT32));\n       if (!escStart)\n       {\n-        ds->dec->free(ds->escStart);\n+        \/\/ Don't free ds->escStart here; it gets handled in JSON_DecodeObject.\n         return SetError(ds, -1, \"Could not reserve memory block\");\n       }\n       ds->escStart = escStart;"
        },
        {
            "index":532,
            "vuln_id":"GHSA-fcxw-hhxq-48wx",
            "cwe_id":"{'CWE-200'}",
            "score":3.3,
            "chain":"{'https:\/\/github.com\/jenkinsci\/git-client-plugin\/commit\/75ea3fe05650fc6ca09046a72493e2b3f066fb98'}",
            "dataset":"osv",
            "summary":"Insecure temporary file usage in Jenkins Git Client Plugin Jenkins Git Client Plugin 2.4.2 and earlier creates temporary file with insecure permissions resulting in information disclosure",
            "published_date":"2022-05-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/git-client-plugin",
            "commit_href":"https:\/\/github.com\/jenkinsci\/git-client-plugin\/commit\/75ea3fe05650fc6ca09046a72493e2b3f066fb98",
            "commit_sha":"75ea3fe05650fc6ca09046a72493e2b3f066fb98",
            "patch":"SINGLE",
            "chain_ord":"['75ea3fe05650fc6ca09046a72493e2b3f066fb98']",
            "before_first_fix_commit":"{'716e3ff56074c018c76cb35826269b976540e7e7'}",
            "last_fix_commit":"75ea3fe05650fc6ca09046a72493e2b3f066fb98",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2017, 04:38:54",
            "message":"[Fix SECURITY-445] better protect temporary files\n\nTemporary files were previously written to the system temporary directory\nwith default permissions.  A malicious actor could have captured sensitive\ninformation by reading files from the temporary directory.  The temporary\nfiles typically are only on the file system for the duration of a single\ncommand line git invocation, but cloning a large git repo could require\nan extended time with those sensitive files in the temporary directory.\n\nThis change sets permissions on the temporary files to be readable only by\nthe file owner. If a workspace is available, a temporary directory adjacent\nto the workspace is used instead of the system temporary directory.",
            "author":"Mark Waite",
            "comments":null,
            "stats":"{'additions': 42, 'deletions': 9, 'total': 51}",
            "files":"{'src\/main\/java\/org\/jenkinsci\/plugins\/gitclient\/CliGitAPIImpl.java': {'additions': 42, 'deletions': 9, 'changes': 51, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/git-client-plugin\/raw\/75ea3fe05650fc6ca09046a72493e2b3f066fb98\/src%2Fmain%2Fjava%2Forg%2Fjenkinsci%2Fplugins%2Fgitclient%2FCliGitAPIImpl.java', 'patch': '@@ -42,6 +42,11 @@\\n import java.net.URISyntaxException;\\n import java.nio.charset.Charset;\\n import java.nio.file.Files;\\n+import java.nio.file.Path;\\n+import java.nio.file.Paths;\\n+import java.nio.file.attribute.FileAttribute;\\n+import java.nio.file.attribute.PosixFilePermission;\\n+import java.nio.file.attribute.PosixFilePermissions;\\n import java.text.MessageFormat;\\n import java.util.ArrayList;\\n import java.util.Arrays;\\n@@ -1411,6 +1416,34 @@ public void addNote(String note, String namespace ) throws GitException, Interru\\n         createNote(note,namespace,\"add\");\\n     }\\n \\n+    private File createTempFileInSystemDir(String prefix, String suffix) throws IOException {\\n+        if (isWindows()) {\\n+            return Files.createTempFile(prefix, suffix).toFile();\\n+        }\\n+        Set<PosixFilePermission> ownerOnly = PosixFilePermissions.fromString(\"rw-------\");\\n+        FileAttribute fileAttribute = PosixFilePermissions.asFileAttribute(ownerOnly);\\n+        return Files.createTempFile(prefix, suffix, fileAttribute).toFile();\\n+    }\\n+\\n+    private File createTempFile(String prefix, String suffix) throws IOException {\\n+        if (workspace == null) {\\n+            return createTempFileInSystemDir(prefix, suffix);\\n+        }\\n+        File workspaceTmp = new File(workspace.getAbsolutePath() + \"@tmp\");\\n+        if (!workspaceTmp.isDirectory() && !workspaceTmp.mkdirs()) {\\n+            if (!workspaceTmp.isDirectory()) {\\n+                return createTempFileInSystemDir(prefix, suffix);\\n+            }\\n+        }\\n+        Path tmpPath = Paths.get(workspaceTmp.getAbsolutePath());\\n+        if (isWindows()) {\\n+            return Files.createTempFile(tmpPath, prefix, suffix).toFile();\\n+        }\\n+        Set<PosixFilePermission> ownerOnly = PosixFilePermissions.fromString(\"rw-------\");\\n+        FileAttribute fileAttribute = PosixFilePermissions.asFileAttribute(ownerOnly);\\n+        return Files.createTempFile(tmpPath, prefix, suffix, fileAttribute).toFile();\\n+    }\\n+\\n     private void deleteTempFile(File tempFile) {\\n         if (tempFile != null && !tempFile.delete() && tempFile.exists()) {\\n             listener.getLogger().println(\"[WARNING] temp file \" + tempFile + \" not deleted\");\\n@@ -1420,7 +1453,7 @@ private void deleteTempFile(File tempFile) {\\n     private void createNote(String note, String namespace, String command ) throws GitException, InterruptedException {\\n         File msg = null;\\n         try {\\n-            msg = File.createTempFile(\"git-note\", \"txt\", workspace);\\n+            msg = createTempFile(\"git-note\", \".txt\");\\n             FileUtils.writeStringToFile(msg,note);\\n             launchCommand(\"notes\", \"--ref=\" + namespace, command, \"-F\", msg.getAbsolutePath());\\n         } catch (IOException | GitException e) {\\n@@ -1561,7 +1594,7 @@ private String launchCommandWithCredentials(ArgumentListBuilder args, File workD\\n     }\\n \\n     private File createSshKeyFile(SSHUserPrivateKey sshUser) throws IOException, InterruptedException {\\n-        File key = File.createTempFile(\"ssh\", \"key\");\\n+        File key = createTempFile(\"ssh\", \".key\");\\n         try (PrintWriter w = new PrintWriter(key, Charset.defaultCharset().toString())) {\\n             List<String> privateKeys = sshUser.getPrivateKeys();\\n             for (String s : privateKeys) {\\n@@ -1597,7 +1630,7 @@ private String quoteUnixCredentials(String str) {\\n     }\\n \\n     private File createWindowsSshAskpass(SSHUserPrivateKey sshUser) throws IOException {\\n-        File ssh = File.createTempFile(\"pass\", \".bat\");\\n+        File ssh = createTempFile(\"pass\", \".bat\");\\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\\n             \/\/ avoid echoing command as part of the password\\n             w.println(\"@echo off\");\\n@@ -1610,7 +1643,7 @@ private File createWindowsSshAskpass(SSHUserPrivateKey sshUser) throws IOExcepti\\n     }\\n \\n     private File createUnixSshAskpass(SSHUserPrivateKey sshUser) throws IOException {\\n-        File ssh = File.createTempFile(\"pass\", \".sh\");\\n+        File ssh = createTempFile(\"pass\", \".sh\");\\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\\n             w.println(\"#!\/bin\/sh\");\\n             w.println(\"echo \\'\" + quoteUnixCredentials(Secret.toString(sshUser.getPassphrase())) + \"\\'\");\\n@@ -1621,7 +1654,7 @@ private File createUnixSshAskpass(SSHUserPrivateKey sshUser) throws IOException\\n \\n     \/* Package protected for testability *\/\\n     File createWindowsBatFile(String userName, String password) throws IOException {\\n-        File askpass = File.createTempFile(\"pass\", \".bat\");\\n+        File askpass = createTempFile(\"pass\", \".bat\");\\n         try (PrintWriter w = new PrintWriter(askpass, Charset.defaultCharset().toString())) {\\n             w.println(\"@set arg=%~1\");\\n             w.println(\"@if (%arg:~0,8%)==(Username) echo \" + escapeWindowsCharsForUnquotedString(userName));\\n@@ -1636,7 +1669,7 @@ private File createWindowsStandardAskpass(StandardUsernamePasswordCredentials cr\\n     }\\n \\n     private File createUnixStandardAskpass(StandardUsernamePasswordCredentials creds) throws IOException {\\n-        File askpass = File.createTempFile(\"pass\", \".sh\");\\n+        File askpass = createTempFile(\"pass\", \".sh\");\\n         try (PrintWriter w = new PrintWriter(askpass, Charset.defaultCharset().toString())) {\\n             w.println(\"#!\/bin\/sh\");\\n             w.println(\"case \\\\\"$1\\\\\" in\");\\n@@ -1766,7 +1799,7 @@ private File getSSHExeFromGitExeParentDir(String userGitExe) {\\n     }\\n \\n     private File createWindowsGitSSH(File key, String user) throws IOException {\\n-        File ssh = File.createTempFile(\"ssh\", \".bat\");\\n+        File ssh = createTempFile(\"ssh\", \".bat\");\\n \\n         File sshexe = getSSHExecutable();\\n \\n@@ -1779,7 +1812,7 @@ private File createWindowsGitSSH(File key, String user) throws IOException {\\n     }\\n \\n     private File createUnixGitSSH(File key, String user) throws IOException {\\n-        File ssh = File.createTempFile(\"ssh\", \".sh\");\\n+        File ssh = createTempFile(\"ssh\", \".sh\");\\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\\n             w.println(\"#!\/bin\/sh\");\\n             \/\/ ${SSH_ASKPASS} might be ignored if ${DISPLAY} is not set\\n@@ -2383,7 +2416,7 @@ public void branch(String name) throws GitException, InterruptedException {\\n     public void commit(String message) throws GitException, InterruptedException {\\n         File f = null;\\n         try {\\n-            f = File.createTempFile(\"gitcommit\", \".txt\");\\n+            f = createTempFile(\"gitcommit\", \".txt\");\\n             try (OutputStream out = Files.newOutputStream(f.toPath())) {\\n                 out.write(message.getBytes(Charset.defaultCharset().toString()));\\n             }'}}",
            "message_norm":"[fix security-445] better protect temporary files\n\ntemporary files were previously written to the system temporary directory\nwith default permissions.  a malicious actor could have captured sensitive\ninformation by reading files from the temporary directory.  the temporary\nfiles typically are only on the file system for the duration of a single\ncommand line git invocation, but cloning a large git repo could require\nan extended time with those sensitive files in the temporary directory.\n\nthis change sets permissions on the temporary files to be readable only by\nthe file owner. if a workspace is available, a temporary directory adjacent\nto the workspace is used instead of the system temporary directory.",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('security-445', 'SECWORD', ''), ('protect', 'SECWORD', ''), ('permissions', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('sensitive', 'SECWORD', ''), ('sensitive', 'SECWORD', ''), ('permissions', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/org\/jenkinsci\/plugins\/gitclient\/CliGitAPIImpl.java'])",
            "num_files":1.0,
            "patch_content":"From 75ea3fe05650fc6ca09046a72493e2b3f066fb98 Mon Sep 17 00:00:00 2001\nFrom: Mark Waite <mark.earl.waite@gmail.com>\nDate: Wed, 12 Apr 2017 22:38:54 -0600\nSubject: [PATCH] [Fix SECURITY-445] better protect temporary files\n\nTemporary files were previously written to the system temporary directory\nwith default permissions.  A malicious actor could have captured sensitive\ninformation by reading files from the temporary directory.  The temporary\nfiles typically are only on the file system for the duration of a single\ncommand line git invocation, but cloning a large git repo could require\nan extended time with those sensitive files in the temporary directory.\n\nThis change sets permissions on the temporary files to be readable only by\nthe file owner. If a workspace is available, a temporary directory adjacent\nto the workspace is used instead of the system temporary directory.\n---\n ...\/plugins\/gitclient\/CliGitAPIImpl.java      | 51 +++++++++++++++----\n 1 file changed, 42 insertions(+), 9 deletions(-)\n\ndiff --git a\/src\/main\/java\/org\/jenkinsci\/plugins\/gitclient\/CliGitAPIImpl.java b\/src\/main\/java\/org\/jenkinsci\/plugins\/gitclient\/CliGitAPIImpl.java\nindex 3994f2a8e1..31e5a72119 100644\n--- a\/src\/main\/java\/org\/jenkinsci\/plugins\/gitclient\/CliGitAPIImpl.java\n+++ b\/src\/main\/java\/org\/jenkinsci\/plugins\/gitclient\/CliGitAPIImpl.java\n@@ -42,6 +42,11 @@\n import java.net.URISyntaxException;\n import java.nio.charset.Charset;\n import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.nio.file.attribute.FileAttribute;\n+import java.nio.file.attribute.PosixFilePermission;\n+import java.nio.file.attribute.PosixFilePermissions;\n import java.text.MessageFormat;\n import java.util.ArrayList;\n import java.util.Arrays;\n@@ -1411,6 +1416,34 @@ public void addNote(String note, String namespace ) throws GitException, Interru\n         createNote(note,namespace,\"add\");\n     }\n \n+    private File createTempFileInSystemDir(String prefix, String suffix) throws IOException {\n+        if (isWindows()) {\n+            return Files.createTempFile(prefix, suffix).toFile();\n+        }\n+        Set<PosixFilePermission> ownerOnly = PosixFilePermissions.fromString(\"rw-------\");\n+        FileAttribute fileAttribute = PosixFilePermissions.asFileAttribute(ownerOnly);\n+        return Files.createTempFile(prefix, suffix, fileAttribute).toFile();\n+    }\n+\n+    private File createTempFile(String prefix, String suffix) throws IOException {\n+        if (workspace == null) {\n+            return createTempFileInSystemDir(prefix, suffix);\n+        }\n+        File workspaceTmp = new File(workspace.getAbsolutePath() + \"@tmp\");\n+        if (!workspaceTmp.isDirectory() && !workspaceTmp.mkdirs()) {\n+            if (!workspaceTmp.isDirectory()) {\n+                return createTempFileInSystemDir(prefix, suffix);\n+            }\n+        }\n+        Path tmpPath = Paths.get(workspaceTmp.getAbsolutePath());\n+        if (isWindows()) {\n+            return Files.createTempFile(tmpPath, prefix, suffix).toFile();\n+        }\n+        Set<PosixFilePermission> ownerOnly = PosixFilePermissions.fromString(\"rw-------\");\n+        FileAttribute fileAttribute = PosixFilePermissions.asFileAttribute(ownerOnly);\n+        return Files.createTempFile(tmpPath, prefix, suffix, fileAttribute).toFile();\n+    }\n+\n     private void deleteTempFile(File tempFile) {\n         if (tempFile != null && !tempFile.delete() && tempFile.exists()) {\n             listener.getLogger().println(\"[WARNING] temp file \" + tempFile + \" not deleted\");\n@@ -1420,7 +1453,7 @@ private void deleteTempFile(File tempFile) {\n     private void createNote(String note, String namespace, String command ) throws GitException, InterruptedException {\n         File msg = null;\n         try {\n-            msg = File.createTempFile(\"git-note\", \"txt\", workspace);\n+            msg = createTempFile(\"git-note\", \".txt\");\n             FileUtils.writeStringToFile(msg,note);\n             launchCommand(\"notes\", \"--ref=\" + namespace, command, \"-F\", msg.getAbsolutePath());\n         } catch (IOException | GitException e) {\n@@ -1561,7 +1594,7 @@ private String launchCommandWithCredentials(ArgumentListBuilder args, File workD\n     }\n \n     private File createSshKeyFile(SSHUserPrivateKey sshUser) throws IOException, InterruptedException {\n-        File key = File.createTempFile(\"ssh\", \"key\");\n+        File key = createTempFile(\"ssh\", \".key\");\n         try (PrintWriter w = new PrintWriter(key, Charset.defaultCharset().toString())) {\n             List<String> privateKeys = sshUser.getPrivateKeys();\n             for (String s : privateKeys) {\n@@ -1597,7 +1630,7 @@ private String quoteUnixCredentials(String str) {\n     }\n \n     private File createWindowsSshAskpass(SSHUserPrivateKey sshUser) throws IOException {\n-        File ssh = File.createTempFile(\"pass\", \".bat\");\n+        File ssh = createTempFile(\"pass\", \".bat\");\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\n             \/\/ avoid echoing command as part of the password\n             w.println(\"@echo off\");\n@@ -1610,7 +1643,7 @@ private File createWindowsSshAskpass(SSHUserPrivateKey sshUser) throws IOExcepti\n     }\n \n     private File createUnixSshAskpass(SSHUserPrivateKey sshUser) throws IOException {\n-        File ssh = File.createTempFile(\"pass\", \".sh\");\n+        File ssh = createTempFile(\"pass\", \".sh\");\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\n             w.println(\"#!\/bin\/sh\");\n             w.println(\"echo '\" + quoteUnixCredentials(Secret.toString(sshUser.getPassphrase())) + \"'\");\n@@ -1621,7 +1654,7 @@ private File createUnixSshAskpass(SSHUserPrivateKey sshUser) throws IOException\n \n     \/* Package protected for testability *\/\n     File createWindowsBatFile(String userName, String password) throws IOException {\n-        File askpass = File.createTempFile(\"pass\", \".bat\");\n+        File askpass = createTempFile(\"pass\", \".bat\");\n         try (PrintWriter w = new PrintWriter(askpass, Charset.defaultCharset().toString())) {\n             w.println(\"@set arg=%~1\");\n             w.println(\"@if (%arg:~0,8%)==(Username) echo \" + escapeWindowsCharsForUnquotedString(userName));\n@@ -1636,7 +1669,7 @@ private File createWindowsStandardAskpass(StandardUsernamePasswordCredentials cr\n     }\n \n     private File createUnixStandardAskpass(StandardUsernamePasswordCredentials creds) throws IOException {\n-        File askpass = File.createTempFile(\"pass\", \".sh\");\n+        File askpass = createTempFile(\"pass\", \".sh\");\n         try (PrintWriter w = new PrintWriter(askpass, Charset.defaultCharset().toString())) {\n             w.println(\"#!\/bin\/sh\");\n             w.println(\"case \\\"$1\\\" in\");\n@@ -1766,7 +1799,7 @@ private File getSSHExeFromGitExeParentDir(String userGitExe) {\n     }\n \n     private File createWindowsGitSSH(File key, String user) throws IOException {\n-        File ssh = File.createTempFile(\"ssh\", \".bat\");\n+        File ssh = createTempFile(\"ssh\", \".bat\");\n \n         File sshexe = getSSHExecutable();\n \n@@ -1779,7 +1812,7 @@ private File createWindowsGitSSH(File key, String user) throws IOException {\n     }\n \n     private File createUnixGitSSH(File key, String user) throws IOException {\n-        File ssh = File.createTempFile(\"ssh\", \".sh\");\n+        File ssh = createTempFile(\"ssh\", \".sh\");\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\n             w.println(\"#!\/bin\/sh\");\n             \/\/ ${SSH_ASKPASS} might be ignored if ${DISPLAY} is not set\n@@ -2383,7 +2416,7 @@ public void branch(String name) throws GitException, InterruptedException {\n     public void commit(String message) throws GitException, InterruptedException {\n         File f = null;\n         try {\n-            f = File.createTempFile(\"gitcommit\", \".txt\");\n+            f = createTempFile(\"gitcommit\", \".txt\");\n             try (OutputStream out = Files.newOutputStream(f.toPath())) {\n                 out.write(message.getBytes(Charset.defaultCharset().toString()));\n             }"
        },
        {
            "index":707,
            "vuln_id":"GHSA-56wv-2wr9-3h9r",
            "cwe_id":"{'CWE-347'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/e592f106edd5acf6dacedfab2ad16fe6c735c9d1', 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/7b64e3efaa806b4daaf73bb5172af3581812f8de', 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/4a16daeaf139be20654ef58a9fe4c79dc030458c'}",
            "dataset":"osv",
            "summary":"Improper Verification of Cryptographic Signature in fastecdsa An issue was discovered in fastecdsa before 2.1.2. When using the NIST P-256 curve in the ECDSA implementation, the point at infinity is mishandled. This means that for an extreme value in k and s^-1, the signature verification fails even if the signature is correct. This behavior is not solely a usability problem. There are some threat models where an attacker can benefit by successfully guessing users for whom signature verification will fail.",
            "published_date":"2021-10-12",
            "chain_len":3,
            "project":"https:\/\/github.com\/AntonKueltz\/fastecdsa",
            "commit_href":"https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/e592f106edd5acf6dacedfab2ad16fe6c735c9d1",
            "commit_sha":"e592f106edd5acf6dacedfab2ad16fe6c735c9d1",
            "patch":"MULTI",
            "chain_ord":"['e592f106edd5acf6dacedfab2ad16fe6c735c9d1', '7b64e3efaa806b4daaf73bb5172af3581812f8de', '4a16daeaf139be20654ef58a9fe4c79dc030458c']",
            "before_first_fix_commit":"{'7b64e3efaa806b4daaf73bb5172af3581812f8de'}",
            "last_fix_commit":"4a16daeaf139be20654ef58a9fe4c79dc030458c",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/14\/2020, 09:15:41",
            "message":"Properly handle the point at infinity",
            "author":"AntonKueltz",
            "comments":null,
            "stats":"{'additions': 50, 'deletions': 1, 'total': 51}",
            "files":"{'src\/curveMath.c': {'additions': 50, 'deletions': 1, 'changes': 51, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/raw\/e592f106edd5acf6dacedfab2ad16fe6c735c9d1\/src%2FcurveMath.c', 'patch': '@@ -15,7 +15,22 @@ int pointZZ_pEqual(const PointZZ_p * op1, const PointZZ_p * op2) {\\n }\\n \\n \\n+int pointZZ_pIsIdentityElement(const PointZZ_p * op) {\\n+    return mpz_cmp_ui(op->x, 0) == 0 && mpz_cmp_ui(op->y, 0) == 0 ? 1 : 0;\\n+}\\n+\\n+\\n+void pointZZ_pSetToIdentityElement(PointZZ_p * op) {\\n+    mpz_set_ui(op->x, 0);\\n+    mpz_set_ui(op->y, 0);\\n+}\\n+\\n+\\n void pointZZ_pDouble(PointZZ_p * rop, const PointZZ_p * op, const CurveZZ_p * curve) {\\n+    if(pointZZ_pIsIdentityElement(op)) {\\n+        return pointZZ_pSetToIdentityElement(rop);\\n+    }\\n+\\n     mpz_t numer, denom, lambda;\\n     mpz_inits(numer, denom, lambda, NULL);\\n \\n@@ -45,6 +60,35 @@ void pointZZ_pDouble(PointZZ_p * rop, const PointZZ_p * op, const CurveZZ_p * cu\\n \\n \\n void pointZZ_pAdd(PointZZ_p * rop, const PointZZ_p * op1, const PointZZ_p * op2, const CurveZZ_p * curve) {\\n+    \/\/ handle identity element cases\\n+    if(pointZZ_pIsIdentityElement(op1) && pointZZ_pIsIdentityElement(op2)) {\\n+        return pointZZ_pSetToIdentityElement(rop);\\n+    } else if(pointZZ_pIsIdentityElement(op1)) {\\n+        mpz_set(rop->x, op2->x);\\n+        mpz_set(rop->y, op2->y);\\n+        return;\\n+    } else if(pointZZ_pIsIdentityElement(op2)) {\\n+        mpz_set(rop->x, op1->x);\\n+        mpz_set(rop->y, op1->y);\\n+        return;\\n+    }\\n+\\n+    \/\/ use doubling algorithm if points are equal\\n+    if(pointZZ_pEqual(op1, op2)) {\\n+        pointZZ_pDouble(rop, op1, curve);\\n+        return;\\n+    }\\n+\\n+    \/\/ check if points sum to identity element\\n+    mpz_t negy;\\n+    mpz_init(negy);\\n+    mpz_sub(negy, curve->p, op2->y);\\n+    if(mpz_cmp(op1->x, op2->x) == 0 && mpz_cmp(op1->y, negy) == 0) {\\n+        mpz_clear(negy);\\n+        return pointZZ_pSetToIdentityElement(rop);\\n+    }\\n+\\n+\\n     mpz_t xdiff, ydiff, lambda;\\n     mpz_inits(xdiff, ydiff, lambda, NULL);\\n \\n@@ -67,11 +111,16 @@ void pointZZ_pAdd(PointZZ_p * rop, const PointZZ_p * op1, const PointZZ_p * op2,\\n     mpz_sub(rop->y, rop->y, op1->y);\\n     mpz_mod(rop->y, rop->y, curve->p);\\n \\n-    mpz_clears(xdiff, ydiff, lambda, NULL);\\n+    mpz_clears(negy, xdiff, ydiff, lambda, NULL);\\n }\\n \\n \\n void pointZZ_pMul(PointZZ_p * rop, const PointZZ_p * point, const mpz_t scalar, const CurveZZ_p * curve) {\\n+    \/\/ handle the identity element\\n+    if(pointZZ_pIsIdentityElement(point)) {\\n+        return pointZZ_pSetToIdentityElement(rop);\\n+    }\\n+\\n     PointZZ_p R0, R1, tmp;\\n     mpz_inits(R1.x, R1.y, tmp.x, tmp.y, NULL);\\n     mpz_init_set(R0.x, point->x);'}}",
            "message_norm":"properly handle the point at infinity",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/curveMath.c'])",
            "num_files":1.0,
            "patch_content":"From e592f106edd5acf6dacedfab2ad16fe6c735c9d1 Mon Sep 17 00:00:00 2001\nFrom: AntonKueltz <kueltz.anton@gmail.com>\nDate: Tue, 14 Apr 2020 02:15:41 -0700\nSubject: [PATCH] Properly handle the point at infinity\n\n---\n src\/curveMath.c | 51 ++++++++++++++++++++++++++++++++++++++++++++++++-\n 1 file changed, 50 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/curveMath.c b\/src\/curveMath.c\nindex 10160a7..0f354c6 100644\n--- a\/src\/curveMath.c\n+++ b\/src\/curveMath.c\n@@ -15,7 +15,22 @@ int pointZZ_pEqual(const PointZZ_p * op1, const PointZZ_p * op2) {\n }\n \n \n+int pointZZ_pIsIdentityElement(const PointZZ_p * op) {\n+    return mpz_cmp_ui(op->x, 0) == 0 && mpz_cmp_ui(op->y, 0) == 0 ? 1 : 0;\n+}\n+\n+\n+void pointZZ_pSetToIdentityElement(PointZZ_p * op) {\n+    mpz_set_ui(op->x, 0);\n+    mpz_set_ui(op->y, 0);\n+}\n+\n+\n void pointZZ_pDouble(PointZZ_p * rop, const PointZZ_p * op, const CurveZZ_p * curve) {\n+    if(pointZZ_pIsIdentityElement(op)) {\n+        return pointZZ_pSetToIdentityElement(rop);\n+    }\n+\n     mpz_t numer, denom, lambda;\n     mpz_inits(numer, denom, lambda, NULL);\n \n@@ -45,6 +60,35 @@ void pointZZ_pDouble(PointZZ_p * rop, const PointZZ_p * op, const CurveZZ_p * cu\n \n \n void pointZZ_pAdd(PointZZ_p * rop, const PointZZ_p * op1, const PointZZ_p * op2, const CurveZZ_p * curve) {\n+    \/\/ handle identity element cases\n+    if(pointZZ_pIsIdentityElement(op1) && pointZZ_pIsIdentityElement(op2)) {\n+        return pointZZ_pSetToIdentityElement(rop);\n+    } else if(pointZZ_pIsIdentityElement(op1)) {\n+        mpz_set(rop->x, op2->x);\n+        mpz_set(rop->y, op2->y);\n+        return;\n+    } else if(pointZZ_pIsIdentityElement(op2)) {\n+        mpz_set(rop->x, op1->x);\n+        mpz_set(rop->y, op1->y);\n+        return;\n+    }\n+\n+    \/\/ use doubling algorithm if points are equal\n+    if(pointZZ_pEqual(op1, op2)) {\n+        pointZZ_pDouble(rop, op1, curve);\n+        return;\n+    }\n+\n+    \/\/ check if points sum to identity element\n+    mpz_t negy;\n+    mpz_init(negy);\n+    mpz_sub(negy, curve->p, op2->y);\n+    if(mpz_cmp(op1->x, op2->x) == 0 && mpz_cmp(op1->y, negy) == 0) {\n+        mpz_clear(negy);\n+        return pointZZ_pSetToIdentityElement(rop);\n+    }\n+\n+\n     mpz_t xdiff, ydiff, lambda;\n     mpz_inits(xdiff, ydiff, lambda, NULL);\n \n@@ -67,11 +111,16 @@ void pointZZ_pAdd(PointZZ_p * rop, const PointZZ_p * op1, const PointZZ_p * op2,\n     mpz_sub(rop->y, rop->y, op1->y);\n     mpz_mod(rop->y, rop->y, curve->p);\n \n-    mpz_clears(xdiff, ydiff, lambda, NULL);\n+    mpz_clears(negy, xdiff, ydiff, lambda, NULL);\n }\n \n \n void pointZZ_pMul(PointZZ_p * rop, const PointZZ_p * point, const mpz_t scalar, const CurveZZ_p * curve) {\n+    \/\/ handle the identity element\n+    if(pointZZ_pIsIdentityElement(point)) {\n+        return pointZZ_pSetToIdentityElement(rop);\n+    }\n+\n     PointZZ_p R0, R1, tmp;\n     mpz_inits(R1.x, R1.y, tmp.x, tmp.y, NULL);\n     mpz_init_set(R0.x, point->x);"
        },
        {
            "index":669,
            "vuln_id":"GHSA-5hj3-vjjf-f5m7",
            "cwe_id":"{'CWE-125'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6'}",
            "dataset":"osv",
            "summary":"Heap OOB in `SdcaOptimizerV2` ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.SdcaOptimizerV2(\n  sparse_example_indices=[[1]],\n  sparse_feature_indices=[[1]],\n  sparse_feature_values=[[1.0,2.0]],\n  dense_features=[[1.0]],\n  example_weights=[1.0],\n  example_labels=[],\n  sparse_indices=[1],\n  sparse_weights=[1.0],\n  dense_weights=[[1.0]],\n  example_state_data=[[100.0,100.0,100.0,100.0]],\n  loss_type='logistic_loss',\n  l1=100.0,\n  l2=100.0,\n  num_loss_partitions=1,\n  num_inner_iterations=1,\n  adaptive=True)       \n``` \n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples.\n\n### Patches\nWe have patched the issue in GitHub commit [a4e138660270e7599793fa438cd7b2fc2ce215a6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6",
            "commit_sha":"a4e138660270e7599793fa438cd7b2fc2ce215a6",
            "patch":"SINGLE",
            "chain_ord":"['a4e138660270e7599793fa438cd7b2fc2ce215a6']",
            "before_first_fix_commit":"{'578e634b4f1c1c684d4b4294f9e5281b2133b3ed'}",
            "last_fix_commit":"a4e138660270e7599793fa438cd7b2fc2ce215a6",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/30\/2021, 05:24:27",
            "message":"Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/sdca_internal.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a4e138660270e7599793fa438cd7b2fc2ce215a6\/tensorflow%2Fcore%2Fkernels%2Fsdca_internal.cc', 'patch': '@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\\n   const Tensor* example_labels_t;\\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\\n   auto example_labels = example_labels_t->flat<float>();\\n+  if (example_labels.size() != num_examples) {\\n+    return errors::InvalidArgument(\"Expected \", num_examples,\\n+                                   \" example labels but got \",\\n+                                   example_labels.size());\\n+  }\\n \\n   OpInputList dense_features_inputs;\\n   TF_RETURN_IF_ERROR('}}",
            "message_norm":"add remaining validation to `sdca_internal.cc`\n\npiperorigin-revid: 387738010\nchange-id: i28eedcfd87a53aaf34deb075acea1f8c95470808",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('387738010', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sdca_internal.cc'])",
            "num_files":1.0,
            "patch_content":"From a4e138660270e7599793fa438cd7b2fc2ce215a6 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 22:24:27 -0700\nSubject: [PATCH] Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808\n---\n tensorflow\/core\/kernels\/sdca_internal.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sdca_internal.cc b\/tensorflow\/core\/kernels\/sdca_internal.cc\nindex 6c4a63b270c25b..164f9382724cac 100644\n--- a\/tensorflow\/core\/kernels\/sdca_internal.cc\n+++ b\/tensorflow\/core\/kernels\/sdca_internal.cc\n@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR("
        },
        {
            "index":604,
            "vuln_id":"GHSA-6qcc-whgp-pjj2",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/8ab06bfbb5a05a1b190731d9c7476ec45f5ee878'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Pimcore Pimcore version 10.3.2 and prior is vulnerable to stored cross-site scripting. A patch is available and anticipated to be part of version 10.3.3.",
            "published_date":"2022-03-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/8ab06bfbb5a05a1b190731d9c7476ec45f5ee878",
            "commit_sha":"8ab06bfbb5a05a1b190731d9c7476ec45f5ee878",
            "patch":"SINGLE",
            "chain_ord":"['8ab06bfbb5a05a1b190731d9c7476ec45f5ee878']",
            "before_first_fix_commit":"{'cef6fb5a9f385f77b9a1af508ecc45a147476458'}",
            "last_fix_commit":"8ab06bfbb5a05a1b190731d9c7476ec45f5ee878",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/02\/2022, 19:06:51",
            "message":"escaping fields in SERP preview",
            "author":"JiaJia Ji",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/8ab06bfbb5a05a1b190731d9c7476ec45f5ee878\/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Fdocument%2Fpages%2Fsettings.js', 'patch': '@@ -79,8 +79,8 @@ pimcore.document.pages.settings = Class.create(pimcore.document.settings_abstrac\\n             var updateSerpPreview = function () {\\n \\n                 var metaPanel = this.layout.getComponent(\"metaDataPanel\");\\n-                var title = metaPanel.getComponent(\"title\").getValue();\\n-                var description = metaPanel.getComponent(\"description\").getValue();\\n+                var title = htmlspecialchars(metaPanel.getComponent(\"title\").getValue());\\n+                var description = htmlspecialchars(metaPanel.getComponent(\"description\").getValue());\\n \\n                 var truncate = function( text, n ){\\n                     if (text.length <= n) { return text; }'}}",
            "message_norm":"escaping fields in serp preview",
            "language":"en",
            "entities":"[('escaping', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js'])",
            "num_files":1.0,
            "patch_content":"From 8ab06bfbb5a05a1b190731d9c7476ec45f5ee878 Mon Sep 17 00:00:00 2001\nFrom: JiaJia Ji <kingjia90@gmail.com>\nDate: Wed, 2 Mar 2022 20:06:51 +0100\nSubject: [PATCH] escaping fields in SERP preview\n\n---\n ...\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js    | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js b\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js\nindex f14c6d28513..3737778b115 100644\n--- a\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js\n+++ b\/bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js\n@@ -79,8 +79,8 @@ pimcore.document.pages.settings = Class.create(pimcore.document.settings_abstrac\n             var updateSerpPreview = function () {\n \n                 var metaPanel = this.layout.getComponent(\"metaDataPanel\");\n-                var title = metaPanel.getComponent(\"title\").getValue();\n-                var description = metaPanel.getComponent(\"description\").getValue();\n+                var title = htmlspecialchars(metaPanel.getComponent(\"title\").getValue());\n+                var description = htmlspecialchars(metaPanel.getComponent(\"description\").getValue());\n \n                 var truncate = function( text, n ){\n                     if (text.length <= n) { return text; }"
        },
        {
            "index":275,
            "vuln_id":"GHSA-25xj-89g5-fm6h",
            "cwe_id":"{'CWE-532', 'CWE-200'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/hashicorp\/vault\/commit\/87f47c216cf1a28f4054b80cff40de8c9e00e36c', 'https:\/\/github.com\/hashicorp\/vault\/commit\/e52f34772affb69f3239b2cdf6523cb7cfd67a92'}",
            "dataset":"osv",
            "summary":"Information Disclosure in HashiCorp Vault HashiCorp Vault and Vault Enterprise before 1.3.6, and 1.4.2 before 1.4.2, insert Sensitive Information into a Log File.",
            "published_date":"2021-05-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/hashicorp\/vault",
            "commit_href":"https:\/\/github.com\/hashicorp\/vault\/commit\/e52f34772affb69f3239b2cdf6523cb7cfd67a92",
            "commit_sha":"e52f34772affb69f3239b2cdf6523cb7cfd67a92",
            "patch":"MULTI",
            "chain_ord":"['e52f34772affb69f3239b2cdf6523cb7cfd67a92', '87f47c216cf1a28f4054b80cff40de8c9e00e36c']",
            "before_first_fix_commit":"{'01a682aa48ede581e12813314e64a75e314e500e'}",
            "last_fix_commit":"87f47c216cf1a28f4054b80cff40de8c9e00e36c",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/19\/2020, 14:07:46",
            "message":"Don't include username or password of proxy env vars when logging them. (#9022)",
            "author":"ncabatoff",
            "comments":null,
            "stats":"{'additions': 27, 'deletions': 7, 'total': 34}",
            "files":"{'command\/server.go': {'additions': 27, 'deletions': 7, 'changes': 34, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hashicorp\/vault\/raw\/e52f34772affb69f3239b2cdf6523cb7cfd67a92\/command%2Fserver.go', 'patch': '@@ -445,9 +445,7 @@ func (c *ServerCommand) runRecoveryMode() int {\\n \\t\\tvault.DefaultMaxRequestDuration = config.DefaultMaxRequestDuration\\n \\t}\\n \\n-\\tproxyCfg := httpproxy.FromEnvironment()\\n-\\tc.logger.Info(\"proxy environment\", \"http_proxy\", proxyCfg.HTTPProxy,\\n-\\t\\t\"https_proxy\", proxyCfg.HTTPSProxy, \"no_proxy\", proxyCfg.NoProxy)\\n+\\tlogProxyEnvironmentVariables(c.logger)\\n \\n \\t\/\/ Initialize the storage backend\\n \\tfactory, exists := c.PhysicalBackends[config.Storage.Type]\\n@@ -684,6 +682,31 @@ func (c *ServerCommand) runRecoveryMode() int {\\n \\treturn 0\\n }\\n \\n+func logProxyEnvironmentVariables(logger hclog.Logger) {\\n+\\tproxyCfg := httpproxy.FromEnvironment()\\n+\\tcfgMap := map[string]string{\\n+\\t\\t\"http_proxy\":  proxyCfg.HTTPProxy,\\n+\\t\\t\"https_proxy\": proxyCfg.HTTPSProxy,\\n+\\t\\t\"no_proxy\":    proxyCfg.NoProxy,\\n+\\t}\\n+\\tfor k, v := range cfgMap {\\n+\\t\\tu, err := url.Parse(v)\\n+\\t\\tif err != nil {\\n+\\t\\t\\t\/\/ Env vars may contain URLs or host:port values.  We only care\\n+\\t\\t\\t\/\/ about the former.\\n+\\t\\t\\tcontinue\\n+\\t\\t}\\n+\\t\\tif _, ok := u.User.Password(); ok {\\n+\\t\\t\\tu.User = url.UserPassword(\"redacted-username\", \"redacted-password\")\\n+\\t\\t} else if user := u.User.Username(); user != \"\" {\\n+\\t\\t\\tu.User = url.User(\"redacted-username\")\\n+\\t\\t}\\n+\\t\\tcfgMap[k] = u.String()\\n+\\t}\\n+\\tlogger.Info(\"proxy environment\", \"http_proxy\", cfgMap[\"http_proxy\"],\\n+\\t\\t\"https_proxy\", cfgMap[\"https_proxy\"], \"no_proxy\", cfgMap[\"no_proxy\"])\\n+}\\n+\\n func (c *ServerCommand) adjustLogLevel(config *server.Config, logLevelWasNotSet bool) (string, error) {\\n \\tvar logLevelString string\\n \\tif config.LogLevel != \"\" && logLevelWasNotSet {\\n@@ -894,10 +917,7 @@ func (c *ServerCommand) Run(args []string) int {\\n \\t\\tvault.DefaultMaxRequestDuration = config.DefaultMaxRequestDuration\\n \\t}\\n \\n-\\t\/\/ log proxy settings\\n-\\tproxyCfg := httpproxy.FromEnvironment()\\n-\\tc.logger.Info(\"proxy environment\", \"http_proxy\", proxyCfg.HTTPProxy,\\n-\\t\\t\"https_proxy\", proxyCfg.HTTPSProxy, \"no_proxy\", proxyCfg.NoProxy)\\n+\\tlogProxyEnvironmentVariables(c.logger)\\n \\n \\t\/\/ If mlockall(2) isn\\'t supported, show a warning. We disable this in dev\\n \\t\/\/ because it is quite scary to see when first using Vault. We also disable'}}",
            "message_norm":"don't include username or password of proxy env vars when logging them. (#9022)",
            "language":"en",
            "entities":"[('password', 'SECWORD', ''), ('#9022', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['command\/server.go'])",
            "num_files":1.0,
            "patch_content":"From e52f34772affb69f3239b2cdf6523cb7cfd67a92 Mon Sep 17 00:00:00 2001\nFrom: ncabatoff <ncabatoff@hashicorp.com>\nDate: Tue, 19 May 2020 10:07:46 -0400\nSubject: [PATCH] Don't include username or password of proxy env vars when\n logging them. (#9022)\n\n---\n command\/server.go | 34 +++++++++++++++++++++++++++-------\n 1 file changed, 27 insertions(+), 7 deletions(-)\n\ndiff --git a\/command\/server.go b\/command\/server.go\nindex 54a5090a3012..0cf866053602 100644\n--- a\/command\/server.go\n+++ b\/command\/server.go\n@@ -445,9 +445,7 @@ func (c *ServerCommand) runRecoveryMode() int {\n \t\tvault.DefaultMaxRequestDuration = config.DefaultMaxRequestDuration\n \t}\n \n-\tproxyCfg := httpproxy.FromEnvironment()\n-\tc.logger.Info(\"proxy environment\", \"http_proxy\", proxyCfg.HTTPProxy,\n-\t\t\"https_proxy\", proxyCfg.HTTPSProxy, \"no_proxy\", proxyCfg.NoProxy)\n+\tlogProxyEnvironmentVariables(c.logger)\n \n \t\/\/ Initialize the storage backend\n \tfactory, exists := c.PhysicalBackends[config.Storage.Type]\n@@ -684,6 +682,31 @@ func (c *ServerCommand) runRecoveryMode() int {\n \treturn 0\n }\n \n+func logProxyEnvironmentVariables(logger hclog.Logger) {\n+\tproxyCfg := httpproxy.FromEnvironment()\n+\tcfgMap := map[string]string{\n+\t\t\"http_proxy\":  proxyCfg.HTTPProxy,\n+\t\t\"https_proxy\": proxyCfg.HTTPSProxy,\n+\t\t\"no_proxy\":    proxyCfg.NoProxy,\n+\t}\n+\tfor k, v := range cfgMap {\n+\t\tu, err := url.Parse(v)\n+\t\tif err != nil {\n+\t\t\t\/\/ Env vars may contain URLs or host:port values.  We only care\n+\t\t\t\/\/ about the former.\n+\t\t\tcontinue\n+\t\t}\n+\t\tif _, ok := u.User.Password(); ok {\n+\t\t\tu.User = url.UserPassword(\"redacted-username\", \"redacted-password\")\n+\t\t} else if user := u.User.Username(); user != \"\" {\n+\t\t\tu.User = url.User(\"redacted-username\")\n+\t\t}\n+\t\tcfgMap[k] = u.String()\n+\t}\n+\tlogger.Info(\"proxy environment\", \"http_proxy\", cfgMap[\"http_proxy\"],\n+\t\t\"https_proxy\", cfgMap[\"https_proxy\"], \"no_proxy\", cfgMap[\"no_proxy\"])\n+}\n+\n func (c *ServerCommand) adjustLogLevel(config *server.Config, logLevelWasNotSet bool) (string, error) {\n \tvar logLevelString string\n \tif config.LogLevel != \"\" && logLevelWasNotSet {\n@@ -894,10 +917,7 @@ func (c *ServerCommand) Run(args []string) int {\n \t\tvault.DefaultMaxRequestDuration = config.DefaultMaxRequestDuration\n \t}\n \n-\t\/\/ log proxy settings\n-\tproxyCfg := httpproxy.FromEnvironment()\n-\tc.logger.Info(\"proxy environment\", \"http_proxy\", proxyCfg.HTTPProxy,\n-\t\t\"https_proxy\", proxyCfg.HTTPSProxy, \"no_proxy\", proxyCfg.NoProxy)\n+\tlogProxyEnvironmentVariables(c.logger)\n \n \t\/\/ If mlockall(2) isn't supported, show a warning. We disable this in dev\n \t\/\/ because it is quite scary to see when first using Vault. We also disable"
        },
        {
            "index":91,
            "vuln_id":"GHSA-4fc4-4p5g-6w89",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/ckeditor\/ckeditor4\/commit\/d158413449692d920a778503502dcb22881bc949'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in CKEditor4 ### Affected packages\nThe vulnerability has been discovered in the core HTML processing module and may affect all plugins used by CKEditor 4.\n\n### Impact\nA potential vulnerability has been discovered in CKEditor 4 HTML processing core module. The vulnerability allowed to inject malformed HTML bypassing content sanitization, which could result in executing JavaScript code. It affects all users using the CKEditor 4 at version < 4.18.0.\n\n### Patches\nThe problem has been recognized and patched. The fix will be available in version 4.18.0.\n\n### For more information\nEmail us at security@cksource.com if you have any questions or comments about this advisory.\n\n### Acknowledgements\nThe CKEditor 4 team would like to thank GHSL team member Kevin Backhouse ([@kevinbackhouse](https:\/\/github.com\/kevinbackhouse)) for recognizing and reporting this vulnerability.",
            "published_date":"2022-03-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/ckeditor\/ckeditor4",
            "commit_href":"https:\/\/github.com\/ckeditor\/ckeditor4\/commit\/d158413449692d920a778503502dcb22881bc949",
            "commit_sha":"d158413449692d920a778503502dcb22881bc949",
            "patch":"SINGLE",
            "chain_ord":"['d158413449692d920a778503502dcb22881bc949']",
            "before_first_fix_commit":"{'8cff1e5aee3d766068792a374ba6b54a5cb92e2d'}",
            "last_fix_commit":"d158413449692d920a778503502dcb22881bc949",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/08\/2022, 16:35:34",
            "message":"Code refactoring.",
            "author":"Tomasz Jakut",
            "comments":null,
            "stats":"{'additions': 26, 'deletions': 14, 'total': 40}",
            "files":"{'core\/htmldataprocessor.js': {'additions': 26, 'deletions': 14, 'changes': 40, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ckeditor\/ckeditor4\/raw\/d158413449692d920a778503502dcb22881bc949\/core%2Fhtmldataprocessor.js', 'patch': '@@ -50,17 +50,18 @@\\n \\t\\thtmlFilter.addRules( createBogusAndFillerRules( editor, \\'html\\' ), { applyToAll: true } );\\n \\n \\t\\teditor.on( \\'toHtml\\', function( evt ) {\\n-\\t\\t\\tvar evtData = evt.data,\\n+\\t\\t\\tvar randomNumber = generateRandomNumber(),\\n+\\t\\t\\t\\tevtData = evt.data,\\n \\t\\t\\t\\tdata = evtData.dataValue,\\n \\t\\t\\t\\tfixBodyTag;\\n \\n \\t\\t\\t\/\/ Before we start protecting markup, make sure there are no externally injected\\n \\t\\t\\t\/\/ protection keywords.\\n-\\t\\t\\tdata = removeReservedKeywords( data );\\n+\\t\\t\\tdata = removeReservedKeywords( data, randomNumber );\\n \\n \\t\\t\\t\/\/ The source data is already HTML, but we need to clean\\n \\t\\t\\t\/\/ it up and apply the filter.\\n-\\t\\t\\tdata = protectSource( data, editor );\\n+\\t\\t\\tdata = protectSource( data, editor, randomNumber );\\n \\n \\t\\t\\t\/\/ Protect content of textareas. (https:\/\/dev.ckeditor.com\/ticket\/9995)\\n \\t\\t\\t\/\/ Do this before protecting attributes to avoid breaking:\\n@@ -70,7 +71,7 @@\\n \\t\\t\\t\/\/ Before anything, we must protect the URL attributes as the\\n \\t\\t\\t\/\/ browser may changing them when setting the innerHTML later in\\n \\t\\t\\t\/\/ the code.\\n-\\t\\t\\tdata = protectAttributes( data );\\n+\\t\\t\\tdata = protectAttributes( data, randomNumber );\\n \\n \\t\\t\\t\/\/ Protect elements than can\\'t be set inside a DIV. E.g. IE removes\\n \\t\\t\\t\/\/ style tags from innerHTML. (https:\/\/dev.ckeditor.com\/ticket\/3710)\\n@@ -90,7 +91,7 @@\\n \\n \\t\\t\\t\/\/ There are attributes which may execute JavaScript code inside fixBin.\\n \\t\\t\\t\/\/ Encode them greedily. They will be unprotected right after getting HTML from fixBin. (https:\/\/dev.ckeditor.com\/ticket\/10)\\n-\\t\\t\\tdata = protectInsecureAttributes( data );\\n+\\t\\t\\tdata = protectInsecureAttributes( data, randomNumber );\\n \\n \\t\\t\\tvar fixBin = evtData.context || editor.editable().getName(),\\n \\t\\t\\t\\tisPre;\\n@@ -110,7 +111,7 @@\\n \\t\\t\\tdata = el.getHtml().substr( 1 );\\n \\n \\t\\t\\t\/\/ Restore shortly protected attribute names.\\n-\\t\\t\\tdata = data.replace( new RegExp( \\'data-cke-\\' + CKEDITOR.rnd + \\'-\\', \\'ig\\' ), \\'\\' );\\n+\\t\\t\\tdata = data.replace( new RegExp( \\'data-cke-\\' + randomNumber + \\'-\\', \\'ig\\' ), \\'\\' );\\n \\n \\t\\t\\tisPre && ( data = data.replace( \/^<pre>|<\\\\\/pre>$\/gi, \\'\\' ) );\\n \\n@@ -838,13 +839,13 @@\\n \\n \\tvar protectSelfClosingRegex = \/<cke:(param|embed)([^>]*?)\\\\\/?>(?!\\\\s*<\\\\\/cke:\\\\1)\/gi;\\n \\n-\\tfunction protectAttributes( html ) {\\n+\\tfunction protectAttributes( html, randomNumber ) {\\n \\t\\treturn html.replace( protectElementRegex, function( element, tag, attributes ) {\\n \\t\\t\\treturn \\'<\\' + tag + attributes.replace( protectAttributeRegex, function( fullAttr, attrName ) {\\n \\t\\t\\t\\t\/\/ Avoid corrupting the inline event attributes (https:\/\/dev.ckeditor.com\/ticket\/7243).\\n \\t\\t\\t\\t\/\/ We should not rewrite the existed protected attributes, e.g. clipboard content from editor. (https:\/\/dev.ckeditor.com\/ticket\/5218)\\n \\t\\t\\t\\tif ( protectAttributeNameRegex.test( attrName ) && attributes.indexOf( \\'data-cke-saved-\\' + attrName ) == -1 )\\n-\\t\\t\\t\\t\\treturn \\' data-cke-saved-\\' + fullAttr + \\' data-cke-\\' + CKEDITOR.rnd + \\'-\\' + fullAttr;\\n+\\t\\t\\t\\t\\treturn \\' data-cke-saved-\\' + fullAttr + \\' data-cke-\\' + randomNumber + \\'-\\' + fullAttr;\\n \\n \\t\\t\\t\\treturn fullAttr;\\n \\t\\t\\t} ) + \\'>\\';\\n@@ -897,8 +898,8 @@\\n \\t\/\/ * opening tags - e.g. `<onfoo`,\\n \\t\/\/ * closing tags - e.g. <\/onfoo> (tested in \"false positive 1\"),\\n \\t\/\/ * part of other attribute - e.g. `data-onfoo` or `fonfoo`.\\n-\\tfunction protectInsecureAttributes( html ) {\\n-\\t\\treturn html.replace( \/([^a-z0-9<\\\\-])(on\\\\w{3,})(?!>)\/gi, \\'$1data-cke-\\' + CKEDITOR.rnd + \\'-$2\\' );\\n+\\tfunction protectInsecureAttributes( html, randomNumber ) {\\n+\\t\\treturn html.replace( \/([^a-z0-9<\\\\-])(on\\\\w{3,})(?!>)\/gi, \\'$1data-cke-\\' + randomNumber + \\'-$2\\' );\\n \\t}\\n \\n \\tfunction unprotectRealComments( html ) {\\n@@ -917,11 +918,11 @@\\n \\t\\t} );\\n \\t}\\n \\n-\\tfunction protectSource( data, editor ) {\\n+\\tfunction protectSource( data, editor, randomNumber ) {\\n \\t\\tvar protectedHtml = [],\\n \\t\\t\\tprotectRegexes = editor.config.protectedSource,\\n \\t\\t\\tstore = editor._.dataStore || ( editor._.dataStore = { id: 1 } ),\\n-\\t\\t\\ttempRegex = \/<\\\\!--\\\\{cke_temp(comment)?\\\\}(\\\\d*?)-->\/g;\\n+\\t\\t\\ttempRegex = new RegExp(\\'<\\\\\\\\!--\\\\\\\\{cke_temp_\\' + randomNumber + \\'(comment)?\\\\\\\\}(\\\\\\\\d*?)-->\\', \\'g\\' );\\n \\n \\t\\tvar regexes = [\\n \\t\\t\\t\/\/ Script tags will also be forced to be protected, otherwise\\n@@ -940,7 +941,7 @@\\n \\t\\t\/\/ Note that we use a different tag for comments, as we need to\\n \\t\\t\/\/ transform them when applying filters.\\n \\t\\tdata = data.replace( ( \/<!--[\\\\s\\\\S]*?-->\/g ), function( match ) {\\n-\\t\\t\\treturn \\'<!--{cke_tempcomment}\\' + ( protectedHtml.push( match ) - 1 ) + \\'-->\\';\\n+\\t\\t\\treturn \\'<!--{cke_temp_\\' + randomNumber + \\'comment}\\' + ( protectedHtml.push( match ) - 1 ) + \\'-->\\';\\n \\t\\t} );\\n \\n \\t\\tfor ( var i = 0; i < regexes.length; i++ ) {\\n@@ -951,7 +952,8 @@\\n \\t\\t\\t\\t} );\\n \\n \\t\\t\\t\\t\/\/ Avoid protecting over protected, e.g. \/\\\\{.*?\\\\}\/\\n-\\t\\t\\t\\treturn ( \/cke_temp(comment)?\/ ).test( match ) ? match : \\'<!--{cke_temp}\\' + ( protectedHtml.push( match ) - 1 ) + \\'-->\\';\\n+\\t\\t\\t\\treturn ( tempRegex ).test( match ) ? match : \\'<!--{cke_temp_\\' + randomNumber + \\'}\\' +\\n+\\t\\t\\t\\t\\t( protectedHtml.push( match ) - 1 ) + \\'-->\\';\\n \\t\\t\\t} );\\n \\t\\t}\\n \\t\\tdata = data.replace( tempRegex, function( $, isComment, id ) {\\n@@ -1107,6 +1109,16 @@\\n \\t\\t\\t};\\n \\t\\t}\\n \\t} )();\\n+\\n+\\tfunction generateRandomNumber() {\\n+\\t\\tvar cryptoApi = window.crypto || window.msCrypto;\\n+\\n+\\t\\tif ( cryptoApi ) {\\n+\\t\\t\\treturn cryptoApi.getRandomValues( new Uint32Array( 1 ) )[ 0 ];\\n+\\t\\t}\\n+\\n+\\t\\treturn Math.floor( Math.random() *  9000000000 + 1000000000 );\\n+\\t}\\n } )();\\n \\n \/**'}}",
            "message_norm":"code refactoring.",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/htmldataprocessor.js'])",
            "num_files":1.0,
            "patch_content":"From d158413449692d920a778503502dcb22881bc949 Mon Sep 17 00:00:00 2001\nFrom: Tomasz Jakut <vepomoc@gmail.com>\nDate: Tue, 8 Feb 2022 17:35:34 +0100\nSubject: [PATCH] Code refactoring.\n\n---\n core\/htmldataprocessor.js | 40 +++++++++++++++++++++++++--------------\n 1 file changed, 26 insertions(+), 14 deletions(-)\n\ndiff --git a\/core\/htmldataprocessor.js b\/core\/htmldataprocessor.js\nindex a57e4b53d60..9c969631609 100644\n--- a\/core\/htmldataprocessor.js\n+++ b\/core\/htmldataprocessor.js\n@@ -50,17 +50,18 @@\n \t\thtmlFilter.addRules( createBogusAndFillerRules( editor, 'html' ), { applyToAll: true } );\n \n \t\teditor.on( 'toHtml', function( evt ) {\n-\t\t\tvar evtData = evt.data,\n+\t\t\tvar randomNumber = generateRandomNumber(),\n+\t\t\t\tevtData = evt.data,\n \t\t\t\tdata = evtData.dataValue,\n \t\t\t\tfixBodyTag;\n \n \t\t\t\/\/ Before we start protecting markup, make sure there are no externally injected\n \t\t\t\/\/ protection keywords.\n-\t\t\tdata = removeReservedKeywords( data );\n+\t\t\tdata = removeReservedKeywords( data, randomNumber );\n \n \t\t\t\/\/ The source data is already HTML, but we need to clean\n \t\t\t\/\/ it up and apply the filter.\n-\t\t\tdata = protectSource( data, editor );\n+\t\t\tdata = protectSource( data, editor, randomNumber );\n \n \t\t\t\/\/ Protect content of textareas. (https:\/\/dev.ckeditor.com\/ticket\/9995)\n \t\t\t\/\/ Do this before protecting attributes to avoid breaking:\n@@ -70,7 +71,7 @@\n \t\t\t\/\/ Before anything, we must protect the URL attributes as the\n \t\t\t\/\/ browser may changing them when setting the innerHTML later in\n \t\t\t\/\/ the code.\n-\t\t\tdata = protectAttributes( data );\n+\t\t\tdata = protectAttributes( data, randomNumber );\n \n \t\t\t\/\/ Protect elements than can't be set inside a DIV. E.g. IE removes\n \t\t\t\/\/ style tags from innerHTML. (https:\/\/dev.ckeditor.com\/ticket\/3710)\n@@ -90,7 +91,7 @@\n \n \t\t\t\/\/ There are attributes which may execute JavaScript code inside fixBin.\n \t\t\t\/\/ Encode them greedily. They will be unprotected right after getting HTML from fixBin. (https:\/\/dev.ckeditor.com\/ticket\/10)\n-\t\t\tdata = protectInsecureAttributes( data );\n+\t\t\tdata = protectInsecureAttributes( data, randomNumber );\n \n \t\t\tvar fixBin = evtData.context || editor.editable().getName(),\n \t\t\t\tisPre;\n@@ -110,7 +111,7 @@\n \t\t\tdata = el.getHtml().substr( 1 );\n \n \t\t\t\/\/ Restore shortly protected attribute names.\n-\t\t\tdata = data.replace( new RegExp( 'data-cke-' + CKEDITOR.rnd + '-', 'ig' ), '' );\n+\t\t\tdata = data.replace( new RegExp( 'data-cke-' + randomNumber + '-', 'ig' ), '' );\n \n \t\t\tisPre && ( data = data.replace( \/^<pre>|<\\\/pre>$\/gi, '' ) );\n \n@@ -838,13 +839,13 @@\n \n \tvar protectSelfClosingRegex = \/<cke:(param|embed)([^>]*?)\\\/?>(?!\\s*<\\\/cke:\\1)\/gi;\n \n-\tfunction protectAttributes( html ) {\n+\tfunction protectAttributes( html, randomNumber ) {\n \t\treturn html.replace( protectElementRegex, function( element, tag, attributes ) {\n \t\t\treturn '<' + tag + attributes.replace( protectAttributeRegex, function( fullAttr, attrName ) {\n \t\t\t\t\/\/ Avoid corrupting the inline event attributes (https:\/\/dev.ckeditor.com\/ticket\/7243).\n \t\t\t\t\/\/ We should not rewrite the existed protected attributes, e.g. clipboard content from editor. (https:\/\/dev.ckeditor.com\/ticket\/5218)\n \t\t\t\tif ( protectAttributeNameRegex.test( attrName ) && attributes.indexOf( 'data-cke-saved-' + attrName ) == -1 )\n-\t\t\t\t\treturn ' data-cke-saved-' + fullAttr + ' data-cke-' + CKEDITOR.rnd + '-' + fullAttr;\n+\t\t\t\t\treturn ' data-cke-saved-' + fullAttr + ' data-cke-' + randomNumber + '-' + fullAttr;\n \n \t\t\t\treturn fullAttr;\n \t\t\t} ) + '>';\n@@ -897,8 +898,8 @@\n \t\/\/ * opening tags - e.g. `<onfoo`,\n \t\/\/ * closing tags - e.g. <\/onfoo> (tested in \"false positive 1\"),\n \t\/\/ * part of other attribute - e.g. `data-onfoo` or `fonfoo`.\n-\tfunction protectInsecureAttributes( html ) {\n-\t\treturn html.replace( \/([^a-z0-9<\\-])(on\\w{3,})(?!>)\/gi, '$1data-cke-' + CKEDITOR.rnd + '-$2' );\n+\tfunction protectInsecureAttributes( html, randomNumber ) {\n+\t\treturn html.replace( \/([^a-z0-9<\\-])(on\\w{3,})(?!>)\/gi, '$1data-cke-' + randomNumber + '-$2' );\n \t}\n \n \tfunction unprotectRealComments( html ) {\n@@ -917,11 +918,11 @@\n \t\t} );\n \t}\n \n-\tfunction protectSource( data, editor ) {\n+\tfunction protectSource( data, editor, randomNumber ) {\n \t\tvar protectedHtml = [],\n \t\t\tprotectRegexes = editor.config.protectedSource,\n \t\t\tstore = editor._.dataStore || ( editor._.dataStore = { id: 1 } ),\n-\t\t\ttempRegex = \/<\\!--\\{cke_temp(comment)?\\}(\\d*?)-->\/g;\n+\t\t\ttempRegex = new RegExp('<\\\\!--\\\\{cke_temp_' + randomNumber + '(comment)?\\\\}(\\\\d*?)-->', 'g' );\n \n \t\tvar regexes = [\n \t\t\t\/\/ Script tags will also be forced to be protected, otherwise\n@@ -940,7 +941,7 @@\n \t\t\/\/ Note that we use a different tag for comments, as we need to\n \t\t\/\/ transform them when applying filters.\n \t\tdata = data.replace( ( \/<!--[\\s\\S]*?-->\/g ), function( match ) {\n-\t\t\treturn '<!--{cke_tempcomment}' + ( protectedHtml.push( match ) - 1 ) + '-->';\n+\t\t\treturn '<!--{cke_temp_' + randomNumber + 'comment}' + ( protectedHtml.push( match ) - 1 ) + '-->';\n \t\t} );\n \n \t\tfor ( var i = 0; i < regexes.length; i++ ) {\n@@ -951,7 +952,8 @@\n \t\t\t\t} );\n \n \t\t\t\t\/\/ Avoid protecting over protected, e.g. \/\\{.*?\\}\/\n-\t\t\t\treturn ( \/cke_temp(comment)?\/ ).test( match ) ? match : '<!--{cke_temp}' + ( protectedHtml.push( match ) - 1 ) + '-->';\n+\t\t\t\treturn ( tempRegex ).test( match ) ? match : '<!--{cke_temp_' + randomNumber + '}' +\n+\t\t\t\t\t( protectedHtml.push( match ) - 1 ) + '-->';\n \t\t\t} );\n \t\t}\n \t\tdata = data.replace( tempRegex, function( $, isComment, id ) {\n@@ -1107,6 +1109,16 @@\n \t\t\t};\n \t\t}\n \t} )();\n+\n+\tfunction generateRandomNumber() {\n+\t\tvar cryptoApi = window.crypto || window.msCrypto;\n+\n+\t\tif ( cryptoApi ) {\n+\t\t\treturn cryptoApi.getRandomValues( new Uint32Array( 1 ) )[ 0 ];\n+\t\t}\n+\n+\t\treturn Math.floor( Math.random() *  9000000000 + 1000000000 );\n+\t}\n } )();\n \n \/**"
        },
        {
            "index":521,
            "vuln_id":"GHSA-j383-35pm-c5h4",
            "cwe_id":"{'CWE-22'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/gruntjs\/grunt\/commit\/aad3d4521c3098fb255fb2db8f2e1d691a033665', 'https:\/\/github.com\/gruntjs\/grunt\/commit\/b0ec6e12426fc8d5720dee1702f6a67455c5986c'}",
            "dataset":"osv",
            "summary":"Path Traversal in Grunt Grunt prior to version 1.5.2 is vulnerable to path traversal.",
            "published_date":"2022-04-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/gruntjs\/grunt",
            "commit_href":"https:\/\/github.com\/gruntjs\/grunt\/commit\/b0ec6e12426fc8d5720dee1702f6a67455c5986c",
            "commit_sha":"b0ec6e12426fc8d5720dee1702f6a67455c5986c",
            "patch":"MULTI",
            "chain_ord":"['aad3d4521c3098fb255fb2db8f2e1d691a033665', 'b0ec6e12426fc8d5720dee1702f6a67455c5986c']",
            "before_first_fix_commit":"{'433f91b78df99d83daa6f56a5505ead743627c30', 'd5969eccf2493c2c579c55a617c70cab48dc12d3'}",
            "last_fix_commit":"b0ec6e12426fc8d5720dee1702f6a67455c5986c",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/12\/2022, 11:51:53",
            "message":"Merge pull request #1743 from gruntjs\/cleanup-link\n\nClean up link handling",
            "author":"Vlad Filippov",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 6, 'total': 12}",
            "files":"{'lib\/grunt\/file.js': {'additions': 6, 'deletions': 6, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/gruntjs\/grunt\/raw\/b0ec6e12426fc8d5720dee1702f6a67455c5986c\/lib%2Fgrunt%2Ffile.js', 'patch': \"@@ -294,7 +294,12 @@ file.write = function(filepath, contents, options) {\\n \/\/ processing content, writing output.\\n \/\/ Handles symlinks by coping them as files or directories.\\n file.copy = function copy(srcpath, destpath, options) {\\n-  if (file._isSymbolicLink(srcpath)) {\\n+  if (file.isLink(destpath)) {\\n+    \/\/ in case destpath is a symlink, avoid following the symlink, instead overwrite it later\\n+    fs.unlinkSync(destpath);\\n+  }\\n+\\n+  if (file.isLink(srcpath)) {\\n     file._copySymbolicLink(srcpath, destpath);\\n   } else if (file.isDir(srcpath)) {\\n     \/\/ Copy a directory, recursively.\\n@@ -452,11 +457,6 @@ file.isPathCwd = function() {\\n   }\\n };\\n \\n-file._isSymbolicLink = function() {\\n-  var filepath = path.join.apply(path, arguments);\\n-  return fs.lstatSync(filepath).isSymbolicLink();\\n-};\\n-\\n file._copySymbolicLink = function(srcpath, destpath) {\\n   var destdir = path.join(destpath, '..');\\n   \/\/ Use the correct relative path for the symlink\"}}",
            "message_norm":"merge pull request #1743 from gruntjs\/cleanup-link\n\nclean up link handling",
            "language":"en",
            "entities":"[('#1743', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/grunt\/file.js'])",
            "num_files":1.0,
            "patch_content":"From 433f91b78df99d83daa6f56a5505ead743627c30 Mon Sep 17 00:00:00 2001\nFrom: Vlad Filippov <vlad.filippov@gmail.com>\nDate: Mon, 11 Apr 2022 11:38:22 -0400\nSubject: [PATCH] Clean up link handling\n\n---\n lib\/grunt\/file.js | 12 ++++++------\n 1 file changed, 6 insertions(+), 6 deletions(-)\n\ndiff --git a\/lib\/grunt\/file.js b\/lib\/grunt\/file.js\nindex b5f51a22..604736cd 100644\n--- a\/lib\/grunt\/file.js\n+++ b\/lib\/grunt\/file.js\n@@ -294,7 +294,12 @@ file.write = function(filepath, contents, options) {\n \/\/ processing content, writing output.\n \/\/ Handles symlinks by coping them as files or directories.\n file.copy = function copy(srcpath, destpath, options) {\n-  if (file._isSymbolicLink(srcpath)) {\n+  if (file.isLink(destpath)) {\n+    \/\/ in case destpath is a symlink, avoid following the symlink, instead overwrite it later\n+    fs.unlinkSync(destpath);\n+  }\n+\n+  if (file.isLink(srcpath)) {\n     file._copySymbolicLink(srcpath, destpath);\n   } else if (file.isDir(srcpath)) {\n     \/\/ Copy a directory, recursively.\n@@ -452,11 +457,6 @@ file.isPathCwd = function() {\n   }\n };\n \n-file._isSymbolicLink = function() {\n-  var filepath = path.join.apply(path, arguments);\n-  return fs.lstatSync(filepath).isSymbolicLink();\n-};\n-\n file._copySymbolicLink = function(srcpath, destpath) {\n   var destdir = path.join(destpath, '..');\n   \/\/ Use the correct relative path for the symlink"
        },
        {
            "index":951,
            "vuln_id":"GHSA-w8rc-pgxq-x2cj",
            "cwe_id":"{'CWE-20'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/shopizer-ecommerce\/shopizer\/commit\/929ca0839a80c6f4dad087e0259089908787ad2a'}",
            "dataset":"osv",
            "summary":"Negative charge in shopping cart in Shopizer ### Impact\nUsing API or Controller based versions negative quantity is not adequately validated hence creating incorrect shopping cart and order total. \n\n### Patches\nAdding a back-end verification to check that quantity parameter isn't negative. If so, it is set to 1. Patched in 2.11.0\n\n### Workarounds\nWithout uprading, it's possible to just apply the fixes in the same files it's done for the patch. Or you use javax constraint validation on the quantity parameter.\n\n### References\n[Input Validation](https:\/\/cheatsheetseries.owasp.org\/cheatsheets\/Input_Validation_Cheat_Sheet.html)\n[Using bean validation constraint](https:\/\/javaee.github.io\/tutorial\/bean-validation002.html)\n[Commits with fixes](https:\/\/github.com\/shopizer-ecommerce\/shopizer\/commit\/929ca0839a80c6f4dad087e0259089908787ad2a)\nCVE Details below : \n[Mitre](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-11007)\n[NVD](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-11007)\n\n### Credits\nFound and solved by Yannick Gosset from Aix-Marseille University cybersecurity\nmaster program supervised by Yassine Ilmi",
            "published_date":"2020-04-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/shopizer-ecommerce\/shopizer",
            "commit_href":"https:\/\/github.com\/shopizer-ecommerce\/shopizer\/commit\/929ca0839a80c6f4dad087e0259089908787ad2a",
            "commit_sha":"929ca0839a80c6f4dad087e0259089908787ad2a",
            "patch":"SINGLE",
            "chain_ord":"['929ca0839a80c6f4dad087e0259089908787ad2a']",
            "before_first_fix_commit":"{'de8a8e3183f8c5fed4695f889e309a6fff70adae', '6858049b39bdc51b71e6419b7c4bba1347737cb7'}",
            "last_fix_commit":"929ca0839a80c6f4dad087e0259089908787ad2a",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/10\/2020, 13:35:12",
            "message":"Merge pull request from GHSA-w8rc-pgxq-x2cj\n\nFixing negative charge vulnerability",
            "author":"Shopizer",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 7, 'total': 12}",
            "files":"{'sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java': {'additions': 5, 'deletions': 7, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/shopizer-ecommerce\/shopizer\/raw\/929ca0839a80c6f4dad087e0259089908787ad2a\/sm-shop%2Fsrc%2Fmain%2Fjava%2Fcom%2Fsalesmanager%2Fshop%2Fstore%2Fcontroller%2FshoppingCart%2Ffacade%2FShoppingCartFacadeImpl.java', 'patch': '@@ -108,7 +108,7 @@ public ShoppingCartData addItemsToShoppingCart( final ShoppingCartData shoppingC\\n     {\\n \\n         ShoppingCart cartModel = null;\\n-        \\n+        if(item.getQuantity() < 1) item.setQuantity(1);\\n         \/**\\n          * Sometimes a user logs in and a shopping cart is present in db (shoppingCartData\\n          * but ui has no cookie with shopping cart code so the cart code will have\\n@@ -216,7 +216,7 @@ private com.salesmanager.core.model.shoppingcart.ShoppingCartItem createCartItem\\n         }\\n         \\t\\n         for(ProductAvailability availability : availabilities) {\\n-        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() ==0) {\\n+        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() <= 0) {\\n                 throw new Exception( \"Item with id \" + product.getId() + \" is not available\");\\n         \\t}\\n         }\\n@@ -288,7 +288,7 @@ private com.salesmanager.core.model.shoppingcart.ShoppingCartItem createCartItem\\n         }\\n         \\t\\n         for(ProductAvailability availability : availabilities) {\\n-        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() ==0) {\\n+        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() <= 0) {\\n                 throw new Exception( \"Item with id \" + product.getId() + \" is not available\");\\n         \\t}\\n         }\\n@@ -554,8 +554,7 @@ public ShoppingCartData updateCartItem( final Long itemID, final String cartId,\\n         return null;\\n     }\\n     \\n-    @SuppressWarnings(\"unchecked\")\\n-\\t@Override\\n+    @Override\\n     public ShoppingCartData updateCartItems( final List<ShoppingCartItem> shoppingCartItems, final MerchantStore store, final Language language )\\n             throws Exception\\n         {\\n@@ -720,7 +719,6 @@ public ReadableShoppingCart addToCart(PersistableShoppingCartItem item, Merchant\\n \\t}\\n \\t\\n \\n-\\t@SuppressWarnings(\"unchecked\")\\n \\t@Override\\n \\tpublic void removeShoppingCartItem(String cartCode, Long productId,\\n \\t      MerchantStore merchant, Language language) throws Exception {\\n@@ -914,7 +912,7 @@ public ReadableShoppingCart addToCart(Customer customer, PersistableShoppingCart\\n \\t\\t\\n \\t\\tValidate.notNull(customer,\"Customer cannot be null\");\\n \\t\\tValidate.notNull(customer.getId(),\"Customer.id cannot be null or empty\");\\n-\\t\\t\\n+\\t\\tif(item.getQuantity() < 1) item.setQuantity(1);\\n \\t\\t\/\/Check if customer has an existing shopping cart\\n \\t\\tShoppingCart cartModel = shoppingCartService.getByCustomer(customer);'}}",
            "message_norm":"merge pull request from ghsa-w8rc-pgxq-x2cj\n\nfixing negative charge vulnerability",
            "language":"en",
            "entities":"[('ghsa-w8rc-pgxq-x2cj', 'VULNID', 'GHSA'), ('fixing', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java'])",
            "num_files":1.0,
            "patch_content":"From 5fe561634c1d06b56b87cbda3e27ca2ed6c120f9 Mon Sep 17 00:00:00 2001\nFrom: \"yannick.gosset\" <yannick.gosset@etu.univ-amu.fr>\nDate: Thu, 9 Apr 2020 00:25:45 +0200\nSubject: [PATCH 1\/2] Checking that quantity isn't negative. If so it sets\n quantity to 1.\n\n---\n ...\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java    | 10 ++++------\n 1 file changed, 4 insertions(+), 6 deletions(-)\n\ndiff --git a\/sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java b\/sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java\nindex 09b20c2a9b..768e8f2e86 100755\n--- a\/sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java\n+++ b\/sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java\n@@ -108,7 +108,7 @@ public ShoppingCartData addItemsToShoppingCart( final ShoppingCartData shoppingC\n     {\n \n         ShoppingCart cartModel = null;\n-        \n+        if(item.getQuantity() < 1) item.setQuantity(1);\n         \/**\n          * Sometimes a user logs in and a shopping cart is present in db (shoppingCartData\n          * but ui has no cookie with shopping cart code so the cart code will have\n@@ -216,7 +216,7 @@ private com.salesmanager.core.model.shoppingcart.ShoppingCartItem createCartItem\n         }\n         \t\n         for(ProductAvailability availability : availabilities) {\n-        \tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() ==0) {\n+        \tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() <= 0) {\n                 throw new Exception( \"Item with id \" + product.getId() + \" is not available\");\n         \t}\n         }\n@@ -288,7 +288,7 @@ private com.salesmanager.core.model.shoppingcart.ShoppingCartItem createCartItem\n         }\n         \t\n         for(ProductAvailability availability : availabilities) {\n-        \tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() ==0) {\n+        \tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() <= 0) {\n                 throw new Exception( \"Item with id \" + product.getId() + \" is not available\");\n         \t}\n         }\n@@ -554,8 +554,7 @@ public ShoppingCartData updateCartItem( final Long itemID, final String cartId,\n         return null;\n     }\n     \n-    @SuppressWarnings(\"unchecked\")\n-\t@Override\n+    @Override\n     public ShoppingCartData updateCartItems( final List<ShoppingCartItem> shoppingCartItems, final MerchantStore store, final Language language )\n             throws Exception\n         {\n@@ -720,7 +719,6 @@ public ReadableShoppingCart addToCart(PersistableShoppingCartItem item, Merchant\n \t}\n \t\n \n-\t@SuppressWarnings(\"unchecked\")\n \t@Override\n \tpublic void removeShoppingCartItem(String cartCode, Long productId,\n \t      MerchantStore merchant, Language language) throws Exception {\n\nFrom 6858049b39bdc51b71e6419b7c4bba1347737cb7 Mon Sep 17 00:00:00 2001\nFrom: \"yannick.gosset\" <yannick.gosset@etu.univ-amu.fr>\nDate: Thu, 9 Apr 2020 18:36:48 +0200\nSubject: [PATCH 2\/2] Adding quantity verification to another function that\n uses PersitableShoppingCartItem\n\n---\n ...\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java  | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java b\/sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java\nindex 768e8f2e86..ee9d1e8b86 100755\n--- a\/sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java\n+++ b\/sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java\n@@ -912,7 +912,7 @@ public ReadableShoppingCart addToCart(Customer customer, PersistableShoppingCart\n \t\t\n \t\tValidate.notNull(customer,\"Customer cannot be null\");\n \t\tValidate.notNull(customer.getId(),\"Customer.id cannot be null or empty\");\n-\t\t\n+\t\tif(item.getQuantity() < 1) item.setQuantity(1);\n \t\t\/\/Check if customer has an existing shopping cart\n \t\tShoppingCart cartModel = shoppingCartService.getByCustomer(customer);"
        },
        {
            "index":106,
            "vuln_id":"GHSA-fp76-f299-v3hj",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/neorazorx\/facturascripts\/commit\/1d1edb40b40016d7fd2893b410b98569d7facca1'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in FacturaScripts Cross-site Scripting (XSS) - Stored in GitHub repository neorazorx\/facturascripts prior to 2022.06.",
            "published_date":"2022-06-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/neorazorx\/facturascripts",
            "commit_href":"https:\/\/github.com\/neorazorx\/facturascripts\/commit\/1d1edb40b40016d7fd2893b410b98569d7facca1",
            "commit_sha":"1d1edb40b40016d7fd2893b410b98569d7facca1",
            "patch":"SINGLE",
            "chain_ord":"['1d1edb40b40016d7fd2893b410b98569d7facca1']",
            "before_first_fix_commit":"{'73a6595ca85984d65f656c6356fabb23d1936c54'}",
            "last_fix_commit":"1d1edb40b40016d7fd2893b410b98569d7facca1",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 09:55:32",
            "message":"Force to download SVG files to prevent security problems.\n------\nForzamos a descargar los archivos SVG para evitar problemas de seguridad.",
            "author":"Carlos Garcia Gomez",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 10, 'total': 29}",
            "files":"{'Core\/App\/AppRouter.php': {'additions': 19, 'deletions': 10, 'changes': 29, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NeoRazorX\/facturascripts\/raw\/1d1edb40b40016d7fd2893b410b98569d7facca1\/Core%2FApp%2FAppRouter.php', 'patch': '@@ -127,8 +127,7 @@ public function getFile(): bool\\n         $allowedFolders = [\\'node_modules\\', \\'vendor\\', \\'Dinamic\\', \\'Core\\', \\'Plugins\\', \\'MyFiles\/Public\\'];\\n         foreach ($allowedFolders as $folder) {\\n             if (\\'\/\\' . $folder === substr($uri, 0, 1 + strlen($folder))) {\\n-                header(\\'Content-Type: \\' . $this->getMime($filePath));\\n-                readfile($filePath);\\n+                $this->download($filePath);\\n                 return true;\\n             }\\n         }\\n@@ -137,14 +136,7 @@ public function getFile(): bool\\n         $token = filter_input(INPUT_GET, \\'myft\\');\\n         $fixedFilePath = substr(urldecode($uri), 1);\\n         if (\\'\/MyFiles\/\\' === substr($uri, 0, 9) && $token && MyFilesToken::validate($fixedFilePath, $token)) {\\n-            header(\\'Content-Type: \\' . $this->getMime($filePath));\\n-\\n-            \/\/ disable the buffer if enabled\\n-            if (ob_get_contents()) {\\n-                ob_end_flush();\\n-            }\\n-\\n-            readfile($filePath);\\n+            $this->download($filePath);\\n             return true;\\n         }\\n \\n@@ -205,6 +197,23 @@ private function deploy()\\n         }\\n     }\\n \\n+    private function download(string $filePath)\\n+    {\\n+        header(\\'Content-Type: \\' . $this->getMime($filePath));\\n+\\n+        \/\/ disable the buffer if enabled\\n+        if (ob_get_contents()) {\\n+            ob_end_flush();\\n+        }\\n+\\n+        \/\/ force to download svg files to prevent XSS attacks\\n+        if (strpos($filePath, \\'.svg\\') !== false) {\\n+            header(\\'Content-Disposition: attachment; filename=\"\\' . basename($filePath) . \\'\"\\');\\n+        }\\n+\\n+        readfile($filePath);\\n+    }\\n+\\n     \/**\\n      * Return the mime type from given file.\\n      *'}}",
            "message_norm":"force to download svg files to prevent security problems.\n------\nforzamos a descargar los archivos svg para evitar problemas de seguridad.",
            "language":"es",
            "entities":"[('prevent', 'ACTION', ''), ('security', 'SECWORD', ''), ('problems', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Core\/App\/AppRouter.php'])",
            "num_files":1.0,
            "patch_content":"From 1d1edb40b40016d7fd2893b410b98569d7facca1 Mon Sep 17 00:00:00 2001\nFrom: Carlos Garcia Gomez <neorazorx@gmail.com>\nDate: Thu, 28 Apr 2022 11:55:32 +0200\nSubject: [PATCH] Force to download SVG files to prevent security problems.\n ------ Forzamos a descargar los archivos SVG para evitar problemas de\n seguridad.\n\n---\n Core\/App\/AppRouter.php | 29 +++++++++++++++++++----------\n 1 file changed, 19 insertions(+), 10 deletions(-)\n\ndiff --git a\/Core\/App\/AppRouter.php b\/Core\/App\/AppRouter.php\nindex 1eed63f833..1de2d09bc9 100644\n--- a\/Core\/App\/AppRouter.php\n+++ b\/Core\/App\/AppRouter.php\n@@ -127,8 +127,7 @@ public function getFile(): bool\n         $allowedFolders = ['node_modules', 'vendor', 'Dinamic', 'Core', 'Plugins', 'MyFiles\/Public'];\n         foreach ($allowedFolders as $folder) {\n             if ('\/' . $folder === substr($uri, 0, 1 + strlen($folder))) {\n-                header('Content-Type: ' . $this->getMime($filePath));\n-                readfile($filePath);\n+                $this->download($filePath);\n                 return true;\n             }\n         }\n@@ -137,14 +136,7 @@ public function getFile(): bool\n         $token = filter_input(INPUT_GET, 'myft');\n         $fixedFilePath = substr(urldecode($uri), 1);\n         if ('\/MyFiles\/' === substr($uri, 0, 9) && $token && MyFilesToken::validate($fixedFilePath, $token)) {\n-            header('Content-Type: ' . $this->getMime($filePath));\n-\n-            \/\/ disable the buffer if enabled\n-            if (ob_get_contents()) {\n-                ob_end_flush();\n-            }\n-\n-            readfile($filePath);\n+            $this->download($filePath);\n             return true;\n         }\n \n@@ -205,6 +197,23 @@ private function deploy()\n         }\n     }\n \n+    private function download(string $filePath)\n+    {\n+        header('Content-Type: ' . $this->getMime($filePath));\n+\n+        \/\/ disable the buffer if enabled\n+        if (ob_get_contents()) {\n+            ob_end_flush();\n+        }\n+\n+        \/\/ force to download svg files to prevent XSS attacks\n+        if (strpos($filePath, '.svg') !== false) {\n+            header('Content-Disposition: attachment; filename=\"' . basename($filePath) . '\"');\n+        }\n+\n+        readfile($filePath);\n+    }\n+\n     \/**\n      * Return the mime type from given file.\n      *"
        },
        {
            "index":478,
            "vuln_id":"GHSA-f6px-w8rh-7r89",
            "cwe_id":"{'CWE-362', 'CWE-732'}",
            "score":4.7,
            "chain":"{'https:\/\/github.com\/beego\/beego\/pull\/3975\/commits\/f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd'}",
            "dataset":"osv",
            "summary":"Data race in Beego The File Session Manager in Beego 1.10.0 allows local users to read session files because there is a race condition involving file creation within a directory with weak permissions.",
            "published_date":"2021-08-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/beego\/beego",
            "commit_href":"https:\/\/github.com\/beego\/beego\/pull\/3975\/commits\/f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd",
            "commit_sha":"f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd",
            "patch":"SINGLE",
            "chain_ord":"['f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd']",
            "before_first_fix_commit":"{'8f3d1c5f42fce57e83e1c3f7d180477595db7cca'}",
            "last_fix_commit":"f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/22\/2020, 15:42:54",
            "message":"Change permission mask",
            "author":"Nico Waisman",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'session\/sess_file.go': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/beego\/beego\/raw\/f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd\/session%2Fsess_file.go', 'patch': '@@ -138,7 +138,7 @@ func (fp *FileProvider) SessionRead(sid string) (Store, error) {\\n \\tfilepder.lock.Lock()\\n \\tdefer filepder.lock.Unlock()\\n \\n-\\terr := os.MkdirAll(path.Join(fp.savePath, string(sid[0]), string(sid[1])), 0777)\\n+\\terr := os.MkdirAll(path.Join(fp.savePath, string(sid[0]), string(sid[1])), 0755)\\n \\tif err != nil {\\n \\t\\tSLogger.Println(err.Error())\\n \\t}\\n@@ -231,7 +231,7 @@ func (fp *FileProvider) SessionRegenerate(oldsid, sid string) (Store, error) {\\n \\t\\treturn nil, fmt.Errorf(\"newsid %s exist\", newSidFile)\\n \\t}\\n \\n-\\terr = os.MkdirAll(newPath, 0777)\\n+\\terr = os.MkdirAll(newPath, 0755)\\n \\tif err != nil {\\n \\t\\tSLogger.Println(err.Error())\\n \\t}'}}",
            "message_norm":"change permission mask",
            "language":"en",
            "entities":"[('change', 'ACTION', ''), ('permission', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['session\/sess_file.go'])",
            "num_files":1.0,
            "patch_content":"From f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd Mon Sep 17 00:00:00 2001\nFrom: Nico Waisman <nicowaisman@github.com>\nDate: Wed, 22 Apr 2020 08:42:54 -0700\nSubject: [PATCH] Change permission mask\n\n---\n session\/sess_file.go | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/session\/sess_file.go b\/session\/sess_file.go\nindex db14352230..9f8ccaedfe 100644\n--- a\/session\/sess_file.go\n+++ b\/session\/sess_file.go\n@@ -138,7 +138,7 @@ func (fp *FileProvider) SessionRead(sid string) (Store, error) {\n \tfilepder.lock.Lock()\n \tdefer filepder.lock.Unlock()\n \n-\terr := os.MkdirAll(path.Join(fp.savePath, string(sid[0]), string(sid[1])), 0777)\n+\terr := os.MkdirAll(path.Join(fp.savePath, string(sid[0]), string(sid[1])), 0755)\n \tif err != nil {\n \t\tSLogger.Println(err.Error())\n \t}\n@@ -231,7 +231,7 @@ func (fp *FileProvider) SessionRegenerate(oldsid, sid string) (Store, error) {\n \t\treturn nil, fmt.Errorf(\"newsid %s exist\", newSidFile)\n \t}\n \n-\terr = os.MkdirAll(newPath, 0777)\n+\terr = os.MkdirAll(newPath, 0755)\n \tif err != nil {\n \t\tSLogger.Println(err.Error())\n \t}"
        },
        {
            "index":463,
            "vuln_id":"GHSA-v6wr-fch2-vm5w",
            "cwe_id":"{'CWE-200'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/orientechnologies\/orientdb\/commit\/668ece96be210e742a4e2820a3085b215cf55104'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects com.orientechnologies:orientdb-studio server\/network\/protocol\/http\/OHttpSessionManager.java in the Studio component in OrientDB Server Community Edition before 2.0.15 and 2.1.x before 2.1.1 improperly relies on the java.util.Random class for generation of random Session ID values, which makes it easier for remote attackers to predict a value by determining the internal state of the PRNG in this class.",
            "published_date":"2018-10-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/orientechnologies\/orientdb",
            "commit_href":"https:\/\/github.com\/orientechnologies\/orientdb\/commit\/668ece96be210e742a4e2820a3085b215cf55104",
            "commit_sha":"668ece96be210e742a4e2820a3085b215cf55104",
            "patch":"SINGLE",
            "chain_ord":"['668ece96be210e742a4e2820a3085b215cf55104']",
            "before_first_fix_commit":"{'41fd20ab022e22bce32d62372dbe279693322086'}",
            "last_fix_commit":"668ece96be210e742a4e2820a3085b215cf55104",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/04\/2015, 14:45:12",
            "message":"Adopted SecureRandom to avoid predicable random numbers in session",
            "author":"lvca",
            "comments":null,
            "stats":"{'additions': 136, 'deletions': 135, 'total': 271}",
            "files":"{'server\/src\/main\/java\/com\/orientechnologies\/orient\/server\/network\/protocol\/http\/OHttpSessionManager.java': {'additions': 136, 'deletions': 135, 'changes': 271, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/orientechnologies\/orientdb\/raw\/668ece96be210e742a4e2820a3085b215cf55104\/server%2Fsrc%2Fmain%2Fjava%2Fcom%2Forientechnologies%2Forient%2Fserver%2Fnetwork%2Fprotocol%2Fhttp%2FOHttpSessionManager.java', 'patch': '@@ -1,141 +1,142 @@\\n \/*\\r\\n-    *\\r\\n-    *  *  Copyright 2014 Orient Technologies LTD (info(at)orientechnologies.com)\\r\\n-    *  *\\r\\n-    *  *  Licensed under the Apache License, Version 2.0 (the \"License\");\\r\\n-    *  *  you may not use this file except in compliance with the License.\\r\\n-    *  *  You may obtain a copy of the License at\\r\\n-    *  *\\r\\n-    *  *       http:\/\/www.apache.org\/licenses\/LICENSE-2.0\\r\\n-    *  *\\r\\n-    *  *  Unless required by applicable law or agreed to in writing, software\\r\\n-    *  *  distributed under the License is distributed on an \"AS IS\" BASIS,\\r\\n-    *  *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\r\\n-    *  *  See the License for the specific language governing permissions and\\r\\n-    *  *  limitations under the License.\\r\\n-    *  *\\r\\n-    *  * For more information: http:\/\/www.orientechnologies.com\\r\\n-    *\\r\\n-    *\/\\r\\n+ *\\r\\n+ *  *  Copyright 2014 Orient Technologies LTD (info(at)orientechnologies.com)\\r\\n+ *  *\\r\\n+ *  *  Licensed under the Apache License, Version 2.0 (the \"License\");\\r\\n+ *  *  you may not use this file except in compliance with the License.\\r\\n+ *  *  You may obtain a copy of the License at\\r\\n+ *  *\\r\\n+ *  *       http:\/\/www.apache.org\/licenses\/LICENSE-2.0\\r\\n+ *  *\\r\\n+ *  *  Unless required by applicable law or agreed to in writing, software\\r\\n+ *  *  distributed under the License is distributed on an \"AS IS\" BASIS,\\r\\n+ *  *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\r\\n+ *  *  See the License for the specific language governing permissions and\\r\\n+ *  *  limitations under the License.\\r\\n+ *  *\\r\\n+ *  * For more information: http:\/\/www.orientechnologies.com\\r\\n+ *\\r\\n+ *\/\\r\\n package com.orientechnologies.orient.server.network.protocol.http;\\r\\n \\r\\n import com.orientechnologies.common.concur.resource.OSharedResourceAbstract;\\r\\n- import com.orientechnologies.common.log.OLogManager;\\r\\n- import com.orientechnologies.orient.core.Orient;\\r\\n- import com.orientechnologies.orient.core.config.OGlobalConfiguration;\\r\\n-\\r\\n- import java.util.HashMap;\\r\\n- import java.util.Iterator;\\r\\n- import java.util.Map;\\r\\n- import java.util.Map.Entry;\\r\\n- import java.util.Random;\\r\\n- import java.util.TimerTask;\\r\\n+import com.orientechnologies.common.log.OLogManager;\\r\\n+import com.orientechnologies.orient.core.Orient;\\r\\n+import com.orientechnologies.orient.core.config.OGlobalConfiguration;\\r\\n+\\r\\n+import java.security.SecureRandom;\\r\\n+import java.util.HashMap;\\r\\n+import java.util.Iterator;\\r\\n+import java.util.Map;\\r\\n+import java.util.Map.Entry;\\r\\n+import java.util.Random;\\r\\n+import java.util.TimerTask;\\r\\n \\r\\n \/**\\r\\n-  * Handles the HTTP sessions such as a real HTTP Server.\\r\\n-  *\\r\\n-  * @author Luca Garulli\\r\\n-  *\/\\r\\n- public class OHttpSessionManager extends OSharedResourceAbstract {\\r\\n-   private static final OHttpSessionManager instance = new OHttpSessionManager();\\r\\n-   private Map<String, OHttpSession>        sessions = new HashMap<String, OHttpSession>();\\r\\n-   private int                              expirationTime;\\r\\n-   private Random                           random   = new Random();\\r\\n-\\r\\n-   protected OHttpSessionManager() {\\r\\n-     expirationTime = OGlobalConfiguration.NETWORK_HTTP_SESSION_EXPIRE_TIMEOUT.getValueAsInteger() * 1000;\\r\\n-\\r\\n-     Orient.instance().scheduleTask(new TimerTask() {\\r\\n-       @Override\\r\\n-       public void run() {\\r\\n-         final int expired = checkSessionsValidity();\\r\\n-         if (expired > 0)\\r\\n-           OLogManager.instance().debug(this, \"Removed %d session because expired\", expired);\\r\\n-       }\\r\\n-     }, expirationTime, expirationTime);\\r\\n-   }\\r\\n-\\r\\n-   public int checkSessionsValidity() {\\r\\n-     int expired = 0;\\r\\n-\\r\\n-     acquireExclusiveLock();\\r\\n-     try {\\r\\n-       final long now = System.currentTimeMillis();\\r\\n-\\r\\n-       Entry<String, OHttpSession> s;\\r\\n-       for (Iterator<Map.Entry<String, OHttpSession>> it = sessions.entrySet().iterator(); it.hasNext();) {\\r\\n-         s = it.next();\\r\\n-\\r\\n-         if (now - s.getValue().getUpdatedOn() > expirationTime) {\\r\\n-           \/\/ REMOVE THE SESSION\\r\\n-           it.remove();\\r\\n-           expired++;\\r\\n-         }\\r\\n-       }\\r\\n-\\r\\n-     } finally {\\r\\n-       releaseExclusiveLock();\\r\\n-     }\\r\\n-\\r\\n-     return expired;\\r\\n-   }\\r\\n-\\r\\n-   public OHttpSession[] getSessions() {\\r\\n-     acquireSharedLock();\\r\\n-     try {\\r\\n-\\r\\n-       return (OHttpSession[]) sessions.values().toArray(new OHttpSession[sessions.size()]);\\r\\n-\\r\\n-     } finally {\\r\\n-       releaseSharedLock();\\r\\n-     }\\r\\n-   }\\r\\n-\\r\\n-   public OHttpSession getSession(final String iId) {\\r\\n-     acquireSharedLock();\\r\\n-     try {\\r\\n-\\r\\n-       final OHttpSession sess = sessions.get(iId);\\r\\n-       if (sess != null)\\r\\n-         sess.updateLastUpdatedOn();\\r\\n-       return sess;\\r\\n-\\r\\n-     } finally {\\r\\n-       releaseSharedLock();\\r\\n-     }\\r\\n-   }\\r\\n-\\r\\n-   public String createSession(final String iDatabaseName, final String iUserName, final String iUserPassword) {\\r\\n-     acquireExclusiveLock();\\r\\n-     try {\\r\\n-       final String id = \"OS\" + System.currentTimeMillis() + random.nextLong();\\r\\n-       sessions.put(id, new OHttpSession(id, iDatabaseName, iUserName, iUserPassword));\\r\\n-       return id;\\r\\n-\\r\\n-     } finally {\\r\\n-       releaseExclusiveLock();\\r\\n-     }\\r\\n-   }\\r\\n-\\r\\n-   public OHttpSession removeSession(final String iSessionId) {\\r\\n-     acquireExclusiveLock();\\r\\n-     try {\\r\\n-       return sessions.remove(iSessionId);\\r\\n-\\r\\n-     } finally {\\r\\n-       releaseExclusiveLock();\\r\\n-     }\\r\\n-   }\\r\\n-\\r\\n-   public int getExpirationTime() {\\r\\n-     return expirationTime;\\r\\n-   }\\r\\n-\\r\\n-   public void setExpirationTime(int expirationTime) {\\r\\n-     this.expirationTime = expirationTime;\\r\\n-   }\\r\\n-\\r\\n-   public static OHttpSessionManager getInstance() {\\r\\n-     return instance;\\r\\n-   }\\r\\n- }\\r\\n+ * Handles the HTTP sessions such as a real HTTP Server.\\r\\n+ *\\r\\n+ * @author Luca Garulli\\r\\n+ *\/\\r\\n+public class OHttpSessionManager extends OSharedResourceAbstract {\\r\\n+  private static final OHttpSessionManager instance = new OHttpSessionManager();\\r\\n+  private Map<String, OHttpSession>        sessions = new HashMap<String, OHttpSession>();\\r\\n+  private int                              expirationTime;\\r\\n+  private Random                           random   = new SecureRandom();\\r\\n+\\r\\n+  protected OHttpSessionManager() {\\r\\n+    expirationTime = OGlobalConfiguration.NETWORK_HTTP_SESSION_EXPIRE_TIMEOUT.getValueAsInteger() * 1000;\\r\\n+\\r\\n+    Orient.instance().scheduleTask(new TimerTask() {\\r\\n+      @Override\\r\\n+      public void run() {\\r\\n+        final int expired = checkSessionsValidity();\\r\\n+        if (expired > 0)\\r\\n+          OLogManager.instance().debug(this, \"Removed %d session because expired\", expired);\\r\\n+      }\\r\\n+    }, expirationTime, expirationTime);\\r\\n+  }\\r\\n+\\r\\n+  public int checkSessionsValidity() {\\r\\n+    int expired = 0;\\r\\n+\\r\\n+    acquireExclusiveLock();\\r\\n+    try {\\r\\n+      final long now = System.currentTimeMillis();\\r\\n+\\r\\n+      Entry<String, OHttpSession> s;\\r\\n+      for (Iterator<Map.Entry<String, OHttpSession>> it = sessions.entrySet().iterator(); it.hasNext();) {\\r\\n+        s = it.next();\\r\\n+\\r\\n+        if (now - s.getValue().getUpdatedOn() > expirationTime) {\\r\\n+          \/\/ REMOVE THE SESSION\\r\\n+          it.remove();\\r\\n+          expired++;\\r\\n+        }\\r\\n+      }\\r\\n+\\r\\n+    } finally {\\r\\n+      releaseExclusiveLock();\\r\\n+    }\\r\\n+\\r\\n+    return expired;\\r\\n+  }\\r\\n+\\r\\n+  public OHttpSession[] getSessions() {\\r\\n+    acquireSharedLock();\\r\\n+    try {\\r\\n+\\r\\n+      return (OHttpSession[]) sessions.values().toArray(new OHttpSession[sessions.size()]);\\r\\n+\\r\\n+    } finally {\\r\\n+      releaseSharedLock();\\r\\n+    }\\r\\n+  }\\r\\n+\\r\\n+  public OHttpSession getSession(final String iId) {\\r\\n+    acquireSharedLock();\\r\\n+    try {\\r\\n+\\r\\n+      final OHttpSession sess = sessions.get(iId);\\r\\n+      if (sess != null)\\r\\n+        sess.updateLastUpdatedOn();\\r\\n+      return sess;\\r\\n+\\r\\n+    } finally {\\r\\n+      releaseSharedLock();\\r\\n+    }\\r\\n+  }\\r\\n+\\r\\n+  public String createSession(final String iDatabaseName, final String iUserName, final String iUserPassword) {\\r\\n+    acquireExclusiveLock();\\r\\n+    try {\\r\\n+      final String id = \"OS\" + System.currentTimeMillis() + random.nextLong();\\r\\n+      sessions.put(id, new OHttpSession(id, iDatabaseName, iUserName, iUserPassword));\\r\\n+      return id;\\r\\n+\\r\\n+    } finally {\\r\\n+      releaseExclusiveLock();\\r\\n+    }\\r\\n+  }\\r\\n+\\r\\n+  public OHttpSession removeSession(final String iSessionId) {\\r\\n+    acquireExclusiveLock();\\r\\n+    try {\\r\\n+      return sessions.remove(iSessionId);\\r\\n+\\r\\n+    } finally {\\r\\n+      releaseExclusiveLock();\\r\\n+    }\\r\\n+  }\\r\\n+\\r\\n+  public int getExpirationTime() {\\r\\n+    return expirationTime;\\r\\n+  }\\r\\n+\\r\\n+  public void setExpirationTime(int expirationTime) {\\r\\n+    this.expirationTime = expirationTime;\\r\\n+  }\\r\\n+\\r\\n+  public static OHttpSessionManager getInstance() {\\r\\n+    return instance;\\r\\n+  }\\r\\n+}'}}",
            "message_norm":"adopted securerandom to avoid predicable random numbers in session",
            "language":"en",
            "entities":"[('securerandom', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/src\/main\/java\/com\/orientechnologies\/orient\/server\/network\/protocol\/http\/OHttpSessionManager.java'])",
            "num_files":1.0,
            "patch_content":"From 668ece96be210e742a4e2820a3085b215cf55104 Mon Sep 17 00:00:00 2001\nFrom: lvca <l.garulli@gmail.com>\nDate: Sat, 4 Apr 2015 11:45:12 -0300\nSubject: [PATCH] Adopted SecureRandom to avoid predicable random numbers in\n session\n\n---\n ...\/protocol\/http\/OHttpSessionManager.java    | 271 +++++++++---------\n 1 file changed, 136 insertions(+), 135 deletions(-)\n\ndiff --git a\/server\/src\/main\/java\/com\/orientechnologies\/orient\/server\/network\/protocol\/http\/OHttpSessionManager.java b\/server\/src\/main\/java\/com\/orientechnologies\/orient\/server\/network\/protocol\/http\/OHttpSessionManager.java\nindex bcc581a06d6..51a16a4349e 100755\n--- a\/server\/src\/main\/java\/com\/orientechnologies\/orient\/server\/network\/protocol\/http\/OHttpSessionManager.java\n+++ b\/server\/src\/main\/java\/com\/orientechnologies\/orient\/server\/network\/protocol\/http\/OHttpSessionManager.java\n@@ -1,141 +1,142 @@\n \/*\r\n-    *\r\n-    *  *  Copyright 2014 Orient Technologies LTD (info(at)orientechnologies.com)\r\n-    *  *\r\n-    *  *  Licensed under the Apache License, Version 2.0 (the \"License\");\r\n-    *  *  you may not use this file except in compliance with the License.\r\n-    *  *  You may obtain a copy of the License at\r\n-    *  *\r\n-    *  *       http:\/\/www.apache.org\/licenses\/LICENSE-2.0\r\n-    *  *\r\n-    *  *  Unless required by applicable law or agreed to in writing, software\r\n-    *  *  distributed under the License is distributed on an \"AS IS\" BASIS,\r\n-    *  *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n-    *  *  See the License for the specific language governing permissions and\r\n-    *  *  limitations under the License.\r\n-    *  *\r\n-    *  * For more information: http:\/\/www.orientechnologies.com\r\n-    *\r\n-    *\/\r\n+ *\r\n+ *  *  Copyright 2014 Orient Technologies LTD (info(at)orientechnologies.com)\r\n+ *  *\r\n+ *  *  Licensed under the Apache License, Version 2.0 (the \"License\");\r\n+ *  *  you may not use this file except in compliance with the License.\r\n+ *  *  You may obtain a copy of the License at\r\n+ *  *\r\n+ *  *       http:\/\/www.apache.org\/licenses\/LICENSE-2.0\r\n+ *  *\r\n+ *  *  Unless required by applicable law or agreed to in writing, software\r\n+ *  *  distributed under the License is distributed on an \"AS IS\" BASIS,\r\n+ *  *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n+ *  *  See the License for the specific language governing permissions and\r\n+ *  *  limitations under the License.\r\n+ *  *\r\n+ *  * For more information: http:\/\/www.orientechnologies.com\r\n+ *\r\n+ *\/\r\n package com.orientechnologies.orient.server.network.protocol.http;\r\n \r\n import com.orientechnologies.common.concur.resource.OSharedResourceAbstract;\r\n- import com.orientechnologies.common.log.OLogManager;\r\n- import com.orientechnologies.orient.core.Orient;\r\n- import com.orientechnologies.orient.core.config.OGlobalConfiguration;\r\n-\r\n- import java.util.HashMap;\r\n- import java.util.Iterator;\r\n- import java.util.Map;\r\n- import java.util.Map.Entry;\r\n- import java.util.Random;\r\n- import java.util.TimerTask;\r\n+import com.orientechnologies.common.log.OLogManager;\r\n+import com.orientechnologies.orient.core.Orient;\r\n+import com.orientechnologies.orient.core.config.OGlobalConfiguration;\r\n+\r\n+import java.security.SecureRandom;\r\n+import java.util.HashMap;\r\n+import java.util.Iterator;\r\n+import java.util.Map;\r\n+import java.util.Map.Entry;\r\n+import java.util.Random;\r\n+import java.util.TimerTask;\r\n \r\n \/**\r\n-  * Handles the HTTP sessions such as a real HTTP Server.\r\n-  *\r\n-  * @author Luca Garulli\r\n-  *\/\r\n- public class OHttpSessionManager extends OSharedResourceAbstract {\r\n-   private static final OHttpSessionManager instance = new OHttpSessionManager();\r\n-   private Map<String, OHttpSession>        sessions = new HashMap<String, OHttpSession>();\r\n-   private int                              expirationTime;\r\n-   private Random                           random   = new Random();\r\n-\r\n-   protected OHttpSessionManager() {\r\n-     expirationTime = OGlobalConfiguration.NETWORK_HTTP_SESSION_EXPIRE_TIMEOUT.getValueAsInteger() * 1000;\r\n-\r\n-     Orient.instance().scheduleTask(new TimerTask() {\r\n-       @Override\r\n-       public void run() {\r\n-         final int expired = checkSessionsValidity();\r\n-         if (expired > 0)\r\n-           OLogManager.instance().debug(this, \"Removed %d session because expired\", expired);\r\n-       }\r\n-     }, expirationTime, expirationTime);\r\n-   }\r\n-\r\n-   public int checkSessionsValidity() {\r\n-     int expired = 0;\r\n-\r\n-     acquireExclusiveLock();\r\n-     try {\r\n-       final long now = System.currentTimeMillis();\r\n-\r\n-       Entry<String, OHttpSession> s;\r\n-       for (Iterator<Map.Entry<String, OHttpSession>> it = sessions.entrySet().iterator(); it.hasNext();) {\r\n-         s = it.next();\r\n-\r\n-         if (now - s.getValue().getUpdatedOn() > expirationTime) {\r\n-           \/\/ REMOVE THE SESSION\r\n-           it.remove();\r\n-           expired++;\r\n-         }\r\n-       }\r\n-\r\n-     } finally {\r\n-       releaseExclusiveLock();\r\n-     }\r\n-\r\n-     return expired;\r\n-   }\r\n-\r\n-   public OHttpSession[] getSessions() {\r\n-     acquireSharedLock();\r\n-     try {\r\n-\r\n-       return (OHttpSession[]) sessions.values().toArray(new OHttpSession[sessions.size()]);\r\n-\r\n-     } finally {\r\n-       releaseSharedLock();\r\n-     }\r\n-   }\r\n-\r\n-   public OHttpSession getSession(final String iId) {\r\n-     acquireSharedLock();\r\n-     try {\r\n-\r\n-       final OHttpSession sess = sessions.get(iId);\r\n-       if (sess != null)\r\n-         sess.updateLastUpdatedOn();\r\n-       return sess;\r\n-\r\n-     } finally {\r\n-       releaseSharedLock();\r\n-     }\r\n-   }\r\n-\r\n-   public String createSession(final String iDatabaseName, final String iUserName, final String iUserPassword) {\r\n-     acquireExclusiveLock();\r\n-     try {\r\n-       final String id = \"OS\" + System.currentTimeMillis() + random.nextLong();\r\n-       sessions.put(id, new OHttpSession(id, iDatabaseName, iUserName, iUserPassword));\r\n-       return id;\r\n-\r\n-     } finally {\r\n-       releaseExclusiveLock();\r\n-     }\r\n-   }\r\n-\r\n-   public OHttpSession removeSession(final String iSessionId) {\r\n-     acquireExclusiveLock();\r\n-     try {\r\n-       return sessions.remove(iSessionId);\r\n-\r\n-     } finally {\r\n-       releaseExclusiveLock();\r\n-     }\r\n-   }\r\n-\r\n-   public int getExpirationTime() {\r\n-     return expirationTime;\r\n-   }\r\n-\r\n-   public void setExpirationTime(int expirationTime) {\r\n-     this.expirationTime = expirationTime;\r\n-   }\r\n-\r\n-   public static OHttpSessionManager getInstance() {\r\n-     return instance;\r\n-   }\r\n- }\r\n+ * Handles the HTTP sessions such as a real HTTP Server.\r\n+ *\r\n+ * @author Luca Garulli\r\n+ *\/\r\n+public class OHttpSessionManager extends OSharedResourceAbstract {\r\n+  private static final OHttpSessionManager instance = new OHttpSessionManager();\r\n+  private Map<String, OHttpSession>        sessions = new HashMap<String, OHttpSession>();\r\n+  private int                              expirationTime;\r\n+  private Random                           random   = new SecureRandom();\r\n+\r\n+  protected OHttpSessionManager() {\r\n+    expirationTime = OGlobalConfiguration.NETWORK_HTTP_SESSION_EXPIRE_TIMEOUT.getValueAsInteger() * 1000;\r\n+\r\n+    Orient.instance().scheduleTask(new TimerTask() {\r\n+      @Override\r\n+      public void run() {\r\n+        final int expired = checkSessionsValidity();\r\n+        if (expired > 0)\r\n+          OLogManager.instance().debug(this, \"Removed %d session because expired\", expired);\r\n+      }\r\n+    }, expirationTime, expirationTime);\r\n+  }\r\n+\r\n+  public int checkSessionsValidity() {\r\n+    int expired = 0;\r\n+\r\n+    acquireExclusiveLock();\r\n+    try {\r\n+      final long now = System.currentTimeMillis();\r\n+\r\n+      Entry<String, OHttpSession> s;\r\n+      for (Iterator<Map.Entry<String, OHttpSession>> it = sessions.entrySet().iterator(); it.hasNext();) {\r\n+        s = it.next();\r\n+\r\n+        if (now - s.getValue().getUpdatedOn() > expirationTime) {\r\n+          \/\/ REMOVE THE SESSION\r\n+          it.remove();\r\n+          expired++;\r\n+        }\r\n+      }\r\n+\r\n+    } finally {\r\n+      releaseExclusiveLock();\r\n+    }\r\n+\r\n+    return expired;\r\n+  }\r\n+\r\n+  public OHttpSession[] getSessions() {\r\n+    acquireSharedLock();\r\n+    try {\r\n+\r\n+      return (OHttpSession[]) sessions.values().toArray(new OHttpSession[sessions.size()]);\r\n+\r\n+    } finally {\r\n+      releaseSharedLock();\r\n+    }\r\n+  }\r\n+\r\n+  public OHttpSession getSession(final String iId) {\r\n+    acquireSharedLock();\r\n+    try {\r\n+\r\n+      final OHttpSession sess = sessions.get(iId);\r\n+      if (sess != null)\r\n+        sess.updateLastUpdatedOn();\r\n+      return sess;\r\n+\r\n+    } finally {\r\n+      releaseSharedLock();\r\n+    }\r\n+  }\r\n+\r\n+  public String createSession(final String iDatabaseName, final String iUserName, final String iUserPassword) {\r\n+    acquireExclusiveLock();\r\n+    try {\r\n+      final String id = \"OS\" + System.currentTimeMillis() + random.nextLong();\r\n+      sessions.put(id, new OHttpSession(id, iDatabaseName, iUserName, iUserPassword));\r\n+      return id;\r\n+\r\n+    } finally {\r\n+      releaseExclusiveLock();\r\n+    }\r\n+  }\r\n+\r\n+  public OHttpSession removeSession(final String iSessionId) {\r\n+    acquireExclusiveLock();\r\n+    try {\r\n+      return sessions.remove(iSessionId);\r\n+\r\n+    } finally {\r\n+      releaseExclusiveLock();\r\n+    }\r\n+  }\r\n+\r\n+  public int getExpirationTime() {\r\n+    return expirationTime;\r\n+  }\r\n+\r\n+  public void setExpirationTime(int expirationTime) {\r\n+    this.expirationTime = expirationTime;\r\n+  }\r\n+\r\n+  public static OHttpSessionManager getInstance() {\r\n+    return instance;\r\n+  }\r\n+}"
        },
        {
            "index":422,
            "vuln_id":"GHSA-mxvc-fwgx-j778",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/benbusby\/whoogle-search\/commit\/abc30d7da3b5c67be7ce84d4699f327442d44606'}",
            "dataset":"osv",
            "summary":"Whoogle Search Cross-site Scripting via string parameter The package whoogle-search before 0.7.2 is vulnerable to Cross-site Scripting (XSS) via the query string parameter q. In the case where it does not contain the http string, it is used to build the error_message that is then rendered in the error.html template, using the [flask.render_template](https:\/\/flask.palletsprojects.com\/en\/2.1.x\/api\/flask.render_template) function. However, the error_message is rendered using the [| safe filter](https:\/\/jinja.palletsprojects.com\/en\/3.1.x\/templates\/working-with-automatic-escaping), meaning the user input is not escaped.",
            "published_date":"2022-07-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/benbusby\/whoogle-search",
            "commit_href":"https:\/\/github.com\/benbusby\/whoogle-search\/commit\/abc30d7da3b5c67be7ce84d4699f327442d44606",
            "commit_sha":"abc30d7da3b5c67be7ce84d4699f327442d44606",
            "patch":"SINGLE",
            "chain_ord":"['abc30d7da3b5c67be7ce84d4699f327442d44606']",
            "before_first_fix_commit":"{'d62ceb84239ee0df677851f46eb885c40e98211f'}",
            "last_fix_commit":"abc30d7da3b5c67be7ce84d4699f327442d44606",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/26\/2022, 15:28:05",
            "message":"Render error message w\/o `safe` filter\n\nThe error message shown in the error template does not need to be\nrendered using the safe filter, and furthermore opens up an XSS\nvulnerability.",
            "author":"Ben Busby",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'app\/templates\/error.html': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/benbusby\/whoogle-search\/raw\/abc30d7da3b5c67be7ce84d4699f327442d44606\/app%2Ftemplates%2Ferror.html', 'patch': '@@ -16,7 +16,7 @@\\n <div>\\n     <h1>Error<\/h1>\\n     <p>\\n-        {{ error_message|safe }}\\n+        {{ error_message }}\\n     <\/p>\\n     <hr>\\n     <p>'}}",
            "message_norm":"render error message w\/o `safe` filter\n\nthe error message shown in the error template does not need to be\nrendered using the safe filter, and furthermore opens up an xss\nvulnerability.",
            "language":"en",
            "entities":"[('error', 'FLAW', ''), ('safe', 'SECWORD', ''), ('error', 'FLAW', ''), ('error', 'FLAW', ''), ('safe', 'SECWORD', ''), ('xss', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/templates\/error.html'])",
            "num_files":1.0,
            "patch_content":"From abc30d7da3b5c67be7ce84d4699f327442d44606 Mon Sep 17 00:00:00 2001\nFrom: Ben Busby <contact@benbusby.com>\nDate: Tue, 26 Apr 2022 09:28:05 -0600\nSubject: [PATCH] Render error message w\/o `safe` filter\n\nThe error message shown in the error template does not need to be\nrendered using the safe filter, and furthermore opens up an XSS\nvulnerability.\n---\n app\/templates\/error.html | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/app\/templates\/error.html b\/app\/templates\/error.html\nindex 58f7f4271e..708f74911c 100644\n--- a\/app\/templates\/error.html\n+++ b\/app\/templates\/error.html\n@@ -16,7 +16,7 @@\n <div>\n     <h1>Error<\/h1>\n     <p>\n-        {{ error_message|safe }}\n+        {{ error_message }}\n     <\/p>\n     <hr>\n     <p>"
        },
        {
            "index":349,
            "vuln_id":"GHSA-c65v-p733-9796",
            "cwe_id":"{'CWE-79'}",
            "score":8.0,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in snipe\/snipe-it snipe-it is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
            "published_date":"2021-11-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e",
            "commit_sha":"7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e",
            "patch":"SINGLE",
            "chain_ord":"['7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e']",
            "before_first_fix_commit":"{'e75a5f13ecb77a53d93d67c23e9f1b3580fe8092', 'f7b483358ff114b56c753ee9c2964059a55a3bd2'}",
            "last_fix_commit":"7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/16\/2021, 04:33:51",
            "message":"Merge pull request #10315 from snipe\/fixes\/escape_custom_fields_in_api_response\n\nEscape custom field values in API response",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 5, 'total': 10}",
            "files":"{'app\/Http\/Transformers\/AssetsTransformer.php': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e\/app%2FHttp%2FTransformers%2FAssetsTransformer.php', 'patch': \"@@ -93,15 +93,15 @@ public function transformAsset(Asset $asset)\\n                     $value = (Gate::allows('superadmin')) ? $decrypted : strtoupper(trans('admin\/custom_fields\/general.encrypted'));\\n \\n                     $fields_array[$field->name] = [\\n-                            'field' => $field->convertUnicodeDbSlug(),\\n-                            'value' => $value,\\n+                            'field' => e($field->convertUnicodeDbSlug()),\\n+                            'value' => e($value),\\n                             'field_format' => $field->format,\\n                         ];\\n \\n                 } else {\\n                     $fields_array[$field->name] = [\\n-                        'field' => $field->convertUnicodeDbSlug(),\\n-                        'value' => $asset->{$field->convertUnicodeDbSlug()},\\n+                        'field' => e($field->convertUnicodeDbSlug()),\\n+                        'value' => e($asset->{$field->convertUnicodeDbSlug()}),\\n                         'field_format' => $field->format,\\n                     ];\\n \\n@@ -134,7 +134,7 @@ public function transformAsset(Asset $asset)\\n                         \\n                             'id' => $component->id,\\n                             'pivot_id' => $component->pivot->id,\\n-                            'name' => $component->name,\\n+                            'name' => e($component->name),\\n                             'qty' => $component->pivot->assigned_qty,\\n                             'price_cost' => $component->purchase_cost,\\n                             'purchase_total' => $component->purchase_cost * $component->pivot->assigned_qty,\"}}",
            "message_norm":"merge pull request #10315 from snipe\/fixes\/escape_custom_fields_in_api_response\n\nescape custom field values in api response",
            "language":"ca",
            "entities":"[('#10315', 'ISSUE', ''), ('escape_custom_fields_in_api_response', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Transformers\/AssetsTransformer.php'])",
            "num_files":1.0,
            "patch_content":"From f7b483358ff114b56c753ee9c2964059a55a3bd2 Mon Sep 17 00:00:00 2001\nFrom: snipe <snipe@snipe.net>\nDate: Mon, 15 Nov 2021 20:32:59 -0800\nSubject: [PATCH] Escape custom field values in API response\n\nSigned-off-by: snipe <snipe@snipe.net>\n---\n app\/Http\/Transformers\/AssetsTransformer.php | 10 +++++-----\n 1 file changed, 5 insertions(+), 5 deletions(-)\n\ndiff --git a\/app\/Http\/Transformers\/AssetsTransformer.php b\/app\/Http\/Transformers\/AssetsTransformer.php\nindex c323241cf01b..0da314002f54 100644\n--- a\/app\/Http\/Transformers\/AssetsTransformer.php\n+++ b\/app\/Http\/Transformers\/AssetsTransformer.php\n@@ -93,15 +93,15 @@ public function transformAsset(Asset $asset)\n                     $value = (Gate::allows('superadmin')) ? $decrypted : strtoupper(trans('admin\/custom_fields\/general.encrypted'));\n \n                     $fields_array[$field->name] = [\n-                            'field' => $field->convertUnicodeDbSlug(),\n-                            'value' => $value,\n+                            'field' => e($field->convertUnicodeDbSlug()),\n+                            'value' => e($value),\n                             'field_format' => $field->format,\n                         ];\n \n                 } else {\n                     $fields_array[$field->name] = [\n-                        'field' => $field->convertUnicodeDbSlug(),\n-                        'value' => $asset->{$field->convertUnicodeDbSlug()},\n+                        'field' => e($field->convertUnicodeDbSlug()),\n+                        'value' => e($asset->{$field->convertUnicodeDbSlug()}),\n                         'field_format' => $field->format,\n                     ];\n \n@@ -134,7 +134,7 @@ public function transformAsset(Asset $asset)\n                         \n                             'id' => $component->id,\n                             'pivot_id' => $component->pivot->id,\n-                            'name' => $component->name,\n+                            'name' => e($component->name),\n                             'qty' => $component->pivot->assigned_qty,\n                             'price_cost' => $component->purchase_cost,\n                             'purchase_total' => $component->purchase_cost * $component->pivot->assigned_qty,"
        },
        {
            "index":466,
            "vuln_id":"GHSA-3872-f48p-pxqj",
            "cwe_id":"{'CWE-88', 'CWE-77'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/d83672a3e7415da1490334e2c9431e5da1966842', 'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/35d59f1f040541c358cece0a8d4a63183ca919b8'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Special Elements used in a Command ('Command Injection') in Weblate ### Impact\nWeblate didn't correctly sanitize some arguments passed to Git and Mercurial, which allowed changing their behavior in an unintended way.\n\n### Patches\n\nThe issues were fixed in the 4.11.1 release. The following commits are addressing it:\n\n* 35d59f1f040541c358cece0a8d4a63183ca919b8\n* d83672a3e7415da1490334e2c9431e5da1966842\n\n### Workarounds\n\nInstances in which untrusted users cannot create new components are not affected.\n\n### References\n* [SNYK-PYTHON-WEBLATE-2414088](https:\/\/security.snyk.io\/vuln\/SNYK-PYTHON-WEBLATE-2414088)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open a topic in [discussions](https:\/\/github.com\/WeblateOrg\/weblate\/discussions)\n* Email us at [care@weblate.org](mailto:care@weblate.org)",
            "published_date":"2022-03-04",
            "chain_len":2,
            "project":"https:\/\/github.com\/WeblateOrg\/weblate",
            "commit_href":"https:\/\/github.com\/WeblateOrg\/weblate\/commit\/35d59f1f040541c358cece0a8d4a63183ca919b8",
            "commit_sha":"35d59f1f040541c358cece0a8d4a63183ca919b8",
            "patch":"MULTI",
            "chain_ord":"['35d59f1f040541c358cece0a8d4a63183ca919b8', 'd83672a3e7415da1490334e2c9431e5da1966842']",
            "before_first_fix_commit":"{'9a5a09781e5a19ab9a24878afb08c9fcafb21ca7'}",
            "last_fix_commit":"d83672a3e7415da1490334e2c9431e5da1966842",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/03\/2022, 07:25:01",
            "message":"vcs: Improve mercurial parameters handling\n\nMake sure that all user provided input is handled as expected.",
            "author":"Michal \u010ciha\u0159",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'weblate\/vcs\/mercurial.py': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/WeblateOrg\/weblate\/raw\/35d59f1f040541c358cece0a8d4a63183ca919b8\/weblate%2Fvcs%2Fmercurial.py', 'patch': '@@ -70,7 +70,7 @@ def check_config(self):\\n     @classmethod\\n     def _clone(cls, source: str, target: str, branch: str):\\n         \"\"\"Clone repository.\"\"\"\\n-        cls._popen([\"clone\", \"--branch\", branch, source, target])\\n+        cls._popen([\"clone\", f\"--branch={branch}\", \"--\", source, target])\\n \\n     def get_config(self, path):\\n         \"\"\"Read entry from configuration.\"\"\"\\n@@ -323,7 +323,7 @@ def on_branch(self, branch):\\n     def configure_branch(self, branch):\\n         \"\"\"Configure repository branch.\"\"\"\\n         if not self.on_branch(branch):\\n-            self.execute([\"update\", branch])\\n+            self.execute([\"update\", \"--\", branch])\\n         self.branch = branch\\n \\n     def describe(self):\\n@@ -343,7 +343,7 @@ def describe(self):\\n     def push(self, branch):\\n         \"\"\"Push given branch to remote repository.\"\"\"\\n         try:\\n-            self.execute([\"push\", \"-b\", self.branch])\\n+            self.execute([\"push\", f\"--branch={self.branch}\"])\\n         except RepositoryException as error:\\n             if error.retcode == 1:\\n                 # No changes found\\n@@ -363,7 +363,7 @@ def cleanup(self):\\n \\n     def update_remote(self):\\n         \"\"\"Update remote repository.\"\"\"\\n-        self.execute([\"pull\", \"--branch\", self.branch])\\n+        self.execute([\"pull\", f\"--branch={self.branch}\"])\\n         self.clean_revision_cache()\\n \\n     def parse_changed_files(self, lines: List[str]) -> Iterator[str]:'}}",
            "message_norm":"vcs: improve mercurial parameters handling\n\nmake sure that all user provided input is handled as expected.",
            "language":"en",
            "entities":"[('improve', 'ACTION', ''), ('user provided input', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['weblate\/vcs\/mercurial.py'])",
            "num_files":1.0,
            "patch_content":"From 35d59f1f040541c358cece0a8d4a63183ca919b8 Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Michal=20=C4=8Ciha=C5=99?= <michal@cihar.com>\nDate: Thu, 3 Mar 2022 08:25:01 +0100\nSubject: [PATCH] vcs: Improve mercurial parameters handling\n\nMake sure that all user provided input is handled as expected.\n---\n weblate\/vcs\/mercurial.py | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/weblate\/vcs\/mercurial.py b\/weblate\/vcs\/mercurial.py\nindex 0399c1b0bae2..1131c1abd1e5 100644\n--- a\/weblate\/vcs\/mercurial.py\n+++ b\/weblate\/vcs\/mercurial.py\n@@ -70,7 +70,7 @@ def check_config(self):\n     @classmethod\n     def _clone(cls, source: str, target: str, branch: str):\n         \"\"\"Clone repository.\"\"\"\n-        cls._popen([\"clone\", \"--branch\", branch, source, target])\n+        cls._popen([\"clone\", f\"--branch={branch}\", \"--\", source, target])\n \n     def get_config(self, path):\n         \"\"\"Read entry from configuration.\"\"\"\n@@ -323,7 +323,7 @@ def on_branch(self, branch):\n     def configure_branch(self, branch):\n         \"\"\"Configure repository branch.\"\"\"\n         if not self.on_branch(branch):\n-            self.execute([\"update\", branch])\n+            self.execute([\"update\", \"--\", branch])\n         self.branch = branch\n \n     def describe(self):\n@@ -343,7 +343,7 @@ def describe(self):\n     def push(self, branch):\n         \"\"\"Push given branch to remote repository.\"\"\"\n         try:\n-            self.execute([\"push\", \"-b\", self.branch])\n+            self.execute([\"push\", f\"--branch={self.branch}\"])\n         except RepositoryException as error:\n             if error.retcode == 1:\n                 # No changes found\n@@ -363,7 +363,7 @@ def cleanup(self):\n \n     def update_remote(self):\n         \"\"\"Update remote repository.\"\"\"\n-        self.execute([\"pull\", \"--branch\", self.branch])\n+        self.execute([\"pull\", f\"--branch={self.branch}\"])\n         self.clean_revision_cache()\n \n     def parse_changed_files(self, lines: List[str]) -> Iterator[str]:"
        },
        {
            "index":92,
            "vuln_id":"GHSA-m8rp-q82r-c5mf",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/b64ef574b82dbf89a908e1569d790c7012d1ccd7'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in microweber Cross-site Scripting (XSS) - Stored in Packagist microweber\/microweber prior to 1.2.11.",
            "published_date":"2022-01-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/b64ef574b82dbf89a908e1569d790c7012d1ccd7",
            "commit_sha":"b64ef574b82dbf89a908e1569d790c7012d1ccd7",
            "patch":"SINGLE",
            "chain_ord":"['b64ef574b82dbf89a908e1569d790c7012d1ccd7']",
            "before_first_fix_commit":"{'e17f3e94289b2dac7187e8039e1a3429779e273c'}",
            "last_fix_commit":"b64ef574b82dbf89a908e1569d790c7012d1ccd7",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/19\/2022, 09:56:21",
            "message":"xss on contact form fix",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 3, 'total': 5}",
            "files":"{'userfiles\/modules\/admin\/notifications\/notif_form_entry.php': {'additions': 2, 'deletions': 3, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/b64ef574b82dbf89a908e1569d790c7012d1ccd7\/userfiles%2Fmodules%2Fadmin%2Fnotifications%2Fnotif_form_entry.php', 'patch': '@@ -91,7 +91,6 @@\\n             <hr class=\"thin\" \/>\\n             <div class=\"row\">\\n \\n-\\n                 <?php\\n                 $iformVr=0;\\n                 foreach ($form_values_formated as $form_values_row) {\\n@@ -106,12 +105,12 @@\\n                             <?php if (!is_array($val1)){ ?>\\n                                 <div>\\n                                     <small class=\"text-muted\"><?php echo str_replace(\\'_\\', \\' \\', $key); ?>:<\/small>\\n-                                    <p><?php print $val1; ?><\/p>\\n+                                    <p><?php print htmlentities($val1); ?><\/p>\\n                                 <\/div>\\n                             <?php } else { ?>\\n                                 <small class=\"text-muted\"><?php echo str_replace(\\'_\\', \\' \\', $key); ?>:<\/small>\\n                                 <?php foreach ($val1 as $val1_1){ ?>\\n-                                    <p><?php print $val1_1 . \\'<br \/>\\'; ?><\/p>\\n+                                    <p><?php print htmlentities($val1_1) . \\'<br \/>\\'; ?><\/p>\\n                                 <?php }?>\\n                             <?php } ?>\\n                         <?php } ?>'}}",
            "message_norm":"xss on contact form fix",
            "language":"en",
            "entities":"[('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['userfiles\/modules\/admin\/notifications\/notif_form_entry.php'])",
            "num_files":1.0,
            "patch_content":"From b64ef574b82dbf89a908e1569d790c7012d1ccd7 Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Wed, 19 Jan 2022 11:56:21 +0200\nSubject: [PATCH] xss on contact form fix\n\n---\n userfiles\/modules\/admin\/notifications\/notif_form_entry.php | 5 ++---\n 1 file changed, 2 insertions(+), 3 deletions(-)\n\ndiff --git a\/userfiles\/modules\/admin\/notifications\/notif_form_entry.php b\/userfiles\/modules\/admin\/notifications\/notif_form_entry.php\nindex 586de353b63..dc92f12cbbc 100644\n--- a\/userfiles\/modules\/admin\/notifications\/notif_form_entry.php\n+++ b\/userfiles\/modules\/admin\/notifications\/notif_form_entry.php\n@@ -91,7 +91,6 @@\n             <hr class=\"thin\" \/>\n             <div class=\"row\">\n \n-\n                 <?php\n                 $iformVr=0;\n                 foreach ($form_values_formated as $form_values_row) {\n@@ -106,12 +105,12 @@\n                             <?php if (!is_array($val1)){ ?>\n                                 <div>\n                                     <small class=\"text-muted\"><?php echo str_replace('_', ' ', $key); ?>:<\/small>\n-                                    <p><?php print $val1; ?><\/p>\n+                                    <p><?php print htmlentities($val1); ?><\/p>\n                                 <\/div>\n                             <?php } else { ?>\n                                 <small class=\"text-muted\"><?php echo str_replace('_', ' ', $key); ?>:<\/small>\n                                 <?php foreach ($val1 as $val1_1){ ?>\n-                                    <p><?php print $val1_1 . '<br \/>'; ?><\/p>\n+                                    <p><?php print htmlentities($val1_1) . '<br \/>'; ?><\/p>\n                                 <?php }?>\n                             <?php } ?>\n                         <?php } ?>"
        },
        {
            "index":930,
            "vuln_id":"GHSA-2cpx-427x-q2c6",
            "cwe_id":"{'CWE-190'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c'}",
            "dataset":"osv",
            "summary":"CHECK-fail in AddManySparseToTensorsMap ### Impact\nAn attacker can trigger a denial of service via a `CHECK`-fail in  `tf.raw_ops.AddManySparseToTensorsMap`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nsparse_indices = tf.constant(530, shape=[1, 1], dtype=tf.int64)\nsparse_values = tf.ones([1], dtype=tf.int64)\n\nshape = tf.Variable(tf.ones([55], dtype=tf.int64))\nshape[:8].assign(np.array([855, 901, 429, 892, 892, 852, 93, 96], dtype=np.int64))\n\ntf.raw_ops.AddManySparseToTensorsMap(sparse_indices=sparse_indices,\n                    sparse_values=sparse_values,\n                    sparse_shape=shape)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f9896890c4c703ae0a0845394086e2e1e523299\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc#L257) takes the values specified in `sparse_shape` as dimensions for the output shape: \n\n```cc\n    TensorShape tensor_input_shape(input_shape->vec<int64>());\n```\n\nThe [`TensorShape` constructor](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f9896890c4c703ae0a0845394086e2e1e523299\/tensorflow\/core\/framework\/tensor_shape.cc#L183-L188) uses a `CHECK` operation which triggers when [`InitDims`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f9896890c4c703ae0a0845394086e2e1e523299\/tensorflow\/core\/framework\/tensor_shape.cc#L212-L296) returns a non-OK status.\n  \n```cc\ntemplate <class Shape>\nTensorShapeBase<Shape>::TensorShapeBase(gtl::ArraySlice<int64> dim_sizes) {\n  set_tag(REP16);\n  set_data_type(DT_INVALID);\n  TF_CHECK_OK(InitDims(dim_sizes));\n}\n```\n\nIn our scenario, this occurs when adding a dimension from the argument results in overflow:\n\n```cc\ntemplate <class Shape>\nStatus TensorShapeBase<Shape>::InitDims(gtl::ArraySlice<int64> dim_sizes) {\n  ...\n  Status status = Status::OK();\n  for (int64 s : dim_sizes) {\n    status.Update(AddDimWithStatus(internal::SubtleMustCopy(s)));\n    if (!status.ok()) {\n      return status;\n    }\n  }\n}\n\ntemplate <class Shape>\nStatus TensorShapeBase<Shape>::AddDimWithStatus(int64 size) {\n  ...\n  int64 new_num_elements;\n  if (kIsPartial && (num_elements() < 0 || size < 0)) {\n    new_num_elements = -1;\n  } else {\n    new_num_elements = MultiplyWithoutOverflow(num_elements(), size);\n    if (TF_PREDICT_FALSE(new_num_elements < 0)) {\n        return errors::Internal(\"Encountered overflow when multiplying \",\n                                num_elements(), \" with \", size,\n                                \", result: \", new_num_elements);\n      }\n  }\n  ...\n}\n```\n\nThis is a legacy implementation of the constructor and operations should use `BuildTensorShapeBase` or `AddDimWithStatus` to prevent `CHECK`-failures in the presence of overflows.\n\n### Patches\nWe have patched the issue in GitHub commit [69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c",
            "commit_sha":"69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c",
            "patch":"SINGLE",
            "chain_ord":"['69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c']",
            "before_first_fix_commit":"{'6f9896890c4c703ae0a0845394086e2e1e523299'}",
            "last_fix_commit":"69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/20\/2021, 19:14:41",
            "message":"Fix overflow CHECK issue with `tf.raw_ops.AddManySparseToTensorsMap`.\n\nPiperOrigin-RevId: 369492969\nChange-Id: I1d70d6c0c92e3d7a25bc3b3aa2a0c0ac9688bf81",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 7, 'total': 26}",
            "files":"{'tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc': {'additions': 19, 'deletions': 7, 'changes': 26, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c\/tensorflow%2Fcore%2Fkernels%2Fsparse_tensors_map_ops.cc', 'patch': '@@ -21,16 +21,14 @@ limitations under the License.\\n #include <utility>\\n #include <vector>\\n \\n-#include \"tensorflow\/core\/framework\/op_kernel.h\"\\n-#include \"tensorflow\/core\/framework\/register_types.h\"\\n-\\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n #include \"tensorflow\/core\/framework\/resource_mgr.h\"\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_util.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\\n+#include \"tensorflow\/core\/util\/overflow.h\"\\n #include \"tensorflow\/core\/util\/sparse\/sparse_tensor.h\"\\n \\n namespace tensorflow {\\n@@ -254,16 +252,30 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\\n         errors::InvalidArgument(\\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\\n \\n-    TensorShape tensor_input_shape(input_shape->vec<int64>());\\n+    auto input_shape_vec = input_shape->vec<int64>();\\n+    int new_num_elements = 1;\\n+    bool overflow_ocurred = false;\\n+    for (int i = 0; i < input_shape_vec.size(); i++) {\\n+      new_num_elements =\\n+          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\\n+      if (new_num_elements < 0) {\\n+        overflow_ocurred = true;\\n+      }\\n+    }\\n+\\n+    OP_REQUIRES(\\n+        context, !overflow_ocurred,\\n+        errors::Internal(\"Encountered overflow from large input shape.\"));\\n+\\n+    TensorShape tensor_input_shape(input_shape_vec);\\n     gtl::InlinedVector<int64, 8> std_order(rank);\\n     std::iota(std_order.begin(), std_order.end(), 0);\\n     SparseTensor input_st;\\n     OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\\n                                                  tensor_input_shape, std_order,\\n                                                  &input_st));\\n \\n-    auto input_shape_t = input_shape->vec<int64>();\\n-    const int64 N = input_shape_t(0);\\n+    const int64 N = input_shape_vec(0);\\n \\n     Tensor sparse_handles(DT_INT64, TensorShape({N}));\\n     auto sparse_handles_t = sparse_handles.vec<int64>();\\n@@ -274,7 +286,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\\n     \/\/ minibatch entries.\\n     TensorShape output_shape;\\n     OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\\n-                                input_shape_t.data() + 1,\\n+                                input_shape_vec.data() + 1,\\n                                 input_shape->NumElements() - 1, &output_shape));\\n \\n     \/\/ Get groups by minibatch dimension'}}",
            "message_norm":"fix overflow check issue with `tf.raw_ops.addmanysparsetotensorsmap`.\n\npiperorigin-revid: 369492969\nchange-id: i1d70d6c0c92e3d7a25bc3b3aa2a0c0ac9688bf81",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('369492969', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 69c68ecbb24dff3fa0e46da0d16c821a2dd22d7c Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Tue, 20 Apr 2021 12:14:41 -0700\nSubject: [PATCH] Fix overflow CHECK issue with\n `tf.raw_ops.AddManySparseToTensorsMap`.\n\nPiperOrigin-RevId: 369492969\nChange-Id: I1d70d6c0c92e3d7a25bc3b3aa2a0c0ac9688bf81\n---\n ...\/core\/kernels\/sparse_tensors_map_ops.cc    | 26 ++++++++++++++-----\n 1 file changed, 19 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc b\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc\nindex c2c0e43ca2ba8d..5ea5fca544d3e9 100644\n--- a\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc\n@@ -21,9 +21,6 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n-#include \"tensorflow\/core\/framework\/op_kernel.h\"\n-#include \"tensorflow\/core\/framework\/register_types.h\"\n-\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\n #include \"tensorflow\/core\/framework\/register_types.h\"\n #include \"tensorflow\/core\/framework\/resource_mgr.h\"\n@@ -31,6 +28,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/tensor_util.h\"\n #include \"tensorflow\/core\/framework\/types.h\"\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\n+#include \"tensorflow\/core\/util\/overflow.h\"\n #include \"tensorflow\/core\/util\/sparse\/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -254,7 +252,22 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n         errors::InvalidArgument(\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n \n-    TensorShape tensor_input_shape(input_shape->vec<int64>());\n+    auto input_shape_vec = input_shape->vec<int64>();\n+    int new_num_elements = 1;\n+    bool overflow_ocurred = false;\n+    for (int i = 0; i < input_shape_vec.size(); i++) {\n+      new_num_elements =\n+          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n+      if (new_num_elements < 0) {\n+        overflow_ocurred = true;\n+      }\n+    }\n+\n+    OP_REQUIRES(\n+        context, !overflow_ocurred,\n+        errors::Internal(\"Encountered overflow from large input shape.\"));\n+\n+    TensorShape tensor_input_shape(input_shape_vec);\n     gtl::InlinedVector<int64, 8> std_order(rank);\n     std::iota(std_order.begin(), std_order.end(), 0);\n     SparseTensor input_st;\n@@ -262,8 +275,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                                                  tensor_input_shape, std_order,\n                                                  &input_st));\n \n-    auto input_shape_t = input_shape->vec<int64>();\n-    const int64 N = input_shape_t(0);\n+    const int64 N = input_shape_vec(0);\n \n     Tensor sparse_handles(DT_INT64, TensorShape({N}));\n     auto sparse_handles_t = sparse_handles.vec<int64>();\n@@ -274,7 +286,7 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n     \/\/ minibatch entries.\n     TensorShape output_shape;\n     OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n-                                input_shape_t.data() + 1,\n+                                input_shape_vec.data() + 1,\n                                 input_shape->NumElements() - 1, &output_shape));\n \n     \/\/ Get groups by minibatch dimension"
        },
        {
            "index":657,
            "vuln_id":"GHSA-fq9f-9wv9-rfmg",
            "cwe_id":"{'CWE-295'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0'}",
            "dataset":"osv",
            "summary":"Improper Certificate Validation in Jenkins Jenkins 2.73.1 and earlier, 2.83 and earlier bundled a version of the commons-httpclient library with the vulnerability CVE-2012-6153 that incorrectly verified SSL certificates, making it susceptible to man-in-the-middle attacks. This library is widely used as a transitive dependency in Jenkins plugins. The fix for CVE-2012-6153 was backported to the version of commons-httpclient that is bundled in core and made available to plugins.",
            "published_date":"2022-05-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0",
            "commit_sha":"fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0",
            "patch":"SINGLE",
            "chain_ord":"['fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0']",
            "before_first_fix_commit":"{'67f68c181033cbabf2075769e0f846f58c226c08'}",
            "last_fix_commit":"fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/29\/2017, 13:39:32",
            "message":"[SECURITY-555] Patch Commons HttpClient 3.x.",
            "author":"Jesse Glick",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'pom.xml': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0\/pom.xml', 'patch': '@@ -164,7 +164,7 @@ THE SOFTWARE.\\n       <dependency>\\n         <groupId>commons-httpclient<\/groupId>\\n         <artifactId>commons-httpclient<\/artifactId>\\n-        <version>3.1<\/version>\\n+        <version>3.1-jenkins-1<\/version>\\n       <\/dependency>\\n \\n       <dependency>'}}",
            "message_norm":"[security-555] patch commons httpclient 3.x.",
            "language":"en",
            "entities":"[('security-555', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['pom.xml'])",
            "num_files":1.0,
            "patch_content":"From fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0 Mon Sep 17 00:00:00 2001\nFrom: Jesse Glick <jglick@cloudbees.com>\nDate: Fri, 29 Sep 2017 09:39:32 -0400\nSubject: [PATCH] [SECURITY-555] Patch Commons HttpClient 3.x.\n\n---\n pom.xml | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/pom.xml b\/pom.xml\nindex 44cdd69f42f1..53d19aaee1b2 100644\n--- a\/pom.xml\n+++ b\/pom.xml\n@@ -164,7 +164,7 @@ THE SOFTWARE.\n       <dependency>\n         <groupId>commons-httpclient<\/groupId>\n         <artifactId>commons-httpclient<\/artifactId>\n-        <version>3.1<\/version>\n+        <version>3.1-jenkins-1<\/version>\n       <\/dependency>\n \n       <dependency>"
        }
    ]
}