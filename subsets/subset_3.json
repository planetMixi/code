{
  "schema": {
    "fields": [
      {
        "name": "index",
        "type": "integer"
      },
      {
        "name": "vuln_id",
        "type": "string"
      },
      {
        "name": "cwe_id",
        "type": "string"
      },
      {
        "name": "score",
        "type": "number"
      },
      {
        "name": "chain",
        "type": "string"
      },
      {
        "name": "dataset",
        "type": "string"
      },
      {
        "name": "summary",
        "type": "string"
      },
      {
        "name": "published_date",
        "type": "string"
      },
      {
        "name": "chain_len",
        "type": "integer"
      },
      {
        "name": "project",
        "type": "string"
      },
      {
        "name": "commit_href",
        "type": "string"
      },
      {
        "name": "commit_sha",
        "type": "string"
      },
      {
        "name": "patch",
        "type": "string"
      },
      {
        "name": "chain_ord",
        "type": "string"
      },
      {
        "name": "before_first_fix_commit",
        "type": "string"
      },
      {
        "name": "last_fix_commit",
        "type": "string"
      },
      {
        "name": "chain_ord_pos",
        "type": "number"
      },
      {
        "name": "commit_datetime",
        "type": "string"
      },
      {
        "name": "message",
        "type": "string"
      },
      {
        "name": "author",
        "type": "string"
      },
      {
        "name": "comments",
        "type": "string"
      },
      {
        "name": "stats",
        "type": "string"
      },
      {
        "name": "files",
        "type": "string"
      },
      {
        "name": "message_norm",
        "type": "string"
      },
      {
        "name": "language",
        "type": "string"
      },
      {
        "name": "entities",
        "type": "string"
      },
      {
        "name": "classification_level_1",
        "type": "string"
      },
      {
        "name": "classification_level_2",
        "type": "string"
      },
      {
        "name": "list_files",
        "type": "string"
      },
      {
        "name": "num_files",
        "type": "number"
      }
    ],
    "primaryKey": [
      "index"
    ],
    "pandas_version": "1.4.0"
  },
  "data": [
    {
      "index": 2603,
      "vuln_id": "GHSA-pm9p-9926-w68m",
      "cwe_id": "{'CWE-20'}",
      "score": 7.5,
      "chain": "{'https://github.com/jfhbrook/node-ecstatic/commit/71ce93988ead4b561a8592168c72143907189f01'}",
      "dataset": "osv",
      "summary": "Denial of Service in ecstatic `ecstatic`, a simple static file server middleware, is vulnerable to denial of service. If a payload with a large number of null bytes (`%00`) is provided by an attacker it can crash ecstatic by running it out of memory.\n\n\n[Results from the original advisory](https://www.checkmarx.com/advisories/denial-of-service-dos-vulnerability-in-ecstatic-npm-package/)\n\n```\nA payload of 22kB caused a lag of 1 second,\nA payload of 35kB caused a lag of 3 seconds,\nA payload of 86kB caused the server to crash\n```\n\n\n## Recommendation\n\nUpdate to version 2.0.0 or later.",
      "published_date": "2017-12-28",
      "chain_len": 1,
      "project": "https://github.com/jfhbrook/node-ecstatic",
      "commit_href": "https://github.com/jfhbrook/node-ecstatic/commit/71ce93988ead4b561a8592168c72143907189f01",
      "commit_sha": "71ce93988ead4b561a8592168c72143907189f01",
      "patch": "SINGLE",
      "chain_ord": "['71ce93988ead4b561a8592168c72143907189f01']",
      "before_first_fix_commit": "{'2fceb40fb9eeaaba29f5d2c3b63583fefb04a130'}",
      "last_fix_commit": "71ce93988ead4b561a8592168c72143907189f01",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/09/2016, 16:37:39",
      "message": "Remove stripping of null bytes\n\nThis was at one point necessary because of an old bug in url.parse\n\nSee: https://github.com/jfhbrook/node-ecstatic/issues/16#issuecomment-3039914\nSee: https://github.com/jfhbrook/node-ecstatic/commit/43f7e72a31524f88f47e367c3cc3af710e67c9f4\n\nBut this opens up a regex dos attack vector! D:\n\nBased on some research (ie asking #node-dev if this is still an issue),\nit's *probably* not an issue. :)",
      "author": "Joshua Holbrook",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 0, 'total': 12}",
      "files": "{'lib/ecstatic.js': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/jfhbrook/node-ecstatic/raw/71ce93988ead4b561a8592168c72143907189f01/lib%2Fecstatic.js', 'patch': \"@@ -52,9 +52,21 @@ var ecstatic = module.exports = function (dir, options) {\\n   return function middleware (req, res, next) {\\n \\n     // Strip any null bytes from the url\\n+    // This was at one point necessary because of an old bug in url.parse\\n+    //\\n+    // See: https://github.com/jfhbrook/node-ecstatic/issues/16#issuecomment-3039914\\n+    // See: https://github.com/jfhbrook/node-ecstatic/commit/43f7e72a31524f88f47e367c3cc3af710e67c9f4\\n+    //\\n+    // But this opens up a regex dos attack vector! D:\\n+    //\\n+    // Based on some research (ie asking #node-dev if this is still an issue),\\n+    // it's *probably* not an issue. :)\\n+    /*\\n     while(req.url.indexOf('%00') !== -1) {\\n       req.url = req.url.replace(/\\\\%00/g, '');\\n     }\\n+    */\\n+\\n     // Figure out the path for the file from the given url\\n     var parsed = url.parse(req.url);\\n     try {\"}}",
      "message_norm": "remove stripping of null bytes\n\nthis was at one point necessary because of an old bug in url.parse\n\nsee: https://github.com/jfhbrook/node-ecstatic/issues/16#issuecomment-3039914\nsee: https://github.com/jfhbrook/node-ecstatic/commit/43f7e72a31524f88f47e367c3cc3af710e67c9f4\n\nbut this opens up a regex dos attack vector! d:\n\nbased on some research (ie asking #node-dev if this is still an issue),\nit's *probably* not an issue. :)",
      "language": "en",
      "entities": "[('remove', 'ACTION', ''), ('bug', 'FLAW', ''), ('https://github.com/jfhbrook/node-ecstatic/issues/16#issuecomment-3039914', 'FLAW', ''), ('https://github.com/jfhbrook/node-ecstatic/commit/43f7e72a31524f88f47e367c3cc3af710e67c9f4', 'SHA', 'github_url_sha'), ('dos', 'SECWORD', ''), ('attack vector', 'SECWORD', ''), ('issue', 'FLAW', ''), ('issue', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/ecstatic.js'])",
      "num_files": 1.0
    },
    {
      "index": 3498,
      "vuln_id": "GHSA-xvm2-9xvc-hx7f",
      "cwe_id": "{'CWE-611'}",
      "score": 9.8,
      "chain": "{'https://github.com/monitorjbl/excel-streaming-reader/commit/0749c7b9709db078ccdeada16d46a34bc2910c73'}",
      "dataset": "osv",
      "summary": "Improper Restriction of XML External Entity Reference in com.monitorjbl:xlsx-streamer ### Impact\nPrior to xlsx-streamer 2.1.0, the XML parser that was used did not apply all the necessary settings to prevent XML Entity Expansion issues.\n\n### Patches\nUpgrade to version 2.1.0.\n\n### Workarounds\nNo known workaround.\n\n### References\nhttps://github.com/monitorjbl/excel-streaming-reader/commit/0749c7b9709db078ccdeada16d46a34bc2910c73\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [monitorjbl/excel-streaming-reader](https://github.com/monitorjbl/excel-streaming-reader)",
      "published_date": "2022-03-02",
      "chain_len": 1,
      "project": "https://github.com/monitorjbl/excel-streaming-reader",
      "commit_href": "https://github.com/monitorjbl/excel-streaming-reader/commit/0749c7b9709db078ccdeada16d46a34bc2910c73",
      "commit_sha": "0749c7b9709db078ccdeada16d46a34bc2910c73",
      "patch": "SINGLE",
      "chain_ord": "['0749c7b9709db078ccdeada16d46a34bc2910c73']",
      "before_first_fix_commit": "{'62470065c35871076ad14480d2df26d9c5c3700a'}",
      "last_fix_commit": "0749c7b9709db078ccdeada16d46a34bc2910c73",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/10/2018, 01:17:35",
      "message": "Updating readme for security release",
      "author": "Taylor Jones",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 2, 'total': 8}",
      "files": "{'README.md': {'additions': 6, 'deletions': 2, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/monitorjbl/excel-streaming-reader/raw/0749c7b9709db078ccdeada16d46a34bc2910c73/README.md', 'patch': \"@@ -1,5 +1,9 @@\\n [![Run Status](https://api.shippable.com/projects/55cfbb00edd7f2c052a980a5/badge?branch=master)](https://app.shippable.com/projects/55cfbb00edd7f2c052a980a5)\\n \\n+# !!! Security Alert !!!\\n+\\n+Update to the latest version (2.1.0) **as soon as possible** to fix a critical vulnerability. The Xerxes XML parsing library that Excel Streaming Reader uses defaulted to allowing [entity expansion](https://www.owasp.org/index.php/XML_External_Entity_(XXE)_Prevention_Cheat_Sheet), which could be exploited by an attacker to read arbitrary data from your system. The latest versions of Excel Streaming Reader do not allow this and will throw a `ParsingException` if a workbook contains an XML document with an entity declaration.\\n+\\n # Excel Streaming Reader\\n \\n If you've used [Apache POI](http://poi.apache.org) in the past to read in Excel files, you probably noticed that it's not very memory efficient. Reading in an entire workbook will cause a severe memory usage spike, which can wreak havoc on a server. \\n@@ -23,7 +27,7 @@ To use it, add this to your POM:\\n   <dependency>\\n     <groupId>com.monitorjbl</groupId>\\n     <artifactId>xlsx-streamer</artifactId>\\n-    <version>2.0.0</version>\\n+    <version>2.1.0</version>\\n   </dependency>\\n </dependencies>  \\n ```\\n@@ -106,7 +110,7 @@ This library uses SLF4j logging. This is a rare use case, but you can plug in yo\\n   <dependency>\\n     <groupId>com.monitorjbl</groupId>\\n     <artifactId>xlsx-streamer</artifactId>\\n-    <version>2.0.0</version>\\n+    <version>2.1.0</version>\\n   </dependency>\\n   <dependency>\\n     <groupId>org.slf4j</groupId>\"}}",
      "message_norm": "updating readme for security release",
      "language": "en",
      "entities": "[('updating', 'ACTION', ''), ('security', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['README.md'])",
      "num_files": 1.0
    },
    {
      "index": 1730,
      "vuln_id": "GHSA-fh37-cx83-q542",
      "cwe_id": "{'CWE-306', 'CWE-269', 'CWE-287'}",
      "score": 5.3,
      "chain": "{'https://github.com/apache/airflow/commit/21cedff205e7d62675949fda2aa4616d77232b76'}",
      "dataset": "osv",
      "summary": "Improper Authentication in Apache Airflow The lineage endpoint of the deprecated Experimental API was not protected by authentication in Airflow 2.0.0. This allowed unauthenticated users to hit that endpoint. This is low-severity issue as the attacker needs to be aware of certain parameters to pass to that endpoint and even after can just get some metadata about a DAG and a Task. This issue only affects Apache Airflow 2.0.0.",
      "published_date": "2021-06-18",
      "chain_len": 1,
      "project": "https://github.com/apache/airflow",
      "commit_href": "https://github.com/apache/airflow/commit/21cedff205e7d62675949fda2aa4616d77232b76",
      "commit_sha": "21cedff205e7d62675949fda2aa4616d77232b76",
      "patch": "SINGLE",
      "chain_ord": "['21cedff205e7d62675949fda2aa4616d77232b76']",
      "before_first_fix_commit": "{'4b1a6f78d132e42f1c946f53eca89789d21bdc1d'}",
      "last_fix_commit": "21cedff205e7d62675949fda2aa4616d77232b76",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/27/2021, 21:47:45",
      "message": "Add authentication to lineage endpoint for experimental API (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)",
      "author": "Ian Carroll",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'airflow/www/api/experimental/endpoints.py': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/apache/airflow/raw/21cedff205e7d62675949fda2aa4616d77232b76/airflow%2Fwww%2Fapi%2Fexperimental%2Fendpoints.py', 'patch': '@@ -389,6 +389,7 @@ def delete_pool(name):\\n \\n \\n @api_experimental.route(\\'/lineage/<string:dag_id>/<string:execution_date>\\', methods=[\\'GET\\'])\\n+@requires_authentication\\n def get_lineage(dag_id: str, execution_date: str):\\n     \"\"\"Get Lineage details for a DagRun\"\"\"\\n     # Convert string datetime into actual datetime'}}",
      "message_norm": "add authentication to lineage endpoint for experimental api (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('authentication', 'SECWORD', ''), ('#13870', 'ISSUE', ''), ('commit 24a54242d56058846c7978130b3f37ca045d5142', 'SHA', 'prefix_colon_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['airflow/www/api/experimental/endpoints.py'])",
      "num_files": 1.0
    },
    {
      "index": 2152,
      "vuln_id": "GHSA-hwv5-w8gm-fq9f",
      "cwe_id": "{'CWE-22'}",
      "score": 3.5,
      "chain": "{'https://github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75'}",
      "dataset": "osv",
      "summary": "Directory Traversal vulnerability in GET/PUT allows attackers to Disclose Information or Write Files via a crafted GET/PUT request ### Impact\n\n#### Information Disclosure\n\nWhen the GET method is attacked, attackers can read files which have a `.data` suffix and which are accompanied by a JSON file with the `.meta` suffix. This can lead to Information Disclosure and in some shared-hosting scenarios also to circumvention of authentication or other limitations on the outbound (GET) traffic.\n\nFor example, in a scenario where a single server has multiple instances of the application running (with separate DATA_ROOT settings), an attacker who has knowledge about the directory structure is able to read files from any other instance to which the process has read access.\n\nIf instances have individual authentication (for example, HTTP authentication via a reverse proxy, source IP based filtering) or other restrictions (such as quotas), attackers may circumvent those limits in such a scenario by using the Directory Traversal to retrieve data from the other instances.\n\n#### File Write\n\nIf the associated XMPP server (or anyone knowing the SECRET_KEY) is malicious, they can write files outside the DATA_ROOT. The files which are written are constrained to have the `.meta` and the `.data` suffixes; the `.meta` file will contain the JSON with the Content-Type of the original request and the `.data` file will contain the payload.\n\n### Patches\n\nPR #12 fixes the issue. The PR has been merged into version 0.4.0 and 0.4.0 has been released and pushed to PyPI. Users are advised to upgrade immediately.\n\n### Workarounds\n\n- Apache can apparently be configured to filter such malicious paths when reverse-proxying. \n- There are no other workarounds known.\n\n### References\n\n- [Pull Request #12](https://github.com/horazont/xmpp-http-upload/pull/12)",
      "published_date": "2020-10-06",
      "chain_len": 1,
      "project": "https://github.com/horazont/xmpp-http-upload",
      "commit_href": "https://github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75",
      "commit_sha": "82056540191e89f0cd697c81f57714c00962ed75",
      "patch": "SINGLE",
      "chain_ord": "['82056540191e89f0cd697c81f57714c00962ed75']",
      "before_first_fix_commit": "{'f0fc7443c06a0e8aecb5696fc2bd513a2cc8b611'}",
      "last_fix_commit": "82056540191e89f0cd697c81f57714c00962ed75",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/05/2020, 23:06:21",
      "message": "Simplify path handling, use safe_join\n\nThe current implementation of sanitized_join did not handle\n\"..\" properly. The problem is, that .absolute() does not do\nwhat .resolve() does, but .resolve() does not work on non\nexistant paths.\n\nAnyway, flask has a function exactly for this: safe_join.\n\nSo let's use that one.\n\nWhile at it, simplified the whole path handling a bit.",
      "author": "Christian Tacke",
      "comments": null,
      "stats": "{'additions': 15, 'deletions': 34, 'total': 49}",
      "files": "{'xhu.py': {'additions': 15, 'deletions': 34, 'changes': 49, 'status': 'modified', 'raw_url': 'https://github.com/horazont/xmpp-http-upload/raw/82056540191e89f0cd697c81f57714c00962ed75/xhu.py', 'patch': '@@ -29,6 +29,7 @@\\n import typing\\n \\n import flask\\n+import werkzeug.exceptions\\n \\n app = flask.Flask(\"xmpp-http-upload\")\\n app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")\\n@@ -39,16 +40,11 @@\\n     CORS(app)\\n \\n \\n-def sanitized_join(path: str, root: pathlib.Path) -> pathlib.Path:\\n-    result = (root / path).absolute()\\n-    if not str(result).startswith(str(root) + \"/\"):\\n-        raise ValueError(\"resulting path is outside root\")\\n-    return result\\n-\\n-\\n-def get_paths(base_path: pathlib.Path):\\n-    data_file = pathlib.Path(str(base_path) + \".data\")\\n-    metadata_file = pathlib.Path(str(base_path) + \".meta\")\\n+def get_paths(root: str, sub_path: str) \\\\\\n+        -> typing.Tuple[pathlib.Path, pathlib.Path]:\\n+    base_path = flask.safe_join(root, sub_path)\\n+    data_file = pathlib.Path(base_path + \".data\")\\n+    metadata_file = pathlib.Path(base_path + \".meta\")\\n \\n     return data_file, metadata_file\\n \\n@@ -58,15 +54,10 @@ def load_metadata(metadata_file):\\n         return json.load(f)\\n \\n \\n-def get_info(path: str, root: pathlib.Path) -> typing.Tuple[\\n+def get_info(path: str) -> typing.Tuple[\\n         pathlib.Path,\\n         dict]:\\n-    dest_path = sanitized_join(\\n-        path,\\n-        pathlib.Path(app.config[\"DATA_ROOT\"]),\\n-    )\\n-\\n-    data_file, metadata_file = get_paths(dest_path)\\n+    data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\\n \\n     return data_file, load_metadata(metadata_file)\\n \\n@@ -104,11 +95,8 @@ def stream_file(src, dest, nbytes):\\n @app.route(\"/<path:path>\", methods=[\"PUT\"])\\n def put_file(path):\\n     try:\\n-        dest_path = sanitized_join(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"]),\\n-        )\\n-    except ValueError:\\n+        data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\\n+    except werkzeug.exceptions.NotFound:\\n         return flask.Response(\\n             \"Not Found\",\\n             404,\\n@@ -134,8 +122,7 @@ def put_file(path):\\n         \"application/octet-stream\",\\n     )\\n \\n-    dest_path.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\\n-    data_file, metadata_file = get_paths(dest_path)\\n+    data_file.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\\n \\n     try:\\n         with write_file(data_file) as fout:\\n@@ -189,13 +176,10 @@ def generate_headers(response_headers, metadata_headers):\\n @app.route(\"/<path:path>\", methods=[\"HEAD\"])\\n def head_file(path):\\n     try:\\n-        data_file, metadata = get_info(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\\n-        )\\n+        data_file, metadata = get_info(path)\\n \\n         stat = data_file.stat()\\n-    except (OSError, ValueError):\\n+    except (OSError, werkzeug.exceptions.NotFound):\\n         return flask.Response(\\n             \"Not Found\",\\n             404,\\n@@ -214,11 +198,8 @@ def head_file(path):\\n @app.route(\"/<path:path>\", methods=[\"GET\"])\\n def get_file(path):\\n     try:\\n-        data_file, metadata = get_info(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\\n-        )\\n-    except (OSError, ValueError):\\n+        data_file, metadata = get_info(path)\\n+    except (OSError, werkzeug.exceptions.NotFound):\\n         return flask.Response(\\n             \"Not Found\",\\n             404,'}}",
      "message_norm": "simplify path handling, use safe_join\n\nthe current implementation of sanitized_join did not handle\n\"..\" properly. the problem is, that .absolute() does not do\nwhat .resolve() does, but .resolve() does not work on non\nexistant paths.\n\nanyway, flask has a function exactly for this: safe_join.\n\nso let's use that one.\n\nwhile at it, simplified the whole path handling a bit.",
      "language": "en",
      "entities": "[('sanitized_join', 'SECWORD', ''), ('problem', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['xhu.py'])",
      "num_files": 1.0
    },
    {
      "index": 1669,
      "vuln_id": "GHSA-f5cx-5wr3-5qrc",
      "cwe_id": "{'CWE-824'}",
      "score": 7.1,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', 'https://github.com/tensorflow/tensorflow/commit/429f009d2b2c09028647dd4bb7b3f6f414bbaad7'}",
      "dataset": "osv",
      "summary": "Reference binding to nullptr in boosted trees ### Impact\nAn attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesCalculateBestGainsPerFeature(\n  node_id_range=[],\n  stats_summary_list=[[1,2,3]],\n  l1=[1.0],\n  l2=[1.0],\n  tree_complexity =[1.0],\n  min_node_weight =[1.17],\n  max_splits=5)\n```\n\nA similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`:\n\n```python\nimport tensorflow as tf\n                                                                                                                                                                                                                                                                                          \ntf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2(\n  node_id_range=[],\n  stats_summaries_list=[[1,2,3]],\n  split_types=[''],\n  candidate_feature_ids=[1,2,3,4],\n  l1=[1],     \n  l2=[1],\n  tree_complexity=[1.0],\n  min_node_weight=[1.17],\n  logits_dimension=5)\n```     \n    \nThe  [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) does not validate the input values.\n\n### Patches\nWe have patched the issue in GitHub commit [9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad](https://github.com/tensorflow/tensorflow/commit/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad) and in commit. [429f009d2b2c09028647dd4bb7b3f6f414bbaad7](https://github.com/tensorflow/tensorflow/commit/429f009d2b2c09028647dd4bb7b3f6f414bbaad7).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad",
      "commit_sha": "9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad",
      "patch": "MULTI",
      "chain_ord": "['9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', '429f009d2b2c09028647dd4bb7b3f6f414bbaad7']",
      "before_first_fix_commit": "{'4f8db85aa9ab71a71e95d5acce7de52a0b195661'}",
      "last_fix_commit": "429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/27/2021, 19:11:33",
      "message": "Disallow empty node_id_range in tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2 and tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature\n\nPiperOrigin-RevId: 387165936\nChange-Id: I2f70341af96236b2776c2a592c917d549c1fc1e2",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 20, 'deletions': 0, 'total': 20}",
      "files": "{'tensorflow/core/kernels/boosted_trees/stats_ops.cc': {'additions': 20, 'deletions': 0, 'changes': 20, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -51,6 +51,16 @@ class BoostedTreesCalculateBestGainsPerFeatureOp : public OpKernel {\\n     // node_id_range\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->dims() == 1,\\n+        errors::InvalidArgument(\"node_id_range must be a rank 1 tensor, but \"\\n+                                \"given node_id_range has dims of \",\\n+                                node_id_range_t->dims()));\\n+    OP_REQUIRES(context, node_id_range_t->dim_size(0) == 2,\\n+                errors::InvalidArgument(\\n+                    \"node_id_range must be a rank 1 tensor with shape=[2], but \"\\n+                    \"given node_id_range has shape \",\\n+                    node_id_range_t->dim_size(0), \" on its first dim\"));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n     const int32_t node_id_first = node_id_range(0);  // inclusive\\n     const int32_t node_id_last = node_id_range(1);   // exclusive\\n@@ -570,6 +580,16 @@ class BoostedTreesCalculateBestFeatureSplitV2 : public OpKernel {\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->dims() == 1,\\n+        errors::InvalidArgument(\"node_id_range must be a rank 1 tensor, but \"\\n+                                \"given node_id_range has dims of \",\\n+                                node_id_range_t->dims()));\\n+    OP_REQUIRES(context, node_id_range_t->dim_size(0) == 2,\\n+                errors::InvalidArgument(\\n+                    \"node_id_range must be a rank 1 tensor with shape=[2], but \"\\n+                    \"given node_id_range has shape \",\\n+                    node_id_range_t->dim_size(0), \" on its first dim\"));\\n     const int32_t node_id_first = node_id_range(0);  // Inclusive.\\n     const int32_t node_id_last = node_id_range(1);   // Exclusive.'}}",
      "message_norm": "disallow empty node_id_range in tf.raw_ops.boostedtreescalculatebestfeaturesplitv2 and tf.raw_ops.boostedtreescalculatebestgainsperfeature\n\npiperorigin-revid: 387165936\nchange-id: i2f70341af96236b2776c2a592c917d549c1fc1e2",
      "language": "en",
      "entities": "[('387165936', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/boosted_trees/stats_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1026,
      "vuln_id": "GHSA-7fvx-3jfc-2cpc",
      "cwe_id": "{'CWE-125'}",
      "score": 7.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/01cff3f986259d661103412a20745928c727326f'}",
      "dataset": "osv",
      "summary": "Heap OOB in `ResourceScatterUpdate` ### Impact\nAn attacker can trigger a read from outside of bounds of heap allocated data by sending invalid arguments to `tf.raw_ops.ResourceScatterUpdate`:\n\n```python\nimport tensorflow as tf\n\nv = tf.Variable([b'vvv'])\ntf.raw_ops.ResourceScatterUpdate(\n  resource=v.handle,\n  indices=[0],\n  updates=['1', '2', '3', '4', '5'])\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L919-L923) has an incomplete validation of the relationship between the shapes of `indices` and `updates`: instead of checking that the shape of `indices` is a prefix of the shape of `updates` (so that broadcasting can happen), code only checks that the number of elements in these two tensors are in a divisibility relationship.\n\n### Patches \nWe have patched the issue in GitHub commit [01cff3f986259d661103412a20745928c727326f](https://github.com/tensorflow/tensorflow/commit/01cff3f986259d661103412a20745928c727326f).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n    \n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n    \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/01cff3f986259d661103412a20745928c727326f",
      "commit_sha": "01cff3f986259d661103412a20745928c727326f",
      "patch": "SINGLE",
      "chain_ord": "['01cff3f986259d661103412a20745928c727326f']",
      "before_first_fix_commit": "{'96f364a1ca3009f98980021c4b32be5fdcca33a1'}",
      "last_fix_commit": "01cff3f986259d661103412a20745928c727326f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/02/2021, 20:33:05",
      "message": "Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`\n\nPiperOrigin-RevId: 388292801\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 5, 'total': 11}",
      "files": "{'tensorflow/core/kernels/resource_variable_ops.cc': {'additions': 6, 'deletions': 5, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/01cff3f986259d661103412a20745928c727326f/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.cc', 'patch': '@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\\n                         params->dim_size(0), \")\"));\\n       } else {\\n         int64_t num_updates = updates.NumElements();\\n-        OP_REQUIRES(c, num_updates % N == 0,\\n-                    errors::InvalidArgument(\\n-                        \"shape of indices (\", indices.shape().DebugString(),\\n-                        \") is not compatible with the shape of updates (\",\\n-                        updates.shape().DebugString(), \")\"));\\n+        OP_REQUIRES(\\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\\n+            errors::InvalidArgument(\\n+                \"The shape of indices (\", indices.shape().DebugString(),\\n+                \") must be a prefix of the shape of updates (\",\\n+                updates.shape().DebugString(), \")\"));\\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\\n \\n         functor::ScatterFunctor<Device, T, Index, op> functor;'}}",
      "message_norm": "fix heap oob due to dimension mismatch in `resourcescatterupdate`\n\npiperorigin-revid: 388292801\nchange-id: id9bd7244d98d41b1517d4771850b32782c0cc949",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('388292801', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/resource_variable_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1013,
      "vuln_id": "GHSA-7cqx-92hp-x6wh",
      "cwe_id": "{'CWE-787', 'CWE-119'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/63c6a29d0f2d692b247f7bf81f8732d6442fad09'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `MaxPool3DGradGrad` ### Impact\nThe implementation of `tf.raw_ops.MaxPool3DGradGrad` is vulnerable to a heap buffer overflow: \n\n```python\nimport tensorflow as tf\n\nvalues = [0.01] * 11\norig_input = tf.constant(values, shape=[11, 1, 1, 1, 1], dtype=tf.float32)\norig_output = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.MaxPool3DGradGrad(\n    orig_input=orig_input, orig_output=orig_output, grad=grad, ksize=ksize,\n    strides=strides, padding=padding)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/596c05a159b6fbb9e39ca10b3f7753b7244fa1e9/tensorflow/core/kernels/pooling_ops_3d.cc#L694-L696) does not check that the initialization of `Pool3dParameters` completes successfully:\n\n```cc\nPool3dParameters params{context,  ksize_,       stride_,\n                        padding_, data_format_, tensor_in.shape()};\n```\n\nSince [the constructor](https://github.com/tensorflow/tensorflow/blob/596c05a159b6fbb9e39ca10b3f7753b7244fa1e9/tensorflow/core/kernels/pooling_ops_3d.cc#L48-L88) uses `OP_REQUIRES` to validate conditions, the first assertion that fails interrupts the initialization of `params`, making it contain invalid data. In turn, this might cause a heap buffer overflow, depending on default initialized values.\n\n### Patches\nWe have patched the issue in GitHub commit [63c6a29d0f2d692b247f7bf81f8732d6442fad09](https://github.com/tensorflow/tensorflow/commit/63c6a29d0f2d692b247f7bf81f8732d6442fad09).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/63c6a29d0f2d692b247f7bf81f8732d6442fad09",
      "commit_sha": "63c6a29d0f2d692b247f7bf81f8732d6442fad09",
      "patch": "SINGLE",
      "chain_ord": "['63c6a29d0f2d692b247f7bf81f8732d6442fad09']",
      "before_first_fix_commit": "{'596c05a159b6fbb9e39ca10b3f7753b7244fa1e9'}",
      "last_fix_commit": "63c6a29d0f2d692b247f7bf81f8732d6442fad09",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/06/2021, 01:07:02",
      "message": "Add missing validation, prevent heap OOB\n\nPiperOrigin-RevId: 372246723\nChange-Id: I1a454a643810e77d7d14821b342098c56a09fbbf",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 0, 'total': 12}",
      "files": "{'tensorflow/core/kernels/pooling_ops_3d.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/63c6a29d0f2d692b247f7bf81f8732d6442fad09/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc', 'patch': '@@ -693,6 +693,7 @@ class MaxPooling3dGradGradOp : public OpKernel {\\n \\n     Pool3dParameters params{context,  ksize_,       stride_,\\n                             padding_, data_format_, tensor_in.shape()};\\n+    if (!context->status().ok()) return;  // params is invalid\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\\n@@ -710,6 +711,17 @@ class MaxPooling3dGradGradOp : public OpKernel {\\n         context, out_grad_backprop.NumElements() > 0,\\n         errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",\\n                                 out_grad_backprop.DebugString()));\\n+    OP_REQUIRES(context,\\n+                tensor_in.NumElements() == out_grad_backprop.NumElements(),\\n+                errors::InvalidArgument(\"tensor_in and out_grad_backprop must \"\\n+                                        \"have same number of elements, got <\",\\n+                                        tensor_in.DebugString(), \"> and <\",\\n+                                        out_grad_backprop.DebugString(), \">\"));\\n+    OP_REQUIRES(\\n+        context, tensor_out.NumElements() == output->NumElements(),\\n+        errors::InvalidArgument(\\n+            \"tensor_out and output must have same number of elements, got <\",\\n+            tensor_out.DebugString(), \"> and <\", output->DebugString(), \">\"));\\n \\n     LaunchMaxPooling3dGradGradOp<Device, T>::launch(\\n         context, params, tensor_in, tensor_out, out_grad_backprop, output);'}}",
      "message_norm": "add missing validation, prevent heap oob\n\npiperorigin-revid: 372246723\nchange-id: i1a454a643810e77d7d14821b342098c56a09fbbf",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('372246723', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/pooling_ops_3d.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2547,
      "vuln_id": "GHSA-pc22-3g76-gm6j",
      "cwe_id": "{'CWE-379', 'CWE-378'}",
      "score": 9.3,
      "chain": "{'https://github.com/swagger-api/swagger-codegen/commit/987ea7a30b463cc239580d6ad166c707ae942a89'}",
      "dataset": "osv",
      "summary": "Generator Web Application: Local Privilege Escalation Vulnerability via System Temp Directory ### Impact\n\nOn Unix like systems, the system's temporary directory is shared between all users on that system. A collocated user can observe the process of creating a temporary sub directory in the shared temporary directory and race to complete the creation of the temporary subdirectory. \n\nThis vulnerability is local privilege escalation because the contents of the `outputFolder` can be appended to by an attacker. As such, code written to this directory, when executed can be attacker controlled.\n\n#### Java Code\n\nThe method `File.createTempFile` from the JDK is vulnerable to this local information disclosure vulnerability.\n\nhttps://github.com/swagger-api/swagger-codegen/blob/068b1ebcb7b04a48ad38f1cadd24bb3810c9f1ab/modules/swagger-generator/src/main/java/io/swagger/generator/online/Generator.java#L174-L185\n\n\n### Patches\n\nFix has been applied to the master branch with:\n\n* https://github.com/swagger-api/swagger-codegen/commit/987ea7a30b463cc239580d6ad166c707ae942a89\n\nincluded in release: 2.4.19\n\n\n### References\n\n* [CWE-378: Creation of Temporary File With Insecure Permissions](https://cwe.mitre.org/data/definitions/378.html)\n* [CWE-379: Creation of Temporary File in Directory with Insecure Permissions](https://cwe.mitre.org/data/definitions/379.html)\n\n### For more information\nIf you have any questions or comments about this advisory:\n\n* Email us at [security@swagger.io](mailto:security@swagger.io)\n\n#### Original vulnerability report\n\n> I'm performing OSS security research under the GitHub Security Lab Bug Bounty program.\n> I've been using a custom CodeQL query to find local temporary directory vulnerabilities in OSS with three custom CodeQL queries.\n> \n> - https://github.com/github/codeql/pull/4388/files#diff-71d36c0f2bd0b08e32866f873f1c906cdc17277e0ad327c0c6cd2c882f30de4f\n> - https://github.com/github/codeql/pull/4388/files#diff-1893a18a8bf43c011d61a7889d0139b998a5a78701a30fe7722eddd4c506aaac\n> - https://github.com/github/codeql/pull/4473\n> \n> The code generated by the Swagger Generator contains a local information disclosure vulnerability. The system temporary directory, on unix-like systems is shared between multiple users. Information written to this directory, or directories created under this directory that do not correctly set the posix standard permissions can have these directories read/modified by other users.\n> \n> ---\n> \n> This vulnerability exists in the maven plugin.\n> \n> This vulnerability is distinctly different. This vulnerability is most likely a local privilege escalation vulnerability.\n> \n> https://github.com/swagger-api/swagger-codegen/blob/068b1ebcb7b04a48ad38f1cadd24bb3810c9f1ab/modules/swagger-generator/src/main/java/io/swagger/generator/online/Generator.java#L174-L185\n> \n> This vulnerability is very similar to this similar vulnerability I disclosed in the Eclipse Jetty project.\n> \n> https://github.com/eclipse/jetty.project/security/advisories/GHSA-g3wg-6mcf-8jj6\n> \n> This is due to a race condition between the call to `delete` and the call to `mkdirs`.\n> \n> ```java\n> // ensure file will always be unique by appending random digits\n> File outputFolder = File.createTempFile(\"codegen-\", \"-tmp\"); // Attacker knows the full path of the file that will be generated\n> // delete the file that was created\n> outputFolder.delete(); // Attacker sees file is deleted and begins a race to create their own directory before Swagger Code Generator.\n> // and make a directory of the same name\n> // SECURITY VULNERABILITY: Race Condition! - Attacker beats Swagger Code Generator and now owns this directory\n> outputFolder.mkdirs();\n> ```\n> \n> This vulnerability is local privilege escalation because the contents of the `outputFolder` can be appended to by an attacker. As such, code written to this directory, when executed can be attacker controlled.\n> \n> The fix here is to switch to the `Files` API for creating temporary directories. Which does not contain this race condition, and appropriately sets the correct file permissions.\n>",
      "published_date": "2021-03-11",
      "chain_len": 1,
      "project": "https://github.com/swagger-api/swagger-codegen",
      "commit_href": "https://github.com/swagger-api/swagger-codegen/commit/987ea7a30b463cc239580d6ad166c707ae942a89",
      "commit_sha": "987ea7a30b463cc239580d6ad166c707ae942a89",
      "patch": "SINGLE",
      "chain_ord": "['987ea7a30b463cc239580d6ad166c707ae942a89']",
      "before_first_fix_commit": "{'3b40539b2260fbf1c8198dceb8797599c3944ef7', 'a4b766beb6141ed66dbe1be23bce32366b5f9486'}",
      "last_fix_commit": "987ea7a30b463cc239580d6ad166c707ae942a89",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/02/2021, 10:05:49",
      "message": "Merge pull request from GHSA-pc22-3g76-gm6j\n\n security: use java.nio.files in Generator.",
      "author": "Francesco Tumanischvili",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 3, 'total': 5}",
      "files": "{'modules/swagger-generator/src/main/java/io/swagger/generator/online/Generator.java': {'additions': 2, 'deletions': 3, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/swagger-api/swagger-codegen/raw/987ea7a30b463cc239580d6ad166c707ae942a89/modules%2Fswagger-generator%2Fsrc%2Fmain%2Fjava%2Fio%2Fswagger%2Fgenerator%2Fonline%2FGenerator.java', 'patch': '@@ -15,6 +15,7 @@\\n import org.slf4j.LoggerFactory;\\n \\n import java.io.File;\\n+import java.nio.file.Files;\\n import java.util.ArrayList;\\n import java.util.LinkedHashMap;\\n import java.util.List;\\n@@ -173,9 +174,7 @@ public static InputOption serverOptions(@SuppressWarnings(\"unused\") String langu\\n \\n     protected static File getTmpFolder() {\\n         try {\\n-            File outputFolder = File.createTempFile(\"codegen-\", \"-tmp\");\\n-            outputFolder.delete();\\n-            outputFolder.mkdir();\\n+            File outputFolder = Files.createTempDirectory(\"codegen-\").toFile();\\n             outputFolder.deleteOnExit();\\n             return outputFolder;\\n         } catch (Exception e) {'}}",
      "message_norm": "merge pull request from ghsa-pc22-3g76-gm6j\n\n security: use java.nio.files in generator.",
      "language": "en",
      "entities": "[('ghsa-pc22-3g76-gm6j', 'VULNID', 'GHSA'), ('security', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['modules/swagger-generator/src/main/java/io/swagger/generator/online/Generator.java'])",
      "num_files": 1.0
    },
    {
      "index": 2475,
      "vuln_id": "GHSA-mw6j-hh29-h379",
      "cwe_id": "{'CWE-190'}",
      "score": 0.0,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/3796cc4fcd93ae55812a457abc96dcd55fbb854b'}",
      "dataset": "osv",
      "summary": "`CHECK` failure in depthwise ops via overflows ### Impact\nThe implementation of depthwise ops in TensorFlow is vulnerable to a denial of service via `CHECK`-failure (assertion failure) caused by overflowing the number of elements in a tensor:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant(1, shape=[1, 4, 4, 3], dtype=tf.float32)\nfilter_sizes = tf.constant(1879048192, shape=[13], dtype=tf.int32)\nout_backprop = tf.constant(1, shape=[1, 4, 4, 3], dtype=tf.float32)\ntf.raw_ops.DepthwiseConv2dNativeBackpropFilter(\n    input=input, filter_sizes=filter_sizes, out_backprop=out_backprop, strides=[1, 1, 1, 1], padding=\"SAME\")\n```\n  \nThis is another instance of [TFSA-2021-198](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa-2021-198.md) (CVE-2021-41197).\n  \n### Patches\nWe have patched the issue in GitHub commit [3796cc4fcd93ae55812a457abc96dcd55fbb854b](https://github.com/tensorflow/tensorflow/commit/3796cc4fcd93ae55812a457abc96dcd55fbb854b).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Neophytos Christou from Secure Systems Lab at Brown University.",
      "published_date": "2022-05-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/3796cc4fcd93ae55812a457abc96dcd55fbb854b",
      "commit_sha": "3796cc4fcd93ae55812a457abc96dcd55fbb854b",
      "patch": "SINGLE",
      "chain_ord": "['3796cc4fcd93ae55812a457abc96dcd55fbb854b']",
      "before_first_fix_commit": "{'8f704c59219243ee66bdeb93cb3471e8e6af7d86'}",
      "last_fix_commit": "3796cc4fcd93ae55812a457abc96dcd55fbb854b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/27/2022, 22:53:46",
      "message": "Fix tf.raw_ops.DepthwiseConv2dNativeBackpropInput vulnerability with large input sizes.\n\nUse AddDimWithStatus rather than AddDim in order to catch and report integer overflow gracefully.\n\nPiperOrigin-RevId: 444989983",
      "author": "Alan Liu",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 2, 'total': 5}",
      "files": "{'tensorflow/core/kernels/depthwise_conv_grad_op.cc': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/3796cc4fcd93ae55812a457abc96dcd55fbb854b/tensorflow%2Fcore%2Fkernels%2Fdepthwise_conv_grad_op.cc', 'patch': '@@ -625,7 +625,7 @@ class DepthwiseConv2dNativeBackpropInputOp : public OpKernel {\\n       OP_REQUIRES(context, in_sizes_data[i] >= 0,\\n                   errors::InvalidArgument(\"Dimension \", i,\\n                                           \" of input_sizes must be >= 0\"));\\n-      input_shape.AddDim(in_sizes_data[i]);\\n+      OP_REQUIRES_OK(context, input_shape.AddDimWithStatus(in_sizes_data[i]));\\n     }\\n     const TensorShape& filter_shape = filter.shape();\\n     EXTRACT_AND_VERIFY_DIMENSIONS(\"DepthwiseConv2DBackpropInput\");\\n@@ -1131,7 +1131,8 @@ class DepthwiseConv2dNativeBackpropFilterOp : public OpKernel {\\n       OP_REQUIRES(context, filter_sizes_data[i] >= 0,\\n                   errors::InvalidArgument(\"Dimension \", i,\\n                                           \" of filter_sizes must be >= 0\"));\\n-      filter_shape.AddDim(filter_sizes_data[i]);\\n+      OP_REQUIRES_OK(context,\\n+                     filter_shape.AddDimWithStatus(filter_sizes_data[i]));\\n     }\\n     const TensorShape& input_shape = input.shape();'}}",
      "message_norm": "fix tf.raw_ops.depthwiseconv2dnativebackpropinput vulnerability with large input sizes.\n\nuse adddimwithstatus rather than adddim in order to catch and report integer overflow gracefully.\n\npiperorigin-revid: 444989983",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('integer overflow', 'SECWORD', ''), ('444989983', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/depthwise_conv_grad_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 688,
      "vuln_id": "GHSA-5rcr-q3rx-j7vr",
      "cwe_id": "{'CWE-787'}",
      "score": 7.5,
      "chain": "{'https://github.com/chakra-core/ChakraCore/commit/75162b7f2d8ac2b37d17564e9c979ba1bae707e8', 'https://github.com/chakra-core/ChakraCore/commit/214dec9461f9acb9a4b9004368d2a81e0c125652'}",
      "dataset": "osv",
      "summary": "Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1062, CVE-2019-1092, CVE-2019-1103, CVE-2019-1106.",
      "published_date": "2021-03-29",
      "chain_len": 2,
      "project": "https://github.com/chakra-core/ChakraCore",
      "commit_href": "https://github.com/chakra-core/ChakraCore/commit/214dec9461f9acb9a4b9004368d2a81e0c125652",
      "commit_sha": "214dec9461f9acb9a4b9004368d2a81e0c125652",
      "patch": "MULTI",
      "chain_ord": "['214dec9461f9acb9a4b9004368d2a81e0c125652', '75162b7f2d8ac2b37d17564e9c979ba1bae707e8']",
      "before_first_fix_commit": "{'12c31f0e83ddc511e57b9aa1e78533899199eb32', 'ba1f4455f921ce5f12091ff8a11c8028c6a64b17'}",
      "last_fix_commit": "75162b7f2d8ac2b37d17564e9c979ba1bae707e8",
      "chain_ord_pos": 1.0,
      "commit_datetime": "06/06/2019, 19:58:34",
      "message": "[CVE-2019-1107] Chakra JIT Type Confusion FinishOptPropOp",
      "author": "Paul Leathers",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 0, 'total': 8}",
      "files": "{'lib/Backend/GlobOptFields.cpp': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/chakra-core/ChakraCore/raw/214dec9461f9acb9a4b9004368d2a81e0c125652/lib%2FBackend%2FGlobOptFields.cpp', 'patch': '@@ -410,6 +410,14 @@ GlobOpt::ProcessFieldKills(IR::Instr *instr, BVSparse<JitArenaAllocator> *bv, bo\\n         if (inGlobOpt)\\n         {\\n             KillObjectHeaderInlinedTypeSyms(this->currentBlock, false);\\n+            if (this->objectTypeSyms)\\n+            {\\n+                if (this->currentBlock->globOptData.maybeWrittenTypeSyms == nullptr)\\n+                {\\n+                    this->currentBlock->globOptData.maybeWrittenTypeSyms = JitAnew(this->alloc, BVSparse<JitArenaAllocator>, this->alloc);\\n+                }\\n+                this->currentBlock->globOptData.maybeWrittenTypeSyms->Or(this->objectTypeSyms);\\n+            }\\n         }\\n \\n         // fall through'}}",
      "message_norm": "[cve-2019-1107] chakra jit type confusion finishoptpropop",
      "language": "en",
      "entities": "[('cve-2019-1107', 'VULNID', 'CVE'), ('type confusion', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/Backend/GlobOptFields.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 1094,
      "vuln_id": "GHSA-7wv8-g97r-432h",
      "cwe_id": "{'CWE-200'}",
      "score": 7.5,
      "chain": "{'https://github.com/microweber/microweber/commit/e680e134a4215c979bfd2eaf58336be34c8fc6e6'}",
      "dataset": "osv",
      "summary": "Exposure of Sensitive Information to an Unauthorized Actor in microweber Exposure of Sensitive Information to an Unauthorized Actor in Packagist microweber/microweber prior to 1.2.11.",
      "published_date": "2022-01-21",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/e680e134a4215c979bfd2eaf58336be34c8fc6e6",
      "commit_sha": "e680e134a4215c979bfd2eaf58336be34c8fc6e6",
      "patch": "SINGLE",
      "chain_ord": "['e680e134a4215c979bfd2eaf58336be34c8fc6e6']",
      "before_first_fix_commit": "{'62aa09ed44ff63f5fffc5addbf000423d7c38e44'}",
      "last_fix_commit": "e680e134a4215c979bfd2eaf58336be34c8fc6e6",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/19/2022, 09:35:10",
      "message": "search_authors only admins",
      "author": "Bozhidar Slaveykov",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'src/MicroweberPackages/User/helpers/api_user.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/e680e134a4215c979bfd2eaf58336be34c8fc6e6/src%2FMicroweberPackages%2FUser%2Fhelpers%2Fapi_user.php', 'patch': \"@@ -63,9 +63,9 @@\\n \\n });\\n \\n-api_expose('users/search_authors', function ($params = false) {\\n+api_expose_admin('users/search_authors', function ($params = false) {\\n \\n-    $return = array();\\n+    $return = array(); \\n \\n     $kw = false;\\n     if (isset($params['kw'])) {\"}}",
      "message_norm": "search_authors only admins",
      "language": "en",
      "entities": "[('admins', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/User/helpers/api_user.php'])",
      "num_files": 1.0
    },
    {
      "index": 2289,
      "vuln_id": "GHSA-jppv-gw3r-w3q8",
      "cwe_id": "{'CWE-78'}",
      "score": 0.0,
      "chain": "{'https://github.com/ruby/rake/commit/5b8f8fc41a5d7d7d6a5d767e48464c60884d3aee'}",
      "dataset": "osv",
      "summary": "OS Command Injection in Rake There is an OS command injection vulnerability in Ruby Rake before 12.3.3 in Rake::FileList when supplying a filename that begins with the pipe character `|`.",
      "published_date": "2020-02-28",
      "chain_len": 1,
      "project": "https://github.com/ruby/rake",
      "commit_href": "https://github.com/ruby/rake/commit/5b8f8fc41a5d7d7d6a5d767e48464c60884d3aee",
      "commit_sha": "5b8f8fc41a5d7d7d6a5d767e48464c60884d3aee",
      "patch": "SINGLE",
      "chain_ord": "['5b8f8fc41a5d7d7d6a5d767e48464c60884d3aee']",
      "before_first_fix_commit": "{'6497ba4d94d12c123df48cc8ab40f0a4eb7fb337'}",
      "last_fix_commit": "5b8f8fc41a5d7d7d6a5d767e48464c60884d3aee",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/22/2019, 01:23:43",
      "message": "Use File.open explicitly.",
      "author": "Hiroshi SHIBATA",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'lib/rake/file_list.rb': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/ruby/rake/raw/5b8f8fc41a5d7d7d6a5d767e48464c60884d3aee/lib%2Frake%2Ffile_list.rb', 'patch': '@@ -294,7 +294,7 @@ def egrep(pattern, *options)\\n       matched = 0\\n       each do |fn|\\n         begin\\n-          open(fn, \"r\", *options) do |inf|\\n+          File.open(fn, \"r\", *options) do |inf|\\n             count = 0\\n             inf.each do |line|\\n               count += 1'}}",
      "message_norm": "use file.open explicitly.",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/rake/file_list.rb'])",
      "num_files": 1.0
    },
    {
      "index": 2252,
      "vuln_id": "GHSA-jgrx-mgxx-jf9v",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/daaku/nodejs-tmpl/commit/4c654e4d1542f329ed561fd95ccd80f30c6872d6'}",
      "dataset": "osv",
      "summary": "tmpl vulnerable to Inefficient Regular Expression Complexity which may lead to resource exhaustion nodejs-tmpl is simple string formatting. tmpl is vulnerable to Inefficient Regular Expression Complexity which may lead to resource exhaustion.",
      "published_date": "2021-09-20",
      "chain_len": 1,
      "project": "https://github.com/daaku/nodejs-tmpl",
      "commit_href": "https://github.com/daaku/nodejs-tmpl/commit/4c654e4d1542f329ed561fd95ccd80f30c6872d6",
      "commit_sha": "4c654e4d1542f329ed561fd95ccd80f30c6872d6",
      "patch": "SINGLE",
      "chain_ord": "['4c654e4d1542f329ed561fd95ccd80f30c6872d6']",
      "before_first_fix_commit": "{'1dbd350783f04743bd759cc5ae1e1e3633d550ff'}",
      "last_fix_commit": "4c654e4d1542f329ed561fd95ccd80f30c6872d6",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/07/2021, 06:41:06",
      "message": "fix potential dos in regex",
      "author": "Naitik Shah",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'lib/tmpl.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/daaku/nodejs-tmpl/raw/4c654e4d1542f329ed561fd95ccd80f30c6872d6/lib%2Ftmpl.js', 'patch': \"@@ -1,4 +1,4 @@\\n-var INTERPOLATE = /{([\\\\s\\\\S]+?)}/g\\n+var INTERPOLATE = /{([^{]+?)}/g\\n \\n module.exports = function(str, data) {\\n   var tmpl = 'var __p=[],print=function(){__p.push.apply(__p,arguments);};' +\"}}",
      "message_norm": "fix potential dos in regex",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('dos', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/tmpl.js'])",
      "num_files": 1.0
    },
    {
      "index": 378,
      "vuln_id": "GHSA-47vg-483w-hp3m",
      "cwe_id": "{'CWE-384'}",
      "score": 4.3,
      "chain": "{'https://github.com/filegator/filegator/commit/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225'}",
      "dataset": "osv",
      "summary": "Improper user session handling in filegator FileGator prior to version 7.8.0 is vulnerable to session fixation.",
      "published_date": "2022-05-25",
      "chain_len": 1,
      "project": "https://github.com/filegator/filegator",
      "commit_href": "https://github.com/filegator/filegator/commit/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
      "commit_sha": "fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
      "patch": "SINGLE",
      "chain_ord": "['fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225']",
      "before_first_fix_commit": "{'6e2b68f17f48cdc1d6a4a93a2369d2069fe64989'}",
      "last_fix_commit": "fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/24/2022, 11:08:43",
      "message": "regenerate session on user update",
      "author": "Milos Stojanovic",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'backend/Services/Auth/Adapters/JsonFile.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/filegator/filegator/raw/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225/backend%2FServices%2FAuth%2FAdapters%2FJsonFile.php', 'patch': \"@@ -53,7 +53,7 @@ public function user(): ?User\\n \\n         if ($user) {\\n             foreach ($this->getUsers() as $u) {\\n-                if ($u['username'] == $user->getUsername() && $hash == $u['password']) {\\n+                if ($u['username'] == $user->getUsername() && $hash == $u['password'].$u['permissions'].$u['homedir'].$u['role']) {\\n                     return $user;\\n                 }\\n             }\\n@@ -70,7 +70,7 @@ public function authenticate($username, $password): bool\\n             if ($u['username'] == $username && $this->verifyPassword($password, $u['password'])) {\\n                 $user = $this->mapToUserObject($u);\\n                 $this->store($user);\\n-                $this->session->set(self::SESSION_HASH, $u['password']);\\n+                $this->session->set(self::SESSION_HASH, $u['password'].$u['permissions'].$u['homedir'].$u['role']);\\n \\n                 return true;\\n             }\"}}",
      "message_norm": "regenerate session on user update",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['backend/Services/Auth/Adapters/JsonFile.php'])",
      "num_files": 1.0
    },
    {
      "index": 1223,
      "vuln_id": "GHSA-8jj7-5vxc-pg2q",
      "cwe_id": "{'CWE-190'}",
      "score": 8.8,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/0aaaae6eca5a7175a193696383f582f53adab23f'}",
      "dataset": "osv",
      "summary": "Integer overflow in TensorFlow ### Impact\nUnder certain scenarios, Grappler component of TensorFlow is vulnerable to an integer overflow during [cost estimation for crop and resize](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/grappler/costs/op_level_cost_estimator.cc#L2621-L2689). Since the cropping parameters are user controlled, a malicious person can trigger undefined behavior.\n\n### Patches\nWe have patched the issue in GitHub commit [0aaaae6eca5a7175a193696383f582f53adab23f](https://github.com/tensorflow/tensorflow/commit/0aaaae6eca5a7175a193696383f582f53adab23f).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/0aaaae6eca5a7175a193696383f582f53adab23f",
      "commit_sha": "0aaaae6eca5a7175a193696383f582f53adab23f",
      "patch": "SINGLE",
      "chain_ord": "['0aaaae6eca5a7175a193696383f582f53adab23f']",
      "before_first_fix_commit": "{'6b5adc0877de832b2a7c189532dbbbc64622eeb6'}",
      "last_fix_commit": "0aaaae6eca5a7175a193696383f582f53adab23f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/13/2021, 16:19:05",
      "message": "Prevent overflow in grappler cost estimation of crop&resize op.\n\nThe crop parameters are user controlled, so we should make sure a user can not trigger an overflow maliciously.\n\nPiperOrigin-RevId: 409670234\nChange-Id: I7994734a98b037c5642e051240329d16f959aae4",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 22, 'deletions': 7, 'total': 29}",
      "files": "{'tensorflow/core/grappler/costs/op_level_cost_estimator.cc': {'additions': 22, 'deletions': 7, 'changes': 29, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/0aaaae6eca5a7175a193696383f582f53adab23f/tensorflow%2Fcore%2Fgrappler%2Fcosts%2Fop_level_cost_estimator.cc', 'patch': '@@ -2681,27 +2681,42 @@ Status OpLevelCostEstimator::PredictCropAndResize(const OpContext& op_context,\\n   // calculation differs from rough estimate in implementation, as it separates\\n   // out cost per box from cost per pixel and cost per element.\\n \\n+  // Since crop arguments are user controlled, check for overflow.\\n+  int64_t crop_area = MultiplyWithoutOverflow(crop_height, crop_width);\\n+  if (crop_area < 0)\\n+    return errors::InvalidArgument(\"Cannot estimate cost, multiplying \",\\n+                                   crop_height, \" with \", crop_width,\\n+                                   \" would overflow\");\\n+  int64_t crop_volume = MultiplyWithoutOverflow(crop_area, num_boxes);\\n+  if (crop_volume < 0)\\n+    return errors::InvalidArgument(\"Cannot estimate cost, multiplying \",\\n+                                   crop_area, \" with \", num_boxes,\\n+                                   \" would overflow\");\\n+  int64_t crop_depth = MultiplyWithoutOverflow(crop_height, num_boxes);\\n+  if (crop_depth < 0)\\n+    return errors::InvalidArgument(\"Cannot estimate cost, multiplying \",\\n+                                   crop_height, \" with \", num_boxes,\\n+                                   \" would overflow\");\\n+\\n   // Ops for variables height_scale and width_scale.\\n   int64_t ops = (sub_cost * 6 + mul_cost * 2 + div_cost * 2) * num_boxes;\\n   // Ops for variable in_y.\\n-  ops += (mul_cost * 2 + sub_cost + add_cost) * crop_height * num_boxes;\\n+  ops += (mul_cost * 2 + sub_cost + add_cost) * crop_depth;\\n   // Ops for variable in_x (same computation across both branches).\\n-  ops += (mul_cost * 2 + sub_cost + add_cost) * crop_height * crop_width *\\n-         num_boxes;\\n+  ops += (mul_cost * 2 + sub_cost + add_cost) * crop_volume;\\n   // Specify op_cost based on the method.\\n   if (use_bilinear_interp) {\\n     // Ops for variables top_y_index, bottom_y_index, y_lerp.\\n-    ops += (floor_cost + ceil_cost + sub_cost) * crop_height * num_boxes;\\n+    ops += (floor_cost + ceil_cost + sub_cost) * crop_depth;\\n     // Ops for variables left_x, right_x, x_lerp;\\n-    ops += (floor_cost + ceil_cost + sub_cost) * crop_height * crop_width *\\n-           num_boxes;\\n+    ops += (floor_cost + ceil_cost + sub_cost) * crop_volume;\\n     // Ops for innermost loop across depth.\\n     ops +=\\n         (cast_to_float_cost * 4 + add_cost * 3 + sub_cost * 3 + mul_cost * 3) *\\n         output_elements;\\n   } else /* method == \"nearest\" */ {\\n     // Ops for variables closest_x_index and closest_y_index.\\n-    ops += round_cost * 2 * crop_height * crop_width * num_boxes;\\n+    ops += round_cost * 2 * crop_volume;\\n     // Ops for innermost loop across depth.\\n     ops += cast_to_float_cost * output_elements;\\n   }'}}",
      "message_norm": "prevent overflow in grappler cost estimation of crop&resize op.\n\nthe crop parameters are user controlled, so we should make sure a user can not trigger an overflow maliciously.\n\npiperorigin-revid: 409670234\nchange-id: i7994734a98b037c5642e051240329d16f959aae4",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('overflow', 'SECWORD', ''), ('maliciously', 'SECWORD', ''), ('409670234', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/grappler/costs/op_level_cost_estimator.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1386,
      "vuln_id": "GHSA-9hx2-hgq2-2g4f",
      "cwe_id": "{'CWE-400'}",
      "score": 6.5,
      "chain": "{'https://github.com/python-pillow/Pillow/commit/6207b44ab1ff4a91d8ddc7579619876d0bb191a4', 'https://github.com/python-pillow/Pillow/commit/3bce145966374dd39ce58a6fc0083f8d1890719c'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service (ReDoS) in Pillow An issue was discovered in Pillow before 8.1.1. The PDF parser allows a regular expression DoS (ReDoS) attack via a crafted PDF file because of a catastrophic backtracking regex.",
      "published_date": "2021-03-29",
      "chain_len": 2,
      "project": "https://github.com/python-pillow/Pillow",
      "commit_href": "https://github.com/python-pillow/Pillow/commit/3bce145966374dd39ce58a6fc0083f8d1890719c",
      "commit_sha": "3bce145966374dd39ce58a6fc0083f8d1890719c",
      "patch": "MULTI",
      "chain_ord": "['6207b44ab1ff4a91d8ddc7579619876d0bb191a4', '3bce145966374dd39ce58a6fc0083f8d1890719c']",
      "before_first_fix_commit": "{'cbdce6c5d054fccaf4af34b47f212355c64ace7a'}",
      "last_fix_commit": "3bce145966374dd39ce58a6fc0083f8d1890719c",
      "chain_ord_pos": 2.0,
      "commit_datetime": "01/09/2021, 13:53:09",
      "message": "Use more specific regex chars to prevent ReDoS\n\n* CVE-2021-25292",
      "author": "Hugo van Kemenade",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 1, 'total': 3}",
      "files": "{'src/PIL/PdfParser.py': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/python-pillow/Pillow/raw/3bce145966374dd39ce58a6fc0083f8d1890719c/src%2FPIL%2FPdfParser.py', 'patch': '@@ -580,8 +580,9 @@ def next_object_id(self, offset=None):\\n     whitespace_or_hex = br\"[\\\\000\\\\011\\\\012\\\\014\\\\015\\\\0400-9a-fA-F]\"\\n     whitespace_optional = whitespace + b\"*\"\\n     whitespace_mandatory = whitespace + b\"+\"\\n+    whitespace_optional_no_nl = br\"[\\\\000\\\\011\\\\014\\\\015\\\\040]*\"  # no \"\\\\012\" aka \"\\\\n\"\\n     newline_only = br\"[\\\\r\\\\n]+\"\\n-    newline = whitespace_optional + newline_only + whitespace_optional\\n+    newline = whitespace_optional_no_nl + newline_only + whitespace_optional_no_nl\\n     re_trailer_end = re.compile(\\n         whitespace_mandatory\\n         + br\"trailer\"'}}",
      "message_norm": "use more specific regex chars to prevent redos\n\n* cve-2021-25292",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('redos', 'SECWORD', ''), ('cve-2021-25292', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/PIL/PdfParser.py'])",
      "num_files": 1.0
    },
    {
      "index": 2758,
      "vuln_id": "GHSA-qhh5-9738-g9mx",
      "cwe_id": "{'CWE-276'}",
      "score": 6.5,
      "chain": "{'https://github.com/apache/incubator-dolphinscheduler/commit/b8a9e2e00f2f207ae60c913a7173b59405ff95f1'}",
      "dataset": "osv",
      "summary": "Incorrect Default Permissions in Apache DolphinScheduler Versions of Apache DolphinScheduler prior to 1.3.2 allowed an ordinary user under any tenant to override another users password through the API interface.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/apache/incubator-dolphinscheduler",
      "commit_href": "https://github.com/apache/incubator-dolphinscheduler/commit/b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
      "commit_sha": "b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
      "patch": "SINGLE",
      "chain_ord": "['b8a9e2e00f2f207ae60c913a7173b59405ff95f1']",
      "before_first_fix_commit": "{'0505ebf45d93fc1518386804ceffa6b36595f9c5'}",
      "last_fix_commit": "b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/18/2020, 06:07:47",
      "message": "modify general user can't create,delete,update token (#3538)\n\nCo-authored-by: qiaozhanwei <qiaozhanwei@analysys.com.cn>",
      "author": "qiaozhanwei",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 8, 'total': 15}",
      "files": "{'dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/AccessTokenService.java': {'additions': 7, 'deletions': 8, 'changes': 15, 'status': 'modified', 'raw_url': 'https://github.com/apache/dolphinscheduler/raw/b8a9e2e00f2f207ae60c913a7173b59405ff95f1/dolphinscheduler-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fdolphinscheduler%2Fapi%2Fservice%2FAccessTokenService.java', 'patch': '@@ -84,7 +84,9 @@ public Map<String, Object> queryAccessTokenList(User loginUser, String searchVal\\n      */\\n     public Map<String, Object> createToken(User loginUser, int userId, String expireTime, String token) {\\n         Map<String, Object> result = new HashMap<>(5);\\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n+\\n+        if (!hasPerm(loginUser,userId)){\\n+            putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n \\n@@ -140,10 +142,6 @@ public Map<String, Object> generateToken(User loginUser, int userId, String expi\\n     public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n         Map<String, Object> result = new HashMap<>(5);\\n \\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n-            return result;\\n-        }\\n-\\n         AccessToken accessToken = accessTokenMapper.selectById(id);\\n \\n         if (accessToken == null) {\\n@@ -152,8 +150,7 @@ public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n             return result;\\n         }\\n \\n-        if (loginUser.getId() != accessToken.getUserId() &&\\n-                loginUser.getUserType() != UserType.ADMIN_USER) {\\n+        if (!hasPerm(loginUser,accessToken.getUserId())){\\n             putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n@@ -176,9 +173,11 @@ public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n     public Map<String, Object> updateToken(User loginUser, int id, int userId, String expireTime, String token) {\\n         Map<String, Object> result = new HashMap<>(5);\\n \\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n+        if (!hasPerm(loginUser,userId)){\\n+            putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n+\\n         AccessToken accessToken = accessTokenMapper.selectById(id);\\n         if (accessToken == null) {\\n             logger.error(\"access token not exist,  access token id {}\", id);'}}",
      "message_norm": "modify general user can't create,delete,update token (#3538)\n\nco-authored-by: qiaozhanwei <qiaozhanwei@analysys.com.cn>",
      "language": "en",
      "entities": "[('update', 'ACTION', ''), ('#3538', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/AccessTokenService.java'])",
      "num_files": 1.0
    },
    {
      "index": 2881,
      "vuln_id": "GHSA-r6cm-wg48-rh2r",
      "cwe_id": "{'CWE-359', 'CWE-863'}",
      "score": 9.1,
      "chain": "{'https://github.com/alextselegidis/easyappointments/commit/44af526a6fc5e898bc1e0132b2af9eb3a9b2c466'}",
      "dataset": "osv",
      "summary": "Exposure of Private Personal Information to an Unauthorized Actor in alextselegidis/easyappointments The software is a booking management system that has a public form to place bookings, and a private area for the calendar and management of services, users, settings, etc. There is a backend API that allows data manipulation, including listing the appointments for a specific time range. This happens on this endpoint: /index.php/backend_api/ajax_get_calendar_events Unfortunately, there is no authentication / permissions-check on that endpoint, the only required parameters in a POST request are \"startDate\", \"endDate\" and \"csrfToken\". Because the csrfToken can be obtained by any unauthenticated user just visiting the public form (and is valid for the backend as well), any attacker can query the backend API and obtain all sorts of private information about the appointment, in JSON format.",
      "published_date": "2022-03-10",
      "chain_len": 1,
      "project": "https://github.com/alextselegidis/easyappointments",
      "commit_href": "https://github.com/alextselegidis/easyappointments/commit/44af526a6fc5e898bc1e0132b2af9eb3a9b2c466",
      "commit_sha": "44af526a6fc5e898bc1e0132b2af9eb3a9b2c466",
      "patch": "SINGLE",
      "chain_ord": "['44af526a6fc5e898bc1e0132b2af9eb3a9b2c466']",
      "before_first_fix_commit": "{'13e81c80b17dfe207b2bdddb395a1345217f2548'}",
      "last_fix_commit": "44af526a6fc5e898bc1e0132b2af9eb3a9b2c466",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/08/2022, 17:27:15",
      "message": "Release v1.4.3",
      "author": "Alex Tselegidis",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'application/config/config.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/alextselegidis/easyappointments/raw/44af526a6fc5e898bc1e0132b2af9eb3a9b2c466/application%2Fconfig%2Fconfig.php', 'patch': \"@@ -8,7 +8,7 @@\\n | Declare some of the global config values of Easy!Appointments.\\n |\\n */\\n-$config['version'] = '1.4.3-beta.1'; // This must be changed manually.\\n+$config['version'] = '1.4.3'; // This must be changed manually.\\n $config['release_label'] = ''; // Leave empty for no title or add Alpha, Beta etc ...\\n $config['debug'] = Config::DEBUG_MODE;\\n \\n@@ -314,7 +314,7 @@\\n | new release.\\n |\\n */\\n-$config['cache_busting_token'] = '8UC842';\\n+$config['cache_busting_token'] = '6398SW';\\n \\n /*\\n |--------------------------------------------------------------------------\"}}",
      "message_norm": "release v1.4.3",
      "language": "sl",
      "entities": "[('v1.4.3', 'VERSION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['application/config/config.php'])",
      "num_files": 1.0
    },
    {
      "index": 3144,
      "vuln_id": "GHSA-vmhh-xh3g-j992",
      "cwe_id": "{'CWE-80', 'CWE-79', 'CWE-116'}",
      "score": 7.4,
      "chain": "{'https://github.com/xwiki/xwiki-platform/commit/bd935320bee3c27cf7548351b1d0f935f116d437'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in the Flamingo theme manager ### Impact\nWe found a possible XSS vector in the `FlamingoThemesCode.WebHomeSheet` wiki page related to the \"newThemeName\" form field.\n\n### Patches\n\nThe issue is patched in versions 12.10.11, 14.0-rc-1, 13.4.7, 13.10.3.\n\n### Workarounds\nThe easiest workaround is to edit the wiki page `FlamingoThemesCode.WebHomeSheet` (with wiki editor) and change the line\n\n```\n<input type=\"hidden\" name=\"newThemeName\" id=\"newThemeName\" value=\"$request.newThemeName\" />\n```\n\ninto\n\n```\n<input type=\"hidden\" name=\"newThemeName\" id=\"newThemeName\" value=\"$escapetool.xml($request.newThemeName)\" />\n```\n\n### References\n  * https://jira.xwiki.org/browse/XWIKI-19294\n  * https://github.com/xwiki/xwiki-platform/commit/bd935320bee3c27cf7548351b1d0f935f116d437\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Jira XWiki](https://jira.xwiki.org)\n* Email us at [security mailing list](mailto:security@xwiki.org)",
      "published_date": "2022-05-25",
      "chain_len": 1,
      "project": "https://github.com/xwiki/xwiki-platform",
      "commit_href": "https://github.com/xwiki/xwiki-platform/commit/bd935320bee3c27cf7548351b1d0f935f116d437",
      "commit_sha": "bd935320bee3c27cf7548351b1d0f935f116d437",
      "patch": "SINGLE",
      "chain_ord": "['bd935320bee3c27cf7548351b1d0f935f116d437']",
      "before_first_fix_commit": "{'21906acb5ee2304552f56f9bbdbf8e7d368f7f3a'}",
      "last_fix_commit": "bd935320bee3c27cf7548351b1d0f935f116d437",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/04/2022, 10:34:49",
      "message": "XWIKI-19294: Fix bad escaping",
      "author": "Thomas Mortagne",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'xwiki-platform-core/xwiki-platform-flamingo/xwiki-platform-flamingo-theme/xwiki-platform-flamingo-theme-ui/src/main/resources/FlamingoThemesCode/WebHomeSheet.xml': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/xwiki/xwiki-platform/raw/bd935320bee3c27cf7548351b1d0f935f116d437/xwiki-platform-core%2Fxwiki-platform-flamingo%2Fxwiki-platform-flamingo-theme%2Fxwiki-platform-flamingo-theme-ui%2Fsrc%2Fmain%2Fresources%2FFlamingoThemesCode%2FWebHomeSheet.xml', 'patch': '@@ -287,7 +287,7 @@\\n       &lt;form action=\"$doc.getURL()\" method=\"post\"&gt;\\n         &lt;input type=\"hidden\" name=\"form_token\" value=\"$services.csrf.token\" /&gt;\\n         &lt;input type=\"hidden\" name=\"action\" value=\"create\"/&gt;\\n-        &lt;input type=\"hidden\" name=\"newThemeName\" id=\"newThemeName\" value=\"$request.newThemeName\" /&gt;\\n+        &lt;input type=\"hidden\" name=\"newThemeName\" id=\"newThemeName\" value=\"$escapetool.xml($request.newThemeName)\" /&gt;\\n         &lt;input type=\"submit\" value=\"$services.localization.render(\\'platform.flamingo.themes.home.create.confirm\\')\" class=\"button\"/&gt;\\n       &lt;/form&gt;\\n     {{/html}}'}}",
      "message_norm": "xwiki-19294: fix bad escaping",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('escaping', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['xwiki-platform-core/xwiki-platform-flamingo/xwiki-platform-flamingo-theme/xwiki-platform-flamingo-theme-ui/src/main/resources/FlamingoThemesCode/WebHomeSheet.xml'])",
      "num_files": 1.0
    },
    {
      "index": 244,
      "vuln_id": "GHSA-3f99-hvg4-qjwj",
      "cwe_id": "{'CWE-335'}",
      "score": 8.7,
      "chain": "{'https://github.com/juliangruber/keypair/commit/9596418d3363d3e757676c0b6a8f2d35a9d1cb18'}",
      "dataset": "osv",
      "summary": "Insecure random number generation in keypair ## Description and Impact\n\nA bug in the pseudo-random number generator used by [keypair](https://github.com/juliangruber/keypair) versions up to and including 1.0.3 could allow for weak RSA key generation. This could enable an attacker to decrypt confidential messages or gain authorized access to an account belonging to the victim. We recommend replacing any RSA keys that were generated using keypair version 1.0.3 or earlier.\n\n## Fix\n\n* The [bug](https://github.com/juliangruber/keypair/blob/87c62f255baa12c1ec4f98a91600f82af80be6db/index.js#L1008) in the pseudo-random number generator is fixed in commit [`9596418`](https://github.com/juliangruber/keypair/commit/9596418d3363d3e757676c0b6a8f2d35a9d1cb18).\n* If the crypto module is available, it is used instead of the pseudo-random number generator. Also fixed in [`9596418`](https://github.com/juliangruber/keypair/commit/9596418d3363d3e757676c0b6a8f2d35a9d1cb18)\n\n## Additional Details\n\nThe specific [line](https://github.com/juliangruber/keypair/blob/87c62f255baa12c1ec4f98a91600f82af80be6db/index.js#L1008) with the flaw is:\n\n```javascript\nb.putByte(String.fromCharCode(next & 0xFF))\n```\n\nThe [definition](https://github.com/juliangruber/keypair/blob/87c62f255baa12c1ec4f98a91600f82af80be6db/index.js#L350-L352) of `putByte` is \n\n```javascript\nutil.ByteBuffer.prototype.putByte = function(b) {\n  this.data += String.fromCharCode(b);\n};\n```\n\nSimplified, this is `String.fromCharCode(String.fromCharCode(next & 0xFF))`. This results in most of the buffer containing zeros. An example generated buffer:\n\n(Note: truncated for brevity)\n\n```\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00....\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n```\n\nSince it is masking with 0xFF, approximately 97% of the bytes are converted to zeros. The impact is that each byte in the RNG seed has a 97% chance of being 0 due to incorrect conversion.\n\n## Credit\n\nThis issue was reported to GitHub Security Lab by Ross Wheeler of Axosoft. It was discovered by Axosoft engineer Dan Suceava, who noticed that [keypair](https://github.com/juliangruber/keypair) was regularly generating duplicate RSA keys. GitHub security engineer [@vcsjones (Kevin Jones)](https://github.com/vcsjones) independently investigated the problem and identified the cause and source code location of the bug.",
      "published_date": "2021-10-11",
      "chain_len": 1,
      "project": "https://github.com/juliangruber/keypair",
      "commit_href": "https://github.com/juliangruber/keypair/commit/9596418d3363d3e757676c0b6a8f2d35a9d1cb18",
      "commit_sha": "9596418d3363d3e757676c0b6a8f2d35a9d1cb18",
      "patch": "SINGLE",
      "chain_ord": "['9596418d3363d3e757676c0b6a8f2d35a9d1cb18']",
      "before_first_fix_commit": "{'87c62f255baa12c1ec4f98a91600f82af80be6db'}",
      "last_fix_commit": "9596418d3363d3e757676c0b6a8f2d35a9d1cb18",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/11/2021, 17:01:56",
      "message": "Merge pull request from GHSA-3f99-hvg4-qjwj\n\n* fix double String.fromCharCode\n\n* use crypto module if available\n\nCo-authored-by: Julian Gruber <julian@juliangruber.com>",
      "author": "Kevin Backhouse",
      "comments": "{'com_1': {'author': 'ChALkeR', 'datetime': '10/12/2021, 16:44:04', 'body': \"How is this a fix?\\r\\n\\r\\nThis looks like it still falls back to xorshift128+ for the purpose of ssh keys generation?\\r\\n\\r\\nThat... doesn't look like a good idea perhaps.\\r\\n\\r\\nWhy is `Math.random` based code even present there?\\r\\n\\r\\nThe environments where there is no way to generate the key in a secure way should fail, and not fall back to a predictable pseudo-random generator.\\r\\n\\r\\n_Note: not considering this confidential, as this is all over Twitter now afaik._\"}, 'com_2': {'author': 'juliangruber', 'datetime': '10/13/2021, 08:21:54', 'body': \"I'm not a security researcher myself so I'm preferring to relay judgement of this issue to those who are, which has happened in this advisory.\\r\\n\\r\\nAt this point I'm not going to perform any major changes to this library myself. If you want to contribute, would you consider making a docs PR with your concerns, adding a disclaimer to the README?\"}, 'com_3': {'author': 'normanr', 'datetime': '10/13/2021, 16:04:03', 'body': 'Thank you for responding promptly to the security researchers and taking the time to merge this security fix. A good example of how to handle security related bug reports.'}}",
      "stats": "{'additions': 6, 'deletions': 2, 'total': 8}",
      "files": "{'index.js': {'additions': 6, 'deletions': 2, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/juliangruber/keypair/raw/9596418d3363d3e757676c0b6a8f2d35a9d1cb18/index.js', 'patch': \"@@ -756,7 +756,11 @@ util.createBuffer = function(input, encoding) {\\n  */\\n \\n var prng = forge.prng = {};\\n-var crypto = null;\\n+\\n+var crypto;\\n+try {\\n+  crypto = require('crypto');\\n+} catch (_) {}\\n \\n prng.create = function(plugin) {\\n   var ctx = {\\n@@ -1005,7 +1009,7 @@ prng.create = function(plugin) {\\n           // throw in more pseudo random\\n           next = seed >>> (i << 3);\\n           next ^= Math.floor(Math.random() * 0xFF);\\n-          b.putByte(String.fromCharCode(next & 0xFF));\\n+          b.putByte(next & 0xFF);\\n         }\\n       }\\n     }\"}}",
      "message_norm": "merge pull request from ghsa-3f99-hvg4-qjwj\n\n* fix double string.fromcharcode\n\n* use crypto module if available\n\nco-authored-by: julian gruber <julian@juliangruber.com>",
      "language": "en",
      "entities": "[('ghsa-3f99-hvg4-qjwj', 'VULNID', 'GHSA'), ('fix', 'ACTION', ''), ('crypto', 'SECWORD', ''), ('julian@juliangruber.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 616,
      "vuln_id": "GHSA-5f2r-qp73-37mr",
      "cwe_id": "{'CWE-617'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/92dba16749fae36c246bec3f9ba474d9ddeb7662'}",
      "dataset": "osv",
      "summary": "`CHECK`-failures during Grappler's `SafeToRemoveIdentity` in Tensorflow ### Impact\nThe Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that [`SafeToRemoveIdentity`](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/grappler/optimizers/dependency_optimizer.cc#L59-L98) would trigger `CHECK` failures.\n\n### Patches\nWe have patched the issue in GitHub commit [92dba16749fae36c246bec3f9ba474d9ddeb7662](https://github.com/tensorflow/tensorflow/commit/92dba16749fae36c246bec3f9ba474d9ddeb7662).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-10",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/92dba16749fae36c246bec3f9ba474d9ddeb7662",
      "commit_sha": "92dba16749fae36c246bec3f9ba474d9ddeb7662",
      "patch": "SINGLE",
      "chain_ord": "['92dba16749fae36c246bec3f9ba474d9ddeb7662']",
      "before_first_fix_commit": "{'1cda4d4a26acea3814d06e7d9525772ab357fc1c'}",
      "last_fix_commit": "92dba16749fae36c246bec3f9ba474d9ddeb7662",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/11/2021, 18:43:29",
      "message": "Prevent a null-pointer dereference / `CHECK`-fail in grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 2, 'total': 6}",
      "files": "{'tensorflow/core/grappler/optimizers/dependency_optimizer.cc': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/92dba16749fae36c246bec3f9ba474d9ddeb7662/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdependency_optimizer.cc', 'patch': '@@ -75,8 +75,10 @@ bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\\n   }\\n \\n   const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\\n-  CHECK(input != nullptr) << \"node = \" << node.name()\\n-                          << \" input = \" << node.input(0);\\n+  if (input == nullptr) {\\n+    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\\n+    return false;\\n+  }\\n   // Don\\'t remove Identity nodes corresponding to Variable reads or following\\n   // Recv.\\n   if (IsVariable(*input) || IsRecv(*input)) {'}}",
      "message_norm": "prevent a null-pointer dereference / `check`-fail in grappler.\n\npiperorigin-revid: 409187354\nchange-id: i369c249cca32e6c56ec193f0ebbf2f2768fc7d43",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('null-pointer dereference', 'SECWORD', ''), ('409187354', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/grappler/optimizers/dependency_optimizer.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3386,
      "vuln_id": "GHSA-x6rc-54xp-ccxx",
      "cwe_id": "{'CWE-611'}",
      "score": 9.8,
      "chain": "{'https://github.com/apache/activemq-artemis/commit/48d9951d879e0c8cbb59d4b64ab59d53ef88310d'}",
      "dataset": "osv",
      "summary": "Improper Restriction of XML External Entity Reference in Apache ActiveMQ XML external entity (XXE) vulnerability in the XPath selector component in Artemis ActiveMQ before commit 48d9951d879e0c8cbb59d4b64ab59d53ef88310d allows remote attackers to have unspecified impact via unknown vectors.",
      "published_date": "2022-05-14",
      "chain_len": 1,
      "project": "https://github.com/apache/activemq-artemis",
      "commit_href": "https://github.com/apache/activemq-artemis/commit/48d9951d879e0c8cbb59d4b64ab59d53ef88310d",
      "commit_sha": "48d9951d879e0c8cbb59d4b64ab59d53ef88310d",
      "patch": "SINGLE",
      "chain_ord": "['48d9951d879e0c8cbb59d4b64ab59d53ef88310d']",
      "before_first_fix_commit": "{'879f4a6bb3b15dfc3d00bcde2d982194bd2dadc4'}",
      "last_fix_commit": "48d9951d879e0c8cbb59d4b64ab59d53ef88310d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/21/2015, 09:49:45",
      "message": "ActiveMQ6-112 Add defaults to the selector parser doc builder",
      "author": "Martyn Taylor",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 4, 'total': 18}",
      "files": "{'artemis-selector/src/main/java/org/apache/activemq/artemis/selector/filter/XalanXPathEvaluator.java': {'additions': 14, 'deletions': 4, 'changes': 18, 'status': 'modified', 'raw_url': 'https://github.com/apache/activemq-artemis/raw/48d9951d879e0c8cbb59d4b64ab59d53ef88310d/artemis-selector%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Factivemq%2Fartemis%2Fselector%2Ffilter%2FXalanXPathEvaluator.java', 'patch': '@@ -18,6 +18,7 @@\\n \\n import javax.xml.parsers.DocumentBuilder;\\n import javax.xml.parsers.DocumentBuilderFactory;\\n+import javax.xml.parsers.ParserConfigurationException;\\n import java.io.StringReader;\\n \\n import org.apache.xpath.CachedXPathAPI;\\n@@ -56,9 +57,7 @@ protected boolean evaluate(InputSource inputSource)\\n    {\\n       try\\n       {\\n-         DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\\n-         factory.setNamespaceAware(true);\\n-         DocumentBuilder dbuilder = factory.newDocumentBuilder();\\n+         DocumentBuilder dbuilder = createDocumentBuilder();\\n          Document doc = dbuilder.parse(inputSource);\\n \\n          //An XPath expression could return a true or false value instead of a node.\\n@@ -75,11 +74,22 @@ protected boolean evaluate(InputSource inputSource)\\n             NodeIterator iterator = cachedXPathAPI.selectNodeIterator(doc, xpath);\\n             return (iterator.nextNode() != null);\\n          }\\n-\\n       }\\n       catch (Throwable e)\\n       {\\n          return false;\\n       }\\n    }\\n+\\n+   private DocumentBuilder createDocumentBuilder() throws ParserConfigurationException\\n+   {\\n+      DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\\n+      factory.setNamespaceAware(true);\\n+\\n+      factory.setFeature(\"http://xml.org/sax/features/external-general-entities\", false);\\n+      factory.setFeature(\"http://xml.org/sax/features/external-parameter-entities\", false);\\n+      factory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\\n+\\n+      return factory.newDocumentBuilder();\\n+   }\\n }'}}",
      "message_norm": "activemq6-112 add defaults to the selector parser doc builder",
      "language": "en",
      "entities": "[('add', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['artemis-selector/src/main/java/org/apache/activemq/artemis/selector/filter/XalanXPathEvaluator.java'])",
      "num_files": 1.0
    },
    {
      "index": 2551,
      "vuln_id": "GHSA-pc5p-h8pf-mvwp",
      "cwe_id": "{'CWE-300'}",
      "score": 6.1,
      "chain": "{'https://github.com/TooTallNate/node-https-proxy-agent/commit/36d8cf509f877fa44f4404fce57ebaf9410fe51b'}",
      "dataset": "osv",
      "summary": "Machine-In-The-Middle in https-proxy-agent Versions of `https-proxy-agent` prior to 2.2.3 are vulnerable to Machine-In-The-Middle. The package fails to enforce TLS on the socket if the proxy server responds the to the request with a HTTP status different than 200. This allows an attacker with access to the proxy server to intercept unencrypted communications, which may include sensitive information such as credentials.\n\n\n## Recommendation\n\nUpgrade to version 3.0.0 or 2.2.3.",
      "published_date": "2020-04-16",
      "chain_len": 1,
      "project": "https://github.com/TooTallNate/node-https-proxy-agent",
      "commit_href": "https://github.com/TooTallNate/node-https-proxy-agent/commit/36d8cf509f877fa44f4404fce57ebaf9410fe51b",
      "commit_sha": "36d8cf509f877fa44f4404fce57ebaf9410fe51b",
      "patch": "SINGLE",
      "chain_ord": "['36d8cf509f877fa44f4404fce57ebaf9410fe51b']",
      "before_first_fix_commit": "{'5252bb9355ad12802d7e0846e5e7cf4ced54fc63'}",
      "last_fix_commit": "36d8cf509f877fa44f4404fce57ebaf9410fe51b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/07/2019, 19:53:24",
      "message": "Use an `EventEmitter` to replay failed proxy connect HTTP requests (#77)\n\n* Use an `EventEmitter` to replay failed proxy connect HTTP requests\r\n\r\nThis is a fix for https://hackerone.com/reports/541502.\r\n\r\nAborts the upstream proxy connection and instead uses a vanilla\r\n`EventEmitter` instance to replay the \"data\" events on to. This way,\r\nthe node core `http` Client doesn't attempt to write the HTTP request\r\nthat is intended to go to the destination server to the proxy server.\r\n\r\nCloses #76.\r\n\r\n* Adjust comment",
      "author": "Nathan Rajlich",
      "comments": "{'com_1': {'author': 'jaimeborjas', 'datetime': '04/17/2020, 01:17:19', 'body': 'Security fixes'}, 'com_2': {'author': 'donurukiran', 'datetime': '04/17/2020, 13:18:32', 'body': 'done with few security issues'}}",
      "stats": "{'additions': 15, 'deletions': 3, 'total': 18}",
      "files": "{'index.js': {'additions': 15, 'deletions': 3, 'changes': 18, 'status': 'modified', 'raw_url': 'https://github.com/TooTallNate/node-https-proxy-agent/raw/36d8cf509f877fa44f4404fce57ebaf9410fe51b/index.js', 'patch': '@@ -5,6 +5,7 @@\\n var net = require(\\'net\\');\\n var tls = require(\\'tls\\');\\n var url = require(\\'url\\');\\n+var events = require(\\'events\\');\\n var Agent = require(\\'agent-base\\');\\n var inherits = require(\\'util\\').inherits;\\n var debug = require(\\'debug\\')(\\'https-proxy-agent\\');\\n@@ -154,20 +155,32 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\\n       fn(null, sock);\\n     } else {\\n       // some other status code that\\'s not 200... need to re-play the HTTP header\\n-      // \"data\" events onto the socket once the HTTP machinery is attached so that\\n-      // the user can parse and handle the error status code\\n+      // \"data\" events onto the socket once the HTTP machinery is attached so\\n+      // that the node core `http` can parse and handle the error status code\\n       cleanup();\\n \\n+      // the original socket is closed, and a \"fake socket\" EventEmitter is\\n+      // returned instead, so that the proxy doesn\\'t get the HTTP request\\n+      // written to it (which may contain `Authorization` headers or other\\n+      // sensitive data).\\n+      //\\n+      // See: https://hackerone.com/reports/541502\\n+      socket.destroy();\\n+      socket = new events.EventEmitter();\\n+\\n       // save a reference to the concat\\'d Buffer for the `onsocket` callback\\n       buffers = buffered;\\n \\n       // need to wait for the \"socket\" event to re-play the \"data\" events\\n       req.once(\\'socket\\', onsocket);\\n+\\n       fn(null, socket);\\n     }\\n   }\\n \\n   function onsocket(socket) {\\n+    debug(\\'replaying proxy buffer for failed request\\');\\n+\\n     // replay the \"buffers\" Buffer onto the `socket`, since at this point\\n     // the HTTP module machinery has been hooked up for the user\\n     if (socket.listenerCount(\\'data\\') > 0) {\\n@@ -177,7 +190,6 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\\n       throw new Error(\\'should not happen...\\');\\n     }\\n \\n-    socket.resume();\\n     // nullify the cached Buffer instance\\n     buffers = null;\\n   }'}}",
      "message_norm": "use an `eventemitter` to replay failed proxy connect http requests (#77)\n\n* use an `eventemitter` to replay failed proxy connect http requests\r\n\r\nthis is a fix for https://hackerone.com/reports/541502.\r\n\r\naborts the upstream proxy connection and instead uses a vanilla\r\n`eventemitter` instance to replay the \"data\" events on to. this way,\r\nthe node core `http` client doesn't attempt to write the http request\r\nthat is intended to go to the destination server to the proxy server.\r\n\r\ncloses #76.\r\n\r\n* adjust comment",
      "language": "en",
      "entities": "[('#77', 'ISSUE', ''), ('https://hackerone.com/reports/541502', 'URL', ''), ('server', 'SECWORD', ''), ('server', 'SECWORD', ''), ('#76', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1261,
      "vuln_id": "GHSA-8v7h-cpc2-r8jp",
      "cwe_id": "{'CWE-362'}",
      "score": 8.1,
      "chain": "{'https://github.com/octobercms/library/commit/fe569f3babf3f593be2b1e0a4ae0283506127a83'}",
      "dataset": "osv",
      "summary": "October CMS upload process vulnerable to RCE via Race Condition ### Impact\n\nThis advisory affects plugins that expose the `October\\Rain\\Database\\Attach\\File::fromData` as a public interface. This vulnerability does not affect vanilla installations of October CMS since this method is not exposed or used by the system internally or externally.\n\nWhen the developer allows the user to specify their own filename in the `fromData` method, an unauthenticated user can perform remote code execution (RCE) by exploiting a race condition in the temporary storage directory.\n\n### Patches\n\nThe issue has been patched in Build 476 (v1.0.476) and v1.1.12 and v2.2.15.\n\n### Workarounds\n\nApply https://github.com/octobercms/library/commit/fe569f3babf3f593be2b1e0a4ae0283506127a83 to your installation manually if unable to upgrade to Build 476 (v1.0.476) or v1.1.12 or v2.2.15.\n\n### References\n\nCredits to:\n- DucNT, HungTD and GiangVQ from RedTeam@VNG Security Response Center.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n- Email us at [hello@octobercms.com](mailto:hello@octobercms.com)",
      "published_date": "2022-07-13",
      "chain_len": 1,
      "project": "https://github.com/octobercms/library",
      "commit_href": "https://github.com/octobercms/library/commit/fe569f3babf3f593be2b1e0a4ae0283506127a83",
      "commit_sha": "fe569f3babf3f593be2b1e0a4ae0283506127a83",
      "patch": "SINGLE",
      "chain_ord": "['fe569f3babf3f593be2b1e0a4ae0283506127a83']",
      "before_first_fix_commit": "{'95ce496038c104571362c92418783b81889a8b9d'}",
      "last_fix_commit": "fe569f3babf3f593be2b1e0a4ae0283506127a83",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/29/2022, 01:51:19",
      "message": "Refactor",
      "author": "Sam Georges",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 4, 'total': 9}",
      "files": "{'src/Database/Attach/File.php': {'additions': 5, 'deletions': 4, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/octobercms/library/raw/fe569f3babf3f593be2b1e0a4ae0283506127a83/src%2FDatabase%2FAttach%2FFile.php', 'patch': \"@@ -124,14 +124,14 @@ public function fromPost($uploadedFile)\\n     /**\\n      * fromFile creates a file object from a file on the disk\\n      */\\n-    public function fromFile($filePath)\\n+    public function fromFile($filePath, $filename = null)\\n     {\\n         if ($filePath === null) {\\n             return;\\n         }\\n \\n         $file = new FileObj($filePath);\\n-        $this->file_name = $file->getFilename();\\n+        $this->file_name = empty($filename) ? $file->getFilename() : $filename;\\n         $this->file_size = $file->getSize();\\n         $this->content_type = $file->getMimeType();\\n         $this->disk_name = $this->getDiskName();\\n@@ -152,10 +152,11 @@ public function fromData($data, $filename)\\n             return;\\n         }\\n \\n-        $tempPath = temp_path(basename($filename));\\n+        $tempName = str_replace('.', '', uniqid('', true)) . '.tmp';\\n+        $tempPath = temp_path($tempName);\\n         FileHelper::put($tempPath, $data);\\n \\n-        $file = $this->fromFile($tempPath);\\n+        $file = $this->fromFile($tempPath, basename($filename));\\n         FileHelper::delete($tempPath);\\n \\n         return $file;\"}}",
      "message_norm": "refactor",
      "language": "ro",
      "entities": null,
      "classification_level_1": "POORLY_DOCUMENTED",
      "classification_level_2": "SINGLE_WORD",
      "list_files": "dict_keys(['src/Database/Attach/File.php'])",
      "num_files": 1.0
    },
    {
      "index": 593,
      "vuln_id": "GHSA-58v3-j75h-xr49",
      "cwe_id": "{'CWE-284'}",
      "score": 4.8,
      "chain": "{'https://github.com/seccomp/libseccomp-golang/commit/06e7a29f36a34b8cf419aeb87b979ee508e58f9e'}",
      "dataset": "osv",
      "summary": "Improper Input Validation in libseccomp-golang libseccomp-golang 0.9.0 and earlier incorrectly generates BPFs that OR multiple arguments rather than ANDing them. A process running under a restrictive seccomp filter that specified multiple syscall arguments could bypass intended access restrictions by specifying a single matching argument.",
      "published_date": "2021-05-18",
      "chain_len": 1,
      "project": "https://github.com/seccomp/libseccomp-golang",
      "commit_href": "https://github.com/seccomp/libseccomp-golang/commit/06e7a29f36a34b8cf419aeb87b979ee508e58f9e",
      "commit_sha": "06e7a29f36a34b8cf419aeb87b979ee508e58f9e",
      "patch": "SINGLE",
      "chain_ord": "['06e7a29f36a34b8cf419aeb87b979ee508e58f9e']",
      "before_first_fix_commit": "{'fc0298087f328ac97a1fa781392de96b2ebb8aac'}",
      "last_fix_commit": "06e7a29f36a34b8cf419aeb87b979ee508e58f9e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/19/2017, 20:28:29",
      "message": "golang: Resolve bug with handling of multiple argument rules\n\nIn the upstream library, when added with a single API call,\nmultiple syscall argument rules should be matched with AND\nlogic - if all of them match, the rule matches.\n\nAt present, the Golang bindings apply OR logic to this case.\nThis commit resolves this and reverts to the behavior of the\nmain library.\n\nSigned-off-by: Matthew Heon <matthew.heon@gmail.com>",
      "author": "Matthew Heon",
      "comments": null,
      "stats": "{'additions': 37, 'deletions': 27, 'total': 64}",
      "files": "{'seccomp_internal.go': {'additions': 37, 'deletions': 27, 'changes': 64, 'status': 'modified', 'raw_url': 'https://github.com/seccomp/libseccomp-golang/raw/06e7a29f36a34b8cf419aeb87b979ee508e58f9e/seccomp_internal.go', 'patch': '@@ -120,23 +120,27 @@ unsigned int get_micro_version()\\n \\n typedef struct scmp_arg_cmp* scmp_cast_t;\\n \\n-// Wrapper to create an scmp_arg_cmp struct\\n-void*\\n-make_struct_arg_cmp(\\n-                    unsigned int arg,\\n-                    int compare,\\n-                    uint64_t a,\\n-                    uint64_t b\\n-                   )\\n+void* make_arg_cmp_array(unsigned int length)\\n {\\n-\\tstruct scmp_arg_cmp *s = malloc(sizeof(struct scmp_arg_cmp));\\n+        return calloc(length, sizeof(struct scmp_arg_cmp));\\n+}\\n \\n-\\ts->arg = arg;\\n-\\ts->op = compare;\\n-\\ts->datum_a = a;\\n-\\ts->datum_b = b;\\n+// Wrapper to add an scmp_arg_cmp struct to an existing arg_cmp array\\n+void add_struct_arg_cmp(\\n+                        struct scmp_arg_cmp* arr,\\n+                        unsigned int pos,\\n+                        unsigned int arg,\\n+                        int compare,\\n+                        uint64_t a,\\n+                        uint64_t b\\n+                       )\\n+{\\n+        arr[pos].arg = arg;\\n+        arr[pos].op = compare;\\n+        arr[pos].datum_a = a;\\n+        arr[pos].datum_b = b;\\n \\n-\\treturn s;\\n+        return;\\n }\\n */\\n import \"C\"\\n@@ -239,12 +243,9 @@ func (f *ScmpFilter) setFilterAttr(attr scmpFilterAttr, value C.uint32_t) error\\n // DOES NOT LOCK OR CHECK VALIDITY\\n // Assumes caller has already done this\\n // Wrapper for seccomp_rule_add_... functions\\n-func (f *ScmpFilter) addRuleWrapper(call ScmpSyscall, action ScmpAction, exact bool, cond C.scmp_cast_t) error {\\n-\\tvar length C.uint\\n-\\tif cond != nil {\\n-\\t\\tlength = 1\\n-\\t} else {\\n-\\t\\tlength = 0\\n+func (f *ScmpFilter) addRuleWrapper(call ScmpSyscall, action ScmpAction, exact bool, length C.uint, cond C.scmp_cast_t) error {\\n+\\tif length != 0 && cond == nil {\\n+\\t\\treturn fmt.Errorf(\"null conditions list, but length is nonzero\")\\n \\t}\\n \\n \\tvar retCode C.int\\n@@ -258,6 +259,8 @@ func (f *ScmpFilter) addRuleWrapper(call ScmpSyscall, action ScmpAction, exact b\\n \\t\\treturn fmt.Errorf(\"unrecognized syscall\")\\n \\t} else if syscall.Errno(-1*retCode) == syscall.EPERM {\\n \\t\\treturn fmt.Errorf(\"requested action matches default action of filter\")\\n+\\t} else if syscall.Errno(-1*retCode) == syscall.EINVAL {\\n+\\t\\treturn fmt.Errorf(\"two checks on same syscall argument\")\\n \\t} else if retCode != 0 {\\n \\t\\treturn syscall.Errno(-1 * retCode)\\n \\t}\\n@@ -275,7 +278,7 @@ func (f *ScmpFilter) addRuleGeneric(call ScmpSyscall, action ScmpAction, exact b\\n \\t}\\n \\n \\tif len(conds) == 0 {\\n-\\t\\tif err := f.addRuleWrapper(call, action, exact, nil); err != nil {\\n+\\t\\tif err := f.addRuleWrapper(call, action, exact, 0, nil); err != nil {\\n \\t\\t\\treturn err\\n \\t\\t}\\n \\t} else {\\n@@ -287,13 +290,20 @@ func (f *ScmpFilter) addRuleGeneric(call ScmpSyscall, action ScmpAction, exact b\\n \\t\\t\\t}\\n \\t\\t}\\n \\n-\\t\\tfor _, cond := range conds {\\n-\\t\\t\\tcmpStruct := C.make_struct_arg_cmp(C.uint(cond.Argument), cond.Op.toNative(), C.uint64_t(cond.Operand1), C.uint64_t(cond.Operand2))\\n-\\t\\t\\tdefer C.free(cmpStruct)\\n+\\t\\targsArr := C.make_arg_cmp_array(C.uint(len(conds)))\\n+\\t\\tif argsArr == nil {\\n+\\t\\t\\treturn fmt.Errorf(\"error allocating memory for conditions\")\\n+\\t\\t}\\n+\\t\\tdefer C.free(argsArr)\\n+\\n+\\t\\tfor i, cond := range conds {\\n+\\t\\t\\tC.add_struct_arg_cmp(C.scmp_cast_t(argsArr), C.uint(i),\\n+\\t\\t\\t\\tC.uint(cond.Argument), cond.Op.toNative(),\\n+\\t\\t\\t\\tC.uint64_t(cond.Operand1), C.uint64_t(cond.Operand2))\\n+\\t\\t}\\n \\n-\\t\\t\\tif err := f.addRuleWrapper(call, action, exact, C.scmp_cast_t(cmpStruct)); err != nil {\\n-\\t\\t\\t\\treturn err\\n-\\t\\t\\t}\\n+\\t\\tif err := f.addRuleWrapper(call, action, exact, C.uint(len(conds)), C.scmp_cast_t(argsArr)); err != nil {\\n+\\t\\t\\treturn err\\n \\t\\t}\\n \\t}'}}",
      "message_norm": "golang: resolve bug with handling of multiple argument rules\n\nin the upstream library, when added with a single api call,\nmultiple syscall argument rules should be matched with and\nlogic - if all of them match, the rule matches.\n\nat present, the golang bindings apply or logic to this case.\nthis commit resolves this and reverts to the behavior of the\nmain library.\n\nsigned-off-by: matthew heon <matthew.heon@gmail.com>",
      "language": "en",
      "entities": "[('bug', 'FLAW', ''), ('added', 'ACTION', ''), ('matthew.heon@gmail.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['seccomp_internal.go'])",
      "num_files": 1.0
    },
    {
      "index": 684,
      "vuln_id": "GHSA-5r2v-6gm6-vpvh",
      "cwe_id": "{'CWE-200'}",
      "score": 9.8,
      "chain": "{'https://github.com/gogs/gogs/commit/c3af3ff1d0484de3bd789ee6c6e47f35d590e945'}",
      "dataset": "osv",
      "summary": "Insecure Permissions in Gogs routes/api/v1/api.go in Gogs 0.11.86 lacks permission checks for routes: deploy keys, collaborators, and hooks.",
      "published_date": "2021-05-18",
      "chain_len": 1,
      "project": "https://github.com/gogs/gogs",
      "commit_href": "https://github.com/gogs/gogs/commit/c3af3ff1d0484de3bd789ee6c6e47f35d590e945",
      "commit_sha": "c3af3ff1d0484de3bd789ee6c6e47f35d590e945",
      "patch": "SINGLE",
      "chain_ord": "['c3af3ff1d0484de3bd789ee6c6e47f35d590e945']",
      "before_first_fix_commit": "{'1592e578ed3ac7190baed6165b093002b931520c'}",
      "last_fix_commit": "c3af3ff1d0484de3bd789ee6c6e47f35d590e945",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/02/2019, 01:36:05",
      "message": "routes/api: fix permission checks for routes\n\nReported by @ManassehZhou #5764",
      "author": "unknwon",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 5, 'total': 19}",
      "files": "{'routes/api/v1/api.go': {'additions': 14, 'deletions': 5, 'changes': 19, 'status': 'modified', 'raw_url': 'https://github.com/gogs/gogs/raw/c3af3ff1d0484de3bd789ee6c6e47f35d590e945/routes%2Fapi%2Fv1%2Fapi.go', 'patch': '@@ -112,6 +112,15 @@ func reqRepoWriter() macaron.Handler {\\n \\t}\\n }\\n \\n+func reqRepoAdmin() macaron.Handler {\\n+\\treturn func(c *context.Context) {\\n+\\t\\tif !c.Repo.IsAdmin() {\\n+\\t\\t\\tc.Error(http.StatusForbidden)\\n+\\t\\t\\treturn\\n+\\t\\t}\\n+\\t}\\n+}\\n+\\n func orgAssignment(args ...bool) macaron.Handler {\\n \\tvar (\\n \\t\\tassignOrg  bool\\n@@ -236,12 +245,12 @@ func RegisterRoutes(m *macaron.Macaron) {\\n \\t\\t\\t\\t\\t\\tPost(bind(api.CreateHookOption{}), repo.CreateHook)\\n \\t\\t\\t\\t\\tm.Combo(\"/:id\").Patch(bind(api.EditHookOption{}), repo.EditHook).\\n \\t\\t\\t\\t\\t\\tDelete(repo.DeleteHook)\\n-\\t\\t\\t\\t}, reqAdmin())\\n+\\t\\t\\t\\t}, reqRepoAdmin())\\n \\t\\t\\t\\tm.Group(\"/collaborators\", func() {\\n \\t\\t\\t\\t\\tm.Get(\"\", repo.ListCollaborators)\\n \\t\\t\\t\\t\\tm.Combo(\"/:collaborator\").Get(repo.IsCollaborator).Put(bind(api.AddCollaboratorOption{}), repo.AddCollaborator).\\n \\t\\t\\t\\t\\t\\tDelete(repo.DeleteCollaborator)\\n-\\t\\t\\t\\t}, reqAdmin())\\n+\\t\\t\\t\\t}, reqRepoAdmin())\\n \\t\\t\\t\\tm.Get(\"/raw/*\", context.RepoRef(), repo.GetRawFile)\\n \\t\\t\\t\\tm.Get(\"/archive/*\", repo.GetArchive)\\n \\t\\t\\t\\tm.Get(\"/forks\", repo.ListForks)\\n@@ -260,7 +269,7 @@ func RegisterRoutes(m *macaron.Macaron) {\\n \\t\\t\\t\\t\\t\\tPost(bind(api.CreateKeyOption{}), repo.CreateDeployKey)\\n \\t\\t\\t\\t\\tm.Combo(\"/:id\").Get(repo.GetDeployKey).\\n \\t\\t\\t\\t\\t\\tDelete(repo.DeleteDeploykey)\\n-\\t\\t\\t\\t}, reqAdmin())\\n+\\t\\t\\t\\t}, reqRepoAdmin())\\n \\t\\t\\t\\tm.Group(\"/issues\", func() {\\n \\t\\t\\t\\t\\tm.Combo(\"\").Get(repo.ListIssues).Post(bind(api.CreateIssueOption{}), repo.CreateIssue)\\n \\t\\t\\t\\t\\tm.Group(\"/comments\", func() {\\n@@ -300,8 +309,8 @@ func RegisterRoutes(m *macaron.Macaron) {\\n \\t\\t\\t\\t\\t\\tDelete(reqRepoWriter(), repo.DeleteMilestone)\\n \\t\\t\\t\\t})\\n \\n-\\t\\t\\t\\tm.Patch(\"/issue-tracker\", bind(api.EditIssueTrackerOption{}), repo.IssueTracker)\\n-\\t\\t\\t\\tm.Post(\"/mirror-sync\", repo.MirrorSync)\\n+\\t\\t\\t\\tm.Patch(\"/issue-tracker\", reqRepoWriter(), bind(api.EditIssueTrackerOption{}), repo.IssueTracker)\\n+\\t\\t\\t\\tm.Post(\"/mirror-sync\", reqRepoWriter(), repo.MirrorSync)\\n \\t\\t\\t\\tm.Get(\"/editorconfig/:filename\", context.RepoRef(), repo.GetEditorconfig)\\n \\t\\t\\t}, repoAssignment())\\n \\t\\t}, reqToken())'}}",
      "message_norm": "routes/api: fix permission checks for routes\n\nreported by @manassehzhou #5764",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('permission', 'SECWORD', ''), ('#5764', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['routes/api/v1/api.go'])",
      "num_files": 1.0
    },
    {
      "index": 1327,
      "vuln_id": "GHSA-9697-98pf-4rw7",
      "cwe_id": "{'CWE-125'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/42459e4273c2e47a3232cc16c4f4fff3b3a35c38'}",
      "dataset": "osv",
      "summary": "Heap OOB in `UpperBound` and `LowerBound` ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.UpperBound`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.UpperBound(\n  sorted_input=[1,2,3],\n  values=tf.constant(value=[[0,0,0],[1,1,1],[2,2,2]],dtype=tf.int64),\n  out_type=tf.int64)\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/searchsorted_op.cc#L85-L104) does not validate the rank of `sorted_input` argument:\n\n```cc\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& sorted_inputs_t = ctx->input(0);\n    // ...\n    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                Status(error::INVALID_ARGUMENT,\n                       \"Leading dim_size of both tensors must match.\"));\n    // ...\n    if (output_t->dtype() == DT_INT32) {\n      OP_REQUIRES(ctx,\n                  FastBoundsCheck(sorted_inputs_t.dim_size(1), ...));\n      // ...\n    }\n```\n\nAs we access the first two dimensions of `sorted_inputs_t` tensor, it must have rank at least 2.\n\nA similar issue occurs in `tf.raw_ops.LowerBound`.\n\n### Patches\nWe have patched the issue in GitHub commit [42459e4273c2e47a3232cc16c4f4fff3b3a35c38](https://github.com/tensorflow/tensorflow/commit/42459e4273c2e47a3232cc16c4f4fff3b3a35c38).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "commit_sha": "42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "patch": "SINGLE",
      "chain_ord": "['42459e4273c2e47a3232cc16c4f4fff3b3a35c38']",
      "before_first_fix_commit": "{'b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58'}",
      "last_fix_commit": "42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/30/2021, 05:25:05",
      "message": "Prevent CHECK-fail/heap OOB in UpperBound and LowerBound\n\nPiperOrigin-RevId: 387738073\nChange-Id: Iee74de95ddad18440d052a75a5a1cb67544f490a",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 0, 'total': 8}",
      "files": "{'tensorflow/core/kernels/searchsorted_op.cc': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/42459e4273c2e47a3232cc16c4f4fff3b3a35c38/tensorflow%2Fcore%2Fkernels%2Fsearchsorted_op.cc', 'patch': '@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\\n     const Tensor& sorted_inputs_t = ctx->input(0);\\n     const Tensor& values_t = ctx->input(1);\\n \\n+    // inputs must be at least a matrix\\n+    OP_REQUIRES(\\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\\n     // must have same batch dim_size for both\\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\\n                 Status(error::INVALID_ARGUMENT,\\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\\n     const Tensor& sorted_inputs_t = ctx->input(0);\\n     const Tensor& values_t = ctx->input(1);\\n \\n+    // inputs must be at least a matrix\\n+    OP_REQUIRES(\\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\\n     // must have same batch dim_size for both\\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\\n                 Status(error::INVALID_ARGUMENT,'}}",
      "message_norm": "prevent check-fail/heap oob in upperbound and lowerbound\n\npiperorigin-revid: 387738073\nchange-id: iee74de95ddad18440d052a75a5a1cb67544f490a",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('387738073', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/searchsorted_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 385,
      "vuln_id": "GHSA-48mj-p7x2-5jfm",
      "cwe_id": "{'CWE-306'}",
      "score": 7.5,
      "chain": "{'https://github.com/esphome/esphome/pull/2409/commits/207cde1667d8c799a197b78ca8a5a14de8d5ca1e', 'https://github.com/esphome/esphome/commit/be965a60eba6bb769e2a5afdbc8eed132f077a59'}",
      "dataset": "osv",
      "summary": "Basic auth bypass in esphome ### Impact\n\nAnyone with web_server enabled and HTTP basic auth configured on 2021.9.1 or older\n\n`web_server` allows OTA update without checking user defined basic auth username & password\n\n### Patches\n\nPatch released in 2021.9.2\n\n### Workarounds\n\nDisable/remove `web_server`",
      "published_date": "2021-09-29",
      "chain_len": 2,
      "project": "https://github.com/esphome/esphome",
      "commit_href": "https://github.com/esphome/esphome/pull/2409/commits/207cde1667d8c799a197b78ca8a5a14de8d5ca1e",
      "commit_sha": "207cde1667d8c799a197b78ca8a5a14de8d5ca1e",
      "patch": "MULTI",
      "chain_ord": "['be965a60eba6bb769e2a5afdbc8eed132f077a59', '207cde1667d8c799a197b78ca8a5a14de8d5ca1e']",
      "before_first_fix_commit": "{'be965a60eba6bb769e2a5afdbc8eed132f077a59'}",
      "last_fix_commit": "207cde1667d8c799a197b78ca8a5a14de8d5ca1e",
      "chain_ord_pos": 2.0,
      "commit_datetime": "09/28/2021, 01:02:04",
      "message": "Fix lint issues in web_server_base",
      "author": "Jesse Hills",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 2, 'total': 5}",
      "files": "{'esphome/components/web_server_base/web_server_base.h': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/esphome/esphome/raw/207cde1667d8c799a197b78ca8a5a14de8d5ca1e/esphome%2Fcomponents%2Fweb_server_base%2Fweb_server_base.h', 'patch': '@@ -3,6 +3,7 @@\\n #ifdef USE_ARDUINO\\n \\n #include <memory>\\n+#include <utility>\\n #include \"esphome/core/component.h\"\\n \\n #include <ESPAsyncWebServer.h>\\n@@ -96,8 +97,8 @@ class WebServerBase : public Component {\\n   std::shared_ptr<AsyncWebServer> get_server() const { return server_; }\\n   float get_setup_priority() const override;\\n \\n-  void set_auth_username(std::string auth_username) { credentials_.username = auth_username; }\\n-  void set_auth_password(std::string auth_password) { credentials_.password = auth_password; }\\n+  void set_auth_username(std::string auth_username) { credentials_.username = std::move(auth_username); }\\n+  void set_auth_password(std::string auth_password) { credentials_.password = std::move(auth_password); }\\n \\n   void add_handler(AsyncWebHandler *handler);'}}",
      "message_norm": "fix lint issues in web_server_base",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('issues', 'FLAW', ''), ('web_server_base', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['esphome/components/web_server_base/web_server_base.h'])",
      "num_files": 1.0
    },
    {
      "index": 2431,
      "vuln_id": "GHSA-mj63-64x7-57xf",
      "cwe_id": "{'CWE-22'}",
      "score": 9.8,
      "chain": "{'https://github.com/SecureAuthCorp/impacket/commit/49c643bf66620646884ed141c94e5fdd85bcdd2f', 'https://github.com/SecureAuthCorp/impacket/commit/99bd29e3995c254e2d6f6c2e3454e4271665955a'}",
      "dataset": "osv",
      "summary": "Path traversal in impacket Multiple path traversal vulnerabilities exist in smbserver.py in Impacket before 0.9.23. An attacker that connects to a running smbserver instance can list and write to arbitrary files via ../ directory traversal. This could potentially be abused to achieve arbitrary code execution by replacing /etc/shadow or an SSH authorized key.",
      "published_date": "2021-06-18",
      "chain_len": 2,
      "project": "https://github.com/SecureAuthCorp/impacket",
      "commit_href": "https://github.com/SecureAuthCorp/impacket/commit/49c643bf66620646884ed141c94e5fdd85bcdd2f",
      "commit_sha": "49c643bf66620646884ed141c94e5fdd85bcdd2f",
      "patch": "MULTI",
      "chain_ord": "['99bd29e3995c254e2d6f6c2e3454e4271665955a', '49c643bf66620646884ed141c94e5fdd85bcdd2f']",
      "before_first_fix_commit": "{'6688da5d97592269aae72b3a00dc1ab186c0b33d', '91902eafb68fea932cf2350cab329f15afa554e5'}",
      "last_fix_commit": "49c643bf66620646884ed141c94e5fdd85bcdd2f",
      "chain_ord_pos": 2.0,
      "commit_datetime": "05/03/2021, 15:43:02",
      "message": "Merge pull request #1066 from omriinbar/master\n\nFix Path Traversal vulnerabilities by checking path prefix against in\u2026",
      "author": "0xdeaddood",
      "comments": null,
      "stats": "{'additions': 2012, 'deletions': 1937, 'total': 3949}",
      "files": "{'impacket/smbserver.py': {'additions': 2012, 'deletions': 1937, 'changes': 3949, 'status': 'modified', 'raw_url': 'https://github.com/SecureAuthCorp/impacket/raw/49c643bf66620646884ed141c94e5fdd85bcdd2f/impacket%2Fsmbserver.py', 'patch': None}}",
      "message_norm": "merge pull request #1066 from omriinbar/master\n\nfix path traversal vulnerabilities by checking path prefix against in\u2026",
      "language": "en",
      "entities": "[('#1066', 'ISSUE', ''), ('path traversal', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['impacket/smbserver.py'])",
      "num_files": 1.0
    },
    {
      "index": 3010,
      "vuln_id": "GHSA-rv62-4pmj-xw6h",
      "cwe_id": "{'CWE-601'}",
      "score": 6.1,
      "chain": "{'https://github.com/jupyter/notebook/commit/08c4c898182edbe97aadef1815cce50448f975cb', 'https://github.com/jupyter/notebook/commit/70fe9f0ddb3023162ece21fbb77d5564306b913b', 'https://github.com/jupyter/notebook/commit/d65328d4841892b412aef9015165db1eb029a8ed'}",
      "dataset": "osv",
      "summary": "Moderate severity vulnerability that affects jupyterhub and notebook An Open Redirect vulnerability for all browsers in Jupyter Notebook before 5.7.8 and some browsers (Chrome, Firefox) in JupyterHub before 0.9.6 allows crafted links to the login page, which will redirect to a malicious site after successful login. Servers running on a base_url prefix are not affected.",
      "published_date": "2019-04-02",
      "chain_len": 3,
      "project": "https://github.com/jupyter/notebook",
      "commit_href": "https://github.com/jupyter/notebook/commit/08c4c898182edbe97aadef1815cce50448f975cb",
      "commit_sha": "08c4c898182edbe97aadef1815cce50448f975cb",
      "patch": "MULTI",
      "chain_ord": "['70fe9f0ddb3023162ece21fbb77d5564306b913b', 'd65328d4841892b412aef9015165db1eb029a8ed', '08c4c898182edbe97aadef1815cce50448f975cb']",
      "before_first_fix_commit": "{'d65328d4841892b412aef9015165db1eb029a8ed'}",
      "last_fix_commit": "08c4c898182edbe97aadef1815cce50448f975cb",
      "chain_ord_pos": 3.0,
      "commit_datetime": "03/27/2019, 20:43:40",
      "message": "protect against chrome mishandling backslash as slash in URLs",
      "author": "Min RK",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'notebook/auth/login.py': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/jupyter/notebook/raw/08c4c898182edbe97aadef1815cce50448f975cb/notebook%2Fauth%2Flogin.py', 'patch': '@@ -39,6 +39,10 @@ def _redirect_safe(self, url, default=None):\\n         \"\"\"\\n         if default is None:\\n             default = self.base_url\\n+        # protect chrome users from mishandling unescaped backslashes.\\n+        # \\\\ is not valid in urls, but some browsers treat it as /\\n+        # instead of %5C, causing `\\\\\\\\` to behave as `//`\\n+        url = url.replace(\"\\\\\\\\\", \"%5C\")\\n         parsed = urlparse(url)\\n         if parsed.netloc or not (parsed.path + \\'/\\').startswith(self.base_url):\\n             # require that next_url be absolute path within our path'}}",
      "message_norm": "protect against chrome mishandling backslash as slash in urls",
      "language": "en",
      "entities": "[('protect', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['notebook/auth/login.py'])",
      "num_files": 1.0
    },
    {
      "index": 1305,
      "vuln_id": "GHSA-93q8-gq69-wqmw",
      "cwe_id": "{'CWE-697', 'CWE-1333'}",
      "score": 7.5,
      "chain": "{'https://github.com/chalk/ansi-regex/commit/8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9'}",
      "dataset": "osv",
      "summary": "Inefficient Regular Expression Complexity in chalk/ansi-regex ansi-regex is vulnerable to Inefficient Regular Expression Complexity which could lead to a denial of service.",
      "published_date": "2021-09-20",
      "chain_len": 1,
      "project": "https://github.com/chalk/ansi-regex",
      "commit_href": "https://github.com/chalk/ansi-regex/commit/8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9",
      "commit_sha": "8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9",
      "patch": "SINGLE",
      "chain_ord": "['8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9']",
      "before_first_fix_commit": "{'c1b5e45f7c65a332ffb03ac8e5804ad37c579cdc'}",
      "last_fix_commit": "8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/10/2021, 20:23:24",
      "message": "Fix potential ReDoS (#37)",
      "author": "Yeting Li",
      "comments": "{'com_1': {'author': 'BeigeBox', 'datetime': '09/23/2021, 21:00:58', 'body': \"Which versions of ansi-regex are impacted by this vulnerability?  Several scanners are flagging all versions of this library other than 5.0.1 and 6.0.1.  I suspect some of the older versions aren't impacted, because the pattern variable is different (just spot checked I think v2.1.1 and v3).\"}, 'com_2': {'author': 'Qix-', 'datetime': '09/26/2021, 15:10:07', 'body': \"Not sure because the security researchers are not doing their due diligence and are instead farming bounty money on e.g. huntr.dev, targeting the most used repositories for clout.\\r\\n\\r\\nI'm really not sure what to do about this and it's eating a lot of time away. The vulnerability itself is not major - unless you're allowing long AND unsanitized user input to hit the API directly, the vulnerability doesn't affect you.\\r\\n\\r\\nI have no idea which versions it actually affects because they didn't test it correctly.\"}, 'com_3': {'author': 'thoger', 'datetime': '09/27/2021, 18:07:58', 'body': \"Confirmed 4.1.0 and 3.0.0 as affected testing using the provided reproducer.  2.1.1 does not reproduce the issue.\\r\\n\\r\\n3.0.0 is the first affected, as that's the first version that includes 69bebf6b8 that the problematic part of the regex.\"}, 'com_4': {'author': 'Qix-', 'datetime': '09/27/2021, 18:22:35', 'body': 'Thank you @thoger. \ud83d\ude42'}, 'com_5': {'author': 'arungpro', 'datetime': '10/12/2021, 11:28:32', 'body': '@thoger Does 5.0.0 or above, are not affected this? Can you confirm on the same?'}, 'com_6': {'author': 'Qix-', 'datetime': '10/12/2021, 11:51:24', 'body': '@arungpro `5.0.0` is affected, `5.0.1` is not. Likewise, `6.0.0` is affected, `6.0.1` is not.'}, 'com_7': {'author': 'OnlineCop', 'datetime': '01/10/2022, 17:01:46', 'body': 'Would someone be able to help me understand the exact formatting going on here?\\r\\n\\r\\nI assume that the `\\\\` backslashes are escaped because this is within a string, meaning `\\\\u001B` must be represented as `\\\\\\\\u001B` ?\\r\\n\\r\\nI copied the \"proposed\" escaped original into [regex101](https://regex101.com/r/UR7Ma5/1) and removed the escape characters to produce this:\\r\\n\\r\\n```[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]*)*)?\\\\u0007)```\\r\\n\\r\\nI then plugged that unescaped version [back in](https://regex101.com/r/UR7Ma5/2) to determine whether there were any problems with the pattern itself, and see that there is an incomplete/unclosed `(?:` which should probably be removed:\\r\\n\\r\\n```[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]*)*)?\\\\u0007```\\r\\n\\r\\nThe next outer `(?: ... )` group appears to have no alternations or quantifiers, so can probably also be removed:\\r\\n\\r\\n```(?:(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]*)*)?\\\\u0007)```\\r\\n\\r\\nThe next `(?: ... | ... )?` group does contain an alternation, and is qualified by its `?` quantifier. Immediately after this optional group, it looks for `\\\\u0007` at the end.\\r\\n\\r\\nWithin both alternations, the character groups `[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]` can be shortened: `[a-zA-Z0-9_]` or `[a-zA-Z\\\\d_]` can be replaced with `\\\\w`, so: `[-\\\\w\\\\/#&.:=?%@~]`.\\r\\n\\r\\nThat would look like this:\\r\\n\\r\\n```[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:;[-\\\\w\\\\/#&.:=?%@~]+)*|[a-zA-Z\\\\d]+(?:;[-\\\\w\\\\/#&.:=?%@~]*)*)?\\\\u0007```\\r\\n\\r\\nSo, within the first alternation, it matches a semicolon `;` followed by **one** or more of those character-group characters. Within the second alternation, it first looks for letters or numbers, followed by any number of semicolon `;` followed by **zero** or more of those character-group characters. I\\'m not sure whether that would want to be a `+` one-or-more, since that would allow \"abc;;;;;;;;;\" to match there instead of requiring characters between those semicolons.\\r\\n\\r\\nIf you look at [this example](https://regex101.com/r/UR7Ma5/3), I\\'ve changed the outer non-capturing `(?: ... )?` to a capturing group just for illustrative purposes so you can see how the semicolon is matched in one case but not in the other due to this **zero** or more quantifiers. You can see this when the semicolon is added to the text in [this next example](https://regex101.com/r/UR7Ma5/4).\\r\\n\\r\\nIf both `;[-\\\\w\\\\/#&.:=?%@~]` character groups are quantified with zero-or-more `*`, then subsequent semicolons `;;` will match, while if they are quantified with one-or-more `+`, the match fails due to subsequent semicolons `;;`.'}, 'com_8': {'author': 'lorand-horvath', 'datetime': '04/02/2022, 07:47:22', 'body': 'ansi-regex v3 and v4 should now include the vulnerability fixes:\\r\\n`3.0.1` in https://github.com/chalk/ansi-regex/commit/419250fa510bf31b4cc672e76537a64f9332e1f1 and https://github.com/chalk/ansi-regex/commit/c57d4c2fdbe0357a0f6dd42d1160defdc9fffdf5\\r\\n`4.1.1` in https://github.com/chalk/ansi-regex/commit/75a657da7af875b2e2724fd6331bf0a4b23d3c9a'}, 'com_9': {'author': 'romans-ovo', 'datetime': '07/13/2022, 15:36:46', 'body': '> ansi-regex v3 and v4 should now include the vulnerability fixes: `3.0.1` in [419250f](https://github.com/chalk/ansi-regex/commit/419250fa510bf31b4cc672e76537a64f9332e1f1) and [c57d4c2](https://github.com/chalk/ansi-regex/commit/c57d4c2fdbe0357a0f6dd42d1160defdc9fffdf5) `4.1.1` in [75a657d](https://github.com/chalk/ansi-regex/commit/75a657da7af875b2e2724fd6331bf0a4b23d3c9a)\\r\\n\\r\\nNeither 3.0.1, nor 4.1.1 are listed on https://www.npmjs.com/package/ansi-regex (under Versions), btw.'}, 'com_10': {'author': 'Qix-', 'datetime': '07/13/2022, 15:42:41', 'body': '<img width=\"614\" alt=\"image\" src=\"https://user-images.githubusercontent.com/885648/178775021-919b8738-8879-4edc-8507-a6b2475c5631.png\">\\r\\nYou sure?'}, 'com_11': {'author': 'papb', 'datetime': '08/01/2022, 02:05:09', 'body': \"> Would someone be able to help me understand the exact formatting going on here?\\r\\n\\r\\n@OnlineCop can you first help me understand what exactly is your question here? Are you trying to understand what the code is doing? Are you proposing a readability improvement? Or performance improvement? Sorry, you said a lot of things but I couldn't even understand what is your goal, roughly...\\r\\n\\r\\n> I assume that the `\\\\` backslashes are escaped because this is within a string, meaning `\\\\u001B` must be represented as `\\\\\\\\u001B` ?\\r\\n\\r\\nYes, exactly.\"}, 'com_12': {'author': 'OnlineCop', 'datetime': '08/01/2022, 14:23:36', 'body': \"In the original, lines 2-5 were looking for:\\r\\n1. either `\\\\u001B` (ESC) or `\\\\u009B` (\u00a2 cent sign) followed by 0 or more of these characters: `[]()#;?`\\r\\n\\r\\nAfter that, it was looking for either:\\r\\n2. any number of letters, numbers, semi-colons, or special characters that came before `\\\\u0007` (BEL)\\r\\n    - There were a _lot_ of 0-or-more groups, all of which was also within its own `(?:...)?` 0-or-1 (optional) group, before that BEL.\\r\\n    - It was definitely something that could cause ReDoS.\\r\\n3. or an optional group of digits and semi-colons, followed by a single character in the range `[\\\\dA-PR-TZcf-ntqry=><~]`.\\r\\n    - This optional group also had potential for a ReDoS.\\r\\n\\r\\nIn the revised version, lines 2-5 were looking for the same characters as 1. above, but increased the variety of characters allowed before `\\\\u0007` and still has a lot of potential for ReDoS (possibly more than before).\\r\\n\\r\\nI don't understand what exactly is supposed to be matched here. Both BEFORE and AFTER versions have a high probability to cause catastrophic backtracking. Are there any tests that should match either of the BEFORE or AFTER regexes?\"}, 'com_13': {'author': 'Qix-', 'datetime': '08/02/2022, 22:47:38', 'body': \"Feel free to create a reproduction case that exploits exponential time complexity and file an issue. Otherwise I'm not sure what you're trying to say.\"}}",
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/chalk/ansi-regex/raw/8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9/index.js', 'patch': \"@@ -1,6 +1,6 @@\\n export default function ansiRegex({onlyFirst = false} = {}) {\\n \\tconst pattern = [\\n-\\t\\t'[\\\\\\\\u001B\\\\\\\\u009B][[\\\\\\\\]()#;?]*(?:(?:(?:[a-zA-Z\\\\\\\\d]*(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\/#&.:=?%@~_]*)*)?\\\\\\\\u0007)',\\n+\\t    '[\\\\\\\\u001B\\\\\\\\u009B][[\\\\\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\\\\\d]+(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\/#&.:=?%@~_]*)*)?\\\\\\\\u0007)',\\n \\t\\t'(?:(?:\\\\\\\\d{1,4}(?:;\\\\\\\\d{0,4})*)?[\\\\\\\\dA-PR-TZcf-ntqry=><~]))'\\n \\t].join('|');\"}}",
      "message_norm": "fix potential redos (#37)",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('#37', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1688,
      "vuln_id": "GHSA-f7r3-p866-q9qr",
      "cwe_id": "{'CWE-400'}",
      "score": 3.7,
      "chain": "{'https://github.com/Twipped/ircdkit/pull/2/commits/595ed02cde517fad57854d2ac2855a09a626e665', 'https://github.com/Twipped/ircdkit/commit/f0cc6dc913ec17b499fa33a676bb72c624456f2c'}",
      "dataset": "osv",
      "summary": "ircdkit vulnerable to Denial of Service due to unhandled connection end event Versions of `ircdkit` 1.0.3 and prior are vulnerable to a remote denial of service.\n\n\n## Recommendation\n\nUpgrade to version 1.0.4.",
      "published_date": "2019-06-03",
      "chain_len": 2,
      "project": "https://github.com/Twipped/ircdkit",
      "commit_href": "https://github.com/Twipped/ircdkit/commit/f0cc6dc913ec17b499fa33a676bb72c624456f2c",
      "commit_sha": "f0cc6dc913ec17b499fa33a676bb72c624456f2c",
      "patch": "MULTI",
      "chain_ord": "['f0cc6dc913ec17b499fa33a676bb72c624456f2c', '595ed02cde517fad57854d2ac2855a09a626e665']",
      "before_first_fix_commit": "{'74aa751e75a90af34ef63377fcbd41285d155380'}",
      "last_fix_commit": "595ed02cde517fad57854d2ac2855a09a626e665",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/30/2019, 03:09:45",
      "message": "DOS fix\n\ncorrected unhandled connection 'end' event, fixes issue #1",
      "author": "Trinity Fox",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'lib/index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/Twipped/ircdkit/raw/f0cc6dc913ec17b499fa33a676bb72c624456f2c/lib%2Findex.js', 'patch': \"@@ -47,7 +47,7 @@ function create (options) {\\n \\n \\t\\tclient.on('end', function () {\\n \\t\\t\\tdebug('connection ended');\\n-\\t\\t\\tremoveClient(client);\\n+\\t\\t\\tclient.close();\\n \\t\\t\\tapp.emit('connection:end', client);\\n \\t\\t});\"}}",
      "message_norm": "dos fix\n\ncorrected unhandled connection 'end' event, fixes issue #1",
      "language": "en",
      "entities": "[('dos', 'SECWORD', ''), ('fix', 'ACTION', ''), ('#1', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/index.js'])",
      "num_files": 1.0
    },
    {
      "index": 3479,
      "vuln_id": "GHSA-xqj7-j8j5-f2xr",
      "cwe_id": "{'CWE-327'}",
      "score": 7.5,
      "chain": "{'https://github.com/bcgit/bc-java/commit/73780ac522b7795fc165630aba8d5f5729acc839', 'https://github.com/bcgit/bc-java/commit/22467b6e8fe19717ecdf201c0cf91bacf04a55ad'}",
      "dataset": "osv",
      "summary": "Bouncy Castle has a flaw in the Low-level interface to RSA key pair generator Bouncy Castle BC 1.54 - 1.59, BC-FJA 1.0.0, BC-FJA 1.0.1 and earlier have a flaw in the Low-level interface to RSA key pair generator, specifically RSA Key Pairs generated in low-level API with added certainty may have less M-R tests than expected. This appears to be fixed in versions BC 1.60 beta 4 and later, BC-FJA 1.0.2 and later.",
      "published_date": "2018-10-16",
      "chain_len": 2,
      "project": "https://github.com/bcgit/bc-java",
      "commit_href": "https://github.com/bcgit/bc-java/commit/73780ac522b7795fc165630aba8d5f5729acc839",
      "commit_sha": "73780ac522b7795fc165630aba8d5f5729acc839",
      "patch": "MULTI",
      "chain_ord": "['73780ac522b7795fc165630aba8d5f5729acc839', '22467b6e8fe19717ecdf201c0cf91bacf04a55ad']",
      "before_first_fix_commit": "{'73780ac522b7795fc165630aba8d5f5729acc839'}",
      "last_fix_commit": "22467b6e8fe19717ecdf201c0cf91bacf04a55ad",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/19/2018, 08:40:01",
      "message": "BJA-694 cleaned up primality test",
      "author": "David Hook",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 4, 'total': 8}",
      "files": "{'core/src/main/java/org/bouncycastle/crypto/generators/RSAKeyPairGenerator.java': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/bcgit/bc-java/raw/73780ac522b7795fc165630aba8d5f5729acc839/core%2Fsrc%2Fmain%2Fjava%2Forg%2Fbouncycastle%2Fcrypto%2Fgenerators%2FRSAKeyPairGenerator.java', 'patch': '@@ -20,12 +20,10 @@\\n     private static final BigInteger ONE = BigInteger.valueOf(1);\\n \\n     private RSAKeyGenerationParameters param;\\n-    private int iterations;\\n \\n     public void init(KeyGenerationParameters param)\\n     {\\n         this.param = (RSAKeyGenerationParameters)param;\\n-        this.iterations = getNumberOfIterations(this.param.getStrength(), this.param.getCertainty());\\n     }\\n \\n     public AsymmetricCipherKeyPair generateKeyPair()\\n@@ -159,6 +157,8 @@ public AsymmetricCipherKeyPair generateKeyPair()\\n      */\\n     protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger sqrdBound)\\n     {\\n+        int iterations = getNumberOfIterations(bitlength, param.getCertainty());\\n+\\n         for (int i = 0; i != 5 * bitlength; i++)\\n         {\\n             BigInteger p = new BigInteger(bitlength, 1, param.getRandom());\\n@@ -173,7 +173,7 @@ protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger s\\n                 continue;\\n             }\\n \\n-            if (!isProbablePrime(p))\\n+            if (!isProbablePrime(p, iterations))\\n             {\\n                 continue;\\n             }\\n@@ -189,7 +189,7 @@ protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger s\\n         throw new IllegalStateException(\"unable to generate prime number for RSA key\");\\n     }\\n \\n-    protected boolean isProbablePrime(BigInteger x)\\n+    protected boolean isProbablePrime(BigInteger x, int iterations)\\n     {\\n         /*\\n          * Primes class for FIPS 186-4 C.3 primality checking'}}",
      "message_norm": "bja-694 cleaned up primality test",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['core/src/main/java/org/bouncycastle/crypto/generators/RSAKeyPairGenerator.java'])",
      "num_files": 1.0
    },
    {
      "index": 3203,
      "vuln_id": "GHSA-w2pm-r78h-4m7v",
      "cwe_id": "{'CWE-78'}",
      "score": 8.8,
      "chain": "{'https://github.com/laravel/framework/commit/44c3feb604944599ad1c782a9942981c3991fa31'}",
      "dataset": "osv",
      "summary": "OS Command Injection in Laravel Framework OS Command injection vulnerability in function link in Filesystem.php in Laravel Framework before 5.8.17.",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/laravel/framework",
      "commit_href": "https://github.com/laravel/framework/commit/44c3feb604944599ad1c782a9942981c3991fa31",
      "commit_sha": "44c3feb604944599ad1c782a9942981c3991fa31",
      "patch": "SINGLE",
      "chain_ord": "['44c3feb604944599ad1c782a9942981c3991fa31']",
      "before_first_fix_commit": "{'c7a3ca1c6df547a807807ffc782c13b92d44a1ad'}",
      "last_fix_commit": "44c3feb604944599ad1c782a9942981c3991fa31",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/14/2019, 15:58:33",
      "message": "use escapeshellarg on windows symlink",
      "author": "Taylor Otwell",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/Illuminate/Filesystem/Filesystem.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/laravel/framework/raw/44c3feb604944599ad1c782a9942981c3991fa31/src%2FIlluminate%2FFilesystem%2FFilesystem.php', 'patch': '@@ -254,7 +254,7 @@ public function link($target, $link)\\n \\n         $mode = $this->isDirectory($target) ? \\'J\\' : \\'H\\';\\n \\n-        exec(\"mklink /{$mode} \\\\\"{$link}\\\\\" \\\\\"{$target}\\\\\"\");\\n+        exec(\"mklink /{$mode} \".escapeshellarg($link).\" \".escapeshellarg($target));\\n     }\\n \\n     /**'}}",
      "message_norm": "use escapeshellarg on windows symlink",
      "language": "en",
      "entities": "[('escapeshellarg', 'SECWORD', ''), ('symlink', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Illuminate/Filesystem/Filesystem.php'])",
      "num_files": 1.0
    },
    {
      "index": 3135,
      "vuln_id": "GHSA-vjv6-gq77-3mjw",
      "cwe_id": "{'CWE-611'}",
      "score": 9.3,
      "chain": "{'https://github.com/mapfish/mapfish-print/pull/1397/commits/e1d0527d13db06b2b62ca7d6afb9e97dacd67a0e'}",
      "dataset": "osv",
      "summary": "XXE attack in Mapfish Print ### Impact\nA user can do to an XML External Entity (XXE) attack with the provided SDL style.\n\n### Patches\nUse version >= 3.24\n\n### Workarounds\nNo\n\n### References\n* https://cwe.mitre.org/data/definitions/611.html\n* https://github.com/mapfish/mapfish-print/pull/1397/commits/e1d0527d13db06b2b62ca7d6afb9e97dacd67a0e\n\n### For more information\nIf you have any questions or comments about this advisory Comment the pull request: https://github.com/mapfish/mapfish-print/pull/1397",
      "published_date": "2020-07-07",
      "chain_len": 1,
      "project": "https://github.com/mapfish/mapfish-print",
      "commit_href": "https://github.com/mapfish/mapfish-print/pull/1397/commits/e1d0527d13db06b2b62ca7d6afb9e97dacd67a0e",
      "commit_sha": "e1d0527d13db06b2b62ca7d6afb9e97dacd67a0e",
      "patch": "SINGLE",
      "chain_ord": "['e1d0527d13db06b2b62ca7d6afb9e97dacd67a0e']",
      "before_first_fix_commit": "{'4b59454140e1bd312c728d99d7de82714000c195'}",
      "last_fix_commit": "e1d0527d13db06b2b62ca7d6afb9e97dacd67a0e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/02/2020, 14:25:50",
      "message": "See: https://github.com/mapfish/mapfish-print/security/code-scanning/3?query=ref%3Arefs%2Fheads%2Fmaster",
      "author": "St\u00e9phane Brunner",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'core/src/main/java/org/mapfish/print/map/style/SLDParserPlugin.java': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/mapfish/mapfish-print/raw/e1d0527d13db06b2b62ca7d6afb9e97dacd67a0e/core%2Fsrc%2Fmain%2Fjava%2Forg%2Fmapfish%2Fprint%2Fmap%2Fstyle%2FSLDParserPlugin.java', 'patch': '@@ -94,6 +94,7 @@ private Optional<Style> tryLoadSLD(\\n             // by setting a custom error handler.\\n             DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();\\n             dbf.setNamespaceAware(true);\\n+            dbf.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", true);\\n             DocumentBuilder db = dbf.newDocumentBuilder();\\n             db.setErrorHandler(new ErrorHandler());\\n             db.parse(new ByteArrayInputStream(bytes));'}}",
      "message_norm": "see: https://github.com/mapfish/mapfish-print/security/code-scanning/3?query=ref%3arefs%2fheads%2fmaster",
      "language": "en",
      "entities": "[('https://github.com/mapfish/mapfish-print/security/code-scanning/3?query=ref%3arefs%2fheads%2fmaster', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['core/src/main/java/org/mapfish/print/map/style/SLDParserPlugin.java'])",
      "num_files": 1.0
    },
    {
      "index": 2740,
      "vuln_id": "GHSA-qf2g-q4mc-w7rr",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/forkcms/forkcms/commit/981730f1a3d59b423ca903b1f4bf79b848a1766e'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in Fork CMS Fork CMS prior to 5.11.1 is vulnerable to stored cross-site scripting. When uploading a new module, the description of the module can contain JavaScript code. The JavaScript code may be executed after uploading the new module and looking at the `Details` page.",
      "published_date": "2022-03-25",
      "chain_len": 1,
      "project": "https://github.com/forkcms/forkcms",
      "commit_href": "https://github.com/forkcms/forkcms/commit/981730f1a3d59b423ca903b1f4bf79b848a1766e",
      "commit_sha": "981730f1a3d59b423ca903b1f4bf79b848a1766e",
      "patch": "SINGLE",
      "chain_ord": "['981730f1a3d59b423ca903b1f4bf79b848a1766e']",
      "before_first_fix_commit": "{'1b38e33a98992793e998a937b717355212346993'}",
      "last_fix_commit": "981730f1a3d59b423ca903b1f4bf79b848a1766e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/23/2022, 13:20:39",
      "message": "Fix xss though the description in the info.xml file of a theme or module",
      "author": "Jelmer Prins",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'src/Backend/Modules/Extensions/Engine/Model.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/forkcms/forkcms/raw/981730f1a3d59b423ca903b1f4bf79b848a1766e/src%2FBackend%2FModules%2FExtensions%2FEngine%2FModel.php', 'patch': \"@@ -839,7 +839,7 @@ public static function processModuleXml(\\\\SimpleXMLElement $xml): array\\n         $information['name'] = (string) $module->name;\\n         $information['version'] = (string) $module->version;\\n         $information['requirements'] = (array) $module->requirements;\\n-        $information['description'] = (string) $module->description;\\n+        $information['description'] = strip_tags((string) $module->description, '<h1><h2><h3><h4><h5><h6><p><li><a>');\\n         $information['cronjobs'] = [];\\n \\n         // authors\\n@@ -900,7 +900,7 @@ public static function processThemeXml(\\\\SimpleXMLElement $xml): array\\n         $information['version'] = (string) $theme->version;\\n         $information['requirements'] = (array) $theme->requirements;\\n         $information['thumbnail'] = (string) $theme->thumbnail;\\n-        $information['description'] = (string) $theme->description;\\n+        $information['description'] = strip_tags((string) $theme->description, '<h1><h2><h3><h4><h5><h6><p><li><a>');\\n \\n         // authors\\n         foreach ($xml->xpath('/theme/authors/author') as $author) {\"}}",
      "message_norm": "fix xss though the description in the info.xml file of a theme or module",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('xss', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Backend/Modules/Extensions/Engine/Model.php'])",
      "num_files": 1.0
    },
    {
      "index": 3092,
      "vuln_id": "GHSA-vc5r-xfc4-4x22",
      "cwe_id": "{'CWE-79'}",
      "score": 4.8,
      "chain": "{'https://github.com/pimcore/data-hub/commit/15d5b57af2466eebd3bbc531ead5dafa35d0a36e'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in Pimcore Datahub Pimcore Datahub prior to 1.2.4 is vulnerable to stored cross-site scripting. An admin user accessing Datahub triggers the attack, which may result in the user's cookie being stolen.",
      "published_date": "2022-03-25",
      "chain_len": 1,
      "project": "https://github.com/pimcore/data-hub",
      "commit_href": "https://github.com/pimcore/data-hub/commit/15d5b57af2466eebd3bbc531ead5dafa35d0a36e",
      "commit_sha": "15d5b57af2466eebd3bbc531ead5dafa35d0a36e",
      "patch": "SINGLE",
      "chain_ord": "['15d5b57af2466eebd3bbc531ead5dafa35d0a36e']",
      "before_first_fix_commit": "{'1561fa5cda0d1a79139efbd2113e42a63d5602e4'}",
      "last_fix_commit": "15d5b57af2466eebd3bbc531ead5dafa35d0a36e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/16/2022, 13:24:41",
      "message": "follow up to https://github.com/pimcore/data-hub/pull/462",
      "author": "dpahuja",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/Controller/ConfigController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/pimcore/data-hub/raw/15d5b57af2466eebd3bbc531ead5dafa35d0a36e/src%2FController%2FConfigController.php', 'patch': \"@@ -50,7 +50,7 @@ private function buildItem($configuration): array\\n \\n         return [\\n             'id' => $name,\\n-            'text' => $name,\\n+            'text' => htmlspecialchars($name),\\n             'type' => 'config',\\n             'iconCls' => 'plugin_pimcore_datahub_icon_' . $type,\\n             'expandable' => false,\"}}",
      "message_norm": "follow up to https://github.com/pimcore/data-hub/pull/462",
      "language": "en",
      "entities": "[('https://github.com/pimcore/data-hub/pull/462', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Controller/ConfigController.php'])",
      "num_files": 1.0
    },
    {
      "index": 2119,
      "vuln_id": "GHSA-hrf4-hcpc-3345",
      "cwe_id": "{'CWE-190'}",
      "score": 7.1,
      "chain": "{'https://github.com/microweber/microweber/commit/f7acbd075dff4825b35b597b74958de9edce67fc'}",
      "dataset": "osv",
      "summary": "Denial of service in microweber Microweber is drag and drop website builder and CMS with E-commerce. The microweber prior 1.2.12 application allows large characters to insert in the input field \"post title\" which can allow attackers to cause a Denial of Service (DoS) via a crafted HTTP request. The post title input can be limited to 500 characters or max 1000 characters as a workaround.",
      "published_date": "2022-03-16",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/f7acbd075dff4825b35b597b74958de9edce67fc",
      "commit_sha": "f7acbd075dff4825b35b597b74958de9edce67fc",
      "patch": "SINGLE",
      "chain_ord": "['f7acbd075dff4825b35b597b74958de9edce67fc']",
      "before_first_fix_commit": "{'14e960d184e681507f5293be86446d18d1c125b5'}",
      "last_fix_commit": "f7acbd075dff4825b35b597b74958de9edce67fc",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2022, 15:00:22",
      "message": "Update PostRequest.php",
      "author": "Bozhidar Slaveykov",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 1, 'total': 9}",
      "files": "{'src/MicroweberPackages/Post/Http/Requests/PostRequest.php': {'additions': 8, 'deletions': 1, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/f7acbd075dff4825b35b597b74958de9edce67fc/src%2FMicroweberPackages%2FPost%2FHttp%2FRequests%2FPostRequest.php', 'patch': \"@@ -22,8 +22,15 @@ public function authorize()\\n      */\\n     public function rules()\\n     {\\n+        // todo with multilanguage\\n+\\n         $rules = [\\n-           // 'title' => 'required', // todo with multilanguage\\n+            'title' => 'required|max:500',\\n+            'url' => 'max:500',\\n+            'description' => 'max:500',\\n+            'content_meta_title' => 'max:500',\\n+            'content_meta_keywords' => 'max:500',\\n+            'original_link' => 'max:500',\\n         ];\\n \\n         return $rules;\"}}",
      "message_norm": "update postrequest.php",
      "language": "fr",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/Post/Http/Requests/PostRequest.php'])",
      "num_files": 1.0
    },
    {
      "index": 3074,
      "vuln_id": "GHSA-v82p-hv3v-p6qp",
      "cwe_id": "{'CWE-20'}",
      "score": 7.8,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9', 'https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69'}",
      "dataset": "osv",
      "summary": "Incomplete validation in MKL requantization ### Impact\nDue to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RequantizationRangePerChannel(\n  input=[],\n  input_min=[0,0,0,0,0],\n  input_max=[1,1,1,1,1],\n  clip_value_max=1)\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor.\n\nA similar issue occurs in `MklRequantizePerChannelOp`:\n\n```python\nimport tensorflow as tf \nfrom tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  out_type=tf.int)\n``` \n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments.\n\n### Patches\nWe have patched the issue in GitHub commit [9e62869465573cb2d9b5053f1fa02a81fce21d69](https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69) and in the Github commit [203214568f5bc237603dbab6e1fd389f1572f5c9](https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9",
      "commit_sha": "203214568f5bc237603dbab6e1fd389f1572f5c9",
      "patch": "MULTI",
      "chain_ord": "['9e62869465573cb2d9b5053f1fa02a81fce21d69', '203214568f5bc237603dbab6e1fd389f1572f5c9']",
      "before_first_fix_commit": "{'aff0d5b2883ea3de9b52f9e7cd996a34b299bf06'}",
      "last_fix_commit": "203214568f5bc237603dbab6e1fd389f1572f5c9",
      "chain_ord_pos": 2.0,
      "commit_datetime": "07/30/2021, 23:06:23",
      "message": "Reorganize and add more validation to MKL requantization\n\nPiperOrigin-RevId: 387901341\nChange-Id: I2515b9034c64e113db0bcec8337d30643ab0a0f1",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 25, 'deletions': 15, 'total': 40}",
      "files": "{'tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc': {'additions': 25, 'deletions': 15, 'changes': 40, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/203214568f5bc237603dbab6e1fd389f1572f5c9/tensorflow%2Fcore%2Fkernels%2Fmkl%2Fmkl_requantize_per_channel_op.cc', 'patch': '@@ -49,35 +49,45 @@ class MklRequantizePerChannelOp : public OpKernel {\\n   void Compute(OpKernelContext* ctx) override {\\n     try {\\n       const Tensor& input = ctx->input(kInputTensorIndex);\\n+      OP_REQUIRES(\\n+          ctx, input.dims() == 4,\\n+          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\\n+                                  \"supports 4D tensors only.\"));\\n+\\n       const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\\n+      size_t depth = input_min_vec.NumElements();\\n       float* input_min_vec_data = (float*)const_cast<void*>(\\n           static_cast<const void*>(input_min_vec.flat<float>().data()));\\n+\\n       const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\\n+      OP_REQUIRES(\\n+          ctx, input_max_vec.NumElements() == depth,\\n+          errors::InvalidArgument(\"input_max has incorrect size, expected \",\\n+                                  depth, \" was \", input_max_vec.NumElements()));\\n       float* input_max_vec_data = (float*)const_cast<void*>(\\n           static_cast<const void*>(input_max_vec.flat<float>().data()));\\n \\n       const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\\n+      OP_REQUIRES(\\n+          ctx, input_requested_min.NumElements() == 1,\\n+          errors::InvalidArgument(\"requested_output_min must be a scalar\"));\\n       const float input_requested_min_float =\\n           input_requested_min.flat<float>()(0);\\n+\\n       const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\\n+      OP_REQUIRES(\\n+          ctx, input_requested_min.NumElements() == 1,\\n+          errors::InvalidArgument(\"requested_output_max must be a scalar\"));\\n       const float input_requested_max_float =\\n           input_requested_max.flat<float>()(0);\\n \\n-      size_t depth = input_min_vec.NumElements();\\n-      OP_REQUIRES(\\n-          ctx, input.dims() == 4,\\n-          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\\n-                                  \"supports 4D tensors only.\"));\\n-      OP_REQUIRES(\\n-          ctx, input_min_vec.dim_size(0) == depth,\\n-          errors::InvalidArgument(\"input_min has incorrect size, expected \",\\n-                                  depth, \" was \", input_min_vec.dim_size(0)));\\n-      OP_REQUIRES(\\n-          ctx, input_max_vec.dim_size(0) == depth,\\n-          errors::InvalidArgument(\"input_max has incorrect size, expected \",\\n-                                  depth, \" was \", input_max_vec.dim_size(0)));\\n-\\n-      if (out_type_ == DT_QINT8) DCHECK(input_requested_min_float < 0.0f);\\n+      if (out_type_ == DT_QINT8) {\\n+        OP_REQUIRES(ctx, input_requested_min_float < 0.0f,\\n+                    errors::InvalidArgument(\\n+                        \"If out_type is QINT8, requested_output_max must be \"\\n+                        \"non negative, got \",\\n+                        input_requested_min_float));\\n+      }\\n \\n       const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\\n       const float requested_min_max ='}}",
      "message_norm": "reorganize and add more validation to mkl requantization\n\npiperorigin-revid: 387901341\nchange-id: i2515b9034c64e113db0bcec8337d30643ab0a0f1",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('387901341', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2791,
      "vuln_id": "GHSA-qpgx-64h2-gc3c",
      "cwe_id": "{'CWE-22'}",
      "score": 7.5,
      "chain": "{'https://github.com/argoproj/argo-events/commit/d0f66dbce78bc31923ca057b20fc722aa24ca961'}",
      "dataset": "osv",
      "summary": "Insecure path traversal in Git Trigger Source can lead to arbitrary file read ### Impact\nA path traversal issue was found in the (g *GitArtifactReader).Read() API. Read() calls into (g *GitArtifactReader).readFromRepository() that opens and reads the file that contains the trigger resource definition:\n\n```go\nfunc (g *GitArtifactReader) readFromRepository(r *git.Repository, dir string)\n```\n\nNo checks are made on this file at read time, which could lead an attacker to read files anywhere on the system. This could be achieved by either using symbolic links, or putting `../` in the path.\n\n### Patches\nA patch for this vulnerability has been released in the following Argo Events version:\n\nv1.7.1\n\n### Credits\nDisclosed by [Ada Logics](https://adalogics.com/) in a security audit sponsored by CNCF and facilitated by OSTIF.\n\n### For more information\nOpen an issue in the [Argo Events issue tracker](https://github.com/argoproj/argo-events/issues) or [discussions](https://github.com/argoproj/argo-events/discussions)\nJoin us on [Slack](https://argoproj.github.io/community/join-slack) in channel #argo-events",
      "published_date": "2022-06-17",
      "chain_len": 1,
      "project": "https://github.com/argoproj/argo-events",
      "commit_href": "https://github.com/argoproj/argo-events/commit/d0f66dbce78bc31923ca057b20fc722aa24ca961",
      "commit_sha": "d0f66dbce78bc31923ca057b20fc722aa24ca961",
      "patch": "SINGLE",
      "chain_ord": "['d0f66dbce78bc31923ca057b20fc722aa24ca961']",
      "before_first_fix_commit": "{'e80ab9f9556f7f97346fb393e312f8a689ca21f8'}",
      "last_fix_commit": "d0f66dbce78bc31923ca057b20fc722aa24ca961",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/13/2022, 03:18:33",
      "message": "fix: git artifactory arbitrary file read issue (#1965)\n\nSigned-off-by: Derek Wang <whynowy@gmail.com>",
      "author": "Derek Wang",
      "comments": null,
      "stats": "{'additions': 34, 'deletions': 2, 'total': 36}",
      "files": "{'sensors/artifacts/git.go': {'additions': 34, 'deletions': 2, 'changes': 36, 'status': 'modified', 'raw_url': 'https://github.com/argoproj/argo-events/raw/d0f66dbce78bc31923ca057b20fc722aa24ca961/sensors%2Fartifacts%2Fgit.go', 'patch': '@@ -20,6 +20,8 @@ import (\\n \\t\"fmt\"\\n \\t\"io/ioutil\"\\n \\t\"os\"\\n+\\t\"path\"\\n+\\t\"strings\"\\n \\n \\t\"github.com/go-git/go-git/v5\"\\n \\t\"github.com/go-git/go-git/v5/config\"\\n@@ -44,6 +46,8 @@ var (\\n \\t\\t\"refs/*:refs/*\",\\n \\t\\t\"HEAD:refs/heads/HEAD\",\\n \\t}\\n+\\n+\\tnotAllowedInPath = []string{\"..\", \"~\", \"\\\\\\\\\"}\\n )\\n \\n type GitArtifactReader struct {\\n@@ -52,6 +56,15 @@ type GitArtifactReader struct {\\n \\n // NewGitReader returns a new git reader\\n func NewGitReader(gitArtifact *v1alpha1.GitArtifact) (*GitArtifactReader, error) {\\n+\\tif gitArtifact == nil {\\n+\\t\\treturn nil, fmt.Errorf(\"nil git artifact\")\\n+\\t}\\n+\\tfor _, na := range notAllowedInPath {\\n+\\t\\tif strings.Contains(gitArtifact.FilePath, na) {\\n+\\t\\t\\treturn nil, fmt.Errorf(\"%q is not allowed in the filepath\", na)\\n+\\t\\t}\\n+\\t}\\n+\\n \\treturn &GitArtifactReader{\\n \\t\\tartifact: gitArtifact,\\n \\t}, nil\\n@@ -176,8 +189,16 @@ func (g *GitArtifactReader) readFromRepository(r *git.Repository, dir string) ([\\n \\t\\t\\treturn nil, fmt.Errorf(\"failed to pull latest updates. err: %+v\", err)\\n \\t\\t}\\n \\t}\\n-\\n-\\treturn ioutil.ReadFile(fmt.Sprintf(\"%s/%s\", dir, g.artifact.FilePath))\\n+\\tfilePath := fmt.Sprintf(\"%s/%s\", dir, g.artifact.FilePath)\\n+\\t// symbol link is not allowed due to security concern\\n+\\tisSymbolLink, err := isSymbolLink(filePath)\\n+\\tif err != nil {\\n+\\t\\treturn nil, err\\n+\\t}\\n+\\tif isSymbolLink {\\n+\\t\\treturn nil, fmt.Errorf(\"%q is a symbol link which is not allowed\", g.artifact.FilePath)\\n+\\t}\\n+\\treturn ioutil.ReadFile(filePath)\\n }\\n \\n func (g *GitArtifactReader) getBranchOrTag() *git.CheckoutOptions {\\n@@ -241,3 +262,14 @@ func (g *GitArtifactReader) Read() ([]byte, error) {\\n \\t}\\n \\treturn g.readFromRepository(r, cloneDir)\\n }\\n+\\n+func isSymbolLink(filepath string) (bool, error) {\\n+\\tfi, err := os.Lstat(path.Clean(filepath))\\n+\\tif err != nil {\\n+\\t\\treturn false, err\\n+\\t}\\n+\\tif fi.Mode()&os.ModeSymlink != 0 {\\n+\\t\\treturn true, nil\\n+\\t}\\n+\\treturn false, nil\\n+}'}}",
      "message_norm": "fix: git artifactory arbitrary file read issue (#1965)\n\nsigned-off-by: derek wang <whynowy@gmail.com>",
      "language": "en",
      "entities": "[('issue', 'FLAW', ''), ('#1965', 'ISSUE', ''), ('whynowy@gmail.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['sensors/artifacts/git.go'])",
      "num_files": 1.0
    },
    {
      "index": 1151,
      "vuln_id": "GHSA-86ch-6w7v-v6xf",
      "cwe_id": "{'CWE-755'}",
      "score": 7.5,
      "chain": "{'https://github.com/soketi/soketi/commit/4b12efef9c31117c36a0a0f1c3aa32114e86364b'}",
      "dataset": "osv",
      "summary": "Denial of Service in soketi ### Impact\n_What kind of vulnerability is it? Who is impacted?_\n\nThere was a wrong behavior when reading POST requests, making the server crash if it couldn't read the body. In case a POST request was sent to any endpoint of the server with an empty body, **even unauthenticated with the Pusher Protocol**, it would simply just crash the server for trying to send a response after the request closed.\n\nAll users that run the server are affected by it and it's highly recommended to upgrade to the latest patch.\n\n### Patches\n_Has the problem been patched? What versions should users upgrade to?_\n\nUpdating to at least 0.24.1 or the latest version.\n\n### Workarounds\n_Is there a way for users to fix or remediate the vulnerability without upgrading?_\n\nNo. Upgrading is the only solution.\n\n### References\n_Are there any links users can visit to find out more?_\n\nhttps://github.com/soketi/soketi/releases/tag/0.24.1\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [the issues board](https://github.com/soketi/soketi/issues)\n* Email us at [alex@renoki.org](mailto:alex@renoki.org)",
      "published_date": "2022-01-08",
      "chain_len": 1,
      "project": "https://github.com/soketi/soketi",
      "commit_href": "https://github.com/soketi/soketi/commit/4b12efef9c31117c36a0a0f1c3aa32114e86364b",
      "commit_sha": "4b12efef9c31117c36a0a0f1c3aa32114e86364b",
      "patch": "SINGLE",
      "chain_ord": "['4b12efef9c31117c36a0a0f1c3aa32114e86364b']",
      "before_first_fix_commit": "{'8541e4e07c97de7b6fd2ce22f4e072ef1072d627', '53ba39c7886c614d27633d347dbd93faac9dbdc0'}",
      "last_fix_commit": "4b12efef9c31117c36a0a0f1c3aa32114e86364b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/07/2022, 11:26:17",
      "message": "Merge pull request #246 from soketi/fix/crash-on-empty-post\n\n[fix] Do not close the connection on empty POST payload",
      "author": "rennokki",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 7, 'total': 16}",
      "files": "{'src/http-handler.ts': {'additions': 9, 'deletions': 7, 'changes': 16, 'status': 'modified', 'raw_url': 'https://github.com/soketi/soketi/raw/4b12efef9c31117c36a0a0f1c3aa32114e86364b/src%2Fhttp-handler.ts', 'patch': \"@@ -417,19 +417,22 @@ export class HttpHandler {\\n             let chunk = Buffer.from(ab);\\n \\n             if (isLast) {\\n-                let json;\\n-                let raw;\\n+                let json = {};\\n+                let raw = '{}';\\n \\n                 if (buffer) {\\n                     try {\\n                         // @ts-ignore\\n                         json = JSON.parse(Buffer.concat([buffer, chunk]));\\n                     } catch (e) {\\n-                        res.close();\\n-                        return;\\n+                        //\\n                     }\\n \\n-                    raw = Buffer.concat([buffer, chunk]).toString();\\n+                    try {\\n+                        raw = Buffer.concat([buffer, chunk]).toString();\\n+                    } catch (e) {\\n+                        //\\n+                    }\\n \\n                     cb(json, raw);\\n                     loggingAction(json);\\n@@ -439,8 +442,7 @@ export class HttpHandler {\\n                         json = JSON.parse(chunk);\\n                         raw = chunk.toString();\\n                     } catch (e) {\\n-                        res.close();\\n-                        return;\\n+                        //\\n                     }\\n \\n                     cb(json, raw);\"}}",
      "message_norm": "merge pull request #246 from soketi/fix/crash-on-empty-post\n\n[fix] do not close the connection on empty post payload",
      "language": "en",
      "entities": "[('#246', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/http-handler.ts'])",
      "num_files": 1.0
    },
    {
      "index": 3269,
      "vuln_id": "GHSA-wf5x-cr3r-xr77",
      "cwe_id": "{'CWE-674'}",
      "score": 8.3,
      "chain": "{'https://github.com/patriksimek/vm2/commit/4b22d704e4794af63a5a2d633385fd20948f6f90'}",
      "dataset": "osv",
      "summary": "vm2 before 3.6.11 vulnerable to sandbox escape This affects the package vm2 before 3.6.11. It is possible to trigger a RangeError exception from the host rather than the \"sandboxed\" context by reaching the stack call limit with an infinite recursion. The returned object is then used to reference the mainModule property of the host code running the script allowing it to spawn a child_process and execute arbitrary code.",
      "published_date": "2022-07-14",
      "chain_len": 1,
      "project": "https://github.com/patriksimek/vm2",
      "commit_href": "https://github.com/patriksimek/vm2/commit/4b22d704e4794af63a5a2d633385fd20948f6f90",
      "commit_sha": "4b22d704e4794af63a5a2d633385fd20948f6f90",
      "patch": "SINGLE",
      "chain_ord": "['4b22d704e4794af63a5a2d633385fd20948f6f90']",
      "before_first_fix_commit": "{'2ac8ff254a71e516e83f6496635fa61420447fa9'}",
      "last_fix_commit": "4b22d704e4794af63a5a2d633385fd20948f6f90",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/07/2019, 23:46:03",
      "message": "Fixes sandbox escape (#197)",
      "author": "Patrik Simek",
      "comments": null,
      "stats": "{'additions': 16, 'deletions': 16, 'total': 32}",
      "files": "{'lib/contextify.js': {'additions': 16, 'deletions': 16, 'changes': 32, 'status': 'modified', 'raw_url': 'https://github.com/patriksimek/vm2/raw/4b22d704e4794af63a5a2d633385fd20948f6f90/lib%2Fcontextify.js', 'patch': \"@@ -327,15 +327,15 @@ Decontextify.object = (object, traps, deepTraps, flags, mock) => {\\n \\treturn proxy;\\n };\\n Decontextify.value = (value, traps, deepTraps, flags, mock) => {\\n-\\tif (Contextified.has(value)) {\\n-\\t\\t// Contextified object has returned back from vm\\n-\\t\\treturn Contextified.get(value);\\n-\\t} else if (Decontextify.proxies.has(value)) {\\n-\\t\\t// Decontextified proxy already exists, reuse\\n-\\t\\treturn Decontextify.proxies.get(value);\\n-\\t}\\n-\\n \\ttry {\\n+\\t\\tif (Contextified.has(value)) {\\n+\\t\\t\\t// Contextified object has returned back from vm\\n+\\t\\t\\treturn Contextified.get(value);\\n+\\t\\t} else if (Decontextify.proxies.has(value)) {\\n+\\t\\t\\t// Decontextified proxy already exists, reuse\\n+\\t\\t\\treturn Decontextify.proxies.get(value);\\n+\\t\\t}\\n+\\n \\t\\tswitch (typeof value) {\\n \\t\\t\\tcase 'object':\\n \\t\\t\\t\\tif (value === null) {\\n@@ -621,15 +621,15 @@ Contextify.object = (object, traps, deepTraps, flags, mock) => {\\n \\treturn proxy;\\n };\\n Contextify.value = (value, traps, deepTraps, flags, mock) => {\\n-\\tif (Decontextified.has(value)) {\\n-\\t\\t// Decontextified object has returned back to vm\\n-\\t\\treturn Decontextified.get(value);\\n-\\t} else if (Contextify.proxies.has(value)) {\\n-\\t\\t// Contextified proxy already exists, reuse\\n-\\t\\treturn Contextify.proxies.get(value);\\n-\\t}\\n-\\n \\ttry {\\n+\\t\\tif (Decontextified.has(value)) {\\n+\\t\\t\\t// Decontextified object has returned back to vm\\n+\\t\\t\\treturn Decontextified.get(value);\\n+\\t\\t} else if (Contextify.proxies.has(value)) {\\n+\\t\\t\\t// Contextified proxy already exists, reuse\\n+\\t\\t\\treturn Contextify.proxies.get(value);\\n+\\t\\t}\\n+\\n \\t\\tswitch (typeof value) {\\n \\t\\t\\tcase 'object':\\n \\t\\t\\t\\tif (value === null) {\"}}",
      "message_norm": "fixes sandbox escape (#197)",
      "language": "ca",
      "entities": "[('fixes', 'ACTION', ''), ('sandbox', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('#197', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/contextify.js'])",
      "num_files": 1.0
    },
    {
      "index": 1483,
      "vuln_id": "GHSA-c545-c4f9-rf6v",
      "cwe_id": "{'CWE-125'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/d94ffe08a65400f898241c0374e9edc6fa8ed257'}",
      "dataset": "osv",
      "summary": "Heap OOB in TFLite ### Impact\nTFLite's [`expand_dims.cc`](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/expand_dims.cc#L36-L50) contains a vulnerability which allows reading one element outside of bounds of heap allocated data:\n\n```cc\n  if (axis < 0) { \n    axis = input_dims.size + 1 + axis;\n  }   \n  TF_LITE_ENSURE(context, axis <= input_dims.size);\n\n  TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\n  for (int i = 0; i < output_dims->size; ++i) {\n    if (i < axis) {\n      output_dims->data[i] = input_dims.data[i];\n    } else if (i == axis) {\n      output_dims->data[i] = 1;\n    } else {\n      output_dims->data[i] = input_dims.data[i - 1];\n    }\n  }\n```\n\nIf `axis` is a large negative value (e.g., `-100000`), then after the first `if` it would still be negative. The check following the `if` statement will pass and the `for` loop would read one element before the start of `input_dims.data` (when `i = 0`).\n\n### Patches\nWe have patched the issue in GitHub commit [d94ffe08a65400f898241c0374e9edc6fa8ed257](https://github.com/tensorflow/tensorflow/commit/d94ffe08a65400f898241c0374e9edc6fa8ed257).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/d94ffe08a65400f898241c0374e9edc6fa8ed257",
      "commit_sha": "d94ffe08a65400f898241c0374e9edc6fa8ed257",
      "patch": "SINGLE",
      "chain_ord": "['d94ffe08a65400f898241c0374e9edc6fa8ed257']",
      "before_first_fix_commit": "{'e95fc647063378993ec84d41cbbda6dcb60bad4e'}",
      "last_fix_commit": "d94ffe08a65400f898241c0374e9edc6fa8ed257",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/27/2021, 21:42:54",
      "message": "Prevent an OOB read in `expand_dims.cc`\n\nThe for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. If user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in Python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\nPiperOrigin-RevId: 387200206\nChange-Id: I162f4feba12d547c3a4340833ae682016a2ebfab",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'tensorflow/lite/kernels/expand_dims.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/d94ffe08a65400f898241c0374e9edc6fa8ed257/tensorflow%2Flite%2Fkernels%2Fexpand_dims.cc', 'patch': '@@ -37,6 +37,7 @@ TfLiteStatus ExpandTensorDim(TfLiteContext* context, const TfLiteTensor& input,\\n     axis = input_dims.size + 1 + axis;\\n   }\\n   TF_LITE_ENSURE(context, axis <= input_dims.size);\\n+  TF_LITE_ENSURE(context, axis >= 0);\\n \\n   TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\\n   for (int i = 0; i < output_dims->size; ++i) {'}}",
      "message_norm": "prevent an oob read in `expand_dims.cc`\n\nthe for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. if user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\npiperorigin-revid: 387200206\nchange-id: i162f4feba12d547c3a4340833ae682016a2ebfab",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('oob', 'SECWORD', ''), ('387200206', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/expand_dims.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2162,
      "vuln_id": "GHSA-hxf9-7h4c-f5jv",
      "cwe_id": "{'CWE-200'}",
      "score": 9.1,
      "chain": "{'https://github.com/anymail/django-anymail/commit/db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'https://github.com/anymail/django-anymail/commit/c07998304b4a31df4c61deddcb03d3607a04691b'}",
      "dataset": "osv",
      "summary": "Django-Anymail prone to a timing attack webhooks/base.py in Anymail (aka django-anymail) before 1.2.1 is prone to a timing attack vulnerability on the WEBHOOK_AUTHORIZATION secret, which allows remote attackers to post arbitrary e-mail tracking events.",
      "published_date": "2018-07-12",
      "chain_len": 2,
      "project": "https://github.com/anymail/django-anymail",
      "commit_href": "https://github.com/anymail/django-anymail/commit/c07998304b4a31df4c61deddcb03d3607a04691b",
      "commit_sha": "c07998304b4a31df4c61deddcb03d3607a04691b",
      "patch": "MULTI",
      "chain_ord": "['db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'c07998304b4a31df4c61deddcb03d3607a04691b']",
      "before_first_fix_commit": "{'7029298b930620b1655dab2548f72d6640a5905e'}",
      "last_fix_commit": "c07998304b4a31df4c61deddcb03d3607a04691b",
      "chain_ord_pos": 2.0,
      "commit_datetime": "02/02/2018, 19:41:14",
      "message": "Security: prevent timing attack on WEBHOOK_AUTHORIZATION secret\n\nAnymail's webhook validation was vulnerable to a timing attack.\nAn attacker could have used this to recover your WEBHOOK_AUTHORIZATION\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nThere have not been any reports of attempted exploit in the wild. (The\nvulnerability was discovered through code review.) Attempts would be\nvisible in http logs as a very large number of 400 responses on\nAnymail's webhook urls, or in Python error monitoring as a very large\nnumber of AnymailWebhookValidationFailure exceptions.\n\nIf you are using Anymail's webhooks, you should upgrade to this release.\nIn addition, you may want to rotate to a new WEBHOOK_AUTHORIZATION\nsecret ([docs](http://anymail.readthedocs.io/en/stable/tips/securing_webhooks/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.\n\n(cherry picked from commit db586ede1fbb41dce21310ea28ae15a1cf1286c5)",
      "author": "medmunds",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 3, 'total': 15}",
      "files": "{'anymail/webhooks/base.py': {'additions': 12, 'deletions': 3, 'changes': 15, 'status': 'modified', 'raw_url': 'https://github.com/anymail/django-anymail/raw/c07998304b4a31df4c61deddcb03d3607a04691b/anymail%2Fwebhooks%2Fbase.py', 'patch': '@@ -3,6 +3,7 @@\\n \\n import six\\n from django.http import HttpResponse\\n+from django.utils.crypto import constant_time_compare\\n from django.utils.decorators import method_decorator\\n from django.views.decorators.csrf import csrf_exempt\\n from django.views.generic import View\\n@@ -41,8 +42,13 @@ def __init__(self, **kwargs):\\n     def validate_request(self, request):\\n         \"\"\"If configured for webhook basic auth, validate request has correct auth.\"\"\"\\n         if self.basic_auth:\\n-            basic_auth = get_request_basic_auth(request)\\n-            if basic_auth is None or basic_auth not in self.basic_auth:\\n+            request_auth = get_request_basic_auth(request)\\n+            # Use constant_time_compare to avoid timing attack on basic auth. (It\\'s OK that any()\\n+            # can terminate early: we\\'re not trying to protect how many auth strings are allowed,\\n+            # just the contents of each individual auth string.)\\n+            auth_ok = any(constant_time_compare(request_auth, allowed_auth)\\n+                          for allowed_auth in self.basic_auth)\\n+            if not auth_ok:\\n                 # noinspection PyUnresolvedReferences\\n                 raise AnymailWebhookValidationFailure(\\n                     \"Missing or invalid basic auth in Anymail %s webhook\" % self.esp_name)\\n@@ -78,8 +84,11 @@ def validate_request(self, request):\\n         *All* definitions of this method in the class chain (including mixins)\\n         will be called. There is no need to chain to the superclass.\\n         (See self.run_validators and collect_all_methods.)\\n+\\n+        Security note: use django.utils.crypto.constant_time_compare for string\\n+        comparisons, to avoid exposing your validation to a timing attack.\\n         \"\"\"\\n-        # if request.POST[\\'signature\\'] != expected_signature:\\n+        # if not constant_time_compare(request.POST[\\'signature\\'], expected_signature):\\n         #     raise AnymailWebhookValidationFailure(\"...message...\")\\n         # (else just do nothing)\\n         pass'}}",
      "message_norm": "security: prevent timing attack on webhook_authorization secret\n\nanymail's webhook validation was vulnerable to a timing attack.\nan attacker could have used this to recover your webhook_authorization\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nthere have not been any reports of attempted exploit in the wild. (the\nvulnerability was discovered through code review.) attempts would be\nvisible in http logs as a very large number of 400 responses on\nanymail's webhook urls, or in python error monitoring as a very large\nnumber of anymailwebhookvalidationfailure exceptions.\n\nif you are using anymail's webhooks, you should upgrade to this release.\nin addition, you may want to rotate to a new webhook_authorization\nsecret ([docs](http://anymail.readthedocs.io/en/stable/tips/securing_webhooks/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.\n\n(cherry picked from commit db586ede1fbb41dce21310ea28ae15a1cf1286c5)",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('attack', 'SECWORD', ''), ('vulnerable', 'SECWORD', ''), ('attack', 'FLAW', ''), ('attacker', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('exploit', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('error', 'FLAW', ''), ('upgrade', 'ACTION', ''), ('docs](http://anymail.readthedocs.io', 'URL', ''), ('exploit', 'SECWORD', ''), ('commit db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'SHA', 'prefix_colon_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['anymail/webhooks/base.py'])",
      "num_files": 1.0
    },
    {
      "index": 1537,
      "vuln_id": "GHSA-cf6r-3wgc-h863",
      "cwe_id": "{'CWE-502'}",
      "score": 7.5,
      "chain": "{'https://github.com/FasterXML/jackson-databind/commit/41b7f9b90149e9d44a65a8261a8deedc7186f6af', 'https://github.com/FasterXML/jackson-databind/commit/819cdbcab51c6da9fb896380f2d46e9b7d4fdc3b'}",
      "dataset": "osv",
      "summary": "Polymorphic deserialization of malicious object in jackson-databind A flaw was discovered in jackson-databind in versions before 2.9.10, 2.8.11.5 and 2.6.7.3, where it would permit polymorphic deserialization of a malicious object using commons-configuration 1 and 2 JNDI classes. An attacker could use this flaw to execute arbitrary code.",
      "published_date": "2020-05-15",
      "chain_len": 2,
      "project": "https://github.com/FasterXML/jackson-databind",
      "commit_href": "https://github.com/FasterXML/jackson-databind/commit/41b7f9b90149e9d44a65a8261a8deedc7186f6af",
      "commit_sha": "41b7f9b90149e9d44a65a8261a8deedc7186f6af",
      "patch": "MULTI",
      "chain_ord": "['41b7f9b90149e9d44a65a8261a8deedc7186f6af', '819cdbcab51c6da9fb896380f2d46e9b7d4fdc3b']",
      "before_first_fix_commit": "{'41b7f9b90149e9d44a65a8261a8deedc7186f6af', 'f4f4a4e035ada20a532a5400e5f093a5a575a0ed'}",
      "last_fix_commit": "819cdbcab51c6da9fb896380f2d46e9b7d4fdc3b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/20/2019, 05:57:18",
      "message": "Actual #2462 fix (prev commit only updates release notes)",
      "author": "Tatu Saloranta",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 1, 'total': 6}",
      "files": "{'src/main/java/com/fasterxml/jackson/databind/jsontype/impl/SubTypeValidator.java': {'additions': 5, 'deletions': 1, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/FasterXML/jackson-databind/raw/41b7f9b90149e9d44a65a8261a8deedc7186f6af/src%2Fmain%2Fjava%2Fcom%2Ffasterxml%2Fjackson%2Fdatabind%2Fjsontype%2Fimpl%2FSubTypeValidator.java', 'patch': '@@ -106,7 +106,11 @@\\n \\n         // [databind#2420]: CXF/JAX-RS provider/XSLT\\n         s.add(\"org.apache.cxf.jaxrs.provider.XSLTJaxbProvider\");\\n-        \\n+\\n+        // [databind#2462]: commons-configuration / -2\\n+        s.add(\"org.apache.commons.configuration.JNDIConfiguration\");\\n+        s.add(\"org.apache.commons.configuration2.JNDIConfiguration\");\\n+\\n         DEFAULT_NO_DESER_CLASS_NAMES = Collections.unmodifiableSet(s);\\n     }'}}",
      "message_norm": "actual #2462 fix (prev commit only updates release notes)",
      "language": "en",
      "entities": "[('#2462', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/main/java/com/fasterxml/jackson/databind/jsontype/impl/SubTypeValidator.java'])",
      "num_files": 1.0
    },
    {
      "index": 720,
      "vuln_id": "GHSA-5xjx-4xcm-hpcm",
      "cwe_id": "{'CWE-1321', 'CWE-915'}",
      "score": 7.3,
      "chain": "{'https://github.com/BadOPCode/NoDash/commit/b9cc2b3b49f6cd5228e406bc57e17a28b998fea5'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in ts-nodash `ts-nodash` before version 1.2.7 is vulnerable to Prototype Pollution via the Merge() function due to lack of validation input.",
      "published_date": "2021-12-10",
      "chain_len": 1,
      "project": "https://github.com/BadOPCode/NoDash",
      "commit_href": "https://github.com/BadOPCode/NoDash/commit/b9cc2b3b49f6cd5228e406bc57e17a28b998fea5",
      "commit_sha": "b9cc2b3b49f6cd5228e406bc57e17a28b998fea5",
      "patch": "SINGLE",
      "chain_ord": "['b9cc2b3b49f6cd5228e406bc57e17a28b998fea5']",
      "before_first_fix_commit": "{'78f4ffab4ed76c43f6f7fb91d8b329acb0d6e684'}",
      "last_fix_commit": "b9cc2b3b49f6cd5228e406bc57e17a28b998fea5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/11/2021, 02:50:07",
      "message": "Security fix for Prototype Pollution (#20)\n\nCo-authored-by: Arjun Shibu <arjunshibu1999@gmail.com>\r\nCo-authored-by: Jamie Slome <jamie@418sec.com>\r\nCo-authored-by: Shawn <BadOPCode@users.noreply.github.com>",
      "author": "huntr.dev | the place to protect open source",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 1, 'total': 7}",
      "files": "{'src/Merge.ts': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/BadOPCode/NoDash/raw/b9cc2b3b49f6cd5228e406bc57e17a28b998fea5/src%2FMerge.ts', 'patch': '@@ -47,13 +47,18 @@ const  handleDefaultBehavior = (originalObject: any, newObject: any, behavior?:\\n     if (originalTypeName === \"Object\" && newTypeName === \"Object\") { // built-in behavior\\n         // tslint:disable:forin\\n         for (const p in newObject) {\\n+            if (isPrototypePolluted(p)) continue\\n             originalObject[p] = processBehavior(originalObject[p], newObject[p], behavior);\\n         }\\n         // tslint:enable:forin\\n         return originalObject;\\n     }\\n };\\n \\n+const isPrototypePolluted = (key: any) => {\\n+    return [\\'__proto__\\', \\'constructor\\', \\'prototype\\'].includes(key)\\n+}\\n+\\n /**\\n  * Recursively merge two objects together.\\n  * @param originalObject The base object. Properties here will be overwritten\\n@@ -72,7 +77,7 @@ export const Merge = (originalObject: any, newObject: any, behavior?: IMergeBeha\\n             return definedBehaviorResults;\\n         }\\n     }\\n-\\n+    \\n     return handleDefaultBehavior(originalObject, newObject, behavior);\\n };'}}",
      "message_norm": "security fix for prototype pollution (#20)\n\nco-authored-by: arjun shibu <arjunshibu1999@gmail.com>\r\nco-authored-by: jamie slome <jamie@418sec.com>\r\nco-authored-by: shawn <badopcode@users.noreply.github.com>",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('prototype pollution', 'SECWORD', ''), ('#20', 'ISSUE', ''), ('arjunshibu1999@gmail.com', 'EMAIL', ''), ('jamie@418sec.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Merge.ts'])",
      "num_files": 1.0
    },
    {
      "index": 3113,
      "vuln_id": "GHSA-vgmw-9cww-qq99",
      "cwe_id": "{'CWE-284', 'CWE-863'}",
      "score": 6.5,
      "chain": "{'https://github.com/janeczku/calibre-web/commit/0c0313f375bed7b035c8c0482bbb09599e16bfcf'}",
      "dataset": "osv",
      "summary": "Incorrect Authorization in calibreweb calibreweb prior to version 0.6.16 contains an Incorrect Authorization vulnerability.",
      "published_date": "2022-01-31",
      "chain_len": 1,
      "project": "https://github.com/janeczku/calibre-web",
      "commit_href": "https://github.com/janeczku/calibre-web/commit/0c0313f375bed7b035c8c0482bbb09599e16bfcf",
      "commit_sha": "0c0313f375bed7b035c8c0482bbb09599e16bfcf",
      "patch": "SINGLE",
      "chain_ord": "['0c0313f375bed7b035c8c0482bbb09599e16bfcf']",
      "before_first_fix_commit": "{'6bf07539788004513c3692c074ebc7ba4ce005e1'}",
      "last_fix_commit": "0c0313f375bed7b035c8c0482bbb09599e16bfcf",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/18/2022, 16:55:10",
      "message": "Prevent creating a public shelf without permission",
      "author": "Ozzie Isaacs",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'cps/shelf.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/janeczku/calibre-web/raw/0c0313f375bed7b035c8c0482bbb09599e16bfcf/cps%2Fshelf.py', 'patch': '@@ -248,7 +248,7 @@ def create_edit_shelf(shelf, page_title, page, shelf_id=False):\\n         if not current_user.role_edit_shelfs() and to_save.get(\"is_public\") == \"on\":\\n             flash(_(u\"Sorry you are not allowed to create a public shelf\"), category=\"error\")\\n             return redirect(url_for(\\'web.index\\'))\\n-        is_public = 1 if to_save.get(\"is_public\") else 0\\n+        is_public = 1 if to_save.get(\"is_public\") == \"on\" else 0\\n         if config.config_kobo_sync:\\n             shelf.kobo_sync = True if to_save.get(\"kobo_sync\") else False\\n             if shelf.kobo_sync:'}}",
      "message_norm": "prevent creating a public shelf without permission",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('permission', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['cps/shelf.py'])",
      "num_files": 1.0
    },
    {
      "index": 1236,
      "vuln_id": "GHSA-8phj-f9w2-cjcc",
      "cwe_id": "{'CWE-22'}",
      "score": 8.6,
      "chain": "{'https://github.com/aimhubio/aim/pull/1003/commits/f01266a1a479ef11d7d6c539e7dd89e9d5639738'}",
      "dataset": "osv",
      "summary": "Arbitrary file reading vulnerability in Aim ### Impact\nA path traversal attack aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files.\n\nVulnerable code: https://github.com/aimhubio/aim/blob/0b99c6ca08e0ba7e7011453a2f68033e9b1d1bce/aim/web/api/views.py#L9-L16\n\n### Patches\nThe vulnerability issue is resolved in Aim v3.1.0.\n\n### References\nhttps://owasp.org/www-community/attacks/Path_Traversal",
      "published_date": "2021-11-23",
      "chain_len": 1,
      "project": "https://github.com/aimhubio/aim",
      "commit_href": "https://github.com/aimhubio/aim/pull/1003/commits/f01266a1a479ef11d7d6c539e7dd89e9d5639738",
      "commit_sha": "f01266a1a479ef11d7d6c539e7dd89e9d5639738",
      "patch": "SINGLE",
      "chain_ord": "['f01266a1a479ef11d7d6c539e7dd89e9d5639738']",
      "before_first_fix_commit": "{'0bcac8b709f9409518134b2eafee817278aca14f'}",
      "last_fix_commit": "f01266a1a479ef11d7d6c539e7dd89e9d5639738",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/12/2021, 14:03:22",
      "message": "Fix security issue when incorrect path is given to the endpoint that serves static files which can lead to a leak of non wanted files (e.g. /static-files/../../../../etc/passwd)",
      "author": "mihran113",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 1, 'total': 10}",
      "files": "{'aim/web/api/views.py': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/aimhubio/aim/raw/f01266a1a479ef11d7d6c539e7dd89e9d5639738/aim%2Fweb%2Fapi%2Fviews.py', 'patch': \"@@ -1,15 +1,23 @@\\n import os\\n+from pathlib import Path\\n \\n from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter\\n from fastapi.responses import FileResponse\\n+from fastapi import HTTPException\\n \\n statics_router = APIRouter()\\n \\n \\n @statics_router.get('/static-files/{path:path}/')\\n async def serve_static_files(path):\\n     from aim import web\\n-    static_file_name = os.path.join(os.path.dirname(web.__file__), 'ui', 'build', path)\\n+    static_file_root = os.path.join(os.path.dirname(web.__file__), 'ui', 'build')\\n+    static_file_name = os.path.join(static_file_root, path)\\n+\\n+    # check if path is leading inside ui/build directory\\n+    if not Path(static_file_root) in Path(static_file_name).resolve().parents:\\n+        raise HTTPException(404)\\n+\\n     compressed_file_name = '{}.gz'.format(static_file_name)\\n     if os.path.exists(compressed_file_name):\\n         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})\"}}",
      "message_norm": "fix security issue when incorrect path is given to the endpoint that serves static files which can lead to a leak of non wanted files (e.g. /static-files/../../../../etc/passwd)",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('leak', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['aim/web/api/views.py'])",
      "num_files": 1.0
    },
    {
      "index": 1973,
      "vuln_id": "GHSA-h3fg-h5v3-vf8m",
      "cwe_id": "{'CWE-352'}",
      "score": 5.3,
      "chain": "{'https://github.com/solidusio/solidus/commit/a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6', 'https://github.com/solidusio/solidus/commit/4d17cacf066d9492fc04eb3a0b16084b47376d81'}",
      "dataset": "osv",
      "summary": "CSRF forgery protection bypass in solidus_frontend ### Impact\nCSRF vulnerability that allows a malicious site to add an item to the user's cart without their knowledge.\n\nAll `solidus_frontend` versions are affected. If you're using your own storefront, please, follow along to make sure you're not affected.\n\nTo reproduce the issue:\n\n- Pick the id for a variant with available stock. From the rails console:\n\n  ```ruby\n  Spree::Variant.in_stock.pluck(:id)\n  ```\n\n  Say we pick variant id `2`.\n\n- Launch your application, for instance, on `http://localhost:3000`:\n\n  ```bash\n  bin/rails server\n  ```\n\n- Open your browser dev tools.\n\n- Click on whatever link in your store.\n\n- Copy the value of the `Cookie` request header sent for the previous request from your browser dev tools.\n\n- Execute the following, using your previously selected variant id and the value of the `Cookie` header (notice how it doesn't contain any authentication token):\n\n  ```bash\n  curl -X POST -d \"variant_id=2&quantity=1\" -H \"Cookie: guest_token=eyJfcmFpbHMiOnsibWVzc2FnZSI6IklrWlRVMWRQWnpKMVZVdFNXRzlPVW1aaWJHTjZZa0VpIiwiZXhwIjpudWxsLCJwdXIiOiJjb29raWUuZ3Vlc3RfdG9rZW4ifX0%3D--5006ba5d346f621c760a29b6a797bf351d17d1b8; _sandbox_session=vhutu5%2FL9NmWrUpGc3DxrFA%2FFsQD1dHn1cNsD7nvE84zcjWf17Af4%2F%2F2Vab3md71b6KTb9NP6WktdXktpwH4eU01jEGIBXG5%2BMzW5nL0nb4W269qk1io4LYljvoOg8%2BZVll7oJCVkJLKKh0sSoS0Kg8j%2FCHHs%2BsShohP%2BGnA%2Bfr9Ub8H6HofpSmloSpsfHHygmX0ho03fEgzHJ4DD5wJctaNKwg7NhVikHh5kgIPPHl84OGCgv3p2oe9jR19HTxOKq7BtyvDd7XZsecWhkcfS8BPnvDDUWZG6qpAEFI5kWo81KkpSJ%2Bp6Q1HOo8%3D--n3G2vgaDG7VS%2B%2FhF--ZTjxBAkfGG3hpr4GRQ2S1Q%3D%3D; __profilin=p%3Dt\" http://localhost:3000/orders/populate\n  ```\n\n- Reload your browser and look at how your cart got updated.\n\n### Patches\n\nPlease, upgrade `solidus` to versions `3.1.5`, `3.0.5` or `2.11.14`.\n\nAfter upgrading, make sure you read the \"Upgrade notes\"  section below.\n\n### Upgrade notes\n\nThe patch adds CSRF token verification to the \"Add to cart\" action. Adding forgery protection to a form that missed it can have some side effects.\n\n#### `InvalidAuthenticityToken` errors\n\nIf you're using the `:exception` strategy, it's likely that after upgrading, you'll see more `ActionController::InvalidAuthenticityToken` errors popping out in your logs. Due to browser-side cache, a form can be re-rendered and sent without any attached request cookie (for instance, when re-opening a mobile browser). That will cause an authentication error, as the sent token won't match with the one in the session (none in this case). That's a known problem in the Rails community (see https://github.com/rails/rails/issues/21948), and, at this point, there's no perfect solution.\n\nAny attempt to mitigate the issue should be seen at the application level. For an excellent survey of all the available options, take a look at https://github.com/betagouv/demarches-simplifiees.fr/blob/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9/doc/adr-csrf-forgery.md. The latter is a third-party link. As the information is relevant here, we're going to copy it below, but it should be clear that all the credit goes to @kemenaran:\n\n> # Protecting against request forgery using CRSF tokens\n> \n> ## Context\n> \n> Rails has CSRF protection enabled by default, to protect against POST-based CSRF attacks.\n> \n> To protect from this, Rails stores two copies of a random token (the so-named CSRF token) on each request:\n> - one copy embedded in each HTML page,\n> - another copy in the user session.\n> \n> When performing a POST request, Rails checks that the two copies match \u2013 and otherwise denies the request. This protects against an attacker that would generate a form secretly pointing to our website: the attacker can't read the token in the session, and so can't post a form with a valid token.\n> \n> The problem is that, much more often, this has false positives. There are several cases for that, including:\n> \n> 1. The web browser (often mobile) loads a page containing a form, then is closed by the user. Later, when the browser is re-opened, it restores the page from the cache. But the session cookie has expired, and so is not restored \u2013 so the copy of the CSRF token stored in the session is missing. When the user submits the form, they get an \"InvalidAuthenticityToken\" exception.\n> \n> 2. The user attempts to fill a form, and gets an error message (usually in response to a POST request). They close the browser. When the browser is re-opened, it attempts to restore the page. On Chrome this is blocked by the browser, because the browser denies retrying a (probably non-idempotent) POST request. Safari however happily retries the POST request \u2013 but without sending any cookies (in an attempt to avoid having unexpected side-effects). So the copy of the CSRF token in the session is missing (because no cookie was sent), and the user get an \"InvalidAuthenticityToken\" exception.\n> \n> ## Options considered\n> \n> ### Extend the session cookie duration\n> \n> We can configure the session cookie to be valid for a longer time (like 2 weeks).\n> \n> Pros:\n> - It solves 1., because when the browser restores the page, the session cookie is still valid.\n> \n> Cons:\n> - Users would be signed-in for a much longer time by default, which has unacceptable security implications.\n> - It doesn't solve 2. (because Safari doesn't send any cookie when restoring a page from a POST request)\n> \n> ### Change the cache parameters\n> \n> We can send a HTTP cache header stating 'Cache-Control: no-store, no-cache'. This instructs the browser to never keep any copy of the page, and to always make a request to the server to restore it.\n> \n> This solution was attempted during a year in production, and solved 1. \u2013 but also introduced another type of InvalidAuthenticityToken errors. In that scenario, the user attempts to fill a form, and gets an error message (usually in response to a POST request). They then navigate on another domain (like France Connect), then hit the \"Back\" button. Crossing back the domain boundary may cause the browser to either block the request or retry an invalid POST request.\n> \n> Pros:\n> - It solves 1., because on relaunch the browser requests a fresh page again (instead of serving it from its cache), thus retrieving a fresh session and a fresh matching CSRF token.\n> \n> Cons:\n> - It doesn't solve 2.\n> - It causes another type of InvalidAuthenticityToken errors.\n> \n> ### Using a null-session strategy\n> \n> We can change the default protect_from_forgery strategy to :null_session. This makes the current request use an empty session for the request duration.\n> \n> Pros:\n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted.\n> \n> Cons:\n> - The user is asked to sign-in only after filling and submitting the form, losing their time and data\n> - The user will not be redirected to their original page after signing-in\n> - It has potential security implications: as the (potentically malicious) request runs anyway, variables cached by a controller before the Null session is created may allow the form submission to succeed anyway (https://www.veracode.com/blog/managing-appsec/when-rails-protectfromforgery-fails)\n> \n> ### Using a reset-session strategy\n> \n> We can change the default protect_from_forgery strategy to :reset_session. This clears the user session permanently, logging them out until they log in again.\n> \n> Pros: \n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted.\n> \n> Cons:\n> - A forgery error in a browser tab will disconnect the user in all its open tabs\n> - It has potential security implications: as the (potentically malicious) request runs anyway, variables cached by a controller before the Null session is created may allow the form submission to succeed anyway (https://www.veracode.com/blog/managing-appsec/when-rails-protectfromforgery-fails)\n> - It allows an attacker to disconnect an user on demand, which is not only inconvenient, but also has security implication (the attacker could then log the user on it's own attacker account, pretending to be the user account)\n> \n> ### Redirect to login form\n> \n> When a forgery error occurs, we can instead redirect to the login form.\n> \n> Pros:\n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted (but the user data is lost).\n> - It kind of solves 2., by redirecting to a \"Please sign-in\" page when a previously POSTed form is reloaded.\n> \n> Cons:\n> - Not all forms require authentication \u2013 so for public forms there is no point redirecting to the login form. \n> - The user will not be redirected to their original page after signing-in (because setting the redirect path is a state-changing action, and it is dangerous to let an unauthorized request changing the state \u2013 an attacker could control the path where an user is automatically redirected to.)\n> - The implementation is finicky, and may introduce security errors. For instance, a naive implementation that catches the exception and redirect_to the sign-in page will prevent Devise from running a cleanup code \u2013 which means the user will still be logged, and the CSRF protection is bypassed. However a well-tested implementation that lets Devise code run should avoid these pittfalls.\n> \n> ### Using a long-lived cookie for CSRF tokens\n> \n> Instead of storing the CSRF token in the session cookie (which is deleted when the browser is closed), we can instead store it in a longer-lived cookie. For this we need to patch Rails.\n> \n> Pros:\n> - It solves 1., because when the user submits a stale form, even if the session cookie because stale, the long-lived CSRF cookie is still valid.\n> \n> Cons:\n> - It doesn't solve 2., because when Safari retries a POST request, it sends none of the cookies (not even long-lived ones).\n> - Patching Rails may introduce security issues (now or in the future)\n\n#### Broken behavior due to session expiration + template cache\n\nAlthough pretty unlikely, you should make sure that your current setup for cache/session expiration is compatible. The upgrade can break the addition of products to the cart if both:\n\n- The \"Add to cart\" form is being cached (usually along with the variant information).\n\n- A user session is reset at every or every few requests.\n\nThe token validation depends on the issuing and consuming sessions being the same. If a product page is cached with the token in it, it can become stale on a subsequent rendering if the session changes.\n\nTo check that you're safe, after having upgraded locally, go through the following steps:\n\n- Enable cache on dev mode:\n\n  ```bash\n  bin/rails dev:cache\n  ```\n\n- Visit the page for a variant with stock.\n\n- Reload that page several times.\n\n- Click on the \"Add to cart\"  button.\n\n- Remember to rerun `bin/rails dev:cache` to turn off cache again.\n\nNo error or session reset should happen.\n\nOtherwise, you can try with:\n\n- Revisiting how your session gets expired.\n- Changing the caching strategy to exclude the token.\n\n#### Using weaker CSRF protection strategies\n\nIt's also important to understand that a complete fix will only be in place when using the `:exception` forgery protection strategy. The `solidus_frontend` engine can't do pretty much anything otherwise. Using weaker CSRF strategies should be an informed and limited decision made by the application team. After the upgrade:\n\n- An app using `:null_session` should also be safe, but there will be side effects. That strategy runs with a null object session. As such, no order and no user is found on it. A new `cart` state order is created in the database, associated with no user. Next time the user visits the site, they won't find any difference in its cart state.\n\n- An app using `:reset_session` is not entirely safe. That strategy resets the session. That means that registered users will be logged out. Next time a user visits, they'll see the cart with the items added during the CSRF attack, although it won't be associated with their account in the case of registered users.\n\n#### Reversing the update\n\nIf you still want to deploy the upgraded version before changing your application code (if the latter is needed), you can add the following workaround to your `config/application.rb` (however, take into account that you'll keep being vulnerable):\n\n```ruby\nconfig.after_initialize do\n  Spree::OrdersController.skip_before_action :verify_authenticity_token, only: [:populate]\nend\n```\n\n### Workarounds\n\nIf an upgrade is not an option, you can work around the issue by adding the following to `config/application.rb`:\n\n```ruby\nconfig.after_initialize do\n  Spree::OrdersController.protect_from_forgery with: ApplicationController.forgery_protection_strategy.name.demodulize.underscore.to_sym, only: [:populate]\nend\n```\n\nHowever, go through the same safety check detailed on \"Upgrade notes\" above.\n\n### References\n\n- [CSRF on the Rails guides](https://guides.rubyonrails.org/security.html#cross-site-request-forgery-csrf)\n- [How CSRF tokens are generated and validated on Rails](https://medium.com/rubyinside/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef)\n- [Solidus security](https://solidus.io/security/)\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an [issue](https://github.com/solidusio/solidus/issues) or a [discussion](https://github.com/solidusio/solidus/discussions) in Solidus.\n* Email us at [security@solidus.io](mailto:security@soliidus.io)\n* Contact the core team on [Slack](http://slack.solidus.io/)",
      "published_date": "2022-01-06",
      "chain_len": 2,
      "project": "https://github.com/solidusio/solidus",
      "commit_href": "https://github.com/solidusio/solidus/commit/4d17cacf066d9492fc04eb3a0b16084b47376d81",
      "commit_sha": "4d17cacf066d9492fc04eb3a0b16084b47376d81",
      "patch": "MULTI",
      "chain_ord": "['4d17cacf066d9492fc04eb3a0b16084b47376d81', 'a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6']",
      "before_first_fix_commit": "{'4d17cacf066d9492fc04eb3a0b16084b47376d81', 'c6b892696881f88d209efaedd8bb378e8261953f'}",
      "last_fix_commit": "a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/14/2021, 09:36:44",
      "message": "Protect `Spree::OrdersController#populate` against CSRF attacks\n\nSee\nhttps://github.com/solidusio/solidus/security/advisories/GHSA-h3fg-h5v3-vf8m\nfor all the details.\n\nSome time ago, all order actions were left out of CSRF protection (see\n95ea57058ab1c5e722b327b10747cd41e68a4deb). The reason given was that the\nauthentication token got stale after the second rendering because the\nproduct page is cached. That was limited to `#populate` in\ncb797542c6948ef33d2cc9e6076c88f4cc927fb2 (see also\nhttps://github.com/spree/spree/pull/5601).\n\nHowever, those assumptions are not correct. Although the authenticity\ntoken changes at every request, that doesn't mean that the old ones are\nno longer valid. The variation comes from a one-time pad added to a\nsession-dependant token (and meant to avoid timing attacks). However,\nbefore validation, that one-time pad is removed. That means the token\nremains valid as long as the session has not been reset. Think about\nsubmitting a form from one browser tab after opening another with the\nsame URL. Even if both tokens differ, the submission from the first tab\nwill still be valid. You can read\nhttps://medium.com/rubyinside/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef\nfor an in-deep understanding.\n\nThe initial confusion could come because of\nhttps://github.com/rails/rails/issues/21948. Due to browser-side cache,\na form can be re-rendered and sent without any attached request cookie.\nThat will cause an authentication error, as the sent token won't match\nwith the one in the session (none in this case). There's no perfect\nsolution for that, and all partial fixes should be seen at the\napplication level. From our side, we must provide a safe default. For an\nexcellent survey of all the available options, take a look at\nhttps://github.com/betagouv/demarches-simplifiees.fr/blob/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9/doc/adr-csrf-forgery.md.\nThe information given in that link is third-party but it's very\nrelevant here. For that reason we've copied it in the security advisory\n(see link above), but all the credit goes to @kemenaran.",
      "author": "Marc Busqu\u00e9",
      "comments": null,
      "stats": "{'additions': 0, 'deletions': 1, 'total': 1}",
      "files": "{'frontend/app/controllers/spree/orders_controller.rb': {'additions': 0, 'deletions': 1, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/solidusio/solidus/raw/4d17cacf066d9492fc04eb3a0b16084b47376d81/frontend%2Fapp%2Fcontrollers%2Fspree%2Forders_controller.rb', 'patch': \"@@ -10,7 +10,6 @@ class OrdersController < Spree::StoreController\\n     before_action :assign_order, only: :update\\n     # note: do not lock the #edit action because that's where we redirect when we fail to acquire a lock\\n     around_action :lock_order, only: :update\\n-    skip_before_action :verify_authenticity_token, only: [:populate]\\n \\n     def show\\n       @order = Spree::Order.find_by!(number: params[:id])\"}}",
      "message_norm": "protect `spree::orderscontroller#populate` against csrf attacks\n\nsee\nhttps://github.com/solidusio/solidus/security/advisories/ghsa-h3fg-h5v3-vf8m\nfor all the details.\n\nsome time ago, all order actions were left out of csrf protection (see\n95ea57058ab1c5e722b327b10747cd41e68a4deb). the reason given was that the\nauthentication token got stale after the second rendering because the\nproduct page is cached. that was limited to `#populate` in\ncb797542c6948ef33d2cc9e6076c88f4cc927fb2 (see also\nhttps://github.com/spree/spree/pull/5601).\n\nhowever, those assumptions are not correct. although the authenticity\ntoken changes at every request, that doesn't mean that the old ones are\nno longer valid. the variation comes from a one-time pad added to a\nsession-dependant token (and meant to avoid timing attacks). however,\nbefore validation, that one-time pad is removed. that means the token\nremains valid as long as the session has not been reset. think about\nsubmitting a form from one browser tab after opening another with the\nsame url. even if both tokens differ, the submission from the first tab\nwill still be valid. you can read\nhttps://medium.com/rubyinside/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef\nfor an in-deep understanding.\n\nthe initial confusion could come because of\nhttps://github.com/rails/rails/issues/21948. due to browser-side cache,\na form can be re-rendered and sent without any attached request cookie.\nthat will cause an authentication error, as the sent token won't match\nwith the one in the session (none in this case). there's no perfect\nsolution for that, and all partial fixes should be seen at the\napplication level. from our side, we must provide a safe default. for an\nexcellent survey of all the available options, take a look at\nhttps://github.com/betagouv/demarches-simplifiees.fr/blob/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9/doc/adr-csrf-forgery.md.\nthe information given in that link is third-party but it's very\nrelevant here. for that reason we've copied it in the security advisory\n(see link above), but all the credit goes to @kemenaran.",
      "language": "en",
      "entities": "[('protect', 'ACTION', ''), ('csrf', 'SECWORD', ''), ('attacks', 'FLAW', ''), ('https://github.com/solidusio/solidus/security/advisories/ghsa-h3fg-h5v3-vf8m', 'VULNID', 'GHSA'), ('csrf', 'SECWORD', ''), ('protection', 'SECWORD', ''), ('95ea57058ab1c5e722b327b10747cd41e68a4deb', 'SHA', 'generic_sha'), ('authentication', 'SECWORD', ''), ('cb797542c6948ef33d2cc9e6076c88f4cc927fb2', 'SHA', 'generic_sha'), ('https://github.com/spree/spree/pull/5601', 'URL', ''), ('added', 'ACTION', ''), ('attacks', 'SECWORD', ''), ('removed', 'ACTION', ''), ('https://medium.com/rubyinside/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef', 'SECWORD', ''), ('https://github.com/rails/rails/issues/21948', 'URL', ''), ('cookie', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('error', 'FLAW', ''), ('safe', 'SECWORD', ''), ('https://github.com/betagouv/demarches-simplifiees.fr/blob/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9/doc/adr-csrf-forgery.md', 'SECWORD', ''), ('security', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['frontend/app/controllers/spree/orders_controller.rb'])",
      "num_files": 1.0
    },
    {
      "index": 302,
      "vuln_id": "GHSA-3qgw-p4fm-x7gf",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/ff489d95a9006be080ad14feb378f2b4dac35552'}",
      "dataset": "osv",
      "summary": "Division by zero in TFLite's convolution code ### Impact\nTFLite's [convolution code](https://github.com/tensorflow/tensorflow/blob/09c73bca7d648e961dd05898292d91a8322a9d45/tensorflow/lite/kernels/conv.cc) has multiple division where the divisor is controlled by the user and not checked to be non-zero. For example:\n\n```cc \nconst int input_size = NumElements(input) / SizeOfDimension(input, 0);\n```\n\n### Patches\nWe have patched the issue in GitHub commit [ff489d95a9006be080ad14feb378f2b4dac35552](https://github.com/tensorflow/tensorflow/commit/ff489d95a9006be080ad14feb378f2b4dac35552).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/ff489d95a9006be080ad14feb378f2b4dac35552",
      "commit_sha": "ff489d95a9006be080ad14feb378f2b4dac35552",
      "patch": "SINGLE",
      "chain_ord": "['ff489d95a9006be080ad14feb378f2b4dac35552']",
      "before_first_fix_commit": "{'09c73bca7d648e961dd05898292d91a8322a9d45'}",
      "last_fix_commit": "ff489d95a9006be080ad14feb378f2b4dac35552",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 19:37:35",
      "message": "Prevent division by 0.\n\nPiperOrigin-RevId: 370962554\nChange-Id: I0b9b62f4d8e1046dd88f9433f8dfeaf61a901680",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 2, 'total': 8}",
      "files": "{'tensorflow/lite/kernels/conv.cc': {'additions': 6, 'deletions': 2, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/ff489d95a9006be080ad14feb378f2b4dac35552/tensorflow%2Flite%2Fkernels%2Fconv.cc', 'patch': '@@ -545,6 +545,7 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\\n     // Only one scale factor per batch is typically necessary. See optimized\\n     // implementation for why we need to allocate for the height of the inputs\\n     // flattened to 2D.\\n+    TF_LITE_ENSURE(context, channels_in != 0);\\n     const int height = NumElements(input) / channels_in;\\n     int scaling_dims[1] = {height};\\n     if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\\n@@ -587,6 +588,7 @@ TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\\n       input_offsets->type = kTfLiteInt32;\\n       input_offsets->allocation_type = kTfLiteArenaRw;\\n       // See above comment for the need to allocate for height of inputs.\\n+      TF_LITE_ENSURE(context, channels_in != 0);\\n       const int height = NumElements(input) / channels_in;\\n       const int input_offset_dims[1] = {height};\\n       if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1,\\n@@ -886,8 +888,9 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\\n   CalculateActivationRange(params->activation, &output_activation_min,\\n                            &output_activation_max);\\n \\n-  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\\n   const int batch_size = SizeOfDimension(input, 0);\\n+  TF_LITE_ENSURE(context, batch_size != 0);\\n+  const int input_size = NumElements(input) / batch_size;\\n   TfLiteTensor* quantized_input_tensor;\\n   TF_LITE_ENSURE_OK(context,\\n                     GetTemporarySafe(context, node, data->input_quantized_index,\\n@@ -989,8 +992,9 @@ TfLiteStatus EvalHybrid(TfLiteContext* context, TfLiteNode* node,\\n   CalculateActivationRange(params->activation, &output_activation_min,\\n                            &output_activation_max);\\n \\n-  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\\n   const int batch_size = SizeOfDimension(input, 0);\\n+  TF_LITE_ENSURE(context, batch_size != 0);\\n+  const int input_size = NumElements(input) / batch_size;\\n \\n   const float* input_ptr = GetTensorData<float>(input);\\n   TfLiteTensor* quantized_input_tensor;'}}",
      "message_norm": "prevent division by 0.\n\npiperorigin-revid: 370962554\nchange-id: i0b9b62f4d8e1046dd88f9433f8dfeaf61a901680",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('370962554', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/conv.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2338,
      "vuln_id": "GHSA-m3f9-w3p3-p669",
      "cwe_id": "{'CWE-787', 'CWE-131'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/efea03b38fb8d3b81762237dc85e579cc5fc6e87'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `QuantizedMul` ### Impact\nAn attacker can cause a heap buffer overflow in `QuantizedMul` by passing in invalid thresholds for the quantization:\n\n```python\nimport tensorflow as tf\n\nx = tf.constant([256, 328], shape=[1, 2], dtype=tf.quint8)\ny = tf.constant([256, 328], shape=[1, 2], dtype=tf.quint8)\nmin_x = tf.constant([], dtype=tf.float32)\nmax_x = tf.constant([], dtype=tf.float32)\nmin_y = tf.constant([], dtype=tf.float32)\nmax_y = tf.constant([], dtype=tf.float32)\n\ntf.raw_ops.QuantizedMul(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/87cf4d3ea9949051e50ca3f071fc909538a51cd0/tensorflow/core/kernels/quantized_mul_op.cc#L287-L290) assumes that the 4 arguments are always valid scalars and tries to access the numeric value directly:\n\n```cc \nconst float min_x = context->input(2).flat<float>()(0);\nconst float max_x = context->input(3).flat<float>()(0);\nconst float min_y = context->input(4).flat<float>()(0);\nconst float max_y = context->input(5).flat<float>()(0);\n```\n\nHowever, if any of these tensors is empty, then `.flat<T>()` is an empty buffer and accessing the element at position 0 results in overflow.\n\n### Patches\nWe have patched the issue in GitHub commit [efea03b38fb8d3b81762237dc85e579cc5fc6e87](https://github.com/tensorflow/tensorflow/commit/efea03b38fb8d3b81762237dc85e579cc5fc6e87).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/efea03b38fb8d3b81762237dc85e579cc5fc6e87",
      "commit_sha": "efea03b38fb8d3b81762237dc85e579cc5fc6e87",
      "patch": "SINGLE",
      "chain_ord": "['efea03b38fb8d3b81762237dc85e579cc5fc6e87']",
      "before_first_fix_commit": "{'87cf4d3ea9949051e50ca3f071fc909538a51cd0'}",
      "last_fix_commit": "efea03b38fb8d3b81762237dc85e579cc5fc6e87",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/21/2021, 23:15:46",
      "message": "Validate inputs to `QuantizedMul`\n\nPiperOrigin-RevId: 369756982\nChange-Id: I00d960cc3b9316fd7a86bd37a44e341c96e17624",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 16, 'deletions': 4, 'total': 20}",
      "files": "{'tensorflow/core/kernels/quantized_mul_op.cc': {'additions': 16, 'deletions': 4, 'changes': 20, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/efea03b38fb8d3b81762237dc85e579cc5fc6e87/tensorflow%2Fcore%2Fkernels%2Fquantized_mul_op.cc', 'patch': '@@ -284,10 +284,22 @@ class QuantizedMulOp : public OpKernel {\\n   void Compute(OpKernelContext* context) override {\\n     const Tensor& x = context->input(0);\\n     const Tensor& y = context->input(1);\\n-    const float min_x = context->input(2).flat<float>()(0);\\n-    const float max_x = context->input(3).flat<float>()(0);\\n-    const float min_y = context->input(4).flat<float>()(0);\\n-    const float max_y = context->input(5).flat<float>()(0);\\n+    auto& min_x_tensor = context->input(2);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\\n+                errors::InvalidArgument(\"min_x must be a scalar\"));\\n+    const float min_x = min_x_tensor.flat<float>()(0);\\n+    auto& max_x_tensor = context->input(3);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\\n+                errors::InvalidArgument(\"max_x must be a scalar\"));\\n+    const float max_x = max_x_tensor.flat<float>()(0);\\n+    auto& min_y_tensor = context->input(4);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\\n+                errors::InvalidArgument(\"min_y must be a scalar\"));\\n+    const float min_y = min_y_tensor.flat<float>()(0);\\n+    auto& max_y_tensor = context->input(5);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\\n+                errors::InvalidArgument(\"max_y must be a scalar\"));\\n+    const float max_y = max_y_tensor.flat<float>()(0);\\n \\n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\\n     if (!bcast.IsValid()) {'}}",
      "message_norm": "validate inputs to `quantizedmul`\n\npiperorigin-revid: 369756982\nchange-id: i00d960cc3b9316fd7a86bd37a44e341c96e17624",
      "language": "it",
      "entities": "[('validate', 'ACTION', ''), ('369756982', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/quantized_mul_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2100,
      "vuln_id": "GHSA-hp68-xhvj-x6j6",
      "cwe_id": "{'CWE-400'}",
      "score": 5.3,
      "chain": "{'https://github.com/yhatt/jsx-slack/commit/46bc88391d89d5fda4ce689e18ca080bcdd29ecc'}",
      "dataset": "osv",
      "summary": "jsx-slack insufficient patch for CVE-2021-43838 ReDoS We found the patch for CVE-2021-43838 in jsx-slack v4.5.1 is insufficient to save from Regular Expression Denial of Service (ReDoS) attack.\n\nThis vulnerability affects to jsx-slack v4.5.1 and earlier versions.\n\n### Impact\n\nIf attacker can put a lot of JSX elements into `<blockquote>` tag _with including multibyte characters_, an internal regular expression for escaping characters may consume an excessive amount of computing resources.\n\n```javascript\n/** @jsxImportSource jsx-slack */\nimport { Section } from 'jsx-slack'\n\nconsole.log(\n  <Section>\n    <blockquote>\n      {[...Array(40)].map(() => (\n        <p>\u4e9c</p>\n      ))}\n    </blockquote>\n  </Section>\n)\n```\n\nv4.5.1 has released by passing the test against ASCII characters but missed the case of multibyte characters.\nhttps://github.com/yhatt/jsx-slack/security/advisories/GHSA-55xv-f85c-248q\n\n### Patches\n\njsx-slack v4.5.2 has updated regular expressions for escaping blockquote characters to prevent catastrophic backtracking. It is also including an updated test case to confirm rendering multiple tags in `<blockquote>` with multibyte characters.\n\n### References\n\n- https://github.com/yhatt/jsx-slack/commit/46bc88391d89d5fda4ce689e18ca080bcdd29ecc\n\n### Credits\n\nThanks to @hieki for finding out this vulnerability.",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/yhatt/jsx-slack",
      "commit_href": "https://github.com/yhatt/jsx-slack/commit/46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
      "commit_sha": "46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
      "patch": "SINGLE",
      "chain_ord": "['46bc88391d89d5fda4ce689e18ca080bcdd29ecc']",
      "before_first_fix_commit": "{'c3722705c8aadf544f922a974883578aa27dbea3'}",
      "last_fix_commit": "46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/18/2021, 07:03:24",
      "message": "Prevent catastrophic backtracking in blockquote escape replacer",
      "author": "Yuki Hattori",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 6, 'total': 13}",
      "files": "{'src/mrkdwn/escape.ts': {'additions': 7, 'deletions': 6, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/yhatt/jsx-slack/raw/46bc88391d89d5fda4ce689e18ca080bcdd29ecc/src%2Fmrkdwn%2Fescape.ts', 'patch': '@@ -1,20 +1,21 @@\\n // An internal HTML tag and emoji shorthand should not escape\\n const preventEscapeRegex =\\n-  /(<.*?>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b\\'\\\\u1100-\\\\u11ff\\\\u2e80-\\\\u2fd5\\\\u3005\\\\u3041-\\\\u3096\\\\u30a0-\\\\u30ff\\\\u3130-\\\\u318f\\\\u3400-\\\\u4db5\\\\u4e00-\\\\u9fcb\\\\ua960-\\\\ua97f\\\\uac00-\\\\ud7ff\\\\uff10-\\\\uff19\\\\uff41-\\\\uff5a\\\\uff61-\\\\uff9f]+:)/\\n+  /(<[^>]*>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b\\'\\\\u1100-\\\\u11ff\\\\u2e80-\\\\u2fd5\\\\u3005\\\\u3041-\\\\u3096\\\\u30a0-\\\\u30ff\\\\u3130-\\\\u318f\\\\u3400-\\\\u4db5\\\\u4e00-\\\\u9fcb\\\\ua960-\\\\ua97f\\\\uac00-\\\\ud7ff\\\\uff10-\\\\uff19\\\\uff41-\\\\uff5a\\\\uff61-\\\\uff9f]+:)/\\n \\n const generateReplacerForEscape = (fallback: string) => (matched: string) =>\\n   `<span data-escape=\"${fallback.repeat(matched.length)}\">${matched}</span>`\\n \\n export const escapeReplacers = {\\n   blockquote: (partial: string) =>\\n     partial\\n-      .replace(/^((?:<.*?>)*)(.{4})/gm, (matched, leading, character) =>\\n-        character === \\'&gt;\\' ? `${leading}\\\\u00ad&gt;` : matched\\n+      .replace(\\n+        /^((?:<(?:[^>]|>(?=<))*>)?)(&gt;)/gm,\\n+        (_, leadingTags, character) => `${leadingTags}\\\\u00ad${character}`\\n       )\\n       .replace(\\n-        /^((?:<.*?>)*)(\uff1e)/gm,\\n-        (_, leading, character) =>\\n-          `${leading}${generateReplacerForEscape(\\'\\\\u00ad\uff1e\\')(character)}`\\n+        /^((?:<(?:[^>]|>(?=<))*>)?)(\uff1e)/gm,\\n+        (_, leadingTags, character) =>\\n+          `${leadingTags}${generateReplacerForEscape(\\'\\\\u00ad\uff1e\\')(character)}`\\n       ),\\n   bold: (partial: string) =>\\n     partial'}}",
      "message_norm": "prevent catastrophic backtracking in blockquote escape replacer",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/mrkdwn/escape.ts'])",
      "num_files": 1.0
    },
    {
      "index": 3109,
      "vuln_id": "GHSA-vfrc-ggmc-5jwv",
      "cwe_id": "{'CWE-79'}",
      "score": 8.8,
      "chain": "{'https://github.com/django-helpdesk/django-helpdesk/commit/04483bdac3b5196737516398b5ce0383875a5c60'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in django-helpdesk django-helpdesk is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
      "published_date": "2021-11-23",
      "chain_len": 1,
      "project": "https://github.com/django-helpdesk/django-helpdesk",
      "commit_href": "https://github.com/django-helpdesk/django-helpdesk/commit/04483bdac3b5196737516398b5ce0383875a5c60",
      "commit_sha": "04483bdac3b5196737516398b5ce0383875a5c60",
      "patch": "SINGLE",
      "chain_ord": "['04483bdac3b5196737516398b5ce0383875a5c60']",
      "before_first_fix_commit": "{'2c7065e0c4296e0c692fb4a7ee19c7357583af30'}",
      "last_fix_commit": "04483bdac3b5196737516398b5ce0383875a5c60",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/18/2021, 03:42:02",
      "message": "Add `att.full_clean()` before saving\n\nFix issue https://github.com/django-helpdesk/django-helpdesk/issues/983\r\nAlso, fix bug stored XSS disclosure: https://huntr.dev/bounties/4d7a5fdd-b2de-467a-ade0-3f2fb386638e/",
      "author": "lethanhphuc",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'helpdesk/lib.py': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/django-helpdesk/django-helpdesk/raw/04483bdac3b5196737516398b5ce0383875a5c60/helpdesk%2Flib.py', 'patch': \"@@ -145,6 +145,7 @@ def process_attachments(followup, attached_files):\\n                 'application/octet-stream',\\n                 size=attached.size,\\n             )\\n+            att.full_clean()\\n             att.save()\\n \\n             if attached.size < max_email_attachment_size:\"}}",
      "message_norm": "add `att.full_clean()` before saving\n\nfix issue https://github.com/django-helpdesk/django-helpdesk/issues/983\r\nalso, fix bug stored xss disclosure: https://huntr.dev/bounties/4d7a5fdd-b2de-467a-ade0-3f2fb386638e/",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('issue', 'FLAW', ''), ('https://github.com/django-helpdesk/django-helpdesk/issues/983', 'URL', ''), ('fix', 'ACTION', ''), ('bug', 'FLAW', ''), ('xss', 'SECWORD', ''), ('disclosure', 'SECWORD', ''), ('https://huntr.dev/bounties/4d7a5fdd-b2de-467a-ade0-3f2fb386638e/', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['helpdesk/lib.py'])",
      "num_files": 1.0
    },
    {
      "index": 859,
      "vuln_id": "GHSA-6jp6-9rf9-gc66",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/WeblateOrg/weblate/commit/9e19a8414337692cc90da2a91c9af5420f2952f1', 'https://github.com/WeblateOrg/weblate/commit/f6753a1a1c63fade6ad418fbda827c6750ab0bda', 'https://github.com/WeblateOrg/weblate/commit/22d577b1f1e88665a88b4569380148030e0f8389'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in Weblate ### Impact\nDue to improper neutralization, it was possible to perform cross-site scripting via crafted user and language names.\n\n### Patches\n\nThe issues were fixed in the 4.11 release. The following commits are addressing it:\n\n* f6753a1a1c63fade6ad418fbda827c6750ab0bda\n* 9e19a8414337692cc90da2a91c9af5420f2952f1\n* 22d577b1f1e88665a88b4569380148030e0f8389\n\n### Workarounds\n\nYou can look for crafted user and language names to see if you were affected.\n\n### References\n* https://hackerone.com/reports/1486674\n* https://hackerone.com/reports/1486718\n* https://hackerone.com/reports/1485226\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open a topic in [discussions](https://github.com/WeblateOrg/weblate/discussions)\n* Email us at [care@weblate.org](mailto:care@weblate.org)",
      "published_date": "2022-02-25",
      "chain_len": 3,
      "project": "https://github.com/WeblateOrg/weblate",
      "commit_href": "https://github.com/WeblateOrg/weblate/commit/f6753a1a1c63fade6ad418fbda827c6750ab0bda",
      "commit_sha": "f6753a1a1c63fade6ad418fbda827c6750ab0bda",
      "patch": "MULTI",
      "chain_ord": "['22d577b1f1e88665a88b4569380148030e0f8389', '9e19a8414337692cc90da2a91c9af5420f2952f1', 'f6753a1a1c63fade6ad418fbda827c6750ab0bda']",
      "before_first_fix_commit": "{'572628cef60e9d839b79b2087960b606a5cca4d8'}",
      "last_fix_commit": "f6753a1a1c63fade6ad418fbda827c6750ab0bda",
      "chain_ord_pos": 3.0,
      "commit_datetime": "02/22/2022, 20:10:41",
      "message": "translate: Add missing escaping to language name\n\nFixes https://hackerone.com/reports/1486674",
      "author": "Michal \u010ciha\u0159",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 1, 'total': 3}",
      "files": "{'weblate/trans/forms.py': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/WeblateOrg/weblate/raw/f6753a1a1c63fade6ad418fbda827c6750ab0bda/weblate%2Ftrans%2Fforms.py', 'patch': '@@ -37,6 +37,7 @@\\n from django.template.loader import render_to_string\\n from django.urls import reverse\\n from django.utils import timezone\\n+from django.utils.html import escape\\n from django.utils.http import urlencode\\n from django.utils.safestring import mark_safe\\n from django.utils.translation import gettext\\n@@ -318,7 +319,7 @@ def render(self, name, value, attrs=None, renderer=None, **kwargs):\\n             # Render textare\\n             textarea = super().render(fieldname, val, attrs, renderer, **kwargs)\\n             # Label for plural\\n-            label = str(unit.translation.language)\\n+            label = escape(unit.translation.language)\\n             if len(values) != 1:\\n                 label = f\"{label}, {plural.get_plural_label(idx)}\"\\n             ret.append('}}",
      "message_norm": "translate: add missing escaping to language name\n\nfixes https://hackerone.com/reports/1486674",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('escaping', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('https://hackerone.com/reports/1486674', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['weblate/trans/forms.py'])",
      "num_files": 1.0
    },
    {
      "index": 1210,
      "vuln_id": "GHSA-8gv3-57p6-g35r",
      "cwe_id": "{'CWE-787', 'CWE-125'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/a84358aa12f0b1518e606095ab9cfddbf597c121'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `RaggedTensorToTensor` ### Impact\nAn attacker can cause a heap buffer overflow in `tf.raw_ops.RaggedTensorToTensor`:\n\n```python\nimport tensorflow as tf\n\nshape = tf.constant([10, 10], shape=[2], dtype=tf.int64)\nvalues = tf.constant(0, shape=[1], dtype=tf.int64)\ndefault_value = tf.constant(0, dtype=tf.int64)\nl = [849, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nrow = tf.constant(l, shape=[5, 43], dtype=tf.int64)\nrows = [row]\ntypes = ['ROW_SPLITS']\n\ntf.raw_ops.RaggedTensorToTensor(\n    shape=shape, values=values, default_value=default_value,\n    row_partition_tensors=rows, row_partition_types=types) \n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/d94227d43aa125ad8b54115c03cece54f6a1977b/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L219-L222) uses the same index to access two arrays in parallel:\n\n```cc\nfor (INDEX_TYPE i = 0; i < row_split_size - 1; ++i) {\n  INDEX_TYPE row_length = row_split(i + 1) - row_split(i);\n  INDEX_TYPE real_length = std::min(output_size, row_length);\n  INDEX_TYPE parent_output_index_current = parent_output_index[i];\n  ...\n}\n```\n\nSince the user controls the shape of the input arguments, an attacker could trigger a heap OOB access when `parent_output_index` is shorter than `row_split`.\n\n### Patches\nWe have patched the issue in GitHub commit [a84358aa12f0b1518e606095ab9cfddbf597c121](https://github.com/tensorflow/tensorflow/commit/a84358aa12f0b1518e606095ab9cfddbf597c121).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/a84358aa12f0b1518e606095ab9cfddbf597c121",
      "commit_sha": "a84358aa12f0b1518e606095ab9cfddbf597c121",
      "patch": "SINGLE",
      "chain_ord": "['a84358aa12f0b1518e606095ab9cfddbf597c121']",
      "before_first_fix_commit": "{'d94227d43aa125ad8b54115c03cece54f6a1977b'}",
      "last_fix_commit": "a84358aa12f0b1518e606095ab9cfddbf597c121",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/04/2021, 20:45:57",
      "message": "Fix heap-buffer-overflow issue with `tf.raw_ops.RaggedTensorToTensor`.\n\nPiperOrigin-RevId: 371986929\nChange-Id: I79ab962a22c5867f36f7f45b780a1ac881b1dbdd",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/a84358aa12f0b1518e606095ab9cfddbf597c121/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_tensor_op.cc', 'patch': '@@ -313,6 +313,12 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n             output_index_multiplier, output_size, result);\\n         return tensorflow::Status::OK();\\n       case RowPartitionType::ROW_SPLITS:\\n+        if (row_partition_tensor.size() - 1 > parent_output_index.size()) {\\n+          return errors::InvalidArgument(\\n+              \"Row partition size is greater than output size: \",\\n+              row_partition_tensor.size() - 1, \" > \",\\n+              parent_output_index.size());\\n+        }\\n         CalculateOutputIndexRowSplit(\\n             context, row_partition_tensor, parent_output_index,\\n             output_index_multiplier, output_size, result);'}}",
      "message_norm": "fix heap-buffer-overflow issue with `tf.raw_ops.raggedtensortotensor`.\n\npiperorigin-revid: 371986929\nchange-id: i79ab962a22c5867f36f7f45b780a1ac881b1dbdd",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371986929', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 621,
      "vuln_id": "GHSA-5f9h-9pjv-v6j7",
      "cwe_id": "{'CWE-22', 'CWE-548'}",
      "score": 8.6,
      "chain": "{'https://github.com/rack/rack/commit/dddb7ad18ed79ca6ab06ccc417a169fde451246e'}",
      "dataset": "osv",
      "summary": "Directory traversal in Rack::Directory app bundled with Rack A directory traversal vulnerability exists in rack < 2.2.0 that allows an attacker perform directory traversal vulnerability in the Rack::Directory app that is bundled with Rack which could result in information disclosure.",
      "published_date": "2020-07-06",
      "chain_len": 1,
      "project": "https://github.com/rack/rack",
      "commit_href": "https://github.com/rack/rack/commit/dddb7ad18ed79ca6ab06ccc417a169fde451246e",
      "commit_sha": "dddb7ad18ed79ca6ab06ccc417a169fde451246e",
      "patch": "SINGLE",
      "chain_ord": "['dddb7ad18ed79ca6ab06ccc417a169fde451246e']",
      "before_first_fix_commit": "{'16a51d8e0b64964323c3719b8154106af5cc0feb'}",
      "last_fix_commit": "dddb7ad18ed79ca6ab06ccc417a169fde451246e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/12/2020, 16:23:33",
      "message": "Use Dir.entries instead of Dir[glob] to prevent user-specified glob metacharacters\n\n[CVE-2020-8161]",
      "author": "Jack McCracken",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 2, 'total': 3}",
      "files": "{'lib/rack/directory.rb': {'additions': 1, 'deletions': 2, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/rack/rack/raw/dddb7ad18ed79ca6ab06ccc417a169fde451246e/lib%2Frack%2Fdirectory.rb', 'patch': \"@@ -106,13 +106,12 @@ def check_forbidden(path_info)\\n \\n     def list_directory(path_info, path, script_name)\\n       files = [['../', 'Parent Directory', '', '', '']]\\n-      glob = ::File.join(path, '*')\\n \\n       url_head = (script_name.split('/') + path_info.split('/')).map do |part|\\n         Rack::Utils.escape_path part\\n       end\\n \\n-      Dir[glob].sort.each do |node|\\n+      Dir.entries(path).reject { |e| e.start_with?('.') }.sort.each do |node|\\n         stat = stat(node)\\n         next unless stat\\n         basename = ::File.basename(node)\"}}",
      "message_norm": "use dir.entries instead of dir[glob] to prevent user-specified glob metacharacters\n\n[cve-2020-8161]",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('cve-2020-8161', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/rack/directory.rb'])",
      "num_files": 1.0
    },
    {
      "index": 1918,
      "vuln_id": "GHSA-gq77-3r6x-383w",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/star7th/showdoc/commit/818d7fe731f452acccacf731ce47ec27ad68049c'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in ShowDoc ShowDoc version 2.10.3 and prior is vulnerable to stored cross-site scripting. A patch is available and anticipated to be part of version 2.10.4.",
      "published_date": "2022-03-13",
      "chain_len": 1,
      "project": "https://github.com/star7th/showdoc",
      "commit_href": "https://github.com/star7th/showdoc/commit/818d7fe731f452acccacf731ce47ec27ad68049c",
      "commit_sha": "818d7fe731f452acccacf731ce47ec27ad68049c",
      "patch": "SINGLE",
      "chain_ord": "['818d7fe731f452acccacf731ce47ec27ad68049c']",
      "before_first_fix_commit": "{'85af5ab5a375ce16f991e2acb15466be4b3ba44b'}",
      "last_fix_commit": "818d7fe731f452acccacf731ce47ec27ad68049c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/08/2022, 03:48:44",
      "message": "file upload bug",
      "author": "star7th",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'server/Application/Api/Model/AttachmentModel.class.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/star7th/showdoc/raw/818d7fe731f452acccacf731ce47ec27ad68049c/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': '@@ -301,6 +301,7 @@ public function isDangerFilename($filename){\\n \\t\\t\\t|| $isDangerStr($filename , \".svg\")\\n \\t\\t\\t|| $isDangerStr($filename , \".htm\")\\n \\t\\t\\t|| $isDangerStr($filename , \"%\")\\n+\\t\\t\\t|| $isDangerStr($filename , \".xml\")\\n \\t\\t) {\\n \\t\\t\\treturn true;\\n \\t\\t}'}}",
      "message_norm": "file upload bug",
      "language": "ro",
      "entities": "[('bug', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/Application/Api/Model/AttachmentModel.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 42,
      "vuln_id": "GHSA-26cm-qrc6-mfgj",
      "cwe_id": "{'CWE-74', 'CWE-90'}",
      "score": 8.1,
      "chain": "{'https://github.com/StevenWeathers/thunderdome-planning-poker/commit/f1524d01e8a0f2d6c3db5461c742456c692dd8c1'}",
      "dataset": "osv",
      "summary": "Improper Neutralization of Special Elements used in an LDAP Query in stevenweathers/thunderdome-planning-poker ### Impact\nLDAP injection vulnerability, only affects instances with LDAP authentication enabled.\n\n### Patches\nPatch for vulnerability released with v1.16.3.\n\n### Workarounds\nDisable LDAP feature if in use\n\n### References\n[OWASP LDAP Injection Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html\n)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Thunderdome Github Repository](https://github.com/StevenWeathers/thunderdome-planning-poker)\n* Email us at [steven@weathers.me](mailto:steven@weathers.me)",
      "published_date": "2021-11-08",
      "chain_len": 1,
      "project": "https://github.com/StevenWeathers/thunderdome-planning-poker",
      "commit_href": "https://github.com/StevenWeathers/thunderdome-planning-poker/commit/f1524d01e8a0f2d6c3db5461c742456c692dd8c1",
      "commit_sha": "f1524d01e8a0f2d6c3db5461c742456c692dd8c1",
      "patch": "SINGLE",
      "chain_ord": "['f1524d01e8a0f2d6c3db5461c742456c692dd8c1']",
      "before_first_fix_commit": "{'2b9ae2e1e70e0fde47d459aa0c16b768c253e51d'}",
      "last_fix_commit": "f1524d01e8a0f2d6c3db5461c742456c692dd8c1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/02/2021, 00:48:52",
      "message": "Fix LDAP vulnerability",
      "author": "Steven Weathers",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'auth.go': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/StevenWeathers/thunderdome-planning-poker/raw/f1524d01e8a0f2d6c3db5461c742456c692dd8c1/auth.go', 'patch': '@@ -68,7 +68,7 @@ func (s *server) authAndCreateUserLdap(UserName string, UserPassword string) (*d\\n \\n \\tsearchRequest := ldap.NewSearchRequest(viper.GetString(\"auth.ldap.basedn\"),\\n \\t\\tldap.ScopeWholeSubtree, ldap.NeverDerefAliases, 0, 0, false,\\n-\\t\\tfmt.Sprintf(viper.GetString(\"auth.ldap.filter\"), UserName),\\n+\\t\\tfmt.Sprintf(viper.GetString(\"auth.ldap.filter\"), ldap.EscapeFilter(UserName)),\\n \\t\\t[]string{\"dn\", viper.GetString(\"auth.ldap.mail_attr\"), viper.GetString(\"auth.ldap.cn_attr\")},\\n \\t\\tnil,\\n \\t)'}}",
      "message_norm": "fix ldap vulnerability",
      "language": "ca",
      "entities": "[('ldap', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['auth.go'])",
      "num_files": 1.0
    },
    {
      "index": 3492,
      "vuln_id": "GHSA-xrr4-74mc-rpjc",
      "cwe_id": "{'CWE-59'}",
      "score": 7.5,
      "chain": "{'https://github.com/irmen/Pyro3/commit/554e095a62c4412c91f981e72fd34a936ac2bf1e'}",
      "dataset": "osv",
      "summary": "Pyro mishandles pid files in temporary directory locations and opening the pid file as root pyro before 3.15 unsafely handles pid files in temporary directory locations and opening the pid file as root. An attacker can use this flaw to overwrite arbitrary files via symlinks.",
      "published_date": "2018-08-21",
      "chain_len": 1,
      "project": "https://github.com/irmen/Pyro3",
      "commit_href": "https://github.com/irmen/Pyro3/commit/554e095a62c4412c91f981e72fd34a936ac2bf1e",
      "commit_sha": "554e095a62c4412c91f981e72fd34a936ac2bf1e",
      "patch": "SINGLE",
      "chain_ord": "['554e095a62c4412c91f981e72fd34a936ac2bf1e']",
      "before_first_fix_commit": "{'1df908f8e8bd3eaf0fd2f1b80d38405f6a10328d'}",
      "last_fix_commit": "554e095a62c4412c91f981e72fd34a936ac2bf1e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/01/2011, 13:32:40",
      "message": "changed pidfile location because of security vulnerability, debian bug #631912",
      "author": "irmen",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 1, 'total': 8}",
      "files": "{'Pyro/ext/daemonizer.py': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/irmen/Pyro3/raw/554e095a62c4412c91f981e72fd34a936ac2bf1e/Pyro%2Fext%2Fdaemonizer.py', 'patch': '@@ -47,7 +47,9 @@ class Daemonizer:\\n     \"\"\"\\n     def __init__(self, pidfile=None):\\n         if not pidfile:\\n-            self.pidfile = \"/tmp/%s.pid\" % self.__class__.__name__.lower()\\n+            # PID file moved out of /tmp to avoid security vulnerability\\n+            # changed by Debian maintainer per Debian bug #631912\\n+            self.pidfile = \"/var/run/pyro-%s.pid\" % self.__class__.__name__.lower()\\n         else:\\n             self.pidfile = pidfile\\n \\n@@ -121,12 +123,16 @@ def main_loop(self):\\n \\n     def process_command_line(self, argv, verbose=1):\\n         usage = \"usage:  %s  start | stop | restart | status | debug \" \\\\\\n+                \"[--pidfile=...] \" \\\\\\n                 \"(run as non-daemon)\" % os.path.basename(argv[0])\\n         if len(argv) < 2:\\n             print usage\\n             raise SystemExit\\n         else:\\n             operation = argv[1]\\n+            if len(argv) > 2 and argv[2].startswith(\\'--pidfile=\\') and \\\\\\n+                len(argv[2]) > len(\\'--pidfile=\\'):\\n+                self.pidfile = argv[2][len(\\'--pidfile=\\'):]\\n         pid = self.get_pid()\\n         if operation == \\'status\\':\\n             if self.is_process_running():'}}",
      "message_norm": "changed pidfile location because of security vulnerability, debian bug #631912",
      "language": "en",
      "entities": "[('changed', 'ACTION', ''), ('security', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('bug', 'FLAW', ''), ('#631912', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['Pyro/ext/daemonizer.py'])",
      "num_files": 1.0
    },
    {
      "index": 9,
      "vuln_id": "GHSA-23cm-x6j7-6hq3",
      "cwe_id": "{'CWE-200'}",
      "score": 5.9,
      "chain": "{'https://github.com/matrix-org/matrix-js-sdk/commit/894c24880da0e1cc81818f51c0db80e3c9fb2be9'}",
      "dataset": "osv",
      "summary": "matrix-js-sdk can be tricked into disclosing E2EE room keys to a participating homeserver ### Impact\n\nA logic error in the room key sharing functionality of matrix-js-sdk before 12.4.1 allows a malicious Matrix homeserver\u2020 participating in an encrypted room to steal room encryption keys from affected Matrix clients participating in that room. This allows the homeserver to decrypt end-to-end encrypted messages sent by affected clients.\n\n\u2020 Or anyone with access to the account of the original recipient of an encrypted message.\n\nKnown clients affected (via their use of vulnerable versions of matrix-js-sdk):\n\n- Element Web (1.8.2 and earlier)\n- Element Desktop (1.8.2 and earlier)\n- SchildiChat Web (1.7.32-sc1 and earlier)\n- SchildiChat Desktop (1.7.32-sc1 and earlier)\n- Cinny (1.2.0 and earlier)\n\n### Patch\n\nThis was fixed in https://github.com/matrix-org/matrix-js-sdk/commit/894c24880da0e1cc81818f51c0db80e3c9fb2be9.\n\n### Workarounds\nTo prevent a homeserver from being able to steal the room keys, vulnerable clients can be taken offline or signed out. If signing out, care should be taken to either set up Secure Backup or export E2E room keys in order to preserve access to past messages.",
      "published_date": "2021-09-14",
      "chain_len": 1,
      "project": "https://github.com/matrix-org/matrix-js-sdk",
      "commit_href": "https://github.com/matrix-org/matrix-js-sdk/commit/894c24880da0e1cc81818f51c0db80e3c9fb2be9",
      "commit_sha": "894c24880da0e1cc81818f51c0db80e3c9fb2be9",
      "patch": "SINGLE",
      "chain_ord": "['894c24880da0e1cc81818f51c0db80e3c9fb2be9']",
      "before_first_fix_commit": "{'f8186add92dd5f0ca2f6a1cda10bc0ece3730f86'}",
      "last_fix_commit": "894c24880da0e1cc81818f51c0db80e3c9fb2be9",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/13/2021, 11:34:48",
      "message": "Verify target device key on reshare",
      "author": "RiotRobot",
      "comments": null,
      "stats": "{'additions': 29, 'deletions': 9, 'total': 38}",
      "files": "{'src/crypto/algorithms/megolm.ts': {'additions': 29, 'deletions': 9, 'changes': 38, 'status': 'modified', 'raw_url': 'https://github.com/matrix-org/matrix-js-sdk/raw/894c24880da0e1cc81818f51c0db80e3c9fb2be9/src%2Fcrypto%2Falgorithms%2Fmegolm.ts', 'patch': '@@ -101,6 +101,13 @@ interface IPayload extends Partial<IMessage> {\\n }\\n /* eslint-enable camelcase */\\n \\n+interface SharedWithData {\\n+    // The identity key of the device we shared with\\n+    deviceKey: string;\\n+    // The message index of the ratchet we shared with that device\\n+    messageIndex: number;\\n+}\\n+\\n /**\\n  * @private\\n  * @constructor\\n@@ -115,12 +122,12 @@ interface IPayload extends Partial<IMessage> {\\n  *\\n  * @property {object} sharedWithDevices\\n  *    devices with which we have shared the session key\\n- *        userId -> {deviceId -> msgindex}\\n+ *        userId -> {deviceId -> SharedWithData}\\n  */\\n class OutboundSessionInfo {\\n     public useCount = 0;\\n     public creationTime: number;\\n-    public sharedWithDevices: Record<string, Record<string, number>> = {};\\n+    public sharedWithDevices: Record<string, Record<string, SharedWithData>> = {};\\n     public blockedDevicesNotified: Record<string, Record<string, boolean>> = {};\\n \\n     constructor(public readonly sessionId: string, public readonly sharedHistory = false) {\\n@@ -150,11 +157,11 @@ class OutboundSessionInfo {\\n         return false;\\n     }\\n \\n-    public markSharedWithDevice(userId: string, deviceId: string, chainIndex: number): void {\\n+    public markSharedWithDevice(userId: string, deviceId: string, deviceKey: string, chainIndex: number): void {\\n         if (!this.sharedWithDevices[userId]) {\\n             this.sharedWithDevices[userId] = {};\\n         }\\n-        this.sharedWithDevices[userId][deviceId] = chainIndex;\\n+        this.sharedWithDevices[userId][deviceId] = { deviceKey, messageIndex: chainIndex };\\n     }\\n \\n     public markNotifiedBlockedDevice(userId: string, deviceId: string): void {\\n@@ -572,6 +579,7 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n         payload: IPayload,\\n     ): Promise<void> {\\n         const contentMap = {};\\n+        const deviceInfoByDeviceId = new Map<string, DeviceInfo>();\\n \\n         const promises = [];\\n         for (let i = 0; i < userDeviceMap.length; i++) {\\n@@ -584,6 +592,7 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n             const userId = val.userId;\\n             const deviceInfo = val.deviceInfo;\\n             const deviceId = deviceInfo.deviceId;\\n+            deviceInfoByDeviceId.set(deviceId, deviceInfo);\\n \\n             if (!contentMap[userId]) {\\n                 contentMap[userId] = {};\\n@@ -636,7 +645,10 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n                 for (const userId of Object.keys(contentMap)) {\\n                     for (const deviceId of Object.keys(contentMap[userId])) {\\n                         session.markSharedWithDevice(\\n-                            userId, deviceId, chainIndex,\\n+                            userId,\\n+                            deviceId,\\n+                            deviceInfoByDeviceId.get(deviceId).getIdentityKey(),\\n+                            chainIndex,\\n                         );\\n                     }\\n                 }\\n@@ -719,19 +731,27 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n             logger.debug(`megolm session ${sessionId} never shared with user ${userId}`);\\n             return;\\n         }\\n-        const sentChainIndex = obSessionInfo.sharedWithDevices[userId][device.deviceId];\\n-        if (sentChainIndex === undefined) {\\n+        const sessionSharedData = obSessionInfo.sharedWithDevices[userId][device.deviceId];\\n+        if (sessionSharedData === undefined) {\\n             logger.debug(\\n                 \"megolm session ID \" + sessionId + \" never shared with device \" +\\n                 userId + \":\" + device.deviceId,\\n             );\\n             return;\\n         }\\n \\n+        if (sessionSharedData.deviceKey !== device.getIdentityKey()) {\\n+            logger.warn(\\n+                `Session has been shared with device ${device.deviceId} but with identity ` +\\n+                `key ${sessionSharedData.deviceKey}. Key is now ${device.getIdentityKey()}!`,\\n+            );\\n+            return;\\n+        }\\n+\\n         // get the key from the inbound session: the outbound one will already\\n         // have been ratcheted to the next chain index.\\n         const key = await this.olmDevice.getInboundGroupSessionKey(\\n-            this.roomId, senderKey, sessionId, sentChainIndex,\\n+            this.roomId, senderKey, sessionId, sessionSharedData.messageIndex,\\n         );\\n \\n         if (!key) {\\n@@ -882,7 +902,7 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n             const deviceId = deviceInfo.deviceId;\\n \\n             session.markSharedWithDevice(\\n-                userId, deviceId, key.chain_index,\\n+                userId, deviceId, deviceInfo.getIdentityKey(), key.chain_index,\\n             );\\n         }'}}",
      "message_norm": "verify target device key on reshare",
      "language": "en",
      "entities": "[('verify', 'ACTION', ''), ('key', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/crypto/algorithms/megolm.ts'])",
      "num_files": 1.0
    },
    {
      "index": 2322,
      "vuln_id": "GHSA-jxvf-m3x5-mxwq",
      "cwe_id": "{'CWE-1321'}",
      "score": 9.8,
      "chain": "{'https://github.com/steveukx/properties/commit/0877cc871db9865f58dd9389ce99e61be05380a5', 'https://github.com/steveukx/properties/commit/4e4bc392ecfd0a128f48c1d69f64a0d7194fcaab'}",
      "dataset": "osv",
      "summary": "Properties-Reader before v2.2.0 vulnerable to prototype pollution Properties-Reader prior to version 2.2.0 is vulnerable to prototype pollution. Version 2.2.0 contains a patch for this issue.",
      "published_date": "2022-07-19",
      "chain_len": 2,
      "project": "https://github.com/steveukx/properties",
      "commit_href": "https://github.com/steveukx/properties/commit/4e4bc392ecfd0a128f48c1d69f64a0d7194fcaab",
      "commit_sha": "4e4bc392ecfd0a128f48c1d69f64a0d7194fcaab",
      "patch": "MULTI",
      "chain_ord": "['0877cc871db9865f58dd9389ce99e61be05380a5', '4e4bc392ecfd0a128f48c1d69f64a0d7194fcaab']",
      "before_first_fix_commit": "{'0877cc871db9865f58dd9389ce99e61be05380a5'}",
      "last_fix_commit": "4e4bc392ecfd0a128f48c1d69f64a0d7194fcaab",
      "chain_ord_pos": 2.0,
      "commit_datetime": "12/30/2020, 06:58:22",
      "message": "Allow for relying on Object prototype in steps of the expanded properties",
      "author": "Steve King",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/properties-reader.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/steveukx/properties/raw/4e4bc392ecfd0a128f48c1d69f64a0d7194fcaab/src%2Fproperties-reader.js', 'patch': '@@ -217,7 +217,7 @@ PropertiesReader.prototype.set = function (key, value) {\\n       }\\n \\n       if (!has(source, step)) {\\n-         Object.defineProperty(source, step, { value: Object.create(null) });\\n+         Object.defineProperty(source, step, { value: {} });\\n       }\\n \\n       source = source[step]'}}",
      "message_norm": "allow for relying on object prototype in steps of the expanded properties",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/properties-reader.js'])",
      "num_files": 1.0
    },
    {
      "index": 2020,
      "vuln_id": "GHSA-h7f9-cvh5-qw7f",
      "cwe_id": "{'CWE-22'}",
      "score": 0.0,
      "chain": "{'https://github.com/pimcore/pimcore/commit/1786bdd4962ee51544fad537352c2b4223309442'}",
      "dataset": "osv",
      "summary": "Path traversal in pimcore/pimcore This affects the package pimcore/pimcore before 6.8.8. A Local FIle Inclusion vulnerability exists in the downloadCsvAction function of the CustomReportController class (bundles/AdminBundle/Controller/Reports/CustomReportController.php). An authenticated user can reach this function with a GET request at the following endpoint: /admin/reports/custom-report/download-csv?exportFile=&91;filename]. Since exportFile variable is not sanitized, an attacker can exploit a local file inclusion vulnerability.",
      "published_date": "2021-02-25",
      "chain_len": 1,
      "project": "https://github.com/pimcore/pimcore",
      "commit_href": "https://github.com/pimcore/pimcore/commit/1786bdd4962ee51544fad537352c2b4223309442",
      "commit_sha": "1786bdd4962ee51544fad537352c2b4223309442",
      "patch": "SINGLE",
      "chain_ord": "['1786bdd4962ee51544fad537352c2b4223309442']",
      "before_first_fix_commit": "{'3224684a3375c35910f8544943f4c073d30c8bfa'}",
      "last_fix_commit": "1786bdd4962ee51544fad537352c2b4223309442",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/05/2021, 09:39:02",
      "message": "Fixed LFI in custom report csv download",
      "author": "Bernhard Rusch",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 1, 'total': 3}",
      "files": "{'bundles/AdminBundle/Controller/Reports/CustomReportController.php': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/pimcore/pimcore/raw/1786bdd4962ee51544fad537352c2b4223309442/bundles%2FAdminBundle%2FController%2FReports%2FCustomReportController.php', 'patch': \"@@ -433,7 +433,7 @@ public function createCsvAction(Request $request)\\n         $progress = $progress > 1 ? 1 : $progress;\\n \\n         return new JsonResponse([\\n-            'exportFile' => $exportFile,\\n+            'exportFile' => basename($exportFile),\\n             'offset' => $offset,\\n             'progress' => $progress,\\n             'finished' => empty($result['data']) || count($result['data']) < $limit,\\n@@ -451,6 +451,7 @@ public function downloadCsvAction(Request $request)\\n     {\\n         $this->checkPermission('reports');\\n         if ($exportFile = $request->get('exportFile')) {\\n+            $exportFile = PIMCORE_SYSTEM_TEMP_DIRECTORY . '/' . basename($exportFile);\\n             $response = new BinaryFileResponse($exportFile);\\n             $response->headers->set('Content-Type', 'text/csv; charset=UTF-8');\\n             $response->setContentDisposition(ResponseHeaderBag::DISPOSITION_ATTACHMENT, 'export.csv');\"}}",
      "message_norm": "fixed lfi in custom report csv download",
      "language": "en",
      "entities": "[('fixed', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['bundles/AdminBundle/Controller/Reports/CustomReportController.php'])",
      "num_files": 1.0
    },
    {
      "index": 2537,
      "vuln_id": "GHSA-p8q8-jfcv-g2h2",
      "cwe_id": "{'CWE-59'}",
      "score": 7.1,
      "chain": "{'https://github.com/pear/Archive_Tar/commit/7789ebb2f34f9e4adb3a4152ad0d1548930a9755', 'https://github.com/pear/Archive_Tar/commit/b5832439b1f37331fb4f87e67fe4f61ca26bf7d4'}",
      "dataset": "osv",
      "summary": "Directory Traversal in Archive_Tar In Archive_Tar before 1.4.14, symlinks can refer to targets outside of the extracted archive, a different vulnerability than CVE-2020-36193.",
      "published_date": "2021-08-09",
      "chain_len": 2,
      "project": "https://github.com/pear/Archive_Tar",
      "commit_href": "https://github.com/pear/Archive_Tar/commit/b5832439b1f37331fb4f87e67fe4f61ca26bf7d4",
      "commit_sha": "b5832439b1f37331fb4f87e67fe4f61ca26bf7d4",
      "patch": "MULTI",
      "chain_ord": "['b5832439b1f37331fb4f87e67fe4f61ca26bf7d4', '7789ebb2f34f9e4adb3a4152ad0d1548930a9755']",
      "before_first_fix_commit": "{'8c00f3c220655961dc3f869f37005794ab3e3500', '4d761c5334c790e45ef3245f0864b8955c562caa'}",
      "last_fix_commit": "7789ebb2f34f9e4adb3a4152ad0d1548930a9755",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/18/2021, 15:21:58",
      "message": "Properly fix symbolic link path traversal (CVE-2021-32610)",
      "author": "Michiel Rook",
      "comments": null,
      "stats": "{'additions': 29, 'deletions': 21, 'total': 50}",
      "files": "{'Archive/Tar.php': {'additions': 29, 'deletions': 21, 'changes': 50, 'status': 'modified', 'raw_url': 'https://github.com/pear/Archive_Tar/raw/b5832439b1f37331fb4f87e67fe4f61ca26bf7d4/Archive%2FTar.php', 'patch': '@@ -2124,39 +2124,47 @@ public function _extractList(\\n                             }\\n                         }\\n                     } elseif ($v_header[\\'typeflag\\'] == \"2\") {\\n+                        if (!$p_symlinks) {\\n+                            $this->_warning(\\'Symbolic links are not allowed. \\'\\n+                                . \\'Unable to extract {\\'\\n+                                . $v_header[\\'filename\\'] . \\'}\\'\\n+                            );\\n+                            return false;\\n+                        }\\n+                        $absolute_link = FALSE;\\n                         $link_depth = 0;\\n-                        foreach (explode(\"/\", $v_header[\\'filename\\']) as $dir) {\\n-                            if ($dir === \"..\") {\\n-                                $link_depth--;\\n-                            } elseif ($dir !== \"\" && $dir !== \".\" ) {\\n-                                $link_depth++;\\n-                            }\\n+                        if (strpos($v_header[\\'link\\'], \"/\") === 0 || strpos($v_header[\\'link\\'], \\':\\') !== FALSE) {\\n+                          $absolute_link = TRUE;\\n                         }\\n-                        foreach (explode(\"/\", $v_header[\\'link\\']) as $dir){\\n-                            if ($link_depth <= 0) {\\n-                                break;\\n+                        else {\\n+                            $s_filename = preg_replace(\\'@^\\' . preg_quote($p_path) . \\'@\\', \"\", $v_header[\\'filename\\']);\\n+                            $s_linkname = str_replace(\\'\\\\\\\\\\', \\'/\\', $v_header[\\'link\\']);\\n+                            foreach (explode(\"/\", $s_filename) as $dir) {\\n+                                if ($dir === \"..\") {\\n+                                    $link_depth--;\\n+                                } elseif ($dir !== \"\" && $dir !== \".\" ) {\\n+                                    $link_depth++;\\n+                                }\\n                             }\\n-                            if ($dir === \"..\") {\\n-                                $link_depth--;\\n-                            } elseif ($dir !== \"\" && $dir !== \".\") {\\n-                                $link_depth++;\\n+                            foreach (explode(\"/\", $s_linkname) as $dir){\\n+                                if ($link_depth <= 0) {\\n+                                    break;\\n+                                }\\n+                                if ($dir === \"..\") {\\n+                                    $link_depth--;\\n+                                } elseif ($dir !== \"\" && $dir !== \".\") {\\n+                                    $link_depth++;\\n+                                }\\n                             }\\n                         }\\n-                        if (strpos($v_header[\\'link\\'], \"/\") === 0 or $link_depth <= 0) {\\n+                        if ($absolute_link || $link_depth <= 0) {\\n                             $this->_error(\\n                                  \\'Out-of-path file extraction {\\'\\n                                  . $v_header[\\'filename\\'] . \\' --> \\' .\\n                                  $v_header[\\'link\\'] . \\'}\\'\\n                             );\\n                             return false;\\n                         }\\n-                        if (!$p_symlinks) {\\n-                            $this->_warning(\\'Symbolic links are not allowed. \\'\\n-                                . \\'Unable to extract {\\'\\n-                                . $v_header[\\'filename\\'] . \\'}\\'\\n-                            );\\n-                            return false;\\n-                        }\\n                         if (@file_exists($v_header[\\'filename\\'])) {\\n                             @unlink($v_header[\\'filename\\']);\\n                         }'}}",
      "message_norm": "properly fix symbolic link path traversal (cve-2021-32610)",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('path traversal', 'SECWORD', ''), ('cve-2021-32610', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['Archive/Tar.php'])",
      "num_files": 1.0
    },
    {
      "index": 1934,
      "vuln_id": "GHSA-gv26-jpj9-c8gq",
      "cwe_id": "{'CWE-754'}",
      "score": 5.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'https://github.com/tensorflow/tensorflow/commit/f6fde895ef9c77d848061c0517f19d0ec2682f3a'}",
      "dataset": "osv",
      "summary": "Incomplete validation in `SparseSparseMinimum` ### Impact\nIncomplete validation in `SparseAdd` results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:\n\n```python \nimport tensorflow as tf\n\na_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    b_shape=b_shape)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/sparse_sparse_binary_op_shared.cc) has a large set of validation for the two sparse tensor inputs (6 tensors in total), but does not validate that the tensors are not empty or that the second dimension of `*_indices` matches the size of corresponding `*_shape`. This allows attackers to send tensor triples that represent invalid sparse tensors to abuse code assumptions that are not protected by validation.\n\n### Patches \nWe have patched the issue in GitHub commit [ba6822bd7b7324ba201a28b2f278c29a98edbef2](https://github.com/tensorflow/tensorflow/commit/ba6822bd7b7324ba201a28b2f278c29a98edbef2) followed by GitHub commit [f6fde895ef9c77d848061c0517f19d0ec2682f3a](https://github.com/tensorflow/tensorflow/commit/f6fde895ef9c77d848061c0517f19d0ec2682f3a).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2022-03-18",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/f6fde895ef9c77d848061c0517f19d0ec2682f3a",
      "commit_sha": "f6fde895ef9c77d848061c0517f19d0ec2682f3a",
      "patch": "MULTI",
      "chain_ord": "['ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'f6fde895ef9c77d848061c0517f19d0ec2682f3a']",
      "before_first_fix_commit": "{'cae81a7ae3ca6207396d5c893e8163f4acb34037'}",
      "last_fix_commit": "f6fde895ef9c77d848061c0517f19d0ec2682f3a",
      "chain_ord_pos": 2.0,
      "commit_datetime": "05/12/2021, 01:32:03",
      "message": "Validate that a and b are proper sparse tensors\n\nPiperOrigin-RevId: 373274848\nChange-Id: I3a665ac3a29dee9fb69bdf408a939330cb93ea75",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 6, 'total': 15}",
      "files": "{'tensorflow/core/kernels/sparse_sparse_binary_op_shared.cc': {'additions': 9, 'deletions': 6, 'changes': 15, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/f6fde895ef9c77d848061c0517f19d0ec2682f3a/tensorflow%2Fcore%2Fkernels%2Fsparse_sparse_binary_op_shared.cc', 'patch': '@@ -150,6 +150,7 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n \\n     const int64 a_nnz = a_indices_t->dim_size(0);\\n     const int64 b_nnz = b_indices_t->dim_size(0);\\n+\\n     const auto a_values = a_values_t->vec<T>();\\n     const auto b_values = b_values_t->vec<T>();\\n \\n@@ -166,6 +167,14 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n                     \"Input shapes should be a vector but received shapes \",\\n                     a_shape_t->shape().DebugString(), \" and \",\\n                     b_shape_t->shape().DebugString()));\\n+    const int num_dims = a_indices_t->dim_size(1);\\n+    OP_REQUIRES(\\n+        ctx, a_shape_t->NumElements() == num_dims,\\n+        errors::InvalidArgument(\"Second dimension of a_indices and length of \"\\n+                                \"a_shape must match, got \",\\n+                                num_dims, \" and \", a_shape_t->NumElements()));\\n+    OP_REQUIRES(ctx, num_dims > 0,\\n+                errors::InvalidArgument(\"Tensors must not be empty\"));\\n     OP_REQUIRES(ctx, a_shape_t->IsSameSize(*b_shape_t),\\n                 errors::InvalidArgument(\\n                     \"Operands do not have the same ranks; got shapes: \",\\n@@ -180,12 +189,6 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n                                           \" for dimension \", i));\\n     }\\n \\n-    OP_REQUIRES(\\n-        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\\n-        errors::InvalidArgument(\\n-            \"Indices\\' dimensions do not match: got \", a_indices_t->dim_size(1),\\n-            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\\n-    const int num_dims = a_indices_t->dim_size(1);\\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\\n     const auto b_indices_mat = b_indices_t->matrix<int64>();\\n     std::vector<T> a_augmented_values, b_augmented_values;'}}",
      "message_norm": "validate that a and b are proper sparse tensors\n\npiperorigin-revid: 373274848\nchange-id: i3a665ac3a29dee9fb69bdf408a939330cb93ea75",
      "language": "en",
      "entities": "[('validate', 'ACTION', ''), ('373274848', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_sparse_binary_op_shared.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2978,
      "vuln_id": "GHSA-rp7r-79rm-2758",
      "cwe_id": "{'CWE-200'}",
      "score": 0.0,
      "chain": "{'https://github.com/apache/derby/commit/fd24a7590ff5426bac68303fbeca07dbc5067412', 'https://github.com/apache/derby/commit/09a7325f75a4f96a7735e46c9723930f88ea2613', 'https://github.com/apache/derby/commit/82d721fd53e30dbb86d6d742c085030985091968'}",
      "dataset": "osv",
      "summary": "Apache Derby exposes user and password attributes Apache Derby before 10.1.2.1 exposes the (1) user and (2) password attributes in cleartext via (a) the RDBNAM parameter of the ACCSEC command and (b) the output of the DatabaseMetaData.getURL function, which allows context-dependent attackers to obtain sensitive information.",
      "published_date": "2022-05-01",
      "chain_len": 3,
      "project": "https://github.com/apache/derby",
      "commit_href": "https://github.com/apache/derby/commit/09a7325f75a4f96a7735e46c9723930f88ea2613",
      "commit_sha": "09a7325f75a4f96a7735e46c9723930f88ea2613",
      "patch": "MULTI",
      "chain_ord": "['09a7325f75a4f96a7735e46c9723930f88ea2613', '82d721fd53e30dbb86d6d742c085030985091968', 'fd24a7590ff5426bac68303fbeca07dbc5067412']",
      "before_first_fix_commit": "{'90f16141b17352af5c934f3cf8bdbbb90c40624e'}",
      "last_fix_commit": "fd24a7590ff5426bac68303fbeca07dbc5067412",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/09/2005, 19:50:58",
      "message": "DERBY-561 - Embedded driver jdbcCompliant() method should return true\nTest will be checked in as part of tess for DERBY-530\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/db/derby/code/trunk@279860 13f79535-47bb-0310-9956-ffa450edef68",
      "author": "Katherine Marsden",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'java/engine/org/apache/derby/jdbc/InternalDriver.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/apache/derby/raw/09a7325f75a4f96a7735e46c9723930f88ea2613/java%2Fengine%2Forg%2Fapache%2Fderby%2Fjdbc%2FInternalDriver.java', 'patch': '@@ -209,7 +209,7 @@ public int getMinorVersion() {\\n \\t}\\r\\n \\r\\n \\tpublic boolean jdbcCompliant() {\\r\\n-\\t\\treturn false;\\r\\n+\\t\\treturn true;\\r\\n \\t}\\r\\n \\r\\n \\t/*'}}",
      "message_norm": "derby-561 - embedded driver jdbccompliant() method should return true\ntest will be checked in as part of tess for derby-530\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/db/derby/code/trunk@279860 13f79535-47bb-0310-9956-ffa450edef68",
      "language": "en",
      "entities": "[('https://svn.apache.org/repos/asf/db/derby/code/trunk@279860', 'URL', ''), ('13f79535', 'SHA', 'generic_sha'), ('ffa450edef68', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['java/engine/org/apache/derby/jdbc/InternalDriver.java'])",
      "num_files": 1.0
    },
    {
      "index": 1880,
      "vuln_id": "GHSA-gh6x-4whr-2qv4",
      "cwe_id": "{'CWE-476', 'CWE-125'}",
      "score": 8.4,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622'}",
      "dataset": "osv",
      "summary": "Null pointer dereference and heap OOB read in operations restoring tensors ### Impact\nWhen restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.Restore(\n  file_pattern=['/tmp'],\n  tensor_name=[], \n  default_value=21,\n  dt=tf.int,\n  preferred_shard=1)\n```\n  \nThe same undefined behavior can be triggered by `tf.raw_ops.RestoreSlice`:\n  \n```python\nimport tensorflow as tf\n\ntf.raw_ops.RestoreSlice(\n  file_pattern=['/tmp'],\n  tensor_name=[], \n  shape_and_slice='2',\n  dt=inp.array([tf.int]),\n  preferred_shard=1)\n```\n\nAlternatively, attackers can read memory outside the bounds of heap allocated data by providing some tensor names but not enough for a successful restoration:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.Restore(\n  file_pattern=['/tmp'],\n  tensor_name=['x'], \n  default_value=21,\n  dt=tf.int,\n  preferred_shard=42)\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/kernels/save_restore_tensor.cc#L158-L159) retrieves the tensor list corresponding to the `tensor_name` user controlled input and immediately retrieves the tensor at the restoration index (controlled via `preferred_shard` argument). This occurs without validating that the provided list has enough values.\n\nIf the list is empty this results in dereferencing a null pointer (undefined behavior). If, however, the list has some elements, if the restoration index is outside the bounds this results in heap OOB read.\n\n### Patches \nWe have patched the issue in GitHub commit [9e82dce6e6bd1f36a57e08fa85af213e2b2f2622](https://github.com/tensorflow/tensorflow/commit/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
      "commit_sha": "9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
      "patch": "SINGLE",
      "chain_ord": "['9e82dce6e6bd1f36a57e08fa85af213e2b2f2622']",
      "before_first_fix_commit": "{'e86605c0a336c088b638da02135ea6f9f6753618'}",
      "last_fix_commit": "9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/02/2021, 21:21:41",
      "message": "Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 1, 'total': 9}",
      "files": "{'tensorflow/core/kernels/save_restore_tensor.cc': {'additions': 8, 'deletions': 1, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622/tensorflow%2Fcore%2Fkernels%2Fsave_restore_tensor.cc', 'patch': '@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\\n         context, size == 1,\\n         errors::InvalidArgument(\\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\\n-            size, \"elements\"));\\n+            size, \" elements\"));\\n   }\\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\\n \\n   const Tensor& tensor_name_t = context->input(1);\\n+  {\\n+    const int64_t size = tensor_name_t.NumElements();\\n+    OP_REQUIRES(context, size > restore_index,\\n+                errors::InvalidArgument(\\n+                    \"Input 1 (file_pattern) must be a have at least \",\\n+                    restore_index + 1, \" elements\"));\\n+  }\\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\\n \\n   // If we cannot find a cached reader we will allocate our own.'}}",
      "message_norm": "fix npe in restoring code.\n\npiperorigin-revid: 388303253\nchange-id: ia8c68568cb854bca538909a182b31a618d68ce55",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('npe', 'SECWORD', ''), ('388303253', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/save_restore_tensor.cc'])",
      "num_files": 1.0
    },
    {
      "index": 495,
      "vuln_id": "GHSA-4vf2-4xcg-65cx",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/b12aa1d44352de21d1a6faaf04172d8c2508b42b'}",
      "dataset": "osv",
      "summary": "Division by 0 in `Conv2D` ### Impact\nAn attacker can trigger a division by 0 in `tf.raw_ops.Conv2D`:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nfilter = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\n\nstrides = [1, 1, 1, 1]\npadding = \"SAME\"\n                               \ntf.raw_ops.Conv2D(input=input, filter=filter, strides=strides, padding=padding)\n```                            \n                               \nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/988087bd83f144af14087fe4fecee2d250d93737/tensorflow/core/kernels/conv_ops.cc#L261-L263) does a division by a quantity that is controlled by the caller:\n```cc\n  const int64 patch_depth = filter.dim_size(2);\n  if (in_depth % patch_depth != 0) { ... }\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [b12aa1d44352de21d1a6faaf04172d8c2508b42b](https://github.com/tensorflow/tensorflow/commit/b12aa1d44352de21d1a6faaf04172d8c2508b42b).\n  \nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/b12aa1d44352de21d1a6faaf04172d8c2508b42b",
      "commit_sha": "b12aa1d44352de21d1a6faaf04172d8c2508b42b",
      "patch": "SINGLE",
      "chain_ord": "['b12aa1d44352de21d1a6faaf04172d8c2508b42b']",
      "before_first_fix_commit": "{'988087bd83f144af14087fe4fecee2d250d93737'}",
      "last_fix_commit": "b12aa1d44352de21d1a6faaf04172d8c2508b42b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/20/2021, 01:32:56",
      "message": "Fix one more FPE.\n\nPiperOrigin-RevId: 369346568\nChange-Id: I840fd575962adc879713a4c9cc59e6da3331caa7",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 13, 'deletions': 0, 'total': 13}",
      "files": "{'tensorflow/core/kernels/conv_ops.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/b12aa1d44352de21d1a6faaf04172d8c2508b42b/tensorflow%2Fcore%2Fkernels%2Fconv_ops.cc', 'patch': '@@ -260,6 +260,11 @@ struct LaunchConv2DOp<CPUDevice, T> {\\n     const int64 out_depth = output->dim_size(3);\\n     const int64 patch_depth = filter.dim_size(2);\\n \\n+    if (patch_depth <= 0) {\\n+      ctx->SetStatus(errors::InvalidArgument(\\n+          \"filter depth must be stricly positive, got \", patch_depth));\\n+      return;\\n+    }\\n     if (in_depth % patch_depth != 0) {\\n       ctx->SetStatus(errors::InvalidArgument(\\n           \"input depth must be evenly divisible by filter depth: \", in_depth,\\n@@ -268,6 +273,11 @@ struct LaunchConv2DOp<CPUDevice, T> {\\n     }\\n \\n     const int64 num_groups = in_depth / patch_depth;\\n+    if (num_groups <= 0) {\\n+      ctx->SetStatus(errors::InvalidArgument(\\n+          \"number of groups must be stricly positive, got \", num_groups));\\n+      return;\\n+    }\\n     if (out_depth % num_groups != 0 || out_depth < num_groups) {\\n       ctx->SetStatus(errors::InvalidArgument(\\n           \"output depth must be evenly divisible by number of groups: \",\\n@@ -536,6 +546,9 @@ Status ComputeConv2DDimension(const Conv2DParameters& params,\\n               errors::InvalidArgument(\"Patch depth too large\"));\\n   const int in_depth = static_cast<int>(in_depth_raw);\\n   const int patch_depth = static_cast<int>(patch_depth_raw);\\n+  TF_REQUIRES(patch_depth > 0,\\n+              errors::InvalidArgument(\\n+                  \"filter depth must be stricly positive, got \", patch_depth));\\n   TF_REQUIRES(in_depth % patch_depth == 0,\\n               errors::InvalidArgument(\\n                   \"input depth must be evenly divisible by filter depth: \",'}}",
      "message_norm": "fix one more fpe.\n\npiperorigin-revid: 369346568\nchange-id: i840fd575962adc879713a4c9cc59e6da3331caa7",
      "language": "it",
      "entities": "[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('369346568', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/conv_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3124,
      "vuln_id": "GHSA-vhfp-9wvj-gwvg",
      "cwe_id": "{'CWE-611'}",
      "score": 9.1,
      "chain": "{'https://github.com/modxcms/revolution/pull/15238/commits/1b7ffe02df30f05dbf67dd15e4d8101687c1585a'}",
      "dataset": "osv",
      "summary": "XML External Entity vulnerability in MODX CMS A XML External Entity (XXE) vulnerability was discovered in the modRestServiceRequest component in MODX CMS 2.7.3 which can lead to an information disclosure or denial of service (DOS).",
      "published_date": "2021-11-01",
      "chain_len": 1,
      "project": "https://github.com/modxcms/revolution",
      "commit_href": "https://github.com/modxcms/revolution/pull/15238/commits/1b7ffe02df30f05dbf67dd15e4d8101687c1585a",
      "commit_sha": "1b7ffe02df30f05dbf67dd15e4d8101687c1585a",
      "patch": "SINGLE",
      "chain_ord": "['1b7ffe02df30f05dbf67dd15e4d8101687c1585a']",
      "before_first_fix_commit": "{'97b4e469500d54cf55a889b18f466a9cc6573983'}",
      "last_fix_commit": "1b7ffe02df30f05dbf67dd15e4d8101687c1585a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/18/2020, 09:14:28",
      "message": "Prevent potential XXE vulnerability in modRestService by disabling the libxml entity loader [#15237]\n\nThe libxml_disable_entity_loader function is deprecated in PHP8, and the entity loader is automatically enabled on v2.9.0+ of libxml which may have been used pre-PHP8 as well. PHP8 comes with at least v2.9.0+ of libxml bundled, so this conditional covers both scenarios.\n\nRef: https://github.com/php/php-src/pull/5867",
      "author": "Mark Hamstra",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 1, 'total': 10}",
      "files": "{'core/model/modx/rest/modrestservice.class.php': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/modxcms/revolution/raw/1b7ffe02df30f05dbf67dd15e4d8101687c1585a/core%2Fmodel%2Fmodx%2Frest%2Fmodrestservice.class.php', 'patch': \"@@ -59,6 +59,7 @@ public function __construct(modX &$modx,array $config = array()) {\\n             'responseSuccessKey' => 'success',\\n             'trimParameters' => false,\\n             'xmlRootNode' => 'response',\\n+            'xmlDisableEntityLoader' => true,\\n \\t\\t),$config);\\n \\t\\t$this->modx->getService('lexicon','modLexicon');\\n         if ($this->modx->lexicon) {\\n@@ -397,7 +398,14 @@ protected function _collectRequestParameters() {\\n             case 'text/xml':\\n                 $data = stream_get_contents($filehandle);\\n                 fclose($filehandle);\\n-                $xml = simplexml_load_string($data);\\n+                if (LIBXML_VERSION < 20900 && $this->service->getOption('xmlDisableEntityLoader')) {\\n+                    $disableEntities = libxml_disable_entity_loader(true);\\n+                    $xml = simplexml_load_string($data);\\n+                    libxml_disable_entity_loader($disableEntities);\\n+                }\\n+                else {\\n+                    $xml = simplexml_load_string($data);\\n+                }\\n                 $params = $this->_xml2array($xml);\\n                 break;\\n             case 'application/json':\"}}",
      "message_norm": "prevent potential xxe vulnerability in modrestservice by disabling the libxml entity loader [#15237]\n\nthe libxml_disable_entity_loader function is deprecated in php8, and the entity loader is automatically enabled on v2.9.0+ of libxml which may have been used pre-php8 as well. php8 comes with at least v2.9.0+ of libxml bundled, so this conditional covers both scenarios.\n\nref: https://github.com/php/php-src/pull/5867",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('xxe', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('#15237', 'ISSUE', ''), ('v2.9.0', 'VERSION', ''), ('v2.9.0', 'VERSION', ''), ('https://github.com/php/php-src/pull/5867', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['core/model/modx/rest/modrestservice.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 2004,
      "vuln_id": "GHSA-h6jh-7gv5-28vg",
      "cwe_id": "{'CWE-681'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/c283e542a3f422420cfdb332414543b62fc4e4a5'}",
      "dataset": "osv",
      "summary": "Bad alloc in `StringNGrams` caused by integer conversion ### Impact\nThe implementation of `tf.raw_ops.StringNGrams` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.StringNGrams(\n  data=['',''],\n  data_splits=[0,2],\n  separator=' '*100,\n  ngram_widths=[-80,0,0,-60],\n  left_pad=' ',\n  right_pad=' ',\n  pad_width=100,\n  preserve_short_sequences=False)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/string_ngrams_op.cc#L184) calls `reserve` on a `tstring` with a value that sometimes can be negative if user supplies negative `ngram_widths`. The `reserve` method calls `TF_TString_Reserve` which has an `unsigned long` argument for the size of the buffer. Hence, the implicit conversion transforms the negative value to a large integer.\n\n### Patches\nWe have patched the issue in GitHub commit [c283e542a3f422420cfdb332414543b62fc4e4a5](https://github.com/tensorflow/tensorflow/commit/c283e542a3f422420cfdb332414543b62fc4e4a5).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/c283e542a3f422420cfdb332414543b62fc4e4a5",
      "commit_sha": "c283e542a3f422420cfdb332414543b62fc4e4a5",
      "patch": "SINGLE",
      "chain_ord": "['c283e542a3f422420cfdb332414543b62fc4e4a5']",
      "before_first_fix_commit": "{'9659aea5b5e9de3b417413f69e58dab7a2907912'}",
      "last_fix_commit": "c283e542a3f422420cfdb332414543b62fc4e4a5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/27/2021, 17:55:35",
      "message": "Disallow negative ngram_widths values in tf.raw_ops.StringNGrams\n\nPiperOrigin-RevId: 387148179\nChange-Id: I641395a09a208be72ef9b3ceb128cf8a83a0775b",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'tensorflow/core/kernels/string_ngrams_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/c283e542a3f422420cfdb332414543b62fc4e4a5/tensorflow%2Fcore%2Fkernels%2Fstring_ngrams_op.cc', 'patch': '@@ -53,6 +53,12 @@ class StringNGramsOp : public tensorflow::OpKernel {\\n   }\\n \\n   void Compute(tensorflow::OpKernelContext* context) override {\\n+    for (int ngram_width : ngram_widths_) {\\n+      OP_REQUIRES(\\n+          context, ngram_width > 0,\\n+          errors::InvalidArgument(\"ngram_widths must contain positive values\"));\\n+    }\\n+\\n     const tensorflow::Tensor* data;\\n     OP_REQUIRES_OK(context, context->input(\"data\", &data));\\n     const auto& input_data = data->flat<tstring>().data();'}}",
      "message_norm": "disallow negative ngram_widths values in tf.raw_ops.stringngrams\n\npiperorigin-revid: 387148179\nchange-id: i641395a09a208be72ef9b3ceb128cf8a83a0775b",
      "language": "en",
      "entities": "[('387148179', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/string_ngrams_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3365,
      "vuln_id": "GHSA-x4qx-4fjv-hmw6",
      "cwe_id": "{'CWE-190'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/6f4d3e8139ec724dbbcb40505891c81dd1052c4a'}",
      "dataset": "osv",
      "summary": "Integer overflow leading to crash in Tensorflow ### Impact \nThe [implementation of `SparseCountSparseOutput`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/kernels/count_ops.cc#L168-L273) can be made to crash a TensorFlow process by an integer overflow whose result is then used in a memory allocation:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n    \ntf.raw_ops.SparseCountSparseOutput(\n  indices=[[1,1]],\n  values=[2],\n  dense_shape=[2 ** 31, 2 ** 32],\n  weights=[1],\n  binary_output=True,\n  minlength=-1,\n  maxlength=-1,\n  name=None)\n```\n\n### Patches\nWe have patched the issue in GitHub commit [6f4d3e8139ec724dbbcb40505891c81dd1052c4a](https://github.com/tensorflow/tensorflow/commit/6f4d3e8139ec724dbbcb40505891c81dd1052c4a).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/6f4d3e8139ec724dbbcb40505891c81dd1052c4a",
      "commit_sha": "6f4d3e8139ec724dbbcb40505891c81dd1052c4a",
      "patch": "SINGLE",
      "chain_ord": "['6f4d3e8139ec724dbbcb40505891c81dd1052c4a']",
      "before_first_fix_commit": "{'adbbabdb0d3abb3cdeac69e38a96de1d678b24b3'}",
      "last_fix_commit": "6f4d3e8139ec724dbbcb40505891c81dd1052c4a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/08/2021, 04:04:02",
      "message": "Prevent crash due to integer overflow followed by allocating negative sized array.\n\nPiperOrigin-RevId: 414891322\nChange-Id: I5df390e0dc1d9f115209293708950cdf9306931c",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 0, 'total': 9}",
      "files": "{'tensorflow/core/kernels/count_ops.cc': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/6f4d3e8139ec724dbbcb40505891c81dd1052c4a/tensorflow%2Fcore%2Fkernels%2Fcount_ops.cc', 'patch': '@@ -13,6 +13,8 @@ See the License for the specific language governing permissions and\\n limitations under the License.\\n ==============================================================================*/\\n \\n+#include <limits>\\n+\\n #include \"absl/container/flat_hash_map.h\"\\n #include \"tensorflow/core/framework/op_kernel.h\"\\n #include \"tensorflow/core/framework/op_requires.h\"\\n@@ -23,6 +25,9 @@ limitations under the License.\\n \\n namespace tensorflow {\\n \\n+// Don\\'t allocate too large `BatchedMap<T>` objects\\n+static int kMaxBatches = std::numeric_limits<int>::max();\\n+\\n template <class T>\\n using BatchedMap = std::vector<absl::flat_hash_map<int64_t, T>>;\\n \\n@@ -235,6 +240,10 @@ class SparseCount : public OpKernel {\\n \\n     bool is_1d = shape.NumElements() == 1;\\n     int num_batches = is_1d ? 1 : shape_vector(0);\\n+    OP_REQUIRES(\\n+        context, 0 < num_batches && num_batches < kMaxBatches,\\n+        errors::InvalidArgument(\"Cannot allocate \", num_batches,\\n+                                \" batches, is the dense shape too wide?\"));\\n \\n     const auto values_values = values.flat<T>();\\n     const auto weight_values = weights.flat<W>();'}}",
      "message_norm": "prevent crash due to integer overflow followed by allocating negative sized array.\n\npiperorigin-revid: 414891322\nchange-id: i5df390e0dc1d9f115209293708950cdf9306931c",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('integer overflow', 'SECWORD', ''), ('414891322', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/count_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2780,
      "vuln_id": "GHSA-qm6v-cg9v-53j3",
      "cwe_id": "{'CWE-287'}",
      "score": 5.4,
      "chain": "{'https://github.com/opencast/opencast/commit/8d5ec1614eed109b812bc27b0c6d3214e456d4e7'}",
      "dataset": "osv",
      "summary": "Limited Authentication Bypass for Media Files Prior to Opencast 10.14 and 11.7, users could pass along URLs for files belonging to organizations other than the user's own, which Opencast would then import into the current organization, bypassing organizational barriers.\n\n### Impact\n\nThe vulnerability allows attackers to bypass organizational barriers. Attackers must have full access to Opencast's ingest REST interface, and also know internal links to resources in another organization of the same Opencast cluster.\n\nIf you do not run a multi-tenant cluster, you are not affected by this issue.\n\n### Patches\n\nThis issue is fixed in Opencast 10.14 and 11.7.\n\n### References\n\n- [Patch fixing the issue](https://github.com/opencast/opencast/commit/8d5ec1614eed109b812bc27b0c6d3214e456d4e7)\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an issue in [our issue tracker](https://github.com/opencast/opencast/issues)\n* Email us at [security@opencast.org](mailto:security@opencast.org)",
      "published_date": "2022-05-25",
      "chain_len": 1,
      "project": "https://github.com/opencast/opencast",
      "commit_href": "https://github.com/opencast/opencast/commit/8d5ec1614eed109b812bc27b0c6d3214e456d4e7",
      "commit_sha": "8d5ec1614eed109b812bc27b0c6d3214e456d4e7",
      "patch": "SINGLE",
      "chain_ord": "['8d5ec1614eed109b812bc27b0c6d3214e456d4e7']",
      "before_first_fix_commit": "{'eee0c26fe33afc0709373fcbd7c6870bee8e2bed'}",
      "last_fix_commit": "8d5ec1614eed109b812bc27b0c6d3214e456d4e7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/18/2022, 10:43:56",
      "message": "Merge pull request from GHSA-qm6v-cg9v-53j3\n\nThis patch fixes the issue that users can pass URLs from other tenants\nto the ingest service which will check only against the other\norganization but not against the one currently active. This allows users\nto easily ingest media from other tenants.",
      "author": "Lars Kiesow",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 12, 'total': 13}",
      "files": "{'modules/ingest-service-impl/src/main/java/org/opencastproject/ingest/impl/IngestServiceImpl.java': {'additions': 1, 'deletions': 12, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/opencast/opencast/raw/8d5ec1614eed109b812bc27b0c6d3214e456d4e7/modules%2Fingest-service-impl%2Fsrc%2Fmain%2Fjava%2Forg%2Fopencastproject%2Fingest%2Fimpl%2FIngestServiceImpl.java', 'patch': '@@ -129,15 +129,13 @@\\n import java.util.Dictionary;\\n import java.util.HashMap;\\n import java.util.HashSet;\\n-import java.util.LinkedList;\\n import java.util.List;\\n import java.util.Map;\\n import java.util.Map.Entry;\\n import java.util.Objects;\\n import java.util.Set;\\n import java.util.UUID;\\n import java.util.concurrent.TimeUnit;\\n-import java.util.stream.Collectors;\\n \\n import javax.management.ObjectInstance;\\n \\n@@ -1568,16 +1566,7 @@ protected URI addContentToRepo(MediaPackage mp, String elementId, URI uri) throw\\n     try {\\n       if (uri.toString().startsWith(\"http\")) {\\n         HttpGet get = new HttpGet(uri);\\n-        List<String> clusterUrls = new LinkedList<>();\\n-        try {\\n-          // Note that we are not checking ports here.\\n-          clusterUrls = organizationDirectoryService.getOrganization(uri.toURL()).getServers()\\n-                          .keySet()\\n-                          .stream()\\n-                          .collect(Collectors.toUnmodifiableList());\\n-        } catch (NotFoundException e) {\\n-          logger.warn(\"Unable to determine cluster members, will not be able to authenticate any downloads from them\", e);\\n-        }\\n+        var clusterUrls = securityService.getOrganization().getServers().keySet();\\n \\n         if (uri.toString().matches(downloadSource)) {\\n           //NB: We\\'re creating a new client here with *different* auth than the system auth creds'}}",
      "message_norm": "merge pull request from ghsa-qm6v-cg9v-53j3\n\nthis patch fixes the issue that users can pass urls from other tenants\nto the ingest service which will check only against the other\norganization but not against the one currently active. this allows users\nto easily ingest media from other tenants.",
      "language": "en",
      "entities": "[('ghsa-qm6v-cg9v-53j3', 'VULNID', 'GHSA'), ('fixes', 'ACTION', ''), ('issue', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['modules/ingest-service-impl/src/main/java/org/opencastproject/ingest/impl/IngestServiceImpl.java'])",
      "num_files": 1.0
    },
    {
      "index": 2036,
      "vuln_id": "GHSA-h9px-9vqg-222h",
      "cwe_id": "{'CWE-125'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/99085e8ff02c3763a0ec2263e44daec416f6a387'}",
      "dataset": "osv",
      "summary": "Heap OOB in `QuantizeAndDequantizeV3` ### Impact\nAn attacker can read data outside of bounds of heap allocated buffer in `tf.raw_ops.QuantizeAndDequantizeV3`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeAndDequantizeV3(\n  input=[2.5,2.5], input_min=[0,0], input_max=[1,1], num_bits=[30],\n  signed_input=False, range_given=False, narrow_range=False, axis=3)\n```   \n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/11ff7f80667e6490d7b5174aa6bf5e01886e770f/tensorflow/core/kernels/quantize_and_dequantize_op.cc#L237) does not validate the value of user supplied `axis` attribute before using it to index in the array backing the `input` argument:\n\n```cc\nconst int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n```\n\n### Patches\nWe have patched the issue in GitHub commit [99085e8ff02c3763a0ec2263e44daec416f6a387](https://github.com/tensorflow/tensorflow/commit/99085e8ff02c3763a0ec2263e44daec416f6a387).\n  \nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/99085e8ff02c3763a0ec2263e44daec416f6a387",
      "commit_sha": "99085e8ff02c3763a0ec2263e44daec416f6a387",
      "patch": "SINGLE",
      "chain_ord": "['99085e8ff02c3763a0ec2263e44daec416f6a387']",
      "before_first_fix_commit": "{'11ff7f80667e6490d7b5174aa6bf5e01886e770f'}",
      "last_fix_commit": "99085e8ff02c3763a0ec2263e44daec416f6a387",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/27/2021, 00:32:41",
      "message": "Fix `tf.raw_ops.QuantizeAndDequantizeV3` array index failure.\n\nPiperOrigin-RevId: 370577691\nChange-Id: Ifeae64212f6bcd139435824fa2748d1329213c4c",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/quantize_and_dequantize_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/99085e8ff02c3763a0ec2263e44daec416f6a387/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\\n limitations under the License.\\n ==============================================================================*/\\n \\n+#include \"tensorflow/core/framework/op_requires.h\"\\n #define EIGEN_USE_THREADS\\n \\n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\\\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& input = ctx->input(0);\\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\\n+                errors::InvalidArgument(\\n+                    \"Axis requested is larger than input dimensions. Axis: \",\\n+                    axis_, \" Input Dimensions: \", input.dims()));\\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));'}}",
      "message_norm": "fix `tf.raw_ops.quantizeanddequantizev3` array index failure.\n\npiperorigin-revid: 370577691\nchange-id: ifeae64212f6bcd139435824fa2748d1329213c4c",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('370577691', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/quantize_and_dequantize_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1933,
      "vuln_id": "GHSA-gv26-jpj9-c8gq",
      "cwe_id": "{'CWE-754'}",
      "score": 5.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'https://github.com/tensorflow/tensorflow/commit/f6fde895ef9c77d848061c0517f19d0ec2682f3a'}",
      "dataset": "osv",
      "summary": "Incomplete validation in `SparseSparseMinimum` ### Impact\nIncomplete validation in `SparseAdd` results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:\n\n```python \nimport tensorflow as tf\n\na_indices = tf.ones([45, 92], dtype=tf.int64)\na_values = tf.ones([45], dtype=tf.int64)\na_shape = tf.ones([1], dtype=tf.int64)\nb_indices = tf.ones([1, 1], dtype=tf.int64)\nb_values = tf.ones([1], dtype=tf.int64)\nb_shape = tf.ones([1], dtype=tf.int64)\n                    \ntf.raw_ops.SparseSparseMinimum(a_indices=a_indices,\n    a_values=a_values,\n    a_shape=a_shape,\n    b_indices=b_indices,\n    b_values=b_values,\n    b_shape=b_shape)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/sparse_sparse_binary_op_shared.cc) has a large set of validation for the two sparse tensor inputs (6 tensors in total), but does not validate that the tensors are not empty or that the second dimension of `*_indices` matches the size of corresponding `*_shape`. This allows attackers to send tensor triples that represent invalid sparse tensors to abuse code assumptions that are not protected by validation.\n\n### Patches \nWe have patched the issue in GitHub commit [ba6822bd7b7324ba201a28b2f278c29a98edbef2](https://github.com/tensorflow/tensorflow/commit/ba6822bd7b7324ba201a28b2f278c29a98edbef2) followed by GitHub commit [f6fde895ef9c77d848061c0517f19d0ec2682f3a](https://github.com/tensorflow/tensorflow/commit/f6fde895ef9c77d848061c0517f19d0ec2682f3a).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2022-03-18",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/ba6822bd7b7324ba201a28b2f278c29a98edbef2",
      "commit_sha": "ba6822bd7b7324ba201a28b2f278c29a98edbef2",
      "patch": "MULTI",
      "chain_ord": "['ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'f6fde895ef9c77d848061c0517f19d0ec2682f3a']",
      "before_first_fix_commit": "{'cae81a7ae3ca6207396d5c893e8163f4acb34037'}",
      "last_fix_commit": "f6fde895ef9c77d848061c0517f19d0ec2682f3a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 23:06:54",
      "message": "Fix OOB issue with `tf.raw_ops.SparseSparseMinimum`.\n\nPiperOrigin-RevId: 371005787\nChange-Id: Ib686ccc077836e8b980b8b5a03936d36a8ecaf71",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/sparse_sparse_binary_op_shared.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/ba6822bd7b7324ba201a28b2f278c29a98edbef2/tensorflow%2Fcore%2Fkernels%2Fsparse_sparse_binary_op_shared.cc', 'patch': '@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n                                           \" for dimension \", i));\\n     }\\n \\n+    OP_REQUIRES(\\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\\n+        errors::InvalidArgument(\\n+            \"Indices\\' dimensions do not match: got \", a_indices_t->dim_size(1),\\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\\n     const int num_dims = a_indices_t->dim_size(1);\\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\\n     const auto b_indices_mat = b_indices_t->matrix<int64>();'}}",
      "message_norm": "fix oob issue with `tf.raw_ops.sparsesparseminimum`.\n\npiperorigin-revid: 371005787\nchange-id: ib686ccc077836e8b980b8b5a03936d36a8ecaf71",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('oob', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371005787', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_sparse_binary_op_shared.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1832,
      "vuln_id": "GHSA-g6vq-wc8w-4g69",
      "cwe_id": "{'CWE-352'}",
      "score": 4.3,
      "chain": "{'https://github.com/firefly-iii/firefly-iii/commit/518b4ba5a7a56760902758ae0a2c6a392c2f4d37'}",
      "dataset": "osv",
      "summary": "firefly-iii is vulnerable to Cross-Site Request Forgery (CSRF) firefly-iii is vulnerable to Cross-Site Request Forgery (CSRF).",
      "published_date": "2021-12-06",
      "chain_len": 1,
      "project": "https://github.com/firefly-iii/firefly-iii",
      "commit_href": "https://github.com/firefly-iii/firefly-iii/commit/518b4ba5a7a56760902758ae0a2c6a392c2f4d37",
      "commit_sha": "518b4ba5a7a56760902758ae0a2c6a392c2f4d37",
      "patch": "SINGLE",
      "chain_ord": "['518b4ba5a7a56760902758ae0a2c6a392c2f4d37']",
      "before_first_fix_commit": "{'0f9c1b9427b946b5eb580112edfcb3ed6a812970'}",
      "last_fix_commit": "518b4ba5a7a56760902758ae0a2c6a392c2f4d37",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/24/2021, 18:22:07",
      "message": "Fix CSRF issues",
      "author": "James Cole",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 5, 'total': 11}",
      "files": "{'routes/web.php': {'additions': 6, 'deletions': 5, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/firefly-iii/firefly-iii/raw/518b4ba5a7a56760902758ae0a2c6a392c2f4d37/routes%2Fweb.php', 'patch': \"@@ -213,7 +213,7 @@ static function () {\\n     ['middleware' => 'user-full-auth', 'namespace' => 'FireflyIII\\\\Http\\\\Controllers', 'prefix' => 'subscriptions', 'as' => 'subscriptions.'],\\n     static function () {\\n         Route::get('', ['uses' => 'Bill\\\\IndexController@index', 'as' => 'index']);\\n-        Route::get('rescan/{bill}', ['uses' => 'Bill\\\\ShowController@rescan', 'as' => 'rescan']);\\n+        Route::post('rescan/{bill}', ['uses' => 'Bill\\\\ShowController@rescan', 'as' => 'rescan']);\\n         Route::get('create', ['uses' => 'Bill\\\\CreateController@create', 'as' => 'create']);\\n         Route::get('edit/{bill}', ['uses' => 'Bill\\\\EditController@edit', 'as' => 'edit']);\\n         Route::get('delete/{bill}', ['uses' => 'Bill\\\\DeleteController@delete', 'as' => 'delete']);\\n@@ -649,7 +649,7 @@ static function () {\\n         Route::get('rate/{fromCurrencyCode}/{toCurrencyCode}/{date}', ['uses' => 'Json\\\\ExchangeController@getRate', 'as' => 'rate']);\\n \\n         // intro things:\\n-        Route::any('intro/finished/{route}/{specificPage?}', ['uses' => 'Json\\\\IntroController@postFinished', 'as' => 'intro.finished']);\\n+        Route::post('intro/finished/{route}/{specificPage?}', ['uses' => 'Json\\\\IntroController@postFinished', 'as' => 'intro.finished']);\\n         Route::post('intro/enable/{route}/{specificPage?}', ['uses' => 'Json\\\\IntroController@postEnable', 'as' => 'intro.enable']);\\n         Route::get('intro/{route}/{specificPage?}', ['uses' => 'Json\\\\IntroController@getIntroSteps', 'as' => 'intro']);\\n     }\\n@@ -726,14 +726,15 @@ static function () {\\n         Route::post('enable2FA', ['uses' => 'ProfileController@enable2FA', 'as' => 'enable2FA']);\\n         Route::get('2fa/code', ['uses' => 'ProfileController@code', 'as' => 'code']);\\n         Route::post('2fa/code', ['uses' => 'ProfileController@postCode', 'as' => 'code.store']);\\n-        Route::get('/delete-code', ['uses' => 'ProfileController@deleteCode', 'as' => 'delete-code']);\\n-        Route::get('2fa/new-codes', ['uses' => 'ProfileController@newBackupCodes', 'as' => 'new-backup-codes']);\\n+        Route::post('/delete-code', ['uses' => 'ProfileController@deleteCode', 'as' => 'delete-code']);\\n+        Route::post('2fa/new-codes', ['uses' => 'ProfileController@newBackupCodes', 'as' => 'new-backup-codes']);\\n \\n     }\\n );\\n \\n /**\\n  * Recurring Transactions Controller.\\n+ * \\n  */\\n Route::group(\\n     ['middleware' => 'user-full-auth', 'namespace' => 'FireflyIII\\\\Http\\\\Controllers', 'prefix' => 'recurring', 'as' => 'recurring.'],\\n@@ -1078,7 +1079,7 @@ static function () {\\n // See reference nr. 6\\n         Route::post('store/{tj}', ['uses' => 'LinkController@store', 'as' => 'store']);\\n         Route::get('delete/{journalLink}', ['uses' => 'LinkController@delete', 'as' => 'delete']);\\n-        Route::get('switch/{journalLink}', ['uses' => 'LinkController@switchLink', 'as' => 'switch']);\\n+        Route::post('switch/{journalLink}', ['uses' => 'LinkController@switchLink', 'as' => 'switch']);\\n \\n         Route::post('destroy/{journalLink}', ['uses' => 'LinkController@destroy', 'as' => 'destroy']);\\n     }\"}}",
      "message_norm": "fix csrf issues",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('csrf', 'SECWORD', ''), ('issues', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['routes/web.php'])",
      "num_files": 1.0
    },
    {
      "index": 3318,
      "vuln_id": "GHSA-wrwf-pmmj-w989",
      "cwe_id": "{'CWE-203'}",
      "score": 5.9,
      "chain": "{'https://github.com/bcgit/bc-java/commit/a00b684465b38d722ca9a3543b8af8568e6bad5c'}",
      "dataset": "osv",
      "summary": "Observable Discrepancy in BouncyCastle BouncyCastle TLS prior to version 1.0.3, when configured to use the JCE (Java Cryptography Extension) for cryptographic functions, provides a weak Bleichenbacher oracle when any TLS cipher suite using RSA key exchange is negotiated. An attacker can recover the private key from a vulnerable application. This vulnerability is referred to as \"ROBOT.\"",
      "published_date": "2022-05-13",
      "chain_len": 1,
      "project": "https://github.com/bcgit/bc-java",
      "commit_href": "https://github.com/bcgit/bc-java/commit/a00b684465b38d722ca9a3543b8af8568e6bad5c",
      "commit_sha": "a00b684465b38d722ca9a3543b8af8568e6bad5c",
      "patch": "SINGLE",
      "chain_ord": "['a00b684465b38d722ca9a3543b8af8568e6bad5c']",
      "before_first_fix_commit": "{'199be1bdc892dcb3360af1b5a887a7e133d2cdac'}",
      "last_fix_commit": "a00b684465b38d722ca9a3543b8af8568e6bad5c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/12/2017, 01:41:43",
      "message": "Confirm size of decrypted PMS before using",
      "author": "Peter Dettman",
      "comments": "{'com_1': {'author': 'carnil', 'datetime': '12/12/2017, 20:44:47', 'body': 'CVE-2017-13098'}, 'com_2': {'author': 'bcgit', 'datetime': '12/12/2017, 23:34:09', 'body': 'This is also available in the current beta in https://www.bouncycastle.org/betas 159b09 or later.'}, 'com_3': {'author': 'zenithravi', 'datetime': '12/14/2017, 09:12:16', 'body': 'Any plan ? When fix for CVE-2017-13098 (159b09) will be released ?'}, 'com_4': {'author': 'bcgit', 'datetime': '12/14/2017, 11:05:34', 'body': \"We're hoping to have 1.59 out in the next week or so.\"}}",
      "stats": "{'additions': 5, 'deletions': 1, 'total': 6}",
      "files": "{'tls/src/main/java/org/bouncycastle/tls/crypto/impl/jcajce/JceDefaultTlsCredentialedDecryptor.java': {'additions': 5, 'deletions': 1, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/bcgit/bc-java/raw/a00b684465b38d722ca9a3543b8af8568e6bad5c/tls%2Fsrc%2Fmain%2Fjava%2Forg%2Fbouncycastle%2Ftls%2Fcrypto%2Fimpl%2Fjcajce%2FJceDefaultTlsCredentialedDecryptor.java', 'patch': '@@ -97,7 +97,11 @@ protected TlsSecret safeDecryptPreMasterSecret(TlsCryptoParameters cryptoParams,\\n         {\\n             Cipher c = crypto.createRSAEncryptionCipher();\\n             c.init(Cipher.DECRYPT_MODE, rsaServerPrivateKey);\\n-            M = c.doFinal(encryptedPreMasterSecret);\\n+            byte[] m = c.doFinal(encryptedPreMasterSecret);\\n+            if (m != null && m.length == 48)\\n+            {\\n+                M = m;\\n+            }\\n         }\\n         catch (Exception e)\\n         {'}}",
      "message_norm": "confirm size of decrypted pms before using",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tls/src/main/java/org/bouncycastle/tls/crypto/impl/jcajce/JceDefaultTlsCredentialedDecryptor.java'])",
      "num_files": 1.0
    },
    {
      "index": 2286,
      "vuln_id": "GHSA-jp6r-xcjj-5h7r",
      "cwe_id": "{'CWE-79'}",
      "score": 6.1,
      "chain": "{'https://github.com/gchq/CyberChef/commit/01f0625d6a177f9c5df9281f12a27c814c2d8bcf'}",
      "dataset": "osv",
      "summary": "Cross-Site Scripting in cyberchef Versions of `cyberchef` prior to 8.31.3 are vulnerable to Cross-Site Scripting. In `Text Encoding Brute Force` the table rows are created by concatenating the `value` variable unsanitized in the HTML code. If this variable is controlled by user input it allows attackers to execute arbitrary JavaScript in a victim's browser.\n\n\n## Recommendation\n\nUpgrade to version 8.31.3 or later.",
      "published_date": "2019-08-27",
      "chain_len": 1,
      "project": "https://github.com/gchq/CyberChef",
      "commit_href": "https://github.com/gchq/CyberChef/commit/01f0625d6a177f9c5df9281f12a27c814c2d8bcf",
      "commit_sha": "01f0625d6a177f9c5df9281f12a27c814c2d8bcf",
      "patch": "SINGLE",
      "chain_ord": "['01f0625d6a177f9c5df9281f12a27c814c2d8bcf']",
      "before_first_fix_commit": "{'38ff7ec89f595dbe5971c3577fa29a142b4b2416'}",
      "last_fix_commit": "01f0625d6a177f9c5df9281f12a27c814c2d8bcf",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/14/2019, 21:00:17",
      "message": "Fixed XSS in 'Text Encoding Brute Force. Closes #539",
      "author": "n1474335",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/core/operations/TextEncodingBruteForce.mjs': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/gchq/CyberChef/raw/01f0625d6a177f9c5df9281f12a27c814c2d8bcf/src%2Fcore%2Foperations%2FTextEncodingBruteForce.mjs', 'patch': '@@ -79,7 +79,7 @@ class TextEncodingBruteForce extends Operation {\\n         let table = \"<table class=\\'table table-hover table-sm table-bordered table-nonfluid\\'><tr><th>Encoding</th><th>Value</th></tr>\";\\n \\n         for (const enc in encodings) {\\n-            const value = Utils.printable(encodings[enc], true);\\n+            const value = Utils.escapeHtml(Utils.printable(encodings[enc], true));\\n             table += `<tr><td>${enc}</td><td>${value}</td></tr>`;\\n         }'}}",
      "message_norm": "fixed xss in 'text encoding brute force. closes #539",
      "language": "en",
      "entities": "[('fixed', 'ACTION', ''), ('xss', 'SECWORD', ''), ('encoding', 'SECWORD', ''), ('#539', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/core/operations/TextEncodingBruteForce.mjs'])",
      "num_files": 1.0
    },
    {
      "index": 415,
      "vuln_id": "GHSA-4fg4-p75j-w5xj",
      "cwe_id": "{'CWE-125'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b'}",
      "dataset": "osv",
      "summary": "Heap out of bounds in `QuantizedBatchNormWithGlobalNormalization` ### Impact\nAn attacker can cause a segfault and denial of service via accessing data outside of bounds in `tf.raw_ops.QuantizedBatchNormWithGlobalNormalization`:\n\n```python\nimport tensorflow as tf\n\nt = tf.constant([1], shape=[1, 1, 1, 1], dtype=tf.quint8)\nt_min = tf.constant([], shape=[0], dtype=tf.float32)\nt_max = tf.constant([], shape=[0], dtype=tf.float32)\nm = tf.constant([1], shape=[1], dtype=tf.quint8)\nm_min = tf.constant([], shape=[0], dtype=tf.float32)\nm_max = tf.constant([], shape=[0], dtype=tf.float32)\nv = tf.constant([1], shape=[1], dtype=tf.quint8)\nv_min = tf.constant([], shape=[0], dtype=tf.float32)\nv_max = tf.constant([], shape=[0], dtype=tf.float32)\nbeta = tf.constant([1], shape=[1], dtype=tf.quint8)\nbeta_min = tf.constant([], shape=[0], dtype=tf.float32)\nbeta_max = tf.constant([], shape=[0], dtype=tf.float32)\ngamma = tf.constant([1], shape=[1], dtype=tf.quint8)\ngamma_min = tf.constant([], shape=[0], dtype=tf.float32)\ngamma_max = tf.constant([], shape=[0], dtype=tf.float32) \n\ntf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n  t=t, t_min=t_min, t_max=t_max, m=m, m_min=m_min, m_max=m_max,\n  v=v, v_min=v_min, v_max=v_max, beta=beta, beta_min=beta_min,\n  beta_max=beta_max, gamma=gamma, gamma_min=gamma_min,\n  gamma_max=gamma_max, out_type=tf.qint32,\n  variance_epsilon=0.1, scale_after_normalization=True)\n```                         \n                            \nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/55a97caa9e99c7f37a0bbbeb414dc55553d3ae7f/tensorflow/core/kernels/quantized_batch_norm_op.cc#L176-L189) assumes the inputs are not empty: \n  \n```cc\nconst float input_min = context->input(1).flat<float>()(0);\nconst float input_max = context->input(2).flat<float>()(0);\n...\nconst float mean_min = context->input(4).flat<float>()(0);\nconst float mean_max = context->input(5).flat<float>()(0);\n...\nconst float var_min = context->input(7).flat<float>()(0);\nconst float var_max = context->input(8).flat<float>()(0);\n...\nconst float beta_min = context->input(10).flat<float>()(0);\nconst float beta_max = context->input(11).flat<float>()(0);\n...\nconst float gamma_min = context->input(13).flat<float>()(0);\nconst float gamma_max = context->input(14).flat<float>()(0);\n```\n\nIf any of these inputs is empty, `.flat<T>()` is an empty buffer, so accessing the element at index 0 is accessing data outside of bounds.\n\n### Patches\nWe have patched the issue in GitHub commit [d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b](https://github.com/tensorflow/tensorflow/commit/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
      "commit_sha": "d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
      "patch": "SINGLE",
      "chain_ord": "['d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b']",
      "before_first_fix_commit": "{'55a97caa9e99c7f37a0bbbeb414dc55553d3ae7f'}",
      "last_fix_commit": "d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/23/2021, 18:40:06",
      "message": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 67, 'deletions': 10, 'total': 77}",
      "files": "{'tensorflow/core/kernels/quantized_batch_norm_op.cc': {'additions': 67, 'deletions': 10, 'changes': 77, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b/tensorflow%2Fcore%2Fkernels%2Fquantized_batch_norm_op.cc', 'patch': '@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* context) override {\\n     const Tensor& input = context->input(0);\\n-    const float input_min = context->input(1).flat<float>()(0);\\n-    const float input_max = context->input(2).flat<float>()(0);\\n+    const auto& input_min_tensor = context->input(1);\\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\\n+    const float input_min = input_min_tensor.flat<float>()(0);\\n+    const auto& input_max_tensor = context->input(2);\\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\\n+    const float input_max = input_max_tensor.flat<float>()(0);\\n     const Tensor& mean = context->input(3);\\n-    const float mean_min = context->input(4).flat<float>()(0);\\n-    const float mean_max = context->input(5).flat<float>()(0);\\n+    const auto& mean_min_tensor = context->input(4);\\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\\n+    const auto& mean_max_tensor = context->input(5);\\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\\n     const Tensor& var = context->input(6);\\n-    const float var_min = context->input(7).flat<float>()(0);\\n-    const float var_max = context->input(8).flat<float>()(0);\\n+    const auto& var_min_tensor = context->input(7);\\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\\n+    const float var_min = var_min_tensor.flat<float>()(0);\\n+    const auto& var_max_tensor = context->input(8);\\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\\n+    const float var_max = var_max_tensor.flat<float>()(0);\\n     const Tensor& beta = context->input(9);\\n-    const float beta_min = context->input(10).flat<float>()(0);\\n-    const float beta_max = context->input(11).flat<float>()(0);\\n+    const auto& beta_min_tensor = context->input(10);\\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\\n+    const auto& beta_max_tensor = context->input(11);\\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\\n     const Tensor& gamma = context->input(12);\\n-    const float gamma_min = context->input(13).flat<float>()(0);\\n-    const float gamma_max = context->input(14).flat<float>()(0);\\n+    const auto& gamma_min_tensor = context->input(13);\\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\\n+    const auto& gamma_max_tensor = context->input(14);\\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\\n \\n     OP_REQUIRES(context, input.dims() == 4,\\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\\n     OP_REQUIRES(context, gamma.dims() == 1,\\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\\n                                         gamma.shape().DebugString()));\\n+    OP_REQUIRES(context, mean.NumElements() > 1,\\n+                errors::InvalidArgument(\"Must have at least a mean value\",\\n+                                        gamma.shape().DebugString()));\\n+    OP_REQUIRES(context, mean.NumElements() > 1,\\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\\n+    const auto last_dim = input.shape().dims() - 1;\\n+    OP_REQUIRES(context,\\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\\n+                errors::InvalidArgument(\"Must provide as many means as the \"\\n+                                        \"last dimension of the input tensor: \",\\n+                                        mean.shape().DebugString(), \" vs. \",\\n+                                        input.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and variance tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and beta tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and gamma tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(context,'}}",
      "message_norm": "add missing validation in `quantizedbatchnormwithglobalnormalization`\n\npiperorigin-revid: 370123451\nchange-id: id234d6dab1ec21230bb8e503dba30f899af87f33",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('370123451', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/quantized_batch_norm_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 371,
      "vuln_id": "GHSA-46hv-7769-j7rx",
      "cwe_id": "{'CWE-548'}",
      "score": 0.0,
      "chain": "{'https://github.com/sintaxi/harp/commit/1ec790baeeb2bfdb4584f1998af3d10a8fa31210'}",
      "dataset": "osv",
      "summary": "Unauthorized File Access in harp Affected versions of `harp` are vulnerable to Unauthorized File Access. The package states that it ignores files and directories with names that start with an underscore, such as `_secret-folder`. If the underscore character is URL encoded the server delivers the file.\n\n## Recommendation\n\nUpgrade to version `0.40.2` or later.",
      "published_date": "2019-06-13",
      "chain_len": 1,
      "project": "https://github.com/sintaxi/harp",
      "commit_href": "https://github.com/sintaxi/harp/commit/1ec790baeeb2bfdb4584f1998af3d10a8fa31210",
      "commit_sha": "1ec790baeeb2bfdb4584f1998af3d10a8fa31210",
      "patch": "SINGLE",
      "chain_ord": "['1ec790baeeb2bfdb4584f1998af3d10a8fa31210']",
      "before_first_fix_commit": "{'d3f7ba27c7554251a91f2987d702a6d4cfe8f081'}",
      "last_fix_commit": "1ec790baeeb2bfdb4584f1998af3d10a8fa31210",
      "chain_ord_pos": 1.0,
      "commit_datetime": "06/02/2021, 18:56:59",
      "message": "Resolves serving private file via encoded underscore. #646",
      "author": "Brock Whitten",
      "comments": null,
      "stats": "{'additions': 867, 'deletions': 1027, 'total': 1894}",
      "files": "{'package-lock.json': {'additions': 867, 'deletions': 1027, 'changes': 1894, 'status': 'modified', 'raw_url': 'https://github.com/sintaxi/harp/raw/1ec790baeeb2bfdb4584f1998af3d10a8fa31210/package-lock.json', 'patch': None}}",
      "message_norm": "resolves serving private file via encoded underscore. #646",
      "language": "it",
      "entities": "[('private file', 'SECWORD', ''), ('encoded', 'SECWORD', ''), ('#646', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['package-lock.json'])",
      "num_files": 1.0
    },
    {
      "index": 132,
      "vuln_id": "GHSA-2r8p-fg3c-wcj4",
      "cwe_id": "{'CWE-125'}",
      "score": 7.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/bc9c546ce7015c57c2f15c168b3d9201de679a1d'}",
      "dataset": "osv",
      "summary": "Heap OOB and CHECK fail in `ResourceGather` ### Impact\nAn attacker can trigger a crash via a `CHECK`-fail in debug builds of TensorFlow using `tf.raw_ops.ResourceGather` or a read from outside the bounds of heap allocated data in the same API in a release build:\n\n```python\nimport tensorflow as tf\n\ntensor = tf.constant(value=[[1,2],[3,4],[5,6]],shape=(3,2),dtype=tf.uint32)\nv = tf.Variable(tensor)\ntf.raw_ops.ResourceGather(\n  resource=v.handle,\n  indices=[0],\n  dtype=tf.uint32,\n  batch_dims=10,\n  validate_indices=False)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L660-L668) does not check that the `batch_dims` value that the user supplies is less than the rank of the input tensor.\n\nSince the implementation uses several for loops over the dimensions of `tensor`, this results in reading data from outside the bounds of heap allocated buffer backing the tensor:\n\n```cc\n    // batch_dims_ = > params.dims() (10 > 2)\n    for (int i = 0; i < batch_dims_; ++i) {\n      result_shape.AddDim(params.dim_size(i));\n    }\n    for (int i = batch_dims_; i < indices.dims(); ++i) {\n      result_shape.AddDim(indices.dim_size(i));\n    }\n    for (int i = batch_dims_ + 1; i < params.dims(); ++i) {\n      result_shape.AddDim(params.dim_size(i));\n    }\n```\n\nIn debug mode, `.dim_size(i)` validates that the argument is less than `.dims()` using a `DCHECK`. But the `DCHECK` is a no-op in release builds.\n\n### Patches\nWe have patched the issue in GitHub commit [bc9c546ce7015c57c2f15c168b3d9201de679a1d](https://github.com/tensorflow/tensorflow/commit/bc9c546ce7015c57c2f15c168b3d9201de679a1d).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/bc9c546ce7015c57c2f15c168b3d9201de679a1d",
      "commit_sha": "bc9c546ce7015c57c2f15c168b3d9201de679a1d",
      "patch": "SINGLE",
      "chain_ord": "['bc9c546ce7015c57c2f15c168b3d9201de679a1d']",
      "before_first_fix_commit": "{'d5f28c9b17220a9c7b3a4c93fc6c3fea6949cadd'}",
      "last_fix_commit": "bc9c546ce7015c57c2f15c168b3d9201de679a1d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/31/2021, 04:37:59",
      "message": "Prevent heap oob access in `resource_variable_ops.cc`\n\nPiperOrigin-RevId: 387936433\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/resource_variable_ops.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/bc9c546ce7015c57c2f15c168b3d9201de679a1d/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.cc', 'patch': '@@ -660,6 +660,11 @@ class ResourceGatherOp : public OpKernel {\\n     OP_REQUIRES(\\n         c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\\n         errors::InvalidArgument(\"params must be at least 1 dimensional\"));\\n+    OP_REQUIRES(\\n+        c, params.shape().dims() >= batch_dims_,\\n+        errors::InvalidArgument(\"params must have at least \", batch_dims_,\\n+                                \" (batch_dims) dimensions but it has shape \",\\n+                                params.shape().DebugString()));\\n \\n     // Check that we have enough index space\\n     const int64_t N = indices.NumElements();'}}",
      "message_norm": "prevent heap oob access in `resource_variable_ops.cc`\n\npiperorigin-revid: 387936433\nchange-id: i9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('387936433', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/resource_variable_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3370,
      "vuln_id": "GHSA-x55w-vjjp-222r",
      "cwe_id": "{'CWE-1333'}",
      "score": 7.5,
      "chain": "{'https://github.com/pksunkara/inflect/commit/a9a0a8e9561c3487854c7cae42565d9652ec858b'}",
      "dataset": "osv",
      "summary": "inflect vulnerable to Inefficient Regular Expression Complexity inflect is customizable inflections for nodejs. inflect is vulnerable to Inefficient Regular Expression Complexity",
      "published_date": "2021-09-29",
      "chain_len": 1,
      "project": "https://github.com/pksunkara/inflect",
      "commit_href": "https://github.com/pksunkara/inflect/commit/a9a0a8e9561c3487854c7cae42565d9652ec858b",
      "commit_sha": "a9a0a8e9561c3487854c7cae42565d9652ec858b",
      "patch": "SINGLE",
      "chain_ord": "['a9a0a8e9561c3487854c7cae42565d9652ec858b']",
      "before_first_fix_commit": "{'c025e153df847bbb2873ae75b1a7bd77b0526745'}",
      "last_fix_commit": "a9a0a8e9561c3487854c7cae42565d9652ec858b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/21/2021, 10:49:42",
      "message": "Fix CVE-2021-3820",
      "author": "Pavan Kumar Sunkara",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'lib/methods.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/pksunkara/inflect/raw/a9a0a8e9561c3487854c7cae42565d9652ec858b/lib%2Fmethods.js', 'patch': '@@ -61,7 +61,7 @@ inflect.camelize = function (lower_case_and_underscored_word, first_letter_in_up\\n inflect.underscore = function (camel_cased_word) {\\n   var self;\\n   self = util.string.gsub(camel_cased_word, /\\\\./, \\'/\\');\\n-  self = util.string.gsub(self, /([A-Z]+)([A-Z][a-z])/, \\'$1_$2\\');\\n+  self = util.string.gsub(self, /([A-Z])([A-Z][a-z])/, \\'$1_$2\\');\\n   self = util.string.gsub(self, /([a-z\\\\d])([A-Z])/, \\'$1_$2\\');\\n   self = util.string.gsub(self, /-/, \\'_\\');\\n   return self.toLowerCase();\\n@@ -230,5 +230,5 @@ inflect.tableize = function (class_name) {\\n //\\n //     \"business\".classify()       // => \"Busines\"\\n inflect.classify = function (table_name) {\\n-  return inflect.camelize(inflect.singularize(util.string.gsub(table_name, /.*\\\\./, \\'\\')));\\n+  return inflect.camelize(inflect.singularize(util.string.gsub(table_name, /^.*\\\\./, \\'\\')));\\n };'}}",
      "message_norm": "fix cve-2021-3820",
      "language": "fr",
      "entities": "[('fix', 'ACTION', ''), ('cve-2021-3820', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/methods.js'])",
      "num_files": 1.0
    },
    {
      "index": 2707,
      "vuln_id": "GHSA-q67f-3jq4-mww2",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/pimcore/pimcore/commit/e786fd44aac46febdbf916ed6c328fbe645d80bf'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in Pimcore Pimcore version 10.3.2 and prior is vulnerable to stored cross-site scripting. A patch is available and anticipated to be part of version 10.3.3.",
      "published_date": "2022-03-05",
      "chain_len": 1,
      "project": "https://github.com/pimcore/pimcore",
      "commit_href": "https://github.com/pimcore/pimcore/commit/e786fd44aac46febdbf916ed6c328fbe645d80bf",
      "commit_sha": "e786fd44aac46febdbf916ed6c328fbe645d80bf",
      "patch": "SINGLE",
      "chain_ord": "['e786fd44aac46febdbf916ed6c328fbe645d80bf']",
      "before_first_fix_commit": "{'ce5c01f4c9f477444aeceb640b60f3b6199e7c22'}",
      "last_fix_commit": "e786fd44aac46febdbf916ed6c328fbe645d80bf",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/02/2022, 20:15:07",
      "message": "escaping 'key' custom property field in elements",
      "author": "JiaJia Ji",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 2, 'total': 5}",
      "files": "{'bundles/AdminBundle/Resources/public/js/pimcore/element/properties.js': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/pimcore/pimcore/raw/e786fd44aac46febdbf916ed6c328fbe645d80bf/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Felement%2Fproperties.js', 'patch': '@@ -568,10 +568,11 @@ pimcore.element.properties = Class.create({\\n \\n     addSetFromUserDefined: function (customKey, customType) {\\n         try {\\n-            if (in_array(customKey.getValue(), this.disallowedKeys)) {\\n+            let key = htmlspecialchars(customKey.getValue());\\n+            if (in_array(key, this.disallowedKeys)) {\\n                 Ext.MessageBox.alert(t(\"error\"), t(\"name_is_not_allowed\"));\\n             }\\n-            this.add(customKey.getValue(), customType.getValue(), false, false, false, true);\\n+            this.add(key, customType.getValue(), false, false, false, true);\\n         } catch (e) {\\n             console.log(e);\\n         }'}}",
      "message_norm": "escaping 'key' custom property field in elements",
      "language": "en",
      "entities": "[('escaping', 'SECWORD', ''), ('key', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['bundles/AdminBundle/Resources/public/js/pimcore/element/properties.js'])",
      "num_files": 1.0
    },
    {
      "index": 1562,
      "vuln_id": "GHSA-cjg2-2fjg-fph4",
      "cwe_id": "{'CWE-191'}",
      "score": 0.0,
      "chain": "{'https://github.com/paritytech/frontier/commit/8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664'}",
      "dataset": "osv",
      "summary": "Integer underflow in Frontier ### Impact\n\nA bug in Frontier's MODEXP precompile implementation can cause an integer underflow in certain conditions. This will cause a node crash for debug builds. For release builds (and production WebAssembly binaries), the impact is limited as it can only cause a normal EVM out-of-gas. It is recommended that you apply the patch as soon as possible.\n\nIf you do not use MODEXP precompile in your runtime, then you are not impacted.\n\n### Patches\n\nPatches are applied in PR #549.\n\n### Workarounds\n\nNone.\n\n### References\n\nPatch PR: #549\n\n### Credits\n\nThanks to SR-Labs for discovering the security vulnerability, and thanks to PureStake team for the patches.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an issue in the [Frontier repo](https://github.com/paritytech/frontier)",
      "published_date": "2022-01-14",
      "chain_len": 1,
      "project": "https://github.com/paritytech/frontier",
      "commit_href": "https://github.com/paritytech/frontier/commit/8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664",
      "commit_sha": "8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664",
      "patch": "SINGLE",
      "chain_ord": "['8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664']",
      "before_first_fix_commit": "{'6dd07a4d581a4c00bb2a2238a81997fc75bc2127'}",
      "last_fix_commit": "8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/13/2022, 16:23:07",
      "message": "Handle 0 exponent with fudged length correctly in ModExp (#549)\n\n* Handle 0 exponent with fudged length correctly in ModExp\r\n\r\n* cargo fmt\r\n\r\n* Revert to following EIP-2565 strictly, subtract after adding terms to prevent underflow\r\n\r\n* Update frame/evm/precompile/modexp/src/lib.rs\r\n\r\nClean up test case\r\n\r\nCo-authored-by: Wei Tang <accounts@that.world>\r\n\r\n* More revert\r\n\r\n* cargo fmt\r\n\r\n* Prefer expect to match\r\n\r\nCo-authored-by: Wei Tang <accounts@that.world>",
      "author": "Stephen Shelton",
      "comments": null,
      "stats": "{'additions': 51, 'deletions': 5, 'total': 56}",
      "files": "{'frame/evm/precompile/modexp/src/lib.rs': {'additions': 51, 'deletions': 5, 'changes': 56, 'status': 'modified', 'raw_url': 'https://github.com/paritytech/frontier/raw/8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664/frame%2Fevm%2Fprecompile%2Fmodexp%2Fsrc%2Flib.rs', 'patch': '@@ -47,7 +47,10 @@ fn calculate_gas_cost(\\n \\t\\t\\twords += 1;\\n \\t\\t}\\n \\n-\\t\\t// TODO: prevent/handle overflow\\n+\\t\\t// Note: can\\'t overflow because we take words to be some u64 value / 8, which is\\n+\\t\\t// necessarily less than sqrt(u64::MAX).\\n+\\t\\t// Additionally, both base_length and mod_length are bounded to 1024, so this has\\n+\\t\\t// an upper bound of roughly (1024 / 8) squared\\n \\t\\twords * words\\n \\t}\\n \\n@@ -63,8 +66,17 @@ fn calculate_gas_cost(\\n \\t\\t\\tlet bytes: [u8; 32] = [0xFF; 32];\\n \\t\\t\\tlet max_256_bit_uint = BigUint::from_bytes_be(&bytes);\\n \\n+\\t\\t\\t// from the EIP spec:\\n+\\t\\t\\t// (8 * (exp_length - 32)) + ((exponent & (2**256 - 1)).bit_length() - 1)\\n+\\t\\t\\t//\\n+\\t\\t\\t// Notes:\\n+\\t\\t\\t// * exp_length is bounded to 1024 and is > 32\\n+\\t\\t\\t// * exponent can be zero, so we subtract 1 after adding the other terms (whose sum\\n+\\t\\t\\t//   must be > 0)\\n+\\t\\t\\t// * the addition can\\'t overflow because the terms are both capped at roughly\\n+\\t\\t\\t//   8 * max size of exp_length (1024)\\n \\t\\t\\titeration_count =\\n-\\t\\t\\t\\t(8 * (exp_length - 32)) + ((exponent.bitand(max_256_bit_uint)).bits() - 1);\\n+\\t\\t\\t\\t(8 * (exp_length - 32)) + exponent.bitand(max_256_bit_uint).bits() - 1;\\n \\t\\t}\\n \\n \\t\\tmax(iteration_count, 1)\\n@@ -89,7 +101,7 @@ fn calculate_gas_cost(\\n // 6) modulus, size as described above\\n //\\n //\\n-// NOTE: input sizes are arbitrarily large (up to 256 bits), with the expectation\\n+// NOTE: input sizes are bound to 1024 bytes, with the expectation\\n //       that gas limits would be applied before actual computation.\\n //\\n //       maximum stack size will also prevent abuse.\\n@@ -133,7 +145,7 @@ impl Precompile for Modexp {\\n \\t\\tlet mod_len_big = BigUint::from_bytes_be(&buf);\\n \\t\\tif mod_len_big > max_size_big {\\n \\t\\t\\treturn Err(PrecompileFailure::Error {\\n-\\t\\t\\t\\texit_status: ExitError::Other(\"unreasonably large exponent length\".into()),\\n+\\t\\t\\t\\texit_status: ExitError::Other(\"unreasonably large modulus length\".into()),\\n \\t\\t\\t});\\n \\t\\t}\\n \\n@@ -162,7 +174,6 @@ impl Precompile for Modexp {\\n \\t\\t\\tlet exponent = BigUint::from_bytes_be(&input[exp_start..exp_start + exp_len]);\\n \\n \\t\\t\\t// do our gas accounting\\n-\\t\\t\\t// TODO: we could technically avoid reading base first...\\n \\t\\t\\tlet gas_cost =\\n \\t\\t\\t\\tcalculate_gas_cost(base_len as u64, exp_len as u64, mod_len as u64, &exponent);\\n \\t\\t\\tif let Some(gas_left) = target_gas {\\n@@ -423,4 +434,39 @@ mod tests {\\n \\t\\t\\t}\\n \\t\\t}\\n \\t}\\n+\\n+\\t#[test]\\n+\\tfn test_zero_exp_with_33_length() {\\n+\\t\\t// This is a regression test which ensures that the \\'iteration_count\\' calculation\\n+\\t\\t// in \\'calculate_iteration_count\\' cannot underflow.\\n+\\t\\t//\\n+\\t\\t// In debug mode, this underflow could cause a panic. Otherwise, it causes N**0 to\\n+\\t\\t// be calculated at more-than-normal expense.\\n+\\t\\t//\\n+\\t\\t// TODO: cite security advisory\\n+\\n+\\t\\tlet input = vec![\\n+\\t\\t\\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n+\\t\\t\\t0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n+\\t\\t\\t0, 0, 0, 0, 0, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n+\\t\\t\\t0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n+\\t\\t\\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\\n+\\t\\t];\\n+\\n+\\t\\tlet cost: u64 = 100000;\\n+\\n+\\t\\tlet context: Context = Context {\\n+\\t\\t\\taddress: Default::default(),\\n+\\t\\t\\tcaller: Default::default(),\\n+\\t\\t\\tapparent_value: From::from(0),\\n+\\t\\t};\\n+\\n+\\t\\tlet precompile_result = Modexp::execute(&input, Some(cost), &context, false)\\n+\\t\\t\\t.expect(\"Modexp::execute() returned error\");\\n+\\n+\\t\\tassert_eq!(precompile_result.output.len(), 1); // should be same length as mod\\n+\\t\\tlet result = BigUint::from_bytes_be(&precompile_result.output[..]);\\n+\\t\\tlet expected = BigUint::parse_bytes(b\"0\", 10).unwrap();\\n+\\t\\tassert_eq!(result, expected);\\n+\\t}\\n }'}}",
      "message_norm": "handle 0 exponent with fudged length correctly in modexp (#549)\n\n* handle 0 exponent with fudged length correctly in modexp\r\n\r\n* cargo fmt\r\n\r\n* revert to following eip-2565 strictly, subtract after adding terms to prevent underflow\r\n\r\n* update frame/evm/precompile/modexp/src/lib.rs\r\n\r\nclean up test case\r\n\r\nco-authored-by: wei tang <accounts@that.world>\r\n\r\n* more revert\r\n\r\n* cargo fmt\r\n\r\n* prefer expect to match\r\n\r\nco-authored-by: wei tang <accounts@that.world>",
      "language": "en",
      "entities": "[('#549', 'ISSUE', ''), ('adding', 'ACTION', ''), ('prevent', 'ACTION', ''), ('underflow', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['frame/evm/precompile/modexp/src/lib.rs'])",
      "num_files": 1.0
    },
    {
      "index": 2039,
      "vuln_id": "GHSA-hc6c-75p4-hmq4",
      "cwe_id": "{'CWE-476'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/a7116dd3913c4a4afd2a3a938573aa7c785fdfc6'}",
      "dataset": "osv",
      "summary": "Reference binding to null pointer in `MatrixDiag*` ops ### Impact\nThe implementation of [`MatrixDiag*` operations](https://github.com/tensorflow/tensorflow/blob/4c4f420e68f1cfaf8f4b6e8e3eb857e9e4c3ff33/tensorflow/core/kernels/linalg/matrix_diag_op.cc#L195-L197) does not validate that the tensor arguments are non-empty:\n\n```cc\n      num_rows = context->input(2).flat<int32>()(0);\n      num_cols = context->input(3).flat<int32>()(0);\n      padding_value = context->input(4).flat<T>()(0); \n``` \n\nThus, users can trigger null pointer dereferences if any of the above tensors are null:\n\n```python\nimport tensorflow as tf\n\nd = tf.convert_to_tensor([],dtype=tf.float32)\np = tf.convert_to_tensor([],dtype=tf.float32)\ntf.raw_ops.MatrixDiagV2(diagonal=d, k=0, num_rows=0, num_cols=0, padding_value=p)\n```\n\nChanging from `tf.raw_ops.MatrixDiagV2` to `tf.raw_ops.MatrixDiagV3` still reproduces the issue.\n\n### Patches\nWe have patched the issue in GitHub commit [a7116dd3913c4a4afd2a3a938573aa7c785fdfc6](https://github.com/tensorflow/tensorflow/commit/a7116dd3913c4a4afd2a3a938573aa7c785fdfc6).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ye Zhang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/a7116dd3913c4a4afd2a3a938573aa7c785fdfc6",
      "commit_sha": "a7116dd3913c4a4afd2a3a938573aa7c785fdfc6",
      "patch": "SINGLE",
      "chain_ord": "['a7116dd3913c4a4afd2a3a938573aa7c785fdfc6']",
      "before_first_fix_commit": "{'4c4f420e68f1cfaf8f4b6e8e3eb857e9e4c3ff33'}",
      "last_fix_commit": "a7116dd3913c4a4afd2a3a938573aa7c785fdfc6",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/18/2021, 03:55:53",
      "message": "Validate `MatrixDiagV{2,3}` arguments to prevent breakage.\n\nPiperOrigin-RevId: 369056033\nChange-Id: Ic2018c297d3dd6f252dc1dd3667f1ed5cb1eaa42",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 16, 'deletions': 3, 'total': 19}",
      "files": "{'tensorflow/core/kernels/linalg/matrix_diag_op.cc': {'additions': 16, 'deletions': 3, 'changes': 19, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/a7116dd3913c4a4afd2a3a938573aa7c785fdfc6/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_diag_op.cc', 'patch': '@@ -192,9 +192,22 @@ class MatrixDiagOp : public OpKernel {\\n           upper_diag_index = diag_index.flat<int32>()(1);\\n         }\\n       }\\n-      num_rows = context->input(2).flat<int32>()(0);\\n-      num_cols = context->input(3).flat<int32>()(0);\\n-      padding_value = context->input(4).flat<T>()(0);\\n+\\n+      auto& num_rows_tensor = context->input(2);\\n+      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_rows_tensor.shape()),\\n+                  errors::InvalidArgument(\"num_rows must be a scalar\"));\\n+      num_rows = num_rows_tensor.flat<int32>()(0);\\n+\\n+      auto& num_cols_tensor = context->input(3);\\n+      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_cols_tensor.shape()),\\n+                  errors::InvalidArgument(\"num_cols must be a scalar\"));\\n+      num_cols = num_cols_tensor.flat<int32>()(0);\\n+\\n+      auto& padding_value_tensor = context->input(4);\\n+      OP_REQUIRES(context,\\n+                  TensorShapeUtils::IsScalar(padding_value_tensor.shape()),\\n+                  errors::InvalidArgument(\"padding_value must be a scalar\"));\\n+      padding_value = padding_value_tensor.flat<T>()(0);\\n     }\\n \\n     // Size validations.'}}",
      "message_norm": "validate `matrixdiagv{2,3}` arguments to prevent breakage.\n\npiperorigin-revid: 369056033\nchange-id: ic2018c297d3dd6f252dc1dd3667f1ed5cb1eaa42",
      "language": "en",
      "entities": "[('validate', 'ACTION', ''), ('prevent', 'ACTION', ''), ('369056033', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/linalg/matrix_diag_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 177,
      "vuln_id": "GHSA-32j9-6qqm-mq9g",
      "cwe_id": "{'CWE-241', 'CWE-703'}",
      "score": 7.5,
      "chain": "{'https://github.com/Venemo/node-lmdb/commit/97760104c0fd311206b88aecd91fa1f59fe2b85a'}",
      "dataset": "osv",
      "summary": "Unhandled case in node-lmdb The package node-lmdb before 0.9.7 is vulnerable to Denial of Service (DoS) when defining a non-invokable `ToString` value, which will cause a crash during type check.",
      "published_date": "2022-03-17",
      "chain_len": 1,
      "project": "https://github.com/Venemo/node-lmdb",
      "commit_href": "https://github.com/Venemo/node-lmdb/commit/97760104c0fd311206b88aecd91fa1f59fe2b85a",
      "commit_sha": "97760104c0fd311206b88aecd91fa1f59fe2b85a",
      "patch": "SINGLE",
      "chain_ord": "['97760104c0fd311206b88aecd91fa1f59fe2b85a']",
      "before_first_fix_commit": "{'4b659d1734e02e09b45a29ac81f425f610bd14ea'}",
      "last_fix_commit": "97760104c0fd311206b88aecd91fa1f59fe2b85a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/12/2022, 14:19:20",
      "message": "Perform argument check for putString",
      "author": "Kris Zyp",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'src/txn.cpp': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/Venemo/node-lmdb/raw/97760104c0fd311206b88aecd91fa1f59fe2b85a/src%2Ftxn.cpp', 'patch': '@@ -295,6 +295,8 @@ Nan::NAN_METHOD_RETURN_TYPE TxnWrap::putCommon(Nan::NAN_METHOD_ARGS_TYPE info, v\\n }\\n \\n NAN_METHOD(TxnWrap::putString) {\\n+    if (!info[2]->IsString())\\n+        return Nan::ThrowError(\"Value must be a string.\");\\n     return putCommon(info, [](Nan::NAN_METHOD_ARGS_TYPE info, MDB_val &data) -> void {\\n         CustomExternalStringResource::writeTo(Local<String>::Cast(info[2]), &data);\\n     }, [](MDB_val &data) -> void {'}}",
      "message_norm": "perform argument check for putstring",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/txn.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 1630,
      "vuln_id": "GHSA-cwv3-863g-39vx",
      "cwe_id": "{'CWE-835', 'CWE-674'}",
      "score": 7.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/c6173f5fe66cdbab74f4f869311fe6aae2ba35f4', 'https://github.com/tensorflow/tensorflow/commit/9c1dc920d8ffb4893d6c9d27d1f039607b326743'}",
      "dataset": "osv",
      "summary": "Stack overflow due to looping TFLite subgraph ### Impact\nTFlite graphs must not have loops between nodes. However, this condition was not checked and an attacker could craft models that would result in infinite loop during evaluation. In certain cases, the infinite loop would be replaced by stack overflow due to too many recursive calls.\n\nFor example, the [`While` implementation](https://github.com/tensorflow/tensorflow/blob/106d8f4fb89335a2c52d7c895b7a7485465ca8d9/tensorflow/lite/kernels/while.cc) could be tricked into a scneario where both the body and the loop subgraphs are the same. Evaluating one of the subgraphs means calling the `Eval` function for the other and this quickly exhaust all stack space.\n    \n### Patches \nWe have patched the issue in GitHub commit [9c1dc920d8ffb4893d6c9d27d1f039607b326743](https://github.com/tensorflow/tensorflow/commit/9c1dc920d8ffb4893d6c9d27d1f039607b326743) (for the `While` operator) and in GitHub commit [c6173f5fe66cdbab74f4f869311fe6aae2ba35f4](https://github.com/tensorflow/tensorflow/commit/c6173f5fe66cdbab74f4f869311fe6aae2ba35f4) (in general).\n    \nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/9c1dc920d8ffb4893d6c9d27d1f039607b326743",
      "commit_sha": "9c1dc920d8ffb4893d6c9d27d1f039607b326743",
      "patch": "MULTI",
      "chain_ord": "['9c1dc920d8ffb4893d6c9d27d1f039607b326743', 'c6173f5fe66cdbab74f4f869311fe6aae2ba35f4']",
      "before_first_fix_commit": "{'46b80bd2a8943d5976dc83bd5c0322c0023255a7'}",
      "last_fix_commit": "c6173f5fe66cdbab74f4f869311fe6aae2ba35f4",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 00:47:46",
      "message": "Prevent infinite loop/stack overflow in TFLite `while` op.\n\nPiperOrigin-RevId: 370800333\nChange-Id: I6a2e4ff849da339545c449db2af7e11ce6ff02c3",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'tensorflow/lite/kernels/while.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/9c1dc920d8ffb4893d6c9d27d1f039607b326743/tensorflow%2Flite%2Fkernels%2Fwhile.cc', 'patch': '@@ -138,6 +138,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   auto* subgraphs = this_subgraph->GetSubgraphs();\\n   TF_LITE_ENSURE(context, op_data->cond_subgraph_index < subgraphs->size());\\n   TF_LITE_ENSURE(context, op_data->body_subgraph_index < subgraphs->size());\\n+  TF_LITE_ENSURE(context,\\n+                 op_data->cond_subgraph_index != op_data->body_subgraph_index);\\n \\n   Subgraph* cond_subgraph = (*subgraphs)[op_data->cond_subgraph_index].get();\\n   Subgraph* body_subgraph = (*subgraphs)[op_data->body_subgraph_index].get();'}}",
      "message_norm": "prevent infinite loop/stack overflow in tflite `while` op.\n\npiperorigin-revid: 370800333\nchange-id: i6a2e4ff849da339545c449db2af7e11ce6ff02c3",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('infinite loop', 'SECWORD', ''), ('overflow', 'SECWORD', ''), ('370800333', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/while.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2477,
      "vuln_id": "GHSA-mw75-qvfr-hpmr",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/star7th/showdoc/commit/830c89a4c2c5fd0dd491422bf8e97b4eb5713f55'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in ShowDoc ShowDoc is vulnerable to stored cross-site scripting through file upload in versions 2.10.3 and prior. A patch is available and anticipated to be part of version 2.10.4.",
      "published_date": "2022-03-15",
      "chain_len": 1,
      "project": "https://github.com/star7th/showdoc",
      "commit_href": "https://github.com/star7th/showdoc/commit/830c89a4c2c5fd0dd491422bf8e97b4eb5713f55",
      "commit_sha": "830c89a4c2c5fd0dd491422bf8e97b4eb5713f55",
      "patch": "SINGLE",
      "chain_ord": "['830c89a4c2c5fd0dd491422bf8e97b4eb5713f55']",
      "before_first_fix_commit": "{'da56d1d68702a7a80506245c251e58eaf84cff27', '42c0d9813df3035728b36116a6ce9116e6fa8ed3'}",
      "last_fix_commit": "830c89a4c2c5fd0dd491422bf8e97b4eb5713f55",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/13/2022, 08:03:16",
      "message": "Merge pull request #1628 from ajaysenr/master\n\nUpdate AttachmentModel.class.php",
      "author": "star7th",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 1, 'total': 3}",
      "files": "{'server/Application/Api/Model/AttachmentModel.class.php': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/star7th/showdoc/raw/830c89a4c2c5fd0dd491422bf8e97b4eb5713f55/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': '@@ -303,6 +303,7 @@ public function isDangerFilename($filename){\\n \\t\\t\\t|| $isDangerStr($filename , \".shtm\")\\n \\t\\t\\t|| $isDangerStr($filename , \"%\")\\n \\t\\t\\t|| $isDangerStr($filename , \".xml\")\\n+\\t\\t\\t|| $isDangerStr($filename , \".xxhtml\")\\n \\t\\t) {\\n \\t\\t\\treturn true;\\n \\t\\t}\\n@@ -312,4 +313,4 @@ public function isDangerFilename($filename){\\n \\n \\n \\n-}\\n\\\\ No newline at end of file\\n+}'}}",
      "message_norm": "merge pull request #1628 from ajaysenr/master\n\nupdate attachmentmodel.class.php",
      "language": "en",
      "entities": "[('#1628', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/Application/Api/Model/AttachmentModel.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 676,
      "vuln_id": "GHSA-5q6m-3h65-w53x",
      "cwe_id": "{'CWE-78'}",
      "score": 5.6,
      "chain": "{'https://github.com/facebook/create-react-app/commit/f5e415f3a5b66f07dcc60aba1b445fa7cda97268'}",
      "dataset": "osv",
      "summary": "react-dev-utils OS Command Injection in function `getProcessForPort` react-dev-utils prior to v11.0.4 exposes a function, `getProcessForPort`, where an input argument is concatenated into a command string to be executed. This function is typically used from react-scripts (in Create React App projects), where the usage is safe. Only when this function is manually invoked with user-provided values (ie: by custom code) is there the potential for command injection. If you're consuming it from react-scripts then this issue does not affect you.",
      "published_date": "2021-03-11",
      "chain_len": 1,
      "project": "https://github.com/facebook/create-react-app",
      "commit_href": "https://github.com/facebook/create-react-app/commit/f5e415f3a5b66f07dcc60aba1b445fa7cda97268",
      "commit_sha": "f5e415f3a5b66f07dcc60aba1b445fa7cda97268",
      "patch": "SINGLE",
      "chain_ord": "['f5e415f3a5b66f07dcc60aba1b445fa7cda97268']",
      "before_first_fix_commit": "{'22f46a8d5dfc46fe0f613cd7efbc82344823f461'}",
      "last_fix_commit": "f5e415f3a5b66f07dcc60aba1b445fa7cda97268",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/08/2021, 19:03:16",
      "message": "Security Fix for Command Injection - huntr.dev (#10644)\n\n* Update getProcessForPort.js\r\n\r\n* Update getProcessForPort.js\r\n\r\nCo-authored-by: Zhou Peng <zpbrent@gmail.com>\r\nCo-authored-by: Dan Abramov <dan.abramov@gmail.com>",
      "author": "huntr.dev | the place to protect open source",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 1, 'total': 3}",
      "files": "{'packages/react-dev-utils/getProcessForPort.js': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/facebook/create-react-app/raw/f5e415f3a5b66f07dcc60aba1b445fa7cda97268/packages%2Freact-dev-utils%2FgetProcessForPort.js', 'patch': \"@@ -9,6 +9,7 @@\\n \\n var chalk = require('chalk');\\n var execSync = require('child_process').execSync;\\n+var execFileSync = require('child_process').execFileSync;\\n var path = require('path');\\n \\n var execOptions = {\\n@@ -25,7 +26,7 @@ function isProcessAReactApp(processCommand) {\\n }\\n \\n function getProcessIdOnPort(port) {\\n-  return execSync('lsof -i:' + port + ' -P -t -sTCP:LISTEN', execOptions)\\n+  return execFileSync('lsof', ['-i:' + port, '-P', '-t', '-sTCP:LISTEN'], execOptions)\\n     .split('\\\\n')[0]\\n     .trim();\\n }\"}}",
      "message_norm": "security fix for command injection - huntr.dev (#10644)\n\n* update getprocessforport.js\r\n\r\n* update getprocessforport.js\r\n\r\nco-authored-by: zhou peng <zpbrent@gmail.com>\r\nco-authored-by: dan abramov <dan.abramov@gmail.com>",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('command injection', 'SECWORD', ''), ('#10644', 'ISSUE', ''), ('zpbrent@gmail.com', 'EMAIL', ''), ('dan.abramov@gmail.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['packages/react-dev-utils/getProcessForPort.js'])",
      "num_files": 1.0
    },
    {
      "index": 1285,
      "vuln_id": "GHSA-8xqr-4cpm-wx7g",
      "cwe_id": "{'CWE-79'}",
      "score": 0.0,
      "chain": "{'https://github.com/tanem/react-svg/pull/57/commits/ec7de5d678f53a085cee1348cb1aa069c9fc42fb'}",
      "dataset": "osv",
      "summary": "Cross-Site Scripting in react-svg Versions of `react-svg` before 2.2.18 are vulnerable to cross-site scripting (xss). This is due to the fact that scripts found in SVG files are run by default.\n\n\n## Recommendation\n\nUpdate to version 2.2.18 or later.",
      "published_date": "2019-05-31",
      "chain_len": 1,
      "project": "https://github.com/tanem/react-svg",
      "commit_href": "https://github.com/tanem/react-svg/pull/57/commits/ec7de5d678f53a085cee1348cb1aa069c9fc42fb",
      "commit_sha": "ec7de5d678f53a085cee1348cb1aa069c9fc42fb",
      "patch": "SINGLE",
      "chain_ord": "['ec7de5d678f53a085cee1348cb1aa069c9fc42fb']",
      "before_first_fix_commit": "{'9fa13da92cc4c44a10b6e2aced023d3199e8c6bb'}",
      "last_fix_commit": "ec7de5d678f53a085cee1348cb1aa069c9fc42fb",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/21/2018, 18:37:51",
      "message": "Changed default evalScripts prop to match documentation.",
      "author": "Ron Perris",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tanem/react-svg/raw/ec7de5d678f53a085cee1348cb1aa069c9fc42fb/src%2Findex.js', 'patch': \"@@ -10,7 +10,7 @@ export default class ReactSVG extends React.Component {\\n   static defaultProps = {\\n     callback: () => {},\\n     className: null,\\n-    evalScripts: 'once',\\n+    evalScripts: 'never',\\n     style: {},\\n     wrapperClassName: null\\n   }\"}}",
      "message_norm": "changed default evalscripts prop to match documentation.",
      "language": "en",
      "entities": "[('changed', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1682,
      "vuln_id": "GHSA-f7f4-hqp2-7prc",
      "cwe_id": "{'CWE-20'}",
      "score": 7.5,
      "chain": "{'https://github.com/balderdashy/sails-hook-sockets/commit/ff02114eaec090ee51db48435cc32d451662606e', 'https://github.com/balderdashy/sails-hook-sockets/commit/0533a4864b1920fd8fbb5287bc0889193c5faf44'}",
      "dataset": "osv",
      "summary": "Improper Input Validation in sails-hook-sockets Sails.js before v1.0.0-46 allows attackers to cause a denial of service with a single request because there is no error handler in sails-hook-sockets to handle an empty pathname in a WebSocket request.",
      "published_date": "2020-07-24",
      "chain_len": 2,
      "project": "https://github.com/balderdashy/sails-hook-sockets",
      "commit_href": "https://github.com/balderdashy/sails-hook-sockets/commit/ff02114eaec090ee51db48435cc32d451662606e",
      "commit_sha": "ff02114eaec090ee51db48435cc32d451662606e",
      "patch": "MULTI",
      "chain_ord": "['ff02114eaec090ee51db48435cc32d451662606e', '0533a4864b1920fd8fbb5287bc0889193c5faf44']",
      "before_first_fix_commit": "{'4f78b7946f7a7ac4c762936d7633298606c1e4a7'}",
      "last_fix_commit": "0533a4864b1920fd8fbb5287bc0889193c5faf44",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/23/2018, 21:18:38",
      "message": "Define req.path for socket requests.",
      "author": "Mike McNeil",
      "comments": "{'com_1': {'author': 'mikermcneil', 'datetime': '10/01/2018, 15:34:06', 'body': 'Thanks Ali!'}}",
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'lib/receive-incoming-sails-io-msg.js': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/balderdashy/sails-hook-sockets/raw/ff02114eaec090ee51db48435cc32d451662606e/lib%2Freceive-incoming-sails-io-msg.js', 'patch': \"@@ -3,6 +3,7 @@\\n  */\\n \\n var util = require('util');\\n+var url = require('url');\\n var _ = require('@sailshq/lodash');\\n var semver = require('semver');\\n var parseSdkMetadata = require('./parse-sdk-metadata');\\n@@ -105,6 +106,8 @@ module.exports = function ToReceiveIncomingSailsIOMsg(app) {\\n \\n       url     : options.incomingSailsIOMsg.url,\\n \\n+      path    : url.parse(options.incomingSailsIOMsg.url).pathname,\\n+\\n       method  : options.eventName,\\n \\n       // Attached data becomes simulated HTTP body (`req.body`)\"}}",
      "message_norm": "define req.path for socket requests.",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/receive-incoming-sails-io-msg.js'])",
      "num_files": 1.0
    },
    {
      "index": 12,
      "vuln_id": "GHSA-23fp-fmrv-f5px",
      "cwe_id": "{'CWE-400'}",
      "score": 4.9,
      "chain": "{'https://github.com/strapi/strapi/commit/c0c191c08f05fe10d7a6b1bf9475c1a651a89362'}",
      "dataset": "osv",
      "summary": "Uncontrolled Resource Consumption in strapi A denial of service exists in strapi v3.0.0-beta.18.3 and earlier that can be abused in the admin console using admin rights can lead to arbitrary restart of the application.",
      "published_date": "2021-12-10",
      "chain_len": 1,
      "project": "https://github.com/strapi/strapi",
      "commit_href": "https://github.com/strapi/strapi/commit/c0c191c08f05fe10d7a6b1bf9475c1a651a89362",
      "commit_sha": "c0c191c08f05fe10d7a6b1bf9475c1a651a89362",
      "patch": "SINGLE",
      "chain_ord": "['c0c191c08f05fe10d7a6b1bf9475c1a651a89362']",
      "before_first_fix_commit": "{'7e3f7ee2de9eecd0bc098d7b77940b64f48b3a96'}",
      "last_fix_commit": "c0c191c08f05fe10d7a6b1bf9475c1a651a89362",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/07/2020, 13:15:16",
      "message": "chore(admin): Improve plugin name validator in install/uninstall plugin",
      "author": "Alexandre Bodin",
      "comments": null,
      "stats": "{'additions': 13, 'deletions': 2, 'total': 15}",
      "files": "{'packages/strapi-admin/controllers/Admin.js': {'additions': 13, 'deletions': 2, 'changes': 15, 'status': 'modified', 'raw_url': 'https://github.com/strapi/strapi/raw/c0c191c08f05fe10d7a6b1bf9475c1a651a89362/packages%2Fstrapi-admin%2Fcontrollers%2FAdmin.js', 'patch': '@@ -7,6 +7,17 @@ const formatError = error => [\\n   { messages: [{ id: error.id, message: error.message, field: error.field }] },\\n ];\\n \\n+const PLUGIN_NAME_REGEX = /^[A-Za-z][A-Za-z0-9-_]+$/;\\n+\\n+/**\\n+ * Validates a plugin name format\\n+ */\\n+const isValidPluginName = plugin => {\\n+  return (\\n+    _.isString(plugin) && !_.isEmpty(plugin) && PLUGIN_NAME_REGEX.test(plugin)\\n+  );\\n+};\\n+\\n /**\\n  * A set of functions called \"actions\" for `Admin`\\n  */\\n@@ -67,7 +78,7 @@ module.exports = {\\n     try {\\n       const { plugin } = ctx.request.body;\\n \\n-      if (!/^[A-Za-z0-9_-]+$/.test(plugin)) {\\n+      if (!isValidPluginName(plugin)) {\\n         return ctx.badRequest(\\'Invalid plugin name\\');\\n       }\\n \\n@@ -107,7 +118,7 @@ module.exports = {\\n     try {\\n       const { plugin } = ctx.params;\\n \\n-      if (!/^[A-Za-z0-9_-]+$/.test(plugin)) {\\n+      if (!isValidPluginName(plugin)) {\\n         return ctx.badRequest(\\'Invalid plugin name\\');\\n       }'}}",
      "message_norm": "chore(admin): improve plugin name validator in install/uninstall plugin",
      "language": "it",
      "entities": "[('chore(admin', 'SECWORD', ''), ('improve', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['packages/strapi-admin/controllers/Admin.js'])",
      "num_files": 1.0
    },
    {
      "index": 3504,
      "vuln_id": "GHSA-xw93-v57j-fcgh",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/7f283ff806b2031f407db64c4d3edcda8fb9f9f5'}",
      "dataset": "osv",
      "summary": "Division by 0 in `SparseMatMul` ### Impact\nAn attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.SparseMatMul`:\n\n```python\nimport tensorflow as tf\n\na = tf.constant([100.0, 100.0, 100.0, 100.0], shape=[2, 2], dtype=tf.float32)\nb = tf.constant([], shape=[0, 2], dtype=tf.float32)\n\ntf.raw_ops.SparseMatMul(\n    a=a, b=b, transpose_a=True, transpose_b=True,\n    a_is_sparse=True, b_is_sparse=True)\n``` \n    \nThe division by 0 occurs deep in Eigen code because the `b` tensor is empty.\n    \n### Patches\nWe have patched the issue in GitHub commit [7f283ff806b2031f407db64c4d3edcda8fb9f9f5](https://github.com/tensorflow/tensorflow/commit/7f283ff806b2031f407db64c4d3edcda8fb9f9f5).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
      "commit_sha": "7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
      "patch": "SINGLE",
      "chain_ord": "['7f283ff806b2031f407db64c4d3edcda8fb9f9f5']",
      "before_first_fix_commit": "{'05a63e605a31e86c5dd96c5c8a763eda9ac7bb33'}",
      "last_fix_commit": "7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 22:00:39",
      "message": "Fix FPE issue in external Eigen source code issue with `tf.raw_ops.SparseMatMul`.\n\nPiperOrigin-RevId: 370992919\nChange-Id: Icfb276fef5fb40928b27c3e44608d2aca72c9fd7",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'tensorflow/core/kernels/sparse_matmul_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/7f283ff806b2031f407db64c4d3edcda8fb9f9f5/tensorflow%2Fcore%2Fkernels%2Fsparse_matmul_op.cc', 'patch': '@@ -1039,6 +1039,10 @@ class SparseMatMulOp : public OpKernel {\\n     if (transpose_b) {\\n       // TODO(agarwal): avoid transposing the matrix here and directly handle\\n       // transpose in CreateDenseSlices.\\n+      OP_REQUIRES(ctx, right->dim_size(0) != 0,\\n+                  errors::InvalidArgument(\"b has an entry 0 in it\\'s shape.\"));\\n+      OP_REQUIRES(ctx, right->dim_size(1) != 0,\\n+                  errors::InvalidArgument(\"b has an entry 0 in it\\'s shape.\"));\\n       right_tr.reset(\\n           new Tensor(right->dtype(),\\n                      TensorShape({right->dim_size(1), right->dim_size(0)})));'}}",
      "message_norm": "fix fpe issue in external eigen source code issue with `tf.raw_ops.sparsematmul`.\n\npiperorigin-revid: 370992919\nchange-id: icfb276fef5fb40928b27c3e44608d2aca72c9fd7",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('issue', 'FLAW', ''), ('issue', 'FLAW', ''), ('370992919', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_matmul_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 823,
      "vuln_id": "GHSA-6f89-8j54-29xf",
      "cwe_id": "{'CWE-787', 'CWE-119'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/12c727cee857fa19be717f336943d95fca4ffe4f'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `FractionalAvgPoolGrad` ### Impact\nThe implementation of `tf.raw_ops.FractionalAvgPoolGrad` is vulnerable to a heap buffer overflow:\n  \n```python\nimport tensorflow as tf\n\norig_input_tensor_shape = tf.constant([1, 3, 2, 3], shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([2], shape=[1, 1, 1, 1], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\n\n\ntf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/dcba796a28364d6d7f003f6fe733d82726dda713/tensorflow/core/kernels/fractional_avg_pool_op.cc#L216) fails to validate that the pooling sequence arguments have enough elements as required by the `out_backprop` tensor shape.\n\n### Patches\nWe have patched the issue in GitHub commit [12c727cee857fa19be717f336943d95fca4ffe4f](https://github.com/tensorflow/tensorflow/commit/12c727cee857fa19be717f336943d95fca4ffe4f).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/12c727cee857fa19be717f336943d95fca4ffe4f",
      "commit_sha": "12c727cee857fa19be717f336943d95fca4ffe4f",
      "patch": "SINGLE",
      "chain_ord": "['12c727cee857fa19be717f336943d95fca4ffe4f']",
      "before_first_fix_commit": "{'dcba796a28364d6d7f003f6fe733d82726dda713'}",
      "last_fix_commit": "12c727cee857fa19be717f336943d95fca4ffe4f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/06/2021, 21:02:47",
      "message": "Validate inputs of `FractionalAvgPoolGrad`.\n\nPiperOrigin-RevId: 372420640\nChange-Id: Icc583928e6cdc3062e12498e4d2337a8fe3da016",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 13, 'deletions': 0, 'total': 13}",
      "files": "{'tensorflow/core/kernels/fractional_avg_pool_op.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/12c727cee857fa19be717f336943d95fca4ffe4f/tensorflow%2Fcore%2Fkernels%2Ffractional_avg_pool_op.cc', 'patch': '@@ -250,6 +250,19 @@ class FractionalAvgPoolGradOp : public OpKernel {\\n     const int64 out_cols = out_backprop.dim_size(2);\\n     const int64 out_depth = out_backprop.dim_size(3);\\n \\n+    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\\n+                errors::InvalidArgument(\"Given out_backprop shape \",\\n+                                        out_backprop.shape().DebugString(),\\n+                                        \", row_seq_tensor must have at least \",\\n+                                        out_rows + 1, \" elements, but got \",\\n+                                        row_seq_tensor.NumElements()));\\n+    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\\n+                errors::InvalidArgument(\"Given out_backprop shape \",\\n+                                        out_backprop.shape().DebugString(),\\n+                                        \", col_seq_tensor must have at least \",\\n+                                        out_cols + 1, \" elements, but got \",\\n+                                        col_seq_tensor.NumElements()));\\n+\\n     auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();\\n     auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();\\n     auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();'}}",
      "message_norm": "validate inputs of `fractionalavgpoolgrad`.\n\npiperorigin-revid: 372420640\nchange-id: icc583928e6cdc3062e12498e4d2337a8fe3da016",
      "language": "it",
      "entities": "[('validate', 'ACTION', ''), ('372420640', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/fractional_avg_pool_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1143,
      "vuln_id": "GHSA-85wq-pqhp-hmq6",
      "cwe_id": "{'CWE-352'}",
      "score": 8.8,
      "chain": "{'https://github.com/jenkinsci/jenkins/commit/3c5e5ca63d9a1ac1c4087682dc0d426625eafed8', 'https://github.com/jenkinsci/jenkins/commit/e69c28e44dae41322112471e1c80f840bde314d4', 'https://github.com/jenkinsci/jenkins/commit/23f4809e6c10a221e9d67f2e841536845387b42d'}",
      "dataset": "osv",
      "summary": "Cross-Site Request Forgery in Jenkins Jenkins versions 2.56 and earlier as well as 2.46.1 LTS and earlier are vulnerable to an issue in the Jenkins user database authentication realm: create an account if signup is enabled; or create an account if the victim is an administrator, possibly deleting the existing default admin user in the process and allowing a wide variety of impacts.",
      "published_date": "2022-05-14",
      "chain_len": 3,
      "project": "https://github.com/jenkinsci/jenkins",
      "commit_href": "https://github.com/jenkinsci/jenkins/commit/e69c28e44dae41322112471e1c80f840bde314d4",
      "commit_sha": "e69c28e44dae41322112471e1c80f840bde314d4",
      "patch": "MULTI",
      "chain_ord": "['3c5e5ca63d9a1ac1c4087682dc0d426625eafed8', 'e69c28e44dae41322112471e1c80f840bde314d4', '23f4809e6c10a221e9d67f2e841536845387b42d']",
      "before_first_fix_commit": "{'eeb699ed8c2ce937f2b836692b36a98da7bb5622'}",
      "last_fix_commit": "23f4809e6c10a221e9d67f2e841536845387b42d",
      "chain_ord_pos": 2.0,
      "commit_datetime": "04/01/2017, 17:41:02",
      "message": "[SECURITY-412] Fix handling of restart/safeRestart URLs",
      "author": "Daniel Beck",
      "comments": null,
      "stats": "{'additions': 21, 'deletions': 8, 'total': 29}",
      "files": "{'core/src/main/java/jenkins/model/Jenkins.java': {'additions': 21, 'deletions': 8, 'changes': 29, 'status': 'modified', 'raw_url': 'https://github.com/jenkinsci/jenkins/raw/e69c28e44dae41322112471e1c80f840bde314d4/core%2Fsrc%2Fmain%2Fjava%2Fjenkins%2Fmodel%2FJenkins.java', 'patch': '@@ -3367,19 +3367,25 @@ public DirectoryBrowserSupport doUserContent() {\\n      *\\n      * This first replaces \"app\" to {@link HudsonIsRestarting}\\n      */\\n-    @CLIMethod(name=\"restart\")\\n-    @RequirePOST\\n     public void doRestart(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException, RestartNotSupportedException {\\n         checkPermission(ADMINISTER);\\n         if (req != null && req.getMethod().equals(\"GET\")) {\\n             req.getView(this,\"_restart.jelly\").forward(req,rsp);\\n             return;\\n         }\\n \\n-        restart();\\n+        if (req != null && req.getMethod().equals(\"POST\")) {\\n+            restart();\\n+        }\\n \\n-        if (rsp != null) // null for CLI\\n-            rsp.sendRedirect2(\".\");\\n+        rsp.sendRedirect2(\".\");\\n+    }\\n+\\n+    @CLIMethod(name=\"restart\")\\n+    @Restricted(NoExternalUse.class)\\n+    public void cliRestart() throws RestartNotSupportedException {\\n+        checkPermission(ADMINISTER);\\n+        restart();\\n     }\\n \\n     /**\\n@@ -3389,18 +3395,25 @@ public void doRestart(StaplerRequest req, StaplerResponse rsp) throws IOExceptio\\n      *\\n      * @since 1.332\\n      */\\n-    @CLIMethod(name=\"safe-restart\")\\n-    @RequirePOST\\n     public HttpResponse doSafeRestart(StaplerRequest req) throws IOException, ServletException, RestartNotSupportedException {\\n         checkPermission(ADMINISTER);\\n         if (req != null && req.getMethod().equals(\"GET\"))\\n             return HttpResponses.forwardToView(this,\"_safeRestart.jelly\");\\n \\n-        safeRestart();\\n+        if (req != null && req.getMethod().equals(\"POST\")) {\\n+            safeRestart();\\n+        }\\n \\n         return HttpResponses.redirectToDot();\\n     }\\n \\n+    @CLIMethod(name=\"safe-restart\")\\n+    @Restricted(NoExternalUse.class)\\n+    public void cliSafeRestart() throws RestartNotSupportedException {\\n+        checkPermission(ADMINISTER);\\n+        safeRestart();\\n+    }\\n+\\n     /**\\n      * Performs a restart.\\n      */'}}",
      "message_norm": "[security-412] fix handling of restart/saferestart urls",
      "language": "en",
      "entities": "[('security-412', 'SECWORD', ''), ('fix', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['core/src/main/java/jenkins/model/Jenkins.java'])",
      "num_files": 1.0
    },
    {
      "index": 234,
      "vuln_id": "GHSA-3c33-3465-fhx2",
      "cwe_id": "{'CWE-668'}",
      "score": 8.8,
      "chain": "{'https://github.com/librenms/librenms/commit/e5bb6d80bc308fc56b9a01ffb76c34159995353c'}",
      "dataset": "osv",
      "summary": "Exposure of Resource to Wrong Sphere in LibreNMS An issue was discovered in LibreNMS before 1.65.1. It has insufficient access control for normal users because of \"'guard' => 'admin'\" instead of \"'middleware' => ['can:admin']\" in routes/web.php.",
      "published_date": "2021-09-08",
      "chain_len": 1,
      "project": "https://github.com/librenms/librenms",
      "commit_href": "https://github.com/librenms/librenms/commit/e5bb6d80bc308fc56b9a01ffb76c34159995353c",
      "commit_sha": "e5bb6d80bc308fc56b9a01ffb76c34159995353c",
      "patch": "SINGLE",
      "chain_ord": "['e5bb6d80bc308fc56b9a01ffb76c34159995353c']",
      "before_first_fix_commit": "{'a30fcbde0a0f8a2109cbd4edb2b27b118190b3ca'}",
      "last_fix_commit": "e5bb6d80bc308fc56b9a01ffb76c34159995353c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/08/2020, 23:04:48",
      "message": "Fix settings access (#11915)\n\nnormal users could access",
      "author": "Tony Murray",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'routes/web.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/librenms/librenms/raw/e5bb6d80bc308fc56b9a01ffb76c34159995353c/routes%2Fweb.php', 'patch': \"@@ -43,7 +43,7 @@\\n     });\\n \\n     // admin pages\\n-    Route::group(['guard' => 'admin'], function () {\\n+    Route::group(['middleware' => ['can:admin']], function () {\\n         Route::get('settings/{tab?}/{section?}', 'SettingsController@index')->name('settings');\\n         Route::put('settings/{name}', 'SettingsController@update')->name('settings.update');\\n         Route::delete('settings/{name}', 'SettingsController@destroy')->name('settings.destroy');\"}}",
      "message_norm": "fix settings access (#11915)\n\nnormal users could access",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('#11915', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['routes/web.php'])",
      "num_files": 1.0
    },
    {
      "index": 1256,
      "vuln_id": "GHSA-8v3j-jfg3-v3fv",
      "cwe_id": "{'CWE-1321'}",
      "score": 9.8,
      "chain": "{'https://github.com/balderdashy/sails/commit/7c5379a656bb305c958df1dcc2b51a9668830358'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in Sails.js Sails.js <= 1.5.2 is vulnerable to Prototype Pollution via controller/load-action-modules.js, function loadActionModules(). A [patch](https://github.com/balderdashy/sails/commit/7c5379a656bb305c958df1dcc2b51a9668830358) is available in the `master` branch of Sails.js's GItHub repository.",
      "published_date": "2022-03-18",
      "chain_len": 1,
      "project": "https://github.com/balderdashy/sails",
      "commit_href": "https://github.com/balderdashy/sails/commit/7c5379a656bb305c958df1dcc2b51a9668830358",
      "commit_sha": "7c5379a656bb305c958df1dcc2b51a9668830358",
      "patch": "SINGLE",
      "chain_ord": "['7c5379a656bb305c958df1dcc2b51a9668830358']",
      "before_first_fix_commit": "{'06ce9cfbe6533734879079e02b0ef7b62f9ce31b'}",
      "last_fix_commit": "7c5379a656bb305c958df1dcc2b51a9668830358",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/18/2022, 22:07:29",
      "message": "closes https://github.com/balderdashy/sails/issues/7209",
      "author": "Mike McNeil",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'docs/reference/application/advanced-usage/sails.reloadActions.md': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/balderdashy/sails/raw/7c5379a656bb305c958df1dcc2b51a9668830358/docs%2Freference%2Fapplication%2Fadvanced-usage%2Fsails.reloadActions.md', 'patch': '@@ -25,6 +25,9 @@ This method is useful primarily in development scenarios.\\n | 1 |      _options_      | ((dictionary?))          | Currently accepts one key, `hooksToSkip`, which if given should be an array of names of hooks that should _not_ call their `reloadActions` method.\\n | 2 |      _callback_              | ((function)) | A callback to be called with the virtual response.\\n \\n+### Notes\\n+> - Never dynamically replace your Sails.js controller or action files on disk with untrusted code at runtime, regardless of whether you are using `.reloadActions()` in your app or not.  Since `reloadActions()` runs the code in your Sails.js app\\'s files, if the files are not safe to run, then using `reloadActions()` would be [a security risk](https://github.com/balderdashy/sails/issues/7209).  This risk is only present if your Sails app is deliberately overwriting its own files to replace them with unsafe code.\\n+\\n \\n <docmeta name=\"displayName\" value=\"sails.reloadActions()\">\\n <docmeta name=\"pageType\" value=\"method\">'}}",
      "message_norm": "closes https://github.com/balderdashy/sails/issues/7209",
      "language": "es",
      "entities": "[('https://github.com/balderdashy/sails/issues/7209', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['docs/reference/application/advanced-usage/sails.reloadActions.md'])",
      "num_files": 1.0
    },
    {
      "index": 647,
      "vuln_id": "GHSA-5jfw-35xp-5m42",
      "cwe_id": "{'CWE-124'}",
      "score": 7.5,
      "chain": "{'https://github.com/pmmp/BedrockProtocol/commit/e3fce7632b94e83fd6a518a87dcaf6a11681c4ac'}",
      "dataset": "osv",
      "summary": "Buffer length underflow in LoginPacket causing unchecked exceptions to be thrown ### Impact\n`LoginPacket` uses `BinaryStream->getLInt()` to read the lengths of JSON payloads it wants to decode. Unfortunately, `BinaryStream->getLInt()` returns a signed integer, meaning that a malicious client can craft a packet with a large uint32 value for payload buffer size (which would be interpreted as a negative signed int32), causing `BinaryStream->get()` to throw an exception.\n\nIn the context of PocketMine-MP, this leads to a server crash when the vulnerability is exploited.\n\n### Patches\ne3fce7632b94e83fd6a518a87dcaf6a11681c4ac\n\n### Workarounds\nThis can be worked around by registering a custom `LoginPacket` implementation into `PacketPool` which overrides [this code](https://github.com/pmmp/BedrockProtocol/blob/47532c95ea37d5f0365b23f734d70d943ff95295/src/LoginPacket.php#L54) to patch it.\n\n### For more information\n* Email us at [team@pmmp.io](mailto:team@pmmp.io)",
      "published_date": "2022-04-05",
      "chain_len": 1,
      "project": "https://github.com/pmmp/BedrockProtocol",
      "commit_href": "https://github.com/pmmp/BedrockProtocol/commit/e3fce7632b94e83fd6a518a87dcaf6a11681c4ac",
      "commit_sha": "e3fce7632b94e83fd6a518a87dcaf6a11681c4ac",
      "patch": "SINGLE",
      "chain_ord": "['e3fce7632b94e83fd6a518a87dcaf6a11681c4ac']",
      "before_first_fix_commit": "{'a740f6095b35278c0e0dac6db84a5e4d2456b113'}",
      "last_fix_commit": "e3fce7632b94e83fd6a518a87dcaf6a11681c4ac",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/01/2022, 21:41:00",
      "message": "LoginPacket: fixed buffer length underflow in payload decoding",
      "author": "Dylan K. Taylor",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 2, 'total': 16}",
      "files": "{'src/LoginPacket.php': {'additions': 14, 'deletions': 2, 'changes': 16, 'status': 'modified', 'raw_url': 'https://github.com/pmmp/BedrockProtocol/raw/e3fce7632b94e83fd6a518a87dcaf6a11681c4ac/src%2FLoginPacket.php', 'patch': '@@ -54,7 +54,13 @@ protected function decodePayload(PacketSerializer $in) : void{\\n \\tprotected function decodeConnectionRequest(string $binary) : void{\\n \\t\\t$connRequestReader = new BinaryStream($binary);\\n \\n-\\t\\t$chainDataJson = json_decode($connRequestReader->get($connRequestReader->getLInt()));\\n+\\t\\t$chainDataJsonLength = $connRequestReader->getLInt();\\n+\\t\\tif($chainDataJsonLength <= 0){\\n+\\t\\t\\t//technically this is always positive; the problem results because getLInt() is implicitly signed\\n+\\t\\t\\t//this is inconsistent with many other methods, but we can\\'t do anything about that for now\\n+\\t\\t\\tthrow new PacketDecodeException(\"Length of chain data JSON must be positive\");\\n+\\t\\t}\\n+\\t\\t$chainDataJson = json_decode($connRequestReader->get($chainDataJsonLength));\\n \\t\\tif(!is_object($chainDataJson)){\\n \\t\\t\\tthrow new PacketDecodeException(\"Failed decoding chain data JSON: \" . json_last_error_msg());\\n \\t\\t}\\n@@ -68,7 +74,13 @@ protected function decodeConnectionRequest(string $binary) : void{\\n \\t\\t}\\n \\n \\t\\t$this->chainDataJwt = $chainData;\\n-\\t\\t$this->clientDataJwt = $connRequestReader->get($connRequestReader->getLInt());\\n+\\t\\t$clientDataJwtLength = $connRequestReader->getLInt();\\n+\\t\\tif($clientDataJwtLength <= 0){\\n+\\t\\t\\t//technically this is always positive; the problem results because getLInt() is implicitly signed\\n+\\t\\t\\t//this is inconsistent with many other methods, but we can\\'t do anything about that for now\\n+\\t\\t\\tthrow new PacketDecodeException(\"Length of clientData JWT must be positive\");\\n+\\t\\t}\\n+\\t\\t$this->clientDataJwt = $connRequestReader->get($clientDataJwtLength);\\n \\t}\\n \\n \\tprotected function encodePayload(PacketSerializer $out) : void{'}}",
      "message_norm": "loginpacket: fixed buffer length underflow in payload decoding",
      "language": "en",
      "entities": "[('fixed', 'ACTION', ''), ('underflow', 'SECWORD', ''), ('decoding', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/LoginPacket.php'])",
      "num_files": 1.0
    },
    {
      "index": 38,
      "vuln_id": "GHSA-2647-c639-qv2j",
      "cwe_id": "{'CWE-918'}",
      "score": 9.8,
      "chain": "{'https://github.com/janeczku/calibre-web/commit/965352c8d96c9eae7a6867ff76b0db137d04b0b8'}",
      "dataset": "osv",
      "summary": "Server-Side Request Forgery in calibreweb calibreweb prior to version 0.6.17 is vulnerable to server-side request forgery (SSRF). This is due to an incomplete fix for [CVE-2022-0339](https://github.com/advisories/GHSA-4w8p-x6g8-fv64). The blacklist does not check for `0.0.0.0`, which would result in a payload of `0.0.0.0` resolving to `localhost`.",
      "published_date": "2022-03-08",
      "chain_len": 1,
      "project": "https://github.com/janeczku/calibre-web",
      "commit_href": "https://github.com/janeczku/calibre-web/commit/965352c8d96c9eae7a6867ff76b0db137d04b0b8",
      "commit_sha": "965352c8d96c9eae7a6867ff76b0db137d04b0b8",
      "patch": "SINGLE",
      "chain_ord": "['965352c8d96c9eae7a6867ff76b0db137d04b0b8']",
      "before_first_fix_commit": "{'8007e450b3178f517b83b0989744c6df38867932'}",
      "last_fix_commit": "965352c8d96c9eae7a6867ff76b0db137d04b0b8",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/26/2022, 07:05:35",
      "message": "Don't allow redirects on cover uploads, catch more addresses which resolve to localhost",
      "author": "Ozzie Isaacs",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'cps/helper.py': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/janeczku/calibre-web/raw/965352c8d96c9eae7a6867ff76b0db137d04b0b8/cps%2Fhelper.py', 'patch': '@@ -734,10 +734,10 @@ def save_cover_from_url(url, book_path):\\n         if not cli.allow_localhost:\\n             # 127.0.x.x, localhost, [::1], [::ffff:7f00:1]\\n             ip = socket.getaddrinfo(urlparse(url).hostname, 0)[0][4][0]\\n-            if ip.startswith(\"127.\") or ip.startswith(\\'::ffff:7f\\') or ip == \"::1\":\\n+            if ip.startswith(\"127.\") or ip.startswith(\\'::ffff:7f\\') or ip == \"::1\" or ip == \"0.0.0.0\" or ip == \"::\":\\n                 log.error(\"Localhost was accessed for cover upload\")\\n                 return False, _(\"You are not allowed to access localhost for cover uploads\")\\n-        img = requests.get(url, timeout=(10, 200))      # ToDo: Error Handling\\n+        img = requests.get(url, timeout=(10, 200), allow_redirects=False)      # ToDo: Error Handling\\n         img.raise_for_status()\\n         return save_cover(img, book_path)\\n     except (socket.gaierror,'}}",
      "message_norm": "don't allow redirects on cover uploads, catch more addresses which resolve to localhost",
      "language": "en",
      "entities": null,
      "classification_level_1": "POORLY_DOCUMENTED",
      "classification_level_2": "REDUNDANT_MESSAGE",
      "list_files": "dict_keys(['cps/helper.py'])",
      "num_files": 1.0
    },
    {
      "index": 402,
      "vuln_id": "GHSA-4c4g-crqm-xrxw",
      "cwe_id": "{'CWE-908'}",
      "score": 4.4,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', 'https://github.com/tensorflow/tensorflow/commit/8933b8a21280696ab119b63263babdb54c298538', 'https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887'}",
      "dataset": "osv",
      "summary": "Use of unitialized value in TFLite ### Impact\nAll TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200):\n\n```cc\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n```\n\nThe issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code.\n\n### Patches\nWe have patched the issue in GitHub commits [537bc7c723439b9194a358f64d871dd326c18887](https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887),\n[4a91f2069f7145aab6ba2d8cfe41be8a110c18a5](https://github.com/tensorflow/tensorflow/commit/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5) and [8933b8a21280696ab119b63263babdb54c298538](https://github.com/tensorflow/tensorflow/commit/8933b8a21280696ab119b63263babdb54c298538).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 3,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887",
      "commit_sha": "537bc7c723439b9194a358f64d871dd326c18887",
      "patch": "MULTI",
      "chain_ord": "['537bc7c723439b9194a358f64d871dd326c18887', '4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', '8933b8a21280696ab119b63263babdb54c298538']",
      "before_first_fix_commit": "{'e35be978351a8578549d30b6f483825d36dc0f8b'}",
      "last_fix_commit": "8933b8a21280696ab119b63263babdb54c298538",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/16/2021, 16:35:48",
      "message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385163909\nChange-Id: I2beb8d50649b6542db224c163033fbcbaa49314f",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 0, 'total': 7}",
      "files": "{'tensorflow/lite/kernels/svdf.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/537bc7c723439b9194a358f64d871dd326c18887/tensorflow%2Flite%2Fkernels%2Fsvdf.cc', 'patch': '@@ -256,14 +256,21 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n                                                      output_temp_size_array));\\n \\n     // Calculate effective scales.\\n+    TF_LITE_ENSURE(context, input->quantization.type != kTfLiteNoQuantization);\\n     auto* input_params =\\n         reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\\n+    TF_LITE_ENSURE(context,\\n+                   weights_feature->quantization.type != kTfLiteNoQuantization);\\n     auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\\n         weights_feature->quantization.params);\\n+    TF_LITE_ENSURE(context, state->quantization.type != kTfLiteNoQuantization);\\n     auto* state_params =\\n         reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\\n+    TF_LITE_ENSURE(context,\\n+                   weights_time->quantization.type != kTfLiteNoQuantization);\\n     auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\\n         weights_time->quantization.params);\\n+    TF_LITE_ENSURE(context, output->quantization.type != kTfLiteNoQuantization);\\n     auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\\n         output->quantization.params);\\n     const double effective_scale_1 = input_params->scale->data[0] *'}}",
      "message_norm": "fix a null pointer exception caused by branching on uninitialized data.\n\nthis is due to not checking that the params for the quantization exists. if there is no quantization, we should not access the `.params` field.\n\npiperorigin-revid: 385163909\nchange-id: i2beb8d50649b6542db224c163033fbcbaa49314f",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('null pointer exception', 'SECWORD', ''), ('uninitialized', 'SECWORD', ''), ('385163909', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/svdf.cc'])",
      "num_files": 1.0
    },
    {
      "index": 756,
      "vuln_id": "GHSA-65mj-7c86-79jf",
      "cwe_id": "{'CWE-305', 'CWE-287'}",
      "score": 9.1,
      "chain": "{'https://github.com/ADOdb/ADOdb/commit/952de6c4273d9b1e91c2b838044f8c2111150c29', 'https://github.com/ADOdb/ADOdb/commit/b4d5ce70034c5aac3a1d51d317d93c037a0938d2'}",
      "dataset": "osv",
      "summary": "Authentication Bypass in ADOdb/ADOdb ### Impact\n\nAn attacker can inject values into a PostgreSQL connection string by providing a parameter surrounded by single quotes.\n\nDepending on how the library is used in the client software, this may allow an attacker to bypass the login process, gain access to the server's IP address, etc.\n\n### Patches\n\nThe vulnerability is fixed in ADOdb versions 5.20.21 (952de6c4273d9b1e91c2b838044f8c2111150c29) and 5.21.4 or later (b4d5ce70034c5aac3a1d51d317d93c037a0938d2).\n\nThe simplest patch is to delete line 29 in `drivers/adodb-postgres64.inc.php`:\n\n```php\ndiff --git a/drivers/adodb-postgres64.inc.php b/drivers/adodb-postgres64.inc.php\nindex d04b7f67..729d7141 100644\n--- a/drivers/adodb-postgres64.inc.php\n+++ b/drivers/adodb-postgres64.inc.php\n@@ -26,7 +26,6 @@ function adodb_addslashes($s)\n {\n    $len = strlen($s);\n    if ($len == 0) return \"''\";\n-   if (strncmp($s,\"'\",1) === 0 && substr($s,$len-1) == \"'\") return $s; // already quoted\n \n    return \"'\".addslashes($s).\"'\";\n }\n```\n\n### Workarounds\n\nEnsure the parameters passed to *ADOConnection::connect()* or related functions (_nConnect()_, _pConnect()_) are not surrounded by single quotes.\n\n### Credits\n\nThanks to **Emmet Leahy** (@meme-lord) of Sorcery Ltd for reporting this vulnerability, and to the [huntr](https://huntr.dev/) team for their support.\n\n### References\n\n- Original issue report https://huntr.dev/bounties/bdf5f216-4499-4225-a737-b28bc6f5801c/\n- ADOdb reference issue #793 \n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Add a note in issue #793\n* Contact the maintainers on [Gitter](https://gitter.im/adodb/adodb)",
      "published_date": "2022-01-27",
      "chain_len": 2,
      "project": "https://github.com/ADOdb/ADOdb",
      "commit_href": "https://github.com/ADOdb/ADOdb/commit/b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
      "commit_sha": "b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
      "patch": "MULTI",
      "chain_ord": "['952de6c4273d9b1e91c2b838044f8c2111150c29', 'b4d5ce70034c5aac3a1d51d317d93c037a0938d2']",
      "before_first_fix_commit": "{'c5415722049f36c446a4034d15f1d17943f11458'}",
      "last_fix_commit": "b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
      "chain_ord_pos": 2.0,
      "commit_datetime": "01/10/2022, 09:00:33",
      "message": "Prevent auth bypass with PostgreSQL connections\n\nThanks to Emmet Leahy of Sorcery Ltd for reporting this vulnerability\n(CVE-2021-3850).\n\nRefactoring ADODB_postgres64::_connect():\n- Remove adodb_addslashes() function, which did not escape the\n  connection parameters when they are wrapped in single quotes\n  (root cause for the identified security issue).\n- Use addcslashes() instead of addslashes() to only escape `'` and `\\`,\n  to strictly follow pg_connect() documentation (addslashes() also\n  escapes `\"`)\n- Use an array and a foreach loop to build the connection string when\n  given individual parameters for host:port, user, password and dbname\n\nFixes #793",
      "author": "Damien Regad",
      "comments": null,
      "stats": "{'additions': 25, 'deletions': 22, 'total': 47}",
      "files": "{'drivers/adodb-postgres64.inc.php': {'additions': 25, 'deletions': 22, 'changes': 47, 'status': 'modified', 'raw_url': 'https://github.com/ADOdb/ADOdb/raw/b4d5ce70034c5aac3a1d51d317d93c037a0938d2/drivers%2Fadodb-postgres64.inc.php', 'patch': '@@ -22,15 +22,6 @@\\n // security - hide paths\\n if (!defined(\\'ADODB_DIR\\')) die();\\n \\n-function adodb_addslashes($s)\\n-{\\n-\\t$len = strlen($s);\\n-\\tif ($len == 0) return \"\\'\\'\";\\n-\\tif (strncmp($s,\"\\'\",1) === 0 && substr($s,$len-1) == \"\\'\") return $s; // already quoted\\n-\\n-\\treturn \"\\'\".addslashes($s).\"\\'\";\\n-}\\n-\\n class ADODB_postgres64 extends ADOConnection{\\n \\tvar $databaseType = \\'postgres64\\';\\n \\tvar $dataProvider = \\'postgres\\';\\n@@ -693,21 +684,33 @@ function _connect($str,$user=\\'\\',$pwd=\\'\\',$db=\\'\\',$ctype=0)\\n \\n \\t\\t$this->_errorMsg = false;\\n \\n+\\t\\t// If $user, $pwd and $db are all null, then $str is a pg_connect()\\n+\\t\\t// connection string. Otherwise we expect it to be a hostname,\\n+\\t\\t// with optional port separated by \\':\\'\\n \\t\\tif ($user || $pwd || $db) {\\n-\\t\\t\\t$user = adodb_addslashes($user);\\n-\\t\\t\\t$pwd = adodb_addslashes($pwd);\\n-\\t\\t\\tif (strlen($db) == 0) $db = \\'template1\\';\\n-\\t\\t\\t$db = adodb_addslashes($db);\\n-\\t\\t\\tif ($str)  {\\n-\\t\\t\\t\\t$host = explode(\":\", $str);\\n-\\t\\t\\t\\tif ($host[0]) $str = \"host=\".adodb_addslashes($host[0]);\\n-\\t\\t\\t\\telse $str = \\'\\';\\n-\\t\\t\\t\\tif (isset($host[1])) $str .= \" port=$host[1]\";\\n-\\t\\t\\t\\telse if (!empty($this->port)) $str .= \" port=\".$this->port;\\n+\\t\\t\\t// Hostname & port\\n+\\t\\t\\tif ($str) {\\n+\\t\\t\\t\\t$host = explode(\\':\\', $str);\\n+\\t\\t\\t\\tif ($host[0]) {\\n+\\t\\t\\t\\t\\t$conn[\\'host\\'] = $host[0];\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t\\tif (isset($host[1])) {\\n+\\t\\t\\t\\t\\t$conn[\\'port\\'] = (int)$host[1];\\n+\\t\\t\\t\\t} elseif (!empty($this->port)) {\\n+\\t\\t\\t\\t\\t$conn[\\'port\\'] = $this->port;\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t}\\n+\\t\\t\\t$conn[\\'user\\'] = $user;\\n+\\t\\t\\t$conn[\\'password\\'] = $pwd;\\n+\\t\\t\\t// @TODO not sure why we default to \\'template1\\', pg_connect() uses the username when dbname is empty\\n+\\t\\t\\t$conn[\\'dbname\\'] = $db ?: \\'template1\\';\\n+\\n+\\t\\t\\t// Generate connection string\\n+\\t\\t\\t$str = \\'\\';\\n+\\t\\t\\tforeach ($conn as $param => $value) {\\n+\\t\\t\\t\\t// Escaping single quotes and backslashes per pg_connect() documentation\\n+\\t\\t\\t\\t$str .= $param . \"=\\'\" . addcslashes($value, \"\\'\\\\\\\\\") . \"\\' \";\\n \\t\\t\\t}\\n-\\t\\t\\tif ($user) $str .= \" user=\".$user;\\n-\\t\\t\\tif ($pwd)  $str .= \" password=\".$pwd;\\n-\\t\\t\\tif ($db)   $str .= \" dbname=\".$db;\\n \\t\\t}\\n \\n \\t\\t//if ($user) $linea = \"user=$user host=$linea password=$pwd dbname=$db port=5432\";'}}",
      "message_norm": "prevent auth bypass with postgresql connections\n\nthanks to emmet leahy of sorcery ltd for reporting this vulnerability\n(cve-2021-3850).\n\nrefactoring adodb_postgres64::_connect():\n- remove adodb_addslashes() function, which did not escape the\n  connection parameters when they are wrapped in single quotes\n  (root cause for the identified security issue).\n- use addcslashes() instead of addslashes() to only escape `'` and `\\`,\n  to strictly follow pg_connect() documentation (addslashes() also\n  escapes `\"`)\n- use an array and a foreach loop to build the connection string when\n  given individual parameters for host:port, user, password and dbname\n\nfixes #793",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('auth', 'SECWORD', ''), ('bypass', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('cve-2021-3850', 'VULNID', 'CVE'), ('remove', 'ACTION', ''), ('escape', 'SECWORD', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('escape', 'SECWORD', ''), ('escapes', 'SECWORD', ''), ('password', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#793', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['drivers/adodb-postgres64.inc.php'])",
      "num_files": 1.0
    },
    {
      "index": 3188,
      "vuln_id": "GHSA-vx6v-xg64-pmr8",
      "cwe_id": "{'CWE-79'}",
      "score": 8.8,
      "chain": "{'https://github.com/django-helpdesk/django-helpdesk/commit/2c7065e0c4296e0c692fb4a7ee19c7357583af30'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in django-helpdesk django-helpdesk is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting').",
      "published_date": "2021-11-15",
      "chain_len": 1,
      "project": "https://github.com/django-helpdesk/django-helpdesk",
      "commit_href": "https://github.com/django-helpdesk/django-helpdesk/commit/2c7065e0c4296e0c692fb4a7ee19c7357583af30",
      "commit_sha": "2c7065e0c4296e0c692fb4a7ee19c7357583af30",
      "patch": "SINGLE",
      "chain_ord": "['2c7065e0c4296e0c692fb4a7ee19c7357583af30']",
      "before_first_fix_commit": "{'3f245871ac91356fd91a4e2cea5048bcac1d833e'}",
      "last_fix_commit": "2c7065e0c4296e0c692fb4a7ee19c7357583af30",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/11/2021, 10:32:09",
      "message": "Add function `htmlEntities`\n\n`htmlentities()` is a function which converts special characters. This allows you to show to display the string without the browser reading it as HTML.",
      "author": "lethanhphuc",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 2, 'total': 8}",
      "files": "{'helpdesk/templates/helpdesk/ticket_list.html': {'additions': 6, 'deletions': 2, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/django-helpdesk/django-helpdesk/raw/2c7065e0c4296e0c692fb4a7ee19c7357583af30/helpdesk%2Ftemplates%2Fhelpdesk%2Fticket_list.html', 'patch': '@@ -330,7 +330,11 @@ <h5 class=\"mb-0\">\\n         function get_url(row) {\\n             return \"{% url \\'helpdesk:view\\' 1234 %}\".replace(/1234/, row.id.toString());\\n         }\\n-\\n+        \\n+        function htmlEntities(str) {\\n+            return String(str).replace(/&/g, \\'&amp;\\').replace(/</g, \\'&lt;\\').replace(/>/g, \\'&gt;\\').replace(/\"/g, \\'&quot;\\');\\n+        }\\n+        \\n         $(document).ready(function () {\\n             // Ticket DataTable Initialization\\n             $(\\'#ticketTable\\').DataTable({\\n@@ -366,7 +370,7 @@ <h5 class=\"mb-0\">\\n                             if (type === \\'display\\') {\\n                                 data = \\'<div class=\"tickettitle\"><a href=\"\\' + get_url(row) + \\'\" >\\' +\\n                                     row.id + \\'. \\' +\\n-                                    row.title + \\'</a></div>\\';\\n+                                    htmlEntities(row.title) + \\'</a></div>\\';\\n                             }\\n                             return data\\n                         }'}}",
      "message_norm": "add function `htmlentities`\n\n`htmlentities()` is a function which converts special characters. this allows you to show to display the string without the browser reading it as html.",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('htmlentities', 'SECWORD', ''), ('htmlentities', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['helpdesk/templates/helpdesk/ticket_list.html'])",
      "num_files": 1.0
    }
  ]
}