{
  "schema": {
    "fields": [
      {
        "name": "index",
        "type": "integer"
      },
      {
        "name": "vuln_id",
        "type": "string"
      },
      {
        "name": "cwe_id",
        "type": "string"
      },
      {
        "name": "score",
        "type": "number"
      },
      {
        "name": "chain",
        "type": "string"
      },
      {
        "name": "dataset",
        "type": "string"
      },
      {
        "name": "summary",
        "type": "string"
      },
      {
        "name": "published_date",
        "type": "string"
      },
      {
        "name": "chain_len",
        "type": "integer"
      },
      {
        "name": "project",
        "type": "string"
      },
      {
        "name": "commit_href",
        "type": "string"
      },
      {
        "name": "commit_sha",
        "type": "string"
      },
      {
        "name": "patch",
        "type": "string"
      },
      {
        "name": "chain_ord",
        "type": "string"
      },
      {
        "name": "before_first_fix_commit",
        "type": "string"
      },
      {
        "name": "last_fix_commit",
        "type": "string"
      },
      {
        "name": "chain_ord_pos",
        "type": "number"
      },
      {
        "name": "commit_datetime",
        "type": "string"
      },
      {
        "name": "message",
        "type": "string"
      },
      {
        "name": "author",
        "type": "string"
      },
      {
        "name": "comments",
        "type": "string"
      },
      {
        "name": "stats",
        "type": "string"
      },
      {
        "name": "files",
        "type": "string"
      },
      {
        "name": "message_norm",
        "type": "string"
      },
      {
        "name": "language",
        "type": "string"
      },
      {
        "name": "entities",
        "type": "string"
      },
      {
        "name": "classification_level_1",
        "type": "string"
      },
      {
        "name": "classification_level_2",
        "type": "string"
      },
      {
        "name": "list_files",
        "type": "string"
      },
      {
        "name": "num_files",
        "type": "number"
      }
    ],
    "primaryKey": [
      "index"
    ],
    "pandas_version": "1.4.0"
  },
  "data": [
    {
      "index": 3502,
      "vuln_id": "GHSA-xw79-hhv6-578c",
      "cwe_id": "{'CWE-79'}",
      "score": 0.0,
      "chain": "{'https://github.com/zeit/serve-handler/commit/65b4d4183a31a8076c78c40118acb0ca1b64f620'}",
      "dataset": "osv",
      "summary": "Cross-Site Scripting in serve Versions of `serve` prior to 10.0.2 are vulnerable to Cross-Site Scripting (XSS). The package does not encode output, allowing attackers to execute arbitrary JavaScript in the victim's browser if user-supplied input is rendered.\n\n\n## Recommendation\n\nUpgrade to version 10.0.2 or later.",
      "published_date": "2020-09-11",
      "chain_len": 1,
      "project": "https://github.com/zeit/serve-handler",
      "commit_href": "https://github.com/zeit/serve-handler/commit/65b4d4183a31a8076c78c40118acb0ca1b64f620",
      "commit_sha": "65b4d4183a31a8076c78c40118acb0ca1b64f620",
      "patch": "SINGLE",
      "chain_ord": "['65b4d4183a31a8076c78c40118acb0ca1b64f620']",
      "before_first_fix_commit": "{'2b3be81a46e09fc5f8bc2c69a5311d439dac74af'}",
      "last_fix_commit": "65b4d4183a31a8076c78c40118acb0ca1b64f620",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/24/2018, 17:05:10",
      "message": "Interpolate template variables correctly (#64)",
      "author": "Leo Lamprecht",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 4, 'total': 8}",
      "files": "{'src/directory.jst': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/vercel/serve-handler/raw/65b4d4183a31a8076c78c40118acb0ca1b64f620/src%2Fdirectory.jst', 'patch': '@@ -4,7 +4,7 @@\\n     <meta charset=\"utf-8\">\\n     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n \\n-    <title>Files within {{=it.directory}}</title>\\n+    <title>Files within {{!it.directory}}</title>\\n \\n \\t<style>\\n \\t\\tbody {\\n@@ -187,7 +187,7 @@\\n           <i>Index of&nbsp;</i>\\n \\n           {{~it.paths :value:index}}\\n-            <a href=\"/{{=value.url}}\">{{=value.name}}</a>\\n+            <a href=\"/{{!value.url}}\">{{!value.name}}</a>\\n           {{~}}\\n         </h1>\\n \\n@@ -197,9 +197,9 @@\\n       <ul id=\"files\">\\n         {{~it.files :value:index}}\\n           <li>\\n-            <a href=\"{{=value.relative}}\" title=\"{{=value.title}}\" class=\"{{=value.ext}}\">{{=value.base}}</a>\\n+            <a href=\"{{!value.relative}}\" title=\"{{!value.title}}\" class=\"{{!value.ext}}\">{{!value.base}}</a>\\n \\t\\t\\t{{? value.size}}\\n-\\t\\t\\t\\t<i>{{=value.size}}</i>\\n+\\t\\t\\t\\t<i>{{!value.size}}</i>\\n \\t\\t\\t{{?}}\\n           </li>\\n         {{~}}'}}",
      "message_norm": "interpolate template variables correctly (#64)",
      "language": "en",
      "entities": "[('#64', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/directory.jst'])",
      "num_files": 1.0
    },
    {
      "index": 2001,
      "vuln_id": "GHSA-h6fg-mjxg-hqq4",
      "cwe_id": "{'CWE-197', 'CWE-754'}",
      "score": 9.0,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/ca8c013b5e97b1373b3bb1c97ea655e69f31a575', 'https://github.com/tensorflow/tensorflow/commit/27b417360cbd671ef55915e4bb6bb06af8b8a832'}",
      "dataset": "osv",
      "summary": "Integer truncation in Shard API usage ### Impact\nThe `Shard` API in TensorFlow expects the last argument to be a function taking two `int64` (i.e., `long long`) arguments:\nhttps://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/core/util/work_sharder.h#L59-L60\n\nHowever, there are several places in TensorFlow where a lambda taking `int` or `int32` arguments is being used:\nhttps://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/core/kernels/random_op.cc#L204-L205\nhttps://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/core/kernels/random_op.cc#L317-L318\n\nIn these cases, if the amount of work to be parallelized is large enough, integer truncation occurs. Depending on how the two arguments of the lambda are used, this can result in segfaults, read/write outside of heap allocated arrays, stack overflows, or data corruption.\n\n### Patches\nWe have patched the issue in 27b417360cbd671ef55915e4bb6bb06af8b8a832 and ca8c013b5e97b1373b3bb1c97ea655e69f31a575. We will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2020-09-25",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/27b417360cbd671ef55915e4bb6bb06af8b8a832",
      "commit_sha": "27b417360cbd671ef55915e4bb6bb06af8b8a832",
      "patch": "MULTI",
      "chain_ord": "['27b417360cbd671ef55915e4bb6bb06af8b8a832', 'ca8c013b5e97b1373b3bb1c97ea655e69f31a575']",
      "before_first_fix_commit": "{'b9465214656c42204d86945eca80d211f50043a1'}",
      "last_fix_commit": "ca8c013b5e97b1373b3bb1c97ea655e69f31a575",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/19/2020, 00:21:24",
      "message": "Prevent `int64` to `int` truncation in `Shard` API usage.\n\nThe function argument in `Shard` must be a function of two `int64` arguments. However, we are passing in a function with two `int` arguments. Thus, for large workloads, these arguments get truncated from positive `int64` values to negative `int` ones, resulting in a buffer out of bounds write.\n\nPiperOrigin-RevId: 332557334\nChange-Id: I236c9a2e7f53580e520571da8ba941a3aa9fa0b5",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'tensorflow/core/kernels/random_op.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/27b417360cbd671ef55915e4bb6bb06af8b8a832/tensorflow%2Fcore%2Fkernels%2Frandom_op.cc', 'patch': '@@ -202,7 +202,7 @@ class RandomGammaOp : public OpKernel {\\n     // avoid a couple flops which can be done on a per-alpha basis.\\n \\n     auto DoWork = [samples_per_alpha, num_alphas, &rng, samples_flat,\\n-                   alpha_flat](int start_output, int limit_output) {\\n+                   alpha_flat](int64 start_output, int64 limit_output) {\\n       using Eigen::numext::exp;\\n       using Eigen::numext::log;\\n       using Eigen::numext::log1p;'}}",
      "message_norm": "prevent `int64` to `int` truncation in `shard` api usage.\n\nthe function argument in `shard` must be a function of two `int64` arguments. however, we are passing in a function with two `int` arguments. thus, for large workloads, these arguments get truncated from positive `int64` values to negative `int` ones, resulting in a buffer out of bounds write.\n\npiperorigin-revid: 332557334\nchange-id: i236c9a2e7f53580e520571da8ba941a3aa9fa0b5",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('out of bounds write', 'SECWORD', ''), ('332557334', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/random_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 694,
      "vuln_id": "GHSA-5rqg-jm4f-cqx7",
      "cwe_id": "{'CWE-835'}",
      "score": 0.0,
      "chain": "{'https://github.com/Marak/colors.js/commit/5d2d242f656103ac38086d6b26433a09f1c38c75', 'https://github.com/Marak/colors.js/commit/137c6dae3339e97f4bbc838c221803c363b0a9fd', 'https://github.com/Marak/colors.js/commit/6bc50e79eeaa1d87369bb3e7e608ebed18c5cf26'}",
      "dataset": "osv",
      "summary": "Infinite loop causing Denial of Service in colors colors is a library for including colored text in node.js consoles. Between 07 and 09 January 2022, colors versions 1.4.1, 1.4.2, and 1.4.44-liberty-2 were published including malicious code that caused a Denial of Service due to an infinite loop. Software dependent on these versions experienced the printing of randomized characters to console and an infinite loop resulting in unbound system resource consumption.\n\nUsers of colors relying on these specific versions should downgrade to version 1.4.0.",
      "published_date": "2022-01-10",
      "chain_len": 3,
      "project": "https://github.com/Marak/colors.js",
      "commit_href": "https://github.com/Marak/colors.js/commit/137c6dae3339e97f4bbc838c221803c363b0a9fd",
      "commit_sha": "137c6dae3339e97f4bbc838c221803c363b0a9fd",
      "patch": "MULTI",
      "chain_ord": "['137c6dae3339e97f4bbc838c221803c363b0a9fd', '5d2d242f656103ac38086d6b26433a09f1c38c75', '6bc50e79eeaa1d87369bb3e7e608ebed18c5cf26']",
      "before_first_fix_commit": "{'5d2d242f656103ac38086d6b26433a09f1c38c75'}",
      "last_fix_commit": "6bc50e79eeaa1d87369bb3e7e608ebed18c5cf26",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/08/2022, 04:19:44",
      "message": "Bump to `v1.4.44-liberty`",
      "author": "Marak",
      "comments": "{'com_1': {'author': 'LeviPesin', 'datetime': '01/12/2022, 06:18:26', 'body': 'No one have commented on this commit yet :-)'}, 'com_2': {'author': 'hello-smile6', 'datetime': '01/14/2022, 04:57:47', 'body': '> No one have commented on this commit yet :-)\\r\\n\\r\\nMake that 2 people'}, 'com_3': {'author': 'hello-smile6', 'datetime': '01/14/2022, 04:57:52', 'body': '@LeviPesin'}, 'com_4': {'author': 'TechStudent10', 'datetime': '01/20/2022, 14:09:20', 'body': '`liberty-1`'}, 'com_5': {'author': 'Fabrisdev', 'datetime': '01/23/2022, 22:51:03', 'body': 'now 5'}}",
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'package.json': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/Marak/colors.js/raw/137c6dae3339e97f4bbc838c221803c363b0a9fd/package.json', 'patch': '@@ -1,7 +1,7 @@\\n {\\n     \"name\": \"colors\",\\n     \"description\": \"get colors in your node.js console\",\\n-    \"version\": \"1.4.0\",\\n+    \"version\": \"1.4.44-liberty\",\\n     \"author\": \"Marak Squires\",\\n     \"contributors\": [\\n         {'}}",
      "message_norm": "bump to `v1.4.44-liberty`",
      "language": "en",
      "entities": "[('v1.4.44', 'VERSION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['package.json'])",
      "num_files": 1.0
    },
    {
      "index": 1766,
      "vuln_id": "GHSA-fq9f-9wv9-rfmg",
      "cwe_id": "{'CWE-295'}",
      "score": 5.9,
      "chain": "{'https://github.com/jenkinsci/jenkins/commit/fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0'}",
      "dataset": "osv",
      "summary": "Improper Certificate Validation in Jenkins Jenkins 2.73.1 and earlier, 2.83 and earlier bundled a version of the commons-httpclient library with the vulnerability CVE-2012-6153 that incorrectly verified SSL certificates, making it susceptible to man-in-the-middle attacks. This library is widely used as a transitive dependency in Jenkins plugins. The fix for CVE-2012-6153 was backported to the version of commons-httpclient that is bundled in core and made available to plugins.",
      "published_date": "2022-05-14",
      "chain_len": 1,
      "project": "https://github.com/jenkinsci/jenkins",
      "commit_href": "https://github.com/jenkinsci/jenkins/commit/fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0",
      "commit_sha": "fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0",
      "patch": "SINGLE",
      "chain_ord": "['fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0']",
      "before_first_fix_commit": "{'67f68c181033cbabf2075769e0f846f58c226c08'}",
      "last_fix_commit": "fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/29/2017, 13:39:32",
      "message": "[SECURITY-555] Patch Commons HttpClient 3.x.",
      "author": "Jesse Glick",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'pom.xml': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/jenkinsci/jenkins/raw/fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0/pom.xml', 'patch': '@@ -164,7 +164,7 @@ THE SOFTWARE.\\n       <dependency>\\n         <groupId>commons-httpclient</groupId>\\n         <artifactId>commons-httpclient</artifactId>\\n-        <version>3.1</version>\\n+        <version>3.1-jenkins-1</version>\\n       </dependency>\\n \\n       <dependency>'}}",
      "message_norm": "[security-555] patch commons httpclient 3.x.",
      "language": "en",
      "entities": "[('security-555', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['pom.xml'])",
      "num_files": 1.0
    },
    {
      "index": 945,
      "vuln_id": "GHSA-73rp-q4rx-5grc",
      "cwe_id": "{'CWE-284', 'CWE-863'}",
      "score": 8.8,
      "chain": "{'https://github.com/microweber/microweber/commit/c162dfffb9bfd264d232aaaf5bb3daee16a3cb38'}",
      "dataset": "osv",
      "summary": "Incorrect Authorization in microweber Users Account Pre-Takeover or Users Account Takeover. in GitHub repository microweber/microweber prior to 1.2.15. Victim Account Take Over. Since, there is no email confirmation, an attacker can easily create an account in the application using the Victim\u2019s Email. This allows an attacker to gain pre-authentication to the victim\u2019s account. Further, due to the lack of proper validation of email coming from Social Login and failing to check if an account already exists, the victim will not identify if an account is already existing. Hence, the attacker\u2019s persistence will remain. An attacker would be able to see all the activities performed by the victim user impacting the confidentiality and attempt to modify/corrupt the data impacting the integrity and availability factor. This attack becomes more interesting when an attacker can register an account from an employee\u2019s email address. Assuming the organization uses G-Suite, it is much more impactful to hijack into an employee\u2019s account.",
      "published_date": "2022-05-10",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/c162dfffb9bfd264d232aaaf5bb3daee16a3cb38",
      "commit_sha": "c162dfffb9bfd264d232aaaf5bb3daee16a3cb38",
      "patch": "SINGLE",
      "chain_ord": "['c162dfffb9bfd264d232aaaf5bb3daee16a3cb38']",
      "before_first_fix_commit": "{'12c0316b3bde8ff6a6adc5d2a05f6409b03c9556'}",
      "last_fix_commit": "c162dfffb9bfd264d232aaaf5bb3daee16a3cb38",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/09/2022, 12:54:29",
      "message": "Update index.blade.php",
      "author": "Bozhidar Slaveykov",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 2, 'total': 6}",
      "files": "{'src/MicroweberPackages/Shop/resources/views/index.blade.php': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/c162dfffb9bfd264d232aaaf5bb3daee16a3cb38/src%2FMicroweberPackages%2FShop%2Fresources%2Fviews%2Findex.blade.php', 'patch': '@@ -46,9 +46,11 @@\\n                         <div class=\"d-flex\">\\n                             <p class=\"col-6 mb-0\">\\n                                 @if($product->hasSpecialPrice())\\n-                                    <span class=\"price-old\"><?php print currency_format($product->specialPrice); ?></span>\\n+                                    <span class=\"price-old\"><?php print currency_format($product->price); ?></span>\\n+                                    <span class=\"money\"><?php print currency_format($product->specialPrice); ?></span>\\n+                                @else\\n+                                    <span class=\"money\"><?php print currency_format($product->price); ?></span>\\n                                 @endif\\n-                                <span class=\"money\"><?php print currency_format($product->price); ?></span>\\n                             </p>\\n \\n                             <a class=\"col-6 text-end text-right align-self-center\" href=\"{{content_link($product->id)}}\"> View</a>'}}",
      "message_norm": "update index.blade.php",
      "language": "sv",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/Shop/resources/views/index.blade.php'])",
      "num_files": 1.0
    },
    {
      "index": 3409,
      "vuln_id": "GHSA-xc7v-wxcw-j472",
      "cwe_id": "{'CWE-200'}",
      "score": 0.0,
      "chain": "{'https://github.com/request/tunnel-agent/commit/9ca95ec7219daface8a6fc2674000653de0922c0'}",
      "dataset": "osv",
      "summary": "Memory Exposure in tunnel-agent Versions of `tunnel-agent` before 0.6.0 are vulnerable to memory exposure.\n\nThis is exploitable if user supplied input is provided to the auth value and is a number.\n\nProof-of-concept:\n```js\nrequire('request')({\n  method: 'GET',\n  uri: 'http://www.example.com',\n  tunnel: true,\n  proxy:{\n    protocol: 'http:',\n    host:'127.0.0.1',\n    port:8080,\n    auth:USERSUPPLIEDINPUT // number\n  }\n});\n```\n\n\n## Recommendation\n\nUpdate to version 0.6.0 or later.",
      "published_date": "2019-06-03",
      "chain_len": 1,
      "project": "https://github.com/request/tunnel-agent",
      "commit_href": "https://github.com/request/tunnel-agent/commit/9ca95ec7219daface8a6fc2674000653de0922c0",
      "commit_sha": "9ca95ec7219daface8a6fc2674000653de0922c0",
      "patch": "SINGLE",
      "chain_ord": "['9ca95ec7219daface8a6fc2674000653de0922c0']",
      "before_first_fix_commit": "{'8a7c86e6e2a1c3fa8577e5b0e14923d54c659552'}",
      "last_fix_commit": "9ca95ec7219daface8a6fc2674000653de0922c0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/05/2017, 00:29:52",
      "message": "Use .from",
      "author": "Mikeal Rogers",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/request/tunnel-agent/raw/9ca95ec7219daface8a6fc2674000653de0922c0/index.js', 'patch': \"@@ -128,7 +128,7 @@ TunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\\n   if (connectOptions.proxyAuth) {\\n     connectOptions.headers = connectOptions.headers || {}\\n     connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\\n-        new Buffer(connectOptions.proxyAuth).toString('base64')\\n+        Buffer.from(connectOptions.proxyAuth).toString('base64')\\n   }\\n \\n   debug('making CONNECT request')\"}}",
      "message_norm": "use .from",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 3012,
      "vuln_id": "GHSA-rv62-4pmj-xw6h",
      "cwe_id": "{'CWE-601'}",
      "score": 6.1,
      "chain": "{'https://github.com/jupyter/notebook/commit/08c4c898182edbe97aadef1815cce50448f975cb', 'https://github.com/jupyter/notebook/commit/70fe9f0ddb3023162ece21fbb77d5564306b913b', 'https://github.com/jupyter/notebook/commit/d65328d4841892b412aef9015165db1eb029a8ed'}",
      "dataset": "osv",
      "summary": "Moderate severity vulnerability that affects jupyterhub and notebook An Open Redirect vulnerability for all browsers in Jupyter Notebook before 5.7.8 and some browsers (Chrome, Firefox) in JupyterHub before 0.9.6 allows crafted links to the login page, which will redirect to a malicious site after successful login. Servers running on a base_url prefix are not affected.",
      "published_date": "2019-04-02",
      "chain_len": 3,
      "project": "https://github.com/jupyter/notebook",
      "commit_href": "https://github.com/jupyter/notebook/commit/d65328d4841892b412aef9015165db1eb029a8ed",
      "commit_sha": "d65328d4841892b412aef9015165db1eb029a8ed",
      "patch": "MULTI",
      "chain_ord": "['70fe9f0ddb3023162ece21fbb77d5564306b913b', 'd65328d4841892b412aef9015165db1eb029a8ed', '08c4c898182edbe97aadef1815cce50448f975cb']",
      "before_first_fix_commit": "{'d65328d4841892b412aef9015165db1eb029a8ed'}",
      "last_fix_commit": "08c4c898182edbe97aadef1815cce50448f975cb",
      "chain_ord_pos": 2.0,
      "commit_datetime": "03/27/2019, 15:19:10",
      "message": "changelog for redirect check\n\nand update cve for 5.7.6",
      "author": "Min RK",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'docs/source/changelog.rst': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/jupyter/notebook/raw/d65328d4841892b412aef9015165db1eb029a8ed/docs%2Fsource%2Fchangelog.rst', 'patch': '@@ -31,21 +31,21 @@ We strongly recommend that you upgrade pip to version 9+ of pip before upgrading\\n - Further improve compatibility with tornado 6 with improved\\n   checks for when websockets are closed.\\n - Fix regression in 5.7.6 on Windows where .js files could have the wrong mime-type.\\n+- Fix Open Redirect vulnerability where certain malicious URLs could redirect from the Jupyter login page to a malicious site after a successful login. A CVE has been requested for this vulnerability.\\n \\n .. _release-5.7.6:\\n \\n 5.7.6\\n -----\\n \\n-5.7.6 contains a security fix for a cross-site inclusion (XSSI) vulnerability,\\n+5.7.6 contains a security fix for a cross-site inclusion (XSSI) vulnerability (CVE-2019\u20139644),\\n where files at a known URL could be included in a page from an unauthorized website if the user is logged into a Jupyter server.\\n The fix involves setting the ``X-Content-Type-Options: nosniff``\\n header, and applying CSRF checks previously on all non-GET\\n API requests to GET requests to API endpoints and the /files/ endpoint.\\n \\n The attacking page is able to access some contents of files when using Internet Explorer through script errors,\\n but this has not been demonstrated with other browsers.\\n-A CVE has been requested for this vulnerability.\\n \\n .. _release-5.7.5:'}}",
      "message_norm": "changelog for redirect check\n\nand update cve for 5.7.6",
      "language": "en",
      "entities": "[('changelog', 'ACTION', ''), ('update', 'ACTION', ''), ('cve', 'SECWORD', ''), ('5.7.6', 'VERSION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['docs/source/changelog.rst'])",
      "num_files": 1.0
    },
    {
      "index": 1416,
      "vuln_id": "GHSA-9px9-73fg-3fqp",
      "cwe_id": "{'CWE-476'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/045deec1cbdebb27d817008ad5df94d96a08b1bf', 'https://github.com/tensorflow/tensorflow/commit/0a365c029e437be0349c31f8d4c9926b69fa3fa1'}",
      "dataset": "osv",
      "summary": "Null pointer dereference in Grappler's `IsConstant` ### Impact\nUnder certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place):\n\nFirst, during [constant folding](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/grappler/optimizers/constant_folding.cc#L3466-L3497), the `GraphDef` might not have the required nodes for the binary operation:\n\n```cc\n  NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n  NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n  // One child must be constant, and the second must be Conv op.\n  const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n  const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n```\n\nIf a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect.\n\nWe have a similar issue during [`IsIdentityConsumingSwitch`](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/grappler/mutable_graph_view.cc#L59-L74):\n\n```cc\n  NodeDef* input_node = graph.GetNode(tensor_id.node());\n  return IsSwitch(*input_node);\n```\n\n### Patches\nWe have patched the issue in GitHub commits [0a365c029e437be0349c31f8d4c9926b69fa3fa1](https://github.com/tensorflow/tensorflow/commit/0a365c029e437be0349c31f8d4c9926b69fa3fa1) and [045deec1cbdebb27d817008ad5df94d96a08b1bf](https://github.com/tensorflow/tensorflow/commit/045deec1cbdebb27d817008ad5df94d96a08b1bf).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-09",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/0a365c029e437be0349c31f8d4c9926b69fa3fa1",
      "commit_sha": "0a365c029e437be0349c31f8d4c9926b69fa3fa1",
      "patch": "MULTI",
      "chain_ord": "['0a365c029e437be0349c31f8d4c9926b69fa3fa1', '045deec1cbdebb27d817008ad5df94d96a08b1bf']",
      "before_first_fix_commit": "{'0a365c029e437be0349c31f8d4c9926b69fa3fa1'}",
      "last_fix_commit": "045deec1cbdebb27d817008ad5df94d96a08b1bf",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/13/2021, 18:05:59",
      "message": "Prevent null pointer dereference in constant folding.\n\nUnder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\n\nPiperOrigin-RevId: 409683530\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'tensorflow/core/grappler/optimizers/constant_folding.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/0a365c029e437be0349c31f8d4c9926b69fa3fa1/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fconstant_folding.cc', 'patch': '@@ -3505,6 +3505,9 @@ bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\\n \\n   NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\\n   NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\\n+  if (mul_left_child == nullptr || mul_right_child == nullptr) {\\n+    return false;\\n+  }\\n   // One child must be constant, and the second must be Conv op.\\n   const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\\n   const bool right_child_is_constant = IsReallyConstant(*mul_right_child);'}}",
      "message_norm": "prevent null pointer dereference in constant folding.\n\nunder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. during optimization phase, grappler optimizer will then dereference a null pointer.\n\npiperorigin-revid: 409683530\nchange-id: i1f10340a7ec384bc9bc587300390f1078cf5caa0",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('null pointer dereference', 'SECWORD', ''), ('409683530', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/grappler/optimizers/constant_folding.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3235,
      "vuln_id": "GHSA-w6cx-qg2q-rvq8",
      "cwe_id": "{'CWE-22'}",
      "score": 7.6,
      "chain": "{'https://github.com/Finastra/ssr-pages/pull/1/commits/c3e4c563384ae3ba3892f37dd190218577620780'}",
      "dataset": "osv",
      "summary": "Path Traversal in @finastra/ssr-pages A path traversal issue can occur when providing untrusted input to the `svg` property as an argument to the `build(MessagePageOptions)` function.\n\n### References\n- https://github.com/Finastra/ssr-pages/pull/1\n- https://github.com/Finastra/ssr-pages/pull/1/commits/c3e4c563384ae3ba3892f37dd190218577620780",
      "published_date": "2022-03-01",
      "chain_len": 1,
      "project": "https://github.com/Finastra/ssr-pages",
      "commit_href": "https://github.com/Finastra/ssr-pages/pull/1/commits/c3e4c563384ae3ba3892f37dd190218577620780",
      "commit_sha": "c3e4c563384ae3ba3892f37dd190218577620780",
      "patch": "SINGLE",
      "chain_ord": "['c3e4c563384ae3ba3892f37dd190218577620780']",
      "before_first_fix_commit": "{'a61ab5a82983ad2d0779454f929bbb76f00ed605'}",
      "last_fix_commit": "c3e4c563384ae3ba3892f37dd190218577620780",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/25/2022, 14:09:28",
      "message": "fix: Fix path traversal vulnerability",
      "author": "David Bocl\u00e9",
      "comments": null,
      "stats": "{'additions': 10, 'deletions': 1, 'total': 11}",
      "files": "{'src/helpers/inlineSVG.helper.ts': {'additions': 10, 'deletions': 1, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/Finastra/ssr-pages/raw/c3e4c563384ae3ba3892f37dd190218577620780/src%2Fhelpers%2FinlineSVG.helper.ts', 'patch': \"@@ -2,6 +2,15 @@ import { readFileSync } from 'fs';\\n import { join } from 'path';\\r\\n \\r\\n export default function inlineSVG(iconName) {\\r\\n-  const path = join(__dirname, `../assets/img/${iconName}.svg`);\\r\\n+  const path = join(__dirname, `../assets/img/${iconNameWhitelist(iconName)}.svg`);\\r\\n   return readFileSync(path, 'utf8');\\r\\n }\\r\\n+\\r\\n+function iconNameWhitelist(iconName) {\\r\\n+  const fallbackIconName = 'warning'\\r\\n+  const whitelist = ['warning', 'exit'];\\r\\n+  if (!whitelist.includes(iconName)) {\\r\\n+    return fallbackIconName;\\r\\n+  }\\r\\n+  return iconName;\\r\\n+}\\n\\\\ No newline at end of file\"}}",
      "message_norm": "fix: fix path traversal vulnerability",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('path traversal', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/helpers/inlineSVG.helper.ts'])",
      "num_files": 1.0
    },
    {
      "index": 343,
      "vuln_id": "GHSA-43f8-2h32-f4cj",
      "cwe_id": "{'CWE-400'}",
      "score": 5.3,
      "chain": "{'https://github.com/npm/hosted-git-info/commit/bede0dc38e1785e732bf0a48ba6f81a4a908eba3', 'https://github.com/npm/hosted-git-info/commit/8d4b3697d79bcd89cdb36d1db165e3696c783a01', 'https://github.com/npm/hosted-git-info/commit/29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service in hosted-git-info The npm package `hosted-git-info` before 3.0.8 are vulnerable to Regular Expression Denial of Service (ReDoS) via regular expression shortcutMatch in the fromUrl function in index.js. The affected regular expression exhibits polynomial worst-case time complexity",
      "published_date": "2021-05-06",
      "chain_len": 3,
      "project": "https://github.com/npm/hosted-git-info",
      "commit_href": "https://github.com/npm/hosted-git-info/commit/bede0dc38e1785e732bf0a48ba6f81a4a908eba3",
      "commit_sha": "bede0dc38e1785e732bf0a48ba6f81a4a908eba3",
      "patch": "MULTI",
      "chain_ord": "['bede0dc38e1785e732bf0a48ba6f81a4a908eba3', '29adfe5ef789784c861b2cdeb15051ec2ba651a7', '8d4b3697d79bcd89cdb36d1db165e3696c783a01']",
      "before_first_fix_commit": "{'29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
      "last_fix_commit": "8d4b3697d79bcd89cdb36d1db165e3696c783a01",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/28/2021, 17:22:16",
      "message": "fix: simplify the regular expression for shortcut matching\n\nPR-URL: https://github.com/npm/hosted-git-info/pull/76\nCredit: @nlf\nClose: #76\nReviewed-by: @isaacs",
      "author": "nlf",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/npm/hosted-git-info/raw/bede0dc38e1785e732bf0a48ba6f81a4a908eba3/index.js', 'patch': \"@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\\n   )\\n   var parsed = parseGitUrl(url)\\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^/]*))[/](.+?)(?:[.]git)?($|#)'))\\n+  var shortcutMatch = url.match(/^([^:]+):(?:[^@]+@)?(?:([^/]*)\\\\/)?([^#]+)/)\\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\\n     try {\\n       var gitHostInfo = gitHosts[gitHostName]\\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\\n       var defaultRepresentation = null\\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\\n-        project = decodeURIComponent(shortcutMatch[3])\\n+        project = decodeURIComponent(shortcutMatch[3].replace(/\\\\.git$/, ''))\\n         defaultRepresentation = 'shortcut'\\n       } else {\\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(/^www[.]/, '') !== gitHostInfo.domain) return\"}}",
      "message_norm": "fix: simplify the regular expression for shortcut matching\n\npr-url: https://github.com/npm/hosted-git-info/pull/76\ncredit: @nlf\nclose: #76\nreviewed-by: @isaacs",
      "language": "en",
      "entities": "[('https://github.com/npm/hosted-git-info/pull/76', 'URL', ''), ('#76', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1706,
      "vuln_id": "GHSA-f98m-q3hr-p5wq",
      "cwe_id": "{'CWE-915', 'CWE-20'}",
      "score": 9.8,
      "chain": "{'https://github.com/locutusjs/locutus/commit/0eb16d8541838e80f3c2340a9ef93ded7c97290f'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in locutus All versions of package locutus prior to version 2.0.12 are vulnerable to Prototype Pollution via the php.strings.parse_str function.",
      "published_date": "2021-05-06",
      "chain_len": 1,
      "project": "https://github.com/locutusjs/locutus",
      "commit_href": "https://github.com/locutusjs/locutus/commit/0eb16d8541838e80f3c2340a9ef93ded7c97290f",
      "commit_sha": "0eb16d8541838e80f3c2340a9ef93ded7c97290f",
      "patch": "SINGLE",
      "chain_ord": "['0eb16d8541838e80f3c2340a9ef93ded7c97290f']",
      "before_first_fix_commit": "{'3f14dc5d142f5dcbdf36b4271c21a850a4a259da'}",
      "last_fix_commit": "0eb16d8541838e80f3c2340a9ef93ded7c97290f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/25/2020, 14:48:03",
      "message": "fixed prototype pollution",
      "author": "Asjid Kalam",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'src/php/strings/parse_str.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/locutusjs/locutus/raw/0eb16d8541838e80f3c2340a9ef93ded7c97290f/src%2Fphp%2Fstrings%2Fparse_str.js', 'patch': \"@@ -74,6 +74,10 @@ module.exports = function parse_str (str, array) { // eslint-disable-line camelc\\n     key = _fixStr(tmp[0])\\n     value = (tmp.length < 2) ? '' : _fixStr(tmp[1])\\n \\n+    if (key.includes('__proto__') || key.includes('constructor') || key.includes('prototype')) {\\n+      break;\\n+    }\\n+\\n     while (key.charAt(0) === ' ') {\\n       key = key.slice(1)\\n     }\"}}",
      "message_norm": "fixed prototype pollution",
      "language": "en",
      "entities": "[('fixed', 'ACTION', ''), ('prototype pollution', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/php/strings/parse_str.js'])",
      "num_files": 1.0
    },
    {
      "index": 3426,
      "vuln_id": "GHSA-xg72-6c83-ghh4",
      "cwe_id": "{'CWE-79'}",
      "score": 4.8,
      "chain": "{'https://github.com/microweber/microweber/commit/d35e691e72d358430abc8e99f5ba9eb374423b9f'}",
      "dataset": "osv",
      "summary": "Microweber Stored Cross-site Scripting before v1.2.20 Microwerber prior to version 1.2.20 is vulnerable to stored Cross-site Scripting (XSS).",
      "published_date": "2022-07-23",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/d35e691e72d358430abc8e99f5ba9eb374423b9f",
      "commit_sha": "d35e691e72d358430abc8e99f5ba9eb374423b9f",
      "patch": "SINGLE",
      "chain_ord": "['d35e691e72d358430abc8e99f5ba9eb374423b9f']",
      "before_first_fix_commit": "{'b39736f1191589e89eb4e54f5f6f05b6349626e3'}",
      "last_fix_commit": "d35e691e72d358430abc8e99f5ba9eb374423b9f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/08/2022, 13:41:01",
      "message": "update",
      "author": "Peter Ivanov",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 4, 'total': 16}",
      "files": "{'src/MicroweberPackages/App/functions/plupload.php': {'additions': 12, 'deletions': 4, 'changes': 16, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/d35e691e72d358430abc8e99f5ba9eb374423b9f/src%2FMicroweberPackages%2FApp%2Ffunctions%2Fplupload.php', 'patch': \"@@ -563,17 +563,25 @@\\n                 }\\n \\n             } else if ($ext === 'svg') {\\n-\\n+                $valid = false;\\n                 if (is_file($filePath)) {\\n                     $sanitizer = new \\\\enshrined\\\\svgSanitize\\\\Sanitizer();\\n                     // Load the dirty svg\\n                     $dirtySVG = file_get_contents($filePath);\\n                      // Pass it to the sanitizer and get it back clean\\n-                    $cleanSVG = $sanitizer->sanitize($dirtySVG);\\n-                    file_put_contents($filePath, $cleanSVG);\\n+                    try {\\n+                        $cleanSVG = $sanitizer->sanitize($dirtySVG);\\n+                        $valid = true;\\n+                    } catch (\\\\Exception $e) {\\n+                        $valid = false;\\n+                    }\\n+\\n+                    if ($valid) {\\n+                        file_put_contents($filePath, $cleanSVG);\\n+                    }\\n \\n                 }\\n-               $valid = true;\\n+\\n \\n             } else {\\n                 $valid = false;\"}}",
      "message_norm": "update",
      "language": "ro",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/App/functions/plupload.php'])",
      "num_files": 1.0
    },
    {
      "index": 624,
      "vuln_id": "GHSA-5fh3-25xr-g85h",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/snipe/snipe-it/commit/ff81e6d5366c2cfb15618793ad919ae4cbb3ac57'}",
      "dataset": "osv",
      "summary": "snipe-it is vulnerable to Cross-site Scripting snipe-it is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting').",
      "published_date": "2021-12-03",
      "chain_len": 1,
      "project": "https://github.com/snipe/snipe-it",
      "commit_href": "https://github.com/snipe/snipe-it/commit/ff81e6d5366c2cfb15618793ad919ae4cbb3ac57",
      "commit_sha": "ff81e6d5366c2cfb15618793ad919ae4cbb3ac57",
      "patch": "SINGLE",
      "chain_ord": "['ff81e6d5366c2cfb15618793ad919ae4cbb3ac57']",
      "before_first_fix_commit": "{'3b68a6f1befeef504c0a3263e87a2afd55abc430', '00fad35c2a6ddc9813d3322da91086eb06cb7406'}",
      "last_fix_commit": "ff81e6d5366c2cfb15618793ad919ae4cbb3ac57",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/25/2021, 03:56:36",
      "message": "Merge pull request #10361 from snipe/fixes/xss_in_accessories_checkout_notes\n\nEscape notes in transformCheckedOutAccessory",
      "author": "snipe",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'app/Http/Transformers/AccessoriesTransformer.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/snipe/snipe-it/raw/ff81e6d5366c2cfb15618793ad919ae4cbb3ac57/app%2FHttp%2FTransformers%2FAccessoriesTransformer.php', 'patch': \"@@ -82,7 +82,7 @@ public function transformCheckedoutAccessory ($accessory, $accessory_users, $tot\\n                 'first_name'=> e($user->first_name),\\n                 'last_name'=> e($user->last_name),\\n                 'employee_number' =>  e($user->employee_num),\\n-                'checkout_notes' => $user->pivot->note,\\n+                'checkout_notes' => e($user->pivot->note),\\n                 'last_checkout' => Helper::getFormattedDateObject($user->pivot->created_at, 'datetime'),\\n                 'type' => 'user',\\n                 'available_actions' => ['checkin' => true]\"}}",
      "message_norm": "merge pull request #10361 from snipe/fixes/xss_in_accessories_checkout_notes\n\nescape notes in transformcheckedoutaccessory",
      "language": "en",
      "entities": "[('#10361', 'ISSUE', ''), ('xss_in_accessories_checkout_notes', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['app/Http/Transformers/AccessoriesTransformer.php'])",
      "num_files": 1.0
    },
    {
      "index": 169,
      "vuln_id": "GHSA-2xw8-j43j-5vxp",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/elgg/elgg/commit/c30b17bf75256ed3fcc84e2083147cc3951423d0'}",
      "dataset": "osv",
      "summary": "elgg is vulnerable to Cross-site Scripting elgg is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/elgg/elgg",
      "commit_href": "https://github.com/elgg/elgg/commit/c30b17bf75256ed3fcc84e2083147cc3951423d0",
      "commit_sha": "c30b17bf75256ed3fcc84e2083147cc3951423d0",
      "patch": "SINGLE",
      "chain_ord": "['c30b17bf75256ed3fcc84e2083147cc3951423d0']",
      "before_first_fix_commit": "{'ea72485b6a08f30f452b8e5425310f2b3546050c'}",
      "last_fix_commit": "c30b17bf75256ed3fcc84e2083147cc3951423d0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/06/2021, 14:39:10",
      "message": "fix(reported_content): sanitize report URLs",
      "author": "Jer\u00f4me Bakker",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'mod/reportedcontent/actions/reportedcontent/add.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/Elgg/Elgg/raw/c30b17bf75256ed3fcc84e2083147cc3951423d0/mod%2Freportedcontent%2Factions%2Freportedcontent%2Fadd.php', 'patch': '@@ -18,7 +18,7 @@\\n $report = new ElggReportedContent();\\n $report->owner_guid = elgg_get_logged_in_user_guid();\\n $report->title = $title;\\n-$report->address = $address;\\n+$report->address = elgg_normalize_site_url($address);\\n $report->description = $description;\\n $report->access_id = $access;'}}",
      "message_norm": "fix(reported_content): sanitize report urls",
      "language": "ro",
      "entities": "[('fix(reported_content', 'ACTION', ''), ('sanitize', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['mod/reportedcontent/actions/reportedcontent/add.php'])",
      "num_files": 1.0
    },
    {
      "index": 2924,
      "vuln_id": "GHSA-rf3h-xgv5-2q39",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0'}",
      "dataset": "osv",
      "summary": "Division by zero in TFLite's implementation of `DepthwiseConv` ### Impact\nThe implementation of the `DepthwiseConv` TFLite operator is [vulnerable to a division by zero error](https://github.com/tensorflow/tensorflow/blob/1a8e885b864c818198a5b2c0cbbeca5a1e833bc8/tensorflow/lite/kernels/depthwise_conv.cc#L287-L288):\n\n```cc\nint num_input_channels = SizeOfDimension(input, 3);\nTF_LITE_ENSURE_EQ(context, num_filter_channels % num_input_channels, 0);\n```\n\nAn attacker can craft a model such that `input`'s fourth dimension would be 0.\n\n### Patches\nWe have patched the issue in GitHub commit [cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0](https://github.com/tensorflow/tensorflow/commit/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0",
      "commit_sha": "cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0",
      "patch": "SINGLE",
      "chain_ord": "['cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0']",
      "before_first_fix_commit": "{'1a8e885b864c818198a5b2c0cbbeca5a1e833bc8'}",
      "last_fix_commit": "cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 22:53:48",
      "message": "Prevent divisions by 0\n\nPiperOrigin-RevId: 371003153\nChange-Id: Idef56c95b9fcaeb97f87e18c7a674dbeb5173204",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 2, 'total': 5}",
      "files": "{'tensorflow/lite/kernels/depthwise_conv.cc': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0/tensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc', 'patch': '@@ -285,8 +285,8 @@ TfLiteStatus ComputeDepthMultiplier(TfLiteContext* context,\\n                                     int16* depth_multiplier) {\\n   int num_filter_channels = SizeOfDimension(filter, 3);\\n   int num_input_channels = SizeOfDimension(input, 3);\\n+  TF_LITE_ENSURE(context, num_input_channels != 0);\\n   TF_LITE_ENSURE_EQ(context, num_filter_channels % num_input_channels, 0);\\n-\\n   *depth_multiplier = num_filter_channels / num_input_channels;\\n   return kTfLiteOk;\\n }\\n@@ -455,8 +455,9 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\\n   float output_activation_min, output_activation_max;\\n   CalculateActivationRange(params->activation, &output_activation_min,\\n                            &output_activation_max);\\n-  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\\n   const int batch_size = SizeOfDimension(input, 0);\\n+  TF_LITE_ENSURE(context, batch_size != 0);\\n+  const int input_size = NumElements(input) / batch_size;\\n   TfLiteTensor* input_quantized;\\n   TF_LITE_ENSURE_OK(context,\\n                     GetTemporarySafe(context, node, data->input_quantized_index,'}}",
      "message_norm": "prevent divisions by 0\n\npiperorigin-revid: 371003153\nchange-id: idef56c95b9fcaeb97f87e18c7a674dbeb5173204",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('divisions by 0', 'SECWORD', ''), ('371003153', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/depthwise_conv.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3418,
      "vuln_id": "GHSA-xfhh-g9f5-x4m4",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/socketio/socket.io-parser/commit/dcb942d24db97162ad16a67c2a0cf30875342d55'}",
      "dataset": "osv",
      "summary": "Resource exhaustion in socket.io-parser The `socket.io-parser` npm package before versions 3.3.2 and 3.4.1 allows attackers to cause a denial of service (memory consumption) via a large packet because a concatenation approach is used.",
      "published_date": "2021-06-30",
      "chain_len": 1,
      "project": "https://github.com/socketio/socket.io-parser",
      "commit_href": "https://github.com/socketio/socket.io-parser/commit/dcb942d24db97162ad16a67c2a0cf30875342d55",
      "commit_sha": "dcb942d24db97162ad16a67c2a0cf30875342d55",
      "patch": "SINGLE",
      "chain_ord": "['dcb942d24db97162ad16a67c2a0cf30875342d55']",
      "before_first_fix_commit": "{'a5d04354e6e98b5318d5276123b0b5a5e698bf8e'}",
      "last_fix_commit": "dcb942d24db97162ad16a67c2a0cf30875342d55",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/13/2020, 05:37:32",
      "message": "fix: prevent DoS (OOM) via massive packets (#95)\n\nWhen maxHttpBufferSize is large (1e8 bytes), a payload of length 100MB\r\ncan be sent like so:\r\n\r\n99999991:422222222222222222222222222222222222222222222...\r\n\r\nThis massive packet can cause OOM via building up many many\r\n`ConsOneByteString` objects due to concatenation:\r\n99999989 `ConsOneByteString`s and then converting the massive integer to\r\na `Number`.\r\n\r\nThe performance can be improved to avoid this by using `substring`\r\nrather than building the string via concatenation.\r\n\r\nBelow I tried one payload of length 7e7 as the 1e8 payload took so\r\nlong to process that it timed out before running out of memory.\r\n\r\n```\r\n==== JS stack trace =========================================\r\n\r\n    0: ExitFrame [pc: 0x13c5b79]\r\nSecurity context: 0x152fe7b808d1 <JSObject>\r\n    1: decodeString [0x2dd385fb5d1] [/node_modules/socket.io-parser/index.js:~276] [pc=0xf59746881be](this=0x175d34c42b69 <JSGlobal Object>,0x14eccff10fe1 <Very long string[69999990]>)\r\n    2: add [0x31fc2693da29] [/node_modules/socket.io-parser/index.js:242] [bytecode=0xa7ed6554889 offset=11](this=0x0a2881be5069 <Decoder map = 0x3ceaa8bf48c9>,0x14eccff10fe1 <Very...\r\n\r\nFATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory\r\n 1: 0xa09830 node::Abort() [node]\r\n 2: 0xa09c55 node::OnFatalError(char const*, char const*) [node]\r\n 3: 0xb7d71e v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [node]\r\n 4: 0xb7da99 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [node]\r\n 5: 0xd2a1f5  [node]\r\n 6: 0xd2a886 v8::internal::Heap::RecomputeLimits(v8::internal::GarbageCollector) [node]\r\n 7: 0xd37105 v8::internal::Heap::PerformGarbageCollection(v8::internal::GarbageCollector, v8::GCCallbackFlags) [node]\r\n 8: 0xd37fb5 v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [node]\r\n 9: 0xd3965f v8::internal::Heap::HandleGCRequest() [node]\r\n10: 0xce8395 v8::internal::StackGuard::HandleInterrupts() [node]\r\n11: 0x1042cb6 v8::internal::Runtime_StackGuard(int, unsigned long*, v8::internal::Isolate*) [node]\r\n12: 0x13c5b79  [node]\r\n```",
      "author": "bcaller",
      "comments": "{'com_1': {'author': 'abergmann', 'datetime': '01/08/2021, 09:15:14', 'body': '[CVE-2020-36049](https://nvd.nist.gov/vuln/detail/CVE-2020-36049) was assigned to this commit.'}}",
      "stats": "{'additions': 7, 'deletions': 10, 'total': 17}",
      "files": "{'index.js': {'additions': 7, 'deletions': 10, 'changes': 17, 'status': 'modified', 'raw_url': 'https://github.com/socketio/socket.io-parser/raw/dcb942d24db97162ad16a67c2a0cf30875342d55/index.js', 'patch': \"@@ -286,11 +286,9 @@ function decodeString(str) {\\n \\n   // look up attachments if type binary\\n   if (exports.BINARY_EVENT === p.type || exports.BINARY_ACK === p.type) {\\n-    var buf = '';\\n-    while (str.charAt(++i) !== '-') {\\n-      buf += str.charAt(i);\\n-      if (i == str.length) break;\\n-    }\\n+    var start = i + 1;\\n+    while (str.charAt(++i) !== '-' && i != str.length) {}\\n+    var buf = str.substring(start, i);\\n     if (buf != Number(buf) || str.charAt(i) !== '-') {\\n       throw new Error('Illegal attachments');\\n     }\\n@@ -299,31 +297,30 @@ function decodeString(str) {\\n \\n   // look up namespace (if any)\\n   if ('/' === str.charAt(i + 1)) {\\n-    p.nsp = '';\\n+    var start = i + 1;\\n     while (++i) {\\n       var c = str.charAt(i);\\n       if (',' === c) break;\\n-      p.nsp += c;\\n       if (i === str.length) break;\\n     }\\n+    p.nsp = str.substring(start, i);\\n   } else {\\n     p.nsp = '/';\\n   }\\n \\n   // look up id\\n   var next = str.charAt(i + 1);\\n   if ('' !== next && Number(next) == next) {\\n-    p.id = '';\\n+    var start = i + 1;\\n     while (++i) {\\n       var c = str.charAt(i);\\n       if (null == c || Number(c) != c) {\\n         --i;\\n         break;\\n       }\\n-      p.id += str.charAt(i);\\n       if (i === str.length) break;\\n     }\\n-    p.id = Number(p.id);\\n+    p.id = Number(str.substring(start, i + 1));\\n   }\\n \\n   // look up json data\"}}",
      "message_norm": "fix: prevent dos (oom) via massive packets (#95)\n\nwhen maxhttpbuffersize is large (1e8 bytes), a payload of length 100mb\r\ncan be sent like so:\r\n\r\n99999991:422222222222222222222222222222222222222222222...\r\n\r\nthis massive packet can cause oom via building up many many\r\n`consonebytestring` objects due to concatenation:\r\n99999989 `consonebytestring`s and then converting the massive integer to\r\na `number`.\r\n\r\nthe performance can be improved to avoid this by using `substring`\r\nrather than building the string via concatenation.\r\n\r\nbelow i tried one payload of length 7e7 as the 1e8 payload took so\r\nlong to process that it timed out before running out of memory.\r\n\r\n```\r\n==== js stack trace =========================================\r\n\r\n    0: exitframe [pc: 0x13c5b79]\r\nsecurity context: 0x152fe7b808d1 <jsobject>\r\n    1: decodestring [0x2dd385fb5d1] [/node_modules/socket.io-parser/index.js:~276] [pc=0xf59746881be](this=0x175d34c42b69 <jsglobal object>,0x14eccff10fe1 <very long string[69999990]>)\r\n    2: add [0x31fc2693da29] [/node_modules/socket.io-parser/index.js:242] [bytecode=0xa7ed6554889 offset=11](this=0x0a2881be5069 <decoder map = 0x3ceaa8bf48c9>,0x14eccff10fe1 <very...\r\n\r\nfatal error: ineffective mark-compacts near heap limit allocation failed - javascript heap out of memory\r\n 1: 0xa09830 node::abort() [node]\r\n 2: 0xa09c55 node::onfatalerror(char const*, char const*) [node]\r\n 3: 0xb7d71e v8::utils::reportoomfailure(v8::internal::isolate*, char const*, bool) [node]\r\n 4: 0xb7da99 v8::internal::v8::fatalprocessoutofmemory(v8::internal::isolate*, char const*, bool) [node]\r\n 5: 0xd2a1f5  [node]\r\n 6: 0xd2a886 v8::internal::heap::recomputelimits(v8::internal::garbagecollector) [node]\r\n 7: 0xd37105 v8::internal::heap::performgarbagecollection(v8::internal::garbagecollector, v8::gccallbackflags) [node]\r\n 8: 0xd37fb5 v8::internal::heap::collectgarbage(v8::internal::allocationspace, v8::internal::garbagecollectionreason, v8::gccallbackflags) [node]\r\n 9: 0xd3965f v8::internal::heap::handlegcrequest() [node]\r\n10: 0xce8395 v8::internal::stackguard::handleinterrupts() [node]\r\n11: 0x1042cb6 v8::internal::runtime_stackguard(int, unsigned long*, v8::internal::isolate*) [node]\r\n12: 0x13c5b79  [node]\r\n```",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('dos', 'SECWORD', ''), ('#95', 'ISSUE', ''), ('99999989', 'SHA', 'generic_sha'), ('improved', 'ACTION', ''), ('out of memory', 'SECWORD', ''), ('security', 'SECWORD', ''), ('decodestring', 'SECWORD', ''), ('add', 'ACTION', ''), ('decoder', 'SECWORD', ''), ('error', 'FLAW', ''), ('out of memory', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 965,
      "vuln_id": "GHSA-75f6-78jr-4656",
      "cwe_id": "{'CWE-476'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/f4c364a5d6880557f6f5b6eb5cee2c407f0186b3'}",
      "dataset": "osv",
      "summary": "Null pointer dereference in `EditDistance` ### Impact\nAn attacker can trigger a null pointer dereference in the implementation of `tf.raw_ops.EditDistance`: \n    \n```python\nimport tensorflow as tf\n\nhypothesis_indices = tf.constant([247, 247, 247], shape=[1, 3], dtype=tf.int64)\nhypothesis_values = tf.constant([-9.9999], shape=[1], dtype=tf.float32)\nhypothesis_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\ntruth_indices = tf.constant([], shape=[0, 3], dtype=tf.int64)\ntruth_values = tf.constant([], shape=[0], dtype=tf.float32)\ntruth_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\n\ntf.raw_ops.EditDistance(\n    hypothesis_indices=hypothesis_indices, hypothesis_values=hypothesis_values,\n    hypothesis_shape=hypothesis_shape, truth_indices=truth_indices,\n    truth_values=truth_values, truth_shape=truth_shape, normalize=True)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/79865b542f9ffdc9caeb255631f7c56f1d4b6517/tensorflow/core/kernels/edit_distance_op.cc#L103-L159) has incomplete validation of the input parameters.\n\nIn the above scenario, an attacker causes an allocation of an empty tensor for the output:\n\n```cc\nOP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\nauto output_t = output->flat<float>();\noutput_t.setZero();\n```\n\nBecause `output_shape` has 0 elements, the result of `output->flat<T>()` has an empty buffer, so calling `setZero` would result in a null dereference.\n\n### Patches\nWe have patched the issue in GitHub commit [f4c364a5d6880557f6f5b6eb5cee2c407f0186b3](https://github.com/tensorflow/tensorflow/commit/f4c364a5d6880557f6f5b6eb5cee2c407f0186b3).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/f4c364a5d6880557f6f5b6eb5cee2c407f0186b3",
      "commit_sha": "f4c364a5d6880557f6f5b6eb5cee2c407f0186b3",
      "patch": "SINGLE",
      "chain_ord": "['f4c364a5d6880557f6f5b6eb5cee2c407f0186b3']",
      "before_first_fix_commit": "{'79865b542f9ffdc9caeb255631f7c56f1d4b6517'}",
      "last_fix_commit": "f4c364a5d6880557f6f5b6eb5cee2c407f0186b3",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/05/2021, 01:06:03",
      "message": "Fix multiple issues in EditDistance\n\nPiperOrigin-RevId: 372033948\nChange-Id: Ieb957c29894af05bdfeb1a0402fced808dfcfd7b",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 47, 'deletions': 0, 'total': 47}",
      "files": "{'tensorflow/core/kernels/edit_distance_op.cc': {'additions': 47, 'deletions': 0, 'changes': 47, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/f4c364a5d6880557f6f5b6eb5cee2c407f0186b3/tensorflow%2Fcore%2Fkernels%2Fedit_distance_op.cc', 'patch': '@@ -64,6 +64,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\\n     return errors::InvalidArgument(\\n         \"truth_shape should be a vector, but got shape: \",\\n         truth_shape.shape().DebugString());\\n+  if (hypothesis_values.NumElements() != hypothesis_indices.dim_size(0))\\n+    return errors::InvalidArgument(\\n+        \"Expected hypothesis_values.NumElements == \"\\n+        \"#rows(hypothesis_indices), their shapes are: \",\\n+        hypothesis_values.shape().DebugString(), \" and \",\\n+        hypothesis_indices.shape().DebugString());\\n   if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))\\n     return errors::InvalidArgument(\\n         \"Expected hypothesis_shape.NumElements == \"\\n@@ -75,6 +81,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\\n         \"Input SparseTensors must have rank at least 2, but truth_shape \"\\n         \"rank is: \",\\n         truth_shape.NumElements());\\n+  if (truth_values.NumElements() != truth_indices.dim_size(0))\\n+    return errors::InvalidArgument(\\n+        \"Expected truth_values.NumElements == \"\\n+        \"#rows(truth_indices), their shapes are: \",\\n+        truth_values.shape().DebugString(), \" and \",\\n+        truth_indices.shape().DebugString());\\n   if (truth_shape.NumElements() != truth_indices.dim_size(1))\\n     return errors::InvalidArgument(\\n         \"Expected truth_shape.NumElements == \"\\n@@ -153,6 +165,11 @@ class EditDistanceOp : public OpKernel {\\n       output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\\n                                    truth_st_shape.dim_size(d)));\\n     }\\n+    const auto output_elements = output_shape.num_elements();\\n+    OP_REQUIRES(\\n+        ctx, output_elements > 0,\\n+        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\\n+                                \" which has 0 elements\"));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\\n@@ -185,6 +202,12 @@ class EditDistanceOp : public OpKernel {\\n       if (g_truth == g_hypothesis) {\\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\\n                                       output_strides.begin(), int64{0});\\n+        OP_REQUIRES(\\n+            ctx, loc < output_elements,\\n+            errors::Internal(\"Got an inner product \", loc,\\n+                             \" which would require in writing to outside of \"\\n+                             \"the buffer for the output tensor (max elements \",\\n+                             output_elements, \")\"));\\n         output_t(loc) =\\n             gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\\n         if (normalize_) output_t(loc) /= truth_seq.size();\\n@@ -194,6 +217,12 @@ class EditDistanceOp : public OpKernel {\\n       } else if (g_truth > g_hypothesis) {  // zero-length truth\\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\\n                                       output_strides.begin(), int64{0});\\n+        OP_REQUIRES(\\n+            ctx, loc < output_elements,\\n+            errors::Internal(\"Got an inner product \", loc,\\n+                             \" which would require in writing to outside of \"\\n+                             \"the buffer for the output tensor (max elements \",\\n+                             output_elements, \")\"));\\n         output_t(loc) = hypothesis_seq.size();\\n         if (normalize_ && output_t(loc) != 0.0f) {\\n           output_t(loc) = std::numeric_limits<float>::infinity();\\n@@ -202,6 +231,12 @@ class EditDistanceOp : public OpKernel {\\n       } else {  // zero-length hypothesis\\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\\n                                       output_strides.begin(), int64{0});\\n+        OP_REQUIRES(\\n+            ctx, loc < output_elements,\\n+            errors::Internal(\"Got an inner product \", loc,\\n+                             \" which would require in writing to outside of \"\\n+                             \"the buffer for the output tensor (max elements \",\\n+                             output_elements, \")\"));\\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\\n         ++truth_iter;\\n       }\\n@@ -212,6 +247,12 @@ class EditDistanceOp : public OpKernel {\\n       auto hypothesis_seq = hypothesis_j.values<T>();\\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\\n                                     output_strides.begin(), int64{0});\\n+      OP_REQUIRES(\\n+          ctx, loc < output_elements,\\n+          errors::Internal(\"Got an inner product \", loc,\\n+                           \" which would require in writing to outside of the \"\\n+                           \"buffer for the output tensor (max elements \",\\n+                           output_elements, \")\"));\\n       output_t(loc) = hypothesis_seq.size();\\n       if (normalize_ && output_t(loc) != 0.0f) {\\n         output_t(loc) = std::numeric_limits<float>::infinity();\\n@@ -224,6 +265,12 @@ class EditDistanceOp : public OpKernel {\\n       auto truth_seq = truth_i.values<T>();\\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\\n                                     output_strides.begin(), int64{0});\\n+      OP_REQUIRES(\\n+          ctx, loc < output_elements,\\n+          errors::Internal(\"Got an inner product \", loc,\\n+                           \" which would require in writing to outside of the \"\\n+                           \"buffer for the output tensor (max elements \",\\n+                           output_elements, \")\"));\\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\\n       ++truth_iter;\\n     }'}}",
      "message_norm": "fix multiple issues in editdistance\n\npiperorigin-revid: 372033948\nchange-id: ieb957c29894af05bdfeb1a0402fced808dfcfd7b",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('issues', 'FLAW', ''), ('372033948', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/edit_distance_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1817,
      "vuln_id": "GHSA-g4w7-3qr8-5623",
      "cwe_id": "{'CWE-351'}",
      "score": 9.8,
      "chain": "{'https://github.com/rusqlite/rusqlite/commit/71b2f5187b0cbace3f8b6ff53432ff2ca0defcf0'}",
      "dataset": "osv",
      "summary": "Improper type usage in rusqlite An issue was discovered in the rusqlite crate before 0.23.0 for Rust. Memory safety can be violated via the repr(Rust) type.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/rusqlite/rusqlite",
      "commit_href": "https://github.com/rusqlite/rusqlite/commit/71b2f5187b0cbace3f8b6ff53432ff2ca0defcf0",
      "commit_sha": "71b2f5187b0cbace3f8b6ff53432ff2ca0defcf0",
      "patch": "SINGLE",
      "chain_ord": "['71b2f5187b0cbace3f8b6ff53432ff2ca0defcf0']",
      "before_first_fix_commit": "{'38aea89809ea4154975d853bffe3cb7715fe84d6'}",
      "last_fix_commit": "71b2f5187b0cbace3f8b6ff53432ff2ca0defcf0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/12/2020, 18:17:56",
      "message": "Ensure type use for auxdata is repr(C)",
      "author": "Thom Chiovoloni",
      "comments": null,
      "stats": "{'additions': 16, 'deletions': 6, 'total': 22}",
      "files": "{'src/functions.rs': {'additions': 16, 'deletions': 6, 'changes': 22, 'status': 'modified', 'raw_url': 'https://github.com/rusqlite/rusqlite/raw/71b2f5187b0cbace3f8b6ff53432ff2ca0defcf0/src%2Ffunctions.rs', 'patch': '@@ -67,6 +67,7 @@\\n //!     Ok(())\\n //! }\\n //! ```\\n+use std::any::TypeId;\\n use std::os::raw::{c_int, c_void};\\n use std::panic::{catch_unwind, RefUnwindSafe, UnwindSafe};\\n use std::ptr;\\n@@ -177,13 +178,16 @@ impl Context<\\'_> {\\n     /// https://www.sqlite.org/c3ref/get_auxdata.html for a discussion of\\n     /// this feature, or the unit tests of this module for an example.\\n     pub fn set_aux<T: \\'static>(&self, arg: c_int, value: T) {\\n-        let boxed = Box::into_raw(Box::new((std::any::TypeId::of::<T>(), value)));\\n+        let boxed = Box::into_raw(Box::new(AuxData {\\n+            id: TypeId::of::<T>(),\\n+            value,\\n+        }));\\n         unsafe {\\n             ffi::sqlite3_set_auxdata(\\n                 self.ctx,\\n                 arg,\\n                 boxed as *mut c_void,\\n-                Some(free_boxed_value::<(std::any::TypeId, T)>),\\n+                Some(free_boxed_value::<AuxData<T>>),\\n             )\\n         };\\n     }\\n@@ -192,20 +196,26 @@ impl Context<\\'_> {\\n     /// via `set_aux`. Returns `Ok(None)` if no data has been associated,\\n     /// and .\\n     pub fn get_aux<T: \\'static>(&self, arg: c_int) -> Result<Option<&T>> {\\n-        let p = unsafe { ffi::sqlite3_get_auxdata(self.ctx, arg) as *mut (std::any::TypeId, T) };\\n+        let p = unsafe { ffi::sqlite3_get_auxdata(self.ctx, arg) as *const AuxData<T> };\\n         if p.is_null() {\\n             Ok(None)\\n         } else {\\n-            let id_val = unsafe { &*p };\\n-            if std::any::TypeId::of::<T>() != id_val.0 {\\n+            let id = unsafe { (*p).id };\\n+            if TypeId::of::<T>() != id {\\n                 Err(Error::GetAuxWrongType)\\n             } else {\\n-                Ok(Some(&id_val.1))\\n+                Ok(Some(unsafe { &(*p).value }))\\n             }\\n         }\\n     }\\n }\\n \\n+#[repr(C)]\\n+struct AuxData<T: \\'static> {\\n+    id: TypeId,\\n+    value: T,\\n+}\\n+\\n /// `feature = \"functions\"` Aggregate is the callback interface for user-defined\\n /// aggregate function.\\n ///'}}",
      "message_norm": "ensure type use for auxdata is repr(c)",
      "language": "fr",
      "entities": "[('ensure', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/functions.rs'])",
      "num_files": 1.0
    },
    {
      "index": 822,
      "vuln_id": "GHSA-6f84-42vf-ppwp",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6'}",
      "dataset": "osv",
      "summary": "Division by 0 in `QuantizedMul` ### Impact\nAn attacker can trigger a division by 0 in `tf.raw_ops.QuantizedMul`:\n\n```python\nimport tensorflow as tf\n\nx = tf.zeros([4, 1], dtype=tf.quint8)\ny = tf.constant([], dtype=tf.quint8)\nmin_x = tf.constant(0.0)\nmax_x = tf.constant(0.0010000000474974513)\nmin_y = tf.constant(0.0)\nmax_y = tf.constant(0.0010000000474974513)\n\ntf.raw_ops.QuantizedMul(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)\n```                            \n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/55900e961ed4a23b438392024912154a2c2f5e85/tensorflow/core/kernels/quantized_mul_op.cc#L188-L198) does a division by a quantity that is controlled by the caller:\n\n```cc\ntemplate <class T, class Toutput>\nvoid VectorTensorMultiply(const T* vector_data, int32 vector_offset,\n                          int64 vector_num_elements, const T* tensor_data,\n                          int32 tensor_offset, int64 tensor_num_elements,\n                          Toutput* output) {\n  for (int i = 0; i < tensor_num_elements; ++i) {\n    const int64 vector_i = i % vector_num_elements;\n    ...\n  }\n}\n```\n\n### Patches\nWe have patched the issue in GitHub commit [a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6](https://github.com/tensorflow/tensorflow/commit/a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6",
      "commit_sha": "a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6",
      "patch": "SINGLE",
      "chain_ord": "['a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6']",
      "before_first_fix_commit": "{'55900e961ed4a23b438392024912154a2c2f5e85'}",
      "last_fix_commit": "a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/20/2021, 17:52:46",
      "message": "Fix one division by zero\n\nPiperOrigin-RevId: 369474832\nChange-Id: I1082858ed78d9b2e4738ce30b231955973d49e1e",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/quantized_mul_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6/tensorflow%2Fcore%2Fkernels%2Fquantized_mul_op.cc', 'patch': '@@ -347,6 +347,11 @@ class QuantizedMulOp : public OpKernel {\\n         tensor_num_elements = x.NumElements();\\n         tensor_offset = offset_x;\\n       }\\n+      if (vector_num_elements == 0) {\\n+        context->SetStatus(\\n+            errors::InvalidArgument(\"vector must have at least 1 element\"));\\n+        return;\\n+      }\\n       VectorTensorMultiply<T, Toutput>(\\n           vector_data, vector_offset, vector_num_elements, tensor_data,\\n           tensor_offset, tensor_num_elements, z_data);'}}",
      "message_norm": "fix one division by zero\n\npiperorigin-revid: 369474832\nchange-id: i1082858ed78d9b2e4738ce30b231955973d49e1e",
      "language": "it",
      "entities": "[('fix', 'ACTION', ''), ('division by zero', 'SECWORD', ''), ('369474832', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/quantized_mul_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1763,
      "vuln_id": "GHSA-fq86-3f29-px2c",
      "cwe_id": "{'CWE-617'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/240655511cd3e701155f944a972db71b6c0b1bb6', 'https://github.com/tensorflow/tensorflow/commit/ebc1a2ffe5a7573d905e99bd0ee3568ee07c12c1', 'https://github.com/tensorflow/tensorflow/commit/1fb27733f943295d874417630edd3b38b34ce082'}",
      "dataset": "osv",
      "summary": "`CHECK`-failures during Grappler's `IsSimplifiableReshape` in Tensorflow ### Impact\nThe Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that [`IsSimplifiableReshape`](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/grappler/optimizers/constant_folding.cc#L1687-L1742) would trigger `CHECK` failures.\n\n### Patches\nWe have patched the issue in GitHub commits [ebc1a2ffe5a7573d905e99bd0ee3568ee07c12c1](https://github.com/tensorflow/tensorflow/commit/ebc1a2ffe5a7573d905e99bd0ee3568ee07c12c1), [1fb27733f943295d874417630edd3b38b34ce082](https://github.com/tensorflow/tensorflow/commit/1fb27733f943295d874417630edd3b38b34ce082), and [240655511cd3e701155f944a972db71b6c0b1bb6](https://github.com/tensorflow/tensorflow/commit/240655511cd3e701155f944a972db71b6c0b1bb6).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-07",
      "chain_len": 3,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/240655511cd3e701155f944a972db71b6c0b1bb6",
      "commit_sha": "240655511cd3e701155f944a972db71b6c0b1bb6",
      "patch": "MULTI",
      "chain_ord": "['ebc1a2ffe5a7573d905e99bd0ee3568ee07c12c1', '1fb27733f943295d874417630edd3b38b34ce082', '240655511cd3e701155f944a972db71b6c0b1bb6']",
      "before_first_fix_commit": "{'1fb27733f943295d874417630edd3b38b34ce082'}",
      "last_fix_commit": "240655511cd3e701155f944a972db71b6c0b1bb6",
      "chain_ord_pos": 3.0,
      "commit_datetime": "11/11/2021, 17:24:31",
      "message": "Eliminate `CHECK`-fails from `IsSimplifiableReshape` via `MakeShape(<invalid shape>)`\n\nPiperOrigin-RevId: 409166738\nChange-Id: I7f0a3590b8acae3f3e3e2fe636e1f5ef285693cf",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 2, 'total': 6}",
      "files": "{'tensorflow/core/grappler/optimizers/constant_folding.cc': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/240655511cd3e701155f944a972db71b6c0b1bb6/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fconstant_folding.cc', 'patch': '@@ -1741,14 +1741,16 @@ Status ConstantFolding::IsSimplifiableReshape(\\n       int32_t dim = outputs[0]->flat<int32>()(i);\\n       shp.push_back(dim);\\n     }\\n-    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\\n+    s = TensorShapeUtils::MakeShape(shp, &new_dims);\\n+    if (!s.ok()) return s;\\n   } else {\\n     std::vector<int64_t> shp;\\n     for (int i = 0; i < outputs[0]->NumElements(); ++i) {\\n       int64_t dim = outputs[0]->flat<int64_t>()(i);\\n       shp.push_back(dim);\\n     }\\n-    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\\n+    s = TensorShapeUtils::MakeShape(shp, &new_dims);\\n+    if (!s.ok()) return s;\\n   }\\n \\n   if (!shape.IsCompatibleWith(new_dims)) {'}}",
      "message_norm": "eliminate `check`-fails from `issimplifiablereshape` via `makeshape(<invalid shape>)`\n\npiperorigin-revid: 409166738\nchange-id: i7f0a3590b8acae3f3e3e2fe636e1f5ef285693cf",
      "language": "en",
      "entities": "[('409166738', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/grappler/optimizers/constant_folding.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1916,
      "vuln_id": "GHSA-gq67-pp9w-43gp",
      "cwe_id": "{'CWE-330', 'CWE-352'}",
      "score": 0.0,
      "chain": "{'https://github.com/apache/myfaces/commit/cc6e1cc7b9aa17e52452f7f2657b3af9c421b2b2'}",
      "dataset": "osv",
      "summary": "Cryptographically weak CSRF tokens in Apache MyFaces In the default configuration, Apache MyFaces Core versions 2.2.0 to 2.2.13, 2.3.0 to 2.3.7, 2.3-next-M1 to 2.3-next-M4, and 3.0.0-RC1 use cryptographically weak implicit and explicit cross-site request forgery (CSRF) tokens. Due to that limitation, it is possible (although difficult) for an attacker to calculate a future CSRF token value and to use that value to trick a user into executing unwanted actions on an application.\n\n\nMitigation:\nExisting web.xml configuration parameters can be used to direct\nMyFaces to use SecureRandom for CSRF token generation:\n\norg.apache.myfaces.RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN=secureRandom\norg.apache.myfaces.RANDOM_KEY_IN_CSRF_SESSION_TOKEN=secureRandom\norg.apache.myfaces.RANDOM_KEY_IN_WEBSOCKET_SESSION_TOKEN=secureRandom",
      "published_date": "2021-06-16",
      "chain_len": 1,
      "project": "https://github.com/apache/myfaces",
      "commit_href": "https://github.com/apache/myfaces/commit/cc6e1cc7b9aa17e52452f7f2657b3af9c421b2b2",
      "commit_sha": "cc6e1cc7b9aa17e52452f7f2657b3af9c421b2b2",
      "patch": "SINGLE",
      "chain_ord": "['cc6e1cc7b9aa17e52452f7f2657b3af9c421b2b2']",
      "before_first_fix_commit": "{'2683d7ec7008eb2a728423ad6e574fa83137b65c', '413d25bfc0ba3a49a06484e17d603a25ce4af436'}",
      "last_fix_commit": "cc6e1cc7b9aa17e52452f7f2657b3af9c421b2b2",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/13/2021, 19:51:15",
      "message": "Merge pull request #132 from wtlucy/secureRandom_master\n\nMYFACES-4373: prefer SecureRandom for token generation",
      "author": "Thomas Andraschko",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 7, 'total': 14}",
      "files": "{'impl/src/main/java/org/apache/myfaces/config/MyfacesConfig.java': {'additions': 7, 'deletions': 7, 'changes': 14, 'status': 'modified', 'raw_url': 'https://github.com/apache/myfaces/raw/cc6e1cc7b9aa17e52452f7f2657b3af9c421b2b2/impl%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fmyfaces%2Fconfig%2FMyfacesConfig.java', 'patch': '@@ -459,12 +459,12 @@\\n      * Adds a random key to the generated view state session token.\\n      */\\n     @JSFWebConfigParam(since=\"2.1.9, 2.0.15\", expectedValues=\"secureRandom, random\", \\n-            defaultValue=\"random\", group=\"state\")\\n+            defaultValue=\"secureRandom\", group=\"state\")\\n     public static final String RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN\\n             = \"org.apache.myfaces.RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN\";\\n-    private static final String RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN_DEFAULT = \"random\";\\n     public static final String RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN_SECURE_RANDOM = \"secureRandom\";\\n     public static final String RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN_RANDOM = \"random\";\\n+    private static final String RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN_DEFAULT = RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN_SECURE_RANDOM;\\n     \\n     /**\\n      * Set the default length of the random key added to the view state session token.\\n@@ -499,16 +499,16 @@\\n             = \"org.apache.myfaces.RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN_SECURE_RANDOM_ALGORITHM\";\\n     private static final String RANDOM_KEY_IN_VIEW_STATE_SESSION_TOKEN_SECURE_RANDOM_ALGORITHM_DEFAULT = \"SHA1PRNG\";\\n     \\n+    public static final String RANDOM_KEY_IN_CSRF_SESSION_TOKEN_SECURE_RANDOM = \"secureRandom\";\\n+    public static final String RANDOM_KEY_IN_CSRF_SESSION_TOKEN_RANDOM = \"random\";\\n+    \\n     /**\\n      * Defines how to generate the csrf session token.\\n      */\\n-    @JSFWebConfigParam(since=\"2.2.0\", expectedValues=\"secureRandom, random\", defaultValue=\"none\", group=\"state\")\\n+    @JSFWebConfigParam(since=\"2.2.0\", expectedValues=\"secureRandom, random\", defaultValue=\"secureRandom\", group=\"state\")\\n     public static final String RANDOM_KEY_IN_CSRF_SESSION_TOKEN\\n             = \"org.apache.myfaces.RANDOM_KEY_IN_CSRF_SESSION_TOKEN\";\\n-    private static final String RANDOM_KEY_IN_CSRF_SESSION_TOKEN_DEFAULT = \"random\";\\n-    \\n-    public static final String RANDOM_KEY_IN_CSRF_SESSION_TOKEN_SECURE_RANDOM = \"secureRandom\";\\n-    public static final String RANDOM_KEY_IN_CSRF_SESSION_TOKEN_RANDOM = \"random\";\\n+    private static final String RANDOM_KEY_IN_CSRF_SESSION_TOKEN_DEFAULT = RANDOM_KEY_IN_CSRF_SESSION_TOKEN_SECURE_RANDOM;\\n     \\n     /**\\n      * Indicates that the serialized state will be compressed before it is written to the session. By default true.'}}",
      "message_norm": "merge pull request #132 from wtlucy/securerandom_master\n\nmyfaces-4373: prefer securerandom for token generation",
      "language": "en",
      "entities": "[('#132', 'ISSUE', ''), ('securerandom_master', 'SECWORD', ''), ('securerandom', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['impl/src/main/java/org/apache/myfaces/config/MyfacesConfig.java'])",
      "num_files": 1.0
    },
    {
      "index": 1228,
      "vuln_id": "GHSA-8m49-2xj8-67v9",
      "cwe_id": "{'CWE-59'}",
      "score": 7.1,
      "chain": "{'https://github.com/waycrate/swhkd/commit/0b620a09605afb815c6d8d8953bbb7a10a8c0575'}",
      "dataset": "osv",
      "summary": "Data Loss/Denial of Service in SWHKD SWHKD 1.1.5 unsafely uses the /tmp/swhks.pid pathname. There can be data loss or a denial of service. A patch is available on the `1.1.0` branch of the repository.",
      "published_date": "2022-03-31",
      "chain_len": 1,
      "project": "https://github.com/waycrate/swhkd",
      "commit_href": "https://github.com/waycrate/swhkd/commit/0b620a09605afb815c6d8d8953bbb7a10a8c0575",
      "commit_sha": "0b620a09605afb815c6d8d8953bbb7a10a8c0575",
      "patch": "SINGLE",
      "chain_ord": "['0b620a09605afb815c6d8d8953bbb7a10a8c0575']",
      "before_first_fix_commit": "{'f70b99dd575fab79d8a942111a6980431f006818'}",
      "last_fix_commit": "0b620a09605afb815c6d8d8953bbb7a10a8c0575",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/25/2022, 15:20:01",
      "message": "[patch] CVE-2022-27816",
      "author": "Shinyzenith",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/server.rs': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/waycrate/swhkd/raw/0b620a09605afb815c6d8d8953bbb7a10a8c0575/src%2Fserver.rs', 'patch': '@@ -12,7 +12,7 @@ fn main() -> std::io::Result<()> {\\n     env::set_var(\"RUST_LOG\", \"swhks=trace\");\\n     env_logger::init();\\n \\n-    let pid_file_path = String::from(\"/tmp/swhks.pid\");\\n+    let pid_file_path = String::from(format!(\"/run/user/{}/swhks.pid\", unistd::Uid::current()));\\n     let sock_file_path = String::from(format!(\"/run/user/{}/swhkd.sock\", unistd::Uid::current()));\\n \\n     if Path::new(&pid_file_path).exists() {'}}",
      "message_norm": "[patch] cve-2022-27816",
      "language": "en",
      "entities": "[('cve-2022-27816', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/server.rs'])",
      "num_files": 1.0
    },
    {
      "index": 2073,
      "vuln_id": "GHSA-hhr9-7xvh-8xgc",
      "cwe_id": "{'CWE-918'}",
      "score": 7.7,
      "chain": "{'https://github.com/livehelperchat/livehelperchat/commit/abc9599ee7aded466ca216741dcaea533c908111'}",
      "dataset": "osv",
      "summary": "Server side request forgery in LiveHelperChat SSRF filter bypass port 80, 433 in LiveHelperChat prior to v3.67. An attacker could make the application perform arbitrary requests, bypass CVE-2022-1191",
      "published_date": "2022-04-06",
      "chain_len": 1,
      "project": "https://github.com/livehelperchat/livehelperchat",
      "commit_href": "https://github.com/livehelperchat/livehelperchat/commit/abc9599ee7aded466ca216741dcaea533c908111",
      "commit_sha": "abc9599ee7aded466ca216741dcaea533c908111",
      "patch": "SINGLE",
      "chain_ord": "['abc9599ee7aded466ca216741dcaea533c908111']",
      "before_first_fix_commit": "{'a583f4c60a98779938766e242991e637c0d938f0'}",
      "last_fix_commit": "abc9599ee7aded466ca216741dcaea533c908111",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/03/2022, 19:37:19",
      "message": "fix #1752",
      "author": "Remigijus Kiminas",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 2, 'total': 10}",
      "files": "{'lhc_web/modules/lhcobrowse/proxycss.php': {'additions': 8, 'deletions': 2, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/LiveHelperChat/livehelperchat/raw/abc9599ee7aded466ca216741dcaea533c908111/lhc_web%2Fmodules%2Flhcobrowse%2Fproxycss.php', 'patch': \"@@ -15,7 +15,13 @@\\n     $browse = erLhcoreClassCoBrowse::getBrowseInstance($chat);\\r\\n }\\r\\n \\r\\n-$url = parse_url($_GET['base']);\\r\\n+$base = trim($_GET['base']);\\r\\n+\\r\\n+if (!filter_var($base, FILTER_VALIDATE_URL)) {\\r\\n+    exit;\\r\\n+}\\r\\n+\\r\\n+$url = parse_url($base);\\r\\n \\r\\n // Only http/https supported\\r\\n if (!in_array($url['scheme'],['http','https']) || (isset($url['port']) && !in_array($url['port'],[80,443]))) {\\r\\n@@ -42,7 +48,7 @@\\n         }\\r\\n     } else {\\r\\n \\r\\n-        if (!in_array($urlCSS['scheme'],['http','https']) || (isset($urlCSS['port']) && !in_array($urlCSS['port'],[80,443]))) {\\r\\n+        if (!filter_var($_GET['css'], FILTER_VALIDATE_URL) || !in_array($urlCSS['scheme'],['http','https']) || (isset($urlCSS['port']) && !in_array($urlCSS['port'],[80,443]))) {\\r\\n             exit;\\r\\n         }\"}}",
      "message_norm": "fix #1752",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('#1752', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lhc_web/modules/lhcobrowse/proxycss.php'])",
      "num_files": 1.0
    },
    {
      "index": 1762,
      "vuln_id": "GHSA-fq6p-x6j3-cmmq",
      "cwe_id": "{'CWE-400'}",
      "score": 0.0,
      "chain": "{'https://github.com/mrdoob/three.js/pull/21143/commits/4a582355216b620176a291ff319d740e619d583e'}",
      "dataset": "osv",
      "summary": "Denial of service in three This affects the package three before 0.125.0. This can happen when handling rgb or hsl colors. PoC: var three = require('three') function build_blank (n) { var ret = \"rgb(\" for (var i = 0; i < n; i++) { ret += \" \" } return ret + \"\"; } var Color = three.Color var time = Date.now(); new Color(build_blank(50000)) var time_cost = Date.now() - time; console.log(time_cost+\" ms\")",
      "published_date": "2021-03-01",
      "chain_len": 1,
      "project": "https://github.com/mrdoob/three.js",
      "commit_href": "https://github.com/mrdoob/three.js/pull/21143/commits/4a582355216b620176a291ff319d740e619d583e",
      "commit_sha": "4a582355216b620176a291ff319d740e619d583e",
      "patch": "SINGLE",
      "chain_ord": "['4a582355216b620176a291ff319d740e619d583e']",
      "before_first_fix_commit": "{'0f5de4f5da1014f81c00d309f93b1a1e709341e4'}",
      "last_fix_commit": "4a582355216b620176a291ff319d740e619d583e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/25/2021, 11:45:42",
      "message": "Fix ReDoS",
      "author": "Yeting Li",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 4, 'total': 8}",
      "files": "{'src/math/Color.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/mrdoob/three.js/raw/4a582355216b620176a291ff319d740e619d583e/src%2Fmath%2FColor.js', 'patch': \"@@ -169,14 +169,14 @@ class Color {\\n \\n \\t\\t\\tlet color;\\n \\t\\t\\tconst name = m[ 1 ];\\n-\\t\\t\\tconst components = m[ 2 ].replace(/^\\\\s*/, '');\\n+\\t\\t\\tconst components = m[ 2 ];\\n \\n \\t\\t\\tswitch ( name ) {\\n \\n \\t\\t\\t\\tcase 'rgb':\\n \\t\\t\\t\\tcase 'rgba':\\n \\n-\\t\\t\\t\\t\\tif ( color = /^(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = /^\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t// rgb(255,0,0) rgba(255,0,0,0.5)\\n \\t\\t\\t\\t\\t\\tthis.r = Math.min( 255, parseInt( color[ 1 ], 10 ) ) / 255;\\n@@ -189,7 +189,7 @@ class Color {\\n \\n \\t\\t\\t\\t\\t}\\n \\n-\\t\\t\\t\\t\\tif ( color = /^(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = /^\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t// rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\\n \\t\\t\\t\\t\\t\\tthis.r = Math.min( 100, parseInt( color[ 1 ], 10 ) ) / 100;\\n@@ -207,7 +207,7 @@ class Color {\\n \\t\\t\\t\\tcase 'hsl':\\n \\t\\t\\t\\tcase 'hsla':\\n \\n-\\t\\t\\t\\t\\tif ( color = /^(\\\\d*\\\\.?\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = /^\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t// hsl(120,50%,50%) hsla(120,50%,50%,0.5)\\n \\t\\t\\t\\t\\t\\tconst h = parseFloat( color[ 1 ] ) / 360;\"}}",
      "message_norm": "fix redos",
      "language": "pt",
      "entities": "[('fix', 'ACTION', ''), ('redos', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/math/Color.js'])",
      "num_files": 1.0
    },
    {
      "index": 92,
      "vuln_id": "GHSA-2gw2-8q9w-cw8p",
      "cwe_id": "{'CWE-426'}",
      "score": 7.8,
      "chain": "{'https://github.com/ffi/ffi/commit/e0fe486df0e117ed67b0282b6ada04b7214ca05c', 'https://github.com/ffi/ffi/commit/09e0c6076466b4383da7fa4e13f714311109945a'}",
      "dataset": "osv",
      "summary": "Ruby-ffi has a DLL loading issue  ruby-ffi version 1.9.23 and earlier has a DLL loading issue which can be hijacked on Windows OS, when a Symbol is used as DLL name instead of a String This vulnerability appears to have been fixed in v1.9.24 and later.",
      "published_date": "2018-08-31",
      "chain_len": 2,
      "project": "https://github.com/ffi/ffi",
      "commit_href": "https://github.com/ffi/ffi/commit/e0fe486df0e117ed67b0282b6ada04b7214ca05c",
      "commit_sha": "e0fe486df0e117ed67b0282b6ada04b7214ca05c",
      "patch": "MULTI",
      "chain_ord": "['e0fe486df0e117ed67b0282b6ada04b7214ca05c', '09e0c6076466b4383da7fa4e13f714311109945a']",
      "before_first_fix_commit": "{'e0fe486df0e117ed67b0282b6ada04b7214ca05c'}",
      "last_fix_commit": "09e0c6076466b4383da7fa4e13f714311109945a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "06/01/2018, 20:18:25",
      "message": "Don't treat Symbol args different to Strings in ffi_lib\n\nSymbols were sent directly to FFI::DynamicLibrary.open in the first\nattempt, resulting in a TypeError, so that only the mangled library\nname was actually loaded.\n\nThis moves conversion to String to the front, so that subsequent\ncalls can assume Strings only.",
      "author": "Lars Kanis",
      "comments": "{'com_1': {'author': 'Cbeg-76', 'datetime': '08/23/2019, 15:31:30', 'body': 'gem install ffi'}}",
      "stats": "{'additions': 1, 'deletions': 3, 'total': 4}",
      "files": "{'lib/ffi/library.rb': {'additions': 1, 'deletions': 3, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/ffi/ffi/raw/e0fe486df0e117ed67b0282b6ada04b7214ca05c/lib%2Fffi%2Flibrary.rb', 'patch': '@@ -43,7 +43,6 @@ module FFI\\n   #  FFI.map_library_name \\'jpeg\\'  # -> \"jpeg.dll\"\\n   def self.map_library_name(lib)\\n     # Mangle the library name to reflect the native library naming conventions\\n-    lib = lib.to_s unless lib.kind_of?(String)\\n     lib = Library::LIBC if lib == \\'c\\'\\n \\n     if lib && File.basename(lib) == lib\\n@@ -103,7 +102,7 @@ def ffi_lib(*names)\\n           FFI::DynamicLibrary.open(nil, FFI::DynamicLibrary::RTLD_LAZY | FFI::DynamicLibrary::RTLD_LOCAL)\\n \\n         else\\n-          libnames = (name.is_a?(::Array) ? name : [ name ]).map { |n| [ n, FFI.map_library_name(n) ].uniq }.flatten.compact\\n+          libnames = (name.is_a?(::Array) ? name : [ name ]).map(&:to_s).map { |n| [ n, FFI.map_library_name(n) ].uniq }.flatten.compact\\n           lib = nil\\n           errors = {}\\n \\n@@ -126,7 +125,6 @@ def ffi_lib(*names)\\n                 retry\\n               else\\n                 # TODO better library lookup logic\\n-                libname = libname.to_s\\n                 unless libname.start_with?(\"/\")\\n                   path = [\\'/usr/lib/\\',\\'/usr/local/lib/\\'].find do |pth|\\n                     File.exist?(pth + libname)'}}",
      "message_norm": "don't treat symbol args different to strings in ffi_lib\n\nsymbols were sent directly to ffi::dynamiclibrary.open in the first\nattempt, resulting in a typeerror, so that only the mangled library\nname was actually loaded.\n\nthis moves conversion to string to the front, so that subsequent\ncalls can assume strings only.",
      "language": "en",
      "entities": "[('typeerror', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/ffi/library.rb'])",
      "num_files": 1.0
    },
    {
      "index": 1262,
      "vuln_id": "GHSA-8v99-48m9-c8pm",
      "cwe_id": "{'CWE-863'}",
      "score": 7.5,
      "chain": "{'https://github.com/containerd/imgcrypt/commit/6fdd9818a4d8142107b7ecd767d839c9707700d9'}",
      "dataset": "osv",
      "summary": "Incorrect Authorization in imgcrypt Imgcrypt implements a function `CheckAuthorization()` that is supposed to check whether a user is authorized to access an encrypted image given the keys that the user has provided on the command line that would enable decryption of the image. The check is to prevent that a user can start a container from an image that has previously been decrypted by another user on the same system and therefore a decrypted version of the image layers may be already available in the cache locally.\n\nThe failure occurs when an image with a ManifestList is used and the architecture of the local host is not the first one in the ManifestList. In the version prior to the fix, only the first architecture in the list was tested, which may not have its layers available locally (were not pulled) since it cannot be run on the host architecture. Therefore, the verdict on unavailable layers was that the image could be run anticipating that image run failure would occur later due to the layers not being available. However, this verdict to allow the image to run lead to other architectures in the ManifestList be able to run an image without providing keys if that image had previously been decrypted. The fixed version now skips over irrelevant architectures and tests the Manifest of the local architecture, if available.\n\nKnown projects that use the `CheckAuthorization()` of imgcrypt is for example the ctr-enc client tool provided by imgcrypt. In this implementation, the call to `CheckAuthorization()` is used on the client side and could therefore also be easily circumvented by a modified client tool not calling this function.\n\nIn relation to the vulnerability in ctr-enc, affected environments would have to allow different users to invoke ctr-enc indirectly using some sort of management stack that gives user indirect access to ctr-enc.\n\nThe patch has been applied to imgcrypt v1.1.4. Workarounds may include usage of different namespaces for each remote user.",
      "published_date": "2022-03-28",
      "chain_len": 1,
      "project": "https://github.com/containerd/imgcrypt",
      "commit_href": "https://github.com/containerd/imgcrypt/commit/6fdd9818a4d8142107b7ecd767d839c9707700d9",
      "commit_sha": "6fdd9818a4d8142107b7ecd767d839c9707700d9",
      "patch": "SINGLE",
      "chain_ord": "['6fdd9818a4d8142107b7ecd767d839c9707700d9']",
      "before_first_fix_commit": "{'f4400580b658c1fcb3cacc52dfb6104ea3c3aa82'}",
      "last_fix_commit": "6fdd9818a4d8142107b7ecd767d839c9707700d9",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/17/2022, 19:52:56",
      "message": "images: Add list of Platforms to CheckAuthorization()\n\nTo be able to properly perform an authorization check on an image we need\nto know the platform to perform check when in cryptManifestList(). Extend\nthe logic for cryptoOp == cryptoOpUnwrapOnly to skip over manifests that\ndo not correspond to the local platform and return an error if no manifest\nwas found that matches the local platform.\n\nThe following projects seem NOT to be affect due to the change in the code\npath of CheckAuthorization() since they are not using it:\n\n- cri-o\n- nerdctl\n- skopeo\n- buildah\n- podman\n\nThe impact on imgcrypt via ctr-enc is not so clear either since\nCheckAuthorization() is not called on the server side but by the ctr-enc\nclient, thus can be modified easily.\n\nResolves: https://github.com/containerd/imgcrypt/issues/69\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
      "author": "Stefan Berger",
      "comments": null,
      "stats": "{'additions': 13, 'deletions': 0, 'total': 13}",
      "files": "{'images/encryption/encryption.go': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/containerd/imgcrypt/raw/6fdd9818a4d8142107b7ecd767d839c9707700d9/images%2Fencryption%2Fencryption.go', 'patch': '@@ -50,6 +50,13 @@ const (\\n // LayerFilter allows to select Layers by certain criteria\\n type LayerFilter func(desc ocispec.Descriptor) bool\\n \\n+// isLocalPlatform determines whether the given platform matches the local one\\n+func isLocalPlatform(platform *ocispec.Platform) bool {\\n+\\tmatcher := platforms.NewMatcher(*platform)\\n+\\n+\\treturn matcher.Match(platforms.DefaultSpec())\\n+}\\n+\\n // IsEncryptedDiff returns true if mediaType is a known encrypted media type.\\n func IsEncryptedDiff(ctx context.Context, mediaType string) bool {\\n \\tswitch mediaType {\\n@@ -380,6 +387,9 @@ func cryptManifestList(ctx context.Context, cs content.Store, desc ocispec.Descr\\n \\tvar newManifests []ocispec.Descriptor\\n \\tmodified := false\\n \\tfor _, manifest := range index.Manifests {\\n+\\t\\tif cryptoOp == cryptoOpUnwrapOnly && !isLocalPlatform(manifest.Platform) {\\n+\\t\\t\\tcontinue\\n+\\t\\t}\\n \\t\\tnewManifest, m, err := cryptChildren(ctx, cs, manifest, cc, lf, cryptoOp, manifest.Platform)\\n \\t\\tif err != nil || cryptoOp == cryptoOpUnwrapOnly {\\n \\t\\t\\treturn ocispec.Descriptor{}, false, err\\n@@ -389,6 +399,9 @@ func cryptManifestList(ctx context.Context, cs content.Store, desc ocispec.Descr\\n \\t\\t}\\n \\t\\tnewManifests = append(newManifests, newManifest)\\n \\t}\\n+\\tif cryptoOp == cryptoOpUnwrapOnly {\\n+\\t\\treturn ocispec.Descriptor{}, false, fmt.Errorf(\"No manifest found for local platform\")\\n+\\t}\\n \\n \\tif modified {\\n \\t\\t// we need to update the index'}}",
      "message_norm": "images: add list of platforms to checkauthorization()\n\nto be able to properly perform an authorization check on an image we need\nto know the platform to perform check when in cryptmanifestlist(). extend\nthe logic for cryptoop == cryptoopunwraponly to skip over manifests that\ndo not correspond to the local platform and return an error if no manifest\nwas found that matches the local platform.\n\nthe following projects seem not to be affect due to the change in the code\npath of checkauthorization() since they are not using it:\n\n- cri-o\n- nerdctl\n- skopeo\n- buildah\n- podman\n\nthe impact on imgcrypt via ctr-enc is not so clear either since\ncheckauthorization() is not called on the server side but by the ctr-enc\nclient, thus can be modified easily.\n\nresolves: https://github.com/containerd/imgcrypt/issues/69\nsigned-off-by: stefan berger <stefanb@linux.ibm.com>",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('cryptoop', 'SECWORD', ''), ('cryptoopunwraponly', 'SECWORD', ''), ('error', 'FLAW', ''), ('found', 'ACTION', ''), ('server', 'SECWORD', ''), ('https://github.com/containerd/imgcrypt/issues/69', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['images/encryption/encryption.go'])",
      "num_files": 1.0
    },
    {
      "index": 469,
      "vuln_id": "GHSA-4r8q-gv9j-3xx6",
      "cwe_id": "{'CWE-601'}",
      "score": 4.3,
      "chain": "{'https://github.com/tenancy/multi-tenant/commit/9c837a21bccce9bcaeb90033ef200d84f0d9e164'}",
      "dataset": "osv",
      "summary": "Open Redirect ### Impact\nIn some situations, it is possible to have open redirects where users can be redirected from your site to any other site using a specially crafted URL.\nThis is only the case for installations where the default Hostname Identification is used and the environment uses tenants that have `force_https` set to `true` (default: `false`)\n\n### Patches\nVersion 5.7.2 contains the relevant patches to fix this bug. Stripping the URL from special characters to prevent specially crafted URL's from being redirected to.\n\n### Workarounds\nThere is a simple way to work around the security issue\n- Set the `force_https` to every tenant to `false`\n\n### References\nhttps://nvd.nist.gov/vuln/detail/CVE-2018-11784\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Contact us in Discord: https://tenancy.dev/chat",
      "published_date": "2022-03-18",
      "chain_len": 1,
      "project": "https://github.com/tenancy/multi-tenant",
      "commit_href": "https://github.com/tenancy/multi-tenant/commit/9c837a21bccce9bcaeb90033ef200d84f0d9e164",
      "commit_sha": "9c837a21bccce9bcaeb90033ef200d84f0d9e164",
      "patch": "SINGLE",
      "chain_ord": "['9c837a21bccce9bcaeb90033ef200d84f0d9e164']",
      "before_first_fix_commit": "{'41150dce84288f24ff68c8df433a45f966a60865'}",
      "last_fix_commit": "9c837a21bccce9bcaeb90033ef200d84f0d9e164",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/27/2021, 04:40:08",
      "message": "Trim slashes from request uri before redirecting (#1001)",
      "author": "Jasper Zonneveld",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/Middleware/HostnameActions.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tenancy/multi-tenant/raw/9c837a21bccce9bcaeb90033ef200d84f0d9e164/src%2FMiddleware%2FHostnameActions.php', 'patch': \"@@ -95,7 +95,7 @@ protected function secure(Hostname $hostname, Request $request)\\n     {\\n         $this->emitEvent(new Secured($hostname));\\n \\n-        return $this->redirect->secure($request->getRequestUri());\\n+        return $this->redirect->secure(ltrim($request->getRequestUri(), '/'));\\n     }\\n \\n     /**\"}}",
      "message_norm": "trim slashes from request uri before redirecting (#1001)",
      "language": "en",
      "entities": "[('#1001', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Middleware/HostnameActions.php'])",
      "num_files": 1.0
    },
    {
      "index": 2746,
      "vuln_id": "GHSA-qfpc-5pjr-mh26",
      "cwe_id": "{'CWE-20'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/da857cfa0fde8f79ad0afdbc94e88b5d4bbec764'}",
      "dataset": "osv",
      "summary": "Missing validation in shape inference for `Dequantize` ### Impact\nThe shape inference code for `tf.raw_ops.Dequantize` has a vulnerability that could trigger a denial of service via a segfault if an attacker provides invalid arguments:\n\n```python\nimport tensorflow as tf\n\ntf.compat.v1.disable_v2_behavior()\ntf.raw_ops.Dequantize(\n  input_tensor = tf.constant(-10.0, dtype=tf.float32),\n  input_tensor = tf.cast(input_tensor, dtype=tf.quint8),\n  min_range = tf.constant([], shape=[0], dtype=tf.float32),\n  max_range = tf.constant([], shape=[0], dtype=tf.float32),\n  mode  = 'MIN_COMBINED',\n  narrow_range=False,\n  axis=-10,\n  dtype=tf.dtypes.float32)\n```\n\nThe shape inference [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/ops/array_ops.cc#L2999-L3014) uses `axis` to select between two different values for `minmax_rank` which is then used to retrieve tensor dimensions. However, code assumes that `axis` can be either `-1` or a value greater than `-1`, with no validation for the other values.\n\n### Patches\nWe have patched the issue in GitHub commit [da857cfa0fde8f79ad0afdbc94e88b5d4bbec764](https://github.com/tensorflow/tensorflow/commit/da857cfa0fde8f79ad0afdbc94e88b5d4bbec764).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/da857cfa0fde8f79ad0afdbc94e88b5d4bbec764",
      "commit_sha": "da857cfa0fde8f79ad0afdbc94e88b5d4bbec764",
      "patch": "SINGLE",
      "chain_ord": "['da857cfa0fde8f79ad0afdbc94e88b5d4bbec764']",
      "before_first_fix_commit": "{'8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4'}",
      "last_fix_commit": "da857cfa0fde8f79ad0afdbc94e88b5d4bbec764",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/30/2021, 01:24:18",
      "message": "Fix a shape inference issue leading to nullptr deref.\n\nPiperOrigin-RevId: 387712259\nChange-Id: I7e670772b259c068a501a187cd89f18773bb95a1",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'tensorflow/core/ops/array_ops.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/da857cfa0fde8f79ad0afdbc94e88b5d4bbec764/tensorflow%2Fcore%2Fops%2Farray_ops.cc', 'patch': '@@ -2990,6 +2990,10 @@ REGISTER_OP(\"Dequantize\")\\n       if (!s.ok() && s.code() != error::NOT_FOUND) {\\n         return s;\\n       }\\n+      if (axis < -1) {\\n+        return errors::InvalidArgument(\"axis should be at least -1, got \",\\n+                                       axis);\\n+      }\\n       const int minmax_rank = (axis == -1) ? 0 : 1;\\n       TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\\n       ShapeHandle minmax;'}}",
      "message_norm": "fix a shape inference issue leading to nullptr deref.\n\npiperorigin-revid: 387712259\nchange-id: i7e670772b259c068a501a187cd89f18773bb95a1",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('issue', 'FLAW', ''), ('nullptr', 'SECWORD', ''), ('387712259', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/ops/array_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1670,
      "vuln_id": "GHSA-f5cx-5wr3-5qrc",
      "cwe_id": "{'CWE-824'}",
      "score": 7.1,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', 'https://github.com/tensorflow/tensorflow/commit/429f009d2b2c09028647dd4bb7b3f6f414bbaad7'}",
      "dataset": "osv",
      "summary": "Reference binding to nullptr in boosted trees ### Impact\nAn attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesCalculateBestGainsPerFeature(\n  node_id_range=[],\n  stats_summary_list=[[1,2,3]],\n  l1=[1.0],\n  l2=[1.0],\n  tree_complexity =[1.0],\n  min_node_weight =[1.17],\n  max_splits=5)\n```\n\nA similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`:\n\n```python\nimport tensorflow as tf\n                                                                                                                                                                                                                                                                                          \ntf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2(\n  node_id_range=[],\n  stats_summaries_list=[[1,2,3]],\n  split_types=[''],\n  candidate_feature_ids=[1,2,3,4],\n  l1=[1],     \n  l2=[1],\n  tree_complexity=[1.0],\n  min_node_weight=[1.17],\n  logits_dimension=5)\n```     \n    \nThe  [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) does not validate the input values.\n\n### Patches\nWe have patched the issue in GitHub commit [9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad](https://github.com/tensorflow/tensorflow/commit/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad) and in commit. [429f009d2b2c09028647dd4bb7b3f6f414bbaad7](https://github.com/tensorflow/tensorflow/commit/429f009d2b2c09028647dd4bb7b3f6f414bbaad7).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
      "commit_sha": "429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
      "patch": "MULTI",
      "chain_ord": "['9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', '429f009d2b2c09028647dd4bb7b3f6f414bbaad7']",
      "before_first_fix_commit": "{'4f8db85aa9ab71a71e95d5acce7de52a0b195661'}",
      "last_fix_commit": "429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
      "chain_ord_pos": 2.0,
      "commit_datetime": "07/28/2021, 20:25:18",
      "message": "Add remaining missing validation to `BoostedTreesCalculateBestFeatureSplit`\n\nPiperOrigin-RevId: 387423006\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 19, 'deletions': 1, 'total': 20}",
      "files": "{'tensorflow/core/kernels/boosted_trees/stats_ops.cc': {'additions': 19, 'deletions': 1, 'changes': 20, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/429f009d2b2c09028647dd4bb7b3f6f414bbaad7/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -14,6 +14,7 @@ limitations under the License.\\n ==============================================================================*/\\n \\n #include <limits>\\n+#include <string>\\n #include <vector>\\n \\n #include \"third_party/eigen3/Eigen/Core\"\\n@@ -22,6 +23,7 @@ limitations under the License.\\n #include \"tensorflow/core/framework/tensor_shape.h\"\\n #include \"tensorflow/core/kernels/boosted_trees/boosted_trees.pb.h\"\\n #include \"tensorflow/core/kernels/boosted_trees/tree_helper.h\"\\n+#include \"tensorflow/core/platform/errors.h\"\\n #include \"tensorflow/core/platform/logging.h\"\\n \\n namespace tensorflow {\\n@@ -254,12 +256,18 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n     // node_id_range\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->NumElements() == 2,\\n+        errors::InvalidArgument(\"node_id_range argument must have shape [2]\"));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n     const int32_t node_id_first = node_id_range(0);  // inclusive\\n     const int32_t node_id_last = node_id_range(1);   // exclusive\\n \\n     const Tensor* stats_summary_t;\\n     OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\\n+    OP_REQUIRES(\\n+        context, stats_summary_t->shape().dims() == 4,\\n+        errors::InvalidArgument(\"stats_summary argument must have rank 4\"));\\n     TTypes<float, 4>::ConstTensor stats_summary =\\n         stats_summary_t->tensor<float, 4>();\\n     const int32_t feature_dims = stats_summary_t->dim_size(1);\\n@@ -272,6 +280,8 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n \\n     const Tensor* l1_t;\\n     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\\n+    OP_REQUIRES(context, l1_t->NumElements() == 1,\\n+                errors::InvalidArgument(\"l1 argument must be a scalar\"));\\n     const auto l1 = l1_t->scalar<float>()();\\n     DCHECK_GE(l1, 0);\\n     if (logits_dim_ > 1) {\\n@@ -281,17 +291,25 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n \\n     const Tensor* l2_t;\\n     OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\\n+    OP_REQUIRES(context, l2_t->NumElements() == 1,\\n+                errors::InvalidArgument(\"l2 argument must be a scalar\"));\\n     const auto l2 = l2_t->scalar<float>()();\\n     DCHECK_GE(l2, 0);\\n \\n     const Tensor* tree_complexity_t;\\n     OP_REQUIRES_OK(context,\\n                    context->input(\"tree_complexity\", &tree_complexity_t));\\n+    OP_REQUIRES(\\n+        context, tree_complexity_t->NumElements() == 1,\\n+        errors::InvalidArgument(\"tree_complexity argument must be a scalar\"));\\n     const auto tree_complexity = tree_complexity_t->scalar<float>()();\\n \\n     const Tensor* min_node_weight_t;\\n     OP_REQUIRES_OK(context,\\n                    context->input(\"min_node_weight\", &min_node_weight_t));\\n+    OP_REQUIRES(\\n+        context, min_node_weight_t->NumElements() == 1,\\n+        errors::InvalidArgument(\"min_node_weight argument must be a scalar\"));\\n     const auto min_node_weight = min_node_weight_t->scalar<float>()();\\n \\n     std::vector<int32> output_node_ids;\\n@@ -300,7 +318,7 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n     std::vector<int32> output_thresholds;\\n     std::vector<Eigen::VectorXf> output_left_node_contribs;\\n     std::vector<Eigen::VectorXf> output_right_node_contribs;\\n-    std::vector<string> output_split_types;\\n+    std::vector<std::string> output_split_types;\\n \\n     // TODO(tanzheny) parallelize the computation.\\n     // Iterate each node and find the best gain per node.'}}",
      "message_norm": "add remaining missing validation to `boostedtreescalculatebestfeaturesplit`\n\npiperorigin-revid: 387423006\nchange-id: i8eaf30efb223011519e60707bfa751b275d3a443",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('387423006', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/boosted_trees/stats_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1229,
      "vuln_id": "GHSA-8m5h-hrqm-pxm2",
      "cwe_id": "{'CWE-22'}",
      "score": 7.5,
      "chain": "{'https://github.com/ESAPI/esapi-java-legacy/commit/a0d67b75593878b1b6e39e2acc1773b3effedb2a'}",
      "dataset": "osv",
      "summary": "Path traversal in the OWASP Enterprise Security API ### Impact\nThe default implementation of `Validator.getValidDirectoryPath(String, String, File, boolean)` may incorrectly treat the tested input string as a child of the specified parent directory. This potentially could allow control-flow bypass checks to be defeated if an attack can specify the entire string representing the 'input' path.\n\n### Patches\nThis vulnerability is patched in release 2.3.0.0 of ESAPI. See https://github.com/ESAPI/esapi-java-legacy/releases/tag/esapi-2.3.0.0 for details.\n\n### Workarounds\nYes; in theory, one _could_ write the own implementation of the Validator interface. This would most easily be done by sub-classing a version of the affected `DefaultValidator` class and then overriding the affected `getValidDirectoryPath()` to correct the issue. However, this is not recommended.\n\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email one of the project co-leaders. See email addresses listed on  the [OWASP ESAPI wiki](https://owasp.org/www-project-enterprise-security-api/) page, under \"Leaders\".\n* Send email to one of the two ESAPI related Google Groups listed under [Where to Find More Information on ESAPI](https://github.com/ESAPI/esapi-java-legacy#where-to-find-more-information-on-esapi) on our [README.md](https://github.com/ESAPI/esapi-java-legacy#readme) page.",
      "published_date": "2022-04-27",
      "chain_len": 1,
      "project": "https://github.com/ESAPI/esapi-java-legacy",
      "commit_href": "https://github.com/ESAPI/esapi-java-legacy/commit/a0d67b75593878b1b6e39e2acc1773b3effedb2a",
      "commit_sha": "a0d67b75593878b1b6e39e2acc1773b3effedb2a",
      "patch": "SINGLE",
      "chain_ord": "['a0d67b75593878b1b6e39e2acc1773b3effedb2a']",
      "before_first_fix_commit": "{'657c2a751c0b8dbd70b8da1bba246d86f7ad3b20'}",
      "last_fix_commit": "a0d67b75593878b1b6e39e2acc1773b3effedb2a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/17/2022, 04:32:15",
      "message": "Fix for GHSL-2022-008 vulnerability.",
      "author": "kwwall",
      "comments": "{'com_1': {'author': 'JLLeitschuh', 'datetime': '04/29/2022, 00:50:01', 'body': 'For back tracking this is related to CVE-2022-23457\\r\\n\\r\\nhttps://github.com/ESAPI/esapi-java-legacy/security/advisories/GHSA-8m5h-hrqm-pxm2'}}",
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/main/java/org/owasp/esapi/reference/DefaultValidator.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/ESAPI/esapi-java-legacy/raw/a0d67b75593878b1b6e39e2acc1773b3effedb2a/src%2Fmain%2Fjava%2Forg%2Fowasp%2Fesapi%2Freference%2FDefaultValidator.java', 'patch': '@@ -466,7 +466,7 @@ public String getValidDirectoryPath(String context, String input, File parent, b\\n \\t\\t\\tif ( !parent.isDirectory() ) {\\n \\t\\t\\t\\tthrow new ValidationException( context + \": Invalid directory name\", \"Invalid directory, specified parent is not a directory: context=\" + context + \", input=\" + input + \", parent=\" + parent );\\n \\t\\t\\t}\\n-\\t\\t\\tif ( !dir.getCanonicalPath().startsWith(parent.getCanonicalPath() ) ) {\\n+\\t\\t\\tif ( !dir.getCanonicalFile().toPath().startsWith( parent.getCanonicalFile().toPath() ) ) { // Fixes GHSL-2022-008\\n \\t\\t\\t\\tthrow new ValidationException( context + \": Invalid directory name\", \"Invalid directory, not inside specified parent: context=\" + context + \", input=\" + input + \", parent=\" + parent );\\n \\t\\t\\t}'}}",
      "message_norm": "fix for ghsl-2022-008 vulnerability.",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/main/java/org/owasp/esapi/reference/DefaultValidator.java'])",
      "num_files": 1.0
    },
    {
      "index": 3157,
      "vuln_id": "GHSA-vpwq-6cp4-ffqc",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/star7th/showdoc/commit/ba45d19e1d77a7eea866dab30eff5da552694891'}",
      "dataset": "osv",
      "summary": "Stored Cross-site Scripting in ShowDoc ShowDoc prior to version 2.10.4 is vulnerable to stored cross-site scripting viva `axd` and `cshtml` file upload.",
      "published_date": "2022-03-16",
      "chain_len": 1,
      "project": "https://github.com/star7th/showdoc",
      "commit_href": "https://github.com/star7th/showdoc/commit/ba45d19e1d77a7eea866dab30eff5da552694891",
      "commit_sha": "ba45d19e1d77a7eea866dab30eff5da552694891",
      "patch": "SINGLE",
      "chain_ord": "['ba45d19e1d77a7eea866dab30eff5da552694891']",
      "before_first_fix_commit": "{'4e6b321c0d63ee7c4480409c7a68ae116096c4bc'}",
      "last_fix_commit": "ba45d19e1d77a7eea866dab30eff5da552694891",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2022, 02:52:48",
      "message": "bug",
      "author": "star7th",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'server/Application/Api/Model/AttachmentModel.class.php': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/star7th/showdoc/raw/ba45d19e1d77a7eea866dab30eff5da552694891/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': '@@ -309,6 +309,8 @@ public function isDangerFilename($filename){\\n \\t\\t\\t|| $isDangerStr($filename , \".aspx\")\\n \\t\\t\\t|| $isDangerStr($filename , \".xsd\")\\n \\t\\t\\t|| $isDangerStr($filename , \".asa\")\\n+\\t\\t\\t|| $isDangerStr($filename , \".cshtml\")\\n+\\t\\t\\t|| $isDangerStr($filename , \".axd\")\\n \\t\\t) {\\n \\t\\t\\treturn true;\\n \\t\\t}'}}",
      "message_norm": "bug",
      "language": "id",
      "entities": "[('bug', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/Application/Api/Model/AttachmentModel.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 2316,
      "vuln_id": "GHSA-jx5q-g37m-h5hj",
      "cwe_id": "{'CWE-74', 'CWE-1321'}",
      "score": 5.3,
      "chain": "{'https://github.com/oroinc/platform/commit/62c26936b3adee9c20255dcd9f8ee5c299b464a9'}",
      "dataset": "osv",
      "summary": "Client-Side JavaScript Prototype Pollution in oro/platform ### Summary\n\nBy sending a specially crafted request, an attacker could inject properties into existing JavaScript language construct prototypes, such as objects. Later this injection may lead to JS code execution by libraries that are vulnerable to Prototype Pollution.\n\n### Workarounds\n\nConfigure WAF to drop requests containing next strings: `__proto__` , `constructor[prototype]`, `constructor.prototype`",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/oroinc/platform",
      "commit_href": "https://github.com/oroinc/platform/commit/62c26936b3adee9c20255dcd9f8ee5c299b464a9",
      "commit_sha": "62c26936b3adee9c20255dcd9f8ee5c299b464a9",
      "patch": "SINGLE",
      "chain_ord": "['62c26936b3adee9c20255dcd9f8ee5c299b464a9']",
      "before_first_fix_commit": "{'d9929d4085f4e38d05c4e4b02c7d4c15de84f88c'}",
      "last_fix_commit": "62c26936b3adee9c20255dcd9f8ee5c299b464a9",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/24/2021, 15:40:19",
      "message": "BAP-21092: JavaScript Prototype Pollution (#31464)",
      "author": "Hryhorii Hrebiniuk",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'src/Oro/Bundle/UIBundle/Resources/public/js/tools.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/oroinc/platform/raw/62c26936b3adee9c20255dcd9f8ee5c299b464a9/src%2FOro%2FBundle%2FUIBundle%2FResources%2Fpublic%2Fjs%2Ftools.js', 'patch': \"@@ -85,6 +85,10 @@ define(function(require) {\\n                 query = query.slice(1);\\n             }\\n             const setValue = function(root, path, value) {\\n+                if (path[0] === '__proto__') {\\n+                    // Prevent Object.prototype pollution\\n+                    return;\\n+                }\\n                 if (path.length > 1) {\\n                     const dir = path.shift();\\n                     if (typeof root[dir] === 'undefined') {\"}}",
      "message_norm": "bap-21092: javascript prototype pollution (#31464)",
      "language": "fr",
      "entities": "[('prototype pollution', 'SECWORD', ''), ('#31464', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Oro/Bundle/UIBundle/Resources/public/js/tools.js'])",
      "num_files": 1.0
    },
    {
      "index": 1567,
      "vuln_id": "GHSA-cm5x-837x-jf3c",
      "cwe_id": "{'CWE-369'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/e86605c0a336c088b638da02135ea6f9f6753618'}",
      "dataset": "osv",
      "summary": "Division by 0 in inplace operations ### Impact\nAn attacker can cause a floating point exception by calling inplace operations with crafted arguments that would result in a division by 0:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.InplaceSub(x=[],i=[-99,-1,-1],v=[1,1,1])\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/inplace_ops.cc#L283) has a logic error: it should skip processing if `x` and `v` are empty but the code uses `||` instead of `&&`.\n\n### Patches\nWe have patched the issue in GitHub commit [e86605c0a336c088b638da02135ea6f9f6753618](https://github.com/tensorflow/tensorflow/commit/e86605c0a336c088b638da02135ea6f9f6753618).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/e86605c0a336c088b638da02135ea6f9f6753618",
      "commit_sha": "e86605c0a336c088b638da02135ea6f9f6753618",
      "patch": "SINGLE",
      "chain_ord": "['e86605c0a336c088b638da02135ea6f9f6753618']",
      "before_first_fix_commit": "{'29e3d6b706a33780b1cb4863200ec7525ff035ce'}",
      "last_fix_commit": "e86605c0a336c088b638da02135ea6f9f6753618",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/02/2021, 21:21:27",
      "message": "Fix FPE in inpace update ops.\n\nPiperOrigin-RevId: 388303197\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'tensorflow/core/kernels/inplace_ops.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/e86605c0a336c088b638da02135ea6f9f6753618/tensorflow%2Fcore%2Fkernels%2Finplace_ops.cc', 'patch': '@@ -225,7 +225,7 @@ class InplaceOpBase : public OpKernel {\\n \\n     Tensor y = x;  // This creates an alias intentionally.\\n     // Skip processing if tensors are empty.\\n-    if (x.NumElements() > 0 || v.NumElements() > 0) {\\n+    if (x.NumElements() > 0 && v.NumElements() > 0) {\\n       OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\\n     }\\n     ctx->set_output(0, y);'}}",
      "message_norm": "fix fpe in inpace update ops.\n\npiperorigin-revid: 388303197\nchange-id: ib48309b6213ffe53eba81004b00e889d653e4b83",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('388303197', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/inplace_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 401,
      "vuln_id": "GHSA-4c4g-crqm-xrxw",
      "cwe_id": "{'CWE-908'}",
      "score": 4.4,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', 'https://github.com/tensorflow/tensorflow/commit/8933b8a21280696ab119b63263babdb54c298538', 'https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887'}",
      "dataset": "osv",
      "summary": "Use of unitialized value in TFLite ### Impact\nAll TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200):\n\n```cc\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n```\n\nThe issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code.\n\n### Patches\nWe have patched the issue in GitHub commits [537bc7c723439b9194a358f64d871dd326c18887](https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887),\n[4a91f2069f7145aab6ba2d8cfe41be8a110c18a5](https://github.com/tensorflow/tensorflow/commit/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5) and [8933b8a21280696ab119b63263babdb54c298538](https://github.com/tensorflow/tensorflow/commit/8933b8a21280696ab119b63263babdb54c298538).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 3,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/8933b8a21280696ab119b63263babdb54c298538",
      "commit_sha": "8933b8a21280696ab119b63263babdb54c298538",
      "patch": "MULTI",
      "chain_ord": "['537bc7c723439b9194a358f64d871dd326c18887', '4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', '8933b8a21280696ab119b63263babdb54c298538']",
      "before_first_fix_commit": "{'e35be978351a8578549d30b6f483825d36dc0f8b'}",
      "last_fix_commit": "8933b8a21280696ab119b63263babdb54c298538",
      "chain_ord_pos": 3.0,
      "commit_datetime": "07/16/2021, 17:22:37",
      "message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'tensorflow/lite/kernels/depthwise_conv.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/8933b8a21280696ab119b63263babdb54c298538/tensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc', 'patch': '@@ -176,6 +176,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   if (data_type != kTfLiteFloat32) {\\n     TF_LITE_ENSURE_EQ(context, filter->quantization.type,\\n                       kTfLiteAffineQuantization);\\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n     const auto* affine_quantization =\\n         reinterpret_cast<TfLiteAffineQuantization*>(\\n             filter->quantization.params);\\n@@ -195,6 +196,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   }\\n \\n   if (is_hybrid) {\\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n     const auto* affine_quantization =\\n         reinterpret_cast<TfLiteAffineQuantization*>(\\n             filter->quantization.params);\\n@@ -495,6 +497,7 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\\n   op_params.weights_offset = 0;\\n   op_params.float_activation_min = output_activation_min;\\n   op_params.float_activation_max = output_activation_max;\\n+  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n   const auto* affine_quantization =\\n       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\\n   if (kernel_type == kReference) {'}}",
      "message_norm": "fix a null pointer exception caused by branching on uninitialized data.\n\nthis is due to not checking that the params for the quantization exists. if there is no quantization, we should not access the `.params` field.\n\npiperorigin-revid: 385173491\nchange-id: i8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('null pointer exception', 'SECWORD', ''), ('uninitialized', 'SECWORD', ''), ('385173491', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/depthwise_conv.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2318,
      "vuln_id": "GHSA-jxhc-q857-3j6g",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/sporkmonger/addressable/commit/0d8a3127e35886ce9284810a7f2438bff6b43cbc', 'https://github.com/sporkmonger/addressable/commit/89c76130ce255c601f642a018cb5fb5a80e679a7'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service in Addressable templates ### Impact\n\nWithin the URI template implementation in Addressable, a maliciously crafted template may result in uncontrolled resource consumption, leading to denial of service when matched against a URI. In typical usage, templates would not normally be read from untrusted user input, but nonetheless, no previous security advisory for Addressable has cautioned against doing this. Users of the parsing capabilities in Addressable but not the URI template capabilities are unaffected.\n\n### Patches\n\nThe vulnerability was introduced in version 2.3.0 (previously yanked) and has been present in all subsequent versions up to, and including, 2.7.0. It is fixed in version 2.8.0.\n\n### Workarounds\n\nThe vulnerability can be avoided by only creating Template objects from trusted sources that have been validated not to produce catastrophic backtracking.\n\n### References\n\n- https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS\n- https://cwe.mitre.org/data/definitions/1333.html\n- https://www.regular-expressions.info/catastrophic.html\n\n### For more information\nIf you have any questions or comments about this advisory:\n* [Open an issue](https://github.com/sporkmonger/addressable/issues)",
      "published_date": "2021-07-12",
      "chain_len": 2,
      "project": "https://github.com/sporkmonger/addressable",
      "commit_href": "https://github.com/sporkmonger/addressable/commit/0d8a3127e35886ce9284810a7f2438bff6b43cbc",
      "commit_sha": "0d8a3127e35886ce9284810a7f2438bff6b43cbc",
      "patch": "MULTI",
      "chain_ord": "['89c76130ce255c601f642a018cb5fb5a80e679a7', '0d8a3127e35886ce9284810a7f2438bff6b43cbc']",
      "before_first_fix_commit": "{'89c76130ce255c601f642a018cb5fb5a80e679a7'}",
      "last_fix_commit": "0d8a3127e35886ce9284810a7f2438bff6b43cbc",
      "chain_ord_pos": 2.0,
      "commit_datetime": "07/03/2021, 04:10:39",
      "message": "Adding note about ReDoS vulnerability",
      "author": "Bob Aman",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'CHANGELOG.md': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/sporkmonger/addressable/raw/0d8a3127e35886ce9284810a7f2438bff6b43cbc/CHANGELOG.md', 'patch': '@@ -1,4 +1,5 @@\\n # Addressable 2.8.0\\n+- fixes ReDoS vulnerability in Addressable::Template#match\\n - no longer replaces `+` with spaces in queries for non-http(s) schemes\\n - fixed encoding ipv6 literals\\n - the `:compacted` flag for `normalized_query` now dedupes parameters'}}",
      "message_norm": "adding note about redos vulnerability",
      "language": "en",
      "entities": "[('adding', 'ACTION', ''), ('redos', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['CHANGELOG.md'])",
      "num_files": 1.0
    },
    {
      "index": 1216,
      "vuln_id": "GHSA-8h4j-vm3r-vcq3",
      "cwe_id": "{'CWE-416'}",
      "score": 9.8,
      "chain": "{'https://github.com/rusqlite/rusqlite/commit/2ef3628dac35aeba0a97d5fb3a57746b4e1d62b3'}",
      "dataset": "osv",
      "summary": "Use after free in rusqlite An issue was discovered in the rusqlite crate before 0.23.0 for Rust. Memory safety can be violated via an Auxdata API use-after-free.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/rusqlite/rusqlite",
      "commit_href": "https://github.com/rusqlite/rusqlite/commit/2ef3628dac35aeba0a97d5fb3a57746b4e1d62b3",
      "commit_sha": "2ef3628dac35aeba0a97d5fb3a57746b4e1d62b3",
      "patch": "SINGLE",
      "chain_ord": "['2ef3628dac35aeba0a97d5fb3a57746b4e1d62b3']",
      "before_first_fix_commit": "{'71b2f5187b0cbace3f8b6ff53432ff2ca0defcf0'}",
      "last_fix_commit": "2ef3628dac35aeba0a97d5fb3a57746b4e1d62b3",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/13/2020, 02:41:01",
      "message": "Actually fix auxdata api...",
      "author": "Thom Chiovoloni",
      "comments": null,
      "stats": "{'additions': 54, 'deletions': 65, 'total': 119}",
      "files": "{'src/functions.rs': {'additions': 54, 'deletions': 65, 'changes': 119, 'status': 'modified', 'raw_url': 'https://github.com/rusqlite/rusqlite/raw/2ef3628dac35aeba0a97d5fb3a57746b4e1d62b3/src%2Ffunctions.rs', 'patch': '@@ -12,6 +12,8 @@\\n //! use regex::Regex;\\n //! use rusqlite::functions::FunctionFlags;\\n //! use rusqlite::{Connection, Error, Result, NO_PARAMS};\\n+//! use std::sync::Arc;\\n+//! type BoxError = Box<dyn std::error::Error + Send + Sync + \\'static>;\\n //!\\n //! fn add_regexp_function(db: &Connection) -> Result<()> {\\n //!     db.create_scalar_function(\\n@@ -20,34 +22,19 @@\\n //!         FunctionFlags::SQLITE_UTF8 | FunctionFlags::SQLITE_DETERMINISTIC,\\n //!         move |ctx| {\\n //!             assert_eq!(ctx.len(), 2, \"called with unexpected number of arguments\");\\n-//!\\n-//!             let saved_re: Option<&Regex> = ctx.get_aux(0)?;\\n-//!             let new_re = match saved_re {\\n-//!                 None => {\\n-//!                     let s = ctx.get::<String>(0)?;\\n-//!                     match Regex::new(&s) {\\n-//!                         Ok(r) => Some(r),\\n-//!                         Err(err) => return Err(Error::UserFunctionError(Box::new(err))),\\n-//!                     }\\n-//!                 }\\n-//!                 Some(_) => None,\\n-//!             };\\n-//!\\n+//!             let regexp: Arc<Regex> = ctx\\n+//!                 .get_or_create_aux(0, |vr| -> Result<_, BoxError> {\\n+//!                     Ok(Regex::new(vr.as_str()?)?)\\n+//!                 })?;\\n //!             let is_match = {\\n-//!                 let re = saved_re.unwrap_or_else(|| new_re.as_ref().unwrap());\\n-//!\\n //!                 let text = ctx\\n //!                     .get_raw(1)\\n //!                     .as_str()\\n //!                     .map_err(|e| Error::UserFunctionError(e.into()))?;\\n //!\\n-//!                 re.is_match(text)\\n+//!                 regexp.is_match(text)\\n //!             };\\n //!\\n-//!             if let Some(re) = new_re {\\n-//!                 ctx.set_aux(0, re);\\n-//!             }\\n-//!\\n //!             Ok(is_match)\\n //!         },\\n //!     )\\n@@ -67,11 +54,12 @@\\n //!     Ok(())\\n //! }\\n //! ```\\n-use std::any::TypeId;\\n+use std::any::Any;\\n use std::os::raw::{c_int, c_void};\\n use std::panic::{catch_unwind, RefUnwindSafe, UnwindSafe};\\n use std::ptr;\\n use std::slice;\\n+use std::sync::Arc;\\n \\n use crate::ffi;\\n use crate::ffi::sqlite3_context;\\n@@ -121,6 +109,7 @@ unsafe extern \"C\" fn free_boxed_value<T>(p: *mut c_void) {\\n pub struct Context<\\'a> {\\n     ctx: *mut sqlite3_context,\\n     args: &\\'a [*mut sqlite3_value],\\n+    // conn: PhantomData<&\\'conn mut Connection>,\\n }\\n \\n impl Context<\\'_> {\\n@@ -174,47 +163,60 @@ impl Context<\\'_> {\\n         unsafe { ValueRef::from_value(arg) }\\n     }\\n \\n+    pub fn get_or_create_aux<T, E, F>(&self, arg: c_int, func: F) -> Result<Arc<T>>\\n+    where\\n+        T: Send + Sync + \\'static,\\n+        E: Into<Box<dyn std::error::Error + Send + Sync + \\'static>>,\\n+        F: FnOnce(ValueRef<\\'_>) -> Result<T, E>,\\n+    {\\n+        if let Some(v) = self.get_aux(arg)? {\\n+            Ok(v)\\n+        } else {\\n+            let vr = self.get_raw(arg as usize);\\n+            self.set_aux(\\n+                arg,\\n+                func(vr).map_err(|e| Error::UserFunctionError(e.into()))?,\\n+            )\\n+        }\\n+    }\\n+\\n     /// Sets the auxilliary data associated with a particular parameter. See\\n     /// https://www.sqlite.org/c3ref/get_auxdata.html for a discussion of\\n     /// this feature, or the unit tests of this module for an example.\\n-    pub fn set_aux<T: \\'static>(&self, arg: c_int, value: T) {\\n-        let boxed = Box::into_raw(Box::new(AuxData {\\n-            id: TypeId::of::<T>(),\\n-            value,\\n-        }));\\n+    pub fn set_aux<T: Send + Sync + \\'static>(&self, arg: c_int, value: T) -> Result<Arc<T>> {\\n+        let orig: Arc<T> = Arc::new(value);\\n+        let inner: AuxInner = orig.clone();\\n+        let outer = Box::new(inner);\\n+        let raw: *mut AuxInner = Box::into_raw(outer);\\n         unsafe {\\n             ffi::sqlite3_set_auxdata(\\n                 self.ctx,\\n                 arg,\\n-                boxed as *mut c_void,\\n-                Some(free_boxed_value::<AuxData<T>>),\\n+                raw as *mut _,\\n+                Some(free_boxed_value::<AuxInner>),\\n             )\\n         };\\n+        Ok(orig)\\n     }\\n \\n-    /// Gets the auxilliary data that was associated with a given parameter\\n-    /// via `set_aux`. Returns `Ok(None)` if no data has been associated,\\n-    /// and .\\n-    pub fn get_aux<T: \\'static>(&self, arg: c_int) -> Result<Option<&T>> {\\n-        let p = unsafe { ffi::sqlite3_get_auxdata(self.ctx, arg) as *const AuxData<T> };\\n+    /// Gets the auxilliary data that was associated with a given parameter via\\n+    /// `set_aux`. Returns `Ok(None)` if no data has been associated, and\\n+    /// Ok(Some(v)) if it has. Returns an error if the requested type does not\\n+    /// match.\\n+    pub fn get_aux<T: Send + Sync + \\'static>(&self, arg: c_int) -> Result<Option<Arc<T>>> {\\n+        let p = unsafe { ffi::sqlite3_get_auxdata(self.ctx, arg) as *const AuxInner };\\n         if p.is_null() {\\n             Ok(None)\\n         } else {\\n-            let id = unsafe { (*p).id };\\n-            if TypeId::of::<T>() != id {\\n-                Err(Error::GetAuxWrongType)\\n-            } else {\\n-                Ok(Some(unsafe { &(*p).value }))\\n-            }\\n+            let v: AuxInner = AuxInner::clone(unsafe { &*p });\\n+            v.downcast::<T>()\\n+                .map(Some)\\n+                .map_err(|_| Error::GetAuxWrongType)\\n         }\\n     }\\n }\\n \\n-#[repr(C)]\\n-struct AuxData<T: \\'static> {\\n-    id: TypeId,\\n-    value: T,\\n-}\\n+type AuxInner = Arc<dyn Any + Send + Sync + \\'static>;\\n \\n /// `feature = \"functions\"` Aggregate is the callback interface for user-defined\\n /// aggregate function.\\n@@ -776,34 +778,21 @@ mod test {\\n     // expression multiple times within one query.\\n     fn regexp_with_auxilliary(ctx: &Context<\\'_>) -> Result<bool> {\\n         assert_eq!(ctx.len(), 2, \"called with unexpected number of arguments\");\\n-\\n-        let saved_re: Option<&Regex> = ctx.get_aux(0)?;\\n-        let new_re = match saved_re {\\n-            None => {\\n-                let s = ctx.get::<String>(0)?;\\n-                match Regex::new(&s) {\\n-                    Ok(r) => Some(r),\\n-                    Err(err) => return Err(Error::UserFunctionError(Box::new(err))),\\n-                }\\n-            }\\n-            Some(_) => None,\\n-        };\\n+        type BoxError = Box<dyn std::error::Error + Send + Sync + \\'static>;\\n+        let regexp: std::sync::Arc<Regex> = ctx\\n+            .get_or_create_aux(0, |vr| -> Result<_, BoxError> {\\n+                Ok(Regex::new(vr.as_str()?)?)\\n+            })?;\\n \\n         let is_match = {\\n-            let re = saved_re.unwrap_or_else(|| new_re.as_ref().unwrap());\\n-\\n             let text = ctx\\n                 .get_raw(1)\\n                 .as_str()\\n                 .map_err(|e| Error::UserFunctionError(e.into()))?;\\n \\n-            re.is_match(text)\\n+            regexp.is_match(text)\\n         };\\n \\n-        if let Some(re) = new_re {\\n-            ctx.set_aux(0, re);\\n-        }\\n-\\n         Ok(is_match)\\n     }\\n \\n@@ -878,10 +867,10 @@ mod test {\\n         let db = Connection::open_in_memory().unwrap();\\n         db.create_scalar_function(\"example\", 2, FunctionFlags::default(), |ctx| {\\n             if !ctx.get::<bool>(1)? {\\n-                ctx.set_aux::<i64>(0, 100);\\n+                ctx.set_aux::<i64>(0, 100)?;\\n             } else {\\n                 assert_eq!(ctx.get_aux::<String>(0), Err(Error::GetAuxWrongType));\\n-                assert_eq!(ctx.get_aux::<i64>(0), Ok(Some(&100)));\\n+                assert_eq!(*ctx.get_aux::<i64>(0).unwrap().unwrap(), 100);\\n             }\\n             Ok(true)\\n         })'}}",
      "message_norm": "actually fix auxdata api...",
      "language": "ca",
      "entities": "[('fix', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/functions.rs'])",
      "num_files": 1.0
    },
    {
      "index": 3283,
      "vuln_id": "GHSA-whv6-rj84-2vh2",
      "cwe_id": "{'CWE-79'}",
      "score": 0.0,
      "chain": "{'https://github.com/juliushaertl/nextcloud-vue-collections/commit/8ec1fca214f003538cec4137792ede928f25f583'}",
      "dataset": "osv",
      "summary": "Cross-Site Scripting in nextcloud-vue-collections Versions of `nextcloud-vue-collections` prior to 0.4.2 are vulnerable to Cross-Site Scripting (XSS).  The `v-tooltip` component has an insecure `defaultHTML` configuration that allows arbitrary JavaScript to be injected in the tooltip of a collection item. This allows attackers to execute arbitrary code in a victim's browser.\n\n\n## Recommendation\n\nUpgrade to version 0.4.2 or later.",
      "published_date": "2020-09-04",
      "chain_len": 1,
      "project": "https://github.com/juliushaertl/nextcloud-vue-collections",
      "commit_href": "https://github.com/juliushaertl/nextcloud-vue-collections/commit/8ec1fca214f003538cec4137792ede928f25f583",
      "commit_sha": "8ec1fca214f003538cec4137792ede928f25f583",
      "patch": "SINGLE",
      "chain_ord": "['8ec1fca214f003538cec4137792ede928f25f583']",
      "before_first_fix_commit": "{'1d55cc3b462bc344de6cfbe45d590d0c2f99fc1a'}",
      "last_fix_commit": "8ec1fca214f003538cec4137792ede928f25f583",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/29/2019, 13:41:42",
      "message": "Force defaultHtml setting of v-tooltip to be disabled\n\nSigned-off-by: Julius H\u00e4rtl <jus@bitgrid.net>",
      "author": "Julius H\u00e4rtl",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'src/components/CollectionListItem.vue': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/nextcloud/nextcloud-vue-collections/raw/8ec1fca214f003538cec4137792ede928f25f583/src%2Fcomponents%2FCollectionListItem.vue', 'patch': \"@@ -60,6 +60,9 @@ import Action from 'nextcloud-vue/dist/Components/Action'\\n import Avatar from 'nextcloud-vue/dist/Components/Avatar'\\n import Tooltip from 'nextcloud-vue/dist/Directives/Tooltip'\\n \\n+Tooltip.options.defaultHtml = false\\n+\\n+\\n export default {\\n \\tname: 'CollectionListItem',\\n \\tcomponents: {\"}}",
      "message_norm": "force defaulthtml setting of v-tooltip to be disabled\n\nsigned-off-by: julius h\u00e4rtl <jus@bitgrid.net>",
      "language": "en",
      "entities": "[('jus@bitgrid.net', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/components/CollectionListItem.vue'])",
      "num_files": 1.0
    },
    {
      "index": 1322,
      "vuln_id": "GHSA-95xm-g58g-3p88",
      "cwe_id": "{'CWE-369'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41'}",
      "dataset": "osv",
      "summary": "Integer division by 0 in sparse reshaping ### Impact\nThe implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.SparseReshape(\n  input_indices = np.ones((1,3)),\n  input_shape = np.array([1,1,0]),\n  new_shape = np.array([1,0]))\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements.\n\nThe [reshape functor](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0.\n  \n### Patches\nWe have patched the issue in GitHub commit [4923de56ec94fff7770df259ab7f2288a74feb41](https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41",
      "commit_sha": "4923de56ec94fff7770df259ab7f2288a74feb41",
      "patch": "SINGLE",
      "chain_ord": "['4923de56ec94fff7770df259ab7f2288a74feb41']",
      "before_first_fix_commit": "{'062534a0e7af9a49e96bc5797851be0e57cad1d6'}",
      "last_fix_commit": "4923de56ec94fff7770df259ab7f2288a74feb41",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/02/2021, 20:52:28",
      "message": "Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232a",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'tensorflow/core/kernels/reshape_util.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/4923de56ec94fff7770df259ab7f2288a74feb41/tensorflow%2Fcore%2Fkernels%2Freshape_util.cc', 'patch': '@@ -174,6 +174,12 @@ void ReshapeSparseTensor(OpKernelContext *context,\\n                                           TensorShape({nnz, output_rank}),\\n                                           &result_indices));\\n   if (nnz > 0) {\\n+    OP_REQUIRES(\\n+        context, dense_size > 0 && product > 0,\\n+        errors::InvalidArgument(\\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\\n+            input_shape.DebugString(), \") or output shape (\",\\n+            output_shape.DebugString(), \") is empty\"));\\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\\n                                 context, input_shape, output_shape,\\n                                 input_indices_in.matrix<int64>(),'}}",
      "message_norm": "don't do any work when reshaping 0 elements sparse tensor.\n\nif reshaping to 0 elements tensor, check that input has no elements.\nif reshaping no elements input, check that output has no elements.\n\npiperorigin-revid: 388296986\nchange-id: iadc9fe7252e14313ca987e69bf0d7042fd10232a",
      "language": "en",
      "entities": "[('388296986', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/reshape_util.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3360,
      "vuln_id": "GHSA-x44x-r84w-8v67",
      "cwe_id": "{'CWE-287'}",
      "score": 6.5,
      "chain": "{'https://github.com/LemonLDAPNG/node-lemonldap-ng-handler/commit/136aa83ed431462fa42ce17b7f9b24e056de06be'}",
      "dataset": "osv",
      "summary": "Lack of URL normalization may lead to authorization bypass when URL access rules are used ### Impact\nWhen access rules are used inside a protected host, some URL encodings may bypass filtering system.\n\n### Patches\nVersion 0.5.2 includes a patch that fixes the vulnerability\n\n### Workarounds\nNo way for users to fix or remediate the vulnerability without upgrading\n\n### References\nhttps://gitlab.ow2.org/lemonldap-ng/lemonldap-ng/-/issues/2290\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [this repository](https://github.com/LemonLDAPNG/node-lemonldap-ng-handler/issues) or [LemonLDAP::NG GitLab](https://gitlab.ow2.org/lemonldap-ng/lemonldap-ng/-/issues)\n* Email us at [lemonldap-ng-users@ow2.org](mailto:lemonldap-ng-users@ow2.org)",
      "published_date": "2020-09-09",
      "chain_len": 1,
      "project": "https://github.com/LemonLDAPNG/node-lemonldap-ng-handler",
      "commit_href": "https://github.com/LemonLDAPNG/node-lemonldap-ng-handler/commit/136aa83ed431462fa42ce17b7f9b24e056de06be",
      "commit_sha": "136aa83ed431462fa42ce17b7f9b24e056de06be",
      "patch": "SINGLE",
      "chain_ord": "['136aa83ed431462fa42ce17b7f9b24e056de06be']",
      "before_first_fix_commit": "{'d6fac9350024d9eef1c180f4e3a6a0ce65f199a8'}",
      "last_fix_commit": "136aa83ed431462fa42ce17b7f9b24e056de06be",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/09/2020, 08:04:46",
      "message": "Normalize URL (related to https://gitlab.ow2.org/lemonldap-ng/lemonldap-ng/-/issues/2290 and CVE-2020-24660)",
      "author": "Xavier Guimard",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 3, 'total': 7}",
      "files": "{'src/lib/index.coffee': {'additions': 4, 'deletions': 3, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/LemonLDAPNG/node-lemonldap-ng-handler/raw/136aa83ed431462fa42ce17b7f9b24e056de06be/src%2Flib%2Findex.coffee', 'patch': '@@ -4,6 +4,7 @@\\n # See README.md for license and copyright\\n ###\\n conf = null\\n+normalizeUrl = require \\'normalize-url\\'\\n \\n class Handler\\n \\tconstructor: (args) ->\\n@@ -15,7 +16,7 @@ class Handler\\n \\trun: (req, res, next) ->\\n \\t\\tself = @\\n \\t\\tvhost = req.headers.host\\n-\\t\\turi = decodeURI req.url\\n+\\t\\turi = normalizeUrl req.url\\n \\t\\tif @conf.tsv.maintenance[vhost]\\n \\t\\t\\tself.logger.info \"Go to portal with maintenance error code #{vhost}\"\\n \\t\\t\\treturn @setError res, \\'/\\', 503, \\'Service Temporarily Unavailable\\'\\n@@ -184,7 +185,7 @@ class Handler\\n \\t\\t\\treturn res\\n \\t\\turlc = @conf.tsv.portal()\\n \\t\\tif uri\\n-\\t\\t\\turlc += \\'?url=\\' + new Buffer(encodeURI(uri)).toString(\\'base64\\')\\n+\\t\\t\\turlc += \\'?url=\\' + new Buffer.from(encodeURI(uri)).toString(\\'base64\\')\\n \\t\\tif args\\n \\t\\t\\turlc += if uri then \\'&\\' else \\'?\\'\\n \\t\\t\\turlc += args\\n@@ -203,7 +204,7 @@ class Handler\\n \\n \\tsetError: (res, uri, code, txt) ->\\n \\t\\tif @conf.tsv.useRedirectOnError\\n-\\t\\t\\tu = @conf.tsv.portal() + \"?lmError=#{code}&url=\" + new Buffer(encodeURI(uri)).toString(\\'base64\\')\\n+\\t\\t\\tu = @conf.tsv.portal() + \"?lmError=#{code}&url=\" + new Buffer.from(encodeURI(uri)).toString(\\'base64\\')\\n \\t\\t\\t@logger.debug \"Redirecting to #{u}\"\\n \\t\\t\\tif res.redirect?\\n \\t\\t\\t\\tres.redirect u'}}",
      "message_norm": "normalize url (related to https://gitlab.ow2.org/lemonldap-ng/lemonldap-ng/-/issues/2290 and cve-2020-24660)",
      "language": "en",
      "entities": "[('https://gitlab.ow2.org/lemonldap-ng/lemonldap-ng/-/issues/2290', 'URL', ''), ('cve-2020-24660', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/lib/index.coffee'])",
      "num_files": 1.0
    },
    {
      "index": 3414,
      "vuln_id": "GHSA-xcvv-84j5-jw9h",
      "cwe_id": "{'CWE-471'}",
      "score": 0.0,
      "chain": "{'https://github.com/jonschlinkert/assign-deep/commit/19953a8c089b0328c470acaaaf6accdfcb34da11'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in assign-deep Versions of `assign-deep` before 0.4.7 are vulnerable to prototype pollution via merging functions.\n\n\n## Recommendation\n\nUpdate to version 0.4.7 or later.",
      "published_date": "2018-07-26",
      "chain_len": 1,
      "project": "https://github.com/jonschlinkert/assign-deep",
      "commit_href": "https://github.com/jonschlinkert/assign-deep/commit/19953a8c089b0328c470acaaaf6accdfcb34da11",
      "commit_sha": "19953a8c089b0328c470acaaaf6accdfcb34da11",
      "patch": "SINGLE",
      "chain_ord": "['19953a8c089b0328c470acaaaf6accdfcb34da11']",
      "before_first_fix_commit": "{'f6cba02d11a1d293593be0e942aff60bfd5a5711'}",
      "last_fix_commit": "19953a8c089b0328c470acaaaf6accdfcb34da11",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/07/2018, 16:20:22",
      "message": "exclude __proto__",
      "author": "doowb",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/jonschlinkert/assign-deep/raw/19953a8c089b0328c470acaaaf6accdfcb34da11/index.js', 'patch': \"@@ -37,7 +37,7 @@ function extend(target, obj) {\\n   assignSymbols(target, obj);\\n \\n   for (var key in obj) {\\n-    if (hasOwn(obj, key)) {\\n+    if (key !== '__proto__' && hasOwn(obj, key)) {\\n       var val = obj[key];\\n       if (isObject(val)) {\\n         if (typeOf(target[key]) === 'undefined' && typeOf(val) === 'function') {\"}}",
      "message_norm": "exclude __proto__",
      "language": "pt",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 3265,
      "vuln_id": "GHSA-wcv5-vrvr-3rx2",
      "cwe_id": "{'CWE-190'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/be7b286d40bc68cb0b56f702186cc4837d508058'}",
      "dataset": "osv",
      "summary": "Integer Overflow or Wraparound in TensorFlow ### Impact\nThe Grappler component of TensorFlow is vulnerable to a denial of service via `CHECK`-failure (assertion failure) in [constant folding](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/grappler/optimizers/constant_folding.cc#L963-L1035):\n\n```cc\n  for (const auto& output_prop : output_props) {\n    const PartialTensorShape output_shape(output_prop.shape());\n    // ...\n  }\n```\n  \nThe `output_prop` tensor has a shape that is controlled by user input and this can result in triggering one of the `CHECK`s in the `PartialTensorShape` constructor. This is an instance of [TFSA-2021-198](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa-2021-198.md) (CVE-2021-41197).\n\n### Patches\nWe have patched the issue in GitHub commit [be7b286d40bc68cb0b56f702186cc4837d508058](https://github.com/tensorflow/tensorflow/commit/be7b286d40bc68cb0b56f702186cc4837d508058).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/be7b286d40bc68cb0b56f702186cc4837d508058",
      "commit_sha": "be7b286d40bc68cb0b56f702186cc4837d508058",
      "patch": "SINGLE",
      "chain_ord": "['be7b286d40bc68cb0b56f702186cc4837d508058']",
      "before_first_fix_commit": "{'6381a7b127bd276a3817a93e5423b15a06c33419'}",
      "last_fix_commit": "be7b286d40bc68cb0b56f702186cc4837d508058",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/15/2021, 21:55:14",
      "message": "Fix `CHECK`-failure caused by constant folding code.\n\nWe're losing a `const` qualifier here, but unless we get to use more `StatusOr` objects, this is the best alternative.\n\nPiperOrigin-RevId: 410072241\nChange-Id: I69535c91490f0d23facb9587d2ff59db0782cda6",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 1, 'total': 7}",
      "files": "{'tensorflow/core/grappler/optimizers/constant_folding.cc': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/be7b286d40bc68cb0b56f702186cc4837d508058/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fconstant_folding.cc', 'patch': '@@ -1017,7 +1017,12 @@ bool ConstantFolding::IsFoldableUncached(\\n       }\\n     }\\n     for (const auto& output_prop : output_props) {\\n-      const PartialTensorShape output_shape(output_prop.shape());\\n+      PartialTensorShape output_shape;\\n+      if (!PartialTensorShape::BuildPartialTensorShape(output_prop.shape(),\\n+                                                       &output_shape)\\n+               .ok()) {\\n+        return false;\\n+      }\\n       if (output_shape.IsFullyDefined()) {\\n         const int64_t num_bytes =\\n             output_shape.num_elements() * DataTypeSize(output_prop.dtype());'}}",
      "message_norm": "fix `check`-failure caused by constant folding code.\n\nwe're losing a `const` qualifier here, but unless we get to use more `statusor` objects, this is the best alternative.\n\npiperorigin-revid: 410072241\nchange-id: i69535c91490f0d23facb9587d2ff59db0782cda6",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('410072241', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/grappler/optimizers/constant_folding.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2670,
      "vuln_id": "GHSA-pxpf-v376-7xx5",
      "cwe_id": "{'CWE-79'}",
      "score": 6.1,
      "chain": "{'https://github.com/yairEO/tagify/commit/198c0451fad188390390395ccfc84ab371def4c7'}",
      "dataset": "osv",
      "summary": "tagify can pass a malicious placeholder to initiate the cross-site scripting (XSS) payload This affects the package @yaireo/tagify before 4.9.8. The package is used for rendering UI components inside the input or text fields, and an attacker can pass a malicious placeholder value to it to fire the cross-site scripting (XSS) payload.",
      "published_date": "2022-04-30",
      "chain_len": 1,
      "project": "https://github.com/yairEO/tagify",
      "commit_href": "https://github.com/yairEO/tagify/commit/198c0451fad188390390395ccfc84ab371def4c7",
      "commit_sha": "198c0451fad188390390395ccfc84ab371def4c7",
      "patch": "SINGLE",
      "chain_ord": "['198c0451fad188390390395ccfc84ab371def4c7']",
      "before_first_fix_commit": "{'93f729c6d1bf45666a1dc21d5cae3aefe1b18043'}",
      "last_fix_commit": "198c0451fad188390390395ccfc84ab371def4c7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/17/2022, 08:16:09",
      "message": "fixes #989 - fix XSS",
      "author": "Yair Even Or",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/tagify.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/yairEO/tagify/raw/198c0451fad188390390395ccfc84ab371def4c7/src%2Ftagify.js', 'patch': '@@ -101,7 +101,7 @@ Tagify.prototype = {\\n \\n         _s.disabled = input.hasAttribute(\\'disabled\\')\\n         _s.readonly = _s.readonly || input.hasAttribute(\\'readonly\\')\\n-        _s.placeholder = input.getAttribute(\\'placeholder\\') || _s.placeholder || \"\"\\n+        _s.placeholder = escapeHTML(input.getAttribute(\\'placeholder\\') || _s.placeholder || \"\")\\n         _s.required = input.hasAttribute(\\'required\\')\\n \\n         for( let name in _s.classNames )'}}",
      "message_norm": "fixes #989 - fix xss",
      "language": "ca",
      "entities": "[('fixes', 'ACTION', ''), ('#989', 'ISSUE', ''), ('xss', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/tagify.js'])",
      "num_files": 1.0
    },
    {
      "index": 1472,
      "vuln_id": "GHSA-c442-3278-rhrg",
      "cwe_id": "{'CWE-434'}",
      "score": 9.8,
      "chain": "{'https://github.com/star7th/showdoc/commit/49b992d4c548c8c615a92b6efe8a50c8f1083abf'}",
      "dataset": "osv",
      "summary": "Unrestricted File Upload in ShowDoc v2.9.5 Unrestricted File Upload in ShowDoc v2.9.5 allows remote attackers to execute arbitrary code via the 'file_url' parameter in the component AdminUpdateController.class.php'.",
      "published_date": "2021-09-09",
      "chain_len": 1,
      "project": "https://github.com/star7th/showdoc",
      "commit_href": "https://github.com/star7th/showdoc/commit/49b992d4c548c8c615a92b6efe8a50c8f1083abf",
      "commit_sha": "49b992d4c548c8c615a92b6efe8a50c8f1083abf",
      "patch": "SINGLE",
      "chain_ord": "['49b992d4c548c8c615a92b6efe8a50c8f1083abf']",
      "before_first_fix_commit": "{'8db2d13196df7067fdf2e37cf1e5e2d7aba3d748'}",
      "last_fix_commit": "49b992d4c548c8c615a92b6efe8a50c8f1083abf",
      "chain_ord_pos": 1.0,
      "commit_datetime": "06/24/2021, 15:25:43",
      "message": "Fix security vulnerabilities",
      "author": "star7th",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'server/Application/Api/Controller/AdminUpdateController.class.php': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/star7th/showdoc/raw/49b992d4c548c8c615a92b6efe8a50c8f1083abf/server%2FApplication%2FApi%2FController%2FAdminUpdateController.class.php', 'patch': '@@ -24,6 +24,8 @@ public function checkUpdate(){\\n \\n     // \u4e0b\u8f7d\u66f4\u65b0\u4ee3\u7801\u5305\\n     public function download(){\\n+        $this->checkLogin();\\n+        $this->checkAdmin();\\n         set_time_limit(1000);\\n         ini_set(\\'memory_limit\\',\\'500M\\');\\n         $new_version = I(\"new_version\") ;\\n@@ -78,6 +80,8 @@ public function download(){\\n \\n     // \u6267\u884c\u5347\u7ea7\u64cd\u4f5c\uff0c\u5347\u7ea7\u8986\u76d6\u6587\u4ef6\\n     public function updateFiles(){\\n+        $this->checkLogin();\\n+        $this->checkAdmin();\\n         set_time_limit(1000);\\n         ini_set(\\'memory_limit\\',\\'500M\\');'}}",
      "message_norm": "fix security vulnerabilities",
      "language": "ro",
      "entities": "[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/Application/Api/Controller/AdminUpdateController.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 1452,
      "vuln_id": "GHSA-c265-37vj-cwcc",
      "cwe_id": "{'CWE-502'}",
      "score": 8.1,
      "chain": "{'https://github.com/FasterXML/jackson-databind/commit/99001cdb6807b5c7b170ec6a9092ecbb618ae79c'}",
      "dataset": "osv",
      "summary": "Deserialization of untrusted data in Jackson Databind FasterXML jackson-databind 2.x before 2.9.10.5 mishandles the interaction between serialization gadgets and typing, related to com.sun.org.apache.xalan.internal.lib.sql.JNDIConnectionPool (aka xalan2).",
      "published_date": "2020-06-18",
      "chain_len": 1,
      "project": "https://github.com/FasterXML/jackson-databind",
      "commit_href": "https://github.com/FasterXML/jackson-databind/commit/99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
      "commit_sha": "99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
      "patch": "SINGLE",
      "chain_ord": "['99001cdb6807b5c7b170ec6a9092ecbb618ae79c']",
      "before_first_fix_commit": "{'716f3f95fb82c686cc20d7255665de54c5330fa7'}",
      "last_fix_commit": "99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/02/2020, 02:17:39",
      "message": "Fix #2704",
      "author": "Tatu Saloranta",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'release-notes/VERSION-2.x': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/FasterXML/jackson-databind/raw/99001cdb6807b5c7b170ec6a9092ecbb618ae79c/release-notes%2FVERSION-2.x', 'patch': '@@ -10,6 +10,8 @@ Project: jackson-databind\\n  (reported by Topsec(tcc))\\n #2698: Block one more gadget type (weblogic/oracle-aqjms)\\n  (reported by Fangrun Li)\\n+#2704: Block one more gadget type (weblogic/oracle-aqjms)\\n+ (reported by XuYuanzhen)\\n \\n 2.9.10.4 (11-Apr-2020)'}}",
      "message_norm": "fix #2704",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('#2704', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['release-notes/VERSION-2.x'])",
      "num_files": 1.0
    },
    {
      "index": 2398,
      "vuln_id": "GHSA-m9m5-cg5h-r582",
      "cwe_id": "{'CWE-338'}",
      "score": 5.1,
      "chain": "{'https://github.com/Absolucy/nanorand-rs/commit/5ba218ac29df4786b002d7d12b47fa0c04a331f2'}",
      "dataset": "osv",
      "summary": "Improper random number generation in nanorand An issue was discovered in the nanorand crate before 0.5.1 for Rust. It caused any random number generator (even ChaCha) to return all zeroes because integer truncation was mishandled.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/Absolucy/nanorand-rs",
      "commit_href": "https://github.com/Absolucy/nanorand-rs/commit/5ba218ac29df4786b002d7d12b47fa0c04a331f2",
      "commit_sha": "5ba218ac29df4786b002d7d12b47fa0c04a331f2",
      "patch": "SINGLE",
      "chain_ord": "['5ba218ac29df4786b002d7d12b47fa0c04a331f2']",
      "before_first_fix_commit": "{'7bf49ecbb254991585c04dd4f4d2a23cb16a1240'}",
      "last_fix_commit": "5ba218ac29df4786b002d7d12b47fa0c04a331f2",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/07/2020, 12:33:01",
      "message": "fix: Fix random number generation",
      "author": "aspen",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 7, 'total': 14}",
      "files": "{'nanorand/src/gen.rs': {'additions': 7, 'deletions': 7, 'changes': 14, 'status': 'modified', 'raw_url': 'https://github.com/Absolucy/nanorand-rs/raw/5ba218ac29df4786b002d7d12b47fa0c04a331f2/nanorand%2Fsrc%2Fgen.rs', 'patch': '@@ -101,44 +101,44 @@ impl<R: RNG> RandomRange<R> for usize {\\n \\n impl<R: RNG> RandomGen<R> for u32 {\\n \\tfn random(r: &mut R) -> Self {\\n-\\t\\t(r.generate::<u64>() >> 32) as u32\\n+\\t\\tr.generate::<u64>() as u32\\n \\t}\\n }\\n \\n impl<R: RNG> RandomRange<R> for u32 {\\n \\tfn random_range(r: &mut R, lower: u32, upper: u32) -> Self {\\n-\\t\\t(r.generate_range::<u64>(lower as u64, upper as u64) >> 32) as u32\\n+\\t\\tr.generate_range::<u64>(lower as u64, upper as u64) as u32\\n \\t}\\n }\\n \\n impl<R: RNG> RandomGen<R> for u16 {\\n \\tfn random(r: &mut R) -> Self {\\n-\\t\\t(r.generate::<u64>() >> 16) as u16\\n+\\t\\tr.generate::<u64>() as u16\\n \\t}\\n }\\n \\n impl<R: RNG> RandomRange<R> for u16 {\\n \\tfn random_range(r: &mut R, lower: u16, upper: u16) -> Self {\\n-\\t\\t(r.generate_range::<u64>(lower as u64, upper as u64) >> 16) as u16\\n+\\t\\tr.generate_range::<u64>(lower as u64, upper as u64) as u16\\n \\t}\\n }\\n \\n impl<R: RNG> RandomGen<R> for u8 {\\n \\tfn random(r: &mut R) -> Self {\\n-\\t\\t(r.generate::<u64>() >> 8) as u8\\n+\\t\\tr.generate::<u64>() as u8\\n \\t}\\n }\\n \\n impl<R: RNG> RandomRange<R> for u8 {\\n \\tfn random_range(r: &mut R, lower: u8, upper: u8) -> Self {\\n-\\t\\t(r.generate_range::<u64>(lower as u64, upper as u64) >> 8) as u8\\n+\\t\\tr.generate_range::<u64>(lower as u64, upper as u64) as u8\\n \\t}\\n }\\n \\n impl<R: RNG> RandomRange<R> for char {\\n \\tfn random_range(r: &mut R, lower: char, upper: char) -> Self {\\n \\t\\tloop {\\n-\\t\\t\\tlet ret = (r.generate_range::<u64>(lower as u64, upper as u64) >> 32) as u32;\\n+\\t\\t\\tlet ret = r.generate_range::<u64>(lower as u64, upper as u64) as u32;\\n \\t\\t\\tif let Some(c) = core::char::from_u32(ret) {\\n \\t\\t\\t\\tbreak c;\\n \\t\\t\\t}'}}",
      "message_norm": "fix: fix random number generation",
      "language": "en",
      "entities": "[('fix', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['nanorand/src/gen.rs'])",
      "num_files": 1.0
    },
    {
      "index": 604,
      "vuln_id": "GHSA-59q2-x2qc-4c97",
      "cwe_id": "{'CWE-125'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/51300ba1cc2f487aefec6e6631fef03b0e08b298'}",
      "dataset": "osv",
      "summary": "Heap OOB access in unicode ops ### Impact\nAn attacker can access data outside of bounds of heap allocated array in `tf.raw_ops.UnicodeEncode`:\n\n```python\nimport tensorflow as tf\n\ninput_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)\noutput_encoding = \"UTF-8\"\n\ntf.raw_ops.UnicodeEncode(\n    input_values=input_values, input_splits=input_splits,\n    output_encoding=output_encoding)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/472c1f12ad9063405737679d4f6bd43094e1d36d/tensorflow/core/kernels/unicode_ops.cc)\nassumes that the `input_value`/`input_splits` pair specify a valid sparse tensor.\n\n### Patches\nWe have patched the issue in GitHub commit [51300ba1cc2f487aefec6e6631fef03b0e08b298](https://github.com/tensorflow/tensorflow/commit/51300ba1cc2f487aefec6e6631fef03b0e08b298).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/51300ba1cc2f487aefec6e6631fef03b0e08b298",
      "commit_sha": "51300ba1cc2f487aefec6e6631fef03b0e08b298",
      "patch": "SINGLE",
      "chain_ord": "['51300ba1cc2f487aefec6e6631fef03b0e08b298']",
      "before_first_fix_commit": "{'472c1f12ad9063405737679d4f6bd43094e1d36d'}",
      "last_fix_commit": "51300ba1cc2f487aefec6e6631fef03b0e08b298",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/03/2021, 16:53:26",
      "message": "Fix heap buffer overflow in tf.raw_ops.UnicodeEncode.\n\nPiperOrigin-RevId: 371717714\nChange-Id: If33443b28f158e58078f1268f6b92f2728d219e0",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 19, 'deletions': 0, 'total': 19}",
      "files": "{'tensorflow/core/kernels/unicode_ops.cc': {'additions': 19, 'deletions': 0, 'changes': 19, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/51300ba1cc2f487aefec6e6631fef03b0e08b298/tensorflow%2Fcore%2Fkernels%2Funicode_ops.cc', 'patch': '@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\\n     const Tensor& input_splits = context->input(1);\\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\\n \\n+    // Operation will treat first argument in input_splits as if it were zero\\n+    // regardless of its actual value since splits should begin with zero and\\n+    // end with the length of the input values vector.\\n+    OP_REQUIRES(\\n+        context, input_splits_flat(0) == 0,\\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\\n+    OP_REQUIRES(context,\\n+                input_splits_flat(input_splits_flat.size() - 1) ==\\n+                    input_tensor_flat.size(),\\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\\n+                                        \"equal to length of input_tensor.\"));\\n     // Since we limit to a 2-D input (flat_values of rank 1 and a single splits\\n     // tensor), our output dimension will be 1 with it\\'s size equal to the\\n     // number of splits (outer dimension or ragged tensor).\\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\\n       icu::UnicodeString unicode_string;\\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\\n+      OP_REQUIRES(\\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\\n+          errors::InvalidArgument(\\n+              \"Values in input_splits must be equal or in ascending order.\"));\\n+      OP_REQUIRES(\\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\\n+                                  \"equal to input_tensor length.\"));\\n       for (; idx < input_splits_flat(i); ++idx) {\\n         int32 code_point = input_tensor_flat(idx);\\n         // Check for invalid code point'}}",
      "message_norm": "fix heap buffer overflow in tf.raw_ops.unicodeencode.\n\npiperorigin-revid: 371717714\nchange-id: if33443b28f158e58078f1268f6b92f2728d219e0",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('tf.raw_ops.unicodeencode', 'SECWORD', ''), ('371717714', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/unicode_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 614,
      "vuln_id": "GHSA-5crj-c72x-m7gq",
      "cwe_id": "{'CWE-476'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/05cbebd3c6bb8f517a158b0155debb8df79017ff'}",
      "dataset": "osv",
      "summary": "Null pointer exception when `Exit` node is not preceded by `Enter` op ### Impact\nThe [process of building the control flow graph](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/common_runtime/immutable_executor_state.cc#L284-L346) for a TensorFlow model is vulnerable to a null pointer exception when nodes that should be paired are not:\n  \n```python\nimport tensorflow as tf\n  \n@tf.function\ndef func():\n  return tf.raw_ops.Exit(data=[False,False])\n    \nfunc()\n```\n\nThis occurs because the code assumes that the first node in the pairing (e.g., an `Enter` node) always exists when encountering the second node (e.g., an `Exit` node):\n  \n```cc\n  ...\n} else if (IsExit(curr_node)) {\n  // Exit to the parent frame.\n  parent = parent_nodes[curr_id];         \n  frame_name = cf_info->frame_names[parent->id()];\n  ...                \n```\n\nWhen this is not the case, `parent` is `nullptr` so dereferencing it causes a crash.\n\n### Patches\nWe have patched the issue in GitHub commit [05cbebd3c6bb8f517a158b0155debb8df79017ff](https://github.com/tensorflow/tensorflow/commit/05cbebd3c6bb8f517a158b0155debb8df79017ff).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-11-10",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/05cbebd3c6bb8f517a158b0155debb8df79017ff",
      "commit_sha": "05cbebd3c6bb8f517a158b0155debb8df79017ff",
      "patch": "SINGLE",
      "chain_ord": "['05cbebd3c6bb8f517a158b0155debb8df79017ff']",
      "before_first_fix_commit": "{'3586950728a5e7cda93d9eeeedfec59ddb30883c'}",
      "last_fix_commit": "05cbebd3c6bb8f517a158b0155debb8df79017ff",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/18/2021, 23:17:46",
      "message": "Fix a NPE issue in invalid Exit op. Now it will report an error instead of crash.\n\nPiperOrigin-RevId: 404089902\nChange-Id: Ia6ec55445ea70ad045a4d339d354959ad0618f2a",
      "author": "Xiao Yu",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'tensorflow/core/common_runtime/immutable_executor_state.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/05cbebd3c6bb8f517a158b0155debb8df79017ff/tensorflow%2Fcore%2Fcommon_runtime%2Fimmutable_executor_state.cc', 'patch': '@@ -316,6 +316,10 @@ Status ImmutableExecutorState::BuildControlFlowInfo(const Graph* g,\\n     } else if (IsExit(curr_node)) {\\n       // Exit to the parent frame.\\n       parent = parent_nodes[curr_id];\\n+      if (!parent) {\\n+        return errors::InvalidArgument(\\n+            \"Invalid Exit op: Cannot find a corresponding Enter op.\");\\n+      }\\n       frame_name = cf_info->frame_names[parent->id()];\\n       parent = parent_nodes[parent->id()];\\n     } else {'}}",
      "message_norm": "fix a npe issue in invalid exit op. now it will report an error instead of crash.\n\npiperorigin-revid: 404089902\nchange-id: ia6ec55445ea70ad045a4d339d354959ad0618f2a",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('npe issue', 'SECWORD', ''), ('error', 'FLAW', ''), ('404089902', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/common_runtime/immutable_executor_state.cc'])",
      "num_files": 1.0
    },
    {
      "index": 776,
      "vuln_id": "GHSA-67j9-c52g-w2q9",
      "cwe_id": "{'CWE-863'}",
      "score": 4.9,
      "chain": "{'https://github.com/spiral-project/ihatemoney/commit/8d77cf5d5646e1d2d8ded13f0660638f57e98471'}",
      "dataset": "osv",
      "summary": "Authorization Bypass in I hate money ### Impact\nAn authenticated member of one project can modify and delete members of another project, without knowledge of this other project's private code. This can be further exploited to access all bills of another project without knowledge of this other project's private code.\n\nWith the default configuration, anybody is allowed to create a new project. An attacker can create a new project and then use it to become authenticated and exploit this flaw. As such, the exposure is similar to an unauthenticated attack, because it is trivial to become authenticated.\n\n### Patches\n```diff\n ihatemoney/models.py | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a/ihatemoney/models.py b/ihatemoney/models.py\nindex fe7b519..5691c75 100644\n--- a/ihatemoney/models.py\n+++ b/ihatemoney/models.py\n@@ -380,7 +380,7 @@ class Person(db.Model):\n         def get_by_name(self, name, project):\n             return (\n                 Person.query.filter(Person.name == name)\n-                .filter(Project.id == project.id)\n+                .filter(Person.project_id == project.id)\n                 .one()\n             )\n \n@@ -389,7 +389,7 @@ class Person(db.Model):\n                 project = g.project\n             return (\n                 Person.query.filter(Person.id == id)\n-                .filter(Project.id == project.id)\n+                .filter(Person.project_id == project.id)\n                 .one()\n             )\n \n```\n\n### Workarounds\n\nTo limit the impact, it is possible to disable public project creation by setting `ALLOW_PUBLIC_PROJECT_CREATION = False` in the configuration (see [documentation](https://ihatemoney.readthedocs.io/en/latest/configuration.html)). Existing users will still be able to exploit the flaw, but this will prevent an external attacker from creating a new project.\n\n### For more information\n\n`Person.query.get()` and `Person.query.get_by_name()` were mistakenly running a database join on the Project table without constraining the result.\n\nAs a result, `Person.query.get(42, \"projectfoo\")` would return the Person with id=42, even if it is not associated to the project \"projectfoo\".  The only condition is that \"projectfoo\" must exist.\n\nThis flaw can be exploited in several places:\n\n1) API: PUT requests to `/api/projects/<project>/members/<personID>` will succeed even though `<personID>` is not a member of `<project>`.\n\n   This allows an authenticated attacker to alter the state of a member (name, weight, activated) in any project.  In addition, the altered member will no longer be associated with its original project but will be associated to the attacker project instead, breaking many features of IHateMoney.  For instance, bills referencing the altered member will no longer be visible in the original project.\n\n   This causes an additional information disclosure and loss of integrity on bills: the attacker will now be able to see, edit and delete bills belonging to the altered member, because IHateMoney now believes that these bills are associated to the attacker project through the altered member.\n\n   For instance, assume that `Person(id=42)` is a member of project \"targetProject\", and that the attacker has access to another project \"attackerProject\" with the private code \"attackerPassword\".  The attacker can modify `Person(id=42)` with this command:\n\n     $ curl -X PUT -d \"name=Pwn3d&activated=1\" --basic -u attackerProject:attackerPassword http://$SERVER/api/projects/attackerProject/members/42\n\n   The attacker can now see, edit and delete bills paid by `Person(id=42)` by simply browsing to http://$SERVER/attackerProject/\n\n2) Editing a member through the web interface at `/<project>/members/<personID>/edit` will succeed even though `<personID>` is not a member of `<project>`.\n\n   This is very similar to the PUT exploit.  Reusing the same example, the attacker needs to login to its \"attackerProject\" project with the private code \"attackerPassword\".  It can then alter the state of `Person(id=42)` by accessing the edit form at the following URL:\n\n     http://$SERVER/attackerProject/members/42/edit\n\n   Again, as a result of the alteration, the altered member will become associated to the project \"attackerProject\", resulting in the same information disclosure and loss of integrity on bills.\n\n3) API: DELETE requests to `/api/projects/<project>/members/<personID>` will similarly allow to delete the member `<personID>` even if it belongs to a different project than `<project>`.\n\n     $ curl -X DELETE --basic -u attackerProject:attackerPassword http://$SERVER/api/projects/attackerProject/members/42\n\n   The impact is less serious than with PUT, because DELETE only deactivates a member (it does not really delete it).\n\nAll these exploits require authentication: an attacker needs to know a valid project name and its associated \"private code\".  Once this requirement is fullfilled, the attacker can exploit this flaw to alter the state of members in any other project, without needing to know the target project name or its private code.\n\n`Person.query.get_by_name()` suffers from the same issue as `Person.query.get()`.  It has an additional issue: if multiple Person objects with the same name exist (this is possible if they are associated to different projects), `get_by_name()` will crash with `MultipleResultsFound` because of the call to `one()`.\n\nHowever, since `Person.query.get_by_name()` is currently not used anywhere in IHateMoney, the bug affecting this function has no impact and is not exploitable.",
      "published_date": "2020-07-27",
      "chain_len": 1,
      "project": "https://github.com/spiral-project/ihatemoney",
      "commit_href": "https://github.com/spiral-project/ihatemoney/commit/8d77cf5d5646e1d2d8ded13f0660638f57e98471",
      "commit_sha": "8d77cf5d5646e1d2d8ded13f0660638f57e98471",
      "patch": "SINGLE",
      "chain_ord": "['8d77cf5d5646e1d2d8ded13f0660638f57e98471']",
      "before_first_fix_commit": "{'040d76af83411fb58ab400dc4eac909191a3e5fa'}",
      "last_fix_commit": "8d77cf5d5646e1d2d8ded13f0660638f57e98471",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/17/2020, 15:43:33",
      "message": "Fix unauthorized access and modification of project data (CVE-2020-15120)\n\nAn authenticated member of one project can modify and delete members of\nanother project, without knowledge of this other project's private\ncode. This can be further exploited to access all bills of another project\nwithout knowledge of this other project's private code.\n\nWith the default configuration, anybody is allowed to create a new\nproject. An attacker can create a new project and then use it to become\nauthenticated and exploit this flaw. As such, the exposure is similar to\nan unauthenticated attack, because it is trivial to become authenticated.\n\nThis issue was caused by a wrong database queries in PersonQuery.\n\nFor more details, see https://github.com/spiral-project/ihatemoney/security/advisories/GHSA-67j9-c52g-w2q9",
      "author": "Baptiste Jonglez",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'ihatemoney/models.py': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/spiral-project/ihatemoney/raw/8d77cf5d5646e1d2d8ded13f0660638f57e98471/ihatemoney%2Fmodels.py', 'patch': '@@ -380,7 +380,7 @@ class PersonQuery(BaseQuery):\\n         def get_by_name(self, name, project):\\n             return (\\n                 Person.query.filter(Person.name == name)\\n-                .filter(Project.id == project.id)\\n+                .filter(Person.project_id == project.id)\\n                 .one()\\n             )\\n \\n@@ -389,7 +389,7 @@ def get(self, id, project=None):\\n                 project = g.project\\n             return (\\n                 Person.query.filter(Person.id == id)\\n-                .filter(Project.id == project.id)\\n+                .filter(Person.project_id == project.id)\\n                 .one()\\n             )'}}",
      "message_norm": "fix unauthorized access and modification of project data (cve-2020-15120)\n\nan authenticated member of one project can modify and delete members of\nanother project, without knowledge of this other project's private\ncode. this can be further exploited to access all bills of another project\nwithout knowledge of this other project's private code.\n\nwith the default configuration, anybody is allowed to create a new\nproject. an attacker can create a new project and then use it to become\nauthenticated and exploit this flaw. as such, the exposure is similar to\nan unauthenticated attack, because it is trivial to become authenticated.\n\nthis issue was caused by a wrong database queries in personquery.\n\nfor more details, see https://github.com/spiral-project/ihatemoney/security/advisories/ghsa-67j9-c52g-w2q9",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('cve-2020-15120', 'VULNID', 'CVE'), ('exploited', 'SECWORD', ''), ('attacker', 'FLAW', ''), ('exploit', 'SECWORD', ''), ('flaw', 'FLAW', ''), ('unauthenticated', 'SECWORD', ''), ('attack', 'FLAW', ''), ('issue', 'FLAW', ''), ('https://github.com/spiral-project/ihatemoney/security/advisories/ghsa-67j9-c52g-w2q9', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['ihatemoney/models.py'])",
      "num_files": 1.0
    },
    {
      "index": 2561,
      "vuln_id": "GHSA-pfj3-56hm-jwq5",
      "cwe_id": "{'CWE-74'}",
      "score": 7.9,
      "chain": "{'https://github.com/jmrozanec/cron-utils/commit/4cf373f7352f5d95f0bf6512af8af326b31c835e'}",
      "dataset": "osv",
      "summary": "Template injection in cron-utils ### Impact\nA Template Injection was identified in cron-utils enabling attackers to inject arbitrary Java EL expressions, leading to unauthenticated Remote Code Execution (RCE) vulnerability. Versions up to 9.1.2 are susceptible to this vulnerability. Please note, that only projects using the @Cron annotation to validate untrusted Cron expressions are affected.\n\n### Patches\nThe issue was patched and a new version released. Please upgrade to version 9.1.3.\n\n### Workarounds\nThere are no known workarounds up to this moment.\n\n### References\nA description of the issue is provided in [issue 461](https://github.com/jmrozanec/cron-utils/issues/461)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [cron-utils Github repository](https://github.com/jmrozanec/cron-utils)",
      "published_date": "2020-11-24",
      "chain_len": 1,
      "project": "https://github.com/jmrozanec/cron-utils",
      "commit_href": "https://github.com/jmrozanec/cron-utils/commit/4cf373f7352f5d95f0bf6512af8af326b31c835e",
      "commit_sha": "4cf373f7352f5d95f0bf6512af8af326b31c835e",
      "patch": "SINGLE",
      "chain_ord": "['4cf373f7352f5d95f0bf6512af8af326b31c835e']",
      "before_first_fix_commit": "{'864f9f09af58bd48133a1492a09fb7fbc1c5858b'}",
      "last_fix_commit": "4cf373f7352f5d95f0bf6512af8af326b31c835e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/17/2020, 13:53:58",
      "message": "Update dependencies to fix security vulnerability.",
      "author": "Joze Rozanec",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 3, 'total': 7}",
      "files": "{'pom.xml': {'additions': 4, 'deletions': 3, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/jmrozanec/cron-utils/raw/4cf373f7352f5d95f0bf6512af8af326b31c835e/pom.xml', 'patch': '@@ -121,11 +121,12 @@\\n             <scope>test</scope>\\n         </dependency>\\n         <dependency>\\n-            <groupId>org.hibernate</groupId>\\n-            <artifactId>hibernate-validator</artifactId>\\n+            <groupId>org.apache.bval</groupId>\\n+            <artifactId>bval-jsr</artifactId>\\n+            <version>1.1.2</version>\\n+            <!--The Hibernate dependency is no longer used, due to security vulnerabilities -->\\n             <!-- https://stackoverflow.com/questions/48323244/java-lang-nosuchmethoderror-javax-validation-bootstrapconfiguration-getclockproExecutionTimeQuartzIntegrationTest -->\\n             <!-- https://stackoverflow.com/questions/24386771/javax-validation-validationexception-hv000183-unable-to-load-javax-el-express -->\\n-            <version>5.3.6.Final</version>\\n             <scope>test</scope>\\n         </dependency>\\n         <dependency>'}}",
      "message_norm": "update dependencies to fix security vulnerability.",
      "language": "en",
      "entities": "[('update', 'ACTION', ''), ('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['pom.xml'])",
      "num_files": 1.0
    },
    {
      "index": 3241,
      "vuln_id": "GHSA-w77p-8cfg-2x43",
      "cwe_id": "{'CWE-284'}",
      "score": 9.8,
      "chain": "{'https://github.com/qos-ch/slf4j/commit/d2b27fba88e983f921558da27fc29b5f5d269405'}",
      "dataset": "osv",
      "summary": "Improper Access Control in SLF4J org.slf4j.ext.EventData in the slf4j-ext module in QOS.CH SLF4J before `1.8.0-beta4` allows remote attackers to bypass intended access restrictions via crafted data. EventData in the slf4j-ext module in QOS.CH SLF4J, has been fixed in SLF4J version `1.7.26` and later and in the `2.0.x` series.\n\nNote that while the [fix commit](https://github.com/qos-ch/slf4j/commit/d2b27fba88e983f921558da27fc29b5f5d269405) is associated with the tag `1.8.0-beta3`, the versions in [Maven](https://mvnrepository.com/artifact/org.slf4j/slf4j-ext) go directly from `1.8.0-beta2` to `1.8.0-beta4`.",
      "published_date": "2022-05-13",
      "chain_len": 1,
      "project": "https://github.com/qos-ch/slf4j",
      "commit_href": "https://github.com/qos-ch/slf4j/commit/d2b27fba88e983f921558da27fc29b5f5d269405",
      "commit_sha": "d2b27fba88e983f921558da27fc29b5f5d269405",
      "patch": "SINGLE",
      "chain_ord": "['d2b27fba88e983f921558da27fc29b5f5d269405']",
      "before_first_fix_commit": "{'0ec1f6aac8648e87a7dda2f5730fef6db3b4fa33'}",
      "last_fix_commit": "d2b27fba88e983f921558da27fc29b5f5d269405",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2018, 00:09:26",
      "message": "fix SLF4J-431",
      "author": "Ceki Gulcu",
      "comments": "{'com_1': {'author': 'kbabioch', 'datetime': '03/20/2018, 08:48:11', 'body': 'What exactly is the issue here? Unfortunately there seem to be no details available on this, and marking a class \"deprecated\" is not necessarily a real fix.'}, 'com_2': {'author': 'ceki', 'datetime': '03/20/2018, 08:50:32', 'body': '@kbabioch  Are you using the EventData class?'}, 'com_3': {'author': 'kbabioch', 'datetime': '03/20/2018, 09:10:00', 'body': \"@ceki I'm evaluating this issue, and realized that basically no details are available yet :-/.\"}, 'com_4': {'author': 'ceki', 'datetime': '03/20/2018, 09:18:17', 'body': 'SLF4J-431 is a subtask of SLF4J-430. EventData is slated to be removed due to a security vulnerability.'}, 'com_5': {'author': 'adioss', 'datetime': '12/14/2018, 16:02:22', 'body': 'Regarding http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-8088, as far as I understand, solution is to update to version to 1.8.0-beta2.\\r\\nHowever, on https://jira.qos.ch/browse/SLF4J-430, you can see that fix version is 1.8.0-beta3.\\r\\nSo, what could we advice in order to fix the threat?'}, 'com_6': {'author': 'ceki', 'datetime': '12/14/2018, 21:07:48', 'body': 'As far as I know, org.slf4j.ext.EventData is not widely used.'}, 'com_7': {'author': 'areguru', 'datetime': '12/20/2018, 17:28:49', 'body': \"@adioss \\r\\nI suppose you use the OWASP dependency-checker or similar and got a warning about CVE-2018-8088.\\r\\n(In that case same as us)\\r\\n\\r\\nMy understanding after analyzing this is that only the slf4j-ext module has the vulnerability, and only the EventData-class is affected. Most users of SLF4J doesn't use this. \\r\\nhttps://nvd.nist.gov/vuln/detail/CVE-2018-8088\\r\\nhttps://mvnrepository.com/artifact/org.slf4j/slf4j-ext\\r\\n   groupId: org.slf4j\\r\\n   artifactId: slf4j-ext\\r\\n   version: 1.7.25\\r\\n\\r\\nSLF4J extensions are packaged within slf4j-ext.jar\\r\\nhttps://www.slf4j.org/extensions.html\\r\\n\\r\\nIf you use maven \\r\\nmvn dependency:tree\\r\\nwill generate the dependencies tree of your maven project.\\r\\n\\r\\nFor us the flagging of slf4j-api as vulnerable was a false positive.\\r\\nhttps://mvnrepository.com/artifact/org.slf4j/slf4j-api\\r\\n   groupId: org.slf4j\\r\\n   artifactId: slf4j-api\\r\\n   version: 1.7.25\\r\\n\\r\\nYou have to check if your application actually use slf4j-ext (and org.slf4j.ext.EventData)\"}, 'com_8': {'author': 'adioss', 'datetime': '12/20/2018, 23:42:45', 'body': '@areguru yep exactly that, you\\'ve got it: CVE is \"badly\" declared so, although only slf4j-ext is sensitive, cpe declaration is too large so slf4j-* are detected by sca tools like dependency-check.\\r\\n\\r\\nAlthough I have no dependencies on slf4j-ext on my projects, for other people that have slf4j-ext in the classpath, I was wandering if \"mark as deprecated\" was enough and if they is no other way to exploit the threat than using the constructor directly (using deserialization for example) but finally I\\'m not sure it\\'s possible.\\r\\nThanks a lot @areguru  and @ceki for feedback.'}, 'com_9': {'author': 'sepe81', 'datetime': '01/09/2019, 09:47:27', 'body': 'According to https://www.slf4j.org/download.html version 1.8.0-beta2 is EXPERIMENTAL. Are there any plans to backport this to the STABLE branch 1.7.x and release a version 1.7.26?'}, 'com_10': {'author': 'cowwoc', 'datetime': '01/09/2019, 14:50:50', 'body': '@adioss I emailed nvd@nist.gov asking them to fix the CVE but got back this nice auto-reply: `Due to a lapse in appropriations, I will be out of the office and unable to reply to e-mail until further notice.` :)'}, 'com_11': {'author': 'cowwoc', 'datetime': '01/09/2019, 15:22:45', 'body': \"Looking again, it looks like I was supposed to email mitre.org instead of nist.gov. I did now and they seem to be active. I'll let you know once I hear back from them.\"}, 'com_12': {'author': 'cowwoc', 'datetime': '01/10/2019, 16:42:30', 'body': \"Hey guys. I've just heard back from nist.gov. They will be updating the CVE for slf4j (and 700 others) within the next 24 hours to fix this kind of error (overly-broad warnings). If you guys run across this kind of error in the future, I recommend reporting it to them. They were extremely responsive and helpful. Have a great day :)\"}, 'com_13': {'author': 'markkolich', 'datetime': '01/25/2019, 20:02:29', 'body': \"@ceki following up on @sepe81's comment above, according to slf4j.org [0], version `1.8.0-beta2` is marked experimental but this version has been available for almost a year [1].\\r\\n\\r\\nIf I can gently ask, what is the plan/timeline for releasing a non-beta version of `1.8.0`?\\r\\n\\r\\n[0] https://www.slf4j.org/download.html\\r\\n[1] https://github.com/qos-ch/slf4j/releases/tag/v_1.8.0_beta2\"}, 'com_14': {'author': 'cowwoc', 'datetime': '01/25/2019, 20:42:43', 'body': 'I am hoping https://jira.qos.ch/browse/SLF4J-428 gets fixed before 1.8.0 is released because it will affect the Java module name.'}, 'com_15': {'author': 'Neustradamus', 'datetime': '01/13/2022, 20:30:30', 'body': 'Dear @kbabioch, @adioss, @areguru, @sepe81, @cowwoc, @markkolich,\\r\\n\\r\\nIn first, I wish you a Happy New Year 2022!\\r\\n\\r\\nToday, there was a progress by @ceki, and a correction about my old requests:\\r\\n- https://jira.qos.ch/browse/SLF4J-455\\r\\n\\r\\nIt has been solved in 1.7.26 and 1.8.0-beta4.\\r\\n\\r\\nI have requested the update of:\\r\\n- https://jira.qos.ch/browse/SLF4J-430\\r\\n- https://jira.qos.ch/browse/SLF4J-431\\r\\n\\r\\nAnd about CVE-2018-8088:\\r\\n- https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=slf4j+slf4j+log4j12\\r\\n- https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-8088\\r\\n- https://www.google.com/search?q=CVE-2018-8088\\r\\n\\r\\nLinked to:\\r\\n- https://github.com/qos-ch/reload4j/issues/10'}}",
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'slf4j-ext/src/main/java/org/slf4j/ext/EventData.java': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/qos-ch/slf4j/raw/d2b27fba88e983f921558da27fc29b5f5d269405/slf4j-ext%2Fsrc%2Fmain%2Fjava%2Forg%2Fslf4j%2Fext%2FEventData.java', 'patch': '@@ -40,6 +40,8 @@\\n  * event. Users may extend this class for each EventType they want to log.\\n  * \\n  * @author Ralph Goers\\n+ * \\n+ * @deprecated Due to a security vulnerability, this class will be removed without replacement.\\n  */\\n public class EventData implements Serializable {'}}",
      "message_norm": "fix slf4j-431",
      "language": "sv",
      "entities": "[('fix', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['slf4j-ext/src/main/java/org/slf4j/ext/EventData.java'])",
      "num_files": 1.0
    },
    {
      "index": 3008,
      "vuln_id": "GHSA-rrx2-r989-2c43",
      "cwe_id": "{'CWE-190'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/1b54cadd19391b60b6fcccd8d076426f7221d5e8', 'https://github.com/tensorflow/tensorflow/commit/e952a89b7026b98fe8cbe626514a93ed68b7c510'}",
      "dataset": "osv",
      "summary": "Integer overflows in Tensorflow ### Impact \nThe [implementations of `Sparse*Cwise*` ops](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc) are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service):\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ntf.raw_ops.SparseDenseCwiseDiv(\n    sp_indices=np.array([[9]]),\n    sp_values=np.array([5]),\n    sp_shape=np.array([92233720368., 92233720368]),\n    dense=np.array([4]))\n```\n\nWe are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The latter is an instance of [TFSA-2021-198](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa-2021-198.md) (CVE-2021-41197) and is easily fixed by replacing a call to `TensorShape` constructor with a call to `BuildTensorShape` static helper factory.\n\n### Patches\nWe have patched the issue in GitHub commits [1b54cadd19391b60b6fcccd8d076426f7221d5e8](https://github.com/tensorflow/tensorflow/commit/1b54cadd19391b60b6fcccd8d076426f7221d5e8) and [e952a89b7026b98fe8cbe626514a93ed68b7c510](https://github.com/tensorflow/tensorflow/commit/e952a89b7026b98fe8cbe626514a93ed68b7c510).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
      "published_date": "2022-02-09",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/e952a89b7026b98fe8cbe626514a93ed68b7c510",
      "commit_sha": "e952a89b7026b98fe8cbe626514a93ed68b7c510",
      "patch": "MULTI",
      "chain_ord": "['1b54cadd19391b60b6fcccd8d076426f7221d5e8', 'e952a89b7026b98fe8cbe626514a93ed68b7c510']",
      "before_first_fix_commit": "{'1b54cadd19391b60b6fcccd8d076426f7221d5e8'}",
      "last_fix_commit": "e952a89b7026b98fe8cbe626514a93ed68b7c510",
      "chain_ord_pos": 2.0,
      "commit_datetime": "12/10/2021, 17:46:48",
      "message": "Prevent overflow in sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543171\nChange-Id: I22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 1, 'total': 4}",
      "files": "{'tensorflow/core/kernels/sparse_dense_binary_op_shared.cc': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/e952a89b7026b98fe8cbe626514a93ed68b7c510/tensorflow%2Fcore%2Fkernels%2Fsparse_dense_binary_op_shared.cc', 'patch': '@@ -99,7 +99,9 @@ class SparseDenseBinaryOpShared : public OpKernel {\\n \\n     const auto indices_mat = indices_t->matrix<int64_t>();\\n     const auto shape_vec = shape_t->vec<int64_t>();\\n-    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\\n+    TensorShape lhs_shape;\\n+    OP_REQUIRES_OK(ctx, TensorShape::BuildTensorShape(shape_vec, &lhs_shape));\\n+    const auto lhs_dims = BCast::FromShape(lhs_shape);\\n     const auto rhs_dims = BCast::FromShape(dense_t->shape());\\n     BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.'}}",
      "message_norm": "prevent overflow in sparse dense cwise ops.\n\npiperorigin-revid: 415543171\nchange-id: i22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('415543171', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_dense_binary_op_shared.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2151,
      "vuln_id": "GHSA-hwr7-8gxx-fj5p",
      "cwe_id": "{'CWE-476'}",
      "score": 7.7,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/301ae88b331d37a2a16159b65b255f4f9eb39314'}",
      "dataset": "osv",
      "summary": "Null pointer dereference in `RaggedTensorToTensor` ### Impact\nSending invalid argument for `row_partition_types` of `tf.raw_ops.RaggedTensorToTensor` API results in a null pointer dereference and undefined behavior:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedTensorToTensor(\n  shape=1,\n  values=10,\n  default_value=21,\n  row_partition_tensors=tf.constant([0,0,0,0]),\n  row_partition_types=[])\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L328) accesses the first element of a user supplied list of values without validating that the provided list is not empty.\n\n### Patches\nWe have patched the issue in GitHub commit [301ae88b331d37a2a16159b65b255f4f9eb39314](https://github.com/tensorflow/tensorflow/commit/301ae88b331d37a2a16159b65b255f4f9eb39314).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/301ae88b331d37a2a16159b65b255f4f9eb39314",
      "commit_sha": "301ae88b331d37a2a16159b65b255f4f9eb39314",
      "patch": "SINGLE",
      "chain_ord": "['301ae88b331d37a2a16159b65b255f4f9eb39314']",
      "before_first_fix_commit": "{'e787d206757e3e87b04ab7bafa8b1e4130a9f774'}",
      "last_fix_commit": "301ae88b331d37a2a16159b65b255f4f9eb39314",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/12/2021, 16:59:54",
      "message": "Fix null ptr deref in tf.raw_ops.RaggedTensorToTensor\n\nPiperOrigin-RevId: 384257511\nChange-Id: I0484ad285039d132d6c41b284a7fcdd2b774a38e",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/301ae88b331d37a2a16159b65b255f4f9eb39314/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_tensor_op.cc', 'patch': '@@ -348,6 +348,9 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n   Status GetFirstDimensionSize(OpKernelContext* context, INDEX_TYPE* result) {\\n     const Tensor first_partition_tensor =\\n         context->input(kFirstPartitionInputIndex);\\n+    if (row_partition_types_.empty()) {\\n+      return errors::InvalidArgument(\"No row_partition_types given.\");\\n+    }\\n     const RowPartitionType first_partition_type = row_partition_types_[0];\\n     switch (first_partition_type) {\\n       case RowPartitionType::FIRST_DIM_SIZE:'}}",
      "message_norm": "fix null ptr deref in tf.raw_ops.raggedtensortotensor\n\npiperorigin-revid: 384257511\nchange-id: i0484ad285039d132d6c41b284a7fcdd2b774a38e",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('384257511', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1253,
      "vuln_id": "GHSA-8rmh-55h4-93h5",
      "cwe_id": "{'CWE-22'}",
      "score": 7.2,
      "chain": "{'https://github.com/DSpace/DSpace/commit/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0', 'https://github.com/DSpace/DSpace/commit/56e76049185bbd87c994128a9d77735ad7af0199'}",
      "dataset": "osv",
      "summary": "DSpace ItemImportService API Vulnerable to Path Traversal in Simple Archive Format Package Import ### Impact\nItemImportServiceImpl is vulnerable to a path traversal vulnerability. This means a malicious SAF (simple archive format) package could cause a file/directory to be created anywhere the Tomcat/DSpace user can write to on the server.  However, this path traversal vulnerability is only possible by a user with special privileges (either Administrators or someone with command-line access to the server).  This vulnerability impacts the XMLUI, JSPUI and command-line.\n\n_This vulnerability does NOT impact 7.x._\n\n### Patches\n\n_DSpace 6.x:_ \n* Fixed in 6.4 via commit: https://github.com/DSpace/DSpace/commit/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0\n* 6.x patch file: https://github.com/DSpace/DSpace/commit/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0.patch (may be applied manually if an immediate upgrade to 6.4 or 7.x is not possible)\n\n_DSpace 5.x:_\n* Fixed in 5.11 via commit: https://github.com/DSpace/DSpace/commit/56e76049185bbd87c994128a9d77735ad7af0199\n* 5.x patch file: https://github.com/DSpace/DSpace/commit/56e76049185bbd87c994128a9d77735ad7af0199.patch (may be applied manually if an immediate upgrade to 5.11 or 6.4 or 7.x is not possible)\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs / configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### Workarounds\n\nAs a basic workaround, you may block all access to the following URL paths:\n* If you are using the XMLUI, block all access to `/admin/batchimport` path (this is the URL of the Admin Batch Import tool). Keep in mind, if your site uses the path \"/xmlui\", then you'd need to block access to `/xmlui/admin/batchimport`.\n* If you are using the JSPUI, block all access to `/dspace-admin/batchimport` path (this is the URL of the Admin Batch Import tool).  Keep in mind, if your site uses the path \"/jspui\", then you'd need to block access to `/jspui/dspace-admin/batchimport`.\n\nKeep in mind, only an Administrative user or a user with command-line access to the server is able to import/upload SAF packages. Therefore, assuming those users do not blindly upload untrusted SAF packages, then it is unlikely your site could be impacted by this vulnerability.\n\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
      "published_date": "2022-08-06",
      "chain_len": 2,
      "project": "https://github.com/DSpace/DSpace",
      "commit_href": "https://github.com/DSpace/DSpace/commit/56e76049185bbd87c994128a9d77735ad7af0199",
      "commit_sha": "56e76049185bbd87c994128a9d77735ad7af0199",
      "patch": "MULTI",
      "chain_ord": "['7af52a0883a9dbc475cf3001f04ed11b24c8a4c0', '56e76049185bbd87c994128a9d77735ad7af0199']",
      "before_first_fix_commit": "{'73cdff26fdc40bb022e21dcfdeefebf28057cde7'}",
      "last_fix_commit": "56e76049185bbd87c994128a9d77735ad7af0199",
      "chain_ord_pos": 2.0,
      "commit_datetime": "01/14/2022, 00:37:25",
      "message": "[DS-4131] Better path handling in ItemImport zips",
      "author": "Kim Shepherd",
      "comments": null,
      "stats": "{'additions': 30, 'deletions': 6, 'total': 36}",
      "files": "{'dspace-api/src/main/java/org/dspace/app/itemimport/ItemImport.java': {'additions': 30, 'deletions': 6, 'changes': 36, 'status': 'modified', 'raw_url': 'https://github.com/DSpace/DSpace/raw/56e76049185bbd87c994128a9d77735ad7af0199/dspace-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdspace%2Fapp%2Fitemimport%2FItemImport.java', 'patch': '@@ -2003,22 +2003,30 @@ public static String unzip(File zipfile, String destDir) throws IOException {\\n         if (destinationDir == null){\\n         \\tdestinationDir = tempWorkDir;\\n         }\\n+        log.debug(\"Using directory \" + destinationDir + \" for zip extraction. (destDir arg is \" + destDir +\\n+                \", tempWorkDir is \" + tempWorkDir + \")\");\\n \\n         File tempdir = new File(destinationDir);\\n         if (!tempdir.isDirectory())\\n         {\\n-            log.error(\"\\'\" + ConfigurationManager.getProperty(\"org.dspace.app.itemexport.work.dir\") +\\n-                    \"\\' as defined by the key \\'org.dspace.app.itemexport.work.dir\\' in dspace.cfg \" +\\n+            log.error(\"\\'\" + ConfigurationManager.getProperty(\"org.dspace.app.batchitemimport.work.dir\") +\\n+                    \"\\' as defined by the key \\'org.dspace.app.batchitemimport.work.dir\\' in dspace.cfg \" +\\n                     \"is not a valid directory\");\\n         }\\n \\n         if (!tempdir.exists() && !tempdir.mkdirs())\\n         {\\n             log.error(\"Unable to create temporary directory: \" + tempdir.getAbsolutePath());\\n         }\\n-        String sourcedir = destinationDir + System.getProperty(\"file.separator\") + zipfile.getName();\\n-        String zipDir = destinationDir + System.getProperty(\"file.separator\") + zipfile.getName() + System.getProperty(\"file.separator\");\\n \\n+        if(!destinationDir.endsWith(System.getProperty(\"file.separator\"))) {\\n+            destinationDir += System.getProperty(\"file.separator\");\\n+        }\\n+\\n+        String sourcedir = destinationDir + zipfile.getName();\\n+        String zipDir = destinationDir + zipfile.getName() + System.getProperty(\"file.separator\");\\n+\\n+        log.debug(\"zip directory to use is \" + zipDir);\\n \\n         // 3\\n         String sourceDirForZip = sourcedir;\\n@@ -2028,11 +2036,26 @@ public static String unzip(File zipfile, String destDir) throws IOException {\\n         while (entries.hasMoreElements())\\n         {\\n             entry = entries.nextElement();\\n+            // Check that the true path to extract files is never outside allowed temp directories\\n+            // without creating any actual files on disk\\n+            log.debug(\"Inspecting entry name: \" + entry.getName() + \" for path traversal security\");\\n+            File potentialExtract = new File(zipDir + entry.getName());\\n+            String canonicalPath = potentialExtract.getCanonicalPath();\\n+            log.debug(\"Canonical path to potential File is \" + canonicalPath);\\n+            if(!canonicalPath.startsWith(zipDir)) {\\n+                log.error(\"Rejecting zip file: \" + zipfile.getName() + \" as it contains an entry that would be extracted \" +\\n+                        \"outside the temporary unzip directory: \" + canonicalPath);\\n+                throw new IOException(\"Error extracting \" + zipfile + \": Canonical path of zip entry: \" +\\n+                        entry.getName() + \" (\" + canonicalPath + \") does not start with permissible temp \" +\\n+                        \"unzip directory (\" + destinationDir + \")\");\\n+            }\\n             if (entry.isDirectory())\\n             {\\n-                if (!new File(zipDir + entry.getName()).mkdir())\\n-                {\\n+                // Log error and throw IOException if a directory entry could not be created\\n+                File newDir = new File(zipDir + entry.getName());\\n+                if (!newDir.mkdirs()) {\\n                     log.error(\"Unable to create contents directory: \" + zipDir + entry.getName());\\n+                    throw new IOException(\"Unable to create contents directory: \" + zipDir + entry.getName());\\n                 }\\n             }\\n             else\\n@@ -2074,6 +2097,7 @@ public static String unzip(File zipfile, String destDir) throws IOException {\\n                 byte[] buffer = new byte[1024];\\n                 int len;\\n                 InputStream in = zf.getInputStream(entry);\\n+                log.debug(\"Reading \" + zipDir + entry.getName() + \" into InputStream\");\\n                 BufferedOutputStream out = new BufferedOutputStream(\\n                         new FileOutputStream(zipDir + entry.getName()));\\n                 while((len = in.read(buffer)) >= 0)'}}",
      "message_norm": "[ds-4131] better path handling in itemimport zips",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['dspace-api/src/main/java/org/dspace/app/itemimport/ItemImport.java'])",
      "num_files": 1.0
    },
    {
      "index": 727,
      "vuln_id": "GHSA-627q-g293-49q7",
      "cwe_id": "{'CWE-400'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/1361fb7e29449629e1df94d44e0427ebec8c83c7'}",
      "dataset": "osv",
      "summary": "Abort caused by allocating a vector that is too large in Tensorflow ### Impact\nDuring shape inference, TensorFlow can [allocate a large vector](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/framework/shape_inference.cc#L788-L790) based on a value from a tensor controlled by the user:\n\n```cc\n  const auto num_dims = Value(shape_dim);\n  std::vector<DimensionHandle> dims;\n  dims.reserve(num_dims);\n``` \n  \n### Patches           \nWe have patched the issue in GitHub commit [1361fb7e29449629e1df94d44e0427ebec8c83c7](https://github.com/tensorflow/tensorflow/commit/1361fb7e29449629e1df94d44e0427ebec8c83c7).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-07",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/1361fb7e29449629e1df94d44e0427ebec8c83c7",
      "commit_sha": "1361fb7e29449629e1df94d44e0427ebec8c83c7",
      "patch": "SINGLE",
      "chain_ord": "['1361fb7e29449629e1df94d44e0427ebec8c83c7']",
      "before_first_fix_commit": "{'f6e7c84316c9fe416ea32086fa3c64fee21fafab'}",
      "last_fix_commit": "1361fb7e29449629e1df94d44e0427ebec8c83c7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/10/2021, 23:52:57",
      "message": "Fix abort caused by allocating a too large vector.\n\nWe need to make sure that the number of dimensions in a shape is within limits.\n\nPiperOrigin-RevId: 408997911\nChange-Id: If59e1c23f2ec9c2d4ff4d8632fd62b2a7773a4eb",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 15, 'deletions': 0, 'total': 15}",
      "files": "{'tensorflow/core/framework/shape_inference.cc': {'additions': 15, 'deletions': 0, 'changes': 15, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/1361fb7e29449629e1df94d44e0427ebec8c83c7/tensorflow%2Fcore%2Fframework%2Fshape_inference.cc', 'patch': '@@ -14,6 +14,8 @@ limitations under the License.\\n ==============================================================================*/\\n #include \"tensorflow/core/framework/shape_inference.h\"\\n \\n+#include <cstdint>\\n+\\n #include \"tensorflow/core/framework/bounds_check.h\"\\n #include \"tensorflow/core/framework/full_type_util.h\"\\n #include \"tensorflow/core/framework/node_def.pb.h\"\\n@@ -789,6 +791,19 @@ Status InferenceContext::InternalMakeShapeFromTensor(\\n       return ReturnUnknownShape(out);\\n     }\\n     const auto num_dims = Value(shape_dim);\\n+    // TODO(mihaimaruseac): Should be `TensorShape::MaxDimensions()` as we are\\n+    // not able to materialize shapes with more than this number of dimensions\\n+    // but then shape inference would fail for operations such as\\n+    // `tf.range`/`tf.ones`, etc. where the shape is not really materialized,\\n+    // only used during the inference. Hence, just prevent doing a `reserve`\\n+    // with a very large argument.\\n+    const int64_t max_dimensions = 1 << 20;\\n+    if (num_dims >= max_dimensions) {\\n+      return errors::Internal(\\n+          \"Cannot create a tensor with \", num_dims,\\n+          \" dimensions, as these would be more than maximum of \",\\n+          max_dimensions);\\n+    }\\n     std::vector<DimensionHandle> dims;\\n     dims.reserve(num_dims);\\n     for (int i = 0; i < num_dims; i++) dims.push_back(UnknownDim());'}}",
      "message_norm": "fix abort caused by allocating a too large vector.\n\nwe need to make sure that the number of dimensions in a shape is within limits.\n\npiperorigin-revid: 408997911\nchange-id: if59e1c23f2ec9c2d4ff4d8632fd62b2a7773a4eb",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('408997911', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/framework/shape_inference.cc'])",
      "num_files": 1.0
    },
    {
      "index": 742,
      "vuln_id": "GHSA-6445-fm66-fvq2",
      "cwe_id": "{'CWE-190'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/b51b82fe65ebace4475e3c54eb089c18a4403f1c', 'https://github.com/tensorflow/tensorflow/commit/a68f68061e263a88321c104a6c911fe5598050a8'}",
      "dataset": "osv",
      "summary": "Integer overflows in Tensorflow ### Impact \nThe [implementation of `AddManySparseToTensorsMap`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/kernels/sparse_tensors_map_ops.cc) is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service):\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ntf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices=[(0,0),(0,1),(0,2),(4,3),(5,0),(5,1)],\n    sparse_values=[1,1,1,1,1,1],\n    sparse_shape=[2**32,2**32],\n    container='',\n    shared_name='',\n    name=None)\n```\n\nWe are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The latter is an instance of [TFSA-2021-198](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa-2021-198.md) (CVE-2021-41197) and is easily fixed by replacing a call to `TensorShape` constructor with a call to `BuildTensorShape` static helper factory.\n### Patches\nWe have patched the issue in GitHub commits [b51b82fe65ebace4475e3c54eb089c18a4403f1c](https://github.com/tensorflow/tensorflow/commit/b51b82fe65ebace4475e3c54eb089c18a4403f1c) and [a68f68061e263a88321c104a6c911fe5598050a8](https://github.com/tensorflow/tensorflow/commit/a68f68061e263a88321c104a6c911fe5598050a8).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
      "published_date": "2022-02-09",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/b51b82fe65ebace4475e3c54eb089c18a4403f1c",
      "commit_sha": "b51b82fe65ebace4475e3c54eb089c18a4403f1c",
      "patch": "MULTI",
      "chain_ord": "['b51b82fe65ebace4475e3c54eb089c18a4403f1c', 'a68f68061e263a88321c104a6c911fe5598050a8']",
      "before_first_fix_commit": "{'e8f4be7958736823b9f56090611ec2fb09824d51'}",
      "last_fix_commit": "a68f68061e263a88321c104a6c911fe5598050a8",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/09/2021, 22:32:48",
      "message": "Add missing validation to `AddManySparseToTensorsMap`.\n\nSparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\nPiperOrigin-RevId: 415358027\nChange-Id: I96cbb672999cd1da772c22fabbd15507e32e12dc",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 15, 'deletions': 2, 'total': 17}",
      "files": "{'tensorflow/core/kernels/sparse_tensors_map_ops.cc': {'additions': 15, 'deletions': 2, 'changes': 17, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/b51b82fe65ebace4475e3c54eb089c18a4403f1c/tensorflow%2Fcore%2Fkernels%2Fsparse_tensors_map_ops.cc', 'patch': '@@ -231,16 +231,29 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\\n                 errors::InvalidArgument(\\n                     \"Input indices should be a matrix but received shape \",\\n                     input_indices->shape().DebugString()));\\n-\\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\\n                 errors::InvalidArgument(\\n                     \"Input values should be a vector but received shape \",\\n                     input_values->shape().DebugString()));\\n-\\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\\n                 errors::InvalidArgument(\\n                     \"Input shape should be a vector but received shape \",\\n                     input_shape->shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context,\\n+        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Number of values must match first dimension of indices. \", \"Got \",\\n+            input_values->shape().dim_size(0),\\n+            \" values, indices shape: \", input_indices->shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context,\\n+        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\\n+        errors::InvalidArgument(\\n+            \"Number of dimensions must match second dimension of indices. \",\\n+            \"Got \", input_shape->shape().dim_size(0),\\n+            \" dimensions, indices shape: \",\\n+            input_indices->shape().DebugString()));\\n \\n     int rank = input_shape->NumElements();'}}",
      "message_norm": "add missing validation to `addmanysparsetotensorsmap`.\n\nsparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\npiperorigin-revid: 415358027\nchange-id: i96cbb672999cd1da772c22fabbd15507e32e12dc",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('415358027', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_tensors_map_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2959,
      "vuln_id": "GHSA-rj44-gpjc-29r7",
      "cwe_id": "{'CWE-78'}",
      "score": 6.4,
      "chain": "{'https://github.com/thi-ng/umbrella/commit/88f61656e5f5cfba960013b8133186389efaf243'}",
      "dataset": "osv",
      "summary": "[thi.ng/egf] Potential arbitrary code execution of `#gpg`-tagged property values ### Impact\n\nPotential for arbitrary code execution in `#gpg`-tagged property values (only if `decrypt: true` option is enabled)\n\n### Patches\n\n[A fix](https://github.com/thi-ng/umbrella/commit/3e14765d6bfd8006742c9e7860bc7d58ae94dfa5) has already been released as v0.4.0\n\n### Workarounds\n\nBy default, EGF parse functions do NOT attempt to decrypt values (since GPG is only available in non-browser env).\n\nHowever, if GPG encrypted values are used/required:\n\n1. Perform a regex search for `#gpg`-tagged values in the EGF source file/string and check for backtick (\\`) chars in the encrypted value string\n2. Replace/remove them or skip parsing if present...\n\n### References\n\nhttps://github.com/thi-ng/umbrella/security/advisories/GHSA-rj44-gpjc-29r7#advisory-comment-65261\n\n### For more information\n\nIf you have any questions or comments about this advisory, please open an issue in the [thi.ng/umbrella repo](https://github.com/thi-ng/umbrella/issues), of which this package is part of.",
      "published_date": "2021-04-06",
      "chain_len": 1,
      "project": "https://github.com/thi-ng/umbrella",
      "commit_href": "https://github.com/thi-ng/umbrella/commit/88f61656e5f5cfba960013b8133186389efaf243",
      "commit_sha": "88f61656e5f5cfba960013b8133186389efaf243",
      "patch": "SINGLE",
      "chain_ord": "['88f61656e5f5cfba960013b8133186389efaf243']",
      "before_first_fix_commit": "{'c3f5ec12f324a4e627b26dc45d480c0e761602ea', '3e14765d6bfd8006742c9e7860bc7d58ae94dfa5'}",
      "last_fix_commit": "88f61656e5f5cfba960013b8133186389efaf243",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/27/2021, 08:52:42",
      "message": "Merge pull request from GHSA-rj44-gpjc-29r7\n\nfix(egf): update GPG invocation to avoid arb code exec",
      "author": "Karsten Schmidt",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 2, 'total': 6}",
      "files": "{'packages/egf/src/tags.ts': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/thi-ng/umbrella/raw/88f61656e5f5cfba960013b8133186389efaf243/packages%2Fegf%2Fsrc%2Ftags.ts', 'patch': '@@ -1,7 +1,7 @@\\n import type { IObjectOf } from \"@thi.ng/api\";\\n import { maybeParseFloat, maybeParseInt, unescape } from \"@thi.ng/strings\";\\n import { base64Decode } from \"@thi.ng/transducers-binary\";\\n-import { execSync } from \"child_process\";\\n+import { execFileSync } from \"child_process\";\\n import { readFileSync } from \"fs\";\\n import { resolve as resolvePath } from \"path\";\\n import { IS_NODE, NODE_ONLY, TagParser } from \"./api\";\\n@@ -24,7 +24,9 @@ export const BUILTINS: IObjectOf<TagParser> = {\\n     gpg: IS_NODE\\n         ? (_, body, ctx) =>\\n               (ctx.opts.decrypt\\n-                  ? execSync(`echo \"${body}\" | gpg --decrypt`).toString()\\n+                  ? execFileSync(\"gpg\", [\"--decrypt\"], {\\n+                        input: body,\\n+                    }).toString()\\n                   : body\\n               ).trim()\\n         : NODE_ONLY,'}}",
      "message_norm": "merge pull request from ghsa-rj44-gpjc-29r7\n\nfix(egf): update gpg invocation to avoid arb code exec",
      "language": "ca",
      "entities": "[('ghsa-rj44-gpjc-29r7', 'VULNID', 'GHSA'), ('fix(egf', 'ACTION', ''), ('code exec', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['packages/egf/src/tags.ts'])",
      "num_files": 1.0
    },
    {
      "index": 518,
      "vuln_id": "GHSA-4wpp-w5r4-7v5v",
      "cwe_id": "{'CWE-918'}",
      "score": 9.8,
      "chain": "{'https://github.com/charmbracelet/charm/commit/3c90668f955c7ce5ef721e4fc9faee7053232fd3'}",
      "dataset": "osv",
      "summary": "Server-Side Request Forgery in charm We've discovered a vulnerability in which attackers could forge HTTP requests to manipulate the `charm` data directory to access or delete anything on the server. This has been patched in https://github.com/charmbracelet/charm/commit/3c90668f955c7ce5ef721e4fc9faee7053232fd3 and is available in release [v0.12.1](https://github.com/charmbracelet/charm/releases/tag/v0.12.1). We recommend that all users running self-hosted `charm` instances update immediately.\n\nThis vulnerability was found in-house and we haven't been notified of any potential exploiters.\n\n### Additional notes\n\n* Encrypted user data uploaded to the Charm server is safe as Charm servers cannot decrypt user data. This includes filenames, paths, and all key-value data.\n* Users running the official Charm [Docker images](https://github.com/charmbracelet/charm/blob/main/docker.md) are at minimal risk because the exploit is limited to the containerized filesystem.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open a [discussion](https://github.com/charmbracelet/charm/discussions)\n* Email us at [vt100@charm.sh](mailto:vt100@charm.sh)\n* Chat with us on [Slack](https://charm.sh/slack)\n\n* * *\n\n<a href=\"https://charm.sh/\"><img alt=\"the Charm logo\" src=\"https://stuff.charm.sh/charm-badge.jpg\" width=\"400\"></a>\n\nCharm\u70ed\u7231\u5f00\u6e90 \u2022 Charm loves open source",
      "published_date": "2022-05-24",
      "chain_len": 1,
      "project": "https://github.com/charmbracelet/charm",
      "commit_href": "https://github.com/charmbracelet/charm/commit/3c90668f955c7ce5ef721e4fc9faee7053232fd3",
      "commit_sha": "3c90668f955c7ce5ef721e4fc9faee7053232fd3",
      "patch": "SINGLE",
      "chain_ord": "['3c90668f955c7ce5ef721e4fc9faee7053232fd3']",
      "before_first_fix_commit": "{'9c620ae07e7f7d7f3c0f6e52166b8b5f899d55d1'}",
      "last_fix_commit": "3c90668f955c7ce5ef721e4fc9faee7053232fd3",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/06/2022, 01:23:14",
      "message": "fix: clean path before accessing file store",
      "author": "Christian Muehlhaeuser",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 3, 'total': 7}",
      "files": "{'server/http.go': {'additions': 4, 'deletions': 3, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/charmbracelet/charm/raw/3c90668f955c7ce5ef721e4fc9faee7053232fd3/server%2Fhttp.go', 'patch': '@@ -10,6 +10,7 @@ import (\\n \\t\"io/ioutil\"\\n \\t\"log\"\\n \\t\"net/http\"\\n+\\t\"path/filepath\"\\n \\t\"strconv\"\\n \\t\"strings\"\\n \\n@@ -279,7 +280,7 @@ func (s *HTTPServer) handlePostSeq(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handlePostFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\tms := r.URL.Query().Get(\"mode\")\\n \\tm, err := strconv.ParseUint(ms, 10, 32)\\n \\tif err != nil {\\n@@ -316,7 +317,7 @@ func (s *HTTPServer) handlePostFile(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handleGetFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\tf, err := s.cfg.FileStore.Get(u.CharmID, path)\\n \\tif errors.Is(err, fs.ErrNotExist) {\\n \\t\\ts.renderCustomError(w, \"file not found\", http.StatusNotFound)\\n@@ -353,7 +354,7 @@ func (s *HTTPServer) handleGetFile(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handleDeleteFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\terr := s.cfg.FileStore.Delete(u.CharmID, path)\\n \\tif err != nil {\\n \\t\\tlog.Printf(\"cannot delete file: %s\", err)'}}",
      "message_norm": "fix: clean path before accessing file store",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/http.go'])",
      "num_files": 1.0
    },
    {
      "index": 2072,
      "vuln_id": "GHSA-hhqj-cfjx-vj25",
      "cwe_id": "{'CWE-79'}",
      "score": 6.1,
      "chain": "{'https://github.com/hakimel/reveal.js/commit/32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2'}",
      "dataset": "osv",
      "summary": "Cross site scripting in reveal.js The onmessage event listener in /plugin/notes/speaker-view.html does not check the origin of postMessage before adding the content to the webpage. The vulnerable code allows any origin to postMessage on the browser window and feeds attacker's input to parts using which attacker can execute arbitrary javascript code on victim's browser window hosting reveal.js",
      "published_date": "2022-03-02",
      "chain_len": 1,
      "project": "https://github.com/hakimel/reveal.js",
      "commit_href": "https://github.com/hakimel/reveal.js/commit/32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2",
      "commit_sha": "32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2",
      "patch": "SINGLE",
      "chain_ord": "['32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2']",
      "before_first_fix_commit": "{'e33c3c72f93d4c70ded3a90f5918f60082c96451'}",
      "last_fix_commit": "32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/26/2022, 11:46:18",
      "message": "Fix DOM XSS",
      "author": "r0hanSH",
      "comments": "{'com_1': {'author': 'Zhila136', 'datetime': '06/16/2022, 03:13:17', 'body': '\u062e\u062f\u0645\u0627\u062a: \u0647\u0645\u0631\u0627\u0647 \u06a9\u0627\u0631\u062a \\r\\n\u0646\u0648\u0639 \u0633\u0631\u0648\u06cc\u0633: \u0647\u0645\u0631\u0627\u0647 \u06a9\u0627\u0631\u062a \u0633\u067e\u0647\\r\\n\u0634\u0645\u0627\u0631\u0647 \u06a9\u0627\u0631\u062a: 9243 3628 1010 5892\\r\\n\u0628\u0646\u0627\u0645: \u0627\u0628\u0631\u0627\u0647\u06cc\u0645 \u0645\u0631\u0627\u062f\u06cc \u0627\u0633\u062a\u06cc\u0627\u0631\\r\\n\u0645\u0648\u062c\u0648\u062f\u06cc \u06a9\u0627\u0631\u062a:\\r\\n147,000,000,000,000\u0631\u06cc\u0627\u0644\\r\\n\u0645\u0628\u0644\u063a \u0642\u0627\u0628\u0644 \u0628\u0631\u062f\u0627\u0634\u062a:\\r\\n147,000,000,000,000\u0631\u06cc\u0627\u0644\\r\\n\u06a9\u062f \u067e\u06cc\u06af\u06cc\u0631\u06cc:963877\\r\\n\u0634\u0645\u0627\u0631\u0647 \u0645\u0631\u062c\u0639:94382963877\\r\\n\u06a9\u062f\u0633\u062f\u0627\u062f:20060530\\r\\nCODETRANSFER:G0956DVY87\\r\\nCOMMON ACCOUNT:947022366\\r\\nISIN:XS2111948803\\r\\nCFI CODE:DBFUFB\\r\\n\\r\\n\u0648\u0636\u0639\u06cc\u062a \u06a9\u0627\u0631\u062a: \u0627\u06a9\u062a\u06cc\u0648 \u0648 \u0642\u0627\u0628\u0644 \u062f\u0633\u062a\u0631\u0633\u06cc\\r\\n            \u0633\u0631\u0648\u0631 \u0628\u0627\u0646\u06a9 \u0633\u067e\u0647'}, 'com_2': {'author': 'Zhila136', 'datetime': '06/16/2022, 03:13:31', 'body': '> \u062e\u062f\u0645\u0627\u062a: \u0647\u0645\u0631\u0627\u0647 \u06a9\u0627\u0631\u062a \u0646\u0648\u0639 \u0633\u0631\u0648\u06cc\u0633: \u0647\u0645\u0631\u0627\u0647 \u06a9\u0627\u0631\u062a \u0633\u067e\u0647 \u0634\u0645\u0627\u0631\u0647 \u06a9\u0627\u0631\u062a: 9243 3628 1010 5892 \u0628\u0646\u0627\u0645: \u0627\u0628\u0631\u0627\u0647\u06cc\u0645 \u0645\u0631\u0627\u062f\u06cc \u0627\u0633\u062a\u06cc\u0627\u0631 \u0645\u0648\u062c\u0648\u062f\u06cc \u06a9\u0627\u0631\u062a: 147,000,000,000,000\u0631\u06cc\u0627\u0644 \u0645\u0628\u0644\u063a \u0642\u0627\u0628\u0644 \u0628\u0631\u062f\u0627\u0634\u062a: 147,000,000,000,000\u0631\u06cc\u0627\u0644 \u06a9\u062f \u067e\u06cc\u06af\u06cc\u0631\u06cc:963877 \u0634\u0645\u0627\u0631\u0647 \u0645\u0631\u062c\u0639:94382963877 \u06a9\u062f\u0633\u062f\u0627\u062f:20060530 CODETRANSFER:G0956DVY87 COMMON ACCOUNT: 947022366 ISIN:XS2111948803 \u06a9\u062f CFI:DBFUFB\\r\\n> \\r\\n> \u06a9\u0627\u0631\u062a \u0648\u0636\u0639\u06cc\u062a: \u0627\u06a9\u062a\u06cc\u0648 \u0648 \u0642\u0627\u0628\u0644 \u062f\u0633\u062a\u0631\u0633\u06cc \u0633\u0631\u0648\u0631 \u0628\u0627\u0646\u06a9 \u0633\u067e\u0647'}, 'com_3': {'author': 'Zhila136', 'datetime': '06/16/2022, 03:13:50', 'body': '![\u06f2\u06f0\u06f2\u06f2\u06f0\u06f6\u06f1\u06f6_\u06f0\u06f7\u06f3\u06f7\u06f4\u06f0](https://user-images.githubusercontent.com/97744031/173983277-3cf21aef-9310-4a21-b681-3457044107ad.jpg)'}}",
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'plugin/notes/speaker-view.html': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/hakimel/reveal.js/raw/32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2/plugin%2Fnotes%2Fspeaker-view.html', 'patch': '@@ -368,6 +368,10 @@ <h4 class=\"label\">Notes</h4>\\n \\n \\t\\t\\t\\twindow.addEventListener( \\'message\\', function( event ) {\\n \\n+\\t\\t\\t\\t\\tif (window.location.origin !== event.origin){\\n+\\t\\t\\t\\t\\t\\treturn;\\n+\\t\\t\\t\\t\\t}\\n+\\n \\t\\t\\t\\t\\tclearTimeout( connectionTimeout );\\n \\t\\t\\t\\t\\tconnectionStatus.style.display = \\'none\\';'}}",
      "message_norm": "fix dom xss",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('xss', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['plugin/notes/speaker-view.html'])",
      "num_files": 1.0
    },
    {
      "index": 3314,
      "vuln_id": "GHSA-wrp6-9w7f-3wxg",
      "cwe_id": "{'CWE-79'}",
      "score": 7.3,
      "chain": "{'https://github.com/janeczku/calibre-web/commit/7ad419dc8c12180e842a82118f4866ac3d074bc5'}",
      "dataset": "osv",
      "summary": "calibre-web is vulnerable to Cross-site Scripting calibre-web is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
      "published_date": "2022-01-21",
      "chain_len": 1,
      "project": "https://github.com/janeczku/calibre-web",
      "commit_href": "https://github.com/janeczku/calibre-web/commit/7ad419dc8c12180e842a82118f4866ac3d074bc5",
      "commit_sha": "7ad419dc8c12180e842a82118f4866ac3d074bc5",
      "patch": "SINGLE",
      "chain_ord": "['7ad419dc8c12180e842a82118f4866ac3d074bc5']",
      "before_first_fix_commit": "{'bcdc97641447965af486964537f3821f47b28874'}",
      "last_fix_commit": "7ad419dc8c12180e842a82118f4866ac3d074bc5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/20/2021, 12:40:23",
      "message": "Fix upload of cover and book formats containing html characters",
      "author": "Ozzie Isaacs",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'cps/static/js/edit_books.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/janeczku/calibre-web/raw/7ad419dc8c12180e842a82118f4866ac3d074bc5/cps%2Fstatic%2Fjs%2Fedit_books.js', 'patch': '@@ -248,15 +248,15 @@ $(\"#btn-upload-format\").on(\"change\", function () {\\n     if (filename.substring(3, 11) === \"fakepath\") {\\n         filename = filename.substring(12);\\n     } // Remove c:\\\\fake at beginning from localhost chrome\\n-    $(\"#upload-format\").html(filename);\\n+    $(\"#upload-format\").text(filename);\\n });\\n \\n $(\"#btn-upload-cover\").on(\"change\", function () {\\n     var filename = $(this).val();\\n     if (filename.substring(3, 11) === \"fakepath\") {\\n         filename = filename.substring(12);\\n     } // Remove c:\\\\fake at beginning from localhost chrome\\n-    $(\"#upload-cover\").html(filename);\\n+    $(\"#upload-cover\").text(filename);\\n });\\n \\n $(\"#xchange\").click(function () {'}}",
      "message_norm": "fix upload of cover and book formats containing html characters",
      "language": "en",
      "entities": "[('fix', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['cps/static/js/edit_books.js'])",
      "num_files": 1.0
    },
    {
      "index": 2256,
      "vuln_id": "GHSA-jhq9-wm9m-cf89",
      "cwe_id": "{'CWE-617'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe'}",
      "dataset": "osv",
      "summary": "CHECK-failure in `UnsortedSegmentJoin` ### Impact\nAn attacker can cause a denial of service by controlling the values of `num_segments` tensor argument for `UnsortedSegmentJoin`:\n\n```python\nimport tensorflow as tf\n\ninputs = tf.constant([], dtype=tf.string)\nsegment_ids = tf.constant([], dtype=tf.int32)\nnum_segments = tf.constant([], dtype=tf.int32)\nseparator = ''\n\ntf.raw_ops.UnsortedSegmentJoin(\n  inputs=inputs, segment_ids=segment_ids,\n  num_segments=num_segments, separator=separator)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/a2a607db15c7cd01d754d37e5448d72a13491bdb/tensorflow/core/kernels/unsorted_segment_join_op.cc#L92-L93) assumes that the `num_segments` tensor is a valid scalar:\n\n```cc\nconst Tensor& num_segments_tensor = context->input(2);\nauto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n```\n\nSince the tensor is empty the `CHECK` involved in `.scalar<T>()()` that checks that the number of elements is exactly 1 will be invalidated and this would result in process termination.\n\n### Patches\nWe have patched the issue in GitHub commit [704866eabe03a9aeda044ec91a8d0c83fc1ebdbe](https://github.com/tensorflow/tensorflow/commit/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
      "commit_sha": "704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
      "patch": "SINGLE",
      "chain_ord": "['704866eabe03a9aeda044ec91a8d0c83fc1ebdbe']",
      "before_first_fix_commit": "{'a2a607db15c7cd01d754d37e5448d72a13491bdb'}",
      "last_fix_commit": "704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/27/2021, 21:41:40",
      "message": "Fix overflow CHECK issue with `tf.raw_ops.UnsortedSegmentJoin`.\n\nPiperOrigin-RevId: 370766155\nChange-Id: I33e7c6626224e1060a8a4ab51ad5d861c6d4c63e",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'tensorflow/core/kernels/unsorted_segment_join_op.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe/tensorflow%2Fcore%2Fkernels%2Funsorted_segment_join_op.cc', 'patch': '@@ -90,6 +90,8 @@ class UnsortedSegmentJoinOp : public OpKernel {\\n     const int32 segment_dims = segment_id_shape.dims();\\n \\n     const Tensor& num_segments_tensor = context->input(2);\\n+    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\\n+                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\\n \\n     OP_REQUIRES(context, segment_dims != 0,'}}",
      "message_norm": "fix overflow check issue with `tf.raw_ops.unsortedsegmentjoin`.\n\npiperorigin-revid: 370766155\nchange-id: i33e7c6626224e1060a8a4ab51ad5d861c6d4c63e",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('370766155', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/unsorted_segment_join_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2376,
      "vuln_id": "GHSA-m7j4-fhg6-xf5v",
      "cwe_id": "{'CWE-1321'}",
      "score": 7.3,
      "chain": "{'https://github.com/DataTables/DataTablesSrc/commit/a51cbe99fd3d02aa5582f97d4af1615d11a1ea03'}",
      "dataset": "osv",
      "summary": "Prototype pollution in datatables.net All versions of package datatables.net are vulnerable to Prototype Pollution due to an incomplete fix for https://snyk.io/vuln/SNYK-JS-DATATABLESNET-598806.",
      "published_date": "2020-12-17",
      "chain_len": 1,
      "project": "https://github.com/DataTables/DataTablesSrc",
      "commit_href": "https://github.com/DataTables/DataTablesSrc/commit/a51cbe99fd3d02aa5582f97d4af1615d11a1ea03",
      "commit_sha": "a51cbe99fd3d02aa5582f97d4af1615d11a1ea03",
      "patch": "SINGLE",
      "chain_ord": "['a51cbe99fd3d02aa5582f97d4af1615d11a1ea03']",
      "before_first_fix_commit": "{'d878f888142e4811f839ea3e099ad1de64d74698'}",
      "last_fix_commit": "a51cbe99fd3d02aa5582f97d4af1615d11a1ea03",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/25/2020, 10:00:54",
      "message": "Fix: Possible prototype pollution if `constructor` were used in a data property name\n\nhttps://github.com/418sec/huntr/pull/827",
      "author": "Allan Jardine",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'js/core/core.data.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/DataTables/DataTablesSrc/raw/a51cbe99fd3d02aa5582f97d4af1615d11a1ea03/js%2Fcore%2Fcore.data.js', 'patch': \"@@ -357,7 +357,7 @@ function _fnSetObjectDataFn( mSource )\\n \\t\\t\\tfor ( var i=0, iLen=a.length-1 ; i<iLen ; i++ )\\n \\t\\t\\t{\\n \\t\\t\\t\\t// Protect against prototype pollution\\n-\\t\\t\\t\\tif (a[i] === '__proto__') {\\n+\\t\\t\\t\\tif (a[i] === '__proto__' || a[i] === 'constructor') {\\n \\t\\t\\t\\t\\tthrow new Error('Cannot set prototype values');\\n \\t\\t\\t\\t}\"}}",
      "message_norm": "fix: possible prototype pollution if `constructor` were used in a data property name\n\nhttps://github.com/418sec/huntr/pull/827",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('prototype pollution', 'SECWORD', ''), ('https://github.com/418sec/huntr/pull/827', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['js/core/core.data.js'])",
      "num_files": 1.0
    },
    {
      "index": 5,
      "vuln_id": "GHSA-2363-cqg2-863c",
      "cwe_id": "{'CWE-611'}",
      "score": 7.5,
      "chain": "{'https://github.com/hunterhacker/jdom/commit/dd4f3c2fc7893edd914954c73eb577f925a7d361'}",
      "dataset": "osv",
      "summary": "XML External Entity (XXE) Injection in JDOM An XXE issue in SAXBuilder in JDOM through 2.0.6 allows attackers to cause a denial of service via a crafted HTTP request.  At this time there is not released fixed version of JDOM.  As a workaround, to avoid external entities being expanded, one can call `builder.setExpandEntities(false)` and they won't be expanded.",
      "published_date": "2021-07-27",
      "chain_len": 1,
      "project": "https://github.com/hunterhacker/jdom",
      "commit_href": "https://github.com/hunterhacker/jdom/commit/dd4f3c2fc7893edd914954c73eb577f925a7d361",
      "commit_sha": "dd4f3c2fc7893edd914954c73eb577f925a7d361",
      "patch": "SINGLE",
      "chain_ord": "['dd4f3c2fc7893edd914954c73eb577f925a7d361']",
      "before_first_fix_commit": "{'1f81562b5cc813bfbacb7e2842b5be17eb34896b'}",
      "last_fix_commit": "dd4f3c2fc7893edd914954c73eb577f925a7d361",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/02/2021, 03:42:05",
      "message": "Addresses #189 - synchronizes external entity expansion setting",
      "author": "Rolf Lear",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'core/src/java/org/jdom2/input/SAXBuilder.java': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/hunterhacker/jdom/raw/dd4f3c2fc7893edd914954c73eb577f925a7d361/core%2Fsrc%2Fjava%2Forg%2Fjdom2%2Finput%2FSAXBuilder.java', 'patch': '@@ -82,6 +82,7 @@ OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT\\n import org.jdom2.DocType;\\n import org.jdom2.Document;\\n import org.jdom2.EntityRef;\\n+import org.jdom2.JDOMConstants;\\n import org.jdom2.JDOMException;\\n import org.jdom2.JDOMFactory;\\n import org.jdom2.Verifier;\\n@@ -797,6 +798,11 @@ public void setFastReconfigure(final boolean fastReconfigure) {\\n \\tpublic void setFeature(final String name, final boolean value) {\\n \\t\\t// Save the specified feature for later.\\n \\t\\tfeatures.put(name, value ? Boolean.TRUE : Boolean.FALSE);\\n+\\t\\tif (JDOMConstants.SAX_FEATURE_EXTERNAL_ENT.equals(name)) {\\n+\\t\\t\\t// See issue https://github.com/hunterhacker/jdom/issues/189\\n+\\t\\t\\t// And PR https://github.com/hunterhacker/jdom/pull/188\\n+\\t\\t\\tsetExpandEntities(value);\\n+\\t\\t}\\n \\t\\tengine = null;\\n \\t}'}}",
      "message_norm": "addresses #189 - synchronizes external entity expansion setting",
      "language": "en",
      "entities": "[('#189', 'ISSUE', ''), ('external entity', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['core/src/java/org/jdom2/input/SAXBuilder.java'])",
      "num_files": 1.0
    },
    {
      "index": 3023,
      "vuln_id": "GHSA-rww7-2gpw-fv6j",
      "cwe_id": "{'CWE-754'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/cb164786dc891ea11d3a900e90367c339305dc7b'}",
      "dataset": "osv",
      "summary": "Crash when type cannot be specialized in Tensorflow ### Impact\nUnder certain scenarios, TensorFlow can fail to specialize a type during [shape inference](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/framework/shape_inference.cc#L168-L174):\n\n```cc\nvoid InferenceContext::PreInputInit(\n    const OpDef& op_def, const std::vector<const Tensor*>& input_tensors,\n    const std::vector<ShapeHandle>& input_tensors_as_shapes) {\n  const auto ret = full_type::SpecializeType(attrs_, op_def);\n  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\n  ret_types_ = ret.ValueOrDie();\n  // ... \n}\n```\n\nHowever, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the `ValueOrDie` line. This results in an assertion failure as `ret` contains an error `Status`, not a value. In the second case we also get a crash due to the assertion failure.\n### Patches\nWe have patched the issue in GitHub commit [cb164786dc891ea11d3a900e90367c339305dc7b](https://github.com/tensorflow/tensorflow/commit/cb164786dc891ea11d3a900e90367c339305dc7b).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/cb164786dc891ea11d3a900e90367c339305dc7b",
      "commit_sha": "cb164786dc891ea11d3a900e90367c339305dc7b",
      "patch": "SINGLE",
      "chain_ord": "['cb164786dc891ea11d3a900e90367c339305dc7b']",
      "before_first_fix_commit": "{'c2b31ff2d3151acb230edc3f5b1832d2c713a9e0'}",
      "last_fix_commit": "cb164786dc891ea11d3a900e90367c339305dc7b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/08/2021, 18:28:34",
      "message": "Properly handle the case where `SpecializeType()` returns an error `Status`.\n\nIf the error case in `SpecializeType()` is reached, then we would get a crash when trying to access the value of an errorenous `StatusOr` object\n\nPiperOrigin-RevId: 408380069\nChange-Id: If3c3fc876dcf9384d5ec7a4985adc68c23ea7318",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 1, 'total': 5}",
      "files": "{'tensorflow/core/framework/shape_inference.cc': {'additions': 4, 'deletions': 1, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/cb164786dc891ea11d3a900e90367c339305dc7b/tensorflow%2Fcore%2Fframework%2Fshape_inference.cc', 'patch': '@@ -170,7 +170,10 @@ void InferenceContext::PreInputInit(\\n     const std::vector<ShapeHandle>& input_tensors_as_shapes) {\\n   // TODO(mdan): This is also done at graph construction. Run only here instead?\\n   const auto ret = full_type::SpecializeType(attrs_, op_def);\\n-  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\\n+  if (!ret.status().ok()) {\\n+    construction_status_ = ret.status();\\n+    return;\\n+  }\\n   ret_types_ = ret.ValueOrDie();\\n \\n   input_tensors_ = input_tensors;'}}",
      "message_norm": "properly handle the case where `specializetype()` returns an error `status`.\n\nif the error case in `specializetype()` is reached, then we would get a crash when trying to access the value of an errorenous `statusor` object\n\npiperorigin-revid: 408380069\nchange-id: if3c3fc876dcf9384d5ec7a4985adc68c23ea7318",
      "language": "en",
      "entities": "[('error', 'FLAW', ''), ('error', 'FLAW', ''), ('408380069', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/framework/shape_inference.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1525,
      "vuln_id": "GHSA-c9qf-r67m-p7cg",
      "cwe_id": "{'CWE-476'}",
      "score": 7.7,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/5dc7f6981fdaf74c8c5be41f393df705841fb7c5'}",
      "dataset": "osv",
      "summary": "Null pointer dereference in `CompressElement` ### Impact\nIt is possible to trigger a null pointer dereference in TensorFlow by passing an invalid input to `tf.raw_ops.CompressElement`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.CompressElement(components=[[]])\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/data/compression_utils.cc#L34) was accessing the size of a buffer obtained from the return of a separate function call before validating that said buffer is valid.\n\n### Patches\nWe have patched the issue in GitHub commit [5dc7f6981fdaf74c8c5be41f393df705841fb7c5](https://github.com/tensorflow/tensorflow/commit/5dc7f6981fdaf74c8c5be41f393df705841fb7c5).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for  more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360. Concurrently, it was resolved in `master` branch as it was also discovered internally and fixed before the report was handled.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/5dc7f6981fdaf74c8c5be41f393df705841fb7c5",
      "commit_sha": "5dc7f6981fdaf74c8c5be41f393df705841fb7c5",
      "patch": "SINGLE",
      "chain_ord": "['5dc7f6981fdaf74c8c5be41f393df705841fb7c5']",
      "before_first_fix_commit": "{'de9a4335c96bec8fa69abb89618b1daa4b2459fa'}",
      "last_fix_commit": "5dc7f6981fdaf74c8c5be41f393df705841fb7c5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/15/2021, 05:07:07",
      "message": "Fix accessing possible nullptr in tensorflow::data::CompressElement and UncompressElement which are used in tf.data.service.\n\nPiperOrigin-RevId: 373920841\nChange-Id: Ia88d78aee09fa19bb53a0f163fd19620d0c68743",
      "author": "A. Unique TensorFlower",
      "comments": null,
      "stats": "{'additions': 15, 'deletions': 7, 'total': 22}",
      "files": "{'tensorflow/core/data/compression_utils.cc': {'additions': 15, 'deletions': 7, 'changes': 22, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/5dc7f6981fdaf74c8c5be41f393df705841fb7c5/tensorflow%2Fcore%2Fdata%2Fcompression_utils.cc', 'patch': '@@ -29,9 +29,10 @@ Status CompressElement(const std::vector<Tensor>& element,\\n   int64 total_size = 0;\\n   for (auto& component : element) {\\n     if (DataTypeCanUseMemcpy(component.dtype())) {\\n-      // Some datatypes can be memcopied, allowing us to save two copies\\n-      // (AsProtoTensorContent and SerializeToArray).\\n-      total_size += DMAHelper::buffer(&component)->size();\\n+      const TensorBuffer* buffer = DMAHelper::buffer(&component);\\n+      if (buffer) {\\n+        total_size += buffer->size();\\n+      }\\n     } else {\\n       non_memcpy_components.emplace_back();\\n       component.AsProtoTensorContent(&non_memcpy_components.back());\\n@@ -53,8 +54,10 @@ Status CompressElement(const std::vector<Tensor>& element,\\n     component.shape().AsProto(metadata->mutable_tensor_shape());\\n     if (DataTypeCanUseMemcpy(component.dtype())) {\\n       const TensorBuffer* buffer = DMAHelper::buffer(&component);\\n-      memcpy(position, buffer->data(), buffer->size());\\n-      metadata->set_tensor_size_bytes(buffer->size());\\n+      if (buffer) {\\n+        memcpy(position, buffer->data(), buffer->size());\\n+        metadata->set_tensor_size_bytes(buffer->size());\\n+      }\\n     } else {\\n       TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\\n       proto.SerializeToArray(position, proto.ByteSizeLong());\\n@@ -94,8 +97,13 @@ Status UncompressElement(const CompressedElement& compressed,\\n     if (DataTypeCanUseMemcpy(metadata.dtype())) {\\n       out->emplace_back(metadata.dtype(), metadata.tensor_shape());\\n       TensorBuffer* buffer = DMAHelper::buffer(&out->back());\\n-      iov[i].iov_base = buffer->data();\\n-      iov[i].iov_len = buffer->size();\\n+      if (buffer) {\\n+        iov[i].iov_base = buffer->data();\\n+        iov[i].iov_len = buffer->size();\\n+      } else {\\n+        iov[i].iov_base = nullptr;\\n+        iov[i].iov_len = 0;\\n+      }\\n     } else {\\n       // Allocate an empty Tensor. We will fill it out later after\\n       // uncompressing into the tensor_proto_str.'}}",
      "message_norm": "fix accessing possible nullptr in tensorflow::data::compresselement and uncompresselement which are used in tf.data.service.\n\npiperorigin-revid: 373920841\nchange-id: ia88d78aee09fa19bb53a0f163fd19620d0c68743",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('tensorflow::data::compresselement', 'SECWORD', ''), ('uncompresselement', 'SECWORD', ''), ('373920841', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/data/compression_utils.cc'])",
      "num_files": 1.0
    },
    {
      "index": 268,
      "vuln_id": "GHSA-3j9m-hcv9-rpj8",
      "cwe_id": "{'CWE-79'}",
      "score": 6.9,
      "chain": "{'https://github.com/grafana/grafana/commit/3cb5214fa45eb5a571fd70d6c6edf0d729983f82', 'https://github.com/grafana/grafana/commit/fb85ed691290d211a5baa44d9a641ab137f0de88', 'https://github.com/grafana/grafana/commit/31b78d51c693d828720a5b285107a50e6024c912'}",
      "dataset": "osv",
      "summary": "XSS vulnerability allowing arbitrary JavaScript execution Today we are releasing Grafana 8.2.3. This patch release includes an important security fix for an issue that affects all Grafana versions from 8.0.0-beta1.\n\n[Grafana Cloud](https://grafana.com/cloud) instances have already been patched and an audit did not find any usage of this attack vector. [Grafana Enterprise](https://grafana.com/products/enterprise) customers were provided with updated binaries under embargo.\n\n## CVE-2021-41174 XSS vulnerability on unauthenticated pages\n\n### Summary\n\nCVSS Score: 6.9 Medium\nCVSS:[CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:C/C:L/I:H/A:N/E:U/RL:O/RC:R/CR:L/MAV:N/MAC:H/MPR:N/MUI:R/MS:C/MC:N/MI:H/MA:L](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:C/C:L/I:H/A:N/E:U/RL:O/RC:R/CR:L/MAV:N/MAC:H/MPR:N/MUI:R/MS:C/MC:N/MI:H/MA:L)\n\nWe received a security report to security@grafana.com on 2021-10-21 about a vulnerability in Grafana regarding the XSS vulnerability.\n\nIt was later identified as affecting Grafana versions from 8.0.0-beta1 to 8.2.2. [CVE-2021-41174](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41174) has been assigned to this vulnerability.\n\n### Impact\n\nIf an attacker is able to convince a victim to visit a URL referencing a vulnerable page, arbitrary JavaScript content may be executed within the context of the victim's browser.\n\nThe user visiting the malicious link must be unauthenticated and the link must be for a page that contains the login button in the menu bar.\n\nThere are two ways an unauthenticated user can open a page in Grafana that contains the login button:\n- Anonymous authentication is enabled. This means all pages in Grafana would be open for the attack.\n- The link is to an unauthenticated page. The following pages are vulnerable:\n  - `/dashboard-solo/snapshot/*`\n  - `/dashboard/snapshot/*`\n  - `/invite/:code`\n\nThe url has to be crafted to exploit AngularJS rendering and contain the interpolation binding for AngularJS expressions. AngularJS uses double curly braces for interpolation binding: {{ }} \n\nAn example of an expression would be: `{{constructor.constructor(\u2018alert(1)\u2019)()}}`. This can be included in the link URL like this: \n\nhttps://play.grafana.org/dashboard/snapshot/%7B%7Bconstructor.constructor('alert(1)')()%7D%7D?orgId=1\n\nWhen the user follows the link and the page renders, the login button will contain the original link with a query parameter to force a redirect to the login page. The URL is not validated and the AngularJS rendering engine will execute the JavaScript expression contained in the URL.\n\n### Attack audit\n\nWe can not guarantee that the below will identify all attacks, so if you find something using the audit process described below, you should consider doing a full assessment.\n\n#### Through reverse proxy/load balancer logs\n\nTo determine if your Grafana installation has been exploited for this vulnerability, search through your reverse proxy/load balancer access logs for instances where the path contains `{{` followed by something that would invoke JavaScript code. For example, this could be code that attempts to show a fake login page or to steal browser or session data. The [OWASP cheat sheet](https://cheatsheetseries.owasp.org/cheatsheets/XSS_Filter_Evasion_Cheat_Sheet.html) has several examples of XSS attacks.\n\n#### Through the Grafana Enterprise audit feature\n\nIf you enabled \u201cLog web requests\u201d in your configuration with `router_logging = true`, look for requests where `path` contains `{{` followed by something that would invoke JavaScript code.\n\n### Patched versions\n\nRelease 8.2.3:\n\n- [Download Grafana 8.2.3](https://grafana.com/grafana/download/8.2.3)\n- [Release notes](https://grafana.com/docs/grafana/latest/release-notes/release-notes-8-2-3/)\n\n### Solutions and mitigations\n\nDownload and install the appropriate patch for your version of Grafana.\n\n[Grafana Cloud](https://grafana.com/cloud) instances have already been patched, and [Grafana Enterprise](https://grafana.com/products/enterprise) customers were provided with updated binaries under embargo.\n\n### Workaround\n\nIf for some reason you cannot upgrade, you can use a reverse proxy or similar to block access to block the literal string `{{` in the path.\n\nExample of an Nginx rule to block the literal string `{{`:\n\n```\nlocation ~ \\{\\{ {\n    deny all;\n}\n```\n### Timeline and postmortem\n\nHere is a detailed timeline starting from when we originally learned of the issue. All times in UTC. \n\n* 2021-10-21 23:13: Security researcher sends the initial report about an XSS vulnerability.\n* 2021-10-21 23:13: Confirmed to be reproducible in at least versions 8.0.5 and 8.2.2.\n* 2021-10-22 02:02 MEDIUM severity declared.\n* 2021-10-22 09:22: it is discovered that Grafana instances with anonymous auth turned on are vulnerable. This includes https://play.grafana.org/ .\n* 2021-10-22 09:50: Anonymous access disabled for all instances on Grafana Cloud as a mitigation measure.\n* 2021-10-22 11:15: Workaround deployed on Grafana Cloud that blocks malicious requests.\n* 2021-10-22 12:35: Enabled anonymous access for instances on Grafana Cloud. \n* 2021-10-22 12:51: All instances protected by the workaround. From this point forward, Grafana Cloud is no longer affected.\n* 2021-10-22 14:05 Grafana Cloud instances updated with a fix.\n* 2021-10-22 19:23 :Determination that no weekend work is needed as the issue is of MEDIUM severity and the root cause has been identified.\n* 2021-10-25 14:13: Audit of Grafana Cloud concluded, no evidence of exploitation.\n* 2021-10-27 12:00: Grafana Enterprise images released to customers under embargo.\n* 2021-11-03 12:00: Public release.\n\n## Reporting security issues\n\nIf you think you have found a security vulnerability, please send a report to [security@grafana.com](mailto:security@grafana.com). This address can be used for all of\nGrafana Labs' open source and commercial products (including but not limited to Grafana, Tempo, Loki, k6, Tanka, and  Grafana Cloud, Grafana Enterprise, and grafana.com). We only accept vulnerability reports at this address. We would prefer that you encrypt your message to us using our PGP key. The key fingerprint is:\n\nF988 7BEA 027A 049F AE8E  5CAA D125 8932 BE24 C5CA\n\nThe key is available from [ keyserver.ubuntu.com]( https://keyserver.ubuntu.com/pks/lookup?op=get&fingerprint=on&search=0xD1258932BE24C5CA) by searching for [security@grafana]( https://keyserver.ubuntu.com/pks/lookup?search=security@grafana&fingerprint=on&op=index).\n\n## Security announcements\n\nThere is a Security [category](https://grafana.com/tags/security/) on the Grafana blog where we will post a summary, remediation, and mitigation details for any patch containing security fixes and you can subscribe to updates from our [Security Announcements RSS feed](https://grafana.com/tags/security/index.xml).",
      "published_date": "2021-11-08",
      "chain_len": 3,
      "project": "https://github.com/grafana/grafana",
      "commit_href": "https://github.com/grafana/grafana/commit/3cb5214fa45eb5a571fd70d6c6edf0d729983f82",
      "commit_sha": "3cb5214fa45eb5a571fd70d6c6edf0d729983f82",
      "patch": "MULTI",
      "chain_ord": "['31b78d51c693d828720a5b285107a50e6024c912', '3cb5214fa45eb5a571fd70d6c6edf0d729983f82', 'fb85ed691290d211a5baa44d9a641ab137f0de88']",
      "before_first_fix_commit": "{'3cb5214fa45eb5a571fd70d6c6edf0d729983f82', 'a3dc30546fce2e437d858c140f1ff307a04365d6'}",
      "last_fix_commit": "fb85ed691290d211a5baa44d9a641ab137f0de88",
      "chain_ord_pos": 2.0,
      "commit_datetime": "10/25/2021, 07:16:51",
      "message": "Merge pull request #151 from grafana/dcech/sanitize-replaceAll\n\nuse global replace when sanitizing urls in 8.2.3",
      "author": "Dimitris Sotirakis",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'packages/grafana-data/src/text/sanitize.ts': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/grafana/grafana/raw/3cb5214fa45eb5a571fd70d6c6edf0d729983f82/packages%2Fgrafana-data%2Fsrc%2Ftext%2Fsanitize.ts', 'patch': \"@@ -40,5 +40,5 @@ export function escapeHtml(str: string): string {\\n }\\n \\n export function sanitizeAngularInterpolation(url: string): string {\\n-  return url.replace('{{', '%7B%7B').replace('}}', '%7D%7D');\\n+  return url.replace(/\\\\{\\\\{/g, '%7B%7B').replace(/\\\\}\\\\}/g, '%7D%7D');\\n }\"}}",
      "message_norm": "merge pull request #151 from grafana/dcech/sanitize-replaceall\n\nuse global replace when sanitizing urls in 8.2.3",
      "language": "en",
      "entities": "[('#151', 'ISSUE', ''), ('sanitize', 'SECWORD', ''), ('sanitizing', 'SECWORD', ''), ('8.2.3', 'VERSION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['packages/grafana-data/src/text/sanitize.ts'])",
      "num_files": 1.0
    },
    {
      "index": 2764,
      "vuln_id": "GHSA-qhx9-7hx7-cp4r",
      "cwe_id": "{'CWE-444'}",
      "score": 6.8,
      "chain": "{'https://github.com/bottlepy/bottle/commit/57a2f22e0c1d2b328c4f54bf75741d74f47f1a6b'}",
      "dataset": "osv",
      "summary": "HTTP Request smuggling in bottle The package bottle before 0.12.19 are vulnerable to Web Cache Poisoning by using a vector called parameter cloaking. When the attacker can separate query parameters using a semicolon (;), they can cause a difference in the interpretation of the request between the proxy (running with default configuration) and the server. This can result in malicious requests being cached as completely safe ones, as the proxy would usually not see the semicolon as a separator, and therefore would not include it in a cache key of an unkeyed parameter.",
      "published_date": "2021-04-07",
      "chain_len": 1,
      "project": "https://github.com/bottlepy/bottle",
      "commit_href": "https://github.com/bottlepy/bottle/commit/57a2f22e0c1d2b328c4f54bf75741d74f47f1a6b",
      "commit_sha": "57a2f22e0c1d2b328c4f54bf75741d74f47f1a6b",
      "patch": "SINGLE",
      "chain_ord": "['57a2f22e0c1d2b328c4f54bf75741d74f47f1a6b']",
      "before_first_fix_commit": "{'2d6acef676d35611dc58ca9c3bac51789adbcce8'}",
      "last_fix_commit": "57a2f22e0c1d2b328c4f54bf75741d74f47f1a6b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/11/2020, 18:24:29",
      "message": "Do not split query strings on `;` anymore.\n\nUsing `;` as a separator instead of `&` was allowed a long time ago,\nbut is now obsolete and actually invalid according to the 2014 W3C\nrecommendations. Even if this change is technically backwards-incompatible,\nno real-world application should depend on broken behavior. If you REALLY\nneed this functionality, monkey-patch the _parse_qsl() function.",
      "author": "Marcel Hellkamp",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'bottle.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/bottlepy/bottle/raw/57a2f22e0c1d2b328c4f54bf75741d74f47f1a6b/bottle.py', 'patch': \"@@ -2585,7 +2585,7 @@ def parse_range_header(header, maxlen=0):\\n \\n def _parse_qsl(qs):\\n     r = []\\n-    for pair in qs.replace(';','&').split('&'):\\n+    for pair in qs.split('&'):\\n         if not pair: continue\\n         nv = pair.split('=', 1)\\n         if len(nv) != 2: nv.append('')\"}}",
      "message_norm": "do not split query strings on `;` anymore.\n\nusing `;` as a separator instead of `&` was allowed a long time ago,\nbut is now obsolete and actually invalid according to the 2014 w3c\nrecommendations. even if this change is technically backwards-incompatible,\nno real-world application should depend on broken behavior. if you really\nneed this functionality, monkey-patch the _parse_qsl() function.",
      "language": "en",
      "entities": "[('monkey', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['bottle.py'])",
      "num_files": 1.0
    },
    {
      "index": 493,
      "vuln_id": "GHSA-4v5p-v5h9-6xjx",
      "cwe_id": "{'CWE-617'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0'}",
      "dataset": "osv",
      "summary": "`CHECK`-failures in Tensorflow ### Impact\nAn attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated.\n\n### Patches\nWe have patched the issue in GitHub commit [c2b31ff2d3151acb230edc3f5b1832d2c713a9e0](https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
      "commit_sha": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
      "patch": "SINGLE",
      "chain_ord": "['c2b31ff2d3151acb230edc3f5b1832d2c713a9e0']",
      "before_first_fix_commit": "{'41424fd983e23b11ed13bbd5a2b2be0e25ab4244'}",
      "last_fix_commit": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/08/2021, 18:14:10",
      "message": "Remove a `DCHECK`-fail, log an error instead.\n\n`DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.\n\nOutside of debug mode, `DCHECK` is a no-op.\n\nA better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.\n\nPiperOrigin-RevId: 408375925\nChange-Id: Id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 3, 'total': 7}",
      "files": "{'tensorflow/core/framework/op_def_util.cc': {'additions': 4, 'deletions': 3, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0/tensorflow%2Fcore%2Fframework%2Fop_def_util.cc', 'patch': '@@ -821,9 +821,10 @@ bool RepeatedAttrDefEqual(\\n     const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\\n   std::unordered_map<string, const OpDef::AttrDef*> a1_set;\\n   for (const OpDef::AttrDef& def : a1) {\\n-    DCHECK(a1_set.find(def.name()) == a1_set.end())\\n-        << \"AttrDef names must be unique, but \\'\" << def.name()\\n-        << \"\\' appears more than once\";\\n+    if (a1_set.find(def.name()) != a1_set.end()) {\\n+      LOG(ERROR) << \"AttrDef names must be unique, but \\'\" << def.name()\\n+                 << \"\\' appears more than once\";\\n+    }\\n     a1_set[def.name()] = &def;\\n   }\\n   for (const OpDef::AttrDef& def : a2) {'}}",
      "message_norm": "remove a `dcheck`-fail, log an error instead.\n\n`dcheck` in debug mode results in crashes. tensorflow has had multiple vulnerabilities due to this.\n\noutside of debug mode, `dcheck` is a no-op.\n\na better alternative is to report an error to the log buffer and continue. this should happen both in debug mode and in prod mode.\n\npiperorigin-revid: 408375925\nchange-id: id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356",
      "language": "en",
      "entities": "[('remove', 'ACTION', ''), ('error', 'FLAW', ''), ('vulnerabilities', 'SECWORD', ''), ('error', 'FLAW', ''), ('408375925', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/framework/op_def_util.cc'])",
      "num_files": 1.0
    },
    {
      "index": 54,
      "vuln_id": "GHSA-278g-rq84-9hmg",
      "cwe_id": "{'CWE-20'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/d7de67733925de196ec8863a33445b73f9562d1d'}",
      "dataset": "osv",
      "summary": "`CHECK`-fail in `MapStage` ### Impact\nAn attacker can trigger a denial of service via a `CHECK`-fail in `tf.raw_ops.MapStage`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.MapStage(\n  key=tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64),\n  indices=tf.constant((0), dtype=tf.int32),\n  values=[tf.constant((0), dtype=tf.int32)],\n  dtypes=[tf.int32,\n  tf.int64],\n  capacity=0,\n  memory_limit=0,\n  container='',\n  shared_name='')\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/map_stage_op.cc#L513) does not check that the `key` input is a valid non-empty tensor.\n  \n### Patches\nWe have patched the issue in GitHub commit [d7de67733925de196ec8863a33445b73f9562d1d](https://github.com/tensorflow/tensorflow/commit/d7de67733925de196ec8863a33445b73f9562d1d).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security  guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/d7de67733925de196ec8863a33445b73f9562d1d",
      "commit_sha": "d7de67733925de196ec8863a33445b73f9562d1d",
      "patch": "SINGLE",
      "chain_ord": "['d7de67733925de196ec8863a33445b73f9562d1d']",
      "before_first_fix_commit": "{'102cacf28ad5a9e7f00b5a195d1995ead8870006'}",
      "last_fix_commit": "d7de67733925de196ec8863a33445b73f9562d1d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/30/2021, 05:23:46",
      "message": "Prevent a CHECK-fail due to empty tensor input in `map_stage_op.cc`\n\nPiperOrigin-RevId: 387737906\nChange-Id: Idc52df0c71c7ed6e2dd633b651a581932f277c8a",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'tensorflow/core/kernels/map_stage_op.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/d7de67733925de196ec8863a33445b73f9562d1d/tensorflow%2Fcore%2Fkernels%2Fmap_stage_op.cc', 'patch': '@@ -527,6 +527,8 @@ class MapStageOp : public OpKernel {\\n     OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\\n     OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\\n     OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\\n+    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\\n+                errors::InvalidArgument(\"key must not be empty\"));\\n \\n     // Create copy for insertion into Staging Area\\n     Tensor key(*key_tensor);'}}",
      "message_norm": "prevent a check-fail due to empty tensor input in `map_stage_op.cc`\n\npiperorigin-revid: 387737906\nchange-id: idc52df0c71c7ed6e2dd633b651a581932f277c8a",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('387737906', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/map_stage_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1410,
      "vuln_id": "GHSA-9p77-mmrw-69c7",
      "cwe_id": "{'CWE-476'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/8a513cec4bec15961fbfdedcaa5376522980455c'}",
      "dataset": "osv",
      "summary": "Null-dereference in Tensorflow ### Impact\nWhen decoding a tensor from protobuf, TensorFlow might do a null-dereference if attributes of some mutable arguments to some operations are missing from the proto. This is [guarded by a `DCHECK`](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/framework/full_type_util.cc#L104-L106):\n\n```cc\n  const auto* attr = attrs.Find(arg->s()); \n  DCHECK(attr != nullptr);\n  if (attr->value_case() == AttrValue::kList) {\n    // ...\n  }\n```\nHowever, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the dereferencing of the null pointer, whereas in the second case it results in a crash due to the assertion failure.\n\n### Patches\nWe have patched the issue in GitHub commit [8a513cec4bec15961fbfdedcaa5376522980455c](https://github.com/tensorflow/tensorflow/commit/8a513cec4bec15961fbfdedcaa5376522980455c).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/8a513cec4bec15961fbfdedcaa5376522980455c",
      "commit_sha": "8a513cec4bec15961fbfdedcaa5376522980455c",
      "patch": "SINGLE",
      "chain_ord": "['8a513cec4bec15961fbfdedcaa5376522980455c']",
      "before_first_fix_commit": "{'258112d838f008a632fe0dc43fc9ebecb9b0b869'}",
      "last_fix_commit": "8a513cec4bec15961fbfdedcaa5376522980455c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/08/2021, 18:35:47",
      "message": "Prevent null dereference read in `SpecializeType()`\n\nFor some adversarial protos, the attribute for a key might not exist.\n\nPiperOrigin-RevId: 408382090\nChange-Id: Ie7eabe532c9ff280fce5dce1f6cdb93c76c2e040",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 1, 'total': 7}",
      "files": "{'tensorflow/core/framework/full_type_util.cc': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/8a513cec4bec15961fbfdedcaa5376522980455c/tensorflow%2Fcore%2Fframework%2Ffull_type_util.cc', 'patch': '@@ -22,6 +22,7 @@ limitations under the License.\\n #include \"tensorflow/core/framework/op_def.pb.h\"\\n #include \"tensorflow/core/framework/types.h\"\\n #include \"tensorflow/core/platform/statusor.h\"\\n+#include \"tensorflow/core/protobuf/error_codes.pb.h\"\\n \\n namespace tensorflow {\\n \\n@@ -102,7 +103,11 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\\n       auto* arg = t->mutable_args(i);\\n       if (arg->type_id() == TFT_VAR) {\\n         const auto* attr = attrs.Find(arg->s());\\n-        DCHECK(attr != nullptr);\\n+        if (attr == nullptr) {\\n+          return Status(\\n+              error::INVALID_ARGUMENT,\\n+              absl::StrCat(\"Could not find an attribute for key \", arg->s()));\\n+        }\\n         if (attr->value_case() == AttrValue::kList) {\\n           const auto& attr_list = attr->list();\\n           arg->set_type_id(TFT_PRODUCT);'}}",
      "message_norm": "prevent null dereference read in `specializetype()`\n\nfor some adversarial protos, the attribute for a key might not exist.\n\npiperorigin-revid: 408382090\nchange-id: ie7eabe532c9ff280fce5dce1f6cdb93c76c2e040",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('null dereference', 'SECWORD', ''), ('adversarial', 'SECWORD', ''), ('key', 'SECWORD', ''), ('408382090', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/framework/full_type_util.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2087,
      "vuln_id": "GHSA-hjp8-2cm3-cc45",
      "cwe_id": "{'CWE-200'}",
      "score": 7.5,
      "chain": "{'https://github.com/fgribreau/node-request-retry/commit/0979c6001d9d57c2aac3157c11b007397158922a'}",
      "dataset": "osv",
      "summary": "Cookie exposure in requestretry Exposure of Sensitive Information to an Unauthorized Actor in GitHub repository fgribreau/node-request-retry prior to 7.0.0 via cookies being leaked to external sites.",
      "published_date": "2022-02-24",
      "chain_len": 1,
      "project": "https://github.com/fgribreau/node-request-retry",
      "commit_href": "https://github.com/fgribreau/node-request-retry/commit/0979c6001d9d57c2aac3157c11b007397158922a",
      "commit_sha": "0979c6001d9d57c2aac3157c11b007397158922a",
      "patch": "SINGLE",
      "chain_ord": "['0979c6001d9d57c2aac3157c11b007397158922a']",
      "before_first_fix_commit": "{'5e1a63c13c9b65ed927e8eb797d8cc7da0dae243'}",
      "last_fix_commit": "0979c6001d9d57c2aac3157c11b007397158922a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/15/2022, 20:20:12",
      "message": "Prevent Cookie & Authorization Headers from being forwarded when the URL redirects to another domain (information leak) #137",
      "author": "Timothee Desurmont",
      "comments": null,
      "stats": "{'additions': 39, 'deletions': 1, 'total': 40}",
      "files": "{'index.js': {'additions': 39, 'deletions': 1, 'changes': 40, 'status': 'modified', 'raw_url': 'https://github.com/FGRibreau/node-request-retry/raw/0979c6001d9d57c2aac3157c11b007397158922a/index.js', 'patch': '@@ -11,6 +11,8 @@ var extend = require(\\'extend\\');\\n var request = require(\\'request\\');\\n var RetryStrategies = require(\\'./strategies\\');\\n var _ = require(\\'lodash\\');\\n+var url = require(\\'url\\');\\n+var querystring = require(\"querystring\");\\n \\n var DEFAULTS = {\\n   maxAttempts: 5, // try 5 times\\n@@ -24,6 +26,42 @@ function defaultPromiseFactory(resolver) {\\n   return new Promise(resolver);\\n }\\n \\n+// Prevent Cookie & Authorization Headers from being forwarded \\n+// when the URL redirects to another domain (information leak) #137 \\n+function sanitizeHeaders(options) {\\n+  \\n+  const HEADERS_TO_IGNORE = [\"cookie\", \"authorization\"];\\n+\\n+  const urlObject = url.parse(options.url)\\n+  const queryObject = querystring.parse(urlObject.query);\\n+  \\n+  const hasExternalLink = Object.keys(queryObject).reduce(function(acc, cur) {\\n+    \\n+    let qUrl = url.parse(queryObject[cur]);\\n+\\n+    // external link if protocol || host || port is different\\n+    if(!!qUrl.host && (qUrl.protocol !== urlObject.protocol || qUrl.host !== urlObject.host || qUrl.port !== urlObject.port) ) {\\n+      acc = true;\\n+    }\\n+    \\n+    return acc;\\n+\\n+  }, false);\\n+\\n+  if (hasExternalLink && options.hasOwnProperty(\"headers\") && typeof(options.headers) === \"object\") {\\n+    \\n+    // if External Link: remove Cookie and Authorization from Headers\\n+    Object.keys(options.headers).filter(function(key) {\\n+      return HEADERS_TO_IGNORE.includes(key.toLowerCase())\\n+    }).map(function(key) {\\n+      return delete options.headers[key]\\n+    });\\n+\\n+  }\\n+\\n+  return options;\\n+}\\n+\\n function _cloneOptions(options) {\\n   const cloned = {};\\n   for (let key in options) {\\n@@ -85,7 +123,7 @@ function Request(url, options, f, retryConfig) {\\n    * Option object\\n    * @type {Object}\\n    */\\n-  this.options = options;\\n+  this.options = sanitizeHeaders(options);\\n \\n   /**\\n    * Return true if the request should be retried'}}",
      "message_norm": "prevent cookie & authorization headers from being forwarded when the url redirects to another domain (information leak) #137",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('cookie', 'SECWORD', ''), ('information leak', 'SECWORD', ''), ('#137', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 411,
      "vuln_id": "GHSA-4f99-p9c2-3j8x",
      "cwe_id": "{'CWE-125', 'CWE-824'}",
      "score": 7.8,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae'}",
      "dataset": "osv",
      "summary": "Undefined behavior via `nullptr` reference binding in sparse matrix multiplication ### Impact\nThe [code for sparse matrix multiplication](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/sparse_matmul_op.cc#L954-L1086) is vulnerable to undefined behavior via binding a reference to `nullptr`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.SparseMatMul(\n  a=[[1.0,1.0,1.0]],\n  b=[[],[],[]],\n  transpose_a=False,\n  transpose_b=False,\n  a_is_sparse=False, \n  b_is_sparse=True)\n```\n\nThis occurs whenever the dimensions of `a` or `b` are 0 or less. In the case on one of these is 0, an empty output tensor should be allocated (to conserve the invariant that output tensors are always allocated when the operation is successful) but nothing should be written to it (that is, we should return early from the kernel implementation). Otherwise, attempts to write to this empty tensor would result in heap OOB access.\n\n### Patches\nWe have patched the issue in GitHub commit [e6cf28c72ba2eb949ca950d834dd6d66bb01cfae](https://github.com/tensorflow/tensorflow/commit/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-11-10",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
      "commit_sha": "e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
      "patch": "SINGLE",
      "chain_ord": "['e6cf28c72ba2eb949ca950d834dd6d66bb01cfae']",
      "before_first_fix_commit": "{'d4fdd7830befb1f3aed8b4d1681471531856ae77'}",
      "last_fix_commit": "e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/06/2021, 04:54:15",
      "message": "Validate that matrix dimension sizes in SparseMatMul are positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d",
      "author": "Penporn Koanantakool",
      "comments": null,
      "stats": "{'additions': 10, 'deletions': 0, 'total': 10}",
      "files": "{'tensorflow/core/kernels/sparse_matmul_op.cc': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae/tensorflow%2Fcore%2Fkernels%2Fsparse_matmul_op.cc', 'patch': '@@ -32,6 +32,7 @@ limitations under the License.\\n #include \"tensorflow/core/kernels/fill_functor.h\"\\n #include \"tensorflow/core/lib/core/blocking_counter.h\"\\n #include \"tensorflow/core/lib/core/threadpool.h\"\\n+#include \"tensorflow/core/platform/errors.h\"\\n #include \"tensorflow/core/platform/logging.h\"\\n #include \"tensorflow/core/platform/macros.h\"\\n #include \"tensorflow/core/platform/mutex.h\"\\n@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {\\n                 errors::InvalidArgument(\\n                     \"Matrix size incompatible: a: \", a.shape().DebugString(),\\n                     \", b: \", b.shape().DebugString()));\\n+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\\n+                errors::InvalidArgument(\\n+                    \"Matrix dimensions cannot be negative: a: \",\\n+                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\\n \\n+    // Return early if at least one of the output dimension size is 0.\\n+    if (m == 0 || n == 0) {\\n+      return;\\n+    }\\n+\\n     if (k == 0) {\\n       // If the inner dimension k in the matrix multiplication is zero, we fill\\n       // the output with zeros.'}}",
      "message_norm": "validate that matrix dimension sizes in sparsematmul are positive.\n\npiperorigin-revid: 401149683\nchange-id: ib33eafc561a39c8741ece80b2edce6d4aae9a57d",
      "language": "en",
      "entities": "[('validate', 'ACTION', ''), ('401149683', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_matmul_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 464,
      "vuln_id": "GHSA-4qwp-7c67-jmcc",
      "cwe_id": "{'CWE-94'}",
      "score": 9.8,
      "chain": "{'https://github.com/facade/ignition/commit/11ffca14abd22db779d90b12e193f8000f6d184b'}",
      "dataset": "osv",
      "summary": "Unauthenticated remote code execution in Ignition Ignition before 2.5.2, as used in Laravel and other products, allows unauthenticated remote attackers to execute arbitrary code because of insecure usage of file_get_contents() and file_put_contents(). This is exploitable on sites using debug mode with Laravel before 8.4.2.",
      "published_date": "2021-03-29",
      "chain_len": 1,
      "project": "https://github.com/facade/ignition",
      "commit_href": "https://github.com/facade/ignition/commit/11ffca14abd22db779d90b12e193f8000f6d184b",
      "commit_sha": "11ffca14abd22db779d90b12e193f8000f6d184b",
      "patch": "SINGLE",
      "chain_ord": "['11ffca14abd22db779d90b12e193f8000f6d184b']",
      "before_first_fix_commit": "{'9fc6c3d3de5271a1b94cff19dce2c9295abf0ffa'}",
      "last_fix_commit": "11ffca14abd22db779d90b12e193f8000f6d184b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/18/2021, 11:46:18",
      "message": "Fix MakeViewVariableOptionalSolution to disallow stream wrappers and files that do not end in .blade.php\n\nThis is already fixed in 2.5.2, See https://github.com/facade/ignition/pull/334\n\nI could not update to 2.5.2 due to some dependent package required php 7.3, currently clients site is running in php 7.2\n\nOn branch 2.4.1-branch\nChanges to be committed:\n\tmodified:   src/Solutions/MakeViewVariableOptionalSolution.php",
      "author": "Anas Mirza",
      "comments": null,
      "stats": "{'additions': 18, 'deletions': 0, 'total': 18}",
      "files": "{'src/Solutions/MakeViewVariableOptionalSolution.php': {'additions': 18, 'deletions': 0, 'changes': 18, 'status': 'modified', 'raw_url': 'https://github.com/facade/ignition/raw/11ffca14abd22db779d90b12e193f8000f6d184b/src%2FSolutions%2FMakeViewVariableOptionalSolution.php', 'patch': '@@ -4,6 +4,7 @@\\n \\n use Facade\\\\IgnitionContracts\\\\RunnableSolution;\\n use Illuminate\\\\Support\\\\Facades\\\\Blade;\\n+use Illuminate\\\\Support\\\\Str;\\n \\n class MakeViewVariableOptionalSolution implements RunnableSolution\\n {\\n@@ -70,8 +71,25 @@ public function run(array $parameters = [])\\n         }\\n     }\\n \\n+    protected function isSafePath(string $path): bool\\n+    {\\n+        if (!Str::startsWith($path, [\\'/\\', \\'./\\'])) {\\n+            return false;\\n+        }\\n+\\n+        if (!Str::endsWith($path, \\'.blade.php\\')) {\\n+            return false;\\n+        }\\n+\\n+        return true;\\n+    }\\n+\\n     public function makeOptional(array $parameters = [])\\n     {\\n+        if (!$this->isSafePath($parameters[\\'viewFile\\'])) {\\n+            return false;\\n+        }\\n+\\n         $originalContents = file_get_contents($parameters[\\'viewFile\\']);\\n         $newContents = str_replace(\\'$\\'.$parameters[\\'variableName\\'], \\'$\\'.$parameters[\\'variableName\\'].\" ?? \\'\\'\", $originalContents);'}}",
      "message_norm": "fix makeviewvariableoptionalsolution to disallow stream wrappers and files that do not end in .blade.php\n\nthis is already fixed in 2.5.2, see https://github.com/facade/ignition/pull/334\n\ni could not update to 2.5.2 due to some dependent package required php 7.3, currently clients site is running in php 7.2\n\non branch 2.4.1-branch\nchanges to be committed:\n\tmodified:   src/solutions/makeviewvariableoptionalsolution.php",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('fixed', 'ACTION', ''), ('2.5.2', 'VERSION', ''), ('https://github.com/facade/ignition/pull/334', 'URL', ''), ('update', 'ACTION', ''), ('2.5.2', 'VERSION', ''), ('2.4.1', 'VERSION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Solutions/MakeViewVariableOptionalSolution.php'])",
      "num_files": 1.0
    },
    {
      "index": 836,
      "vuln_id": "GHSA-6gmv-pjp9-p8w8",
      "cwe_id": "{'CWE-125'}",
      "score": 8.1,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/37c01fb5e25c3d80213060460196406c43d31995'}",
      "dataset": "osv",
      "summary": "Out of bounds read in Tensorflow ### Impact \nThe [implementation of shape inference for `ReverseSequence`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/ops/array_ops.cc#L1636-L1671) does not fully validate the value of `batch_dim` and can result in a heap OOB read:\n\n```python\nimport tensorflow as tf\n\n@tf.function\ndef test():\n  y = tf.raw_ops.ReverseSequence(\n    input = ['aaa','bbb'],\n    seq_lengths = [1,1,1],\n    seq_dim = -10,\n    batch_dim = -10 )\n  return y\n    \ntest()\n```\n\nThere is a check to make sure the value of `batch_dim` does not go over the rank of the input, but there is no check for negative values:\n\n```cc\n  const int32_t input_rank = c->Rank(input);\n  if (batch_dim >= input_rank) {\n    return errors::InvalidArgument( \n        \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\n  }\n  // ...\n  \n  DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\n``` \n    \nNegative dimensions are allowed in some cases to mimic Python's negative indexing (i.e., indexing from the end of the array), however if the value is too negative then [the implementation of `Dim`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/shape_inference.h#L415-L428) would access elements before the start of an array:\n\n```cc\n  DimensionHandle Dim(ShapeHandle s, int64_t idx) {\n    if (!s.Handle() || s->rank_ == kUnknownRank) {\n      return UnknownDim();\n    }\n    return DimKnownRank(s, idx);\n  } \n\u00b7\n  static DimensionHandle DimKnownRank(ShapeHandle s, int64_t idx) {\n    CHECK_NE(s->rank_, kUnknownRank);\n    if (idx < 0) {\n      return s->dims_[s->dims_.size() + idx];\n    }\n    return s->dims_[idx];\n  }\n```\n\n### Patches\nWe have patched the issue in GitHub commit [37c01fb5e25c3d80213060460196406c43d31995](https://github.com/tensorflow/tensorflow/commit/37c01fb5e25c3d80213060460196406c43d31995).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yu Tian of Qihoo 360 AIVul Team.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/37c01fb5e25c3d80213060460196406c43d31995",
      "commit_sha": "37c01fb5e25c3d80213060460196406c43d31995",
      "patch": "SINGLE",
      "chain_ord": "['37c01fb5e25c3d80213060460196406c43d31995']",
      "before_first_fix_commit": "{'3218043d6d3a019756607643cf65574fbfef5d7a'}",
      "last_fix_commit": "37c01fb5e25c3d80213060460196406c43d31995",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/23/2021, 22:27:30",
      "message": "Fix out of bound error in ReverseSequence Op shape function\n\nPiperOrigin-RevId: 411896080\nChange-Id: I7e59a38e2f960886edf2b6c54ed5a84e86a9b193",
      "author": "Isha Arkatkar",
      "comments": null,
      "stats": "{'additions': 10, 'deletions': 0, 'total': 10}",
      "files": "{'tensorflow/core/ops/array_ops.cc': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/37c01fb5e25c3d80213060460196406c43d31995/tensorflow%2Fcore%2Fops%2Farray_ops.cc', 'patch': '@@ -1653,11 +1653,21 @@ REGISTER_OP(\"ReverseSequence\")\\n         return errors::InvalidArgument(\\n             \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\\n       }\\n+\\n       if (seq_dim >= input_rank) {\\n         return errors::InvalidArgument(\\n             \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);\\n       }\\n \\n+      // To prevent out of bound access when calling c->Dim(input, batch_dim),\\n+      // batch_dim range [-1 * input rank, input rank) is allowed. However,\\n+      // the op implementation has a stricter bound for batch_dim requiring >= 0\\n+      // value. Thus, perform strict check here.\\n+      if (batch_dim < 0) {\\n+        return errors::InvalidArgument(\"batch_dim must be >=0, got \",\\n+                                       batch_dim);\\n+      }\\n+\\n       DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\\n       TF_RETURN_IF_ERROR(\\n           c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));'}}",
      "message_norm": "fix out of bound error in reversesequence op shape function\n\npiperorigin-revid: 411896080\nchange-id: i7e59a38e2f960886edf2b6c54ed5a84e86a9b193",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('out of bound', 'SECWORD', ''), ('error', 'FLAW', ''), ('411896080', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/ops/array_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2729,
      "vuln_id": "GHSA-q9p4-qfc8-fvpp",
      "cwe_id": "{'CWE-89'}",
      "score": 9.8,
      "chain": "{'https://github.com/catfan/Medoo/commit/659864b393961bf224bba1efc03b7dcbed7de533'}",
      "dataset": "osv",
      "summary": "SQL Injection in medoo columnQuote in medoo before 1.7.5 allows remote attackers to perform a SQL Injection due to improper escaping.",
      "published_date": "2021-10-12",
      "chain_len": 1,
      "project": "https://github.com/catfan/Medoo",
      "commit_href": "https://github.com/catfan/Medoo/commit/659864b393961bf224bba1efc03b7dcbed7de533",
      "commit_sha": "659864b393961bf224bba1efc03b7dcbed7de533",
      "patch": "SINGLE",
      "chain_ord": "['659864b393961bf224bba1efc03b7dcbed7de533']",
      "before_first_fix_commit": "{'b3f05edf256d63ec3cfd31d6a078c564daf9863d'}",
      "last_fix_commit": "659864b393961bf224bba1efc03b7dcbed7de533",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/11/2019, 15:50:40",
      "message": "[fix] Fix columnQuote for \bsecurity issue reported by Snyk",
      "author": "Angel Lai",
      "comments": "{'com_1': {'author': 'jfcherng', 'datetime': '10/12/2019, 11:57:36', 'body': \"It's perfect valid to use `_` in a column name and I believe it's used quite often. This change would make `v1.7.4` literally unusable for most of people.\\r\\n\\r\\nNot sure about other SQL standard. For MySQL, it's valid to use some of UTF-8 chars as the column name.\\r\\nhttps://dev.mysql.com/doc/refman/8.0/en/identifiers.html\"}, 'com_2': {'author': 'catfan', 'datetime': '10/12/2019, 13:18:09', 'body': \"Thanks for this great spot. The `_` should be added. Although it's possible to use UTF-8 chars for column name, it may have some problem for some databases. Using `a-zA-Z0-9_` is enough for most case.\"}}",
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'src/Medoo.php': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/catfan/Medoo/raw/659864b393961bf224bba1efc03b7dcbed7de533/src%2FMedoo.php', 'patch': '@@ -500,6 +500,11 @@ protected function typeMap($value, $type)\\n \\n \\tprotected function columnQuote($string)\\n \\t{\\n+\\t\\tif (!preg_match(\\'/^[a-zA-Z0-9]+(\\\\.?[a-zA-Z0-9]+)?$/i\\', $string))\\n+\\t\\t{\\n+\\t\\t\\tthrow new InvalidArgumentException(\"Incorrect column name \\\\\"$string\\\\\"\");\\n+\\t\\t}\\n+\\n \\t\\tif (strpos($string, \\'.\\') !== false)\\n \\t\\t{\\n \\t\\t\\treturn \\'\"\\' . $this->prefix . str_replace(\\'.\\', \\'\".\"\\', $string) . \\'\"\\';'}}",
      "message_norm": "[fix] fix columnquote for \bsecurity issue reported by snyk",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('fix', 'ACTION', ''), ('\\x08security', 'SECWORD', ''), ('issue', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Medoo.php'])",
      "num_files": 1.0
    },
    {
      "index": 2725,
      "vuln_id": "GHSA-q97v-764g-r2rp",
      "cwe_id": "{'CWE-284'}",
      "score": 8.8,
      "chain": "{'https://github.com/gollum/grit_adapter/commit/4520d973c81fecfebbeacd2ef2f1849d763951c7'}",
      "dataset": "osv",
      "summary": "High severity vulnerability that affects gollum and gollum-lib The gollum-grit_adapter Ruby gem dependency in gollum before 3.1.1 and the gollum-lib gem dependency in gollum-lib before 4.0.1 when the string \"master\" is in any of the wiki documents, allows remote authenticated users to execute arbitrary code via the -O or --open-files-in-pager flags.",
      "published_date": "2017-11-16",
      "chain_len": 1,
      "project": "https://github.com/gollum/grit_adapter",
      "commit_href": "https://github.com/gollum/grit_adapter/commit/4520d973c81fecfebbeacd2ef2f1849d763951c7",
      "commit_sha": "4520d973c81fecfebbeacd2ef2f1849d763951c7",
      "patch": "SINGLE",
      "chain_ord": "['4520d973c81fecfebbeacd2ef2f1849d763951c7']",
      "before_first_fix_commit": "{'1b04ba5a1e822a990d6bde99b7332eef56a9998c'}",
      "last_fix_commit": "4520d973c81fecfebbeacd2ef2f1849d763951c7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/04/2014, 12:45:17",
      "message": "Fix security issue with git grep -O",
      "author": "Dawa Ometto",
      "comments": "{'com_1': {'author': 'dometto', 'datetime': '12/04/2014, 13:53:01', 'body': 'Escape the `ls_files` query for good measure.'}}",
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'lib/grit_adapter/git_layer_grit.rb': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/gollum/grit_adapter/raw/4520d973c81fecfebbeacd2ef2f1849d763951c7/lib%2Fgrit_adapter%2Fgit_layer_grit.rb', 'patch': '@@ -136,6 +136,8 @@ def exist?\\n       \\n       def grep(query, options={})\\n         ref = options[:ref] ? options[:ref] : \"HEAD\"\\n+        query = Shellwords.split(query).select {|q| !(q =~ /^(-O)|(--open-files-in-pager)/) }\\n+        query = Shellwords.join(query)\\n         args = [{}, \\'-I\\', \\'-i\\', \\'-c\\', query, ref, \\'--\\']\\n         args << options[:path] if options[:path]\\n         result = @git.grep(*args).split(\"\\\\n\")\\n@@ -165,6 +167,7 @@ def rev_list(options, *refs)\\n       \\n       def ls_files(query, options = {})\\n         options[:ref] = options[:ref] ? options[:ref] : \"HEAD\"\\n+        query = Shellwords.shellescape(query)\\n         @git.ls_files({}, \"*#{query}*\").split(\"\\\\n\")\\n       end'}}",
      "message_norm": "fix security issue with git grep -o",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/grit_adapter/git_layer_grit.rb'])",
      "num_files": 1.0
    },
    {
      "index": 3407,
      "vuln_id": "GHSA-xc47-3rch-cv57",
      "cwe_id": "{'CWE-284'}",
      "score": 5.4,
      "chain": "{'https://github.com/snipe/snipe-it/commit/0e5ef53c352754de2778ffa20c85da15fd6f7ae0'}",
      "dataset": "osv",
      "summary": "Improper Access Control in snipe-it Users with no system permissions are able to see and create personal access tokens",
      "published_date": "2022-01-26",
      "chain_len": 1,
      "project": "https://github.com/snipe/snipe-it",
      "commit_href": "https://github.com/snipe/snipe-it/commit/0e5ef53c352754de2778ffa20c85da15fd6f7ae0",
      "commit_sha": "0e5ef53c352754de2778ffa20c85da15fd6f7ae0",
      "patch": "SINGLE",
      "chain_ord": "['0e5ef53c352754de2778ffa20c85da15fd6f7ae0']",
      "before_first_fix_commit": "{'512dbfee7acfcafa1524c8b2fb4cc4ef96958d0b', 'eb8f23a888ccb2dc53a11c6dd240cbe8373500aa'}",
      "last_fix_commit": "0e5ef53c352754de2778ffa20c85da15fd6f7ae0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/13/2022, 09:36:52",
      "message": "Merge pull request #10504 from snipe/fixes/auth_controls_on_api_key_creation\n\nFixes auth controls on api key creation",
      "author": "snipe",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'app/Http/Controllers/ProfileController.php': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/snipe/snipe-it/raw/0e5ef53c352754de2778ffa20c85da15fd6f7ae0/app%2FHttp%2FControllers%2FProfileController.php', 'patch': \"@@ -113,6 +113,12 @@ public function postIndex(ImageUploadRequest $request)\\n      */\\n     public function api()\\n     {\\n+\\n+        // Make sure the self.api permission has been granted\\n+        if (!Gate::allows('self.api')) {\\n+            abort(403);\\n+        }\\n+\\n         return view('account/api');\\n     }\"}}",
      "message_norm": "merge pull request #10504 from snipe/fixes/auth_controls_on_api_key_creation\n\nfixes auth controls on api key creation",
      "language": "en",
      "entities": "[('#10504', 'ISSUE', ''), ('auth_controls_on_api_key_creation', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('auth', 'SECWORD', ''), ('key', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['app/Http/Controllers/ProfileController.php'])",
      "num_files": 1.0
    },
    {
      "index": 436,
      "vuln_id": "GHSA-4hvf-hxvg-f67v",
      "cwe_id": "{'CWE-787', 'CWE-125'}",
      "score": 8.8,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/6364463d6f5b6254cac3d6aedf999b6a96225038'}",
      "dataset": "osv",
      "summary": "Read and Write outside of bounds in TensorFlow ### Impact\nAn attacker can craft a TFLite model that would allow limited reads and writes outside of arrays in TFLite. This exploits missing validation in [the conversion from sparse tensors to dense tensors](https://github.com/tensorflow/tensorflow/blob/ca6f96b62ad84207fbec580404eaa7dd7403a550/tensorflow/lite/kernels/internal/utils/sparsity_format_converter.cc#L252-L293).\n\n### Patches\nWe have patched the issue in GitHub commit [6364463d6f5b6254cac3d6aedf999b6a96225038](https://github.com/tensorflow/tensorflow/commit/6364463d6f5b6254cac3d6aedf999b6a96225038).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/6364463d6f5b6254cac3d6aedf999b6a96225038",
      "commit_sha": "6364463d6f5b6254cac3d6aedf999b6a96225038",
      "patch": "SINGLE",
      "chain_ord": "['6364463d6f5b6254cac3d6aedf999b6a96225038']",
      "before_first_fix_commit": "{'3e49ff637ad4f05c133d235a568943d19216fa9a'}",
      "last_fix_commit": "6364463d6f5b6254cac3d6aedf999b6a96225038",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/16/2021, 23:37:14",
      "message": "[lite] Add some safety checks to avoid out of bound access for sparsity format\n\nPiperOrigin-RevId: 416910386\nChange-Id: Ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
      "author": "Karim Nosir",
      "comments": null,
      "stats": "{'additions': 11, 'deletions': 7, 'total': 18}",
      "files": "{'tensorflow/lite/kernels/internal/utils/sparsity_format_converter.cc': {'additions': 11, 'deletions': 7, 'changes': 18, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/6364463d6f5b6254cac3d6aedf999b6a96225038/tensorflow%2Flite%2Fkernels%2Finternal%2Futils%2Fsparsity_format_converter.cc', 'patch': '@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\\n   block_size_.resize(block_map_.size());\\n   for (int i = 0; i < original_rank; i++) {\\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\\n-      int orig_dim = traversal_order_[original_rank + block_dim];\\n-      block_size_[block_dim] = dense_size[orig_dim];\\n-      blocked_shape_[i] = dense_shape_[i] / dense_size[orig_dim];\\n-      block_dim++;\\n+      if (original_rank + block_dim < traversal_order_.size()) {\\n+        int orig_dim = traversal_order_[original_rank + block_dim];\\n+        block_size_[block_dim] = dense_size[orig_dim];\\n+        blocked_shape_[i] = dense_shape_[i] / dense_size[orig_dim];\\n+        block_dim++;\\n+      }\\n     } else {\\n       blocked_shape_[i] = dense_shape_[i];\\n     }\\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\\n                src_data_ptr, dest_data);\\n     }\\n-  } else {\\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\\n     const auto& array_segments = dim_metadata_[metadata_idx];\\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\\n          i++) {\\n-      indices[level] = array_indices[i];\\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      if (i < array_indices.size() && level < indices.size()) {\\n+        indices[level] = array_indices[i];\\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      }\\n     }\\n   }\\n }'}}",
      "message_norm": "[lite] add some safety checks to avoid out of bound access for sparsity format\n\npiperorigin-revid: 416910386\nchange-id: ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('safety checks', 'SECWORD', ''), ('out of bound access', 'SECWORD', ''), ('416910386', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/internal/utils/sparsity_format_converter.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1234,
      "vuln_id": "GHSA-8p5c-f328-9fvv",
      "cwe_id": "{'CWE-22'}",
      "score": 9.8,
      "chain": "{'https://github.com/anthraxx/diffoscope/commit/632a40828a54b399787c25e7fa243f732aef7e05'}",
      "dataset": "osv",
      "summary": "Diffoscope may write to arbitrary locations due to an untrusted archive diffoscope before 76 writes to arbitrary locations on disk based on the contents of an untrusted archive.",
      "published_date": "2018-07-13",
      "chain_len": 1,
      "project": "https://github.com/anthraxx/diffoscope",
      "commit_href": "https://github.com/anthraxx/diffoscope/commit/632a40828a54b399787c25e7fa243f732aef7e05",
      "commit_sha": "632a40828a54b399787c25e7fa243f732aef7e05",
      "patch": "SINGLE",
      "chain_ord": "['632a40828a54b399787c25e7fa243f732aef7e05']",
      "before_first_fix_commit": "{'b468a2840a097f4b2f7719929d690d5738dbcae4'}",
      "last_fix_commit": "632a40828a54b399787c25e7fa243f732aef7e05",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/09/2017, 21:47:05",
      "message": "Extract archive members using an auto-incrementing integer, avoiding the need to sanitise filenames. (Closes: #854723)\n\nSigned-off-by: Chris Lamb <lamby@debian.org>",
      "author": "Chris Lamb",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 27, 'total': 41}",
      "files": "{'diffoscope/comparators/utils/libarchive.py': {'additions': 14, 'deletions': 27, 'changes': 41, 'status': 'modified', 'raw_url': 'https://github.com/anthraxx/diffoscope/raw/632a40828a54b399787c25e7fa243f732aef7e05/diffoscope%2Fcomparators%2Futils%2Flibarchive.py', 'patch': '@@ -23,6 +23,7 @@\\n import ctypes\\n import logging\\n import libarchive\\n+import collections\\n \\n from diffoscope.tempfiles import get_temporary_directory\\n \\n@@ -168,11 +169,11 @@ def close_archive(self):\\n \\n     def get_member_names(self):\\n         self.ensure_unpacked()\\n-        return self._member_names\\n+        return self._members.keys()\\n \\n     def extract(self, member_name, dest_dir):\\n         self.ensure_unpacked()\\n-        return os.path.join(self._unpacked, member_name)\\n+        return self._members[member_name]\\n \\n     def get_member(self, member_name):\\n         with libarchive.file_reader(self.source.path) as archive:\\n@@ -197,45 +198,31 @@ def get_subclass(self, entry):\\n         return LibarchiveMember(self, entry)\\n \\n     def ensure_unpacked(self):\\n-        if hasattr(self, \\'_unpacked\\'):\\n+        if hasattr(self, \\'_members\\'):\\n             return\\n \\n-        self._unpacked = get_temporary_directory().name\\n-        self._member_names = []\\n+        tmpdir = get_temporary_directory().name\\n+        self._members = collections.OrderedDict()\\n \\n-        logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)\\n+        logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)\\n \\n         with libarchive.file_reader(self.source.path) as archive:\\n-            for entry in archive:\\n-                self._member_names.append(entry.pathname)\\n+            for idx, entry in enumerate(archive):\\n+                # Maintain a mapping of archive path to the extracted path,\\n+                # avoiding the need to sanitise filenames.\\n+                dst = os.path.join(tmpdir, \\'{}\\'.format(idx))\\n+                self._members[entry.pathname] = dst\\n \\n                 if entry.isdir:\\n                     continue\\n \\n-                # All extracted locations must be underneath self._unpacked\\n-                force_prefix = os.path.join(self._unpacked, \"\")\\n-\\n-                # Try to pick a safe and reasonable candidate name\\n-                candidate_name = os.path.normpath(entry.pathname.rstrip(\\'/\\' + os.sep))\\n-                if os.path.isabs(candidate_name):\\n-                    candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))\\n-\\n-                dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))\\n-                if not dst.startswith(force_prefix):\\n-                    logger.warn(\"Skipping member because we could not make a safe name to extract it to: \\'%s\\'\",\\n-                                entry.pathname)\\n-                    continue\\n-\\n-                # TODO: need to fix reading these cleaned members. currently\\n-                # reading will still try to use the uncleaned name.\\n-                #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)\\n-                os.makedirs(os.path.dirname(dst), exist_ok=True)\\n+                logger.debug(\"Extracting %s to %s\", entry.pathname, dst)\\n \\n                 with open(dst, \\'wb\\') as f:\\n                     for block in entry.get_blocks():\\n                         f.write(block)\\n \\n         logger.debug(\\n             \"Extracted %d entries from %s to %s\",\\n-            len(self._member_names), self.source.path, self._unpacked,\\n+            len(self._members), self.source.path, tmpdir,\\n         )'}}",
      "message_norm": "extract archive members using an auto-incrementing integer, avoiding the need to sanitise filenames. (closes: #854723)\n\nsigned-off-by: chris lamb <lamby@debian.org>",
      "language": "en",
      "entities": "[('sanitise', 'SECWORD', ''), ('#854723', 'ISSUE', ''), ('lamby@debian.org', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['diffoscope/comparators/utils/libarchive.py'])",
      "num_files": 1.0
    },
    {
      "index": 3225,
      "vuln_id": "GHSA-w4xf-2pqw-5mq7",
      "cwe_id": "{'CWE-824'}",
      "score": 7.8,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/be7a4de6adfbd303ce08be4332554dff70362612'}",
      "dataset": "osv",
      "summary": "Reference binding to nullptr in `RaggedTensorToVariant` ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToVariant`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedTensorToVariant(\n  rt_nested_splits=[],\n  rt_dense_values=[1,2,3],\n  batched_input=True)\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc#L129) has an incomplete validation of the splits values, missing the case when the argument would be empty.\n\n### Patches\nWe have patched the issue in GitHub commit [be7a4de6adfbd303ce08be4332554dff70362612](https://github.com/tensorflow/tensorflow/commit/be7a4de6adfbd303ce08be4332554dff70362612).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/be7a4de6adfbd303ce08be4332554dff70362612",
      "commit_sha": "be7a4de6adfbd303ce08be4332554dff70362612",
      "patch": "SINGLE",
      "chain_ord": "['be7a4de6adfbd303ce08be4332554dff70362612']",
      "before_first_fix_commit": "{'ffbdacfce0c9c8f627d0ce89d9d4db8fd0a7cfd1'}",
      "last_fix_commit": "be7a4de6adfbd303ce08be4332554dff70362612",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/29/2021, 21:05:34",
      "message": "Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant\n\nPiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'tensorflow/core/kernels/ragged_tensor_to_variant_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/be7a4de6adfbd303ce08be4332554dff70362612/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_variant_op.cc', 'patch': '@@ -157,6 +157,12 @@ class RaggedTensorToVariantOp : public OpKernel {\\n       return;\\n     }\\n \\n+    // Checked here instead of at input in case batched_input_ is false\\n+    OP_REQUIRES(context, ragged_nested_splits_len > 0,\\n+                errors::InvalidArgument(\\n+                    \"rt_nested_splits must be a list of one or more, but \"\\n+                    \"received rt_nested_splits of length 0.\"));\\n+\\n     // Unbatch the Ragged Tensor and encode the components.\\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\\n     auto batched_splits_top_vec ='}}",
      "message_norm": "ensure non-empty rt_nested_splits in tf.raw_ops.raggedtensortovariant\n\npiperorigin-revid: 387664237\nchange-id: ia1700c34b5610873d63561abc86e23b46ead93b3",
      "language": "en",
      "entities": "[('ensure', 'ACTION', ''), ('387664237', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/ragged_tensor_to_variant_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1518,
      "vuln_id": "GHSA-c94w-c95p-phf8",
      "cwe_id": "{'CWE-190'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/fcd18ce3101f245b083b30655c27b239dc72221e'}",
      "dataset": "osv",
      "summary": "Integer overflow in Tensorflow ### Impact\nThe [implementation of `OpLevelCostEstimator::CalculateTensorSize`](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/grappler/costs/op_level_cost_estimator.cc#L1552-L1558) is vulnerable to an integer overflow if an attacker can create an operation which would involve a tensor with large enough number of elements:\n```cc\nint64_t OpLevelCostEstimator::CalculateTensorSize(\n    const OpInfo::TensorProperties& tensor, bool* found_unknown_shapes) {\n  int64_t count = CalculateTensorElementCount(tensor, found_unknown_shapes);\n  int size = DataTypeSize(BaseType(tensor.dtype()));\n  VLOG(2) << \"Count: \" << count << \" DataTypeSize: \" << size;\n  return count * size;\n}\n```\nHere, `count` and `size` can be large enough to cause `count * size` to overflow.\n\n### Patches\nWe have patched the issue in GitHub commit [fcd18ce3101f245b083b30655c27b239dc72221e](https://github.com/tensorflow/tensorflow/commit/fcd18ce3101f245b083b30655c27b239dc72221e).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-10",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/fcd18ce3101f245b083b30655c27b239dc72221e",
      "commit_sha": "fcd18ce3101f245b083b30655c27b239dc72221e",
      "patch": "SINGLE",
      "chain_ord": "['fcd18ce3101f245b083b30655c27b239dc72221e']",
      "before_first_fix_commit": "{'29e899868d77d8f575907515acefa012c5574246'}",
      "last_fix_commit": "fcd18ce3101f245b083b30655c27b239dc72221e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/09/2021, 22:54:52",
      "message": "Prevent integer overflow in `OpLevelCostEstimator::CalculateTensorSize`.\n\nIn order to not change the API, we return a negative value in case of overflow. A better fix is to change the API to return a status instead.\n\nPiperOrigin-RevId: 408713061\nChange-Id: I3771475b0c72a2844a3854086966562fd33f2da5",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 1, 'total': 8}",
      "files": "{'tensorflow/core/grappler/costs/op_level_cost_estimator.cc': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/fcd18ce3101f245b083b30655c27b239dc72221e/tensorflow%2Fcore%2Fgrappler%2Fcosts%2Fop_level_cost_estimator.cc', 'patch': '@@ -1555,7 +1555,13 @@ int64_t OpLevelCostEstimator::CalculateTensorSize(\\n   int64_t count = CalculateTensorElementCount(tensor, found_unknown_shapes);\\n   int size = DataTypeSize(BaseType(tensor.dtype()));\\n   VLOG(2) << \"Count: \" << count << \" DataTypeSize: \" << size;\\n-  return count * size;\\n+  int64_t tensor_size = MultiplyWithoutOverflow(count, size);\\n+  if (tensor_size < 0) {\\n+    VLOG(1) << \"Overflow encountered when computing tensor size, multiplying \"\\n+            << count << \" with \" << size;\\n+    return -1;\\n+  }\\n+  return tensor_size;\\n }\\n \\n int64_t OpLevelCostEstimator::CalculateInputSize(const OpInfo& op_info,'}}",
      "message_norm": "prevent integer overflow in `oplevelcostestimator::calculatetensorsize`.\n\nin order to not change the api, we return a negative value in case of overflow. a better fix is to change the api to return a status instead.\n\npiperorigin-revid: 408713061\nchange-id: i3771475b0c72a2844a3854086966562fd33f2da5",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('integer overflow', 'SECWORD', ''), ('change', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('change', 'ACTION', ''), ('408713061', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/grappler/costs/op_level_cost_estimator.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1624,
      "vuln_id": "GHSA-cwfw-4gq5-mrqx",
      "cwe_id": "{'CWE-400'}",
      "score": 0.0,
      "chain": "{'https://github.com/micromatch/braces/commit/abdafb0cae1e0c00f184abbadc692f4eaa98f451'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service (ReDoS) in braces A vulnerability was found in Braces versions prior to 2.3.1. Affected versions of this package are vulnerable to Regular Expression Denial of Service (ReDoS) attacks.",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/micromatch/braces",
      "commit_href": "https://github.com/micromatch/braces/commit/abdafb0cae1e0c00f184abbadc692f4eaa98f451",
      "commit_sha": "abdafb0cae1e0c00f184abbadc692f4eaa98f451",
      "patch": "SINGLE",
      "chain_ord": "['abdafb0cae1e0c00f184abbadc692f4eaa98f451']",
      "before_first_fix_commit": "{'37934142c1aeea48b6fb03edbdcf90e45b5cb4a1'}",
      "last_fix_commit": "abdafb0cae1e0c00f184abbadc692f4eaa98f451",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/16/2018, 21:09:36",
      "message": "optimize regex",
      "author": "jonschlinkert",
      "comments": "{'com_1': {'author': 'sathish-spidie', 'datetime': '04/18/2019, 03:42:11', 'body': \"can you explain, how to achieve this? I'm a low-level developer and didn't understand why this code stands for and what to do with it! sorry if I waste your time by making you read this comment, in case you find this comment useless.\\r\\n\\r\\nmy error is\\r\\n\\r\\n` Low             Regular Expression Denial of Service                          \\r\\n                                                                                \\r\\n  Package         braces                                                        \\r\\n                                                                                \\r\\n  Patched in      >=2.3.1                                                       \\r\\n                                                                                \\r\\n  Dependency of   browser-sync [dev]                                            \\r\\n                                                                                \\r\\n  Path            browser-sync > micromatch > braces                            \\r\\n                                                                                \\r\\n  More info       https://npmjs.com/advisories/786         `\"}, 'com_2': {'author': 'kousu', 'datetime': '04/18/2019, 18:24:04', 'body': '@sathish-spidie , you can find out the solution on the link there: https://npmjs.com/advisories/786:\\r\\n\\r\\n> Remediation\\r\\n> \\r\\n> Upgrade to version 2.3.1 or higher.\\r\\n\\r\\nWhat this means is that in your package.json you should make sure the line for \"braces\" under \"dependencies\"  says\\r\\n\\r\\n```\\r\\n\"braces\": \"^2.3.1\",\\r\\n```\\r\\n\\r\\nand then delete your cached npm packages by \\r\\n\\r\\n```\\r\\nrm -r node_modules/ package-lock.json\\r\\n```\\r\\n\\r\\nand then\\r\\n\\r\\n```\\r\\nnpm install\\r\\n```\\r\\n\\r\\n---\\r\\n\\r\\nIf you don\\'t directly depend on \"braces\", which is the situation I am in, you can use\\r\\n\\r\\n```\\r\\nnpm list\\r\\n```\\r\\n\\r\\nto figure out which of your packages is depending on \"braces\", and then go make sure to update each of those packages in the same way: version bump them, make sure to prefix the versions of everything with \"^\", and then delete your packages and regenerate package-lock.json by redoing `npm install`; that will get the latest, hopefully bugfixed, versions of all your packages; but if any of your packages have not yet updated to use `\"braces\": \"^2.3.1\"` then you will have to go to their github projects and file an issue. \\r\\n\\r\\n---\\r\\n\\r\\nA comment on a commit inside the braces project isn\\'t really a proper general support forum for npm. For that, and for future questions, you will probably have good luck asking at https://npm.community/c/support.  I hope the above helps and lets you extend your developer skills.'}, 'com_3': {'author': 'jonschlinkert', 'datetime': '04/18/2019, 20:01:13', 'body': \"@kousu that was a fantastic description, and a really good summary of the steps that need to be taken. Thank you!\\r\\n\\r\\n> you will probably have good luck asking at https://npm.community/c/support. I hope the above helps and lets you extend your developer skills.\\r\\n\\r\\nOnly one thing I'd like to point out. Generally, https://npm.community/c/support is for **NPM** support, not for packages like this one. Meaning, if you need something directly related to the package manager itself, that's the place to go. But ideally, when a user has an issue or support question like this, the best place to get answers is to:\\r\\n\\r\\n1. read through previous issues first - @sathish-spidie would have seen that this question has been answered a couple of dozen times already on this project and other projects that depend on this one\\r\\n1. StackOverflow - people get reputation points for helping others\\r\\n1. if it seems like no one has addressed the issue already, and you have genuinely stumbled across a previously undiscovered bug, then create a new issue on the GitHub repository of the code project.\"}, 'com_4': {'author': 'KevinGrant12', 'datetime': '05/08/2019, 23:49:41', 'body': \"Hello, I have the same exact issue that stems from babel.\\r\\nI was unable to run this line rm -r node_modules/ package-lock.json and it makes sense because the packag-lock is not inside the node_modules directory.\\r\\nWhen I run npm list I can see that instances of 'braces' are at 2.3.2.\\r\\n\\r\\nAny thoughts on how to fix?\\r\\nThanks!\"}, 'com_5': {'author': 'biggianteye', 'datetime': '06/07/2019, 12:57:09', 'body': \"> I was unable to run this line rm -r node_modules/ package-lock.json and it makes sense because the packag-lock is not inside the node_modules directory.\\r\\n\\r\\nThere is a space between `node_modules` and `package-lock.json`. The lock file is not inside the node_modules folder. It's at the same level.\"}, 'com_6': {'author': 'robpl1', 'datetime': '07/14/2019, 08:57:18', 'body': 'The problem I have here is that the braces package itself is showing \\r\\n{  \"_from\": \"braces@^1.8.2\",\\r\\n  \"_id\": \"braces@1.8.5\",\\r\\n\\r\\nSo how to update that would help.'}, 'com_7': {'author': 'martynawilkonska', 'datetime': '07/16/2019, 08:45:50', 'body': 'I have the same problem. I am unable to update braces, after reinstall they are still 1.8.5.'}, 'com_8': {'author': 'janzenz', 'datetime': '10/08/2019, 02:02:12', 'body': \"@martynawilkonska have you removed your `node_modules` cache and `package-lock.json` file? If not, try that and `npm install` again. If it still does that, my next hunch is that you're `braces` is a transitive dependency in your package. Try `npm ls braces` and see which package requires it and maybe you can try and upgrade that parent package which potentially will fix your problem.\"}}",
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'lib/parsers.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/micromatch/braces/raw/abdafb0cae1e0c00f184abbadc692f4eaa98f451/lib%2Fparsers.js', 'patch': \"@@ -127,7 +127,7 @@ module.exports = function(braces, options) {\\n     .set('multiplier', function() {\\n       var isInside = this.isInside('brace');\\n       var pos = this.position();\\n-      var m = this.match(/^\\\\{(,+(?:(\\\\{,+\\\\})*),*|,*(?:(\\\\{,+\\\\})*),+)\\\\}/);\\n+      var m = this.match(/^\\\\{((?:,|\\\\{,+\\\\})+)\\\\}/);\\n       if (!m) return;\\n \\n       this.multiplier = true;\"}}",
      "message_norm": "optimize regex",
      "language": "ro",
      "entities": "[('optimize', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/parsers.js'])",
      "num_files": 1.0
    },
    {
      "index": 180,
      "vuln_id": "GHSA-32wx-4gxx-h48f",
      "cwe_id": "{'CWE-639'}",
      "score": 0.0,
      "chain": "{'https://github.com/flarum/tags/commit/c8fcd000857493f1e4cc00b6f2771ce388b93e9d'}",
      "dataset": "osv",
      "summary": "Users can edit the tags of any discussion This advisory concerns a vulnerability which was patched and publicly released on October 5, 2020.\n\n### Impact\nThis vulnerability allowed any registered user to edit the tags of any discussion for which they have READ access using the REST API.\n\nUsers were able to remove any existing tag, and add any tag in which they are allowed to create discussions. The chosen tags still had to match the configured Tags minimums and maximums.\n\nBy moving the discussion to new tags, users were able to go around permissions applied to restricted tags. Depending on the setup, this can include publicly exposing content that was only visible to certain groups, or gain the ability to interact with content where such interaction was limited.\n\nThe full impact varies depending on the configuration of permissions and restricted tags, and which community extensions are being used. All tag-scoped permissions offered by extensions are impacted by this ability to go around them.\n\nForums that don't use restricted tags and don't use any extension that relies on tags for access control should not see any security impact. An update is still required to stop users from being able to change any discussion's tags.\n\nForums that don't use the Tags extension are unaffected.\n\n### Patches\nThe fix will be available in version v0.1.0-beta.14 with Flarum beta 14. The fix has already been back-ported to Flarum beta 13 as version v0.1.0-beta.13.2 of the Tags extension.\n\n### Workarounds\nVersion v0.1.0-beta.13.2 of the Tags extension allows existing Flarum beta 13 forums to fix the issue without the need to update to beta 14.\n\nForums that have not yet updated to Flarum beta 13 are encouraged to update as soon as possible.\n\n### References\n\n- [Release announcement](https://discuss.flarum.org/d/25059-security-update-to-flarum-tags-010-beta132)\n- [GitHub issue](https://github.com/flarum/core/issues/2355)\n\n### For more information\nIf you have any questions or comments about this advisory, please start a new discussion on our [support forum](https://discuss.flarum.org/t/support).\n\nIf you discover a security vulnerability within Flarum, please send an e-mail to [security@flarum.org](mailto:security@flarum.org). All security vulnerabilities will be promptly addressed. More details can be found in our [security policy](https://github.com/flarum/core/security/policy).",
      "published_date": "2021-01-29",
      "chain_len": 1,
      "project": "https://github.com/flarum/tags",
      "commit_href": "https://github.com/flarum/tags/commit/c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
      "commit_sha": "c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
      "patch": "SINGLE",
      "chain_ord": "['c8fcd000857493f1e4cc00b6f2771ce388b93e9d']",
      "before_first_fix_commit": "{'c207faa17ffc496d5ce0161923f19556a0ac4c5b'}",
      "last_fix_commit": "c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/03/2020, 22:37:56",
      "message": "Fix Editing Discussion Tags Permission (#95)",
      "author": "Sami Mazouz",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'src/Listener/SaveTagsToDatabase.php': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/flarum/tags/raw/c8fcd000857493f1e4cc00b6f2771ce388b93e9d/src%2FListener%2FSaveTagsToDatabase.php', 'patch': \"@@ -59,6 +59,10 @@ public function handle(Saving $event)\\n \\n         // TODO: clean up, prevent discussion from being created without tags\\n         if (isset($event->data['relationships']['tags']['data'])) {\\n+            if ($discussion->exists) {\\n+                $actor->assertCan('tag', $discussion);\\n+            }\\n+\\n             $linkage = (array) $event->data['relationships']['tags']['data'];\\n \\n             $newTagIds = [];\"}}",
      "message_norm": "fix editing discussion tags permission (#95)",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('permission', 'SECWORD', ''), ('#95', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Listener/SaveTagsToDatabase.php'])",
      "num_files": 1.0
    },
    {
      "index": 732,
      "vuln_id": "GHSA-62gx-355r-9fhg",
      "cwe_id": "{'CWE-476'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/ff70c47a396ef1e3cb73c90513da4f5cb71bebba'}",
      "dataset": "osv",
      "summary": "Session operations in eager mode lead to null pointer dereferences ### Impact\nIn eager mode (default in TF 2.0 and later), session operations are invalid. However, users could still call the raw ops associated with them and trigger a null pointer dereference:\n\n```python\nimport tensorflow as tf\ntf.raw_ops.GetSessionTensor(handle=['\\x12\\x1a\\x07'],dtype=4)\n```\n```python\nimport tensorflow as tf\ntf.raw_ops.DeleteSessionTensor(handle=['\\x12\\x1a\\x07'])\n``` \n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/eebb96c2830d48597d055d247c0e9aebaea94cd5/tensorflow/core/kernels/session_ops.cc#L104) dereferences the session state pointer without checking if it is valid:\n  \n```cc\n  OP_REQUIRES_OK(ctx, ctx->session_state()->GetTensor(name, &val));\n```\n\nThus, in eager mode, `ctx->session_state()` is nullptr and the call of the member function is undefined behavior.\n\n### Patches\nWe have patched the issue in GitHub commit [ff70c47a396ef1e3cb73c90513da4f5cb71bebba](https://github.com/tensorflow/tensorflow/commit/ff70c47a396ef1e3cb73c90513da4f5cb71bebba).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/ff70c47a396ef1e3cb73c90513da4f5cb71bebba",
      "commit_sha": "ff70c47a396ef1e3cb73c90513da4f5cb71bebba",
      "patch": "SINGLE",
      "chain_ord": "['ff70c47a396ef1e3cb73c90513da4f5cb71bebba']",
      "before_first_fix_commit": "{'eebb96c2830d48597d055d247c0e9aebaea94cd5'}",
      "last_fix_commit": "ff70c47a396ef1e3cb73c90513da4f5cb71bebba",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/13/2021, 21:24:00",
      "message": "Fix `tf.raw_ops.GetSessionTensor` and `tf.raw_ops.DeleteSessionTensor` null pointer dereferences.\n\nPiperOrigin-RevId: 368294154\nChange-Id: Ie10f07a0a9a1c2b685e08153d48a0ca4b93f9fc9",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 10, 'deletions': 4, 'total': 14}",
      "files": "{'tensorflow/core/kernels/session_ops.cc': {'additions': 10, 'deletions': 4, 'changes': 14, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/ff70c47a396ef1e3cb73c90513da4f5cb71bebba/tensorflow%2Fcore%2Fkernels%2Fsession_ops.cc', 'patch': '@@ -91,7 +91,6 @@ TF_CALL_NUMBER_TYPES(REGISTER_GPU_KERNEL);\\n REGISTER_GPU_KERNEL(bool);\\n #undef REGISTER_GPU_KERNEL\\n \\n-\\n class GetSessionTensorOp : public OpKernel {\\n  public:\\n   explicit GetSessionTensorOp(OpKernelConstruction* context)\\n@@ -101,7 +100,11 @@ class GetSessionTensorOp : public OpKernel {\\n     const Tensor& handle = ctx->input(0);\\n     const string& name = handle.scalar<tstring>()();\\n     Tensor val;\\n-    OP_REQUIRES_OK(ctx, ctx->session_state()->GetTensor(name, &val));\\n+    auto session_state = ctx->session_state();\\n+    OP_REQUIRES(ctx, session_state != nullptr,\\n+                errors::FailedPrecondition(\\n+                    \"GetSessionTensor called on null session state\"));\\n+    OP_REQUIRES_OK(ctx, session_state->GetTensor(name, &val));\\n     ctx->set_output(0, val);\\n   }\\n \\n@@ -122,7 +125,6 @@ TF_CALL_NUMBER_TYPES(REGISTER_GPU_KERNEL);\\n REGISTER_GPU_KERNEL(bool);\\n #undef REGISTER_GPU_KERNEL\\n \\n-\\n class DeleteSessionTensorOp : public OpKernel {\\n  public:\\n   explicit DeleteSessionTensorOp(OpKernelConstruction* context)\\n@@ -131,7 +133,11 @@ class DeleteSessionTensorOp : public OpKernel {\\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& handle = ctx->input(0);\\n     const string& name = handle.scalar<tstring>()();\\n-    OP_REQUIRES_OK(ctx, ctx->session_state()->DeleteTensor(name));\\n+    auto session_state = ctx->session_state();\\n+    OP_REQUIRES(ctx, session_state != nullptr,\\n+                errors::FailedPrecondition(\\n+                    \"DeleteSessionTensor called on null session state\"));\\n+    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));\\n   }\\n \\n   TF_DISALLOW_COPY_AND_ASSIGN(DeleteSessionTensorOp);'}}",
      "message_norm": "fix `tf.raw_ops.getsessiontensor` and `tf.raw_ops.deletesessiontensor` null pointer dereferences.\n\npiperorigin-revid: 368294154\nchange-id: ie10f07a0a9a1c2b685e08153d48a0ca4b93f9fc9",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('null pointer dereferences', 'SECWORD', ''), ('368294154', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/session_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2500,
      "vuln_id": "GHSA-p463-639r-q9g9",
      "cwe_id": "{'CWE-94'}",
      "score": 0.0,
      "chain": "{'https://github.com/markevans/dragonfly/commit/a8775aacf9e5c81cf11bec34b7afa7f27ddfe277'}",
      "dataset": "osv",
      "summary": "High severity vulnerability that affects dragonfly The Dragonfly gem 0.7 before 0.8.6 and 0.9.x before 0.9.13 for Ruby, when used with Ruby on Rails, allows remote attackers to execute arbitrary code via a crafted request.",
      "published_date": "2017-10-24",
      "chain_len": 1,
      "project": "https://github.com/markevans/dragonfly",
      "commit_href": "https://github.com/markevans/dragonfly/commit/a8775aacf9e5c81cf11bec34b7afa7f27ddfe277",
      "commit_sha": "a8775aacf9e5c81cf11bec34b7afa7f27ddfe277",
      "patch": "SINGLE",
      "chain_ord": "['a8775aacf9e5c81cf11bec34b7afa7f27ddfe277']",
      "before_first_fix_commit": "{'4fb2145b6b5731841e23ecddfa988675b9e194cb'}",
      "last_fix_commit": "a8775aacf9e5c81cf11bec34b7afa7f27ddfe277",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/19/2013, 10:44:17",
      "message": "security update note",
      "author": "Mark Evans",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'README.md': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/markevans/dragonfly/raw/a8775aacf9e5c81cf11bec34b7afa7f27ddfe277/README.md', 'patch': \"@@ -7,6 +7,8 @@ Ideal for using with Ruby on Rails (2.3 and 3), Sinatra and all that gubbins.\\n \\n However, Dragonfly is NOT JUST FOR RAILS, and NOT JUST FOR IMAGES!!\\n \\n+**IMPORTANT: if you're running a version between 0.7.0 and 0.9.12, please update to 0.9.14 for a security update [details here](https://groups.google.com/forum/?fromgroups=#!topic/dragonfly-users/3c3WIU3VQTo)**\\n+\\n For the lazy Rails user...\\n --------------------------\\n **Gemfile**:\"}}",
      "message_norm": "security update note",
      "language": "en",
      "entities": "[('security', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['README.md'])",
      "num_files": 1.0
    },
    {
      "index": 1870,
      "vuln_id": "GHSA-gfh2-7jg5-653p",
      "cwe_id": "{'CWE-835'}",
      "score": 4.0,
      "chain": "{'https://github.com/appc/docker2aci/pull/204/commits/54331ec7020e102935c31096f336d31f6400064f'}",
      "dataset": "osv",
      "summary": "Denial of Service in docker2aci docker2aci <= 0.12.3 has an infinite loop when handling local images with cyclic dependency chain.",
      "published_date": "2022-02-15",
      "chain_len": 1,
      "project": "https://github.com/appc/docker2aci",
      "commit_href": "https://github.com/appc/docker2aci/pull/204/commits/54331ec7020e102935c31096f336d31f6400064f",
      "commit_sha": "54331ec7020e102935c31096f336d31f6400064f",
      "patch": "SINGLE",
      "chain_ord": "['54331ec7020e102935c31096f336d31f6400064f']",
      "before_first_fix_commit": "{'8a4173c3067a557fba64a03c6efac613dfbba6ac'}",
      "last_fix_commit": "54331ec7020e102935c31096f336d31f6400064f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/10/2016, 13:23:55",
      "message": "backend/file: fix an infinite loop in deps walking (CVE-2016-8579)\n\nThis commit fixes a possible infinite loop while traversing\nthe dependency ancestry of a malformed local image file.\n\nThis has been assigned CVE-2016-8579:\nhttps://github.com/appc/docker2aci/issues/203#issuecomment-253494006",
      "author": "Luca Bruno",
      "comments": null,
      "stats": "{'additions': 11, 'deletions': 0, 'total': 11}",
      "files": "{'lib/internal/backend/file/file.go': {'additions': 11, 'deletions': 0, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/appc/docker2aci/raw/54331ec7020e102935c31096f336d31f6400064f/lib%2Finternal%2Fbackend%2Ffile%2Ffile.go', 'patch': '@@ -279,14 +279,24 @@ func extractEmbeddedLayer(file *os.File, layerID string, outputPath string) (*os\\n \\treturn layerFile, nil\\n }\\n \\n+// getAncestry computes an image ancestry, returning an ordered list\\n+// of dependencies starting from the topmost image to the base.\\n+// It checks for dependency loops via duplicate detection in the image\\n+// chain and errors out in such cases.\\n func getAncestry(file *os.File, imgID string) ([]string, error) {\\n \\tvar ancestry []string\\n+\\tdeps := make(map[string]bool)\\n \\n \\tcurImgID := imgID\\n \\n \\tvar err error\\n \\tfor curImgID != \"\" {\\n+\\t\\tif deps[curImgID] {\\n+\\t\\t\\treturn nil, fmt.Errorf(\"dependency loop detected at image %q\", curImgID)\\n+\\t\\t}\\n+\\t\\tdeps[curImgID] = true\\n \\t\\tancestry = append(ancestry, curImgID)\\n+\\t\\tlog.Debug(fmt.Sprintf(\"Getting ancestry for layer %q\", curImgID))\\n \\t\\tcurImgID, err = getParent(file, curImgID)\\n \\t\\tif err != nil {\\n \\t\\t\\treturn nil, err\\n@@ -328,5 +338,6 @@ func getParent(file *os.File, imgID string) (string, error) {\\n \\t\\treturn \"\", err\\n \\t}\\n \\n+\\tlog.Debug(fmt.Sprintf(\"Layer %q depends on layer %q\", imgID, parent))\\n \\treturn parent, nil\\n }'}}",
      "message_norm": "backend/file: fix an infinite loop in deps walking (cve-2016-8579)\n\nthis commit fixes a possible infinite loop while traversing\nthe dependency ancestry of a malformed local image file.\n\nthis has been assigned cve-2016-8579:\nhttps://github.com/appc/docker2aci/issues/203#issuecomment-253494006",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('infinite loop', 'SECWORD', ''), ('cve-2016-8579', 'VULNID', 'CVE'), ('fixes', 'ACTION', ''), ('infinite loop', 'SECWORD', ''), ('cve-2016-8579', 'VULNID', 'CVE'), ('https://github.com/appc/docker2aci/issues/203#issuecomment-253494006', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/internal/backend/file/file.go'])",
      "num_files": 1.0
    },
    {
      "index": 1949,
      "vuln_id": "GHSA-gx5w-rrhp-f436",
      "cwe_id": "{'CWE-79'}",
      "score": 8.2,
      "chain": "{'https://github.com/rust-lang/mdBook/commit/32abeef088e98327ca0dfccdad92e84afa9d2e9b'}",
      "dataset": "osv",
      "summary": "XSS in mdBook > This is a cross-post of [the official security advisory][ml]. The official post contains a signed version with our PGP key, as well.\n\n[ml]: https://groups.google.com/g/rustlang-security-announcements/c/3-sO6of29O0\n\nThe Rust Security Response Working Group was recently notified of a security issue affecting the search feature of mdBook, which could allow an attacker to execute arbitrary JavaScript code on the page.\n\nThe CVE for this vulnerability is [CVE-2020-26297](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26297).\n\n## Overview\n\nThe search feature of mdBook (introduced in version 0.1.4) was affected by a cross site scripting vulnerability that allowed an attacker to execute arbitrary JavaScript code on an user's browser by tricking the user into typing a malicious search query, or tricking the user into clicking a link to the search page with the malicious search query prefilled.\n\nmdBook 0.4.5 fixes the vulnerability by properly escaping the search query.\n\n## Mitigations\n\nOwners of websites built with mdBook have to upgrade to mdBook 0.4.5 or greater and rebuild their website contents with it. It's possible to install mdBook 0.4.5 on the local system with:\n\n```\ncargo install mdbook --version 0.4.5 --force\n```\n\n## Acknowledgements\n\nThanks to Kamil Vavra for responsibly disclosing the vulnerability to us according to [our security policy](https://www.rust-lang.org/policies/security).\n\n## Timeline of events\n\nAll times are listed in UTC.\n\n- 2020-12-30 20:14 - The issue is reported to the Rust Security Response WG\n- 2020-12-30 20:32 - The issue is acknowledged and the investigation began\n- 2020-12-30 21:21 - Found the cause of the vulnerability and prepared the patch\n- 2021-01-04 15:00 - Patched version released and vulnerability disclosed",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/rust-lang/mdBook",
      "commit_href": "https://github.com/rust-lang/mdBook/commit/32abeef088e98327ca0dfccdad92e84afa9d2e9b",
      "commit_sha": "32abeef088e98327ca0dfccdad92e84afa9d2e9b",
      "patch": "SINGLE",
      "chain_ord": "['32abeef088e98327ca0dfccdad92e84afa9d2e9b']",
      "before_first_fix_commit": "{'5de9b6841ed03c8149eeec3c8a5fcd40b5d4dbe0'}",
      "last_fix_commit": "32abeef088e98327ca0dfccdad92e84afa9d2e9b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/30/2020, 21:13:15",
      "message": "fix xss in the search page\n\nThanks to Kamil Vavra for responsibly disclosing the vulnerability\naccording to Rust's Security Policy.",
      "author": "Pietro Albini",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'src/theme/searcher/searcher.js': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/rust-lang/mdBook/raw/32abeef088e98327ca0dfccdad92e84afa9d2e9b/src%2Ftheme%2Fsearcher%2Fsearcher.js', 'patch': '@@ -145,6 +145,11 @@ window.search = window.search || {};\\n             url.push(\"\");\\n         }\\n \\n+        // encodeURIComponent escapes all chars that could allow an XSS except\\n+        // for \\'. Due to that we also manually replace \\' with its url-encoded\\n+        // representation (%27).\\n+        var searchterms = encodeURIComponent(searchterms.join(\" \")).replace(/\\\\\\'/g, \"%27\");\\n+\\n         return \\'<a href=\"\\' + path_to_root + url[0] + \\'?\\' + URL_MARK_PARAM + \\'=\\' + searchterms + \\'#\\' + url[1]\\n             + \\'\" aria-details=\"teaser_\\' + teaser_count + \\'\">\\' + result.doc.breadcrumbs + \\'</a>\\'\\n             + \\'<span class=\"teaser\" id=\"teaser_\\' + teaser_count + \\'\" aria-label=\"Search Result Teaser\">\\''}}",
      "message_norm": "fix xss in the search page\n\nthanks to kamil vavra for responsibly disclosing the vulnerability\naccording to rust's security policy.",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('xss', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('security', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/theme/searcher/searcher.js'])",
      "num_files": 1.0
    },
    {
      "index": 3273,
      "vuln_id": "GHSA-wg6g-ppvx-927h",
      "cwe_id": "{'CWE-1321'}",
      "score": 7.3,
      "chain": "{'https://github.com/ashaffer/cached-path-relative/commit/40c73bf70c58add5aec7d11e4f36b93d144bb760'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in cached-path-relative The package cached-path-relative before 1.1.0 is vulnerable to Prototype Pollution via the cache variable that is set as {} instead of Object.create(null) in the cachedPathRelative function, which allows access to the parent prototype properties when the object is used to create the cached relative path. When using the origin path as __proto__, the attribute of the object is accessed instead of a path. **Note:** This vulnerability derives from an incomplete fix in https://security.snyk.io/vuln/SNYK-JS-CACHEDPATHRELATIVE-72573",
      "published_date": "2022-01-27",
      "chain_len": 1,
      "project": "https://github.com/ashaffer/cached-path-relative",
      "commit_href": "https://github.com/ashaffer/cached-path-relative/commit/40c73bf70c58add5aec7d11e4f36b93d144bb760",
      "commit_sha": "40c73bf70c58add5aec7d11e4f36b93d144bb760",
      "patch": "SINGLE",
      "chain_ord": "['40c73bf70c58add5aec7d11e4f36b93d144bb760']",
      "before_first_fix_commit": "{'dfc753a020508cf42cde98024c68bf16bed12edc'}",
      "last_fix_commit": "40c73bf70c58add5aec7d11e4f36b93d144bb760",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/19/2022, 19:12:34",
      "message": "Fix other instances of prototype pollution vulnerability",
      "author": "Andrew",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'lib/index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/ashaffer/cached-path-relative/raw/40c73bf70c58add5aec7d11e4f36b93d144bb760/lib%2Findex.js', 'patch': '@@ -27,15 +27,15 @@ function cachedPathRelative (from, to) {\\n   // to invalidate the cache\\n   var cwd = process.cwd()\\n   if (cwd !== lastCwd) {\\n-    cache = {}\\n+    cache = Object.create(null)\\n     lastCwd = cwd\\n   }\\n \\n   if (cache[from] && cache[from][to]) return cache[from][to]\\n \\n   var result = relative.call(path, from, to)\\n \\n-  cache[from] = cache[from] || {}\\n+  cache[from] = cache[from] || Object.create(null)\\n   cache[from][to] = result\\n \\n   return result'}}",
      "message_norm": "fix other instances of prototype pollution vulnerability",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('prototype pollution', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1560,
      "vuln_id": "GHSA-cjc7-49v2-jp64",
      "cwe_id": "{'CWE-787', 'CWE-665'}",
      "score": 5.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/6fd02f44810754ae7481838b6a67c5df7f909ca3', 'https://github.com/tensorflow/tensorflow/commit/41727ff06111117bdf86b37db198217fd7a143cc'}",
      "dataset": "osv",
      "summary": "Incomplete validation in `SparseAdd` ### Impact\nIncomplete validation in `SparseAdd` results in allowing attackers to exploit undefined behavior (dereferencing null pointers) as well as write outside of bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\na_indices = tf.zeros([10, 97], dtype=tf.int64)\na_values = tf.zeros([10], dtype=tf.int64)\na_shape = tf.zeros([0], dtype=tf.int64)\n\nb_indices = tf.zeros([0, 0], dtype=tf.int64)\nb_values = tf.zeros([0], dtype=tf.int64)\nb_shape = tf.zeros([0], dtype=tf.int64)\n  \nthresh = 0\n\ntf.raw_ops.SparseAdd(a_indices=a_indices,\n                    a_values=a_values,\n                    a_shape=a_shape,\n                    b_indices=b_indices,\n                    b_values=b_values,\n                    b_shape=b_shape,\n                    thresh=thresh)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/sparse_add_op.cc) has a large set of validation for the two sparse tensor inputs (6 tensors in total), but does not validate that the tensors are not empty or that the second dimension of `*_indices` matches the size of corresponding `*_shape`. This allows attackers to send tensor triples that represent invalid sparse tensors to abuse code assumptions that are not protected by validation.\n\n### Patches\nWe have patched the issue in GitHub commit [6fd02f44810754ae7481838b6a67c5df7f909ca3](https://github.com/tensorflow/tensorflow/commit/6fd02f44810754ae7481838b6a67c5df7f909ca3) followed by GitHub commit  [41727ff06111117bdf86b37db198217fd7a143cc](https://github.com/tensorflow/tensorflow/commit/41727ff06111117bdf86b37db198217fd7a143cc).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/6fd02f44810754ae7481838b6a67c5df7f909ca3",
      "commit_sha": "6fd02f44810754ae7481838b6a67c5df7f909ca3",
      "patch": "MULTI",
      "chain_ord": "['6fd02f44810754ae7481838b6a67c5df7f909ca3', '41727ff06111117bdf86b37db198217fd7a143cc']",
      "before_first_fix_commit": "{'6f432d6334edc93fd5af0070170def56b0413e8a'}",
      "last_fix_commit": "41727ff06111117bdf86b37db198217fd7a143cc",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/26/2021, 23:40:49",
      "message": "Fix `tf.raw_ops.SparseAdd ` invalid memory access failure.\n\nPiperOrigin-RevId: 370568774\nChange-Id: I5f73b31c865f2948a1c8dfb7ebd22b3cfb6405bf",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/sparse_add_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/6fd02f44810754ae7481838b6a67c5df7f909ca3/tensorflow%2Fcore%2Fkernels%2Fsparse_add_op.cc', 'patch': '@@ -14,6 +14,7 @@ limitations under the License.\\n ==============================================================================*/\\n \\n #include \"tensorflow/core/framework/op_kernel.h\"\\n+#include \"tensorflow/core/framework/op_requires.h\"\\n #include \"tensorflow/core/framework/register_types.h\"\\n #include \"tensorflow/core/framework/tensor.h\"\\n #include \"tensorflow/core/framework/tensor_util.h\"\\n@@ -101,6 +102,10 @@ class SparseAddOp : public OpKernel {\\n     std::vector<T> out_values;\\n     const int num_dims = a_shape->dim_size(0);\\n \\n+    OP_REQUIRES(ctx, num_dims > 0,\\n+                errors::InvalidArgument(\"Invalid input_a shape. Received: \",\\n+                                        a_shape->DebugString()));\\n+\\n     // The input and output sparse tensors are assumed to be ordered along\\n     // increasing dimension number.\\n     int64 i = 0, j = 0;'}}",
      "message_norm": "fix `tf.raw_ops.sparseadd ` invalid memory access failure.\n\npiperorigin-revid: 370568774\nchange-id: i5f73b31c865f2948a1c8dfb7ebd22b3cfb6405bf",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('invalid memory access', 'SECWORD', ''), ('370568774', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_add_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2329,
      "vuln_id": "GHSA-m2fc-9h5m-29cm",
      "cwe_id": "{'CWE-77'}",
      "score": 9.8,
      "chain": "{'https://github.com/acrontum/filesystem-template/pull/14/commits/baeb727b60991ad82d9e63ac660883793abc0acc'}",
      "dataset": "osv",
      "summary": "@acrontum/filesystem-template vulnerable to Command Injection due to fetchRepo API missing sanitization The package @acrontum/filesystem-template before 0.0.2 is vulnerable to Arbitrary Command Injection due to the fetchRepo API missing sanitization of the href field of external input.",
      "published_date": "2022-08-06",
      "chain_len": 1,
      "project": "https://github.com/acrontum/filesystem-template",
      "commit_href": "https://github.com/acrontum/filesystem-template/pull/14/commits/baeb727b60991ad82d9e63ac660883793abc0acc",
      "commit_sha": "baeb727b60991ad82d9e63ac660883793abc0acc",
      "patch": "SINGLE",
      "chain_ord": "['baeb727b60991ad82d9e63ac660883793abc0acc']",
      "before_first_fix_commit": "{'7883cb4e87c1bd2bf276f741fa8eeaa2af7565c7'}",
      "last_fix_commit": "baeb727b60991ad82d9e63ac660883793abc0acc",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/04/2022, 17:45:08",
      "message": "remove url from fetch repo\n\ncloses #13",
      "author": "p-mcgowan",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 3, 'total': 6}",
      "files": "{'src/lib/file-utils.ts': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/acrontum/filesystem-template/raw/baeb727b60991ad82d9e63ac660883793abc0acc/src%2Flib%2Ffile-utils.ts', 'patch': \"@@ -162,7 +162,7 @@ export const fetchSource = async (pathlike: string, options?: SourceOptions): Pr\\n \\n   const cache = getCacheDir(url);\\n   if (!sourceCache[cache?.path]) {\\n-    sourceCache[cache?.path] = isRecipeFile(url.pathname) ? fetchRecipe(url, cache, options) : fetchRepo(url, cache, options);\\n+    sourceCache[cache?.path] = isRecipeFile(url.pathname) ? fetchRecipe(url, cache, options) : fetchRepo(cache, options);\\n   } else {\\n     logger.log(`cache hit on ${cache?.path}`);\\n   }\\n@@ -237,7 +237,7 @@ export const fetchRecipe = async (url: URL, cacheInfo: CacheInfo, options?: Sour\\n  *\\n  * @return {Promise<string>}  The repo.\\n  */\\n-export const fetchRepo = async (url: URL, cacheInfo: CacheInfo, options?: SourceOptions): Promise<string> => {\\n+export const fetchRepo = async (cacheInfo: CacheInfo, options?: SourceOptions): Promise<string> => {\\n   let branch = cacheInfo.branch;\\n   const { path: repo, origin, repoName } = cacheInfo;\\n \\n@@ -247,7 +247,7 @@ export const fetchRepo = async (url: URL, cacheInfo: CacheInfo, options?: Source\\n     return repo;\\n   }\\n \\n-  logger.debug({ url, branch, repo, origin });\\n+  logger.debug({ branch, repo, origin });\\n   logger.info(`will clone ${branch ? `${logger.blu(branch)} of ` : ''}${logger.ylw(origin)} into ${logger.grn(repoName)}`);\\n \\n   const cwd = repo;\"}}",
      "message_norm": "remove url from fetch repo\n\ncloses #13",
      "language": "en",
      "entities": "[('remove', 'ACTION', ''), ('#13', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/lib/file-utils.ts'])",
      "num_files": 1.0
    },
    {
      "index": 1160,
      "vuln_id": "GHSA-874w-m2v2-mj64",
      "cwe_id": "{'CWE-415'}",
      "score": 9.8,
      "chain": "{'https://github.com/adplug/adplug/commit/1a282a486a8e33fef3e15998bf6408d3515dc07e', 'https://github.com/miller-alex/adplug/commit/8abb9328bf27dcbdafc67ade3e75af0ffd8f7633'}",
      "dataset": "osv",
      "summary": "Double Free in Adplug AdPlug 2.3.1 has a double free in the Cu6mPlayer class in u6m.h.",
      "published_date": "2021-03-29",
      "chain_len": 2,
      "project": "https://github.com/miller-alex/adplug",
      "commit_href": "https://github.com/miller-alex/adplug/commit/8abb9328bf27dcbdafc67ade3e75af0ffd8f7633",
      "commit_sha": "8abb9328bf27dcbdafc67ade3e75af0ffd8f7633",
      "patch": "MULTI",
      "chain_ord": "['8abb9328bf27dcbdafc67ade3e75af0ffd8f7633', '1a282a486a8e33fef3e15998bf6408d3515dc07e']",
      "before_first_fix_commit": "{'a8903d884e2c900e77af5c70ef440e72626646ad'}",
      "last_fix_commit": "1a282a486a8e33fef3e15998bf6408d3515dc07e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/24/2020, 14:43:22",
      "message": "Fix double free in Cu6mPlayer::~Cu6mPlayer() (issue #91)\n\nLeave deallocation of song_data to destructor when\ndecompression fails, just like on success.\n\nThis fixes CVE-2019-15151.\n\nEven though load() is apparently not supposed to be called\ntwice (and bad things happen in many players if you do),\nlet's also avoid leaking song_data's memory in that case.\n\nFixes: https://github.com/adplug/adplug/issues/91",
      "author": "Alexander Miller",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 2, 'total': 3}",
      "files": "{'src/u6m.cpp': {'additions': 1, 'deletions': 2, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/miller-alex/adplug/raw/8abb9328bf27dcbdafc67ade3e75af0ffd8f7633/src%2Fu6m.cpp', 'patch': '@@ -66,6 +66,7 @@ bool Cu6mPlayer::load(const std::string &filename, const CFileProvider &fp)\\n     }\\n \\n   // load section\\n+  delete[] song_data;\\n   song_data = new unsigned char[decompressed_filesize];\\n   unsigned char* compressed_song_data = new unsigned char[filesize-3];\\n \\n@@ -74,7 +75,6 @@ bool Cu6mPlayer::load(const std::string &filename, const CFileProvider &fp)\\n   fp.close(f);\\n \\n   // attempt to decompress the song data\\n-  // if unsuccessful, deallocate song_data[] on the spot, and return(false)\\n   data_block source, destination;\\n   source.size = filesize-4;\\n   source.data = compressed_song_data;\\n@@ -84,7 +84,6 @@ bool Cu6mPlayer::load(const std::string &filename, const CFileProvider &fp)\\n   if (!lzw_decompress(source,destination))\\n     {\\n       delete[] compressed_song_data;\\n-      delete[] song_data;\\n       return(false);\\n     }'}}",
      "message_norm": "fix double free in cu6mplayer::~cu6mplayer() (issue #91)\n\nleave deallocation of song_data to destructor when\ndecompression fails, just like on success.\n\nthis fixes cve-2019-15151.\n\neven though load() is apparently not supposed to be called\ntwice (and bad things happen in many players if you do),\nlet's also avoid leaking song_data's memory in that case.\n\nfixes: https://github.com/adplug/adplug/issues/91",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('double free', 'SECWORD', ''), ('#91', 'ISSUE', ''), ('decompression', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('cve-2019-15151', 'VULNID', 'CVE'), ('fixes', 'ACTION', ''), ('https://github.com/adplug/adplug/issues/91', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/u6m.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 1325,
      "vuln_id": "GHSA-9689-rx4v-cqgc",
      "cwe_id": "{'CWE-601'}",
      "score": 5.4,
      "chain": "{'https://github.com/concourse/concourse/pull/5350/commits/38cb4cc025e5ed28764b4adc363a0bbf41f3c7cb'}",
      "dataset": "osv",
      "summary": "Open Redirect Pivotal Concourse Release, versions 4.x prior to 4.2.2, login flow allows redirects to untrusted websites. A remote unauthenticated attacker could convince a user to click on a link using the oAuth redirect link with an untrusted website and gain access to that user's access token in Concourse.",
      "published_date": "2022-02-15",
      "chain_len": 1,
      "project": "https://github.com/concourse/concourse",
      "commit_href": "https://github.com/concourse/concourse/pull/5350/commits/38cb4cc025e5ed28764b4adc363a0bbf41f3c7cb",
      "commit_sha": "38cb4cc025e5ed28764b4adc363a0bbf41f3c7cb",
      "patch": "SINGLE",
      "chain_ord": "['38cb4cc025e5ed28764b4adc363a0bbf41f3c7cb']",
      "before_first_fix_commit": "{'091671e19b3779e439f5ad4a6b4b89aa20a33778'}",
      "last_fix_commit": "38cb4cc025e5ed28764b4adc363a0bbf41f3c7cb",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/20/2020, 16:32:09",
      "message": "skymarshal: use escaped path for redirect URI\n\nSigned-off-by: Rui Yang <ryang@pivotal.io>",
      "author": "Rui Yang",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'skymarshal/skyserver/skyserver.go': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/concourse/concourse/raw/38cb4cc025e5ed28764b4adc363a0bbf41f3c7cb/skymarshal%2Fskyserver%2Fskyserver.go', 'patch': '@@ -257,7 +257,7 @@ func (s *SkyServer) Redirect(w http.ResponseWriter, r *http.Request, token *oaut\\n \\tparams := redirectURL.Query()\\n \\tparams.Set(\"csrf_token\", csrfToken)\\n \\n-\\thttp.Redirect(w, r, redirectURL.Path+\"?\"+params.Encode(), http.StatusTemporaryRedirect)\\n+\\thttp.Redirect(w, r, redirectURL.EscapedPath()+\"?\"+params.Encode(), http.StatusTemporaryRedirect)\\n }\\n \\n func (s *SkyServer) Token(w http.ResponseWriter, r *http.Request) {'}}",
      "message_norm": "skymarshal: use escaped path for redirect uri\n\nsigned-off-by: rui yang <ryang@pivotal.io>",
      "language": "en",
      "entities": "[('escaped', 'SECWORD', ''), ('ryang@pivotal.io', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['skymarshal/skyserver/skyserver.go'])",
      "num_files": 1.0
    },
    {
      "index": 564,
      "vuln_id": "GHSA-566m-qj78-rww5",
      "cwe_id": "{'CWE-400'}",
      "score": 5.3,
      "chain": "{'https://github.com/postcss/postcss/commit/2b1d04c867995e55124e0a165b7c6622c1735956'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service in postcss The package postcss versions before 7.0.36 or between 8.0.0 and 8.2.13 are vulnerable to Regular Expression Denial of Service (ReDoS) via getAnnotationURL() and loadAnnotation() in lib/previous-map.js. The vulnerable regexes are caused mainly by the sub-pattern \\/\\*\\s* sourceMappingURL=(.*).",
      "published_date": "2022-01-07",
      "chain_len": 1,
      "project": "https://github.com/postcss/postcss",
      "commit_href": "https://github.com/postcss/postcss/commit/2b1d04c867995e55124e0a165b7c6622c1735956",
      "commit_sha": "2b1d04c867995e55124e0a165b7c6622c1735956",
      "patch": "SINGLE",
      "chain_ord": "['2b1d04c867995e55124e0a165b7c6622c1735956']",
      "before_first_fix_commit": "{'dc6cff1d7f9e0d6cba440d1b4f797a0f57b13595', '2ad1ca9b965dde32223bee28dc259c339cbaaa05'}",
      "last_fix_commit": "2b1d04c867995e55124e0a165b7c6622c1735956",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/26/2021, 12:08:17",
      "message": "Merge pull request #1567 from yetingli/main\n\nFix ReDoS in previous-map",
      "author": "Andrey Sitnik",
      "comments": "{'com_1': {'author': 'abergmann', 'datetime': '04/27/2021, 06:37:03', 'body': '[CVE-2021-23382](https://nvd.nist.gov/vuln/detail/CVE-2021-23382) was assigned to this commit.'}}",
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'lib/previous-map.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/postcss/postcss/raw/2b1d04c867995e55124e0a165b7c6622c1735956/lib%2Fprevious-map.js', 'patch': '@@ -48,11 +48,11 @@ class PreviousMap {\\n   }\\n \\n   getAnnotationURL(sourceMapString) {\\n-    return sourceMapString.match(/\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\*\\\\//)[1].trim()\\n+    return sourceMapString.match(/\\\\/\\\\*\\\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\\\*\\\\//)[1].trim()\\n   }\\n \\n   loadAnnotation(css) {\\n-    let annotations = css.match(/\\\\/\\\\*\\\\s*# sourceMappingURL=.*\\\\*\\\\//gm)\\n+    let annotations = css.match(/\\\\/\\\\*\\\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\\\*\\\\//gm)\\n \\n     if (annotations && annotations.length > 0) {\\n       // Locate the last sourceMappingURL to avoid picking up'}}",
      "message_norm": "merge pull request #1567 from yetingli/main\n\nfix redos in previous-map",
      "language": "en",
      "entities": "[('#1567', 'ISSUE', ''), ('redos', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/previous-map.js'])",
      "num_files": 1.0
    },
    {
      "index": 3055,
      "vuln_id": "GHSA-v5rv-hpxg-8x49",
      "cwe_id": "{'CWE-347'}",
      "score": 0.0,
      "chain": "{'https://github.com/ServiceStack/ServiceStack/commit/540d4060e877a03ae95343c1a8560a26768585ee'}",
      "dataset": "osv",
      "summary": "Signature validation bypass in ServiceStack ServiceStack before 5.9.2 mishandles JWT signature verification unless an application has a custom ValidateToken function that establishes a valid minimum length for a signature.",
      "published_date": "2021-01-13",
      "chain_len": 1,
      "project": "https://github.com/ServiceStack/ServiceStack",
      "commit_href": "https://github.com/ServiceStack/ServiceStack/commit/540d4060e877a03ae95343c1a8560a26768585ee",
      "commit_sha": "540d4060e877a03ae95343c1a8560a26768585ee",
      "patch": "SINGLE",
      "chain_ord": "['540d4060e877a03ae95343c1a8560a26768585ee']",
      "before_first_fix_commit": "{'794f1363f51f81fbead1dc8eb4dbc5076b2236a3'}",
      "last_fix_commit": "540d4060e877a03ae95343c1a8560a26768585ee",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/04/2020, 06:16:17",
      "message": "Update EquivalentTo to test length & null for equality as well",
      "author": "Demis Bellot",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'src/ServiceStack.Common/EnumerableExtensions.cs': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/ServiceStack/ServiceStack/raw/540d4060e877a03ae95343c1a8560a26768585ee/src%2FServiceStack.Common%2FEnumerableExtensions.cs', 'patch': '@@ -234,6 +234,12 @@ public static T FirstNonDefault<T>(this IEnumerable<T> values)\\n         [MethodImpl(MethodImplOptions.AggressiveInlining)]\\n         public static bool EquivalentTo(this byte[] bytes, byte[] other)\\n         {\\n+            if (bytes == null || other == null)\\n+                return bytes == other;\\n+\\n+            if (bytes.Length != other.Length)\\n+                return false;\\n+\\n             var compare = 0;\\n             for (var i = 0; i < other.Length; i++)\\n                 compare |= other[i] ^ bytes[i];'}}",
      "message_norm": "update equivalentto to test length & null for equality as well",
      "language": "en",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/ServiceStack.Common/EnumerableExtensions.cs'])",
      "num_files": 1.0
    },
    {
      "index": 3249,
      "vuln_id": "GHSA-w8f3-pvx4-4c3h",
      "cwe_id": "{'CWE-1321'}",
      "score": 0.0,
      "chain": "{'https://github.com/Quernest/arr-flatten-unflatten/commit/cb4351c75f87a4fbec3b6140c40ee2993f574372'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in arr-flatten-unflatten All versions of package arr-flatten-unflatten up to and including version 1.1.4 are vulnerable to Prototype Pollution via the constructor.",
      "published_date": "2021-05-06",
      "chain_len": 1,
      "project": "https://github.com/Quernest/arr-flatten-unflatten",
      "commit_href": "https://github.com/Quernest/arr-flatten-unflatten/commit/cb4351c75f87a4fbec3b6140c40ee2993f574372",
      "commit_sha": "cb4351c75f87a4fbec3b6140c40ee2993f574372",
      "patch": "SINGLE",
      "chain_ord": "['cb4351c75f87a4fbec3b6140c40ee2993f574372']",
      "before_first_fix_commit": "{'f4ccf0a8d55288490e729233fe2885eec15f74d0', '28bf4357297b67730ec1db002c001a76cd349b61'}",
      "last_fix_commit": "cb4351c75f87a4fbec3b6140c40ee2993f574372",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/25/2021, 20:45:17",
      "message": "Merge pull request #8 from 418sec/1-npm-arr-flatten-unflatten\n\nSecurity Fix for Prototype Pollution - huntr.dev",
      "author": "Quernest",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'unflatten.js': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/Quernest/arr-flatten-unflatten/raw/cb4351c75f87a4fbec3b6140c40ee2993f574372/unflatten.js', 'patch': '@@ -10,6 +10,8 @@ function unflatten(obj = {}) {\\n     let m = {};\\n \\n     while ((m = regex.exec(p))) {\\n+      if (curr[prop] === constructor.prototype)\\n+        curr[prop] = {}\\n       curr = curr[prop] || (curr[prop] = m[2] ? [] : {});\\n       prop = m[2] || m[1];\\n     }'}}",
      "message_norm": "merge pull request #8 from 418sec/1-npm-arr-flatten-unflatten\n\nsecurity fix for prototype pollution - huntr.dev",
      "language": "en",
      "entities": "[('#8', 'ISSUE', ''), ('security', 'SECWORD', ''), ('prototype pollution', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['unflatten.js'])",
      "num_files": 1.0
    },
    {
      "index": 2288,
      "vuln_id": "GHSA-jpj5-hg26-6jgc",
      "cwe_id": "{'CWE-79'}",
      "score": 6.1,
      "chain": "{'https://github.com/Xhofe/alist/commit/6af17e2509a400979420f613fd7f2f9721fdcd6e'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in Alist Alist versions 2.0.10 through 2.1.0 were discovered to contain a cross-site scripting (XSS) vulnerability via /i/:data/ipa.plist. This issue was fixed in version 2.1.1.",
      "published_date": "2022-03-13",
      "chain_len": 1,
      "project": "https://github.com/Xhofe/alist",
      "commit_href": "https://github.com/Xhofe/alist/commit/6af17e2509a400979420f613fd7f2f9721fdcd6e",
      "commit_sha": "6af17e2509a400979420f613fd7f2f9721fdcd6e",
      "patch": "SINGLE",
      "chain_ord": "['6af17e2509a400979420f613fd7f2f9721fdcd6e']",
      "before_first_fix_commit": "{'5193b2aa7df73231ebf68e90b3295f2a5c0916a2'}",
      "last_fix_commit": "6af17e2509a400979420f613fd7f2f9721fdcd6e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/01/2022, 12:09:25",
      "message": ":lock: fix #645 xss vulnerability",
      "author": "Xhofe",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 0, 'total': 9}",
      "files": "{'server/controllers/other.go': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/alist-org/alist/raw/6af17e2509a400979420f613fd7f2f9721fdcd6e/server%2Fcontrollers%2Fother.go', 'patch': '@@ -7,6 +7,7 @@ import (\\n \\t\"github.com/Xhofe/alist/server/common\"\\n \\t\"github.com/Xhofe/alist/utils\"\\n \\t\"github.com/gin-gonic/gin\"\\n+\\t\"net/url\"\\n \\t\"strings\"\\n )\\n \\n@@ -24,11 +25,19 @@ func Plist(c *gin.Context) {\\n \\t\\treturn\\n \\t}\\n \\tu := string(bytes)\\n+\\tuUrl, err := url.Parse(u)\\n+\\tif err != nil {\\n+\\t\\tcommon.ErrorResp(c, err, 500)\\n+\\t\\treturn\\n+\\t}\\n \\tname := utils.Base(u)\\n+\\tu = uUrl.String()\\n \\tipaIndex := strings.Index(name, \".ipa\")\\n \\tif ipaIndex != -1 {\\n \\t\\tname = name[:ipaIndex]\\n \\t}\\n+\\tname = strings.ReplaceAll(name, \"<\", \"[\")\\n+\\tname = strings.ReplaceAll(name, \">\", \"]\")\\n \\tplist := fmt.Sprintf(`<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\\n <plist version=\"1.0\">\\n     <dict>'}}",
      "message_norm": ":lock: fix #645 xss vulnerability",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('#645', 'ISSUE', ''), ('xss', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/controllers/other.go'])",
      "num_files": 1.0
    },
    {
      "index": 332,
      "vuln_id": "GHSA-4278-2v5v-65r4",
      "cwe_id": "{'CWE-787', 'CWE-120'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/eebb96c2830d48597d055d247c0e9aebaea94cd5'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `RaggedBinCount` ### Impact\nIf the `splits` argument of `RaggedBincount` does not specify a valid [`SparseTensor`](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor), then an attacker can trigger a heap buffer overflow:\n\n```python\nimport tensorflow as tf\ntf.raw_ops.RaggedBincount(splits=[0], values=[1,1,1,1,1], size=5, weights=[1,2,3,4], binary_output=False)\n```\n\nThis will cause a read from outside the bounds of the `splits` tensor buffer in the [implementation of the `RaggedBincount` op](https://github.com/tensorflow/tensorflow/blob/8b677d79167799f71c42fd3fa074476e0295413a/tensorflow/core/kernels/bincount_op.cc#L430-L433):\n\n```cc\n    for (int idx = 0; idx < num_values; ++idx) {\n      while (idx >= splits(batch_idx)) {\n        batch_idx++;\n      }\n      ...\n    }\n```\n\nBefore the `for` loop, `batch_idx` is set to 0. The user controls the `splits` array, making it contain only one element, 0. Thus, the code in the `while` loop would increment `batch_idx` and then try to read `splits(1)`, which is outside of bounds.\n\n### Patches\nWe have patched the issue in GitHub commit [eebb96c2830d48597d055d247c0e9aebaea94cd5](https://github.com/tensorflow/tensorflow/commit/eebb96c2830d48597d055d247c0e9aebaea94cd5).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2 and TensorFlow 2.3.3, as these are also affected.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/eebb96c2830d48597d055d247c0e9aebaea94cd5",
      "commit_sha": "eebb96c2830d48597d055d247c0e9aebaea94cd5",
      "patch": "SINGLE",
      "chain_ord": "['eebb96c2830d48597d055d247c0e9aebaea94cd5']",
      "before_first_fix_commit": "{'8b677d79167799f71c42fd3fa074476e0295413a'}",
      "last_fix_commit": "eebb96c2830d48597d055d247c0e9aebaea94cd5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/13/2021, 21:18:51",
      "message": "Fix an invalid address vulnerability in `tf.raw_ops.RaggedBincount`.\n\nPiperOrigin-RevId: 368293153\nChange-Id: I4b4e493d3fd05e7dc55a55de3a041a80a4f275c3",
      "author": "Amit Patankar",
      "comments": "{'com_1': {'author': 'Rayyan335', 'datetime': '05/14/2021, 19:00:36', 'body': 'tensorflow/core/kernels/bincount_op.cc'}}",
      "stats": "{'additions': 9, 'deletions': 0, 'total': 9}",
      "files": "{'tensorflow/core/kernels/bincount_op.cc': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/eebb96c2830d48597d055d247c0e9aebaea94cd5/tensorflow%2Fcore%2Fkernels%2Fbincount_op.cc', 'patch': '@@ -420,6 +420,15 @@ class RaggedBincountOp : public OpKernel {\\n     int num_values = values.size();\\n     int batch_idx = 0;\\n \\n+    OP_REQUIRES(ctx, splits(0) == 0,\\n+                errors::InvalidArgument(\"Splits must start with 0, not with \",\\n+                                        splits(0)));\\n+\\n+    OP_REQUIRES(ctx, splits(num_rows) == num_values,\\n+                errors::InvalidArgument(\\n+                    \"Splits must end with the number of values, got \",\\n+                    splits(num_rows), \" instead of \", num_values));\\n+\\n     Tensor* out_t;\\n     OP_REQUIRES_OK(\\n         ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));'}}",
      "message_norm": "fix an invalid address vulnerability in `tf.raw_ops.raggedbincount`.\n\npiperorigin-revid: 368293153\nchange-id: i4b4e493d3fd05e7dc55a55de3a041a80a4f275c3",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('368293153', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/bincount_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3326,
      "vuln_id": "GHSA-wvjw-p9f5-vq28",
      "cwe_id": "{'CWE-755'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/82e6203221865de4008445b13c69b6826d2b28d9'}",
      "dataset": "osv",
      "summary": "Segfault in `tf.raw_ops.SparseCountSparseOutput` ### Impact\nPassing invalid arguments (e.g., discovered via fuzzing) to `tf.raw_ops.SparseCountSparseOutput` results in segfault.\n\n### Patches\nWe have patched the issue in GitHub commit [82e6203221865de4008445b13c69b6826d2b28d9](https://github.com/tensorflow/tensorflow/commit/82e6203221865de4008445b13c69b6826d2b28d9).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/82e6203221865de4008445b13c69b6826d2b28d9",
      "commit_sha": "82e6203221865de4008445b13c69b6826d2b28d9",
      "patch": "SINGLE",
      "chain_ord": "['82e6203221865de4008445b13c69b6826d2b28d9']",
      "before_first_fix_commit": "{'0e182ba66c18db83668c05d26ee0c84ca9e2dbff'}",
      "last_fix_commit": "82e6203221865de4008445b13c69b6826d2b28d9",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/03/2021, 01:02:03",
      "message": "Fix segfaults in `tf.raw_ops.SparseCountSparseOutput`.\n\nPiperOrigin-RevId: 360547563\nChange-Id: I781c7af4b54a63d867c6e18d43a44d64a5c4e7c9",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 0, 'total': 12}",
      "files": "{'tensorflow/core/kernels/count_ops.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/82e6203221865de4008445b13c69b6826d2b28d9/tensorflow%2Fcore%2Fkernels%2Fcount_ops.cc', 'patch': '@@ -192,6 +192,10 @@ class SparseCount : public OpKernel {\\n               \"; values shape: \", values.shape().DebugString()));\\n     }\\n \\n+    OP_REQUIRES(context, shape.NumElements() != 0,\\n+                errors::InvalidArgument(\\n+                    \"The shape argument requires at least one element.\"));\\n+\\n     bool is_1d = shape.NumElements() == 1;\\n     int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\\n     int num_values = values.NumElements();\\n@@ -212,6 +216,14 @@ class SparseCount : public OpKernel {\\n \\n     for (int idx = 0; idx < num_values; ++idx) {\\n       int batch = is_1d ? 0 : indices_values(idx, 0);\\n+      if (batch >= num_batches) {\\n+        OP_REQUIRES(context, batch < num_batches,\\n+                    errors::InvalidArgument(\\n+                        \"Indices value along the first dimension must be \",\\n+                        \"lower than the first index of the shape.\", \"Got \",\\n+                        batch, \" as batch and \", num_batches,\\n+                        \" as the first dimension of the shape.\"));\\n+      }\\n       const auto& value = values_values(idx);\\n       if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\\n         if (binary_output_) {'}}",
      "message_norm": "fix segfaults in `tf.raw_ops.sparsecountsparseoutput`.\n\npiperorigin-revid: 360547563\nchange-id: i781c7af4b54a63d867c6e18d43a44d64a5c4e7c9",
      "language": "en",
      "entities": "[('segfaults', 'SECWORD', ''), ('360547563', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/count_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 263,
      "vuln_id": "GHSA-3j58-p785-f27x",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/microweber/microweber/commit/fc7e1a026735b93f0e0047700d08c44954fce9ce'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in microweber There is a reflected cross sitem scripting attack in microweber via url parameters.",
      "published_date": "2022-01-28",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/fc7e1a026735b93f0e0047700d08c44954fce9ce",
      "commit_sha": "fc7e1a026735b93f0e0047700d08c44954fce9ce",
      "patch": "SINGLE",
      "chain_ord": "['fc7e1a026735b93f0e0047700d08c44954fce9ce']",
      "before_first_fix_commit": "{'6e9fcaa043b4211ef21a494f9892dd19ba8a572c'}",
      "last_fix_commit": "fc7e1a026735b93f0e0047700d08c44954fce9ce",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/19/2022, 10:33:18",
      "message": "fix xss on module api call in value parameters",
      "author": "Bozhidar Slaveykov",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 4, 'total': 8}",
      "files": "{'src/MicroweberPackages/App/Http/Controllers/ApiController.php': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/fc7e1a026735b93f0e0047700d08c44954fce9ce/src%2FMicroweberPackages%2FApp%2FHttp%2FControllers%2FApiController.php', 'patch': \"@@ -17,9 +17,6 @@\\n class ApiController  extends FrontendController\\n {\\n \\n-\\n-\\n-\\n     public function api_html()\\n     {\\n         if (!defined('MW_API_HTML_OUTPUT')) {\\n@@ -609,12 +606,14 @@ public function module()\\n \\n         $request_data = array_merge($_GET, $_POST);\\n \\n-\\n         // sanitize attributes\\n         if($request_data){\\n             $request_data_new = [];\\n             $antixss = new AntiXSS();\\n             foreach ($request_data as $k=>$v){\\n+\\n+                $v = $antixss->xss_clean($v);\\n+\\n                 if(is_string($k)){\\n                     $k = $antixss->xss_clean($k);\\n                     if($k){\\n@@ -623,6 +622,7 @@ public function module()\\n                 } else {\\n                     $request_data_new[$k] = $v;\\n                 }\\n+                \\n             }\\n             $request_data = $request_data_new;\\n         }\"}}",
      "message_norm": "fix xss on module api call in value parameters",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('xss', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/App/Http/Controllers/ApiController.php'])",
      "num_files": 1.0
    },
    {
      "index": 2460,
      "vuln_id": "GHSA-mr6r-82x4-f4jj",
      "cwe_id": "{'CWE-203'}",
      "score": 7.4,
      "chain": "{'https://github.com/simplito/elliptic-php/commit/15652609aa55968d56685c2a9120535ccdc00fd9'}",
      "dataset": "osv",
      "summary": "Timing attacks might allow practical recovery of the long-term private key In elliptic-php versions priot to 1.0.6, Timing attacks might be possible which can result in practical recovery of the long-term private key generated by the library under certain conditions. Leakage of a bit-length of the scalar during scalar multiplication is possible on an elliptic curve which might allow practical recovery of the long-term private key.",
      "published_date": "2019-11-20",
      "chain_len": 1,
      "project": "https://github.com/simplito/elliptic-php",
      "commit_href": "https://github.com/simplito/elliptic-php/commit/15652609aa55968d56685c2a9120535ccdc00fd9",
      "commit_sha": "15652609aa55968d56685c2a9120535ccdc00fd9",
      "patch": "SINGLE",
      "chain_ord": "['15652609aa55968d56685c2a9120535ccdc00fd9']",
      "before_first_fix_commit": "{'03a8dbc6514a1c8e6b00b967bca388d36ab73169'}",
      "last_fix_commit": "15652609aa55968d56685c2a9120535ccdc00fd9",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/14/2019, 13:43:07",
      "message": "ecdsa: Apply nonce bit-length mitigation to stop timing leakage.\n\nPorted from elliptic-js: https://github.com/indutny/elliptic/pull/203",
      "author": "Sebastian Smyczy\u0144ski",
      "comments": null,
      "stats": "{'additions': 11, 'deletions': 1, 'total': 12}",
      "files": "{'lib/EC.php': {'additions': 11, 'deletions': 1, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/simplito/elliptic-php/raw/15652609aa55968d56685c2a9120535ccdc00fd9/lib%2FEC.php', 'patch': \"@@ -136,7 +136,17 @@ public function sign($msg, $key, $enc = null, $options = null)\\n             if( $k->cmpn(1) <= 0 || $k->cmp($ns1) >= 0 )\\n                 continue;\\n \\n-            $kp = $this->g->mul($k);\\n+            // Fix the bit-length of the random nonce,\\n+            // so that it doesn't leak via timing.\\n+            // This does not change that ks = k mod k\\n+            $ks = $k->add($this->n);\\n+            $kt = $ks->add($this->n);\\n+            if ($ks->bitLength() === $this->n->bitLength()) {\\n+                $kp = $this->g->mul($kt);\\n+            } else {\\n+                $kp = $this->g->mul($ks);\\n+            }\\n+\\n             if( $kp->isInfinity() )\\n                 continue;\"}}",
      "message_norm": "ecdsa: apply nonce bit-length mitigation to stop timing leakage.\n\nported from elliptic-js: https://github.com/indutny/elliptic/pull/203",
      "language": "en",
      "entities": "[('ecdsa', 'SECWORD', ''), ('nonce', 'SECWORD', ''), ('timing leakage', 'SECWORD', ''), ('https://github.com/indutny/elliptic/pull/203', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/EC.php'])",
      "num_files": 1.0
    },
    {
      "index": 441,
      "vuln_id": "GHSA-4jqc-8m5r-9rpr",
      "cwe_id": "{'CWE-1321', 'CWE-843'}",
      "score": 7.3,
      "chain": "{'https://github.com/jonschlinkert/set-value/commit/7cf8073bb06bf0c15e08475f9f952823b4576452'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in set-value This affects the package `set-value` before 2.0.1, and starting with 3.0.0 but prior to 4.0.1. A type confusion vulnerability can lead to a bypass of CVE-2019-10747 when the user-provided keys used in the path parameter are arrays.",
      "published_date": "2021-09-13",
      "chain_len": 1,
      "project": "https://github.com/jonschlinkert/set-value",
      "commit_href": "https://github.com/jonschlinkert/set-value/commit/7cf8073bb06bf0c15e08475f9f952823b4576452",
      "commit_sha": "7cf8073bb06bf0c15e08475f9f952823b4576452",
      "patch": "SINGLE",
      "chain_ord": "['7cf8073bb06bf0c15e08475f9f952823b4576452']",
      "before_first_fix_commit": "{'17ac6b7baa01f328a41987e02c73b71b5b82bc3a'}",
      "last_fix_commit": "7cf8073bb06bf0c15e08475f9f952823b4576452",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/12/2021, 07:36:46",
      "message": "4.0.1\n\nFixes https://github.com/jonschlinkert/set-value/pull/33 thanks to @ready-research.",
      "author": "Jon Schlinkert",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'package.json': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/jonschlinkert/set-value/raw/7cf8073bb06bf0c15e08475f9f952823b4576452/package.json', 'patch': '@@ -1,6 +1,6 @@\\n {\\n   \"name\": \"set-value\",\\n-  \"version\": \"4.0.0\",\\n+  \"version\": \"4.0.1\",\\n   \"description\": \"Set nested properties on an object using dot notation.\",\\n   \"license\": \"MIT\",\\n   \"repository\": \"jonschlinkert/set-value\",\\n@@ -122,4 +122,4 @@\\n       \"update\"\\n     ]\\n   }\\n-}\\n\\\\ No newline at end of file\\n+}'}}",
      "message_norm": "4.0.1\n\nfixes https://github.com/jonschlinkert/set-value/pull/33 thanks to @ready-research.",
      "language": "en",
      "entities": "[('4.0.1', 'VERSION', ''), ('https://github.com/jonschlinkert/set-value/pull/33', 'URL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['package.json'])",
      "num_files": 1.0
    }
  ]
}