{
    "schema":{
        "fields":[
            {
                "name":"index",
                "type":"integer"
            },
            {
                "name":"vuln_id",
                "type":"string"
            },
            {
                "name":"cwe_id",
                "type":"string"
            },
            {
                "name":"score",
                "type":"number"
            },
            {
                "name":"chain",
                "type":"string"
            },
            {
                "name":"dataset",
                "type":"string"
            },
            {
                "name":"summary",
                "type":"string"
            },
            {
                "name":"published_date",
                "type":"string"
            },
            {
                "name":"chain_len",
                "type":"integer"
            },
            {
                "name":"project",
                "type":"string"
            },
            {
                "name":"commit_href",
                "type":"string"
            },
            {
                "name":"commit_sha",
                "type":"string"
            },
            {
                "name":"patch",
                "type":"string"
            },
            {
                "name":"chain_ord",
                "type":"string"
            },
            {
                "name":"before_first_fix_commit",
                "type":"string"
            },
            {
                "name":"last_fix_commit",
                "type":"string"
            },
            {
                "name":"chain_ord_pos",
                "type":"number"
            },
            {
                "name":"commit_datetime",
                "type":"string"
            },
            {
                "name":"message",
                "type":"string"
            },
            {
                "name":"author",
                "type":"string"
            },
            {
                "name":"comments",
                "type":"string"
            },
            {
                "name":"stats",
                "type":"string"
            },
            {
                "name":"files",
                "type":"string"
            },
            {
                "name":"message_norm",
                "type":"string"
            },
            {
                "name":"language",
                "type":"string"
            },
            {
                "name":"entities",
                "type":"string"
            },
            {
                "name":"classification_level_1",
                "type":"string"
            },
            {
                "name":"classification_level_2",
                "type":"string"
            },
            {
                "name":"list_files",
                "type":"string"
            },
            {
                "name":"num_files",
                "type":"number"
            }
        ],
        "primaryKey":[
            "index"
        ],
        "pandas_version":"1.4.0"
    },
    "data":[
        {
            "index":169,
            "vuln_id":"GHSA-2xw8-j43j-5vxp",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/elgg\/elgg\/commit\/c30b17bf75256ed3fcc84e2083147cc3951423d0'}",
            "dataset":"osv",
            "summary":"elgg is vulnerable to Cross-site Scripting elgg is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/elgg\/elgg",
            "commit_href":"https:\/\/github.com\/elgg\/elgg\/commit\/c30b17bf75256ed3fcc84e2083147cc3951423d0",
            "commit_sha":"c30b17bf75256ed3fcc84e2083147cc3951423d0",
            "patch":"SINGLE",
            "chain_ord":"['c30b17bf75256ed3fcc84e2083147cc3951423d0']",
            "before_first_fix_commit":"{'ea72485b6a08f30f452b8e5425310f2b3546050c'}",
            "last_fix_commit":"c30b17bf75256ed3fcc84e2083147cc3951423d0",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/06\/2021, 14:39:10",
            "message":"fix(reported_content): sanitize report URLs",
            "author":"Jer\u00f4me Bakker",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'mod\/reportedcontent\/actions\/reportedcontent\/add.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Elgg\/Elgg\/raw\/c30b17bf75256ed3fcc84e2083147cc3951423d0\/mod%2Freportedcontent%2Factions%2Freportedcontent%2Fadd.php', 'patch': '@@ -18,7 +18,7 @@\\n $report = new ElggReportedContent();\\n $report->owner_guid = elgg_get_logged_in_user_guid();\\n $report->title = $title;\\n-$report->address = $address;\\n+$report->address = elgg_normalize_site_url($address);\\n $report->description = $description;\\n $report->access_id = $access;'}}",
            "message_norm":"fix(reported_content): sanitize report urls",
            "language":"ro",
            "entities":"[('fix(reported_content', 'ACTION', ''), ('sanitize', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['mod\/reportedcontent\/actions\/reportedcontent\/add.php'])",
            "num_files":1.0
        },
        {
            "index":2899,
            "vuln_id":"GHSA-r89v-cgv7-3jhx",
            "cwe_id":"{'CWE-862'}",
            "score":5.2,
            "chain":"{'https:\/\/github.com\/octobercms\/october\/commit\/d34fb8ab51108495a9a651b841202d935f4e12f7'}",
            "dataset":"osv",
            "summary":"Bypass of fix for CVE-2020-15247, Twig sandbox escape ### Impact\nA bypass of CVE-2020-15247 (fixed in 1.0.469 and 1.1.0) was discovered that has the same impact as CVE-2020-15247:\n\nAn authenticated backend user with the `cms.manage_pages`, `cms.manage_layouts`, or `cms.manage_partials` permissions who would **normally** not be permitted to provide PHP code to be executed by the CMS due to `cms.enableSafeMode` being enabled is able to write specific Twig code to escape the Twig sandbox and execute arbitrary PHP.\n\nThis is not a problem for anyone that trusts their users with those permissions to normally write & manage PHP within the CMS by not having `cms.enableSafeMode` enabled, but would be a problem for anyone relying on `cms.enableSafeMode` to ensure that users with those permissions in production do not have access to write & execute arbitrary PHP.\n\n### Patches\nIssue has been patched in Build 470 (v1.0.470) and v1.1.1.\n\n### Workarounds\nApply https:\/\/github.com\/octobercms\/october\/commit\/d34fb8ab51108495a9a651b841202d935f4e12f7 to your installation manually if unable to upgrade to Build 470 or v1.1.1.\n\n### References\nReported by [ka1n4t](https:\/\/github.com\/ka1n4t)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at [hello@octobercms.com](mailto:hello@octobercms.com)\n\n### Threat assessment:\n<img width=\"1108\" alt=\"Screen Shot 2020-10-10 at 1 21 13 PM\" src=\"https:\/\/user-images.githubusercontent.com\/7253840\/95663316-7de28b80-0afb-11eb-999d-a6526cf78709.png\">",
            "published_date":"2020-11-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/octobercms\/october",
            "commit_href":"https:\/\/github.com\/octobercms\/october\/commit\/d34fb8ab51108495a9a651b841202d935f4e12f7",
            "commit_sha":"d34fb8ab51108495a9a651b841202d935f4e12f7",
            "patch":"SINGLE",
            "chain_ord":"['d34fb8ab51108495a9a651b841202d935f4e12f7']",
            "before_first_fix_commit":"{'16e0bd4d094264fd00d0af86180bde4e0c73b4be'}",
            "last_fix_commit":"d34fb8ab51108495a9a651b841202d935f4e12f7",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/13\/2020, 09:48:27",
            "message":"Improve Twig security policy\n\nFollow up to https:\/\/github.com\/octobercms\/october\/compare\/106daa2930de4cebb18732732d47d4056f01dd5b...7cb148c1677373ac30ccfd3069d18098e403e1ca. Thanks to @ka1n4t for the additional review.",
            "author":"Luke Towers",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'modules\/system\/twig\/SecurityPolicy.php': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/octobercms\/october\/raw\/d34fb8ab51108495a9a651b841202d935f4e12f7\/modules%2Fsystem%2Ftwig%2FSecurityPolicy.php', 'patch': \"@@ -20,6 +20,8 @@ final class SecurityPolicy implements SecurityPolicyInterface\\n     protected $blockedMethods = [\\n         'addDynamicMethod',\\n         'addDynamicProperty',\\n+        'bindEvent',\\n+        'bindEventOnce',\\n     ];\\n \\n     \/**\"}}",
            "message_norm":"improve twig security policy\n\nfollow up to https:\/\/github.com\/octobercms\/october\/compare\/106daa2930de4cebb18732732d47d4056f01dd5b...7cb148c1677373ac30ccfd3069d18098e403e1ca. thanks to @ka1n4t for the additional review.",
            "language":"en",
            "entities":"[('improve', 'ACTION', ''), ('security', 'SECWORD', ''), ('https:\/\/github.com\/octobercms\/october\/compare\/106daa2930de4cebb18732732d47d4056f01dd5b...7cb148c1677373ac30ccfd3069d18098e403e1ca', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/system\/twig\/SecurityPolicy.php'])",
            "num_files":1.0
        },
        {
            "index":1305,
            "vuln_id":"GHSA-93q8-gq69-wqmw",
            "cwe_id":"{'CWE-697', 'CWE-1333'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chalk\/ansi-regex\/commit\/8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9'}",
            "dataset":"osv",
            "summary":"Inefficient Regular Expression Complexity in chalk\/ansi-regex ansi-regex is vulnerable to Inefficient Regular Expression Complexity which could lead to a denial of service.",
            "published_date":"2021-09-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/chalk\/ansi-regex",
            "commit_href":"https:\/\/github.com\/chalk\/ansi-regex\/commit\/8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9",
            "commit_sha":"8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9",
            "patch":"SINGLE",
            "chain_ord":"['8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9']",
            "before_first_fix_commit":"{'c1b5e45f7c65a332ffb03ac8e5804ad37c579cdc'}",
            "last_fix_commit":"8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/10\/2021, 20:23:24",
            "message":"Fix potential ReDoS (#37)",
            "author":"Yeting Li",
            "comments":"{'com_1': {'author': 'BeigeBox', 'datetime': '09\/23\/2021, 21:00:58', 'body': \"Which versions of ansi-regex are impacted by this vulnerability?  Several scanners are flagging all versions of this library other than 5.0.1 and 6.0.1.  I suspect some of the older versions aren't impacted, because the pattern variable is different (just spot checked I think v2.1.1 and v3).\"}, 'com_2': {'author': 'Qix-', 'datetime': '09\/26\/2021, 15:10:07', 'body': \"Not sure because the security researchers are not doing their due diligence and are instead farming bounty money on e.g. huntr.dev, targeting the most used repositories for clout.\\r\\n\\r\\nI'm really not sure what to do about this and it's eating a lot of time away. The vulnerability itself is not major - unless you're allowing long AND unsanitized user input to hit the API directly, the vulnerability doesn't affect you.\\r\\n\\r\\nI have no idea which versions it actually affects because they didn't test it correctly.\"}, 'com_3': {'author': 'thoger', 'datetime': '09\/27\/2021, 18:07:58', 'body': \"Confirmed 4.1.0 and 3.0.0 as affected testing using the provided reproducer.  2.1.1 does not reproduce the issue.\\r\\n\\r\\n3.0.0 is the first affected, as that's the first version that includes 69bebf6b8 that the problematic part of the regex.\"}, 'com_4': {'author': 'Qix-', 'datetime': '09\/27\/2021, 18:22:35', 'body': 'Thank you @thoger. \ud83d\ude42'}, 'com_5': {'author': 'arungpro', 'datetime': '10\/12\/2021, 11:28:32', 'body': '@thoger Does 5.0.0 or above, are not affected this? Can you confirm on the same?'}, 'com_6': {'author': 'Qix-', 'datetime': '10\/12\/2021, 11:51:24', 'body': '@arungpro `5.0.0` is affected, `5.0.1` is not. Likewise, `6.0.0` is affected, `6.0.1` is not.'}, 'com_7': {'author': 'OnlineCop', 'datetime': '01\/10\/2022, 17:01:46', 'body': 'Would someone be able to help me understand the exact formatting going on here?\\r\\n\\r\\nI assume that the `\\\\` backslashes are escaped because this is within a string, meaning `\\\\u001B` must be represented as `\\\\\\\\u001B` ?\\r\\n\\r\\nI copied the \"proposed\" escaped original into [regex101](https:\/\/regex101.com\/r\/UR7Ma5\/1) and removed the escape characters to produce this:\\r\\n\\r\\n```[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]*)*)?\\\\u0007)```\\r\\n\\r\\nI then plugged that unescaped version [back in](https:\/\/regex101.com\/r\/UR7Ma5\/2) to determine whether there were any problems with the pattern itself, and see that there is an incomplete\/unclosed `(?:` which should probably be removed:\\r\\n\\r\\n```[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]*)*)?\\\\u0007```\\r\\n\\r\\nThe next outer `(?: ... )` group appears to have no alternations or quantifiers, so can probably also be removed:\\r\\n\\r\\n```(?:(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]*)*)?\\\\u0007)```\\r\\n\\r\\nThe next `(?: ... | ... )?` group does contain an alternation, and is qualified by its `?` quantifier. Immediately after this optional group, it looks for `\\\\u0007` at the end.\\r\\n\\r\\nWithin both alternations, the character groups `[-a-zA-Z\\\\d\\\\\/#&.:=?%@~_]` can be shortened: `[a-zA-Z0-9_]` or `[a-zA-Z\\\\d_]` can be replaced with `\\\\w`, so: `[-\\\\w\\\\\/#&.:=?%@~]`.\\r\\n\\r\\nThat would look like this:\\r\\n\\r\\n```[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:;[-\\\\w\\\\\/#&.:=?%@~]+)*|[a-zA-Z\\\\d]+(?:;[-\\\\w\\\\\/#&.:=?%@~]*)*)?\\\\u0007```\\r\\n\\r\\nSo, within the first alternation, it matches a semicolon `;` followed by **one** or more of those character-group characters. Within the second alternation, it first looks for letters or numbers, followed by any number of semicolon `;` followed by **zero** or more of those character-group characters. I\\'m not sure whether that would want to be a `+` one-or-more, since that would allow \"abc;;;;;;;;;\" to match there instead of requiring characters between those semicolons.\\r\\n\\r\\nIf you look at [this example](https:\/\/regex101.com\/r\/UR7Ma5\/3), I\\'ve changed the outer non-capturing `(?: ... )?` to a capturing group just for illustrative purposes so you can see how the semicolon is matched in one case but not in the other due to this **zero** or more quantifiers. You can see this when the semicolon is added to the text in [this next example](https:\/\/regex101.com\/r\/UR7Ma5\/4).\\r\\n\\r\\nIf both `;[-\\\\w\\\\\/#&.:=?%@~]` character groups are quantified with zero-or-more `*`, then subsequent semicolons `;;` will match, while if they are quantified with one-or-more `+`, the match fails due to subsequent semicolons `;;`.'}, 'com_8': {'author': 'lorand-horvath', 'datetime': '04\/02\/2022, 07:47:22', 'body': 'ansi-regex v3 and v4 should now include the vulnerability fixes:\\r\\n`3.0.1` in https:\/\/github.com\/chalk\/ansi-regex\/commit\/419250fa510bf31b4cc672e76537a64f9332e1f1 and https:\/\/github.com\/chalk\/ansi-regex\/commit\/c57d4c2fdbe0357a0f6dd42d1160defdc9fffdf5\\r\\n`4.1.1` in https:\/\/github.com\/chalk\/ansi-regex\/commit\/75a657da7af875b2e2724fd6331bf0a4b23d3c9a'}, 'com_9': {'author': 'romans-ovo', 'datetime': '07\/13\/2022, 15:36:46', 'body': '> ansi-regex v3 and v4 should now include the vulnerability fixes: `3.0.1` in [419250f](https:\/\/github.com\/chalk\/ansi-regex\/commit\/419250fa510bf31b4cc672e76537a64f9332e1f1) and [c57d4c2](https:\/\/github.com\/chalk\/ansi-regex\/commit\/c57d4c2fdbe0357a0f6dd42d1160defdc9fffdf5) `4.1.1` in [75a657d](https:\/\/github.com\/chalk\/ansi-regex\/commit\/75a657da7af875b2e2724fd6331bf0a4b23d3c9a)\\r\\n\\r\\nNeither 3.0.1, nor 4.1.1 are listed on https:\/\/www.npmjs.com\/package\/ansi-regex (under Versions), btw.'}, 'com_10': {'author': 'Qix-', 'datetime': '07\/13\/2022, 15:42:41', 'body': '<img width=\"614\" alt=\"image\" src=\"https:\/\/user-images.githubusercontent.com\/885648\/178775021-919b8738-8879-4edc-8507-a6b2475c5631.png\">\\r\\nYou sure?'}, 'com_11': {'author': 'papb', 'datetime': '08\/01\/2022, 02:05:09', 'body': \"> Would someone be able to help me understand the exact formatting going on here?\\r\\n\\r\\n@OnlineCop can you first help me understand what exactly is your question here? Are you trying to understand what the code is doing? Are you proposing a readability improvement? Or performance improvement? Sorry, you said a lot of things but I couldn't even understand what is your goal, roughly...\\r\\n\\r\\n> I assume that the `\\\\` backslashes are escaped because this is within a string, meaning `\\\\u001B` must be represented as `\\\\\\\\u001B` ?\\r\\n\\r\\nYes, exactly.\"}, 'com_12': {'author': 'OnlineCop', 'datetime': '08\/01\/2022, 14:23:36', 'body': \"In the original, lines 2-5 were looking for:\\r\\n1. either `\\\\u001B` (ESC) or `\\\\u009B` (\u00a2 cent sign) followed by 0 or more of these characters: `[]()#;?`\\r\\n\\r\\nAfter that, it was looking for either:\\r\\n2. any number of letters, numbers, semi-colons, or special characters that came before `\\\\u0007` (BEL)\\r\\n    - There were a _lot_ of 0-or-more groups, all of which was also within its own `(?:...)?` 0-or-1 (optional) group, before that BEL.\\r\\n    - It was definitely something that could cause ReDoS.\\r\\n3. or an optional group of digits and semi-colons, followed by a single character in the range `[\\\\dA-PR-TZcf-ntqry=><~]`.\\r\\n    - This optional group also had potential for a ReDoS.\\r\\n\\r\\nIn the revised version, lines 2-5 were looking for the same characters as 1. above, but increased the variety of characters allowed before `\\\\u0007` and still has a lot of potential for ReDoS (possibly more than before).\\r\\n\\r\\nI don't understand what exactly is supposed to be matched here. Both BEFORE and AFTER versions have a high probability to cause catastrophic backtracking. Are there any tests that should match either of the BEFORE or AFTER regexes?\"}, 'com_13': {'author': 'Qix-', 'datetime': '08\/02\/2022, 22:47:38', 'body': \"Feel free to create a reproduction case that exploits exponential time complexity and file an issue. Otherwise I'm not sure what you're trying to say.\"}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chalk\/ansi-regex\/raw\/8d1d7cdb586269882c4bdc1b7325d0c58c8f76f9\/index.js', 'patch': \"@@ -1,6 +1,6 @@\\n export default function ansiRegex({onlyFirst = false} = {}) {\\n \\tconst pattern = [\\n-\\t\\t'[\\\\\\\\u001B\\\\\\\\u009B][[\\\\\\\\]()#;?]*(?:(?:(?:[a-zA-Z\\\\\\\\d]*(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\\/#&.:=?%@~_]*)*)?\\\\\\\\u0007)',\\n+\\t    '[\\\\\\\\u001B\\\\\\\\u009B][[\\\\\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\\\\\d]+(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\\/#&.:=?%@~_]*)*)?\\\\\\\\u0007)',\\n \\t\\t'(?:(?:\\\\\\\\d{1,4}(?:;\\\\\\\\d{0,4})*)?[\\\\\\\\dA-PR-TZcf-ntqry=><~]))'\\n \\t].join('|');\"}}",
            "message_norm":"fix potential redos (#37)",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('#37', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":368,
            "vuln_id":"GHSA-468q-v4jj-485h",
            "cwe_id":"{'CWE-1333'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/nervjs\/taro\/commit\/acadb6c826ba57f2030a626f1de4f7b4608fcdb5'}",
            "dataset":"osv",
            "summary":"Inefficient Regular Expression Complexity in taro taro is vulnerable to Inefficient Regular Expression Complexity",
            "published_date":"2021-09-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/nervjs\/taro",
            "commit_href":"https:\/\/github.com\/nervjs\/taro\/commit\/acadb6c826ba57f2030a626f1de4f7b4608fcdb5",
            "commit_sha":"acadb6c826ba57f2030a626f1de4f7b4608fcdb5",
            "patch":"SINGLE",
            "chain_ord":"['acadb6c826ba57f2030a626f1de4f7b4608fcdb5']",
            "before_first_fix_commit":"{'51a672907177558f20d664e7c196fdb0bff41c75'}",
            "last_fix_commit":"acadb6c826ba57f2030a626f1de4f7b4608fcdb5",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/02\/2021, 14:08:46",
            "message":"Security fix for ReDoS\n\nFixed Regular Expression Denial of Service vulnerability in url validation",
            "author":"ready-research",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'packages\/taro-helper\/src\/constants.ts': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NervJS\/taro\/raw\/acadb6c826ba57f2030a626f1de4f7b4608fcdb5\/packages%2Ftaro-helper%2Fsrc%2Fconstants.ts', 'patch': '@@ -104,7 +104,7 @@ export const REG_JSON = \/\\\\.json(\\\\?.*)?$\/\\n export const REG_UX = \/\\\\.ux(\\\\?.*)?$\/\\n export const REG_TEMPLATE = \/\\\\.(wxml|axml|ttml|qml|swan|jxml)(\\\\?.*)?$\/\\n export const REG_WXML_IMPORT = \/<import(.*)?src=(?:(?:\\'([^\\']*)\\')|(?:\"([^\"]*)\"))\/gi\\n-export const REG_URL = \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:\\\\S+(?::\\\\S*)?@)?(?:(?!(?:10|127)(?:\\\\.\\\\d{1,3}){3})(?!(?:169\\\\.254|192\\\\.168)(?:\\\\.\\\\d{1,3}){2})(?!172\\\\.(?:1[6-9]|2\\\\d|3[0-1])(?:\\\\.\\\\d{1,3}){2})(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)*(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,}))\\\\.?)(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i\\n+export const REG_URL = \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:\\\\S+(?::\\\\S*)?@)?(?:(?!(?:10|127)(?:\\\\.\\\\d{1,3}){3})(?!(?:169\\\\.254|192\\\\.168)(?:\\\\.\\\\d{1,3}){2})(?!172\\\\.(?:1[6-9]|2\\\\d|3[0-1])(?:\\\\.\\\\d{1,3}){2})(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z0-9\\\\u00a1-\\\\uffff][a-z0-9\\\\u00a1-\\\\uffff_-]{0,62})?[a-z0-9\\\\u00a1-\\\\uffff]\\\\.)+(?:[a-z\\\\u00a1-\\\\uffff]{2,}\\\\.?))(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i\\n export const CSS_IMPORT_REG = \/@import ([\"\\'])(.+?)\\\\1;\/g\\n \\n export const NODE_MODULES = \\'node_modules\\''}}",
            "message_norm":"security fix for redos\n\nfixed regular expression denial of service vulnerability in url validation",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('redos', 'SECWORD', ''), ('fixed', 'ACTION', ''), ('denial of service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('url validation', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['packages\/taro-helper\/src\/constants.ts'])",
            "num_files":1.0
        },
        {
            "index":2924,
            "vuln_id":"GHSA-rf3h-xgv5-2q39",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite's implementation of `DepthwiseConv` ### Impact\nThe implementation of the `DepthwiseConv` TFLite operator is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/1a8e885b864c818198a5b2c0cbbeca5a1e833bc8\/tensorflow\/lite\/kernels\/depthwise_conv.cc#L287-L288):\n\n```cc\nint num_input_channels = SizeOfDimension(input, 3);\nTF_LITE_ENSURE_EQ(context, num_filter_channels % num_input_channels, 0);\n```\n\nAn attacker can craft a model such that `input`'s fourth dimension would be 0.\n\n### Patches\nWe have patched the issue in GitHub commit [cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0",
            "commit_sha":"cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0",
            "patch":"SINGLE",
            "chain_ord":"['cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0']",
            "before_first_fix_commit":"{'1a8e885b864c818198a5b2c0cbbeca5a1e833bc8'}",
            "last_fix_commit":"cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 22:53:48",
            "message":"Prevent divisions by 0\n\nPiperOrigin-RevId: 371003153\nChange-Id: Idef56c95b9fcaeb97f87e18c7a674dbeb5173204",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 2, 'total': 5}",
            "files":"{'tensorflow\/lite\/kernels\/depthwise_conv.cc': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0\/tensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc', 'patch': '@@ -285,8 +285,8 @@ TfLiteStatus ComputeDepthMultiplier(TfLiteContext* context,\\n                                     int16* depth_multiplier) {\\n   int num_filter_channels = SizeOfDimension(filter, 3);\\n   int num_input_channels = SizeOfDimension(input, 3);\\n+  TF_LITE_ENSURE(context, num_input_channels != 0);\\n   TF_LITE_ENSURE_EQ(context, num_filter_channels % num_input_channels, 0);\\n-\\n   *depth_multiplier = num_filter_channels \/ num_input_channels;\\n   return kTfLiteOk;\\n }\\n@@ -455,8 +455,9 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\\n   float output_activation_min, output_activation_max;\\n   CalculateActivationRange(params->activation, &output_activation_min,\\n                            &output_activation_max);\\n-  const int input_size = NumElements(input) \/ SizeOfDimension(input, 0);\\n   const int batch_size = SizeOfDimension(input, 0);\\n+  TF_LITE_ENSURE(context, batch_size != 0);\\n+  const int input_size = NumElements(input) \/ batch_size;\\n   TfLiteTensor* input_quantized;\\n   TF_LITE_ENSURE_OK(context,\\n                     GetTemporarySafe(context, node, data->input_quantized_index,'}}",
            "message_norm":"prevent divisions by 0\n\npiperorigin-revid: 371003153\nchange-id: idef56c95b9fcaeb97f87e18c7a674dbeb5173204",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('divisions by 0', 'SECWORD', ''), ('371003153', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/depthwise_conv.cc'])",
            "num_files":1.0
        },
        {
            "index":268,
            "vuln_id":"GHSA-3j9m-hcv9-rpj8",
            "cwe_id":"{'CWE-79'}",
            "score":6.9,
            "chain":"{'https:\/\/github.com\/grafana\/grafana\/commit\/3cb5214fa45eb5a571fd70d6c6edf0d729983f82', 'https:\/\/github.com\/grafana\/grafana\/commit\/fb85ed691290d211a5baa44d9a641ab137f0de88', 'https:\/\/github.com\/grafana\/grafana\/commit\/31b78d51c693d828720a5b285107a50e6024c912'}",
            "dataset":"osv",
            "summary":"XSS vulnerability allowing arbitrary JavaScript execution Today we are releasing Grafana 8.2.3. This patch release includes an important security fix for an issue that affects all Grafana versions from 8.0.0-beta1.\n\n[Grafana Cloud](https:\/\/grafana.com\/cloud) instances have already been patched and an audit did not find any usage of this attack vector. [Grafana Enterprise](https:\/\/grafana.com\/products\/enterprise) customers were provided with updated binaries under embargo.\n\n## CVE-2021-41174 XSS vulnerability on unauthenticated pages\n\n### Summary\n\nCVSS Score: 6.9 Medium\nCVSS:[CVSS:3.0\/AV:N\/AC:H\/PR:N\/UI:R\/S:C\/C:L\/I:H\/A:N\/E:U\/RL:O\/RC:R\/CR:L\/MAV:N\/MAC:H\/MPR:N\/MUI:R\/MS:C\/MC:N\/MI:H\/MA:L](https:\/\/www.first.org\/cvss\/calculator\/3.0#CVSS:3.0\/AV:N\/AC:H\/PR:N\/UI:R\/S:C\/C:L\/I:H\/A:N\/E:U\/RL:O\/RC:R\/CR:L\/MAV:N\/MAC:H\/MPR:N\/MUI:R\/MS:C\/MC:N\/MI:H\/MA:L)\n\nWe received a security report to security@grafana.com on 2021-10-21 about a vulnerability in Grafana regarding the XSS vulnerability.\n\nIt was later identified as affecting Grafana versions from 8.0.0-beta1 to 8.2.2. [CVE-2021-41174](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-41174) has been assigned to this vulnerability.\n\n### Impact\n\nIf an attacker is able to convince a victim to visit a URL referencing a vulnerable page, arbitrary JavaScript content may be executed within the context of the victim's browser.\n\nThe user visiting the malicious link must be unauthenticated and the link must be for a page that contains the login button in the menu bar.\n\nThere are two ways an unauthenticated user can open a page in Grafana that contains the login button:\n- Anonymous authentication is enabled. This means all pages in Grafana would be open for the attack.\n- The link is to an unauthenticated page. The following pages are vulnerable:\n  - `\/dashboard-solo\/snapshot\/*`\n  - `\/dashboard\/snapshot\/*`\n  - `\/invite\/:code`\n\nThe url has to be crafted to exploit AngularJS rendering and contain the interpolation binding for AngularJS expressions. AngularJS uses double curly braces for interpolation binding: {{ }} \n\nAn example of an expression would be: `{{constructor.constructor(\u2018alert(1)\u2019)()}}`. This can be included in the link URL like this: \n\nhttps:\/\/play.grafana.org\/dashboard\/snapshot\/%7B%7Bconstructor.constructor('alert(1)')()%7D%7D?orgId=1\n\nWhen the user follows the link and the page renders, the login button will contain the original link with a query parameter to force a redirect to the login page. The URL is not validated and the AngularJS rendering engine will execute the JavaScript expression contained in the URL.\n\n### Attack audit\n\nWe can not guarantee that the below will identify all attacks, so if you find something using the audit process described below, you should consider doing a full assessment.\n\n#### Through reverse proxy\/load balancer logs\n\nTo determine if your Grafana installation has been exploited for this vulnerability, search through your reverse proxy\/load balancer access logs for instances where the path contains `{{` followed by something that would invoke JavaScript code. For example, this could be code that attempts to show a fake login page or to steal browser or session data. The [OWASP cheat sheet](https:\/\/cheatsheetseries.owasp.org\/cheatsheets\/XSS_Filter_Evasion_Cheat_Sheet.html) has several examples of XSS attacks.\n\n#### Through the Grafana Enterprise audit feature\n\nIf you enabled \u201cLog web requests\u201d in your configuration with `router_logging = true`, look for requests where `path` contains `{{` followed by something that would invoke JavaScript code.\n\n### Patched versions\n\nRelease 8.2.3:\n\n- [Download Grafana 8.2.3](https:\/\/grafana.com\/grafana\/download\/8.2.3)\n- [Release notes](https:\/\/grafana.com\/docs\/grafana\/latest\/release-notes\/release-notes-8-2-3\/)\n\n### Solutions and mitigations\n\nDownload and install the appropriate patch for your version of Grafana.\n\n[Grafana Cloud](https:\/\/grafana.com\/cloud) instances have already been patched, and [Grafana Enterprise](https:\/\/grafana.com\/products\/enterprise) customers were provided with updated binaries under embargo.\n\n### Workaround\n\nIf for some reason you cannot upgrade, you can use a reverse proxy or similar to block access to block the literal string `{{` in the path.\n\nExample of an Nginx rule to block the literal string `{{`:\n\n```\nlocation ~ \\{\\{ {\n    deny all;\n}\n```\n### Timeline and postmortem\n\nHere is a detailed timeline starting from when we originally learned of the issue. All times in UTC. \n\n* 2021-10-21 23:13: Security researcher sends the initial report about an XSS vulnerability.\n* 2021-10-21 23:13: Confirmed to be reproducible in at least versions 8.0.5 and 8.2.2.\n* 2021-10-22 02:02 MEDIUM severity declared.\n* 2021-10-22 09:22: it is discovered that Grafana instances with anonymous auth turned on are vulnerable. This includes https:\/\/play.grafana.org\/ .\n* 2021-10-22 09:50: Anonymous access disabled for all instances on Grafana Cloud as a mitigation measure.\n* 2021-10-22 11:15: Workaround deployed on Grafana Cloud that blocks malicious requests.\n* 2021-10-22 12:35: Enabled anonymous access for instances on Grafana Cloud. \n* 2021-10-22 12:51: All instances protected by the workaround. From this point forward, Grafana Cloud is no longer affected.\n* 2021-10-22 14:05 Grafana Cloud instances updated with a fix.\n* 2021-10-22 19:23 :Determination that no weekend work is needed as the issue is of MEDIUM severity and the root cause has been identified.\n* 2021-10-25 14:13: Audit of Grafana Cloud concluded, no evidence of exploitation.\n* 2021-10-27 12:00: Grafana Enterprise images released to customers under embargo.\n* 2021-11-03 12:00: Public release.\n\n## Reporting security issues\n\nIf you think you have found a security vulnerability, please send a report to [security@grafana.com](mailto:security@grafana.com). This address can be used for all of\nGrafana Labs' open source and commercial products (including but not limited to Grafana, Tempo, Loki, k6, Tanka, and  Grafana Cloud, Grafana Enterprise, and grafana.com). We only accept vulnerability reports at this address. We would prefer that you encrypt your message to us using our PGP key. The key fingerprint is:\n\nF988 7BEA 027A 049F AE8E  5CAA D125 8932 BE24 C5CA\n\nThe key is available from [ keyserver.ubuntu.com]( https:\/\/keyserver.ubuntu.com\/pks\/lookup?op=get&fingerprint=on&search=0xD1258932BE24C5CA) by searching for [security@grafana]( https:\/\/keyserver.ubuntu.com\/pks\/lookup?search=security@grafana&fingerprint=on&op=index).\n\n## Security announcements\n\nThere is a Security [category](https:\/\/grafana.com\/tags\/security\/) on the Grafana blog where we will post a summary, remediation, and mitigation details for any patch containing security fixes and you can subscribe to updates from our [Security Announcements RSS feed](https:\/\/grafana.com\/tags\/security\/index.xml).",
            "published_date":"2021-11-08",
            "chain_len":3,
            "project":"https:\/\/github.com\/grafana\/grafana",
            "commit_href":"https:\/\/github.com\/grafana\/grafana\/commit\/3cb5214fa45eb5a571fd70d6c6edf0d729983f82",
            "commit_sha":"3cb5214fa45eb5a571fd70d6c6edf0d729983f82",
            "patch":"MULTI",
            "chain_ord":"['31b78d51c693d828720a5b285107a50e6024c912', '3cb5214fa45eb5a571fd70d6c6edf0d729983f82', 'fb85ed691290d211a5baa44d9a641ab137f0de88']",
            "before_first_fix_commit":"{'3cb5214fa45eb5a571fd70d6c6edf0d729983f82', 'a3dc30546fce2e437d858c140f1ff307a04365d6'}",
            "last_fix_commit":"fb85ed691290d211a5baa44d9a641ab137f0de88",
            "chain_ord_pos":2.0,
            "commit_datetime":"10\/25\/2021, 07:16:51",
            "message":"Merge pull request #151 from grafana\/dcech\/sanitize-replaceAll\n\nuse global replace when sanitizing urls in 8.2.3",
            "author":"Dimitris Sotirakis",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'packages\/grafana-data\/src\/text\/sanitize.ts': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/grafana\/grafana\/raw\/3cb5214fa45eb5a571fd70d6c6edf0d729983f82\/packages%2Fgrafana-data%2Fsrc%2Ftext%2Fsanitize.ts', 'patch': \"@@ -40,5 +40,5 @@ export function escapeHtml(str: string): string {\\n }\\n \\n export function sanitizeAngularInterpolation(url: string): string {\\n-  return url.replace('{{', '%7B%7B').replace('}}', '%7D%7D');\\n+  return url.replace(\/\\\\{\\\\{\/g, '%7B%7B').replace(\/\\\\}\\\\}\/g, '%7D%7D');\\n }\"}}",
            "message_norm":"merge pull request #151 from grafana\/dcech\/sanitize-replaceall\n\nuse global replace when sanitizing urls in 8.2.3",
            "language":"en",
            "entities":"[('#151', 'ISSUE', ''), ('sanitize', 'SECWORD', ''), ('sanitizing', 'SECWORD', ''), ('8.2.3', 'VERSION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['packages\/grafana-data\/src\/text\/sanitize.ts'])",
            "num_files":1.0
        },
        {
            "index":738,
            "vuln_id":"GHSA-63m4-fhf2-cmf7",
            "cwe_id":"{'CWE-78'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/KyleRoss\/windows-cpu\/commit\/b75e19aa2f7459a9506bceb577ba2341fe273117'}",
            "dataset":"osv",
            "summary":"Command Execution in windows-cpu Version of `windows-cpu` before 0.1.5 will execute arbitrary code passed into the first argument of the `findLoad` method, resulting in remote code execution.\n\n## Proof of Concept\n\n```\nvar win = require('windows-cpu');\nwind.findLoad('foo & calc.exe');\n```\n\n\n## Recommendation\n\nUpdate to version 0.1.5 or later.",
            "published_date":"2020-09-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/KyleRoss\/windows-cpu",
            "commit_href":"https:\/\/github.com\/KyleRoss\/windows-cpu\/commit\/b75e19aa2f7459a9506bceb577ba2341fe273117",
            "commit_sha":"b75e19aa2f7459a9506bceb577ba2341fe273117",
            "patch":"SINGLE",
            "chain_ord":"['b75e19aa2f7459a9506bceb577ba2341fe273117']",
            "before_first_fix_commit":"{'da656c1a9d5edbf4e8bf0640f349aeb714a4f1a0'}",
            "last_fix_commit":"b75e19aa2f7459a9506bceb577ba2341fe273117",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2017, 04:32:09",
            "message":"ES6 Refactor + fix vulnerability",
            "author":"Kyle Ross",
            "comments":null,
            "stats":"{'additions': 120, 'deletions': 143, 'total': 263}",
            "files":"{'index.js': {'additions': 120, 'deletions': 143, 'changes': 263, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/KyleRoss\/windows-cpu\/raw\/b75e19aa2f7459a9506bceb577ba2341fe273117\/index.js', 'patch': '@@ -1,120 +1,92 @@\\n \/**\\n  * windows-cpu module for Node.js to get various load statistics.\\n  * @module windows-cpu\\n- * @version 0.1.4\\n- * @author Kyle Ross <kylerross1324@gmail.com>\\n+ * @version 1.0.0\\n+ * @author Kyle Ross\\n  * @license MIT License\\n- * \\n- * @requires os\\n- * @requires child_process\\n- *\\n- * @example\\n- *\\n- * var cpu = require(\\'windows-cpu\\');\\n  *\/\\n+\"use strict\";\\n \\n-(function() {\\n-    var platform = require(\\'os\\').platform(),\\n-        path     = require(\\'path\\'),\\n-        exec     = require(\\'child_process\\').exec,\\n-        execFile = require(\\'child_process\\').execFile,\\n-        wmic     = platform === \\'win32\\'? path.join(process.env.SystemRoot, \\'System32\\', \\'wbem\\', \\'wmic.exe\\') : null,\\n-        emptyFn  = function(){},\\n-        findLoad;\\n-    \\n-    \/*\\n-     * Checks current platform to ensure we are running on `win32`.\\n-     * @private\\n-     * @param {function} cb A callback function to call if there is an error.\\n-     * @returns {boolean} True if `win32` platform, else false.\\n-     *\/\\n-    function checkPlatform(cb) {\\n-        if(platform !== \\'win32\\') {\\n-            if(isFunction(cb)) cb(new Error(\\'windows-cpu> [ERROR] This module only works on Windows platforms.\\'));\\n-            return false;\\n-        }\\n-        return true;\\n-    }\\n+const fs = require(\\'fs\\');\\n+const path = require(\\'path\\');\\n+const cp = require(\\'child_process\\');\\n+const platform = require(\\'os\\').platform();\\n+\\n+const exec = cp.exec;\\n+const execFile = cp.execFile;\\n+const wmic = path.join(process.env.SystemRoot, \\'System32\\', \\'wbem\\', \\'wmic.exe\\');\\n+\\n+\/**\\n+ * Finds the current processor load of a specific process name or id.\\n+ * @private\\n+ * @param  {String}   arg Process name or id to lookup\\n+ * @param  {Function} cb  Callback to call with results\\n+ *\/\\n+function findLoad(arg, cb) {\\n+    let cmd = `wmic path Win32_PerfFormattedData_PerfProc_Process get Name,PercentProcessorTime,IDProcess | findstr \/i \/c:${arg}`;\\n     \\n-    \/*\\n-     * Proper checking to see if variable is a function.\\n-     * @private\\n-     * @param {*} fn The variable to check if is a function.\\n-     * @returns {boolean} True if is a function, else false.\\n-     *\/\\n-    function isFunction(fn) {\\n-        var getType = {};\\n-        return fn && getType.toString.call(fn) === \\'[object Function]\\';\\n+    exec(cmd, function(error, res, stderr) {\\n+        if(error !== null || stderr) return cb(error || stderr);\\n+        if(!res) return cb(`Cannot find results for provided arg: ${arg}`, { load: 0, results: [] });\\n+        \\n+        let found = res.replace(\/[^\\\\S\\\\n]+\/g, \\':\\').replace(\/:\\\\s\/g, \\'|\\').split(\\'|\\').filter(function(v) {\\n+            return !!v;\\n+        }).map(function(v) {\\n+            let [pid, proc, load] = v.split(\\':\\');\\n+            return {\\n+                pid: +pid,\\n+                process: proc,\\n+                load: +load\\n+            };\\n+        });\\n+        \\n+        let load = found.reduce((acc, val) => {\\n+            return acc + val.load;\\n+        }, 0);\\n+        \\n+        cb(null, { load, found });\\n+    });\\n+}\\n+\\n+\/**\\n+ * @class Public class for WindowsCPU\\n+ *\/\\n+class WindowsCPU {\\n+    constructor() {\\n+        \/**\\n+         * Access to uninstantiated WindowsCPU class\\n+         * @type {Class}\\n+         *\/\\n+        this.WindowsCPU = WindowsCPU;\\n+        this.checkPlatform();\\n     }\\n     \\n     \/**\\n-     * Gets the total load in percent for process(es) by a specific search parameter.\\n-     * @param {string|number} arg Specific search parameter. Can be a Process ID or Process Name.\\n-     * @param {function} cb A callback function to handle the results (error, results).\\n-     * @example\\n-     *\\n-     * var cpu = require(\\'windows-cpu\\');\\n-     *\\n-     * \/\/ Find the total load for \"chrome\" processes\\n-     * cpu.findLoad(\\'chrome\\', function(error, results) {\\n-     *      if(error) {\\n-     *          return console.log(error);\\n-     *      }\\n-     *\\n-     *      \/\/ results =>\\n-     *      \/\/ {\\n-     *      \/\/    load: 8,\\n-     *      \/\/    found: [\\n-     *      \/\/        { pid: \\'900\\', process: \\'chrome\\', load: 4 },\\n-     *      \/\/        { pid: \\'905\\', process: \\'chrome#1\\', load: 0 },\\n-     *      \/\/        { pid: \\'910\\', process: \\'chrome#2\\', load: 4 }\\n-     *      \/\/    ]\\n-     *      \/\/ }\\n-     *\\n-     *      console.log(\\'Google Chrome is currently using \\' + results.load + \\'% of the cpu.\\');\\n-     * });\\n+     * Checks if the current platform is supported by windows-cpu\\n+     * @return {Boolean} Returns `true` if platform is supported\\n+     * @throws {Error} If platform is not Windows\\n+     * @throws {Error} If wmic.exe process does not exist or cannot be accessed\\n      *\/\\n-    findLoad = exports.findLoad = function findLoad(arg, cb) {\\n-        if(!isFunction(cb)) cb = emptyFn;\\n-        if(!checkPlatform(cb)) return;\\n+    checkPlatform() {\\n+        if(platform !== \\'win32\\') \\n+            throw new Error(\\'windows-cpu only works on Windows platforms.\\');\\n         \\n-        var cmd = \"wmic path Win32_PerfFormattedData_PerfProc_Process get Name,PercentProcessorTime,IDProcess | findstr \/i \/c:\" + arg;\\n-        exec(cmd, function (error, res, stderr) {\\n-            if(error !== null || stderr) return cb(error || stderr);\\n-            if(!res) return cb(\\'Cannot find results for provided arg: \\' + arg, { load: 0, results: [] });\\n-            \\n-            var found = res.replace(\/[^\\\\S\\\\n]+\/g, \\':\\').replace(\/\\\\:\\\\s\/g, \\'|\\').split(\\'|\\').filter(function(v) {\\n-                return !!v;\\n-            }).map(function(v) {\\n-                var data = v.split(\\':\\');\\n-                return {\\n-                    pid: +data[0],\\n-                    process: data[1],\\n-                    load: +data[2]\\n-                };\\n-            });\\n-            \\n-            var totalLoad = 0;\\n-            \\n-            found.forEach(function(obj) {\\n-                totalLoad += obj.load;\\n-            });\\n-            \\n-            var output = {\\n-                load: totalLoad,\\n-                found: found\\n-            };\\n-            \\n-            cb(null, output);\\n-        });\\n-    };\\n+        try {\\n+            fs.accessSync(wmic);\\n+        } catch(e) {\\n+            throw new Error(\\'windows-cpu is not supported on your version of Windows or you are not running as administrator.\\');\\n+        }\\n+        \\n+        return true;\\n+    }\\n     \\n     \/**\\n      * Gets the total load in percent for all processes running on the current machine per CPU.\\n-     * @param {function} cb A callback function to handle the results (error, results).\\n+     * @param  {Function} cb Callback to call with results (error, results)\\n+     * @return {WindowsCPU}  Instance of the WindowsCPU class\\n      * @example\\n      *\\n-     * var cpu = require(\\'windows-cpu\\');\\n+     * const cpu = require(\\'windows-cpu\\');\\n      *\\n      * \/\/ Get total load on server for each CPU\\n      * cpu.totalLoad(function(error, results) {\\n@@ -129,27 +101,27 @@\\n      *      \/\/ [3, 10]\\n      * });\\n      *\/\\n-    exports.totalLoad = function totalLoad(cb) {\\n-        if (!isFunction(cb)) cb = emptyFn;\\n-        if (!checkPlatform(cb)) return;\\n-        \\n-        execFile(wmic, [\\'cpu\\', \\'get\\', \\'loadpercentage\\'], function (error, res, stderr) {\\n+    totalLoad(cb) {\\n+        execFile(wmic, [\\'cpu\\', \\'get\\', \\'loadpercentage\\'], function(error, res, stderr) {\\n             if(error !== null || stderr) return cb(error || stderr);\\n             \\n-            var cpus = (res.match(\/\\\\d+\/g) || []).map(function(x) { \\n+            let cpus = (res.match(\/\\\\d+\/g) || []).map(function(x) { \\n                 return +(x.trim()); \\n             });\\n             \\n             cb(null, cpus);\\n         });\\n-    };\\n+        \\n+        return this;\\n+    }\\n     \\n     \/**\\n-     * Gets the total load in percent for all Node.js processes running on the current machine.\\n-     * @param {function} cb A callback function to handle the results (error, results).\\n+     * Retrieves the current cpu load for all node processes running on the current machine\\n+     * @param  {Function} cb Callback to call with results (error, results)\\n+     * @return {WindowsCPU}  Instance of the WindowsCPU class\\n      * @example\\n      *\\n-     * var cpu = require(\\'windows-cpu\\');\\n+     * const cpu = require(\\'windows-cpu\\');\\n      *\\n      * \/\/ Get total load for all node processes\\n      * cpu.nodeLoad(function(error, results) {\\n@@ -167,19 +139,21 @@\\n      *      \/\/    ]\\n      *      \/\/ }\\n      *\\n-     *      console.log(\\'Total Node.js Load: \\' + results.load);\\n+     *      console.log(`Total Node.js Load: ${results.load}%`);\\n      * });\\n      *\/\\n-    exports.nodeLoad = function nodeLoad(cb) {\\n+    nodeLoad(cb) {\\n         findLoad(\\'node\\', cb);\\n-    };\\n+        return this;\\n+    }\\n     \\n     \/**\\n-     * Gets the total load in percent for all processes running on the current machine per CPU.\\n-     * @param {function} cb A callback function to handle the results (error, results).\\n+     * Retrieves the current cpu load for this process.\\n+     * @param  {Function} cb Callback to call with results (error, results)\\n+     * @return {WindowsCPU}  Instance of the WindowsCPU class\\n      * @example\\n      *\\n-     * var cpu = require(\\'windows-cpu\\');\\n+     * const cpu = require(\\'windows-cpu\\');\\n      *\\n      * \/\/ Get load for current running node process\\n      * cpu.processLoad(function(error, results) {\\n@@ -195,19 +169,21 @@\\n      *      \/\/    ]\\n      *      \/\/ }\\n      *\\n-     *      console.log(\\'Total Process Load: \\' + results.load);\\n+     *      console.log(`Total Process Load: ${results.load}%`);\\n      * });\\n      *\/\\n-    exports.processLoad = function processLoad(cb) {\\n+    processLoad(cb) {\\n         findLoad(process.pid, cb);\\n-    };\\n+        return this;\\n+    }\\n     \\n     \/**\\n-     * Gets the name of each processor in the machine.\\n-     * @param {function} cb A callback function to handle the results (error, results).\\n+     * Gets list of all processors in the current machine.\\n+     * @param  {Function} cb Callback to call with results (error, results)\\n+     * @return {WindowsCPU}  Instance of the WindowsCPU class\\n      * @example\\n      *\\n-     * var cpu = require(\\'windows-cpu\\');\\n+     * const cpu = require(\\'windows-cpu\\');\\n      *\\n      * \/\/ Get listing of processors\\n      * cpu.cpuInfo(function(error, results) {\\n@@ -224,28 +200,28 @@\\n      *      console.log(\\'Installed Processors: \\', results);\\n      * });\\n      *\/\\n-    exports.cpuInfo = function cpuInfo(cb) {\\n-        if(!isFunction(cb)) cb = emptyFn;\\n-        if(!checkPlatform(cb)) return;\\n-        \\n-        execFile(wmic, [\\'cpu\\', \\'get\\', \\'Name\\'], function (error, res, stderr) {\\n+    cpuInfo(cb) {\\n+        execFile(wmic, [\\'cpu\\', \\'get\\', \\'Name\\'], function(error, res, stderr) {\\n             if(error !== null || stderr) return cb(error || stderr);\\n             \\n-            var cpus = res.match(\/[^\\\\r\\\\n]+\/g).map(function(v) {\\n+            let cpus = res.match(\/[^\\\\r\\\\n]+\/g).map(function(v) {\\n                 return v.trim();\\n             });\\n             \\n             cpus.shift();\\n             cb(null, cpus);\\n         });\\n-    };\\n-\\n+        \\n+        return this;\\n+    }\\n+    \\n     \/**\\n-     * Gets the total memory usage value in KB , MB and GB .\\n-     * @param {function} cb A callback function to handle the result (error, results).\\n+     * Gets the total memory usage on the machine in KB, MB and GB.\\n+     * @param  {Function} cb Callback to call with results (error, results)\\n+     * @return {WindowsCPU}  Instance of the WindowsCPU class\\n      * @example\\n      *\\n-     * var cpu = require(\\'windows-cpu\\');\\n+     * const cpu = require(\\'windows-cpu\\');\\n      *\\n      * \/\/ Get the memory usage\\n      * cpu.totalMemoryUsage(function(error, results) {\\n@@ -263,17 +239,14 @@\\n      *      console.log(\\'Total Memory Usage: \\', result);\\n      * });\\n      *\/\\n-    exports.totalMemoryUsage = function totalMemoryUsage(cb) {\\n-        if (!isFunction(cb)) cb = emptyFn;\\n-        if (!checkPlatform(cb)) return;\\n-        \\n-        var cmd = \"tasklist \/FO csv \/nh\";\\n-        exec(cmd, function (error, res, stderr) {\\n+    totalMemoryUsage(cb) {\\n+        let cmd = \\'tasklist \/FO csv \/nh\\';\\n+        exec(cmd, function(error, res, stderr) {\\n             if(error !== null || stderr) return cb(error || stderr);\\n-            var results = { usageInKb: 0 , usageInMb: 0 , usageInGb: 0 };\\n+            let results = { usageInKb: 0 , usageInMb: 0 , usageInGb: 0 };\\n             \\n             results.usageInKb = res.match(\/[^\\\\r\\\\n]+\/g).map(function(v) {\\n-                var amt = +v.split(\\'\",\"\\')[4].replace(\/[^\\\\d]\/g, \\'\\');\\n+                let amt = +v.split(\\'\",\"\\')[4].replace(\/[^\\\\d]\/g, \\'\\');\\n                 return (!isNaN(amt) && typeof amt === \\'number\\')? amt : 0;\\n             }).reduce(function(prev, current) {\\n                 return prev + current;\\n@@ -284,5 +257,9 @@\\n             \\n             cb(null, results);\\n         });\\n-    };\\n-}());\\n+        \\n+        return this;\\n+    }\\n+}\\n+\\n+module.exports = new WindowsCPU();'}}",
            "message_norm":"es6 refactor + fix vulnerability",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":2780,
            "vuln_id":"GHSA-qm6v-cg9v-53j3",
            "cwe_id":"{'CWE-287'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/opencast\/opencast\/commit\/8d5ec1614eed109b812bc27b0c6d3214e456d4e7'}",
            "dataset":"osv",
            "summary":"Limited Authentication Bypass for Media Files Prior to Opencast 10.14 and 11.7, users could pass along URLs for files belonging to organizations other than the user's own, which Opencast would then import into the current organization, bypassing organizational barriers.\n\n### Impact\n\nThe vulnerability allows attackers to bypass organizational barriers. Attackers must have full access to Opencast's ingest REST interface, and also know internal links to resources in another organization of the same Opencast cluster.\n\nIf you do not run a multi-tenant cluster, you are not affected by this issue.\n\n### Patches\n\nThis issue is fixed in Opencast 10.14 and 11.7.\n\n### References\n\n- [Patch fixing the issue](https:\/\/github.com\/opencast\/opencast\/commit\/8d5ec1614eed109b812bc27b0c6d3214e456d4e7)\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an issue in [our issue tracker](https:\/\/github.com\/opencast\/opencast\/issues)\n* Email us at [security@opencast.org](mailto:security@opencast.org)",
            "published_date":"2022-05-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/opencast\/opencast",
            "commit_href":"https:\/\/github.com\/opencast\/opencast\/commit\/8d5ec1614eed109b812bc27b0c6d3214e456d4e7",
            "commit_sha":"8d5ec1614eed109b812bc27b0c6d3214e456d4e7",
            "patch":"SINGLE",
            "chain_ord":"['8d5ec1614eed109b812bc27b0c6d3214e456d4e7']",
            "before_first_fix_commit":"{'eee0c26fe33afc0709373fcbd7c6870bee8e2bed'}",
            "last_fix_commit":"8d5ec1614eed109b812bc27b0c6d3214e456d4e7",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/18\/2022, 10:43:56",
            "message":"Merge pull request from GHSA-qm6v-cg9v-53j3\n\nThis patch fixes the issue that users can pass URLs from other tenants\nto the ingest service which will check only against the other\norganization but not against the one currently active. This allows users\nto easily ingest media from other tenants.",
            "author":"Lars Kiesow",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 12, 'total': 13}",
            "files":"{'modules\/ingest-service-impl\/src\/main\/java\/org\/opencastproject\/ingest\/impl\/IngestServiceImpl.java': {'additions': 1, 'deletions': 12, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencast\/opencast\/raw\/8d5ec1614eed109b812bc27b0c6d3214e456d4e7\/modules%2Fingest-service-impl%2Fsrc%2Fmain%2Fjava%2Forg%2Fopencastproject%2Fingest%2Fimpl%2FIngestServiceImpl.java', 'patch': '@@ -129,15 +129,13 @@\\n import java.util.Dictionary;\\n import java.util.HashMap;\\n import java.util.HashSet;\\n-import java.util.LinkedList;\\n import java.util.List;\\n import java.util.Map;\\n import java.util.Map.Entry;\\n import java.util.Objects;\\n import java.util.Set;\\n import java.util.UUID;\\n import java.util.concurrent.TimeUnit;\\n-import java.util.stream.Collectors;\\n \\n import javax.management.ObjectInstance;\\n \\n@@ -1568,16 +1566,7 @@ protected URI addContentToRepo(MediaPackage mp, String elementId, URI uri) throw\\n     try {\\n       if (uri.toString().startsWith(\"http\")) {\\n         HttpGet get = new HttpGet(uri);\\n-        List<String> clusterUrls = new LinkedList<>();\\n-        try {\\n-          \/\/ Note that we are not checking ports here.\\n-          clusterUrls = organizationDirectoryService.getOrganization(uri.toURL()).getServers()\\n-                          .keySet()\\n-                          .stream()\\n-                          .collect(Collectors.toUnmodifiableList());\\n-        } catch (NotFoundException e) {\\n-          logger.warn(\"Unable to determine cluster members, will not be able to authenticate any downloads from them\", e);\\n-        }\\n+        var clusterUrls = securityService.getOrganization().getServers().keySet();\\n \\n         if (uri.toString().matches(downloadSource)) {\\n           \/\/NB: We\\'re creating a new client here with *different* auth than the system auth creds'}}",
            "message_norm":"merge pull request from ghsa-qm6v-cg9v-53j3\n\nthis patch fixes the issue that users can pass urls from other tenants\nto the ingest service which will check only against the other\norganization but not against the one currently active. this allows users\nto easily ingest media from other tenants.",
            "language":"en",
            "entities":"[('ghsa-qm6v-cg9v-53j3', 'VULNID', 'GHSA'), ('fixes', 'ACTION', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/ingest-service-impl\/src\/main\/java\/org\/opencastproject\/ingest\/impl\/IngestServiceImpl.java'])",
            "num_files":1.0
        },
        {
            "index":545,
            "vuln_id":"GHSA-545v-42p7-98fq",
            "cwe_id":"{'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886'}",
            "dataset":"osv",
            "summary":"Heap out of bounds read in `MaxPoolGradWithArgmax` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGradWithArgmax` can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32)\ngrad = tf.constant([10.0, 10.0, 10.0, 10.0], shape=[1, 1, 1, 4], dtype=tf.float32)\nargmax = tf.constant([1], shape=[1], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n  \ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  padding='SAME', include_batch_in_index=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e\/tensorflow\/core\/kernels\/maxpooling_op.cc#L1016-L1017) uses the same value to index in two different arrays but there is no guarantee that the sizes are identical. \n\n### Patches\nWe have patched the issue in GitHub commit [dcd7867de0fea4b72a2b34bd41eb74548dc23886](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "commit_sha":"dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "patch":"SINGLE",
            "chain_ord":"['dcd7867de0fea4b72a2b34bd41eb74548dc23886']",
            "before_first_fix_commit":"{'ef0c008ee84bad91ec6725ddc42091e19a30cf0e'}",
            "last_fix_commit":"dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 15:38:03",
            "message":"Fix heap buffer overflow\n\nPiperOrigin-RevId: 372132844\nChange-Id: Idef9895efaf145f2b1c23d31983601ec980cd5e4",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/maxpooling_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/dcd7867de0fea4b72a2b34bd41eb74548dc23886\/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc', 'patch': '@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\\n         const int input_start = start * input_size_per_batch;\\n         const int input_end = limit * input_size_per_batch;\\n         for (int64 index = input_start; index < input_end; index++) {\\n+          if (index >= argmax.NumElements()) {\\n+            break;\\n+          }\\n           int64 grad_out_index = argmax_flat(index);\\n           if (!include_batch_in_index) {\\n             const int64 cur_batch = index \/ input_size_per_batch;'}}",
            "message_norm":"fix heap buffer overflow\n\npiperorigin-revid: 372132844\nchange-id: idef9895efaf145f2b1c23d31983601ec980cd5e4",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('372132844', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/maxpooling_op.cc'])",
            "num_files":1.0
        },
        {
            "index":1314,
            "vuln_id":"GHSA-94qw-r73x-j7hg",
            "cwe_id":"{'CWE-285'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/opencast\/opencast\/commit\/72fad0031d8a82c860e2bde0b27570c5042320ee'}",
            "dataset":"osv",
            "summary":"Users with ROLE_COURSE_ADMIN can create new users in Opencast ### Impact\n\nUsers with the role `ROLE_COURSE_ADMIN` can use the user-utils endpoint to create new users not including the role `ROLE_ADMIN`. For example:\n\n```bash\n# Use the admin to create a new user with ROLE_COURSE_ADMIN using the admin user.\n# We expect this to work.\n% curl -i -u admin:opencast 'https:\/\/example.opencast.org\/user-utils\/xy.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n\n# Use the new user to create more new users.\n# We don't exp\u00fcect a user with just role ROLE_COURSE_ADMIN to succeed.\n# But it does work\n% curl -i -u xy:f 'https:\/\/example.opencast.org\/user-utils\/ab.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n```\n`ROLE_COURSE_ADMIN` is a non-standard role in Opencast which is referenced neither in the documentation nor in any code (except for tests) but only in the security configuration. From the name \u2013 implying an admin for a specific course \u2013 users would never expect that this role allows user creation.\n\n### Patches\n\nThis issue is fixed in 7.6 and 8.1 which both ship a new default security configuration.\n\n### Workarounds\n\nYou can fix this issue by removing all instances of `ROLE_COURSE_ADMIN` in your organization's security configuration (`etc\/security\/mh_default_org.xml` by default).\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n- Open an issue in [opencast\/opencast](https:\/\/github.com\/opencast\/opencast\/issues)\n- For security-relevant information, email us at security@opencast.org",
            "published_date":"2020-01-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/opencast\/opencast",
            "commit_href":"https:\/\/github.com\/opencast\/opencast\/commit\/72fad0031d8a82c860e2bde0b27570c5042320ee",
            "commit_sha":"72fad0031d8a82c860e2bde0b27570c5042320ee",
            "patch":"SINGLE",
            "chain_ord":"['72fad0031d8a82c860e2bde0b27570c5042320ee']",
            "before_first_fix_commit":"{'b157e1fb3b35991ca7bf59f0730329fbe7ce82e8'}",
            "last_fix_commit":"72fad0031d8a82c860e2bde0b27570c5042320ee",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/16\/2020, 15:40:23",
            "message":"Remove ROLE_COURSE_ADMIN\n\nUsers with the role `ROLE_COURSE_ADMIN` can use the user-utils endpoint\nto create new users not including the role ROLE_ADMIN. For example:\n\n```sh\n% curl -i -u admin:opencast 'https:\/\/example.opencast.org\/user-utils\/xy.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n\n% curl -i -u xy:f 'https:\/\/example.opencast.org\/user-utils\/ab.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP\/2 201\n```\n\n`ROLE_COURSE_ADMIN` is a non-standard role in Opencast which is\nreferenced neither in the documentation nor in any code (except for\ntests) but only in the security configuration. From the name \u2013 implying\nan admin for a specific course \u2013 users would never expect that this role\nallows user creation.\n\nThis patch fixes the problem by dropping the default access rules for\n`ROLE_COURSE_ADMIN`. Users which use and need this custom role can\neasily configure this specific to their needs. There is no reason to\nship this by default.",
            "author":"Lars Kiesow",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 5, 'total': 10}",
            "files":"{'etc\/security\/mh_default_org.xml': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencast\/opencast\/raw\/72fad0031d8a82c860e2bde0b27570c5042320ee\/etc%2Fsecurity%2Fmh_default_org.xml', 'patch': '@@ -297,11 +297,11 @@\\n     <sec:intercept-url pattern=\"\/transcripts\/watson\/results*\" method=\"POST\" access=\"ROLE_ANONYMOUS\" \/>\\n \\n     <!-- Everything else is for the admin users -->\\n-    <sec:intercept-url pattern=\"\/admin-ng\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\\n-    <sec:intercept-url pattern=\"\/admin-ng\/\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\\n-    <sec:intercept-url pattern=\"\/admin-ng\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\\n-    <sec:intercept-url pattern=\"\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" \/>\\n-    <sec:intercept-url pattern=\"\/**\" access=\"ROLE_ADMIN, ROLE_COURSE_ADMIN\" \/>\\n+    <sec:intercept-url pattern=\"\/admin-ng\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\\n+    <sec:intercept-url pattern=\"\/admin-ng\/\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\\n+    <sec:intercept-url pattern=\"\/admin-ng\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\\n+    <sec:intercept-url pattern=\"\/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" \/>\\n+    <sec:intercept-url pattern=\"\/**\" access=\"ROLE_ADMIN\" \/>\\n \\n     <!-- ############################# -->\\n     <!-- # LOGIN \/ LOGOUT MECHANISMS # -->'}}",
            "message_norm":"remove role_course_admin\n\nusers with the role `role_course_admin` can use the user-utils endpoint\nto create new users not including the role role_admin. for example:\n\n```sh\n% curl -i -u admin:opencast 'https:\/\/example.opencast.org\/user-utils\/xy.json' -x put \\\n  --data 'password=f&roles=%5b%22role_course_admin%22%5d'\nhttp\/2 201\n\n% curl -i -u xy:f 'https:\/\/example.opencast.org\/user-utils\/ab.json' -x put \\\n  --data 'password=f&roles=%5b%22role_course_admin%22%5d'\nhttp\/2 201\n```\n\n`role_course_admin` is a non-standard role in opencast which is\nreferenced neither in the documentation nor in any code (except for\ntests) but only in the security configuration. from the name \u2013 implying\nan admin for a specific course \u2013 users would never expect that this role\nallows user creation.\n\nthis patch fixes the problem by dropping the default access rules for\n`role_course_admin`. users which use and need this custom role can\neasily configure this specific to their needs. there is no reason to\nship this by default.",
            "language":"en",
            "entities":"[('remove', 'ACTION', ''), ('role_course_admin', 'SECWORD', ''), ('role_course_admin', 'SECWORD', ''), ('role_admin', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('https:\/\/example.opencast.org\/user-utils\/xy.json', 'URL', ''), ('password', 'SECWORD', ''), ('f&roles=%5b%22role_course_admin%22%5d', 'SECWORD', ''), ('https:\/\/example.opencast.org\/user-utils\/ab.json', 'URL', ''), ('password', 'SECWORD', ''), ('f&roles=%5b%22role_course_admin%22%5d', 'SECWORD', ''), ('role_course_admin', 'SECWORD', ''), ('security', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('problem', 'FLAW', ''), ('role_course_admin', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['etc\/security\/mh_default_org.xml'])",
            "num_files":1.0
        },
        {
            "index":2748,
            "vuln_id":"GHSA-qg48-85hg-mqc5",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/da5ff2daf618591f64b2b62d9d9803951b945e9f'}",
            "dataset":"osv",
            "summary":"Division by 0 in `DenseCountSparseOutput` ### Impact\nAn attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.DenseCountSparseOutput`:\n\n```python\nimport tensorflow as tf\n\nvalues = tf.constant([], shape=[0, 0], dtype=tf.int64)\nweights = tf.constant([])\n\ntf.raw_ops.DenseCountSparseOutput(\n  values=values, weights=weights,\n  minlength=-1, maxlength=58, binary_output=True)\n```\n  \nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/efff014f3b2d8ef6141da30c806faf141297eca1\/tensorflow\/core\/kernels\/count_ops.cc#L123-L127) computes a divisor value from user data but does not check that the result is 0 before doing the division:\n\n```cc\nint num_batch_elements = 1;\nfor (int i = 0; i < num_batch_dimensions; ++i) {\n  num_batch_elements *= data.shape().dim_size(i);\n}\nint num_value_elements = data.shape().num_elements() \/ num_batch_elements;\n```\n\nSince `data` is given by the `values` argument, `num_batch_elements` is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [da5ff2daf618591f64b2b62d9d9803951b945e9f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/da5ff2daf618591f64b2b62d9d9803951b945e9f).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, and TensorFlow 2.3.3, as these are also affected.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/da5ff2daf618591f64b2b62d9d9803951b945e9f",
            "commit_sha":"da5ff2daf618591f64b2b62d9d9803951b945e9f",
            "patch":"SINGLE",
            "chain_ord":"['da5ff2daf618591f64b2b62d9d9803951b945e9f']",
            "before_first_fix_commit":"{'efff014f3b2d8ef6141da30c806faf141297eca1'}",
            "last_fix_commit":"da5ff2daf618591f64b2b62d9d9803951b945e9f",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 18:24:45",
            "message":"Fix FPE issue with `tf.raw_ops.DenseCountSparseOutput`.\n\nPiperOrigin-RevId: 370946862\nChange-Id: I3752584ad04aaecb327ff6793a9640ac56acfe7a",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/count_ops.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/da5ff2daf618591f64b2b62d9d9803951b945e9f\/tensorflow%2Fcore%2Fkernels%2Fcount_ops.cc', 'patch': '@@ -122,6 +122,9 @@ class DenseCount : public OpKernel {\\n \\n     int num_batch_elements = 1;\\n     for (int i = 0; i < num_batch_dimensions; ++i) {\\n+      OP_REQUIRES(context, data.shape().dim_size(i) != 0,\\n+                  errors::InvalidArgument(\\n+                      \"Invalid input: Shapes dimension cannot be 0.\"));\\n       num_batch_elements *= data.shape().dim_size(i);\\n     }\\n     int num_value_elements = data.shape().num_elements() \/ num_batch_elements;'}}",
            "message_norm":"fix fpe issue with `tf.raw_ops.densecountsparseoutput`.\n\npiperorigin-revid: 370946862\nchange-id: i3752584ad04aaecb327ff6793a9640ac56acfe7a",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('issue', 'FLAW', ''), ('370946862', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/count_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":2040,
            "vuln_id":"GHSA-hc72-vj3g-5g2g",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/SeriaWei\/ZKEACMS\/commit\/833c5460dc5c6152092f6ad54b8b832870a59903'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in ZKEACMS A cross-site scripting (XSS) vulnerability in \/navigation\/create?ParentID=%23 of ZKEACMS v3.5.2 allows attackers to execute arbitrary web scripts or HTML via a crafted payload injected into the ParentID parameter.",
            "published_date":"2022-05-26",
            "chain_len":1,
            "project":"https:\/\/github.com\/SeriaWei\/ZKEACMS",
            "commit_href":"https:\/\/github.com\/SeriaWei\/ZKEACMS\/commit\/833c5460dc5c6152092f6ad54b8b832870a59903",
            "commit_sha":"833c5460dc5c6152092f6ad54b8b832870a59903",
            "patch":"SINGLE",
            "chain_ord":"['833c5460dc5c6152092f6ad54b8b832870a59903']",
            "before_first_fix_commit":"{'53109ba58bbeac75074583ec261732772ed1ecc5'}",
            "last_fix_commit":"833c5460dc5c6152092f6ad54b8b832870a59903",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/14\/2022, 14:55:34",
            "message":"Sanitize Html\n\n#457",
            "author":"wayne",
            "comments":null,
            "stats":"{'additions': 36, 'deletions': 1, 'total': 37}",
            "files":"{'src\/ZKEACMS\/Common\/Service\/NavigationService.cs': {'additions': 36, 'deletions': 1, 'changes': 37, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/SeriaWei\/ZKEACMS\/raw\/833c5460dc5c6152092f6ad54b8b832870a59903\/src%2FZKEACMS%2FCommon%2FService%2FNavigationService.cs', 'patch': '@@ -11,13 +11,16 @@\\n using ZKEACMS.Common.Models;\\n using Easy;\\n using Microsoft.EntityFrameworkCore;\\n+using ZKEACMS.Safety;\\n \\n namespace ZKEACMS.Common.Service\\n {\\n     public class NavigationService : ServiceBase<NavigationEntity, CMSDbContext>, INavigationService\\n     {\\n-        public NavigationService(IApplicationContext applicationContext, CMSDbContext dbContext) : base(applicationContext, dbContext)\\n+        private readonly IHtmlSanitizer _htmlSanitizer;\\n+        public NavigationService(IApplicationContext applicationContext, CMSDbContext dbContext, IHtmlSanitizer htmlSanitizer) : base(applicationContext, dbContext)\\n         {\\n+            _htmlSanitizer = htmlSanitizer;\\n         }\\n         public override DbSet<NavigationEntity> CurrentDbSet => DbContext.Navigation;\\n         public override ServiceResult<NavigationEntity> Add(NavigationEntity item)\\n@@ -27,8 +30,34 @@ public override ServiceResult<NavigationEntity> Add(NavigationEntity item)\\n                 item.ParentId = \"#\";\\n             }\\n             item.ID = Guid.NewGuid().ToString(\"N\");\\n+            Santize(item);\\n             return base.Add(item);\\n         }\\n+\\n+        public override ServiceResult<NavigationEntity> AddRange(params NavigationEntity[] items)\\n+        {\\n+            foreach (var item in items)\\n+            {\\n+                Santize(item);\\n+            }\\n+            return base.AddRange(items);\\n+        }\\n+\\n+        public override ServiceResult<NavigationEntity> Update(NavigationEntity item)\\n+        {\\n+            Santize(item);\\n+            return base.Update(item);\\n+        }\\n+\\n+        public override ServiceResult<NavigationEntity> UpdateRange(params NavigationEntity[] items)\\n+        {\\n+            foreach (var item in items)\\n+            {\\n+                Santize(item);\\n+            }\\n+            return base.UpdateRange(items);\\n+        }\\n+\\n         public override void Remove(NavigationEntity item)\\n         {\\n             Remove(m => m.ParentId == item.ID);\\n@@ -73,5 +102,11 @@ public void Move(string id, string parentId, int position, int oldPosition)\\n             }\\n             Update(nav);\\n         }\\n+\\n+        private void Santize(NavigationEntity item)\\n+        {\\n+            item.Title = _htmlSanitizer.Sanitize(item.Title);\\n+            item.Html = _htmlSanitizer.Sanitize(item.Html);\\n+        }\\n     }\\n }\\n\\\\ No newline at end of file'}}",
            "message_norm":"sanitize html\n\n#457",
            "language":"sq",
            "entities":"[('sanitize', 'SECWORD', ''), ('#457', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/ZKEACMS\/Common\/Service\/NavigationService.cs'])",
            "num_files":1.0
        },
        {
            "index":1842,
            "vuln_id":"GHSA-g7xr-v82w-qggq",
            "cwe_id":"{'CWE-94'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d'}",
            "dataset":"osv",
            "summary":"Code Injection in SEOmatic In the SEOmatic plugin up to 3.4.11 for Craft CMS 3, it is possible for unauthenticated attackers to perform a Server-Side Template Injection, allowing for remote code execution.",
            "published_date":"2022-06-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/nystudio107\/craft-seomatic",
            "commit_href":"https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d",
            "commit_sha":"3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d",
            "patch":"SINGLE",
            "chain_ord":"['3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d']",
            "before_first_fix_commit":"{'4e46b792ce973ac0c652fb330055f41aca1981c8'}",
            "last_fix_commit":"3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/24\/2021, 18:08:04",
            "message":"Sanitize the canonical URL after the absolute URL has been returned, to mitigate poisoned `X-Forwarded-Host` headers",
            "author":"Andrew Welch",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 2, 'total': 3}",
            "files":"{'src\/services\/Helper.php': {'additions': 1, 'deletions': 2, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nystudio107\/craft-seomatic\/raw\/3fee7d50147cdf3f999cfc1e04cbc3fb3d9f2f7d\/src%2Fservices%2FHelper.php', 'patch': '@@ -148,9 +148,8 @@ public static function safeCanonicalUrl(): string\\n         } catch (InvalidConfigException $e) {\\n             Craft::error($e->getMessage(), __METHOD__);\\n         }\\n-        $url = DynamicMetaHelper::sanitizeUrl($url);\\n \\n-        return UrlHelper::absoluteUrlWithProtocol($url);\\n+        return DynamicMetaHelper::sanitizeUrl(UrlHelper::absoluteUrlWithProtocol($url));\\n     }\\n \\n     \/**'}}",
            "message_norm":"sanitize the canonical url after the absolute url has been returned, to mitigate poisoned `x-forwarded-host` headers",
            "language":"en",
            "entities":"[('sanitize', 'SECWORD', ''), ('mitigate', 'ACTION', ''), ('poisoned', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/services\/Helper.php'])",
            "num_files":1.0
        },
        {
            "index":2727,
            "vuln_id":"GHSA-q99r-j969-6jwr",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/7e9a2ee60baa95ceb4f48f522f823c812ca90c80', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/31f2588c7ba5b446bccf2769e9ecf4d444b73045'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1138, CVE-2019-1217, CVE-2019-1298, CVE-2019-1300.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/31f2588c7ba5b446bccf2769e9ecf4d444b73045",
            "commit_sha":"31f2588c7ba5b446bccf2769e9ecf4d444b73045",
            "patch":"MULTI",
            "chain_ord":"['31f2588c7ba5b446bccf2769e9ecf4d444b73045', '7e9a2ee60baa95ceb4f48f522f823c812ca90c80']",
            "before_first_fix_commit":"{'edf5eeef49168bbcc30dac82f57048ad46988295', 'c5297b86536fbf1a02d27cec28fea3c516e6ab84'}",
            "last_fix_commit":"7e9a2ee60baa95ceb4f48f522f823c812ca90c80",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/26\/2019, 22:39:34",
            "message":"[CVE-2019-1237]",
            "author":"Michael Holman",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'lib\/Runtime\/Library\/BoundFunction.cpp': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/31f2588c7ba5b446bccf2769e9ecf4d444b73045\/lib%2FRuntime%2FLibrary%2FBoundFunction.cpp', 'patch': \"@@ -354,6 +354,12 @@ namespace Js\\n             Var varLength;\\n             if (targetFunction->GetProperty(targetFunction, PropertyIds::length, &varLength, nullptr, requestContext))\\n             {\\n+                if (!TaggedInt::Is(varLength))\\n+                {\\n+                    \/\/ ToInt32 conversion on non-primitive length can invalidate assumptions made by the JIT,\\n+                    \/\/ so add implicit call flag if length isn't a TaggedInt already\\n+                    requestContext->GetThreadContext()->AddImplicitCallFlags(ImplicitCall_Accessor);\\n+                }\\n                 len = JavascriptConversion::ToInt32(varLength, requestContext);\\n             }\"}}",
            "message_norm":"[cve-2019-1237]",
            "language":"ro",
            "entities":"[('cve-2019-1237', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Runtime\/Library\/BoundFunction.cpp'])",
            "num_files":1.0
        },
        {
            "index":3365,
            "vuln_id":"GHSA-x4qx-4fjv-hmw6",
            "cwe_id":"{'CWE-190'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6f4d3e8139ec724dbbcb40505891c81dd1052c4a'}",
            "dataset":"osv",
            "summary":"Integer overflow leading to crash in Tensorflow ### Impact \nThe [implementation of `SparseCountSparseOutput`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/count_ops.cc#L168-L273) can be made to crash a TensorFlow process by an integer overflow whose result is then used in a memory allocation:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n    \ntf.raw_ops.SparseCountSparseOutput(\n  indices=[[1,1]],\n  values=[2],\n  dense_shape=[2 ** 31, 2 ** 32],\n  weights=[1],\n  binary_output=True,\n  minlength=-1,\n  maxlength=-1,\n  name=None)\n```\n\n### Patches\nWe have patched the issue in GitHub commit [6f4d3e8139ec724dbbcb40505891c81dd1052c4a](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6f4d3e8139ec724dbbcb40505891c81dd1052c4a).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6f4d3e8139ec724dbbcb40505891c81dd1052c4a",
            "commit_sha":"6f4d3e8139ec724dbbcb40505891c81dd1052c4a",
            "patch":"SINGLE",
            "chain_ord":"['6f4d3e8139ec724dbbcb40505891c81dd1052c4a']",
            "before_first_fix_commit":"{'adbbabdb0d3abb3cdeac69e38a96de1d678b24b3'}",
            "last_fix_commit":"6f4d3e8139ec724dbbcb40505891c81dd1052c4a",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/08\/2021, 04:04:02",
            "message":"Prevent crash due to integer overflow followed by allocating negative sized array.\n\nPiperOrigin-RevId: 414891322\nChange-Id: I5df390e0dc1d9f115209293708950cdf9306931c",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 0, 'total': 9}",
            "files":"{'tensorflow\/core\/kernels\/count_ops.cc': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6f4d3e8139ec724dbbcb40505891c81dd1052c4a\/tensorflow%2Fcore%2Fkernels%2Fcount_ops.cc', 'patch': '@@ -13,6 +13,8 @@ See the License for the specific language governing permissions and\\n limitations under the License.\\n ==============================================================================*\/\\n \\n+#include <limits>\\n+\\n #include \"absl\/container\/flat_hash_map.h\"\\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n #include \"tensorflow\/core\/framework\/op_requires.h\"\\n@@ -23,6 +25,9 @@ limitations under the License.\\n \\n namespace tensorflow {\\n \\n+\/\/ Don\\'t allocate too large `BatchedMap<T>` objects\\n+static int kMaxBatches = std::numeric_limits<int>::max();\\n+\\n template <class T>\\n using BatchedMap = std::vector<absl::flat_hash_map<int64_t, T>>;\\n \\n@@ -235,6 +240,10 @@ class SparseCount : public OpKernel {\\n \\n     bool is_1d = shape.NumElements() == 1;\\n     int num_batches = is_1d ? 1 : shape_vector(0);\\n+    OP_REQUIRES(\\n+        context, 0 < num_batches && num_batches < kMaxBatches,\\n+        errors::InvalidArgument(\"Cannot allocate \", num_batches,\\n+                                \" batches, is the dense shape too wide?\"));\\n \\n     const auto values_values = values.flat<T>();\\n     const auto weight_values = weights.flat<W>();'}}",
            "message_norm":"prevent crash due to integer overflow followed by allocating negative sized array.\n\npiperorigin-revid: 414891322\nchange-id: i5df390e0dc1d9f115209293708950cdf9306931c",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('integer overflow', 'SECWORD', ''), ('414891322', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/count_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":2475,
            "vuln_id":"GHSA-mw6j-hh29-h379",
            "cwe_id":"{'CWE-190'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3796cc4fcd93ae55812a457abc96dcd55fbb854b'}",
            "dataset":"osv",
            "summary":"`CHECK` failure in depthwise ops via overflows ### Impact\nThe implementation of depthwise ops in TensorFlow is vulnerable to a denial of service via `CHECK`-failure (assertion failure) caused by overflowing the number of elements in a tensor:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant(1, shape=[1, 4, 4, 3], dtype=tf.float32)\nfilter_sizes = tf.constant(1879048192, shape=[13], dtype=tf.int32)\nout_backprop = tf.constant(1, shape=[1, 4, 4, 3], dtype=tf.float32)\ntf.raw_ops.DepthwiseConv2dNativeBackpropFilter(\n    input=input, filter_sizes=filter_sizes, out_backprop=out_backprop, strides=[1, 1, 1, 1], padding=\"SAME\")\n```\n  \nThis is another instance of [TFSA-2021-198](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/security\/advisory\/tfsa-2021-198.md) (CVE-2021-41197).\n  \n### Patches\nWe have patched the issue in GitHub commit [3796cc4fcd93ae55812a457abc96dcd55fbb854b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3796cc4fcd93ae55812a457abc96dcd55fbb854b).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Neophytos Christou from Secure Systems Lab at Brown University.",
            "published_date":"2022-05-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3796cc4fcd93ae55812a457abc96dcd55fbb854b",
            "commit_sha":"3796cc4fcd93ae55812a457abc96dcd55fbb854b",
            "patch":"SINGLE",
            "chain_ord":"['3796cc4fcd93ae55812a457abc96dcd55fbb854b']",
            "before_first_fix_commit":"{'8f704c59219243ee66bdeb93cb3471e8e6af7d86'}",
            "last_fix_commit":"3796cc4fcd93ae55812a457abc96dcd55fbb854b",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/27\/2022, 22:53:46",
            "message":"Fix tf.raw_ops.DepthwiseConv2dNativeBackpropInput vulnerability with large input sizes.\n\nUse AddDimWithStatus rather than AddDim in order to catch and report integer overflow gracefully.\n\nPiperOrigin-RevId: 444989983",
            "author":"Alan Liu",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 2, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/3796cc4fcd93ae55812a457abc96dcd55fbb854b\/tensorflow%2Fcore%2Fkernels%2Fdepthwise_conv_grad_op.cc', 'patch': '@@ -625,7 +625,7 @@ class DepthwiseConv2dNativeBackpropInputOp : public OpKernel {\\n       OP_REQUIRES(context, in_sizes_data[i] >= 0,\\n                   errors::InvalidArgument(\"Dimension \", i,\\n                                           \" of input_sizes must be >= 0\"));\\n-      input_shape.AddDim(in_sizes_data[i]);\\n+      OP_REQUIRES_OK(context, input_shape.AddDimWithStatus(in_sizes_data[i]));\\n     }\\n     const TensorShape& filter_shape = filter.shape();\\n     EXTRACT_AND_VERIFY_DIMENSIONS(\"DepthwiseConv2DBackpropInput\");\\n@@ -1131,7 +1131,8 @@ class DepthwiseConv2dNativeBackpropFilterOp : public OpKernel {\\n       OP_REQUIRES(context, filter_sizes_data[i] >= 0,\\n                   errors::InvalidArgument(\"Dimension \", i,\\n                                           \" of filter_sizes must be >= 0\"));\\n-      filter_shape.AddDim(filter_sizes_data[i]);\\n+      OP_REQUIRES_OK(context,\\n+                     filter_shape.AddDimWithStatus(filter_sizes_data[i]));\\n     }\\n     const TensorShape& input_shape = input.shape();'}}",
            "message_norm":"fix tf.raw_ops.depthwiseconv2dnativebackpropinput vulnerability with large input sizes.\n\nuse adddimwithstatus rather than adddim in order to catch and report integer overflow gracefully.\n\npiperorigin-revid: 444989983",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('integer overflow', 'SECWORD', ''), ('444989983', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/depthwise_conv_grad_op.cc'])",
            "num_files":1.0
        },
        {
            "index":2147,
            "vuln_id":"GHSA-hwj9-h5mp-3pm3",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734', 'https:\/\/github.com\/postcss\/postcss\/commit\/b6f3e4d5a8d7504d553267f80384373af3a3dec5', 'https:\/\/github.com\/postcss\/postcss\/commit\/8682b1e4e328432ba692bed52326e84439cec9e4'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in postcss The npm package `postcss` from 7.0.0 and before versions 7.0.36 and 8.2.10 is vulnerable to Regular Expression Denial of Service (ReDoS) during source map parsing.",
            "published_date":"2021-05-10",
            "chain_len":3,
            "project":"https:\/\/github.com\/postcss\/postcss",
            "commit_href":"https:\/\/github.com\/postcss\/postcss\/commit\/b6f3e4d5a8d7504d553267f80384373af3a3dec5",
            "commit_sha":"b6f3e4d5a8d7504d553267f80384373af3a3dec5",
            "patch":"MULTI",
            "chain_ord":"['8682b1e4e328432ba692bed52326e84439cec9e4', 'b6f3e4d5a8d7504d553267f80384373af3a3dec5', '54cbf3c4847eb0fb1501b9d2337465439e849734']",
            "before_first_fix_commit":"{'12832f3d203474bd273bd06bd3b2407567bfe09e'}",
            "last_fix_commit":"54cbf3c4847eb0fb1501b9d2337465439e849734",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/11\/2021, 13:03:12",
            "message":"Fix unsafe regexp in getAnnotationURL() too",
            "author":"Andrey Sitnik",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 3, 'total': 4}",
            "files":"{'lib\/previous-map.js': {'additions': 1, 'deletions': 3, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/postcss\/postcss\/raw\/b6f3e4d5a8d7504d553267f80384373af3a3dec5\/lib%2Fprevious-map.js', 'patch': '@@ -48,9 +48,7 @@ class PreviousMap {\\n   }\\n \\n   getAnnotationURL(sourceMapString) {\\n-    return sourceMapString\\n-      .match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\s*\\\\*\\\\\/\/)[1]\\n-      .trim()\\n+    return sourceMapString.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\*\\\\\/\/)[1].trim()\\n   }\\n \\n   loadAnnotation(css) {'}}",
            "message_norm":"fix unsafe regexp in getannotationurl() too",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('unsafe', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/previous-map.js'])",
            "num_files":1.0
        },
        {
            "index":3023,
            "vuln_id":"GHSA-rww7-2gpw-fv6j",
            "cwe_id":"{'CWE-754'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cb164786dc891ea11d3a900e90367c339305dc7b'}",
            "dataset":"osv",
            "summary":"Crash when type cannot be specialized in Tensorflow ### Impact\nUnder certain scenarios, TensorFlow can fail to specialize a type during [shape inference](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/shape_inference.cc#L168-L174):\n\n```cc\nvoid InferenceContext::PreInputInit(\n    const OpDef& op_def, const std::vector<const Tensor*>& input_tensors,\n    const std::vector<ShapeHandle>& input_tensors_as_shapes) {\n  const auto ret = full_type::SpecializeType(attrs_, op_def);\n  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\n  ret_types_ = ret.ValueOrDie();\n  \/\/ ... \n}\n```\n\nHowever, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the `ValueOrDie` line. This results in an assertion failure as `ret` contains an error `Status`, not a value. In the second case we also get a crash due to the assertion failure.\n### Patches\nWe have patched the issue in GitHub commit [cb164786dc891ea11d3a900e90367c339305dc7b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cb164786dc891ea11d3a900e90367c339305dc7b).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cb164786dc891ea11d3a900e90367c339305dc7b",
            "commit_sha":"cb164786dc891ea11d3a900e90367c339305dc7b",
            "patch":"SINGLE",
            "chain_ord":"['cb164786dc891ea11d3a900e90367c339305dc7b']",
            "before_first_fix_commit":"{'c2b31ff2d3151acb230edc3f5b1832d2c713a9e0'}",
            "last_fix_commit":"cb164786dc891ea11d3a900e90367c339305dc7b",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/08\/2021, 18:28:34",
            "message":"Properly handle the case where `SpecializeType()` returns an error `Status`.\n\nIf the error case in `SpecializeType()` is reached, then we would get a crash when trying to access the value of an errorenous `StatusOr` object\n\nPiperOrigin-RevId: 408380069\nChange-Id: If3c3fc876dcf9384d5ec7a4985adc68c23ea7318",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 1, 'total': 5}",
            "files":"{'tensorflow\/core\/framework\/shape_inference.cc': {'additions': 4, 'deletions': 1, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/cb164786dc891ea11d3a900e90367c339305dc7b\/tensorflow%2Fcore%2Fframework%2Fshape_inference.cc', 'patch': '@@ -170,7 +170,10 @@ void InferenceContext::PreInputInit(\\n     const std::vector<ShapeHandle>& input_tensors_as_shapes) {\\n   \/\/ TODO(mdan): This is also done at graph construction. Run only here instead?\\n   const auto ret = full_type::SpecializeType(attrs_, op_def);\\n-  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\\n+  if (!ret.status().ok()) {\\n+    construction_status_ = ret.status();\\n+    return;\\n+  }\\n   ret_types_ = ret.ValueOrDie();\\n \\n   input_tensors_ = input_tensors;'}}",
            "message_norm":"properly handle the case where `specializetype()` returns an error `status`.\n\nif the error case in `specializetype()` is reached, then we would get a crash when trying to access the value of an errorenous `statusor` object\n\npiperorigin-revid: 408380069\nchange-id: if3c3fc876dcf9384d5ec7a4985adc68c23ea7318",
            "language":"en",
            "entities":"[('error', 'FLAW', ''), ('error', 'FLAW', ''), ('408380069', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/shape_inference.cc'])",
            "num_files":1.0
        },
        {
            "index":3206,
            "vuln_id":"GHSA-w37f-pvvx-wcwm",
            "cwe_id":"{'CWE-682'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/moodle\/moodle\/commit\/59b5858da200f63ecb59a9113af2b99ef1496fe5'}",
            "dataset":"osv",
            "summary":"Incorrect Calculation in moodle A flaw was found in moodle where logic used to count failed login attempts could result in the account lockout threshold being bypassed.",
            "published_date":"2022-05-19",
            "chain_len":1,
            "project":"https:\/\/github.com\/moodle\/moodle",
            "commit_href":"https:\/\/github.com\/moodle\/moodle\/commit\/59b5858da200f63ecb59a9113af2b99ef1496fe5",
            "commit_sha":"59b5858da200f63ecb59a9113af2b99ef1496fe5",
            "patch":"SINGLE",
            "chain_ord":"['59b5858da200f63ecb59a9113af2b99ef1496fe5']",
            "before_first_fix_commit":"{'a0f47c8bc4d6f5971025de7d63f22475701d2f86'}",
            "last_fix_commit":"59b5858da200f63ecb59a9113af2b99ef1496fe5",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/26\/2022, 08:52:20",
            "message":"MDL-73736 core_auth: Fix concurrency issue in login_attempt_failed()\n\nThis patch wraps the login_failed_count logic in a resource lock and\nforces a user preferences cache reload. Each thread must wait for the\nlock and must fetch the current count before incrementing it. This\nensures that login_failed_count is correct across threads and that the\nlockout threshold is correctly honoured.\n\nCo-Authored-By: Sujith Haridasan <sujith@moodle.com>",
            "author":"Jake Dallimore",
            "comments":null,
            "stats":"{'additions': 43, 'deletions': 19, 'total': 62}",
            "files":"{'lib\/authlib.php': {'additions': 43, 'deletions': 19, 'changes': 62, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/moodle\/moodle\/raw\/59b5858da200f63ecb59a9113af2b99ef1496fe5\/lib%2Fauthlib.php', 'patch': \"@@ -877,6 +877,7 @@ function login_attempt_valid($user) {\\n \/**\\n  * To be called after failed user login.\\n  * @param stdClass $user\\n+ * @throws moodle_exception\\n  *\/\\n function login_attempt_failed($user) {\\n     global $CFG;\\n@@ -888,30 +889,53 @@ function login_attempt_failed($user) {\\n         return;\\n     }\\n \\n-    $count = get_user_preferences('login_failed_count', 0, $user);\\n-    $last = get_user_preferences('login_failed_last', 0, $user);\\n-    $sincescuccess = get_user_preferences('login_failed_count_since_success', $count, $user);\\n-    $sincescuccess = $sincescuccess + 1;\\n-    set_user_preference('login_failed_count_since_success', $sincescuccess, $user);\\n+    \/\/ Force user preferences cache reload to ensure the most up-to-date login_failed_count is fetched.\\n+    \/\/ This is perhaps overzealous but is the documented way of reloading the cache, as per the test method\\n+    \/\/ 'test_check_user_preferences_loaded'.\\n+    unset($user->preference);\\n+\\n+    $resource = 'user:' . $user->id;\\n+    $lockfactory = \\\\core\\\\lock\\\\lock_config::get_lock_factory('core_failed_login_count_lock');\\n+\\n+    \/\/ Get a new lock for the resource, waiting for it for a maximum of 10 seconds.\\n+    if ($lock = $lockfactory->get_lock($resource, 10)) {\\n+        try {\\n+            $count = get_user_preferences('login_failed_count', 0, $user);\\n+            $last = get_user_preferences('login_failed_last', 0, $user);\\n+            $sincescuccess = get_user_preferences('login_failed_count_since_success', $count, $user);\\n+            $sincescuccess = $sincescuccess + 1;\\n+            set_user_preference('login_failed_count_since_success', $sincescuccess, $user);\\n+\\n+            if (empty($CFG->lockoutthreshold)) {\\n+                \/\/ No threshold means no lockout.\\n+                \/\/ Always unlock here, there might be some race conditions or leftovers when switching threshold.\\n+                login_unlock_account($user);\\n+                $lock->release();\\n+                return;\\n+            }\\n \\n-    if (empty($CFG->lockoutthreshold)) {\\n-        \/\/ No threshold means no lockout.\\n-        \/\/ Always unlock here, there might be some race conditions or leftovers when switching threshold.\\n-        login_unlock_account($user);\\n-        return;\\n-    }\\n+            if (!empty($CFG->lockoutwindow) and time() - $last > $CFG->lockoutwindow) {\\n+                $count = 0;\\n+            }\\n \\n-    if (!empty($CFG->lockoutwindow) and time() - $last > $CFG->lockoutwindow) {\\n-        $count = 0;\\n-    }\\n+            $count = $count + 1;\\n \\n-    $count = $count+1;\\n+            set_user_preference('login_failed_count', $count, $user);\\n+            set_user_preference('login_failed_last', time(), $user);\\n \\n-    set_user_preference('login_failed_count', $count, $user);\\n-    set_user_preference('login_failed_last', time(), $user);\\n+            if ($count >= $CFG->lockoutthreshold) {\\n+                login_lock_account($user);\\n+            }\\n \\n-    if ($count >= $CFG->lockoutthreshold) {\\n-        login_lock_account($user);\\n+            \/\/ Release locks when we're done.\\n+            $lock->release();\\n+        } catch (Exception $e) {\\n+            \/\/ Always release the lock on a failure.\\n+            $lock->release();\\n+        }\\n+    } else {\\n+        \/\/ We did not get access to the resource in time, give up.\\n+        throw new moodle_exception('locktimeout');\\n     }\\n }\"}}",
            "message_norm":"mdl-73736 core_auth: fix concurrency issue in login_attempt_failed()\n\nthis patch wraps the login_failed_count logic in a resource lock and\nforces a user preferences cache reload. each thread must wait for the\nlock and must fetch the current count before incrementing it. this\nensures that login_failed_count is correct across threads and that the\nlockout threshold is correctly honoured.\n\nco-authored-by: sujith haridasan <sujith@moodle.com>",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('issue', 'FLAW', ''), ('ensures', 'ACTION', ''), ('sujith@moodle.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/authlib.php'])",
            "num_files":1.0
        },
        {
            "index":2073,
            "vuln_id":"GHSA-hhr9-7xvh-8xgc",
            "cwe_id":"{'CWE-918'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/livehelperchat\/livehelperchat\/commit\/abc9599ee7aded466ca216741dcaea533c908111'}",
            "dataset":"osv",
            "summary":"Server side request forgery in LiveHelperChat SSRF filter bypass port 80, 433 in LiveHelperChat prior to v3.67. An attacker could make the application perform arbitrary requests, bypass CVE-2022-1191",
            "published_date":"2022-04-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/livehelperchat\/livehelperchat",
            "commit_href":"https:\/\/github.com\/livehelperchat\/livehelperchat\/commit\/abc9599ee7aded466ca216741dcaea533c908111",
            "commit_sha":"abc9599ee7aded466ca216741dcaea533c908111",
            "patch":"SINGLE",
            "chain_ord":"['abc9599ee7aded466ca216741dcaea533c908111']",
            "before_first_fix_commit":"{'a583f4c60a98779938766e242991e637c0d938f0'}",
            "last_fix_commit":"abc9599ee7aded466ca216741dcaea533c908111",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/03\/2022, 19:37:19",
            "message":"fix #1752",
            "author":"Remigijus Kiminas",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 2, 'total': 10}",
            "files":"{'lhc_web\/modules\/lhcobrowse\/proxycss.php': {'additions': 8, 'deletions': 2, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/LiveHelperChat\/livehelperchat\/raw\/abc9599ee7aded466ca216741dcaea533c908111\/lhc_web%2Fmodules%2Flhcobrowse%2Fproxycss.php', 'patch': \"@@ -15,7 +15,13 @@\\n     $browse = erLhcoreClassCoBrowse::getBrowseInstance($chat);\\r\\n }\\r\\n \\r\\n-$url = parse_url($_GET['base']);\\r\\n+$base = trim($_GET['base']);\\r\\n+\\r\\n+if (!filter_var($base, FILTER_VALIDATE_URL)) {\\r\\n+    exit;\\r\\n+}\\r\\n+\\r\\n+$url = parse_url($base);\\r\\n \\r\\n \/\/ Only http\/https supported\\r\\n if (!in_array($url['scheme'],['http','https']) || (isset($url['port']) && !in_array($url['port'],[80,443]))) {\\r\\n@@ -42,7 +48,7 @@\\n         }\\r\\n     } else {\\r\\n \\r\\n-        if (!in_array($urlCSS['scheme'],['http','https']) || (isset($urlCSS['port']) && !in_array($urlCSS['port'],[80,443]))) {\\r\\n+        if (!filter_var($_GET['css'], FILTER_VALIDATE_URL) || !in_array($urlCSS['scheme'],['http','https']) || (isset($urlCSS['port']) && !in_array($urlCSS['port'],[80,443]))) {\\r\\n             exit;\\r\\n         }\"}}",
            "message_norm":"fix #1752",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('#1752', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lhc_web\/modules\/lhcobrowse\/proxycss.php'])",
            "num_files":1.0
        },
        {
            "index":1355,
            "vuln_id":"GHSA-9c84-4hx6-xmm4",
            "cwe_id":"{'CWE-190'}",
            "score":6.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4253f96a58486ffe84b61c0415bb234a4632ee73'}",
            "dataset":"osv",
            "summary":"Integer overflow in TFLite concatentation ### Impact\nThe TFLite implementation of concatenation is [vulnerable to an integer overflow issue](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/7b7352a724b690b11bfaae2cd54bc3907daf6285\/tensorflow\/lite\/kernels\/concatenation.cc#L70-L76):\n\n```cc\nfor (int d = 0; d < t0->dims->size; ++d) {\n  if (d == axis) { \n    sum_axis += t->dims->data[axis]; \n  } else {\n    TF_LITE_ENSURE_EQ(context, t->dims->data[d], t0->dims->data[d]);\n  }\n}\n```\n\nAn attacker can craft a model such that the dimensions of one of the concatenation input overflow the values of `int`. TFLite uses `int` to represent tensor dimensions, whereas TF uses `int64`. Hence, valid TF models can trigger an integer overflow when converted to TFLite format.\n\n### Patches\nWe have patched the issue in GitHub commit [4253f96a58486ffe84b61c0415bb234a4632ee73](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4253f96a58486ffe84b61c0415bb234a4632ee73).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4253f96a58486ffe84b61c0415bb234a4632ee73",
            "commit_sha":"4253f96a58486ffe84b61c0415bb234a4632ee73",
            "patch":"SINGLE",
            "chain_ord":"['4253f96a58486ffe84b61c0415bb234a4632ee73']",
            "before_first_fix_commit":"{'7b7352a724b690b11bfaae2cd54bc3907daf6285'}",
            "last_fix_commit":"4253f96a58486ffe84b61c0415bb234a4632ee73",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 23:50:55",
            "message":"Fix integer overflow in TFLite concat\n\nPiperOrigin-RevId: 371013841\nChange-Id: I6a4782ce7ca753e23ff31e7fb6aeb7f9d412cd29",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/lite\/kernels\/concatenation.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/4253f96a58486ffe84b61c0415bb234a4632ee73\/tensorflow%2Flite%2Fkernels%2Fconcatenation.cc', 'patch': '@@ -16,6 +16,8 @@ limitations under the License.\\n \\n #include <stdint.h>\\n \\n+#include <limits>\\n+\\n #include \"tensorflow\/lite\/c\/builtin_op_data.h\"\\n #include \"tensorflow\/lite\/c\/common.h\"\\n #include \"tensorflow\/lite\/kernels\/internal\/compatibility.h\"\\n@@ -69,6 +71,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n     TF_LITE_ENSURE_EQ(context, t->type, input_type);\\n     for (int d = 0; d < t0->dims->size; ++d) {\\n       if (d == axis) {\\n+        \/\/ Avoid integer overflow in sum_axis below\\n+        TF_LITE_ENSURE(context, t->dims->data[axis] >= 0);\\n+        TF_LITE_ENSURE(context, t->dims->data[axis] <=\\n+                                    std::numeric_limits<int>::max() - sum_axis);\\n         sum_axis += t->dims->data[axis];\\n       } else {\\n         TF_LITE_ENSURE_EQ(context, t->dims->data[d], t0->dims->data[d]);'}}",
            "message_norm":"fix integer overflow in tflite concat\n\npiperorigin-revid: 371013841\nchange-id: i6a4782ce7ca753e23ff31e7fb6aeb7f9d412cd29",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('integer overflow', 'SECWORD', ''), ('371013841', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/concatenation.cc'])",
            "num_files":1.0
        },
        {
            "index":3415,
            "vuln_id":"GHSA-xcwj-wfcm-m23c",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd'}",
            "dataset":"osv",
            "summary":"Invalid validation in `SparseMatrixSparseCholesky` ### Impact\nAn attacker can trigger a null pointer dereference by providing an invalid `permutation` to `tf.raw_ops.SparseMatrixSparseCholesky`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\n\nindices_array = np.array([[0, 0]])\nvalue_array = np.array([-10.0], dtype=np.float32)\ndense_shape = [1, 1]\nst = tf.SparseTensor(indices_array, value_array, dense_shape)\n\ninput = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n       st.indices, st.values, st.dense_shape)\n\npermutation = tf.constant([], shape=[1, 0], dtype=tf.int32)\n \ntf.raw_ops.SparseMatrixSparseCholesky(input=input, permutation=permutation, type=tf.float32)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/080f1d9e257589f78b3ffb75debf584168aa6062\/tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc#L85-L86) fails to properly validate the input arguments: \n                          \n```cc \nvoid Compute(OpKernelContext* ctx) final {\n  ...\n  const Tensor& input_permutation_indices = ctx->input(1);\n  ...\n  ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size, &num_rows);\n  ...\n}\n\nvoid ValidateInputs(OpKernelContext* ctx,\n    const CSRSparseMatrix& sparse_matrix,\n    const Tensor& permutation_indices, int* batch_size,\n    int64* num_rows) {\n  OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value, ...)\n  ...\n}\n```\nAlthough `ValidateInputs` is called and there are checks in the body of this function, the code proceeds to the next line in `ValidateInputs` since [`OP_REQUIRES`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/080f1d9e257589f78b3ffb75debf584168aa6062\/tensorflow\/core\/framework\/op_requires.h#L41-L48) is a macro that only exits the current function.\n\n```cc\n#define OP_REQUIRES(CTX, EXP, STATUS)                     \\\n  do {                                                    \\\n    if (!TF_PREDICT_TRUE(EXP)) {                          \\\n      CheckNotInComputeAsync((CTX), \"OP_REQUIRES_ASYNC\"); \\\n      (CTX)->CtxFailure(__FILE__, __LINE__, (STATUS));    \\\n      return;                                             \\\n    }                                                     \\\n  } while (0)\n```\n\nThus, the first validation condition that fails in `ValidateInputs` will cause an early return from that function. However, the caller will continue execution from the next line. The fix is to either explicitly check `context->status()` or to convert `ValidateInputs` to return a `Status`.\n\n### Patches\nWe have patched the issue in GitHub commit [e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd",
            "commit_sha":"e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd",
            "patch":"SINGLE",
            "chain_ord":"['e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd']",
            "before_first_fix_commit":"{'080f1d9e257589f78b3ffb75debf584168aa6062'}",
            "last_fix_commit":"e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/20\/2021, 21:45:33",
            "message":"Remove `OP_REQUIRES` call from helper function.\n\nSince `OP_REQUIRES` macro expands to a `return;` (among other), calling it in a helper function only ends the helper function's execution earlier, but the kernel will still run from start to end. Thus, all the expected validations are actually broken\/useless as the code ploughs through the next crash anyway.\n\nPiperOrigin-RevId: 369524386\nChange-Id: I54f6cf9328445675ccc392e661b04336b229c9da",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 34, 'deletions': 33, 'total': 67}",
            "files":"{'tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc': {'additions': 34, 'deletions': 33, 'changes': 67, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd\/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_cholesky_op.cc', 'patch': '@@ -17,6 +17,8 @@ limitations under the License.\\n #include <numeric>\\n #include <vector>\\n \\n+#include \"tensorflow\/core\/framework\/op_requires.h\"\\n+\\n #define EIGEN_USE_THREADS\\n \\n #include \"third_party\/eigen3\/Eigen\/Core\"\\n@@ -82,8 +84,8 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\\n \\n     int64 num_rows;\\n     int batch_size;\\n-    ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size,\\n-                   &num_rows);\\n+    OP_REQUIRES_OK(ctx, ValidateInputs(*input_matrix, input_permutation_indices,\\n+                                       &batch_size, &num_rows));\\n \\n     \/\/ Allocate batch pointers.\\n     Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\\n@@ -226,49 +228,48 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\\n   }\\n \\n  private:\\n-  void ValidateInputs(OpKernelContext* ctx,\\n-                      const CSRSparseMatrix& sparse_matrix,\\n-                      const Tensor& permutation_indices, int* batch_size,\\n-                      int64* num_rows) {\\n-    OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value,\\n-                errors::InvalidArgument(\\n-                    \"Asked for a CSRSparseMatrix of type \",\\n-                    DataTypeString(DataTypeToEnum<T>::value),\\n-                    \" but saw dtype: \", DataTypeString(sparse_matrix.dtype())));\\n+  Status ValidateInputs(const CSRSparseMatrix& sparse_matrix,\\n+                        const Tensor& permutation_indices, int* batch_size,\\n+                        int64* num_rows) {\\n+    if (sparse_matrix.dtype() != DataTypeToEnum<T>::value)\\n+      return errors::InvalidArgument(\\n+          \"Asked for a CSRSparseMatrix of type \",\\n+          DataTypeString(DataTypeToEnum<T>::value),\\n+          \" but saw dtype: \", DataTypeString(sparse_matrix.dtype()));\\n \\n     const Tensor& dense_shape = sparse_matrix.dense_shape();\\n     const int rank = dense_shape.dim_size(0);\\n-    OP_REQUIRES(ctx, rank == 2 || rank == 3,\\n-                errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\\n-                                        \"but dense_shape has size \", rank));\\n+    if (rank < 2 || rank > 3)\\n+      return errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\\n+                                     \"but dense_shape has size \", rank);\\n     const int row_dim = (rank == 2) ? 0 : 1;\\n     auto dense_shape_vec = dense_shape.vec<int64>();\\n     *num_rows = dense_shape_vec(row_dim);\\n     const int64 num_cols = dense_shape_vec(row_dim + 1);\\n-    OP_REQUIRES(ctx, *num_rows == num_cols,\\n-                errors::InvalidArgument(\"sparse matrix must be square; got: \",\\n-                                        *num_rows, \" != \", num_cols));\\n+    if (*num_rows != num_cols)\\n+      return errors::InvalidArgument(\\n+          \"sparse matrix must be square; got: \", *num_rows, \" != \", num_cols);\\n     const TensorShape& perm_shape = permutation_indices.shape();\\n-    OP_REQUIRES(\\n-        ctx, perm_shape.dims() + 1 == rank,\\n-        errors::InvalidArgument(\\n-            \"sparse matrix must have the same rank as permutation; got: \", rank,\\n-            \" != \", perm_shape.dims(), \" + 1.\"));\\n-    OP_REQUIRES(\\n-        ctx, perm_shape.dim_size(rank - 2) == *num_rows,\\n-        errors::InvalidArgument(\\n-            \"permutation must have the same number of elements in each batch \"\\n-            \"as the number of rows in sparse matrix; got: \",\\n-            perm_shape.dim_size(rank - 2), \" != \", *num_rows));\\n+    if (perm_shape.dims() + 1 != rank)\\n+      return errors::InvalidArgument(\\n+          \"sparse matrix must have the same rank as permutation; got: \", rank,\\n+          \" != \", perm_shape.dims(), \" + 1.\");\\n+    if (perm_shape.dim_size(rank - 2) != *num_rows)\\n+      return errors::InvalidArgument(\\n+          \"permutation must have the same number of elements in each batch \"\\n+          \"as the number of rows in sparse matrix; got: \",\\n+          perm_shape.dim_size(rank - 2), \" != \", *num_rows);\\n \\n     *batch_size = sparse_matrix.batch_size();\\n     if (*batch_size > 1) {\\n-      OP_REQUIRES(\\n-          ctx, perm_shape.dim_size(0) == *batch_size,\\n-          errors::InvalidArgument(\"permutation must have the same batch size \"\\n-                                  \"as sparse matrix; got: \",\\n-                                  perm_shape.dim_size(0), \" != \", *batch_size));\\n+      if (perm_shape.dim_size(0) != *batch_size)\\n+        return errors::InvalidArgument(\\n+            \"permutation must have the same batch size \"\\n+            \"as sparse matrix; got: \",\\n+            perm_shape.dim_size(0), \" != \", *batch_size);\\n     }\\n+\\n+    return Status::OK();\\n   }\\n };'}}",
            "message_norm":"remove `op_requires` call from helper function.\n\nsince `op_requires` macro expands to a `return;` (among other), calling it in a helper function only ends the helper function's execution earlier, but the kernel will still run from start to end. thus, all the expected validations are actually broken\/useless as the code ploughs through the next crash anyway.\n\npiperorigin-revid: 369524386\nchange-id: i54f6cf9328445675ccc392e661b04336b229c9da",
            "language":"en",
            "entities":"[('remove', 'ACTION', ''), ('369524386', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3395,
            "vuln_id":"GHSA-x83m-p7pv-ch8v",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/744009c9e5cc5d0447f0dc39d055f917e1fd9e16'}",
            "dataset":"osv",
            "summary":"Division by 0 in `QuantizedAdd` ### Impact\nAn attacker can cause a runtime division by zero error and denial of service in `tf.raw_ops.QuantizedAdd`:\n\n```python\nimport tensorflow as tf\n\nx = tf.constant([68, 228], shape=[2, 1], dtype=tf.quint8)\ny = tf.constant([], shape=[2, 0], dtype=tf.quint8)\n\nmin_x = tf.constant(10.723421015884028)\nmax_x = tf.constant(15.19578006631113)\nmin_y = tf.constant(-5.539003866682977)\nmax_y = tf.constant(42.18819949559947)\n\ntf.raw_ops.QuantizedAdd(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f26b3f3418201479c264f2a02000880d8df151c\/tensorflow\/core\/kernels\/quantized_add_op.cc#L289-L295) computes a modulo operation without validating that the divisor is not zero.\n\n```cc\nvoid VectorTensorAddition(const T* vector_data, float min_vector,\n                          float max_vector, int64 vector_num_elements,\n                          const T* tensor_data, float min_tensor,\n                          float max_tensor, int64 tensor_num_elements,\n                          float output_min, float output_max, Toutput* output) {\n  for (int i = 0; i < tensor_num_elements; ++i) {\n    const int64 vector_i = i % vector_num_elements;\n    ...\n  }\n}\n```\n\nSince `vector_num_elements` is [determined based on input shapes](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/6f26b3f3418201479c264f2a02000880d8df151c\/tensorflow\/core\/kernels\/quantized_add_op.cc#L522-L544), a user can trigger scenarios where this quantity is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [744009c9e5cc5d0447f0dc39d055f917e1fd9e16](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/744009c9e5cc5d0447f0dc39d055f917e1fd9e16).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/744009c9e5cc5d0447f0dc39d055f917e1fd9e16",
            "commit_sha":"744009c9e5cc5d0447f0dc39d055f917e1fd9e16",
            "patch":"SINGLE",
            "chain_ord":"['744009c9e5cc5d0447f0dc39d055f917e1fd9e16']",
            "before_first_fix_commit":"{'6f26b3f3418201479c264f2a02000880d8df151c'}",
            "last_fix_commit":"744009c9e5cc5d0447f0dc39d055f917e1fd9e16",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2021, 19:00:12",
            "message":"Validate work in `QuantizedAdd`, ensure at least one element.\n\nPiperOrigin-RevId: 370127996\nChange-Id: I57c6f3e01afdeada84737820a131590137463855",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/quantized_add_op.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/744009c9e5cc5d0447f0dc39d055f917e1fd9e16\/tensorflow%2Fcore%2Fkernels%2Fquantized_add_op.cc', 'patch': '@@ -538,6 +538,8 @@ class QuantizedAddOp : public OpKernel {\\n         tensor_min = min_x;\\n         tensor_max = max_x;\\n       }\\n+      OP_REQUIRES(context, vector_num_elements > 0,\\n+                  errors::InvalidArgument(\"Must have some elements to add\"));\\n       VectorTensorAddition<T, Toutput>(\\n           vector_data, vector_min, vector_max, vector_num_elements, tensor_data,\\n           tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,'}}",
            "message_norm":"validate work in `quantizedadd`, ensure at least one element.\n\npiperorigin-revid: 370127996\nchange-id: i57c6f3e01afdeada84737820a131590137463855",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('ensure', 'ACTION', ''), ('370127996', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_add_op.cc'])",
            "num_files":1.0
        },
        {
            "index":2381,
            "vuln_id":"GHSA-m884-279h-32v2",
            "cwe_id":"{'CWE-209'}",
            "score":4.6,
            "chain":"{'https:\/\/github.com\/symfony\/symfony\/commit\/629d21b800a15dc649fb0ae9ed7cd9211e7e45db', 'https:\/\/github.com\/symfony\/symfony\/commit\/cf80224589ac05402d4f72f5ddf80900ec94d5ad'}",
            "dataset":"osv",
            "summary":"Exceptions displayed in non-debug configurations in Symfony Description\n-----------\n\nWhen `ErrorHandler` renders an exception HTML page, it uses un-escaped properties from the related Exception class to render the stacktrace. The security issue comes from the fact that the stacktraces were also displayed in non-`debug` environments.\n\nResolution\n----------\n\nThe `ErrorHandler` class now escapes all properties coming from the related Exception, and the stacktrace is not displayed anymore in non-`debug` environments.\n\nThe patches for this issue are available [here](https:\/\/github.com\/symfony\/symfony\/commit\/cf80224589ac05402d4f72f5ddf80900ec94d5ad) and [here](https:\/\/github.com\/symfony\/symfony\/commit\/629d21b800a15dc649fb0ae9ed7cd9211e7e45db) for branch 4.4.\n\nCredits\n-------\n\nI would like to thank Luka Sikic for reporting & Yonel Ceruto and J\u00e9r\u00e9my Deruss\u00e9 for fixing the issue.",
            "published_date":"2020-03-30",
            "chain_len":2,
            "project":"https:\/\/github.com\/symfony\/symfony",
            "commit_href":"https:\/\/github.com\/symfony\/symfony\/commit\/629d21b800a15dc649fb0ae9ed7cd9211e7e45db",
            "commit_sha":"629d21b800a15dc649fb0ae9ed7cd9211e7e45db",
            "patch":"MULTI",
            "chain_ord":"['cf80224589ac05402d4f72f5ddf80900ec94d5ad', '629d21b800a15dc649fb0ae9ed7cd9211e7e45db']",
            "before_first_fix_commit":"{'3ee39e7468f1cd0b5a88b89aad72d61214e950f4'}",
            "last_fix_commit":"629d21b800a15dc649fb0ae9ed7cd9211e7e45db",
            "chain_ord_pos":2.0,
            "commit_datetime":"02\/04\/2020, 09:49:52",
            "message":"Escape variable in Exception Template",
            "author":"J\u00e9r\u00e9my Deruss\u00e9",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 3, 'total': 6}",
            "files":"{'src\/Symfony\/Component\/ErrorHandler\/Resources\/views\/traces_text.html.php': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/symfony\/symfony\/raw\/629d21b800a15dc649fb0ae9ed7cd9211e7e45db\/src%2FSymfony%2FComponent%2FErrorHandler%2FResources%2Fviews%2Ftraces_text.html.php', 'patch': '@@ -20,15 +20,15 @@\\n                 <?php if ($exception[\\'trace\\']) { ?>\\n                 <pre class=\"stacktrace\">\\n <?php\\n-                    echo $exception[\\'class\\'].\":\\\\n\";\\n+                    echo $this->escape($exception[\\'class\\']).\":\\\\n\";\\n                     if ($exception[\\'message\\']) {\\n-                        echo $exception[\\'message\\'].\"\\\\n\";\\n+                        echo $this->escape($exception[\\'message\\']).\"\\\\n\";\\n                     }\\n \\n                     foreach ($exception[\\'trace\\'] as $trace) {\\n                         echo \"\\\\n  \";\\n                         if ($trace[\\'function\\']) {\\n-                            echo \\'at \\'.$trace[\\'class\\'].$trace[\\'type\\'].$trace[\\'function\\'].\\'(\\'.(isset($trace[\\'args\\']) ? $this->formatArgsAsText($trace[\\'args\\']) : \\'\\').\\')\\';\\n+                            echo $this->escape(\\'at \\'.$trace[\\'class\\'].$trace[\\'type\\'].$trace[\\'function\\']).\\'(\\'.(isset($trace[\\'args\\']) ? $this->formatArgsAsText($trace[\\'args\\']) : \\'\\').\\')\\';\\n                         }\\n                         if ($trace[\\'file\\'] && $trace[\\'line\\']) {\\n                             echo($trace[\\'function\\'] ? \"\\\\n     (\" : \\'at \\').strtr(strip_tags($this->formatFile($trace[\\'file\\'], $trace[\\'line\\'])), [\\' at line \\'.$trace[\\'line\\'] => \\'\\']).\\':\\'.$trace[\\'line\\'].($trace[\\'function\\'] ? \\')\\' : \\'\\');'}}",
            "message_norm":"escape variable in exception template",
            "language":"ro",
            "entities":"[('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Symfony\/Component\/ErrorHandler\/Resources\/views\/traces_text.html.php'])",
            "num_files":1.0
        },
        {
            "index":3064,
            "vuln_id":"GHSA-v6vg-pxvv-g5cq",
            "cwe_id":"{'CWE-269'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/db0c0e790892db874573d95f8ae4268b8a011ab1'}",
            "dataset":"osv",
            "summary":"Improper Privilege Management in Snipe-IT Snipe-IT prior to 5.3.9 is vulnerable to improper privilege management. A user who does not have access to the supplier module may view supplier content.",
            "published_date":"2022-02-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/db0c0e790892db874573d95f8ae4268b8a011ab1",
            "commit_sha":"db0c0e790892db874573d95f8ae4268b8a011ab1",
            "patch":"SINGLE",
            "chain_ord":"['db0c0e790892db874573d95f8ae4268b8a011ab1']",
            "before_first_fix_commit":"{'05c0819776b07425b2831cd31a8a0f4e7ac30c09', 'd77a47765ea1fd112a9b0731a88de1e26ed24256'}",
            "last_fix_commit":"db0c0e790892db874573d95f8ae4268b8a011ab1",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/13\/2022, 18:56:55",
            "message":"Merge pull request #10665 from snipe\/fixes\/adds_gate_to_supplier_view\n\nAdds gate to supplier",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'app\/Http\/Controllers\/SuppliersController.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/db0c0e790892db874573d95f8ae4268b8a011ab1\/app%2FHttp%2FControllers%2FSuppliersController.php', 'patch': \"@@ -184,6 +184,7 @@ public function destroy($supplierId)\\n      *\/\\n     public function show($supplierId = null)\\n     {\\n+        $this->authorize('view', Supplier::class);\\n         $supplier = Supplier::find($supplierId);\\n \\n         if (isset($supplier->id)) {\"}}",
            "message_norm":"merge pull request #10665 from snipe\/fixes\/adds_gate_to_supplier_view\n\nadds gate to supplier",
            "language":"en",
            "entities":"[('#10665', 'ISSUE', ''), ('adds_gate_to_supplier_view', 'ACTION', ''), ('adds', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/SuppliersController.php'])",
            "num_files":1.0
        },
        {
            "index":945,
            "vuln_id":"GHSA-73rp-q4rx-5grc",
            "cwe_id":"{'CWE-284', 'CWE-863'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/c162dfffb9bfd264d232aaaf5bb3daee16a3cb38'}",
            "dataset":"osv",
            "summary":"Incorrect Authorization in microweber Users Account Pre-Takeover or Users Account Takeover. in GitHub repository microweber\/microweber prior to 1.2.15. Victim Account Take Over. Since, there is no email confirmation, an attacker can easily create an account in the application using the Victim\u2019s Email. This allows an attacker to gain pre-authentication to the victim\u2019s account. Further, due to the lack of proper validation of email coming from Social Login and failing to check if an account already exists, the victim will not identify if an account is already existing. Hence, the attacker\u2019s persistence will remain. An attacker would be able to see all the activities performed by the victim user impacting the confidentiality and attempt to modify\/corrupt the data impacting the integrity and availability factor. This attack becomes more interesting when an attacker can register an account from an employee\u2019s email address. Assuming the organization uses G-Suite, it is much more impactful to hijack into an employee\u2019s account.",
            "published_date":"2022-05-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/c162dfffb9bfd264d232aaaf5bb3daee16a3cb38",
            "commit_sha":"c162dfffb9bfd264d232aaaf5bb3daee16a3cb38",
            "patch":"SINGLE",
            "chain_ord":"['c162dfffb9bfd264d232aaaf5bb3daee16a3cb38']",
            "before_first_fix_commit":"{'12c0316b3bde8ff6a6adc5d2a05f6409b03c9556'}",
            "last_fix_commit":"c162dfffb9bfd264d232aaaf5bb3daee16a3cb38",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/09\/2022, 12:54:29",
            "message":"Update index.blade.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'src\/MicroweberPackages\/Shop\/resources\/views\/index.blade.php': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/c162dfffb9bfd264d232aaaf5bb3daee16a3cb38\/src%2FMicroweberPackages%2FShop%2Fresources%2Fviews%2Findex.blade.php', 'patch': '@@ -46,9 +46,11 @@\\n                         <div class=\"d-flex\">\\n                             <p class=\"col-6 mb-0\">\\n                                 @if($product->hasSpecialPrice())\\n-                                    <span class=\"price-old\"><?php print currency_format($product->specialPrice); ?><\/span>\\n+                                    <span class=\"price-old\"><?php print currency_format($product->price); ?><\/span>\\n+                                    <span class=\"money\"><?php print currency_format($product->specialPrice); ?><\/span>\\n+                                @else\\n+                                    <span class=\"money\"><?php print currency_format($product->price); ?><\/span>\\n                                 @endif\\n-                                <span class=\"money\"><?php print currency_format($product->price); ?><\/span>\\n                             <\/p>\\n \\n                             <a class=\"col-6 text-end text-right align-self-center\" href=\"{{content_link($product->id)}}\"> View<\/a>'}}",
            "message_norm":"update index.blade.php",
            "language":"sv",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/Shop\/resources\/views\/index.blade.php'])",
            "num_files":1.0
        },
        {
            "index":1452,
            "vuln_id":"GHSA-c265-37vj-cwcc",
            "cwe_id":"{'CWE-502'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/99001cdb6807b5c7b170ec6a9092ecbb618ae79c'}",
            "dataset":"osv",
            "summary":"Deserialization of untrusted data in Jackson Databind FasterXML jackson-databind 2.x before 2.9.10.5 mishandles the interaction between serialization gadgets and typing, related to com.sun.org.apache.xalan.internal.lib.sql.JNDIConnectionPool (aka xalan2).",
            "published_date":"2020-06-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/FasterXML\/jackson-databind",
            "commit_href":"https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
            "commit_sha":"99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
            "patch":"SINGLE",
            "chain_ord":"['99001cdb6807b5c7b170ec6a9092ecbb618ae79c']",
            "before_first_fix_commit":"{'716f3f95fb82c686cc20d7255665de54c5330fa7'}",
            "last_fix_commit":"99001cdb6807b5c7b170ec6a9092ecbb618ae79c",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/02\/2020, 02:17:39",
            "message":"Fix #2704",
            "author":"Tatu Saloranta",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'release-notes\/VERSION-2.x': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/FasterXML\/jackson-databind\/raw\/99001cdb6807b5c7b170ec6a9092ecbb618ae79c\/release-notes%2FVERSION-2.x', 'patch': '@@ -10,6 +10,8 @@ Project: jackson-databind\\n  (reported by Topsec(tcc))\\n #2698: Block one more gadget type (weblogic\/oracle-aqjms)\\n  (reported by Fangrun Li)\\n+#2704: Block one more gadget type (weblogic\/oracle-aqjms)\\n+ (reported by XuYuanzhen)\\n \\n 2.9.10.4 (11-Apr-2020)'}}",
            "message_norm":"fix #2704",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('#2704', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['release-notes\/VERSION-2.x'])",
            "num_files":1.0
        },
        {
            "index":1904,
            "vuln_id":"GHSA-gp2m-7cfp-h6gf",
            "cwe_id":"{'CWE-384'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/simplesamlphp\/simplesamlphp\/commit\/90dca835158495b173808273e7df127303b8b953'}",
            "dataset":"osv",
            "summary":"Incorrect persistent NameID generation in SimpleSAMLphp ### Background\nWhen a SimpleSAMLphp Identity Provider is misconfigured, a bug in the software when trying to build a persistent `NameID` to univocally identify the authenticating subject could cause different users to get the same identifier generated, depending on the attributes available for them right after authentication.\n\nPlease note that even though this is possible thanks to a bug, **an IdP must be misconfigured** to release persistent `NameID`s even if it is not properly configured to generate them based on the specifics of the deployment.\n\n### Description\nPersistent `NameID`s will typically be sent as part of the `Subject` element of a SAML assertion, or as the contents of the `eduPersonTargetedID` attribute. Here is an example of such a `NameID`:\n\n    <NameID Format=\u201curn:oasis:names:tc:SAML:2.0:nameid-format:persistent\u201c>\n        zbonsm0Yn9Gnw14uQEEPr6AO7d+IvxwCQN3t+o24jYs=\n    <\/NameID>\n\nSome service providers will use this information to identify a user across sessions because a persistent `NameID` will never change for a given user. This could lead to different users accessing the same account in those service providers.\n\nIn order to be affected by this issue, the following circumstances must concur:\n\n- SimpleSAMLphp acts as an identity provider.\n- The service provider asking for authentication requests a persistent `NameID`.\n- No `saml:PersistentNameID` authentication processing filter is configured (neither for the whole IdP, nor for a given SP).\n- No `simplesaml.nameidattribute` configuration option is set (neither for the whole IdP, nor for a given SP).\n- One of the following alternatives:\n  - No `userid.attribute` configuration option is set **and** the users don't have an `eduPersonPrincipalName` attribute in the users backend, **or**\n  - the `userid.attribute` configuration option is set to an empty or missing attribute.\n\nIf all these requirements are met, the `SimpleSAML_Auth_ProcessingChain` class will try to keep a unique user identifier in the state array (`addUserID()` method). Bear in mind that this code is executed **before** all the authentication processing filters configured, meaning that only those attributes retrieved for the user during **initial authentication** will be available. If no `userid.attribute` configuration option is set, the default `eduPersonPrincipalName` will then be used. However, since it is missing, no identifier will be kept. Alternatively, if `userid.attribute` is set to a missing or empty attribute, the `addUserID()` method will abort trying to register an identifier.\n\nAfter executing all authentication processing filters, SimpleSAMLphp will build a SAML assertion. If the service provider requests persistent `NameID`s, SimpleSAMLphp will attempt to generate one given that none is already available (because the `saml:PersistentNameID` filter was not used). At this point, the code will look for the `simplesaml.nameidattribute` configuration option in either the local IdP metadata or in the remote SP metadata. If none of them are configured, it will default to the unique user identifier previously registered by `SimpleSAML_Auth_ProcessingChain`. If no identifier was kept there, the code will log an error message:\n\n    Unable to generate NameID. Check the userid.attribute option.\n\nHowever, instead of aborting the `NameID` generation at that point, it will go on and use a value missing from the state array as the source for the computation, meaning the `null` type will be used. Hence, all users connecting to a given service provider will get the same `NameID` generated, because all the input parameters will be the same:\n\n- The SP's entity identifier.\n- The IdP's entity identifier.\n- The `null` value.\n- The common secret salt from the main configuration.\n\n### Affected versions\nAll SimpleSAMLphp versions between 1.7.0 and 1.14.10, inclusive.\n\n### Impact\nThose identity providers affected by this bug and misconfigured as previously described could be issuing SAML assertions with common `NameID`s for all or a subset of their users. If a service provider uses those `NameID`s to identify the users of the affected IdP, all the users will be associated with the same user account at the service provider, causing all sorts of potential security issues like information disclosure or unauthorized access.\n\nWhile we can consider this unlikely to happen, some cases have been already observed. In particular, some identity providers using default configurations and consuming metadata automatically (i.e. using the _metarefresh_ module) while using a user backend like _Active Directory_ that does not populate `eduPersonPrincipalName` are particularly sensitive to this issue.\n\n### Resolution\nUpgrade to the latest version.\n\nConfigure a `saml:PersistentNameID` authentication processing filter according to your needs. Remember to check that **the attribute used as the source** for the `NameID` **is present at the moment the `saml:PersistentNameID` filter is executed**. The attribute used must be **unique** per user, and **must not change** over time.",
            "published_date":"2020-01-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/simplesamlphp\/simplesamlphp",
            "commit_href":"https:\/\/github.com\/simplesamlphp\/simplesamlphp\/commit\/90dca835158495b173808273e7df127303b8b953",
            "commit_sha":"90dca835158495b173808273e7df127303b8b953",
            "patch":"SINGLE",
            "chain_ord":"['90dca835158495b173808273e7df127303b8b953']",
            "before_first_fix_commit":"{'300d8aa48fe93706ade95be481c68e9cf2f32d1f'}",
            "last_fix_commit":"90dca835158495b173808273e7df127303b8b953",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/12\/2016, 11:21:31",
            "message":"bugfix: Make sure a persistent NameID is not generated by default when the UserID is missing in the state array.\n\nThis allowed misconfigured IdPs (i.e. those without both a PersistenNameID authproc filter, a \u201cuserid.attribute\u201d configuration option and no \u201ceduPersonPrincipalName\u201d attribute available after running all the authentication processing filters) to generate a persistent NameID based on \u201cnull\u201d, effectively giving all users the same identifier.",
            "author":"Jaime Pe\u0301rez",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'modules\/saml\/lib\/IdP\/SAML2.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/simplesamlphp\/simplesamlphp\/raw\/90dca835158495b173808273e7df127303b8b953\/modules%2Fsaml%2Flib%2FIdP%2FSAML2.php', 'patch': \"@@ -623,6 +623,7 @@ private static function generateNameIdValue(SimpleSAML_Configuration $idpMetadat\\n \\t\\t\\tif ($attribute === NULL) {\\n \\t\\t\\t\\tif (!isset($state['UserID'])) {\\n \\t\\t\\t\\t\\tSimpleSAML_Logger::error('Unable to generate NameID. Check the userid.attribute option.');\\n+\\t\\t\\t\\t\\treturn NULL;\\n \\t\\t\\t\\t}\\n \\t\\t\\t\\t$attributeValue = $state['UserID'];\\n \\t\\t\\t\\t$idpEntityId = $idpMetadata->getString('entityid');\"}}",
            "message_norm":"bugfix: make sure a persistent nameid is not generated by default when the userid is missing in the state array.\n\nthis allowed misconfigured idps (i.e. those without both a persistennameid authproc filter, a \u201cuserid.attribute\u201d configuration option and no \u201cedupersonprincipalname\u201d attribute available after running all the authentication processing filters) to generate a persistent nameid based on \u201cnull\u201d, effectively giving all users the same identifier.",
            "language":"en",
            "entities":"[('bugfix', 'FLAW', ''), ('authentication', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/saml\/lib\/IdP\/SAML2.php'])",
            "num_files":1.0
        },
        {
            "index":2923,
            "vuln_id":"GHSA-rcxc-3w2m-mp8h",
            "cwe_id":"{'CWE-502'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/NVIDIA\/NVFlare\/commit\/fd018eea9dff925a765079a94c2f017920fcda67'}",
            "dataset":"osv",
            "summary":"Unsafe deserialisation in the PKI implementation scheme of NVFlare ### Impact\nNVFLARE contains a vulnerability in its PKI implementation module, where The CA credentials are transported via pickle and no safe deserialization. The deserialization of Untrusted Data may allow an unprivileged network attacker to cause Remote Code Execution, Denial Of Service, and Impact to both Confidentiality and Integrity.\nAll versions before 2.1.2 are affected.\n\nCVSS Score = 9.8\n[AV:N\/AC:L\/PR:N\/UI:N\/S:U\/C:H\/I:H\/A:H](https:\/\/nam11.safelinks.protection.outlook.com\/?url=https%3A%2F%2Fnvd.nist.gov%2Fvuln-metrics%2Fcvss%2Fv3-calculator%3Fvector%3DAV%3AN%2FAC%3AL%2FPR%3AN%2FUI%3AN%2FS%3AU%2FC%3AH%2FI%3AH%2FA%3AH&data=05%7C01%7Cchesterc%40nvidia.com%7Ce9600bde16854b0b380008da4fc544f7%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C637910005925574215%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=5kBrXEmAbqp8R31JCH%2FG95MUly72UPVihnBwiRFmvBY%3D&reserved=0)\n\n\n\n### Patches\nThe patch will be included in nvflare==2.1.2\n\n### Workarounds\nReplace pickle serialization with JSON and change the code accordingly\n\nAdditional information\nIssue Found by: Oliver Sellwood (@Nintorac)",
            "published_date":"2022-06-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/NVIDIA\/NVFlare",
            "commit_href":"https:\/\/github.com\/NVIDIA\/NVFlare\/commit\/fd018eea9dff925a765079a94c2f017920fcda67",
            "commit_sha":"fd018eea9dff925a765079a94c2f017920fcda67",
            "patch":"SINGLE",
            "chain_ord":"['fd018eea9dff925a765079a94c2f017920fcda67']",
            "before_first_fix_commit":"{'f0a005982122277a1ac22cb04f977186393d8ab2'}",
            "last_fix_commit":"fd018eea9dff925a765079a94c2f017920fcda67",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/19\/2022, 15:30:59",
            "message":"Replace pickle in state persistence in provision cert with json (#412)",
            "author":"Isaac Yang",
            "comments":null,
            "stats":"{'additions': 17, 'deletions': 13, 'total': 30}",
            "files":"{'nvflare\/lighter\/impl\/cert.py': {'additions': 17, 'deletions': 13, 'changes': 30, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NVIDIA\/NVFlare\/raw\/fd018eea9dff925a765079a94c2f017920fcda67\/nvflare%2Flighter%2Fimpl%2Fcert.py', 'patch': '@@ -13,8 +13,8 @@\\n # limitations under the License.\\n \\n import datetime\\n+import json\\n import os\\n-import pickle\\n \\n from cryptography import x509\\n from cryptography.hazmat.backends import default_backend\\n@@ -50,13 +50,13 @@ def __init__(self):\\n \\n     def initialize(self, ctx):\\n         state_dir = self.get_state_dir(ctx)\\n-        cert_file = os.path.join(state_dir, \"cert.pkl\")\\n+        cert_file = os.path.join(state_dir, \"cert.json\")\\n         if os.path.exists(cert_file):\\n-            self.persistent_state = pickle.load(open(cert_file, \"rb\"))\\n-            self.serialized_cert = self.persistent_state[\"root_cert\"]\\n+            self.persistent_state = json.load(open(cert_file, \"rt\"))\\n+            self.serialized_cert = self.persistent_state[\"root_cert\"].encode(\"ascii\")\\n             self.root_cert = x509.load_pem_x509_certificate(self.serialized_cert, default_backend())\\n             self.pri_key = serialization.load_pem_private_key(\\n-                self.persistent_state[\"root_pri_key\"], password=None, backend=default_backend()\\n+                self.persistent_state[\"root_pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\\n             )\\n             self.pub_key = self.pri_key.public_key()\\n             self.subject = self.root_cert.subject\\n@@ -69,26 +69,30 @@ def _build_root(self, subject):\\n             self.pri_key = pri_key\\n             self.pub_key = pub_key\\n             self.serialized_cert = serialize_cert(self.root_cert)\\n-            self.persistent_state[\"root_cert\"] = self.serialized_cert\\n-            self.persistent_state[\"root_pri_key\"] = serialize_pri_key(self.pri_key)\\n+            self.persistent_state[\"root_cert\"] = self.serialized_cert.decode(\"ascii\")\\n+            self.persistent_state[\"root_pri_key\"] = serialize_pri_key(self.pri_key).decode(\"ascii\")\\n \\n     def _build_write_cert_pair(self, participant, base_name, ctx):\\n         subject = participant.subject\\n         if self.persistent_state and subject in self.persistent_state:\\n-            cert = x509.load_pem_x509_certificate(self.persistent_state[subject][\"cert\"], default_backend())\\n+            cert = x509.load_pem_x509_certificate(\\n+                self.persistent_state[subject][\"cert\"].encode(\"ascii\"), default_backend()\\n+            )\\n             pri_key = serialization.load_pem_private_key(\\n-                self.persistent_state[subject][\"pri_key\"], password=None, backend=default_backend()\\n+                self.persistent_state[subject][\"pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\\n             )\\n         else:\\n             pri_key, cert = self.get_pri_key_cert(participant)\\n-            self.persistent_state[subject] = dict(cert=serialize_cert(cert), pri_key=serialize_pri_key(pri_key))\\n+            self.persistent_state[subject] = dict(\\n+                cert=serialize_cert(cert).decode(\"ascii\"), pri_key=serialize_pri_key(pri_key).decode(\"ascii\")\\n+            )\\n         dest_dir = self.get_kit_dir(participant, ctx)\\n         with open(os.path.join(dest_dir, f\"{base_name}.crt\"), \"wb\") as f:\\n             f.write(serialize_cert(cert))\\n         with open(os.path.join(dest_dir, f\"{base_name}.key\"), \"wb\") as f:\\n             f.write(serialize_pri_key(pri_key))\\n         pkcs12 = serialization.pkcs12.serialize_key_and_certificates(\\n-            subject.encode(\"utf-8\"), pri_key, cert, None, serialization.BestAvailableEncryption(subject.encode(\"utf-8\"))\\n+            subject.encode(\"ascii\"), pri_key, cert, None, serialization.BestAvailableEncryption(subject.encode(\"ascii\"))\\n         )\\n         with open(os.path.join(dest_dir, f\"{base_name}.pfx\"), \"wb\") as f:\\n             f.write(pkcs12)\\n@@ -163,5 +167,5 @@ def _x509_name(self, cn_name, org_name=None):\\n \\n     def finalize(self, ctx):\\n         state_dir = self.get_state_dir(ctx)\\n-        cert_file = os.path.join(state_dir, \"cert.pkl\")\\n-        pickle.dump(self.persistent_state, open(cert_file, \"wb\"))\\n+        cert_file = os.path.join(state_dir, \"cert.json\")\\n+        json.dump(self.persistent_state, open(cert_file, \"wt\"))'}}",
            "message_norm":"replace pickle in state persistence in provision cert with json (#412)",
            "language":"en",
            "entities":"[('#412', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['nvflare\/lighter\/impl\/cert.py'])",
            "num_files":1.0
        },
        {
            "index":2046,
            "vuln_id":"GHSA-hf44-3mx6-vhhw",
            "cwe_id":"{'CWE-400'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/graphhopper\/graphhopper\/commit\/eb189be1fa7443ebf4ae881e737a18f818c95f41'}",
            "dataset":"osv",
            "summary":"Navigate endpoint is vulnerable to regex injection that may lead to Denial of Service. ### Impact\nThe regex injection that may lead to Denial of Service.\n\n### Patches\nWill be patched in 2.4 and 3.0\n\n### Workarounds\nVersions lower than 2.x are only affected if the navigation module is added\n\n### References\nSee this pull request for the fix: https:\/\/github.com\/graphhopper\/graphhopper\/pull\/2304\n\nIf you have any questions or comments about this advisory please [send us an Email](https:\/\/www.graphhopper.com\/contact-form\/) or create a topic [here](https:\/\/discuss.graphhopper.com\/).",
            "published_date":"2021-05-19",
            "chain_len":1,
            "project":"https:\/\/github.com\/graphhopper\/graphhopper",
            "commit_href":"https:\/\/github.com\/graphhopper\/graphhopper\/commit\/eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "commit_sha":"eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "patch":"SINGLE",
            "chain_ord":"['eb189be1fa7443ebf4ae881e737a18f818c95f41']",
            "before_first_fix_commit":"{'744f0e2535355e67aefbb6906303332b8aff0a7f'}",
            "last_fix_commit":"eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/04\/2021, 18:03:31",
            "message":"avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexOf\r\n\r\n* make check stricter\r\n\r\n* use @easbar's suggestion",
            "author":"Peter",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 5, 'total': 8}",
            "files":"{'navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java': {'additions': 3, 'deletions': 5, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/graphhopper\/graphhopper\/raw\/eb189be1fa7443ebf4ae881e737a18f818c95f41\/navigation%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgraphhopper%2Fnavigation%2FNavigateResource.java', 'patch': '@@ -188,13 +188,11 @@ private GHResponse calcRoute(List<Double> favoredHeadings, List<GHPoint> request\\n      * The url looks like: \"...\/{profile}\/1.522438,42.504606;1.527209,42.504776;1.526113,42.505144;1.527218,42.50529?..\"\\n      *\/\\n     private List<GHPoint> getPointsFromRequest(HttpServletRequest httpServletRequest, String profile) {\\n-\\n         String url = httpServletRequest.getRequestURI();\\n-        url = url.replaceFirst(\"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\", \"\");\\n-        url = url.replaceAll(\"\\\\\\\\?[*]\", \"\");\\n-\\n+        String urlStart = \"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\";\\n+        if (!url.startsWith(urlStart)) throw new IllegalArgumentException(\"Incorrect URL \" + url);\\n+        url = url.substring(urlStart.length());\\n         String[] pointStrings = url.split(\";\");\\n-\\n         List<GHPoint> points = new ArrayList<>(pointStrings.length);\\n         for (int i = 0; i < pointStrings.length; i++) {\\n             points.add(GHPoint.fromStringLonLat(pointStrings[i]));'}}",
            "message_norm":"avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexof\r\n\r\n* make check stricter\r\n\r\n* use @easbar's suggestion",
            "language":"en",
            "entities":"[('#2304', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java'])",
            "num_files":1.0
        },
        {
            "index":1410,
            "vuln_id":"GHSA-9p77-mmrw-69c7",
            "cwe_id":"{'CWE-476'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a513cec4bec15961fbfdedcaa5376522980455c'}",
            "dataset":"osv",
            "summary":"Null-dereference in Tensorflow ### Impact\nWhen decoding a tensor from protobuf, TensorFlow might do a null-dereference if attributes of some mutable arguments to some operations are missing from the proto. This is [guarded by a `DCHECK`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/full_type_util.cc#L104-L106):\n\n```cc\n  const auto* attr = attrs.Find(arg->s()); \n  DCHECK(attr != nullptr);\n  if (attr->value_case() == AttrValue::kList) {\n    \/\/ ...\n  }\n```\nHowever, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the dereferencing of the null pointer, whereas in the second case it results in a crash due to the assertion failure.\n\n### Patches\nWe have patched the issue in GitHub commit [8a513cec4bec15961fbfdedcaa5376522980455c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a513cec4bec15961fbfdedcaa5376522980455c).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a513cec4bec15961fbfdedcaa5376522980455c",
            "commit_sha":"8a513cec4bec15961fbfdedcaa5376522980455c",
            "patch":"SINGLE",
            "chain_ord":"['8a513cec4bec15961fbfdedcaa5376522980455c']",
            "before_first_fix_commit":"{'258112d838f008a632fe0dc43fc9ebecb9b0b869'}",
            "last_fix_commit":"8a513cec4bec15961fbfdedcaa5376522980455c",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/08\/2021, 18:35:47",
            "message":"Prevent null dereference read in `SpecializeType()`\n\nFor some adversarial protos, the attribute for a key might not exist.\n\nPiperOrigin-RevId: 408382090\nChange-Id: Ie7eabe532c9ff280fce5dce1f6cdb93c76c2e040",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 1, 'total': 7}",
            "files":"{'tensorflow\/core\/framework\/full_type_util.cc': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/8a513cec4bec15961fbfdedcaa5376522980455c\/tensorflow%2Fcore%2Fframework%2Ffull_type_util.cc', 'patch': '@@ -22,6 +22,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/op_def.pb.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/platform\/statusor.h\"\\n+#include \"tensorflow\/core\/protobuf\/error_codes.pb.h\"\\n \\n namespace tensorflow {\\n \\n@@ -102,7 +103,11 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\\n       auto* arg = t->mutable_args(i);\\n       if (arg->type_id() == TFT_VAR) {\\n         const auto* attr = attrs.Find(arg->s());\\n-        DCHECK(attr != nullptr);\\n+        if (attr == nullptr) {\\n+          return Status(\\n+              error::INVALID_ARGUMENT,\\n+              absl::StrCat(\"Could not find an attribute for key \", arg->s()));\\n+        }\\n         if (attr->value_case() == AttrValue::kList) {\\n           const auto& attr_list = attr->list();\\n           arg->set_type_id(TFT_PRODUCT);'}}",
            "message_norm":"prevent null dereference read in `specializetype()`\n\nfor some adversarial protos, the attribute for a key might not exist.\n\npiperorigin-revid: 408382090\nchange-id: ie7eabe532c9ff280fce5dce1f6cdb93c76c2e040",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('null dereference', 'SECWORD', ''), ('adversarial', 'SECWORD', ''), ('key', 'SECWORD', ''), ('408382090', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/full_type_util.cc'])",
            "num_files":1.0
        },
        {
            "index":2020,
            "vuln_id":"GHSA-h7f9-cvh5-qw7f",
            "cwe_id":"{'CWE-22'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/1786bdd4962ee51544fad537352c2b4223309442'}",
            "dataset":"osv",
            "summary":"Path traversal in pimcore\/pimcore This affects the package pimcore\/pimcore before 6.8.8. A Local FIle Inclusion vulnerability exists in the downloadCsvAction function of the CustomReportController class (bundles\/AdminBundle\/Controller\/Reports\/CustomReportController.php). An authenticated user can reach this function with a GET request at the following endpoint: \/admin\/reports\/custom-report\/download-csv?exportFile=&91;filename]. Since exportFile variable is not sanitized, an attacker can exploit a local file inclusion vulnerability.",
            "published_date":"2021-02-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/1786bdd4962ee51544fad537352c2b4223309442",
            "commit_sha":"1786bdd4962ee51544fad537352c2b4223309442",
            "patch":"SINGLE",
            "chain_ord":"['1786bdd4962ee51544fad537352c2b4223309442']",
            "before_first_fix_commit":"{'3224684a3375c35910f8544943f4c073d30c8bfa'}",
            "last_fix_commit":"1786bdd4962ee51544fad537352c2b4223309442",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/05\/2021, 09:39:02",
            "message":"Fixed LFI in custom report csv download",
            "author":"Bernhard Rusch",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'bundles\/AdminBundle\/Controller\/Reports\/CustomReportController.php': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/1786bdd4962ee51544fad537352c2b4223309442\/bundles%2FAdminBundle%2FController%2FReports%2FCustomReportController.php', 'patch': \"@@ -433,7 +433,7 @@ public function createCsvAction(Request $request)\\n         $progress = $progress > 1 ? 1 : $progress;\\n \\n         return new JsonResponse([\\n-            'exportFile' => $exportFile,\\n+            'exportFile' => basename($exportFile),\\n             'offset' => $offset,\\n             'progress' => $progress,\\n             'finished' => empty($result['data']) || count($result['data']) < $limit,\\n@@ -451,6 +451,7 @@ public function downloadCsvAction(Request $request)\\n     {\\n         $this->checkPermission('reports');\\n         if ($exportFile = $request->get('exportFile')) {\\n+            $exportFile = PIMCORE_SYSTEM_TEMP_DIRECTORY . '\/' . basename($exportFile);\\n             $response = new BinaryFileResponse($exportFile);\\n             $response->headers->set('Content-Type', 'text\/csv; charset=UTF-8');\\n             $response->setContentDisposition(ResponseHeaderBag::DISPOSITION_ATTACHMENT, 'export.csv');\"}}",
            "message_norm":"fixed lfi in custom report csv download",
            "language":"en",
            "entities":"[('fixed', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Controller\/Reports\/CustomReportController.php'])",
            "num_files":1.0
        },
        {
            "index":1697,
            "vuln_id":"GHSA-f8h4-7rgh-q2gm",
            "cwe_id":"{'CWE-787', 'CWE-120'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e0b6e58c328059829c3eb968136f17aa72b6c876'}",
            "dataset":"osv",
            "summary":"Segfault and heap buffer overflow in `{Experimental,}DatasetToTFRecord` ### Impact\nThe implementation for `tf.raw_ops.ExperimentalDatasetToTFRecord` and `tf.raw_ops.DatasetToTFRecord` can trigger heap buffer overflow and segmentation fault:\n\n```python\nimport tensorflow as tf\n\ndataset = tf.data.Dataset.range(3)\ndataset = tf.data.experimental.to_variant(dataset)\ntf.raw_ops.ExperimentalDatasetToTFRecord(\n  input_dataset=dataset,\n  filename='\/tmp\/output',\n  compression_type='')\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc#L93-L102) assumes that all records in the dataset are of string type. However, there is no check for that, and the example given above uses numeric types.\n\n### Patches\nWe have patched the issue in GitHub commit [e0b6e58c328059829c3eb968136f17aa72b6c876](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e0b6e58c328059829c3eb968136f17aa72b6c876).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e0b6e58c328059829c3eb968136f17aa72b6c876",
            "commit_sha":"e0b6e58c328059829c3eb968136f17aa72b6c876",
            "patch":"SINGLE",
            "chain_ord":"['e0b6e58c328059829c3eb968136f17aa72b6c876']",
            "before_first_fix_commit":"{'b5b9ae94a68215d4498ea2b3d1072dc4b2bf5600'}",
            "last_fix_commit":"e0b6e58c328059829c3eb968136f17aa72b6c876",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/29\/2021, 21:58:43",
            "message":"Fix segfault\/heap buffer overflow in `{Experimental,}DatasetToTFRecord` where dataset is numeric.\n\nCode assumes only strings inputs and then interprets numbers as valid `tstring`s. Then, when trying to compute the CRC of the record this results in heap buffer overflow.\n\nPiperOrigin-RevId: 387675909\nChange-Id: I7396b9b8afc1ac744112af7c0b1cd7bb41e0f556",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 1, 'total': 15}",
            "files":"{'tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc': {'additions': 14, 'deletions': 1, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e0b6e58c328059829c3eb968136f17aa72b6c876\/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fto_tf_record_op.cc', 'patch': '@@ -18,6 +18,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/function_handle_cache.h\"\\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n #include \"tensorflow\/core\/framework\/resource_mgr.h\"\\n+#include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/kernels\/ops_util.h\"\\n #include \"tensorflow\/core\/lib\/core\/threadpool.h\"\\n #include \"tensorflow\/core\/lib\/io\/record_writer.h\"\\n@@ -91,8 +92,20 @@ class ToTFRecordOp : public AsyncOpKernel {\\n     TF_RETURN_IF_ERROR(finalized_dataset->MakeIterator(\\n         &iter_ctx, \/*parent=*\/nullptr, \"ToTFRecordOpIterator\", &iterator));\\n \\n+    const int num_output_dtypes = finalized_dataset->output_dtypes().size();\\n+    if (num_output_dtypes != 1) {\\n+      return errors::InvalidArgument(\\n+          \"ToTFRecordOp currently only support datasets of 1 single column, \",\\n+          \"but got \", num_output_dtypes);\\n+    }\\n+    const DataType dt = finalized_dataset->output_dtypes()[0];\\n+    if (dt != DT_STRING) {\\n+      return errors::InvalidArgument(\\n+          \"ToTFRecordOp currently only supports DT_STRING dataypes, but got \",\\n+          DataTypeString(dt));\\n+    }\\n     std::vector<Tensor> components;\\n-    components.reserve(finalized_dataset->output_dtypes().size());\\n+    components.reserve(num_output_dtypes);\\n     bool end_of_sequence;\\n     do {\\n       TF_RETURN_IF_ERROR('}}",
            "message_norm":"fix segfault\/heap buffer overflow in `{experimental,}datasettotfrecord` where dataset is numeric.\n\ncode assumes only strings inputs and then interprets numbers as valid `tstring`s. then, when trying to compute the crc of the record this results in heap buffer overflow.\n\npiperorigin-revid: 387675909\nchange-id: i7396b9b8afc1ac744112af7c0b1cd7bb41e0f556",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('segfault', 'SECWORD', ''), ('buffer overflow', 'SECWORD', ''), ('crc', 'SECWORD', ''), ('buffer overflow', 'SECWORD', ''), ('387675909', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3273,
            "vuln_id":"GHSA-wg6g-ppvx-927h",
            "cwe_id":"{'CWE-1321'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/ashaffer\/cached-path-relative\/commit\/40c73bf70c58add5aec7d11e4f36b93d144bb760'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in cached-path-relative The package cached-path-relative before 1.1.0 is vulnerable to Prototype Pollution via the cache variable that is set as {} instead of Object.create(null) in the cachedPathRelative function, which allows access to the parent prototype properties when the object is used to create the cached relative path. When using the origin path as __proto__, the attribute of the object is accessed instead of a path. **Note:** This vulnerability derives from an incomplete fix in https:\/\/security.snyk.io\/vuln\/SNYK-JS-CACHEDPATHRELATIVE-72573",
            "published_date":"2022-01-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/ashaffer\/cached-path-relative",
            "commit_href":"https:\/\/github.com\/ashaffer\/cached-path-relative\/commit\/40c73bf70c58add5aec7d11e4f36b93d144bb760",
            "commit_sha":"40c73bf70c58add5aec7d11e4f36b93d144bb760",
            "patch":"SINGLE",
            "chain_ord":"['40c73bf70c58add5aec7d11e4f36b93d144bb760']",
            "before_first_fix_commit":"{'dfc753a020508cf42cde98024c68bf16bed12edc'}",
            "last_fix_commit":"40c73bf70c58add5aec7d11e4f36b93d144bb760",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/19\/2022, 19:12:34",
            "message":"Fix other instances of prototype pollution vulnerability",
            "author":"Andrew",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'lib\/index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ashaffer\/cached-path-relative\/raw\/40c73bf70c58add5aec7d11e4f36b93d144bb760\/lib%2Findex.js', 'patch': '@@ -27,15 +27,15 @@ function cachedPathRelative (from, to) {\\n   \/\/ to invalidate the cache\\n   var cwd = process.cwd()\\n   if (cwd !== lastCwd) {\\n-    cache = {}\\n+    cache = Object.create(null)\\n     lastCwd = cwd\\n   }\\n \\n   if (cache[from] && cache[from][to]) return cache[from][to]\\n \\n   var result = relative.call(path, from, to)\\n \\n-  cache[from] = cache[from] || {}\\n+  cache[from] = cache[from] || Object.create(null)\\n   cache[from][to] = result\\n \\n   return result'}}",
            "message_norm":"fix other instances of prototype pollution vulnerability",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('prototype pollution', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/index.js'])",
            "num_files":1.0
        },
        {
            "index":1321,
            "vuln_id":"GHSA-95hx-62rh-gg96",
            "cwe_id":"{'CWE-79'}",
            "score":8.0,
            "chain":"{'https:\/\/github.com\/PrestaShop\/contactform\/commit\/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09'}",
            "dataset":"osv",
            "summary":"Potential XSS injection In PrestaShop contactform ### Impact\nAn attacker is able to inject javascript while using the contact form. \n\n### Patches\nThe problem is fixed in v4.3.0\n\n### References\n[Cross-site Scripting (XSS) - Stored (CWE-79)](https:\/\/cwe.mitre.org\/data\/definitions\/79.html)",
            "published_date":"2020-09-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/PrestaShop\/contactform",
            "commit_href":"https:\/\/github.com\/PrestaShop\/contactform\/commit\/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
            "commit_sha":"ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
            "patch":"SINGLE",
            "chain_ord":"['ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09']",
            "before_first_fix_commit":"{'a883e56240357b4aaaf594ade573bb596e518078', 'aa3c77923734854bb7168f30db43544e42638202'}",
            "last_fix_commit":"ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/15\/2020, 08:03:00",
            "message":"Merge pull request from GHSA-95hx-62rh-gg96\n\nDo not unescape form message data",
            "author":"GoT",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 8, 'total': 17}",
            "files":"{'contactform.php': {'additions': 9, 'deletions': 8, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/PrestaShop\/contactform\/raw\/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09\/contactform.php', 'patch': \"@@ -317,7 +317,7 @@ public function getWidgetVariables($hookName = null, array $configuration = [])\\n             }\\n         }\\n         $this->contact['contacts'] = $this->getTemplateVarContact();\\n-        $this->contact['message'] = html_entity_decode(Tools::getValue('message'));\\n+        $this->contact['message'] = Tools::getValue('message');\\n         $this->contact['allow_file_upload'] = (bool) Configuration::get('PS_CUSTOMER_SERVICE_FILE_UPLOAD');\\n \\n         if (!(bool)Configuration::isCatalogMode()) {\\n@@ -388,9 +388,10 @@ public function getTemplateVarOrders()\\n     {\\n         $orders = [];\\n \\n-        if (!isset($this->customer_thread['id_order'])\\n+        if (empty($this->customer_thread['id_order'])\\n             && isset($this->context->customer)\\n-            && $this->context->customer->isLogged()) {\\n+            && $this->context->customer->isLogged()\\n+        ) {\\n             $customer_orders = Order::getCustomerOrders($this->context->customer->id);\\n \\n             foreach ($customer_orders as $customer_order) {\\n@@ -401,7 +402,7 @@ public function getTemplateVarOrders()\\n                     $orders[$customer_order['id_order']]['products'] = $myOrder->getProducts();\\n                 }\\n             }\\n-        } elseif (isset($this->customer_thread['id_order']) && (int)$this->customer_thread['id_order'] > 0) {\\n+        } elseif (isset($this->customer_thread['id_order']) && (int) $this->customer_thread['id_order'] > 0) {\\n             $myOrder = new Order($this->customer_thread['id_order']);\\n \\n             if (Validate::isLoadedObject($myOrder)) {\\n@@ -411,13 +412,13 @@ public function getTemplateVarOrders()\\n             }\\n         }\\n \\n-        if (isset($this->customer_thread['id_product'])) {\\n+        if (!empty($this->customer_thread['id_product'])) {\\n             $id_order = isset($this->customer_thread['id_order']) ?\\n-                      (int)$this->customer_thread['id_order'] :\\n+                      (int) $this->customer_thread['id_order'] :\\n                       0;\\n \\n             $orders[$id_order]['products'][(int)$this->customer_thread['id_product']] = $this->context->controller->objectPresenter->present(\\n-                new Product((int)$this->customer_thread['id_product'])\\n+                new Product((int) $this->customer_thread['id_product'])\\n             );\\n         }\\n \\n@@ -586,7 +587,7 @@ public function sendMessage()\\n                     '{lastname}' => '',\\n                     '{order_name}' => '-',\\n                     '{attached_file}' => '-',\\n-                    '{message}' => Tools::nl2br(Tools::stripslashes($message)),\\n+                    '{message}' => Tools::nl2br(Tools::htmlentitiesUTF8(Tools::stripslashes($message))),\\n                     '{email}' =>  $from,\\n                     '{product_name}' => '',\\n                 ];\"}}",
            "message_norm":"merge pull request from ghsa-95hx-62rh-gg96\n\ndo not unescape form message data",
            "language":"fr",
            "entities":"[('ghsa-95hx-62rh-gg96', 'VULNID', 'GHSA'), ('unescape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['contactform.php'])",
            "num_files":1.0
        },
        {
            "index":513,
            "vuln_id":"GHSA-4w97-57v2-3w44",
            "cwe_id":"{'CWE-697'}",
            "score":8.6,
            "chain":"{'https:\/\/github.com\/simpleledger\/slp-validate\/commit\/cde95c0c6470dceb4f023cd462f904135ebd73e7'}",
            "dataset":"osv",
            "summary":"False-negative validation results in MINT transactions with invalid baton ### Impact\nUsers could experience false-negative validation outcomes for [MINT](https:\/\/github.com\/simpleledger\/slp-specifications\/blob\/master\/slp-token-type-1.md#mint---extended-minting-transaction) transaction operations.  A poorly implemented SLP wallet could allow spending of the affected tokens which would result in the destruction of a user's minting baton.\n\n### Patches\nnpm package [slp-validate](https:\/\/www.npmjs.com\/package\/slp-validate) has been patched and published as version 1.2.1.\n\n### Workarounds\nUpgrade to slp-validate 1.2.1.\n\n### References\n* slp-validate [commit](https:\/\/github.com\/simpleledger\/slp-validate\/commit\/cde95c0c6470dceb4f023cd462f904135ebd73e7)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [slp-validate](https:\/\/github.com\/simpleledger\/slp-validate\/issues)",
            "published_date":"2020-05-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/simpleledger\/slp-validate",
            "commit_href":"https:\/\/github.com\/simpleledger\/slp-validate\/commit\/cde95c0c6470dceb4f023cd462f904135ebd73e7",
            "commit_sha":"cde95c0c6470dceb4f023cd462f904135ebd73e7",
            "patch":"SINGLE",
            "chain_ord":"['cde95c0c6470dceb4f023cd462f904135ebd73e7']",
            "before_first_fix_commit":"{'4ca5ea8556bfacdaa6c81f0c3151a23e728cb8b6'}",
            "last_fix_commit":"cde95c0c6470dceb4f023cd462f904135ebd73e7",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/29\/2020, 13:52:56",
            "message":"fix false negative case for MINT transactions\n\nSee the newly added unit test case for this issue.\nCurrently there are 151 unit tests.",
            "author":"James Cramer",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 6, 'total': 16}",
            "files":"{'lib\/validation.ts': {'additions': 10, 'deletions': 6, 'changes': 16, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/simpleledger\/slp-validate.js\/raw\/cde95c0c6470dceb4f023cd462f904135ebd73e7\/lib%2Fvalidation.ts', 'patch': '@@ -408,10 +408,10 @@ export class ValidatorType1 {\\n                     }\\n                 } catch (_) { }\\n             }\\n-            if (validation.parents.length !== 1) {\\n+            if (validation.parents.length < 1) {\\n                 validation.validity = false;\\n                 validation.waiting = false;\\n-                validation.invalidReason = \"MINT transaction must have 1 valid baton parent.\";\\n+                validation.invalidReason = \"MINT transaction must have at least 1 candidate baton parent input.\";\\n                 return validation.validity!;\\n             }\\n         } else if (slpmsg.transactionType === SlpTransactionType.SEND) {\\n@@ -468,10 +468,14 @@ export class ValidatorType1 {\\n         \/\/ Set validity validation-cache for parents, and handle MINT condition with no valid input\\n         \/\/ we don\\'t need to check proper token id since we only added parents with same ID in above steps.\\n         const parentTxids = [...new Set(validation.parents.map(p => p.txid))];\\n-        for (let i = 0; i < parentTxids.length; i++) {\\n-            const valid = await this.isValidSlpTxid({ txid: parentTxids[i] });\\n-            validation.parents.filter(p => p.txid === parentTxids[i]).map(p => p.valid = valid);\\n-            if (validation.details!.transactionType === SlpTransactionType.MINT && !valid) {\\n+        for (const id of parentTxids) {\\n+            const valid = await this.isValidSlpTxid({ txid: id });\\n+            validation.parents.filter(p => p.txid === id).map(p => p.valid = valid);\\n+        }\\n+\\n+        \/\/ Check MINT for exactly 1 valid MINT baton\\n+        if (validation.details!.transactionType === SlpTransactionType.MINT) {\\n+            if (validation.parents.filter(p => p.valid && p.inputQty === null).length !== 1) {\\n                 validation.validity = false;\\n                 validation.waiting = false;\\n                 validation.invalidReason = \"MINT transaction with invalid baton parent.\";'}}",
            "message_norm":"fix false negative case for mint transactions\n\nsee the newly added unit test case for this issue.\ncurrently there are 151 unit tests.",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('added', 'ACTION', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/validation.ts'])",
            "num_files":1.0
        },
        {
            "index":820,
            "vuln_id":"GHSA-6cpj-3g83-q2j4",
            "cwe_id":"{'CWE-611'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/apache\/lucene-solr\/commit\/f230486ce6707762c1a6e81655d0fac52887906d', 'https:\/\/github.com\/apache\/lucene-solr\/commit\/0d21b900975b7048d2e925d852aeacb9bdc6766c'}",
            "dataset":"osv",
            "summary":"Improper Restriction of XML External Entity Reference in Apache Solr The (1) UpdateRequestHandler for XSLT or (2) XPathEntityProcessor in Apache Solr before 4.1 allows remote attackers to have an unspecified impact via XML data containing an external entity declaration in conjunction with an entity reference, related to an XML External Entity (XXE) issue, different vectors than CVE-2013-6407.",
            "published_date":"2022-05-17",
            "chain_len":2,
            "project":"https:\/\/github.com\/apache\/lucene-solr",
            "commit_href":"https:\/\/github.com\/apache\/lucene-solr\/commit\/0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "commit_sha":"0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "patch":"MULTI",
            "chain_ord":"['f230486ce6707762c1a6e81655d0fac52887906d', '0d21b900975b7048d2e925d852aeacb9bdc6766c']",
            "before_first_fix_commit":"{'f230486ce6707762c1a6e81655d0fac52887906d'}",
            "last_fix_commit":"0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "chain_ord_pos":2.0,
            "commit_datetime":"09\/27\/2012, 13:15:24",
            "message":"SOLR-3895, SOLR-3614: Fix javadocs\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991 13f79535-47bb-0310-9956-ffa450edef68",
            "author":"Uwe Schindler",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/lucene-solr\/raw\/0d21b900975b7048d2e925d852aeacb9bdc6766c\/solr%2Fcore%2Fsrc%2Fjava%2Forg%2Fapache%2Fsolr%2Futil%2FEmptyEntityResolver.java', 'patch': '@@ -67,7 +67,7 @@ private static void trySetSAXFeature(SAXParserFactory saxFactory, String feature\\n   }\\n   \\n   \/** Configures the given {@link SAXParserFactory} to do secure XML processing of untrusted sources.\\n-   * It is required to also set {@link #SAX_INSTANCE} on the created {@link XMLReader}.\\n+   * It is required to also set {@link #SAX_INSTANCE} on the created {@link org.xml.sax.XMLReader}.\\n    * @see #SAX_INSTANCE\\n    *\/\\n   public static void configureSAXParserFactory(SAXParserFactory saxFactory) {'}}",
            "message_norm":"solr-3895, solr-3614: fix javadocs\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991 13f79535-47bb-0310-9956-ffa450edef68",
            "language":"sv",
            "entities":"[('fix', 'ACTION', ''), ('https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991', 'URL', ''), ('13f79535', 'SHA', 'generic_sha'), ('ffa450edef68', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java'])",
            "num_files":1.0
        },
        {
            "index":496,
            "vuln_id":"GHSA-4vhw-4rw7-jfpv",
            "cwe_id":"{'CWE-22'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/NilsIrl\/MozWire\/pull\/17\/commits\/dd0639bf2876773b66382f47285f7db701f628d9'}",
            "dataset":"osv",
            "summary":"Path traversal in mozwire An issue was discovered in the mozwire crate through 2020-08-18 for Rust. A ..\/ directory-traversal situation allows overwriting local files that have .conf at the end of the filename.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/NilsIrl\/MozWire",
            "commit_href":"https:\/\/github.com\/NilsIrl\/MozWire\/pull\/17\/commits\/dd0639bf2876773b66382f47285f7db701f628d9",
            "commit_sha":"dd0639bf2876773b66382f47285f7db701f628d9",
            "patch":"SINGLE",
            "chain_ord":"['dd0639bf2876773b66382f47285f7db701f628d9']",
            "before_first_fix_commit":"{'1e58d8ba41268b36232e6830808565850ec65587'}",
            "last_fix_commit":"dd0639bf2876773b66382f47285f7db701f628d9",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/18\/2020, 19:05:11",
            "message":"Validate server hostnames to prevent path traversal\n\nIf Mozilla servers were compromised, hostnames could be used for path\ntraversal attacks. The impact would be very low as it would only be\npossible to write wireguard configs.\n\nFix #14",
            "author":"Nils",
            "comments":null,
            "stats":"{'additions': 23, 'deletions': 2, 'total': 25}",
            "files":"{'src\/main.rs': {'additions': 23, 'deletions': 2, 'changes': 25, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NilsIrl\/MozWire\/raw\/dd0639bf2876773b66382f47285f7db701f628d9\/src%2Fmain.rs', 'patch': '@@ -106,6 +106,14 @@ struct Server {\\n     port_ranges: Vec<(u16, u16)>,\\n }\\n \\n+impl Server {\\n+    fn validate_hostname(&self) -> bool {\\n+        self.hostname\\n+            .chars()\\n+            .all(|c| c.is_ascii_alphanumeric() || c == \\'-\\')\\n+    }\\n+}\\n+\\n \/\/ latitude and longitude omitted\\n #[derive(serde::Deserialize)]\\n struct City {\\n@@ -130,13 +138,26 @@ struct ServerList {\\n \\n impl ServerList {\\n     fn new(client: reqwest::blocking::Client, token: &str) -> Self {\\n-        client\\n+        let server_list = client\\n             .get(&format!(\"{}\/vpn\/servers\", BASE_URL))\\n             .bearer_auth(token)\\n             .send()\\n             .unwrap()\\n             .json::<ServerList>()\\n-            .unwrap()\\n+            .unwrap();\\n+        if let Some(server) = server_list\\n+            .countries\\n+            .iter()\\n+            .flat_map(|country| country.cities.iter().flat_map(|city| city.servers.iter()))\\n+            .find(|server| !server.validate_hostname())\\n+        {\\n+            eprintln!(\\n+                \"A server contains invalid characters in its hostname: {}\",\\n+                server.hostname\\n+            );\\n+            std::process::exit(3);\\n+        }\\n+        server_list\\n     }\\n }'}}",
            "message_norm":"validate server hostnames to prevent path traversal\n\nif mozilla servers were compromised, hostnames could be used for path\ntraversal attacks. the impact would be very low as it would only be\npossible to write wireguard configs.\n\nfix #14",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('server', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('path traversal', 'SECWORD', ''), ('servers', 'SECWORD', ''), ('attacks', 'SECWORD', ''), ('low', 'SEVERITY', ''), ('fix', 'ACTION', ''), ('#14', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main.rs'])",
            "num_files":1.0
        },
        {
            "index":1322,
            "vuln_id":"GHSA-95xm-g58g-3p88",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4923de56ec94fff7770df259ab7f2288a74feb41'}",
            "dataset":"osv",
            "summary":"Integer division by 0 in sparse reshaping ### Impact\nThe implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.SparseReshape(\n  input_indices = np.ones((1,3)),\n  input_shape = np.array([1,1,0]),\n  new_shape = np.array([1,0]))\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements.\n\nThe [reshape functor](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0.\n  \n### Patches\nWe have patched the issue in GitHub commit [4923de56ec94fff7770df259ab7f2288a74feb41](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4923de56ec94fff7770df259ab7f2288a74feb41).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4923de56ec94fff7770df259ab7f2288a74feb41",
            "commit_sha":"4923de56ec94fff7770df259ab7f2288a74feb41",
            "patch":"SINGLE",
            "chain_ord":"['4923de56ec94fff7770df259ab7f2288a74feb41']",
            "before_first_fix_commit":"{'062534a0e7af9a49e96bc5797851be0e57cad1d6'}",
            "last_fix_commit":"4923de56ec94fff7770df259ab7f2288a74feb41",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2021, 20:52:28",
            "message":"Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232a",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/reshape_util.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/4923de56ec94fff7770df259ab7f2288a74feb41\/tensorflow%2Fcore%2Fkernels%2Freshape_util.cc', 'patch': '@@ -174,6 +174,12 @@ void ReshapeSparseTensor(OpKernelContext *context,\\n                                           TensorShape({nnz, output_rank}),\\n                                           &result_indices));\\n   if (nnz > 0) {\\n+    OP_REQUIRES(\\n+        context, dense_size > 0 && product > 0,\\n+        errors::InvalidArgument(\\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\\n+            input_shape.DebugString(), \") or output shape (\",\\n+            output_shape.DebugString(), \") is empty\"));\\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\\n                                 context, input_shape, output_shape,\\n                                 input_indices_in.matrix<int64>(),'}}",
            "message_norm":"don't do any work when reshaping 0 elements sparse tensor.\n\nif reshaping to 0 elements tensor, check that input has no elements.\nif reshaping no elements input, check that output has no elements.\n\npiperorigin-revid: 388296986\nchange-id: iadc9fe7252e14313ca987e69bf0d7042fd10232a",
            "language":"en",
            "entities":"[('388296986', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/reshape_util.cc'])",
            "num_files":1.0
        },
        {
            "index":1978,
            "vuln_id":"GHSA-h3vq-wv8j-36gw",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/LLK\/scratch-svg-renderer\/commit\/7c74ec7de3254143ec3c557677f5355a90a3d07f'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Scratch-Svg-Renderer A DOM-based cross-site scripting (XSS) vulnerability in Scratch-Svg-Renderer v0.2.0 allows attackers to execute arbitrary web scripts or HTML via a crafted sb3 file.",
            "published_date":"2022-01-08",
            "chain_len":1,
            "project":"https:\/\/github.com\/LLK\/scratch-svg-renderer",
            "commit_href":"https:\/\/github.com\/LLK\/scratch-svg-renderer\/commit\/7c74ec7de3254143ec3c557677f5355a90a3d07f",
            "commit_sha":"7c74ec7de3254143ec3c557677f5355a90a3d07f",
            "patch":"SINGLE",
            "chain_ord":"['7c74ec7de3254143ec3c557677f5355a90a3d07f']",
            "before_first_fix_commit":"{'d010f2d0edc3ab87ecabb27b9160f91317aa2722'}",
            "last_fix_commit":"7c74ec7de3254143ec3c557677f5355a90a3d07f",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/09\/2020, 19:50:27",
            "message":"Remove lots of event handlers",
            "author":"Eric Rosenbaum",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 2, 'total': 17}",
            "files":"{'src\/fixup-svg-string.js': {'additions': 15, 'deletions': 2, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/LLK\/scratch-svg-renderer\/raw\/7c74ec7de3254143ec3c557677f5355a90a3d07f\/src%2Ffixup-svg-string.js', 'patch': '@@ -50,8 +50,21 @@ module.exports = function (svgString) {\\n     \/\/ Empty script tags and javascript executing\\n     svgString = svgString.replace(\/<script[\\\\s\\\\S]*>[\\\\s\\\\S]*<\\\\\/script>\/, \\'<script><\/script>\\');\\n     \\n-    \/\/ Remove error handlers\\n-    svgString = svgString.replace(\/onerror=[\\\\s\\\\S]*[\\'\"].*?[\\'\"]\/i, \\'\\');\\n+    \/\/ Remove event handlers\\n+    const eventNames = [\\n+        \\'onbegin\\', \\'onend\\', \\'onrepeat\\', \\'onabort\\', \\'onerror\\', \\'onresize\\', \\'onscroll\\', \\'onunload\\', \\'oncopy\\',\\n+        \\'oncut\\', \\'onpaste\\', \\'oncancel\\', \\'oncanplay\\', \\'oncanplaythrough\\', \\'onchange\\', \\'onclick\\', \\'onclose\\',\\n+        \\'oncuechange\\', \\'ondblclick\\', \\'ondrag\\', \\'ondragend\\', \\'ondragenter\\', \\'ondragexit\\', \\'ondragleave\\',\\n+        \\'ondragover\\', \\'ondragstart\\', \\'ondrop\\', \\'ondurationchange\\', \\'onloadeddata\\', \\'onloadedmetadata\\',\\n+        \\'onloadstart\\', \\'onmousedown\\', \\'onmouseenter\\', \\'onmouseleave\\', \\'onmousemove\\',\\n+        \\'onemptied\\', \\'onended\\', \\'onerror\\', \\'onfocus\\', \\'oninput\\', \\'oninvalid\\', \\'onkeydown\\', \\'onkeypress\\',\\n+        \\'onkeyup\\', \\'onload\\', \\'onmouseout\\', \\'onmouseover\\', \\'onmouseup\\', \\'onmousewheel\\', \\'onpause\\', \\'onplay\\',\\n+        \\'onplaying\\', \\'onprogress\\', \\'onratechange\\', \\'onreset\\', \\'onresize\\', \\'onscroll\\', \\'onseeked\\', \\'onseeking\\',\\n+        \\'onselect\\', \\'onshow\\', \\'onstalled\\', \\'onsubmit\\', \\'onsuspend\\', \\'ontimeupdate\\', \\'ontoggle\\', \\'onvolumechange\\',\\n+        \\'onwaiting\\', \\'onactivate\\', \\'onfocusin\\', \\'onfocusout\\'\\n+    ];\\n+    const eventsRegex = new RegExp(`(${eventNames.join(\\'|\\')})\\\\\\\\s*=\\\\\\\\s*[\\'\"].*[\\'\"]`, \\'i\\');\\n+    svgString = svgString.replace(eventsRegex, \\'\\');\\n \\n     return svgString;\\n };'}}",
            "message_norm":"remove lots of event handlers",
            "language":"en",
            "entities":"[('remove', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/fixup-svg-string.js'])",
            "num_files":1.0
        },
        {
            "index":1274,
            "vuln_id":"GHSA-8wf2-3ggj-78q9",
            "cwe_id":"{'CWE-287'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/phpmyadmin\/phpmyadmin\/commit\/ca54f1db050859eb8555875c6aa5d7796fdf4b32'}",
            "dataset":"osv",
            "summary":"Improper Authentication in phpmyadmin An issue was discovered in phpMyAdmin 4.9 before 4.9.8 and 5.1 before 5.1.2. A valid user who is already authenticated to phpMyAdmin can manipulate their account to bypass two-factor authentication for future login instances.",
            "published_date":"2022-01-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/phpmyadmin\/phpmyadmin",
            "commit_href":"https:\/\/github.com\/phpmyadmin\/phpmyadmin\/commit\/ca54f1db050859eb8555875c6aa5d7796fdf4b32",
            "commit_sha":"ca54f1db050859eb8555875c6aa5d7796fdf4b32",
            "patch":"SINGLE",
            "chain_ord":"['ca54f1db050859eb8555875c6aa5d7796fdf4b32']",
            "before_first_fix_commit":"{'ae11d5260b4bde42100c8696218a2bfd11a2d740'}",
            "last_fix_commit":"ca54f1db050859eb8555875c6aa5d7796fdf4b32",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/13\/2022, 01:59:41",
            "message":"security - Fix - 2FA\/U2F can be disabled without any code change\n\nSigned-off-by: William Desportes <williamdes@wdes.fr>",
            "author":"William Desportes",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 11, 'total': 27}",
            "files":"{'libraries\/classes\/DatabaseInterface.php': {'additions': 16, 'deletions': 11, 'changes': 27, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/phpmyadmin\/phpmyadmin\/raw\/ca54f1db050859eb8555875c6aa5d7796fdf4b32\/libraries%2Fclasses%2FDatabaseInterface.php', 'patch': '@@ -1563,17 +1563,22 @@ public function setCollation($collation)\\n      *\/\\n     public function initRelationParamsCache()\\n     {\\n-        if (strlen($GLOBALS[\\'db\\'])) {\\n-            $cfgRelation = $this->relation->getRelationsParam();\\n-            if (empty($cfgRelation[\\'db\\'])) {\\n-                $this->relation->fixPmaTables($GLOBALS[\\'db\\'], false);\\n-            }\\n-        }\\n-        $cfgRelation = $this->relation->getRelationsParam();\\n-        if (empty($cfgRelation[\\'db\\']) && isset($GLOBALS[\\'dblist\\'])) {\\n-            if ($GLOBALS[\\'dblist\\']->databases->exists(\\'phpmyadmin\\')) {\\n-                $this->relation->fixPmaTables(\\'phpmyadmin\\', false);\\n-            }\\n+        $storageDbName = $GLOBALS[\\'cfg\\'][\\'Server\\'][\\'pmadb\\'] ?? \\'\\';\\n+        \/\/ Use \"phpmyadmin\" as a default database name to check to keep the behavior consistent\\n+        $storageDbName = $storageDbName !== null\\n+                            && is_string($storageDbName)\\n+                            && $storageDbName !== \\'\\' ? $storageDbName : \\'phpmyadmin\\';\\n+\\n+        \/\/ This will make users not having explicitly listed databases\\n+        \/\/ have config values filled by the default phpMyAdmin storage table name values\\n+        $this->relation->fixPmaTables($storageDbName, false);\\n+\\n+        \/\/ This global will be changed if fixPmaTables did find one valid table\\n+        $storageDbName = $GLOBALS[\\'cfg\\'][\\'Server\\'][\\'pmadb\\'] ?? \\'\\';\\n+\\n+        \/\/ Empty means that until now no pmadb was found eligible\\n+        if (empty($storageDbName)) {\\n+            $this->relation->fixPmaTables($GLOBALS[\\'db\\'], false);\\n         }\\n     }'}}",
            "message_norm":"security - fix - 2fa\/u2f can be disabled without any code change\n\nsigned-off-by: william desportes <williamdes@wdes.fr>",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('williamdes@wdes.fr', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['libraries\/classes\/DatabaseInterface.php'])",
            "num_files":1.0
        },
        {
            "index":2901,
            "vuln_id":"GHSA-r8j4-96mx-rjcc",
            "cwe_id":"{'CWE-611'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/skylot\/jadx\/commit\/d22db30166e7cb369d72be41382bb63ac8b81c52'}",
            "dataset":"osv",
            "summary":"Improper Restriction of XML External Entity Reference in skylot\/jadx skylot\/jadx prior to 1.3.2 is vulnerable to Improper Restriction of XML External Entities when a user is tricked into exporting a malicious APK file (via the -e option) containing a crafted AndroidManifest.xml \/ strings.xml to gradle, leading to possible local file disclosure.",
            "published_date":"2022-01-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/skylot\/jadx",
            "commit_href":"https:\/\/github.com\/skylot\/jadx\/commit\/d22db30166e7cb369d72be41382bb63ac8b81c52",
            "commit_sha":"d22db30166e7cb369d72be41382bb63ac8b81c52",
            "patch":"SINGLE",
            "chain_ord":"['d22db30166e7cb369d72be41382bb63ac8b81c52']",
            "before_first_fix_commit":"{'6db61e7a5908db0138a3a15d42c0a46ae787c72c'}",
            "last_fix_commit":"d22db30166e7cb369d72be41382bb63ac8b81c52",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/20\/2022, 11:17:12",
            "message":"fix: use secure xml parser for process manifest",
            "author":"Skylot",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'jadx-core\/src\/main\/java\/jadx\/core\/export\/ExportGradleProject.java': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/skylot\/jadx\/raw\/d22db30166e7cb369d72be41382bb63ac8b81c52\/jadx-core%2Fsrc%2Fmain%2Fjava%2Fjadx%2Fcore%2Fexport%2FExportGradleProject.java', 'patch': '@@ -8,7 +8,6 @@\\n import java.util.Set;\\n \\n import javax.xml.parsers.DocumentBuilder;\\n-import javax.xml.parsers.DocumentBuilderFactory;\\n \\n import org.slf4j.Logger;\\n import org.slf4j.LoggerFactory;\\n@@ -24,6 +23,7 @@\\n import jadx.core.utils.exceptions.JadxRuntimeException;\\n import jadx.core.utils.files.FileUtils;\\n import jadx.core.xmlgen.ResContainer;\\n+import jadx.core.xmlgen.XmlSecurity;\\n \\n public class ExportGradleProject {\\n \\n@@ -139,7 +139,7 @@ private ApplicationParams getApplicationParams(Document androidManifest, Documen\\n \\n \\tprivate Document parseXml(String xmlContent) {\\n \\t\\ttry {\\n-\\t\\t\\tDocumentBuilder builder = DocumentBuilderFactory.newInstance().newDocumentBuilder();\\n+\\t\\t\\tDocumentBuilder builder = XmlSecurity.getSecureDbf().newDocumentBuilder();\\n \\t\\t\\tDocument document = builder.parse(new InputSource(new StringReader(xmlContent)));\\n \\n \\t\\t\\tdocument.getDocumentElement().normalize();'}}",
            "message_norm":"fix: use secure xml parser for process manifest",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('secure', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['jadx-core\/src\/main\/java\/jadx\/core\/export\/ExportGradleProject.java'])",
            "num_files":1.0
        },
        {
            "index":1109,
            "vuln_id":"GHSA-8278-88vv-x98r",
            "cwe_id":"{'CWE-502'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/tenable\/integration-jira-cloud\/commit\/f8c2095fd529e664e7fa25403a0a4a85bb3907d0'}",
            "dataset":"osv",
            "summary":"Execution of untrusted code through config file ### Impact\nIt is possible to run arbitrary commands through the yaml.load() method.  This could allow an attacker with local access to the host to run arbitrary code by running the application with a specially crafted YAML configuration file.\n\n### Workarounds\nManually adjust yaml.load() to yaml.safe_load()\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [tenable\/integration-jira-cloud](https:\/\/github.com\/tenable\/integration-jira-cloud\/issues)\n* Email us at [vulnreport@tenable.com](mailto:vulnreport@tenable.com)",
            "published_date":"2021-03-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tenable\/integration-jira-cloud",
            "commit_href":"https:\/\/github.com\/tenable\/integration-jira-cloud\/commit\/f8c2095fd529e664e7fa25403a0a4a85bb3907d0",
            "commit_sha":"f8c2095fd529e664e7fa25403a0a4a85bb3907d0",
            "patch":"SINGLE",
            "chain_ord":"['f8c2095fd529e664e7fa25403a0a4a85bb3907d0']",
            "before_first_fix_commit":"{'fa838db45f1ae5581a47e1965f74919c12488cf5'}",
            "last_fix_commit":"f8c2095fd529e664e7fa25403a0a4a85bb3907d0",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/04\/2021, 14:58:38",
            "message":"switched yaml.load() to yaml.safe_load() to not load serialized python objects.",
            "author":"Steve McGrath",
            "comments":"{'com_1': {'author': 'rabby28698869', 'datetime': '03\/11\/2021, 03:07:50', 'body': 'f8c2095'}, 'com_2': {'author': 'SteveMcGrath', 'datetime': '03\/11\/2021, 15:23:59', 'body': '?'}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'tenable_jira\/cli.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tenable\/integration-jira-cloud\/raw\/f8c2095fd529e664e7fa25403a0a4a85bb3907d0\/tenable_jira%2Fcli.py', 'patch': \"@@ -62,7 +62,7 @@ def cli(configfile, observed_since, setup_only=False, troubleshoot=False):\\n     '''\\n     # Load the config, but ensure that any additional fields are additive to the\\n     # basic field set.\\n-    config_from_file = yaml.load(configfile, Loader=yaml.Loader)\\n+    config_from_file = yaml.safe_load(configfile)\\n     fields = config_from_file.pop('custom_fields', list())\\n     config = dict_merge(base_config(), config_from_file)\\n     config['fields'] = config['fields'] + fields\"}}",
            "message_norm":"switched yaml.load() to yaml.safe_load() to not load serialized python objects.",
            "language":"en",
            "entities":"[('serialized', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tenable_jira\/cli.py'])",
            "num_files":1.0
        },
        {
            "index":2945,
            "vuln_id":"GHSA-rgvq-pcvf-hx75",
            "cwe_id":"{'CWE-131'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f94ef358bb3e91d517446454edff6535bcfe8e4a', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c4d7afb6a5986b04505aca4466ae1951686c80f6', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b761c9b652af2107cfbc33efd19be0ce41daa33e'}",
            "dataset":"osv",
            "summary":"Heap OOB and null pointer dereference in `RaggedTensorToTensor` ### Impact\nDue to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty:\n\n```python\nimport tensorflow as tf\n\nshape = tf.constant([-1, -1], shape=[2], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\ndefault_value = tf.constant(404, dtype=tf.int64)\nrow = tf.constant([269, 404, 0, 0, 0, 0, 0], shape=[7], dtype=tf.int64)\nrows = [row]\ntypes = ['ROW_SPLITS']\n\ntf.raw_ops.RaggedTensorToTensor(\n  shape=shape, values=values, default_value=default_value, \n  row_partition_tensors=rows, row_partition_types=types)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/656e7673b14acd7835dc778867f84916c6d1cac2\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones.\n\nThere are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything.\n\n### Patches\nWe have patched the issue in GitHub commit [b761c9b652af2107cfbc33efd19be0ce41daa33e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b761c9b652af2107cfbc33efd19be0ce41daa33e) followed by GitHub commit [f94ef358bb3e91d517446454edff6535bcfe8e4a](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f94ef358bb3e91d517446454edff6535bcfe8e4a) and GitHub commit [c4d7afb6a5986b04505aca4466ae1951686c80f6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c4d7afb6a5986b04505aca4466ae1951686c80f6).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":3,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c4d7afb6a5986b04505aca4466ae1951686c80f6",
            "commit_sha":"c4d7afb6a5986b04505aca4466ae1951686c80f6",
            "patch":"MULTI",
            "chain_ord":"['f94ef358bb3e91d517446454edff6535bcfe8e4a', 'b761c9b652af2107cfbc33efd19be0ce41daa33e', 'c4d7afb6a5986b04505aca4466ae1951686c80f6']",
            "before_first_fix_commit":"{'50034ad2d55b10eb9d4593374546710b12f134e1'}",
            "last_fix_commit":"c4d7afb6a5986b04505aca4466ae1951686c80f6",
            "chain_ord_pos":3.0,
            "commit_datetime":"05\/11\/2021, 22:22:49",
            "message":"Fix heap OOB \/ undefined behavior in `RaggedTensorToTensor`\n\nPiperOrigin-RevId: 373244623\nChange-Id: I2d6cbbc8c67b238a8815bf58097f7586d87c54f2",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 35, 'deletions': 20, 'total': 55}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc': {'additions': 35, 'deletions': 20, 'changes': 55, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c4d7afb6a5986b04505aca4466ae1951686c80f6\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_tensor_op.cc', 'patch': '@@ -207,8 +207,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n     DCHECK_EQ(result->size(), first_dimension);\\n   }\\n \\n-  void CalculateOutputIndexRowSplit(\\n-      OpKernelContext* context, const RowPartitionTensor& row_split,\\n+  Status CalculateOutputIndexRowSplit(\\n+      const RowPartitionTensor& row_split,\\n       const vector<INDEX_TYPE>& parent_output_index,\\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\\n       vector<INDEX_TYPE>* result) {\\n@@ -232,10 +232,11 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n         result->push_back(-1);\\n       }\\n     }\\n-    if (row_split_size > 0) {\\n-      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\\n-                  errors::InvalidArgument(\"Invalid row split size.\"));\\n+    if (row_split_size > 0 && result->size() != row_split(row_split_size - 1)) {\\n+      return errors::InvalidArgument(\"Invalid row split size.\");\\n     }\\n+\\n+    return Status::OK();\\n   }\\n \\n   \/\/ Calculate the output index of the first element of a list.\\n@@ -259,20 +260,26 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n   \/\/ result[6] = -1 because parent_output_index[value_rowids[6]] == -1\\n   \/\/ result[7] = -1 because parent_output_index[value_rowids[6]] == -1\\n   \/\/ result[8] = parent_output_index[value_rowids[7]]\\n-  void CalculateOutputIndexValueRowID(\\n-      OpKernelContext* context, const RowPartitionTensor& value_rowids,\\n+  Status CalculateOutputIndexValueRowID(\\n+      const RowPartitionTensor& value_rowids,\\n       const vector<INDEX_TYPE>& parent_output_index,\\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\\n       vector<INDEX_TYPE>* result) {\\n     const INDEX_TYPE index_size = value_rowids.size();\\n     result->reserve(index_size);\\n     if (index_size == 0) {\\n-      return;\\n+      return Status::OK();\\n     }\\n \\n     INDEX_TYPE current_output_column = 0;\\n     INDEX_TYPE current_value_rowid = value_rowids(0);\\n-    DCHECK_LT(current_value_rowid, parent_output_index.size());\\n+\\n+    if (current_value_rowid >= parent_output_index.size()) {\\n+      return errors::InvalidArgument(\\n+          \"Got current_value_rowid=\", current_value_rowid,\\n+          \" which is not less than \", parent_output_index.size());\\n+    }\\n+\\n     INDEX_TYPE current_output_index = parent_output_index[current_value_rowid];\\n     result->push_back(current_output_index);\\n     for (INDEX_TYPE i = 1; i < index_size; ++i) {\\n@@ -289,13 +296,23 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n       } else {\\n         current_output_column = 0;\\n         current_value_rowid = next_value_rowid;\\n-        DCHECK_LT(next_value_rowid, parent_output_index.size());\\n+\\n+        if (next_value_rowid >= parent_output_index.size()) {\\n+          return errors::InvalidArgument(\\n+              \"Got next_value_rowid=\", next_value_rowid,\\n+              \" which is not less than \", parent_output_index.size());\\n+        }\\n+\\n         current_output_index = parent_output_index[next_value_rowid];\\n       }\\n       result->push_back(current_output_index);\\n     }\\n-    OP_REQUIRES(context, result->size() == value_rowids.size(),\\n-                errors::InvalidArgument(\"Invalid row ids.\"));\\n+\\n+    if (result->size() != value_rowids.size()) {\\n+      return errors::InvalidArgument(\"Invalid row ids.\");\\n+    }\\n+\\n+    return Status::OK();\\n   }\\n \\n   Status CalculateOutputIndex(OpKernelContext* context, int dimension,\\n@@ -308,21 +325,19 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n     auto partition_type = GetRowPartitionTypeByDimension(dimension);\\n     switch (partition_type) {\\n       case RowPartitionType::VALUE_ROWIDS:\\n-        CalculateOutputIndexValueRowID(\\n-            context, row_partition_tensor, parent_output_index,\\n-            output_index_multiplier, output_size, result);\\n-        return tensorflow::Status::OK();\\n+        return CalculateOutputIndexValueRowID(\\n+            row_partition_tensor, parent_output_index, output_index_multiplier,\\n+            output_size, result);\\n       case RowPartitionType::ROW_SPLITS:\\n         if (row_partition_tensor.size() - 1 > parent_output_index.size()) {\\n           return errors::InvalidArgument(\\n               \"Row partition size is greater than output size: \",\\n               row_partition_tensor.size() - 1, \" > \",\\n               parent_output_index.size());\\n         }\\n-        CalculateOutputIndexRowSplit(\\n-            context, row_partition_tensor, parent_output_index,\\n-            output_index_multiplier, output_size, result);\\n-        return tensorflow::Status::OK();\\n+        return CalculateOutputIndexRowSplit(\\n+            row_partition_tensor, parent_output_index, output_index_multiplier,\\n+            output_size, result);\\n       default:\\n         return errors::InvalidArgument(\\n             \"Unsupported partition type:\",'}}",
            "message_norm":"fix heap oob \/ undefined behavior in `raggedtensortotensor`\n\npiperorigin-revid: 373244623\nchange-id: i2d6cbbc8c67b238a8815bf58097f7586d87c54f2",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('373244623', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc'])",
            "num_files":1.0
        },
        {
            "index":1630,
            "vuln_id":"GHSA-cwv3-863g-39vx",
            "cwe_id":"{'CWE-835', 'CWE-674'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c6173f5fe66cdbab74f4f869311fe6aae2ba35f4', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c1dc920d8ffb4893d6c9d27d1f039607b326743'}",
            "dataset":"osv",
            "summary":"Stack overflow due to looping TFLite subgraph ### Impact\nTFlite graphs must not have loops between nodes. However, this condition was not checked and an attacker could craft models that would result in infinite loop during evaluation. In certain cases, the infinite loop would be replaced by stack overflow due to too many recursive calls.\n\nFor example, the [`While` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/106d8f4fb89335a2c52d7c895b7a7485465ca8d9\/tensorflow\/lite\/kernels\/while.cc) could be tricked into a scneario where both the body and the loop subgraphs are the same. Evaluating one of the subgraphs means calling the `Eval` function for the other and this quickly exhaust all stack space.\n    \n### Patches \nWe have patched the issue in GitHub commit [9c1dc920d8ffb4893d6c9d27d1f039607b326743](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c1dc920d8ffb4893d6c9d27d1f039607b326743) (for the `While` operator) and in GitHub commit [c6173f5fe66cdbab74f4f869311fe6aae2ba35f4](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c6173f5fe66cdbab74f4f869311fe6aae2ba35f4) (in general).\n    \nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c1dc920d8ffb4893d6c9d27d1f039607b326743",
            "commit_sha":"9c1dc920d8ffb4893d6c9d27d1f039607b326743",
            "patch":"MULTI",
            "chain_ord":"['9c1dc920d8ffb4893d6c9d27d1f039607b326743', 'c6173f5fe66cdbab74f4f869311fe6aae2ba35f4']",
            "before_first_fix_commit":"{'46b80bd2a8943d5976dc83bd5c0322c0023255a7'}",
            "last_fix_commit":"c6173f5fe66cdbab74f4f869311fe6aae2ba35f4",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 00:47:46",
            "message":"Prevent infinite loop\/stack overflow in TFLite `while` op.\n\nPiperOrigin-RevId: 370800333\nChange-Id: I6a2e4ff849da339545c449db2af7e11ce6ff02c3",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/lite\/kernels\/while.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/9c1dc920d8ffb4893d6c9d27d1f039607b326743\/tensorflow%2Flite%2Fkernels%2Fwhile.cc', 'patch': '@@ -138,6 +138,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   auto* subgraphs = this_subgraph->GetSubgraphs();\\n   TF_LITE_ENSURE(context, op_data->cond_subgraph_index < subgraphs->size());\\n   TF_LITE_ENSURE(context, op_data->body_subgraph_index < subgraphs->size());\\n+  TF_LITE_ENSURE(context,\\n+                 op_data->cond_subgraph_index != op_data->body_subgraph_index);\\n \\n   Subgraph* cond_subgraph = (*subgraphs)[op_data->cond_subgraph_index].get();\\n   Subgraph* body_subgraph = (*subgraphs)[op_data->body_subgraph_index].get();'}}",
            "message_norm":"prevent infinite loop\/stack overflow in tflite `while` op.\n\npiperorigin-revid: 370800333\nchange-id: i6a2e4ff849da339545c449db2af7e11ce6ff02c3",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('infinite loop', 'SECWORD', ''), ('overflow', 'SECWORD', ''), ('370800333', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/while.cc'])",
            "num_files":1.0
        },
        {
            "index":806,
            "vuln_id":"GHSA-69q2-p9xp-739v",
            "cwe_id":"{'CWE-91'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/petl-developers\/petl\/pull\/527\/commits\/1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8'}",
            "dataset":"osv",
            "summary":"XML Injection in petl petl before 1.68, in some configurations, allows resolution of entities in an XML document.",
            "published_date":"2021-04-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/petl-developers\/petl",
            "commit_href":"https:\/\/github.com\/petl-developers\/petl\/pull\/527\/commits\/1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8",
            "commit_sha":"1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8",
            "patch":"SINGLE",
            "chain_ord":"['1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8']",
            "before_first_fix_commit":"{'364c3e5d0263a99dffebcd9df70b17bce57b3b06'}",
            "last_fix_commit":"1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/05\/2020, 22:42:56",
            "message":"allow using a custom\/restricted xml parser",
            "author":"Juarez Rudsatz",
            "comments":null,
            "stats":"{'additions': 20, 'deletions': 2, 'total': 22}",
            "files":"{'petl\/io\/xml.py': {'additions': 20, 'deletions': 2, 'changes': 22, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/petl-developers\/petl\/raw\/1b0a09f08c3cdfe2e69647bd02f97c1367a5b5f8\/petl%2Fio%2Fxml.py', 'patch': '@@ -133,6 +133,9 @@ def fromxml(source, *args, **kwargs):\\n     or list of paths can be provided, e.g.,\\n     ``fromxml(\\'example.html\\', \\'.\/\/tr\\', (\\'th\\', \\'td\\'))``.\\n \\n+    Optionally a custom parser can be provided, e.g.,\\n+    ``etl.fromxml(\\'example1.xml\\', \\'tr\\', \\'td\\', parser=my_parser)``.\\n+\\n     \"\"\"\\n \\n     source = read_source_from_arg(source)\\n@@ -162,14 +165,15 @@ def __init__(self, source, *args, **kwargs):\\n         else:\\n             assert False, \\'bad parameters\\'\\n         self.missing = kwargs.get(\\'missing\\', None)\\n+        self.user_parser = kwargs.get(\\'parser\\', None)\\n \\n     def __iter__(self):\\n         vmatch = self.vmatch\\n         vdict = self.vdict\\n \\n         with self.source.open(\\'rb\\') as xmlf:\\n-\\n-            tree = etree.parse(xmlf)\\n+            parser2 = _create_xml_parser(self.user_parser)\\n+            tree = etree.parse(xmlf, parser=parser2)\\n             if not hasattr(tree, \\'iterfind\\'):\\n                 # Python 2.6 compatibility\\n                 tree.iterfind = tree.findall\\n@@ -219,6 +223,20 @@ def __iter__(self):\\n                                 for f in flds)\\n \\n \\n+def _create_xml_parser(user_parser):\\n+    if user_parser is not None:\\n+        return user_parser\\n+    try:\\n+        # Default lxml parser.\\n+        # This will throw an error if parser is not set and lxml could not be imported\\n+        # because Python\\'s built XML parser doesn\\'t like the `resolve_entities` kwarg.\\n+        # return etree.XMLParser(resolve_entities=False)\\n+        return etree.XMLParser(resolve_entities=False)\\n+    except TypeError:\\n+        # lxml not available\\n+        return None\\n+\\n+\\n def element_text_getter(missing):\\n     def _get(v):\\n         if len(v) > 1:'}}",
            "message_norm":"allow using a custom\/restricted xml parser",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['petl\/io\/xml.py'])",
            "num_files":1.0
        },
        {
            "index":1354,
            "vuln_id":"GHSA-9c78-vcq7-7vxq",
            "cwe_id":"{'CWE-787'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6c0b2b70eeee588591680f5b7d5d38175fd7cdf6'}",
            "dataset":"osv",
            "summary":"Out of bounds write in TFLite ### Impact \nAn attacker can craft a TFLite model that would cause a write outside of bounds of an array in TFLite. In fact, the attacker can override the linked list used by the memory allocator. This can be leveraged for an arbitrary write primitive under certain conditions.\n\n### Patches\nWe have patched the issue in GitHub commit [6c0b2b70eeee588591680f5b7d5d38175fd7cdf6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6c0b2b70eeee588591680f5b7d5d38175fd7cdf6).\n  \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n    \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6c0b2b70eeee588591680f5b7d5d38175fd7cdf6",
            "commit_sha":"6c0b2b70eeee588591680f5b7d5d38175fd7cdf6",
            "patch":"SINGLE",
            "chain_ord":"['6c0b2b70eeee588591680f5b7d5d38175fd7cdf6']",
            "before_first_fix_commit":"{'1de49725a5fc4e48f1a3b902ec3599ee99283043'}",
            "last_fix_commit":"6c0b2b70eeee588591680f5b7d5d38175fd7cdf6",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/21\/2021, 16:50:37",
            "message":"[lite] add validation check for sparse fully connected\n\nPiperOrigin-RevId: 417629354\nChange-Id: If96171c4bd4f5fdb01d6368d6deab19d1c9beca7",
            "author":"Karim Nosir",
            "comments":null,
            "stats":"{'additions': 48, 'deletions': 10, 'total': 58}",
            "files":"{'tensorflow\/lite\/kernels\/fully_connected.cc': {'additions': 48, 'deletions': 10, 'changes': 58, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6c0b2b70eeee588591680f5b7d5d38175fd7cdf6\/tensorflow%2Flite%2Fkernels%2Ffully_connected.cc', 'patch': '@@ -928,6 +928,36 @@ TfLiteStatus EvalShuffledQuantized(TfLiteContext* context, TfLiteNode* node,\\n   return kTfLiteOk;\\n }\\n \\n+\/\/ Verifies that sparsity values are valid given input\/weight\/output.\\n+bool VerifySparsity(const RuntimeShape& weights_shape,\\n+                    const RuntimeShape& input_shape,\\n+                    const RuntimeShape& output_shape,\\n+                    const TfLiteSparsity* sparsity) {\\n+  const int weights_dims_count = weights_shape.DimensionsCount();\\n+  const int output_dims_count = output_shape.DimensionsCount();\\n+  const int w0_size = sparsity->dim_metadata[0].dense_size;\\n+  const int accum_depth = weights_shape.Dims(weights_dims_count - 1);\\n+  const int output_elements = output_shape.FlatSize();\\n+  const int input_elements = input_shape.FlatSize();\\n+  const int batches = FlatSizeSkipDim(output_shape, output_dims_count - 1);\\n+  const int output_depth = MatchingDim(weights_shape, weights_dims_count - 2,\\n+                                       output_shape, output_dims_count - 1);\\n+  const int max_batch_index = batches - 1;\\n+  const int max_output = max_batch_index * output_depth + w0_size;\\n+  const int max_batch_depth = accum_depth * max_batch_index;\\n+\\n+  \/\/ Verify output size is enough.\\n+  if (output_elements < max_output) return false;\\n+\\n+  \/\/ Verify index from sparse in input is valid.\\n+  for (int i = 0; i < sparsity->dim_metadata[1].array_indices->size; ++i) {\\n+    if (input_elements <=\\n+        max_batch_depth + sparsity->dim_metadata[1].array_indices->data[i])\\n+      return false;\\n+  }\\n+  return true;\\n+}\\n+\\n template <KernelType kernel_type>\\n TfLiteStatus EvalFloat(TfLiteContext* context, TfLiteNode* node,\\n                        TfLiteFullyConnectedParams* params, OpData* data,\\n@@ -968,24 +998,32 @@ TfLiteStatus EvalFloat(TfLiteContext* context, TfLiteNode* node,\\n                            \"Unsupported sparse fully-connected weight format.\");\\n         return kTfLiteError;\\n       }\\n+      const auto& input_shape = GetTensorShape(input);\\n+      const auto& filter_shape = GetTensorShape(filter);\\n+      const auto& output_shape = GetTensorShape(output);\\n+      const auto& bias_shape = GetTensorShape(bias);\\n+      if (!VerifySparsity(filter_shape, input_shape, output_shape, &sparsity)) {\\n+        TF_LITE_KERNEL_LOG(context, \"Invalid sparse fully-connected format.\");\\n+        return kTfLiteError;\\n+      }\\n \\n       if (sparsity.dim_metadata_size == kDimMetadataSizeRandomSparse) {\\n         \/\/ Random sparse.\\n         optimized_ops::FullyConnectedSparseWeight(\\n-            sparsity, op_params, GetTensorShape(input),\\n-            GetTensorData<float>(input), GetTensorShape(filter),\\n-            GetTensorData<float>(filter), GetTensorShape(bias),\\n-            GetTensorData<float>(bias), GetTensorShape(output),\\n-            GetTensorData<float>(output));\\n+            sparsity, op_params,                         \/\/ Disable formatting\\n+            input_shape, GetTensorData<float>(input),    \/\/ Disable formatting\\n+            filter_shape, GetTensorData<float>(filter),  \/\/ Disable formatting\\n+            bias_shape, GetTensorData<float>(bias),      \/\/ Disable formatting\\n+            output_shape, GetTensorData<float>(output));\\n       } else if (sparsity.dim_metadata_size == kDimMetadataSizeBlockSparse &&\\n                  sparsity.dim_metadata[2].dense_size == 4) {\\n         \/\/ Block sparse with block size of 1x4.\\n         optimized_ops::FullyConnectedSparseWeight1x4(\\n-            sparsity, op_params, GetTensorShape(input),\\n-            GetTensorData<float>(input), GetTensorShape(filter),\\n-            GetTensorData<float>(filter), GetTensorShape(bias),\\n-            GetTensorData<float>(bias), GetTensorShape(output),\\n-            GetTensorData<float>(output),\\n+            sparsity, op_params,                         \/\/ Disable formatting\\n+            input_shape, GetTensorData<float>(input),    \/\/ Disable formatting\\n+            filter_shape, GetTensorData<float>(filter),  \/\/ Disable formatting\\n+            bias_shape, GetTensorData<float>(bias),      \/\/ Disable formatting\\n+            output_shape, GetTensorData<float>(output),\\n             CpuBackendContext::GetFromContext(context));\\n       } else {\\n         TF_LITE_KERNEL_LOG(context,'}}",
            "message_norm":"[lite] add validation check for sparse fully connected\n\npiperorigin-revid: 417629354\nchange-id: if96171c4bd4f5fdb01d6368d6deab19d1c9beca7",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('417629354', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/fully_connected.cc'])",
            "num_files":1.0
        },
        {
            "index":326,
            "vuln_id":"GHSA-3x96-m42v-hvh5",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/c51285f791e48e536111cd57a9544ccbf7f33961'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Microweber Cross-site Scripting (XSS) - Reflected in GitHub repository microweber\/microweber prior to 1.2.18.",
            "published_date":"2022-06-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/c51285f791e48e536111cd57a9544ccbf7f33961",
            "commit_sha":"c51285f791e48e536111cd57a9544ccbf7f33961",
            "patch":"SINGLE",
            "chain_ord":"['c51285f791e48e536111cd57a9544ccbf7f33961']",
            "before_first_fix_commit":"{'10550ec85018bb0f581edd0ac2aed0d7bc9fe6b1'}",
            "last_fix_commit":"c51285f791e48e536111cd57a9544ccbf7f33961",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/22\/2022, 11:56:16",
            "message":"update",
            "author":"Peter Ivanov",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 3, 'total': 12}",
            "files":"{'userfiles\/modules\/microweber\/toolbar\/editor_tools\/module_settings\/index.php': {'additions': 9, 'deletions': 3, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/c51285f791e48e536111cd57a9544ccbf7f33961\/userfiles%2Fmodules%2Fmicroweber%2Ftoolbar%2Feditor_tools%2Fmodule_settings%2Findex.php', 'patch': '@@ -87,11 +87,13 @@\\n     if (isset($_GET[\\'autosize\\'])) {\\n         $autoSize = $_GET[\\'autosize\\'];\\n     }\\n+    $autoSize = xss_clean($autoSize);\\n \\n     $type = \\'\\';\\n     if (isset($_GET[\\'type\\'])) {\\n         $type = $_GET[\\'type\\'];\\n     }\\n+    $type = xss_clean($type);\\n \\n     $mod_id = $mod_orig_id = false;\\n     $is_linked_mod = false;\\n@@ -403,7 +405,9 @@\\n                 if (mw.notification) {\\n                     mw.notification.success(\\'<?php _ejs(\\'Settings are saved\\') ?>\\');\\n                 }\\n+                <?php if (isset($params[\\'id\\'])) : ?>\\n                 mw.reload_module_parent(\\'#<?php print $params[\\'id\\']  ?>\\')\\n+                <?php endif; ?>\\n \\n             });\\n \\n@@ -440,9 +444,11 @@\\n <body class=\"mw-external-loading loading\">\\n <div id=\"settings-main\">\\n     <div id=\"settings-container\">\\n-        <div class=\"mw-module-live-edit-settings <?php print $params[\\'id\\'] ?>\"\\n-             id=\"module-id-<?php print $params[\\'id\\'] ?>\">{content}\\n-        <\/div>\\n+        <?php if (isset($params[\\'id\\'])) : ?>\\n+            <div class=\"mw-module-live-edit-settings <?php print $params[\\'id\\'] ?>\"\\n+                 id=\"module-id-<?php print $params[\\'id\\'] ?>\">{content}\\n+            <\/div>\\n+        <?php endif; ?>\\n     <\/div>\\n <\/div>'}}",
            "message_norm":"update",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['userfiles\/modules\/microweber\/toolbar\/editor_tools\/module_settings\/index.php'])",
            "num_files":1.0
        },
        {
            "index":215,
            "vuln_id":"GHSA-37pf-w9ff-gqvm",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/d797e3f00e34c12c8c0ae52f56344325439dccd7', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/87ac2b5a751710ee288fdda3fd4d9818e22387a1'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-0912, CVE-2019-0913, CVE-2019-0914, CVE-2019-0915, CVE-2019-0916, CVE-2019-0917, CVE-2019-0922, CVE-2019-0923, CVE-2019-0924, CVE-2019-0925, CVE-2019-0933, CVE-2019-0937.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/87ac2b5a751710ee288fdda3fd4d9818e22387a1",
            "commit_sha":"87ac2b5a751710ee288fdda3fd4d9818e22387a1",
            "patch":"MULTI",
            "chain_ord":"['87ac2b5a751710ee288fdda3fd4d9818e22387a1', 'd797e3f00e34c12c8c0ae52f56344325439dccd7']",
            "before_first_fix_commit":"{'ea0491305137183603bf43844b5584d4cc972e28', '4594e340bc9ca9f857010a68e8b562d65b46eed6'}",
            "last_fix_commit":"d797e3f00e34c12c8c0ae52f56344325439dccd7",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/17\/2019, 17:22:17",
            "message":"[CVE-2019-0927]",
            "author":"Michael Holman",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'lib\/Backend\/GlobOptFields.cpp': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/87ac2b5a751710ee288fdda3fd4d9818e22387a1\/lib%2FBackend%2FGlobOptFields.cpp', 'patch': '@@ -394,6 +394,7 @@ GlobOpt::ProcessFieldKills(IR::Instr *instr, BVSparse<JitArenaAllocator> *bv, bo\\n     case Js::OpCode::StRootFldStrict:\\n     case Js::OpCode::StSlot:\\n     case Js::OpCode::StSlotChkUndecl:\\n+    case Js::OpCode::StSuperFld:\\n         Assert(dstOpnd != nullptr);\\n         sym = dstOpnd->AsSymOpnd()->m_sym;\\n         if (inGlobOpt)'}}",
            "message_norm":"[cve-2019-0927]",
            "language":"ro",
            "entities":"[('cve-2019-0927', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Backend\/GlobOptFields.cpp'])",
            "num_files":1.0
        },
        {
            "index":3131,
            "vuln_id":"GHSA-vj9x-w7ch-f46p",
            "cwe_id":"{'CWE-89'}",
            "score":8.3,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/66281c12479dc01a06258d8533eaddfb1770d5bd'}",
            "dataset":"osv",
            "summary":"pimcore is vulnerable to SQL Injection pimcore is vulnerable to Improper Neutralization of Special Elements used in an SQL Command",
            "published_date":"2022-01-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/66281c12479dc01a06258d8533eaddfb1770d5bd",
            "commit_sha":"66281c12479dc01a06258d8533eaddfb1770d5bd",
            "patch":"SINGLE",
            "chain_ord":"['66281c12479dc01a06258d8533eaddfb1770d5bd']",
            "before_first_fix_commit":"{'d8377fc752dc3a42ca72cb49650481191f14ec63'}",
            "last_fix_commit":"66281c12479dc01a06258d8533eaddfb1770d5bd",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/17\/2022, 14:39:43",
            "message":"[Data Object] Classification Store quote filtering",
            "author":"Bernhard Rusch",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassificationstoreController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/66281c12479dc01a06258d8533eaddfb1770d5bd\/bundles%2FAdminBundle%2FController%2FAdmin%2FDataObject%2FClassificationstoreController.php', 'patch': \"@@ -1242,7 +1242,7 @@ public function propertiesGetAction(Request $request)\\n         }\\n \\n         if ($storeId) {\\n-            $conditionParts[] = '(storeId = ' . $storeId . ')';\\n+            $conditionParts[] = '(storeId = '. $db->quote($storeId) . ')';\\n         }\\n \\n         if ($request->get('filter')) {\"}}",
            "message_norm":"[data object] classification store quote filtering",
            "language":"it",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassificationstoreController.php'])",
            "num_files":1.0
        },
        {
            "index":1936,
            "vuln_id":"GHSA-gv3v-92v6-m48j",
            "cwe_id":"{'CWE-444'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/jooby-project\/jooby\/commit\/b66e3342cf95205324023cfdf2cb5811e8a6dcf4'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of CRLF Sequences in HTTP Headers in Jooby ('HTTP Response Splitting) ### Impact\n\n - Cross Site Scripting\n - Cache Poisoning\n - Page Hijacking\n\n### Patches\n\nThis was fixed in version `2.2.1`.\n\n### Workarounds\n\nIf you are unable to update, ensure that user supplied data isn't able to flow to HTTP headers. If it does, pre-sanitize for CRLF characters.\n\n### References\n\n##### [CWE-113: Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting')](https:\/\/cwe.mitre.org\/data\/definitions\/113.html)\n\nI've been poking at libraries to see if they are vulnerable to HTTP Response Splitting and Jooby is my third case of finding this vulnerability.\n\n### Root Cause\n\nThis roots cause back to this line in the Jooby codebase:\n\nhttps:\/\/github.com\/jooby-project\/jooby\/blob\/93cfc80aa20c188f71a442ea7a1827da380e1c27\/modules\/jooby-netty\/src\/main\/java\/io\/jooby\/internal\/netty\/NettyContext.java#L102\n\nThe `DefaultHttpHeaders` takes a parameter `validate` which, when `true` (as it is for the no-arg constructor) validates that the header isn't being abused to do HTTP Response Splitting.\n\n### Reported By\n\nThis vulnerability was reported by @JLLeitschuh ([Twitter](https:\/\/twitter.com\/JLLeitschuh))\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [jooby-project\/jooby](https:\/\/github.com\/jooby-project\/jooby\/issues)",
            "published_date":"2020-04-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/jooby-project\/jooby",
            "commit_href":"https:\/\/github.com\/jooby-project\/jooby\/commit\/b66e3342cf95205324023cfdf2cb5811e8a6dcf4",
            "commit_sha":"b66e3342cf95205324023cfdf2cb5811e8a6dcf4",
            "patch":"SINGLE",
            "chain_ord":"['b66e3342cf95205324023cfdf2cb5811e8a6dcf4']",
            "before_first_fix_commit":"{'d5708760bdd27f8f6e1dbbbabbda4379fd5ba926'}",
            "last_fix_commit":"b66e3342cf95205324023cfdf2cb5811e8a6dcf4",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/12\/2019, 13:30:52",
            "message":"CWE-113: Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting fix #GHSA-gv3v-92v6-m48j",
            "author":"Edgar Espina",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'modules\/jooby-netty\/src\/main\/java\/io\/jooby\/internal\/netty\/NettyContext.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jooby-project\/jooby\/raw\/b66e3342cf95205324023cfdf2cb5811e8a6dcf4\/modules%2Fjooby-netty%2Fsrc%2Fmain%2Fjava%2Fio%2Fjooby%2Finternal%2Fnetty%2FNettyContext.java', 'patch': '@@ -99,7 +99,7 @@\\n public class NettyContext implements DefaultContext, ChannelFutureListener {\\n \\n   private static final HttpHeaders NO_TRAILING = EmptyHttpHeaders.INSTANCE;\\n-  final DefaultHttpHeaders setHeaders = new DefaultHttpHeaders(false);\\n+  final DefaultHttpHeaders setHeaders = new DefaultHttpHeaders(true);\\n   private final int bufferSize;\\n   InterfaceHttpPostRequestDecoder decoder;\\n   private Router router;'}}",
            "message_norm":"cwe-113: improper neutralization of crlf sequences in http headers ('http response splitting fix #ghsa-gv3v-92v6-m48j",
            "language":"en",
            "entities":"[('cwe-113', 'CWEID', ''), ('improper neutralization', 'SECWORD', ''), ('http response splitting', 'SECWORD', ''), ('ghsa-gv3v-92v6-m48j', 'VULNID', 'GHSA')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/jooby-netty\/src\/main\/java\/io\/jooby\/internal\/netty\/NettyContext.java'])",
            "num_files":1.0
        },
        {
            "index":3249,
            "vuln_id":"GHSA-w8f3-pvx4-4c3h",
            "cwe_id":"{'CWE-1321'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/Quernest\/arr-flatten-unflatten\/commit\/cb4351c75f87a4fbec3b6140c40ee2993f574372'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in arr-flatten-unflatten All versions of package arr-flatten-unflatten up to and including version 1.1.4 are vulnerable to Prototype Pollution via the constructor.",
            "published_date":"2021-05-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/Quernest\/arr-flatten-unflatten",
            "commit_href":"https:\/\/github.com\/Quernest\/arr-flatten-unflatten\/commit\/cb4351c75f87a4fbec3b6140c40ee2993f574372",
            "commit_sha":"cb4351c75f87a4fbec3b6140c40ee2993f574372",
            "patch":"SINGLE",
            "chain_ord":"['cb4351c75f87a4fbec3b6140c40ee2993f574372']",
            "before_first_fix_commit":"{'f4ccf0a8d55288490e729233fe2885eec15f74d0', '28bf4357297b67730ec1db002c001a76cd349b61'}",
            "last_fix_commit":"cb4351c75f87a4fbec3b6140c40ee2993f574372",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/25\/2021, 20:45:17",
            "message":"Merge pull request #8 from 418sec\/1-npm-arr-flatten-unflatten\n\nSecurity Fix for Prototype Pollution - huntr.dev",
            "author":"Quernest",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'unflatten.js': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Quernest\/arr-flatten-unflatten\/raw\/cb4351c75f87a4fbec3b6140c40ee2993f574372\/unflatten.js', 'patch': '@@ -10,6 +10,8 @@ function unflatten(obj = {}) {\\n     let m = {};\\n \\n     while ((m = regex.exec(p))) {\\n+      if (curr[prop] === constructor.prototype)\\n+        curr[prop] = {}\\n       curr = curr[prop] || (curr[prop] = m[2] ? [] : {});\\n       prop = m[2] || m[1];\\n     }'}}",
            "message_norm":"merge pull request #8 from 418sec\/1-npm-arr-flatten-unflatten\n\nsecurity fix for prototype pollution - huntr.dev",
            "language":"en",
            "entities":"[('#8', 'ISSUE', ''), ('security', 'SECWORD', ''), ('prototype pollution', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['unflatten.js'])",
            "num_files":1.0
        },
        {
            "index":883,
            "vuln_id":"GHSA-6qcc-whgp-pjj2",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/8ab06bfbb5a05a1b190731d9c7476ec45f5ee878'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Pimcore Pimcore version 10.3.2 and prior is vulnerable to stored cross-site scripting. A patch is available and anticipated to be part of version 10.3.3.",
            "published_date":"2022-03-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/8ab06bfbb5a05a1b190731d9c7476ec45f5ee878",
            "commit_sha":"8ab06bfbb5a05a1b190731d9c7476ec45f5ee878",
            "patch":"SINGLE",
            "chain_ord":"['8ab06bfbb5a05a1b190731d9c7476ec45f5ee878']",
            "before_first_fix_commit":"{'cef6fb5a9f385f77b9a1af508ecc45a147476458'}",
            "last_fix_commit":"8ab06bfbb5a05a1b190731d9c7476ec45f5ee878",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/02\/2022, 19:06:51",
            "message":"escaping fields in SERP preview",
            "author":"JiaJia Ji",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/8ab06bfbb5a05a1b190731d9c7476ec45f5ee878\/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Fdocument%2Fpages%2Fsettings.js', 'patch': '@@ -79,8 +79,8 @@ pimcore.document.pages.settings = Class.create(pimcore.document.settings_abstrac\\n             var updateSerpPreview = function () {\\n \\n                 var metaPanel = this.layout.getComponent(\"metaDataPanel\");\\n-                var title = metaPanel.getComponent(\"title\").getValue();\\n-                var description = metaPanel.getComponent(\"description\").getValue();\\n+                var title = htmlspecialchars(metaPanel.getComponent(\"title\").getValue());\\n+                var description = htmlspecialchars(metaPanel.getComponent(\"description\").getValue());\\n \\n                 var truncate = function( text, n ){\\n                     if (text.length <= n) { return text; }'}}",
            "message_norm":"escaping fields in serp preview",
            "language":"en",
            "entities":"[('escaping', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/document\/pages\/settings.js'])",
            "num_files":1.0
        },
        {
            "index":2413,
            "vuln_id":"GHSA-mg5h-9rhq-4cqx",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/42c0d9813df3035728b36116a6ce9116e6fa8ed3'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in ShowDoc ShowDoc is vulnerable to stored cross-site scripting through file upload in versions 2.10.3 and prior. A patch is available and anticipated to be part of version 2.10.4.",
            "published_date":"2022-03-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/42c0d9813df3035728b36116a6ce9116e6fa8ed3",
            "commit_sha":"42c0d9813df3035728b36116a6ce9116e6fa8ed3",
            "patch":"SINGLE",
            "chain_ord":"['42c0d9813df3035728b36116a6ce9116e6fa8ed3']",
            "before_first_fix_commit":"{'818d7fe731f452acccacf731ce47ec27ad68049c'}",
            "last_fix_commit":"42c0d9813df3035728b36116a6ce9116e6fa8ed3",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/13\/2022, 02:27:22",
            "message":"file upload bug",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'server\/Application\/Api\/Model\/AttachmentModel.class.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/42c0d9813df3035728b36116a6ce9116e6fa8ed3\/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': '@@ -300,6 +300,7 @@ public function isDangerFilename($filename){\\n \\t\\t\\t $isDangerStr($filename , \".php\")\\n \\t\\t\\t|| $isDangerStr($filename , \".svg\")\\n \\t\\t\\t|| $isDangerStr($filename , \".htm\")\\n+\\t\\t\\t|| $isDangerStr($filename , \".shtm\")\\n \\t\\t\\t|| $isDangerStr($filename , \"%\")\\n \\t\\t\\t|| $isDangerStr($filename , \".xml\")\\n \\t\\t) {'}}",
            "message_norm":"file upload bug",
            "language":"ro",
            "entities":"[('bug', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Model\/AttachmentModel.class.php'])",
            "num_files":1.0
        },
        {
            "index":2774,
            "vuln_id":"GHSA-qjw2-hr98-qgfh",
            "cwe_id":"{'CWE-502'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/ad5a630174f08d279504bc51ebba8772fd71b86b', 'https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/2118e71325486c68f089a9761c9d8a11b4ddd1cb'}",
            "dataset":"osv",
            "summary":"Unsafe Deserialization in jackson-databind FasterXML jackson-databind 2.x before 2.6.7.5 and from 2.7.x before 2.9.10.6 mishandles the interaction between serialization gadgets and typing, related to com.pastdev.httpcomponents.configuration.JndiConfiguration.",
            "published_date":"2021-12-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/FasterXML\/jackson-databind",
            "commit_href":"https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/ad5a630174f08d279504bc51ebba8772fd71b86b",
            "commit_sha":"ad5a630174f08d279504bc51ebba8772fd71b86b",
            "patch":"MULTI",
            "chain_ord":"['ad5a630174f08d279504bc51ebba8772fd71b86b', '2118e71325486c68f089a9761c9d8a11b4ddd1cb']",
            "before_first_fix_commit":"{'8069e46dd9c288d4a52911ebdc52192cd3d0e96c'}",
            "last_fix_commit":"2118e71325486c68f089a9761c9d8a11b4ddd1cb",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/18\/2020, 17:17:24",
            "message":"Add cve id for #2798",
            "author":"Tatu Saloranta",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'release-notes\/VERSION-2.x': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/FasterXML\/jackson-databind\/raw\/ad5a630174f08d279504bc51ebba8772fd71b86b\/release-notes%2FVERSION-2.x', 'patch': '@@ -11,7 +11,7 @@ Project: jackson-databind\\n \\n 2.9.10.6 (24-Aug-2020)\\n \\n-#2798: Block one more gadget type (xxx, CVE-xxxx-xxx)\\n+#2798: Block one more gadget type (com.pastdev.httpcomponents, CVE-2020-24750)\\n  (reported by Al1ex@knownsec)\\n #2814: Block one more gadget type (Anteros-DBCP, CVE-2020-24616)\\n  (reported by ChenZhaojun)'}}",
            "message_norm":"add cve id for #2798",
            "language":"cy",
            "entities":"[('add', 'ACTION', ''), ('cve', 'SECWORD', ''), ('#2798', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['release-notes\/VERSION-2.x'])",
            "num_files":1.0
        },
        {
            "index":1528,
            "vuln_id":"GHSA-cchx-mfrc-fwqr",
            "cwe_id":"{'CWE-200', 'CWE-287'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/symfony\/symfony\/commit\/a29ce2817cf43bb1850cf6af114004ac26c7a081'}",
            "dataset":"osv",
            "summary":"Improper authentication in Symfony In Symfony before 2.7.51, 2.8.x before 2.8.50, 3.x before 3.4.26, 4.x before 4.1.12, and 4.2.x before 4.2.7, a vulnerability would allow an attacker to authenticate as a privileged user on sites with user registration and remember me login functionality enabled. This is related to symfony\/security.",
            "published_date":"2020-02-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/symfony\/symfony",
            "commit_href":"https:\/\/github.com\/symfony\/symfony\/commit\/a29ce2817cf43bb1850cf6af114004ac26c7a081",
            "commit_sha":"a29ce2817cf43bb1850cf6af114004ac26c7a081",
            "patch":"SINGLE",
            "chain_ord":"['a29ce2817cf43bb1850cf6af114004ac26c7a081']",
            "before_first_fix_commit":"{'3e0b2354dbc8813a1f5ff91757e1dce40dfe31b4'}",
            "last_fix_commit":"a29ce2817cf43bb1850cf6af114004ac26c7a081",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/06\/2019, 10:40:18",
            "message":"[Security] Add a separator in the remember me cookie hash",
            "author":"Pascal Borreli",
            "comments":"{'com_1': {'author': 'simoheinonen', 'datetime': '06\/05\/2019, 12:10:12', 'body': 'This logs out all users with the old hash. \ud83d\ude10'}, 'com_2': {'author': 'stof', 'datetime': '06\/05\/2019, 12:18:28', 'body': '@simoheinonen which is better than allowing to spoof remember me cookies'}, 'com_3': {'author': 'simoheinonen', 'datetime': '06\/05\/2019, 12:24:05', 'body': 'Yeah but worth mentioning imo. Logging out thousands of users might cost a lot'}, 'com_4': {'author': 'stefanospetrakis', 'datetime': '06\/25\/2019, 16:29:42', 'body': \"One remark regarding this (a bit too late perhaps);\\r\\nI would like this a little bit shorter for readability\/redundancy\/etc., sth like that:\\r\\n`return hash_hmac('sha256', implode(self::COOKIE_DELIMITER, func_get_args()), $this->getSecret());`\\r\\n\\r\\nAny point to opening a follow-up issue for this?\"}, 'com_5': {'author': 'stof', 'datetime': '06\/25\/2019, 16:37:07', 'body': '@stefanospetrakis this code is less explicit about what gets included in the hash exactly, due to using `func_get_args` instead of the actual arguments. So to me, this actually makes it less readable.'}, 'com_6': {'author': 'stefanospetrakis', 'datetime': '06\/25\/2019, 19:53:54', 'body': '@stof Fair enough, how about the following:\\r\\n\\r\\n`implode(self::COOKIE_DELIMITER, [$class, $username, $expires, $password])`'}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/Symfony\/Component\/Security\/Http\/RememberMe\/TokenBasedRememberMeServices.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/symfony\/symfony\/raw\/a29ce2817cf43bb1850cf6af114004ac26c7a081\/src%2FSymfony%2FComponent%2FSecurity%2FHttp%2FRememberMe%2FTokenBasedRememberMeServices.php', 'patch': \"@@ -120,6 +120,6 @@ protected function generateCookieValue($class, $username, $expires, $password)\\n      *\/\\n     protected function generateCookieHash($class, $username, $expires, $password)\\n     {\\n-        return hash_hmac('sha256', $class.$username.$expires.$password, $this->getSecret());\\n+        return hash_hmac('sha256', $class.self::COOKIE_DELIMITER.$username.self::COOKIE_DELIMITER.$expires.self::COOKIE_DELIMITER.$password, $this->getSecret());\\n     }\\n }\"}}",
            "message_norm":"[security] add a separator in the remember me cookie hash",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('add', 'ACTION', ''), ('cookie', 'SECWORD', ''), ('hash', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Symfony\/Component\/Security\/Http\/RememberMe\/TokenBasedRememberMeServices.php'])",
            "num_files":1.0
        },
        {
            "index":2304,
            "vuln_id":"GHSA-jv6v-fvvx-4932",
            "cwe_id":"{'CWE-610', 'CWE-73'}",
            "score":6.2,
            "chain":"{'https:\/\/github.com\/octobercms\/october\/commit\/2b8939cc8b5b6fe81e093fe2c9f883ada4e3c8cc'}",
            "dataset":"osv",
            "summary":"Arbitrary File Deletion vulnerability in OctoberCMS ### Impact\nAn attacker can exploit this vulnerability to delete arbitrary local files of an October CMS server. The vulnerability is only exploitable by an authenticated backend user with the `cms.manage_assets` permission.\n\n### Patches\nIssue has been patched in Build 466 (v1.0.466).\n\n### Workarounds\nApply https:\/\/github.com\/octobercms\/october\/commit\/2b8939cc8b5b6fe81e093fe2c9f883ada4e3c8cc to your installation manually if unable to upgrade to Build 466.\n\n### References\nReported by [Sivanesh Ashok](https:\/\/stazot.com\/)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at [hello@octobercms.com](mailto:hello@octobercms.com)\n\n### Threat assessment:\n<img width=\"1241\" alt=\"Screen Shot 2020-03-31 at 12 16 53 PM\" src=\"https:\/\/user-images.githubusercontent.com\/7253840\/78060872-89354d00-7349-11ea-8c2b-5881b0a50736.png\">",
            "published_date":"2020-06-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/octobercms\/october",
            "commit_href":"https:\/\/github.com\/octobercms\/october\/commit\/2b8939cc8b5b6fe81e093fe2c9f883ada4e3c8cc",
            "commit_sha":"2b8939cc8b5b6fe81e093fe2c9f883ada4e3c8cc",
            "patch":"SINGLE",
            "chain_ord":"['2b8939cc8b5b6fe81e093fe2c9f883ada4e3c8cc']",
            "before_first_fix_commit":"{'a9b4a5b2c77afe5ad974455bec69da620b443a5d'}",
            "last_fix_commit":"2b8939cc8b5b6fe81e093fe2c9f883ada4e3c8cc",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/31\/2020, 09:37:31",
            "message":"Improve asset file path handling",
            "author":"Luke Towers",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 1, 'total': 9}",
            "files":"{'modules\/cms\/classes\/Asset.php': {'additions': 8, 'deletions': 1, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/octobercms\/october\/raw\/2b8939cc8b5b6fe81e093fe2c9f883ada4e3c8cc\/modules%2Fcms%2Fclasses%2FAsset.php', 'patch': \"@@ -285,7 +285,14 @@ public function getFilePath($fileName = null)\\n             $fileName = $this->fileName;\\n         }\\n \\n-        return $this->theme->getPath().'\/'.$this->dirName.'\/'.$fileName;\\n+        \/\/ Limit paths to those under the assets directory\\n+        $directory = $this->theme->getPath() . '\/' . $this->dirName . '\/';\\n+        $path = realpath($directory . $fileName);\\n+        if (!starts_with($path, $directory)) {\\n+            return false;\\n+        }\\n+\\n+        return $path;\\n     }\\n \\n     \/**\"}}",
            "message_norm":"improve asset file path handling",
            "language":"en",
            "entities":"[('improve', 'ACTION', ''), ('asset', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/cms\/classes\/Asset.php'])",
            "num_files":1.0
        },
        {
            "index":3286,
            "vuln_id":"GHSA-wjh9-344g-vc49",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/francoisjacquet\/rosariosis\/commit\/6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in RosarioSIS Cross-site Scripting (XSS) - Stored in GitHub repository francoisjacquet\/rosariosis prior to 9.0.",
            "published_date":"2022-06-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/francoisjacquet\/rosariosis",
            "commit_href":"https:\/\/github.com\/francoisjacquet\/rosariosis\/commit\/6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8",
            "commit_sha":"6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8",
            "patch":"SINGLE",
            "chain_ord":"['6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8']",
            "before_first_fix_commit":"{'25eb3196e26df31917dfef87aa9f66f78c1646ea'}",
            "last_fix_commit":"6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/04\/2022, 11:44:21",
            "message":"Fix stored XSS security issue: remove inline JS from URL in PreparePHP_SELF.fnc.php",
            "author":"Fran\u00e7ois Jacquet",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'functions\/PreparePHP_SELF.fnc.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/francoisjacquet\/rosariosis\/raw\/6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8\/functions%2FPreparePHP_SELF.fnc.php', 'patch': \"@@ -200,7 +200,7 @@ function( $match ) {\\n \\n \\tforeach ( $remove as $remove_string )\\n \\t{\\n-\\t\\twhile ( strpos( $string, $remove_string ) !== false )\\n+\\t\\twhile ( stripos( $string, $remove_string ) !== false )\\n \\t\\t{\\n \\t\\t\\t$string = str_ireplace( $remove, '', $string );\\n \\t\\t}\"}}",
            "message_norm":"fix stored xss security issue: remove inline js from url in preparephp_self.fnc.php",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('xss', 'SECWORD', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('remove', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['functions\/PreparePHP_SELF.fnc.php'])",
            "num_files":1.0
        },
        {
            "index":3484,
            "vuln_id":"GHSA-xr38-w74q-r8jv",
            "cwe_id":"{'CWE-862', 'CWE-863'}",
            "score":6.4,
            "chain":"{'https:\/\/github.com\/inveniosoftware\/invenio-drafts-resources\/commit\/039b0cff1ad4b952000f4d8c3a93f347108b6626'}",
            "dataset":"osv",
            "summary":"Permissions not properly checked in Invenio-Drafts-Resources ### Impact\n\nInvenio-Drafts-Resources does not properly check permissions when a record is published. The vulnerability is exploitable in a default installation of InvenioRDM. An authenticated user is able via REST API calls to publish draft records of other users if they know the record identifier and the draft validates (e.g. all require fields filled out). An attacker is not able to modify the data in the record, and thus e.g. *cannot* change a record from restricted to public.\n\n### Details\n\nThe service's ``publish()`` method contains the following permission check:\n\n```python\ndef publish(..):\n    self.require_permission(identity, \"publish\")\n```\nHowever, the record should have been passed into the permission check so that the need generators have access to e.g. the record owner.\n\n```python\ndef publish(..):\n    self.require_permission(identity, \"publish\", record=record)\n```\nThe bug is activated in Invenio-RDM-Records which has a need generator called ``RecordOwners()``, which when no record is passed in defaults to allow any authenticated user:\n\n```python\nclass RecordOwners(Generator):\n    def needs(self, record=None, **kwargs):\n        if record is None:\n            return [authenticated_user]\n    # ...\n```\n\n### Patches\n\nThe problem is patched in Invenio-Drafts-Resources v0.13.7 and 0.14.6+, which is part of InvenioRDM v6.0.1 and InvenioRDM v7.0 respectively.\n\nYou can verify the version installed of Invenio-Drafts-Resources via PIP:\n\n```console\ncd ~\/src\/my-site\npipenv run pip freeze | grep invenio-drafts-resources\n```\n\n### References\n\n- [Security policy](https:\/\/invenio.readthedocs.io\/en\/latest\/community\/security-policy.html)\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Chat with us on Discord: https:\/\/discord.gg\/8qatqBC",
            "published_date":"2021-12-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/inveniosoftware\/invenio-drafts-resources",
            "commit_href":"https:\/\/github.com\/inveniosoftware\/invenio-drafts-resources\/commit\/039b0cff1ad4b952000f4d8c3a93f347108b6626",
            "commit_sha":"039b0cff1ad4b952000f4d8c3a93f347108b6626",
            "patch":"SINGLE",
            "chain_ord":"['039b0cff1ad4b952000f4d8c3a93f347108b6626']",
            "before_first_fix_commit":"{'998ede99c377c84f11fe22c07c20f90c88c463dc'}",
            "last_fix_commit":"039b0cff1ad4b952000f4d8c3a93f347108b6626",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/24\/2021, 14:32:41",
            "message":"security: fix missing permission check of publish\n\n* Invenio-Drafts-Resources does not properly check permissions when a\n  record is published. The vulnerability is exploitable in a default\n  installation of InvenioRDM. An authenticated a user is able via REST\n  API calls to publish draft records of other users if they know the\n  record identifier and the draft validates (e.g. all require fields\n  filled out). An attacker is not able to modify the data in the record,\n  and thus e.g. cannot change a record from restricted to public.",
            "author":"Lars Holm Nielsen",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 2, 'total': 3}",
            "files":"{'invenio_drafts_resources\/services\/records\/service.py': {'additions': 1, 'deletions': 2, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/inveniosoftware\/invenio-drafts-resources\/raw\/039b0cff1ad4b952000f4d8c3a93f347108b6626\/invenio_drafts_resources%2Fservices%2Frecords%2Fservice.py', 'patch': '@@ -267,10 +267,9 @@ def publish(self, id_, identity, uow=None):\\n               into records)\\n             - Create or update associated (published) record with data\\n         \"\"\"\\n-        self.require_permission(identity, \"publish\")\\n-\\n         # Get the draft\\n         draft = self.draft_cls.pid.resolve(id_, registered_only=False)\\n+        self.require_permission(identity, \"publish\", record=draft)\\n \\n         # Validate the draft strictly - since a draft can be saved with errors\\n         # we do a strict validation here to make sure only valid drafts can be'}}",
            "message_norm":"security: fix missing permission check of publish\n\n* invenio-drafts-resources does not properly check permissions when a\n  record is published. the vulnerability is exploitable in a default\n  installation of inveniordm. an authenticated a user is able via rest\n  api calls to publish draft records of other users if they know the\n  record identifier and the draft validates (e.g. all require fields\n  filled out). an attacker is not able to modify the data in the record,\n  and thus e.g. cannot change a record from restricted to public.",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('fix', 'ACTION', ''), ('permission', 'SECWORD', ''), ('permissions', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('exploitable', 'SECWORD', ''), ('validates', 'ACTION', ''), ('attacker', 'FLAW', ''), ('change', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['invenio_drafts_resources\/services\/records\/service.py'])",
            "num_files":1.0
        },
        {
            "index":1150,
            "vuln_id":"GHSA-8687-vv9j-hgph",
            "cwe_id":"{'CWE-20'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/Automattic\/mongoose\/commit\/f3eca5b94d822225c04e96cbeed9f095afb3c31c'}",
            "dataset":"osv",
            "summary":"Improper Input Validation in Automattic Mongoose Automattic Mongoose through 5.7.4 allows attackers to bypass access control (in some applications) because any query object with a _bsontype attribute is ignored. For example, adding \"_bsontype\":\"a\" can sometimes interfere with a query filter. NOTE: this CVE is about Mongoose's failure to work around this _bsontype special case that exists in older versions of the bson parser (aka the mongodb\/js-bson project).",
            "published_date":"2019-10-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/Automattic\/mongoose",
            "commit_href":"https:\/\/github.com\/Automattic\/mongoose\/commit\/f3eca5b94d822225c04e96cbeed9f095afb3c31c",
            "commit_sha":"f3eca5b94d822225c04e96cbeed9f095afb3c31c",
            "patch":"SINGLE",
            "chain_ord":"['f3eca5b94d822225c04e96cbeed9f095afb3c31c']",
            "before_first_fix_commit":"{'cc10e0dc441f469330c1af2822d171fcd6fa8f89'}",
            "last_fix_commit":"f3eca5b94d822225c04e96cbeed9f095afb3c31c",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/09\/2019, 22:41:25",
            "message":"fix(query): delete top-level `_bsontype` property in queries to prevent silent empty queries\n\nFix #8222",
            "author":"Valeri Karpov",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'lib\/cast.js': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Automattic\/mongoose\/raw\/f3eca5b94d822225c04e96cbeed9f095afb3c31c\/lib%2Fcast.js', 'patch': \"@@ -27,6 +27,12 @@ module.exports = function cast(schema, obj, options, context) {\\n     throw new Error('Query filter must be an object, got an array ', util.inspect(obj));\\n   }\\n \\n+  \/\/ bson 1.x has the unfortunate tendency to remove filters that have a top-level\\n+  \/\/ `_bsontype` property. Should remove this when we upgrade to bson 4.x. See gh-8222\\n+  if (obj.hasOwnProperty('_bsontype')) {\\n+    delete obj._bsontype;\\n+  }\\n+\\n   const paths = Object.keys(obj);\\n   let i = paths.length;\\n   let _keys;\"}}",
            "message_norm":"fix(query): delete top-level `_bsontype` property in queries to prevent silent empty queries\n\nfix #8222",
            "language":"fr",
            "entities":"[('fix(query', 'ACTION', ''), ('prevent', 'ACTION', ''), ('fix', 'ACTION', ''), ('#8222', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/cast.js'])",
            "num_files":1.0
        },
        {
            "index":610,
            "vuln_id":"GHSA-5c8j-xr24-2665",
            "cwe_id":"{'CWE-77'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/tojocky\/node-printer\/commit\/e001e38738c17219a1d9dd8c31f7d82b9c0013c7'}",
            "dataset":"osv",
            "summary":"Potential Command Injection in printer Versions 0.0.1 and earlier of `printer` are affected by a command injection vulnerability resulting from a failure to sanitize command arguments properly in the `printDirect()` function. \n\n\n\n## Recommendation\n\nUpdate to version 0.0.2 or later.",
            "published_date":"2017-11-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/tojocky\/node-printer",
            "commit_href":"https:\/\/github.com\/tojocky\/node-printer\/commit\/e001e38738c17219a1d9dd8c31f7d82b9c0013c7",
            "commit_sha":"e001e38738c17219a1d9dd8c31f7d82b9c0013c7",
            "patch":"SINGLE",
            "chain_ord":"['e001e38738c17219a1d9dd8c31f7d82b9c0013c7']",
            "before_first_fix_commit":"{'7987544670c37fdef659f8ee9e5db20fae118705'}",
            "last_fix_commit":"e001e38738c17219a1d9dd8c31f7d82b9c0013c7",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/28\/2013, 18:30:28",
            "message":"Removed possible command injection",
            "author":"chieffancypants",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/printer.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tojocky\/node-printer\/raw\/e001e38738c17219a1d9dd8c31f7d82b9c0013c7\/lib%2Fprinter.js', 'patch': '@@ -93,7 +93,7 @@ function printDirect(parameters){\\n     }else if (!printer_helper.printDirect){\/\/ should be POSIX\\n         var temp_file_name = path.join(os.tmpDir(),\"printing\");\\n         fs.writeFileSync(temp_file_name, data);\\n-        child_process.exec(\\'lpr -P\\'+printer+\\' -oraw -r\\'+\\' \\'+temp_file_name, function(err, stdout, stderr){\\n+        child_process.execFile(\\'lpr\\', [\\'-P\\' + printer, \\'-oraw\\', \\'-r\\', temp_file_name], function(err, stdout, stderr){\\n             if (err !== null) {\\n                 error(\\'ERROR: \\' + err);\\n                 return;'}}",
            "message_norm":"removed possible command injection",
            "language":"en",
            "entities":"[('removed', 'ACTION', ''), ('possible command injection', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/printer.js'])",
            "num_files":1.0
        },
        {
            "index":3090,
            "vuln_id":"GHSA-vc2p-r46x-m3vx",
            "cwe_id":"{'CWE-77'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/lettre\/lettre\/pull\/508\/commits\/bbe7cc5381c5380b54fb8bbb4f77a3725917ff0b'}",
            "dataset":"osv",
            "summary":"Argument injection in lettre ### Impact\n\nAffected versions of lettre allowed argument injection to the sendmail command. It was possible, using forged to addresses, to pass arbitrary arguments to the sendmail executable.\n\nDepending on the implementation (original sendmail, postfix, exim, etc.) it could be possible in some cases to write email data into abritrary files (using sendmail's logging features).\n\n*NOTE*: This vulnerability only affects the sendmail transport. Others, including smtp, are not affected.\n\n### Fix\n\nThe flaw is corrected by modifying the executed command to stop parsing arguments before passing the destination addresses.\n\n### References\n\n* [RUSTSEC-2020-0069](https:\/\/rustsec.org\/advisories\/RUSTSEC-2020-0069.html)\n* [CVE-2020-28247](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-28247)",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/lettre\/lettre",
            "commit_href":"https:\/\/github.com\/lettre\/lettre\/pull\/508\/commits\/bbe7cc5381c5380b54fb8bbb4f77a3725917ff0b",
            "commit_sha":"bbe7cc5381c5380b54fb8bbb4f77a3725917ff0b",
            "patch":"SINGLE",
            "chain_ord":"['bbe7cc5381c5380b54fb8bbb4f77a3725917ff0b']",
            "before_first_fix_commit":"{'b187885e70af400d50e3200390306b9bd2109675'}",
            "last_fix_commit":"bbe7cc5381c5380b54fb8bbb4f77a3725917ff0b",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/11\/2020, 15:43:09",
            "message":"fix(transport-sendmail): Stop argument parsing before destination addresses",
            "author":"Alexis Mousset",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'src\/transport\/sendmail\/mod.rs': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/lettre\/lettre\/raw\/bbe7cc5381c5380b54fb8bbb4f77a3725917ff0b\/src%2Ftransport%2Fsendmail%2Fmod.rs', 'patch': '@@ -120,6 +120,7 @@ impl SendmailTransport {\\n         c.arg(\"-i\")\\n             .arg(\"-f\")\\n             .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\\\"\\\\\"\"))\\n+            .arg(\"--\")\\n             .args(envelope.to())\\n             .stdin(Stdio::piped())\\n             .stdout(Stdio::piped());\\n@@ -135,6 +136,7 @@ impl SendmailTransport {\\n         c.arg(\"-i\")\\n             .arg(\"-f\")\\n             .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\\\"\\\\\"\"))\\n+            .arg(\"--\")\\n             .args(envelope.to())\\n             .stdin(Stdio::piped())\\n             .stdout(Stdio::piped());\\n@@ -150,6 +152,7 @@ impl SendmailTransport {\\n         c.arg(\"-i\")\\n             .arg(\"-f\")\\n             .arg(envelope.from().map(|f| f.as_ref()).unwrap_or(\"\\\\\"\\\\\"\"))\\n+            .arg(\"--\")\\n             .args(envelope.to())\\n             .stdin(Stdio::piped())\\n             .stdout(Stdio::piped());'}}",
            "message_norm":"fix(transport-sendmail): stop argument parsing before destination addresses",
            "language":"fr",
            "entities":"[('fix(transport', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/transport\/sendmail\/mod.rs'])",
            "num_files":1.0
        },
        {
            "index":2487,
            "vuln_id":"GHSA-p23j-g745-8449",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/a4e56547fb8b7450656bfd26dfc52b8477c8ef27', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1307, CVE-2019-1308, CVE-2019-1366.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/a4e56547fb8b7450656bfd26dfc52b8477c8ef27",
            "commit_sha":"a4e56547fb8b7450656bfd26dfc52b8477c8ef27",
            "patch":"MULTI",
            "chain_ord":"['a4e56547fb8b7450656bfd26dfc52b8477c8ef27', 'cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d']",
            "before_first_fix_commit":"{'7e9a2ee60baa95ceb4f48f522f823c812ca90c80', '5989c6e038d80f92dcd8e10d725cdf45396201bb'}",
            "last_fix_commit":"cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/03\/2019, 21:52:17",
            "message":"CVE-2019-1335",
            "author":"Wyatt",
            "comments":null,
            "stats":"{'additions': 52, 'deletions': 13, 'total': 65}",
            "files":"{'lib\/Backend\/GlobOpt.cpp': {'additions': 52, 'deletions': 13, 'changes': 65, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/a4e56547fb8b7450656bfd26dfc52b8477c8ef27\/lib%2FBackend%2FGlobOpt.cpp', 'patch': '@@ -2161,27 +2161,46 @@ GlobOpt::CollectMemOpInfo(IR::Instr *instrBegin, IR::Instr *instr, Value *src1Va\\n             return false;\\n         }\\n         break;\\n-    case Js::OpCode::Decr_A:\\n-        isIncr = false;\\n-    case Js::OpCode::Incr_A:\\n-        isChangedByOne = true;\\n-        goto MemOpCheckInductionVariable;\\n     case Js::OpCode::Sub_I4:\\n-    case Js::OpCode::Sub_A:\\n         isIncr = false;\\n-    case Js::OpCode::Add_A:\\n     case Js::OpCode::Add_I4:\\n     {\\n-MemOpCheckInductionVariable:\\n-        StackSym *sym = instr->GetSrc1()->GetStackSym();\\n-        if (!sym)\\n+        \/\/ The only case in which these OpCodes can contribute to an inductionVariableChangeInfo\\n+        \/\/ is when the induction variable is being modified and overwritten aswell (ex: j = j + 1)\\n+        \/\/ and not when the induction variable is modified but not overwritten (ex: k = j + 1).\\n+        \/\/ This can either be detected in IR as\\n+        \/\/ s1     = Add_I4 s1     1  \/\/ Case #1, can be seen with \"j++\".\\n+        \/\/ or as\\n+        \/\/ s4(s2) = Add_I4 s3(s1) 1  \/\/ Case #2, can be see with \"j = j + 1\".\\n+        \/\/ s1     = Ld_A   s2\\n+        bool isInductionVar = false;\\n+        IR::Instr* nextInstr = instr->m_next;\\n+        if (\\n+            \/\/ Checks for Case #1 and Case #2\\n+            instr->GetDst()->GetStackSym() != nullptr &&\\n+            instr->GetDst()->IsRegOpnd() &&\\n+            (\\n+                \/\/ Checks for Case #1\\n+                (instr->GetDst()->GetStackSym() == instr->GetSrc1()->GetStackSym()) ||\\n+\\n+                \/\/ Checks for Case #2\\n+                (nextInstr&& nextInstr->m_opcode == Js::OpCode::Ld_A &&\\n+                 nextInstr->GetSrc1()->IsRegOpnd() &&\\n+                 nextInstr->GetDst()->IsRegOpnd() &&\\n+                 GetVarSymID(instr->GetDst()->GetStackSym()) == nextInstr->GetSrc1()->GetStackSym()->m_id &&\\n+                 GetVarSymID(instr->GetSrc1()->GetStackSym()) == nextInstr->GetDst()->GetStackSym()->m_id)\\n+            )\\n+        )\\n         {\\n-            sym = instr->GetSrc2()->GetStackSym();\\n+            isInductionVar = true;\\n         }\\n+        \\n+        \/\/ Even if dstIsInductionVar then dst == src1 so it\\'s safe to use src1 as the induction sym always.\\n+        StackSym* sym = instr->GetSrc1()->GetStackSym();\\n \\n         SymID inductionSymID = GetVarSymID(sym);\\n \\n-        if (IsSymIDInductionVariable(inductionSymID, this->currentBlock->loop))\\n+        if (isInductionVar && IsSymIDInductionVariable(inductionSymID, this->currentBlock->loop))\\n         {\\n             if (!isChangedByOne)\\n             {\\n@@ -2246,7 +2265,6 @@ GlobOpt::CollectMemOpInfo(IR::Instr *instrBegin, IR::Instr *instr, Value *src1Va\\n                     {\\n                         inductionVariableChangeInfo.unroll++;\\n                     }\\n-                    \\n                     inductionVariableChangeInfo.isIncremental = isIncr;\\n                     loop->memOpInfo->inductionVariableChangeInfoMap->Item(inductionSymID, inductionVariableChangeInfo);\\n                 }\\n@@ -2284,6 +2302,27 @@ GlobOpt::CollectMemOpInfo(IR::Instr *instrBegin, IR::Instr *instr, Value *src1Va\\n             }\\n         }\\n         NEXT_INSTR_IN_RANGE;\\n+        IR::Instr* prevInstr = instr->m_prev;\\n+\\n+        \/\/ If an instr where the dst is an induction variable (and thus is being written to) is not caught by a case in the above\\n+        \/\/ switch statement (which implies that this instr does not contributes to a inductionVariableChangeInfo) and in the default\\n+        \/\/ case does not set doMemOp to false (which implies that this instr does not invalidate this MemOp), then FailFast as we\\n+        \/\/ should not be performing a MemOp under these conditions. \\n+        AssertOrFailFast(!instr->GetDst() || instr->m_opcode == Js::OpCode::IncrLoopBodyCount || !loop->memOpInfo ||\\n+\\n+            \/\/ Refer to \"Case #2\" described above in this function. For the following IR:\\n+            \/\/ Line #1: s4(s2) = Add_I4 s3(s1) 1\\n+            \/\/ Line #2: s3(s1) = Ld_A   s4(s2)\\n+            \/\/ do not consider line #2 as a violating instr\\n+            (instr->m_opcode == Js::OpCode::Ld_I4 &&\\n+                prevInstr && (prevInstr->m_opcode == Js::OpCode::Add_I4 || prevInstr->m_opcode == Js::OpCode::Sub_I4) &&\\n+                instr->GetSrc1()->IsRegOpnd() &&\\n+                instr->GetDst()->IsRegOpnd() &&\\n+                prevInstr->GetDst()->IsRegOpnd() &&\\n+                instr->GetDst()->GetStackSym() == prevInstr->GetSrc1()->GetStackSym() &&\\n+                instr->GetSrc1()->GetStackSym() == prevInstr->GetDst()->GetStackSym()) ||\\n+\\n+            !loop->memOpInfo->inductionVariableChangeInfoMap->ContainsKey(GetVarSymID(instr->GetDst()->GetStackSym())));\\n     }\\n \\n     return true;'}}",
            "message_norm":"cve-2019-1335",
            "language":"ro",
            "entities":"[('cve-2019-1335', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Backend\/GlobOpt.cpp'])",
            "num_files":1.0
        },
        {
            "index":2146,
            "vuln_id":"GHSA-hwj9-h5mp-3pm3",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734', 'https:\/\/github.com\/postcss\/postcss\/commit\/b6f3e4d5a8d7504d553267f80384373af3a3dec5', 'https:\/\/github.com\/postcss\/postcss\/commit\/8682b1e4e328432ba692bed52326e84439cec9e4'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in postcss The npm package `postcss` from 7.0.0 and before versions 7.0.36 and 8.2.10 is vulnerable to Regular Expression Denial of Service (ReDoS) during source map parsing.",
            "published_date":"2021-05-10",
            "chain_len":3,
            "project":"https:\/\/github.com\/postcss\/postcss",
            "commit_href":"https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734",
            "commit_sha":"54cbf3c4847eb0fb1501b9d2337465439e849734",
            "patch":"MULTI",
            "chain_ord":"['8682b1e4e328432ba692bed52326e84439cec9e4', 'b6f3e4d5a8d7504d553267f80384373af3a3dec5', '54cbf3c4847eb0fb1501b9d2337465439e849734']",
            "before_first_fix_commit":"{'12832f3d203474bd273bd06bd3b2407567bfe09e'}",
            "last_fix_commit":"54cbf3c4847eb0fb1501b9d2337465439e849734",
            "chain_ord_pos":3.0,
            "commit_datetime":"06\/11\/2021, 02:38:48",
            "message":"Backport ReDoS vulnerabilities from PostCSS 8",
            "author":"Andrey Sitnik",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'lib\/previous-map.es6': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/postcss\/postcss\/raw\/54cbf3c4847eb0fb1501b9d2337465439e849734\/lib%2Fprevious-map.es6', 'patch': '@@ -73,12 +73,14 @@ class PreviousMap {\\n \\n   getAnnotationURL (sourceMapString) {\\n     return sourceMapString\\n-      .match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\s*\\\\*\\\\\/\/)[1]\\n+      .match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\\\*\\\\\/\/)[1]\\n       .trim()\\n   }\\n \\n   loadAnnotation (css) {\\n-    let annotations = css.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\s*\\\\*\\\\\/\/mg)\\n+    let annotations = css.match(\\n+      \/\\\\\/\\\\*\\\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\\\*\\\\\/\/gm\\n+    )\\n \\n     if (annotations && annotations.length > 0) {\\n       \/\/ Locate the last sourceMappingURL to avoid picking up'}}",
            "message_norm":"backport redos vulnerabilities from postcss 8",
            "language":"en",
            "entities":"[('redos', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/previous-map.es6'])",
            "num_files":1.0
        },
        {
            "index":1256,
            "vuln_id":"GHSA-8v3j-jfg3-v3fv",
            "cwe_id":"{'CWE-1321'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/balderdashy\/sails\/commit\/7c5379a656bb305c958df1dcc2b51a9668830358'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in Sails.js Sails.js <= 1.5.2 is vulnerable to Prototype Pollution via controller\/load-action-modules.js, function loadActionModules(). A [patch](https:\/\/github.com\/balderdashy\/sails\/commit\/7c5379a656bb305c958df1dcc2b51a9668830358) is available in the `master` branch of Sails.js's GItHub repository.",
            "published_date":"2022-03-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/balderdashy\/sails",
            "commit_href":"https:\/\/github.com\/balderdashy\/sails\/commit\/7c5379a656bb305c958df1dcc2b51a9668830358",
            "commit_sha":"7c5379a656bb305c958df1dcc2b51a9668830358",
            "patch":"SINGLE",
            "chain_ord":"['7c5379a656bb305c958df1dcc2b51a9668830358']",
            "before_first_fix_commit":"{'06ce9cfbe6533734879079e02b0ef7b62f9ce31b'}",
            "last_fix_commit":"7c5379a656bb305c958df1dcc2b51a9668830358",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/18\/2022, 22:07:29",
            "message":"closes https:\/\/github.com\/balderdashy\/sails\/issues\/7209",
            "author":"Mike McNeil",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'docs\/reference\/application\/advanced-usage\/sails.reloadActions.md': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/balderdashy\/sails\/raw\/7c5379a656bb305c958df1dcc2b51a9668830358\/docs%2Freference%2Fapplication%2Fadvanced-usage%2Fsails.reloadActions.md', 'patch': '@@ -25,6 +25,9 @@ This method is useful primarily in development scenarios.\\n | 1 |      _options_      | ((dictionary?))          | Currently accepts one key, `hooksToSkip`, which if given should be an array of names of hooks that should _not_ call their `reloadActions` method.\\n | 2 |      _callback_              | ((function)) | A callback to be called with the virtual response.\\n \\n+### Notes\\n+> - Never dynamically replace your Sails.js controller or action files on disk with untrusted code at runtime, regardless of whether you are using `.reloadActions()` in your app or not.  Since `reloadActions()` runs the code in your Sails.js app\\'s files, if the files are not safe to run, then using `reloadActions()` would be [a security risk](https:\/\/github.com\/balderdashy\/sails\/issues\/7209).  This risk is only present if your Sails app is deliberately overwriting its own files to replace them with unsafe code.\\n+\\n \\n <docmeta name=\"displayName\" value=\"sails.reloadActions()\">\\n <docmeta name=\"pageType\" value=\"method\">'}}",
            "message_norm":"closes https:\/\/github.com\/balderdashy\/sails\/issues\/7209",
            "language":"es",
            "entities":"[('https:\/\/github.com\/balderdashy\/sails\/issues\/7209', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['docs\/reference\/application\/advanced-usage\/sails.reloadActions.md'])",
            "num_files":1.0
        },
        {
            "index":439,
            "vuln_id":"GHSA-4j82-5ccr-4r8v",
            "cwe_id":"{'CWE-617'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c2426bba00a01de6913738df8fa78e0215fcce02'}",
            "dataset":"osv",
            "summary":"`CHECK`-failures in `TensorByteSize` in Tensorflow ### Impact\nA malicious user can cause a denial of service by altering a `SavedModel` such that [`TensorByteSize`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/attr_value_util.cc#L46-L50) would trigger `CHECK` failures.\n\n```cc\nint64_t TensorByteSize(const TensorProto& t) {\n  \/\/ num_elements returns -1 if shape is not fully defined.\n  int64_t num_elems = TensorShape(t.tensor_shape()).num_elements();\n  return num_elems < 0 ? -1 : num_elems * DataTypeSize(t.dtype());\n}\n```\n`TensorShape` constructor throws a `CHECK`-fail if shape is partial or has a number of elements that would overflow the size of an `int`. The `PartialTensorShape` constructor instead does not cause a `CHECK`-abort if the shape is partial, which is exactly what this function needs to be able to return `-1`.\n\n### Patches\nWe have patched the issue in GitHub commit [c2426bba00a01de6913738df8fa78e0215fcce02](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c2426bba00a01de6913738df8fa78e0215fcce02).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c2426bba00a01de6913738df8fa78e0215fcce02",
            "commit_sha":"c2426bba00a01de6913738df8fa78e0215fcce02",
            "patch":"SINGLE",
            "chain_ord":"['c2426bba00a01de6913738df8fa78e0215fcce02']",
            "before_first_fix_commit":"{'31d8f8035f559fc6f03516f18ca3afea652d69b0'}",
            "last_fix_commit":"c2426bba00a01de6913738df8fa78e0215fcce02",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/11\/2021, 19:50:53",
            "message":"Use `PartialTensorShape` instead of `TensorShape`.\n\n`TensorShape` constructor throws a CHECK-fail if shape is partial\/overflows which the other doesn't. We are only determining the number of elements in the shape and partial shape should be used as it returns negative number when needed.\n\nPiperOrigin-RevId: 409205384\nChange-Id: Ia56542ff9ec758f2c9ffc7e4dcc9fa7eecd86e7b",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'tensorflow\/core\/framework\/attr_value_util.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c2426bba00a01de6913738df8fa78e0215fcce02\/tensorflow%2Fcore%2Fframework%2Fattr_value_util.cc', 'patch': '@@ -45,7 +45,7 @@ constexpr int kMaxTensorNestDepth = 100;\\n \/\/ not fully defined return -1.\\n int64_t TensorByteSize(const TensorProto& t) {\\n   \/\/ num_elements returns -1 if shape is not fully defined.\\n-  int64_t num_elems = TensorShape(t.tensor_shape()).num_elements();\\n+  int64_t num_elems = PartialTensorShape(t.tensor_shape()).num_elements();\\n   return num_elems < 0 ? -1 : num_elems * DataTypeSize(t.dtype());\\n }'}}",
            "message_norm":"use `partialtensorshape` instead of `tensorshape`.\n\n`tensorshape` constructor throws a check-fail if shape is partial\/overflows which the other doesn't. we are only determining the number of elements in the shape and partial shape should be used as it returns negative number when needed.\n\npiperorigin-revid: 409205384\nchange-id: ia56542ff9ec758f2c9ffc7e4dcc9fa7eecd86e7b",
            "language":"en",
            "entities":"[('overflows', 'SECWORD', ''), ('409205384', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/attr_value_util.cc'])",
            "num_files":1.0
        },
        {
            "index":2095,
            "vuln_id":"GHSA-hm45-mgqm-gjm4",
            "cwe_id":"{'CWE-79'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/commit\/a6b9785338003ec87fb75305e7d1cc2d40c7ab91', 'https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/commit\/99d88b840674674166ce005b784ae8e31e955ab1'}",
            "dataset":"osv",
            "summary":"Remote Code Execution (RCE) Exploit on Cross Site Scripting (XSS) Vulnerability ### Impact\nA RCE exploit has been discovered in the Red Discord Bot - Dashboard Webserver: this exploit allows Discord users with specially crafted Server names and Usernames\/Nicknames to inject code into the webserver front-end code.  By abusing this exploit, it's possible to perform destructive actions and\/or access sensitive information.\n\n### Patches\nThis high severity exploit has been fixed on version `0.1.7a`.\n\n### Workarounds\nThere are no workarounds, bot owners must upgrade their relevant packages (Dashboard module and Dashboard webserver) in order to patch this issue\n\n### References\n- 99d88b8\n- a6b9785\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Cog-Creators\/Red-Dashboard](https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/issues\/new\/choose)\n* Over on the official [Red Server](https:\/\/discord.gg\/red) or at the Third Party Server [Toxic Layer](https:\/\/discord.gg\/vQZTdB9)",
            "published_date":"2020-12-08",
            "chain_len":2,
            "project":"https:\/\/github.com\/Cog-Creators\/Red-Dashboard",
            "commit_href":"https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/commit\/99d88b840674674166ce005b784ae8e31e955ab1",
            "commit_sha":"99d88b840674674166ce005b784ae8e31e955ab1",
            "patch":"MULTI",
            "chain_ord":"['99d88b840674674166ce005b784ae8e31e955ab1', 'a6b9785338003ec87fb75305e7d1cc2d40c7ab91']",
            "before_first_fix_commit":"{'261f00f52bbfee4db67f624fd7409bf08124a6c4'}",
            "last_fix_commit":"a6b9785338003ec87fb75305e7d1cc2d40c7ab91",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/30\/2020, 11:49:18",
            "message":"Fix unformatted HTML",
            "author":"NeuroAssassin",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 2, 'total': 8}",
            "files":"{'reddash\/app\/home\/templates\/dashboard.html': {'additions': 6, 'deletions': 2, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/raw\/99d88b840674674166ce005b784ae8e31e955ab1\/reddash%2Fapp%2Fhome%2Ftemplates%2Fdashboard.html', 'patch': '@@ -72,6 +72,7 @@ <h1>{{ _(\\'Loading servers...\\') }}<\/h1>\\n                 } else {\\r\\n                     var base_guild_url = \"{{ url_for(\\'home_blueprint.guild\\', guild=\\'123456789123456789\\') }}\"\\r\\n                     $(\"#serverrow\").html(\"\")\\r\\n+                    let counter = 0\\r\\n                     for (let g of json.data) {\\r\\n                         var current_guild_url = base_guild_url.replace(\"123456789123456789\", g.id)\\r\\n                         $(\"#serverrow\").append(`\\r\\n@@ -80,13 +81,16 @@ <h1>{{ _(\\'Loading servers...\\') }}<\/h1>\\n                                     <div class=\"card h-100\" onmouseover=\"playGif(this)\" onmouseout=\"stopGif(this)\">\\r\\n                                         <img class=\"card-img-top\" src=\"${g.icon}png\" alt=\"Card image cap\" data-src-url=\"${g.icon}\" data-is-animated=${g.animated}>\\r\\n                                         <div class=\"card-body\">\\r\\n-                                            <h5 class=\"card-title\">${g.name}<\/h5>\\r\\n-                                            <p class=\"card-text\">Owner: ${g.owner}<\/p>\\r\\n+                                            <h5 class=\"card-title\" id=\"guild-counter-${counter}\">Loading...<\/h5>\\r\\n+                                            <p class=\"card-text\" id=\"owner-counter-${counter}\">Owner: Loading...<\/p>\\r\\n                                         <\/div>\\r\\n                                     <\/div>\\r\\n                                 <\/a>\\r\\n                             <\/div>\\r\\n                         `)\\r\\n+                        $(`#guild-counter-${counter}`).text(g.name)\\r\\n+                        $(`#owner-counter-${counter}`).text(g.owner)\\r\\n+                        counter += 1\\r\\n                     }\\r\\n                 }\\r\\n             }'}}",
            "message_norm":"fix unformatted html",
            "language":"en",
            "entities":"[('fix', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['reddash\/app\/home\/templates\/dashboard.html'])",
            "num_files":1.0
        },
        {
            "index":2185,
            "vuln_id":"GHSA-j47c-j42c-mwqq",
            "cwe_id":"{'CWE-670'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/solana-labs\/solana-pay\/commit\/ac6ce0d0a81137700874a8bf5a7caac3be999fad'}",
            "dataset":"osv",
            "summary":"Solana Pay Vulnerable to Weakness in Transfer Validation Logic ### Description\nWhen a Solana Pay transaction is located using a [reference key](https:\/\/github.com\/solana-labs\/solana-pay\/blob\/master\/SPEC.md#reference), it may be checked to represent a transfer of the desired amount to the recipient, using the supplied [`validateTransfer` function](https:\/\/github.com\/solana-labs\/solana-pay\/blob\/master\/core\/src\/validateTransfer.ts). An edge case regarding this mechanism could cause the validation logic to validate multiple transfers.\n\n### Impact\nMost known Solana Pay point of sale applications are currently run on physical point of sale devices, which makes this issue unlikely to occur. However, there may be web-based point of sale applications using the protocol where it may be more likely to occur.\n\n### Patches\nThis issue has been patched as of version [`0.2.1`](https:\/\/www.npmjs.com\/package\/@solana\/pay\/v\/0.2.1). Users of the Solana Pay SDK should upgrade to it.",
            "published_date":"2022-08-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/solana-labs\/solana-pay",
            "commit_href":"https:\/\/github.com\/solana-labs\/solana-pay\/commit\/ac6ce0d0a81137700874a8bf5a7caac3be999fad",
            "commit_sha":"ac6ce0d0a81137700874a8bf5a7caac3be999fad",
            "patch":"SINGLE",
            "chain_ord":"['ac6ce0d0a81137700874a8bf5a7caac3be999fad']",
            "before_first_fix_commit":"{'f41701dc7931f7882c6eb0582c9ddd796eb9d3aa'}",
            "last_fix_commit":"ac6ce0d0a81137700874a8bf5a7caac3be999fad",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/28\/2022, 17:15:33",
            "message":"finish transfer validation implementation",
            "author":"Jordan Sexton",
            "comments":null,
            "stats":"{'additions': 60, 'deletions': 18, 'total': 78}",
            "files":"{'core\/src\/validateTransfer.ts': {'additions': 60, 'deletions': 18, 'changes': 78, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/solana-labs\/solana-pay\/raw\/ac6ce0d0a81137700874a8bf5a7caac3be999fad\/core%2Fsrc%2FvalidateTransfer.ts', 'patch': \"@@ -1,15 +1,23 @@\\n-import { getAssociatedTokenAddress } from '@solana\/spl-token';\\n+import {\\n+    decodeInstruction,\\n+    getAssociatedTokenAddress,\\n+    isTransferCheckedInstruction,\\n+    isTransferInstruction,\\n+} from '@solana\/spl-token';\\n import {\\n     ConfirmedTransactionMeta,\\n     Connection,\\n     Finality,\\n     LAMPORTS_PER_SOL,\\n     Message,\\n+    SystemInstruction,\\n+    Transaction,\\n     TransactionResponse,\\n     TransactionSignature,\\n } from '@solana\/web3.js';\\n import BigNumber from 'bignumber.js';\\n-import { Amount, Memo, Recipient, References, SPLToken } from '.\/types';\\n+import { MEMO_PROGRAM_ID } from '.\/constants';\\n+import { Amount, Memo, Recipient, Reference, References, SPLToken } from '.\/types';\\n \\n \/**\\n  * Thrown when a transaction doesn't contain a valid Solana Pay transfer.\\n@@ -58,33 +66,49 @@ export async function validateTransfer(\\n     if (!meta) throw new ValidateTransferError('missing meta');\\n     if (meta.err) throw meta.err;\\n \\n-    const [preAmount, postAmount] = splToken\\n-        ? await validateSPLTokenTransfer(message, meta, recipient, splToken)\\n-        : await validateSystemTransfer(message, meta, recipient);\\n+    if (reference && !Array.isArray(reference)) {\\n+        reference = [reference];\\n+    }\\n \\n+    const [preAmount, postAmount] = splToken\\n+        ? await validateSPLTokenTransfer(message, meta, recipient, splToken, reference)\\n+        : await validateSystemTransfer(message, meta, recipient, reference);\\n     if (postAmount.minus(preAmount).lt(amount)) throw new ValidateTransferError('amount not transferred');\\n \\n-    if (reference) {\\n-        if (!Array.isArray(reference)) {\\n-            reference = [reference];\\n-        }\\n-\\n-        for (const pubkey of reference) {\\n-            if (!message.accountKeys.some((accountKey) => accountKey.equals(pubkey)))\\n-                throw new ValidateTransferError('reference not found');\\n-        }\\n+    if (memo) {\\n+        \/\/ Check that the second instruction is a memo instruction with the expected memo.\\n+        const transaction = Transaction.populate(message);\\n+        const instruction = transaction.instructions[1];\\n+        if (!instruction) throw new ValidateTransferError('missing memo instruction');\\n+        if (!instruction.programId.equals(MEMO_PROGRAM_ID)) throw new ValidateTransferError('invalid memo program');\\n+        if (!instruction.data.equals(Buffer.from(memo, 'utf8'))) throw new ValidateTransferError('invalid memo');\\n     }\\n \\n-    \/\/ FIXME: add memo check\\n-\\n     return response;\\n }\\n \\n async function validateSystemTransfer(\\n     message: Message,\\n     meta: ConfirmedTransactionMeta,\\n-    recipient: Recipient\\n+    recipient: Recipient,\\n+    references?: Reference[]\\n ): Promise<[BigNumber, BigNumber]> {\\n+    if (references) {\\n+        \/\/ Check that the first instruction is a system transfer instruction.\\n+        const transaction = Transaction.populate(message);\\n+        const instruction = transaction.instructions[0];\\n+        SystemInstruction.decodeTransfer(instruction);\\n+\\n+        \/\/ Check that the expected reference keys exactly match the extra keys provided to the instruction.\\n+        const [_from, _to, ...extraKeys] = instruction.keys;\\n+        const length = extraKeys.length;\\n+        if (length !== references.length) throw new ValidateTransferError('invalid references');\\n+\\n+        for (let i = 0; i < length; i++) {\\n+            if (!extraKeys[i].pubkey.equals(references[i])) throw new ValidateTransferError(`invalid reference ${i}`);\\n+        }\\n+    }\\n+\\n     const accountIndex = message.accountKeys.findIndex((pubkey) => pubkey.equals(recipient));\\n     if (accountIndex === -1) throw new ValidateTransferError('recipient not found');\\n \\n@@ -98,8 +122,26 @@ async function validateSPLTokenTransfer(\\n     message: Message,\\n     meta: ConfirmedTransactionMeta,\\n     recipient: Recipient,\\n-    splToken: SPLToken\\n+    splToken: SPLToken,\\n+    references?: Reference[]\\n ): Promise<[BigNumber, BigNumber]> {\\n+    if (references) {\\n+        \/\/ Check that the first instruction is an SPL token transfer instruction.\\n+        const transaction = Transaction.populate(message);\\n+        const instruction = decodeInstruction(transaction.instructions[0]);\\n+        if (!isTransferCheckedInstruction(instruction) && !isTransferInstruction(instruction))\\n+            throw new ValidateTransferError('invalid transfer');\\n+\\n+        \/\/ Check that the expected reference keys exactly match the extra keys provided to the instruction.\\n+        const extraKeys = instruction.keys.multiSigners;\\n+        const length = extraKeys.length;\\n+        if (length !== references.length) throw new ValidateTransferError('invalid references');\\n+\\n+        for (let i = 0; i < length; i++) {\\n+            if (!extraKeys[i].pubkey.equals(references[i])) throw new ValidateTransferError(`invalid reference ${i}`);\\n+        }\\n+    }\\n+\\n     const recipientATA = await getAssociatedTokenAddress(splToken, recipient);\\n     const accountIndex = message.accountKeys.findIndex((pubkey) => pubkey.equals(recipientATA));\\n     if (accountIndex === -1) throw new ValidateTransferError('recipient not found');\"}}",
            "message_norm":"finish transfer validation implementation",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/src\/validateTransfer.ts'])",
            "num_files":1.0
        },
        {
            "index":1624,
            "vuln_id":"GHSA-cwfw-4gq5-mrqx",
            "cwe_id":"{'CWE-400'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/micromatch\/braces\/commit\/abdafb0cae1e0c00f184abbadc692f4eaa98f451'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service (ReDoS) in braces A vulnerability was found in Braces versions prior to 2.3.1. Affected versions of this package are vulnerable to Regular Expression Denial of Service (ReDoS) attacks.",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/micromatch\/braces",
            "commit_href":"https:\/\/github.com\/micromatch\/braces\/commit\/abdafb0cae1e0c00f184abbadc692f4eaa98f451",
            "commit_sha":"abdafb0cae1e0c00f184abbadc692f4eaa98f451",
            "patch":"SINGLE",
            "chain_ord":"['abdafb0cae1e0c00f184abbadc692f4eaa98f451']",
            "before_first_fix_commit":"{'37934142c1aeea48b6fb03edbdcf90e45b5cb4a1'}",
            "last_fix_commit":"abdafb0cae1e0c00f184abbadc692f4eaa98f451",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/16\/2018, 21:09:36",
            "message":"optimize regex",
            "author":"jonschlinkert",
            "comments":"{'com_1': {'author': 'sathish-spidie', 'datetime': '04\/18\/2019, 03:42:11', 'body': \"can you explain, how to achieve this? I'm a low-level developer and didn't understand why this code stands for and what to do with it! sorry if I waste your time by making you read this comment, in case you find this comment useless.\\r\\n\\r\\nmy error is\\r\\n\\r\\n` Low             Regular Expression Denial of Service                          \\r\\n                                                                                \\r\\n  Package         braces                                                        \\r\\n                                                                                \\r\\n  Patched in      >=2.3.1                                                       \\r\\n                                                                                \\r\\n  Dependency of   browser-sync [dev]                                            \\r\\n                                                                                \\r\\n  Path            browser-sync > micromatch > braces                            \\r\\n                                                                                \\r\\n  More info       https:\/\/npmjs.com\/advisories\/786         `\"}, 'com_2': {'author': 'kousu', 'datetime': '04\/18\/2019, 18:24:04', 'body': '@sathish-spidie , you can find out the solution on the link there: https:\/\/npmjs.com\/advisories\/786:\\r\\n\\r\\n> Remediation\\r\\n> \\r\\n> Upgrade to version 2.3.1 or higher.\\r\\n\\r\\nWhat this means is that in your package.json you should make sure the line for \"braces\" under \"dependencies\"  says\\r\\n\\r\\n```\\r\\n\"braces\": \"^2.3.1\",\\r\\n```\\r\\n\\r\\nand then delete your cached npm packages by \\r\\n\\r\\n```\\r\\nrm -r node_modules\/ package-lock.json\\r\\n```\\r\\n\\r\\nand then\\r\\n\\r\\n```\\r\\nnpm install\\r\\n```\\r\\n\\r\\n---\\r\\n\\r\\nIf you don\\'t directly depend on \"braces\", which is the situation I am in, you can use\\r\\n\\r\\n```\\r\\nnpm list\\r\\n```\\r\\n\\r\\nto figure out which of your packages is depending on \"braces\", and then go make sure to update each of those packages in the same way: version bump them, make sure to prefix the versions of everything with \"^\", and then delete your packages and regenerate package-lock.json by redoing `npm install`; that will get the latest, hopefully bugfixed, versions of all your packages; but if any of your packages have not yet updated to use `\"braces\": \"^2.3.1\"` then you will have to go to their github projects and file an issue. \\r\\n\\r\\n---\\r\\n\\r\\nA comment on a commit inside the braces project isn\\'t really a proper general support forum for npm. For that, and for future questions, you will probably have good luck asking at https:\/\/npm.community\/c\/support.  I hope the above helps and lets you extend your developer skills.'}, 'com_3': {'author': 'jonschlinkert', 'datetime': '04\/18\/2019, 20:01:13', 'body': \"@kousu that was a fantastic description, and a really good summary of the steps that need to be taken. Thank you!\\r\\n\\r\\n> you will probably have good luck asking at https:\/\/npm.community\/c\/support. I hope the above helps and lets you extend your developer skills.\\r\\n\\r\\nOnly one thing I'd like to point out. Generally, https:\/\/npm.community\/c\/support is for **NPM** support, not for packages like this one. Meaning, if you need something directly related to the package manager itself, that's the place to go. But ideally, when a user has an issue or support question like this, the best place to get answers is to:\\r\\n\\r\\n1. read through previous issues first - @sathish-spidie would have seen that this question has been answered a couple of dozen times already on this project and other projects that depend on this one\\r\\n1. StackOverflow - people get reputation points for helping others\\r\\n1. if it seems like no one has addressed the issue already, and you have genuinely stumbled across a previously undiscovered bug, then create a new issue on the GitHub repository of the code project.\"}, 'com_4': {'author': 'KevinGrant12', 'datetime': '05\/08\/2019, 23:49:41', 'body': \"Hello, I have the same exact issue that stems from babel.\\r\\nI was unable to run this line rm -r node_modules\/ package-lock.json and it makes sense because the packag-lock is not inside the node_modules directory.\\r\\nWhen I run npm list I can see that instances of 'braces' are at 2.3.2.\\r\\n\\r\\nAny thoughts on how to fix?\\r\\nThanks!\"}, 'com_5': {'author': 'biggianteye', 'datetime': '06\/07\/2019, 12:57:09', 'body': \"> I was unable to run this line rm -r node_modules\/ package-lock.json and it makes sense because the packag-lock is not inside the node_modules directory.\\r\\n\\r\\nThere is a space between `node_modules` and `package-lock.json`. The lock file is not inside the node_modules folder. It's at the same level.\"}, 'com_6': {'author': 'robpl1', 'datetime': '07\/14\/2019, 08:57:18', 'body': 'The problem I have here is that the braces package itself is showing \\r\\n{  \"_from\": \"braces@^1.8.2\",\\r\\n  \"_id\": \"braces@1.8.5\",\\r\\n\\r\\nSo how to update that would help.'}, 'com_7': {'author': 'martynawilkonska', 'datetime': '07\/16\/2019, 08:45:50', 'body': 'I have the same problem. I am unable to update braces, after reinstall they are still 1.8.5.'}, 'com_8': {'author': 'janzenz', 'datetime': '10\/08\/2019, 02:02:12', 'body': \"@martynawilkonska have you removed your `node_modules` cache and `package-lock.json` file? If not, try that and `npm install` again. If it still does that, my next hunch is that you're `braces` is a transitive dependency in your package. Try `npm ls braces` and see which package requires it and maybe you can try and upgrade that parent package which potentially will fix your problem.\"}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/parsers.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/micromatch\/braces\/raw\/abdafb0cae1e0c00f184abbadc692f4eaa98f451\/lib%2Fparsers.js', 'patch': \"@@ -127,7 +127,7 @@ module.exports = function(braces, options) {\\n     .set('multiplier', function() {\\n       var isInside = this.isInside('brace');\\n       var pos = this.position();\\n-      var m = this.match(\/^\\\\{(,+(?:(\\\\{,+\\\\})*),*|,*(?:(\\\\{,+\\\\})*),+)\\\\}\/);\\n+      var m = this.match(\/^\\\\{((?:,|\\\\{,+\\\\})+)\\\\}\/);\\n       if (!m) return;\\n \\n       this.multiplier = true;\"}}",
            "message_norm":"optimize regex",
            "language":"ro",
            "entities":"[('optimize', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/parsers.js'])",
            "num_files":1.0
        },
        {
            "index":341,
            "vuln_id":"GHSA-437j-5qc3-c589",
            "cwe_id":"{'CWE-601'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/187e949daf7dea6f10b80da70988f0f86444eeff'}",
            "dataset":"osv",
            "summary":"Open Redirect in microweber Open Redirect in GitHub repository microweber\/microweber prior to 1.2.19.",
            "published_date":"2022-06-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/187e949daf7dea6f10b80da70988f0f86444eeff",
            "commit_sha":"187e949daf7dea6f10b80da70988f0f86444eeff",
            "patch":"SINGLE",
            "chain_ord":"['187e949daf7dea6f10b80da70988f0f86444eeff']",
            "before_first_fix_commit":"{'e6361e9fdcaaf2b27fb664beaa2fb33d46e3542e'}",
            "last_fix_commit":"187e949daf7dea6f10b80da70988f0f86444eeff",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/29\/2022, 15:14:26",
            "message":"update",
            "author":"Peter Ivanov",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'src\/MicroweberPackages\/Helper\/UrlManager.php': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/187e949daf7dea6f10b80da70988f0f86444eeff\/src%2FMicroweberPackages%2FHelper%2FUrlManager.php', 'patch': \"@@ -105,7 +105,15 @@ public function redirect($url)\\n \\n         $redirectUrl = site_url();\\n         $parseUrl = parse_url($url);\\n+\\n         if (isset($parseUrl['host'])) {\\n+            if(isset($parseUrl['user']) and $parseUrl['user']){\\n+                return \\\\Redirect::to(site_url());\\n+            }\\n+\\n+            if(isset($parseUrl['pass']) and $parseUrl['pass']){\\n+                return \\\\Redirect::to(site_url());\\n+            }\\n             if ($parseUrl['host'] == site_hostname()) {\\n                 $redirectUrl = $url;\\n             }\"}}",
            "message_norm":"update",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/Helper\/UrlManager.php'])",
            "num_files":1.0
        },
        {
            "index":852,
            "vuln_id":"GHSA-6j89-jhpr-849f",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/3fe5e24694729966a157dc613f5586a6c75f1e9b', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1308, CVE-2019-1335, CVE-2019-1366.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/3fe5e24694729966a157dc613f5586a6c75f1e9b",
            "commit_sha":"3fe5e24694729966a157dc613f5586a6c75f1e9b",
            "patch":"MULTI",
            "chain_ord":"['3fe5e24694729966a157dc613f5586a6c75f1e9b', 'cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d']",
            "before_first_fix_commit":"{'7e9a2ee60baa95ceb4f48f522f823c812ca90c80', '5989c6e038d80f92dcd8e10d725cdf45396201bb'}",
            "last_fix_commit":"cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/03\/2019, 19:26:32",
            "message":"CVE-2019-1307",
            "author":"Paul Leathers",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'lib\/Backend\/GlobOpt.h': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/3fe5e24694729966a157dc613f5586a6c75f1e9b\/lib%2FBackend%2FGlobOpt.h', 'patch': '@@ -370,6 +370,7 @@ class JsArrayKills\\n             (valueType.IsArrayOrObjectWithArray() &&\\n              (\\n               (killsArraysWithNoMissingValues && valueType.HasNoMissingValues()) ||\\n+              (killsObjectArraysWithNoMissingValues && !valueType.IsArray() && valueType.HasNoMissingValues()) ||\\n               (killsNativeArrays && !valueType.HasVarElements())\\n              )\\n             );'}}",
            "message_norm":"cve-2019-1307",
            "language":"ro",
            "entities":"[('cve-2019-1307', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Backend\/GlobOpt.h'])",
            "num_files":1.0
        },
        {
            "index":848,
            "vuln_id":"GHSA-6hjc-m38h-7jhh",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/4e46b792ce973ac0c652fb330055f41aca1981c8', 'https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in SEOmatic plugin A cross-site scripting (XSS) vulnerability in the SEOmatic plugin 3.4.10 for Craft CMS 3 allows remote attackers to inject arbitrary web script via a GET to \/index.php?action=seomatic\/file\/seo-file-link with url parameter containing the base64 encoded URL of a malicious web page \/ file and fileName parameter containing an arbitrary filename with the intended content-type to be rendered in the user's browser as the extension.",
            "published_date":"2022-06-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/nystudio107\/craft-seomatic",
            "commit_href":"https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/4e46b792ce973ac0c652fb330055f41aca1981c8",
            "commit_sha":"4e46b792ce973ac0c652fb330055f41aca1981c8",
            "patch":"MULTI",
            "chain_ord":"['5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873', '4e46b792ce973ac0c652fb330055f41aca1981c8']",
            "before_first_fix_commit":"{'8c0dc48d026fd076cd0a8fae917bdadc8d67cfa6'}",
            "last_fix_commit":"4e46b792ce973ac0c652fb330055f41aca1981c8",
            "chain_ord_pos":2.0,
            "commit_datetime":"09\/24\/2021, 15:01:54",
            "message":"Disallow SVGs",
            "author":"Andrew Welch",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/controllers\/FileController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nystudio107\/craft-seomatic\/raw\/4e46b792ce973ac0c652fb330055f41aca1981c8\/src%2Fcontrollers%2FFileController.php', 'patch': \"@@ -96,7 +96,7 @@ public function actionSeoFileLink($url, $robots = '', $canonical = '', $inline =\\n             if (($ext = pathinfo($fileName, PATHINFO_EXTENSION)) !== '') {\\n                 $ext = strtolower($ext);\\n             }\\n-            if ($ext === '' || !in_array($ext, $allowedExtensions, true)) {\\n+            if ($ext === '' || $ext === 'svg' || !in_array($ext, $allowedExtensions, true)) {\\n                 throw new ServerErrorHttpException(Craft::t('seomatic', 'File format not allowed.'));\\n             }\\n             \/\/ Send the file as a stream, so it can exist anywhere\"}}",
            "message_norm":"disallow svgs",
            "language":"it",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/controllers\/FileController.php'])",
            "num_files":1.0
        },
        {
            "index":2643,
            "vuln_id":"GHSA-pv4c-p2j5-38j4",
            "cwe_id":"{'CWE-425'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/unshiftio\/url-parse\/commit\/d7b582ec1243e8024e60ac0b62d2569c939ef5de', 'https:\/\/github.com\/unshiftio\/url-parse\/commit\/53b1794e54d0711ceb52505e0f74145270570d5a'}",
            "dataset":"osv",
            "summary":"Open Redirect in url-parse Versions of `url-parse` before 1.4.3 returns the wrong hostname which could lead to Open Redirect, Server Side Request Forgery (SSRF), or Bypass Authentication Protocol vulnerabilities.\n\n\n## Recommendation\n\nUpdate to version 1.4.3 or later.",
            "published_date":"2018-08-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/unshiftio\/url-parse",
            "commit_href":"https:\/\/github.com\/unshiftio\/url-parse\/commit\/d7b582ec1243e8024e60ac0b62d2569c939ef5de",
            "commit_sha":"d7b582ec1243e8024e60ac0b62d2569c939ef5de",
            "patch":"MULTI",
            "chain_ord":"['53b1794e54d0711ceb52505e0f74145270570d5a', 'd7b582ec1243e8024e60ac0b62d2569c939ef5de']",
            "before_first_fix_commit":"{'53b1794e54d0711ceb52505e0f74145270570d5a'}",
            "last_fix_commit":"d7b582ec1243e8024e60ac0b62d2569c939ef5de",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/29\/2018, 12:42:38",
            "message":"[security] Added missing SECURITY.md",
            "author":"Arnout Kazemier",
            "comments":"{'com_1': {'author': 'lpinca', 'datetime': '07\/29\/2018, 13:18:42', 'body': 'The open redirect vulnerability is not fixed.'}, 'com_2': {'author': '3rd-Eden', 'datetime': '07\/29\/2018, 18:01:14', 'body': \"Right, I just copy and pasted this from the reported issue. I can change it, and add a security section to the README and warn people to not bluntly accept user-input as valid URL's.\"}, 'com_3': {'author': 'lirantal', 'datetime': '07\/30\/2018, 08:19:29', 'body': \"@3rd-Eden that's really awesome that you're adding this!\\r\\nWe have a template over at the security-wg repo (https:\/\/github.com\/nodejs\/security-wg\/blob\/master\/processes\/responsible_disclosure_template.md) that I'd be happy to work with you on to improve with references to what you've also added here. \\r\\n\\r\\nYou may also add a security badge to raise awareness:\\r\\n[![Security Responsible Disclosure](https:\/\/img.shields.io\/badge\/Security-Responsible%20Disclosure-yellow.svg)](https:\/\/github.com\/nodejs\/security-wg\/blob\/master\/processes\/responsible_disclosure_template.md\\r\\n)\"}, 'com_4': {'author': 'SegfaultMasters', 'datetime': '09\/03\/2018, 06:26:18', 'body': 'Though it replaced double slash, one can still perform open-redirect using encoded format \"%5c%5c\"\\r\\nHere\\'s the testcase \\r\\n```\\r\\n\\'use strict\\';\\r\\nvar URL = require(\\'url-parse\\');\\r\\nvar url = new URL(\\'http:\/\/google.com:80%5c%5cyahoo.com\/\/#what\\\\\\\\is going on\\');\\r\\nconsole.log(url.hostname);\\r\\n```'}, 'com_5': {'author': 'lirantal', 'datetime': '09\/05\/2018, 19:49:45', 'body': '@SegfaultMasters would you be able to submit a vuln repot on the HackerOne platform with the details?'}}",
            "stats":"{'additions': 47, 'deletions': 0, 'total': 47}",
            "files":"{'SECURITY.md': {'additions': 47, 'deletions': 0, 'changes': 47, 'status': 'added', 'raw_url': 'https:\/\/github.com\/unshiftio\/url-parse\/raw\/d7b582ec1243e8024e60ac0b62d2569c939ef5de\/SECURITY.md', 'patch': \"@@ -0,0 +1,47 @@\\n+# Security Guidelines\\n+\\n+Please contact us directly at **security@3rd-Eden.com** for any bug that might\\n+impact the security of this project. Please prefix the subject of your email\\n+with `[security]` in lowercase and square brackets. Our email filters will\\n+automatically prevent these messages from being moved to our spam box. All\\n+emails that do not include security vulnerabilities will be removed and blocked\\n+instantly.\\n+\\n+In addition to a dedicated email address to receive security related reports,\\n+we also have a [Hacker1 account][hacker1] that can be used be used for\\n+communicating security related issues.\\n+\\n+You will receive an acknowledgement of your report within **24 hours** of\\n+notification.\\n+\\n+## Exceptions\\n+\\n+If you do not receive an acknowledgement within the said time frame please give\\n+us the benefit of the doubt as it's possible that we haven't seen it yet. In\\n+this case please send us a message **without details** using one of the\\n+following methods:\\n+\\n+- Give a poke on Twitter [@3rdEden](https:\/\/twitter.com\/3rdEden)\\n+- Contact the lead developers of this project on their personal e-mails. You\\n+  can find the e-mails in the git logs, for example using the following command:\\n+  `git --no-pager show -s --format='%an <%ae>' <gitsha>` where `<gitsha>` is the\\n+  SHA1 of their latest commit in the project.\\n+\\n+Once we have acknowledged receipt of your report and confirmed the bug\\n+ourselves we will work with you to fix the vulnerability and publicly\\n+acknowledge your responsible disclosure, if you wish.\\n+\\n+## History\\n+\\n+> url-parse returns wrong hostname which leads to multiple vulnerabilities such\\n+> as SSRF, Open Redirect, Bypass Authentication Protocol.\\n+\\n+- Hacker1 report: https:\/\/hackerone.com\/reports\/384029\\n+- Reported by [lolwaleet](https:\/\/hackerone.com\/lolwalee)\\n+- Triaged by [Liran Tal](https:\/\/hackerone.com\/lirantal)\\n+- Fixed in: 1.4.3\\n+\\n+---\\n+\\n+[twitter]: https:\/\/twitter.com\/3rdEden\\n+[hacker1]: https:\/\/hackerone.com\/3rdeden\"}}",
            "message_norm":"[security] added missing security.md",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('added', 'ACTION', ''), ('security.md', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['SECURITY.md'])",
            "num_files":1.0
        },
        {
            "index":102,
            "vuln_id":"GHSA-2hxv-mx8x-mcj9",
            "cwe_id":"{'CWE-352'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/denkGroot\/Spina\/commit\/bfe44f289e336f80b6593032679300c493735e75'}",
            "dataset":"osv",
            "summary":"Spina vulnerable to a cross-site request forgery (CSRF) vulnerability Cross-site request forgery (CSRF) vulnerability in Spina before commit bfe44f289e336f80b6593032679300c493735e75.",
            "published_date":"2018-08-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/denkGroot\/Spina",
            "commit_href":"https:\/\/github.com\/denkGroot\/Spina\/commit\/bfe44f289e336f80b6593032679300c493735e75",
            "commit_sha":"bfe44f289e336f80b6593032679300c493735e75",
            "patch":"SINGLE",
            "chain_ord":"['bfe44f289e336f80b6593032679300c493735e75']",
            "before_first_fix_commit":"{'2b3e8f724a97b312a61503f378a5ce6def58bfe2'}",
            "last_fix_commit":"bfe44f289e336f80b6593032679300c493735e75",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/16\/2015, 14:23:27",
            "message":"protect from forgery",
            "author":"Bram Jetten",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'app\/controllers\/spina\/application_controller.rb': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/denkGroot\/Spina\/raw\/bfe44f289e336f80b6593032679300c493735e75\/app%2Fcontrollers%2Fspina%2Fapplication_controller.rb', 'patch': '@@ -1,5 +1,7 @@\\n module Spina\\n   class ApplicationController < ActionController::Base\\n+    protect_from_forgery\\n+    \\n     include ApplicationHelper\\n \\n     private'}}",
            "message_norm":"protect from forgery",
            "language":"en",
            "entities":"[('protect', 'SECWORD', ''), ('forgery', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/controllers\/spina\/application_controller.rb'])",
            "num_files":1.0
        },
        {
            "index":683,
            "vuln_id":"GHSA-5qw5-89mw-wcg2",
            "cwe_id":"{'CWE-787'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/97282c6d0d34476b6ba033f961590b783fa184cd'}",
            "dataset":"osv",
            "summary":"Out of bounds write in Tensorflow ### Impact\nTensorFlow is vulnerable to a heap OOB write in [Grappler](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/grappler\/costs\/graph_properties.cc#L1132-L1141):\n\n```cc\nStatus SetUnknownShape(const NodeDef* node, int output_port) {\n  shape_inference::ShapeHandle shape = \n      GetUnknownOutputShape(node, output_port);\n  InferenceContext* ctx = GetContext(node);\n  if (ctx == nullptr) {\n    return errors::InvalidArgument(\"Missing context\");\n  }\n  ctx->set_output(output_port, shape);\n  return Status::OK();\n}\n```\n\nThe [`set_output`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/shape_inference.h#L394) function writes to an array at the specified index:\n\n```cc\nvoid set_output(int idx, ShapeHandle shape) { outputs_.at(idx) = shape; }\n```\n\nHence, this gives a malicious user a write primitive.\n\n### Patches\nWe have patched the issue in GitHub commit [97282c6d0d34476b6ba033f961590b783fa184cd](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/97282c6d0d34476b6ba033f961590b783fa184cd).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/97282c6d0d34476b6ba033f961590b783fa184cd",
            "commit_sha":"97282c6d0d34476b6ba033f961590b783fa184cd",
            "patch":"SINGLE",
            "chain_ord":"['97282c6d0d34476b6ba033f961590b783fa184cd']",
            "before_first_fix_commit":"{'557a09455bc98108bc29b3b78e818f9d7dca920f'}",
            "last_fix_commit":"97282c6d0d34476b6ba033f961590b783fa184cd",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/08\/2021, 13:48:40",
            "message":"Prevent a crash due to heap OOB write in grappler.\n\nPiperOrigin-RevId: 408318417\nChange-Id: If095feb8c001e3a8ac4a85b7387b81e8309df47d",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 1, 'total': 7}",
            "files":"{'tensorflow\/core\/grappler\/costs\/graph_properties.cc': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/97282c6d0d34476b6ba033f961590b783fa184cd\/tensorflow%2Fcore%2Fgrappler%2Fcosts%2Fgraph_properties.cc', 'patch': '@@ -1134,7 +1134,12 @@ class SymbolicShapeRefiner {\\n         GetUnknownOutputShape(node, output_port);\\n     InferenceContext* ctx = GetContext(node);\\n     if (ctx == nullptr) {\\n-      return errors::InvalidArgument(\"Missing context\");\\n+      return errors::InvalidArgument(\"SetUnknownShape: Missing context\");\\n+    }\\n+    if (output_port < 0 || output_port >= ctx->num_outputs()) {\\n+      return errors::InvalidArgument(\\n+          \"SetUnknownShape: output_port must be in [0, \", ctx->num_outputs(),\\n+          \") but was \", output_port);\\n     }\\n     ctx->set_output(output_port, shape);\\n     return Status::OK();'}}",
            "message_norm":"prevent a crash due to heap oob write in grappler.\n\npiperorigin-revid: 408318417\nchange-id: if095feb8c001e3a8ac4a85b7387b81e8309df47d",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('408318417', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/grappler\/costs\/graph_properties.cc'])",
            "num_files":1.0
        },
        {
            "index":1562,
            "vuln_id":"GHSA-cjg2-2fjg-fph4",
            "cwe_id":"{'CWE-191'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/paritytech\/frontier\/commit\/8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664'}",
            "dataset":"osv",
            "summary":"Integer underflow in Frontier ### Impact\n\nA bug in Frontier's MODEXP precompile implementation can cause an integer underflow in certain conditions. This will cause a node crash for debug builds. For release builds (and production WebAssembly binaries), the impact is limited as it can only cause a normal EVM out-of-gas. It is recommended that you apply the patch as soon as possible.\n\nIf you do not use MODEXP precompile in your runtime, then you are not impacted.\n\n### Patches\n\nPatches are applied in PR #549.\n\n### Workarounds\n\nNone.\n\n### References\n\nPatch PR: #549\n\n### Credits\n\nThanks to SR-Labs for discovering the security vulnerability, and thanks to PureStake team for the patches.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an issue in the [Frontier repo](https:\/\/github.com\/paritytech\/frontier)",
            "published_date":"2022-01-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/paritytech\/frontier",
            "commit_href":"https:\/\/github.com\/paritytech\/frontier\/commit\/8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664",
            "commit_sha":"8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664",
            "patch":"SINGLE",
            "chain_ord":"['8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664']",
            "before_first_fix_commit":"{'6dd07a4d581a4c00bb2a2238a81997fc75bc2127'}",
            "last_fix_commit":"8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/13\/2022, 16:23:07",
            "message":"Handle 0 exponent with fudged length correctly in ModExp (#549)\n\n* Handle 0 exponent with fudged length correctly in ModExp\r\n\r\n* cargo fmt\r\n\r\n* Revert to following EIP-2565 strictly, subtract after adding terms to prevent underflow\r\n\r\n* Update frame\/evm\/precompile\/modexp\/src\/lib.rs\r\n\r\nClean up test case\r\n\r\nCo-authored-by: Wei Tang <accounts@that.world>\r\n\r\n* More revert\r\n\r\n* cargo fmt\r\n\r\n* Prefer expect to match\r\n\r\nCo-authored-by: Wei Tang <accounts@that.world>",
            "author":"Stephen Shelton",
            "comments":null,
            "stats":"{'additions': 51, 'deletions': 5, 'total': 56}",
            "files":"{'frame\/evm\/precompile\/modexp\/src\/lib.rs': {'additions': 51, 'deletions': 5, 'changes': 56, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/paritytech\/frontier\/raw\/8a93fdc6c9f4eb1d2f2a11b7ff1d12d70bf5a664\/frame%2Fevm%2Fprecompile%2Fmodexp%2Fsrc%2Flib.rs', 'patch': '@@ -47,7 +47,10 @@ fn calculate_gas_cost(\\n \\t\\t\\twords += 1;\\n \\t\\t}\\n \\n-\\t\\t\/\/ TODO: prevent\/handle overflow\\n+\\t\\t\/\/ Note: can\\'t overflow because we take words to be some u64 value \/ 8, which is\\n+\\t\\t\/\/ necessarily less than sqrt(u64::MAX).\\n+\\t\\t\/\/ Additionally, both base_length and mod_length are bounded to 1024, so this has\\n+\\t\\t\/\/ an upper bound of roughly (1024 \/ 8) squared\\n \\t\\twords * words\\n \\t}\\n \\n@@ -63,8 +66,17 @@ fn calculate_gas_cost(\\n \\t\\t\\tlet bytes: [u8; 32] = [0xFF; 32];\\n \\t\\t\\tlet max_256_bit_uint = BigUint::from_bytes_be(&bytes);\\n \\n+\\t\\t\\t\/\/ from the EIP spec:\\n+\\t\\t\\t\/\/ (8 * (exp_length - 32)) + ((exponent & (2**256 - 1)).bit_length() - 1)\\n+\\t\\t\\t\/\/\\n+\\t\\t\\t\/\/ Notes:\\n+\\t\\t\\t\/\/ * exp_length is bounded to 1024 and is > 32\\n+\\t\\t\\t\/\/ * exponent can be zero, so we subtract 1 after adding the other terms (whose sum\\n+\\t\\t\\t\/\/   must be > 0)\\n+\\t\\t\\t\/\/ * the addition can\\'t overflow because the terms are both capped at roughly\\n+\\t\\t\\t\/\/   8 * max size of exp_length (1024)\\n \\t\\t\\titeration_count =\\n-\\t\\t\\t\\t(8 * (exp_length - 32)) + ((exponent.bitand(max_256_bit_uint)).bits() - 1);\\n+\\t\\t\\t\\t(8 * (exp_length - 32)) + exponent.bitand(max_256_bit_uint).bits() - 1;\\n \\t\\t}\\n \\n \\t\\tmax(iteration_count, 1)\\n@@ -89,7 +101,7 @@ fn calculate_gas_cost(\\n \/\/ 6) modulus, size as described above\\n \/\/\\n \/\/\\n-\/\/ NOTE: input sizes are arbitrarily large (up to 256 bits), with the expectation\\n+\/\/ NOTE: input sizes are bound to 1024 bytes, with the expectation\\n \/\/       that gas limits would be applied before actual computation.\\n \/\/\\n \/\/       maximum stack size will also prevent abuse.\\n@@ -133,7 +145,7 @@ impl Precompile for Modexp {\\n \\t\\tlet mod_len_big = BigUint::from_bytes_be(&buf);\\n \\t\\tif mod_len_big > max_size_big {\\n \\t\\t\\treturn Err(PrecompileFailure::Error {\\n-\\t\\t\\t\\texit_status: ExitError::Other(\"unreasonably large exponent length\".into()),\\n+\\t\\t\\t\\texit_status: ExitError::Other(\"unreasonably large modulus length\".into()),\\n \\t\\t\\t});\\n \\t\\t}\\n \\n@@ -162,7 +174,6 @@ impl Precompile for Modexp {\\n \\t\\t\\tlet exponent = BigUint::from_bytes_be(&input[exp_start..exp_start + exp_len]);\\n \\n \\t\\t\\t\/\/ do our gas accounting\\n-\\t\\t\\t\/\/ TODO: we could technically avoid reading base first...\\n \\t\\t\\tlet gas_cost =\\n \\t\\t\\t\\tcalculate_gas_cost(base_len as u64, exp_len as u64, mod_len as u64, &exponent);\\n \\t\\t\\tif let Some(gas_left) = target_gas {\\n@@ -423,4 +434,39 @@ mod tests {\\n \\t\\t\\t}\\n \\t\\t}\\n \\t}\\n+\\n+\\t#[test]\\n+\\tfn test_zero_exp_with_33_length() {\\n+\\t\\t\/\/ This is a regression test which ensures that the \\'iteration_count\\' calculation\\n+\\t\\t\/\/ in \\'calculate_iteration_count\\' cannot underflow.\\n+\\t\\t\/\/\\n+\\t\\t\/\/ In debug mode, this underflow could cause a panic. Otherwise, it causes N**0 to\\n+\\t\\t\/\/ be calculated at more-than-normal expense.\\n+\\t\\t\/\/\\n+\\t\\t\/\/ TODO: cite security advisory\\n+\\n+\\t\\tlet input = vec![\\n+\\t\\t\\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n+\\t\\t\\t0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n+\\t\\t\\t0, 0, 0, 0, 0, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n+\\t\\t\\t0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n+\\t\\t\\t0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\\n+\\t\\t];\\n+\\n+\\t\\tlet cost: u64 = 100000;\\n+\\n+\\t\\tlet context: Context = Context {\\n+\\t\\t\\taddress: Default::default(),\\n+\\t\\t\\tcaller: Default::default(),\\n+\\t\\t\\tapparent_value: From::from(0),\\n+\\t\\t};\\n+\\n+\\t\\tlet precompile_result = Modexp::execute(&input, Some(cost), &context, false)\\n+\\t\\t\\t.expect(\"Modexp::execute() returned error\");\\n+\\n+\\t\\tassert_eq!(precompile_result.output.len(), 1); \/\/ should be same length as mod\\n+\\t\\tlet result = BigUint::from_bytes_be(&precompile_result.output[..]);\\n+\\t\\tlet expected = BigUint::parse_bytes(b\"0\", 10).unwrap();\\n+\\t\\tassert_eq!(result, expected);\\n+\\t}\\n }'}}",
            "message_norm":"handle 0 exponent with fudged length correctly in modexp (#549)\n\n* handle 0 exponent with fudged length correctly in modexp\r\n\r\n* cargo fmt\r\n\r\n* revert to following eip-2565 strictly, subtract after adding terms to prevent underflow\r\n\r\n* update frame\/evm\/precompile\/modexp\/src\/lib.rs\r\n\r\nclean up test case\r\n\r\nco-authored-by: wei tang <accounts@that.world>\r\n\r\n* more revert\r\n\r\n* cargo fmt\r\n\r\n* prefer expect to match\r\n\r\nco-authored-by: wei tang <accounts@that.world>",
            "language":"en",
            "entities":"[('#549', 'ISSUE', ''), ('adding', 'ACTION', ''), ('prevent', 'ACTION', ''), ('underflow', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['frame\/evm\/precompile\/modexp\/src\/lib.rs'])",
            "num_files":1.0
        },
        {
            "index":1026,
            "vuln_id":"GHSA-7fvx-3jfc-2cpc",
            "cwe_id":"{'CWE-125'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/01cff3f986259d661103412a20745928c727326f'}",
            "dataset":"osv",
            "summary":"Heap OOB in `ResourceScatterUpdate` ### Impact\nAn attacker can trigger a read from outside of bounds of heap allocated data by sending invalid arguments to `tf.raw_ops.ResourceScatterUpdate`:\n\n```python\nimport tensorflow as tf\n\nv = tf.Variable([b'vvv'])\ntf.raw_ops.ResourceScatterUpdate(\n  resource=v.handle,\n  indices=[0],\n  updates=['1', '2', '3', '4', '5'])\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/resource_variable_ops.cc#L919-L923) has an incomplete validation of the relationship between the shapes of `indices` and `updates`: instead of checking that the shape of `indices` is a prefix of the shape of `updates` (so that broadcasting can happen), code only checks that the number of elements in these two tensors are in a divisibility relationship.\n\n### Patches \nWe have patched the issue in GitHub commit [01cff3f986259d661103412a20745928c727326f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/01cff3f986259d661103412a20745928c727326f).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n    \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n    \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/01cff3f986259d661103412a20745928c727326f",
            "commit_sha":"01cff3f986259d661103412a20745928c727326f",
            "patch":"SINGLE",
            "chain_ord":"['01cff3f986259d661103412a20745928c727326f']",
            "before_first_fix_commit":"{'96f364a1ca3009f98980021c4b32be5fdcca33a1'}",
            "last_fix_commit":"01cff3f986259d661103412a20745928c727326f",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2021, 20:33:05",
            "message":"Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`\n\nPiperOrigin-RevId: 388292801\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 5, 'total': 11}",
            "files":"{'tensorflow\/core\/kernels\/resource_variable_ops.cc': {'additions': 6, 'deletions': 5, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/01cff3f986259d661103412a20745928c727326f\/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.cc', 'patch': '@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\\n                         params->dim_size(0), \")\"));\\n       } else {\\n         int64_t num_updates = updates.NumElements();\\n-        OP_REQUIRES(c, num_updates % N == 0,\\n-                    errors::InvalidArgument(\\n-                        \"shape of indices (\", indices.shape().DebugString(),\\n-                        \") is not compatible with the shape of updates (\",\\n-                        updates.shape().DebugString(), \")\"));\\n+        OP_REQUIRES(\\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\\n+            errors::InvalidArgument(\\n+                \"The shape of indices (\", indices.shape().DebugString(),\\n+                \") must be a prefix of the shape of updates (\",\\n+                updates.shape().DebugString(), \")\"));\\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates \/ N});\\n \\n         functor::ScatterFunctor<Device, T, Index, op> functor;'}}",
            "message_norm":"fix heap oob due to dimension mismatch in `resourcescatterupdate`\n\npiperorigin-revid: 388292801\nchange-id: id9bd7244d98d41b1517d4771850b32782c0cc949",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('388292801', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/resource_variable_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":3146,
            "vuln_id":"GHSA-vmjw-c2vp-p33c",
            "cwe_id":"{'CWE-681'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d'}",
            "dataset":"osv",
            "summary":"Crash in NMS ops caused by integer conversion to unsigned ### Impact\nAn attacker can cause denial of service in applications serving models using `tf.raw_ops.NonMaxSuppressionV5` by triggering a division by 0:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.NonMaxSuppressionV5(\n  boxes=[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],\n  scores=[1.0,2.0,3.0],\n  max_output_size=-1,\n  iou_threshold=0.5,\n  score_threshold=0.5,\n  soft_nms_sigma=1.0,\n  pad_to_max_output_size=True)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/image\/non_max_suppression_op.cc#L170-L271) uses a user controlled argument to resize a `std::vector`:\n\n```cc\n  const int output_size = max_output_size.scalar<int>()();\n  \/\/ ...\n  std::vector<int> selected;\n  \/\/ ...\n  if (pad_to_max_output_size) {\n    selected.resize(output_size, 0);\n    \/\/ ...\n  }\n```\n    \nHowever, as `std::vector::resize` takes the size argument as a `size_t` and `output_size` is an `int`, there is an implicit conversion to usigned. If the attacker supplies a negative value, this conversion results in a crash.\n\nA similar issue occurs in `CombinedNonMaxSuppression`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.NonMaxSuppressionV5(\n  boxes=[[[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]],[[0.1,0.1,0.1,0.1],[0.2,0.2,0.2,0.2],[0.3,0.3,0.3,0.3]]]],\n  scores=[[[1.0,2.0,3.0],[1.0,2.0,3.0],[1.0,2.0,3.0]]],\n  max_output_size_per_class=-1,\n  max_total_size=10,\n  iou_threshold=score_threshold=0.5,\n  pad_per_class=True,\n  clip_boxes=True)\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d) and commit [b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58",
            "commit_sha":"b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58",
            "patch":"MULTI",
            "chain_ord":"['b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58', '3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d']",
            "before_first_fix_commit":"{'a87fa31dc3becc97c7e945b9b8c8711acb92fc12'}",
            "last_fix_commit":"3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/30\/2021, 05:24:52",
            "message":"Prevent overflow due to integer conversion to unsigned.\n\nPiperOrigin-RevId: 387738045\nChange-Id: Id7e95bc07e02df1c66b72bd09f389608c87bdebe",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/image\/non_max_suppression_op.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58\/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.cc', 'patch': '@@ -930,6 +930,8 @@ class CombinedNonMaxSuppressionOp : public OpKernel {\\n         errors::InvalidArgument(\"max_size_per_class must be 0-D, got shape \",\\n                                 max_output_size.shape().DebugString()));\\n     const int max_size_per_class = max_output_size.scalar<int>()();\\n+    OP_REQUIRES(context, max_size_per_class > 0,\\n+                errors::InvalidArgument(\"max_size_per_class must be positive\"));\\n     \/\/ max_total_size: scalar\\n     const Tensor& max_total_size = context->input(3);\\n     OP_REQUIRES('}}",
            "message_norm":"prevent overflow due to integer conversion to unsigned.\n\npiperorigin-revid: 387738045\nchange-id: id7e95bc07e02df1c66b72bd09f389608c87bdebe",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('387738045', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/image\/non_max_suppression_op.cc'])",
            "num_files":1.0
        },
        {
            "index":318,
            "vuln_id":"GHSA-3wcq-x3mq-6r9p",
            "cwe_id":"{'CWE-908', 'CWE-200'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/mafintosh\/dns-packet\/commit\/0d0d593f8df4e2712c43957a6c62e95047f12b2d', 'https:\/\/github.com\/mafintosh\/dns-packet\/commit\/25f15dd0fedc53688b25fd053ebbdffe3d5c1c56'}",
            "dataset":"osv",
            "summary":"Potential memory exposure in dns-packet This affects the package dns-packet before versions 1.3.2 and 5.2.2. It creates buffers with allocUnsafe and does not always fill them before forming network packets. This can expose internal application memory over unencrypted network when querying crafted invalid domain names.",
            "published_date":"2021-05-24",
            "chain_len":2,
            "project":"https:\/\/github.com\/mafintosh\/dns-packet",
            "commit_href":"https:\/\/github.com\/mafintosh\/dns-packet\/commit\/0d0d593f8df4e2712c43957a6c62e95047f12b2d",
            "commit_sha":"0d0d593f8df4e2712c43957a6c62e95047f12b2d",
            "patch":"MULTI",
            "chain_ord":"['25f15dd0fedc53688b25fd053ebbdffe3d5c1c56', '0d0d593f8df4e2712c43957a6c62e95047f12b2d']",
            "before_first_fix_commit":"{'7f35bac5b4680d7bfbb34fbc475ecfdbf9d25092'}",
            "last_fix_commit":"0d0d593f8df4e2712c43957a6c62e95047f12b2d",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/25\/2021, 08:35:02",
            "message":"backport encodingLength fix to v1",
            "author":"Mathias Buus",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'index.js': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mafintosh\/dns-packet\/raw\/0d0d593f8df4e2712c43957a6c62e95047f12b2d\/index.js', 'patch': \"@@ -74,7 +74,8 @@ name.decode = function (buf, offset) {\\n name.decode.bytes = 0\\n \\n name.encodingLength = function (n) {\\n-  return Buffer.byteLength(n) + 2\\n+  if (n === '.') return 1\\n+  return Buffer.byteLength(n.replace(\/^\\\\.|\\\\.$\/gm, '')) + 2\\n }\\n \\n var string = {}\"}}",
            "message_norm":"backport encodinglength fix to v1",
            "language":"en",
            "entities":"[('encodinglength', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":3247,
            "vuln_id":"GHSA-w89r-qch4-8jv5",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/d797e3f00e34c12c8c0ae52f56344325439dccd7', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/936a5af1c07e0fdec9aab85c05339dabe4aaeeb1'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-0913, CVE-2019-0914, CVE-2019-0915, CVE-2019-0916, CVE-2019-0917, CVE-2019-0922, CVE-2019-0923, CVE-2019-0924, CVE-2019-0925, CVE-2019-0927, CVE-2019-0933, CVE-2019-0937.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/936a5af1c07e0fdec9aab85c05339dabe4aaeeb1",
            "commit_sha":"936a5af1c07e0fdec9aab85c05339dabe4aaeeb1",
            "patch":"MULTI",
            "chain_ord":"['936a5af1c07e0fdec9aab85c05339dabe4aaeeb1', 'd797e3f00e34c12c8c0ae52f56344325439dccd7']",
            "before_first_fix_commit":"{'ea0491305137183603bf43844b5584d4cc972e28', '4594e340bc9ca9f857010a68e8b562d65b46eed6'}",
            "last_fix_commit":"d797e3f00e34c12c8c0ae52f56344325439dccd7",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/17\/2019, 17:18:03",
            "message":"[CVE-2019-0912]",
            "author":"Michael Holman",
            "comments":null,
            "stats":"{'additions': 24, 'deletions': 7, 'total': 31}",
            "files":"{'lib\/Backend\/GlobOptFields.cpp': {'additions': 24, 'deletions': 7, 'changes': 31, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/936a5af1c07e0fdec9aab85c05339dabe4aaeeb1\/lib%2FBackend%2FGlobOptFields.cpp', 'patch': '@@ -415,11 +415,19 @@ GlobOpt::ProcessFieldKills(IR::Instr *instr, BVSparse<JitArenaAllocator> *bv, bo\\n \\n     case Js::OpCode::InlineArrayPush:\\n     case Js::OpCode::InlineArrayPop:\\n-        KillLiveFields(this->lengthEquivBv, bv);\\n-        if (inGlobOpt)\\n+        if(instr->m_func->GetThisOrParentInlinerHasArguments())\\n         {\\n-            \/\/ Deleting an item, or pushing a property to a non-array, may change object layout\\n-            KillAllObjectTypes(bv);\\n+            this->KillAllFields(bv);\\n+            this->SetAnyPropertyMayBeWrittenTo();\\n+        }\\n+        else\\n+        {\\n+            KillLiveFields(this->lengthEquivBv, bv);\\n+            if (inGlobOpt)\\n+            {\\n+                \/\/ Deleting an item, or pushing a property to a non-array, may change object layout\\n+                KillAllObjectTypes(bv);\\n+            }\\n         }\\n         break;\\n \\n@@ -444,14 +452,23 @@ GlobOpt::ProcessFieldKills(IR::Instr *instr, BVSparse<JitArenaAllocator> *bv, bo\\n                 \/\/ Kill length field for built-ins that can update it.\\n                 if (nullptr != this->lengthEquivBv)\\n                 {\\n-                    KillLiveFields(this->lengthEquivBv, bv);\\n+                    \/\/ If has arguments, all fields are killed in fall through\\n+                    if (!instr->m_func->GetThisOrParentInlinerHasArguments())\\n+                    {\\n+                        KillLiveFields(this->lengthEquivBv, bv);\\n+                    }\\n                 }\\n                 \/\/ fall through\\n \\n             case IR::JnHelperMethod::HelperArray_Reverse:\\n-                \/\/ Deleting an item may change object layout\\n-                if (inGlobOpt)\\n+                if (instr->m_func->GetThisOrParentInlinerHasArguments())\\n+                {\\n+                    this->KillAllFields(bv);\\n+                    this->SetAnyPropertyMayBeWrittenTo();\\n+                }\\n+                else if (inGlobOpt)\\n                 {\\n+                    \/\/ Deleting an item may change object layout\\n                     KillAllObjectTypes(bv);\\n                 }\\n                 break;'}}",
            "message_norm":"[cve-2019-0912]",
            "language":"ro",
            "entities":"[('cve-2019-0912', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Backend\/GlobOptFields.cpp'])",
            "num_files":1.0
        },
        {
            "index":539,
            "vuln_id":"GHSA-53m6-44rc-h2q5",
            "cwe_id":"{'CWE-347'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/octobercms\/october\/commit\/e3b455ad587282f0fbcb7763c6d9c3d000ca1e6a'}",
            "dataset":"osv",
            "summary":"Missing server signature validation in OctoberCMS ### Impact\n\nThis advisory affects authors of plugins and themes listed on the October CMS marketplace where an end-user will inadvertently expose authors to potential financial loss by entering their private license key into a compromised server.\n\nIt has been disclosed that a project fork of October CMS v1.0 is using a compromised gateway to access the October CMS marketplace service. The compromised gateway captures the personal\/business information of users and authors, including private source code files. It was also disclosed that captured plugin files are freely redistributed to other users without authorization.\n\n1. End-users are provided with a forked version of October CMS v1.0. The provided software is modified to use a compromised gateway server.\n\n2. The user is instructed to enter their October CMS license key into the administration panel to access the October CMS marketplace. The key is sent to the compromised server while appearing to access the genuine October CMS gateway server.\n\n3. The compromised gateway server uses a \"man in the middle\" mechanism that captures information while forwarding the request to the genuine October CMS gateway and relaying the response back to the client.\n\n4. The compromised gateway server stores the license key and other information about the user account including client name, email address and contents of purchased plugins and privately uploaded plugin files. \n\n5. The stored plugin files are made available to other users of the compromised gateway server.\n\n### Patches\n\nThe issue has been patched in Build 475 (v1.0.475) and v1.1.11.\n\n### Workarounds\n\nApply https:\/\/github.com\/octobercms\/october\/commit\/e3b455ad587282f0fbcb7763c6d9c3d000ca1e6a to your installation manually if unable to upgrade to Build 475 or v1.1.11.\n\n### Recommendations\n\nWe recommend the following steps to make sure your account information stays secure:\n\n- Do not share your license key with anyone except October CMS.\n- Check to make sure that your gateway update server has not been modified.\n- Be aware of phishing websites, including other platforms that use the same appearance.\n- For authors, you may contact us for help requesting the removal of affected plugins.\n- Before providing plugin support, verify that the user holds a legitimate copy of the plugin.\n\n### References\n\nCredits for research on this exploit:\n\u2022 Nikita Khaetsky\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Email us at [hello@octobercms.com](mailto:hello@octobercms.com)",
            "published_date":"2022-02-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/octobercms\/october",
            "commit_href":"https:\/\/github.com\/octobercms\/october\/commit\/e3b455ad587282f0fbcb7763c6d9c3d000ca1e6a",
            "commit_sha":"e3b455ad587282f0fbcb7763c6d9c3d000ca1e6a",
            "patch":"SINGLE",
            "chain_ord":"['e3b455ad587282f0fbcb7763c6d9c3d000ca1e6a']",
            "before_first_fix_commit":"{'e6867a5eb69f5c723adb33b6ca97fcda99634446'}",
            "last_fix_commit":"e3b455ad587282f0fbcb7763c6d9c3d000ca1e6a",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/20\/2022, 01:54:45",
            "message":"Checks gateway server has a valid signature",
            "author":"Sam Georges",
            "comments":null,
            "stats":"{'additions': 38, 'deletions': 2, 'total': 40}",
            "files":"{'modules\/system\/classes\/UpdateManager.php': {'additions': 38, 'deletions': 2, 'changes': 40, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/octobercms\/october\/raw\/e3b455ad587282f0fbcb7763c6d9c3d000ca1e6a\/modules%2Fsystem%2Fclasses%2FUpdateManager.php', 'patch': \"@@ -8,6 +8,7 @@\\n use Cache;\\n use Schema;\\n use Config;\\n+use Request;\\n use ApplicationException;\\n use Cms\\\\Classes\\\\ThemeManager;\\n use System\\\\Models\\\\Parameter;\\n@@ -885,6 +886,10 @@ public function requestServerData($uri, $postData = [])\\n             throw new ApplicationException(Lang::get('system::lang.server.response_invalid'));\\n         }\\n \\n+        if (!$this->validateServerSignature($resultData, $result->headers['Rest-Sign'] ?? '')) {\\n+            throw new ApplicationException(Lang::get('system::lang.server.response_invalid') . ' (Bad signature)');\\n+        }\\n+\\n         return $resultData;\\n     }\\n \\n@@ -963,12 +968,13 @@ protected function createServerUrl($uri)\\n      *\/\\n     protected function applyHttpAttributes($http, $postData)\\n     {\\n-        $postData['protocol_version'] = '1.2';\\n-        $postData['client'] = 'october';\\n+        $postData['protocol_version'] = '1.3';\\n+        $postData['client'] = 'October CMS';\\n \\n         $postData['server'] = base64_encode(json_encode([\\n             'php'   => PHP_VERSION,\\n             'url'   => Url::to('\/'),\\n+            'ip'    => Request::ip(),\\n             'since' => PluginVersion::orderBy('created_at')->value('created_at')\\n         ]));\\n \\n@@ -1070,4 +1076,34 @@ protected function printMessages()\\n             }\\n         }\\n     }\\n+\\n+    \/**\\n+     * validateServerSignature checks the server has provided a valid signature\\n+     *\\n+     * @return bool\\n+     *\/\\n+    protected function validateServerSignature($data, $signature)\\n+    {\\n+        if (!$signature) {\\n+            return false;\\n+        }\\n+\\n+        $signature = base64_decode($signature);\\n+\\n+        $pubKey = '-----BEGIN PUBLIC KEY-----\\n+MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAt+KwvTXqC8Mz9vV4KIvX\\n+3y+aZusrlg26jdbNVUuhXNFbt1VisjJydHW2+WGsiEHSy2s61ZAV2dICR6f3huSw\\n+jY\/MH9j23Oo\/u61CBpvIS3Q8uC+TLtJl4\/F9eqlnzocfMoKe8NmcBbUR3TKQoIok\\n+xbSMl6jiE2k5TJdzhHUxjZRIeeLDLMKYX6xt37LdhuM8zO6sXQmCGg4J6LmHTJph\\n+96H11gBvcFSFJSmIiDykJOELZl\/aVcY1g3YgpL0mw5Bw1VTmKaRdz1eBi9DmKrKX\\n+UijG4gD8eLRV\/FS\/sZCFNR\/evbQXvTBxO0TOIVi85PlQEcMl4SBj0CoTyNbcAGtz\\n+4wIDAQAB\\n+-----END PUBLIC KEY-----';\\n+\\n+        $pubKey = Config::get('system.update_gateway_key', $pubKey);\\n+\\n+        $data = base64_encode(json_encode($data));\\n+\\n+        return openssl_verify($data, $signature, $pubKey) === 1;\\n+    }\\n }\"}}",
            "message_norm":"checks gateway server has a valid signature",
            "language":"en",
            "entities":"[('server', 'SECWORD', ''), ('signature', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/system\/classes\/UpdateManager.php'])",
            "num_files":1.0
        },
        {
            "index":260,
            "vuln_id":"GHSA-3hw5-q855-g6cw",
            "cwe_id":"{'CWE-94'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/dojo\/dojox\/commit\/47d1b302b5b23d94e875b77b9b9a8c4f5622c9da'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in Dojox The Dojox jQuery wrapper `jqMix` mixin method is vulnerable to Prototype Pollution. \n\nAffected Area:\n```\n\/\/https:\/\/github.com\/dojo\/dojox\/blob\/master\/jq.js#L442\n\t\tvar tobj = {};\n\t\tfor(var x in props){\n\t\t\t\/\/ the \"tobj\" condition avoid copying properties in \"props\"\n\t\t\t\/\/ inherited from Object.prototype.  For example, if obj has a custom\n\t\t\t\/\/ toString() method, don't overwrite it with the toString() method\n\t\t\t\/\/ that props inherited from Object.prototype\n\t\t\tif((tobj[x] === undefined || tobj[x] != props[x]) && props[x] !== undefined && obj != props[x]){\n\t\t\t\tif(dojo.isObject(obj[x]) && dojo.isObject(props[x])){\n\t\t\t\t\tif(dojo.isArray(props[x])){\n\t\t\t\t\t\tobj[x] = props[x];\n\t\t\t\t\t}else{\n\t\t\t\t\t\tobj[x] = jqMix(obj[x], props[x]);\n\t\t\t\t\t}\n\t\t\t\t}else{\n\t\t\t\t\tobj[x] = props[x];\n\t\t\t\t}\n```",
            "published_date":"2020-03-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/dojo\/dojox",
            "commit_href":"https:\/\/github.com\/dojo\/dojox\/commit\/47d1b302b5b23d94e875b77b9b9a8c4f5622c9da",
            "commit_sha":"47d1b302b5b23d94e875b77b9b9a8c4f5622c9da",
            "patch":"SINGLE",
            "chain_ord":"['47d1b302b5b23d94e875b77b9b9a8c4f5622c9da']",
            "before_first_fix_commit":"{'5491effdb1b586f1a5f5b173460fe26e23abcfe6'}",
            "last_fix_commit":"47d1b302b5b23d94e875b77b9b9a8c4f5622c9da",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/10\/2020, 14:25:04",
            "message":"Merge pull request from GHSA-3hw5-q855-g6cw\n\nPrevent the special __proto__ property name from being mixed in to\nprevent polluting the prototoype of the object being mixed into in the\njqMix function in jq.js",
            "author":"Nick Nisi",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'jq.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/dojo\/dojox\/raw\/47d1b302b5b23d94e875b77b9b9a8c4f5622c9da\/jq.js', 'patch': \"@@ -455,7 +455,7 @@ dojo.query differences that cause some tests to fail:\\n \\t\\t\\t\/\/ inherited from Object.prototype.  For example, if obj has a custom\\n \\t\\t\\t\/\/ toString() method, don't overwrite it with the toString() method\\n \\t\\t\\t\/\/ that props inherited from Object.prototype\\n-\\t\\t\\tif((tobj[x] === undefined || tobj[x] != props[x]) && props[x] !== undefined && obj != props[x]){\\n+\\t\\t\\tif(x !== '__proto__ ' && ((tobj[x] === undefined || tobj[x] != props[x])) && props[x] !== undefined && obj != props[x]){\\n \\t\\t\\t\\tif(dojo.isObject(obj[x]) && dojo.isObject(props[x])){\\n \\t\\t\\t\\t\\tif(dojo.isArray(props[x])){\\n \\t\\t\\t\\t\\t\\tobj[x] = props[x];\"}}",
            "message_norm":"merge pull request from ghsa-3hw5-q855-g6cw\n\nprevent the special __proto__ property name from being mixed in to\nprevent polluting the prototoype of the object being mixed into in the\njqmix function in jq.js",
            "language":"en",
            "entities":"[('ghsa-3hw5-q855-g6cw', 'VULNID', 'GHSA'), ('prevent', 'ACTION', ''), ('prevent', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['jq.js'])",
            "num_files":1.0
        },
        {
            "index":2129,
            "vuln_id":"GHSA-hv96-xxx2-5v7w",
            "cwe_id":"{'CWE-311'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/nwjs\/npm-installer\/commit\/adb4df1e012d38a3872578d484291b9af07aad5b'}",
            "dataset":"osv",
            "summary":"Downloads Resources over HTTP in nw Affected versions of `nw` insecurely download an executable over an unencrypted HTTP connection. \n\nIn scenarios where an attacker has a privileged network position, it is possible to intercept the response and replace the executable with a malicious one, resulting in code execution on the system running `nw`.\n\n\n## Recommendation\n\nUpdate to version 0.23.6-1 or later.",
            "published_date":"2019-02-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/nwjs\/npm-installer",
            "commit_href":"https:\/\/github.com\/nwjs\/npm-installer\/commit\/adb4df1e012d38a3872578d484291b9af07aad5b",
            "commit_sha":"adb4df1e012d38a3872578d484291b9af07aad5b",
            "patch":"SINGLE",
            "chain_ord":"['adb4df1e012d38a3872578d484291b9af07aad5b']",
            "before_first_fix_commit":"{'0fe9b728586885f7ab185dc27e60e696381d1b6f'}",
            "last_fix_commit":"adb4df1e012d38a3872578d484291b9af07aad5b",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/12\/2017, 16:57:53",
            "message":"fix nwjs\/npm-installer#2 (start\u00a0using HTTPS: it\u00a0improves security)",
            "author":"Mithgol the Webmaster",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'scripts\/install.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nwjs\/npm-installer\/raw\/adb4df1e012d38a3872578d484291b9af07aad5b\/scripts%2Finstall.js', 'patch': \"@@ -33,7 +33,7 @@ if ( version.slice(-4) === '-sdk' ){\\n }\\n \\n var url = false;\\n-var urlBase = process.env.npm_config_nwjs_urlbase || process.env.NWJS_URLBASE ||  'http:\/\/dl.nwjs.io\/v';\\n+var urlBase = process.env.npm_config_nwjs_urlbase || process.env.NWJS_URLBASE ||  'https:\/\/dl.nwjs.io\/v';\\n var buildTypeSuffix = buildType === 'normal' ? '' : ('-' + buildType);\\n \\n \/\/ Determine download url\"}}",
            "message_norm":"fix nwjs\/npm-installer#2 (start\u00a0using https: it\u00a0improves security)",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('improves', 'ACTION', ''), ('security', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['scripts\/install.js'])",
            "num_files":1.0
        },
        {
            "index":3138,
            "vuln_id":"GHSA-vm37-j55j-8655",
            "cwe_id":"{'CWE-78'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/0a7e5f1d81de884861ca677ee1aaac31f188d632'}",
            "dataset":"osv",
            "summary":"OS Command Injection in Microweber Microweber is a content management system with drag and drop. Prior to version 1.2.11, Microweber is vulnerable to OS Command Injection.",
            "published_date":"2022-02-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/0a7e5f1d81de884861ca677ee1aaac31f188d632",
            "commit_sha":"0a7e5f1d81de884861ca677ee1aaac31f188d632",
            "patch":"SINGLE",
            "chain_ord":"['0a7e5f1d81de884861ca677ee1aaac31f188d632']",
            "before_first_fix_commit":"{'b66537fbd7792d10f07fa7870ead7aae293f1120'}",
            "last_fix_commit":"0a7e5f1d81de884861ca677ee1aaac31f188d632",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/10\/2022, 08:27:09",
            "message":"Update plupload.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 2, 'total': 3}",
            "files":"{'src\/MicroweberPackages\/App\/functions\/plupload.php': {'additions': 1, 'deletions': 2, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/0a7e5f1d81de884861ca677ee1aaac31f188d632\/src%2FMicroweberPackages%2FApp%2Ffunctions%2Fplupload.php', 'patch': \"@@ -149,14 +149,13 @@\\n                             $is_ext = strtolower($is_ext);\\n \\n                             switch ($is_ext) {\\n-                                case 'php':\\n+                                case 'php': \\n                                 case 'php12':\\n                                 case 'php11':\\n                                 case 'php10':\\n                                 case 'php9':\\n                                 case 'php8':\\n                                 case 'php7':\\n-                                case 'php6':\\n                                 case 'php5':\\n                                 case 'php4':\\n                                 case 'php3':\"}}",
            "message_norm":"update plupload.php",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/App\/functions\/plupload.php'])",
            "num_files":1.0
        },
        {
            "index":743,
            "vuln_id":"GHSA-6445-fm66-fvq2",
            "cwe_id":"{'CWE-190'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b51b82fe65ebace4475e3c54eb089c18a4403f1c', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a68f68061e263a88321c104a6c911fe5598050a8'}",
            "dataset":"osv",
            "summary":"Integer overflows in Tensorflow ### Impact \nThe [implementation of `AddManySparseToTensorsMap`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc) is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service):\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ntf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices=[(0,0),(0,1),(0,2),(4,3),(5,0),(5,1)],\n    sparse_values=[1,1,1,1,1,1],\n    sparse_shape=[2**32,2**32],\n    container='',\n    shared_name='',\n    name=None)\n```\n\nWe are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The latter is an instance of [TFSA-2021-198](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/security\/advisory\/tfsa-2021-198.md) (CVE-2021-41197) and is easily fixed by replacing a call to `TensorShape` constructor with a call to `BuildTensorShape` static helper factory.\n### Patches\nWe have patched the issue in GitHub commits [b51b82fe65ebace4475e3c54eb089c18a4403f1c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b51b82fe65ebace4475e3c54eb089c18a4403f1c) and [a68f68061e263a88321c104a6c911fe5598050a8](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a68f68061e263a88321c104a6c911fe5598050a8).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
            "published_date":"2022-02-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a68f68061e263a88321c104a6c911fe5598050a8",
            "commit_sha":"a68f68061e263a88321c104a6c911fe5598050a8",
            "patch":"MULTI",
            "chain_ord":"['b51b82fe65ebace4475e3c54eb089c18a4403f1c', 'a68f68061e263a88321c104a6c911fe5598050a8']",
            "before_first_fix_commit":"{'e8f4be7958736823b9f56090611ec2fb09824d51'}",
            "last_fix_commit":"a68f68061e263a88321c104a6c911fe5598050a8",
            "chain_ord_pos":2.0,
            "commit_datetime":"12\/10\/2021, 00:17:26",
            "message":"Replace faulty overflow check with a builder for `TensorShape`.\n\nPrevents an integer overflow that was not caught before.\n\nPiperOrigin-RevId: 415381595\nChange-Id: I76585ddedc912bd9f4a390aeafa8e2ced1a28863",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 15, 'total': 18}",
            "files":"{'tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc': {'additions': 3, 'deletions': 15, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a68f68061e263a88321c104a6c911fe5598050a8\/tensorflow%2Fcore%2Fkernels%2Fsparse_tensors_map_ops.cc', 'patch': '@@ -263,22 +263,10 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\\n             \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\\n \\n     auto input_shape_vec = input_shape->vec<int64_t>();\\n-    int new_num_elements = 1;\\n-    bool overflow_ocurred = false;\\n-    for (int i = 0; i < input_shape_vec.size(); i++) {\\n-      new_num_elements =\\n-          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\\n-      if (new_num_elements < 0) {\\n-        overflow_ocurred = true;\\n-        break;\\n-      }\\n-    }\\n-\\n-    OP_REQUIRES(\\n-        context, !overflow_ocurred,\\n-        errors::Internal(\"Encountered overflow from large input shape.\"));\\n \\n-    TensorShape tensor_input_shape(input_shape_vec);\\n+    TensorShape tensor_input_shape;\\n+    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(input_shape_vec,\\n+                                                          &tensor_input_shape));\\n     gtl::InlinedVector<int64_t, 8> std_order(rank);\\n     std::iota(std_order.begin(), std_order.end(), 0);\\n     SparseTensor input_st;'}}",
            "message_norm":"replace faulty overflow check with a builder for `tensorshape`.\n\nprevents an integer overflow that was not caught before.\n\npiperorigin-revid: 415381595\nchange-id: i76585ddedc912bd9f4a390aeafa8e2ced1a28863",
            "language":"en",
            "entities":"[('overflow', 'SECWORD', ''), ('prevents', 'ACTION', ''), ('integer overflow', 'SECWORD', ''), ('415381595', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":1661,
            "vuln_id":"GHSA-f4rr-5m7v-wxcw",
            "cwe_id":"{'CWE-843'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b917181c29b50cb83399ba41f4d938dc369109a1'}",
            "dataset":"osv",
            "summary":"Type confusion leading to `CHECK`-failure based denial of service in TensorFlow ### Impact\nThe [macros that TensorFlow uses for writing assertions (e.g., `CHECK_LT`, `CHECK_GT`, etc.)](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f3b9bf4c3c0597563b289c0512e98d4ce81f886e\/tensorflow\/core\/platform\/default\/logging.h) have an incorrect logic when comparing `size_t` and `int` values. Due to type conversion rules, several of the macros would trigger incorrectly.\n\n### Patches\nWe have patched the issue in GitHub commit [b917181c29b50cb83399ba41f4d938dc369109a1](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b917181c29b50cb83399ba41f4d938dc369109a1) (merging GitHub PR [#55730](https:\/\/github.com\/tensorflow\/tensorflow\/pull\/55730)).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [GitHub issue](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/55530).",
            "published_date":"2022-05-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b917181c29b50cb83399ba41f4d938dc369109a1",
            "commit_sha":"b917181c29b50cb83399ba41f4d938dc369109a1",
            "patch":"SINGLE",
            "chain_ord":"['b917181c29b50cb83399ba41f4d938dc369109a1']",
            "before_first_fix_commit":"{'cce6f6484e967a0be4df8702c8ac36d021542455', 'd73521b7603f10e3029a2f1cd5067ca985738fc8'}",
            "last_fix_commit":"b917181c29b50cb83399ba41f4d938dc369109a1",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 21:41:18",
            "message":"Merge pull request #55730 from graphcore:awf\/issue-55530\n\nPiperOrigin-RevId: 445252025",
            "author":"TensorFlower Gardener",
            "comments":null,
            "stats":"{'additions': 73, 'deletions': 28, 'total': 101}",
            "files":"{'tensorflow\/core\/platform\/default\/logging.h': {'additions': 73, 'deletions': 28, 'changes': 101, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b917181c29b50cb83399ba41f4d938dc369109a1\/tensorflow%2Fcore%2Fplatform%2Fdefault%2Flogging.h', 'patch': '@@ -85,7 +85,7 @@ class LogMessage : public std::basic_ostringstream<char> {\\n \/\/ that the ternary VLOG() implementation is balanced, type wise.\\n struct Voidifier {\\n   template <typename T>\\n-  void operator&(const T&)const {}\\n+  void operator&(const T&) const {}\\n };\\n \\n \/\/ LogMessageFatal ensures the process will exit in failure after\\n@@ -348,11 +348,13 @@ string* MakeCheckOpString(const T1& v1, const T2& v2, const char* exprtext) {\\n }\\n \\n \/\/ Helper functions for CHECK_OP macro.\\n-\/\/ The (int, int) specialization works around the issue that the compiler\\n+\/\/ We use the full name Check_EQ, Check_NE, etc. in case the file including\\n+\/\/ base\/logging.h provides its own #defines for the simpler names EQ, NE, etc.\\n+\/\/ This happens if, for example, those are used as token names in a\\n+\/\/ yacc grammar.\\n+\/\/ The (int, int) overload works around the issue that the compiler\\n \/\/ will not instantiate the template version of the function on values of\\n \/\/ unnamed enum type - see comment below.\\n-\/\/ The (size_t, int) and (int, size_t) specialization are to handle unsigned\\n-\/\/ comparison errors while still being thorough with the comparison.\\n #define TF_DEFINE_CHECK_OP_IMPL(name, op)                                 \\\\\\n   template <typename T1, typename T2>                                     \\\\\\n   inline string* name##Impl(const T1& v1, const T2& v2,                   \\\\\\n@@ -364,34 +366,77 @@ string* MakeCheckOpString(const T1& v1, const T2& v2, const char* exprtext) {\\n   }                                                                       \\\\\\n   inline string* name##Impl(int v1, int v2, const char* exprtext) {       \\\\\\n     return name##Impl<int, int>(v1, v2, exprtext);                        \\\\\\n-  }                                                                       \\\\\\n-  inline string* name##Impl(const size_t v1, const int v2,                \\\\\\n-                            const char* exprtext) {                       \\\\\\n-    if (TF_PREDICT_FALSE(v2 < 0)) {                                       \\\\\\n-      return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext); \\\\\\n-    }                                                                     \\\\\\n-    return name##Impl<size_t, size_t>(v1, v2, exprtext);                  \\\\\\n-  }                                                                       \\\\\\n-  inline string* name##Impl(const int v1, const size_t v2,                \\\\\\n-                            const char* exprtext) {                       \\\\\\n-    if (TF_PREDICT_FALSE(v2 >= std::numeric_limits<int>::max())) {        \\\\\\n-      return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext); \\\\\\n-    }                                                                     \\\\\\n-    const size_t uval = (size_t)((unsigned)v2);                           \\\\\\n-    return name##Impl<size_t, size_t>(v1, uval, exprtext);                \\\\\\n   }\\n \\n-\/\/ We use the full name Check_EQ, Check_NE, etc. in case the file including\\n-\/\/ base\/logging.h provides its own #defines for the simpler names EQ, NE, etc.\\n-\/\/ This happens if, for example, those are used as token names in a\\n-\/\/ yacc grammar.\\n-TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\\n-                        ==)  \/\/ Compilation error with CHECK_EQ(NULL, x)?\\n-TF_DEFINE_CHECK_OP_IMPL(Check_NE, !=)  \/\/ Use CHECK(x == NULL) instead.\\n+\/\/ The (size_t, int) and (int, size_t) specialization are to handle unsigned\\n+\/\/ comparison errors while still being thorough with the comparison.\\n+\\n+TF_DEFINE_CHECK_OP_IMPL(Check_EQ, ==)\\n+\/\/ Compilation error with CHECK_EQ(NULL, x)?\\n+\/\/ Use CHECK(x == NULL) instead.\\n+\\n+inline string* Check_EQImpl(int v1, size_t v2, const char* exprtext) {\\n+  if (TF_PREDICT_FALSE(v1 < 0))\\n+    ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);\\n+\\n+  return Check_EQImpl(size_t(v1), v2, exprtext);\\n+}\\n+\\n+inline string* Check_EQImpl(size_t v1, int v2, const char* exprtext) {\\n+  return Check_EQImpl(v2, v1, exprtext);\\n+}\\n+\\n+TF_DEFINE_CHECK_OP_IMPL(Check_NE, !=)\\n+\\n+inline string* Check_NEImpl(int v1, size_t v2, const char* exprtext) {\\n+  if (v1 < 0) return NULL;\\n+\\n+  return Check_NEImpl(size_t(v1), v2, exprtext);\\n+}\\n+\\n+inline string* Check_NEImpl(size_t v1, int v2, const char* exprtext) {\\n+  return Check_NEImpl(v2, v1, exprtext);\\n+}\\n+\\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)\\n+\\n+inline string* Check_LEImpl(int v1, size_t v2, const char* exprtext) {\\n+  if (v1 <= 0) return NULL;\\n+\\n+  return Check_LEImpl(size_t(v1), v2, exprtext);\\n+}\\n+\\n+inline string* Check_LEImpl(size_t v1, int v2, const char* exprtext) {\\n+  if (TF_PREDICT_FALSE(v2 < 0))\\n+    return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);\\n+  return Check_LEImpl(v1, size_t(v2), exprtext);\\n+}\\n+\\n TF_DEFINE_CHECK_OP_IMPL(Check_LT, <)\\n-TF_DEFINE_CHECK_OP_IMPL(Check_GE, >=)\\n-TF_DEFINE_CHECK_OP_IMPL(Check_GT, >)\\n+\\n+inline string* Check_LTImpl(int v1, size_t v2, const char* exprtext) {\\n+  if (v1 < 0) return NULL;\\n+\\n+  return Check_LTImpl(size_t(v1), v2, exprtext);\\n+}\\n+\\n+inline string* Check_LTImpl(size_t v1, int v2, const char* exprtext) {\\n+  if (v2 < 0)\\n+    return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);\\n+  return Check_LTImpl(v1, size_t(v2), exprtext);\\n+}\\n+\\n+\/\/ Implement GE,GT in terms of LE,LT\\n+template <typename T1, typename T2>\\n+inline string* Check_GEImpl(const T1& v1, const T2& v2, const char* exprtext) {\\n+  return Check_LEImpl(v2, v1, exprtext);\\n+}\\n+\\n+template <typename T1, typename T2>\\n+inline string* Check_GTImpl(const T1& v1, const T2& v2, const char* exprtext) {\\n+  return Check_LTImpl(v2, v1, exprtext);\\n+}\\n+\\n #undef TF_DEFINE_CHECK_OP_IMPL\\n \\n \/\/ In optimized mode, use CheckOpString to hint to compiler that'}}",
            "message_norm":"merge pull request #55730 from graphcore:awf\/issue-55530\n\npiperorigin-revid: 445252025",
            "language":"en",
            "entities":"[('#55730', 'ISSUE', ''), ('445252025', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/platform\/default\/logging.h'])",
            "num_files":1.0
        },
        {
            "index":367,
            "vuln_id":"GHSA-465w-gg5p-85c9",
            "cwe_id":"{'CWE-613', 'CWE-384', 'CWE-295'}",
            "score":8.6,
            "chain":"{'https:\/\/github.com\/kiali\/kiali\/commit\/93f5cd0b6698e8fe8772afb8f35816f6c086aef1', 'https:\/\/github.com\/kiali\/kiali\/commit\/c91a0949683976f621cca213c1193831d63b381c'}",
            "dataset":"osv",
            "summary":"Insufficient Session Expiration in Kiali An insufficient JWT validation vulnerability was found in Kiali versions 0.4.0 to 1.15.0 and was fixed in Kiali version 1.15.1, wherein a remote attacker could abuse this flaw by stealing a valid JWT cookie and using that to spoof a user session, possibly gaining privileges to view and alter the Istio configuration.",
            "published_date":"2021-05-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/kiali\/kiali",
            "commit_href":"https:\/\/github.com\/kiali\/kiali\/commit\/c91a0949683976f621cca213c1193831d63b381c",
            "commit_sha":"c91a0949683976f621cca213c1193831d63b381c",
            "patch":"MULTI",
            "chain_ord":"['c91a0949683976f621cca213c1193831d63b381c', '93f5cd0b6698e8fe8772afb8f35816f6c086aef1']",
            "before_first_fix_commit":"{'a660a80b2add1fd2fcfb5662c63824ca1dff95b9'}",
            "last_fix_commit":"93f5cd0b6698e8fe8772afb8f35816f6c086aef1",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/17\/2020, 18:05:17",
            "message":"Fix security issues around 'token' strategy\n\n* Require presence of sid claim",
            "author":"Edgar Hern\u00e1ndez",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'handlers\/authentication.go': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/kiali\/kiali\/raw\/c91a0949683976f621cca213c1193831d63b381c\/handlers%2Fauthentication.go', 'patch': '@@ -425,6 +425,12 @@ func checkTokenSession(w http.ResponseWriter, r *http.Request) (int, string) {\\n \\tif claims, err := config.GetTokenClaimsIfValid(tokenString); err != nil {\\n \\t\\tlog.Warningf(\"Token is invalid: %s\", err.Error())\\n \\t} else {\\n+\\t\\t\/\/ Session ID claim must be present\\n+\\t\\tif len(claims.SessionId) == 0 {\\n+\\t\\t\\tlog.Warning(\"Token is invalid: sid claim is required\")\\n+\\t\\t\\treturn http.StatusUnauthorized, \"\"\\n+\\t\\t}\\n+\\n \\t\\tbusiness, err := business.Get(claims.SessionId)\\n \\t\\tif err != nil {\\n \\t\\t\\tlog.Warning(\"Could not get the business layer : \", err)'}}",
            "message_norm":"fix security issues around 'token' strategy\n\n* require presence of sid claim",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issues', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['handlers\/authentication.go'])",
            "num_files":1.0
        },
        {
            "index":1809,
            "vuln_id":"GHSA-g452-6rfc-vrvx",
            "cwe_id":"{'CWE-915'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/samholmes\/node-open-graph\/commit\/a0cef507a90adaac7dbbe9c404f09a50bdefb348'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in open-graph This affects the package open-graph before 0.2.6. The function parse could be tricked into adding or modifying properties of Object.prototype using a __proto__ or constructor payload.",
            "published_date":"2021-09-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/samholmes\/node-open-graph",
            "commit_href":"https:\/\/github.com\/samholmes\/node-open-graph\/commit\/a0cef507a90adaac7dbbe9c404f09a50bdefb348",
            "commit_sha":"a0cef507a90adaac7dbbe9c404f09a50bdefb348",
            "patch":"SINGLE",
            "chain_ord":"['a0cef507a90adaac7dbbe9c404f09a50bdefb348']",
            "before_first_fix_commit":"{'ef532ed1c51be12155bc1f9baecad09a7c587e04'}",
            "last_fix_commit":"a0cef507a90adaac7dbbe9c404f09a50bdefb348",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/03\/2021, 16:31:10",
            "message":"Patch: Filter out blacklisted keys in og property name",
            "author":"Samuel Holmes",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
            "files":"{'index.js': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/samholmes\/node-open-graph\/raw\/a0cef507a90adaac7dbbe9c404f09a50bdefb348\/index.js', 'patch': '@@ -10,6 +10,11 @@ var shorthandProperties = {\\n \\t\"audio\": \"audio:url\"\\n }\\n \\n+var keyBlacklist = [\\n+\\t\\'__proto__\\',\\n+\\t\\'constructor\\',\\n+\\t\\'prototype\\'\\n+]\\n \\n exports = module.exports = function(url, cb, options){\\n   var userAgent = (options || {}).userAgent || \\'NodeOpenGraphCrawler (https:\/\/github.com\/samholmes\/node-open-graph)\\'\\n@@ -122,6 +127,8 @@ exports.parse = function($, options){\\n \\t\\twhile (keys.length > 1) {\\n \\t\\t\\tkey = keys.shift();\\n \\n+\\t\\t\\tif (keyBlacklist.includes(key)) continue\\n+\\n \\t\\t\\tif (Array.isArray(ptr[key])) {\\n \\t\\t\\t\\t\/\/ the last index of ptr[key] should become\\n \\t\\t\\t\\t\/\/ the object we are examining.'}}",
            "message_norm":"patch: filter out blacklisted keys in og property name",
            "language":"en",
            "entities":"[('blacklisted', 'SECWORD', ''), ('keys', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":2460,
            "vuln_id":"GHSA-mr6r-82x4-f4jj",
            "cwe_id":"{'CWE-203'}",
            "score":7.4,
            "chain":"{'https:\/\/github.com\/simplito\/elliptic-php\/commit\/15652609aa55968d56685c2a9120535ccdc00fd9'}",
            "dataset":"osv",
            "summary":"Timing attacks might allow practical recovery of the long-term private key In elliptic-php versions priot to 1.0.6, Timing attacks might be possible which can result in practical recovery of the long-term private key generated by the library under certain conditions. Leakage of a bit-length of the scalar during scalar multiplication is possible on an elliptic curve which might allow practical recovery of the long-term private key.",
            "published_date":"2019-11-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/simplito\/elliptic-php",
            "commit_href":"https:\/\/github.com\/simplito\/elliptic-php\/commit\/15652609aa55968d56685c2a9120535ccdc00fd9",
            "commit_sha":"15652609aa55968d56685c2a9120535ccdc00fd9",
            "patch":"SINGLE",
            "chain_ord":"['15652609aa55968d56685c2a9120535ccdc00fd9']",
            "before_first_fix_commit":"{'03a8dbc6514a1c8e6b00b967bca388d36ab73169'}",
            "last_fix_commit":"15652609aa55968d56685c2a9120535ccdc00fd9",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/14\/2019, 13:43:07",
            "message":"ecdsa: Apply nonce bit-length mitigation to stop timing leakage.\n\nPorted from elliptic-js: https:\/\/github.com\/indutny\/elliptic\/pull\/203",
            "author":"Sebastian Smyczy\u0144ski",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 1, 'total': 12}",
            "files":"{'lib\/EC.php': {'additions': 11, 'deletions': 1, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/simplito\/elliptic-php\/raw\/15652609aa55968d56685c2a9120535ccdc00fd9\/lib%2FEC.php', 'patch': \"@@ -136,7 +136,17 @@ public function sign($msg, $key, $enc = null, $options = null)\\n             if( $k->cmpn(1) <= 0 || $k->cmp($ns1) >= 0 )\\n                 continue;\\n \\n-            $kp = $this->g->mul($k);\\n+            \/\/ Fix the bit-length of the random nonce,\\n+            \/\/ so that it doesn't leak via timing.\\n+            \/\/ This does not change that ks = k mod k\\n+            $ks = $k->add($this->n);\\n+            $kt = $ks->add($this->n);\\n+            if ($ks->bitLength() === $this->n->bitLength()) {\\n+                $kp = $this->g->mul($kt);\\n+            } else {\\n+                $kp = $this->g->mul($ks);\\n+            }\\n+\\n             if( $kp->isInfinity() )\\n                 continue;\"}}",
            "message_norm":"ecdsa: apply nonce bit-length mitigation to stop timing leakage.\n\nported from elliptic-js: https:\/\/github.com\/indutny\/elliptic\/pull\/203",
            "language":"en",
            "entities":"[('ecdsa', 'SECWORD', ''), ('nonce', 'SECWORD', ''), ('timing leakage', 'SECWORD', ''), ('https:\/\/github.com\/indutny\/elliptic\/pull\/203', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/EC.php'])",
            "num_files":1.0
        },
        {
            "index":1492,
            "vuln_id":"GHSA-c5r5-7pfh-6qg6",
            "cwe_id":"{'CWE-78'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/inukshuk\/bibtex-ruby\/commit\/14406f4460f4e1ecabd25ca94f809b3ea7c5fb11'}",
            "dataset":"osv",
            "summary":"OS command injection in BibTeX-Ruby BibTeX-ruby before 5.1.0 allows shell command injection due to unsanitized user input being passed directly to the built-in Ruby Kernel.open method through BibTeX.open.",
            "published_date":"2020-02-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/inukshuk\/bibtex-ruby",
            "commit_href":"https:\/\/github.com\/inukshuk\/bibtex-ruby\/commit\/14406f4460f4e1ecabd25ca94f809b3ea7c5fb11",
            "commit_sha":"14406f4460f4e1ecabd25ca94f809b3ea7c5fb11",
            "patch":"SINGLE",
            "chain_ord":"['14406f4460f4e1ecabd25ca94f809b3ea7c5fb11']",
            "before_first_fix_commit":"{'707b9303e4ed9a7e136dd1268e21d73d5faab817'}",
            "last_fix_commit":"14406f4460f4e1ecabd25ca94f809b3ea7c5fb11",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/17\/2020, 13:34:37",
            "message":"Use File.read instead of Kernel.open\n\nTo avoid command injection with | strings",
            "author":"Sylvester Keil",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/bibtex\/bibliography.rb': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/inukshuk\/bibtex-ruby\/raw\/14406f4460f4e1ecabd25ca94f809b3ea7c5fb11\/lib%2Fbibtex%2Fbibliography.rb', 'patch': \"@@ -47,7 +47,7 @@ class << self\\n       # -:filter: convert all entries using the sepcified filter (not set by default)\\n       #\\n       def open(path, options = {})\\n-        b = parse(Kernel.open(path, 'r:UTF-8').read, options)\\n+        b = parse(File.read(path), options)\\n         b.path = path\\n         return b unless block_given?\"}}",
            "message_norm":"use file.read instead of kernel.open\n\nto avoid command injection with | strings",
            "language":"en",
            "entities":"[('command injection', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/bibtex\/bibliography.rb'])",
            "num_files":1.0
        },
        {
            "index":3252,
            "vuln_id":"GHSA-w8rc-pgxq-x2cj",
            "cwe_id":"{'CWE-20'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/shopizer-ecommerce\/shopizer\/commit\/929ca0839a80c6f4dad087e0259089908787ad2a'}",
            "dataset":"osv",
            "summary":"Negative charge in shopping cart in Shopizer ### Impact\nUsing API or Controller based versions negative quantity is not adequately validated hence creating incorrect shopping cart and order total. \n\n### Patches\nAdding a back-end verification to check that quantity parameter isn't negative. If so, it is set to 1. Patched in 2.11.0\n\n### Workarounds\nWithout uprading, it's possible to just apply the fixes in the same files it's done for the patch. Or you use javax constraint validation on the quantity parameter.\n\n### References\n[Input Validation](https:\/\/cheatsheetseries.owasp.org\/cheatsheets\/Input_Validation_Cheat_Sheet.html)\n[Using bean validation constraint](https:\/\/javaee.github.io\/tutorial\/bean-validation002.html)\n[Commits with fixes](https:\/\/github.com\/shopizer-ecommerce\/shopizer\/commit\/929ca0839a80c6f4dad087e0259089908787ad2a)\nCVE Details below : \n[Mitre](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-11007)\n[NVD](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-11007)\n\n### Credits\nFound and solved by Yannick Gosset from Aix-Marseille University cybersecurity\nmaster program supervised by Yassine Ilmi",
            "published_date":"2020-04-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/shopizer-ecommerce\/shopizer",
            "commit_href":"https:\/\/github.com\/shopizer-ecommerce\/shopizer\/commit\/929ca0839a80c6f4dad087e0259089908787ad2a",
            "commit_sha":"929ca0839a80c6f4dad087e0259089908787ad2a",
            "patch":"SINGLE",
            "chain_ord":"['929ca0839a80c6f4dad087e0259089908787ad2a']",
            "before_first_fix_commit":"{'de8a8e3183f8c5fed4695f889e309a6fff70adae', '6858049b39bdc51b71e6419b7c4bba1347737cb7'}",
            "last_fix_commit":"929ca0839a80c6f4dad087e0259089908787ad2a",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/10\/2020, 13:35:12",
            "message":"Merge pull request from GHSA-w8rc-pgxq-x2cj\n\nFixing negative charge vulnerability",
            "author":"Shopizer",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 7, 'total': 12}",
            "files":"{'sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java': {'additions': 5, 'deletions': 7, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/shopizer-ecommerce\/shopizer\/raw\/929ca0839a80c6f4dad087e0259089908787ad2a\/sm-shop%2Fsrc%2Fmain%2Fjava%2Fcom%2Fsalesmanager%2Fshop%2Fstore%2Fcontroller%2FshoppingCart%2Ffacade%2FShoppingCartFacadeImpl.java', 'patch': '@@ -108,7 +108,7 @@ public ShoppingCartData addItemsToShoppingCart( final ShoppingCartData shoppingC\\n     {\\n \\n         ShoppingCart cartModel = null;\\n-        \\n+        if(item.getQuantity() < 1) item.setQuantity(1);\\n         \/**\\n          * Sometimes a user logs in and a shopping cart is present in db (shoppingCartData\\n          * but ui has no cookie with shopping cart code so the cart code will have\\n@@ -216,7 +216,7 @@ private com.salesmanager.core.model.shoppingcart.ShoppingCartItem createCartItem\\n         }\\n         \\t\\n         for(ProductAvailability availability : availabilities) {\\n-        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() ==0) {\\n+        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() <= 0) {\\n                 throw new Exception( \"Item with id \" + product.getId() + \" is not available\");\\n         \\t}\\n         }\\n@@ -288,7 +288,7 @@ private com.salesmanager.core.model.shoppingcart.ShoppingCartItem createCartItem\\n         }\\n         \\t\\n         for(ProductAvailability availability : availabilities) {\\n-        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() ==0) {\\n+        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() <= 0) {\\n                 throw new Exception( \"Item with id \" + product.getId() + \" is not available\");\\n         \\t}\\n         }\\n@@ -554,8 +554,7 @@ public ShoppingCartData updateCartItem( final Long itemID, final String cartId,\\n         return null;\\n     }\\n     \\n-    @SuppressWarnings(\"unchecked\")\\n-\\t@Override\\n+    @Override\\n     public ShoppingCartData updateCartItems( final List<ShoppingCartItem> shoppingCartItems, final MerchantStore store, final Language language )\\n             throws Exception\\n         {\\n@@ -720,7 +719,6 @@ public ReadableShoppingCart addToCart(PersistableShoppingCartItem item, Merchant\\n \\t}\\n \\t\\n \\n-\\t@SuppressWarnings(\"unchecked\")\\n \\t@Override\\n \\tpublic void removeShoppingCartItem(String cartCode, Long productId,\\n \\t      MerchantStore merchant, Language language) throws Exception {\\n@@ -914,7 +912,7 @@ public ReadableShoppingCart addToCart(Customer customer, PersistableShoppingCart\\n \\t\\t\\n \\t\\tValidate.notNull(customer,\"Customer cannot be null\");\\n \\t\\tValidate.notNull(customer.getId(),\"Customer.id cannot be null or empty\");\\n-\\t\\t\\n+\\t\\tif(item.getQuantity() < 1) item.setQuantity(1);\\n \\t\\t\/\/Check if customer has an existing shopping cart\\n \\t\\tShoppingCart cartModel = shoppingCartService.getByCustomer(customer);'}}",
            "message_norm":"merge pull request from ghsa-w8rc-pgxq-x2cj\n\nfixing negative charge vulnerability",
            "language":"en",
            "entities":"[('ghsa-w8rc-pgxq-x2cj', 'VULNID', 'GHSA'), ('fixing', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['sm-shop\/src\/main\/java\/com\/salesmanager\/shop\/store\/controller\/shoppingCart\/facade\/ShoppingCartFacadeImpl.java'])",
            "num_files":1.0
        },
        {
            "index":2915,
            "vuln_id":"GHSA-rc8h-3fv6-pxv8",
            "cwe_id":"{'CWE-400'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/hapijs\/hapi\/commit\/aab2496e930dce5ee1ab28eecec94e0e45f03580'}",
            "dataset":"osv",
            "summary":"Denial of Service in hapi Versions of `hapi` prior to 11.1.3 are affected by a denial of service vulnerability.\n\nThe vulnerability is triggered when certain input is passed into the If-Modified-Since or Last-Modified headers.\n\nThis causes an 'illegal access' exception to be raised, and instead of sending a HTTP 500 error back to the sender, hapi will continue to hold the socket open until timed out (default node timeout is 2 minutes).\n\n\n\n\n\n## Recommendation\n\nUpdate to v11.1.3 or later",
            "published_date":"2018-06-07",
            "chain_len":1,
            "project":"https:\/\/github.com\/hapijs\/hapi",
            "commit_href":"https:\/\/github.com\/hapijs\/hapi\/commit\/aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "commit_sha":"aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "patch":"SINGLE",
            "chain_ord":"['aab2496e930dce5ee1ab28eecec94e0e45f03580']",
            "before_first_fix_commit":"{'1ad65ba793377928aa5a2dfc819888c5c9793394', 'ef2a0f85d558eeb102c512fac45386b2145cb903'}",
            "last_fix_commit":"aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/23\/2015, 21:54:47",
            "message":"Merge pull request #2988 from hapijs\/v11.1.x\n\nHandle invalid date exceptions",
            "author":"Eran Hammer",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 2, 'total': 13}",
            "files":"{'lib\/transmit.js': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hapijs\/hapi\/raw\/aab2496e930dce5ee1ab28eecec94e0e45f03580\/lib%2Ftransmit.js', 'patch': '@@ -82,8 +82,8 @@ internals.marshal = function (request, next) {\\n \\n                 \/\/ Weak verifier\\n \\n-                const ifModifiedSince = Date.parse(ifModifiedSinceHeader);\\n-                const lastModified = Date.parse(lastModifiedHeader);\\n+                const ifModifiedSince = internals.parseDate(ifModifiedSinceHeader);\\n+                const lastModified = internals.parseDate(lastModifiedHeader);\\n \\n                 if (ifModifiedSince &&\\n                     lastModified &&\\n@@ -147,6 +147,15 @@ internals.marshal = function (request, next) {\\n };\\n \\n \\n+internals.parseDate = function (string) {\\n+\\n+    try {\\n+        return Date.parse(string);\\n+    }\\n+    catch (errIgnore) { }\\n+};\\n+\\n+\\n internals.fail = function (request, boom, callback) {\\n \\n     const error = boom.output;'}}",
            "message_norm":"merge pull request #2988 from hapijs\/v11.1.x\n\nhandle invalid date exceptions",
            "language":"en",
            "entities":"[('#2988', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/transmit.js'])",
            "num_files":1.0
        },
        {
            "index":1698,
            "vuln_id":"GHSA-f8m6-h2c7-8h9x",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/nltk\/nltk\/commit\/1405aad979c6b8080dbbc8e0858f89b2e3690341'}",
            "dataset":"osv",
            "summary":"Inefficient Regular Expression Complexity in nltk (word_tokenize, sent_tokenize) ### Impact\nThe vulnerability is present in [`PunktSentenceTokenizer`](https:\/\/www.nltk.org\/api\/nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer), [`sent_tokenize`](https:\/\/www.nltk.org\/api\/nltk.tokenize.html#nltk.tokenize.sent_tokenize)  and [`word_tokenize`](https:\/\/www.nltk.org\/api\/nltk.tokenize.html#nltk.tokenize.word_tokenize). Any users of this class, or these two functions, are vulnerable to a Regular Expression Denial of Service (ReDoS) attack. \nIn short, a specifically crafted long input to any of these vulnerable functions will cause them to take a significant amount of execution time. The effect of this vulnerability is noticeable with the following example:\n```python\nfrom nltk.tokenize import word_tokenize\n\nn = 8\nfor length in [10**i for i in range(2, n)]:\n    # Prepare a malicious input\n    text = \"a\" * length\n    start_t = time.time()\n    # Call `word_tokenize` and naively measure the execution time\n    word_tokenize(text)\n    print(f\"A length of {length:<{n}} takes {time.time() - start_t:.4f}s\")\n```\nWhich gave the following output during testing:\n```python\nA length of 100      takes 0.0060s\nA length of 1000     takes 0.0060s\nA length of 10000    takes 0.6320s\nA length of 100000   takes 56.3322s\n...\n```\nI canceled the execution of the program after running it for several hours.\n\nIf your program relies on any of the vulnerable functions for tokenizing unpredictable user input, then we would strongly recommend upgrading to a version of NLTK without the vulnerability, or applying the workaround described below.\n\n### Patches\nThe problem has been patched in NLTK 3.6.6. After the fix, running the above program gives the following result:\n```python\nA length of 100      takes 0.0070s\nA length of 1000     takes 0.0010s\nA length of 10000    takes 0.0060s\nA length of 100000   takes 0.0400s\nA length of 1000000  takes 0.3520s\nA length of 10000000 takes 3.4641s\n```\nThis output shows a linear relationship in execution time versus input length, which is desirable for regular expressions.\nWe recommend updating to NLTK 3.6.6+ if possible.\n\n### Workarounds\nThe execution time of the vulnerable functions is exponential to the length of a malicious input. With other words, the execution time can be bounded by limiting the maximum length of an input to any of the vulnerable functions. Our recommendation is to implement such a limit.\n\n### References\n* The issue showcasing the vulnerability: https:\/\/github.com\/nltk\/nltk\/issues\/2866\n* The pull request containing considerably more information on the vulnerability, and the fix: https:\/\/github.com\/nltk\/nltk\/pull\/2869\n* The commit containing the fix: 1405aad979c6b8080dbbc8e0858f89b2e3690341\n* Information on CWE-1333: Inefficient Regular Expression Complexity: https:\/\/cwe.mitre.org\/data\/definitions\/1333.html\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [github.com\/nltk\/nltk](https:\/\/github.com\/nltk\/nltk)\n* Email us at [nltk.team@gmail.com](mailto:nltk.team@gmail.com)",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/nltk\/nltk",
            "commit_href":"https:\/\/github.com\/nltk\/nltk\/commit\/1405aad979c6b8080dbbc8e0858f89b2e3690341",
            "commit_sha":"1405aad979c6b8080dbbc8e0858f89b2e3690341",
            "patch":"SINGLE",
            "chain_ord":"['1405aad979c6b8080dbbc8e0858f89b2e3690341']",
            "before_first_fix_commit":"{'0b7b076247ec41f9b6b8a94400d48ea299e4b507'}",
            "last_fix_commit":"1405aad979c6b8080dbbc8e0858f89b2e3690341",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/26\/2021, 11:58:19",
            "message":"Resolved serious ReDoS in PunktSentenceTokenizer (#2869)\n\n* Resolved serious ReDOS in PunktSentenceTokenizer\r\n\r\n* Improve performance by relying on string split instead of re.search\r\n\r\n* Solved issue if sentence contains just one token",
            "author":"Tom Aarsen",
            "comments":null,
            "stats":"{'additions': 61, 'deletions': 5, 'total': 66}",
            "files":"{'nltk\/tokenize\/punkt.py': {'additions': 61, 'deletions': 5, 'changes': 66, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nltk\/nltk\/raw\/1405aad979c6b8080dbbc8e0858f89b2e3690341\/nltk%2Ftokenize%2Fpunkt.py', 'patch': '@@ -266,7 +266,6 @@ def word_tokenize(self, s):\\n         return self._word_tokenizer_re().findall(s)\\n \\n     _period_context_fmt = r\"\"\"\\n-        \\\\S*                          # some word material\\n         %(SentEndChars)s             # a potential sentence ending\\n         (?=(?P<after_tok>\\n             %(NonWord)s              # either other punctuation\\n@@ -1284,8 +1283,7 @@ def debug_decisions(self, text):\\n         See format_debug_decision() to help make this output readable.\\n         \"\"\"\\n \\n-        for match in self._lang_vars.period_context_re().finditer(text):\\n-            decision_text = match.group() + match.group(\"after_tok\")\\n+        for match, decision_text in self._match_potential_end_contexts(text):\\n             tokens = self._tokenize_words(decision_text)\\n             tokens = list(self._annotate_first_pass(tokens))\\n             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars):\\n@@ -1333,10 +1331,68 @@ def sentences_from_text(self, text, realign_boundaries=True):\\n         \"\"\"\\n         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\\n \\n+    def _match_potential_end_contexts(self, text):\\n+        \"\"\"\\n+        Given a text, find the matches of potential sentence breaks,\\n+        alongside the contexts surrounding these sentence breaks.\\n+\\n+        Since the fix for the ReDOS discovered in issue #2866, we no longer match\\n+        the word before a potential end of sentence token. Instead, we use a separate\\n+        regex for this. As a consequence, `finditer`\\'s desire to find non-overlapping\\n+        matches no longer aids us in finding the single longest match.\\n+        Where previously, we could use::\\n+\\n+            >>> pst = PunktSentenceTokenizer()\\n+            >>> text = \"Very bad acting!!! I promise.\"\\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP\\n+            [<re.Match object; span=(9, 18), match=\\'acting!!!\\'>]\\n+\\n+        Now we have to find the word before (i.e. \\'acting\\') separately, and `finditer`\\n+        returns::\\n+\\n+            >>> pst = PunktSentenceTokenizer()\\n+            >>> text = \"Very bad acting!!! I promise.\"\\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE\\n+            [<re.Match object; span=(15, 16), match=\\'!\\'>,\\n+            <re.Match object; span=(16, 17), match=\\'!\\'>,\\n+            <re.Match object; span=(17, 18), match=\\'!\\'>]\\n+\\n+        So, we need to find the word before the match from right to left, and then manually remove\\n+        the overlaps. That is what this method does::\\n+\\n+            >>> pst = PunktSentenceTokenizer()\\n+            >>> text = \"Very bad acting!!! I promise.\"\\n+            >>> pst._match_potential_end_contexts(text)\\n+            [(<re.Match object; span=(17, 18), match=\\'!\\'>, \\'acting!!! I\\')]\\n+\\n+        :param text: String of one or more sentences\\n+        :type text: str\\n+        :return: List of match-context tuples.\\n+        :rtype: List[Tuple[re.Match, str]]\\n+        \"\"\"\\n+        before_words = {}\\n+        matches = []\\n+        for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):\\n+            # Ignore matches that have already been captured by matches to the right of this match\\n+            if matches and match.end() > before_start:\\n+                continue\\n+            # Find the word before the current match\\n+            split = text[: match.start()].rsplit(maxsplit=1)\\n+            before_start = len(split[0]) if len(split) == 2 else 0\\n+            before_words[match] = split[-1]\\n+            matches.append(match)\\n+\\n+        return [\\n+            (\\n+                match,\\n+                before_words[match] + match.group() + match.group(\"after_tok\"),\\n+            )\\n+            for match in matches[::-1]\\n+        ]\\n+\\n     def _slices_from_text(self, text):\\n         last_break = 0\\n-        for match in self._lang_vars.period_context_re().finditer(text):\\n-            context = match.group() + match.group(\"after_tok\")\\n+        for match, context in self._match_potential_end_contexts(text):\\n             if self.text_contains_sentbreak(context):\\n                 yield slice(last_break, match.end())\\n                 if match.group(\"next_tok\"):'}}",
            "message_norm":"resolved serious redos in punktsentencetokenizer (#2869)\n\n* resolved serious redos in punktsentencetokenizer\r\n\r\n* improve performance by relying on string split instead of re.search\r\n\r\n* solved issue if sentence contains just one token",
            "language":"en",
            "entities":"[('redos', 'SECWORD', ''), ('#2869', 'ISSUE', ''), ('redos', 'SECWORD', ''), ('improve', 'ACTION', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['nltk\/tokenize\/punkt.py'])",
            "num_files":1.0
        },
        {
            "index":2117,
            "vuln_id":"GHSA-hr84-fqvp-48mm",
            "cwe_id":"{'CWE-131'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c57c0b9f3a4f8684f3489dd9a9ec627ad8b599f5'}",
            "dataset":"osv",
            "summary":"Segfault in SparseCountSparseOutput ### Impact\nSpecifying a negative dense shape in `tf.raw_ops.SparseCountSparseOutput` results in a segmentation fault being thrown out from the standard library as `std::vector` invariants are broken.\n\n```python\nimport tensorflow as tf\n\nindices = tf.constant([], shape=[0, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0, 0], dtype=tf.int64)\ndense_shape = tf.constant([-100, -100, -100], shape=[3], dtype=tf.int64)\nweights = tf.constant([], shape=[0, 0], dtype=tf.int64)\n\ntf.raw_ops.SparseCountSparseOutput(indices=indices, values=values, dense_shape=dense_shape, weights=weights, minlength=79, maxlength=96, binary_output=False)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8f7b60ee8c0206a2c99802e3a4d1bb55d2bc0624\/tensorflow\/core\/kernels\/count_ops.cc#L199-L213) assumes the first element of the dense shape is always positive and uses it to initialize a `BatchedMap<T>` (i.e., [`std::vector<absl::flat_hash_map<int64,T>>`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8f7b60ee8c0206a2c99802e3a4d1bb55d2bc0624\/tensorflow\/core\/kernels\/count_ops.cc#L27)) data structure.\n\n```cc\n  bool is_1d = shape.NumElements() == 1;\n  int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\n  ...\n  auto per_batch_counts = BatchedMap<W>(num_batches); \n```\n\nIf the `shape` tensor has more than one element, `num_batches` is the first value in `shape`.\n                       \nEnsuring that the `dense_shape` argument is a valid tensor shape (that is, all elements are non-negative) solves this issue.\n\n### Patches\nWe have patched the issue in GitHub commit [c57c0b9f3a4f8684f3489dd9a9ec627ad8b599f5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c57c0b9f3a4f8684f3489dd9a9ec627ad8b599f5).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2 and TensorFlow 2.3.3.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c57c0b9f3a4f8684f3489dd9a9ec627ad8b599f5",
            "commit_sha":"c57c0b9f3a4f8684f3489dd9a9ec627ad8b599f5",
            "patch":"SINGLE",
            "chain_ord":"['c57c0b9f3a4f8684f3489dd9a9ec627ad8b599f5']",
            "before_first_fix_commit":"{'8f7b60ee8c0206a2c99802e3a4d1bb55d2bc0624'}",
            "last_fix_commit":"c57c0b9f3a4f8684f3489dd9a9ec627ad8b599f5",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/19\/2021, 18:33:50",
            "message":"Fix the segfault in `tf.raw_ops.SparseCountSparseOutput`.\n\nPiperOrigin-RevId: 369264941\nChange-Id: I23a96a15b8370c01ee21ba3841e1c7dcbf55e93d",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 1, 'total': 10}",
            "files":"{'tensorflow\/core\/kernels\/count_ops.cc': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c57c0b9f3a4f8684f3489dd9a9ec627ad8b599f5\/tensorflow%2Fcore%2Fkernels%2Fcount_ops.cc', 'patch': '@@ -197,9 +197,17 @@ class SparseCount : public OpKernel {\\n                     \"The shape argument requires at least one element.\"));\\n \\n     bool is_1d = shape.NumElements() == 1;\\n-    int num_batches = is_1d ? 1 : shape.flat<int64>()(0);\\n+    auto shape_vector = shape.flat<int64>();\\n+    int num_batches = is_1d ? 1 : shape_vector(0);\\n     int num_values = values.NumElements();\\n \\n+    for (int b = 0; b < shape_vector.size(); b++) {\\n+      OP_REQUIRES(context, shape_vector(b) >= 0,\\n+                  errors::InvalidArgument(\\n+                      \"Elements in dense_shape must be >= 0. Instead got:\",\\n+                      shape.DebugString()));\\n+    }\\n+\\n     OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\\n                 errors::InvalidArgument(\\n                     \"Number of values must match first dimension of indices.\",'}}",
            "message_norm":"fix the segfault in `tf.raw_ops.sparsecountsparseoutput`.\n\npiperorigin-revid: 369264941\nchange-id: i23a96a15b8370c01ee21ba3841e1c7dcbf55e93d",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('segfault', 'SECWORD', ''), ('369264941', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/count_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":1463,
            "vuln_id":"GHSA-c32w-3cqh-f6jx",
            "cwe_id":"{'CWE-640'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/Dolibarr\/dolibarr\/commit\/87f9530272925f0d651f59337a35661faeb6f377'}",
            "dataset":"osv",
            "summary":"Weak Password Recovery Mechanism for Forgotten Password In \u201cDolibarr\u201d application, v2.8.1 to v13.0.2 are vulnerable to account takeover via password reset functionality. A low privileged attacker can reset the password of any user in the application using the password reset link the user received through email when requested for a forgotten password.",
            "published_date":"2021-09-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/Dolibarr\/dolibarr",
            "commit_href":"https:\/\/github.com\/Dolibarr\/dolibarr\/commit\/87f9530272925f0d651f59337a35661faeb6f377",
            "commit_sha":"87f9530272925f0d651f59337a35661faeb6f377",
            "patch":"SINGLE",
            "chain_ord":"['87f9530272925f0d651f59337a35661faeb6f377']",
            "before_first_fix_commit":"{'8b07e99e05a9ed3c57bdc00c6a469fbbaa5672ef'}",
            "last_fix_commit":"87f9530272925f0d651f59337a35661faeb6f377",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/05\/2021, 15:29:10",
            "message":"Fix report by Ahsan Aziz (can reset the password of another user that\ndid not request password reset).",
            "author":"Laurent Destailleur",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'htdocs\/user\/passwordforgotten.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Dolibarr\/dolibarr\/raw\/87f9530272925f0d651f59337a35661faeb6f377\/htdocs%2Fuser%2Fpasswordforgotten.php', 'patch': '@@ -87,14 +87,14 @@\\n \\t\/\/ Validate new password\\n \\tif ($action == \\'validatenewpassword\\' && $username && $passworduidhash) {\\n \\t\\t$edituser = new User($db);\\n-\\t\\t$result = $edituser->fetch(\\'\\', $_GET[\"username\"]);\\n+\\t\\t$result = $edituser->fetch(\\'\\', $username);\\n \\t\\tif ($result < 0) {\\n \\t\\t\\t$message = \\'<div class=\"error\">\\'.dol_escape_htmltag($langs->trans(\"ErrorLoginDoesNotExists\", $username)).\\'<\/div>\\';\\n \\t\\t} else {\\n \\t\\t\\tglobal $dolibarr_main_instance_unique_id;\\n \\n \\t\\t\\t\/\/print $edituser->pass_temp.\\'-\\'.$edituser->id.\\'-\\'.$dolibarr_main_instance_unique_id.\\' \\'.$passworduidhash;\\n-\\t\\t\\tif (dol_verifyHash($edituser->pass_temp.\\'-\\'.$edituser->id.\\'-\\'.$dolibarr_main_instance_unique_id, $passworduidhash)) {\\n+\\t\\t\\tif ($edituser->pass_temp && dol_verifyHash($edituser->pass_temp.\\'-\\'.$edituser->id.\\'-\\'.$dolibarr_main_instance_unique_id, $passworduidhash)) {\\n \\t\\t\\t\\t\/\/ Clear session\\n \\t\\t\\t\\tunset($_SESSION[\\'dol_login\\']);\\n \\t\\t\\t\\t$_SESSION[\\'dol_loginmesg\\'] = $langs->trans(\\'NewPasswordValidated\\'); \/\/ Save message for the session page'}}",
            "message_norm":"fix report by ahsan aziz (can reset the password of another user that\ndid not request password reset).",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('password', 'SECWORD', ''), ('password', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['htdocs\/user\/passwordforgotten.php'])",
            "num_files":1.0
        },
        {
            "index":251,
            "vuln_id":"GHSA-3fw8-66wf-pr7m",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/senchalabs\/connect\/commit\/126187c4e12162e231b87350740045e5bb06e93a', 'https:\/\/github.com\/senchalabs\/connect\/commit\/277e5aad6a95d00f55571a9a0e11f2fa190d8135'}",
            "dataset":"osv",
            "summary":"methodOverride Middleware Reflected Cross-Site Scripting in connect Connect is a stack of middleware that is executed in order in each request.\n\nThe \"methodOverride\" middleware allows the http post to override the method of the request with the value of the \"_method\" post key or with the header \"x-http-method-override\".\n\nBecause the user post input was not checked, req.method could contain any kind of value. Because the req.method did not match any common method VERB, connect answered with a 404 page containing the \"Cannot `[method]` `[url]`\" content. The method was not properly encoded for output in the browser.\n\n\n###Example:\n```\n~ curl \"localhost:3000\" -d \"_method=<script src=http:\/\/nodesecurity.io\/xss.js><\/script>\"\nCannot <SCRIPT SRC=HTTP:\/\/NODESECURITY.IO\/XSS.JS><\/SCRIPT> \/\n```\n\n## Recommendation\n\nUpdate to the newest version of Connect or disable methodOverride. It is not possible to avoid the vulnerability if you have enabled this middleware in the top of your stack.",
            "published_date":"2020-08-31",
            "chain_len":2,
            "project":"https:\/\/github.com\/senchalabs\/connect",
            "commit_href":"https:\/\/github.com\/senchalabs\/connect\/commit\/277e5aad6a95d00f55571a9a0e11f2fa190d8135",
            "commit_sha":"277e5aad6a95d00f55571a9a0e11f2fa190d8135",
            "patch":"MULTI",
            "chain_ord":"['277e5aad6a95d00f55571a9a0e11f2fa190d8135', '126187c4e12162e231b87350740045e5bb06e93a']",
            "before_first_fix_commit":"{'b0df35bcf2e1b4e487a17889a8440ecf254ac3b4'}",
            "last_fix_commit":"126187c4e12162e231b87350740045e5bb06e93a",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/27\/2013, 15:31:23",
            "message":"fix: escape req.method in 404 response",
            "author":"TJ Holowaychuk",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'lib\/proto.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/senchalabs\/connect\/raw\/277e5aad6a95d00f55571a9a0e11f2fa190d8135\/lib%2Fproto.js', 'patch': \"@@ -152,7 +152,7 @@ app.handle = function(req, res, out) {\\n         res.statusCode = 404;\\n         res.setHeader('Content-Type', 'text\/plain');\\n         if ('HEAD' == req.method) return res.end();\\n-        res.end('Cannot ' + req.method + ' ' + utils.escape(req.originalUrl));\\n+        res.end('Cannot ' + utils.escape(req.method) + ' ' + utils.escape(req.originalUrl));\\n       }\\n       return;\\n     }\\n@@ -202,7 +202,7 @@ app.handle = function(req, res, out) {\\n  * Listen for connections.\\n  *\\n  * This method takes the same arguments\\n- * as node's `http.Server#listen()`.  \\n+ * as node's `http.Server#listen()`.\\n  *\\n  * HTTP and HTTPS:\\n  *\\n@@ -214,9 +214,9 @@ app.handle = function(req, res, out) {\\n  *      var connect = require('connect')\\n  *        , http = require('http')\\n  *        , https = require('https');\\n- *      \\n+ *\\n  *      var app = connect();\\n- *      \\n+ *\\n  *      http.createServer(app).listen(80);\\n  *      https.createServer(options, app).listen(443);\\n  *\"}}",
            "message_norm":"fix: escape req.method in 404 response",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/proto.js'])",
            "num_files":1.0
        },
        {
            "index":63,
            "vuln_id":"GHSA-2877-693q-pj33",
            "cwe_id":"{'CWE-78'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/genieacs\/genieacs\/commit\/7f295beeecc1c1f14308a93c82413bb334045af6'}",
            "dataset":"osv",
            "summary":"OS Command Injection in GenieACS In GenieACS 1.2.x before 1.2.8, the UI interface API is vulnerable to unauthenticated OS command injection via the ping host argument (lib\/ui\/api.ts and lib\/ping.ts). The vulnerability arises from insufficient input validation combined with a missing authorization check.",
            "published_date":"2022-03-07",
            "chain_len":1,
            "project":"https:\/\/github.com\/genieacs\/genieacs",
            "commit_href":"https:\/\/github.com\/genieacs\/genieacs\/commit\/7f295beeecc1c1f14308a93c82413bb334045af6",
            "commit_sha":"7f295beeecc1c1f14308a93c82413bb334045af6",
            "patch":"SINGLE",
            "chain_ord":"['7f295beeecc1c1f14308a93c82413bb334045af6']",
            "before_first_fix_commit":"{'2ac536bf8f2dd03c24b2eff35b69578b4efae94e'}",
            "last_fix_commit":"7f295beeecc1c1f14308a93c82413bb334045af6",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/14\/2021, 07:33:35",
            "message":"Validate host arg passed to ping\n\nFixes remote code execution vulnerability reported by Alex Hordijk.",
            "author":"Zaid Abdulla",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
            "files":"{'lib\/ping.ts': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/genieacs\/genieacs\/raw\/7f295beeecc1c1f14308a93c82413bb334045af6\/lib%2Fping.ts', 'patch': '@@ -19,6 +19,7 @@\\n \\n import { platform } from \"os\";\\n import { exec } from \"child_process\";\\n+import { domainToASCII } from \"url\";\\n \\n export interface PingResult {\\n   packetsTransmitted: number;\\n@@ -30,11 +31,23 @@ export interface PingResult {\\n   mdev: number;\\n }\\n \\n+function isValidHost(host: string): boolean {\\n+  \/\/ Valid chars in IPv4, IPv6, domain names\\n+  if (\/^[a-zA-Z0-9\\\\-.:[\\\\]-]+$\/.test(host)) return true;\\n+\\n+  \/\/ Check if input is an IDN convert to Punycode\\n+  \/\/ Can\\'t merge with above because domainToASCII doesn\\'t accept IP addresses\\n+  return \/^[a-zA-Z0-9\\\\-.:[\\\\]-]+$\/.test(domainToASCII(host));\\n+}\\n+\\n export function ping(\\n   host: string,\\n   callback: (err: Error, res?: PingResult, stdout?: string) => void\\n ): void {\\n   let cmd: string, parseRegExp1: RegExp, parseRegExp2: RegExp;\\n+  \/\/ Validate input to prevent possible remote code execution\\n+  \/\/ Credit to Alex Hordijk for reporting this vulnerability\\n+  if (!isValidHost(host)) return callback(new Error(\"Invalid host\"));\\n   host = host.replace(\"[\", \"\").replace(\"]\", \"\");\\n   switch (platform()) {\\n     case \"linux\":'}}",
            "message_norm":"validate host arg passed to ping\n\nfixes remote code execution vulnerability reported by alex hordijk.",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('fixes', 'ACTION', ''), ('remote code execution', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/ping.ts'])",
            "num_files":1.0
        },
        {
            "index":1022,
            "vuln_id":"GHSA-7fc2-rm35-2pp7",
            "cwe_id":"{'CWE-352'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/ipython\/ipython\/commit\/1415a9710407e7c14900531813c15ba6165f0816', 'https:\/\/github.com\/ipython\/ipython\/commit\/a05fe052a18810e92d9be8c1185952c13fe4e5b0'}",
            "dataset":"osv",
            "summary":"IPython vulnerable to cross site request forgery (CSRF) IPython (Interactive Python) is a command shell. Cross-site request forgery in the REST API is possible in in IPython 2 and 3. Versions 2.4.1 and 3.2.3 contain patches.",
            "published_date":"2022-05-17",
            "chain_len":2,
            "project":"https:\/\/github.com\/ipython\/ipython",
            "commit_href":"https:\/\/github.com\/ipython\/ipython\/commit\/a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "commit_sha":"a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "patch":"MULTI",
            "chain_ord":"['1415a9710407e7c14900531813c15ba6165f0816', 'a05fe052a18810e92d9be8c1185952c13fe4e5b0']",
            "before_first_fix_commit":"{'6884e8b36dc1e2d59e1d8ddb5e95788728d76e6f'}",
            "last_fix_commit":"a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/12\/2015, 15:36:44",
            "message":"backport origin check for API requests",
            "author":"Min RK",
            "comments":null,
            "stats":"{'additions': 48, 'deletions': 0, 'total': 48}",
            "files":"{'IPython\/html\/base\/handlers.py': {'additions': 48, 'deletions': 0, 'changes': 48, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ipython\/ipython\/raw\/a05fe052a18810e92d9be8c1185952c13fe4e5b0\/IPython%2Fhtml%2Fbase%2Fhandlers.py', 'patch': '@@ -29,6 +29,10 @@\\n     from http.client import responses\\n except ImportError:\\n     from httplib import responses\\n+try:\\n+    from urllib.parse import urlparse # Py 3\\n+except ImportError:\\n+    from urlparse import urlparse # Py 2\\n \\n from jinja2 import TemplateNotFound\\n from tornado import web\\n@@ -208,6 +212,50 @@ def get_origin(self):\\n             origin = self.request.headers.get(\"Sec-Websocket-Origin\", None)\\n         return origin\\n \\n+    def check_origin_api(self):\\n+        \"\"\"Check Origin for cross-site API requests.\\n+        \\n+        Copied from WebSocket with changes:\\n+        \\n+        - allow unspecified host\/origin (e.g. scripts)\\n+        \"\"\"\\n+        if self.allow_origin == \\'*\\':\\n+            return True\\n+\\n+        host = self.request.headers.get(\"Host\")\\n+        origin = self.request.headers.get(\"Origin\")\\n+\\n+        # If no header is provided, assume it comes from a script\/curl.\\n+        # We are only concerned with cross-site browser stuff here.\\n+        if origin is None or host is None:\\n+            return True\\n+        \\n+        origin = origin.lower()\\n+        origin_host = urlparse(origin).netloc\\n+        \\n+        # OK if origin matches host\\n+        if origin_host == host:\\n+            return True\\n+        \\n+        # Check CORS headers\\n+        if self.allow_origin:\\n+            allow = self.allow_origin == origin\\n+        elif self.allow_origin_pat:\\n+            allow = bool(self.allow_origin_pat.match(origin))\\n+        else:\\n+            # No CORS headers deny the request\\n+            allow = False\\n+        if not allow:\\n+            self.log.warn(\"Blocking Cross Origin API request.  Origin: %s, Host: %s\",\\n+                origin, host,\\n+            )\\n+        return allow\\n+\\n+    def prepare(self):\\n+        if not self.check_origin_api():\\n+            raise web.HTTPError(404)\\n+        return super(IPythonHandler, self).prepare()\\n+\\n     #---------------------------------------------------------------\\n     # template rendering\\n     #---------------------------------------------------------------'}}",
            "message_norm":"backport origin check for api requests",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['IPython\/html\/base\/handlers.py'])",
            "num_files":1.0
        },
        {
            "index":2028,
            "vuln_id":"GHSA-h8v5-p258-pqf4",
            "cwe_id":"{'CWE-327'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/26728f3f23658288683667a5182a916c7ecefc52'}",
            "dataset":"osv",
            "summary":"Use of a Broken or Risky Cryptographic Algorithm in XWiki Crypto API ### Impact\nXWiki Crypto API will generate X509 certificates signed by default using SHA1 with RSA, which is not considered safe anymore for use in certificate signatures, due to the risk of collisions with SHA1.\nNote that this API is never used in XWiki Standard but it might be used in some extensions of XWiki.\n\n### Patches\nThe problem has been patched in XWiki version 13.10.6, 14.3.1 and 14.4-rc-1. Since then, the Crypto API will generate X509 certificates signed by default using SHA256 with RSA.\n\n### Workarounds\nAdministrators are advised to upgrade their XWiki installation to one of the patched versions.\nIf the upgrade is not possible, it is possible to patch the module xwiki-platform-crypto in a local installation by applying the change exposed in https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/26728f3f23658288683667a5182a916c7ecefc52 and re-compiling the module.\n\n### References\nhttps:\/\/jira.xwiki.org\/browse\/XWIKI-19676\nhttps:\/\/github.com\/openssl\/openssl\/blob\/master\/CHANGES.md?plain=1#L938\nhttps:\/\/github.com\/openssl\/openssl\/issues\/16650\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Jira XWiki](https:\/\/jira.xwiki.org)\n* Email us at [security ML](mailto:security@xwiki.org)",
            "published_date":"2022-05-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/xwiki\/xwiki-platform",
            "commit_href":"https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/26728f3f23658288683667a5182a916c7ecefc52",
            "commit_sha":"26728f3f23658288683667a5182a916c7ecefc52",
            "patch":"SINGLE",
            "chain_ord":"['26728f3f23658288683667a5182a916c7ecefc52']",
            "before_first_fix_commit":"{'3b871d906e664fa1875fbeb088404cf31e9f0094'}",
            "last_fix_commit":"26728f3f23658288683667a5182a916c7ecefc52",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/30\/2022, 10:13:25",
            "message":"XWIKI-19676: Update the RSA Crypto script service to use SHA256 instead of SHA1 for certificate signature",
            "author":"Cl\u00e9ment Aubin",
            "comments":"{'com_1': {'author': 'surli', 'datetime': '05\/02\/2022, 06:58:35', 'body': \"I don't know much this class, but is that ok in term of backward compatibility? If you have some signed stuff in the wiki with that script service, will it be still be able to verify the signature?\"}, 'com_2': {'author': 'aubincleme', 'datetime': '05\/02\/2022, 07:27:55', 'body': 'Yes to me it is fine : the SignerFactory is only used to sign certificates, not verify them. For this the CMSSignedDataVerifier is used instead, which is able to verify signatures based on the different algorithms supported by the crypto API.'}, 'com_3': {'author': 'tmortagne', 'datetime': '05\/02\/2022, 09:10:05', 'body': \"In that case, I'm wondering if this should be cherry-picked in 13.10.x. WDYT @aubincleme ?\"}, 'com_4': {'author': 'aubincleme', 'datetime': '05\/02\/2022, 09:46:37', 'body': 'Yes why not ; doing it now'}, 'com_5': {'author': 'aubincleme', 'datetime': '05\/02\/2022, 09:48:21', 'body': 'done as part of a7c3628609f63b04de80935efa2e1f82e1356846 ;\\xa0updating issue + release notes'}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'xwiki-platform-core\/xwiki-platform-crypto\/xwiki-platform-crypto-script\/src\/main\/java\/org\/xwiki\/crypto\/script\/RSACryptoScriptService.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/xwiki\/xwiki-platform\/raw\/26728f3f23658288683667a5182a916c7ecefc52\/xwiki-platform-core%2Fxwiki-platform-crypto%2Fxwiki-platform-crypto-script%2Fsrc%2Fmain%2Fjava%2Forg%2Fxwiki%2Fcrypto%2Fscript%2FRSACryptoScriptService.java', 'patch': '@@ -86,7 +86,7 @@ public class RSACryptoScriptService implements ScriptService\\n     private KeyPairGenerator keyPairGenerator;\\n \\n     @Inject\\n-    @Named(\"SHA1withRSAEncryption\")\\n+    @Named(\"SHA256withRSAEncryption\")\\n     private SignerFactory signerFactory;\\n \\n     @Inject'}}",
            "message_norm":"xwiki-19676: update the rsa crypto script service to use sha256 instead of sha1 for certificate signature",
            "language":"en",
            "entities":"[('update', 'ACTION', ''), ('rsa', 'SECWORD', ''), ('crypto', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('signature', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['xwiki-platform-core\/xwiki-platform-crypto\/xwiki-platform-crypto-script\/src\/main\/java\/org\/xwiki\/crypto\/script\/RSACryptoScriptService.java'])",
            "num_files":1.0
        },
        {
            "index":3204,
            "vuln_id":"GHSA-w32p-76xr-88pc",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/90f67afac6362828c750f3bccbcc1c360caf29e4', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/3d6226cc2d1077537220361c82e34a362c6c76ee'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-0989, CVE-2019-0991, CVE-2019-0992, CVE-2019-0993, CVE-2019-1002, CVE-2019-1024, CVE-2019-1051, CVE-2019-1052.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/90f67afac6362828c750f3bccbcc1c360caf29e4",
            "commit_sha":"90f67afac6362828c750f3bccbcc1c360caf29e4",
            "patch":"MULTI",
            "chain_ord":"['90f67afac6362828c750f3bccbcc1c360caf29e4', '3d6226cc2d1077537220361c82e34a362c6c76ee']",
            "before_first_fix_commit":"{'d797e3f00e34c12c8c0ae52f56344325439dccd7', 'eabf77ad17010f220639e5261798da9ac14e43e3'}",
            "last_fix_commit":"3d6226cc2d1077537220361c82e34a362c6c76ee",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/15\/2019, 22:37:38",
            "message":"CVE-2019-1003",
            "author":"Paul Leathers",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'lib\/Runtime\/Library\/JavascriptProxy.cpp': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/90f67afac6362828c750f3bccbcc1c360caf29e4\/lib%2FRuntime%2FLibrary%2FJavascriptProxy.cpp', 'patch': '@@ -392,6 +392,8 @@ namespace Js\\n         }\\n         propertyDescriptor->SetValue(getGetResult);\\n \\n+        threadContext->AddImplicitCallFlags(Js::ImplicitCall_External);\\n+\\n         return TRUE;\\n     }\\n \\n@@ -1907,6 +1909,9 @@ namespace Js\\n                 }\\n             }\\n         }\\n+\\n+        threadContext->AddImplicitCallFlags(Js::ImplicitCall_External);\\n+\\n         return TRUE;\\n \\n     }'}}",
            "message_norm":"cve-2019-1003",
            "language":"ro",
            "entities":"[('cve-2019-1003', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Runtime\/Library\/JavascriptProxy.cpp'])",
            "num_files":1.0
        }
    ]
}