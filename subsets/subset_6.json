{
    "schema":{
        "fields":[
            {
                "name":"index",
                "type":"integer"
            },
            {
                "name":"vuln_id",
                "type":"string"
            },
            {
                "name":"cwe_id",
                "type":"string"
            },
            {
                "name":"score",
                "type":"number"
            },
            {
                "name":"chain",
                "type":"string"
            },
            {
                "name":"dataset",
                "type":"string"
            },
            {
                "name":"summary",
                "type":"string"
            },
            {
                "name":"published_date",
                "type":"string"
            },
            {
                "name":"chain_len",
                "type":"integer"
            },
            {
                "name":"project",
                "type":"string"
            },
            {
                "name":"commit_href",
                "type":"string"
            },
            {
                "name":"commit_sha",
                "type":"string"
            },
            {
                "name":"patch",
                "type":"string"
            },
            {
                "name":"chain_ord",
                "type":"string"
            },
            {
                "name":"before_first_fix_commit",
                "type":"string"
            },
            {
                "name":"last_fix_commit",
                "type":"string"
            },
            {
                "name":"chain_ord_pos",
                "type":"number"
            },
            {
                "name":"commit_datetime",
                "type":"string"
            },
            {
                "name":"message",
                "type":"string"
            },
            {
                "name":"author",
                "type":"string"
            },
            {
                "name":"comments",
                "type":"string"
            },
            {
                "name":"stats",
                "type":"string"
            },
            {
                "name":"files",
                "type":"string"
            },
            {
                "name":"message_norm",
                "type":"string"
            },
            {
                "name":"language",
                "type":"string"
            },
            {
                "name":"entities",
                "type":"string"
            },
            {
                "name":"classification_level_1",
                "type":"string"
            },
            {
                "name":"classification_level_2",
                "type":"string"
            },
            {
                "name":"list_files",
                "type":"string"
            },
            {
                "name":"num_files",
                "type":"number"
            }
        ],
        "primaryKey":[
            "index"
        ],
        "pandas_version":"1.4.0"
    },
    "data":[
        {
            "index":1670,
            "vuln_id":"GHSA-f5cx-5wr3-5qrc",
            "cwe_id":"{'CWE-824'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in boosted trees ### Impact\nAn attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesCalculateBestGainsPerFeature(\n  node_id_range=[],\n  stats_summary_list=[[1,2,3]],\n  l1=[1.0],\n  l2=[1.0],\n  tree_complexity =[1.0],\n  min_node_weight =[1.17],\n  max_splits=5)\n```\n\nA similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`:\n\n```python\nimport tensorflow as tf\n                                                                                                                                                                                                                                                                                          \ntf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2(\n  node_id_range=[],\n  stats_summaries_list=[[1,2,3]],\n  split_types=[''],\n  candidate_feature_ids=[1,2,3,4],\n  l1=[1],     \n  l2=[1],\n  tree_complexity=[1.0],\n  min_node_weight=[1.17],\n  logits_dimension=5)\n```     \n    \nThe  [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc) does not validate the input values.\n\n### Patches\nWe have patched the issue in GitHub commit [9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad) and in commit. [429f009d2b2c09028647dd4bb7b3f6f414bbaad7](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "commit_sha":"429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "patch":"MULTI",
            "chain_ord":"['9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', '429f009d2b2c09028647dd4bb7b3f6f414bbaad7']",
            "before_first_fix_commit":"{'4f8db85aa9ab71a71e95d5acce7de52a0b195661'}",
            "last_fix_commit":"429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/28\/2021, 20:25:18",
            "message":"Add remaining missing validation to `BoostedTreesCalculateBestFeatureSplit`\n\nPiperOrigin-RevId: 387423006\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 1, 'total': 20}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc': {'additions': 19, 'deletions': 1, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -14,6 +14,7 @@ limitations under the License.\\n ==============================================================================*\/\\n \\n #include <limits>\\n+#include <string>\\n #include <vector>\\n \\n #include \"third_party\/eigen3\/Eigen\/Core\"\\n@@ -22,6 +23,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n #include \"tensorflow\/core\/kernels\/boosted_trees\/boosted_trees.pb.h\"\\n #include \"tensorflow\/core\/kernels\/boosted_trees\/tree_helper.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/platform\/logging.h\"\\n \\n namespace tensorflow {\\n@@ -254,12 +256,18 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n     \/\/ node_id_range\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->NumElements() == 2,\\n+        errors::InvalidArgument(\"node_id_range argument must have shape [2]\"));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n     const int32_t node_id_first = node_id_range(0);  \/\/ inclusive\\n     const int32_t node_id_last = node_id_range(1);   \/\/ exclusive\\n \\n     const Tensor* stats_summary_t;\\n     OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\\n+    OP_REQUIRES(\\n+        context, stats_summary_t->shape().dims() == 4,\\n+        errors::InvalidArgument(\"stats_summary argument must have rank 4\"));\\n     TTypes<float, 4>::ConstTensor stats_summary =\\n         stats_summary_t->tensor<float, 4>();\\n     const int32_t feature_dims = stats_summary_t->dim_size(1);\\n@@ -272,6 +280,8 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n \\n     const Tensor* l1_t;\\n     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\\n+    OP_REQUIRES(context, l1_t->NumElements() == 1,\\n+                errors::InvalidArgument(\"l1 argument must be a scalar\"));\\n     const auto l1 = l1_t->scalar<float>()();\\n     DCHECK_GE(l1, 0);\\n     if (logits_dim_ > 1) {\\n@@ -281,17 +291,25 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n \\n     const Tensor* l2_t;\\n     OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\\n+    OP_REQUIRES(context, l2_t->NumElements() == 1,\\n+                errors::InvalidArgument(\"l2 argument must be a scalar\"));\\n     const auto l2 = l2_t->scalar<float>()();\\n     DCHECK_GE(l2, 0);\\n \\n     const Tensor* tree_complexity_t;\\n     OP_REQUIRES_OK(context,\\n                    context->input(\"tree_complexity\", &tree_complexity_t));\\n+    OP_REQUIRES(\\n+        context, tree_complexity_t->NumElements() == 1,\\n+        errors::InvalidArgument(\"tree_complexity argument must be a scalar\"));\\n     const auto tree_complexity = tree_complexity_t->scalar<float>()();\\n \\n     const Tensor* min_node_weight_t;\\n     OP_REQUIRES_OK(context,\\n                    context->input(\"min_node_weight\", &min_node_weight_t));\\n+    OP_REQUIRES(\\n+        context, min_node_weight_t->NumElements() == 1,\\n+        errors::InvalidArgument(\"min_node_weight argument must be a scalar\"));\\n     const auto min_node_weight = min_node_weight_t->scalar<float>()();\\n \\n     std::vector<int32> output_node_ids;\\n@@ -300,7 +318,7 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n     std::vector<int32> output_thresholds;\\n     std::vector<Eigen::VectorXf> output_left_node_contribs;\\n     std::vector<Eigen::VectorXf> output_right_node_contribs;\\n-    std::vector<string> output_split_types;\\n+    std::vector<std::string> output_split_types;\\n \\n     \/\/ TODO(tanzheny) parallelize the computation.\\n     \/\/ Iterate each node and find the best gain per node.'}}",
            "message_norm":"add remaining missing validation to `boostedtreescalculatebestfeaturesplit`\n\npiperorigin-revid: 387423006\nchange-id: i8eaf30efb223011519e60707bfa751b275d3a443",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('387423006', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":389,
            "vuln_id":"GHSA-4952-p58q-6crx",
            "cwe_id":"{'CWE-87', 'CWE-79', 'CWE-75'}",
            "score":7.4,
            "chain":"{'https:\/\/github.com\/jupyterlab\/jupyterlab\/commit\/504825938c0abfa2fb8ff8d529308830a5ae42ed'}",
            "dataset":"osv",
            "summary":"JupyterLab: XSS due to lack of sanitization of the action attribute of an html <form> ### Impact\n\nUntrusted notebook can execute code on load. This is a remote code execution, but requires user action to open a notebook.\n\n### Patches\n\nPatched in the following versions: 3.1.4, 3.0.17, 2.3.2, 2.2.10, 1.2.21.\n\n### References\n\n[OWASP Page on Restricting Form Submissions](https:\/\/cheatsheetseries.owasp.org\/cheatsheets\/Content_Security_Policy_Cheat_Sheet.html)\n\n### For more information\n\nIf you have any questions or comments about this advisory, or vulnerabilities to report, please email our security list security@ipython.org.\n\nCredit: Guillaume Jeanne from Google",
            "published_date":"2021-08-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/jupyterlab\/jupyterlab",
            "commit_href":"https:\/\/github.com\/jupyterlab\/jupyterlab\/commit\/504825938c0abfa2fb8ff8d529308830a5ae42ed",
            "commit_sha":"504825938c0abfa2fb8ff8d529308830a5ae42ed",
            "patch":"SINGLE",
            "chain_ord":"['504825938c0abfa2fb8ff8d529308830a5ae42ed']",
            "before_first_fix_commit":"{'ccb65656e3ed9c47d3e6fedbcff2405885d0bcaa'}",
            "last_fix_commit":"504825938c0abfa2fb8ff8d529308830a5ae42ed",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/05\/2021, 16:42:03",
            "message":"Merge pull request from GHSA-4952-p58q-6crx\n\nRemove `form` tags' `action` attribute during sanitizing.\n\nCo-authored-by: Afshin Taylor Darian <git@darian.af>",
            "author":"Steven Silvester",
            "comments":null,
            "stats":"{'additions': 0, 'deletions': 1, 'total': 1}",
            "files":"{'packages\/apputils\/src\/sanitizer.ts': {'additions': 0, 'deletions': 1, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jupyterlab\/jupyterlab\/raw\/504825938c0abfa2fb8ff8d529308830a5ae42ed\/packages%2Fapputils%2Fsrc%2Fsanitizer.ts', 'patch': \"@@ -624,7 +624,6 @@ export class Sanitizer implements ISanitizer {\\n       font: ['color', 'face', 'size'],\\n       form: [\\n         'accept',\\n-        'action',\\n         'autocomplete',\\n         'enctype',\\n         'method',\"}}",
            "message_norm":"merge pull request from ghsa-4952-p58q-6crx\n\nremove `form` tags' `action` attribute during sanitizing.\n\nco-authored-by: afshin taylor darian <git@darian.af>",
            "language":"en",
            "entities":"[('ghsa-4952-p58q-6crx', 'VULNID', 'GHSA'), ('remove', 'ACTION', ''), ('sanitizing', 'SECWORD', ''), ('git@darian.af', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['packages\/apputils\/src\/sanitizer.ts'])",
            "num_files":1.0
        },
        {
            "index":2707,
            "vuln_id":"GHSA-q67f-3jq4-mww2",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/e786fd44aac46febdbf916ed6c328fbe645d80bf'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Pimcore Pimcore version 10.3.2 and prior is vulnerable to stored cross-site scripting. A patch is available and anticipated to be part of version 10.3.3.",
            "published_date":"2022-03-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/e786fd44aac46febdbf916ed6c328fbe645d80bf",
            "commit_sha":"e786fd44aac46febdbf916ed6c328fbe645d80bf",
            "patch":"SINGLE",
            "chain_ord":"['e786fd44aac46febdbf916ed6c328fbe645d80bf']",
            "before_first_fix_commit":"{'ce5c01f4c9f477444aeceb640b60f3b6199e7c22'}",
            "last_fix_commit":"e786fd44aac46febdbf916ed6c328fbe645d80bf",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/02\/2022, 20:15:07",
            "message":"escaping 'key' custom property field in elements",
            "author":"JiaJia Ji",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 2, 'total': 5}",
            "files":"{'bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/element\/properties.js': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/e786fd44aac46febdbf916ed6c328fbe645d80bf\/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Felement%2Fproperties.js', 'patch': '@@ -568,10 +568,11 @@ pimcore.element.properties = Class.create({\\n \\n     addSetFromUserDefined: function (customKey, customType) {\\n         try {\\n-            if (in_array(customKey.getValue(), this.disallowedKeys)) {\\n+            let key = htmlspecialchars(customKey.getValue());\\n+            if (in_array(key, this.disallowedKeys)) {\\n                 Ext.MessageBox.alert(t(\"error\"), t(\"name_is_not_allowed\"));\\n             }\\n-            this.add(customKey.getValue(), customType.getValue(), false, false, false, true);\\n+            this.add(key, customType.getValue(), false, false, false, true);\\n         } catch (e) {\\n             console.log(e);\\n         }'}}",
            "message_norm":"escaping 'key' custom property field in elements",
            "language":"en",
            "entities":"[('escaping', 'SECWORD', ''), ('key', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/element\/properties.js'])",
            "num_files":1.0
        },
        {
            "index":244,
            "vuln_id":"GHSA-3f99-hvg4-qjwj",
            "cwe_id":"{'CWE-335'}",
            "score":8.7,
            "chain":"{'https:\/\/github.com\/juliangruber\/keypair\/commit\/9596418d3363d3e757676c0b6a8f2d35a9d1cb18'}",
            "dataset":"osv",
            "summary":"Insecure random number generation in keypair ## Description and Impact\n\nA bug in the pseudo-random number generator used by [keypair](https:\/\/github.com\/juliangruber\/keypair) versions up to and including 1.0.3 could allow for weak RSA key generation. This could enable an attacker to decrypt confidential messages or gain authorized access to an account belonging to the victim. We recommend replacing any RSA keys that were generated using keypair version 1.0.3 or earlier.\n\n## Fix\n\n* The [bug](https:\/\/github.com\/juliangruber\/keypair\/blob\/87c62f255baa12c1ec4f98a91600f82af80be6db\/index.js#L1008) in the pseudo-random number generator is fixed in commit [`9596418`](https:\/\/github.com\/juliangruber\/keypair\/commit\/9596418d3363d3e757676c0b6a8f2d35a9d1cb18).\n* If the crypto module is available, it is used instead of the pseudo-random number generator. Also fixed in [`9596418`](https:\/\/github.com\/juliangruber\/keypair\/commit\/9596418d3363d3e757676c0b6a8f2d35a9d1cb18)\n\n## Additional Details\n\nThe specific [line](https:\/\/github.com\/juliangruber\/keypair\/blob\/87c62f255baa12c1ec4f98a91600f82af80be6db\/index.js#L1008) with the flaw is:\n\n```javascript\nb.putByte(String.fromCharCode(next & 0xFF))\n```\n\nThe [definition](https:\/\/github.com\/juliangruber\/keypair\/blob\/87c62f255baa12c1ec4f98a91600f82af80be6db\/index.js#L350-L352) of `putByte` is \n\n```javascript\nutil.ByteBuffer.prototype.putByte = function(b) {\n  this.data += String.fromCharCode(b);\n};\n```\n\nSimplified, this is `String.fromCharCode(String.fromCharCode(next & 0xFF))`. This results in most of the buffer containing zeros. An example generated buffer:\n\n(Note: truncated for brevity)\n\n```\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00....\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n```\n\nSince it is masking with 0xFF, approximately 97% of the bytes are converted to zeros. The impact is that each byte in the RNG seed has a 97% chance of being 0 due to incorrect conversion.\n\n## Credit\n\nThis issue was reported to GitHub Security Lab by Ross Wheeler of Axosoft. It was discovered by Axosoft engineer Dan Suceava, who noticed that [keypair](https:\/\/github.com\/juliangruber\/keypair) was regularly generating duplicate RSA keys. GitHub security engineer [@vcsjones (Kevin Jones)](https:\/\/github.com\/vcsjones) independently investigated the problem and identified the cause and source code location of the bug.",
            "published_date":"2021-10-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/juliangruber\/keypair",
            "commit_href":"https:\/\/github.com\/juliangruber\/keypair\/commit\/9596418d3363d3e757676c0b6a8f2d35a9d1cb18",
            "commit_sha":"9596418d3363d3e757676c0b6a8f2d35a9d1cb18",
            "patch":"SINGLE",
            "chain_ord":"['9596418d3363d3e757676c0b6a8f2d35a9d1cb18']",
            "before_first_fix_commit":"{'87c62f255baa12c1ec4f98a91600f82af80be6db'}",
            "last_fix_commit":"9596418d3363d3e757676c0b6a8f2d35a9d1cb18",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/11\/2021, 17:01:56",
            "message":"Merge pull request from GHSA-3f99-hvg4-qjwj\n\n* fix double String.fromCharCode\n\n* use crypto module if available\n\nCo-authored-by: Julian Gruber <julian@juliangruber.com>",
            "author":"Kevin Backhouse",
            "comments":"{'com_1': {'author': 'ChALkeR', 'datetime': '10\/12\/2021, 16:44:04', 'body': \"How is this a fix?\\r\\n\\r\\nThis looks like it still falls back to xorshift128+ for the purpose of ssh keys generation?\\r\\n\\r\\nThat... doesn't look like a good idea perhaps.\\r\\n\\r\\nWhy is `Math.random` based code even present there?\\r\\n\\r\\nThe environments where there is no way to generate the key in a secure way should fail, and not fall back to a predictable pseudo-random generator.\\r\\n\\r\\n_Note: not considering this confidential, as this is all over Twitter now afaik._\"}, 'com_2': {'author': 'juliangruber', 'datetime': '10\/13\/2021, 08:21:54', 'body': \"I'm not a security researcher myself so I'm preferring to relay judgement of this issue to those who are, which has happened in this advisory.\\r\\n\\r\\nAt this point I'm not going to perform any major changes to this library myself. If you want to contribute, would you consider making a docs PR with your concerns, adding a disclaimer to the README?\"}, 'com_3': {'author': 'normanr', 'datetime': '10\/13\/2021, 16:04:03', 'body': 'Thank you for responding promptly to the security researchers and taking the time to merge this security fix. A good example of how to handle security related bug reports.'}}",
            "stats":"{'additions': 6, 'deletions': 2, 'total': 8}",
            "files":"{'index.js': {'additions': 6, 'deletions': 2, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/juliangruber\/keypair\/raw\/9596418d3363d3e757676c0b6a8f2d35a9d1cb18\/index.js', 'patch': \"@@ -756,7 +756,11 @@ util.createBuffer = function(input, encoding) {\\n  *\/\\n \\n var prng = forge.prng = {};\\n-var crypto = null;\\n+\\n+var crypto;\\n+try {\\n+  crypto = require('crypto');\\n+} catch (_) {}\\n \\n prng.create = function(plugin) {\\n   var ctx = {\\n@@ -1005,7 +1009,7 @@ prng.create = function(plugin) {\\n           \/\/ throw in more pseudo random\\n           next = seed >>> (i << 3);\\n           next ^= Math.floor(Math.random() * 0xFF);\\n-          b.putByte(String.fromCharCode(next & 0xFF));\\n+          b.putByte(next & 0xFF);\\n         }\\n       }\\n     }\"}}",
            "message_norm":"merge pull request from ghsa-3f99-hvg4-qjwj\n\n* fix double string.fromcharcode\n\n* use crypto module if available\n\nco-authored-by: julian gruber <julian@juliangruber.com>",
            "language":"en",
            "entities":"[('ghsa-3f99-hvg4-qjwj', 'VULNID', 'GHSA'), ('fix', 'ACTION', ''), ('crypto', 'SECWORD', ''), ('julian@juliangruber.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":2915,
            "vuln_id":"GHSA-rc8h-3fv6-pxv8",
            "cwe_id":"{'CWE-400'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/hapijs\/hapi\/commit\/aab2496e930dce5ee1ab28eecec94e0e45f03580'}",
            "dataset":"osv",
            "summary":"Denial of Service in hapi Versions of `hapi` prior to 11.1.3 are affected by a denial of service vulnerability.\n\nThe vulnerability is triggered when certain input is passed into the If-Modified-Since or Last-Modified headers.\n\nThis causes an 'illegal access' exception to be raised, and instead of sending a HTTP 500 error back to the sender, hapi will continue to hold the socket open until timed out (default node timeout is 2 minutes).\n\n\n\n\n\n## Recommendation\n\nUpdate to v11.1.3 or later",
            "published_date":"2018-06-07",
            "chain_len":1,
            "project":"https:\/\/github.com\/hapijs\/hapi",
            "commit_href":"https:\/\/github.com\/hapijs\/hapi\/commit\/aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "commit_sha":"aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "patch":"SINGLE",
            "chain_ord":"['aab2496e930dce5ee1ab28eecec94e0e45f03580']",
            "before_first_fix_commit":"{'1ad65ba793377928aa5a2dfc819888c5c9793394', 'ef2a0f85d558eeb102c512fac45386b2145cb903'}",
            "last_fix_commit":"aab2496e930dce5ee1ab28eecec94e0e45f03580",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/23\/2015, 21:54:47",
            "message":"Merge pull request #2988 from hapijs\/v11.1.x\n\nHandle invalid date exceptions",
            "author":"Eran Hammer",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 2, 'total': 13}",
            "files":"{'lib\/transmit.js': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hapijs\/hapi\/raw\/aab2496e930dce5ee1ab28eecec94e0e45f03580\/lib%2Ftransmit.js', 'patch': '@@ -82,8 +82,8 @@ internals.marshal = function (request, next) {\\n \\n                 \/\/ Weak verifier\\n \\n-                const ifModifiedSince = Date.parse(ifModifiedSinceHeader);\\n-                const lastModified = Date.parse(lastModifiedHeader);\\n+                const ifModifiedSince = internals.parseDate(ifModifiedSinceHeader);\\n+                const lastModified = internals.parseDate(lastModifiedHeader);\\n \\n                 if (ifModifiedSince &&\\n                     lastModified &&\\n@@ -147,6 +147,15 @@ internals.marshal = function (request, next) {\\n };\\n \\n \\n+internals.parseDate = function (string) {\\n+\\n+    try {\\n+        return Date.parse(string);\\n+    }\\n+    catch (errIgnore) { }\\n+};\\n+\\n+\\n internals.fail = function (request, boom, callback) {\\n \\n     const error = boom.output;'}}",
            "message_norm":"merge pull request #2988 from hapijs\/v11.1.x\n\nhandle invalid date exceptions",
            "language":"en",
            "entities":"[('#2988', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/transmit.js'])",
            "num_files":1.0
        },
        {
            "index":610,
            "vuln_id":"GHSA-5c8j-xr24-2665",
            "cwe_id":"{'CWE-77'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/tojocky\/node-printer\/commit\/e001e38738c17219a1d9dd8c31f7d82b9c0013c7'}",
            "dataset":"osv",
            "summary":"Potential Command Injection in printer Versions 0.0.1 and earlier of `printer` are affected by a command injection vulnerability resulting from a failure to sanitize command arguments properly in the `printDirect()` function. \n\n\n\n## Recommendation\n\nUpdate to version 0.0.2 or later.",
            "published_date":"2017-11-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/tojocky\/node-printer",
            "commit_href":"https:\/\/github.com\/tojocky\/node-printer\/commit\/e001e38738c17219a1d9dd8c31f7d82b9c0013c7",
            "commit_sha":"e001e38738c17219a1d9dd8c31f7d82b9c0013c7",
            "patch":"SINGLE",
            "chain_ord":"['e001e38738c17219a1d9dd8c31f7d82b9c0013c7']",
            "before_first_fix_commit":"{'7987544670c37fdef659f8ee9e5db20fae118705'}",
            "last_fix_commit":"e001e38738c17219a1d9dd8c31f7d82b9c0013c7",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/28\/2013, 18:30:28",
            "message":"Removed possible command injection",
            "author":"chieffancypants",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/printer.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tojocky\/node-printer\/raw\/e001e38738c17219a1d9dd8c31f7d82b9c0013c7\/lib%2Fprinter.js', 'patch': '@@ -93,7 +93,7 @@ function printDirect(parameters){\\n     }else if (!printer_helper.printDirect){\/\/ should be POSIX\\n         var temp_file_name = path.join(os.tmpDir(),\"printing\");\\n         fs.writeFileSync(temp_file_name, data);\\n-        child_process.exec(\\'lpr -P\\'+printer+\\' -oraw -r\\'+\\' \\'+temp_file_name, function(err, stdout, stderr){\\n+        child_process.execFile(\\'lpr\\', [\\'-P\\' + printer, \\'-oraw\\', \\'-r\\', temp_file_name], function(err, stdout, stderr){\\n             if (err !== null) {\\n                 error(\\'ERROR: \\' + err);\\n                 return;'}}",
            "message_norm":"removed possible command injection",
            "language":"en",
            "entities":"[('removed', 'ACTION', ''), ('possible command injection', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/printer.js'])",
            "num_files":1.0
        },
        {
            "index":89,
            "vuln_id":"GHSA-2gfx-95x2-5v3x",
            "cwe_id":"{'CWE-787'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a324ac84e573fba362a5e53d4e74d5de6729933e'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `QuantizedReshape` ### Impact\nAn attacker can cause a heap buffer overflow in `QuantizedReshape` by passing in invalid thresholds for the quantization:\n\n```python\nimport tensorflow as tf\n\ntensor = tf.constant([], dtype=tf.qint32)\nshape = tf.constant([], dtype=tf.int32)\ninput_min = tf.constant([], dtype=tf.float32)\ninput_max = tf.constant([], dtype=tf.float32)\n\ntf.raw_ops.QuantizedReshape(tensor=tensor, shape=shape, input_min=input_min, input_max=input_max)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a324ac84e573fba362a5e53d4e74d5de6729933e\/tensorflow\/core\/kernels\/quantized_reshape_op.cc#L38-L55) assumes that the 2 arguments are always valid scalars and tries to access the numeric value directly:\n\n```cc\nconst auto& input_min_float_tensor = ctx->input(2);\n...\nconst float input_min_float = input_min_float_tensor.flat<float>()(0);\nconst auto& input_max_float_tensor = ctx->input(3);\n...\nconst float input_max_float = input_max_float_tensor.flat<float>()(0);\n```\n\nHowever, if any of these tensors is empty, then `.flat<T>()` is an empty buffer and accessing the element at position 0 results in overflow.\n\n### Patches\nWe have patched the issue in GitHub commit [a324ac84e573fba362a5e53d4e74d5de6729933e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a324ac84e573fba362a5e53d4e74d5de6729933e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a324ac84e573fba362a5e53d4e74d5de6729933e",
            "commit_sha":"a324ac84e573fba362a5e53d4e74d5de6729933e",
            "patch":"SINGLE",
            "chain_ord":"['a324ac84e573fba362a5e53d4e74d5de6729933e']",
            "before_first_fix_commit":"{'2ec2ce48365486311e56b3503bb75ab9e72a813d'}",
            "last_fix_commit":"a324ac84e573fba362a5e53d4e74d5de6729933e",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/22\/2021, 01:11:15",
            "message":"Validate arguments to `QuantizedReshape`.\n\nEnsure that validations from `Reshape` also terminate `QuantizedReshape` on failure.\n\nPiperOrigin-RevId: 369775421\nChange-Id: If8c5342267aceea65b7cb83a4b183304886f1ce8",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 23, 'deletions': 2, 'total': 25}",
            "files":"{'tensorflow\/core\/kernels\/quantized_reshape_op.cc': {'additions': 23, 'deletions': 2, 'changes': 25, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a324ac84e573fba362a5e53d4e74d5de6729933e\/tensorflow%2Fcore%2Fkernels%2Fquantized_reshape_op.cc', 'patch': '@@ -17,6 +17,7 @@ limitations under the License.\\n \\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n+#include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n #include \"tensorflow\/core\/framework\/tensor_types.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/kernels\/reshape_op.h\"\\n@@ -30,9 +31,29 @@ class QuantizedReshapeOp : public ReshapeOp {\\n   void Compute(OpKernelContext* ctx) override {\\n     \/\/ This call processes inputs 1 and 2 to write output 0.\\n     ReshapeOp::Compute(ctx);\\n+    if (!ctx->status().ok()) {\\n+      return;\\n+    }\\n+\\n+    const auto& input_min_float_tensor = ctx->input(2);\\n+    const auto& input_min_float_shape = input_min_float_tensor.shape();\\n+    OP_REQUIRES(ctx,\\n+                TensorShapeUtils::IsScalar(input_min_float_shape) ||\\n+                    (TensorShapeUtils::IsVector(input_min_float_shape) &&\\n+                     (input_min_float_shape.dim_size(0) == 1)),\\n+                errors::InvalidArgument(\\n+                    \"input_min must be a scalar or a vector of 1 element\"));\\n+    const float input_min_float = input_min_float_tensor.flat<float>()(0);\\n+    const auto& input_max_float_tensor = ctx->input(3);\\n+    const auto& input_max_float_shape = input_max_float_tensor.shape();\\n+    OP_REQUIRES(ctx,\\n+                TensorShapeUtils::IsScalar(input_max_float_shape) ||\\n+                    (TensorShapeUtils::IsVector(input_max_float_shape) &&\\n+                     (input_max_float_shape.dim_size(0) == 1)),\\n+                errors::InvalidArgument(\\n+                    \"input_max must be a scalar or a vector of 1 element\"));\\n+    const float input_max_float = input_max_float_tensor.flat<float>()(0);\\n \\n-    const float input_min_float = ctx->input(2).flat<float>()(0);\\n-    const float input_max_float = ctx->input(3).flat<float>()(0);\\n     Tensor* output_min = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\\n     output_min->flat<float>()(0) = input_min_float;'}}",
            "message_norm":"validate arguments to `quantizedreshape`.\n\nensure that validations from `reshape` also terminate `quantizedreshape` on failure.\n\npiperorigin-revid: 369775421\nchange-id: if8c5342267aceea65b7cb83a4b183304886f1ce8",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('ensure', 'ACTION', ''), ('369775421', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_reshape_op.cc'])",
            "num_files":1.0
        },
        {
            "index":41,
            "vuln_id":"GHSA-269q-hmxg-m83q",
            "cwe_id":"{'CWE-379', 'CWE-378', 'CWE-668'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/netty\/netty\/commit\/185f8b2756a36aaa4f973f1a2a025e7d981823f1'}",
            "dataset":"osv",
            "summary":"Local Information Disclosure Vulnerability in io.netty:netty-codec-http ### Description ###\n[GHSA-5mcr-gq6c-3hq2](https:\/\/github.com\/netty\/netty\/security\/advisories\/GHSA-5mcr-gq6c-3hq2) (CVE-2021-21290) contains an insufficient fix for the vulnerability identified.\n\n### Impact ###\n\nWhen netty's multipart decoders are used local information disclosure can occur via the local system temporary directory if temporary storing uploads on the disk is enabled.\n\nThis only impacts applications running on Java version 6 and lower. Additionally, this vulnerability impacts code running on Unix-like systems, and very old versions of Mac OSX and Windows as they all share the system temporary directory between all users.\n\n### Vulnerability Details ###\n\nTo fix the vulnerability the code was changed to the following:\n\n```java\n    @SuppressJava6Requirement(reason = \"Guarded by version check\")\n    public static File createTempFile(String prefix, String suffix, File directory) throws IOException {\n        if (javaVersion() >= 7) {\n            if (directory == null) {\n                return Files.createTempFile(prefix, suffix).toFile();\n            }\n            return Files.createTempFile(directory.toPath(), prefix, suffix).toFile();\n        }\n        if (directory == null) {\n            return File.createTempFile(prefix, suffix);\n        }\n        File file = File.createTempFile(prefix, suffix, directory);\n        \/\/ Try to adjust the perms, if this fails there is not much else we can do...\n        file.setReadable(false, false);\n        file.setReadable(true, true);\n        return file;\n    }\n```\n\nUnfortunately, this logic path was left vulnerable:\n\n```java\n        if (directory == null) {\n            return File.createTempFile(prefix, suffix);\n        }\n```\n\nThis file is still readable by all local users.\n\n### Patches ###\n\nUpdate to 4.1.77.Final\n\n### Workarounds ###\n\nSpecify your own `java.io.tmpdir` when you start the JVM or use `DefaultHttpDataFactory.setBaseDir(...)` to set the directory to something that is only readable by the current user or update to Java 7 or above.\n\n### References ###\n\n - [CWE-378: Creation of Temporary File With Insecure Permissions](https:\/\/cwe.mitre.org\/data\/definitions\/378.html)\n - [CWE-379: Creation of Temporary File in Directory with Insecure Permissions](https:\/\/cwe.mitre.org\/data\/definitions\/379.html)\n\n\n### For more information ###\n\nIf you have any questions or comments about this advisory:\n\nOpen an issue in [netty](https:\/\/github.com\/netty\/netty)",
            "published_date":"2022-05-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/netty\/netty",
            "commit_href":"https:\/\/github.com\/netty\/netty\/commit\/185f8b2756a36aaa4f973f1a2a025e7d981823f1",
            "commit_sha":"185f8b2756a36aaa4f973f1a2a025e7d981823f1",
            "patch":"SINGLE",
            "chain_ord":"['185f8b2756a36aaa4f973f1a2a025e7d981823f1']",
            "before_first_fix_commit":"{'7dbca6aedc8cf5971e2a26d8fc2b7f265f2b4bf1'}",
            "last_fix_commit":"185f8b2756a36aaa4f973f1a2a025e7d981823f1",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2022, 06:57:43",
            "message":"Merge pull request from GHSA-269q-hmxg-m83q\n\n* Correctly modify permission for temporary files when using Java 6 in all cases\n\nMotivation:\n\n[GHSA-5mcr-gq6c-3hq2](https:\/\/github.com\/netty\/netty\/security\/advisories\/GHSA-5mcr-gq6c-3hq2) did not correctly fix all cases for temprory files when running on java 6.\n\nModifications:\n\n- Add correctly adjust perms in all cases\n- Add logging if adjusting of permissions fails\n\nResult:\n\nFixes https:\/\/github.com\/netty\/netty\/security\/advisories\/GHSA-269q-hmxg-m83q\n\n* Throw on failure",
            "author":"Norman Maurer",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 4, 'total': 15}",
            "files":"{'common\/src\/main\/java\/io\/netty\/util\/internal\/PlatformDependent.java': {'additions': 11, 'deletions': 4, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/netty\/netty\/raw\/185f8b2756a36aaa4f973f1a2a025e7d981823f1\/common%2Fsrc%2Fmain%2Fjava%2Fio%2Fnetty%2Futil%2Finternal%2FPlatformDependent.java', 'patch': '@@ -1447,13 +1447,20 @@ public static File createTempFile(String prefix, String suffix, File directory)\\n             }\\n             return Files.createTempFile(directory.toPath(), prefix, suffix).toFile();\\n         }\\n+        final File file;\\n         if (directory == null) {\\n-            return File.createTempFile(prefix, suffix);\\n+            file = File.createTempFile(prefix, suffix);\\n+        } else {\\n+            file = File.createTempFile(prefix, suffix, directory);\\n         }\\n-        File file = File.createTempFile(prefix, suffix, directory);\\n+\\n         \/\/ Try to adjust the perms, if this fails there is not much else we can do...\\n-        file.setReadable(false, false);\\n-        file.setReadable(true, true);\\n+        if (!file.setReadable(false, false)) {\\n+            throw new IOException(\"Failed to set permissions on temporary file \" + file);\\n+        }\\n+        if (!file.setReadable(true, true)) {\\n+            throw new IOException(\"Failed to set permissions on temporary file \" + file);\\n+        }\\n         return file;\\n     }'}}",
            "message_norm":"merge pull request from ghsa-269q-hmxg-m83q\n\n* correctly modify permission for temporary files when using java 6 in all cases\n\nmotivation:\n\n[ghsa-5mcr-gq6c-3hq2](https:\/\/github.com\/netty\/netty\/security\/advisories\/ghsa-5mcr-gq6c-3hq2) did not correctly fix all cases for temprory files when running on java 6.\n\nmodifications:\n\n- add correctly adjust perms in all cases\n- add logging if adjusting of permissions fails\n\nresult:\n\nfixes https:\/\/github.com\/netty\/netty\/security\/advisories\/ghsa-269q-hmxg-m83q\n\n* throw on failure",
            "language":"en",
            "entities":"[('ghsa-269q-hmxg-m83q', 'VULNID', 'GHSA'), ('permission', 'SECWORD', ''), ('ghsa-5mcr-gq6c-3hq2](https:\/\/github.com\/netty\/netty', 'VULNID', 'GHSA'), ('security', 'SECWORD', ''), ('ghsa-5mcr-gq6c-3hq2) did not', 'VULNID', 'GHSA'), ('fix', 'ACTION', ''), ('add', 'ACTION', ''), ('add', 'ACTION', ''), ('permissions', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('https:\/\/github.com\/netty\/netty\/security\/advisories\/ghsa-269q-hmxg-m83q', 'VULNID', 'GHSA')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['common\/src\/main\/java\/io\/netty\/util\/internal\/PlatformDependent.java'])",
            "num_files":1.0
        },
        {
            "index":2453,
            "vuln_id":"GHSA-mq5p-2mcr-m52j",
            "cwe_id":"{'CWE-94'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/jupyterhub\/nbgitpuller\/commit\/07690644f29a566011dd0d7ba14cae3eb0490481'}",
            "dataset":"osv",
            "summary":"Code injection in nbgitpuller ### Impact\n\nDue to an unsanitized input, visiting maliciously crafted links could result in arbitrary code execution in the user environment.\n\n### Patches\n\n0.10.2\n\n### Workarounds\n\nNone, other than upgrade to 0.10.2 or downgrade to 0.8.x.\n\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [nbgitpuller](https:\/\/github.com\/jupyterhub\/nbgitpuller\/issues)\n* Email our security team at [security@ipython.org](mailto:security@ipython.org)",
            "published_date":"2021-08-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/jupyterhub\/nbgitpuller",
            "commit_href":"https:\/\/github.com\/jupyterhub\/nbgitpuller\/commit\/07690644f29a566011dd0d7ba14cae3eb0490481",
            "commit_sha":"07690644f29a566011dd0d7ba14cae3eb0490481",
            "patch":"SINGLE",
            "chain_ord":"['07690644f29a566011dd0d7ba14cae3eb0490481']",
            "before_first_fix_commit":"{'f25d3f2685035c11bd668d48e71caf4fc245ba68', '2cad6147f1769a962f8d0733045967663add53cb'}",
            "last_fix_commit":"07690644f29a566011dd0d7ba14cae3eb0490481",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/25\/2021, 12:23:02",
            "message":"Merge pull request from GHSA-mq5p-2mcr-m52j\n\nmake positional args explicit",
            "author":"Erik Sundell",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'nbgitpuller\/pull.py': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jupyterhub\/nbgitpuller\/raw\/07690644f29a566011dd0d7ba14cae3eb0490481\/nbgitpuller%2Fpull.py', 'patch': '@@ -88,13 +88,13 @@ def branch_exists(self, branch):\\n         \"\"\"\\n         try:\\n             heads = subprocess.run(\\n-                [\"git\", \"ls-remote\", \"--heads\", self.git_url],\\n+                [\"git\", \"ls-remote\", \"--heads\", \"--\", self.git_url],\\n                 capture_output=True,\\n                 text=True,\\n                 check=True\\n             )\\n             tags = subprocess.run(\\n-                [\"git\", \"ls-remote\", \"--tags\", self.git_url],\\n+                [\"git\", \"ls-remote\", \"--tags\", \"--\", self.git_url],\\n                 capture_output=True,\\n                 text=True,\\n                 check=True\\n@@ -118,7 +118,7 @@ def resolve_default_branch(self):\\n         \"\"\"\\n         try:\\n             head_branch = subprocess.run(\\n-                [\"git\", \"ls-remote\", \"--symref\", self.git_url, \"HEAD\"],\\n+                [\"git\", \"ls-remote\", \"--symref\", \"--\", self.git_url, \"HEAD\"],\\n                 capture_output=True,\\n                 text=True,\\n                 check=True\\n@@ -154,7 +154,7 @@ def initialize_repo(self):\\n         if self.depth and self.depth > 0:\\n             clone_args.extend([\\'--depth\\', str(self.depth)])\\n         clone_args.extend([\\'--branch\\', self.branch_name])\\n-        clone_args.extend([self.git_url, self.repo_dir])\\n+        clone_args.extend([\"--\", self.git_url, self.repo_dir])\\n         yield from execute_cmd(clone_args)\\n         logging.info(\\'Repo {} initialized\\'.format(self.repo_dir))'}}",
            "message_norm":"merge pull request from ghsa-mq5p-2mcr-m52j\n\nmake positional args explicit",
            "language":"ca",
            "entities":"[('ghsa-mq5p-2mcr-m52j', 'VULNID', 'GHSA')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['nbgitpuller\/pull.py'])",
            "num_files":1.0
        },
        {
            "index":1022,
            "vuln_id":"GHSA-7fc2-rm35-2pp7",
            "cwe_id":"{'CWE-352'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/ipython\/ipython\/commit\/1415a9710407e7c14900531813c15ba6165f0816', 'https:\/\/github.com\/ipython\/ipython\/commit\/a05fe052a18810e92d9be8c1185952c13fe4e5b0'}",
            "dataset":"osv",
            "summary":"IPython vulnerable to cross site request forgery (CSRF) IPython (Interactive Python) is a command shell. Cross-site request forgery in the REST API is possible in in IPython 2 and 3. Versions 2.4.1 and 3.2.3 contain patches.",
            "published_date":"2022-05-17",
            "chain_len":2,
            "project":"https:\/\/github.com\/ipython\/ipython",
            "commit_href":"https:\/\/github.com\/ipython\/ipython\/commit\/a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "commit_sha":"a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "patch":"MULTI",
            "chain_ord":"['1415a9710407e7c14900531813c15ba6165f0816', 'a05fe052a18810e92d9be8c1185952c13fe4e5b0']",
            "before_first_fix_commit":"{'6884e8b36dc1e2d59e1d8ddb5e95788728d76e6f'}",
            "last_fix_commit":"a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/12\/2015, 15:36:44",
            "message":"backport origin check for API requests",
            "author":"Min RK",
            "comments":null,
            "stats":"{'additions': 48, 'deletions': 0, 'total': 48}",
            "files":"{'IPython\/html\/base\/handlers.py': {'additions': 48, 'deletions': 0, 'changes': 48, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ipython\/ipython\/raw\/a05fe052a18810e92d9be8c1185952c13fe4e5b0\/IPython%2Fhtml%2Fbase%2Fhandlers.py', 'patch': '@@ -29,6 +29,10 @@\\n     from http.client import responses\\n except ImportError:\\n     from httplib import responses\\n+try:\\n+    from urllib.parse import urlparse # Py 3\\n+except ImportError:\\n+    from urlparse import urlparse # Py 2\\n \\n from jinja2 import TemplateNotFound\\n from tornado import web\\n@@ -208,6 +212,50 @@ def get_origin(self):\\n             origin = self.request.headers.get(\"Sec-Websocket-Origin\", None)\\n         return origin\\n \\n+    def check_origin_api(self):\\n+        \"\"\"Check Origin for cross-site API requests.\\n+        \\n+        Copied from WebSocket with changes:\\n+        \\n+        - allow unspecified host\/origin (e.g. scripts)\\n+        \"\"\"\\n+        if self.allow_origin == \\'*\\':\\n+            return True\\n+\\n+        host = self.request.headers.get(\"Host\")\\n+        origin = self.request.headers.get(\"Origin\")\\n+\\n+        # If no header is provided, assume it comes from a script\/curl.\\n+        # We are only concerned with cross-site browser stuff here.\\n+        if origin is None or host is None:\\n+            return True\\n+        \\n+        origin = origin.lower()\\n+        origin_host = urlparse(origin).netloc\\n+        \\n+        # OK if origin matches host\\n+        if origin_host == host:\\n+            return True\\n+        \\n+        # Check CORS headers\\n+        if self.allow_origin:\\n+            allow = self.allow_origin == origin\\n+        elif self.allow_origin_pat:\\n+            allow = bool(self.allow_origin_pat.match(origin))\\n+        else:\\n+            # No CORS headers deny the request\\n+            allow = False\\n+        if not allow:\\n+            self.log.warn(\"Blocking Cross Origin API request.  Origin: %s, Host: %s\",\\n+                origin, host,\\n+            )\\n+        return allow\\n+\\n+    def prepare(self):\\n+        if not self.check_origin_api():\\n+            raise web.HTTPError(404)\\n+        return super(IPythonHandler, self).prepare()\\n+\\n     #---------------------------------------------------------------\\n     # template rendering\\n     #---------------------------------------------------------------'}}",
            "message_norm":"backport origin check for api requests",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['IPython\/html\/base\/handlers.py'])",
            "num_files":1.0
        },
        {
            "index":2807,
            "vuln_id":"GHSA-qr2j-wrhx-4829",
            "cwe_id":"{'CWE-20'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/ethereum\/go-ethereum\/commit\/106d196ec4a6451efedc60ab15957f231fa85639'}",
            "dataset":"osv",
            "summary":"Improper Input Validation In Go Ethereum (aka geth) before 1.8.14, TraceChain in eth\/api_tracer.go does not verify that the end block is after the start block.",
            "published_date":"2021-05-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/ethereum\/go-ethereum",
            "commit_href":"https:\/\/github.com\/ethereum\/go-ethereum\/commit\/106d196ec4a6451efedc60ab15957f231fa85639",
            "commit_sha":"106d196ec4a6451efedc60ab15957f231fa85639",
            "patch":"SINGLE",
            "chain_ord":"['106d196ec4a6451efedc60ab15957f231fa85639']",
            "before_first_fix_commit":"{'6d1e292eefa70b5cb76cd03ff61fc6c4550d7c36'}",
            "last_fix_commit":"106d196ec4a6451efedc60ab15957f231fa85639",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/21\/2018, 07:48:53",
            "message":"eth: ensure from<to when tracing chain (credits Chen Nan via bugbounty)",
            "author":"Martin Holst Swende",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'eth\/api_tracer.go': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ethereum\/go-ethereum\/raw\/106d196ec4a6451efedc60ab15957f231fa85639\/eth%2Fapi_tracer.go', 'patch': '@@ -119,6 +119,9 @@ func (api *PrivateDebugAPI) TraceChain(ctx context.Context, start, end rpc.Block\\n \\tif to == nil {\\n \\t\\treturn nil, fmt.Errorf(\"end block #%d not found\", end)\\n \\t}\\n+\\tif from.Number().Cmp(to.Number()) >= 0 {\\n+\\t\\treturn nil, fmt.Errorf(\"end block (#%d) needs to come after start block (#%d)\", end, start)\\n+\\t}\\n \\treturn api.traceChain(ctx, from, to, config)\\n }'}}",
            "message_norm":"eth: ensure from<to when tracing chain (credits chen nan via bugbounty)",
            "language":"en",
            "entities":"[('ensure', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['eth\/api_tracer.go'])",
            "num_files":1.0
        },
        {
            "index":1253,
            "vuln_id":"GHSA-8rmh-55h4-93h5",
            "cwe_id":"{'CWE-22'}",
            "score":7.2,
            "chain":"{'https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199'}",
            "dataset":"osv",
            "summary":"DSpace ItemImportService API Vulnerable to Path Traversal in Simple Archive Format Package Import ### Impact\nItemImportServiceImpl is vulnerable to a path traversal vulnerability. This means a malicious SAF (simple archive format) package could cause a file\/directory to be created anywhere the Tomcat\/DSpace user can write to on the server.  However, this path traversal vulnerability is only possible by a user with special privileges (either Administrators or someone with command-line access to the server).  This vulnerability impacts the XMLUI, JSPUI and command-line.\n\n_This vulnerability does NOT impact 7.x._\n\n### Patches\n\n_DSpace 6.x:_ \n* Fixed in 6.4 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0\n* 6.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0.patch (may be applied manually if an immediate upgrade to 6.4 or 7.x is not possible)\n\n_DSpace 5.x:_\n* Fixed in 5.11 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199\n* 5.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199.patch (may be applied manually if an immediate upgrade to 5.11 or 6.4 or 7.x is not possible)\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs \/ configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### Workarounds\n\nAs a basic workaround, you may block all access to the following URL paths:\n* If you are using the XMLUI, block all access to `\/admin\/batchimport` path (this is the URL of the Admin Batch Import tool). Keep in mind, if your site uses the path \"\/xmlui\", then you'd need to block access to `\/xmlui\/admin\/batchimport`.\n* If you are using the JSPUI, block all access to `\/dspace-admin\/batchimport` path (this is the URL of the Admin Batch Import tool).  Keep in mind, if your site uses the path \"\/jspui\", then you'd need to block access to `\/jspui\/dspace-admin\/batchimport`.\n\nKeep in mind, only an Administrative user or a user with command-line access to the server is able to import\/upload SAF packages. Therefore, assuming those users do not blindly upload untrusted SAF packages, then it is unlikely your site could be impacted by this vulnerability.\n\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
            "published_date":"2022-08-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/DSpace\/DSpace",
            "commit_href":"https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199",
            "commit_sha":"56e76049185bbd87c994128a9d77735ad7af0199",
            "patch":"MULTI",
            "chain_ord":"['7af52a0883a9dbc475cf3001f04ed11b24c8a4c0', '56e76049185bbd87c994128a9d77735ad7af0199']",
            "before_first_fix_commit":"{'73cdff26fdc40bb022e21dcfdeefebf28057cde7'}",
            "last_fix_commit":"56e76049185bbd87c994128a9d77735ad7af0199",
            "chain_ord_pos":2.0,
            "commit_datetime":"01\/14\/2022, 00:37:25",
            "message":"[DS-4131] Better path handling in ItemImport zips",
            "author":"Kim Shepherd",
            "comments":null,
            "stats":"{'additions': 30, 'deletions': 6, 'total': 36}",
            "files":"{'dspace-api\/src\/main\/java\/org\/dspace\/app\/itemimport\/ItemImport.java': {'additions': 30, 'deletions': 6, 'changes': 36, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DSpace\/DSpace\/raw\/56e76049185bbd87c994128a9d77735ad7af0199\/dspace-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdspace%2Fapp%2Fitemimport%2FItemImport.java', 'patch': '@@ -2003,22 +2003,30 @@ public static String unzip(File zipfile, String destDir) throws IOException {\\n         if (destinationDir == null){\\n         \\tdestinationDir = tempWorkDir;\\n         }\\n+        log.debug(\"Using directory \" + destinationDir + \" for zip extraction. (destDir arg is \" + destDir +\\n+                \", tempWorkDir is \" + tempWorkDir + \")\");\\n \\n         File tempdir = new File(destinationDir);\\n         if (!tempdir.isDirectory())\\n         {\\n-            log.error(\"\\'\" + ConfigurationManager.getProperty(\"org.dspace.app.itemexport.work.dir\") +\\n-                    \"\\' as defined by the key \\'org.dspace.app.itemexport.work.dir\\' in dspace.cfg \" +\\n+            log.error(\"\\'\" + ConfigurationManager.getProperty(\"org.dspace.app.batchitemimport.work.dir\") +\\n+                    \"\\' as defined by the key \\'org.dspace.app.batchitemimport.work.dir\\' in dspace.cfg \" +\\n                     \"is not a valid directory\");\\n         }\\n \\n         if (!tempdir.exists() && !tempdir.mkdirs())\\n         {\\n             log.error(\"Unable to create temporary directory: \" + tempdir.getAbsolutePath());\\n         }\\n-        String sourcedir = destinationDir + System.getProperty(\"file.separator\") + zipfile.getName();\\n-        String zipDir = destinationDir + System.getProperty(\"file.separator\") + zipfile.getName() + System.getProperty(\"file.separator\");\\n \\n+        if(!destinationDir.endsWith(System.getProperty(\"file.separator\"))) {\\n+            destinationDir += System.getProperty(\"file.separator\");\\n+        }\\n+\\n+        String sourcedir = destinationDir + zipfile.getName();\\n+        String zipDir = destinationDir + zipfile.getName() + System.getProperty(\"file.separator\");\\n+\\n+        log.debug(\"zip directory to use is \" + zipDir);\\n \\n         \/\/ 3\\n         String sourceDirForZip = sourcedir;\\n@@ -2028,11 +2036,26 @@ public static String unzip(File zipfile, String destDir) throws IOException {\\n         while (entries.hasMoreElements())\\n         {\\n             entry = entries.nextElement();\\n+            \/\/ Check that the true path to extract files is never outside allowed temp directories\\n+            \/\/ without creating any actual files on disk\\n+            log.debug(\"Inspecting entry name: \" + entry.getName() + \" for path traversal security\");\\n+            File potentialExtract = new File(zipDir + entry.getName());\\n+            String canonicalPath = potentialExtract.getCanonicalPath();\\n+            log.debug(\"Canonical path to potential File is \" + canonicalPath);\\n+            if(!canonicalPath.startsWith(zipDir)) {\\n+                log.error(\"Rejecting zip file: \" + zipfile.getName() + \" as it contains an entry that would be extracted \" +\\n+                        \"outside the temporary unzip directory: \" + canonicalPath);\\n+                throw new IOException(\"Error extracting \" + zipfile + \": Canonical path of zip entry: \" +\\n+                        entry.getName() + \" (\" + canonicalPath + \") does not start with permissible temp \" +\\n+                        \"unzip directory (\" + destinationDir + \")\");\\n+            }\\n             if (entry.isDirectory())\\n             {\\n-                if (!new File(zipDir + entry.getName()).mkdir())\\n-                {\\n+                \/\/ Log error and throw IOException if a directory entry could not be created\\n+                File newDir = new File(zipDir + entry.getName());\\n+                if (!newDir.mkdirs()) {\\n                     log.error(\"Unable to create contents directory: \" + zipDir + entry.getName());\\n+                    throw new IOException(\"Unable to create contents directory: \" + zipDir + entry.getName());\\n                 }\\n             }\\n             else\\n@@ -2074,6 +2097,7 @@ public static String unzip(File zipfile, String destDir) throws IOException {\\n                 byte[] buffer = new byte[1024];\\n                 int len;\\n                 InputStream in = zf.getInputStream(entry);\\n+                log.debug(\"Reading \" + zipDir + entry.getName() + \" into InputStream\");\\n                 BufferedOutputStream out = new BufferedOutputStream(\\n                         new FileOutputStream(zipDir + entry.getName()));\\n                 while((len = in.read(buffer)) >= 0)'}}",
            "message_norm":"[ds-4131] better path handling in itemimport zips",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dspace-api\/src\/main\/java\/org\/dspace\/app\/itemimport\/ItemImport.java'])",
            "num_files":1.0
        },
        {
            "index":823,
            "vuln_id":"GHSA-6f89-8j54-29xf",
            "cwe_id":"{'CWE-787', 'CWE-119'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/12c727cee857fa19be717f336943d95fca4ffe4f'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `FractionalAvgPoolGrad` ### Impact\nThe implementation of `tf.raw_ops.FractionalAvgPoolGrad` is vulnerable to a heap buffer overflow:\n  \n```python\nimport tensorflow as tf\n\norig_input_tensor_shape = tf.constant([1, 3, 2, 3], shape=[4], dtype=tf.int64)\nout_backprop = tf.constant([2], shape=[1, 1, 1, 1], dtype=tf.int64)\nrow_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\ncol_pooling_sequence = tf.constant([1], shape=[1], dtype=tf.int64)\n\n\ntf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=orig_input_tensor_shape, out_backprop=out_backprop,\n  row_pooling_sequence=row_pooling_sequence,\n  col_pooling_sequence=col_pooling_sequence, overlapping=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/dcba796a28364d6d7f003f6fe733d82726dda713\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc#L216) fails to validate that the pooling sequence arguments have enough elements as required by the `out_backprop` tensor shape.\n\n### Patches\nWe have patched the issue in GitHub commit [12c727cee857fa19be717f336943d95fca4ffe4f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/12c727cee857fa19be717f336943d95fca4ffe4f).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/12c727cee857fa19be717f336943d95fca4ffe4f",
            "commit_sha":"12c727cee857fa19be717f336943d95fca4ffe4f",
            "patch":"SINGLE",
            "chain_ord":"['12c727cee857fa19be717f336943d95fca4ffe4f']",
            "before_first_fix_commit":"{'dcba796a28364d6d7f003f6fe733d82726dda713'}",
            "last_fix_commit":"12c727cee857fa19be717f336943d95fca4ffe4f",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 21:02:47",
            "message":"Validate inputs of `FractionalAvgPoolGrad`.\n\nPiperOrigin-RevId: 372420640\nChange-Id: Icc583928e6cdc3062e12498e4d2337a8fe3da016",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
            "files":"{'tensorflow\/core\/kernels\/fractional_avg_pool_op.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/12c727cee857fa19be717f336943d95fca4ffe4f\/tensorflow%2Fcore%2Fkernels%2Ffractional_avg_pool_op.cc', 'patch': '@@ -250,6 +250,19 @@ class FractionalAvgPoolGradOp : public OpKernel {\\n     const int64 out_cols = out_backprop.dim_size(2);\\n     const int64 out_depth = out_backprop.dim_size(3);\\n \\n+    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\\n+                errors::InvalidArgument(\"Given out_backprop shape \",\\n+                                        out_backprop.shape().DebugString(),\\n+                                        \", row_seq_tensor must have at least \",\\n+                                        out_rows + 1, \" elements, but got \",\\n+                                        row_seq_tensor.NumElements()));\\n+    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\\n+                errors::InvalidArgument(\"Given out_backprop shape \",\\n+                                        out_backprop.shape().DebugString(),\\n+                                        \", col_seq_tensor must have at least \",\\n+                                        out_cols + 1, \" elements, but got \",\\n+                                        col_seq_tensor.NumElements()));\\n+\\n     auto row_seq_tensor_flat = row_seq_tensor.flat<int64>();\\n     auto col_seq_tensor_flat = col_seq_tensor.flat<int64>();\\n     auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64>();'}}",
            "message_norm":"validate inputs of `fractionalavgpoolgrad`.\n\npiperorigin-revid: 372420640\nchange-id: icc583928e6cdc3062e12498e4d2337a8fe3da016",
            "language":"it",
            "entities":"[('validate', 'ACTION', ''), ('372420640', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/fractional_avg_pool_op.cc'])",
            "num_files":1.0
        },
        {
            "index":871,
            "vuln_id":"GHSA-6mv9-hcx5-7mhh",
            "cwe_id":"{'CWE-918'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/2d16b459205730d85e51499c2457109b234ca9d9'}",
            "dataset":"osv",
            "summary":"Server-Side Request Forgery in Jenkins An improper authorization vulnerability exists in Jenkins versions 2.106 and earlier, and LTS 2.89.3 and earlier, that allows an attacker to have Jenkins submit HTTP GET requests and get limited information about the response.",
            "published_date":"2022-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/2d16b459205730d85e51499c2457109b234ca9d9",
            "commit_sha":"2d16b459205730d85e51499c2457109b234ca9d9",
            "patch":"SINGLE",
            "chain_ord":"['2d16b459205730d85e51499c2457109b234ca9d9']",
            "before_first_fix_commit":"{'ccc374a7176d7704941fb494589790b7673efe2e'}",
            "last_fix_commit":"2d16b459205730d85e51499c2457109b234ca9d9",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/30\/2018, 17:15:48",
            "message":"[SECURITY-506] Require admin permission to validate proxy config.",
            "author":"Jesse Glick",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'core\/src\/main\/java\/hudson\/ProxyConfiguration.java': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/2d16b459205730d85e51499c2457109b234ca9d9\/core%2Fsrc%2Fmain%2Fjava%2Fhudson%2FProxyConfiguration.java', 'patch': '@@ -341,6 +341,8 @@ public FormValidation doValidateProxy(\\n                 @QueryParameter(\"userName\") String userName, @QueryParameter(\"password\") String password,\\n                 @QueryParameter(\"noProxyHost\") String noProxyHost) {\\n \\n+            Jenkins.getInstance().checkPermission(Jenkins.ADMINISTER);\\n+\\n             if (Util.fixEmptyAndTrim(testUrl) == null) {\\n                 return FormValidation.error(Messages.ProxyConfiguration_TestUrlRequired());\\n             }'}}",
            "message_norm":"[security-506] require admin permission to validate proxy config.",
            "language":"en",
            "entities":"[('security-506', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('permission', 'SECWORD', ''), ('validate', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/src\/main\/java\/hudson\/ProxyConfiguration.java'])",
            "num_files":1.0
        },
        {
            "index":3203,
            "vuln_id":"GHSA-w2pm-r78h-4m7v",
            "cwe_id":"{'CWE-78'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/laravel\/framework\/commit\/44c3feb604944599ad1c782a9942981c3991fa31'}",
            "dataset":"osv",
            "summary":"OS Command Injection in Laravel Framework OS Command injection vulnerability in function link in Filesystem.php in Laravel Framework before 5.8.17.",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/laravel\/framework",
            "commit_href":"https:\/\/github.com\/laravel\/framework\/commit\/44c3feb604944599ad1c782a9942981c3991fa31",
            "commit_sha":"44c3feb604944599ad1c782a9942981c3991fa31",
            "patch":"SINGLE",
            "chain_ord":"['44c3feb604944599ad1c782a9942981c3991fa31']",
            "before_first_fix_commit":"{'c7a3ca1c6df547a807807ffc782c13b92d44a1ad'}",
            "last_fix_commit":"44c3feb604944599ad1c782a9942981c3991fa31",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/14\/2019, 15:58:33",
            "message":"use escapeshellarg on windows symlink",
            "author":"Taylor Otwell",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/Illuminate\/Filesystem\/Filesystem.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/laravel\/framework\/raw\/44c3feb604944599ad1c782a9942981c3991fa31\/src%2FIlluminate%2FFilesystem%2FFilesystem.php', 'patch': '@@ -254,7 +254,7 @@ public function link($target, $link)\\n \\n         $mode = $this->isDirectory($target) ? \\'J\\' : \\'H\\';\\n \\n-        exec(\"mklink \/{$mode} \\\\\"{$link}\\\\\" \\\\\"{$target}\\\\\"\");\\n+        exec(\"mklink \/{$mode} \".escapeshellarg($link).\" \".escapeshellarg($target));\\n     }\\n \\n     \/**'}}",
            "message_norm":"use escapeshellarg on windows symlink",
            "language":"en",
            "entities":"[('escapeshellarg', 'SECWORD', ''), ('symlink', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Illuminate\/Filesystem\/Filesystem.php'])",
            "num_files":1.0
        },
        {
            "index":1042,
            "vuln_id":"GHSA-7mpx-vg3c-cmr4",
            "cwe_id":"{'CWE-287'}",
            "score":8.2,
            "chain":"{'https:\/\/github.com\/salvoravida\/react-adal\/commit\/74158dba1647b12fe96fa401e306a6287fe9e2a9'}",
            "dataset":"osv",
            "summary":"Improper Authentication in react-adal This affects versions of react-adal < 0.5.1. It is possible for a specially crafted JWT token and request URL can cause the nonce, session and refresh values to be incorrectly validated, causing the application to treat an attacker-generated JWT token as authentic. The logical defect is caused by how the nonce, session and refresh values are stored in the browser local storage or session storage. Each key is automatically appended by ||. When the received nonce and session keys are generated, the list of values is stored in the browser storage, separated by ||, with || always appended to the end of the list. Since || will always be the last 2 characters of the stored values, an empty string (\"\") will always be in the list of the valid values. Therefore, if an empty session parameter is provided in the callback URL, and a specially-crafted JWT token contains an nonce value of \"\" (empty string), then adal.js will consider the JWT token as authentic.",
            "published_date":"2021-04-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/salvoravida\/react-adal",
            "commit_href":"https:\/\/github.com\/salvoravida\/react-adal\/commit\/74158dba1647b12fe96fa401e306a6287fe9e2a9",
            "commit_sha":"74158dba1647b12fe96fa401e306a6287fe9e2a9",
            "patch":"SINGLE",
            "chain_ord":"['74158dba1647b12fe96fa401e306a6287fe9e2a9']",
            "before_first_fix_commit":"{'e82bc421d70805ff308e11a1f0f1fcd7fb2b3186'}",
            "last_fix_commit":"74158dba1647b12fe96fa401e306a6287fe9e2a9",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/05\/2020, 20:19:06",
            "message":"ADAL.js update",
            "author":"Kris Hardy",
            "comments":null,
            "stats":"{'additions': 32, 'deletions': 51, 'total': 83}",
            "files":"{'src\/adal.js': {'additions': 32, 'deletions': 51, 'changes': 83, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/salvoravida\/react-adal\/raw\/74158dba1647b12fe96fa401e306a6287fe9e2a9\/src%2Fadal.js', 'patch': \"@@ -135,10 +135,6 @@ var AuthenticationContext = (function () {\\n         this._openedWindows = [];\\n         this._requestType = this.REQUEST_TYPE.LOGIN;\\n         window._adalInstance = this;\\n-        this._storageSupport = {\\n-            localStorage: null,\\n-            sessionStorage: null\\n-        };\\n \\n         \/\/ validate before constructor assignments\\n         if (config.displayCall && typeof config.displayCall !== 'function') {\\n@@ -813,7 +809,6 @@ var AuthenticationContext = (function () {\\n      * Clears cache items.\\n      *\/\\n     AuthenticationContext.prototype.clearCache = function () {\\n-        this._user = null;\\n         this._saveItem(this.CONSTANTS.STORAGE.LOGIN_REQUEST, '');\\n         this._saveItem(this.CONSTANTS.STORAGE.ANGULAR_LOGIN_REQUEST, '');\\n         this._saveItem(this.CONSTANTS.STORAGE.SESSION_STATE, '');\\n@@ -860,6 +855,7 @@ var AuthenticationContext = (function () {\\n      *\/\\n     AuthenticationContext.prototype.logOut = function () {\\n         this.clearCache();\\n+        this._user = null;\\n         var urlNavigate;\\n \\n         if (this.config.logOutUri) {\\n@@ -928,8 +924,7 @@ var AuthenticationContext = (function () {\\n      * @ignore\\n      *\/\\n     AuthenticationContext.prototype._addHintParameters = function (urlNavigate) {\\n-\\n-        \/\/If you don't use prompt=none, then if the session does not exist, there will be a failure.\\n+        \/\/If you don\ufffdt use prompt=none, then if the session does not exist, there will be a failure.\\n         \/\/If sid is sent alongside domain or login hints, there will be a failure since request is ambiguous.\\n         \/\/If sid is sent with a prompt value other than none or attempt_none, there will be a failure since the request is ambiguous.\\n \\n@@ -1103,7 +1098,7 @@ var AuthenticationContext = (function () {\\n         if (requestNonce) {\\n             requestNonce = requestNonce.split(this.CONSTANTS.CACHE_DELIMETER);\\n             for (var i = 0; i < requestNonce.length; i++) {\\n-                if (requestNonce[i] === user.profile.nonce) {\\n+                if (requestNonce[i] && requestNonce[i] === user.profile.nonce) {\\n                     return true;\\n                 }\\n             }\\n@@ -1122,7 +1117,7 @@ var AuthenticationContext = (function () {\\n         if (loginStates) {\\n             loginStates = loginStates.split(this.CONSTANTS.CACHE_DELIMETER);\\n             for (var i = 0; i < loginStates.length; i++) {\\n-                if (loginStates[i] === requestInfo.stateResponse) {\\n+                if (loginStates[i] && loginStates[i] === requestInfo.stateResponse) {\\n                     requestInfo.requestType = this.REQUEST_TYPE.LOGIN;\\n                     requestInfo.stateMatch = true;\\n                     return true;\\n@@ -1135,7 +1130,7 @@ var AuthenticationContext = (function () {\\n         if (acquireTokenStates) {\\n             acquireTokenStates = acquireTokenStates.split(this.CONSTANTS.CACHE_DELIMETER);\\n             for (var i = 0; i < acquireTokenStates.length; i++) {\\n-                if (acquireTokenStates[i] === requestInfo.stateResponse) {\\n+                if (acquireTokenStates[i] && acquireTokenStates[i] === requestInfo.stateResponse) {\\n                     requestInfo.requestType = this.REQUEST_TYPE.RENEW_TOKEN;\\n                     requestInfo.stateMatch = true;\\n                     return true;\\n@@ -1218,16 +1213,17 @@ var AuthenticationContext = (function () {\\n                             this._user = null;\\n                         } else {\\n                             this._saveItem(this.CONSTANTS.STORAGE.IDTOKEN, requestInfo.parameters[this.CONSTANTS.ID_TOKEN]);\\n+\\n                             \/\/ Save idtoken as access token for app itself\\n-                            var idTokenResource = this.config.loginResource ? this.config.loginResource : this.config.clientId;\\n+                            resource = this.config.loginResource ? this.config.loginResource : this.config.clientId;\\n \\n-                            if (!this._hasResource(idTokenResource)) {\\n+                            if (!this._hasResource(resource)) {\\n                                 keys = this._getItem(this.CONSTANTS.STORAGE.TOKEN_KEYS) || '';\\n-                                this._saveItem(this.CONSTANTS.STORAGE.TOKEN_KEYS, keys + idTokenResource + this.CONSTANTS.RESOURCE_DELIMETER);\\n+                                this._saveItem(this.CONSTANTS.STORAGE.TOKEN_KEYS, keys + resource + this.CONSTANTS.RESOURCE_DELIMETER);\\n                             }\\n \\n-                            this._saveItem(this.CONSTANTS.STORAGE.ACCESS_TOKEN_KEY + idTokenResource, requestInfo.parameters[this.CONSTANTS.ID_TOKEN]);\\n-                            this._saveItem(this.CONSTANTS.STORAGE.EXPIRATION_KEY + idTokenResource, this._user.profile.exp);\\n+                            this._saveItem(this.CONSTANTS.STORAGE.ACCESS_TOKEN_KEY + resource, requestInfo.parameters[this.CONSTANTS.ID_TOKEN]);\\n+                            this._saveItem(this.CONSTANTS.STORAGE.EXPIRATION_KEY + resource, this._user.profile.exp);\\n                         }\\n                     }\\n                     else {\\n@@ -1689,7 +1685,7 @@ var AuthenticationContext = (function () {\\n                 ifr.setAttribute('aria-hidden', 'true');\\n                 ifr.style.visibility = 'hidden';\\n                 ifr.style.position = 'absolute';\\n-                ifr.style.width = ifr.style.height = ifr.style.borderWidth = '0px';\\n+                ifr.style.width = ifr.style.height = ifr.borderWidth = '0px';\\n \\n                 adalFrame = document.getElementsByTagName('body')[0].appendChild(ifr);\\n             }\\n@@ -1764,52 +1760,37 @@ var AuthenticationContext = (function () {\\n     };\\n \\n     \/**\\n-     * Returns true if the browser supports given storage type\\n+     * Returns true if browser supports localStorage, false otherwise.\\n      * @ignore\\n      *\/\\n-    AuthenticationContext.prototype._supportsStorage = function(storageType) {\\n-        if (!(storageType in this._storageSupport)) {\\n-            return false;\\n-        }\\n-\\n-        if (this._storageSupport[storageType] !== null) {\\n-            return this._storageSupport[storageType];\\n-        }\\n-\\n+    AuthenticationContext.prototype._supportsLocalStorage = function () {\\n         try {\\n-            if (!(storageType in window) || window[storageType] === null) {\\n-                throw new Error();\\n-            }\\n-            var testKey = '__storageTest__';\\n-            window[storageType].setItem(testKey, 'A');\\n-            if (window[storageType].getItem(testKey) !== 'A') {\\n-                throw new Error();\\n-            }\\n-            window[storageType].removeItem(testKey);\\n-            if (window[storageType].getItem(testKey)) {\\n-                throw new Error();\\n-            }\\n-            this._storageSupport[storageType] = true;\\n+            if (!window.localStorage) return false; \/\/ Test availability\\n+            window.localStorage.setItem('storageTest', 'A'); \/\/ Try write\\n+            if (window.localStorage.getItem('storageTest') != 'A') return false; \/\/ Test read\/write\\n+            window.localStorage.removeItem('storageTest'); \/\/ Try delete\\n+            if (window.localStorage.getItem('storageTest')) return false; \/\/ Test delete\\n+            return true; \/\/ Success\\n         } catch (e) {\\n-            this._storageSupport[storageType] = false;\\n+            return false;\\n         }\\n-        return this._storageSupport[storageType];\\n-    }\\n-\\n-    \/**\\n-     * Returns true if browser supports localStorage, false otherwise.\\n-     * @ignore\\n-     *\/\\n-    AuthenticationContext.prototype._supportsLocalStorage = function () {        \\n-        return this._supportsStorage('localStorage');\\n     };\\n \\n     \/**\\n      * Returns true if browser supports sessionStorage, false otherwise.\\n      * @ignore\\n      *\/\\n     AuthenticationContext.prototype._supportsSessionStorage = function () {\\n-        return this._supportsStorage('sessionStorage');\\n+        try {\\n+            if (!window.sessionStorage) return false; \/\/ Test availability\\n+            window.sessionStorage.setItem('storageTest', 'A'); \/\/ Try write\\n+            if (window.sessionStorage.getItem('storageTest') != 'A') return false; \/\/ Test read\/write\\n+            window.sessionStorage.removeItem('storageTest'); \/\/ Try delete\\n+            if (window.sessionStorage.getItem('storageTest')) return false; \/\/ Test delete\\n+            return true; \/\/ Success\\n+        } catch (e) {\\n+            return false;\\n+        }\\n     };\\n \\n     \/**\\n@@ -1955,4 +1936,4 @@ var AuthenticationContext = (function () {\\n \\n     return AuthenticationContext;\\n \\n-}());\\n\\\\ No newline at end of file\\n+}());\"}}",
            "message_norm":"adal.js update",
            "language":"id",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"SUBMIT_CENTERED",
            "list_files":"dict_keys(['src\/adal.js'])",
            "num_files":1.0
        },
        {
            "index":2009,
            "vuln_id":"GHSA-h6wm-mr85-4h9g",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/neorazorx\/facturascripts\/commit\/73a6595ca85984d65f656c6356fabb23d1936c54'}",
            "dataset":"osv",
            "summary":"Cross site scripting in facturascripts A Cross-site Scripting (XSS) vulnerability exists in the fsNick parameter in facturascripts prior to version 2022.06",
            "published_date":"2022-06-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/neorazorx\/facturascripts",
            "commit_href":"https:\/\/github.com\/neorazorx\/facturascripts\/commit\/73a6595ca85984d65f656c6356fabb23d1936c54",
            "commit_sha":"73a6595ca85984d65f656c6356fabb23d1936c54",
            "patch":"SINGLE",
            "chain_ord":"['73a6595ca85984d65f656c6356fabb23d1936c54']",
            "before_first_fix_commit":"{'298eb4b1a94c5898fde5a21e412955fc77a3ef93'}",
            "last_fix_commit":"73a6595ca85984d65f656c6356fabb23d1936c54",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 09:29:31",
            "message":"Sanitized username when showing user not found message.\n------\nSaneado nombre de usuario al mostrar el mensaje de usuario no encontrado.",
            "author":"Carlos Garcia Gomez",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'Core\/App\/AppController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NeoRazorX\/facturascripts\/raw\/73a6595ca85984d65f656c6356fabb23d1936c54\/Core%2FApp%2FAppController.php', 'patch': \"@@ -287,7 +287,7 @@ private function userAuth()\\n         }\\n \\n         $this->ipWarning();\\n-        ToolBox::i18nLog()->warning('login-user-not-found', ['%nick%' => $nick]);\\n+        ToolBox::i18nLog()->warning('login-user-not-found', ['%nick%' => htmlspecialchars($nick)]);\\n         return false;\\n     }\"}}",
            "message_norm":"sanitized username when showing user not found message.\n------\nsaneado nombre de usuario al mostrar el mensaje de usuario no encontrado.",
            "language":"en",
            "entities":"[('sanitized', 'SECWORD', ''), ('found', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Core\/App\/AppController.php'])",
            "num_files":1.0
        },
        {
            "index":288,
            "vuln_id":"GHSA-3pg8-c473-w6rr",
            "cwe_id":"{'CWE-79'}",
            "score":6.9,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/3caa32334db0c277b84e993eaca2036f5d1dbef8'}",
            "dataset":"osv",
            "summary":"Stored Cross-site Scripting in showdoc ShowDoc is a tool for an IT team to share documents online. showdoc contains a stored cross-site scripting vulnerability in the File Library page when uploading a file in .ofd format in versions prior to 2.10.4. At this time, there is no known workaround. Users should update to version 2.10.4.",
            "published_date":"2022-03-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/3caa32334db0c277b84e993eaca2036f5d1dbef8",
            "commit_sha":"3caa32334db0c277b84e993eaca2036f5d1dbef8",
            "patch":"SINGLE",
            "chain_ord":"['3caa32334db0c277b84e993eaca2036f5d1dbef8']",
            "before_first_fix_commit":"{'92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f'}",
            "last_fix_commit":"3caa32334db0c277b84e993eaca2036f5d1dbef8",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2022, 15:26:49",
            "message":"Upload file vulnerability",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 7, 'total': 12}",
            "files":"{'server\/Application\/Api\/Model\/AttachmentModel.class.php': {'additions': 5, 'deletions': 7, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/3caa32334db0c277b84e993eaca2036f5d1dbef8\/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -54,10 +54,10 @@ public function deleteFile($file_id){\\n \\t}\\n \\n \\t\/\/\u4e0a\u4f20\u6587\u4ef6\uff0c\u8fd4\u56deurl\\n-\\tpublic function upload($_files , $file_key , $uid , $item_id = 0  , $page_id = 0  ){\\n+\\tpublic function upload($_files , $file_key , $uid , $item_id = 0  , $page_id = 0 , $check_filename = true  ){\\n \\t\\t$uploadFile = $_files[$file_key] ;\\n \\n-\\t\\tif( !$this->isAllowedFilename($_files[$file_key]['name']) ){\\n+\\t\\tif( $check_filename && !$this->isAllowedFilename($_files[$file_key]['name']) ){\\n \\t\\t\\treturn false;\\n \\t\\t}\\n \\n@@ -324,14 +324,12 @@ public function isDangerFilename($filename){\\n \\tpublic function isAllowedFilename($filename){\\n \\t\\t$allow_array = array(\\n \\t\\t\\t'.jpg','.jpeg','.png','.bmp','.gif','.ico','.webp',\\n-\\t\\t\\t'.mp3','.wav','.mp4',\\n-\\t\\t\\t'.mov','.webmv','.flac','.mkv',\\n+\\t\\t\\t'.mp3','.wav','.mp4','.mov','.flac','.mkv',\\n \\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso',\\n-\\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n-\\t\\t\\t'.doc','.docx','.wps',\\n+\\t\\t\\t'.pdf','.epub','.xps','.doc','.docx','.wps',\\n \\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\\n \\t\\t\\t'.cer','.ppt','.pub','.json','.css',\\n-\\t\\t\\t) ;\\n+\\t\\t) ;\\n \\n \\t\\t$ext = strtolower(substr($filename,strripos($filename,'.')) ); \/\/\u83b7\u53d6\u6587\u4ef6\u6269\u5c55\u540d\uff08\u8f6c\u4e3a\u5c0f\u5199\u540e\uff09\\n \\t\\tif(in_array( $ext , $allow_array ) ){\"}}",
            "message_norm":"upload file vulnerability",
            "language":"ro",
            "entities":"[('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Model\/AttachmentModel.class.php'])",
            "num_files":1.0
        },
        {
            "index":2423,
            "vuln_id":"GHSA-mh83-jcw5-rjh8",
            "cwe_id":"{'CWE-611'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/stanfordnlp\/corenlp\/commit\/1f52136321cfca68b991bd7870563d06cf96624d'}",
            "dataset":"osv",
            "summary":"XML External Entity Reference in edu.stanford.nlp:stanford-corenlp The TransformXML() function makes use of SAXParser generated from a SAXParserFactory with no FEATURE_SECURE_PROCESSING set, allowing for XXE attacks.",
            "published_date":"2022-01-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/stanfordnlp\/corenlp",
            "commit_href":"https:\/\/github.com\/stanfordnlp\/corenlp\/commit\/1f52136321cfca68b991bd7870563d06cf96624d",
            "commit_sha":"1f52136321cfca68b991bd7870563d06cf96624d",
            "patch":"SINGLE",
            "chain_ord":"['1f52136321cfca68b991bd7870563d06cf96624d']",
            "before_first_fix_commit":"{'76666dd1d1697177585bbc618c21faf998028509'}",
            "last_fix_commit":"1f52136321cfca68b991bd7870563d06cf96624d",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/12\/2022, 07:13:08",
            "message":"Fix SAXParser security issue",
            "author":"Haxatron",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'src\/edu\/stanford\/nlp\/process\/TransformXML.java': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/stanfordnlp\/CoreNLP\/raw\/1f52136321cfca68b991bd7870563d06cf96624d\/src%2Fedu%2Fstanford%2Fnlp%2Fprocess%2FTransformXML.java', 'patch': '@@ -5,6 +5,7 @@\\n import java.io.*;\\n import java.util.*;\\n \\n+import javax.xml.XMLConstants;\\n import javax.xml.parsers.SAXParser;\\n import javax.xml.parsers.SAXParserFactory;\\n \\n@@ -195,6 +196,8 @@ public void processText(String text) {\\n \\n   public TransformXML() {\\n     try {\\n+      SAXParserFactory spf = SAXParserFactory.newInstance();\\n+      spf.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\\n       saxParser = SAXParserFactory.newInstance().newSAXParser();\\n     } catch (Exception e) {\\n       log.info(\"Error configuring XML parser: \" + e);'}}",
            "message_norm":"fix saxparser security issue",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/edu\/stanford\/nlp\/process\/TransformXML.java'])",
            "num_files":1.0
        },
        {
            "index":3504,
            "vuln_id":"GHSA-xw93-v57j-fcgh",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5'}",
            "dataset":"osv",
            "summary":"Division by 0 in `SparseMatMul` ### Impact\nAn attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.SparseMatMul`:\n\n```python\nimport tensorflow as tf\n\na = tf.constant([100.0, 100.0, 100.0, 100.0], shape=[2, 2], dtype=tf.float32)\nb = tf.constant([], shape=[0, 2], dtype=tf.float32)\n\ntf.raw_ops.SparseMatMul(\n    a=a, b=b, transpose_a=True, transpose_b=True,\n    a_is_sparse=True, b_is_sparse=True)\n``` \n    \nThe division by 0 occurs deep in Eigen code because the `b` tensor is empty.\n    \n### Patches\nWe have patched the issue in GitHub commit [7f283ff806b2031f407db64c4d3edcda8fb9f9f5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "commit_sha":"7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "patch":"SINGLE",
            "chain_ord":"['7f283ff806b2031f407db64c4d3edcda8fb9f9f5']",
            "before_first_fix_commit":"{'05a63e605a31e86c5dd96c5c8a763eda9ac7bb33'}",
            "last_fix_commit":"7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 22:00:39",
            "message":"Fix FPE issue in external Eigen source code issue with `tf.raw_ops.SparseMatMul`.\n\nPiperOrigin-RevId: 370992919\nChange-Id: Icfb276fef5fb40928b27c3e44608d2aca72c9fd7",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/sparse_matmul_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5\/tensorflow%2Fcore%2Fkernels%2Fsparse_matmul_op.cc', 'patch': '@@ -1039,6 +1039,10 @@ class SparseMatMulOp : public OpKernel {\\n     if (transpose_b) {\\n       \/\/ TODO(agarwal): avoid transposing the matrix here and directly handle\\n       \/\/ transpose in CreateDenseSlices.\\n+      OP_REQUIRES(ctx, right->dim_size(0) != 0,\\n+                  errors::InvalidArgument(\"b has an entry 0 in it\\'s shape.\"));\\n+      OP_REQUIRES(ctx, right->dim_size(1) != 0,\\n+                  errors::InvalidArgument(\"b has an entry 0 in it\\'s shape.\"));\\n       right_tr.reset(\\n           new Tensor(right->dtype(),\\n                      TensorShape({right->dim_size(1), right->dim_size(0)})));'}}",
            "message_norm":"fix fpe issue in external eigen source code issue with `tf.raw_ops.sparsematmul`.\n\npiperorigin-revid: 370992919\nchange-id: icfb276fef5fb40928b27c3e44608d2aca72c9fd7",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('issue', 'FLAW', ''), ('issue', 'FLAW', ''), ('370992919', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_matmul_op.cc'])",
            "num_files":1.0
        },
        {
            "index":682,
            "vuln_id":"GHSA-5qjq-69w6-fg57",
            "cwe_id":"{'CWE-79'}",
            "score":10.0,
            "chain":"{'https:\/\/github.com\/flarum\/core\/commit\/440bed81b8019dff00642c8f493b4909d505a28a'}",
            "dataset":"osv",
            "summary":"XSS vulnerability with translator Flarum's translation system allowed for string inputs to be converted into HTML DOM nodes when rendered. This change was made after v0.1.0-beta.16 (our last beta before v1.0.0) and was not noticed or documented.\n\nThis allowed for any user to type malicious HTML markup within certain user input fields and have this execute on client browsers. The example which led to the discovery of this vulnerability was in the forum search box. Entering faux-malicious HTML markup, such as <script>alert('test')<\/script> resulted in an alert box appearing on the forum. This attack could also be modified to perform AJAX requests on behalf of a user, possibly deleting discussions, modifying their settings or profile, or even modifying settings on the Admin panel if the attack was targetted towards a privileged user.\n\n### Impact\n\nAll Flarum communities that run flarum v1.0.0 or v1.0.1 are impacted.\n\n### Patches\n\nThe vulnerability has been fixed and published as flarum\/core v1.0.2. All communities running Flarum v1.0 have to upgrade as soon as possible to v1.0.2 using:\n\n```\ncomposer update --prefer-dist --no-dev -a -W\n```\n\nYou can then confirm you run the latest version using:\n\n```\ncomposer show flarum\/core\n```\n\n### Workarounds\n\n__None.__\n\n### For more information\n\nFor any questions or comments on this vulnerability please visit https:\/\/discuss.flarum.org\/d\/27558.\n\nFor support questions create a discussion at https:\/\/discuss.flarum.org\/t\/support.\n\nA reminder that if you ever become aware of a security issue in Flarum, please report it to us privately by emailing security@flarum.org, and we will address it promptly.",
            "published_date":"2021-06-07",
            "chain_len":1,
            "project":"https:\/\/github.com\/flarum\/core",
            "commit_href":"https:\/\/github.com\/flarum\/core\/commit\/440bed81b8019dff00642c8f493b4909d505a28a",
            "commit_sha":"440bed81b8019dff00642c8f493b4909d505a28a",
            "patch":"SINGLE",
            "chain_ord":"['440bed81b8019dff00642c8f493b4909d505a28a']",
            "before_first_fix_commit":"{'eeb8fe1443b98f5f622ca52b4a02732f62d1aa77'}",
            "last_fix_commit":"440bed81b8019dff00642c8f493b4909d505a28a",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/06\/2021, 01:41:48",
            "message":"Fix XSS vulnerability",
            "author":"David Wheatley",
            "comments":"{'com_1': {'author': 'davwheat', 'datetime': '06\/07\/2021, 20:53:34', 'body': 'The details about this vulnerability have now been made public.\\r\\n\\r\\nFor more information, please see: https:\/\/discuss.flarum.org\/d\/27558-critical-security-update-to-flarum-core-v102'}}",
            "stats":"{'additions': 12, 'deletions': 1, 'total': 13}",
            "files":"{'js\/src\/common\/Translator.tsx': {'additions': 12, 'deletions': 1, 'changes': 13, 'status': 'renamed', 'raw_url': 'https:\/\/github.com\/flarum\/framework\/raw\/440bed81b8019dff00642c8f493b4909d505a28a\/js%2Fsrc%2Fcommon%2FTranslator.tsx', 'patch': \"@@ -48,12 +48,23 @@ export default class Translator {\\n     \/\/ future there should be a hook here to inspect the user and change the\\n     \/\/ translation key. This will allow a gender property to determine which\\n     \/\/ translation key is used.\\n+\\n     if ('user' in parameters) {\\n       const user = extract(parameters, 'user');\\n \\n       if (!parameters.username) parameters.username = username(user);\\n     }\\n-    return parameters;\\n+\\n+    const escapedParameters: TranslatorParameters = {};\\n+\\n+    for (const param in parameters) {\\n+      const paramValue = parameters[param];\\n+\\n+      if (typeof paramValue === 'string') escapedParameters[param] = <>{parameters[param]}<\/>;\\n+      else escapedParameters[param] = parameters[param];\\n+    }\\n+\\n+    return escapedParameters;\\n   }\\n \\n   trans(id: string, parameters: TranslatorParameters = {}) {\"}}",
            "message_norm":"fix xss vulnerability",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('xss', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['js\/src\/common\/Translator.tsx'])",
            "num_files":1.0
        },
        {
            "index":2173,
            "vuln_id":"GHSA-j383-35pm-c5h4",
            "cwe_id":"{'CWE-22'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/gruntjs\/grunt\/commit\/aad3d4521c3098fb255fb2db8f2e1d691a033665', 'https:\/\/github.com\/gruntjs\/grunt\/commit\/b0ec6e12426fc8d5720dee1702f6a67455c5986c'}",
            "dataset":"osv",
            "summary":"Path Traversal in Grunt Grunt prior to version 1.5.2 is vulnerable to path traversal.",
            "published_date":"2022-04-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/gruntjs\/grunt",
            "commit_href":"https:\/\/github.com\/gruntjs\/grunt\/commit\/b0ec6e12426fc8d5720dee1702f6a67455c5986c",
            "commit_sha":"b0ec6e12426fc8d5720dee1702f6a67455c5986c",
            "patch":"MULTI",
            "chain_ord":"['aad3d4521c3098fb255fb2db8f2e1d691a033665', 'b0ec6e12426fc8d5720dee1702f6a67455c5986c']",
            "before_first_fix_commit":"{'433f91b78df99d83daa6f56a5505ead743627c30', 'd5969eccf2493c2c579c55a617c70cab48dc12d3'}",
            "last_fix_commit":"b0ec6e12426fc8d5720dee1702f6a67455c5986c",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/12\/2022, 11:51:53",
            "message":"Merge pull request #1743 from gruntjs\/cleanup-link\n\nClean up link handling",
            "author":"Vlad Filippov",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 6, 'total': 12}",
            "files":"{'lib\/grunt\/file.js': {'additions': 6, 'deletions': 6, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/gruntjs\/grunt\/raw\/b0ec6e12426fc8d5720dee1702f6a67455c5986c\/lib%2Fgrunt%2Ffile.js', 'patch': \"@@ -294,7 +294,12 @@ file.write = function(filepath, contents, options) {\\n \/\/ processing content, writing output.\\n \/\/ Handles symlinks by coping them as files or directories.\\n file.copy = function copy(srcpath, destpath, options) {\\n-  if (file._isSymbolicLink(srcpath)) {\\n+  if (file.isLink(destpath)) {\\n+    \/\/ in case destpath is a symlink, avoid following the symlink, instead overwrite it later\\n+    fs.unlinkSync(destpath);\\n+  }\\n+\\n+  if (file.isLink(srcpath)) {\\n     file._copySymbolicLink(srcpath, destpath);\\n   } else if (file.isDir(srcpath)) {\\n     \/\/ Copy a directory, recursively.\\n@@ -452,11 +457,6 @@ file.isPathCwd = function() {\\n   }\\n };\\n \\n-file._isSymbolicLink = function() {\\n-  var filepath = path.join.apply(path, arguments);\\n-  return fs.lstatSync(filepath).isSymbolicLink();\\n-};\\n-\\n file._copySymbolicLink = function(srcpath, destpath) {\\n   var destdir = path.join(destpath, '..');\\n   \/\/ Use the correct relative path for the symlink\"}}",
            "message_norm":"merge pull request #1743 from gruntjs\/cleanup-link\n\nclean up link handling",
            "language":"en",
            "entities":"[('#1743', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/grunt\/file.js'])",
            "num_files":1.0
        },
        {
            "index":2046,
            "vuln_id":"GHSA-hf44-3mx6-vhhw",
            "cwe_id":"{'CWE-400'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/graphhopper\/graphhopper\/commit\/eb189be1fa7443ebf4ae881e737a18f818c95f41'}",
            "dataset":"osv",
            "summary":"Navigate endpoint is vulnerable to regex injection that may lead to Denial of Service. ### Impact\nThe regex injection that may lead to Denial of Service.\n\n### Patches\nWill be patched in 2.4 and 3.0\n\n### Workarounds\nVersions lower than 2.x are only affected if the navigation module is added\n\n### References\nSee this pull request for the fix: https:\/\/github.com\/graphhopper\/graphhopper\/pull\/2304\n\nIf you have any questions or comments about this advisory please [send us an Email](https:\/\/www.graphhopper.com\/contact-form\/) or create a topic [here](https:\/\/discuss.graphhopper.com\/).",
            "published_date":"2021-05-19",
            "chain_len":1,
            "project":"https:\/\/github.com\/graphhopper\/graphhopper",
            "commit_href":"https:\/\/github.com\/graphhopper\/graphhopper\/commit\/eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "commit_sha":"eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "patch":"SINGLE",
            "chain_ord":"['eb189be1fa7443ebf4ae881e737a18f818c95f41']",
            "before_first_fix_commit":"{'744f0e2535355e67aefbb6906303332b8aff0a7f'}",
            "last_fix_commit":"eb189be1fa7443ebf4ae881e737a18f818c95f41",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/04\/2021, 18:03:31",
            "message":"avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexOf\r\n\r\n* make check stricter\r\n\r\n* use @easbar's suggestion",
            "author":"Peter",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 5, 'total': 8}",
            "files":"{'navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java': {'additions': 3, 'deletions': 5, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/graphhopper\/graphhopper\/raw\/eb189be1fa7443ebf4ae881e737a18f818c95f41\/navigation%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgraphhopper%2Fnavigation%2FNavigateResource.java', 'patch': '@@ -188,13 +188,11 @@ private GHResponse calcRoute(List<Double> favoredHeadings, List<GHPoint> request\\n      * The url looks like: \"...\/{profile}\/1.522438,42.504606;1.527209,42.504776;1.526113,42.505144;1.527218,42.50529?..\"\\n      *\/\\n     private List<GHPoint> getPointsFromRequest(HttpServletRequest httpServletRequest, String profile) {\\n-\\n         String url = httpServletRequest.getRequestURI();\\n-        url = url.replaceFirst(\"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\", \"\");\\n-        url = url.replaceAll(\"\\\\\\\\?[*]\", \"\");\\n-\\n+        String urlStart = \"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\";\\n+        if (!url.startsWith(urlStart)) throw new IllegalArgumentException(\"Incorrect URL \" + url);\\n+        url = url.substring(urlStart.length());\\n         String[] pointStrings = url.split(\";\");\\n-\\n         List<GHPoint> points = new ArrayList<>(pointStrings.length);\\n         for (int i = 0; i < pointStrings.length; i++) {\\n             points.add(GHPoint.fromStringLonLat(pointStrings[i]));'}}",
            "message_norm":"avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexof\r\n\r\n* make check stricter\r\n\r\n* use @easbar's suggestion",
            "language":"en",
            "entities":"[('#2304', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java'])",
            "num_files":1.0
        },
        {
            "index":1974,
            "vuln_id":"GHSA-h3gg-7wx2-cq3h",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/flarum\/sticky\/commit\/7ebd30462bd405c4c0570b93a6d48710e6c3db19'}",
            "dataset":"osv",
            "summary":"XSS in Flarum Sticky extension ### Impact\nA change in release beta 14 of the Sticky extension caused the plain text content of the first post of a pinned discussion to be injected as HTML on the discussion list. The issue was discovered following an internal audit.\n\nAny HTML would be injected through Mithril's `m.trust()` helper. This resulted in an HTML injection where `<script>` tags would not be executed. However it was possible to run javascript from other HTML attributes, enabling a cross-site scripting (XSS) attack to be performed.\n\nSince the exploit only happens with the first post of a pinned discussion, an attacker would need the ability to pin their own discussion, or be able to edit a discussion that was previously pinned.\n\nOn forums where all pinned posts are authored by your staff, you can be relatively certain the vulnerability has not been exploited.\n\nForums where some user-created discussions were pinned can look at the first post edit date to find whether the vulnerability might have been exploited. Because Flarum doesn't store the post content history, you cannot be certain if a malicious edit was reverted.\n\n### Patches\nThe fix will be available in version v0.1.0-beta.16 with Flarum beta 16. The fix has already been back-ported to Flarum beta 15 as version v0.1.0-beta.15.1 of the Sticky extension.\n\n### Workarounds\nForum administrators can disable the Sticky extension until they are able to apply the update. The vulnerability cannot be exploited while the extension is disabled.\n\n### References\n\n- [Release announcement](https:\/\/discuss.flarum.org\/d\/26042-security-update-to-flarum-sticky-010-beta151)\n- [Pull Request](https:\/\/github.com\/flarum\/sticky\/pull\/24)\n\n### For more information\nIf you have any questions or comments about this advisory, please start a new discussion on our [support forum](https:\/\/discuss.flarum.org\/t\/support).\n\nIf you discover a security vulnerability within Flarum, please send an e-mail to [security@flarum.org](mailto:security@flarum.org). All security vulnerabilities will be promptly addressed. More details can be found in our [security policy](https:\/\/github.com\/flarum\/core\/security\/policy).",
            "published_date":"2021-01-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/flarum\/sticky",
            "commit_href":"https:\/\/github.com\/flarum\/sticky\/commit\/7ebd30462bd405c4c0570b93a6d48710e6c3db19",
            "commit_sha":"7ebd30462bd405c4c0570b93a6d48710e6c3db19",
            "patch":"SINGLE",
            "chain_ord":"['7ebd30462bd405c4c0570b93a6d48710e6c3db19']",
            "before_first_fix_commit":"{'62a74d25ab3f84f69d1c4b5920080963788a8360'}",
            "last_fix_commit":"7ebd30462bd405c4c0570b93a6d48710e6c3db19",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/22\/2021, 18:53:11",
            "message":"Fix evaluation of post content by m.trust() (#24)",
            "author":"Sami Mazouz",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'js\/src\/forum\/addStickyExcerpt.js': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/flarum\/sticky\/raw\/7ebd30462bd405c4c0570b93a6d48710e6c3db19\/js%2Fsrc%2Fforum%2FaddStickyExcerpt.js', 'patch': \"@@ -21,7 +21,8 @@ export default function addStickyControl() {\\n       if (firstPost) {\\n         const excerpt = truncate(firstPost.contentPlain(), 175);\\n \\n-        items.add('excerpt', m.trust(excerpt), -100);\\n+        \/\/ Wrapping in <div> because ItemList entries need to be vnodes\\n+        items.add('excerpt', <div>{excerpt}<\/div>, -100);\\n       }\\n     }\\n   });\"}}",
            "message_norm":"fix evaluation of post content by m.trust() (#24)",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('#24', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['js\/src\/forum\/addStickyExcerpt.js'])",
            "num_files":1.0
        },
        {
            "index":2508,
            "vuln_id":"GHSA-p4v2-r99v-wjc2",
            "cwe_id":"{'CWE-116'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/nicotine-plus\/nicotine-plus\/commit\/0e3e2fac27a518f0a84330f1ddf1193424522045'}",
            "dataset":"osv",
            "summary":"Improper Encoding or Escaping of Output in Nicotine+ Denial of service (DoS) vulnerability in Nicotine+ starting with version 3.0.3 and prior to version 3.2.1 allows a user with a modified Soulseek client to crash Nicotine+ by sending a file download request with a file path containing a null character.",
            "published_date":"2022-03-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/nicotine-plus\/nicotine-plus",
            "commit_href":"https:\/\/github.com\/nicotine-plus\/nicotine-plus\/commit\/0e3e2fac27a518f0a84330f1ddf1193424522045",
            "commit_sha":"0e3e2fac27a518f0a84330f1ddf1193424522045",
            "patch":"SINGLE",
            "chain_ord":"['0e3e2fac27a518f0a84330f1ddf1193424522045']",
            "before_first_fix_commit":"{'aabfa856bd57bcf986c2ea296457986e83c0c98b'}",
            "last_fix_commit":"0e3e2fac27a518f0a84330f1ddf1193424522045",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/22\/2021, 18:49:21",
            "message":"Handle invalid file paths in file download requests\n\nFixes #1777",
            "author":"mathiascode",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 4, 'total': 17}",
            "files":"{'pynicotine\/shares.py': {'additions': 13, 'deletions': 4, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nicotine-plus\/nicotine-plus\/raw\/0e3e2fac27a518f0a84330f1ddf1193424522045\/pynicotine%2Fshares.py', 'patch': '@@ -609,13 +609,22 @@ def load_shares(cls, shares, dbs, reset_shares=False):\\n \\n     def file_is_shared(self, user, virtualfilename, realfilename):\\n \\n-        log.add_transfer(\"Checking if file %(virtual_name)s with real path %(path)s is shared\", {\\n+        log.add_transfer(\"Checking if file is shared: %(virtual_name)s with real path %(path)s\", {\\n             \"virtual_name\": virtualfilename,\\n             \"path\": realfilename\\n         })\\n \\n-        if not os.access(realfilename, os.R_OK):\\n-            log.add_transfer(\"Can\\'t access file %(virtual_name)s with real path %(path)s, not sharing\", {\\n+        try:\\n+            if not os.access(realfilename, os.R_OK):\\n+                log.add_transfer(\"Cannot access file, not sharing: %(virtual_name)s with real path %(path)s\", {\\n+                    \"virtual_name\": virtualfilename,\\n+                    \"path\": realfilename\\n+                })\\n+                return False\\n+\\n+        except Exception:\\n+            log.add_transfer((\"Requested file path contains invalid characters or other errors, not sharing: \"\\n+                              \"%(virtual_name)s with real path %(path)s\"), {\\n                 \"virtual_name\": virtualfilename,\\n                 \"path\": realfilename\\n             })\\n@@ -643,7 +652,7 @@ def file_is_shared(self, user, virtualfilename, realfilename):\\n                 if file == fileinfo[0]:\\n                     return True\\n \\n-        log.add_transfer(\"Failed to share file %(virtual_name)s with real path %(path)s, since it wasn\\'t found\", {\\n+        log.add_transfer(\"Failed to share file, since it wasn\\'t found: %(virtual_name)s with real path %(path)s\", {\\n             \"virtual_name\": virtualfilename,\\n             \"path\": realfilename\\n         })'}}",
            "message_norm":"handle invalid file paths in file download requests\n\nfixes #1777",
            "language":"en",
            "entities":"[('fixes', 'ACTION', ''), ('#1777', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['pynicotine\/shares.py'])",
            "num_files":1.0
        },
        {
            "index":3040,
            "vuln_id":"GHSA-v3jv-wrf4-5845",
            "cwe_id":"{'CWE-59'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/npm\/npm\/commit\/f4d31693e73a963574a88000580db1a716fe66f1'}",
            "dataset":"osv",
            "summary":"Local Privilege Escalation in npm Affected versions of `npm` use predictable temporary file names during archive unpacking. If an attacker can create a symbolic link at the location of one of these temporary file names, the attacker can arbitrarily write to any file that the user which owns the `npm` process has permission to write to, potentially resulting in local privilege escalation.\n\n\n\n## Recommendation\n\nUpdate to version 1.3.3 or later.",
            "published_date":"2020-09-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/npm\/npm",
            "commit_href":"https:\/\/github.com\/npm\/npm\/commit\/f4d31693e73a963574a88000580db1a716fe66f1",
            "commit_sha":"f4d31693e73a963574a88000580db1a716fe66f1",
            "patch":"SINGLE",
            "chain_ord":"['f4d31693e73a963574a88000580db1a716fe66f1']",
            "before_first_fix_commit":"{'e3007309aa93e94b69b5094fa1b11070b2ef993c'}",
            "last_fix_commit":"f4d31693e73a963574a88000580db1a716fe66f1",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/10\/2013, 15:59:28",
            "message":"Put 6 bytes of random in tmp folder name\n\nCloses #3635",
            "author":"isaacs",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 1, 'total': 7}",
            "files":"{'lib\/npm.js': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/npm\/npm\/raw\/f4d31693e73a963574a88000580db1a716fe66f1\/lib%2Fnpm.js', 'patch': '@@ -477,9 +477,14 @@ Object.defineProperty(npm, \"cache\",\\n   })\\n \\n var tmpFolder\\n+var crypto = require(\"crypto\")\\n+var rand = crypto.randomBytes(6)\\n+                 .toString(\"base64\")\\n+                 .replace(\/\\\\\/\/g, \\'_\\')\\n+                 .replace(\/\\\\+\/, \\'-\\')\\n Object.defineProperty(npm, \"tmp\",\\n   { get : function () {\\n-      if (!tmpFolder) tmpFolder = \"npm-\" + process.pid\\n+      if (!tmpFolder) tmpFolder = \"npm-\" + process.pid + \"-\" + rand\\n       return path.resolve(npm.config.get(\"tmp\"), tmpFolder)\\n     }\\n   , enumerable : true'}}",
            "message_norm":"put 6 bytes of random in tmp folder name\n\ncloses #3635",
            "language":"en",
            "entities":"[('#3635', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/npm.js'])",
            "num_files":1.0
        },
        {
            "index":3062,
            "vuln_id":"GHSA-v6r6-84gr-92rm",
            "cwe_id":"{'CWE-787', 'CWE-119'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6fc9141f42f6a72180ecd24021c3e6b36165fe0d'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `AvgPool3DGrad` ### Impact\nThe implementation of `tf.raw_ops.AvgPool3DGrad` is vulnerable to a heap buffer overflow:\n\n```python\nimport tensorflow as tf\n\norig_input_shape = tf.constant([10, 6, 3, 7, 7], shape=[5], dtype=tf.int32)\ngrad = tf.constant([0.01, 0, 0], shape=[3, 1, 1, 1, 1], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.AvgPool3DGrad(\n  orig_input_shape=orig_input_shape, grad=grad, ksize=ksize, strides=strides,\n  padding=padding)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/d80ffba9702dc19d1fac74fc4b766b3fa1ee976b\/tensorflow\/core\/kernels\/pooling_ops_3d.cc#L376-L450) assumes that the `orig_input_shape` and `grad` tensors have similar first and last dimensions but does not check that this assumption is validated.\n\n### Patches\nWe have patched the issue in GitHub commit [6fc9141f42f6a72180ecd24021c3e6b36165fe0d](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6fc9141f42f6a72180ecd24021c3e6b36165fe0d).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6fc9141f42f6a72180ecd24021c3e6b36165fe0d",
            "commit_sha":"6fc9141f42f6a72180ecd24021c3e6b36165fe0d",
            "patch":"SINGLE",
            "chain_ord":"['6fc9141f42f6a72180ecd24021c3e6b36165fe0d']",
            "before_first_fix_commit":"{'d80ffba9702dc19d1fac74fc4b766b3fa1ee976b'}",
            "last_fix_commit":"6fc9141f42f6a72180ecd24021c3e6b36165fe0d",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 16:51:26",
            "message":"Fix assertion failure in pooling_ops_3d\n\nPiperOrigin-RevId: 372364504\nChange-Id: Iecde4fe26b47a8fa935d6e2611b5585ed5777781",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
            "files":"{'tensorflow\/core\/kernels\/pooling_ops_3d.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6fc9141f42f6a72180ecd24021c3e6b36165fe0d\/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc', 'patch': '@@ -383,6 +383,19 @@ struct LaunchAvgPooling3dGradOp<CPUDevice, T> {\\n                      const std::array<int64, 3>& output_shape,\\n                      const std::array<int64, 3>& padding,\\n                      TensorFormat data_format, Tensor* output) {\\n+    OP_REQUIRES(\\n+        context, tensor_in_shape.dim_size(0) == out_backprop.dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Expected first dimension of tensor_in_shape and \"\\n+            \"out_backprop to match, got \",\\n+            tensor_in_shape.dim_size(0), \" and \", out_backprop.dim_size(0)));\\n+    OP_REQUIRES(\\n+        context, tensor_in_shape.dim_size(4) == out_backprop.dim_size(4),\\n+        errors::InvalidArgument(\\n+            \"Expected last dimension of tensor_in_shape and \"\\n+            \"out_backprop to match, got \",\\n+            tensor_in_shape.dim_size(4), \" and \", out_backprop.dim_size(4)));\\n+\\n     output->flat<T>().setZero();\\n     std::array<int64, 3> input_size = {{tensor_in_shape.dim_size(3),\\n                                         tensor_in_shape.dim_size(2),'}}",
            "message_norm":"fix assertion failure in pooling_ops_3d\n\npiperorigin-revid: 372364504\nchange-id: iecde4fe26b47a8fa935d6e2611b5585ed5777781",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('372364504', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/pooling_ops_3d.cc'])",
            "num_files":1.0
        },
        {
            "index":3172,
            "vuln_id":"GHSA-vvg4-vgrv-xfr7",
            "cwe_id":"{'CWE-665'}",
            "score":6.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4504a081af71514bb1828048363e6540f797005b', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/14607c0707040d775e06b6817325640cb4b5864c'}",
            "dataset":"osv",
            "summary":"Incomplete validation in `tf.raw_ops.CTCLoss` ### Impact \nIncomplete validation in `tf.raw_ops.CTCLoss` allows an attacker to trigger an OOB read from heap:\n\n```python\nimport tensorflow as tf\n\ninputs = tf.constant([], shape=[10, 16, 0], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[8, 0], dtype=tf.int64)\nlabels_values = tf.constant([-100] * 8, shape=[8], dtype=tf.int32)\nsequence_length = tf.constant([-100] * 16, shape=[16], dtype=tf.int32)\n  \ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=True, ctc_merge_repeated=False,\n                   ignore_longer_outputs_than_inputs=True)\n```   \n      \nAn attacker can also trigger a heap buffer overflow:\n\n```python\nimport tensorflow as tf\n\ninputs = tf.constant([], shape=[7, 2, 0], dtype=tf.float32)\nlabels_indices = tf.constant([-100, -100], shape=[2, 1], dtype=tf.int64)\nlabels_values = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ignore_longer_outputs_than_inputs=False)\n```\n\nFinally, an attacker can trigger a null pointer dereference:\n\n```python \nimport tensorflow as tf\n\ninputs = tf.constant([], shape=[0, 2, 11], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ignore_longer_outputs_than_inputs=False)\n```\n\n### Patches\nWe have patched the issue in GitHub commit[14607c0707040d775e06b6817325640cb4b5864c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/14607c0707040d775e06b6817325640cb4b5864c) followed by GitHub commit [4504a081af71514bb1828048363e6540f797005b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4504a081af71514bb1828048363e6540f797005b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/14607c0707040d775e06b6817325640cb4b5864c",
            "commit_sha":"14607c0707040d775e06b6817325640cb4b5864c",
            "patch":"MULTI",
            "chain_ord":"['4504a081af71514bb1828048363e6540f797005b', '14607c0707040d775e06b6817325640cb4b5864c']",
            "before_first_fix_commit":"{'8410ce671b48e96965a1e4a97017f8a5bbd03d3a'}",
            "last_fix_commit":"14607c0707040d775e06b6817325640cb4b5864c",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/06\/2021, 04:09:21",
            "message":"Fix nullptr deref in `tf.raw_ops.CTCLoss`.\n\nPiperOrigin-RevId: 372266334\nChange-Id: Ic52c3e9f13a38f54482d670907eda1688450862b",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/ctc_loss_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/14607c0707040d775e06b6817325640cb4b5864c\/tensorflow%2Fcore%2Fkernels%2Fctc_loss_op.cc', 'patch': '@@ -109,6 +109,9 @@ class CTCLossOp : public OpKernel {\\n \\n     const TensorShape& inputs_shape = inputs->shape();\\n     const int64 max_time = inputs_shape.dim_size(0);\\n+    OP_REQUIRES(ctx, max_time != 0,\\n+                errors::InvalidArgument(\\n+                    \"Max time or first dimension of input cannot be 0.\"));\\n     const int64 batch_size = inputs_shape.dim_size(1);\\n     const int64 num_classes_raw = inputs_shape.dim_size(2);\\n     OP_REQUIRES('}}",
            "message_norm":"fix nullptr deref in `tf.raw_ops.ctcloss`.\n\npiperorigin-revid: 372266334\nchange-id: ic52c3e9f13a38f54482d670907eda1688450862b",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('372266334', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ctc_loss_op.cc'])",
            "num_files":1.0
        },
        {
            "index":287,
            "vuln_id":"GHSA-3pcq-34w5-p4g2",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/nicolas-van\/modern-async\/commit\/0010d28de1b15d51db3976080e26357fa7144436'}",
            "dataset":"osv",
            "summary":"forEachSeries and forEachLimit do not limit the number of requests ### Impact\n\nThis is a bug affecting two of the functions in this library: forEachSeries and forEachLimit. They should limit the concurrency of some actions but, in practice, they don't. Any code calling these functions will be written thinking they would limit the concurrency but they won't. This could lead to potential security issues in other projects.\n\n### Patches\n\nThe problem has been patched in 1.0.4.\n\n### Workarounds\n\nThere is no workaround aside from upgrading to 1.0.4.",
            "published_date":"2021-10-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/nicolas-van\/modern-async",
            "commit_href":"https:\/\/github.com\/nicolas-van\/modern-async\/commit\/0010d28de1b15d51db3976080e26357fa7144436",
            "commit_sha":"0010d28de1b15d51db3976080e26357fa7144436",
            "patch":"SINGLE",
            "chain_ord":"['0010d28de1b15d51db3976080e26357fa7144436']",
            "before_first_fix_commit":"{'7aa934294e59bc7359651a852e73bd5785b9b99b'}",
            "last_fix_commit":"0010d28de1b15d51db3976080e26357fa7144436",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/19\/2021, 21:22:02",
            "message":"Fix #5",
            "author":"Nicolas Vanhoren",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/forEachLimit.mjs': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nicolas-van\/modern-async\/raw\/0010d28de1b15d51db3976080e26357fa7144436\/src%2FforEachLimit.mjs', 'patch': \"@@ -35,7 +35,7 @@ import mapLimit from '.\/mapLimit.mjs'\\n  *\/\\n async function forEachLimit (iterable, iteratee, concurrency) {\\n   await mapLimit(iterable, async (v, i, t) => {\\n-    iteratee(v, i, t)\\n+    await iteratee(v, i, t)\\n   }, concurrency)\\n }\"}}",
            "message_norm":"fix #5",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('#5', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/forEachLimit.mjs'])",
            "num_files":1.0
        },
        {
            "index":336,
            "vuln_id":"GHSA-428x-9xc2-m8mj",
            "cwe_id":"{'CWE-369'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e5b0eec199c2d03de54fd6a7fd9275692218e2bc'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite ### Impact \nAn attacker can craft a TFLite model that would trigger a division by zero in [the implementation of depthwise convolutions](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/lite\/kernels\/depthwise_conv.cc#L96).\n\nThe parameters of the convolution can be user controlled and are also used within a division operation to determine the size of the padding that needs to be added before applying the convolution. There is no check before this division that the divisor is stricly positive.\n\n### Patches              \nWe have patched the issue in GitHub commit [e5b0eec199c2d03de54fd6a7fd9275692218e2bc](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e5b0eec199c2d03de54fd6a7fd9275692218e2bc).\n  \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e5b0eec199c2d03de54fd6a7fd9275692218e2bc",
            "commit_sha":"e5b0eec199c2d03de54fd6a7fd9275692218e2bc",
            "patch":"SINGLE",
            "chain_ord":"['e5b0eec199c2d03de54fd6a7fd9275692218e2bc']",
            "before_first_fix_commit":"{'ece78f4001dd87f50daab1d1b43f70a51726b8fb'}",
            "last_fix_commit":"e5b0eec199c2d03de54fd6a7fd9275692218e2bc",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/15\/2021, 01:04:19",
            "message":"[lite] Add validation check for dilation height\/width to be positive integers.\n\nPiperOrigin-RevId: 416429178\nChange-Id: If7cdcddca54486434d9b2f06e7e2b401d7c3ee25",
            "author":"Karim Nosir",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/lite\/kernels\/depthwise_conv.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e5b0eec199c2d03de54fd6a7fd9275692218e2bc\/tensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc', 'patch': '@@ -115,6 +115,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n \\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\\n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\\n+  TF_LITE_ENSURE(context, params->dilation_height_factor > 0);\\n+  TF_LITE_ENSURE(context, params->dilation_width_factor > 0);\\n \\n   const TfLiteType data_type = input->type;'}}",
            "message_norm":"[lite] add validation check for dilation height\/width to be positive integers.\n\npiperorigin-revid: 416429178\nchange-id: if7cdcddca54486434d9b2f06e7e2b401d7c3ee25",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('416429178', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/depthwise_conv.cc'])",
            "num_files":1.0
        },
        {
            "index":2483,
            "vuln_id":"GHSA-mxh3-2699-98g9",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/b5a9ad65e5a4dde1916f02019f8686ad835681ce'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting pimcore pimcore version 10.3.0 and prior is vulnerable to cross-site scripting.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/b5a9ad65e5a4dde1916f02019f8686ad835681ce",
            "commit_sha":"b5a9ad65e5a4dde1916f02019f8686ad835681ce",
            "patch":"SINGLE",
            "chain_ord":"['b5a9ad65e5a4dde1916f02019f8686ad835681ce']",
            "before_first_fix_commit":"{'6ccb5c12fc1be065ebce9c89c4677ee939b88597'}",
            "last_fix_commit":"b5a9ad65e5a4dde1916f02019f8686ad835681ce",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/07\/2022, 14:23:39",
            "message":"[Admin] DataObject - Escape class definitions group properly",
            "author":"dpahuja",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassController.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/b5a9ad65e5a4dde1916f02019f8686ad835681ce\/bundles%2FAdminBundle%2FController%2FAdmin%2FDataObject%2FClassController.php', 'patch': \"@@ -861,7 +861,7 @@ public function fieldcollectionTreeAction(Request $request, EventDispatcherInter\\n                 if (!isset($groups[$item->getGroup()])) {\\n                     $groups[$item->getGroup()] = [\\n                         'id' => 'group_' . $item->getKey(),\\n-                        'text' => $item->getGroup(),\\n+                        'text' => htmlspecialchars($item->getGroup()),\\n                         'expandable' => true,\\n                         'leaf' => false,\\n                         'allowChildren' => true,\\n@@ -1266,7 +1266,7 @@ public function objectbrickTreeAction(Request $request, EventDispatcherInterface\\n                 if (!isset($groups[$item->getGroup()])) {\\n                     $groups[$item->getGroup()] = [\\n                         'id' => 'group_' . $item->getKey(),\\n-                        'text' => $item->getGroup(),\\n+                        'text' => htmlspecialchars($item->getGroup()),\\n                         'expandable' => true,\\n                         'leaf' => false,\\n                         'allowChildren' => true,\"}}",
            "message_norm":"[admin] dataobject - escape class definitions group properly",
            "language":"fr",
            "entities":"[('admin', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Controller\/Admin\/DataObject\/ClassController.php'])",
            "num_files":1.0
        },
        {
            "index":2487,
            "vuln_id":"GHSA-p23j-g745-8449",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/a4e56547fb8b7450656bfd26dfc52b8477c8ef27', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1307, CVE-2019-1308, CVE-2019-1366.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/a4e56547fb8b7450656bfd26dfc52b8477c8ef27",
            "commit_sha":"a4e56547fb8b7450656bfd26dfc52b8477c8ef27",
            "patch":"MULTI",
            "chain_ord":"['a4e56547fb8b7450656bfd26dfc52b8477c8ef27', 'cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d']",
            "before_first_fix_commit":"{'7e9a2ee60baa95ceb4f48f522f823c812ca90c80', '5989c6e038d80f92dcd8e10d725cdf45396201bb'}",
            "last_fix_commit":"cc871514deeaeaedb5b757c2ca8cd4ab9abccb5d",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/03\/2019, 21:52:17",
            "message":"CVE-2019-1335",
            "author":"Wyatt",
            "comments":null,
            "stats":"{'additions': 52, 'deletions': 13, 'total': 65}",
            "files":"{'lib\/Backend\/GlobOpt.cpp': {'additions': 52, 'deletions': 13, 'changes': 65, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/a4e56547fb8b7450656bfd26dfc52b8477c8ef27\/lib%2FBackend%2FGlobOpt.cpp', 'patch': '@@ -2161,27 +2161,46 @@ GlobOpt::CollectMemOpInfo(IR::Instr *instrBegin, IR::Instr *instr, Value *src1Va\\n             return false;\\n         }\\n         break;\\n-    case Js::OpCode::Decr_A:\\n-        isIncr = false;\\n-    case Js::OpCode::Incr_A:\\n-        isChangedByOne = true;\\n-        goto MemOpCheckInductionVariable;\\n     case Js::OpCode::Sub_I4:\\n-    case Js::OpCode::Sub_A:\\n         isIncr = false;\\n-    case Js::OpCode::Add_A:\\n     case Js::OpCode::Add_I4:\\n     {\\n-MemOpCheckInductionVariable:\\n-        StackSym *sym = instr->GetSrc1()->GetStackSym();\\n-        if (!sym)\\n+        \/\/ The only case in which these OpCodes can contribute to an inductionVariableChangeInfo\\n+        \/\/ is when the induction variable is being modified and overwritten aswell (ex: j = j + 1)\\n+        \/\/ and not when the induction variable is modified but not overwritten (ex: k = j + 1).\\n+        \/\/ This can either be detected in IR as\\n+        \/\/ s1     = Add_I4 s1     1  \/\/ Case #1, can be seen with \"j++\".\\n+        \/\/ or as\\n+        \/\/ s4(s2) = Add_I4 s3(s1) 1  \/\/ Case #2, can be see with \"j = j + 1\".\\n+        \/\/ s1     = Ld_A   s2\\n+        bool isInductionVar = false;\\n+        IR::Instr* nextInstr = instr->m_next;\\n+        if (\\n+            \/\/ Checks for Case #1 and Case #2\\n+            instr->GetDst()->GetStackSym() != nullptr &&\\n+            instr->GetDst()->IsRegOpnd() &&\\n+            (\\n+                \/\/ Checks for Case #1\\n+                (instr->GetDst()->GetStackSym() == instr->GetSrc1()->GetStackSym()) ||\\n+\\n+                \/\/ Checks for Case #2\\n+                (nextInstr&& nextInstr->m_opcode == Js::OpCode::Ld_A &&\\n+                 nextInstr->GetSrc1()->IsRegOpnd() &&\\n+                 nextInstr->GetDst()->IsRegOpnd() &&\\n+                 GetVarSymID(instr->GetDst()->GetStackSym()) == nextInstr->GetSrc1()->GetStackSym()->m_id &&\\n+                 GetVarSymID(instr->GetSrc1()->GetStackSym()) == nextInstr->GetDst()->GetStackSym()->m_id)\\n+            )\\n+        )\\n         {\\n-            sym = instr->GetSrc2()->GetStackSym();\\n+            isInductionVar = true;\\n         }\\n+        \\n+        \/\/ Even if dstIsInductionVar then dst == src1 so it\\'s safe to use src1 as the induction sym always.\\n+        StackSym* sym = instr->GetSrc1()->GetStackSym();\\n \\n         SymID inductionSymID = GetVarSymID(sym);\\n \\n-        if (IsSymIDInductionVariable(inductionSymID, this->currentBlock->loop))\\n+        if (isInductionVar && IsSymIDInductionVariable(inductionSymID, this->currentBlock->loop))\\n         {\\n             if (!isChangedByOne)\\n             {\\n@@ -2246,7 +2265,6 @@ GlobOpt::CollectMemOpInfo(IR::Instr *instrBegin, IR::Instr *instr, Value *src1Va\\n                     {\\n                         inductionVariableChangeInfo.unroll++;\\n                     }\\n-                    \\n                     inductionVariableChangeInfo.isIncremental = isIncr;\\n                     loop->memOpInfo->inductionVariableChangeInfoMap->Item(inductionSymID, inductionVariableChangeInfo);\\n                 }\\n@@ -2284,6 +2302,27 @@ GlobOpt::CollectMemOpInfo(IR::Instr *instrBegin, IR::Instr *instr, Value *src1Va\\n             }\\n         }\\n         NEXT_INSTR_IN_RANGE;\\n+        IR::Instr* prevInstr = instr->m_prev;\\n+\\n+        \/\/ If an instr where the dst is an induction variable (and thus is being written to) is not caught by a case in the above\\n+        \/\/ switch statement (which implies that this instr does not contributes to a inductionVariableChangeInfo) and in the default\\n+        \/\/ case does not set doMemOp to false (which implies that this instr does not invalidate this MemOp), then FailFast as we\\n+        \/\/ should not be performing a MemOp under these conditions. \\n+        AssertOrFailFast(!instr->GetDst() || instr->m_opcode == Js::OpCode::IncrLoopBodyCount || !loop->memOpInfo ||\\n+\\n+            \/\/ Refer to \"Case #2\" described above in this function. For the following IR:\\n+            \/\/ Line #1: s4(s2) = Add_I4 s3(s1) 1\\n+            \/\/ Line #2: s3(s1) = Ld_A   s4(s2)\\n+            \/\/ do not consider line #2 as a violating instr\\n+            (instr->m_opcode == Js::OpCode::Ld_I4 &&\\n+                prevInstr && (prevInstr->m_opcode == Js::OpCode::Add_I4 || prevInstr->m_opcode == Js::OpCode::Sub_I4) &&\\n+                instr->GetSrc1()->IsRegOpnd() &&\\n+                instr->GetDst()->IsRegOpnd() &&\\n+                prevInstr->GetDst()->IsRegOpnd() &&\\n+                instr->GetDst()->GetStackSym() == prevInstr->GetSrc1()->GetStackSym() &&\\n+                instr->GetSrc1()->GetStackSym() == prevInstr->GetDst()->GetStackSym()) ||\\n+\\n+            !loop->memOpInfo->inductionVariableChangeInfoMap->ContainsKey(GetVarSymID(instr->GetDst()->GetStackSym())));\\n     }\\n \\n     return true;'}}",
            "message_norm":"cve-2019-1335",
            "language":"ro",
            "entities":"[('cve-2019-1335', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Backend\/GlobOpt.cpp'])",
            "num_files":1.0
        },
        {
            "index":1719,
            "vuln_id":"GHSA-fcxw-hhxq-48wx",
            "cwe_id":"{'CWE-200'}",
            "score":3.3,
            "chain":"{'https:\/\/github.com\/jenkinsci\/git-client-plugin\/commit\/75ea3fe05650fc6ca09046a72493e2b3f066fb98'}",
            "dataset":"osv",
            "summary":"Insecure temporary file usage in Jenkins Git Client Plugin Jenkins Git Client Plugin 2.4.2 and earlier creates temporary file with insecure permissions resulting in information disclosure",
            "published_date":"2022-05-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/git-client-plugin",
            "commit_href":"https:\/\/github.com\/jenkinsci\/git-client-plugin\/commit\/75ea3fe05650fc6ca09046a72493e2b3f066fb98",
            "commit_sha":"75ea3fe05650fc6ca09046a72493e2b3f066fb98",
            "patch":"SINGLE",
            "chain_ord":"['75ea3fe05650fc6ca09046a72493e2b3f066fb98']",
            "before_first_fix_commit":"{'716e3ff56074c018c76cb35826269b976540e7e7'}",
            "last_fix_commit":"75ea3fe05650fc6ca09046a72493e2b3f066fb98",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2017, 04:38:54",
            "message":"[Fix SECURITY-445] better protect temporary files\n\nTemporary files were previously written to the system temporary directory\nwith default permissions.  A malicious actor could have captured sensitive\ninformation by reading files from the temporary directory.  The temporary\nfiles typically are only on the file system for the duration of a single\ncommand line git invocation, but cloning a large git repo could require\nan extended time with those sensitive files in the temporary directory.\n\nThis change sets permissions on the temporary files to be readable only by\nthe file owner. If a workspace is available, a temporary directory adjacent\nto the workspace is used instead of the system temporary directory.",
            "author":"Mark Waite",
            "comments":null,
            "stats":"{'additions': 42, 'deletions': 9, 'total': 51}",
            "files":"{'src\/main\/java\/org\/jenkinsci\/plugins\/gitclient\/CliGitAPIImpl.java': {'additions': 42, 'deletions': 9, 'changes': 51, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/git-client-plugin\/raw\/75ea3fe05650fc6ca09046a72493e2b3f066fb98\/src%2Fmain%2Fjava%2Forg%2Fjenkinsci%2Fplugins%2Fgitclient%2FCliGitAPIImpl.java', 'patch': '@@ -42,6 +42,11 @@\\n import java.net.URISyntaxException;\\n import java.nio.charset.Charset;\\n import java.nio.file.Files;\\n+import java.nio.file.Path;\\n+import java.nio.file.Paths;\\n+import java.nio.file.attribute.FileAttribute;\\n+import java.nio.file.attribute.PosixFilePermission;\\n+import java.nio.file.attribute.PosixFilePermissions;\\n import java.text.MessageFormat;\\n import java.util.ArrayList;\\n import java.util.Arrays;\\n@@ -1411,6 +1416,34 @@ public void addNote(String note, String namespace ) throws GitException, Interru\\n         createNote(note,namespace,\"add\");\\n     }\\n \\n+    private File createTempFileInSystemDir(String prefix, String suffix) throws IOException {\\n+        if (isWindows()) {\\n+            return Files.createTempFile(prefix, suffix).toFile();\\n+        }\\n+        Set<PosixFilePermission> ownerOnly = PosixFilePermissions.fromString(\"rw-------\");\\n+        FileAttribute fileAttribute = PosixFilePermissions.asFileAttribute(ownerOnly);\\n+        return Files.createTempFile(prefix, suffix, fileAttribute).toFile();\\n+    }\\n+\\n+    private File createTempFile(String prefix, String suffix) throws IOException {\\n+        if (workspace == null) {\\n+            return createTempFileInSystemDir(prefix, suffix);\\n+        }\\n+        File workspaceTmp = new File(workspace.getAbsolutePath() + \"@tmp\");\\n+        if (!workspaceTmp.isDirectory() && !workspaceTmp.mkdirs()) {\\n+            if (!workspaceTmp.isDirectory()) {\\n+                return createTempFileInSystemDir(prefix, suffix);\\n+            }\\n+        }\\n+        Path tmpPath = Paths.get(workspaceTmp.getAbsolutePath());\\n+        if (isWindows()) {\\n+            return Files.createTempFile(tmpPath, prefix, suffix).toFile();\\n+        }\\n+        Set<PosixFilePermission> ownerOnly = PosixFilePermissions.fromString(\"rw-------\");\\n+        FileAttribute fileAttribute = PosixFilePermissions.asFileAttribute(ownerOnly);\\n+        return Files.createTempFile(tmpPath, prefix, suffix, fileAttribute).toFile();\\n+    }\\n+\\n     private void deleteTempFile(File tempFile) {\\n         if (tempFile != null && !tempFile.delete() && tempFile.exists()) {\\n             listener.getLogger().println(\"[WARNING] temp file \" + tempFile + \" not deleted\");\\n@@ -1420,7 +1453,7 @@ private void deleteTempFile(File tempFile) {\\n     private void createNote(String note, String namespace, String command ) throws GitException, InterruptedException {\\n         File msg = null;\\n         try {\\n-            msg = File.createTempFile(\"git-note\", \"txt\", workspace);\\n+            msg = createTempFile(\"git-note\", \".txt\");\\n             FileUtils.writeStringToFile(msg,note);\\n             launchCommand(\"notes\", \"--ref=\" + namespace, command, \"-F\", msg.getAbsolutePath());\\n         } catch (IOException | GitException e) {\\n@@ -1561,7 +1594,7 @@ private String launchCommandWithCredentials(ArgumentListBuilder args, File workD\\n     }\\n \\n     private File createSshKeyFile(SSHUserPrivateKey sshUser) throws IOException, InterruptedException {\\n-        File key = File.createTempFile(\"ssh\", \"key\");\\n+        File key = createTempFile(\"ssh\", \".key\");\\n         try (PrintWriter w = new PrintWriter(key, Charset.defaultCharset().toString())) {\\n             List<String> privateKeys = sshUser.getPrivateKeys();\\n             for (String s : privateKeys) {\\n@@ -1597,7 +1630,7 @@ private String quoteUnixCredentials(String str) {\\n     }\\n \\n     private File createWindowsSshAskpass(SSHUserPrivateKey sshUser) throws IOException {\\n-        File ssh = File.createTempFile(\"pass\", \".bat\");\\n+        File ssh = createTempFile(\"pass\", \".bat\");\\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\\n             \/\/ avoid echoing command as part of the password\\n             w.println(\"@echo off\");\\n@@ -1610,7 +1643,7 @@ private File createWindowsSshAskpass(SSHUserPrivateKey sshUser) throws IOExcepti\\n     }\\n \\n     private File createUnixSshAskpass(SSHUserPrivateKey sshUser) throws IOException {\\n-        File ssh = File.createTempFile(\"pass\", \".sh\");\\n+        File ssh = createTempFile(\"pass\", \".sh\");\\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\\n             w.println(\"#!\/bin\/sh\");\\n             w.println(\"echo \\'\" + quoteUnixCredentials(Secret.toString(sshUser.getPassphrase())) + \"\\'\");\\n@@ -1621,7 +1654,7 @@ private File createUnixSshAskpass(SSHUserPrivateKey sshUser) throws IOException\\n \\n     \/* Package protected for testability *\/\\n     File createWindowsBatFile(String userName, String password) throws IOException {\\n-        File askpass = File.createTempFile(\"pass\", \".bat\");\\n+        File askpass = createTempFile(\"pass\", \".bat\");\\n         try (PrintWriter w = new PrintWriter(askpass, Charset.defaultCharset().toString())) {\\n             w.println(\"@set arg=%~1\");\\n             w.println(\"@if (%arg:~0,8%)==(Username) echo \" + escapeWindowsCharsForUnquotedString(userName));\\n@@ -1636,7 +1669,7 @@ private File createWindowsStandardAskpass(StandardUsernamePasswordCredentials cr\\n     }\\n \\n     private File createUnixStandardAskpass(StandardUsernamePasswordCredentials creds) throws IOException {\\n-        File askpass = File.createTempFile(\"pass\", \".sh\");\\n+        File askpass = createTempFile(\"pass\", \".sh\");\\n         try (PrintWriter w = new PrintWriter(askpass, Charset.defaultCharset().toString())) {\\n             w.println(\"#!\/bin\/sh\");\\n             w.println(\"case \\\\\"$1\\\\\" in\");\\n@@ -1766,7 +1799,7 @@ private File getSSHExeFromGitExeParentDir(String userGitExe) {\\n     }\\n \\n     private File createWindowsGitSSH(File key, String user) throws IOException {\\n-        File ssh = File.createTempFile(\"ssh\", \".bat\");\\n+        File ssh = createTempFile(\"ssh\", \".bat\");\\n \\n         File sshexe = getSSHExecutable();\\n \\n@@ -1779,7 +1812,7 @@ private File createWindowsGitSSH(File key, String user) throws IOException {\\n     }\\n \\n     private File createUnixGitSSH(File key, String user) throws IOException {\\n-        File ssh = File.createTempFile(\"ssh\", \".sh\");\\n+        File ssh = createTempFile(\"ssh\", \".sh\");\\n         try (PrintWriter w = new PrintWriter(ssh, Charset.defaultCharset().toString())) {\\n             w.println(\"#!\/bin\/sh\");\\n             \/\/ ${SSH_ASKPASS} might be ignored if ${DISPLAY} is not set\\n@@ -2383,7 +2416,7 @@ public void branch(String name) throws GitException, InterruptedException {\\n     public void commit(String message) throws GitException, InterruptedException {\\n         File f = null;\\n         try {\\n-            f = File.createTempFile(\"gitcommit\", \".txt\");\\n+            f = createTempFile(\"gitcommit\", \".txt\");\\n             try (OutputStream out = Files.newOutputStream(f.toPath())) {\\n                 out.write(message.getBytes(Charset.defaultCharset().toString()));\\n             }'}}",
            "message_norm":"[fix security-445] better protect temporary files\n\ntemporary files were previously written to the system temporary directory\nwith default permissions.  a malicious actor could have captured sensitive\ninformation by reading files from the temporary directory.  the temporary\nfiles typically are only on the file system for the duration of a single\ncommand line git invocation, but cloning a large git repo could require\nan extended time with those sensitive files in the temporary directory.\n\nthis change sets permissions on the temporary files to be readable only by\nthe file owner. if a workspace is available, a temporary directory adjacent\nto the workspace is used instead of the system temporary directory.",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('security-445', 'SECWORD', ''), ('protect', 'SECWORD', ''), ('permissions', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('sensitive', 'SECWORD', ''), ('sensitive', 'SECWORD', ''), ('permissions', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/org\/jenkinsci\/plugins\/gitclient\/CliGitAPIImpl.java'])",
            "num_files":1.0
        },
        {
            "index":2492,
            "vuln_id":"GHSA-p2vw-f87c-q597",
            "cwe_id":"{'CWE-863'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c'}",
            "dataset":"osv",
            "summary":"Improper Access Control in snipe\/snipe-it Improper Access Control in GitHub repository snipe\/snipe-it prior to 5.4.4.",
            "published_date":"2022-04-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c",
            "commit_sha":"2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c",
            "patch":"SINGLE",
            "chain_ord":"['2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c']",
            "before_first_fix_commit":"{'126bb486b5146975f562d51b8f75dd2e30bee74d'}",
            "last_fix_commit":"2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 14:45:37",
            "message":"Added access gate to the requested assets index\n\nSigned-off-by: snipe <snipe@snipe.net>",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'app\/Http\/Controllers\/Assets\/AssetsController.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c\/app%2FHttp%2FControllers%2FAssets%2FAssetsController.php', 'patch': \"@@ -861,6 +861,7 @@ public function auditStore(Request $request, $id)\\n \\n     public function getRequestedIndex($user_id = null)\\n     {\\n+        $this->authorize('index', Asset::class);\\n         $requestedItems = CheckoutRequest::with('user', 'requestedItem')->whereNull('canceled_at')->with('user', 'requestedItem');\\n \\n         if ($user_id) {\"}}",
            "message_norm":"added access gate to the requested assets index\n\nsigned-off-by: snipe <snipe@snipe.net>",
            "language":"en",
            "entities":"[('added', 'ACTION', ''), ('snipe@snipe.net', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/Assets\/AssetsController.php'])",
            "num_files":1.0
        },
        {
            "index":3269,
            "vuln_id":"GHSA-wf5x-cr3r-xr77",
            "cwe_id":"{'CWE-674'}",
            "score":8.3,
            "chain":"{'https:\/\/github.com\/patriksimek\/vm2\/commit\/4b22d704e4794af63a5a2d633385fd20948f6f90'}",
            "dataset":"osv",
            "summary":"vm2 before 3.6.11 vulnerable to sandbox escape This affects the package vm2 before 3.6.11. It is possible to trigger a RangeError exception from the host rather than the \"sandboxed\" context by reaching the stack call limit with an infinite recursion. The returned object is then used to reference the mainModule property of the host code running the script allowing it to spawn a child_process and execute arbitrary code.",
            "published_date":"2022-07-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/patriksimek\/vm2",
            "commit_href":"https:\/\/github.com\/patriksimek\/vm2\/commit\/4b22d704e4794af63a5a2d633385fd20948f6f90",
            "commit_sha":"4b22d704e4794af63a5a2d633385fd20948f6f90",
            "patch":"SINGLE",
            "chain_ord":"['4b22d704e4794af63a5a2d633385fd20948f6f90']",
            "before_first_fix_commit":"{'2ac8ff254a71e516e83f6496635fa61420447fa9'}",
            "last_fix_commit":"4b22d704e4794af63a5a2d633385fd20948f6f90",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/07\/2019, 23:46:03",
            "message":"Fixes sandbox escape (#197)",
            "author":"Patrik Simek",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 16, 'total': 32}",
            "files":"{'lib\/contextify.js': {'additions': 16, 'deletions': 16, 'changes': 32, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/patriksimek\/vm2\/raw\/4b22d704e4794af63a5a2d633385fd20948f6f90\/lib%2Fcontextify.js', 'patch': \"@@ -327,15 +327,15 @@ Decontextify.object = (object, traps, deepTraps, flags, mock) => {\\n \\treturn proxy;\\n };\\n Decontextify.value = (value, traps, deepTraps, flags, mock) => {\\n-\\tif (Contextified.has(value)) {\\n-\\t\\t\/\/ Contextified object has returned back from vm\\n-\\t\\treturn Contextified.get(value);\\n-\\t} else if (Decontextify.proxies.has(value)) {\\n-\\t\\t\/\/ Decontextified proxy already exists, reuse\\n-\\t\\treturn Decontextify.proxies.get(value);\\n-\\t}\\n-\\n \\ttry {\\n+\\t\\tif (Contextified.has(value)) {\\n+\\t\\t\\t\/\/ Contextified object has returned back from vm\\n+\\t\\t\\treturn Contextified.get(value);\\n+\\t\\t} else if (Decontextify.proxies.has(value)) {\\n+\\t\\t\\t\/\/ Decontextified proxy already exists, reuse\\n+\\t\\t\\treturn Decontextify.proxies.get(value);\\n+\\t\\t}\\n+\\n \\t\\tswitch (typeof value) {\\n \\t\\t\\tcase 'object':\\n \\t\\t\\t\\tif (value === null) {\\n@@ -621,15 +621,15 @@ Contextify.object = (object, traps, deepTraps, flags, mock) => {\\n \\treturn proxy;\\n };\\n Contextify.value = (value, traps, deepTraps, flags, mock) => {\\n-\\tif (Decontextified.has(value)) {\\n-\\t\\t\/\/ Decontextified object has returned back to vm\\n-\\t\\treturn Decontextified.get(value);\\n-\\t} else if (Contextify.proxies.has(value)) {\\n-\\t\\t\/\/ Contextified proxy already exists, reuse\\n-\\t\\treturn Contextify.proxies.get(value);\\n-\\t}\\n-\\n \\ttry {\\n+\\t\\tif (Decontextified.has(value)) {\\n+\\t\\t\\t\/\/ Decontextified object has returned back to vm\\n+\\t\\t\\treturn Decontextified.get(value);\\n+\\t\\t} else if (Contextify.proxies.has(value)) {\\n+\\t\\t\\t\/\/ Contextified proxy already exists, reuse\\n+\\t\\t\\treturn Contextify.proxies.get(value);\\n+\\t\\t}\\n+\\n \\t\\tswitch (typeof value) {\\n \\t\\t\\tcase 'object':\\n \\t\\t\\t\\tif (value === null) {\"}}",
            "message_norm":"fixes sandbox escape (#197)",
            "language":"ca",
            "entities":"[('fixes', 'ACTION', ''), ('sandbox', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('#197', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/contextify.js'])",
            "num_files":1.0
        },
        {
            "index":1950,
            "vuln_id":"GHSA-gx6h-936c-vrrr",
            "cwe_id":"{'CWE-79'}",
            "score":7.4,
            "chain":"{'https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/053d957d53f2a543d158f3ab651e390d2728e0b9'}",
            "dataset":"osv",
            "summary":"Cross site scripting in registration template in xwiki-platform ### Impact\n\nWe found a possible XSS vector in the `registerinline.vm` template related to the `xredirect` hidden field. \nThis template is only used in the following conditions:\n  - the wiki must be open to registration for anyone\n  - the wiki must be closed to view for Guest users (more specifically the XWiki.Registration page must be forbidden in View for guest user)\n\nA way to obtain the second condition is when administrators checked the \"Prevent unregistered users from viewing pages, regardless of the page rights\" box in the administration rights.\n\n### Patches\n\nThe issue is patched in versions 12.10.11, 14.0-rc-1, 13.4.7, 13.10.3.\n\n### Workarounds\n\nThere are two main ways for protecting against this vulnerability, the easiest and the best one is by applying a patch in the `registerinline.vm` template, the patch consists in checking the value of the xredirect field to ensure it matches the following:\n```\n<input type=\"hidden\" name=\"xredirect\" value=\"$escapetool.xml($!request.xredirect)\" \/>\n```\n\nIf for some reason it's not possible to patch this file, another workaround is to ensure \"Prevent unregistered users from viewing pages, regardless of the page rights\" is not checked in the rights and apply a better right scheme using groups and rights on spaces. \n\n### References\n\nhttps:\/\/jira.xwiki.org\/browse\/XWIKI-19291\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Jira XWiki](https:\/\/jira.xwiki.org)\n* Email us at [security mailing list](mailto:security@xwiki.org)",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/xwiki\/xwiki-platform",
            "commit_href":"https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/053d957d53f2a543d158f3ab651e390d2728e0b9",
            "commit_sha":"053d957d53f2a543d158f3ab651e390d2728e0b9",
            "patch":"SINGLE",
            "chain_ord":"['053d957d53f2a543d158f3ab651e390d2728e0b9']",
            "before_first_fix_commit":"{'9ae3703c535e34d328fd60758f85a8ee358224ca'}",
            "last_fix_commit":"053d957d53f2a543d158f3ab651e390d2728e0b9",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/04\/2022, 10:09:57",
            "message":"XWIKI-19291: redirect parameter is badly handled in register page\n\n  * Fix the typo",
            "author":"Simon Urli",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'xwiki-platform-core\/xwiki-platform-web\/xwiki-platform-web-templates\/src\/main\/resources\/templates\/registerinline.vm': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/xwiki\/xwiki-platform\/raw\/053d957d53f2a543d158f3ab651e390d2728e0b9\/xwiki-platform-core%2Fxwiki-platform-web%2Fxwiki-platform-web-templates%2Fsrc%2Fmain%2Fresources%2Ftemplates%2Fregisterinline.vm', 'patch': '@@ -45,7 +45,7 @@\\n       <div>\\n         <input type=\"hidden\" name=\"form_token\" value=\"$!services.csrf.token\" \/>\\n         <input type=\"hidden\" name=\"register\" value=\"1\" \/>\\n-        <input type=\"hidden\" name=\"xredirect\" value=\"$!request.xredirect\" \/>\\n+        <input type=\"hidden\" name=\"xredirect\" value=\"$escapetool.xml($!request.xredirect)\" \/>\\n         #set ($class = $xwiki.getClass(\\'XWiki.XWikiUsers\\'))\\n         #set ($obj = $class.newObject())\\n         #set ($serverobj = $class.newObject())'}}",
            "message_norm":"xwiki-19291: redirect parameter is badly handled in register page\n\n  * fix the typo",
            "language":"en",
            "entities":"[('fix', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['xwiki-platform-core\/xwiki-platform-web\/xwiki-platform-web-templates\/src\/main\/resources\/templates\/registerinline.vm'])",
            "num_files":1.0
        },
        {
            "index":2823,
            "vuln_id":"GHSA-qw5h-7f53-xrp6",
            "cwe_id":"{'CWE-674'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e07e1c3d26492c06f078c7e5bf2d138043e199c1'}",
            "dataset":"osv",
            "summary":"Stack overflow in `ParseAttrValue` with nested tensors ### Impact\nThe implementation of [`ParseAttrValue`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/c22d88d6ff33031aa113e48aa3fc9aa74ed79595\/tensorflow\/core\/framework\/attr_value_util.cc#L397-L453) can be tricked into stack overflow due to recursion by giving in a specially crafted input.\n\n### Patches\nWe have patched the issue in GitHub commit [e07e1c3d26492c06f078c7e5bf2d138043e199c1](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e07e1c3d26492c06f078c7e5bf2d138043e199c1).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e07e1c3d26492c06f078c7e5bf2d138043e199c1",
            "commit_sha":"e07e1c3d26492c06f078c7e5bf2d138043e199c1",
            "patch":"SINGLE",
            "chain_ord":"['e07e1c3d26492c06f078c7e5bf2d138043e199c1']",
            "before_first_fix_commit":"{'c22d88d6ff33031aa113e48aa3fc9aa74ed79595'}",
            "last_fix_commit":"e07e1c3d26492c06f078c7e5bf2d138043e199c1",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2021, 17:33:00",
            "message":"Prevent memory overflow in ParseAttrValue from nested tensors.\n\nPiperOrigin-RevId: 370108442\nChange-Id: I84d64a5e8895a6aeffbf4749841b4c54d51b5889",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 57, 'deletions': 1, 'total': 58}",
            "files":"{'tensorflow\/core\/framework\/attr_value_util.cc': {'additions': 57, 'deletions': 1, 'changes': 58, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e07e1c3d26492c06f078c7e5bf2d138043e199c1\/tensorflow%2Fcore%2Fframework%2Fattr_value_util.cc', 'patch': '@@ -38,6 +38,9 @@ namespace {\\n \/\/ Do not construct large tensors to compute their hash or compare for equality.\\n constexpr int kMaxAttrValueTensorByteSize = 32 * 1024 * 1024;  \/\/ 32mb\\n \\n+\/\/ Limit nesting of tensors to 100 deep to prevent memory overflow.\\n+constexpr int kMaxTensorNestDepth = 100;\\n+\\n \/\/ Return the size of the tensor represented by this TensorProto. If shape is\\n \/\/ not fully defined return -1.\\n int64 TensorByteSize(const TensorProto& t) {\\n@@ -224,6 +227,54 @@ string SummarizeFunc(const NameAttrList& func) {\\n   return strings::StrCat(func.name(), \"[\", absl::StrJoin(entries, \", \"), \"]\");\\n }\\n \\n+bool ParseAttrValueHelper_TensorNestsUnderLimit(int limit, string to_parse) {\\n+  int nests = 0;\\n+  int maxed_out = to_parse.length();\\n+  int open_curly = to_parse.find(\\'{\\');\\n+  int open_bracket = to_parse.find(\\'<\\');\\n+  int close_curly = to_parse.find(\\'}\\');\\n+  int close_bracket = to_parse.find(\\'>\\');\\n+  if (open_curly == -1) {\\n+    open_curly = maxed_out;\\n+  }\\n+  if (open_bracket == -1) {\\n+    open_bracket = maxed_out;\\n+  }\\n+  int min = std::min(open_curly, open_bracket);\\n+  do {\\n+    if (open_curly == maxed_out && open_bracket == maxed_out) {\\n+      return true;\\n+    }\\n+    if (min == open_curly) {\\n+      nests += 1;\\n+      open_curly = to_parse.find(\\'{\\', open_curly + 1);\\n+      if (open_curly == -1) {\\n+        open_curly = maxed_out;\\n+      }\\n+    } else if (min == open_bracket) {\\n+      nests += 1;\\n+      open_bracket = to_parse.find(\\'<\\', open_bracket + 1);\\n+      if (open_bracket == -1) {\\n+        open_bracket = maxed_out;\\n+      }\\n+    } else if (min == close_curly) {\\n+      nests -= 1;\\n+      close_curly = to_parse.find(\\'}\\', close_curly + 1);\\n+      if (close_curly == -1) {\\n+        close_curly = maxed_out;\\n+      }\\n+    } else if (min == close_bracket) {\\n+      nests -= 1;\\n+      close_bracket = to_parse.find(\\'>\\', close_bracket + 1);\\n+      if (close_bracket == -1) {\\n+        close_bracket = maxed_out;\\n+      }\\n+    }\\n+    min = std::min({open_curly, open_bracket, close_curly, close_bracket});\\n+  } while (nests < 100);\\n+  return false;\\n+}\\n+\\n }  \/\/ namespace\\n \\n string SummarizeAttrValue(const AttrValue& attr_value) {\\n@@ -448,7 +499,12 @@ bool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\\n   } else {\\n     to_parse = strings::StrCat(field_name, \": \", text);\\n   }\\n-\\n+  if (field_name == \"tensor\") {\\n+    if (!ParseAttrValueHelper_TensorNestsUnderLimit(kMaxTensorNestDepth,\\n+                                                    to_parse)) {\\n+      return false;\\n+    }\\n+  }\\n   return ProtoParseFromString(to_parse, out);\\n }'}}",
            "message_norm":"prevent memory overflow in parseattrvalue from nested tensors.\n\npiperorigin-revid: 370108442\nchange-id: i84d64a5e8895a6aeffbf4749841b4c54d51b5889",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('370108442', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/attr_value_util.cc'])",
            "num_files":1.0
        },
        {
            "index":2148,
            "vuln_id":"GHSA-hwj9-h5mp-3pm3",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734', 'https:\/\/github.com\/postcss\/postcss\/commit\/b6f3e4d5a8d7504d553267f80384373af3a3dec5', 'https:\/\/github.com\/postcss\/postcss\/commit\/8682b1e4e328432ba692bed52326e84439cec9e4'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in postcss The npm package `postcss` from 7.0.0 and before versions 7.0.36 and 8.2.10 is vulnerable to Regular Expression Denial of Service (ReDoS) during source map parsing.",
            "published_date":"2021-05-10",
            "chain_len":3,
            "project":"https:\/\/github.com\/postcss\/postcss",
            "commit_href":"https:\/\/github.com\/postcss\/postcss\/commit\/8682b1e4e328432ba692bed52326e84439cec9e4",
            "commit_sha":"8682b1e4e328432ba692bed52326e84439cec9e4",
            "patch":"MULTI",
            "chain_ord":"['8682b1e4e328432ba692bed52326e84439cec9e4', 'b6f3e4d5a8d7504d553267f80384373af3a3dec5', '54cbf3c4847eb0fb1501b9d2337465439e849734']",
            "before_first_fix_commit":"{'12832f3d203474bd273bd06bd3b2407567bfe09e'}",
            "last_fix_commit":"54cbf3c4847eb0fb1501b9d2337465439e849734",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/08\/2021, 06:57:25",
            "message":"Fix unsafe regexp",
            "author":"Andrey Sitnik",
            "comments":"{'com_1': {'author': 'aw3218', 'datetime': '04\/19\/2021, 18:32:44', 'body': 'Any chance of getting this change into a 7.0.36 version?'}, 'com_2': {'author': 'ai', 'datetime': '04\/19\/2021, 18:35:03', 'body': '7.x support is over on Jan 1, 2020.\\r\\n\\r\\nThe issue is not so critical (it affects only online tools like CodePen). It is better to use this reason to update to PostCSS 8.'}, 'com_3': {'author': 'aw3218', 'datetime': '04\/19\/2021, 18:43:33', 'body': \"Angular 11 is calling cssnano@4.1.10 which calls version 7.0.35. Updating to cssnano@5.0.1 won't compile angular 11.\\r\\n\\r\\n`-- @angular-devkit\/build-angular@0.1102.7\\r\\n  +-- css-loader@5.0.1\\r\\n  | `-- postcss@8.2.10\\r\\n  +-- **cssnano@4.1.10**\\r\\n  | +-- cssnano-preset-default@4.0.8\\r\\n  | | +-- css-declaration-sorter@4.0.1\\r\\n  | | | `-**- postcss@7.0.35**\"}, 'com_4': {'author': 'ai', 'datetime': '04\/19\/2021, 18:44:29', 'body': 'Ask Angular 11 to update cssnano.'}, 'com_5': {'author': 'GeorgiosP', 'datetime': '04\/21\/2021, 15:59:36', 'body': 'Would this effect any project using editors like [monaco-editor](https:\/\/github.com\/microsoft\/monaco-editor\/blob\/92d6800a00070f876faad9ee7997e9efea7c5e4b\/package-lock.json#L2825) which has postcss or other browser based code editors with a dependency on V7 of postcss \ud83d\udcad'}, 'com_6': {'author': 'ai', 'datetime': '04\/21\/2021, 16:10:07', 'body': '@GeorgiosP it affects only use cases when:\\r\\n\\r\\n1. User send you CSS\\r\\n2. You compile this CSS on your servers\\r\\n\\r\\nIn this case, the user can generate special CSS which will take seconds or minutes to compile. An attacker can use it to DoS your servers.\\r\\n\\r\\nIf you can\u2019t update PostCSS, you can add timeout for CSS processing.'}, 'com_7': {'author': 'GeorgiosP', 'datetime': '04\/21\/2021, 16:16:41', 'body': '@ai thanks for the additional context \ud83d\ude4f\ud83c\udffc'}, 'com_8': {'author': 'Sesughter01', 'datetime': '05\/17\/2021, 08:22:18', 'body': 'how do I upgrade from 8.1.14 to the patched 8.2.10 in my laravel project?'}, 'com_9': {'author': 'Kmap-Holdings', 'datetime': '05\/17\/2021, 11:18:13', 'body': 'Eagerly waiting for this answer'}, 'com_10': {'author': 'ai', 'datetime': '05\/17\/2021, 11:30:43', 'body': '@Sesughter01 `yarn upgrade` or `npm update` should update your nested dependencies. But it is better to ask in Laravel community.'}, 'com_11': {'author': 'josephzidell', 'datetime': '05\/21\/2021, 14:00:06', 'body': \"@ai We run a DevSecOps pipeline (gov't work), and these vulns are causing full blockages. Not every plugin is compatible with v8 at the moment. Seems like it's taking the community some time to make the jump. Would you consider cutting a 7.x release for this?\"}, 'com_12': {'author': 'ai', 'datetime': '05\/21\/2021, 14:11:11', 'body': '@josephzidell this vulnerability affects only runner (`postcss-loader`, `postcss-cli`, `gulp-postcss`) and only on web compilers accepting user-generated CSS (like CodePen).\\r\\n\\r\\nPostCSS in plugin dependencies doesn\u2019t affect by this vulnerability.\\r\\n\\r\\nPostCSS 7 support ended in January 2021.\\r\\n\\r\\nIf you want extended support, you can pay for PostCSS commercial support.'}, 'com_13': {'author': 'josaphatmayuba', 'datetime': '01\/13\/2022, 06:07:16', 'body': 'I have\\r\\n\\r\\n> npm update\\r\\n\\r\\n![image](https:\/\/user-images.githubusercontent.com\/97654468\/149274944-50df9859-8e4d-4d20-8532-e43bdfd949da.png)'}, 'com_14': {'author': 'hakkisabah', 'datetime': '01\/15\/2022, 08:45:37', 'body': \"> I have\\r\\n> \\r\\n> > npm update\\r\\n> \\r\\n> ![image](https:\/\/user-images.githubusercontent.com\/97654468\/149274944-50df9859-8e4d-4d20-8532-e43bdfd949da.png)\\r\\n\\r\\nI don't understand, i have same issue and even more...\\r\\n![Screenshot (11)](https:\/\/user-images.githubusercontent.com\/10910670\/149615701-8738f08d-e779-4fa6-9587-94c524e1d140.png)\"}}",
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/previous-map.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/postcss\/postcss\/raw\/8682b1e4e328432ba692bed52326e84439cec9e4\/lib%2Fprevious-map.js', 'patch': '@@ -54,7 +54,7 @@ class PreviousMap {\\n   }\\n \\n   loadAnnotation(css) {\\n-    let annotations = css.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=.*\\\\s*\\\\*\\\\\/\/gm)\\n+    let annotations = css.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=.*\\\\*\\\\\/\/gm)\\n \\n     if (annotations && annotations.length > 0) {\\n       \/\/ Locate the last sourceMappingURL to avoid picking up'}}",
            "message_norm":"fix unsafe regexp",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('unsafe', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/previous-map.js'])",
            "num_files":1.0
        },
        {
            "index":2168,
            "vuln_id":"GHSA-hxp5-8pgq-mgv9",
            "cwe_id":"{'CWE-295'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/apache\/calcite\/commit\/43eeafcbac29d02c72bd520c003cdfc571de2d15'}",
            "dataset":"osv",
            "summary":"Missing Authentication for Critical Function in Apache Calcite \"HttpUtils#getURLConnection method disables explicitly hostname verification for HTTPS connections making clients vulnerable to man-in-the-middle attacks. Calcite uses this method internally to connect with Druid and Splunk so information leakage may happen when using the respective Calcite adapters. The method itself is in a utility class so people may use it to create vulnerable HTTPS connections for other applications. From Apache Calcite 1.26 onwards, the hostname verification will be performed using the default JVM truststore.\"",
            "published_date":"2021-04-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/calcite",
            "commit_href":"https:\/\/github.com\/apache\/calcite\/commit\/43eeafcbac29d02c72bd520c003cdfc571de2d15",
            "commit_sha":"43eeafcbac29d02c72bd520c003cdfc571de2d15",
            "patch":"SINGLE",
            "chain_ord":"['43eeafcbac29d02c72bd520c003cdfc571de2d15']",
            "before_first_fix_commit":"{'ab19f98172848fe303a18173946c2def0b0d0312'}",
            "last_fix_commit":"43eeafcbac29d02c72bd520c003cdfc571de2d15",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/22\/2020, 21:42:06",
            "message":"[CALCITE-4298] Avoid disabling hostname verification on HTTPS connections",
            "author":"Stamatis Zampetakis",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 16, 'total': 17}",
            "files":"{'core\/src\/main\/java\/org\/apache\/calcite\/runtime\/HttpUtils.java': {'additions': 1, 'deletions': 16, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/calcite\/raw\/43eeafcbac29d02c72bd520c003cdfc571de2d15\/core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fcalcite%2Fruntime%2FHttpUtils.java', 'patch': \"@@ -23,11 +23,9 @@\\n import java.io.Writer;\\n import java.net.HttpURLConnection;\\n import java.net.URL;\\n-import java.net.URLConnection;\\n import java.net.URLEncoder;\\n import java.nio.charset.StandardCharsets;\\n import java.util.Map;\\n-import javax.net.ssl.HttpsURLConnection;\\n \\n \/**\\n  * Utilities for connecting to REST services such as Splunk via HTTP.\\n@@ -37,20 +35,7 @@ private HttpUtils() {}\\n \\n   public static HttpURLConnection getURLConnection(String url)\\n       throws IOException {\\n-    URLConnection conn = new URL(url).openConnection();\\n-    final HttpURLConnection httpConn = (HttpURLConnection) conn;\\n-\\n-    \/\/ take care of https stuff - most of the time it's only needed to\\n-    \/\/ secure client\/server comm\\n-    \/\/ not to establish the identity of the server\\n-    if (httpConn instanceof HttpsURLConnection) {\\n-      HttpsURLConnection httpsConn = (HttpsURLConnection) httpConn;\\n-      httpsConn.setSSLSocketFactory(\\n-          TrustAllSslSocketFactory.createSSLSocketFactory());\\n-      httpsConn.setHostnameVerifier((arg0, arg1) -> true);\\n-    }\\n-\\n-    return httpConn;\\n+    return (HttpURLConnection) new URL(url).openConnection();\\n   }\\n \\n   public static void appendURLEncodedArgs(\"}}",
            "message_norm":"[calcite-4298] avoid disabling hostname verification on https connections",
            "language":"en",
            "entities":"[('hostname', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/src\/main\/java\/org\/apache\/calcite\/runtime\/HttpUtils.java'])",
            "num_files":1.0
        },
        {
            "index":2243,
            "vuln_id":"GHSA-jff5-55xj-4jcq",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/307ed31caba68a46426b8c73a787a05add2c7489'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Input During Web Page Generation in Jenkins jenkins before versions 2.44, 2.32.2 is vulnerable to a persisted cross-site scripting in search suggestions due to improperly escaping users with less-than and greater-than characters in their names (SECURITY-388).",
            "published_date":"2022-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/307ed31caba68a46426b8c73a787a05add2c7489",
            "commit_sha":"307ed31caba68a46426b8c73a787a05add2c7489",
            "patch":"SINGLE",
            "chain_ord":"['307ed31caba68a46426b8c73a787a05add2c7489']",
            "before_first_fix_commit":"{'97a61a9fe55f4c16168c123f98301a5173b9fa86', '7ae469770fd10c79bebc07511cd0ab1cafd33292'}",
            "last_fix_commit":"307ed31caba68a46426b8c73a787a05add2c7489",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/10\/2017, 22:21:40",
            "message":"Merge pull request #98 from jenkinsci-cert\/SECURITY-388\n\n[SECURITY-388] Escape metacharacters in the search box",
            "author":"Jesse Glick",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'war\/src\/main\/webapp\/scripts\/hudson-behavior.js': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/307ed31caba68a46426b8c73a787a05add2c7489\/war%2Fsrc%2Fmain%2Fwebapp%2Fscripts%2Fhudson-behavior.js', 'patch': '@@ -2168,6 +2168,7 @@ function createSearchBox(searchURL) {\\n     var ac = new YAHOO.widget.AutoComplete(\"search-box\",\"search-box-completion\",ds);\\n     ac.typeAhead = false;\\n     ac.autoHighlight = false;\\n+    ac.formatResult = ac.formatEscapedResult;\\n \\n     var box   = $(\"search-box\");\\n     var sizer = $(\"search-box-sizer\");'}}",
            "message_norm":"merge pull request #98 from jenkinsci-cert\/security-388\n\n[security-388] escape metacharacters in the search box",
            "language":"en",
            "entities":"[('#98', 'ISSUE', ''), ('security-388', 'SECWORD', ''), ('security-388', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['war\/src\/main\/webapp\/scripts\/hudson-behavior.js'])",
            "num_files":1.0
        },
        {
            "index":3302,
            "vuln_id":"GHSA-wp3c-xw9g-gpcg",
            "cwe_id":"{'CWE-617'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7ae2af34087fb4b5c8915279efd03da3b81028bc'}",
            "dataset":"osv",
            "summary":"Lack of validation in `SparseDenseCwiseMul` ### Impact\nDue to lack of validation in `tf.raw_ops.SparseDenseCwiseMul`, an attacker can trigger denial of service via `CHECK`-fails or accesses to outside the bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\nindices = tf.constant([], shape=[10, 0], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\nshape = tf.constant([0, 0], shape=[2], dtype=tf.int64)\ndense = tf.constant([], shape=[0], dtype=tf.int64)\n  \ntf.raw_ops.SparseDenseCwiseMul(\n    sp_indices=indices, sp_values=values, sp_shape=shape, dense=dense)\n```\n\nSince the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/38178a2f7a681a7835bb0912702a134bfe3b4d84\/tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc#L68-L80) only validates the rank of the input arguments but no [constraints between dimensions](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/raw_ops\/SparseDenseCwiseMul), an attacker can abuse them to trigger internal `CHECK` assertions (and cause program termination, denial of service) or to write to memory outside of bounds of heap allocated tensor buffers.\n\n### Patches\nWe have patched the issue in GitHub commit [7ae2af34087fb4b5c8915279efd03da3b81028bc](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7ae2af34087fb4b5c8915279efd03da3b81028bc).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/7ae2af34087fb4b5c8915279efd03da3b81028bc",
            "commit_sha":"7ae2af34087fb4b5c8915279efd03da3b81028bc",
            "patch":"SINGLE",
            "chain_ord":"['7ae2af34087fb4b5c8915279efd03da3b81028bc']",
            "before_first_fix_commit":"{'38178a2f7a681a7835bb0912702a134bfe3b4d84'}",
            "last_fix_commit":"7ae2af34087fb4b5c8915279efd03da3b81028bc",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 04:30:50",
            "message":"Fix heap-buffer-overflow issue with `tf.raw_ops.SparseDenseCwiseMul`.\n\nPiperOrigin-RevId: 372054410\nChange-Id: Ifcce0491e2e3816838c87e73be30a1e61b65174d",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/7ae2af34087fb4b5c8915279efd03da3b81028bc\/tensorflow%2Fcore%2Fkernels%2Fsparse_dense_binary_op_shared.cc', 'patch': '@@ -78,6 +78,11 @@ class SparseDenseBinaryOpShared : public OpKernel {\\n                     \"but received shapes: \",\\n                     values_t->shape().DebugString(), \" and \",\\n                     shape_t->shape().DebugString()));\\n+    OP_REQUIRES(\\n+        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"The first dimension of values and indices should match. (\",\\n+            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\\n \\n     const auto indices_mat = indices_t->matrix<int64>();\\n     const auto shape_vec = shape_t->vec<int64>();'}}",
            "message_norm":"fix heap-buffer-overflow issue with `tf.raw_ops.sparsedensecwisemul`.\n\npiperorigin-revid: 372054410\nchange-id: ifcce0491e2e3816838c87e73be30a1e61b65174d",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('372054410', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_dense_binary_op_shared.cc'])",
            "num_files":1.0
        },
        {
            "index":1865,
            "vuln_id":"GHSA-gf2j-f278-xh4v",
            "cwe_id":"{'CWE-369'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8c6f391a2282684a25cbfec7687bd5d35261a209'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite ### Impact \nAn attacker can craft a TFLite model that would trigger a division by zero in [`BiasAndClamp` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/lite\/kernels\/internal\/common.h#L75):\n\n```cc\ninline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                         const float* bias_data, int array_size,\n                         float* array_data) {\n  \/\/ ...\n  TFLITE_DCHECK_EQ((array_size % bias_size), 0);\n  \/\/ ...\n} \n```\n  \nThere is no check that the `bias_size` is non zero.\n  \n### Patches\nWe have patched the issue in GitHub commit [8c6f391a2282684a25cbfec7687bd5d35261a209](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8c6f391a2282684a25cbfec7687bd5d35261a209).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8c6f391a2282684a25cbfec7687bd5d35261a209",
            "commit_sha":"8c6f391a2282684a25cbfec7687bd5d35261a209",
            "patch":"SINGLE",
            "chain_ord":"['8c6f391a2282684a25cbfec7687bd5d35261a209']",
            "before_first_fix_commit":"{'c8dafc9f9ae6658d922e443e59e0f553167c990b'}",
            "last_fix_commit":"8c6f391a2282684a25cbfec7687bd5d35261a209",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/14\/2021, 21:40:56",
            "message":"[lite] Add check for bias_size is zero to avoid division by zero. This shouldn't happen for properly converted models. Just safety check\n\nPiperOrigin-RevId: 416383645\nChange-Id: If8e508bf696ae8ecfb927e69c139a8ccf7fe60cb",
            "author":"Karim Nosir",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/lite\/kernels\/internal\/common.h': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/8c6f391a2282684a25cbfec7687bd5d35261a209\/tensorflow%2Flite%2Fkernels%2Finternal%2Fcommon.h', 'patch': '@@ -75,6 +75,7 @@ float ActivationFunction(float x) {\\n inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\\n                          const float* bias_data, int array_size,\\n                          float* array_data) {\\n+  if (bias_size == 0) return;\\n   \/\/ Note: see b\/132215220: in May 2019 we thought it would be OK to replace\\n   \/\/ this with the Eigen one-liner:\\n   \/\/   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).'}}",
            "message_norm":"[lite] add check for bias_size is zero to avoid division by zero. this shouldn't happen for properly converted models. just safety check\n\npiperorigin-revid: 416383645\nchange-id: if8e508bf696ae8ecfb927e69c139a8ccf7fe60cb",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('division by zero', 'SECWORD', ''), ('safety check', 'SECWORD', ''), ('416383645', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/internal\/common.h'])",
            "num_files":1.0
        },
        {
            "index":755,
            "vuln_id":"GHSA-65mj-7c86-79jf",
            "cwe_id":"{'CWE-305', 'CWE-287'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/ADOdb\/ADOdb\/commit\/952de6c4273d9b1e91c2b838044f8c2111150c29', 'https:\/\/github.com\/ADOdb\/ADOdb\/commit\/b4d5ce70034c5aac3a1d51d317d93c037a0938d2'}",
            "dataset":"osv",
            "summary":"Authentication Bypass in ADOdb\/ADOdb ### Impact\n\nAn attacker can inject values into a PostgreSQL connection string by providing a parameter surrounded by single quotes.\n\nDepending on how the library is used in the client software, this may allow an attacker to bypass the login process, gain access to the server's IP address, etc.\n\n### Patches\n\nThe vulnerability is fixed in ADOdb versions 5.20.21 (952de6c4273d9b1e91c2b838044f8c2111150c29) and 5.21.4 or later (b4d5ce70034c5aac3a1d51d317d93c037a0938d2).\n\nThe simplest patch is to delete line 29 in `drivers\/adodb-postgres64.inc.php`:\n\n```php\ndiff --git a\/drivers\/adodb-postgres64.inc.php b\/drivers\/adodb-postgres64.inc.php\nindex d04b7f67..729d7141 100644\n--- a\/drivers\/adodb-postgres64.inc.php\n+++ b\/drivers\/adodb-postgres64.inc.php\n@@ -26,7 +26,6 @@ function adodb_addslashes($s)\n {\n    $len = strlen($s);\n    if ($len == 0) return \"''\";\n-   if (strncmp($s,\"'\",1) === 0 && substr($s,$len-1) == \"'\") return $s; \/\/ already quoted\n \n    return \"'\".addslashes($s).\"'\";\n }\n```\n\n### Workarounds\n\nEnsure the parameters passed to *ADOConnection::connect()* or related functions (_nConnect()_, _pConnect()_) are not surrounded by single quotes.\n\n### Credits\n\nThanks to **Emmet Leahy** (@meme-lord) of Sorcery Ltd for reporting this vulnerability, and to the [huntr](https:\/\/huntr.dev\/) team for their support.\n\n### References\n\n- Original issue report https:\/\/huntr.dev\/bounties\/bdf5f216-4499-4225-a737-b28bc6f5801c\/\n- ADOdb reference issue #793 \n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Add a note in issue #793\n* Contact the maintainers on [Gitter](https:\/\/gitter.im\/adodb\/adodb)",
            "published_date":"2022-01-27",
            "chain_len":2,
            "project":"https:\/\/github.com\/ADOdb\/ADOdb",
            "commit_href":"https:\/\/github.com\/ADOdb\/ADOdb\/commit\/952de6c4273d9b1e91c2b838044f8c2111150c29",
            "commit_sha":"952de6c4273d9b1e91c2b838044f8c2111150c29",
            "patch":"MULTI",
            "chain_ord":"['952de6c4273d9b1e91c2b838044f8c2111150c29', 'b4d5ce70034c5aac3a1d51d317d93c037a0938d2']",
            "before_first_fix_commit":"{'c5415722049f36c446a4034d15f1d17943f11458'}",
            "last_fix_commit":"b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/10\/2022, 08:41:32",
            "message":"Prevent auth bypass with PostgreSQL connections\n\nThanks to Emmet Leahy of Sorcery Ltd for reporting this vulnerability\n(CVE-2021-3850).\n\nThis is a minimalistic approach to patch the issue, to reduce the risk\nof causing regressions in the legacy stable branch.\n\nFixes #793",
            "author":"Damien Regad",
            "comments":null,
            "stats":"{'additions': 0, 'deletions': 1, 'total': 1}",
            "files":"{'drivers\/adodb-postgres64.inc.php': {'additions': 0, 'deletions': 1, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ADOdb\/ADOdb\/raw\/952de6c4273d9b1e91c2b838044f8c2111150c29\/drivers%2Fadodb-postgres64.inc.php', 'patch': '@@ -51,7 +51,6 @@ function adodb_addslashes($s)\\n {\\n \\t$len = strlen($s);\\n \\tif ($len == 0) return \"\\'\\'\";\\n-\\tif (strncmp($s,\"\\'\",1) === 0 && substr($s,$len-1) == \"\\'\") return $s; \/\/ already quoted\\n \\n \\treturn \"\\'\".addslashes($s).\"\\'\";\\n }'}}",
            "message_norm":"prevent auth bypass with postgresql connections\n\nthanks to emmet leahy of sorcery ltd for reporting this vulnerability\n(cve-2021-3850).\n\nthis is a minimalistic approach to patch the issue, to reduce the risk\nof causing regressions in the legacy stable branch.\n\nfixes #793",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('auth', 'SECWORD', ''), ('bypass', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('cve-2021-3850', 'VULNID', 'CVE'), ('patch', 'ACTION', ''), ('issue', 'FLAW', ''), ('fixes', 'ACTION', ''), ('#793', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['drivers\/adodb-postgres64.inc.php'])",
            "num_files":1.0
        },
        {
            "index":1952,
            "vuln_id":"GHSA-gx8x-g87m-h5q6",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/sparklemotion\/nekohtml\/commit\/a800fce3b079def130ed42a408ff1d09f89e773d'}",
            "dataset":"osv",
            "summary":"Denial of Service (DoS) in Nokogiri on JRuby ## Summary\n\nNokogiri `v1.13.4` updates the vendored `org.cyberneko.html` library to `1.9.22.noko2` which addresses [CVE-2022-24839](https:\/\/github.com\/sparklemotion\/nekohtml\/security\/advisories\/GHSA-9849-p7jc-9rmv). That CVE is rated 7.5 (High Severity).\n\nSee [GHSA-9849-p7jc-9rmv](https:\/\/github.com\/sparklemotion\/nekohtml\/security\/advisories\/GHSA-9849-p7jc-9rmv) for more information.\n\nPlease note that this advisory only applies to the **JRuby** implementation of Nokogiri `< 1.13.4`.\n\n\n## Mitigation\n\nUpgrade to Nokogiri `>= 1.13.4`.\n\n\n## Impact\n\n### [CVE-2022-24839](https:\/\/github.com\/sparklemotion\/nekohtml\/security\/advisories\/GHSA-9849-p7jc-9rmv) in nekohtml\n\n- **Severity**: High 7.5\n- **Type**: [CWE-400](https:\/\/cwe.mitre.org\/data\/definitions\/400.html) Uncontrolled Resource Consumption\n- **Description**: The fork of `org.cyberneko.html` used by Nokogiri (Rubygem) raises a `java.lang.OutOfMemoryError` exception when parsing ill-formed HTML markup.\n- **See also**: [GHSA-9849-p7jc-9rmv](https:\/\/github.com\/sparklemotion\/nekohtml\/security\/advisories\/GHSA-9849-p7jc-9rmv)",
            "published_date":"2022-04-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/sparklemotion\/nekohtml",
            "commit_href":"https:\/\/github.com\/sparklemotion\/nekohtml\/commit\/a800fce3b079def130ed42a408ff1d09f89e773d",
            "commit_sha":"a800fce3b079def130ed42a408ff1d09f89e773d",
            "patch":"SINGLE",
            "chain_ord":"['a800fce3b079def130ed42a408ff1d09f89e773d']",
            "before_first_fix_commit":"{'6fe9b53bc289d0e90d684c0f4a8e9f2b19f3460f'}",
            "last_fix_commit":"a800fce3b079def130ed42a408ff1d09f89e773d",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/03\/2022, 23:03:39",
            "message":"fix: ensure ill-formed PIs are parsed correctly",
            "author":"Mike Dalessio",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/org\/cyberneko\/html\/HTMLScanner.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sparklemotion\/nekohtml\/raw\/a800fce3b079def130ed42a408ff1d09f89e773d\/src%2Forg%2Fcyberneko%2Fhtml%2FHTMLScanner.java', 'patch': \"@@ -2588,7 +2588,7 @@ protected void scanPI() throws IOException {\\n                     if (c == '?' || c == '\/') {\\n                         char c0 = (char)c;\\n                         c = fCurrentEntity.read();\\n-                        if (c == '>') {\\n+                        if (c == '>' || c == -1) {\\n                             break;\\n                         }\\n                         fStringBuffer.append(c0);\"}}",
            "message_norm":"fix: ensure ill-formed pis are parsed correctly",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('ensure', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/org\/cyberneko\/html\/HTMLScanner.java'])",
            "num_files":1.0
        },
        {
            "index":1923,
            "vuln_id":"GHSA-grc3-8q8m-4j7c",
            "cwe_id":"{'CWE-280', 'CWE-732'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/apache\/accumulo\/commit\/877ad502f6857e48342664e4b0ce83db74e4cda4'}",
            "dataset":"osv",
            "summary":"Improper privilege handling in Apache Accumulo Apache Accumulo versions 1.5.0 through 1.10.0 and version 2.0.0 do not properly check the return value of some policy enforcement functions before permitting an authenticated user to perform certain administrative operations. Specifically, the return values of the 'canFlush' and 'canPerformSystemActions' security functions are not checked in some instances, therefore allowing an authenticated user with insufficient permissions to perform the following actions: flushing a table, shutting down Accumulo or an individual tablet server, and setting or removing system-wide Accumulo configuration properties.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/accumulo",
            "commit_href":"https:\/\/github.com\/apache\/accumulo\/commit\/877ad502f6857e48342664e4b0ce83db74e4cda4",
            "commit_sha":"877ad502f6857e48342664e4b0ce83db74e4cda4",
            "patch":"SINGLE",
            "chain_ord":"['877ad502f6857e48342664e4b0ce83db74e4cda4']",
            "before_first_fix_commit":"{'024a72ed8b80c21470ab2eed04787e3216b7b606'}",
            "last_fix_commit":"877ad502f6857e48342664e4b0ce83db74e4cda4",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/08\/2020, 19:08:36",
            "message":"Throw exceptions when permissions checks fail (#1828)\n\n(cherry-picked for 2.0.1)\n\nAdd and throw missing exceptions when permissions checks fail. This\nprevents certain operations that the user does not have privileges to\nperform from succeeding anyway.",
            "author":"Christopher Tubbs",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 7, 'total': 21}",
            "files":"{'server\/master\/src\/main\/java\/org\/apache\/accumulo\/master\/MasterClientServiceHandler.java': {'additions': 14, 'deletions': 7, 'changes': 21, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/accumulo\/raw\/877ad502f6857e48342664e4b0ce83db74e4cda4\/server%2Fmaster%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Faccumulo%2Fmaster%2FMasterClientServiceHandler.java', 'patch': '@@ -112,7 +112,8 @@ public long initiateFlush(TInfo tinfo, TCredentials c, String tableIdStr)\\n       throws ThriftSecurityException, ThriftTableOperationException {\\n     TableId tableId = TableId.of(tableIdStr);\\n     NamespaceId namespaceId = getNamespaceIdFromTableId(TableOperation.FLUSH, tableId);\\n-    master.security.canFlush(c, tableId, namespaceId);\\n+    if (!master.security.canFlush(c, tableId, namespaceId))\\n+      throw new ThriftSecurityException(c.getPrincipal(), SecurityErrorCode.PERMISSION_DENIED);\\n \\n     String zTablePath = Constants.ZROOT + \"\/\" + master.getInstanceID() + Constants.ZTABLES + \"\/\"\\n         + tableId + Constants.ZTABLE_FLUSH_ID;\\n@@ -145,7 +146,8 @@ public void waitForFlush(TInfo tinfo, TCredentials c, String tableIdStr, ByteBuf\\n       throws ThriftSecurityException, ThriftTableOperationException {\\n     TableId tableId = TableId.of(tableIdStr);\\n     NamespaceId namespaceId = getNamespaceIdFromTableId(TableOperation.FLUSH, tableId);\\n-    master.security.canFlush(c, tableId, namespaceId);\\n+    if (!master.security.canFlush(c, tableId, namespaceId))\\n+      throw new ThriftSecurityException(c.getPrincipal(), SecurityErrorCode.PERMISSION_DENIED);\\n \\n     Text startRow = ByteBufferUtil.toText(startRowBB);\\n     Text endRow = ByteBufferUtil.toText(endRowBB);\\n@@ -247,7 +249,8 @@ public void setTableProperty(TInfo info, TCredentials credentials, String tableN\\n   @Override\\n   public void shutdown(TInfo info, TCredentials c, boolean stopTabletServers)\\n       throws ThriftSecurityException {\\n-    master.security.canPerformSystemActions(c);\\n+    if (!master.security.canPerformSystemActions(c))\\n+      throw new ThriftSecurityException(c.getPrincipal(), SecurityErrorCode.PERMISSION_DENIED);\\n     if (stopTabletServers) {\\n       master.setMasterGoalState(MasterGoalState.CLEAN_STOP);\\n       EventCoordinator.Listener eventListener = master.nextEvent.getListener();\\n@@ -261,7 +264,8 @@ public void shutdown(TInfo info, TCredentials c, boolean stopTabletServers)\\n   @Override\\n   public void shutdownTabletServer(TInfo info, TCredentials c, String tabletServer, boolean force)\\n       throws ThriftSecurityException {\\n-    master.security.canPerformSystemActions(c);\\n+    if (!master.security.canPerformSystemActions(c))\\n+      throw new ThriftSecurityException(c.getPrincipal(), SecurityErrorCode.PERMISSION_DENIED);\\n \\n     final TServerInstance doomed = master.tserverSet.find(tabletServer);\\n     if (!force) {\\n@@ -333,15 +337,17 @@ public void reportTabletStatus(TInfo info, TCredentials credentials, String serv\\n   @Override\\n   public void setMasterGoalState(TInfo info, TCredentials c, MasterGoalState state)\\n       throws ThriftSecurityException {\\n-    master.security.canPerformSystemActions(c);\\n+    if (!master.security.canPerformSystemActions(c))\\n+      throw new ThriftSecurityException(c.getPrincipal(), SecurityErrorCode.PERMISSION_DENIED);\\n \\n     master.setMasterGoalState(state);\\n   }\\n \\n   @Override\\n   public void removeSystemProperty(TInfo info, TCredentials c, String property)\\n       throws ThriftSecurityException {\\n-    master.security.canPerformSystemActions(c);\\n+    if (!master.security.canPerformSystemActions(c))\\n+      throw new ThriftSecurityException(c.getPrincipal(), SecurityErrorCode.PERMISSION_DENIED);\\n \\n     try {\\n       SystemPropUtil.removeSystemProperty(master.getContext(), property);\\n@@ -355,7 +361,8 @@ public void removeSystemProperty(TInfo info, TCredentials c, String property)\\n   @Override\\n   public void setSystemProperty(TInfo info, TCredentials c, String property, String value)\\n       throws ThriftSecurityException, TException {\\n-    master.security.canPerformSystemActions(c);\\n+    if (!master.security.canPerformSystemActions(c))\\n+      throw new ThriftSecurityException(c.getPrincipal(), SecurityErrorCode.PERMISSION_DENIED);\\n \\n     try {\\n       SystemPropUtil.setSystemProperty(master.getContext(), property, value);'}}",
            "message_norm":"throw exceptions when permissions checks fail (#1828)\n\n(cherry-picked for 2.0.1)\n\nadd and throw missing exceptions when permissions checks fail. this\nprevents certain operations that the user does not have privileges to\nperform from succeeding anyway.",
            "language":"en",
            "entities":"[('permissions', 'SECWORD', ''), ('#1828', 'ISSUE', ''), ('2.0.1', 'VERSION', ''), ('add', 'ACTION', ''), ('permissions', 'SECWORD', ''), ('prevents', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/master\/src\/main\/java\/org\/apache\/accumulo\/master\/MasterClientServiceHandler.java'])",
            "num_files":1.0
        },
        {
            "index":2152,
            "vuln_id":"GHSA-hwv5-w8gm-fq9f",
            "cwe_id":"{'CWE-22'}",
            "score":3.5,
            "chain":"{'https:\/\/github.com\/horazont\/xmpp-http-upload\/commit\/82056540191e89f0cd697c81f57714c00962ed75'}",
            "dataset":"osv",
            "summary":"Directory Traversal vulnerability in GET\/PUT allows attackers to Disclose Information or Write Files via a crafted GET\/PUT request ### Impact\n\n#### Information Disclosure\n\nWhen the GET method is attacked, attackers can read files which have a `.data` suffix and which are accompanied by a JSON file with the `.meta` suffix. This can lead to Information Disclosure and in some shared-hosting scenarios also to circumvention of authentication or other limitations on the outbound (GET) traffic.\n\nFor example, in a scenario where a single server has multiple instances of the application running (with separate DATA_ROOT settings), an attacker who has knowledge about the directory structure is able to read files from any other instance to which the process has read access.\n\nIf instances have individual authentication (for example, HTTP authentication via a reverse proxy, source IP based filtering) or other restrictions (such as quotas), attackers may circumvent those limits in such a scenario by using the Directory Traversal to retrieve data from the other instances.\n\n#### File Write\n\nIf the associated XMPP server (or anyone knowing the SECRET_KEY) is malicious, they can write files outside the DATA_ROOT. The files which are written are constrained to have the `.meta` and the `.data` suffixes; the `.meta` file will contain the JSON with the Content-Type of the original request and the `.data` file will contain the payload.\n\n### Patches\n\nPR #12 fixes the issue. The PR has been merged into version 0.4.0 and 0.4.0 has been released and pushed to PyPI. Users are advised to upgrade immediately.\n\n### Workarounds\n\n- Apache can apparently be configured to filter such malicious paths when reverse-proxying. \n- There are no other workarounds known.\n\n### References\n\n- [Pull Request #12](https:\/\/github.com\/horazont\/xmpp-http-upload\/pull\/12)",
            "published_date":"2020-10-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/horazont\/xmpp-http-upload",
            "commit_href":"https:\/\/github.com\/horazont\/xmpp-http-upload\/commit\/82056540191e89f0cd697c81f57714c00962ed75",
            "commit_sha":"82056540191e89f0cd697c81f57714c00962ed75",
            "patch":"SINGLE",
            "chain_ord":"['82056540191e89f0cd697c81f57714c00962ed75']",
            "before_first_fix_commit":"{'f0fc7443c06a0e8aecb5696fc2bd513a2cc8b611'}",
            "last_fix_commit":"82056540191e89f0cd697c81f57714c00962ed75",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/05\/2020, 23:06:21",
            "message":"Simplify path handling, use safe_join\n\nThe current implementation of sanitized_join did not handle\n\"..\" properly. The problem is, that .absolute() does not do\nwhat .resolve() does, but .resolve() does not work on non\nexistant paths.\n\nAnyway, flask has a function exactly for this: safe_join.\n\nSo let's use that one.\n\nWhile at it, simplified the whole path handling a bit.",
            "author":"Christian Tacke",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 34, 'total': 49}",
            "files":"{'xhu.py': {'additions': 15, 'deletions': 34, 'changes': 49, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/horazont\/xmpp-http-upload\/raw\/82056540191e89f0cd697c81f57714c00962ed75\/xhu.py', 'patch': '@@ -29,6 +29,7 @@\\n import typing\\n \\n import flask\\n+import werkzeug.exceptions\\n \\n app = flask.Flask(\"xmpp-http-upload\")\\n app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")\\n@@ -39,16 +40,11 @@\\n     CORS(app)\\n \\n \\n-def sanitized_join(path: str, root: pathlib.Path) -> pathlib.Path:\\n-    result = (root \/ path).absolute()\\n-    if not str(result).startswith(str(root) + \"\/\"):\\n-        raise ValueError(\"resulting path is outside root\")\\n-    return result\\n-\\n-\\n-def get_paths(base_path: pathlib.Path):\\n-    data_file = pathlib.Path(str(base_path) + \".data\")\\n-    metadata_file = pathlib.Path(str(base_path) + \".meta\")\\n+def get_paths(root: str, sub_path: str) \\\\\\n+        -> typing.Tuple[pathlib.Path, pathlib.Path]:\\n+    base_path = flask.safe_join(root, sub_path)\\n+    data_file = pathlib.Path(base_path + \".data\")\\n+    metadata_file = pathlib.Path(base_path + \".meta\")\\n \\n     return data_file, metadata_file\\n \\n@@ -58,15 +54,10 @@ def load_metadata(metadata_file):\\n         return json.load(f)\\n \\n \\n-def get_info(path: str, root: pathlib.Path) -> typing.Tuple[\\n+def get_info(path: str) -> typing.Tuple[\\n         pathlib.Path,\\n         dict]:\\n-    dest_path = sanitized_join(\\n-        path,\\n-        pathlib.Path(app.config[\"DATA_ROOT\"]),\\n-    )\\n-\\n-    data_file, metadata_file = get_paths(dest_path)\\n+    data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\\n \\n     return data_file, load_metadata(metadata_file)\\n \\n@@ -104,11 +95,8 @@ def stream_file(src, dest, nbytes):\\n @app.route(\"\/<path:path>\", methods=[\"PUT\"])\\n def put_file(path):\\n     try:\\n-        dest_path = sanitized_join(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"]),\\n-        )\\n-    except ValueError:\\n+        data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\\n+    except werkzeug.exceptions.NotFound:\\n         return flask.Response(\\n             \"Not Found\",\\n             404,\\n@@ -134,8 +122,7 @@ def put_file(path):\\n         \"application\/octet-stream\",\\n     )\\n \\n-    dest_path.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\\n-    data_file, metadata_file = get_paths(dest_path)\\n+    data_file.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\\n \\n     try:\\n         with write_file(data_file) as fout:\\n@@ -189,13 +176,10 @@ def generate_headers(response_headers, metadata_headers):\\n @app.route(\"\/<path:path>\", methods=[\"HEAD\"])\\n def head_file(path):\\n     try:\\n-        data_file, metadata = get_info(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\\n-        )\\n+        data_file, metadata = get_info(path)\\n \\n         stat = data_file.stat()\\n-    except (OSError, ValueError):\\n+    except (OSError, werkzeug.exceptions.NotFound):\\n         return flask.Response(\\n             \"Not Found\",\\n             404,\\n@@ -214,11 +198,8 @@ def head_file(path):\\n @app.route(\"\/<path:path>\", methods=[\"GET\"])\\n def get_file(path):\\n     try:\\n-        data_file, metadata = get_info(\\n-            path,\\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\\n-        )\\n-    except (OSError, ValueError):\\n+        data_file, metadata = get_info(path)\\n+    except (OSError, werkzeug.exceptions.NotFound):\\n         return flask.Response(\\n             \"Not Found\",\\n             404,'}}",
            "message_norm":"simplify path handling, use safe_join\n\nthe current implementation of sanitized_join did not handle\n\"..\" properly. the problem is, that .absolute() does not do\nwhat .resolve() does, but .resolve() does not work on non\nexistant paths.\n\nanyway, flask has a function exactly for this: safe_join.\n\nso let's use that one.\n\nwhile at it, simplified the whole path handling a bit.",
            "language":"en",
            "entities":"[('sanitized_join', 'SECWORD', ''), ('problem', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['xhu.py'])",
            "num_files":1.0
        },
        {
            "index":545,
            "vuln_id":"GHSA-545v-42p7-98fq",
            "cwe_id":"{'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886'}",
            "dataset":"osv",
            "summary":"Heap out of bounds read in `MaxPoolGradWithArgmax` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGradWithArgmax` can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32)\ngrad = tf.constant([10.0, 10.0, 10.0, 10.0], shape=[1, 1, 1, 4], dtype=tf.float32)\nargmax = tf.constant([1], shape=[1], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n  \ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  padding='SAME', include_batch_in_index=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e\/tensorflow\/core\/kernels\/maxpooling_op.cc#L1016-L1017) uses the same value to index in two different arrays but there is no guarantee that the sizes are identical. \n\n### Patches\nWe have patched the issue in GitHub commit [dcd7867de0fea4b72a2b34bd41eb74548dc23886](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "commit_sha":"dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "patch":"SINGLE",
            "chain_ord":"['dcd7867de0fea4b72a2b34bd41eb74548dc23886']",
            "before_first_fix_commit":"{'ef0c008ee84bad91ec6725ddc42091e19a30cf0e'}",
            "last_fix_commit":"dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 15:38:03",
            "message":"Fix heap buffer overflow\n\nPiperOrigin-RevId: 372132844\nChange-Id: Idef9895efaf145f2b1c23d31983601ec980cd5e4",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/maxpooling_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/dcd7867de0fea4b72a2b34bd41eb74548dc23886\/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc', 'patch': '@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\\n         const int input_start = start * input_size_per_batch;\\n         const int input_end = limit * input_size_per_batch;\\n         for (int64 index = input_start; index < input_end; index++) {\\n+          if (index >= argmax.NumElements()) {\\n+            break;\\n+          }\\n           int64 grad_out_index = argmax_flat(index);\\n           if (!include_batch_in_index) {\\n             const int64 cur_batch = index \/ input_size_per_batch;'}}",
            "message_norm":"fix heap buffer overflow\n\npiperorigin-revid: 372132844\nchange-id: idef9895efaf145f2b1c23d31983601ec980cd5e4",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('372132844', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/maxpooling_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3225,
            "vuln_id":"GHSA-w4xf-2pqw-5mq7",
            "cwe_id":"{'CWE-824'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/be7a4de6adfbd303ce08be4332554dff70362612'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in `RaggedTensorToVariant` ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToVariant`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedTensorToVariant(\n  rt_nested_splits=[],\n  rt_dense_values=[1,2,3],\n  batched_input=True)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc#L129) has an incomplete validation of the splits values, missing the case when the argument would be empty.\n\n### Patches\nWe have patched the issue in GitHub commit [be7a4de6adfbd303ce08be4332554dff70362612](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/be7a4de6adfbd303ce08be4332554dff70362612).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/be7a4de6adfbd303ce08be4332554dff70362612",
            "commit_sha":"be7a4de6adfbd303ce08be4332554dff70362612",
            "patch":"SINGLE",
            "chain_ord":"['be7a4de6adfbd303ce08be4332554dff70362612']",
            "before_first_fix_commit":"{'ffbdacfce0c9c8f627d0ce89d9d4db8fd0a7cfd1'}",
            "last_fix_commit":"be7a4de6adfbd303ce08be4332554dff70362612",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/29\/2021, 21:05:34",
            "message":"Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant\n\nPiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/be7a4de6adfbd303ce08be4332554dff70362612\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_variant_op.cc', 'patch': '@@ -157,6 +157,12 @@ class RaggedTensorToVariantOp : public OpKernel {\\n       return;\\n     }\\n \\n+    \/\/ Checked here instead of at input in case batched_input_ is false\\n+    OP_REQUIRES(context, ragged_nested_splits_len > 0,\\n+                errors::InvalidArgument(\\n+                    \"rt_nested_splits must be a list of one or more, but \"\\n+                    \"received rt_nested_splits of length 0.\"));\\n+\\n     \/\/ Unbatch the Ragged Tensor and encode the components.\\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\\n     auto batched_splits_top_vec ='}}",
            "message_norm":"ensure non-empty rt_nested_splits in tf.raw_ops.raggedtensortovariant\n\npiperorigin-revid: 387664237\nchange-id: ia1700c34b5610873d63561abc86e23b46ead93b3",
            "language":"en",
            "entities":"[('ensure', 'ACTION', ''), ('387664237', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc'])",
            "num_files":1.0
        },
        {
            "index":665,
            "vuln_id":"GHSA-5pg2-qg87-vmj7",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/9ebbb4dd35da74025ab6965f722829a7f8f86566'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in microweber Cross-site Scripting (XSS) - Stored in GitHub repository microweber\/microweber prior to 1.2.19.",
            "published_date":"2022-07-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/9ebbb4dd35da74025ab6965f722829a7f8f86566",
            "commit_sha":"9ebbb4dd35da74025ab6965f722829a7f8f86566",
            "patch":"SINGLE",
            "chain_ord":"['9ebbb4dd35da74025ab6965f722829a7f8f86566']",
            "before_first_fix_commit":"{'c2991b3a44896320a834a4b611257db587129645'}",
            "last_fix_commit":"9ebbb4dd35da74025ab6965f722829a7f8f86566",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/01\/2022, 08:07:47",
            "message":"update",
            "author":"Peter Ivanov",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 1, 'total': 5}",
            "files":"{'src\/MicroweberPackages\/App\/functions\/plupload.php': {'additions': 4, 'deletions': 1, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/9ebbb4dd35da74025ab6965f722829a7f8f86566\/src%2FMicroweberPackages%2FApp%2Ffunctions%2Fplupload.php', 'patch': \"@@ -336,9 +336,12 @@\\n \/\/ Make sure the fileName is unique but only if chunking is disabled\\n if ($chunks < 2 && file_exists($targetDir . DIRECTORY_SEPARATOR . $fileName)) {\\n     $ext = strrpos($fileName, '.');\\n+\\n     $fileName_a = substr($fileName, 0, $ext);\\n     $fileName_b = substr($fileName, $ext);\\n \\n+    $fileName_b = strtolower($fileName_b);\\n+\\n     $count = 1;\\n     while (file_exists($targetDir . DIRECTORY_SEPARATOR . $fileName_a . '_' . $count . $fileName_b)) {\\n         ++$count;\\n@@ -500,7 +503,7 @@\\n \\n     if (is_file($filePath) and !$chunks || $chunk == $chunks - 1) {\\n         $ext = get_file_extension($filePath);\\n-\\n+        $ext = strtolower($ext);\\n         if (function_exists('finfo_open') and function_exists('finfo_file')) {\\n             $finfo = finfo_open(FILEINFO_MIME_TYPE); \/\/ return mime type ala mimetype extension\\n             $mime = @finfo_file($finfo, $filePath);\"}}",
            "message_norm":"update",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/App\/functions\/plupload.php'])",
            "num_files":1.0
        },
        {
            "index":1553,
            "vuln_id":"GHSA-cgjv-rghq-qhgp",
            "cwe_id":"{'CWE-22'}",
            "score":8.6,
            "chain":"{'https:\/\/github.com\/AlgoRythm-Dylan\/httpserv\/commit\/bcfe9d4316c2b59aab3a64a38905376026888735'}",
            "dataset":"osv",
            "summary":"Path Traversal in algo-httpserv Versions of `algo-httpserv` prior to 1.1.2 are vulnerable to Path Traversal.  Due to insufficient input sanitization, attackers can access server files by using relative paths. \n\n\n## Recommendation\n\nUpgrade to version 1.1.2 or later.",
            "published_date":"2019-09-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/AlgoRythm-Dylan\/httpserv",
            "commit_href":"https:\/\/github.com\/AlgoRythm-Dylan\/httpserv\/commit\/bcfe9d4316c2b59aab3a64a38905376026888735",
            "commit_sha":"bcfe9d4316c2b59aab3a64a38905376026888735",
            "patch":"SINGLE",
            "chain_ord":"['bcfe9d4316c2b59aab3a64a38905376026888735']",
            "before_first_fix_commit":"{'7763b4f9b0b9e1873ae0cdfef582c786ee96f091'}",
            "last_fix_commit":"bcfe9d4316c2b59aab3a64a38905376026888735",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/17\/2019, 22:10:35",
            "message":"Fixed path vulnerability",
            "author":"AlgoRythm-Dylan",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 2, 'total': 9}",
            "files":"{'httpserv.js': {'additions': 7, 'deletions': 2, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/AlgoRythm-Dylan\/httpserv\/raw\/bcfe9d4316c2b59aab3a64a38905376026888735\/httpserv.js', 'patch': '@@ -1,6 +1,7 @@\\n \/\/ Stream-based KISS HTTP(S) server\\n \\n const url = require(\"url\");\\n+const pathlib = require(\"path\")\\n const fs = require(\"fs\");\\n \\n \/\/ A small database of MIME associations\\n@@ -32,7 +33,7 @@ var MIMES = {\\n     \".zip\": \"application\/zip\"\\n }\\n \\n-var servePath = \"serve\";\\n+var servePath = \"serve\/\";\\n function doStream(request, response, filePath, stats, MIME){\\n     let responseOptions = {};\\n     let streamOptions = {};\\n@@ -82,7 +83,11 @@ module.exports.serve = function(request, response){\\n         MIME = MIMES[fileType];\\n     }\\n     \/\/ Serve the actual file\\n-    var filePath = servePath + path;\\n+    var filePath = pathlib.join(servePath, path);\\n+    if(filePath.indexOf(servePath) !== 0){\\n+        response.end();\\n+        return;\\n+    }\\n     let handler = handlers[path];\\n     if(handler !== undefined){\\n         if(handler.requestTypes === null || handler.requestTypes.indexOf(request.method) != -1){'}}",
            "message_norm":"fixed path vulnerability",
            "language":"en",
            "entities":"[('fixed', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['httpserv.js'])",
            "num_files":1.0
        },
        {
            "index":2935,
            "vuln_id":"GHSA-rfw2-x9f8-2f6m",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/linkedin\/oncall\/commit\/843bc106a1c1b1699e9e52b6b0d01c7efe1d6225'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting LinkedIn Oncall through 1.4.0 allows reflected XSS via \/query because of mishandling of the \"No results found for\" message in the search bar.",
            "published_date":"2021-04-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/linkedin\/oncall",
            "commit_href":"https:\/\/github.com\/linkedin\/oncall\/commit\/843bc106a1c1b1699e9e52b6b0d01c7efe1d6225",
            "commit_sha":"843bc106a1c1b1699e9e52b6b0d01c7efe1d6225",
            "patch":"SINGLE",
            "chain_ord":"['843bc106a1c1b1699e9e52b6b0d01c7efe1d6225']",
            "before_first_fix_commit":"{'605d10ef5d68181b2c516dc857fdc3c8575539cd'}",
            "last_fix_commit":"843bc106a1c1b1699e9e52b6b0d01c7efe1d6225",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/05\/2021, 23:30:43",
            "message":"prevent potential XSS from searchbar results (#342)\n\n* prevent potential XSS from searchbar results\r\n\r\n* use built in handlebars expression escaping\r\n\r\n* use handlebars encodeURIComponent",
            "author":"Diego Cepeda",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'src\/oncall\/ui\/static\/js\/oncall.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/linkedin\/oncall\/raw\/843bc106a1c1b1699e9e52b6b0d01c7efe1d6225\/src%2Foncall%2Fui%2Fstatic%2Fjs%2Foncall.js', 'patch': '@@ -579,11 +579,11 @@ var oncall = {\\n               },\\n               footer: function(resp){\\n                 if (teamsCt > typeaheadLimit) {\\n-                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + resp.query + \\'\/teams\" data-navigo> See all \\' + teamsCt + \\' results for teams \u00bb<\/a><\/div>\\';\\n+                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + \\'\/teams\" data-navigo> See all \\' + teamsCt + \\' results for teams \u00bb<\/a><\/div>\\';\\n                 }\\n               },\\n               empty: function(resp){\\n-                return \\'<h4> No results found for \"\\' + resp.query + \\'\" <\/h4>\\';\\n+                return \\'<h4> No results found for \"\\' + Handlebars.escapeExpression(resp.query) + \\'\" <\/h4>\\';\\n               }\\n             }\\n           },\\n@@ -604,7 +604,7 @@ var oncall = {\\n               },\\n               footer: function(resp){\\n                 if (servicesCt > typeaheadLimit) {\\n-                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + resp.query + \\'\/services\" data-navigo> See all \\' + servicesCt + \\' results for services \u00bb<\/a><\/div>\\';\\n+                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + \\'\/services\" data-navigo> See all \\' + servicesCt + \\' results for services \u00bb<\/a><\/div>\\';\\n                 }\\n               }\\n             }\\n@@ -626,7 +626,7 @@ var oncall = {\\n               },\\n               footer: function(resp){\\n                 if (usersCt > typeaheadLimit) {\\n-                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + resp.query + \\'\/users\" data-navigo> See all \\' + usersCt + \\' results for users \u00bb<\/a><\/div>\\';\\n+                  return \\'<div class=\"tt-see-all\"><a href=\"\/query\/\\' + Handlebars.escapeExpression(encodeURIComponent(resp.query)) + \\'\/users\" data-navigo> See all \\' + usersCt + \\' results for users \u00bb<\/a><\/div>\\';\\n                 }\\n               }\\n             }'}}",
            "message_norm":"prevent potential xss from searchbar results (#342)\n\n* prevent potential xss from searchbar results\r\n\r\n* use built in handlebars expression escaping\r\n\r\n* use handlebars encodeuricomponent",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('xss', 'SECWORD', ''), ('#342', 'ISSUE', ''), ('prevent', 'ACTION', ''), ('xss', 'SECWORD', ''), ('escaping', 'SECWORD', ''), ('encodeuricomponent', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/oncall\/ui\/static\/js\/oncall.js'])",
            "num_files":1.0
        },
        {
            "index":1133,
            "vuln_id":"GHSA-84mw-34w6-2q43",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b055b9c474cd376259dde8779908f9eeaf097d93'}",
            "dataset":"osv",
            "summary":"Null pointer dereference via invalid Ragged Tensors ### Impact\nCalling `tf.raw_ops.RaggedTensorToVariant` with arguments specifying an invalid ragged tensor results in a null pointer dereference:\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 56, 56, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 23, 1])\n```\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 39, 34, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])\n```\n\nThe implementation of [`RaggedTensorToVariant` operations](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/904b3926ed1c6c70380d5313d282d248a776baa1\/tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc#L39-L40) does not validate that the ragged tensor argument is non-empty:\n\n```cc\n  int ragged_rank = batched_ragged.ragged_rank();\n  auto batched_splits_top_vec = batched_ragged.splits(0).vec<SPLIT_TYPE>();\n```\n\nSince `batched_ragged` contains no elements, `batched_ragged.splits` is a null vector, thus `batched_ragged.splits(0)` will result in  dereferencing `nullptr`.\n\n### Patches\nWe have patched the issue in GitHub commit [b055b9c474cd376259dde8779908f9eeaf097d93](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b055b9c474cd376259dde8779908f9eeaf097d93).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b055b9c474cd376259dde8779908f9eeaf097d93",
            "commit_sha":"b055b9c474cd376259dde8779908f9eeaf097d93",
            "patch":"SINGLE",
            "chain_ord":"['b055b9c474cd376259dde8779908f9eeaf097d93']",
            "before_first_fix_commit":"{'904b3926ed1c6c70380d5313d282d248a776baa1'}",
            "last_fix_commit":"b055b9c474cd376259dde8779908f9eeaf097d93",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2021, 21:49:50",
            "message":"Fix `tf.raw_ops.RaggedTensorToVariant` invalid resize.\n\nPiperOrigin-RevId: 368299574\nChange-Id: I751c186325aa0bab397928845e790e60c2d90918",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b055b9c474cd376259dde8779908f9eeaf097d93\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_variant_op.cc', 'patch': '@@ -159,6 +159,11 @@ class RaggedTensorToVariantOp : public OpKernel {\\n \\n     \/\/ Unbatch the Ragged Tensor and encode the components.\\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\\n+    auto batched_splits_top_vec =\\n+        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\\n+    int num_components = batched_splits_top_vec.size() - 1;\\n+    OP_REQUIRES(context, num_components >= 0,\\n+                errors::Internal(\"Invalid split argument.\"));\\n     OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\\n                                 batched_ragged_input, &unbatched_ragged_input));'}}",
            "message_norm":"fix `tf.raw_ops.raggedtensortovariant` invalid resize.\n\npiperorigin-revid: 368299574\nchange-id: i751c186325aa0bab397928845e790e60c2d90918",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('368299574', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc'])",
            "num_files":1.0
        },
        {
            "index":2432,
            "vuln_id":"GHSA-mj63-64x7-57xf",
            "cwe_id":"{'CWE-22'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/49c643bf66620646884ed141c94e5fdd85bcdd2f', 'https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/99bd29e3995c254e2d6f6c2e3454e4271665955a'}",
            "dataset":"osv",
            "summary":"Path traversal in impacket Multiple path traversal vulnerabilities exist in smbserver.py in Impacket before 0.9.23. An attacker that connects to a running smbserver instance can list and write to arbitrary files via ..\/ directory traversal. This could potentially be abused to achieve arbitrary code execution by replacing \/etc\/shadow or an SSH authorized key.",
            "published_date":"2021-06-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/SecureAuthCorp\/impacket",
            "commit_href":"https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/99bd29e3995c254e2d6f6c2e3454e4271665955a",
            "commit_sha":"99bd29e3995c254e2d6f6c2e3454e4271665955a",
            "patch":"MULTI",
            "chain_ord":"['99bd29e3995c254e2d6f6c2e3454e4271665955a', '49c643bf66620646884ed141c94e5fdd85bcdd2f']",
            "before_first_fix_commit":"{'6688da5d97592269aae72b3a00dc1ab186c0b33d', '91902eafb68fea932cf2350cab329f15afa554e5'}",
            "last_fix_commit":"49c643bf66620646884ed141c94e5fdd85bcdd2f",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/25\/2021, 11:06:02",
            "message":"Fix Path Traversal vulnerabilities by checking path prefix against incoming filename",
            "author":"OmriI",
            "comments":null,
            "stats":"{'additions': 2011, 'deletions': 1936, 'total': 3947}",
            "files":"{'impacket\/smbserver.py': {'additions': 2011, 'deletions': 1936, 'changes': 3947, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/SecureAuthCorp\/impacket\/raw\/99bd29e3995c254e2d6f6c2e3454e4271665955a\/impacket%2Fsmbserver.py', 'patch': None}}",
            "message_norm":"fix path traversal vulnerabilities by checking path prefix against incoming filename",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('path traversal', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['impacket\/smbserver.py'])",
            "num_files":1.0
        },
        {
            "index":3081,
            "vuln_id":"GHSA-v8v8-6859-qxm4",
            "cwe_id":"{'CWE-94'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/zamotany\/logkitty\/commit\/ef2f673e25c629544dd3de6429999318447dd6bf'}",
            "dataset":"osv",
            "summary":"Arbitrary shell command execution in logkitty Lack of output sanitization allowed an attack to execute arbitrary shell commands via the logkitty npm package before version 0.7.1.",
            "published_date":"2020-06-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/zamotany\/logkitty",
            "commit_href":"https:\/\/github.com\/zamotany\/logkitty\/commit\/ef2f673e25c629544dd3de6429999318447dd6bf",
            "commit_sha":"ef2f673e25c629544dd3de6429999318447dd6bf",
            "patch":"SINGLE",
            "chain_ord":"['ef2f673e25c629544dd3de6429999318447dd6bf']",
            "before_first_fix_commit":"{'e1e229687472d8c9266d17f2969ff7431a78db86'}",
            "last_fix_commit":"ef2f673e25c629544dd3de6429999318447dd6bf",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/07\/2020, 09:35:09",
            "message":"huntr - Command Injection Fix (#18)\n\nCo-authored-by: jammy <jammy@loves.shib.es>\r\nCo-authored-by: Pawe\u0142 Trys\u0142a <zamotany@users.noreply.github.com>",
            "author":"huntr-helper",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 6, 'total': 15}",
            "files":"{'src\/android\/adb.ts': {'additions': 9, 'deletions': 6, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/zamotany\/logkitty\/raw\/ef2f673e25c629544dd3de6429999318447dd6bf\/src%2Fandroid%2Fadb.ts', 'patch': \"@@ -1,4 +1,4 @@\\n-import { spawn, execSync, ChildProcess } from 'child_process';\\n+import { spawn, execFileSync, ChildProcess } from 'child_process';\\n import path from 'path';\\n import {\\n   CodeError,\\n@@ -25,7 +25,7 @@ export function getAdbPath(customPath?: string): string {\\n \\n export function spawnLogcatProcess(adbPath: string): ChildProcess {\\n   try {\\n-    execSync(`${adbPath} logcat -c`);\\n+    execFileSync(adbPath, ['logcat', '-c']);\\n   } catch (error) {\\n     throw new CodeError(\\n       ERR_ANDROID_CANNOT_CLEAN_LOGCAT_BUFFER,\\n@@ -49,11 +49,14 @@ export function getApplicationPid(\\n   applicationId: string,\\n   adbPath?: string\\n ): number {\\n-  let output: Buffer | undefined;\\n+  let output: Buffer | String | undefined;\\n   try {\\n-    output = execSync(\\n-      `'${getAdbPath(adbPath)}' shell pidof -s ${applicationId}`\\n-    );\\n+    output = execFileSync(getAdbPath(adbPath), [\\n+      'shell',\\n+      'pidof',\\n+      '-s',\\n+      applicationId,\\n+    ]);\\n   } catch (error) {\\n     throw new CodeError(\\n       ERR_ANDROID_CANNOT_GET_APP_PID,\"}}",
            "message_norm":"huntr - command injection fix (#18)\n\nco-authored-by: jammy <jammy@loves.shib.es>\r\nco-authored-by: pawe\u0142 trys\u0142a <zamotany@users.noreply.github.com>",
            "language":"en",
            "entities":"[('command injection', 'SECWORD', ''), ('#18', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/android\/adb.ts'])",
            "num_files":1.0
        },
        {
            "index":2040,
            "vuln_id":"GHSA-hc72-vj3g-5g2g",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/SeriaWei\/ZKEACMS\/commit\/833c5460dc5c6152092f6ad54b8b832870a59903'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in ZKEACMS A cross-site scripting (XSS) vulnerability in \/navigation\/create?ParentID=%23 of ZKEACMS v3.5.2 allows attackers to execute arbitrary web scripts or HTML via a crafted payload injected into the ParentID parameter.",
            "published_date":"2022-05-26",
            "chain_len":1,
            "project":"https:\/\/github.com\/SeriaWei\/ZKEACMS",
            "commit_href":"https:\/\/github.com\/SeriaWei\/ZKEACMS\/commit\/833c5460dc5c6152092f6ad54b8b832870a59903",
            "commit_sha":"833c5460dc5c6152092f6ad54b8b832870a59903",
            "patch":"SINGLE",
            "chain_ord":"['833c5460dc5c6152092f6ad54b8b832870a59903']",
            "before_first_fix_commit":"{'53109ba58bbeac75074583ec261732772ed1ecc5'}",
            "last_fix_commit":"833c5460dc5c6152092f6ad54b8b832870a59903",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/14\/2022, 14:55:34",
            "message":"Sanitize Html\n\n#457",
            "author":"wayne",
            "comments":null,
            "stats":"{'additions': 36, 'deletions': 1, 'total': 37}",
            "files":"{'src\/ZKEACMS\/Common\/Service\/NavigationService.cs': {'additions': 36, 'deletions': 1, 'changes': 37, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/SeriaWei\/ZKEACMS\/raw\/833c5460dc5c6152092f6ad54b8b832870a59903\/src%2FZKEACMS%2FCommon%2FService%2FNavigationService.cs', 'patch': '@@ -11,13 +11,16 @@\\n using ZKEACMS.Common.Models;\\n using Easy;\\n using Microsoft.EntityFrameworkCore;\\n+using ZKEACMS.Safety;\\n \\n namespace ZKEACMS.Common.Service\\n {\\n     public class NavigationService : ServiceBase<NavigationEntity, CMSDbContext>, INavigationService\\n     {\\n-        public NavigationService(IApplicationContext applicationContext, CMSDbContext dbContext) : base(applicationContext, dbContext)\\n+        private readonly IHtmlSanitizer _htmlSanitizer;\\n+        public NavigationService(IApplicationContext applicationContext, CMSDbContext dbContext, IHtmlSanitizer htmlSanitizer) : base(applicationContext, dbContext)\\n         {\\n+            _htmlSanitizer = htmlSanitizer;\\n         }\\n         public override DbSet<NavigationEntity> CurrentDbSet => DbContext.Navigation;\\n         public override ServiceResult<NavigationEntity> Add(NavigationEntity item)\\n@@ -27,8 +30,34 @@ public override ServiceResult<NavigationEntity> Add(NavigationEntity item)\\n                 item.ParentId = \"#\";\\n             }\\n             item.ID = Guid.NewGuid().ToString(\"N\");\\n+            Santize(item);\\n             return base.Add(item);\\n         }\\n+\\n+        public override ServiceResult<NavigationEntity> AddRange(params NavigationEntity[] items)\\n+        {\\n+            foreach (var item in items)\\n+            {\\n+                Santize(item);\\n+            }\\n+            return base.AddRange(items);\\n+        }\\n+\\n+        public override ServiceResult<NavigationEntity> Update(NavigationEntity item)\\n+        {\\n+            Santize(item);\\n+            return base.Update(item);\\n+        }\\n+\\n+        public override ServiceResult<NavigationEntity> UpdateRange(params NavigationEntity[] items)\\n+        {\\n+            foreach (var item in items)\\n+            {\\n+                Santize(item);\\n+            }\\n+            return base.UpdateRange(items);\\n+        }\\n+\\n         public override void Remove(NavigationEntity item)\\n         {\\n             Remove(m => m.ParentId == item.ID);\\n@@ -73,5 +102,11 @@ public void Move(string id, string parentId, int position, int oldPosition)\\n             }\\n             Update(nav);\\n         }\\n+\\n+        private void Santize(NavigationEntity item)\\n+        {\\n+            item.Title = _htmlSanitizer.Sanitize(item.Title);\\n+            item.Html = _htmlSanitizer.Sanitize(item.Html);\\n+        }\\n     }\\n }\\n\\\\ No newline at end of file'}}",
            "message_norm":"sanitize html\n\n#457",
            "language":"sq",
            "entities":"[('sanitize', 'SECWORD', ''), ('#457', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/ZKEACMS\/Common\/Service\/NavigationService.cs'])",
            "num_files":1.0
        },
        {
            "index":1802,
            "vuln_id":"GHSA-g25h-jr74-qp5j",
            "cwe_id":"{'CWE-20'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6da6620efad397c85493b8f8667b821403516708'}",
            "dataset":"osv",
            "summary":"Incomplete validation in `QuantizeV2` ### Impact                                                                                                                                                                                                                                                                                \nDue to incomplete validation in `tf.raw_ops.QuantizeV2`, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeV2(\n  input=[1,2,3],\n  min_range=[1,2],\n  max_range=[],\n  T=tf.qint32,\n  mode='SCALED',\n  round_mode='HALF_AWAY_FROM_ZERO',\n  narrow_range=False,\n  axis=1,\n  ensure_minimum_range=3)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/quantize_op.cc#L59) has some validation but does not check that `min_range` and `max_range` both have the same non-zero number of elements. If `axis` is provided (i.e., not `-1`), then validation should check that it is a value in range for the rank of `input` tensor and then the lengths of `min_range` and `max_range` inputs match the `axis` dimension of the `input` tensor.\n  \n### Patches\nWe have patched the issue in GitHub commit [6da6620efad397c85493b8f8667b821403516708](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6da6620efad397c85493b8f8667b821403516708).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6da6620efad397c85493b8f8667b821403516708",
            "commit_sha":"6da6620efad397c85493b8f8667b821403516708",
            "patch":"SINGLE",
            "chain_ord":"['6da6620efad397c85493b8f8667b821403516708']",
            "before_first_fix_commit":"{'eb921122119a6b6e470ee98b89e65d721663179d'}",
            "last_fix_commit":"6da6620efad397c85493b8f8667b821403516708",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/28\/2021, 00:19:57",
            "message":"Secure tf.raw_ops.QuantizeV2\n\nValidate size and shape of min_range and max_range\nEnsure axis is within input dims limits\n\nPiperOrigin-RevId: 387232799\nChange-Id: I36975281f7b5758e9e31a8dcc73fe610ef456318",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 43, 'deletions': 0, 'total': 43}",
            "files":"{'tensorflow\/core\/kernels\/quantize_op.cc': {'additions': 43, 'deletions': 0, 'changes': 43, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6da6620efad397c85493b8f8667b821403516708\/tensorflow%2Fcore%2Fkernels%2Fquantize_op.cc', 'patch': '@@ -113,7 +113,50 @@ class QuantizeV2Op : public OpKernel {\\n \\n     int num_slices = 1;\\n     if (axis_ > -1) {\\n+      OP_REQUIRES(\\n+          ctx, input.dims() > axis_,\\n+          errors::InvalidArgument(\\n+              \"Axis is on a zero-based index, so its value must always be less \"\\n+              \"than number of input\\'s dims, but given axis value was \",\\n+              axis_, \" and input\\'s dims was \", input.dims()));\\n       num_slices = input.dim_size(axis_);\\n+      OP_REQUIRES(ctx, input_min_range.dims() == 1,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\\n+                      \"whose size matches the axis dimension of the input and \"\\n+                      \"output tensors, but min_range dims are \",\\n+                      input_min_range.dims()));\\n+      OP_REQUIRES(ctx, input_min_range.dim_size(0) == num_slices,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is specified, min_range must be a 1-D tensor \"\\n+                      \"whose size matches the axis dimension of the input and \"\\n+                      \"output tensors, but min_range is a 1-D tensor of size \",\\n+                      input_min_range.dim_size(0),\\n+                      \" and input\\'s axis dimension is of size \", num_slices));\\n+      OP_REQUIRES(ctx, input_max_range.dims() == 1,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\\n+                      \"whose size matches the axis dimension of the input and \"\\n+                      \"output tensors, but max_range dims are \",\\n+                      input_max_range.dims()));\\n+      OP_REQUIRES(ctx, input_max_range.dim_size(0) == num_slices,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is specified, max_range must be a 1-D tensor \"\\n+                      \"whose size matches the axis dimension of the input and \"\\n+                      \"output tensors, but max_range is a 1-D tensor of size \",\\n+                      input_max_range.dim_size(0),\\n+                      \" and input\\'s axis dimension is of size \", num_slices));\\n+    } else {\\n+      OP_REQUIRES(ctx, input_min_range.NumElements() == 1,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is not specified, min_range must contain a \"\\n+                      \"single float element, but it contains \",\\n+                      input_min_range.NumElements(), \" elements\"));\\n+      OP_REQUIRES(ctx, input_max_range.NumElements() == 1,\\n+                  errors::InvalidArgument(\\n+                      \"If axis is not specified, max_range must contain a \"\\n+                      \"single float element, but it contains \",\\n+                      input_max_range.NumElements(), \" elements\"));\\n     }\\n \\n     const TensorShape& minmax_shape = ctx->input(1).shape();'}}",
            "message_norm":"secure tf.raw_ops.quantizev2\n\nvalidate size and shape of min_range and max_range\nensure axis is within input dims limits\n\npiperorigin-revid: 387232799\nchange-id: i36975281f7b5758e9e31a8dcc73fe610ef456318",
            "language":"en",
            "entities":"[('secure', 'SECWORD', ''), ('validate', 'ACTION', ''), ('ensure', 'ACTION', ''), ('387232799', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3053,
            "vuln_id":"GHSA-v592-xf75-856p",
            "cwe_id":"{'CWE-682'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/ethereum\/go-ethereum\/commit\/d990df909d7839640143344e79356754384dcdd0'}",
            "dataset":"osv",
            "summary":"Erroneous Proof of Work calculation in geth ### Impact\nAn ethash mining DAG generation flaw in Geth could cause miners to erroneously calculate PoW in an upcoming epoch (estimated early January, 2021). This happened on the ETC chain on 2020-11-06. This issue is relevant only for miners, non-mining nodes are unaffected.\n\n### Patches\nThis issue is also fixed as of 1.9.24. Thanks to @slavikus for bringing the issue to our attention and writing the fix. \n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [go-ethereum](https:\/\/github.com\/ethereum\/go-ethereum)\n* Email us at [security@ethereum.org](mailto:security@ethereum.org)",
            "published_date":"2021-06-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/ethereum\/go-ethereum",
            "commit_href":"https:\/\/github.com\/ethereum\/go-ethereum\/commit\/d990df909d7839640143344e79356754384dcdd0",
            "commit_sha":"d990df909d7839640143344e79356754384dcdd0",
            "patch":"SINGLE",
            "chain_ord":"['d990df909d7839640143344e79356754384dcdd0']",
            "before_first_fix_commit":"{'27d93c1848846b75d0e67fcac284a0d417acd47c'}",
            "last_fix_commit":"d990df909d7839640143344e79356754384dcdd0",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/11\/2020, 20:13:12",
            "message":"consensus\/ethash: use 64bit indexes for the DAG generation (#21793)\n\n* Bit boundary fix for the DAG generation routine\r\n\r\n* Fix unnecessary conversion warnings\r\n\r\nCo-authored-by: Sergey Pavlov <spavlov@gmail.com>",
            "author":"Slava Karpenko",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 5, 'total': 10}",
            "files":"{'consensus\/ethash\/algorithm.go': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ethereum\/go-ethereum\/raw\/d990df909d7839640143344e79356754384dcdd0\/consensus%2Fethash%2Falgorithm.go', 'patch': '@@ -304,16 +304,16 @@ func generateDataset(dest []uint32, epoch uint64, cache []uint32) {\\n \\t\\t\\tkeccak512 := makeHasher(sha3.NewLegacyKeccak512())\\n \\n \\t\\t\\t\/\/ Calculate the data segment this thread should generate\\n-\\t\\t\\tbatch := uint32((size + hashBytes*uint64(threads) - 1) \/ (hashBytes * uint64(threads)))\\n-\\t\\t\\tfirst := uint32(id) * batch\\n+\\t\\t\\tbatch := (size + hashBytes*uint64(threads) - 1) \/ (hashBytes * uint64(threads))\\n+\\t\\t\\tfirst := uint64(id) * batch\\n \\t\\t\\tlimit := first + batch\\n-\\t\\t\\tif limit > uint32(size\/hashBytes) {\\n-\\t\\t\\t\\tlimit = uint32(size \/ hashBytes)\\n+\\t\\t\\tif limit > size\/hashBytes {\\n+\\t\\t\\t\\tlimit = size \/ hashBytes\\n \\t\\t\\t}\\n \\t\\t\\t\/\/ Calculate the dataset segment\\n \\t\\t\\tpercent := size \/ hashBytes \/ 100\\n \\t\\t\\tfor index := first; index < limit; index++ {\\n-\\t\\t\\t\\titem := generateDatasetItem(cache, index, keccak512)\\n+\\t\\t\\t\\titem := generateDatasetItem(cache, uint32(index), keccak512)\\n \\t\\t\\t\\tif swapped {\\n \\t\\t\\t\\t\\tswap(item)\\n \\t\\t\\t\\t}'}}",
            "message_norm":"consensus\/ethash: use 64bit indexes for the dag generation (#21793)\n\n* bit boundary fix for the dag generation routine\r\n\r\n* fix unnecessary conversion warnings\r\n\r\nco-authored-by: sergey pavlov <spavlov@gmail.com>",
            "language":"en",
            "entities":"[('#21793', 'ISSUE', ''), ('fix', 'ACTION', ''), ('warnings', 'FLAW', ''), ('spavlov@gmail.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['consensus\/ethash\/algorithm.go'])",
            "num_files":1.0
        },
        {
            "index":2921,
            "vuln_id":"GHSA-rcvx-rmvf-mxch",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/eclipse\/hawkbit\/commit\/94b7c12cde1b38eda5414bd88d6d068008cfb9f9'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Eclipse Hawkbit In all version of Eclipse Hawkbit prior to 0.3.0M7, the HTTP 404 (Not Found) JSON response body returned by the REST API may contain unsafe characters within the path attribute. Sending a POST request to a non existing resource will return the full path from the given URL unescaped to the client.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/eclipse\/hawkbit",
            "commit_href":"https:\/\/github.com\/eclipse\/hawkbit\/commit\/94b7c12cde1b38eda5414bd88d6d068008cfb9f9",
            "commit_sha":"94b7c12cde1b38eda5414bd88d6d068008cfb9f9",
            "patch":"SINGLE",
            "chain_ord":"['94b7c12cde1b38eda5414bd88d6d068008cfb9f9']",
            "before_first_fix_commit":"{'8816396d18880d2020743ce2e83a08446449d0db'}",
            "last_fix_commit":"94b7c12cde1b38eda5414bd88d6d068008cfb9f9",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/12\/2021, 10:56:44",
            "message":"Fixes #1067\n\nJSON body response for HTTP 404 error may contain unsafe URL path characters. Thus removing path from the response\n\nSigned-off-by: Dominic Schabel <dominic.schabel@bosch.io>",
            "author":"Dominic Schabel",
            "comments":null,
            "stats":"{'additions': 22, 'deletions': 4, 'total': 26}",
            "files":"{'hawkbit-runtime\/hawkbit-update-server\/src\/main\/java\/org\/eclipse\/hawkbit\/app\/ErrorController.java': {'additions': 22, 'deletions': 4, 'changes': 26, 'status': 'renamed', 'raw_url': 'https:\/\/github.com\/eclipse\/hawkbit\/raw\/94b7c12cde1b38eda5414bd88d6d068008cfb9f9\/hawkbit-runtime%2Fhawkbit-update-server%2Fsrc%2Fmain%2Fjava%2Forg%2Feclipse%2Fhawkbit%2Fapp%2FErrorController.java', 'patch': '@@ -8,6 +8,8 @@\\n  *\/\\n package org.eclipse.hawkbit.app;\\n \\n+import java.util.Map;\\n+\\n import javax.servlet.http.HttpServletRequest;\\n import javax.servlet.http.HttpServletResponse;\\n \\n@@ -23,22 +25,23 @@\\n \/**\\n  * Error page controller that ensures that ocet stream does not return text in\\n  * case of an error.\\n- *\\n  *\/\\n @Controller\\n \/\/ Exception squid:S3752 - errors need handling for all methods\\n @SuppressWarnings(\"squid:S3752\")\\n-public class StreamAwareErrorController extends BasicErrorController {\\n+public class ErrorController extends BasicErrorController {\\n+\\n+    private static final String PATH = \"path\";\\n \\n     \/**\\n-     * A new {@link StreamAwareErrorController}.\\n+     * A new {@link ErrorController}.\\n      * \\n      * @param errorAttributes\\n      *            the error attributes\\n      * @param serverProperties\\n      *            configuration properties\\n      *\/\\n-    public StreamAwareErrorController(final ErrorAttributes errorAttributes, final ServerProperties serverProperties) {\\n+    public ErrorController(final ErrorAttributes errorAttributes, final ServerProperties serverProperties) {\\n         super(errorAttributes, serverProperties.getError());\\n     }\\n \\n@@ -48,4 +51,19 @@ public ResponseEntity<Void> errorStream(final HttpServletRequest request, final\\n         return new ResponseEntity<>(status);\\n     }\\n \\n+    @Override\\n+    @RequestMapping\\n+    public ResponseEntity<Map<String, Object>> error(final HttpServletRequest request) {\\n+        final HttpStatus status = getStatus(request);\\n+        final Map<String, Object> body = getErrorAttributesWithoutPath(request);\\n+        return new ResponseEntity<>(body, status);\\n+    }\\n+\\n+    private Map<String, Object> getErrorAttributesWithoutPath(final HttpServletRequest request) {\\n+        final Map<String, Object> body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL));\\n+        if (body != null && body.containsKey(PATH)) {\\n+            body.remove(PATH);\\n+        }\\n+        return body;\\n+    }\\n }'}}",
            "message_norm":"fixes #1067\n\njson body response for http 404 error may contain unsafe url path characters. thus removing path from the response\n\nsigned-off-by: dominic schabel <dominic.schabel@bosch.io>",
            "language":"en",
            "entities":"[('fixes', 'ACTION', ''), ('#1067', 'ISSUE', ''), ('error', 'FLAW', ''), ('unsafe', 'SECWORD', ''), ('removing', 'ACTION', ''), ('dominic.schabel@bosch.io', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['hawkbit-runtime\/hawkbit-update-server\/src\/main\/java\/org\/eclipse\/hawkbit\/app\/ErrorController.java'])",
            "num_files":1.0
        },
        {
            "index":2050,
            "vuln_id":"GHSA-hf79-8hjp-rrvq",
            "cwe_id":"{'CWE-416'}",
            "score":8.5,
            "chain":"{'https:\/\/github.com\/bytecodealliance\/lucet\/commit\/7c7757c772fb709c61b1442bcc1e1fbee97bf4a8'}",
            "dataset":"osv",
            "summary":"Use After Free in lucet ### Impact\nThere is a bug in the main branch of Lucet's `lucet-runtime` that allows a use-after-free in an `Instance` object that could result in memory corruption, data race, or other related issues.  This bug was introduced early in the development of Lucet and is present in all releases.  As a result of this bug, and dependent on the memory backing for the `Instance` objects, it is possible to trigger a use-after-free when the `Instance` is dropped.\n\n### Patches\nUsers should upgrade to the `main` branch of the Lucet repository. Lucet does not provide versioned releases on crates.io.\n\n### Workarounds\nThere is no way to remediate this vulnerability without upgrading.\n\n### Description\nLucet uses a \"pool\" allocator for new WebAssembly instances that are created. This pool allocator manages everything from the linear memory of the wasm instance, the runtime stack for async switching, as well as the memory behind the Instance itself. `Instances` are referred to via an `InstanceHandle` type which will, on drop, release the memory backing the Instance back to the pool.\n\nWhen an Instance is dropped, the fields of the `Instance` are destructed top-to-bottom, however when the `alloc: Alloc` field is destructed, the memory backing the `Instance` is released back to the pool before the destructors of the remaining fields are run. If another thread allocates the same memory from the pool while these destructors are still running, a race condition occurs that can lead to use-after-free errors.\n\nThe bug was corrected by changing how the `InstanceHandle` destructor operates to ensure that the memory backing an Instance is only returned to the pool once the `Instance` has been completely destroyed.\n\nThis security advisory has been assigned CVE-2021-43790.\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [lucet repository](https:\/\/github.com\/bytecodealliance\/lucet)\n* Email [the lucet team](mailto:lucet@fastly.com)\n* See the [Bytecode Alliance security policy](https:\/\/bytecodealliance.org\/security)",
            "published_date":"2021-11-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/bytecodealliance\/lucet",
            "commit_href":"https:\/\/github.com\/bytecodealliance\/lucet\/commit\/7c7757c772fb709c61b1442bcc1e1fbee97bf4a8",
            "commit_sha":"7c7757c772fb709c61b1442bcc1e1fbee97bf4a8",
            "patch":"SINGLE",
            "chain_ord":"['7c7757c772fb709c61b1442bcc1e1fbee97bf4a8']",
            "before_first_fix_commit":"{'8fb1fece339927e178f6cfef4eb67328b500237d'}",
            "last_fix_commit":"7c7757c772fb709c61b1442bcc1e1fbee97bf4a8",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/29\/2021, 23:00:02",
            "message":"Merge pull request from GHSA-hf79-8hjp-rrvq\n\n* Use manual drop\n\n* Add some comments to `ManuallyDrop` usage\n\n* rustfmt\n\nCo-authored-by: Aaron Turon <aturon@fastly.com>\nCo-authored-by: Alex Crichton <alex@alexcrichton.com>",
            "author":"Pat Hickey",
            "comments":null,
            "stats":"{'additions': 26, 'deletions': 13, 'total': 39}",
            "files":"{'lucet-runtime\/lucet-runtime-internals\/src\/instance.rs': {'additions': 26, 'deletions': 13, 'changes': 39, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/bytecodealliance\/lucet\/raw\/7c7757c772fb709c61b1442bcc1e1fbee97bf4a8\/lucet-runtime%2Flucet-runtime-internals%2Fsrc%2Finstance.rs', 'patch': '@@ -14,7 +14,6 @@ use crate::error::Error;\\n #[cfg(feature = \"concurrent_testpoints\")]\\n use crate::lock_testpoints::LockTestpoints;\\n use crate::module::{self, FunctionHandle, Global, GlobalValue, Module, TrapCode};\\n-use crate::region::RegionInternal;\\n use crate::sysdeps::HOST_PAGE_SIZE_EXPECTED;\\n use crate::val::{UntypedRetVal, Val};\\n use crate::vmctx::Vmctx;\\n@@ -27,6 +26,7 @@ use std::cell::{BorrowError, BorrowMutError, Ref, RefCell, RefMut, UnsafeCell};\\n use std::convert::TryFrom;\\n use std::marker::PhantomData;\\n use std::mem;\\n+use std::mem::ManuallyDrop;\\n use std::ops::{Deref, DerefMut};\\n use std::ptr::{self, NonNull};\\n use std::sync::Arc;\\n@@ -147,20 +147,29 @@ impl Drop for InstanceHandle {\\n             unsafe {\\n                 let inst = self.inst.as_mut();\\n \\n-                \/\/ Grab a handle to the region to ensure it outlives `inst`.\\n+                \/\/ The `inst.alloc` field manages the memory of the instance\\n+                \/\/ itself. Note, though, that this field is in a `ManuallyDrop`\\n+                \/\/ so it won\\'t get dropped automatically in `drop_in_place`.\\n+                \/\/ This is the point where we take over that precise drop.\\n                 \/\/\\n-                \/\/ This ensures that the region won\\'t be dropped by `inst` being\\n-                \/\/ dropped, which could result in `inst` being unmapped by the\\n-                \/\/ Region *during* drop of the Instance\\'s fields.\\n-                let region: Arc<dyn RegionInternal> = inst.alloc().region.clone();\\n+                \/\/ By using `take` here we\\'re basically calling `ptr::read`\\n+                \/\/ which \"duplicates\" the `alloc` since the `alloc` local\\n+                \/\/ variable here is the exact same as `inst.alloc`. All we do\\n+                \/\/ with `inst`, though, is call `drop_in_place`, which\\n+                \/\/ invalidates every other field in `inst`.\\n+                let alloc: Alloc = ManuallyDrop::take(&mut inst.alloc);\\n \\n                 \/\/ drop the actual instance\\n                 std::ptr::drop_in_place(inst);\\n \\n-                \/\/ and now we can drop what may be the last Arc<Region>. If it is\\n-                \/\/ it can safely do what it needs with memory; we\\'re not running\\n-                \/\/ destructors on it anymore.\\n-                mem::drop(region);\\n+                \/\/ Now that we\\'re 100% done with the instance, destructors and\\n+                \/\/ all, we can release the memory of the instance back to the\\n+                \/\/ original allocator from whence it came (be it mmap or uffd\\n+                \/\/ based). This will run the \"official\" destructor for `Alloc`\\n+                \/\/ which internally does the release. Note that after this\\n+                \/\/ operation the `inst` pointer is invalid and can no longer be\\n+                \/\/ used.\\n+                drop(alloc);\\n             }\\n         }\\n     }\\n@@ -233,8 +242,12 @@ pub struct Instance {\\n     \/\/\/ Conditionally-present helpers to force permutations of possible races in testing.\\n     pub lock_testpoints: Arc<LockTestpoints>,\\n \\n-    \/\/\/ The memory allocated for this instance\\n-    alloc: Alloc,\\n+    \/\/\/ The memory allocated for this instance.\\n+    \/\/\/\\n+    \/\/\/ Note that this is in a `ManuallyDrop` because this manages the memory of\\n+    \/\/\/ this `Instance` itself. To have precise control over this memory we\\n+    \/\/\/ handle this in `Drop for InstanceHandle`.\\n+    alloc: ManuallyDrop<Alloc>,\\n \\n     \/\/\/ Handler run for signals that do not arise from a known WebAssembly trap, or that involve\\n     \/\/\/ memory outside of the current instance.\\n@@ -1055,7 +1068,7 @@ impl Instance {\\n             kill_state,\\n             #[cfg(feature = \"concurrent_testpoints\")]\\n             lock_testpoints,\\n-            alloc,\\n+            alloc: ManuallyDrop::new(alloc),\\n             fatal_handler: default_fatal_handler,\\n             c_fatal_handler: None,\\n             signal_handler: Box::new(signal_handler_none) as Box<SignalHandler>,'}}",
            "message_norm":"merge pull request from ghsa-hf79-8hjp-rrvq\n\n* use manual drop\n\n* add some comments to `manuallydrop` usage\n\n* rustfmt\n\nco-authored-by: aaron turon <aturon@fastly.com>\nco-authored-by: alex crichton <alex@alexcrichton.com>",
            "language":"en",
            "entities":"[('ghsa-hf79-8hjp-rrvq', 'VULNID', 'GHSA'), ('add', 'ACTION', ''), ('aturon@fastly.com', 'EMAIL', ''), ('alex@alexcrichton.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lucet-runtime\/lucet-runtime-internals\/src\/instance.rs'])",
            "num_files":1.0
        },
        {
            "index":1484,
            "vuln_id":"GHSA-c558-5gfm-p2r8",
            "cwe_id":"{'CWE-79'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a'}",
            "dataset":"osv",
            "summary":"JSPUI spellcheck and autocomplete tools vulnerable to Cross Site Scripting ### Impact\nThe JSPUI spellcheck \"Did you mean\" HTML escapes the data-spell attribute in the link, but not the actual displayed text.  Similarly, the JSPUI autocomplete HTML does not properly escape text passed to it. Both are vulnerable to XSS.  This vulnerability only impacts the JSPUI.\n\n_This vulnerability does NOT impact the XMLUI or 7.x._\n\n### Patches\n_DSpace 6.x:_\n* Fixed in 6.4 via two commits: \n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7\n* 6.x patch files available (may be applied manually if an immediate upgrade to 6.4 or above is not possible)\n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d.patch\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7.patch\n\n_DSpace 5.x:_\n* Fixed in 5.11 via two commits: \n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5\n* 5.x patch files available (may be applied manually if an immediate upgrade to 5.11 or 6.4 is not possible)\n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a.patch\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5.patch\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs \/ configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### References\nDiscovered & reported by Hassan Bhuiyan (Brunel University London)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
            "published_date":"2022-08-06",
            "chain_len":4,
            "project":"https:\/\/github.com\/DSpace\/DSpace",
            "commit_href":"https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5",
            "commit_sha":"6f75bb084ab1937d094208c55cd84340040bcbb5",
            "patch":"MULTI",
            "chain_ord":"['ebb83a75234d3de9be129464013e998dc929b68d', '35030a23e48b5946f5853332c797e1c4adea7bb7', 'c89e493e517b424dea6175caba54e91d3847fc3a', '6f75bb084ab1937d094208c55cd84340040bcbb5']",
            "before_first_fix_commit":"{'d1dd7d23329ef055069759df15cfa200c8e32e54'}",
            "last_fix_commit":"6f75bb084ab1937d094208c55cd84340040bcbb5",
            "chain_ord_pos":4.0,
            "commit_datetime":"07\/26\/2022, 21:12:22",
            "message":"[DS-4453] Discovery autocomplete HTML escaping (JSPUI)",
            "author":"Kim Shepherd",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 2, 'total': 9}",
            "files":"{'dspace-jspui\/src\/main\/webapp\/search\/discovery.jsp': {'additions': 7, 'deletions': 2, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DSpace\/DSpace\/raw\/6f75bb084ab1937d094208c55cd84340040bcbb5\/dspace-jspui%2Fsrc%2Fmain%2Fwebapp%2Fsearch%2Fdiscovery.jsp', 'patch': '@@ -141,7 +141,7 @@\\n \\t\\t\\t\\t\\t\\t\\t\\t\\ttmp_val = item.displayedValue;\\n \\t\\t\\t\\t\\t\\t\\t\\t}\\n \\t\\t\\t\\t\\t\\t\\t\\treturn {\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\tlabel: item.displayedValue + \" (\" + item.count + \")\",\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\tlabel: escapeHtml(item.displayedValue) + \" (\" + item.count + \")\",\\n \\t\\t\\t\\t\\t\\t\\t\\t\\tvalue: tmp_val\\n \\t\\t\\t\\t\\t\\t\\t\\t};\\n \\t\\t\\t\\t\\t\\t\\t}))\\t\\t\\t\\n@@ -153,7 +153,12 @@\\n \\tfunction validateFilters() {\\n \\t\\treturn document.getElementById(\"filterquery\").value.length > 0;\\n \\t}\\n-<\/script>\\t\\t\\n+\\t\/\/ Generic HTML escape utility\\n+\\tvar escapeHtml = s => (s + \\'\\').replace(\/[&<>\"\\']\/g, m => ({\\n+\\t\\t\\'&\\': \\'&amp;\\', \\'<\\': \\'&lt;\\', \\'>\\': \\'&gt;\\',\\n+\\t\\t\\'\"\\': \\'&quot;\\', \"\\'\": \\'&#39;\\'\\n+\\t})[m]);\\n+<\/script>\\n <\/c:set>\\n \\n <dspace:layout titlekey=\"jsp.search.title\">'}}",
            "message_norm":"[ds-4453] discovery autocomplete html escaping (jspui)",
            "language":"it",
            "entities":"[('escaping', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dspace-jspui\/src\/main\/webapp\/search\/discovery.jsp'])",
            "num_files":1.0
        },
        {
            "index":314,
            "vuln_id":"GHSA-3v6h-hqm4-2rg6",
            "cwe_id":"{'CWE-22'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/cthackers\/adm-zip\/commit\/62f64004fefb894c523a7143e8a88ebe6c84df25'}",
            "dataset":"osv",
            "summary":"Arbitrary File Write in adm-zip Versions of `adm-zip` before 0.4.9 are vulnerable to arbitrary file write when used to extract a specifically crafted archive that contains path traversal filenames (`..\/..\/file.txt` for example).\n\n\n## Recommendation\n\nUpdate to version 0.4.9 or later.",
            "published_date":"2018-07-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/cthackers\/adm-zip",
            "commit_href":"https:\/\/github.com\/cthackers\/adm-zip\/commit\/62f64004fefb894c523a7143e8a88ebe6c84df25",
            "commit_sha":"62f64004fefb894c523a7143e8a88ebe6c84df25",
            "patch":"SINGLE",
            "chain_ord":"['62f64004fefb894c523a7143e8a88ebe6c84df25']",
            "before_first_fix_commit":"{'e116bc18df51e4e50c493cede82ae7696954b511', '6f4dfeb9a2166e93207443879988f97d88a37cde'}",
            "last_fix_commit":"62f64004fefb894c523a7143e8a88ebe6c84df25",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2018, 07:20:56",
            "message":"Merge pull request #212 from aviadatsnyk\/master\n\nfix: prevent extracting archived files outside of target path.  Credit to Snyk Security Research Team for disclosure and fixing the issue.",
            "author":"The Brain",
            "comments":"{'com_1': {'author': 'Shubham-9798', 'datetime': '08\/27\/2018, 04:25:44', 'body': 'adding adm-zip'}}",
            "stats":"{'additions': 11, 'deletions': 0, 'total': 11}",
            "files":"{'adm-zip.js': {'additions': 11, 'deletions': 0, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/cthackers\/adm-zip\/raw\/62f64004fefb894c523a7143e8a88ebe6c84df25\/adm-zip.js', 'patch': '@@ -354,6 +354,9 @@ module.exports = function(\/*String*\/input) {\\n \\n \\n             var target = pth.resolve(targetPath, maintainEntryPath ? entryName : pth.basename(entryName));\\n+            if(!target.startsWith(targetPath)) {\\n+                throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\\n+            }\\n \\n             if (item.isDirectory) {\\n                 target = pth.resolve(target, \"..\");\\n@@ -429,6 +432,10 @@ module.exports = function(\/*String*\/input) {\\n             _zip.entries.forEach(function(entry) {\\n                 entryName = entry.entryName.toString();\\n \\n+                if(!pth.resolve(targetPath, entryName).startsWith(targetPath)) {\\n+                    throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\\n+                }\\n+\\n                 if(isWin){\\n                     entryName = escapeFileName(entryName)\\n                 }\\n@@ -471,6 +478,10 @@ module.exports = function(\/*String*\/input) {\\n                     entryName = escapeFileName(entryName)\\n                 }\\n \\n+                if(!pth.resolve(targetPath, entryName).startsWith(targetPath)) {\\n+                  throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\\n+                }\\n+\\n                 if (entry.isDirectory) {\\n                     Utils.makeDir(pth.resolve(targetPath, entryName));\\n                     if(--i == 0)'}}",
            "message_norm":"merge pull request #212 from aviadatsnyk\/master\n\nfix: prevent extracting archived files outside of target path.  credit to snyk security research team for disclosure and fixing the issue.",
            "language":"en",
            "entities":"[('#212', 'ISSUE', ''), ('prevent', 'ACTION', ''), ('security', 'SECWORD', ''), ('disclosure', 'SECWORD', ''), ('fixing', 'ACTION', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['adm-zip.js'])",
            "num_files":1.0
        },
        {
            "index":1518,
            "vuln_id":"GHSA-c94w-c95p-phf8",
            "cwe_id":"{'CWE-190'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/fcd18ce3101f245b083b30655c27b239dc72221e'}",
            "dataset":"osv",
            "summary":"Integer overflow in Tensorflow ### Impact\nThe [implementation of `OpLevelCostEstimator::CalculateTensorSize`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/grappler\/costs\/op_level_cost_estimator.cc#L1552-L1558) is vulnerable to an integer overflow if an attacker can create an operation which would involve a tensor with large enough number of elements:\n```cc\nint64_t OpLevelCostEstimator::CalculateTensorSize(\n    const OpInfo::TensorProperties& tensor, bool* found_unknown_shapes) {\n  int64_t count = CalculateTensorElementCount(tensor, found_unknown_shapes);\n  int size = DataTypeSize(BaseType(tensor.dtype()));\n  VLOG(2) << \"Count: \" << count << \" DataTypeSize: \" << size;\n  return count * size;\n}\n```\nHere, `count` and `size` can be large enough to cause `count * size` to overflow.\n\n### Patches\nWe have patched the issue in GitHub commit [fcd18ce3101f245b083b30655c27b239dc72221e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/fcd18ce3101f245b083b30655c27b239dc72221e).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/fcd18ce3101f245b083b30655c27b239dc72221e",
            "commit_sha":"fcd18ce3101f245b083b30655c27b239dc72221e",
            "patch":"SINGLE",
            "chain_ord":"['fcd18ce3101f245b083b30655c27b239dc72221e']",
            "before_first_fix_commit":"{'29e899868d77d8f575907515acefa012c5574246'}",
            "last_fix_commit":"fcd18ce3101f245b083b30655c27b239dc72221e",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/09\/2021, 22:54:52",
            "message":"Prevent integer overflow in `OpLevelCostEstimator::CalculateTensorSize`.\n\nIn order to not change the API, we return a negative value in case of overflow. A better fix is to change the API to return a status instead.\n\nPiperOrigin-RevId: 408713061\nChange-Id: I3771475b0c72a2844a3854086966562fd33f2da5",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 1, 'total': 8}",
            "files":"{'tensorflow\/core\/grappler\/costs\/op_level_cost_estimator.cc': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/fcd18ce3101f245b083b30655c27b239dc72221e\/tensorflow%2Fcore%2Fgrappler%2Fcosts%2Fop_level_cost_estimator.cc', 'patch': '@@ -1555,7 +1555,13 @@ int64_t OpLevelCostEstimator::CalculateTensorSize(\\n   int64_t count = CalculateTensorElementCount(tensor, found_unknown_shapes);\\n   int size = DataTypeSize(BaseType(tensor.dtype()));\\n   VLOG(2) << \"Count: \" << count << \" DataTypeSize: \" << size;\\n-  return count * size;\\n+  int64_t tensor_size = MultiplyWithoutOverflow(count, size);\\n+  if (tensor_size < 0) {\\n+    VLOG(1) << \"Overflow encountered when computing tensor size, multiplying \"\\n+            << count << \" with \" << size;\\n+    return -1;\\n+  }\\n+  return tensor_size;\\n }\\n \\n int64_t OpLevelCostEstimator::CalculateInputSize(const OpInfo& op_info,'}}",
            "message_norm":"prevent integer overflow in `oplevelcostestimator::calculatetensorsize`.\n\nin order to not change the api, we return a negative value in case of overflow. a better fix is to change the api to return a status instead.\n\npiperorigin-revid: 408713061\nchange-id: i3771475b0c72a2844a3854086966562fd33f2da5",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('integer overflow', 'SECWORD', ''), ('change', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('change', 'ACTION', ''), ('408713061', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/grappler\/costs\/op_level_cost_estimator.cc'])",
            "num_files":1.0
        },
        {
            "index":164,
            "vuln_id":"GHSA-2xgj-xhgf-ggjv",
            "cwe_id":"{'CWE-120'}",
            "score":3.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `BandedTriangularSolve` ### Impact\nAn attacker can trigger a heap buffer overflow in Eigen implementation of `tf.raw_ops.BandedTriangularSolve`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n  \nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_array = np.array([1,1])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)\ntf.raw_ops.BandedTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc#L269-L278) calls `ValidateInputTensors` for input validation but fails to validate that the two tensors are not empty:\n  \n```cc\nvoid ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0, const Tensor& in1) {\n  OP_REQUIRES(\n      ctx, in0.dims() >= 2, \n      errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n\n  OP_REQUIRES(\n      ctx, in1.dims() >= 2,\n      errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1.dims()));\n}\n``` \n\nFurthermore, since `OP_REQUIRES` macro only stops execution of current function after setting `ctx->status()` to a non-OK value, callers of helper functions that use `OP_REQUIRES` must check value of `ctx->status()` before continuing. This doesn't happen [in this op's implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc#L219), hence the validation that is present is also not effective.\n\n### Patches\nWe have patched the issue in GitHub commit [ba6822bd7b7324ba201a28b2f278c29a98edbef2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2) followed by GitHub commit [0ab290774f91a23bebe30a358fde4e53ab4876a0](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ye Zhang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0",
            "commit_sha":"0ab290774f91a23bebe30a358fde4e53ab4876a0",
            "patch":"MULTI",
            "chain_ord":"['ba6822bd7b7324ba201a28b2f278c29a98edbef2', '0ab290774f91a23bebe30a358fde4e53ab4876a0']",
            "before_first_fix_commit":"{'327ef310be67923824814e85e13007e9699f4e0d'}",
            "last_fix_commit":"0ab290774f91a23bebe30a358fde4e53ab4876a0",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/12\/2021, 01:36:43",
            "message":"Ensure validation sticks in banded_triangular_solve_op\n\nPiperOrigin-RevId: 373275480\nChange-Id: Id7717cf275b2d6fdb9441fbbe166d555182d2e79",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/0ab290774f91a23bebe30a358fde4e53ab4876a0\/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fbanded_triangular_solve_op.cc', 'patch': '@@ -217,6 +217,7 @@ class BandedTriangularSolveOpCpu : public OpKernel {\\n     const Tensor& in1 = ctx->input(1);\\n \\n     ValidateInputTensors(ctx, in0, in1);\\n+    if (!ctx->status().ok()) return;\\n \\n     MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\\n     OP_REQUIRES('}}",
            "message_norm":"ensure validation sticks in banded_triangular_solve_op\n\npiperorigin-revid: 373275480\nchange-id: id7717cf275b2d6fdb9441fbbe166d555182d2e79",
            "language":"en",
            "entities":"[('ensure', 'ACTION', ''), ('373275480', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc'])",
            "num_files":1.0
        },
        {
            "index":903,
            "vuln_id":"GHSA-6vqp-h455-42mr",
            "cwe_id":"{'CWE-789'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/apache\/pdfbox\/commit\/8c47be1011c11dc47300faecffd8ab32fba3646f'}",
            "dataset":"osv",
            "summary":"Uncontrolled Memory Allocation in Apache PDFBox A carefully crafted PDF file can trigger an OutOfMemory-Exception while loading the file. This issue affects Apache PDFBox version 2.0.22 and prior 2.0.x versions.",
            "published_date":"2021-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/pdfbox",
            "commit_href":"https:\/\/github.com\/apache\/pdfbox\/commit\/8c47be1011c11dc47300faecffd8ab32fba3646f",
            "commit_sha":"8c47be1011c11dc47300faecffd8ab32fba3646f",
            "patch":"SINGLE",
            "chain_ord":"['8c47be1011c11dc47300faecffd8ab32fba3646f']",
            "before_first_fix_commit":"{'ef53b45f111c4e391faf1c331c4e81a21e24c0b8'}",
            "last_fix_commit":"8c47be1011c11dc47300faecffd8ab32fba3646f",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/07\/2021, 13:18:31",
            "message":"PDFBOX-5112: SonarCube fix, throw NoSuchElementException if no more elements are available\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/pdfbox\/branches\/2.0@1887295 13f79535-47bb-0310-9956-ffa450edef68",
            "author":"Andreas Lehmk\u00fchler",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'pdfbox\/src\/main\/java\/org\/apache\/pdfbox\/pdfparser\/PDFXrefStreamParser.java': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/pdfbox\/raw\/8c47be1011c11dc47300faecffd8ab32fba3646f\/pdfbox%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fpdfbox%2Fpdfparser%2FPDFXrefStreamParser.java', 'patch': '@@ -19,6 +19,7 @@\\n import java.io.IOException;\\n import java.util.Arrays;\\n import java.util.Iterator;\\n+import java.util.NoSuchElementException;\\n \\n import org.apache.pdfbox.cos.COSArray;\\n import org.apache.pdfbox.cos.COSBase;\\n@@ -212,6 +213,10 @@ public boolean hasNext()\\n         @Override\\n         public Long next()\\n         {\\n+            if (currentNumber >= maxValue)\\n+            {\\n+                throw new NoSuchElementException();\\n+            }\\n             if (currentNumber < currentEnd)\\n             {\\n                 return currentNumber++;'}}",
            "message_norm":"pdfbox-5112: sonarcube fix, throw nosuchelementexception if no more elements are available\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/pdfbox\/branches\/2.0@1887295 13f79535-47bb-0310-9956-ffa450edef68",
            "language":"en",
            "entities":"[('sonarcube', 'DETECTION', ''), ('https:\/\/svn.apache.org\/repos\/asf\/pdfbox\/branches\/2.0@1887295', 'URL', ''), ('13f79535', 'SHA', 'generic_sha'), ('ffa450edef68', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['pdfbox\/src\/main\/java\/org\/apache\/pdfbox\/pdfparser\/PDFXrefStreamParser.java'])",
            "num_files":1.0
        },
        {
            "index":1616,
            "vuln_id":"GHSA-cvpc-8phh-8f45",
            "cwe_id":"{'CWE-787', 'CWE-125'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/00302787b788c5ff04cb6f62aed5a74d936e86c0', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e11f55585f614645b360563072ffeb5c3eeff162', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/46d5b0852528ddfd614ded79bccc75589f801bd9', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1970c2158b1ffa416d159d03c3370b9a462aee35', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/fff2c8326280c07733828f990548979bdc893859'}",
            "dataset":"osv",
            "summary":"Out of bounds access in tensorflow-lite ### Impact\nIn TensorFlow Lite, saved models in the flatbuffer format use a double indexing scheme: a model has a set of subgraphs, each subgraph has a set of operators and each operator has a set of input\/output tensors. The flatbuffer format uses indices for the tensors, indexing into an array of tensors that is owned by the subgraph. This results in a pattern of double array indexing when trying to get the data of each tensor:https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/kernels\/kernel_util.cc#L36\n\nHowever, some operators can have some tensors be optional. To handle this scenario, the flatbuffer model uses a negative `-1` value as index for these tensors:\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/c\/common.h#L82\n\nThis results in special casing during validation at model loading time: https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/core\/subgraph.cc#L566-L580\n\nUnfortunately, this means that the `-1` index is a valid tensor index for any operator, including those that don't expect optional inputs and including for output tensors. Thus, this allows writing and reading from outside the bounds of heap allocated arrays, although only at a specific offset from the start of these arrays.\n\nThis results in both read and write gadgets, albeit very limited in scope.\n\n### Patches\nWe have patched the issue in several commits (46d5b0852, 00302787b7, e11f5558, cd31fd0ce, 1970c21, and fff2c83). We will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### Workarounds\nA potential workaround would be to add a custom `Verifier` to the model loading code to ensure that only operators which accept optional inputs use the `-1` special value and only for the tensors that they expect to be optional. Since this allow-list type approach is erro-prone, we advise upgrading to the patched code.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2020-09-25",
            "chain_len":6,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f",
            "commit_sha":"cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f",
            "patch":"MULTI",
            "chain_ord":"['46d5b0852528ddfd614ded79bccc75589f801bd9', '00302787b788c5ff04cb6f62aed5a74d936e86c0', 'e11f55585f614645b360563072ffeb5c3eeff162', 'cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'fff2c8326280c07733828f990548979bdc893859', '1970c2158b1ffa416d159d03c3370b9a462aee35']",
            "before_first_fix_commit":"{'fff2c8326280c07733828f990548979bdc893859'}",
            "last_fix_commit":"1970c2158b1ffa416d159d03c3370b9a462aee35",
            "chain_ord_pos":4.0,
            "commit_datetime":"09\/18\/2020, 20:44:32",
            "message":"[tflite]: Insert `nullptr` checks when obtaining tensors.\n\nAs part of ongoing refactoring, `tflite::GetInput`, `tflite::GetOutput`, `tflite::GetTemporary` and `tflite::GetIntermediates` will return `nullptr` in some cases. Hence, we insert the `nullptr` checks on all usages.\n\nWe also insert `nullptr` checks on usages of `tflite::GetVariableInput` and `tflite::GetOptionalInputTensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\nPiperOrigin-RevId: 332518902\nChange-Id: I92eb164a6101ac3cca66090061a9b56a97288236",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 7, 'total': 23}",
            "files":"{'tensorflow\/lite\/micro\/test_helpers.cc': {'additions': 16, 'deletions': 7, 'changes': 23, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f\/tensorflow%2Flite%2Fmicro%2Ftest_helpers.cc', 'patch': '@@ -601,7 +601,8 @@ TfLiteStatus SimpleStatefulOp::Prepare(TfLiteContext* context,\\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\\n \\n   \/\/ Make sure that the input is in uint8_t with at least 1 data entry.\\n-  const TfLiteTensor* input = tflite::GetInput(context, node, kInputTensor);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\\n   if (input->type != kTfLiteUInt8) return kTfLiteError;\\n   if (NumElements(input->dims) == 0) return kTfLiteError;\\n \\n@@ -622,7 +623,8 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\\n   *data->invoke_count += 1;\\n \\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\\n   const uint8_t* input_data = GetTensorData<uint8_t>(input);\\n   int size = NumElements(input->dims);\\n \\n@@ -641,9 +643,13 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\\n     }\\n   }\\n \\n-  TfLiteTensor* median = GetOutput(context, node, kMedianTensor);\\n+  TfLiteTensor* median;\\n+  TF_LITE_ENSURE_OK(context,\\n+                    GetOutputSafe(context, node, kMedianTensor, &median));\\n   uint8_t* median_data = GetTensorData<uint8_t>(median);\\n-  TfLiteTensor* invoke_count = GetOutput(context, node, kInvokeCount);\\n+  TfLiteTensor* invoke_count;\\n+  TF_LITE_ENSURE_OK(context,\\n+                    GetOutputSafe(context, node, kInvokeCount, &invoke_count));\\n   int32_t* invoke_count_data = GetTensorData<int32_t>(invoke_count);\\n \\n   median_data[0] = sorting_buffer[size \/ 2];\\n@@ -681,11 +687,14 @@ TfLiteStatus MockCustom::Prepare(TfLiteContext* context, TfLiteNode* node) {\\n }\\n \\n TfLiteStatus MockCustom::Invoke(TfLiteContext* context, TfLiteNode* node) {\\n-  const TfLiteTensor* input = tflite::GetInput(context, node, 0);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\\n   const int32_t* input_data = input->data.i32;\\n-  const TfLiteTensor* weight = tflite::GetInput(context, node, 1);\\n+  const TfLiteTensor* weight;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &weight));\\n   const uint8_t* weight_data = weight->data.uint8;\\n-  TfLiteTensor* output = GetOutput(context, node, 0);\\n+  TfLiteTensor* output;\\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\\n   int32_t* output_data = output->data.i32;\\n   output_data[0] =\\n       0;  \/\/ Catch output tensor sharing memory with an input tensor'}}",
            "message_norm":"[tflite]: insert `nullptr` checks when obtaining tensors.\n\nas part of ongoing refactoring, `tflite::getinput`, `tflite::getoutput`, `tflite::gettemporary` and `tflite::getintermediates` will return `nullptr` in some cases. hence, we insert the `nullptr` checks on all usages.\n\nwe also insert `nullptr` checks on usages of `tflite::getvariableinput` and `tflite::getoptionalinputtensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\npiperorigin-revid: 332518902\nchange-id: i92eb164a6101ac3cca66090061a9b56a97288236",
            "language":"en",
            "entities":"[('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('332518902', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/micro\/test_helpers.cc'])",
            "num_files":1.0
        },
        {
            "index":1252,
            "vuln_id":"GHSA-8rmh-55h4-93h5",
            "cwe_id":"{'CWE-22'}",
            "score":7.2,
            "chain":"{'https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199'}",
            "dataset":"osv",
            "summary":"DSpace ItemImportService API Vulnerable to Path Traversal in Simple Archive Format Package Import ### Impact\nItemImportServiceImpl is vulnerable to a path traversal vulnerability. This means a malicious SAF (simple archive format) package could cause a file\/directory to be created anywhere the Tomcat\/DSpace user can write to on the server.  However, this path traversal vulnerability is only possible by a user with special privileges (either Administrators or someone with command-line access to the server).  This vulnerability impacts the XMLUI, JSPUI and command-line.\n\n_This vulnerability does NOT impact 7.x._\n\n### Patches\n\n_DSpace 6.x:_ \n* Fixed in 6.4 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0\n* 6.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0.patch (may be applied manually if an immediate upgrade to 6.4 or 7.x is not possible)\n\n_DSpace 5.x:_\n* Fixed in 5.11 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199\n* 5.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/56e76049185bbd87c994128a9d77735ad7af0199.patch (may be applied manually if an immediate upgrade to 5.11 or 6.4 or 7.x is not possible)\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs \/ configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### Workarounds\n\nAs a basic workaround, you may block all access to the following URL paths:\n* If you are using the XMLUI, block all access to `\/admin\/batchimport` path (this is the URL of the Admin Batch Import tool). Keep in mind, if your site uses the path \"\/xmlui\", then you'd need to block access to `\/xmlui\/admin\/batchimport`.\n* If you are using the JSPUI, block all access to `\/dspace-admin\/batchimport` path (this is the URL of the Admin Batch Import tool).  Keep in mind, if your site uses the path \"\/jspui\", then you'd need to block access to `\/jspui\/dspace-admin\/batchimport`.\n\nKeep in mind, only an Administrative user or a user with command-line access to the server is able to import\/upload SAF packages. Therefore, assuming those users do not blindly upload untrusted SAF packages, then it is unlikely your site could be impacted by this vulnerability.\n\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
            "published_date":"2022-08-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/DSpace\/DSpace",
            "commit_href":"https:\/\/github.com\/DSpace\/DSpace\/commit\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0",
            "commit_sha":"7af52a0883a9dbc475cf3001f04ed11b24c8a4c0",
            "patch":"MULTI",
            "chain_ord":"['7af52a0883a9dbc475cf3001f04ed11b24c8a4c0', '56e76049185bbd87c994128a9d77735ad7af0199']",
            "before_first_fix_commit":"{'73cdff26fdc40bb022e21dcfdeefebf28057cde7'}",
            "last_fix_commit":"56e76049185bbd87c994128a9d77735ad7af0199",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/08\/2020, 00:44:54",
            "message":"[DS-4131] Fix zip import handling to avoid path traversal exploit",
            "author":"Kim Shepherd",
            "comments":null,
            "stats":"{'additions': 36, 'deletions': 7, 'total': 43}",
            "files":"{'dspace-api\/src\/main\/java\/org\/dspace\/app\/itemimport\/ItemImportServiceImpl.java': {'additions': 36, 'deletions': 7, 'changes': 43, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DSpace\/DSpace\/raw\/7af52a0883a9dbc475cf3001f04ed11b24c8a4c0\/dspace-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fdspace%2Fapp%2Fitemimport%2FItemImportServiceImpl.java', 'patch': '@@ -55,6 +55,8 @@\\n import javax.xml.transform.TransformerException;\\n import java.io.*;\\n import java.net.URL;\\n+import java.nio.file.Path;\\n+import java.nio.file.Paths;\\n import java.sql.SQLException;\\n import java.text.SimpleDateFormat;\\n import java.util.*;\\n@@ -1630,26 +1632,36 @@ public String unzip(File zipfile, String destDir) throws IOException {\\n         {\\n             log.error(\"Zip file \\'\" + zipfile.getAbsolutePath() + \"\\' does not exist, or is not readable.\");\\n         }\\n+        log.debug(\"Extracting zip at \" + zipfile.getAbsolutePath());\\n \\n         String destinationDir = destDir;\\n         if (destinationDir == null){\\n         \\tdestinationDir = tempWorkDir;\\n         }\\n+        log.debug(\"Using directory \" + destinationDir + \" for zip extraction. (destDir arg is \" + destDir +\\n+                \", tempWorkDir is \" + tempWorkDir + \")\");\\n \\n         File tempdir = new File(destinationDir);\\n         if (!tempdir.isDirectory())\\n         {\\n-            log.error(\"\\'\" + ConfigurationManager.getProperty(\"org.dspace.app.itemexport.work.dir\") +\\n-                    \"\\' as defined by the key \\'org.dspace.app.itemexport.work.dir\\' in dspace.cfg \" +\\n+            log.error(\"\\'\" + ConfigurationManager.getProperty(\"org.dspace.app.batchitemexport.work.dir\") +\\n+                    \"\\' as defined by the key \\'org.dspace.app.batchitemexport.work.dir\\' in dspace.cfg \" +\\n                     \"is not a valid directory\");\\n         }\\n \\n         if (!tempdir.exists() && !tempdir.mkdirs())\\n         {\\n             log.error(\"Unable to create temporary directory: \" + tempdir.getAbsolutePath());\\n         }\\n-        String sourcedir = destinationDir + System.getProperty(\"file.separator\") + zipfile.getName();\\n-        String zipDir = destinationDir + System.getProperty(\"file.separator\") + zipfile.getName() + System.getProperty(\"file.separator\");\\n+\\n+        if(!destinationDir.endsWith(System.getProperty(\"file.separator\"))) {\\n+            destinationDir += System.getProperty(\"file.separator\");\\n+        }\\n+\\n+        String sourcedir = destinationDir + zipfile.getName();\\n+        String zipDir = destinationDir + zipfile.getName() + System.getProperty(\"file.separator\");\\n+\\n+        log.debug(\"zip directory to use is \" + zipDir);\\n \\n \\n         \/\/ 3\\n@@ -1660,11 +1672,27 @@ public String unzip(File zipfile, String destDir) throws IOException {\\n         while (entries.hasMoreElements())\\n         {\\n             entry = entries.nextElement();\\n+            \/\/ Check that the true path to extract files is never outside allowed temp directories\\n+            \/\/ without creating any actual files on disk\\n+            log.debug(\"Inspecting entry name: \" + entry.getName() + \" for path traversal security\");\\n+            File potentialExtract = new File(zipDir + entry.getName());\\n+            String canonicalPath = potentialExtract.getCanonicalPath();\\n+            log.debug(\"Canonical path to potential File is \" + canonicalPath);\\n+            if(!canonicalPath.startsWith(zipDir)) {\\n+                log.error(\"Rejecting zip file: \" + zipfile.getName() + \" as it contains an entry that would be extracted \" +\\n+                        \"outside the temporary unzip directory: \" + canonicalPath);\\n+                throw new IOException(\"Error extracting \" + zipfile + \": Canonical path of zip entry: \" +\\n+                        entry.getName() + \" (\" + canonicalPath + \") does not start with permissible temp unzip directory (\" + destinationDir +\\n+                        \")\");\\n+            }\\n+\\n             if (entry.isDirectory())\\n             {\\n-                if (!new File(zipDir + entry.getName()).mkdir())\\n-                {\\n+                \/\/ Log error and throw IOException if a directory entry could not be created\\n+                File newDir = new File(zipDir + entry.getName());\\n+                if (!newDir.mkdirs()) {\\n                     log.error(\"Unable to create contents directory: \" + zipDir + entry.getName());\\n+                    throw new IOException(\"Unable to create contents directory: \" + zipDir + entry.getName());\\n                 }\\n             }\\n             else\\n@@ -1673,6 +1701,7 @@ public String unzip(File zipfile, String destDir) throws IOException {\\n                 log.info(\"Extracting file: \" + entry.getName());\\n \\n                 int index = entry.getName().lastIndexOf(\\'\/\\');\\n+                log.debug(\"Index of \" + entry.getName() + \" is \" + index);\\n                 if (index == -1)\\n                 {\\n                     \/\/ Was it created on Windows instead?\\n@@ -1701,11 +1730,11 @@ public String unzip(File zipfile, String destDir) throws IOException {\\n                         }\\n                     }\\n \\n-\\n                 }\\n                 byte[] buffer = new byte[1024];\\n                 int len;\\n                 InputStream in = zf.getInputStream(entry);\\n+                log.debug(\"Reading \" + zipDir + entry.getName() + \" into InputStream\");\\n                 BufferedOutputStream out = new BufferedOutputStream(\\n                         new FileOutputStream(zipDir + entry.getName()));\\n                 while((len = in.read(buffer)) >= 0)'}}",
            "message_norm":"[ds-4131] fix zip import handling to avoid path traversal exploit",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('path traversal', 'SECWORD', ''), ('exploit', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dspace-api\/src\/main\/java\/org\/dspace\/app\/itemimport\/ItemImportServiceImpl.java'])",
            "num_files":1.0
        },
        {
            "index":1013,
            "vuln_id":"GHSA-7cqx-92hp-x6wh",
            "cwe_id":"{'CWE-787', 'CWE-119'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/63c6a29d0f2d692b247f7bf81f8732d6442fad09'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `MaxPool3DGradGrad` ### Impact\nThe implementation of `tf.raw_ops.MaxPool3DGradGrad` is vulnerable to a heap buffer overflow: \n\n```python\nimport tensorflow as tf\n\nvalues = [0.01] * 11\norig_input = tf.constant(values, shape=[11, 1, 1, 1, 1], dtype=tf.float32)\norig_output = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([0.01], shape=[1, 1, 1, 1, 1], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.MaxPool3DGradGrad(\n    orig_input=orig_input, orig_output=orig_output, grad=grad, ksize=ksize,\n    strides=strides, padding=padding)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/596c05a159b6fbb9e39ca10b3f7753b7244fa1e9\/tensorflow\/core\/kernels\/pooling_ops_3d.cc#L694-L696) does not check that the initialization of `Pool3dParameters` completes successfully:\n\n```cc\nPool3dParameters params{context,  ksize_,       stride_,\n                        padding_, data_format_, tensor_in.shape()};\n```\n\nSince [the constructor](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/596c05a159b6fbb9e39ca10b3f7753b7244fa1e9\/tensorflow\/core\/kernels\/pooling_ops_3d.cc#L48-L88) uses `OP_REQUIRES` to validate conditions, the first assertion that fails interrupts the initialization of `params`, making it contain invalid data. In turn, this might cause a heap buffer overflow, depending on default initialized values.\n\n### Patches\nWe have patched the issue in GitHub commit [63c6a29d0f2d692b247f7bf81f8732d6442fad09](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/63c6a29d0f2d692b247f7bf81f8732d6442fad09).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/63c6a29d0f2d692b247f7bf81f8732d6442fad09",
            "commit_sha":"63c6a29d0f2d692b247f7bf81f8732d6442fad09",
            "patch":"SINGLE",
            "chain_ord":"['63c6a29d0f2d692b247f7bf81f8732d6442fad09']",
            "before_first_fix_commit":"{'596c05a159b6fbb9e39ca10b3f7753b7244fa1e9'}",
            "last_fix_commit":"63c6a29d0f2d692b247f7bf81f8732d6442fad09",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 01:07:02",
            "message":"Add missing validation, prevent heap OOB\n\nPiperOrigin-RevId: 372246723\nChange-Id: I1a454a643810e77d7d14821b342098c56a09fbbf",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'tensorflow\/core\/kernels\/pooling_ops_3d.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/63c6a29d0f2d692b247f7bf81f8732d6442fad09\/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc', 'patch': '@@ -693,6 +693,7 @@ class MaxPooling3dGradGradOp : public OpKernel {\\n \\n     Pool3dParameters params{context,  ksize_,       stride_,\\n                             padding_, data_format_, tensor_in.shape()};\\n+    if (!context->status().ok()) return;  \/\/ params is invalid\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\\n@@ -710,6 +711,17 @@ class MaxPooling3dGradGradOp : public OpKernel {\\n         context, out_grad_backprop.NumElements() > 0,\\n         errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",\\n                                 out_grad_backprop.DebugString()));\\n+    OP_REQUIRES(context,\\n+                tensor_in.NumElements() == out_grad_backprop.NumElements(),\\n+                errors::InvalidArgument(\"tensor_in and out_grad_backprop must \"\\n+                                        \"have same number of elements, got <\",\\n+                                        tensor_in.DebugString(), \"> and <\",\\n+                                        out_grad_backprop.DebugString(), \">\"));\\n+    OP_REQUIRES(\\n+        context, tensor_out.NumElements() == output->NumElements(),\\n+        errors::InvalidArgument(\\n+            \"tensor_out and output must have same number of elements, got <\",\\n+            tensor_out.DebugString(), \"> and <\", output->DebugString(), \">\"));\\n \\n     LaunchMaxPooling3dGradGradOp<Device, T>::launch(\\n         context, params, tensor_in, tensor_out, out_grad_backprop, output);'}}",
            "message_norm":"add missing validation, prevent heap oob\n\npiperorigin-revid: 372246723\nchange-id: i1a454a643810e77d7d14821b342098c56a09fbbf",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('372246723', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/pooling_ops_3d.cc'])",
            "num_files":1.0
        },
        {
            "index":2380,
            "vuln_id":"GHSA-m87f-9fvv-2mgg",
            "cwe_id":"{'CWE-502'}",
            "score":8.4,
            "chain":"{'https:\/\/github.com\/facebookresearch\/ParlAI\/commit\/4374fa2aba383db6526ab36e939eb1cf8ef99879', 'https:\/\/github.com\/facebookresearch\/ParlAI\/commit\/507d066ef432ea27d3e201da08009872a2f37725'}",
            "dataset":"osv",
            "summary":"Deserialization of Untrusted Data in parlai ### Impact\nDue to use of unsafe YAML deserialization logic, an attacker with the ability to modify local YAML configuration files could provide malicious input, resulting in remote code execution or similar risks.\n\n### Patches\nThe issue can be patched by upgrading to v1.1.0 or later. It can also be patched by replacing YAML deserialization with equivalent safe_load calls.\n\n### References\n\n- https:\/\/github.com\/facebookresearch\/ParlAI\/commit\/507d066ef432ea27d3e201da08009872a2f37725\n- https:\/\/github.com\/facebookresearch\/ParlAI\/commit\/4374fa2aba383db6526ab36e939eb1cf8ef99879\n- https:\/\/anon-artist.github.io\/blogs\/blog3.html",
            "published_date":"2021-09-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/facebookresearch\/ParlAI",
            "commit_href":"https:\/\/github.com\/facebookresearch\/ParlAI\/commit\/507d066ef432ea27d3e201da08009872a2f37725",
            "commit_sha":"507d066ef432ea27d3e201da08009872a2f37725",
            "patch":"MULTI",
            "chain_ord":"['507d066ef432ea27d3e201da08009872a2f37725', '4374fa2aba383db6526ab36e939eb1cf8ef99879']",
            "before_first_fix_commit":"{'15fbf55f32e64722c452c907425e10fdb977f62e'}",
            "last_fix_commit":"4374fa2aba383db6526ab36e939eb1cf8ef99879",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/26\/2021, 21:06:01",
            "message":"RCE Fixed (#3402)\n\nCo-authored-by: Anon-Artist <61599526+Anon-Artist@users.noreply.github.com>\r\nCo-authored-by: Jamie Slome <jamie@418sec.com>",
            "author":"huntr.dev | the place to protect open source",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'parlai\/chat_service\/utils\/config.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/facebookresearch\/ParlAI\/raw\/507d066ef432ea27d3e201da08009872a2f37725\/parlai%2Fchat_service%2Futils%2Fconfig.py', 'patch': '@@ -36,7 +36,7 @@ def parse_configuration_file(config_path):\\n     result = {}\\n     result[\"configs\"] = {}\\n     with open(config_path) as f:\\n-        cfg = yaml.load(f.read(), Loader=yaml.FullLoader)\\n+        cfg = yaml.load(f.read(), Loader=yaml.SafeLoader)\\n         # get world path\\n         result[\"world_path\"] = cfg.get(\"world_module\")\\n         if not result[\"world_path\"]:'}}",
            "message_norm":"rce fixed (#3402)\n\nco-authored-by: anon-artist <61599526+anon-artist@users.noreply.github.com>\r\nco-authored-by: jamie slome <jamie@418sec.com>",
            "language":"en",
            "entities":"[('fixed', 'ACTION', ''), ('#3402', 'ISSUE', ''), ('jamie@418sec.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['parlai\/chat_service\/utils\/config.py'])",
            "num_files":1.0
        },
        {
            "index":3112,
            "vuln_id":"GHSA-vg44-fw64-cpjx",
            "cwe_id":"{'CWE-287'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/commit\/f32e529d13a53e55f558d903534d631846dc26ce'}",
            "dataset":"osv",
            "summary":"Incorrect Account Used for Signing ### Impact\n\nAnybody using this library to sign with a BIP44 account other than the first account may be affected. If a user is signing with the first account (i.e. the account at index `0`), or with the legacy MEW\/MyCrypto HD path, they are not affected.\n\nThe vulnerability impacts cases where the user signs a personal message or transaction without first adding the account. This includes cases where the user has already added the account in a previous session (i.e. they added the account, reset the application, then signed something). The serialization\/deserialization process does restore a previously added account, but it doesn&#39;t restore the index instructing the keyring to use that account for signing. As a result, after serializing then deserializing the keyring state, the account at index `0` is always used for signing even if it isn&#39;t the current account.\n\n### Patches\n\nThis has been patched ([#14](https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/pull\/14)) in version &gt;=0.2.1 of [`eth-ledger-bridge-keyring`](https:\/\/www.npmjs.com\/package\/eth-ledger-bridge-keyring), and in version &gt;=0.2.2 of [`@metamask\/eth-ledger-bridge-keyring`](https:\/\/www.npmjs.com\/package\/@metamask\/eth-ledger-bridge-keyring). Users are encouraged to migrate to the new package name.\n\n### Workarounds\n\nTo work around this problem without updating, you should remove then re-add the account before use. As long as the account was added during the lifetime of that process, signing with that account should work correctly.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [MetaMask\/eth-ledger-bridge-keyring on GitHub](https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring)\n* Email the MetaMask team at [hello@metamask.io](mailto:hello@metamask.io)",
            "published_date":"2020-03-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring",
            "commit_href":"https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/commit\/f32e529d13a53e55f558d903534d631846dc26ce",
            "commit_sha":"f32e529d13a53e55f558d903534d631846dc26ce",
            "patch":"SINGLE",
            "chain_ord":"['f32e529d13a53e55f558d903534d631846dc26ce']",
            "before_first_fix_commit":"{'25d96289bdffb369a70cbafd70b4ca1f1be47fcc'}",
            "last_fix_commit":"f32e529d13a53e55f558d903534d631846dc26ce",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/02\/2020, 22:58:21",
            "message":"Always sign transactions and messages with the correct account (#14)\n\nThe account used to sign transactions and messages should be the one\r\nthe transaction or message is from. Instead, the last connected account\r\nwas being used to sign any messages or transactions.\r\n\r\nThis was especially problematic considering the last connected account\r\nwas not persisted, meaning that signatures were being performed with\r\nthe wrong account after a reset (unless the last connected account\r\nhappened to be account 0, which was the default).\r\n\r\nA mapping of addresses to indexes as been added to the keyring state,\r\nand this mapping has been persisted. This should ensure the correct\r\naccount index is used, and thus the correct hd path, each time this\r\nkeyring is used for signing.",
            "author":"Mark Stacey",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 2, 'total': 17}",
            "files":"{'index.js': {'additions': 15, 'deletions': 2, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/MetaMask\/eth-ledger-bridge-keyring\/raw\/f32e529d13a53e55f558d903534d631846dc26ce\/index.js', 'patch': \"@@ -18,6 +18,7 @@ const NETWORK_API_URLS = {\\n class LedgerBridgeKeyring extends EventEmitter {\\n   constructor (opts = {}) {\\n     super()\\n+    this.accountIndexes = {}\\n     this.bridgeUrl = null\\n     this.type = type\\n     this.page = 0\\n@@ -36,6 +37,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n     return Promise.resolve({\\n       hdPath: this.hdPath,\\n       accounts: this.accounts,\\n+      accountIndexes: this.accountIndexes,\\n       bridgeUrl: this.bridgeUrl,\\n       implementFullBIP44: false,\\n     })\\n@@ -45,6 +47,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n     this.hdPath = opts.hdPath || hdPathString\\n     this.bridgeUrl = opts.bridgeUrl || BRIDGE_URL\\n     this.accounts = opts.accounts || []\\n+    this.accountIndexes = opts.accountIndexes || {}\\n     this.implementFullBIP44 = opts.implementFullBIP44 || false\\n     return Promise.resolve()\\n   }\\n@@ -100,6 +103,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n             if (this._isBIP44()) {\\n               const path = this._getPathForIndex(i)\\n               address = await this.unlock(path)\\n+              this.accountIndexes[ethUtil.toChecksumAddress(address)] = i\\n             } else {\\n               address = this._addressFromIndex(pathBase, i)\\n             }\\n@@ -136,6 +140,7 @@ class LedgerBridgeKeyring extends EventEmitter {\\n       throw new Error(`Address ${address} not found in this keyring`)\\n     }\\n     this.accounts = this.accounts.filter(a => a.toLowerCase() !== address.toLowerCase())\\n+    delete this.accountIndexes[ethUtil.toChecksumAddress(address)]\\n   }\\n \\n   \/\/ tx is an instance of the ethereumjs-transaction class.\\n@@ -150,7 +155,11 @@ class LedgerBridgeKeyring extends EventEmitter {\\n \\n           let hdPath\\n           if (this._isBIP44()) {\\n-            hdPath = this._getPathForIndex(this.unlockedAccount)\\n+            const checksummedAddress = ethUtil.toChecksumAddress(address)\\n+            if (!this.accountIndexes[checksummedAddress]) {\\n+              reject(new Error(`Ledger: Index for address '${checksummedAddress}' not found`))\\n+            }\\n+            hdPath = this._getPathForIndex(this.accountIndexes[checksummedAddress])\\n           } else {\\n             hdPath = this._toLedgerPath(this._pathFromAddress(address))\\n           }\\n@@ -195,7 +204,11 @@ class LedgerBridgeKeyring extends EventEmitter {\\n         .then(_ => {\\n           let hdPath\\n           if (this._isBIP44()) {\\n-            hdPath = this._getPathForIndex(this.unlockedAccount)\\n+            const checksummedAddress = ethUtil.toChecksumAddress(withAccount)\\n+            if (!this.accountIndexes[checksummedAddress]) {\\n+              reject(new Error(`Ledger: Index for address '${checksummedAddress}' not found`))\\n+            }\\n+            hdPath = this._getPathForIndex(this.accountIndexes[checksummedAddress])\\n           } else {\\n             hdPath = this._toLedgerPath(this._pathFromAddress(withAccount))\\n           }\"}}",
            "message_norm":"always sign transactions and messages with the correct account (#14)\n\nthe account used to sign transactions and messages should be the one\r\nthe transaction or message is from. instead, the last connected account\r\nwas being used to sign any messages or transactions.\r\n\r\nthis was especially problematic considering the last connected account\r\nwas not persisted, meaning that signatures were being performed with\r\nthe wrong account after a reset (unless the last connected account\r\nhappened to be account 0, which was the default).\r\n\r\na mapping of addresses to indexes as been added to the keyring state,\r\nand this mapping has been persisted. this should ensure the correct\r\naccount index is used, and thus the correct hd path, each time this\r\nkeyring is used for signing.",
            "language":"en",
            "entities":"[('#14', 'ISSUE', ''), ('added', 'ACTION', ''), ('keyring', 'SECWORD', ''), ('ensure', 'ACTION', ''), ('keyring', 'SECWORD', ''), ('signing', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":962,
            "vuln_id":"GHSA-75c5-f4gw-38r9",
            "cwe_id":"{'CWE-74'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/pear\/Archive_Tar\/commit\/0670a05fdab997036a3fc3ef113b8f5922e574da'}",
            "dataset":"osv",
            "summary":"Multiple vulnerabilities through filename manipulation in Archive_Tar Archive_Tar through 1.4.10 has :\/\/ filename sanitization only to address phar attacks, and thus any other stream-wrapper attack (such as file:\/\/ to overwrite files) can still succeed. See: https:\/\/github.com\/pear\/Archive_Tar\/issues\/33",
            "published_date":"2021-04-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/pear\/Archive_Tar",
            "commit_href":"https:\/\/github.com\/pear\/Archive_Tar\/commit\/0670a05fdab997036a3fc3ef113b8f5922e574da",
            "commit_sha":"0670a05fdab997036a3fc3ef113b8f5922e574da",
            "patch":"SINGLE",
            "chain_ord":"['0670a05fdab997036a3fc3ef113b8f5922e574da']",
            "before_first_fix_commit":"{'bbb4f10f71a1da2715ec6d9a683f4f23c507a49b'}",
            "last_fix_commit":"0670a05fdab997036a3fc3ef113b8f5922e574da",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/19\/2020, 08:52:43",
            "message":"Fixes #33 - ensure we catch additional malicious\/crafted filenames",
            "author":"Michiel Rook",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'Archive\/Tar.php': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pear\/Archive_Tar\/raw\/0670a05fdab997036a3fc3ef113b8f5922e574da\/Archive%2FTar.php', 'patch': '@@ -1730,7 +1730,7 @@ public function _readHeader($v_binary_data, &$v_header)\\n \\n         \/\/ ----- Extract the properties\\n         $v_header[\\'filename\\'] = rtrim($v_data[\\'filename\\'], \"\\\\0\");\\n-        if ($this->_maliciousFilename($v_header[\\'filename\\'])) {\\n+        if ($this->_isMaliciousFilename($v_header[\\'filename\\'])) {\\n             $this->_error(\\n                 \\'Malicious .tar detected, file \"\\' . $v_header[\\'filename\\'] .\\n                 \\'\" will not install in desired directory tree\\'\\n@@ -1800,9 +1800,9 @@ private function _tarRecToSize($tar_size)\\n      *\\n      * @return bool\\n      *\/\\n-    private function _maliciousFilename($file)\\n+    private function _isMaliciousFilename($file)\\n     {\\n-        if (strpos($file, \\'phar:\/\/\\') === 0) {\\n+        if (strpos($file, \\':\/\/\\') !== false) {\\n             return true;\\n         }\\n         if (strpos($file, \\'..\/\\') !== false || strpos($file, \\'..\\\\\\\\\\') !== false) {\\n@@ -1838,7 +1838,7 @@ public function _readLongHeader(&$v_header)\\n \\n         $v_filename = rtrim(substr($v_filename, 0, $v_filesize), \"\\\\0\");\\n         $v_header[\\'filename\\'] = $v_filename;\\n-        if ($this->_maliciousFilename($v_filename)) {\\n+        if ($this->_isMaliciousFilename($v_filename)) {\\n             $this->_error(\\n                 \\'Malicious .tar detected, file \"\\' . $v_filename .\\n                 \\'\" will not install in desired directory tree\\''}}",
            "message_norm":"fixes #33 - ensure we catch additional malicious\/crafted filenames",
            "language":"en",
            "entities":"[('fixes', 'ACTION', ''), ('#33', 'ISSUE', ''), ('ensure', 'ACTION', ''), ('malicious', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Archive\/Tar.php'])",
            "num_files":1.0
        },
        {
            "index":3349,
            "vuln_id":"GHSA-x2mc-8fgj-3wmr",
            "cwe_id":"{'CWE-20'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/mafintosh\/tar-fs\/commit\/06672828e6fa29ac8551b1b6f36c852a9a3c58a2'}",
            "dataset":"osv",
            "summary":"Improper Input Validation in tar-fs A vulnerability was found in tar-fs before 1.16.2. An Arbitrary File Overwrite issue exists when extracting a tarball containing a hardlink to a file that already exists on the system, in conjunction with a later plain file with the same name as the hardlink. This plain file content replaces the existing file content.",
            "published_date":"2019-05-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/mafintosh\/tar-fs",
            "commit_href":"https:\/\/github.com\/mafintosh\/tar-fs\/commit\/06672828e6fa29ac8551b1b6f36c852a9a3c58a2",
            "commit_sha":"06672828e6fa29ac8551b1b6f36c852a9a3c58a2",
            "patch":"SINGLE",
            "chain_ord":"['06672828e6fa29ac8551b1b6f36c852a9a3c58a2']",
            "before_first_fix_commit":"{'7b4ab17e950832cfd3e67421e48898fdb50318fc'}",
            "last_fix_commit":"06672828e6fa29ac8551b1b6f36c852a9a3c58a2",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/30\/2018, 11:20:56",
            "message":"force hardlink targets to be in the tar",
            "author":"Mathias Buus",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mafintosh\/tar-fs\/raw\/06672828e6fa29ac8551b1b6f36c852a9a3c58a2\/index.js', 'patch': \"@@ -261,7 +261,7 @@ exports.extract = function (cwd, opts) {\\n     var onlink = function () {\\n       if (win32) return next() \/\/ skip links on win for now before it can be tested\\n       xfs.unlink(name, function () {\\n-        var srcpath = path.resolve(cwd, header.linkname)\\n+        var srcpath = path.join(cwd, path.join('\/', header.linkname))\\n \\n         xfs.link(srcpath, name, function (err) {\\n           if (err && err.code === 'EPERM' && opts.hardlinkAsFilesFallback) {\"}}",
            "message_norm":"force hardlink targets to be in the tar",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":720,
            "vuln_id":"GHSA-5xjx-4xcm-hpcm",
            "cwe_id":"{'CWE-1321', 'CWE-915'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/BadOPCode\/NoDash\/commit\/b9cc2b3b49f6cd5228e406bc57e17a28b998fea5'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in ts-nodash `ts-nodash` before version 1.2.7 is vulnerable to Prototype Pollution via the Merge() function due to lack of validation input.",
            "published_date":"2021-12-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/BadOPCode\/NoDash",
            "commit_href":"https:\/\/github.com\/BadOPCode\/NoDash\/commit\/b9cc2b3b49f6cd5228e406bc57e17a28b998fea5",
            "commit_sha":"b9cc2b3b49f6cd5228e406bc57e17a28b998fea5",
            "patch":"SINGLE",
            "chain_ord":"['b9cc2b3b49f6cd5228e406bc57e17a28b998fea5']",
            "before_first_fix_commit":"{'78f4ffab4ed76c43f6f7fb91d8b329acb0d6e684'}",
            "last_fix_commit":"b9cc2b3b49f6cd5228e406bc57e17a28b998fea5",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/11\/2021, 02:50:07",
            "message":"Security fix for Prototype Pollution (#20)\n\nCo-authored-by: Arjun Shibu <arjunshibu1999@gmail.com>\r\nCo-authored-by: Jamie Slome <jamie@418sec.com>\r\nCo-authored-by: Shawn <BadOPCode@users.noreply.github.com>",
            "author":"huntr.dev | the place to protect open source",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 1, 'total': 7}",
            "files":"{'src\/Merge.ts': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/BadOPCode\/NoDash\/raw\/b9cc2b3b49f6cd5228e406bc57e17a28b998fea5\/src%2FMerge.ts', 'patch': '@@ -47,13 +47,18 @@ const  handleDefaultBehavior = (originalObject: any, newObject: any, behavior?:\\n     if (originalTypeName === \"Object\" && newTypeName === \"Object\") { \/\/ built-in behavior\\n         \/\/ tslint:disable:forin\\n         for (const p in newObject) {\\n+            if (isPrototypePolluted(p)) continue\\n             originalObject[p] = processBehavior(originalObject[p], newObject[p], behavior);\\n         }\\n         \/\/ tslint:enable:forin\\n         return originalObject;\\n     }\\n };\\n \\n+const isPrototypePolluted = (key: any) => {\\n+    return [\\'__proto__\\', \\'constructor\\', \\'prototype\\'].includes(key)\\n+}\\n+\\n \/**\\n  * Recursively merge two objects together.\\n  * @param originalObject The base object. Properties here will be overwritten\\n@@ -72,7 +77,7 @@ export const Merge = (originalObject: any, newObject: any, behavior?: IMergeBeha\\n             return definedBehaviorResults;\\n         }\\n     }\\n-\\n+    \\n     return handleDefaultBehavior(originalObject, newObject, behavior);\\n };'}}",
            "message_norm":"security fix for prototype pollution (#20)\n\nco-authored-by: arjun shibu <arjunshibu1999@gmail.com>\r\nco-authored-by: jamie slome <jamie@418sec.com>\r\nco-authored-by: shawn <badopcode@users.noreply.github.com>",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('prototype pollution', 'SECWORD', ''), ('#20', 'ISSUE', ''), ('arjunshibu1999@gmail.com', 'EMAIL', ''), ('jamie@418sec.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Merge.ts'])",
            "num_files":1.0
        },
        {
            "index":585,
            "vuln_id":"GHSA-5875-p652-2ppm",
            "cwe_id":"{'CWE-668'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/76361264d9fdfff38a1af79c63141455cc4d36e3'}",
            "dataset":"osv",
            "summary":"Exposure of Resource to Wrong Sphere in microweber Exposure of Resource to Wrong Sphere in microweber prior to 1.3 allows users to add deleted products to a cart and buy it.",
            "published_date":"2022-02-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/76361264d9fdfff38a1af79c63141455cc4d36e3",
            "commit_sha":"76361264d9fdfff38a1af79c63141455cc4d36e3",
            "patch":"SINGLE",
            "chain_ord":"['76361264d9fdfff38a1af79c63141455cc4d36e3']",
            "before_first_fix_commit":"{'cc5947c83f05f5490c9190d4a68dc199461b34e3'}",
            "last_fix_commit":"76361264d9fdfff38a1af79c63141455cc4d36e3",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/25\/2022, 09:43:45",
            "message":"check product is deleted before add to cart",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 0, 'total': 14}",
            "files":"{'src\/MicroweberPackages\/Cart\/CartManager.php': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/76361264d9fdfff38a1af79c63141455cc4d36e3\/src%2FMicroweberPackages%2FCart%2FCartManager.php', 'patch': \"@@ -565,7 +565,21 @@ public function update_cart($data)\\n         }\\n \\n         if ($data['for'] == 'content') {\\n+\\n             $cont = $this->app->content_manager->get_by_id($for_id);\\n+\\n+            if (isset($cont['is_active'])) {\\n+                if ($cont['is_active'] != 1) {\\n+                    $cont = false;\\n+                }\\n+            }\\n+\\n+            if (isset($cont['is_deleted'])) {\\n+                if ($cont['is_deleted'] > 0) {\\n+                    $cont = false;\\n+                }\\n+            }\\n+\\n             $cont_data = $this->app->content_manager->data($for_id);\\n             if ($cont == false) {\\n                 return array('error' => 'Invalid product?');\"}}",
            "message_norm":"check product is deleted before add to cart",
            "language":"en",
            "entities":null,
            "classification_level_1":"POORLY_DOCUMENTED",
            "classification_level_2":"REDUNDANT_MESSAGE",
            "list_files":"dict_keys(['src\/MicroweberPackages\/Cart\/CartManager.php'])",
            "num_files":1.0
        },
        {
            "index":1573,
            "vuln_id":"GHSA-cmgw-8vpc-rc59",
            "cwe_id":"{'CWE-20'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8721ba96e5760c229217b594f6d2ba332beedf22'}",
            "dataset":"osv",
            "summary":"Segfault on strings tensors with mistmatched dimensions, due to Go code ### Impact\nUnder certain conditions, Go code can trigger a segfault in string deallocation.\n\n\nFor string tensors, `C.TF_TString_Dealloc` is called during garbage collection within a finalizer function.  However, tensor structure isn't checked until encoding to avoid a performance penalty.  The current method for dealloc assumes that encoding succeeded, but segfaults when a string tensor is garbage collected whose encoding failed (e.g., due to mismatched dimensions).\n\nTo fix this, the call to set the finalizer function is deferred until `NewTensor` returns and, if encoding failed for a string tensor, deallocs are determined based on bytes written.\n\n### Patches\nWe have patched the issue in GitHub commit [8721ba96e5760c229217b594f6d2ba332beedf22](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8721ba96e5760c229217b594f6d2ba332beedf22) (merging [#50508](https:\/\/github.com\/tensorflow\/tensorflow\/pull\/50508)).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, which is the other affected version.                                                                                                                                               \n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [fixing PR](https:\/\/github.com\/tensorflow\/tensorflow\/pull\/50508).",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8721ba96e5760c229217b594f6d2ba332beedf22",
            "commit_sha":"8721ba96e5760c229217b594f6d2ba332beedf22",
            "patch":"SINGLE",
            "chain_ord":"['8721ba96e5760c229217b594f6d2ba332beedf22']",
            "before_first_fix_commit":"{'5a14b2e21e2026b0838f892fed43c4c0e4b3c299', '49499c17794b39a2a7d5be2b477ed7d5704d0629'}",
            "last_fix_commit":"8721ba96e5760c229217b594f6d2ba332beedf22",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/13\/2021, 22:13:47",
            "message":"Merge pull request #50508 from wamuir:fix-tstring-dealloc\n\nPiperOrigin-RevId: 384557722\nChange-Id: I72858edf72952fd4e7e0a1d9776c9408a7081d42",
            "author":"TensorFlower Gardener",
            "comments":null,
            "stats":"{'additions': 17, 'deletions': 13, 'total': 30}",
            "files":"{'tensorflow\/go\/tensor.go': {'additions': 17, 'deletions': 13, 'changes': 30, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/8721ba96e5760c229217b594f6d2ba332beedf22\/tensorflow%2Fgo%2Ftensor.go', 'patch': '@@ -98,9 +98,9 @@ func NewTensor(value interface{}) (*Tensor, error) {\\n \\n \\traw := tensorData(t.c)\\n \\n-\\truntime.SetFinalizer(t, func(t *Tensor) {\\n+\\tdefer runtime.SetFinalizer(t, func(t *Tensor) {\\n \\t\\tif dataType == String {\\n-\\t\\t\\tt.clearTStrings(raw, nflattened)\\n+\\t\\t\\tt.clearTStrings(raw, int64(nbytes\/C.sizeof_TF_TString))\\n \\t\\t}\\n \\n \\t\\tt.finalize()\\n@@ -111,15 +111,18 @@ func NewTensor(value interface{}) (*Tensor, error) {\\n \\tif isAllArray(val.Type()) {\\n \\t\\t\/\/ We have arrays all the way down, or just primitive types. We can\\n \\t\\t\/\/ just copy the memory in as it is all contiguous.\\n-\\t\\tif err := copyPtr(buf, unpackEFace(value).data, int(val.Type().Size())); err != nil {\\n+\\t\\tif _, err := copyPtr(buf, unpackEFace(value).data, int(val.Type().Size())); err != nil {\\n \\t\\t\\treturn nil, err\\n \\t\\t}\\n \\t} else {\\n \\t\\t\/\/ When there are slices involved the memory for each leaf slice may\\n \\t\\t\/\/ not be contiguous with the others or in the order we might\\n \\t\\t\/\/ expect, so we need to work our way down to each slice of\\n \\t\\t\/\/ primitives and copy them individually\\n-\\t\\tif err := encodeTensorWithSlices(buf, val, shape); err != nil {\\n+\\t\\tif n, err := encodeTensorWithSlices(buf, val, shape); err != nil {\\n+\\t\\t\\t\/\/ Set nbytes to count of bytes written for deferred call to\\n+\\t\\t\\t\/\/ runtime.SetFinalizer\\n+\\t\\t\\tnbytes = uintptr(n)\\n \\t\\t\\treturn nil, err\\n \\t\\t}\\n \\t}\\n@@ -486,13 +489,13 @@ func sizeVarUint(v uint64) int {\\n \\n \/\/ encodeTensorWithSlices writes v to the specified buffer using the format specified in\\n \/\/ c_api.h. Use stringEncoder for String tensors.\\n-func encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) error {\\n+func encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) (int, error) {\\n \\t\/\/ If current dimension is a slice, verify that it has the expected size\\n \\t\/\/ Go\\'s type system makes that guarantee for arrays.\\n \\tif v.Kind() == reflect.Slice {\\n \\t\\texpected := int(shape[0])\\n \\t\\tif v.Len() != expected {\\n-\\t\\t\\treturn fmt.Errorf(\"mismatched slice lengths: %d and %d\", v.Len(), expected)\\n+\\t\\t\\treturn 0, fmt.Errorf(\"mismatched slice lengths: %d and %d\", v.Len(), expected)\\n \\t\\t}\\n \\t} else if v.Kind() == reflect.String {\\n \\t\\ts := v.Interface().(string)\\n@@ -501,7 +504,7 @@ func encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) err\\n \\t\\tptr := unsafe.Pointer(&tstr)\\n \\t\\treturn copyPtr(w, ptr, C.sizeof_TF_TString)\\n \\t} else if v.Kind() != reflect.Array {\\n-\\t\\treturn fmt.Errorf(\"unsupported type %v\", v.Type())\\n+\\t\\treturn 0, fmt.Errorf(\"unsupported type %v\", v.Type())\\n \\t}\\n \\n \\t\/\/ Once we have just a single dimension we can just copy the data\\n@@ -514,15 +517,17 @@ func encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) err\\n \\t\\treturn copyPtr(w, ptr, v.Len()*int(elt.Type().Size()))\\n \\t}\\n \\n+\\tn := 0\\n \\tsubShape := shape[1:]\\n \\tfor i := 0; i < v.Len(); i++ {\\n-\\t\\terr := encodeTensorWithSlices(w, v.Index(i), subShape)\\n+\\t\\tj, err := encodeTensorWithSlices(w, v.Index(i), subShape)\\n \\t\\tif err != nil {\\n-\\t\\t\\treturn err\\n+\\t\\t\\treturn n + j, err\\n \\t\\t}\\n+\\t\\tn += j\\n \\t}\\n \\n-\\treturn nil\\n+\\treturn n, nil\\n }\\n \\n \/\/ It isn\\'t safe to use reflect.SliceHeader as it uses a uintptr for Data and\\n@@ -536,15 +541,14 @@ type sliceHeader struct {\\n \/\/ copyPtr copies the backing data for a slice or array directly into w. Note\\n \/\/ we don\\'t need to worry about byte ordering because we want the natural byte\\n \/\/ order for the machine we\\'re running on.\\n-func copyPtr(w *bytes.Buffer, ptr unsafe.Pointer, l int) error {\\n+func copyPtr(w *bytes.Buffer, ptr unsafe.Pointer, l int) (int, error) {\\n \\t\/\/ Convert our slice header into a []byte so we can call w.Write\\n \\tb := *(*[]byte)(unsafe.Pointer(&sliceHeader{\\n \\t\\tData: ptr,\\n \\t\\tLen:  l,\\n \\t\\tCap:  l,\\n \\t}))\\n-\\t_, err := w.Write(b)\\n-\\treturn err\\n+\\treturn w.Write(b)\\n }\\n \\n func bug(format string, args ...interface{}) error {'}}",
            "message_norm":"merge pull request #50508 from wamuir:fix-tstring-dealloc\n\npiperorigin-revid: 384557722\nchange-id: i72858edf72952fd4e7e0a1d9776c9408a7081d42",
            "language":"en",
            "entities":"[('#50508', 'ISSUE', ''), ('384557722', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/go\/tensor.go'])",
            "num_files":1.0
        },
        {
            "index":2588,
            "vuln_id":"GHSA-ph87-fvjr-v33w",
            "cwe_id":"{'CWE-617'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/31bd5026304677faa8a0b77602c6154171b9aec1'}",
            "dataset":"osv",
            "summary":"CHECK-fail in `tf.raw_ops.RFFT` ### Impact\nAn attacker can cause a denial of service by exploiting a `CHECK`-failure coming from the implementation of `tf.raw_ops.RFFT`:\n    \n```python\nimport tensorflow as tf\n\ninputs = tf.constant([1], shape=[1], dtype=tf.float32)\nfft_length = tf.constant([0], shape=[1], dtype=tf.int32)\n\ntf.raw_ops.RFFT(input=inputs, fft_length=fft_length)\n```\n\nThe above example causes Eigen code to operate on an empty matrix. This triggers on an assertion and causes program termination.\n    \n### Patches\nWe have patched the issue in GitHub commit [31bd5026304677faa8a0b77602c6154171b9aec1](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/31bd5026304677faa8a0b77602c6154171b9aec1).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/31bd5026304677faa8a0b77602c6154171b9aec1",
            "commit_sha":"31bd5026304677faa8a0b77602c6154171b9aec1",
            "patch":"SINGLE",
            "chain_ord":"['31bd5026304677faa8a0b77602c6154171b9aec1']",
            "before_first_fix_commit":"{'1c56f53be0b722ca657cbc7df461ed676c8642a2'}",
            "last_fix_commit":"31bd5026304677faa8a0b77602c6154171b9aec1",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 00:42:54",
            "message":"Prevent check fail in FFT\n\nPiperOrigin-RevId: 372031044\nChange-Id: I50994e3e8a5d1342d01bde80256f6bf2730ca299",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/fft_ops.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/31bd5026304677faa8a0b77602c6154171b9aec1\/tensorflow%2Fcore%2Fkernels%2Ffft_ops.cc', 'patch': '@@ -222,6 +222,9 @@ class FFTCPU : public FFTBase {\\n       input_slice_sizes[i] = fft_shape[i - 1];\\n       temp_shape.AddDim(fft_shape[i - 1]);\\n     }\\n+    OP_REQUIRES(ctx, temp_shape.num_elements() > 0,\\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\\n+                                        temp_shape.DebugString()));\\n \\n     auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\\n     const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;'}}",
            "message_norm":"prevent check fail in fft\n\npiperorigin-revid: 372031044\nchange-id: i50994e3e8a5d1342d01bde80256f6bf2730ca299",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('372031044', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/fft_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":463,
            "vuln_id":"GHSA-4q97-fh3f-j294",
            "cwe_id":"{'CWE-1321'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/tiny-conf\/tiny-conf\/commit\/1f7be78bc68927996647cd45b4367f8975a3ea05'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in tiny-conf All versions of package tiny-conf up to and including version 1.1.0 are vulnerable to Prototype Pollution via the set function.",
            "published_date":"2021-05-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tiny-conf\/tiny-conf",
            "commit_href":"https:\/\/github.com\/tiny-conf\/tiny-conf\/commit\/1f7be78bc68927996647cd45b4367f8975a3ea05",
            "commit_sha":"1f7be78bc68927996647cd45b4367f8975a3ea05",
            "patch":"SINGLE",
            "chain_ord":"['1f7be78bc68927996647cd45b4367f8975a3ea05']",
            "before_first_fix_commit":"{'c4d8b44ab53b9810b76a04caec249762d8c7fbc7', 'c1f4181bc3583fff49fe6e34c6e745479c569eb2'}",
            "last_fix_commit":"1f7be78bc68927996647cd45b4367f8975a3ea05",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/01\/2020, 08:21:02",
            "message":"Merge pull request #1 from d3m0n-r00t\/master\n\nFixed prototype pollution",
            "author":"Maxime Tricoire",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tiny-conf.js': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tiny-conf\/tiny-conf\/raw\/1f7be78bc68927996647cd45b4367f8975a3ea05\/tiny-conf.js', 'patch': \"@@ -44,6 +44,9 @@ Store.prototype = {\\n    * @return {boolean} true if set; false otherwise\\n    *\/\\n   set: function (key, val) {\\n+    if (key.includes('__proto__') || key.includes('prototype') || key.includes('constructor')){\\n+      return undefined;\\n+    }\\n     if (val === undefined) {\\n       val = key;\\n       key = null;\"}}",
            "message_norm":"merge pull request #1 from d3m0n-r00t\/master\n\nfixed prototype pollution",
            "language":"en",
            "entities":"[('#1', 'ISSUE', ''), ('fixed', 'ACTION', ''), ('prototype pollution', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tiny-conf.js'])",
            "num_files":1.0
        },
        {
            "index":2534,
            "vuln_id":"GHSA-p885-prv3-m4xv",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/f211c11034baf4281aa62e7b5e0347248d995ee9'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in snipe-it Stored Cross Site Scripting vulnerability in Item name parameter in GitHub repository snipe\/snipe-it prior to v5.4.3. The vulnerability is capable of stolen the user Cookie.",
            "published_date":"2022-04-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/f211c11034baf4281aa62e7b5e0347248d995ee9",
            "commit_sha":"f211c11034baf4281aa62e7b5e0347248d995ee9",
            "patch":"SINGLE",
            "chain_ord":"['f211c11034baf4281aa62e7b5e0347248d995ee9']",
            "before_first_fix_commit":"{'698c7f4904f8fd843c5b9761053c9c68819ec288', '7479f5f12d73f73d9bc8c479651e0e5602ad1791'}",
            "last_fix_commit":"f211c11034baf4281aa62e7b5e0347248d995ee9",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/15\/2022, 11:25:56",
            "message":"Merge pull request #10942 from snipe\/fixes\/xss_user_requested\n\nFixes potential XSS vuln in user requestable results",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 5, 'total': 10}",
            "files":"{'app\/Http\/Controllers\/Api\/ProfileController.php': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/f211c11034baf4281aa62e7b5e0347248d995ee9\/app%2FHttp%2FControllers%2FApi%2FProfileController.php', 'patch': \"@@ -30,11 +30,11 @@ public function requestedAssets()\\n             \/\/ Make sure the asset and request still exist\\n             if ($checkoutRequest && $checkoutRequest->itemRequested()) {\\n                 $results['rows'][] = [\\n-                    'image' => $checkoutRequest->itemRequested()->present()->getImageUrl(),\\n-                    'name' => $checkoutRequest->itemRequested()->present()->name(),\\n-                    'type' => $checkoutRequest->itemType(),\\n-                    'qty' => $checkoutRequest->quantity,\\n-                    'location' => ($checkoutRequest->location()) ? $checkoutRequest->location()->name : null,\\n+                    'image' => e($checkoutRequest->itemRequested()->present()->getImageUrl()),\\n+                    'name' => e($checkoutRequest->itemRequested()->present()->name()),\\n+                    'type' => e($checkoutRequest->itemType()),\\n+                    'qty' => (int) $checkoutRequest->quantity,\\n+                    'location' => ($checkoutRequest->location()) ? e($checkoutRequest->location()->name) : null,\\n                     'expected_checkin' => Helper::getFormattedDateObject($checkoutRequest->itemRequested()->expected_checkin, 'datetime'),\\n                     'request_date' => Helper::getFormattedDateObject($checkoutRequest->created_at, 'datetime'),\\n                 ];\"}}",
            "message_norm":"merge pull request #10942 from snipe\/fixes\/xss_user_requested\n\nfixes potential xss vuln in user requestable results",
            "language":"ca",
            "entities":"[('#10942', 'ISSUE', ''), ('xss_user_requested', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/Api\/ProfileController.php'])",
            "num_files":1.0
        },
        {
            "index":791,
            "vuln_id":"GHSA-68wm-pfjf-wqp6",
            "cwe_id":"{'CWE-287'}",
            "score":10.0,
            "chain":"{'https:\/\/github.com\/authelia\/authelia\/commit\/c62dbd43d6e69ae81530e7c4f8763857f8ff1dda'}",
            "dataset":"osv",
            "summary":"Authentication bypassed with malformed request URI on nginx ### Impact\nThis affects uses who are using nginx ngx_http_auth_request_module with Authelia, it allows a malicious individual who crafts a malformed HTTP request to bypass the authentication mechanism. It additionally could theoretically affect other proxy servers, but all of the ones we officially support except nginx do not allow malformed URI paths.\n\n### Patches\nThe problem is rectified entirely in v4.29.3. As this patch is relatively straightforward we can back port this to any version upon request. Alternatively we are supplying a git patch to 4.25.1 which should be relatively straightforward to apply to any version, the git patches for specific versions can be found below.\n\n<details><summary>Patch for 4.25.1:<\/summary><p>\n\n```patch\nFrom ca22f3d2c44ca7bef043ffbeeb06d6659c1d550f Mon Sep 17 00:00:00 2001\nFrom: James Elliott <james-d-elliott@users.noreply.github.com>\nDate: Wed, 19 May 2021 12:10:13 +1000\nSubject: [PATCH] fix(handlers): verify returns 200 on malformed request\n\nThis is a git patch for commit at tag v4.25.1 to address a potential method to bypass authentication in proxies that forward malformed information to Authelia in the forward auth process. Instead of returning a 200 this ensures that Authelia returns a 401 when this occurs.\n---\n internal\/handlers\/handler_verify.go | 4 +++-\n 1 file changed, 3 insertions(+), 1 deletion(-)\n\ndiff --git a\/internal\/handlers\/handler_verify.go b\/internal\/handlers\/handler_verify.go\nindex 65c064ce..4dd9702d 100644\n--- a\/internal\/handlers\/handler_verify.go\n+++ b\/internal\/handlers\/handler_verify.go\n@@ -396,7 +396,9 @@ func VerifyGet(cfg schema.AuthenticationBackendConfiguration) middlewares.Reques\n \t\ttargetURL, err := getOriginalURL(ctx)\n \n \t\tif err != nil {\n-\t\t\tctx.Error(fmt.Errorf(\"Unable to parse target URL: %s\", err), operationFailedMessage)\n+\t\t\tctx.Logger.Error(fmt.Errorf(\"Unable to parse target URL: %s\", err))\n+\t\t\tctx.ReplyUnauthorized()\n+\n \t\t\treturn\n \t\t}\n \n-- \n2.31.1\n```\n\n<\/p><\/details>\n\n### Workarounds\nThe most relevant workaround is upgrading. **If you need assistance with an upgrade please contact us on [Matrix](https:\/\/riot.im\/app\/#\/room\/#authelia:matrix.org) or [Discord](https:\/\/discord.authelia.com).** Please just let us know you're needing help upgrading to above 4.29.2. \n\nYou can add an block which fails requests that contains a malformed URI in the internal location block. We have crafted one that should work in most instances, it basically checks no chars that are required to be URL-encoded for either the path or the query are in the URI. Basically this regex checks that the characters between the square braces are the only characters in the $request_uri header, if they exist, it returns a HTTP 401 status code. The characters in the regex match are tested to not cause a parsing error that would result in a failure, however they are not exhaustive since query strings seem to not always conform to the RFC.\n\n<details><summary>authelia.conf:<\/summary><p>\n\n```nginx\nlocation \/authelia {\n    internal;\n    # **IMPORTANT**\n    # This block rejects requests with a 401 which contain characters that are unable to be parsed.\n    # It is necessary for security prior to v4.29.3 due to the fact we returned an invalid code in the event of a parser error.\n    # You may comment this section if you're using Authelia v4.29.3 or above. We strongly recommend upgrading.\n    # RFC3986: http:\/\/tools.ietf.org\/html\/rfc3986\n    # Commentary on RFC regarding Query Strings: https:\/\/www.456bereastreet.com\/archive\/201008\/what_characters_are_allowed_unencoded_in_query_strings\/\n    if ($request_uri ~ [^a-zA-Z0-9_+-=\\!@$%&*?~.:#'\\;\\(\\)\\[\\]]) {\n        return 401;\n    }\n\n    # Include the remainder of the block here. \n}\n````\n\n<\/p><\/details>\n\n### Discovery\n\nThis issue was discovered by:\n\nSiemens Energy\nCybersecurity Red Team\n\n- Silas Francisco\n- Ricardo Pesqueira\n\n\n### Identifying active exploitation of the vulnerability\n\nThe following regex should match log entries that are an indication of the vulnerability being exploited:\n```regex\nlevel=error msg=\"Unable to parse target URL: Unable to parse URL (extracted from X-Original-URL header)?.*?: parse.*?net\/url:.*github\\.com\/authelia\/authelia\/internal\/handlers\/handler_verify\\.go\n```\n\nExample log entry ***with*** X-Original-URL configured:\n```log\ntime=\"2021-05-21T16:31:15+10:00\" level=error msg=\"Unable to parse target URL: Unable to parse URL extracted from X-Original-URL header: parse \\\"https:\/\/example.com\/\": net\/url: invalid control character in URL\" method=GET path=\/api\/verify remote_ip=192.168.1.10 stack=\"github.com\/authelia\/authelia\/internal\/middlewares\/authelia_context.go:65 (*AutheliaCtx).Error\\ngithub.com\/authelia\/authelia\/internal\/handlers\/handler_verify.go:431     VerifyGet.func1\\ngithub.com\/authelia\/authelia\/internal\/middlewares\/authelia_context.go:50 AutheliaMiddleware.func1.1\\ngithub.com\/fasthttp\/router@v1.3.12\/router.go:414                         (*Router).Handler\\ngithub.com\/authelia\/authelia\/internal\/middlewares\/log_request.go:14      LogRequestMiddleware.func1\\ngithub.com\/valyala\/fasthttp@v1.24.0\/server.go:2219                       (*Server).serveConn\\ngithub.com\/valyala\/fasthttp@v1.24.0\/workerpool.go:223                    (*workerPool).workerFunc\\ngithub.com\/valyala\/fasthttp@v1.24.0\/workerpool.go:195                    (*workerPool).getCh.func1\\nruntime\/asm_amd64.s:1371                                                 goexit\"\n```\n\nExample log entry ***without*** X-Original-URL configured:\n```log\ntime=\"2021-05-21T16:30:17+10:00\" level=error msg=\"Unable to parse target URL: Unable to parse URL https:\/\/example.com\/: parse \\\"https:\/\/example.com\/\": net\/url: invalid control character in URL\" method=GET path=\/api\/verify remote_ip=192.168.1.10 stack=\"github.com\/authelia\/authelia\/internal\/middlewares\/authelia_context.go:65 (*AutheliaCtx).Error\\ngithub.com\/authelia\/authelia\/internal\/handlers\/handler_verify.go:431     VerifyGet.func1\\ngithub.com\/authelia\/authelia\/internal\/middlewares\/authelia_context.go:50 AutheliaMiddleware.func1.1\\ngithub.com\/fasthttp\/router@v1.3.12\/router.go:414                         (*Router).Handler\\ngithub.com\/authelia\/authelia\/internal\/middlewares\/log_request.go:14      LogRequestMiddleware.func1\\ngithub.com\/valyala\/fasthttp@v1.24.0\/server.go:2219                       (*Server).serveConn\\ngithub.com\/valyala\/fasthttp@v1.24.0\/workerpool.go:223                    (*workerPool).workerFunc\\ngithub.com\/valyala\/fasthttp@v1.24.0\/workerpool.go:195                    (*workerPool).getCh.func1\\nruntime\/asm_amd64.s:1371                                                 goexit\"\n```\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue at [authelia](https:\/\/github.com\/authelia\/authelia\/issues)\n* Email us at [security@authelia.com](mailto:security@authelia.com)",
            "published_date":"2021-12-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/authelia\/authelia",
            "commit_href":"https:\/\/github.com\/authelia\/authelia\/commit\/c62dbd43d6e69ae81530e7c4f8763857f8ff1dda",
            "commit_sha":"c62dbd43d6e69ae81530e7c4f8763857f8ff1dda",
            "patch":"SINGLE",
            "chain_ord":"['c62dbd43d6e69ae81530e7c4f8763857f8ff1dda']",
            "before_first_fix_commit":"{'a56cffa129a0fedb830971855ab695a95cf96312'}",
            "last_fix_commit":"c62dbd43d6e69ae81530e7c4f8763857f8ff1dda",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/21\/2021, 12:03:44",
            "message":"fix(handlers): align response status codes for the verify endpoint (#2016)\n\nThis aligns all response status codes on the \/api\/verify endpoint when an error occurs, making it impossible to determine the actual reason for the failure.",
            "author":"James Elliott",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'internal\/handlers\/handler_verify.go': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/authelia\/authelia\/raw\/c62dbd43d6e69ae81530e7c4f8763857f8ff1dda\/internal%2Fhandlers%2Fhandler_verify.go', 'patch': '@@ -428,7 +428,9 @@ func VerifyGet(cfg schema.AuthenticationBackendConfiguration) middlewares.Reques\\n \\t\\ttargetURL, err := ctx.GetOriginalURL()\\n \\n \\t\\tif err != nil {\\n-\\t\\t\\tctx.Error(fmt.Errorf(\"Unable to parse target URL: %s\", err), operationFailedMessage)\\n+\\t\\t\\tctx.Logger.Error(fmt.Errorf(\"Unable to parse target URL: %s\", err))\\n+\\t\\t\\tctx.ReplyUnauthorized()\\n+\\n \\t\\t\\treturn\\n \\t\\t}'}}",
            "message_norm":"fix(handlers): align response status codes for the verify endpoint (#2016)\n\nthis aligns all response status codes on the \/api\/verify endpoint when an error occurs, making it impossible to determine the actual reason for the failure.",
            "language":"en",
            "entities":"[('fix(handlers', 'ACTION', ''), ('#2016', 'ISSUE', ''), ('verify', 'ACTION', ''), ('error', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['internal\/handlers\/handler_verify.go'])",
            "num_files":1.0
        },
        {
            "index":3386,
            "vuln_id":"GHSA-x6rc-54xp-ccxx",
            "cwe_id":"{'CWE-611'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/apache\/activemq-artemis\/commit\/48d9951d879e0c8cbb59d4b64ab59d53ef88310d'}",
            "dataset":"osv",
            "summary":"Improper Restriction of XML External Entity Reference in Apache ActiveMQ XML external entity (XXE) vulnerability in the XPath selector component in Artemis ActiveMQ before commit 48d9951d879e0c8cbb59d4b64ab59d53ef88310d allows remote attackers to have unspecified impact via unknown vectors.",
            "published_date":"2022-05-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/activemq-artemis",
            "commit_href":"https:\/\/github.com\/apache\/activemq-artemis\/commit\/48d9951d879e0c8cbb59d4b64ab59d53ef88310d",
            "commit_sha":"48d9951d879e0c8cbb59d4b64ab59d53ef88310d",
            "patch":"SINGLE",
            "chain_ord":"['48d9951d879e0c8cbb59d4b64ab59d53ef88310d']",
            "before_first_fix_commit":"{'879f4a6bb3b15dfc3d00bcde2d982194bd2dadc4'}",
            "last_fix_commit":"48d9951d879e0c8cbb59d4b64ab59d53ef88310d",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/21\/2015, 09:49:45",
            "message":"ActiveMQ6-112 Add defaults to the selector parser doc builder",
            "author":"Martyn Taylor",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 4, 'total': 18}",
            "files":"{'artemis-selector\/src\/main\/java\/org\/apache\/activemq\/artemis\/selector\/filter\/XalanXPathEvaluator.java': {'additions': 14, 'deletions': 4, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/activemq-artemis\/raw\/48d9951d879e0c8cbb59d4b64ab59d53ef88310d\/artemis-selector%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Factivemq%2Fartemis%2Fselector%2Ffilter%2FXalanXPathEvaluator.java', 'patch': '@@ -18,6 +18,7 @@\\n \\n import javax.xml.parsers.DocumentBuilder;\\n import javax.xml.parsers.DocumentBuilderFactory;\\n+import javax.xml.parsers.ParserConfigurationException;\\n import java.io.StringReader;\\n \\n import org.apache.xpath.CachedXPathAPI;\\n@@ -56,9 +57,7 @@ protected boolean evaluate(InputSource inputSource)\\n    {\\n       try\\n       {\\n-         DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\\n-         factory.setNamespaceAware(true);\\n-         DocumentBuilder dbuilder = factory.newDocumentBuilder();\\n+         DocumentBuilder dbuilder = createDocumentBuilder();\\n          Document doc = dbuilder.parse(inputSource);\\n \\n          \/\/An XPath expression could return a true or false value instead of a node.\\n@@ -75,11 +74,22 @@ protected boolean evaluate(InputSource inputSource)\\n             NodeIterator iterator = cachedXPathAPI.selectNodeIterator(doc, xpath);\\n             return (iterator.nextNode() != null);\\n          }\\n-\\n       }\\n       catch (Throwable e)\\n       {\\n          return false;\\n       }\\n    }\\n+\\n+   private DocumentBuilder createDocumentBuilder() throws ParserConfigurationException\\n+   {\\n+      DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\\n+      factory.setNamespaceAware(true);\\n+\\n+      factory.setFeature(\"http:\/\/xml.org\/sax\/features\/external-general-entities\", false);\\n+      factory.setFeature(\"http:\/\/xml.org\/sax\/features\/external-parameter-entities\", false);\\n+      factory.setFeature(\"http:\/\/apache.org\/xml\/features\/disallow-doctype-decl\", true);\\n+\\n+      return factory.newDocumentBuilder();\\n+   }\\n }'}}",
            "message_norm":"activemq6-112 add defaults to the selector parser doc builder",
            "language":"en",
            "entities":"[('add', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['artemis-selector\/src\/main\/java\/org\/apache\/activemq\/artemis\/selector\/filter\/XalanXPathEvaluator.java'])",
            "num_files":1.0
        },
        {
            "index":152,
            "vuln_id":"GHSA-2wc6-2rcj-8v76",
            "cwe_id":"{'CWE-1240'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/sodiumoxide\/sodiumoxide\/commit\/24c7a5550807ac8a09648b5878f19d14c3a69135'}",
            "dataset":"osv",
            "summary":"scalarmult() vulnerable to degenerate public keys The `scalarmult()` function included in previous versions of this crate\naccepted all-zero public keys, for which the resulting Diffie-Hellman shared\nsecret will always be zero regardless of the private key used.\n\nThis issue was fixed by checking for this class of keys and rejecting them\nif they are used.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/sodiumoxide\/sodiumoxide",
            "commit_href":"https:\/\/github.com\/sodiumoxide\/sodiumoxide\/commit\/24c7a5550807ac8a09648b5878f19d14c3a69135",
            "commit_sha":"24c7a5550807ac8a09648b5878f19d14c3a69135",
            "patch":"SINGLE",
            "chain_ord":"['24c7a5550807ac8a09648b5878f19d14c3a69135']",
            "before_first_fix_commit":"{'12d49e8ed1b53821465f24312695376eb86c89d2'}",
            "last_fix_commit":"24c7a5550807ac8a09648b5878f19d14c3a69135",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/26\/2017, 19:24:31",
            "message":"Check the return value of `scalarmult()`. Closes #154",
            "author":"Daniel Ashhami",
            "comments":null,
            "stats":"{'additions': 55, 'deletions': 46, 'total': 101}",
            "files":"{'src\/crypto\/scalarmult\/curve25519.rs': {'additions': 55, 'deletions': 46, 'changes': 101, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sodiumoxide\/sodiumoxide\/raw\/24c7a5550807ac8a09648b5878f19d14c3a69135\/src%2Fcrypto%2Fscalarmult%2Fcurve25519.rs', 'patch': '@@ -23,14 +23,20 @@ new_type! {\\n \\n \/\/\/ `scalarmult()` multiplies a group element `p`\\n \/\/\/ by an integer `n`. It returns the resulting group element\\n-\/\/\/ `q`.\\n+\/\/\/ `Ok(q)`.\\n+\/\/\/ If the the `GroupElement` is all zero, `scalarmult()` returns `Err(())` since\\n+\/\/\/ the resulting `GroupElement` would be all zero, no matter the `Scalar`.\\n pub fn scalarmult(&Scalar(ref n): &Scalar,\\n-                  &GroupElement(ref p): &GroupElement) -> GroupElement {\\n+                  &GroupElement(ref p): &GroupElement)\\n+                  -> Result<GroupElement, ()> {\\n     let mut q = [0; GROUPELEMENTBYTES];\\n     unsafe {\\n-        ffi::crypto_scalarmult_curve25519(&mut q, n, p);\\n+        if ffi::crypto_scalarmult_curve25519(&mut q, n, p) != 0 {\\n+            Err(())\\n+        } else {\\n+            Ok(GroupElement(q))\\n+        }\\n     }\\n-    GroupElement(q)\\n }\\n \\n \/\/\/ `scalarmult_base()` computes the scalar product of a standard\\n@@ -47,74 +53,77 @@ pub fn scalarmult_base(&Scalar(ref n): &Scalar) -> GroupElement {\\n #[cfg(test)]\\n mod test {\\n     use super::*;\\n+    use randombytes::randombytes_into;\\n \\n     #[test]\\n     fn test_vector_1() {\\n         \/\/ corresponding to tests\/scalarmult.c and tests\/scalarmult3.cpp from NaCl\\n-        let alicesk = Scalar([0x77,0x07,0x6d,0x0a,0x73,0x18,0xa5,0x7d\\n-                             ,0x3c,0x16,0xc1,0x72,0x51,0xb2,0x66,0x45\\n-                             ,0xdf,0x4c,0x2f,0x87,0xeb,0xc0,0x99,0x2a\\n-                             ,0xb1,0x77,0xfb,0xa5,0x1d,0xb9,0x2c,0x2a]);\\n-        let alicepk_expected = [0x85,0x20,0xf0,0x09,0x89,0x30,0xa7,0x54\\n-                               ,0x74,0x8b,0x7d,0xdc,0xb4,0x3e,0xf7,0x5a\\n-                               ,0x0d,0xbf,0x3a,0x0d,0x26,0x38,0x1a,0xf4\\n-                               ,0xeb,0xa4,0xa9,0x8e,0xaa,0x9b,0x4e,0x6a];\\n+        let alicesk = Scalar([0x77, 0x07, 0x6d, 0x0a, 0x73, 0x18, 0xa5, 0x7d, 0x3c, 0x16, 0xc1,\\n+                              0x72, 0x51, 0xb2, 0x66, 0x45, 0xdf, 0x4c, 0x2f, 0x87, 0xeb, 0xc0,\\n+                              0x99, 0x2a, 0xb1, 0x77, 0xfb, 0xa5, 0x1d, 0xb9, 0x2c, 0x2a]);\\n+        let alicepk_expected = [0x85, 0x20, 0xf0, 0x09, 0x89, 0x30, 0xa7, 0x54, 0x74, 0x8b, 0x7d,\\n+                                0xdc, 0xb4, 0x3e, 0xf7, 0x5a, 0x0d, 0xbf, 0x3a, 0x0d, 0x26, 0x38,\\n+                                0x1a, 0xf4, 0xeb, 0xa4, 0xa9, 0x8e, 0xaa, 0x9b, 0x4e, 0x6a];\\n         let GroupElement(alicepk) = scalarmult_base(&alicesk);\\n         assert!(alicepk == alicepk_expected);\\n     }\\n \\n     #[test]\\n     fn test_vector_2() {\\n         \/\/ corresponding to tests\/scalarmult2.c and tests\/scalarmult4.cpp from NaCl\\n-        let bobsk = Scalar([0x5d,0xab,0x08,0x7e,0x62,0x4a,0x8a,0x4b\\n-                           ,0x79,0xe1,0x7f,0x8b,0x83,0x80,0x0e,0xe6\\n-                           ,0x6f,0x3b,0xb1,0x29,0x26,0x18,0xb6,0xfd\\n-                           ,0x1c,0x2f,0x8b,0x27,0xff,0x88,0xe0,0xeb]);\\n-        let bobpk_expected = [0xde,0x9e,0xdb,0x7d,0x7b,0x7d,0xc1,0xb4\\n-                             ,0xd3,0x5b,0x61,0xc2,0xec,0xe4,0x35,0x37\\n-                             ,0x3f,0x83,0x43,0xc8,0x5b,0x78,0x67,0x4d\\n-                             ,0xad,0xfc,0x7e,0x14,0x6f,0x88,0x2b,0x4f];\\n+        let bobsk = Scalar([0x5d, 0xab, 0x08, 0x7e, 0x62, 0x4a, 0x8a, 0x4b, 0x79, 0xe1, 0x7f,\\n+                            0x8b, 0x83, 0x80, 0x0e, 0xe6, 0x6f, 0x3b, 0xb1, 0x29, 0x26, 0x18,\\n+                            0xb6, 0xfd, 0x1c, 0x2f, 0x8b, 0x27, 0xff, 0x88, 0xe0, 0xeb]);\\n+        let bobpk_expected = [0xde, 0x9e, 0xdb, 0x7d, 0x7b, 0x7d, 0xc1, 0xb4, 0xd3, 0x5b, 0x61,\\n+                              0xc2, 0xec, 0xe4, 0x35, 0x37, 0x3f, 0x83, 0x43, 0xc8, 0x5b, 0x78,\\n+                              0x67, 0x4d, 0xad, 0xfc, 0x7e, 0x14, 0x6f, 0x88, 0x2b, 0x4f];\\n         let GroupElement(bobpk) = scalarmult_base(&bobsk);\\n         assert!(bobpk == bobpk_expected);\\n     }\\n \\n     #[test]\\n     fn test_vector_3() {\\n         \/\/ corresponding to tests\/scalarmult5.c and tests\/scalarmult7.cpp from NaCl\\n-        let alicesk = Scalar([0x77,0x07,0x6d,0x0a,0x73,0x18,0xa5,0x7d\\n-                             ,0x3c,0x16,0xc1,0x72,0x51,0xb2,0x66,0x45\\n-                             ,0xdf,0x4c,0x2f,0x87,0xeb,0xc0,0x99,0x2a\\n-                             ,0xb1,0x77,0xfb,0xa5,0x1d,0xb9,0x2c,0x2a]);\\n-        let bobpk = GroupElement([0xde,0x9e,0xdb,0x7d,0x7b,0x7d,0xc1,0xb4\\n-                                 ,0xd3,0x5b,0x61,0xc2,0xec,0xe4,0x35,0x37\\n-                                 ,0x3f,0x83,0x43,0xc8,0x5b,0x78,0x67,0x4d\\n-                                 ,0xad,0xfc,0x7e,0x14,0x6f,0x88,0x2b,0x4f]);\\n-        let k_expected = [0x4a,0x5d,0x9d,0x5b,0xa4,0xce,0x2d,0xe1\\n-                         ,0x72,0x8e,0x3b,0xf4,0x80,0x35,0x0f,0x25\\n-                         ,0xe0,0x7e,0x21,0xc9,0x47,0xd1,0x9e,0x33\\n-                         ,0x76,0xf0,0x9b,0x3c,0x1e,0x16,0x17,0x42];\\n-        let GroupElement(k) = scalarmult(&alicesk, &bobpk);\\n+        let alicesk = Scalar([0x77, 0x07, 0x6d, 0x0a, 0x73, 0x18, 0xa5, 0x7d, 0x3c, 0x16, 0xc1,\\n+                              0x72, 0x51, 0xb2, 0x66, 0x45, 0xdf, 0x4c, 0x2f, 0x87, 0xeb, 0xc0,\\n+                              0x99, 0x2a, 0xb1, 0x77, 0xfb, 0xa5, 0x1d, 0xb9, 0x2c, 0x2a]);\\n+        let bobpk = GroupElement([0xde, 0x9e, 0xdb, 0x7d, 0x7b, 0x7d, 0xc1, 0xb4, 0xd3, 0x5b,\\n+                                  0x61, 0xc2, 0xec, 0xe4, 0x35, 0x37, 0x3f, 0x83, 0x43, 0xc8,\\n+                                  0x5b, 0x78, 0x67, 0x4d, 0xad, 0xfc, 0x7e, 0x14, 0x6f, 0x88,\\n+                                  0x2b, 0x4f]);\\n+        let k_expected = [0x4a, 0x5d, 0x9d, 0x5b, 0xa4, 0xce, 0x2d, 0xe1, 0x72, 0x8e, 0x3b, 0xf4,\\n+                          0x80, 0x35, 0x0f, 0x25, 0xe0, 0x7e, 0x21, 0xc9, 0x47, 0xd1, 0x9e, 0x33,\\n+                          0x76, 0xf0, 0x9b, 0x3c, 0x1e, 0x16, 0x17, 0x42];\\n+        let GroupElement(k) = scalarmult(&alicesk, &bobpk).unwrap();\\n         assert!(k == k_expected);\\n     }\\n \\n     #[test]\\n     fn test_vector_4() {\\n         \/\/ corresponding to tests\/scalarmult6.c from NaCl\\n-        let bobsk = Scalar([0x5d,0xab,0x08,0x7e,0x62,0x4a,0x8a,0x4b\\n-                           ,0x79,0xe1,0x7f,0x8b,0x83,0x80,0x0e,0xe6\\n-                           ,0x6f,0x3b,0xb1,0x29,0x26,0x18,0xb6,0xfd\\n-                           ,0x1c,0x2f,0x8b,0x27,0xff,0x88,0xe0,0xeb]);\\n-        let alicepk = GroupElement([0x85,0x20,0xf0,0x09,0x89,0x30,0xa7,0x54\\n-                                   ,0x74,0x8b,0x7d,0xdc,0xb4,0x3e,0xf7,0x5a\\n-                                   ,0x0d,0xbf,0x3a,0x0d,0x26,0x38,0x1a,0xf4\\n-                                   ,0xeb,0xa4,0xa9,0x8e,0xaa,0x9b,0x4e,0x6a]);\\n-        let k_expected = [0x4a,0x5d,0x9d,0x5b,0xa4,0xce,0x2d,0xe1\\n-                         ,0x72,0x8e,0x3b,0xf4,0x80,0x35,0x0f,0x25\\n-                         ,0xe0,0x7e,0x21,0xc9,0x47,0xd1,0x9e,0x33\\n-                         ,0x76,0xf0,0x9b,0x3c,0x1e,0x16,0x17,0x42];\\n-        let GroupElement(k) = scalarmult(&bobsk, &alicepk);\\n+        let bobsk = Scalar([0x5d, 0xab, 0x08, 0x7e, 0x62, 0x4a, 0x8a, 0x4b, 0x79, 0xe1, 0x7f,\\n+                            0x8b, 0x83, 0x80, 0x0e, 0xe6, 0x6f, 0x3b, 0xb1, 0x29, 0x26, 0x18,\\n+                            0xb6, 0xfd, 0x1c, 0x2f, 0x8b, 0x27, 0xff, 0x88, 0xe0, 0xeb]);\\n+        let alicepk = GroupElement([0x85, 0x20, 0xf0, 0x09, 0x89, 0x30, 0xa7, 0x54, 0x74, 0x8b,\\n+                                    0x7d, 0xdc, 0xb4, 0x3e, 0xf7, 0x5a, 0x0d, 0xbf, 0x3a, 0x0d,\\n+                                    0x26, 0x38, 0x1a, 0xf4, 0xeb, 0xa4, 0xa9, 0x8e, 0xaa, 0x9b,\\n+                                    0x4e, 0x6a]);\\n+        let k_expected = [0x4a, 0x5d, 0x9d, 0x5b, 0xa4, 0xce, 0x2d, 0xe1, 0x72, 0x8e, 0x3b, 0xf4,\\n+                          0x80, 0x35, 0x0f, 0x25, 0xe0, 0x7e, 0x21, 0xc9, 0x47, 0xd1, 0x9e, 0x33,\\n+                          0x76, 0xf0, 0x9b, 0x3c, 0x1e, 0x16, 0x17, 0x42];\\n+        let GroupElement(k) = scalarmult(&bobsk, &alicepk).unwrap();\\n         assert!(k == k_expected);\\n     }\\n+\\n+    #[test]\\n+    #[should_panic]\\n+    fn test_all_zero() {\\n+        let mut sk = [0; SCALARBYTES];\\n+        randombytes_into(&mut sk);\\n+        let sk = Scalar(sk);\\n+        let pk = GroupElement([0; GROUPELEMENTBYTES]);\\n+        let _ = scalarmult(&sk, &pk).unwrap();\\n+    }\\n }\\n \\n #[cfg(feature = \"benchmarks\")]'}}",
            "message_norm":"check the return value of `scalarmult()`. closes #154",
            "language":"en",
            "entities":"[('#154', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/crypto\/scalarmult\/curve25519.rs'])",
            "num_files":1.0
        },
        {
            "index":498,
            "vuln_id":"GHSA-4vrf-ff7v-hpgr",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f61c57bd425878be108ec787f4d96390579fb83e'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite's implementation of `EmbeddingLookup` The implementation of the `EmbeddingLookup` TFLite operator is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e4b29809543b250bc9b19678ec4776299dd569ba\/tensorflow\/lite\/kernels\/embedding_lookup.cc#L73-L74):\n\n```cc\nconst int row_size = SizeOfDimension(value, 0);\nconst int row_bytes = value->bytes \/ row_size;\n```\n\nAn attacker can craft a model such that the first dimension of the `value` input is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [f61c57bd425878be108ec787f4d96390579fb83e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f61c57bd425878be108ec787f4d96390579fb83e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f61c57bd425878be108ec787f4d96390579fb83e",
            "commit_sha":"f61c57bd425878be108ec787f4d96390579fb83e",
            "patch":"SINGLE",
            "chain_ord":"['f61c57bd425878be108ec787f4d96390579fb83e']",
            "before_first_fix_commit":"{'e4b29809543b250bc9b19678ec4776299dd569ba'}",
            "last_fix_commit":"f61c57bd425878be108ec787f4d96390579fb83e",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 19:57:00",
            "message":"Prevent division by 0\n\nPiperOrigin-RevId: 370966645\nChange-Id: I831bfd96c7eb77b02d7ebb744335f59f6e5728cb",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/lite\/kernels\/embedding_lookup.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f61c57bd425878be108ec787f4d96390579fb83e\/tensorflow%2Flite%2Fkernels%2Fembedding_lookup.cc', 'patch': '@@ -71,6 +71,10 @@ TfLiteStatus EvalSimple(TfLiteContext* context, TfLiteNode* node,\\n                         const TfLiteTensor* lookup, const TfLiteTensor* value,\\n                         TfLiteTensor* output) {\\n   const int row_size = SizeOfDimension(value, 0);\\n+  if (row_size == 0) {\\n+    \/\/ Propagate empty tensor if input is empty\\n+    return kTfLiteOk;\\n+  }\\n   const int row_bytes = value->bytes \/ row_size;\\n \\n   char* output_raw = GetTensorData<char>(output);'}}",
            "message_norm":"prevent division by 0\n\npiperorigin-revid: 370966645\nchange-id: i831bfd96c7eb77b02d7ebb744335f59f6e5728cb",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('370966645', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/embedding_lookup.cc'])",
            "num_files":1.0
        },
        {
            "index":92,
            "vuln_id":"GHSA-2gw2-8q9w-cw8p",
            "cwe_id":"{'CWE-426'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/ffi\/ffi\/commit\/e0fe486df0e117ed67b0282b6ada04b7214ca05c', 'https:\/\/github.com\/ffi\/ffi\/commit\/09e0c6076466b4383da7fa4e13f714311109945a'}",
            "dataset":"osv",
            "summary":"Ruby-ffi has a DLL loading issue  ruby-ffi version 1.9.23 and earlier has a DLL loading issue which can be hijacked on Windows OS, when a Symbol is used as DLL name instead of a String This vulnerability appears to have been fixed in v1.9.24 and later.",
            "published_date":"2018-08-31",
            "chain_len":2,
            "project":"https:\/\/github.com\/ffi\/ffi",
            "commit_href":"https:\/\/github.com\/ffi\/ffi\/commit\/e0fe486df0e117ed67b0282b6ada04b7214ca05c",
            "commit_sha":"e0fe486df0e117ed67b0282b6ada04b7214ca05c",
            "patch":"MULTI",
            "chain_ord":"['e0fe486df0e117ed67b0282b6ada04b7214ca05c', '09e0c6076466b4383da7fa4e13f714311109945a']",
            "before_first_fix_commit":"{'e0fe486df0e117ed67b0282b6ada04b7214ca05c'}",
            "last_fix_commit":"09e0c6076466b4383da7fa4e13f714311109945a",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/01\/2018, 20:18:25",
            "message":"Don't treat Symbol args different to Strings in ffi_lib\n\nSymbols were sent directly to FFI::DynamicLibrary.open in the first\nattempt, resulting in a TypeError, so that only the mangled library\nname was actually loaded.\n\nThis moves conversion to String to the front, so that subsequent\ncalls can assume Strings only.",
            "author":"Lars Kanis",
            "comments":"{'com_1': {'author': 'Cbeg-76', 'datetime': '08\/23\/2019, 15:31:30', 'body': 'gem install ffi'}}",
            "stats":"{'additions': 1, 'deletions': 3, 'total': 4}",
            "files":"{'lib\/ffi\/library.rb': {'additions': 1, 'deletions': 3, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ffi\/ffi\/raw\/e0fe486df0e117ed67b0282b6ada04b7214ca05c\/lib%2Fffi%2Flibrary.rb', 'patch': '@@ -43,7 +43,6 @@ module FFI\\n   #  FFI.map_library_name \\'jpeg\\'  # -> \"jpeg.dll\"\\n   def self.map_library_name(lib)\\n     # Mangle the library name to reflect the native library naming conventions\\n-    lib = lib.to_s unless lib.kind_of?(String)\\n     lib = Library::LIBC if lib == \\'c\\'\\n \\n     if lib && File.basename(lib) == lib\\n@@ -103,7 +102,7 @@ def ffi_lib(*names)\\n           FFI::DynamicLibrary.open(nil, FFI::DynamicLibrary::RTLD_LAZY | FFI::DynamicLibrary::RTLD_LOCAL)\\n \\n         else\\n-          libnames = (name.is_a?(::Array) ? name : [ name ]).map { |n| [ n, FFI.map_library_name(n) ].uniq }.flatten.compact\\n+          libnames = (name.is_a?(::Array) ? name : [ name ]).map(&:to_s).map { |n| [ n, FFI.map_library_name(n) ].uniq }.flatten.compact\\n           lib = nil\\n           errors = {}\\n \\n@@ -126,7 +125,6 @@ def ffi_lib(*names)\\n                 retry\\n               else\\n                 # TODO better library lookup logic\\n-                libname = libname.to_s\\n                 unless libname.start_with?(\"\/\")\\n                   path = [\\'\/usr\/lib\/\\',\\'\/usr\/local\/lib\/\\'].find do |pth|\\n                     File.exist?(pth + libname)'}}",
            "message_norm":"don't treat symbol args different to strings in ffi_lib\n\nsymbols were sent directly to ffi::dynamiclibrary.open in the first\nattempt, resulting in a typeerror, so that only the mangled library\nname was actually loaded.\n\nthis moves conversion to string to the front, so that subsequent\ncalls can assume strings only.",
            "language":"en",
            "entities":"[('typeerror', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/ffi\/library.rb'])",
            "num_files":1.0
        },
        {
            "index":971,
            "vuln_id":"GHSA-75vw-3m5v-fprh",
            "cwe_id":"{'CWE-611'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/stanfordnlp\/corenlp\/commit\/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd'}",
            "dataset":"osv",
            "summary":"corenlp is vulnerable to Improper Restriction of XML External Entity Reference corenlp is vulnerable to Improper Restriction of XML External Entity Reference",
            "published_date":"2022-01-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/stanfordnlp\/corenlp",
            "commit_href":"https:\/\/github.com\/stanfordnlp\/corenlp\/commit\/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
            "commit_sha":"1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
            "patch":"SINGLE",
            "chain_ord":"['1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd']",
            "before_first_fix_commit":"{'820192ce1ad1062057cf6abcb359cd635988bf63'}",
            "last_fix_commit":"1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/16\/2022, 06:10:35",
            "message":"Fix XML schema vulnerability",
            "author":"Haxatron",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'src\/edu\/stanford\/nlp\/util\/XMLUtils.java': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/stanfordnlp\/CoreNLP\/raw\/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd\/src%2Fedu%2Fstanford%2Fnlp%2Futil%2FXMLUtils.java', 'patch': '@@ -302,6 +302,7 @@ public static DocumentBuilder getValidatingXmlParser(File schemaFile) {\\n       DocumentBuilderFactory dbf = safeDocumentBuilderFactory();\\n \\n       SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);\\n+      factory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\\n       Schema schema = factory.newSchema(schemaFile);\\n       dbf.setSchema(schema);'}}",
            "message_norm":"fix xml schema vulnerability",
            "language":"ro",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/edu\/stanford\/nlp\/util\/XMLUtils.java'])",
            "num_files":1.0
        },
        {
            "index":1236,
            "vuln_id":"GHSA-8phj-f9w2-cjcc",
            "cwe_id":"{'CWE-22'}",
            "score":8.6,
            "chain":"{'https:\/\/github.com\/aimhubio\/aim\/pull\/1003\/commits\/f01266a1a479ef11d7d6c539e7dd89e9d5639738'}",
            "dataset":"osv",
            "summary":"Arbitrary file reading vulnerability in Aim ### Impact\nA path traversal attack aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (..\/)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files.\n\nVulnerable code: https:\/\/github.com\/aimhubio\/aim\/blob\/0b99c6ca08e0ba7e7011453a2f68033e9b1d1bce\/aim\/web\/api\/views.py#L9-L16\n\n### Patches\nThe vulnerability issue is resolved in Aim v3.1.0.\n\n### References\nhttps:\/\/owasp.org\/www-community\/attacks\/Path_Traversal",
            "published_date":"2021-11-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/aimhubio\/aim",
            "commit_href":"https:\/\/github.com\/aimhubio\/aim\/pull\/1003\/commits\/f01266a1a479ef11d7d6c539e7dd89e9d5639738",
            "commit_sha":"f01266a1a479ef11d7d6c539e7dd89e9d5639738",
            "patch":"SINGLE",
            "chain_ord":"['f01266a1a479ef11d7d6c539e7dd89e9d5639738']",
            "before_first_fix_commit":"{'0bcac8b709f9409518134b2eafee817278aca14f'}",
            "last_fix_commit":"f01266a1a479ef11d7d6c539e7dd89e9d5639738",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/12\/2021, 14:03:22",
            "message":"Fix security issue when incorrect path is given to the endpoint that serves static files which can lead to a leak of non wanted files (e.g. \/static-files\/..\/..\/..\/..\/etc\/passwd)",
            "author":"mihran113",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 1, 'total': 10}",
            "files":"{'aim\/web\/api\/views.py': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/aimhubio\/aim\/raw\/f01266a1a479ef11d7d6c539e7dd89e9d5639738\/aim%2Fweb%2Fapi%2Fviews.py', 'patch': \"@@ -1,15 +1,23 @@\\n import os\\n+from pathlib import Path\\n \\n from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter\\n from fastapi.responses import FileResponse\\n+from fastapi import HTTPException\\n \\n statics_router = APIRouter()\\n \\n \\n @statics_router.get('\/static-files\/{path:path}\/')\\n async def serve_static_files(path):\\n     from aim import web\\n-    static_file_name = os.path.join(os.path.dirname(web.__file__), 'ui', 'build', path)\\n+    static_file_root = os.path.join(os.path.dirname(web.__file__), 'ui', 'build')\\n+    static_file_name = os.path.join(static_file_root, path)\\n+\\n+    # check if path is leading inside ui\/build directory\\n+    if not Path(static_file_root) in Path(static_file_name).resolve().parents:\\n+        raise HTTPException(404)\\n+\\n     compressed_file_name = '{}.gz'.format(static_file_name)\\n     if os.path.exists(compressed_file_name):\\n         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})\"}}",
            "message_norm":"fix security issue when incorrect path is given to the endpoint that serves static files which can lead to a leak of non wanted files (e.g. \/static-files\/..\/..\/..\/..\/etc\/passwd)",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('leak', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['aim\/web\/api\/views.py'])",
            "num_files":1.0
        },
        {
            "index":3023,
            "vuln_id":"GHSA-rww7-2gpw-fv6j",
            "cwe_id":"{'CWE-754'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cb164786dc891ea11d3a900e90367c339305dc7b'}",
            "dataset":"osv",
            "summary":"Crash when type cannot be specialized in Tensorflow ### Impact\nUnder certain scenarios, TensorFlow can fail to specialize a type during [shape inference](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/shape_inference.cc#L168-L174):\n\n```cc\nvoid InferenceContext::PreInputInit(\n    const OpDef& op_def, const std::vector<const Tensor*>& input_tensors,\n    const std::vector<ShapeHandle>& input_tensors_as_shapes) {\n  const auto ret = full_type::SpecializeType(attrs_, op_def);\n  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\n  ret_types_ = ret.ValueOrDie();\n  \/\/ ... \n}\n```\n\nHowever, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the `ValueOrDie` line. This results in an assertion failure as `ret` contains an error `Status`, not a value. In the second case we also get a crash due to the assertion failure.\n### Patches\nWe have patched the issue in GitHub commit [cb164786dc891ea11d3a900e90367c339305dc7b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cb164786dc891ea11d3a900e90367c339305dc7b).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cb164786dc891ea11d3a900e90367c339305dc7b",
            "commit_sha":"cb164786dc891ea11d3a900e90367c339305dc7b",
            "patch":"SINGLE",
            "chain_ord":"['cb164786dc891ea11d3a900e90367c339305dc7b']",
            "before_first_fix_commit":"{'c2b31ff2d3151acb230edc3f5b1832d2c713a9e0'}",
            "last_fix_commit":"cb164786dc891ea11d3a900e90367c339305dc7b",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/08\/2021, 18:28:34",
            "message":"Properly handle the case where `SpecializeType()` returns an error `Status`.\n\nIf the error case in `SpecializeType()` is reached, then we would get a crash when trying to access the value of an errorenous `StatusOr` object\n\nPiperOrigin-RevId: 408380069\nChange-Id: If3c3fc876dcf9384d5ec7a4985adc68c23ea7318",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 1, 'total': 5}",
            "files":"{'tensorflow\/core\/framework\/shape_inference.cc': {'additions': 4, 'deletions': 1, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/cb164786dc891ea11d3a900e90367c339305dc7b\/tensorflow%2Fcore%2Fframework%2Fshape_inference.cc', 'patch': '@@ -170,7 +170,10 @@ void InferenceContext::PreInputInit(\\n     const std::vector<ShapeHandle>& input_tensors_as_shapes) {\\n   \/\/ TODO(mdan): This is also done at graph construction. Run only here instead?\\n   const auto ret = full_type::SpecializeType(attrs_, op_def);\\n-  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\\n+  if (!ret.status().ok()) {\\n+    construction_status_ = ret.status();\\n+    return;\\n+  }\\n   ret_types_ = ret.ValueOrDie();\\n \\n   input_tensors_ = input_tensors;'}}",
            "message_norm":"properly handle the case where `specializetype()` returns an error `status`.\n\nif the error case in `specializetype()` is reached, then we would get a crash when trying to access the value of an errorenous `statusor` object\n\npiperorigin-revid: 408380069\nchange-id: if3c3fc876dcf9384d5ec7a4985adc68c23ea7318",
            "language":"en",
            "entities":"[('error', 'FLAW', ''), ('error', 'FLAW', ''), ('408380069', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/shape_inference.cc'])",
            "num_files":1.0
        },
        {
            "index":3382,
            "vuln_id":"GHSA-x67x-vg9m-65c3",
            "cwe_id":"{'CWE-119'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/alicemaz\/rust-base64\/commit\/24ead980daf11ba563e4fb2516187a56a71ad319'}",
            "dataset":"osv",
            "summary":"Integer overflow in base64 Affected versions of this crate suffered from an integer overflow bug when\ncalculating the size of a buffer to use when encoding base64 using the\n`encode_config_buf` and `encode_config` functions.  If the input string\nwas large, this would cause a buffer to be allocated that was too small.\nSince this function writes to the buffer using unsafe code, it would\nallow an attacker to write beyond the buffer, causing memory corruption\nand possibly the execution of arbitrary code.\n\nThis flaw was corrected by using checked arithmetic to calculate\nthe size of the buffer.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/alicemaz\/rust-base64",
            "commit_href":"https:\/\/github.com\/alicemaz\/rust-base64\/commit\/24ead980daf11ba563e4fb2516187a56a71ad319",
            "commit_sha":"24ead980daf11ba563e4fb2516187a56a71ad319",
            "patch":"SINGLE",
            "chain_ord":"['24ead980daf11ba563e4fb2516187a56a71ad319']",
            "before_first_fix_commit":"{'21a9389cf340f1e36e48856859d5713b97744383'}",
            "last_fix_commit":"24ead980daf11ba563e4fb2516187a56a71ad319",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/03\/2017, 05:26:40",
            "message":"Use checked arithmetic in encoded_size\n\npreviously encoded_size could silently overflow usize, resulting in\nwrite past the bounds of the buffer allocated by reserve. this changes\nencoded_size to return an option, with none if overflow occurs.\npresently callers simply panic on this case, but it could conceivably be\nrendered as an error in the future\n\ncredit to Andrew Ayer for reporting this vulnerability",
            "author":"Alice Maz",
            "comments":null,
            "stats":"{'additions': 75, 'deletions': 61, 'total': 136}",
            "files":"{'src\/lib.rs': {'additions': 75, 'deletions': 61, 'changes': 136, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/marshallpierce\/rust-base64\/raw\/24ead980daf11ba563e4fb2516187a56a71ad319\/src%2Flib.rs', 'patch': '@@ -171,31 +171,36 @@ pub fn decode<T: ?Sized + AsRef<[u8]>>(input: &T) -> Result<Vec<u8>, DecodeError\\n \/\/\/}\\n \/\/\/```\\n pub fn encode_config<T: ?Sized + AsRef<[u8]>>(input: &T, config: Config) -> String {\\n-    let mut buf = String::with_capacity(encoded_size(input.as_ref().len(), config));\\n+    let mut buf = match encoded_size(input.as_ref().len(), config) {\\n+        Some(n) => String::with_capacity(n),\\n+        None => panic!(\"integer overflow when calculating buffer size\")\\n+    };\\n \\n     encode_config_buf(input, config, &mut buf);\\n \\n     buf\\n }\\n \\n \/\/\/ calculate the base64 encoded string size, including padding\\n-fn encoded_size(bytes_len: usize, config: Config) -> usize {\\n-    let rem = bytes_len % 3;\\n-\\n-    let complete_input_chunks = bytes_len \/ 3;\\n-    let complete_output_chars = complete_input_chunks * 4;\\n-    let printing_output_chars = if rem == 0 {\\n-        complete_output_chars\\n-    } else {\\n-        complete_output_chars + 4\\n-    };\\n+fn encoded_size(bytes_len: usize, config: Config) -> Option<usize> {\\n+    let printing_output_chars = bytes_len\\n+        .checked_add(2)\\n+        .map(|x| x \/ 3)\\n+        .and_then(|x| x.checked_mul(4));\\n+\\n+    \/\/TODO this is subtly wrong but in a not dangerous way\\n+    \/\/pushing patch with identical to previous behavior, then fixing\\n     let line_ending_output_chars = match config.line_wrap {\\n-        LineWrap::NoWrap => 0,\\n-        LineWrap::Wrap(n, LineEnding::CRLF) => printing_output_chars \/ n * 2,\\n-        LineWrap::Wrap(n, LineEnding::LF) => printing_output_chars \/ n,\\n+        LineWrap::NoWrap => Some(0),\\n+        LineWrap::Wrap(n, LineEnding::CRLF) =>\\n+            printing_output_chars.map(|y| y \/ n).and_then(|y| y.checked_mul(2)),\\n+        LineWrap::Wrap(n, LineEnding::LF) =>\\n+            printing_output_chars.map(|y| y \/ n),\\n     };\\n \\n-    return printing_output_chars + line_ending_output_chars;\\n+    printing_output_chars.and_then(|x|\\n+        line_ending_output_chars.and_then(|y| x.checked_add(y))\\n+    )\\n }\\n \\n \/\/\/Encode arbitrary octets as base64.\\n@@ -224,7 +229,11 @@ pub fn encode_config_buf<T: ?Sized + AsRef<[u8]>>(input: &T, config: Config, buf\\n     };\\n \\n     \/\/ reserve to make sure the memory we\\'ll be writing to with unsafe is allocated\\n-    buf.reserve(encoded_size(input_bytes.len(), config));\\n+    let resv_size = match encoded_size(input_bytes.len(), config) {\\n+        Some(n) => n,\\n+        None => panic!(\"integer overflow when calculating buffer size\"),\\n+    };\\n+    buf.reserve(resv_size);\\n \\n     let orig_buf_len = buf.len();\\n     let mut fast_loop_output_buf_len = orig_buf_len;\\n@@ -579,52 +588,52 @@ mod tests {\\n \\n     #[test]\\n     fn encoded_size_correct() {\\n-        assert_eq!(0, encoded_size(0, STANDARD));\\n+        assert_eq!(Some(0), encoded_size(0, STANDARD));\\n \\n-        assert_eq!(4, encoded_size(1, STANDARD));\\n-        assert_eq!(4, encoded_size(2, STANDARD));\\n-        assert_eq!(4, encoded_size(3, STANDARD));\\n+        assert_eq!(Some(4), encoded_size(1, STANDARD));\\n+        assert_eq!(Some(4), encoded_size(2, STANDARD));\\n+        assert_eq!(Some(4), encoded_size(3, STANDARD));\\n \\n-        assert_eq!(8, encoded_size(4, STANDARD));\\n-        assert_eq!(8, encoded_size(5, STANDARD));\\n-        assert_eq!(8, encoded_size(6, STANDARD));\\n+        assert_eq!(Some(8), encoded_size(4, STANDARD));\\n+        assert_eq!(Some(8), encoded_size(5, STANDARD));\\n+        assert_eq!(Some(8), encoded_size(6, STANDARD));\\n \\n-        assert_eq!(12, encoded_size(7, STANDARD));\\n-        assert_eq!(12, encoded_size(8, STANDARD));\\n-        assert_eq!(12, encoded_size(9, STANDARD));\\n+        assert_eq!(Some(12), encoded_size(7, STANDARD));\\n+        assert_eq!(Some(12), encoded_size(8, STANDARD));\\n+        assert_eq!(Some(12), encoded_size(9, STANDARD));\\n \\n-        assert_eq!(72, encoded_size(54, STANDARD));\\n+        assert_eq!(Some(72), encoded_size(54, STANDARD));\\n \\n-        assert_eq!(76, encoded_size(55, STANDARD));\\n-        assert_eq!(76, encoded_size(56, STANDARD));\\n-        assert_eq!(76, encoded_size(57, STANDARD));\\n+        assert_eq!(Some(76), encoded_size(55, STANDARD));\\n+        assert_eq!(Some(76), encoded_size(56, STANDARD));\\n+        assert_eq!(Some(76), encoded_size(57, STANDARD));\\n \\n-        assert_eq!(80, encoded_size(58, STANDARD));\\n+        assert_eq!(Some(80), encoded_size(58, STANDARD));\\n     }\\n \\n     #[test]\\n     fn encoded_size_correct_mime() {\\n-        assert_eq!(0, encoded_size(0, MIME));\\n+        assert_eq!(Some(0), encoded_size(0, MIME));\\n \\n-        assert_eq!(4, encoded_size(1, MIME));\\n-        assert_eq!(4, encoded_size(2, MIME));\\n-        assert_eq!(4, encoded_size(3, MIME));\\n+        assert_eq!(Some(4), encoded_size(1, MIME));\\n+        assert_eq!(Some(4), encoded_size(2, MIME));\\n+        assert_eq!(Some(4), encoded_size(3, MIME));\\n \\n-        assert_eq!(8, encoded_size(4, MIME));\\n-        assert_eq!(8, encoded_size(5, MIME));\\n-        assert_eq!(8, encoded_size(6, MIME));\\n+        assert_eq!(Some(8), encoded_size(4, MIME));\\n+        assert_eq!(Some(8), encoded_size(5, MIME));\\n+        assert_eq!(Some(8), encoded_size(6, MIME));\\n \\n-        assert_eq!(12, encoded_size(7, MIME));\\n-        assert_eq!(12, encoded_size(8, MIME));\\n-        assert_eq!(12, encoded_size(9, MIME));\\n+        assert_eq!(Some(12), encoded_size(7, MIME));\\n+        assert_eq!(Some(12), encoded_size(8, MIME));\\n+        assert_eq!(Some(12), encoded_size(9, MIME));\\n \\n-        assert_eq!(72, encoded_size(54, MIME));\\n+        assert_eq!(Some(72), encoded_size(54, MIME));\\n \\n-        assert_eq!(78, encoded_size(55, MIME));\\n-        assert_eq!(78, encoded_size(56, MIME));\\n-        assert_eq!(78, encoded_size(57, MIME));\\n+        assert_eq!(Some(78), encoded_size(55, MIME));\\n+        assert_eq!(Some(78), encoded_size(56, MIME));\\n+        assert_eq!(Some(78), encoded_size(57, MIME));\\n \\n-        assert_eq!(82, encoded_size(58, MIME));\\n+        assert_eq!(Some(82), encoded_size(58, MIME));\\n     }\\n \\n     #[test]\\n@@ -636,26 +645,31 @@ mod tests {\\n             LineWrap::Wrap(76, LineEnding::LF)\\n         );\\n \\n-        assert_eq!(0, encoded_size(0, config));\\n+        assert_eq!(Some(0), encoded_size(0, config));\\n+\\n+        assert_eq!(Some(4), encoded_size(1, config));\\n+        assert_eq!(Some(4), encoded_size(2, config));\\n+        assert_eq!(Some(4), encoded_size(3, config));\\n \\n-        assert_eq!(4, encoded_size(1, config));\\n-        assert_eq!(4, encoded_size(2, config));\\n-        assert_eq!(4, encoded_size(3, config));\\n+        assert_eq!(Some(8), encoded_size(4, config));\\n+        assert_eq!(Some(8), encoded_size(5, config));\\n+        assert_eq!(Some(8), encoded_size(6, config));\\n \\n-        assert_eq!(8, encoded_size(4, config));\\n-        assert_eq!(8, encoded_size(5, config));\\n-        assert_eq!(8, encoded_size(6, config));\\n+        assert_eq!(Some(12), encoded_size(7, config));\\n+        assert_eq!(Some(12), encoded_size(8, config));\\n+        assert_eq!(Some(12), encoded_size(9, config));\\n \\n-        assert_eq!(12, encoded_size(7, config));\\n-        assert_eq!(12, encoded_size(8, config));\\n-        assert_eq!(12, encoded_size(9, config));\\n+        assert_eq!(Some(72), encoded_size(54, config));\\n \\n-        assert_eq!(72, encoded_size(54, config));\\n+        assert_eq!(Some(77), encoded_size(55, config));\\n+        assert_eq!(Some(77), encoded_size(56, config));\\n+        assert_eq!(Some(77), encoded_size(57, config));\\n \\n-        assert_eq!(77, encoded_size(55, config));\\n-        assert_eq!(77, encoded_size(56, config));\\n-        assert_eq!(77, encoded_size(57, config));\\n+        assert_eq!(Some(81), encoded_size(58, config));\\n+    }\\n \\n-        assert_eq!(81, encoded_size(58, config));\\n+    #[test]\\n+    fn encoded_size_overflow() {\\n+        assert_eq!(None, encoded_size(std::usize::MAX, STANDARD));\\n     }\\n }'}}",
            "message_norm":"use checked arithmetic in encoded_size\n\npreviously encoded_size could silently overflow usize, resulting in\nwrite past the bounds of the buffer allocated by reserve. this changes\nencoded_size to return an option, with none if overflow occurs.\npresently callers simply panic on this case, but it could conceivably be\nrendered as an error in the future\n\ncredit to andrew ayer for reporting this vulnerability",
            "language":"en",
            "entities":"[('encoded_size', 'SECWORD', ''), ('encoded_size', 'SECWORD', ''), ('overflow', 'SECWORD', ''), ('encoded_size', 'SECWORD', ''), ('overflow', 'SECWORD', ''), ('error', 'FLAW', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/lib.rs'])",
            "num_files":1.0
        },
        {
            "index":1274,
            "vuln_id":"GHSA-8wf2-3ggj-78q9",
            "cwe_id":"{'CWE-287'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/phpmyadmin\/phpmyadmin\/commit\/ca54f1db050859eb8555875c6aa5d7796fdf4b32'}",
            "dataset":"osv",
            "summary":"Improper Authentication in phpmyadmin An issue was discovered in phpMyAdmin 4.9 before 4.9.8 and 5.1 before 5.1.2. A valid user who is already authenticated to phpMyAdmin can manipulate their account to bypass two-factor authentication for future login instances.",
            "published_date":"2022-01-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/phpmyadmin\/phpmyadmin",
            "commit_href":"https:\/\/github.com\/phpmyadmin\/phpmyadmin\/commit\/ca54f1db050859eb8555875c6aa5d7796fdf4b32",
            "commit_sha":"ca54f1db050859eb8555875c6aa5d7796fdf4b32",
            "patch":"SINGLE",
            "chain_ord":"['ca54f1db050859eb8555875c6aa5d7796fdf4b32']",
            "before_first_fix_commit":"{'ae11d5260b4bde42100c8696218a2bfd11a2d740'}",
            "last_fix_commit":"ca54f1db050859eb8555875c6aa5d7796fdf4b32",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/13\/2022, 01:59:41",
            "message":"security - Fix - 2FA\/U2F can be disabled without any code change\n\nSigned-off-by: William Desportes <williamdes@wdes.fr>",
            "author":"William Desportes",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 11, 'total': 27}",
            "files":"{'libraries\/classes\/DatabaseInterface.php': {'additions': 16, 'deletions': 11, 'changes': 27, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/phpmyadmin\/phpmyadmin\/raw\/ca54f1db050859eb8555875c6aa5d7796fdf4b32\/libraries%2Fclasses%2FDatabaseInterface.php', 'patch': '@@ -1563,17 +1563,22 @@ public function setCollation($collation)\\n      *\/\\n     public function initRelationParamsCache()\\n     {\\n-        if (strlen($GLOBALS[\\'db\\'])) {\\n-            $cfgRelation = $this->relation->getRelationsParam();\\n-            if (empty($cfgRelation[\\'db\\'])) {\\n-                $this->relation->fixPmaTables($GLOBALS[\\'db\\'], false);\\n-            }\\n-        }\\n-        $cfgRelation = $this->relation->getRelationsParam();\\n-        if (empty($cfgRelation[\\'db\\']) && isset($GLOBALS[\\'dblist\\'])) {\\n-            if ($GLOBALS[\\'dblist\\']->databases->exists(\\'phpmyadmin\\')) {\\n-                $this->relation->fixPmaTables(\\'phpmyadmin\\', false);\\n-            }\\n+        $storageDbName = $GLOBALS[\\'cfg\\'][\\'Server\\'][\\'pmadb\\'] ?? \\'\\';\\n+        \/\/ Use \"phpmyadmin\" as a default database name to check to keep the behavior consistent\\n+        $storageDbName = $storageDbName !== null\\n+                            && is_string($storageDbName)\\n+                            && $storageDbName !== \\'\\' ? $storageDbName : \\'phpmyadmin\\';\\n+\\n+        \/\/ This will make users not having explicitly listed databases\\n+        \/\/ have config values filled by the default phpMyAdmin storage table name values\\n+        $this->relation->fixPmaTables($storageDbName, false);\\n+\\n+        \/\/ This global will be changed if fixPmaTables did find one valid table\\n+        $storageDbName = $GLOBALS[\\'cfg\\'][\\'Server\\'][\\'pmadb\\'] ?? \\'\\';\\n+\\n+        \/\/ Empty means that until now no pmadb was found eligible\\n+        if (empty($storageDbName)) {\\n+            $this->relation->fixPmaTables($GLOBALS[\\'db\\'], false);\\n         }\\n     }'}}",
            "message_norm":"security - fix - 2fa\/u2f can be disabled without any code change\n\nsigned-off-by: william desportes <williamdes@wdes.fr>",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('williamdes@wdes.fr', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['libraries\/classes\/DatabaseInterface.php'])",
            "num_files":1.0
        },
        {
            "index":3015,
            "vuln_id":"GHSA-rv87-vcv4-fjvr",
            "cwe_id":"{'CWE-918'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/jenkinsci\/urltrigger-plugin\/commit\/aec43e370550b26636aa9cab0f23a5cbcffdc44f', 'https:\/\/github.com\/jenkinsci\/urltrigger-plugin\/commit\/46220e69c220bacf8eb23911c8feba9dd68d1a26'}",
            "dataset":"osv",
            "summary":"URLTrigger Plugin server-side request forgery vulnerability A server-side request forgery vulnerability exists in Jenkins URLTrigger Plugin 0.41 and earlier in URLTrigger.java that allows attackers with Overall\/Read access to cause Jenkins to send a GET request to a specified URL. As of version 0.43, this form validation method no longer connects to a user provided URL.",
            "published_date":"2022-05-14",
            "chain_len":2,
            "project":"https:\/\/github.com\/jenkinsci\/urltrigger-plugin",
            "commit_href":"https:\/\/github.com\/jenkinsci\/urltrigger-plugin\/commit\/aec43e370550b26636aa9cab0f23a5cbcffdc44f",
            "commit_sha":"aec43e370550b26636aa9cab0f23a5cbcffdc44f",
            "patch":"MULTI",
            "chain_ord":"['46220e69c220bacf8eb23911c8feba9dd68d1a26', 'aec43e370550b26636aa9cab0f23a5cbcffdc44f']",
            "before_first_fix_commit":"{'46220e69c220bacf8eb23911c8feba9dd68d1a26'}",
            "last_fix_commit":"aec43e370550b26636aa9cab0f23a5cbcffdc44f",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/29\/2018, 21:33:01",
            "message":"Given that the URL is polled, may be valid at poll-time but not at\nconfiguration-time and may contain environment variables that could\nchange the URL at poll-time, validating it during configuration is\npointless.",
            "author":"Tony Noble",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 15, 'total': 17}",
            "files":"{'src\/main\/java\/org\/jenkinsci\/plugins\/urltrigger\/URLTrigger.java': {'additions': 2, 'deletions': 15, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/urltrigger-plugin\/raw\/aec43e370550b26636aa9cab0f23a5cbcffdc44f\/src%2Fmain%2Fjava%2Forg%2Fjenkinsci%2Fplugins%2Furltrigger%2FURLTrigger.java', 'patch': '@@ -743,21 +743,8 @@ public FormValidation doCheckURL(@QueryParameter String value) {\\n             if ( value.contains( \"$\" ) ) {\\n             \\treturn FormValidation.warning( \"URL is parameterised and cannot be fully validated\" ) ;\\n             }\\n-\\n-            try {\\n-                URI uri = new URI(value);\\n-                if (uri.getScheme().equals(\"ftp\")) {\\n-                    FTPClient ftpClient = getFTPClientObject(value, null, null);\\n-                    ftpClient.getModificationTime(uri.getPath());\\n-                } else {\\n-                    ClientConfig cc = new DefaultClientConfig();\\n-                    Client client = Client.create(cc);\\n-                    client.resource(value).get(ClientResponse.class);\\n-                }\\n-                return FormValidation.ok();\\n-            } catch (Exception e) {\\n-                return FormValidation.error(e.getMessage());\\n-            }\\n+            \\n+            return FormValidation.ok();\\n         }\\n \\n         public FormValidation doCheckTimeout(@QueryParameter String value) {'}}",
            "message_norm":"given that the url is polled, may be valid at poll-time but not at\nconfiguration-time and may contain environment variables that could\nchange the url at poll-time, validating it during configuration is\npointless.",
            "language":"en",
            "entities":"[('change', 'ACTION', ''), ('validating', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/org\/jenkinsci\/plugins\/urltrigger\/URLTrigger.java'])",
            "num_files":1.0
        },
        {
            "index":1973,
            "vuln_id":"GHSA-h3fg-h5v3-vf8m",
            "cwe_id":"{'CWE-352'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/solidusio\/solidus\/commit\/a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6', 'https:\/\/github.com\/solidusio\/solidus\/commit\/4d17cacf066d9492fc04eb3a0b16084b47376d81'}",
            "dataset":"osv",
            "summary":"CSRF forgery protection bypass in solidus_frontend ### Impact\nCSRF vulnerability that allows a malicious site to add an item to the user's cart without their knowledge.\n\nAll `solidus_frontend` versions are affected. If you're using your own storefront, please, follow along to make sure you're not affected.\n\nTo reproduce the issue:\n\n- Pick the id for a variant with available stock. From the rails console:\n\n  ```ruby\n  Spree::Variant.in_stock.pluck(:id)\n  ```\n\n  Say we pick variant id `2`.\n\n- Launch your application, for instance, on `http:\/\/localhost:3000`:\n\n  ```bash\n  bin\/rails server\n  ```\n\n- Open your browser dev tools.\n\n- Click on whatever link in your store.\n\n- Copy the value of the `Cookie` request header sent for the previous request from your browser dev tools.\n\n- Execute the following, using your previously selected variant id and the value of the `Cookie` header (notice how it doesn't contain any authentication token):\n\n  ```bash\n  curl -X POST -d \"variant_id=2&quantity=1\" -H \"Cookie: guest_token=eyJfcmFpbHMiOnsibWVzc2FnZSI6IklrWlRVMWRQWnpKMVZVdFNXRzlPVW1aaWJHTjZZa0VpIiwiZXhwIjpudWxsLCJwdXIiOiJjb29raWUuZ3Vlc3RfdG9rZW4ifX0%3D--5006ba5d346f621c760a29b6a797bf351d17d1b8; _sandbox_session=vhutu5%2FL9NmWrUpGc3DxrFA%2FFsQD1dHn1cNsD7nvE84zcjWf17Af4%2F%2F2Vab3md71b6KTb9NP6WktdXktpwH4eU01jEGIBXG5%2BMzW5nL0nb4W269qk1io4LYljvoOg8%2BZVll7oJCVkJLKKh0sSoS0Kg8j%2FCHHs%2BsShohP%2BGnA%2Bfr9Ub8H6HofpSmloSpsfHHygmX0ho03fEgzHJ4DD5wJctaNKwg7NhVikHh5kgIPPHl84OGCgv3p2oe9jR19HTxOKq7BtyvDd7XZsecWhkcfS8BPnvDDUWZG6qpAEFI5kWo81KkpSJ%2Bp6Q1HOo8%3D--n3G2vgaDG7VS%2B%2FhF--ZTjxBAkfGG3hpr4GRQ2S1Q%3D%3D; __profilin=p%3Dt\" http:\/\/localhost:3000\/orders\/populate\n  ```\n\n- Reload your browser and look at how your cart got updated.\n\n### Patches\n\nPlease, upgrade `solidus` to versions `3.1.5`, `3.0.5` or `2.11.14`.\n\nAfter upgrading, make sure you read the \"Upgrade notes\"  section below.\n\n### Upgrade notes\n\nThe patch adds CSRF token verification to the \"Add to cart\" action. Adding forgery protection to a form that missed it can have some side effects.\n\n#### `InvalidAuthenticityToken` errors\n\nIf you're using the `:exception` strategy, it's likely that after upgrading, you'll see more `ActionController::InvalidAuthenticityToken` errors popping out in your logs. Due to browser-side cache, a form can be re-rendered and sent without any attached request cookie (for instance, when re-opening a mobile browser). That will cause an authentication error, as the sent token won't match with the one in the session (none in this case). That's a known problem in the Rails community (see https:\/\/github.com\/rails\/rails\/issues\/21948), and, at this point, there's no perfect solution.\n\nAny attempt to mitigate the issue should be seen at the application level. For an excellent survey of all the available options, take a look at https:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md. The latter is a third-party link. As the information is relevant here, we're going to copy it below, but it should be clear that all the credit goes to @kemenaran:\n\n> # Protecting against request forgery using CRSF tokens\n> \n> ## Context\n> \n> Rails has CSRF protection enabled by default, to protect against POST-based CSRF attacks.\n> \n> To protect from this, Rails stores two copies of a random token (the so-named CSRF token) on each request:\n> - one copy embedded in each HTML page,\n> - another copy in the user session.\n> \n> When performing a POST request, Rails checks that the two copies match \u2013 and otherwise denies the request. This protects against an attacker that would generate a form secretly pointing to our website: the attacker can't read the token in the session, and so can't post a form with a valid token.\n> \n> The problem is that, much more often, this has false positives. There are several cases for that, including:\n> \n> 1. The web browser (often mobile) loads a page containing a form, then is closed by the user. Later, when the browser is re-opened, it restores the page from the cache. But the session cookie has expired, and so is not restored \u2013 so the copy of the CSRF token stored in the session is missing. When the user submits the form, they get an \"InvalidAuthenticityToken\" exception.\n> \n> 2. The user attempts to fill a form, and gets an error message (usually in response to a POST request). They close the browser. When the browser is re-opened, it attempts to restore the page. On Chrome this is blocked by the browser, because the browser denies retrying a (probably non-idempotent) POST request. Safari however happily retries the POST request \u2013 but without sending any cookies (in an attempt to avoid having unexpected side-effects). So the copy of the CSRF token in the session is missing (because no cookie was sent), and the user get an \"InvalidAuthenticityToken\" exception.\n> \n> ## Options considered\n> \n> ### Extend the session cookie duration\n> \n> We can configure the session cookie to be valid for a longer time (like 2 weeks).\n> \n> Pros:\n> - It solves 1., because when the browser restores the page, the session cookie is still valid.\n> \n> Cons:\n> - Users would be signed-in for a much longer time by default, which has unacceptable security implications.\n> - It doesn't solve 2. (because Safari doesn't send any cookie when restoring a page from a POST request)\n> \n> ### Change the cache parameters\n> \n> We can send a HTTP cache header stating 'Cache-Control: no-store, no-cache'. This instructs the browser to never keep any copy of the page, and to always make a request to the server to restore it.\n> \n> This solution was attempted during a year in production, and solved 1. \u2013 but also introduced another type of InvalidAuthenticityToken errors. In that scenario, the user attempts to fill a form, and gets an error message (usually in response to a POST request). They then navigate on another domain (like France Connect), then hit the \"Back\" button. Crossing back the domain boundary may cause the browser to either block the request or retry an invalid POST request.\n> \n> Pros:\n> - It solves 1., because on relaunch the browser requests a fresh page again (instead of serving it from its cache), thus retrieving a fresh session and a fresh matching CSRF token.\n> \n> Cons:\n> - It doesn't solve 2.\n> - It causes another type of InvalidAuthenticityToken errors.\n> \n> ### Using a null-session strategy\n> \n> We can change the default protect_from_forgery strategy to :null_session. This makes the current request use an empty session for the request duration.\n> \n> Pros:\n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted.\n> \n> Cons:\n> - The user is asked to sign-in only after filling and submitting the form, losing their time and data\n> - The user will not be redirected to their original page after signing-in\n> - It has potential security implications: as the (potentically malicious) request runs anyway, variables cached by a controller before the Null session is created may allow the form submission to succeed anyway (https:\/\/www.veracode.com\/blog\/managing-appsec\/when-rails-protectfromforgery-fails)\n> \n> ### Using a reset-session strategy\n> \n> We can change the default protect_from_forgery strategy to :reset_session. This clears the user session permanently, logging them out until they log in again.\n> \n> Pros: \n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted.\n> \n> Cons:\n> - A forgery error in a browser tab will disconnect the user in all its open tabs\n> - It has potential security implications: as the (potentically malicious) request runs anyway, variables cached by a controller before the Null session is created may allow the form submission to succeed anyway (https:\/\/www.veracode.com\/blog\/managing-appsec\/when-rails-protectfromforgery-fails)\n> - It allows an attacker to disconnect an user on demand, which is not only inconvenient, but also has security implication (the attacker could then log the user on it's own attacker account, pretending to be the user account)\n> \n> ### Redirect to login form\n> \n> When a forgery error occurs, we can instead redirect to the login form.\n> \n> Pros:\n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted (but the user data is lost).\n> - It kind of solves 2., by redirecting to a \"Please sign-in\" page when a previously POSTed form is reloaded.\n> \n> Cons:\n> - Not all forms require authentication \u2013 so for public forms there is no point redirecting to the login form. \n> - The user will not be redirected to their original page after signing-in (because setting the redirect path is a state-changing action, and it is dangerous to let an unauthorized request changing the state \u2013 an attacker could control the path where an user is automatically redirected to.)\n> - The implementation is finicky, and may introduce security errors. For instance, a naive implementation that catches the exception and redirect_to the sign-in page will prevent Devise from running a cleanup code \u2013 which means the user will still be logged, and the CSRF protection is bypassed. However a well-tested implementation that lets Devise code run should avoid these pittfalls.\n> \n> ### Using a long-lived cookie for CSRF tokens\n> \n> Instead of storing the CSRF token in the session cookie (which is deleted when the browser is closed), we can instead store it in a longer-lived cookie. For this we need to patch Rails.\n> \n> Pros:\n> - It solves 1., because when the user submits a stale form, even if the session cookie because stale, the long-lived CSRF cookie is still valid.\n> \n> Cons:\n> - It doesn't solve 2., because when Safari retries a POST request, it sends none of the cookies (not even long-lived ones).\n> - Patching Rails may introduce security issues (now or in the future)\n\n#### Broken behavior due to session expiration + template cache\n\nAlthough pretty unlikely, you should make sure that your current setup for cache\/session expiration is compatible. The upgrade can break the addition of products to the cart if both:\n\n- The \"Add to cart\" form is being cached (usually along with the variant information).\n\n- A user session is reset at every or every few requests.\n\nThe token validation depends on the issuing and consuming sessions being the same. If a product page is cached with the token in it, it can become stale on a subsequent rendering if the session changes.\n\nTo check that you're safe, after having upgraded locally, go through the following steps:\n\n- Enable cache on dev mode:\n\n  ```bash\n  bin\/rails dev:cache\n  ```\n\n- Visit the page for a variant with stock.\n\n- Reload that page several times.\n\n- Click on the \"Add to cart\"  button.\n\n- Remember to rerun `bin\/rails dev:cache` to turn off cache again.\n\nNo error or session reset should happen.\n\nOtherwise, you can try with:\n\n- Revisiting how your session gets expired.\n- Changing the caching strategy to exclude the token.\n\n#### Using weaker CSRF protection strategies\n\nIt's also important to understand that a complete fix will only be in place when using the `:exception` forgery protection strategy. The `solidus_frontend` engine can't do pretty much anything otherwise. Using weaker CSRF strategies should be an informed and limited decision made by the application team. After the upgrade:\n\n- An app using `:null_session` should also be safe, but there will be side effects. That strategy runs with a null object session. As such, no order and no user is found on it. A new `cart` state order is created in the database, associated with no user. Next time the user visits the site, they won't find any difference in its cart state.\n\n- An app using `:reset_session` is not entirely safe. That strategy resets the session. That means that registered users will be logged out. Next time a user visits, they'll see the cart with the items added during the CSRF attack, although it won't be associated with their account in the case of registered users.\n\n#### Reversing the update\n\nIf you still want to deploy the upgraded version before changing your application code (if the latter is needed), you can add the following workaround to your `config\/application.rb` (however, take into account that you'll keep being vulnerable):\n\n```ruby\nconfig.after_initialize do\n  Spree::OrdersController.skip_before_action :verify_authenticity_token, only: [:populate]\nend\n```\n\n### Workarounds\n\nIf an upgrade is not an option, you can work around the issue by adding the following to `config\/application.rb`:\n\n```ruby\nconfig.after_initialize do\n  Spree::OrdersController.protect_from_forgery with: ApplicationController.forgery_protection_strategy.name.demodulize.underscore.to_sym, only: [:populate]\nend\n```\n\nHowever, go through the same safety check detailed on \"Upgrade notes\" above.\n\n### References\n\n- [CSRF on the Rails guides](https:\/\/guides.rubyonrails.org\/security.html#cross-site-request-forgery-csrf)\n- [How CSRF tokens are generated and validated on Rails](https:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef)\n- [Solidus security](https:\/\/solidus.io\/security\/)\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an [issue](https:\/\/github.com\/solidusio\/solidus\/issues) or a [discussion](https:\/\/github.com\/solidusio\/solidus\/discussions) in Solidus.\n* Email us at [security@solidus.io](mailto:security@soliidus.io)\n* Contact the core team on [Slack](http:\/\/slack.solidus.io\/)",
            "published_date":"2022-01-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/solidusio\/solidus",
            "commit_href":"https:\/\/github.com\/solidusio\/solidus\/commit\/4d17cacf066d9492fc04eb3a0b16084b47376d81",
            "commit_sha":"4d17cacf066d9492fc04eb3a0b16084b47376d81",
            "patch":"MULTI",
            "chain_ord":"['4d17cacf066d9492fc04eb3a0b16084b47376d81', 'a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6']",
            "before_first_fix_commit":"{'4d17cacf066d9492fc04eb3a0b16084b47376d81', 'c6b892696881f88d209efaedd8bb378e8261953f'}",
            "last_fix_commit":"a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/14\/2021, 09:36:44",
            "message":"Protect `Spree::OrdersController#populate` against CSRF attacks\n\nSee\nhttps:\/\/github.com\/solidusio\/solidus\/security\/advisories\/GHSA-h3fg-h5v3-vf8m\nfor all the details.\n\nSome time ago, all order actions were left out of CSRF protection (see\n95ea57058ab1c5e722b327b10747cd41e68a4deb). The reason given was that the\nauthentication token got stale after the second rendering because the\nproduct page is cached. That was limited to `#populate` in\ncb797542c6948ef33d2cc9e6076c88f4cc927fb2 (see also\nhttps:\/\/github.com\/spree\/spree\/pull\/5601).\n\nHowever, those assumptions are not correct. Although the authenticity\ntoken changes at every request, that doesn't mean that the old ones are\nno longer valid. The variation comes from a one-time pad added to a\nsession-dependant token (and meant to avoid timing attacks). However,\nbefore validation, that one-time pad is removed. That means the token\nremains valid as long as the session has not been reset. Think about\nsubmitting a form from one browser tab after opening another with the\nsame URL. Even if both tokens differ, the submission from the first tab\nwill still be valid. You can read\nhttps:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef\nfor an in-deep understanding.\n\nThe initial confusion could come because of\nhttps:\/\/github.com\/rails\/rails\/issues\/21948. Due to browser-side cache,\na form can be re-rendered and sent without any attached request cookie.\nThat will cause an authentication error, as the sent token won't match\nwith the one in the session (none in this case). There's no perfect\nsolution for that, and all partial fixes should be seen at the\napplication level. From our side, we must provide a safe default. For an\nexcellent survey of all the available options, take a look at\nhttps:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md.\nThe information given in that link is third-party but it's very\nrelevant here. For that reason we've copied it in the security advisory\n(see link above), but all the credit goes to @kemenaran.",
            "author":"Marc Busqu\u00e9",
            "comments":null,
            "stats":"{'additions': 0, 'deletions': 1, 'total': 1}",
            "files":"{'frontend\/app\/controllers\/spree\/orders_controller.rb': {'additions': 0, 'deletions': 1, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/solidusio\/solidus\/raw\/4d17cacf066d9492fc04eb3a0b16084b47376d81\/frontend%2Fapp%2Fcontrollers%2Fspree%2Forders_controller.rb', 'patch': \"@@ -10,7 +10,6 @@ class OrdersController < Spree::StoreController\\n     before_action :assign_order, only: :update\\n     # note: do not lock the #edit action because that's where we redirect when we fail to acquire a lock\\n     around_action :lock_order, only: :update\\n-    skip_before_action :verify_authenticity_token, only: [:populate]\\n \\n     def show\\n       @order = Spree::Order.find_by!(number: params[:id])\"}}",
            "message_norm":"protect `spree::orderscontroller#populate` against csrf attacks\n\nsee\nhttps:\/\/github.com\/solidusio\/solidus\/security\/advisories\/ghsa-h3fg-h5v3-vf8m\nfor all the details.\n\nsome time ago, all order actions were left out of csrf protection (see\n95ea57058ab1c5e722b327b10747cd41e68a4deb). the reason given was that the\nauthentication token got stale after the second rendering because the\nproduct page is cached. that was limited to `#populate` in\ncb797542c6948ef33d2cc9e6076c88f4cc927fb2 (see also\nhttps:\/\/github.com\/spree\/spree\/pull\/5601).\n\nhowever, those assumptions are not correct. although the authenticity\ntoken changes at every request, that doesn't mean that the old ones are\nno longer valid. the variation comes from a one-time pad added to a\nsession-dependant token (and meant to avoid timing attacks). however,\nbefore validation, that one-time pad is removed. that means the token\nremains valid as long as the session has not been reset. think about\nsubmitting a form from one browser tab after opening another with the\nsame url. even if both tokens differ, the submission from the first tab\nwill still be valid. you can read\nhttps:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef\nfor an in-deep understanding.\n\nthe initial confusion could come because of\nhttps:\/\/github.com\/rails\/rails\/issues\/21948. due to browser-side cache,\na form can be re-rendered and sent without any attached request cookie.\nthat will cause an authentication error, as the sent token won't match\nwith the one in the session (none in this case). there's no perfect\nsolution for that, and all partial fixes should be seen at the\napplication level. from our side, we must provide a safe default. for an\nexcellent survey of all the available options, take a look at\nhttps:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md.\nthe information given in that link is third-party but it's very\nrelevant here. for that reason we've copied it in the security advisory\n(see link above), but all the credit goes to @kemenaran.",
            "language":"en",
            "entities":"[('protect', 'ACTION', ''), ('csrf', 'SECWORD', ''), ('attacks', 'FLAW', ''), ('https:\/\/github.com\/solidusio\/solidus\/security\/advisories\/ghsa-h3fg-h5v3-vf8m', 'VULNID', 'GHSA'), ('csrf', 'SECWORD', ''), ('protection', 'SECWORD', ''), ('95ea57058ab1c5e722b327b10747cd41e68a4deb', 'SHA', 'generic_sha'), ('authentication', 'SECWORD', ''), ('cb797542c6948ef33d2cc9e6076c88f4cc927fb2', 'SHA', 'generic_sha'), ('https:\/\/github.com\/spree\/spree\/pull\/5601', 'URL', ''), ('added', 'ACTION', ''), ('attacks', 'SECWORD', ''), ('removed', 'ACTION', ''), ('https:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef', 'SECWORD', ''), ('https:\/\/github.com\/rails\/rails\/issues\/21948', 'URL', ''), ('cookie', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('error', 'FLAW', ''), ('safe', 'SECWORD', ''), ('https:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md', 'SECWORD', ''), ('security', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['frontend\/app\/controllers\/spree\/orders_controller.rb'])",
            "num_files":1.0
        },
        {
            "index":2758,
            "vuln_id":"GHSA-qhh5-9738-g9mx",
            "cwe_id":"{'CWE-276'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/apache\/incubator-dolphinscheduler\/commit\/b8a9e2e00f2f207ae60c913a7173b59405ff95f1'}",
            "dataset":"osv",
            "summary":"Incorrect Default Permissions in Apache DolphinScheduler Versions of Apache DolphinScheduler prior to 1.3.2 allowed an ordinary user under any tenant to override another users password through the API interface.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/incubator-dolphinscheduler",
            "commit_href":"https:\/\/github.com\/apache\/incubator-dolphinscheduler\/commit\/b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
            "commit_sha":"b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
            "patch":"SINGLE",
            "chain_ord":"['b8a9e2e00f2f207ae60c913a7173b59405ff95f1']",
            "before_first_fix_commit":"{'0505ebf45d93fc1518386804ceffa6b36595f9c5'}",
            "last_fix_commit":"b8a9e2e00f2f207ae60c913a7173b59405ff95f1",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/18\/2020, 06:07:47",
            "message":"modify general user can't create,delete,update token (#3538)\n\nCo-authored-by: qiaozhanwei <qiaozhanwei@analysys.com.cn>",
            "author":"qiaozhanwei",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 8, 'total': 15}",
            "files":"{'dolphinscheduler-api\/src\/main\/java\/org\/apache\/dolphinscheduler\/api\/service\/AccessTokenService.java': {'additions': 7, 'deletions': 8, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/dolphinscheduler\/raw\/b8a9e2e00f2f207ae60c913a7173b59405ff95f1\/dolphinscheduler-api%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fdolphinscheduler%2Fapi%2Fservice%2FAccessTokenService.java', 'patch': '@@ -84,7 +84,9 @@ public Map<String, Object> queryAccessTokenList(User loginUser, String searchVal\\n      *\/\\n     public Map<String, Object> createToken(User loginUser, int userId, String expireTime, String token) {\\n         Map<String, Object> result = new HashMap<>(5);\\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n+\\n+        if (!hasPerm(loginUser,userId)){\\n+            putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n \\n@@ -140,10 +142,6 @@ public Map<String, Object> generateToken(User loginUser, int userId, String expi\\n     public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n         Map<String, Object> result = new HashMap<>(5);\\n \\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n-            return result;\\n-        }\\n-\\n         AccessToken accessToken = accessTokenMapper.selectById(id);\\n \\n         if (accessToken == null) {\\n@@ -152,8 +150,7 @@ public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n             return result;\\n         }\\n \\n-        if (loginUser.getId() != accessToken.getUserId() &&\\n-                loginUser.getUserType() != UserType.ADMIN_USER) {\\n+        if (!hasPerm(loginUser,accessToken.getUserId())){\\n             putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n@@ -176,9 +173,11 @@ public Map<String, Object> delAccessTokenById(User loginUser, int id) {\\n     public Map<String, Object> updateToken(User loginUser, int id, int userId, String expireTime, String token) {\\n         Map<String, Object> result = new HashMap<>(5);\\n \\n-        if(check(result, !isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)){\\n+        if (!hasPerm(loginUser,userId)){\\n+            putMsg(result, Status.USER_NO_OPERATION_PERM);\\n             return result;\\n         }\\n+\\n         AccessToken accessToken = accessTokenMapper.selectById(id);\\n         if (accessToken == null) {\\n             logger.error(\"access token not exist,  access token id {}\", id);'}}",
            "message_norm":"modify general user can't create,delete,update token (#3538)\n\nco-authored-by: qiaozhanwei <qiaozhanwei@analysys.com.cn>",
            "language":"en",
            "entities":"[('update', 'ACTION', ''), ('#3538', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dolphinscheduler-api\/src\/main\/java\/org\/apache\/dolphinscheduler\/api\/service\/AccessTokenService.java'])",
            "num_files":1.0
        },
        {
            "index":2944,
            "vuln_id":"GHSA-rgvq-pcvf-hx75",
            "cwe_id":"{'CWE-131'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f94ef358bb3e91d517446454edff6535bcfe8e4a', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c4d7afb6a5986b04505aca4466ae1951686c80f6', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b761c9b652af2107cfbc33efd19be0ce41daa33e'}",
            "dataset":"osv",
            "summary":"Heap OOB and null pointer dereference in `RaggedTensorToTensor` ### Impact\nDue to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty:\n\n```python\nimport tensorflow as tf\n\nshape = tf.constant([-1, -1], shape=[2], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\ndefault_value = tf.constant(404, dtype=tf.int64)\nrow = tf.constant([269, 404, 0, 0, 0, 0, 0], shape=[7], dtype=tf.int64)\nrows = [row]\ntypes = ['ROW_SPLITS']\n\ntf.raw_ops.RaggedTensorToTensor(\n  shape=shape, values=values, default_value=default_value, \n  row_partition_tensors=rows, row_partition_types=types)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/656e7673b14acd7835dc778867f84916c6d1cac2\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones.\n\nThere are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything.\n\n### Patches\nWe have patched the issue in GitHub commit [b761c9b652af2107cfbc33efd19be0ce41daa33e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b761c9b652af2107cfbc33efd19be0ce41daa33e) followed by GitHub commit [f94ef358bb3e91d517446454edff6535bcfe8e4a](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f94ef358bb3e91d517446454edff6535bcfe8e4a) and GitHub commit [c4d7afb6a5986b04505aca4466ae1951686c80f6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c4d7afb6a5986b04505aca4466ae1951686c80f6).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":3,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f94ef358bb3e91d517446454edff6535bcfe8e4a",
            "commit_sha":"f94ef358bb3e91d517446454edff6535bcfe8e4a",
            "patch":"MULTI",
            "chain_ord":"['f94ef358bb3e91d517446454edff6535bcfe8e4a', 'b761c9b652af2107cfbc33efd19be0ce41daa33e', 'c4d7afb6a5986b04505aca4466ae1951686c80f6']",
            "before_first_fix_commit":"{'50034ad2d55b10eb9d4593374546710b12f134e1'}",
            "last_fix_commit":"c4d7afb6a5986b04505aca4466ae1951686c80f6",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2021, 21:54:18",
            "message":"Fix `tf.raw_ops.RaggedTensorToTensor` failing CHECK in `tensor.cc`.\n\nPiperOrigin-RevId: 368300502\nChange-Id: I91255d23c4bfd3aa3c029aac773937c09daf3c64",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f94ef358bb3e91d517446454edff6535bcfe8e4a\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_tensor_op.cc', 'patch': '@@ -345,6 +345,11 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* context) override {\\n     INDEX_TYPE first_dimension;\\n+    const Tensor first_partition_tensor =\\n+        context->input(kFirstPartitionInputIndex);\\n+    OP_REQUIRES(context, first_partition_tensor.NumElements() > 0,\\n+                errors::InvalidArgument(\"Invalid first partition input. Tensor \"\\n+                                        \"requires at least one element.\"));\\n     OP_REQUIRES_OK(context, GetFirstDimensionSize(context, &first_dimension));\\n     vector<INDEX_TYPE> output_size;\\n     OP_REQUIRES_OK(context,'}}",
            "message_norm":"fix `tf.raw_ops.raggedtensortotensor` failing check in `tensor.cc`.\n\npiperorigin-revid: 368300502\nchange-id: i91255d23c4bfd3aa3c029aac773937c09daf3c64",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('368300502', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc'])",
            "num_files":1.0
        },
        {
            "index":163,
            "vuln_id":"GHSA-2xgj-xhgf-ggjv",
            "cwe_id":"{'CWE-120'}",
            "score":3.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `BandedTriangularSolve` ### Impact\nAn attacker can trigger a heap buffer overflow in Eigen implementation of `tf.raw_ops.BandedTriangularSolve`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n  \nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_array = np.array([1,1])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)\ntf.raw_ops.BandedTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc#L269-L278) calls `ValidateInputTensors` for input validation but fails to validate that the two tensors are not empty:\n  \n```cc\nvoid ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0, const Tensor& in1) {\n  OP_REQUIRES(\n      ctx, in0.dims() >= 2, \n      errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n\n  OP_REQUIRES(\n      ctx, in1.dims() >= 2,\n      errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1.dims()));\n}\n``` \n\nFurthermore, since `OP_REQUIRES` macro only stops execution of current function after setting `ctx->status()` to a non-OK value, callers of helper functions that use `OP_REQUIRES` must check value of `ctx->status()` before continuing. This doesn't happen [in this op's implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc#L219), hence the validation that is present is also not effective.\n\n### Patches\nWe have patched the issue in GitHub commit [ba6822bd7b7324ba201a28b2f278c29a98edbef2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2) followed by GitHub commit [0ab290774f91a23bebe30a358fde4e53ab4876a0](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ye Zhang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2",
            "commit_sha":"ba6822bd7b7324ba201a28b2f278c29a98edbef2",
            "patch":"MULTI",
            "chain_ord":"['ba6822bd7b7324ba201a28b2f278c29a98edbef2', '0ab290774f91a23bebe30a358fde4e53ab4876a0']",
            "before_first_fix_commit":"{'327ef310be67923824814e85e13007e9699f4e0d'}",
            "last_fix_commit":"0ab290774f91a23bebe30a358fde4e53ab4876a0",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 23:06:54",
            "message":"Fix OOB issue with `tf.raw_ops.SparseSparseMinimum`.\n\nPiperOrigin-RevId: 371005787\nChange-Id: Ib686ccc077836e8b980b8b5a03936d36a8ecaf71",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ba6822bd7b7324ba201a28b2f278c29a98edbef2\/tensorflow%2Fcore%2Fkernels%2Fsparse_sparse_binary_op_shared.cc', 'patch': '@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n                                           \" for dimension \", i));\\n     }\\n \\n+    OP_REQUIRES(\\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\\n+        errors::InvalidArgument(\\n+            \"Indices\\' dimensions do not match: got \", a_indices_t->dim_size(1),\\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\\n     const int num_dims = a_indices_t->dim_size(1);\\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\\n     const auto b_indices_mat = b_indices_t->matrix<int64>();'}}",
            "message_norm":"fix oob issue with `tf.raw_ops.sparsesparseminimum`.\n\npiperorigin-revid: 371005787\nchange-id: ib686ccc077836e8b980b8b5a03936d36a8ecaf71",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('oob', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371005787', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_sparse_binary_op_shared.cc'])",
            "num_files":1.0
        },
        {
            "index":1251,
            "vuln_id":"GHSA-8rm6-75mf-7r7r",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5117e0851348065ed59c991562c0ec80d9193db2'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite's implementation of hashtable lookup ### Impact\nThe TFLite implementation of hashtable lookup is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/1a8e885b864c818198a5b2c0cbbeca5a1e833bc8\/tensorflow\/lite\/kernels\/hashtable_lookup.cc#L114-L115):\n\n```cc\nconst int num_rows = SizeOfDimension(value, 0); \nconst int row_bytes = value->bytes \/ num_rows; \n```\n\nAn attacker can craft a model such that `values`'s first dimension would be 0.\n\n### Patches\nWe have patched the issue in GitHub commit [5117e0851348065ed59c991562c0ec80d9193db2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5117e0851348065ed59c991562c0ec80d9193db2).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5117e0851348065ed59c991562c0ec80d9193db2",
            "commit_sha":"5117e0851348065ed59c991562c0ec80d9193db2",
            "patch":"SINGLE",
            "chain_ord":"['5117e0851348065ed59c991562c0ec80d9193db2']",
            "before_first_fix_commit":"{'ba6822bd7b7324ba201a28b2f278c29a98edbef2'}",
            "last_fix_commit":"5117e0851348065ed59c991562c0ec80d9193db2",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 23:16:56",
            "message":"Prevent a division by 0\n\nPiperOrigin-RevId: 371007407\nChange-Id: Iecf2718de48d6bf5a69b02a9df9deda8ec1b19d3",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/lite\/kernels\/hashtable_lookup.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/5117e0851348065ed59c991562c0ec80d9193db2\/tensorflow%2Flite%2Fkernels%2Fhashtable_lookup.cc', 'patch': '@@ -112,6 +112,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\\n \\n   const int num_rows = SizeOfDimension(value, 0);\\n+  TF_LITE_ENSURE(context, num_rows != 0);\\n   const int row_bytes = value->bytes \/ num_rows;\\n   void* pointer = nullptr;\\n   DynamicBuffer buf;'}}",
            "message_norm":"prevent a division by 0\n\npiperorigin-revid: 371007407\nchange-id: iecf2718de48d6bf5a69b02a9df9deda8ec1b19d3",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('371007407', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/hashtable_lookup.cc'])",
            "num_files":1.0
        },
        {
            "index":567,
            "vuln_id":"GHSA-56wv-2wr9-3h9r",
            "cwe_id":"{'CWE-347'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/e592f106edd5acf6dacedfab2ad16fe6c735c9d1', 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/7b64e3efaa806b4daaf73bb5172af3581812f8de', 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/4a16daeaf139be20654ef58a9fe4c79dc030458c'}",
            "dataset":"osv",
            "summary":"Improper Verification of Cryptographic Signature in fastecdsa An issue was discovered in fastecdsa before 2.1.2. When using the NIST P-256 curve in the ECDSA implementation, the point at infinity is mishandled. This means that for an extreme value in k and s^-1, the signature verification fails even if the signature is correct. This behavior is not solely a usability problem. There are some threat models where an attacker can benefit by successfully guessing users for whom signature verification will fail.",
            "published_date":"2021-10-12",
            "chain_len":3,
            "project":"https:\/\/github.com\/AntonKueltz\/fastecdsa",
            "commit_href":"https:\/\/github.com\/AntonKueltz\/fastecdsa\/commit\/7b64e3efaa806b4daaf73bb5172af3581812f8de",
            "commit_sha":"7b64e3efaa806b4daaf73bb5172af3581812f8de",
            "patch":"MULTI",
            "chain_ord":"['e592f106edd5acf6dacedfab2ad16fe6c735c9d1', '7b64e3efaa806b4daaf73bb5172af3581812f8de', '4a16daeaf139be20654ef58a9fe4c79dc030458c']",
            "before_first_fix_commit":"{'7b64e3efaa806b4daaf73bb5172af3581812f8de'}",
            "last_fix_commit":"4a16daeaf139be20654ef58a9fe4c79dc030458c",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/14\/2020, 09:45:48",
            "message":"Update docs to v2.1.2",
            "author":"AntonKueltz",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'docs\/conf.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/AntonKueltz\/fastecdsa\/raw\/7b64e3efaa806b4daaf73bb5172af3581812f8de\/docs%2Fconf.py', 'patch': \"@@ -64,7 +64,7 @@\\n # The short X.Y version.\\n version = '2.1'\\n # The full version, including alpha\/beta\/rc tags.\\n-release = '2.1.1'\\n+release = '2.1.2'\\n \\n # The language for content autogenerated by Sphinx. Refer to documentation\\n # for a list of supported languages.\"}}",
            "message_norm":"update docs to v2.1.2",
            "language":"sl",
            "entities":"[('v2.1.2', 'VERSION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['docs\/conf.py'])",
            "num_files":1.0
        },
        {
            "index":1671,
            "vuln_id":"GHSA-f5fj-7265-jxhj",
            "cwe_id":"{'CWE-200'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/go-gitea\/gitea\/commit\/194a11eb110cd98fc2ba52861abf7770db6885a3'}",
            "dataset":"osv",
            "summary":"Information Exposure Gitea version prior to version 1.5.1 contains a CWE-200 vulnerability that can result in Exposure of users private email addresses. This attack appear to be exploitable via Watch a repository to receive email notifications. Emails received contain the other recipients even if they have the email set as private. This vulnerability appears to have been fixed in 1.5.1.",
            "published_date":"2022-02-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/go-gitea\/gitea",
            "commit_href":"https:\/\/github.com\/go-gitea\/gitea\/commit\/194a11eb110cd98fc2ba52861abf7770db6885a3",
            "commit_sha":"194a11eb110cd98fc2ba52861abf7770db6885a3",
            "patch":"SINGLE",
            "chain_ord":"['194a11eb110cd98fc2ba52861abf7770db6885a3']",
            "before_first_fix_commit":"{'912953e82a851492c7fd1f2e9c10d3a1955b625c'}",
            "last_fix_commit":"194a11eb110cd98fc2ba52861abf7770db6885a3",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/24\/2018, 04:41:26",
            "message":"Don't disclose emails of all users when sending out emails (#4664)",
            "author":"techknowlogick",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 2, 'total': 12}",
            "files":"{'models\/issue_mail.go': {'additions': 10, 'deletions': 2, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/go-gitea\/gitea\/raw\/194a11eb110cd98fc2ba52861abf7770db6885a3\/models%2Fissue_mail.go', 'patch': '@@ -1,4 +1,5 @@\\n \/\/ Copyright 2016 The Gogs Authors. All rights reserved.\\n+\/\/ Copyright 2018 The Gitea Authors. All rights reserved.\\n \/\/ Use of this source code is governed by a MIT-style\\n \/\/ license that can be found in the LICENSE file.\\n \\n@@ -87,7 +88,9 @@ func mailIssueCommentToParticipants(e Engine, issue *Issue, doer *User, content\\n \\t\\tnames = append(names, participants[i].Name)\\n \\t}\\n \\n-\\tSendIssueCommentMail(issue, doer, content, comment, tos)\\n+\\tfor _, to := range tos {\\n+\\t\\tSendIssueCommentMail(issue, doer, content, comment, []string{to})\\n+\\t}\\n \\n \\t\/\/ Mail mentioned people and exclude watchers.\\n \\tnames = append(names, doer.Name)\\n@@ -99,7 +102,12 @@ func mailIssueCommentToParticipants(e Engine, issue *Issue, doer *User, content\\n \\n \\t\\ttos = append(tos, mentions[i])\\n \\t}\\n-\\tSendIssueMentionMail(issue, doer, content, comment, getUserEmailsByNames(e, tos))\\n+\\n+\\temails := getUserEmailsByNames(e, tos)\\n+\\n+\\tfor _, to := range emails {\\n+\\t\\tSendIssueMentionMail(issue, doer, content, comment, []string{to})\\n+\\t}\\n \\n \\treturn nil\\n }'}}",
            "message_norm":"don't disclose emails of all users when sending out emails (#4664)",
            "language":"en",
            "entities":"[('disclose', 'SECWORD', ''), ('#4664', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['models\/issue_mail.go'])",
            "num_files":1.0
        },
        {
            "index":3370,
            "vuln_id":"GHSA-x55w-vjjp-222r",
            "cwe_id":"{'CWE-1333'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/pksunkara\/inflect\/commit\/a9a0a8e9561c3487854c7cae42565d9652ec858b'}",
            "dataset":"osv",
            "summary":"inflect vulnerable to Inefficient Regular Expression Complexity inflect is customizable inflections for nodejs. inflect is vulnerable to Inefficient Regular Expression Complexity",
            "published_date":"2021-09-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/pksunkara\/inflect",
            "commit_href":"https:\/\/github.com\/pksunkara\/inflect\/commit\/a9a0a8e9561c3487854c7cae42565d9652ec858b",
            "commit_sha":"a9a0a8e9561c3487854c7cae42565d9652ec858b",
            "patch":"SINGLE",
            "chain_ord":"['a9a0a8e9561c3487854c7cae42565d9652ec858b']",
            "before_first_fix_commit":"{'c025e153df847bbb2873ae75b1a7bd77b0526745'}",
            "last_fix_commit":"a9a0a8e9561c3487854c7cae42565d9652ec858b",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/21\/2021, 10:49:42",
            "message":"Fix CVE-2021-3820",
            "author":"Pavan Kumar Sunkara",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'lib\/methods.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pksunkara\/inflect\/raw\/a9a0a8e9561c3487854c7cae42565d9652ec858b\/lib%2Fmethods.js', 'patch': '@@ -61,7 +61,7 @@ inflect.camelize = function (lower_case_and_underscored_word, first_letter_in_up\\n inflect.underscore = function (camel_cased_word) {\\n   var self;\\n   self = util.string.gsub(camel_cased_word, \/\\\\.\/, \\'\/\\');\\n-  self = util.string.gsub(self, \/([A-Z]+)([A-Z][a-z])\/, \\'$1_$2\\');\\n+  self = util.string.gsub(self, \/([A-Z])([A-Z][a-z])\/, \\'$1_$2\\');\\n   self = util.string.gsub(self, \/([a-z\\\\d])([A-Z])\/, \\'$1_$2\\');\\n   self = util.string.gsub(self, \/-\/, \\'_\\');\\n   return self.toLowerCase();\\n@@ -230,5 +230,5 @@ inflect.tableize = function (class_name) {\\n \/\/\\n \/\/     \"business\".classify()       \/\/ => \"Busines\"\\n inflect.classify = function (table_name) {\\n-  return inflect.camelize(inflect.singularize(util.string.gsub(table_name, \/.*\\\\.\/, \\'\\')));\\n+  return inflect.camelize(inflect.singularize(util.string.gsub(table_name, \/^.*\\\\.\/, \\'\\')));\\n };'}}",
            "message_norm":"fix cve-2021-3820",
            "language":"fr",
            "entities":"[('fix', 'ACTION', ''), ('cve-2021-3820', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/methods.js'])",
            "num_files":1.0
        },
        {
            "index":360,
            "vuln_id":"GHSA-452g-f7fp-9jf7",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/030af767d357d1b4088c4a25c72cb3906abac489'}",
            "dataset":"osv",
            "summary":"Type confusion during tensor casts lead to dereferencing null pointers ### Impact\nCalling TF operations with tensors of non-numeric types when the operations expect numeric tensors result in null pointer dereferences.\n\nThere are multiple ways to reproduce this, listing a few examples here:\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata = tf.random.truncated_normal(shape=1,mean=np.float32(20.8739),stddev=779.973,dtype=20,seed=64)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata =\ntf.random.stateless_truncated_normal(shape=1,seed=[63,70],mean=np.float32(20.8739),stddev=779.973,dtype=20)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata = tf.one_hot(indices=[62,50],depth=136,on_value=np.int32(237),off_value=158,axis=856,dtype=20)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata = tf.range(start=np.int32(214),limit=660,delta=129,dtype=20)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\ndata = tf.raw_ops.ResourceCountUpTo(resource=np.int32(30), limit=872, T=3)\n```\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nwriter_array = np.array([1,2],dtype=np.int32)\nwriter_tensor = tf.convert_to_tensor(writer_array,dtype=tf.resource)\n```\n\nAll these examples and similar ones have the same behavior: the [conversion from Python array to C++ array](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ff70c47a396ef1e3cb73c90513da4f5cb71bebba\/tensorflow\/python\/lib\/core\/ndarray_tensor.cc#L113-L169) is vulnerable to a type confusion:\n\n```cc\n  int pyarray_type = PyArray_TYPE(array);\n  PyArray_Descr* descr = PyArray_DESCR(array);\n  switch (pyarray_type) {\n    ...\n    case NPY_VOID:\n      \/\/ Quantized types are currently represented as custom struct types.\n      \/\/ PyArray_TYPE returns NPY_VOID for structs, and we should look into\n      \/\/ descr to derive the actual type.\n      \/\/ Direct feeds of certain types of ResourceHandles are represented as a\n      \/\/ custom struct type.\n      return PyArrayDescr_to_TF_DataType(descr, out_tf_datatype);\n    ...\n  }\n```\n\nFor the tensor types involved in the above example, the `pyarray_type` is `NPY_VOID` but the `descr` field is such that `descr->field = NULL`. Then [`PyArrayDescr_to_TF_DataType`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ff70c47a396ef1e3cb73c90513da4f5cb71bebba\/tensorflow\/python\/lib\/core\/ndarray_tensor.cc#L72-L77) will trigger a null dereference:\n\n```cc\nStatus PyArrayDescr_to_TF_DataType(PyArray_Descr* descr,\n                                   TF_DataType* out_tf_datatype) {\n  PyObject* key;\n  PyObject* value;\n  Py_ssize_t pos = 0;\n  if (PyDict_Next(descr->fields, &pos, &key, &value)) {\n    ...\n  }\n}\n```\n\nThis is because the Python's `PyDict_Next` implementation would dereference the first argument.\n\n### Patches\nWe have patched the issue in GitHub commit [030af767d357d1b4088c4a25c72cb3906abac489](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/030af767d357d1b4088c4a25c72cb3906abac489).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360 as well as Ye Zhang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/030af767d357d1b4088c4a25c72cb3906abac489",
            "commit_sha":"030af767d357d1b4088c4a25c72cb3906abac489",
            "patch":"SINGLE",
            "chain_ord":"['030af767d357d1b4088c4a25c72cb3906abac489']",
            "before_first_fix_commit":"{'ff70c47a396ef1e3cb73c90513da4f5cb71bebba'}",
            "last_fix_commit":"030af767d357d1b4088c4a25c72cb3906abac489",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2021, 21:25:01",
            "message":"Fix `tf.raw_ops.ResourceCountUpTo` null pointer dereference.\n\nPiperOrigin-RevId: 368294347\nChange-Id: I2c16fbfc9b4966c402c3d8e311f0d665a9c852d8",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'tensorflow\/python\/lib\/core\/ndarray_tensor.cc': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/030af767d357d1b4088c4a25c72cb3906abac489\/tensorflow%2Fpython%2Flib%2Fcore%2Fndarray_tensor.cc', 'patch': '@@ -16,6 +16,7 @@ limitations under the License.\\n #include \"tensorflow\/python\/lib\/core\/ndarray_tensor.h\"\\n \\n #include <cstring>\\n+#include <optional>\\n \\n #include \"tensorflow\/c\/eager\/tfe_context_internal.h\"\\n #include \"tensorflow\/c\/tf_tensor_internal.h\"\\n@@ -74,6 +75,13 @@ Status PyArrayDescr_to_TF_DataType(PyArray_Descr* descr,\\n   PyObject* key;\\n   PyObject* value;\\n   Py_ssize_t pos = 0;\\n+\\n+  \/\/ Return an error if the fields attribute is null.\\n+  \/\/ Occurs with an improper conversion attempt to resource.\\n+  if (descr->fields == nullptr) {\\n+    return errors::Internal(\"Unexpected numpy data type\");\\n+  }\\n+\\n   if (PyDict_Next(descr->fields, &pos, &key, &value)) {\\n     \/\/ In Python 3, the keys of numpy custom struct types are unicode, unlike\\n     \/\/ Python 2, where the keys are bytes.'}}",
            "message_norm":"fix `tf.raw_ops.resourcecountupto` null pointer dereference.\n\npiperorigin-revid: 368294347\nchange-id: i2c16fbfc9b4966c402c3d8e311f0d665a9c852d8",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('null pointer dereference', 'SECWORD', ''), ('368294347', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/python\/lib\/core\/ndarray_tensor.cc'])",
            "num_files":1.0
        },
        {
            "index":604,
            "vuln_id":"GHSA-59q2-x2qc-4c97",
            "cwe_id":"{'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/51300ba1cc2f487aefec6e6631fef03b0e08b298'}",
            "dataset":"osv",
            "summary":"Heap OOB access in unicode ops ### Impact\nAn attacker can access data outside of bounds of heap allocated array in `tf.raw_ops.UnicodeEncode`:\n\n```python\nimport tensorflow as tf\n\ninput_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)\noutput_encoding = \"UTF-8\"\n\ntf.raw_ops.UnicodeEncode(\n    input_values=input_values, input_splits=input_splits,\n    output_encoding=output_encoding)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/472c1f12ad9063405737679d4f6bd43094e1d36d\/tensorflow\/core\/kernels\/unicode_ops.cc)\nassumes that the `input_value`\/`input_splits` pair specify a valid sparse tensor.\n\n### Patches\nWe have patched the issue in GitHub commit [51300ba1cc2f487aefec6e6631fef03b0e08b298](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/51300ba1cc2f487aefec6e6631fef03b0e08b298).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/51300ba1cc2f487aefec6e6631fef03b0e08b298",
            "commit_sha":"51300ba1cc2f487aefec6e6631fef03b0e08b298",
            "patch":"SINGLE",
            "chain_ord":"['51300ba1cc2f487aefec6e6631fef03b0e08b298']",
            "before_first_fix_commit":"{'472c1f12ad9063405737679d4f6bd43094e1d36d'}",
            "last_fix_commit":"51300ba1cc2f487aefec6e6631fef03b0e08b298",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/03\/2021, 16:53:26",
            "message":"Fix heap buffer overflow in tf.raw_ops.UnicodeEncode.\n\nPiperOrigin-RevId: 371717714\nChange-Id: If33443b28f158e58078f1268f6b92f2728d219e0",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 0, 'total': 19}",
            "files":"{'tensorflow\/core\/kernels\/unicode_ops.cc': {'additions': 19, 'deletions': 0, 'changes': 19, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/51300ba1cc2f487aefec6e6631fef03b0e08b298\/tensorflow%2Fcore%2Fkernels%2Funicode_ops.cc', 'patch': '@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\\n     const Tensor& input_splits = context->input(1);\\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\\n \\n+    \/\/ Operation will treat first argument in input_splits as if it were zero\\n+    \/\/ regardless of its actual value since splits should begin with zero and\\n+    \/\/ end with the length of the input values vector.\\n+    OP_REQUIRES(\\n+        context, input_splits_flat(0) == 0,\\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\\n+    OP_REQUIRES(context,\\n+                input_splits_flat(input_splits_flat.size() - 1) ==\\n+                    input_tensor_flat.size(),\\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\\n+                                        \"equal to length of input_tensor.\"));\\n     \/\/ Since we limit to a 2-D input (flat_values of rank 1 and a single splits\\n     \/\/ tensor), our output dimension will be 1 with it\\'s size equal to the\\n     \/\/ number of splits (outer dimension or ragged tensor).\\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\\n       icu::UnicodeString unicode_string;\\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\\n+      OP_REQUIRES(\\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\\n+          errors::InvalidArgument(\\n+              \"Values in input_splits must be equal or in ascending order.\"));\\n+      OP_REQUIRES(\\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\\n+                                  \"equal to input_tensor length.\"));\\n       for (; idx < input_splits_flat(i); ++idx) {\\n         int32 code_point = input_tensor_flat(idx);\\n         \/\/ Check for invalid code point'}}",
            "message_norm":"fix heap buffer overflow in tf.raw_ops.unicodeencode.\n\npiperorigin-revid: 371717714\nchange-id: if33443b28f158e58078f1268f6b92f2728d219e0",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('tf.raw_ops.unicodeencode', 'SECWORD', ''), ('371717714', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/unicode_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":820,
            "vuln_id":"GHSA-6cpj-3g83-q2j4",
            "cwe_id":"{'CWE-611'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/apache\/lucene-solr\/commit\/f230486ce6707762c1a6e81655d0fac52887906d', 'https:\/\/github.com\/apache\/lucene-solr\/commit\/0d21b900975b7048d2e925d852aeacb9bdc6766c'}",
            "dataset":"osv",
            "summary":"Improper Restriction of XML External Entity Reference in Apache Solr The (1) UpdateRequestHandler for XSLT or (2) XPathEntityProcessor in Apache Solr before 4.1 allows remote attackers to have an unspecified impact via XML data containing an external entity declaration in conjunction with an entity reference, related to an XML External Entity (XXE) issue, different vectors than CVE-2013-6407.",
            "published_date":"2022-05-17",
            "chain_len":2,
            "project":"https:\/\/github.com\/apache\/lucene-solr",
            "commit_href":"https:\/\/github.com\/apache\/lucene-solr\/commit\/0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "commit_sha":"0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "patch":"MULTI",
            "chain_ord":"['f230486ce6707762c1a6e81655d0fac52887906d', '0d21b900975b7048d2e925d852aeacb9bdc6766c']",
            "before_first_fix_commit":"{'f230486ce6707762c1a6e81655d0fac52887906d'}",
            "last_fix_commit":"0d21b900975b7048d2e925d852aeacb9bdc6766c",
            "chain_ord_pos":2.0,
            "commit_datetime":"09\/27\/2012, 13:15:24",
            "message":"SOLR-3895, SOLR-3614: Fix javadocs\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991 13f79535-47bb-0310-9956-ffa450edef68",
            "author":"Uwe Schindler",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/lucene-solr\/raw\/0d21b900975b7048d2e925d852aeacb9bdc6766c\/solr%2Fcore%2Fsrc%2Fjava%2Forg%2Fapache%2Fsolr%2Futil%2FEmptyEntityResolver.java', 'patch': '@@ -67,7 +67,7 @@ private static void trySetSAXFeature(SAXParserFactory saxFactory, String feature\\n   }\\n   \\n   \/** Configures the given {@link SAXParserFactory} to do secure XML processing of untrusted sources.\\n-   * It is required to also set {@link #SAX_INSTANCE} on the created {@link XMLReader}.\\n+   * It is required to also set {@link #SAX_INSTANCE} on the created {@link org.xml.sax.XMLReader}.\\n    * @see #SAX_INSTANCE\\n    *\/\\n   public static void configureSAXParserFactory(SAXParserFactory saxFactory) {'}}",
            "message_norm":"solr-3895, solr-3614: fix javadocs\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991 13f79535-47bb-0310-9956-ffa450edef68",
            "language":"sv",
            "entities":"[('fix', 'ACTION', ''), ('https:\/\/svn.apache.org\/repos\/asf\/lucene\/dev\/trunk@1390991', 'URL', ''), ('13f79535', 'SHA', 'generic_sha'), ('ffa450edef68', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['solr\/core\/src\/java\/org\/apache\/solr\/util\/EmptyEntityResolver.java'])",
            "num_files":1.0
        },
        {
            "index":1017,
            "vuln_id":"GHSA-7f53-fmmv-mfjv",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/facebook\/react-native\/commit\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7'}",
            "dataset":"osv",
            "summary":"Regular expression denial of service in react-native A regular expression denial of service (ReDoS) vulnerability in the validateBaseUrl function can cause the application to use excessive resources, become unresponsive, or crash. This was introduced in react-native version 0.59.0 and fixed in version 0.64.1.",
            "published_date":"2021-07-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/facebook\/react-native",
            "commit_href":"https:\/\/github.com\/facebook\/react-native\/commit\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
            "commit_sha":"ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
            "patch":"SINGLE",
            "chain_ord":"['ca09ae82715e33c9ac77b3fa55495cf84ba891c7']",
            "before_first_fix_commit":"{'166a5ddf88aca0d0235e48c624681eec095e9ef8'}",
            "last_fix_commit":"ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/29\/2021, 21:51:29",
            "message":"Update validateBaseUrl to use latest regex\n\nSummary:\nUpdating the regex to avoid a potential regular expression denial-of-service vulnerability.\n\nChangelog: Update validateBaseUrl to use a more robust regular expression. Fixes CVE-2020-1920, GHSL-2020-293\n\nReviewed By: lunaleaps\n\nDifferential Revision: D25507604\n\nfbshipit-source-id: c36a03c456881bc655c861e1a2c5cd41a7127c9d",
            "author":"Neal Poole",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'Libraries\/Blob\/URL.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/facebook\/react-native\/raw\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7\/Libraries%2FBlob%2FURL.js', 'patch': '@@ -107,7 +107,7 @@ export class URLSearchParams {\\n \\n function validateBaseUrl(url: string) {\\n   \/\/ from this MIT-licensed gist: https:\/\/gist.github.com\/dperini\/729294\\n-  return \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)*(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,}))?)(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i.test(\\n+  return \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z0-9\\\\u00a1-\\\\uffff][a-z0-9\\\\u00a1-\\\\uffff_-]{0,62})?[a-z0-9\\\\u00a1-\\\\uffff]\\\\.)*(?:[a-z\\\\u00a1-\\\\uffff]{2,}\\\\.?))(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/.test(\\n     url,\\n   );\\n }'}}",
            "message_norm":"update validatebaseurl to use latest regex\n\nsummary:\nupdating the regex to avoid a potential regular expression denial-of-service vulnerability.\n\nchangelog: update validatebaseurl to use a more robust regular expression. fixes cve-2020-1920, ghsl-2020-293\n\nreviewed by: lunaleaps\n\ndifferential revision: d25507604\n\nfbshipit-source-id: c36a03c456881bc655c861e1a2c5cd41a7127c9d",
            "language":"en",
            "entities":"[('update', 'ACTION', ''), ('updating', 'ACTION', ''), ('denial-of-service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('update', 'ACTION', ''), ('cve-2020-1920', 'VULNID', 'CVE'), ('d25507604', 'SHA', 'generic_sha'), ('c36a03c456881bc655c861e1a2c5cd41a7127c9d', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Libraries\/Blob\/URL.js'])",
            "num_files":1.0
        }
    ]
}