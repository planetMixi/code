{
    "schema":{
        "fields":[
            {
                "name":"index",
                "type":"integer"
            },
            {
                "name":"vuln_id",
                "type":"string"
            },
            {
                "name":"cwe_id",
                "type":"string"
            },
            {
                "name":"score",
                "type":"number"
            },
            {
                "name":"chain",
                "type":"string"
            },
            {
                "name":"dataset",
                "type":"string"
            },
            {
                "name":"summary",
                "type":"string"
            },
            {
                "name":"published_date",
                "type":"string"
            },
            {
                "name":"chain_len",
                "type":"integer"
            },
            {
                "name":"project",
                "type":"string"
            },
            {
                "name":"commit_href",
                "type":"string"
            },
            {
                "name":"commit_sha",
                "type":"string"
            },
            {
                "name":"patch",
                "type":"string"
            },
            {
                "name":"chain_ord",
                "type":"string"
            },
            {
                "name":"before_first_fix_commit",
                "type":"string"
            },
            {
                "name":"last_fix_commit",
                "type":"string"
            },
            {
                "name":"chain_ord_pos",
                "type":"number"
            },
            {
                "name":"commit_datetime",
                "type":"string"
            },
            {
                "name":"message",
                "type":"string"
            },
            {
                "name":"author",
                "type":"string"
            },
            {
                "name":"comments",
                "type":"string"
            },
            {
                "name":"stats",
                "type":"string"
            },
            {
                "name":"files",
                "type":"string"
            },
            {
                "name":"message_norm",
                "type":"string"
            },
            {
                "name":"language",
                "type":"string"
            },
            {
                "name":"entities",
                "type":"string"
            },
            {
                "name":"classification_level_1",
                "type":"string"
            },
            {
                "name":"classification_level_2",
                "type":"string"
            },
            {
                "name":"list_files",
                "type":"string"
            },
            {
                "name":"num_files",
                "type":"number"
            },
            {
                "name":"patch_content",
                "type":"string"
            }
        ],
        "primaryKey":[
            "index"
        ],
        "pandas_version":"1.4.0"
    },
    "data":[
        {
            "index":347,
            "vuln_id":"GHSA-jfp7-4j67-8r3q",
            "cwe_id":"{'CWE-193', 'CWE-131'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f851613f8f0fb0c838d160ced13c134f778e3ce7'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow caused by rounding ### Impact\nAn attacker can trigger a heap buffer overflow in `tf.raw_ops.QuantizedResizeBilinear` by manipulating input values so that float rounding results in off-by-one error in accessing image elements:\n\n```python\nimport tensorflow as tf\n\nl = [256, 328, 361, 17, 361, 361, 361, 361, 361, 361, 361, 361, 361, 361, 384]\nimages = tf.constant(l, shape=[1, 1, 15, 1], dtype=tf.qint32)\nsize = tf.constant([12, 6], shape=[2], dtype=tf.int32)\nmin = tf.constant(80.22522735595703)\nmax = tf.constant(80.39215850830078)\n\ntf.raw_ops.QuantizedResizeBilinear(images=images, size=size, min=min, max=max,\n                                   align_corners=True, half_pixel_centers=True)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/44b7f486c0143f68b56c34e2d01e146ee445134a\/tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc#L62-L66) computes two integers (representing the upper and lower bounds for interpolation) by ceiling and flooring a floating point value:\n\n```cc\nconst float in_f = std::floor(in);\ninterpolation->lower[i] = std::max(static_cast<int64>(in_f), static_cast<int64>(0));\ninterpolation->upper[i] = std::min(static_cast<int64>(std::ceil(in)), in_size - 1);\n```\n  \nFor some values of `in`, `interpolation->upper[i]` might be smaller than `interpolation->lower[i]`. This is an issue if `interpolation->upper[i]` is capped at `in_size-1` as it means that `interpolation->lower[i]` points outside of the image. Then, [in the interpolation code](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/44b7f486c0143f68b56c34e2d01e146ee445134a\/tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc#L245-L264), this would result in heap buffer overflow:\n\n```cc\ntemplate <int RESOLUTION, typename T, typename T_SCALE, typename T_CALC>\ninline void OutputLerpForChannels(const InterpolationCache<T_SCALE>& xs,\n                                  const int64 x, const T_SCALE ys_ilerp,\n                                  const int channels, const float min,\n                                  const float max, const T* ys_input_lower_ptr,\n                                  const T* ys_input_upper_ptr,\n                                  T* output_y_ptr) {\n  const int64 xs_lower = xs.lower[x];\n  ...\n  for (int c = 0; c < channels; ++c) {\n    const T top_left = ys_input_lower_ptr[xs_lower + c];\n    ...\n  }\n}\n```\n\nFor the other cases where `interpolation->upper[i]` is smaller than `interpolation->lower[i]`, we can set them to be equal without affecting the output.\n\n### Patches\nWe have patched the issue in GitHub commit [f851613f8f0fb0c838d160ced13c134f778e3ce7](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f851613f8f0fb0c838d160ced13c134f778e3ce7).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f851613f8f0fb0c838d160ced13c134f778e3ce7",
            "commit_sha":"f851613f8f0fb0c838d160ced13c134f778e3ce7",
            "patch":"SINGLE",
            "chain_ord":"['f851613f8f0fb0c838d160ced13c134f778e3ce7']",
            "before_first_fix_commit":"{'44b7f486c0143f68b56c34e2d01e146ee445134a'}",
            "last_fix_commit":"f851613f8f0fb0c838d160ced13c134f778e3ce7",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/21\/2021, 23:20:48",
            "message":"Fix heap buffer overflow caused by rounding.\n\nThis was hard to fix. Due to the way we compute the pixels that influence an output pixel in resized images, for certain input configuration we might have issued a read to a pixel that is outside of boundary of the original image. This is because of floating errors that affected truncation results.\n\nPiperOrigin-RevId: 369757871\nChange-Id: If89425fff930983829a2168203c11858883eebc9",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f851613f8f0fb0c838d160ced13c134f778e3ce7\/tensorflow%2Fcore%2Fkernels%2Fquantized_resize_bilinear_op.cc', 'patch': '@@ -64,6 +64,8 @@ inline void ComputeInterpolationWeights(\\n         std::max(static_cast<int64>(in_f), static_cast<int64>(0));\\n     interpolation->upper[i] =\\n         std::min(static_cast<int64>(std::ceil(in)), in_size - 1);\\n+    interpolation->lower[i] =\\n+        std::min(interpolation->lower[i], interpolation->upper[i]);\\n     interpolation->lerp[i] = in - in_f;\\n     interpolation->ilerp[i] =\\n         static_cast<T_SCALE>((in - in_f) * (1 << resolution));'}}",
            "message_norm":"fix heap buffer overflow caused by rounding.\n\nthis was hard to fix. due to the way we compute the pixels that influence an output pixel in resized images, for certain input configuration we might have issued a read to a pixel that is outside of boundary of the original image. this is because of floating errors that affected truncation results.\n\npiperorigin-revid: 369757871\nchange-id: if89425fff930983829a2168203c11858883eebc9",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('fix', 'ACTION', ''), ('outside of boundary', 'SECWORD', ''), ('errors', 'FLAW', ''), ('369757871', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc'])",
            "num_files":1.0,
            "patch_content":"From f851613f8f0fb0c838d160ced13c134f778e3ce7 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 21 Apr 2021 16:20:48 -0700\nSubject: [PATCH] Fix heap buffer overflow caused by rounding.\n\nThis was hard to fix. Due to the way we compute the pixels that influence an output pixel in resized images, for certain input configuration we might have issued a read to a pixel that is outside of boundary of the original image. This is because of floating errors that affected truncation results.\n\nPiperOrigin-RevId: 369757871\nChange-Id: If89425fff930983829a2168203c11858883eebc9\n---\n tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc b\/tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc\nindex 07453c7e73284b..2fd807f6df9614 100644\n--- a\/tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantized_resize_bilinear_op.cc\n@@ -64,6 +64,8 @@ inline void ComputeInterpolationWeights(\n         std::max(static_cast<int64>(in_f), static_cast<int64>(0));\n     interpolation->upper[i] =\n         std::min(static_cast<int64>(std::ceil(in)), in_size - 1);\n+    interpolation->lower[i] =\n+        std::min(interpolation->lower[i], interpolation->upper[i]);\n     interpolation->lerp[i] = in - in_f;\n     interpolation->ilerp[i] =\n         static_cast<T_SCALE>((in - in_f) * (1 << resolution));"
        },
        {
            "index":232,
            "vuln_id":"GHSA-43jf-985q-588j",
            "cwe_id":"{'CWE-617'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3d89911481ba6ebe8c88c1c0b595412121e6c645'}",
            "dataset":"osv",
            "summary":"Multiple `CHECK`-fails in `function.cc` in TensowFlow ### Impact\nA malicious user can cause a denial of service by altering a `SavedModel` such that [assertions in `function.cc`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/function.cc) would be falsified and crash the Python interpreter.\n### Patches\nWe have patched the issue in GitHub commits [dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2) and [3d89911481ba6ebe8c88c1c0b595412121e6c645](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3d89911481ba6ebe8c88c1c0b595412121e6c645).\n  \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/3d89911481ba6ebe8c88c1c0b595412121e6c645",
            "commit_sha":"3d89911481ba6ebe8c88c1c0b595412121e6c645",
            "patch":"MULTI",
            "chain_ord":"['3d89911481ba6ebe8c88c1c0b595412121e6c645', 'dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2']",
            "before_first_fix_commit":"{'955059813cc325dc1db5e2daa6221271406d4439'}",
            "last_fix_commit":"dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/12\/2021, 16:12:05",
            "message":"Eliminate `CHECK`-fail from `function.cc`.\n\nPiperOrigin-RevId: 409414744\nChange-Id: Ic854e12ab2edb88b165d32e2d632c4ee654d71ad",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'tensorflow\/core\/framework\/function.cc': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/3d89911481ba6ebe8c88c1c0b595412121e6c645\/tensorflow%2Fcore%2Fframework%2Ffunction.cc', 'patch': '@@ -181,7 +181,9 @@ class FunctionInstantiationHelper {\\n     DataTypeVector dtypes;\\n     TF_RETURN_IF_ERROR(\\n         ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\\n-    CHECK_GE(dtypes.size(), size_t{1});\\n+    if (dtypes.size() < size_t{1}) {\\n+      return errors::Internal(\"Expected a list of at least one dtype\");\\n+    }\\n     int arg_index = result_.nodes.size();\\n     TF_RETURN_IF_ERROR(\\n         AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));'}}",
            "message_norm":"eliminate `check`-fail from `function.cc`.\n\npiperorigin-revid: 409414744\nchange-id: ic854e12ab2edb88b165d32e2d632c4ee654d71ad",
            "language":"it",
            "entities":"[('409414744', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/framework\/function.cc'])",
            "num_files":1.0,
            "patch_content":"From 3d89911481ba6ebe8c88c1c0b595412121e6c645 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 12 Nov 2021 08:12:05 -0800\nSubject: [PATCH] Eliminate `CHECK`-fail from `function.cc`.\n\nPiperOrigin-RevId: 409414744\nChange-Id: Ic854e12ab2edb88b165d32e2d632c4ee654d71ad\n---\n tensorflow\/core\/framework\/function.cc | 4 +++-\n 1 file changed, 3 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/framework\/function.cc b\/tensorflow\/core\/framework\/function.cc\nindex 41b8d446149694..492d9d54fe60eb 100644\n--- a\/tensorflow\/core\/framework\/function.cc\n+++ b\/tensorflow\/core\/framework\/function.cc\n@@ -181,7 +181,9 @@ class FunctionInstantiationHelper {\n     DataTypeVector dtypes;\n     TF_RETURN_IF_ERROR(\n         ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n-    CHECK_GE(dtypes.size(), size_t{1});\n+    if (dtypes.size() < size_t{1}) {\n+      return errors::Internal(\"Expected a list of at least one dtype\");\n+    }\n     int arg_index = result_.nodes.size();\n     TF_RETURN_IF_ERROR(\n         AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));"
        },
        {
            "index":564,
            "vuln_id":"GHSA-cvpc-8phh-8f45",
            "cwe_id":"{'CWE-787', 'CWE-125'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/00302787b788c5ff04cb6f62aed5a74d936e86c0', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e11f55585f614645b360563072ffeb5c3eeff162', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/46d5b0852528ddfd614ded79bccc75589f801bd9', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1970c2158b1ffa416d159d03c3370b9a462aee35', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/fff2c8326280c07733828f990548979bdc893859'}",
            "dataset":"osv",
            "summary":"Out of bounds access in tensorflow-lite ### Impact\nIn TensorFlow Lite, saved models in the flatbuffer format use a double indexing scheme: a model has a set of subgraphs, each subgraph has a set of operators and each operator has a set of input\/output tensors. The flatbuffer format uses indices for the tensors, indexing into an array of tensors that is owned by the subgraph. This results in a pattern of double array indexing when trying to get the data of each tensor:https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/kernels\/kernel_util.cc#L36\n\nHowever, some operators can have some tensors be optional. To handle this scenario, the flatbuffer model uses a negative `-1` value as index for these tensors:\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/c\/common.h#L82\n\nThis results in special casing during validation at model loading time: https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/core\/subgraph.cc#L566-L580\n\nUnfortunately, this means that the `-1` index is a valid tensor index for any operator, including those that don't expect optional inputs and including for output tensors. Thus, this allows writing and reading from outside the bounds of heap allocated arrays, although only at a specific offset from the start of these arrays.\n\nThis results in both read and write gadgets, albeit very limited in scope.\n\n### Patches\nWe have patched the issue in several commits (46d5b0852, 00302787b7, e11f5558, cd31fd0ce, 1970c21, and fff2c83). We will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### Workarounds\nA potential workaround would be to add a custom `Verifier` to the model loading code to ensure that only operators which accept optional inputs use the `-1` special value and only for the tensors that they expect to be optional. Since this allow-list type approach is erro-prone, we advise upgrading to the patched code.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2020-09-25",
            "chain_len":6,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f",
            "commit_sha":"cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f",
            "patch":"MULTI",
            "chain_ord":"['46d5b0852528ddfd614ded79bccc75589f801bd9', '00302787b788c5ff04cb6f62aed5a74d936e86c0', 'e11f55585f614645b360563072ffeb5c3eeff162', 'cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'fff2c8326280c07733828f990548979bdc893859', '1970c2158b1ffa416d159d03c3370b9a462aee35']",
            "before_first_fix_commit":"{'fff2c8326280c07733828f990548979bdc893859'}",
            "last_fix_commit":"1970c2158b1ffa416d159d03c3370b9a462aee35",
            "chain_ord_pos":4.0,
            "commit_datetime":"09\/18\/2020, 20:44:32",
            "message":"[tflite]: Insert `nullptr` checks when obtaining tensors.\n\nAs part of ongoing refactoring, `tflite::GetInput`, `tflite::GetOutput`, `tflite::GetTemporary` and `tflite::GetIntermediates` will return `nullptr` in some cases. Hence, we insert the `nullptr` checks on all usages.\n\nWe also insert `nullptr` checks on usages of `tflite::GetVariableInput` and `tflite::GetOptionalInputTensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\nPiperOrigin-RevId: 332518902\nChange-Id: I92eb164a6101ac3cca66090061a9b56a97288236",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 7, 'total': 23}",
            "files":"{'tensorflow\/lite\/micro\/test_helpers.cc': {'additions': 16, 'deletions': 7, 'changes': 23, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f\/tensorflow%2Flite%2Fmicro%2Ftest_helpers.cc', 'patch': '@@ -601,7 +601,8 @@ TfLiteStatus SimpleStatefulOp::Prepare(TfLiteContext* context,\\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\\n \\n   \/\/ Make sure that the input is in uint8_t with at least 1 data entry.\\n-  const TfLiteTensor* input = tflite::GetInput(context, node, kInputTensor);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\\n   if (input->type != kTfLiteUInt8) return kTfLiteError;\\n   if (NumElements(input->dims) == 0) return kTfLiteError;\\n \\n@@ -622,7 +623,8 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\\n   *data->invoke_count += 1;\\n \\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\\n   const uint8_t* input_data = GetTensorData<uint8_t>(input);\\n   int size = NumElements(input->dims);\\n \\n@@ -641,9 +643,13 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\\n     }\\n   }\\n \\n-  TfLiteTensor* median = GetOutput(context, node, kMedianTensor);\\n+  TfLiteTensor* median;\\n+  TF_LITE_ENSURE_OK(context,\\n+                    GetOutputSafe(context, node, kMedianTensor, &median));\\n   uint8_t* median_data = GetTensorData<uint8_t>(median);\\n-  TfLiteTensor* invoke_count = GetOutput(context, node, kInvokeCount);\\n+  TfLiteTensor* invoke_count;\\n+  TF_LITE_ENSURE_OK(context,\\n+                    GetOutputSafe(context, node, kInvokeCount, &invoke_count));\\n   int32_t* invoke_count_data = GetTensorData<int32_t>(invoke_count);\\n \\n   median_data[0] = sorting_buffer[size \/ 2];\\n@@ -681,11 +687,14 @@ TfLiteStatus MockCustom::Prepare(TfLiteContext* context, TfLiteNode* node) {\\n }\\n \\n TfLiteStatus MockCustom::Invoke(TfLiteContext* context, TfLiteNode* node) {\\n-  const TfLiteTensor* input = tflite::GetInput(context, node, 0);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\\n   const int32_t* input_data = input->data.i32;\\n-  const TfLiteTensor* weight = tflite::GetInput(context, node, 1);\\n+  const TfLiteTensor* weight;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &weight));\\n   const uint8_t* weight_data = weight->data.uint8;\\n-  TfLiteTensor* output = GetOutput(context, node, 0);\\n+  TfLiteTensor* output;\\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\\n   int32_t* output_data = output->data.i32;\\n   output_data[0] =\\n       0;  \/\/ Catch output tensor sharing memory with an input tensor'}}",
            "message_norm":"[tflite]: insert `nullptr` checks when obtaining tensors.\n\nas part of ongoing refactoring, `tflite::getinput`, `tflite::getoutput`, `tflite::gettemporary` and `tflite::getintermediates` will return `nullptr` in some cases. hence, we insert the `nullptr` checks on all usages.\n\nwe also insert `nullptr` checks on usages of `tflite::getvariableinput` and `tflite::getoptionalinputtensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\npiperorigin-revid: 332518902\nchange-id: i92eb164a6101ac3cca66090061a9b56a97288236",
            "language":"en",
            "entities":"[('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('332518902', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/micro\/test_helpers.cc'])",
            "num_files":1.0,
            "patch_content":"From cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 18 Sep 2020 13:44:32 -0700\nSubject: [PATCH] [tflite]: Insert `nullptr` checks when obtaining tensors.\n\nAs part of ongoing refactoring, `tflite::GetInput`, `tflite::GetOutput`, `tflite::GetTemporary` and `tflite::GetIntermediates` will return `nullptr` in some cases. Hence, we insert the `nullptr` checks on all usages.\n\nWe also insert `nullptr` checks on usages of `tflite::GetVariableInput` and `tflite::GetOptionalInputTensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\nPiperOrigin-RevId: 332518902\nChange-Id: I92eb164a6101ac3cca66090061a9b56a97288236\n---\n tensorflow\/lite\/micro\/test_helpers.cc | 23 ++++++++++++++++-------\n 1 file changed, 16 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/micro\/test_helpers.cc b\/tensorflow\/lite\/micro\/test_helpers.cc\nindex dd5e996ac26aa6..26575a4d98da9f 100644\n--- a\/tensorflow\/lite\/micro\/test_helpers.cc\n+++ b\/tensorflow\/lite\/micro\/test_helpers.cc\n@@ -601,7 +601,8 @@ TfLiteStatus SimpleStatefulOp::Prepare(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n   \/\/ Make sure that the input is in uint8_t with at least 1 data entry.\n-  const TfLiteTensor* input = tflite::GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   if (input->type != kTfLiteUInt8) return kTfLiteError;\n   if (NumElements(input->dims) == 0) return kTfLiteError;\n \n@@ -622,7 +623,8 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n   *data->invoke_count += 1;\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const uint8_t* input_data = GetTensorData<uint8_t>(input);\n   int size = NumElements(input->dims);\n \n@@ -641,9 +643,13 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\n     }\n   }\n \n-  TfLiteTensor* median = GetOutput(context, node, kMedianTensor);\n+  TfLiteTensor* median;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kMedianTensor, &median));\n   uint8_t* median_data = GetTensorData<uint8_t>(median);\n-  TfLiteTensor* invoke_count = GetOutput(context, node, kInvokeCount);\n+  TfLiteTensor* invoke_count;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kInvokeCount, &invoke_count));\n   int32_t* invoke_count_data = GetTensorData<int32_t>(invoke_count);\n \n   median_data[0] = sorting_buffer[size \/ 2];\n@@ -681,11 +687,14 @@ TfLiteStatus MockCustom::Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus MockCustom::Invoke(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = tflite::GetInput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   const int32_t* input_data = input->data.i32;\n-  const TfLiteTensor* weight = tflite::GetInput(context, node, 1);\n+  const TfLiteTensor* weight;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &weight));\n   const uint8_t* weight_data = weight->data.uint8;\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   int32_t* output_data = output->data.i32;\n   output_data[0] =\n       0;  \/\/ Catch output tensor sharing memory with an input tensor"
        },
        {
            "index":712,
            "vuln_id":"GHSA-q99r-j969-6jwr",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/7e9a2ee60baa95ceb4f48f522f823c812ca90c80', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/31f2588c7ba5b446bccf2769e9ecf4d444b73045'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1138, CVE-2019-1217, CVE-2019-1298, CVE-2019-1300.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/31f2588c7ba5b446bccf2769e9ecf4d444b73045",
            "commit_sha":"31f2588c7ba5b446bccf2769e9ecf4d444b73045",
            "patch":"MULTI",
            "chain_ord":"['31f2588c7ba5b446bccf2769e9ecf4d444b73045', '7e9a2ee60baa95ceb4f48f522f823c812ca90c80']",
            "before_first_fix_commit":"{'edf5eeef49168bbcc30dac82f57048ad46988295', 'c5297b86536fbf1a02d27cec28fea3c516e6ab84'}",
            "last_fix_commit":"7e9a2ee60baa95ceb4f48f522f823c812ca90c80",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/26\/2019, 22:39:34",
            "message":"[CVE-2019-1237]",
            "author":"Michael Holman",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'lib\/Runtime\/Library\/BoundFunction.cpp': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/31f2588c7ba5b446bccf2769e9ecf4d444b73045\/lib%2FRuntime%2FLibrary%2FBoundFunction.cpp', 'patch': \"@@ -354,6 +354,12 @@ namespace Js\\n             Var varLength;\\n             if (targetFunction->GetProperty(targetFunction, PropertyIds::length, &varLength, nullptr, requestContext))\\n             {\\n+                if (!TaggedInt::Is(varLength))\\n+                {\\n+                    \/\/ ToInt32 conversion on non-primitive length can invalidate assumptions made by the JIT,\\n+                    \/\/ so add implicit call flag if length isn't a TaggedInt already\\n+                    requestContext->GetThreadContext()->AddImplicitCallFlags(ImplicitCall_Accessor);\\n+                }\\n                 len = JavascriptConversion::ToInt32(varLength, requestContext);\\n             }\"}}",
            "message_norm":"[cve-2019-1237]",
            "language":"ro",
            "entities":"[('cve-2019-1237', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Runtime\/Library\/BoundFunction.cpp'])",
            "num_files":1.0,
            "patch_content":"From 31f2588c7ba5b446bccf2769e9ecf4d444b73045 Mon Sep 17 00:00:00 2001\nFrom: Michael Holman <michhol@microsoft.com>\nDate: Fri, 26 Jul 2019 15:39:34 -0700\nSubject: [PATCH] [CVE-2019-1237]\n\n---\n lib\/Runtime\/Library\/BoundFunction.cpp | 6 ++++++\n 1 file changed, 6 insertions(+)\n\ndiff --git a\/lib\/Runtime\/Library\/BoundFunction.cpp b\/lib\/Runtime\/Library\/BoundFunction.cpp\nindex 754350e3ae7..ce4a0d5c892 100644\n--- a\/lib\/Runtime\/Library\/BoundFunction.cpp\n+++ b\/lib\/Runtime\/Library\/BoundFunction.cpp\n@@ -354,6 +354,12 @@ namespace Js\n             Var varLength;\n             if (targetFunction->GetProperty(targetFunction, PropertyIds::length, &varLength, nullptr, requestContext))\n             {\n+                if (!TaggedInt::Is(varLength))\n+                {\n+                    \/\/ ToInt32 conversion on non-primitive length can invalidate assumptions made by the JIT,\n+                    \/\/ so add implicit call flag if length isn't a TaggedInt already\n+                    requestContext->GetThreadContext()->AddImplicitCallFlags(ImplicitCall_Accessor);\n+                }\n                 len = JavascriptConversion::ToInt32(varLength, requestContext);\n             }"
        },
        {
            "index":361,
            "vuln_id":"GHSA-83rx-c8cr-6j8q",
            "cwe_id":"{'CWE-829'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/naptha\/tesseract.js\/commit\/679eba055f2a4271558e86beec3d1b70cae3fb28'}",
            "dataset":"osv",
            "summary":"Insecure Default Configuration in tesseract.js Versions of `tesseract.js` prior to 1.0.19 default to using a third-party proxy.  Requests may be proxied through `crossorigin.me` which clearly states is not suitable for production use. This may lead to instability and privacy violations.\n\n\n## Recommendation\n\nUpgrade to version 1.0.19 or later.",
            "published_date":"2019-06-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/naptha\/tesseract.js",
            "commit_href":"https:\/\/github.com\/naptha\/tesseract.js\/commit\/679eba055f2a4271558e86beec3d1b70cae3fb28",
            "commit_sha":"679eba055f2a4271558e86beec3d1b70cae3fb28",
            "patch":"SINGLE",
            "chain_ord":"['679eba055f2a4271558e86beec3d1b70cae3fb28']",
            "before_first_fix_commit":"{'06d32c6804acbf1f5af1c13966cb72a4ff864ecb'}",
            "last_fix_commit":"679eba055f2a4271558e86beec3d1b70cae3fb28",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/16\/2019, 12:34:36",
            "message":"Add stubs for error handling",
            "author":"HoldYourWaffle",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 6, 'total': 17}",
            "files":"{'src\/browser\/index.js': {'additions': 11, 'deletions': 6, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/naptha\/tesseract.js\/raw\/679eba055f2a4271558e86beec3d1b70cae3fb28\/src%2Fbrowser%2Findex.js', 'patch': '@@ -52,25 +52,30 @@ function loadImage(image, cb){\\n             var im = new Image\\n             im.src = image;\\n             im.onload = e => loadImage(im, cb);\\n+            \/\/im.onerror = e => ?; TODO handle error\\n             return\\n         }else{\\n             var xhr = new XMLHttpRequest();\\n             xhr.open(\\'GET\\', image, true)\\n             xhr.responseType = \"blob\";\\n-            xhr.onload = e => loadImage(xhr.response, cb);\\n-            xhr.onerror = function(e){\\n-                if(\/^https?:\\\\\/\\\\\/\/.test(image) && !\/^https:\\\\\/\\\\\/crossorigin.me\/.test(image)){\\n-                    console.debug(\\'Attempting to load image with CORS proxy\\')\\n-                    loadImage(\\'https:\/\/crossorigin.me\/\\' + image, cb)\\n+            \\n+            xhr.onload = e => {\\n+                if (xhr.status >= 400){\\n+                    \/\/TODO handle error\\n+                }else{\\n+                    loadImage(xhr.response, cb);\\n                 }\\n-            }\\n+            };\\n+            \/\/xhr.onerror = e => ?; TODO handle error\\n+            \\n             xhr.send(null)\\n             return\\n         }\\n     }else if(image instanceof File){\\n         \/\/ files\\n         var fr = new FileReader()\\n         fr.onload = e => loadImage(fr.result, cb);\\n+        \/\/fr.onerror = e => ?; TODO handle error\\n         fr.readAsDataURL(image)\\n         return\\n     }else if(image instanceof Blob){'}}",
            "message_norm":"add stubs for error handling",
            "language":"da",
            "entities":"[('add', 'ACTION', ''), ('error handling', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/browser\/index.js'])",
            "num_files":1.0,
            "patch_content":"From 679eba055f2a4271558e86beec3d1b70cae3fb28 Mon Sep 17 00:00:00 2001\nFrom: HoldYourWaffle <ravivanrooijen@live.nl>\nDate: Sat, 16 Feb 2019 13:34:36 +0100\nSubject: [PATCH] Add stubs for error handling\n\n---\n src\/browser\/index.js | 17 +++++++++++------\n 1 file changed, 11 insertions(+), 6 deletions(-)\n\ndiff --git a\/src\/browser\/index.js b\/src\/browser\/index.js\nindex c4ff83b20..e955462ef 100644\n--- a\/src\/browser\/index.js\n+++ b\/src\/browser\/index.js\n@@ -52,18 +52,22 @@ function loadImage(image, cb){\n             var im = new Image\n             im.src = image;\n             im.onload = e => loadImage(im, cb);\n+            \/\/im.onerror = e => ?; TODO handle error\n             return\n         }else{\n             var xhr = new XMLHttpRequest();\n             xhr.open('GET', image, true)\n             xhr.responseType = \"blob\";\n-            xhr.onload = e => loadImage(xhr.response, cb);\n-            xhr.onerror = function(e){\n-                if(\/^https?:\\\/\\\/\/.test(image) && !\/^https:\\\/\\\/crossorigin.me\/.test(image)){\n-                    console.debug('Attempting to load image with CORS proxy')\n-                    loadImage('https:\/\/crossorigin.me\/' + image, cb)\n+            \n+            xhr.onload = e => {\n+                if (xhr.status >= 400){\n+                    \/\/TODO handle error\n+                }else{\n+                    loadImage(xhr.response, cb);\n                 }\n-            }\n+            };\n+            \/\/xhr.onerror = e => ?; TODO handle error\n+            \n             xhr.send(null)\n             return\n         }\n@@ -71,6 +75,7 @@ function loadImage(image, cb){\n         \/\/ files\n         var fr = new FileReader()\n         fr.onload = e => loadImage(fr.result, cb);\n+        \/\/fr.onerror = e => ?; TODO handle error\n         fr.readAsDataURL(image)\n         return\n     }else if(image instanceof Blob){"
        },
        {
            "index":4,
            "vuln_id":"GHSA-mvqp-q37c-wf9j",
            "cwe_id":"{'CWE-74'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/ratpack\/ratpack\/commit\/c560a8d10cb8bdd7a526c1ca2e67c8f224ca23ae', 'https:\/\/github.com\/ratpack\/ratpack\/commit\/efb910d38a96494256f36675ef0e5061097dd77d'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects io.ratpack:ratpack-core ## CWE-113: Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting')\n\nVersions of Ratpack 0.9.1 through and including 1.7.4 are vulnerable to [HTTP Response Splitting](https:\/\/www.owasp.org\/index.php\/HTTP_Response_Splitting), \nif untrusted and unsanitized data is used to populate the headers of an HTTP response.\nAn attacker can utilize this vulnerability to have the server issue any HTTP response they specify.\n\nIf your application uses arbitrary user input as the value of a response header it is vulnerable.\nIf your application does not use arbitrary values as response header values, it is not vulnerable.\n\nPreviously, Ratpack did not validate response header values.\nNow, adding a header value that contains the header value termination characters (CRLF) produces a runtime exception.\nSince there is no mechanism for escaping or encoding the termination characters in a String, a runtime exception is necessary.\n\nAs potentially dangerous values now cause runtime exceptions, it is a good idea to continue to validate and sanitize any user-supplied values being used as response headers.\n\nWe would like to thank [Jonathan Leitschuh](https:\/\/github.com\/JLLeitschuh) for reporting this vulnerability.\n\n### Vulnerable Example\n\nThe following example server uses a query parameter value as a response header, without validating or sanitizing it.\n```java\nRatpackServer startedServer =  RatpackServer.start(server -> {\n    server.handlers(chain -> chain.all(ctx -> {\n        \/\/ User supplied query parameter\n        String header = ctx.getRequest().getQueryParams().get(\"header\");\n        \/\/ User supplied data used to populate a header value.\n        ctx.header(\"the-header\", header)\n            .render(\"OK!\");\n    }));\n});\n```\n\nSending a request to the server with the following value for the `header` query param would allow the execution of arbitrary Javascript.\n\n```\nContent-Type: text\/html\nX-XSS-Protection: 0\n\n<script>alert(document.domain)<\/script>\n```\n\n### Impact\n\n- Cross-User Defacement\n- Cache Poisoning\n- Cross-Site Scripting\n- Page Hijacking\n\n### Patches\n\nThis vulnerability has been patched in Ratpack version 1.7.5.\n\n### Root Cause\n\nThe root cause was due to using the netty `DefaultHttpHeaders` object with verification disabled.\n\nhttps:\/\/github.com\/ratpack\/ratpack\/blob\/af1e8c8590f164d7dd84d4212886fad4ead99080\/ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java#L159\n\nThis vulnerability is now more clearly documented in the Netty documentation: https:\/\/github.com\/netty\/netty\/pull\/9646\n\n### Workarounds\n\nThe workaround for this vulnerability is to either not use arbitrary input as response header values or validate such values before being used to ensure they don't contain a carriage return and\/or line feed characters.\n\n### References\n\n - [CWE-113: Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting')](https:\/\/cwe.mitre.org\/data\/definitions\/113.html)\n - Fix commit: https:\/\/github.com\/ratpack\/ratpack\/commit\/efb910d38a96494256f36675ef0e5061097dd77d\n \n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an issue in [ratpack\/ratpack](https:\/\/github.com\/ratpack\/ratpack\/issues)\n* Ask in our [Slack channel](https:\/\/slack-signup.ratpack.io\/)",
            "published_date":"2019-10-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/ratpack\/ratpack",
            "commit_href":"https:\/\/github.com\/ratpack\/ratpack\/commit\/efb910d38a96494256f36675ef0e5061097dd77d",
            "commit_sha":"efb910d38a96494256f36675ef0e5061097dd77d",
            "patch":"MULTI",
            "chain_ord":"['efb910d38a96494256f36675ef0e5061097dd77d', 'c560a8d10cb8bdd7a526c1ca2e67c8f224ca23ae']",
            "before_first_fix_commit":"{'efb910d38a96494256f36675ef0e5061097dd77d'}",
            "last_fix_commit":"c560a8d10cb8bdd7a526c1ca2e67c8f224ca23ae",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/08\/2019, 23:24:24",
            "message":"Enable HTTP header validation",
            "author":"Luke Daley",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ratpack\/ratpack\/raw\/efb910d38a96494256f36675ef0e5061097dd77d\/ratpack-core%2Fsrc%2Fmain%2Fjava%2Fratpack%2Fserver%2Finternal%2FNettyHandlerAdapter.java', 'patch': '@@ -156,7 +156,7 @@ private void newRequest(ChannelHandlerContext ctx, HttpRequest nettyRequest) thr\\n       channel.attr(CLIENT_CERT_KEY).get()\\n     );\\n \\n-    HttpHeaders nettyHeaders = new DefaultHttpHeaders(false);\\n+    HttpHeaders nettyHeaders = new DefaultHttpHeaders();\\n     MutableHeaders responseHeaders = new NettyHeadersBackedMutableHeaders(nettyHeaders);\\n     AtomicBoolean transmitted = new AtomicBoolean(false);'}}",
            "message_norm":"enable http header validation",
            "language":"nl",
            "entities":"[('header validation', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java'])",
            "num_files":1.0,
            "patch_content":"From efb910d38a96494256f36675ef0e5061097dd77d Mon Sep 17 00:00:00 2001\nFrom: Luke Daley <ld@ldaley.com>\nDate: Wed, 9 Oct 2019 09:24:24 +1000\nSubject: [PATCH] Enable HTTP header validation\n\n---\n ...\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java  | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java b\/ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java\nindex bfd97aa643..ee1034f6bb 100644\n--- a\/ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java\n+++ b\/ratpack-core\/src\/main\/java\/ratpack\/server\/internal\/NettyHandlerAdapter.java\n@@ -156,7 +156,7 @@ private void newRequest(ChannelHandlerContext ctx, HttpRequest nettyRequest) thr\n       channel.attr(CLIENT_CERT_KEY).get()\n     );\n \n-    HttpHeaders nettyHeaders = new DefaultHttpHeaders(false);\n+    HttpHeaders nettyHeaders = new DefaultHttpHeaders();\n     MutableHeaders responseHeaders = new NettyHeadersBackedMutableHeaders(nettyHeaders);\n     AtomicBoolean transmitted = new AtomicBoolean(false);"
        },
        {
            "index":939,
            "vuln_id":"GHSA-6445-fm66-fvq2",
            "cwe_id":"{'CWE-190'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b51b82fe65ebace4475e3c54eb089c18a4403f1c', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a68f68061e263a88321c104a6c911fe5598050a8'}",
            "dataset":"osv",
            "summary":"Integer overflows in Tensorflow ### Impact \nThe [implementation of `AddManySparseToTensorsMap`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc) is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service):\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ntf.raw_ops.AddManySparseToTensorsMap(\n    sparse_indices=[(0,0),(0,1),(0,2),(4,3),(5,0),(5,1)],\n    sparse_values=[1,1,1,1,1,1],\n    sparse_shape=[2**32,2**32],\n    container='',\n    shared_name='',\n    name=None)\n```\n\nWe are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The latter is an instance of [TFSA-2021-198](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/security\/advisory\/tfsa-2021-198.md) (CVE-2021-41197) and is easily fixed by replacing a call to `TensorShape` constructor with a call to `BuildTensorShape` static helper factory.\n### Patches\nWe have patched the issue in GitHub commits [b51b82fe65ebace4475e3c54eb089c18a4403f1c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b51b82fe65ebace4475e3c54eb089c18a4403f1c) and [a68f68061e263a88321c104a6c911fe5598050a8](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a68f68061e263a88321c104a6c911fe5598050a8).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
            "published_date":"2022-02-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b51b82fe65ebace4475e3c54eb089c18a4403f1c",
            "commit_sha":"b51b82fe65ebace4475e3c54eb089c18a4403f1c",
            "patch":"MULTI",
            "chain_ord":"['b51b82fe65ebace4475e3c54eb089c18a4403f1c', 'a68f68061e263a88321c104a6c911fe5598050a8']",
            "before_first_fix_commit":"{'e8f4be7958736823b9f56090611ec2fb09824d51'}",
            "last_fix_commit":"a68f68061e263a88321c104a6c911fe5598050a8",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/09\/2021, 22:32:48",
            "message":"Add missing validation to `AddManySparseToTensorsMap`.\n\nSparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\nPiperOrigin-RevId: 415358027\nChange-Id: I96cbb672999cd1da772c22fabbd15507e32e12dc",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 15, 'deletions': 2, 'total': 17}",
            "files":"{'tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc': {'additions': 15, 'deletions': 2, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b51b82fe65ebace4475e3c54eb089c18a4403f1c\/tensorflow%2Fcore%2Fkernels%2Fsparse_tensors_map_ops.cc', 'patch': '@@ -231,16 +231,29 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\\n                 errors::InvalidArgument(\\n                     \"Input indices should be a matrix but received shape \",\\n                     input_indices->shape().DebugString()));\\n-\\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\\n                 errors::InvalidArgument(\\n                     \"Input values should be a vector but received shape \",\\n                     input_values->shape().DebugString()));\\n-\\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\\n                 errors::InvalidArgument(\\n                     \"Input shape should be a vector but received shape \",\\n                     input_shape->shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context,\\n+        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Number of values must match first dimension of indices. \", \"Got \",\\n+            input_values->shape().dim_size(0),\\n+            \" values, indices shape: \", input_indices->shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context,\\n+        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\\n+        errors::InvalidArgument(\\n+            \"Number of dimensions must match second dimension of indices. \",\\n+            \"Got \", input_shape->shape().dim_size(0),\\n+            \" dimensions, indices shape: \",\\n+            input_indices->shape().DebugString()));\\n \\n     int rank = input_shape->NumElements();'}}",
            "message_norm":"add missing validation to `addmanysparsetotensorsmap`.\n\nsparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\npiperorigin-revid: 415358027\nchange-id: i96cbb672999cd1da772c22fabbd15507e32e12dc",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('415358027', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From b51b82fe65ebace4475e3c54eb089c18a4403f1c Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 9 Dec 2021 14:32:48 -0800\nSubject: [PATCH] Add missing validation to `AddManySparseToTensorsMap`.\n\nSparse tensors have a set of requirements for the 3 components and not all of them were checked.\n\nPiperOrigin-RevId: 415358027\nChange-Id: I96cbb672999cd1da772c22fabbd15507e32e12dc\n---\n ...\/core\/kernels\/sparse_tensors_map_ops.cc      | 17 +++++++++++++++--\n 1 file changed, 15 insertions(+), 2 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc b\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc\nindex 04efed5fd90c75..5fa690743b05c1 100644\n--- a\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_tensors_map_ops.cc\n@@ -231,16 +231,29 @@ class AddManySparseToTensorsMapOp : public SparseTensorAccessingOp {\n                 errors::InvalidArgument(\n                     \"Input indices should be a matrix but received shape \",\n                     input_indices->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                 errors::InvalidArgument(\n                     \"Input values should be a vector but received shape \",\n                     input_values->shape().DebugString()));\n-\n     OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                 errors::InvalidArgument(\n                     \"Input shape should be a vector but received shape \",\n                     input_shape->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Number of values must match first dimension of indices. \", \"Got \",\n+            input_values->shape().dim_size(0),\n+            \" values, indices shape: \", input_indices->shape().DebugString()));\n+    OP_REQUIRES(\n+        context,\n+        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n+        errors::InvalidArgument(\n+            \"Number of dimensions must match second dimension of indices. \",\n+            \"Got \", input_shape->shape().dim_size(0),\n+            \" dimensions, indices shape: \",\n+            input_indices->shape().DebugString()));\n \n     int rank = input_shape->NumElements();"
        },
        {
            "index":179,
            "vuln_id":"GHSA-pm77-c4q7-3fwj",
            "cwe_id":"{'CWE-295'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/globalpayments\/php-sdk\/pull\/8\/commits\/c86e18f28c5eba0d6ede7d557756d978ea83d3c9'}",
            "dataset":"osv",
            "summary":"Improper Certificate Validation in Heartland & Global Payments PHP SDK Gateways\/Gateway.php in Heartland & Global Payments PHP SDK before 2.0.0 does not enforce SSL certificate validations.",
            "published_date":"2021-10-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/globalpayments\/php-sdk",
            "commit_href":"https:\/\/github.com\/globalpayments\/php-sdk\/pull\/8\/commits\/c86e18f28c5eba0d6ede7d557756d978ea83d3c9",
            "commit_sha":"c86e18f28c5eba0d6ede7d557756d978ea83d3c9",
            "patch":"SINGLE",
            "chain_ord":"['c86e18f28c5eba0d6ede7d557756d978ea83d3c9']",
            "before_first_fix_commit":"{'b860aca9b7ed1aeb5a13b5ef52120f5d15efd2f7'}",
            "last_fix_commit":"c86e18f28c5eba0d6ede7d557756d978ea83d3c9",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/26\/2019, 23:32:57",
            "message":"Remove unsecure CURLOPT_SSL_VERIFY* options\n\nVerification of peer certificate against trusted CAs and hostname verification should never be turned off otherwise MITM attacks are possible.",
            "author":"oldpec",
            "comments":null,
            "stats":"{'additions': 0, 'deletions': 2, 'total': 2}",
            "files":"{'src\/Gateways\/Gateway.php': {'additions': 0, 'deletions': 2, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/globalpayments\/php-sdk\/raw\/c86e18f28c5eba0d6ede7d557756d978ea83d3c9\/src%2FGateways%2FGateway.php', 'patch': '@@ -77,8 +77,6 @@ protected function sendRequest(\\n             curl_setopt($request, CURLOPT_CONNECTTIMEOUT, $this->timeout);\\n             curl_setopt($request, CURLOPT_TIMEOUT, $this->timeout);\\n             curl_setopt($request, CURLOPT_RETURNTRANSFER, true);\\n-            curl_setopt($request, CURLOPT_SSL_VERIFYPEER, false); \/\/true,);\\n-            curl_setopt($request, CURLOPT_SSL_VERIFYHOST, false); \/\/2,);\\n             curl_setopt($request, CURLOPT_CUSTOMREQUEST, strtoupper($verb));\\n             curl_setopt($request, CURLOPT_POSTFIELDS, $data);\\n             curl_setopt($request, CURLOPT_HTTPHEADER, $headers);'}}",
            "message_norm":"remove unsecure curlopt_ssl_verify* options\n\nverification of peer certificate against trusted cas and hostname verification should never be turned off otherwise mitm attacks are possible.",
            "language":"en",
            "entities":"[('remove', 'ACTION', ''), ('unsecure', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('hostname', 'SECWORD', ''), ('mitm', 'SECWORD', ''), ('attacks', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Gateways\/Gateway.php'])",
            "num_files":1.0,
            "patch_content":"From c86e18f28c5eba0d6ede7d557756d978ea83d3c9 Mon Sep 17 00:00:00 2001\nFrom: oldpec <paul@paulmcgarry.com>\nDate: Wed, 27 Mar 2019 10:32:57 +1100\nSubject: [PATCH] Remove unsecure CURLOPT_SSL_VERIFY* options\n\nVerification of peer certificate against trusted CAs and hostname verification should never be turned off otherwise MITM attacks are possible.\n---\n src\/Gateways\/Gateway.php | 2 --\n 1 file changed, 2 deletions(-)\n\ndiff --git a\/src\/Gateways\/Gateway.php b\/src\/Gateways\/Gateway.php\nindex 600e42dc..bbe25d42 100644\n--- a\/src\/Gateways\/Gateway.php\n+++ b\/src\/Gateways\/Gateway.php\n@@ -77,8 +77,6 @@ protected function sendRequest(\n             curl_setopt($request, CURLOPT_CONNECTTIMEOUT, $this->timeout);\n             curl_setopt($request, CURLOPT_TIMEOUT, $this->timeout);\n             curl_setopt($request, CURLOPT_RETURNTRANSFER, true);\n-            curl_setopt($request, CURLOPT_SSL_VERIFYPEER, false); \/\/true,);\n-            curl_setopt($request, CURLOPT_SSL_VERIFYHOST, false); \/\/2,);\n             curl_setopt($request, CURLOPT_CUSTOMREQUEST, strtoupper($verb));\n             curl_setopt($request, CURLOPT_POSTFIELDS, $data);\n             curl_setopt($request, CURLOPT_HTTPHEADER, $headers);"
        },
        {
            "index":665,
            "vuln_id":"GHSA-c383-q5vf-hx55",
            "cwe_id":"{'CWE-190'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/7559e141d0707f8eeff2f9aeaa5a0ca2e3fe6583'}",
            "dataset":"osv",
            "summary":"Integer Overflow or Wraparound in Microweber Microweber prior to 1.2.12 is vulnerable to Integer Overflow or Wraparound.",
            "published_date":"2022-03-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/7559e141d0707f8eeff2f9aeaa5a0ca2e3fe6583",
            "commit_sha":"7559e141d0707f8eeff2f9aeaa5a0ca2e3fe6583",
            "patch":"SINGLE",
            "chain_ord":"['7559e141d0707f8eeff2f9aeaa5a0ca2e3fe6583']",
            "before_first_fix_commit":"{'28f2677ea228a36e7692505e1821ae373a8b07e4'}",
            "last_fix_commit":"7559e141d0707f8eeff2f9aeaa5a0ca2e3fe6583",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/11\/2022, 08:30:42",
            "message":"checkout shipping address validation - max chars allowed",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 21, 'deletions': 4, 'total': 25}",
            "files":"{'src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ShippingTrait.php': {'additions': 21, 'deletions': 4, 'changes': 25, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/7559e141d0707f8eeff2f9aeaa5a0ca2e3fe6583\/src%2FMicroweberPackages%2FCheckout%2FHttp%2FControllers%2FTraits%2FShippingTrait.php', 'patch': \"@@ -38,13 +38,30 @@ public function shippingMethodSave(Request $request) {\\n \\n         if (is_array($request->get('Address'))) {\\n             $request->merge([\\n-               'city'=>$request->get('Address')['city'],\\n-               'zip'=>$request->get('Address')['zip'],\\n-               'state'=>$request->get('Address')['state'],\\n-               'address'=>$request->get('Address')['address'],\\n+                'city'=>$request->get('Address')['city'],\\n+                'zip'=>$request->get('Address')['zip'],\\n+                'state'=>$request->get('Address')['state'],\\n+                'address'=>$request->get('Address')['address'],\\n             ]);\\n         }\\n \\n+        $rules = [];\\n+        $rules['shipping_gw'] = 'max:500';\\n+        $rules['city'] = 'max:500';\\n+        $rules['address'] = 'max:500';\\n+        $rules['country'] = 'max:500';\\n+        $rules['state'] = 'max:500';\\n+        $rules['zip'] = 'max:500';\\n+        $rules['other_info'] = 'max:500';\\n+\\n+        $validator = Validator::make($request->all(), $rules);\\n+\\n+        if ($validator->fails()) {\\n+            $errors = $validator->messages()->toArray();\\n+            session_set('errors', $errors);\\n+            return redirect(route('checkout.shipping_method'));\\n+        }\\n+\\n         session_append_array('checkout_v2', [\\n             'shipping_gw'=> $request->get('shipping_gw'),\\n             'city'=> $request->get('city'),\"}}",
            "message_norm":"checkout shipping address validation - max chars allowed",
            "language":"en",
            "entities":null,
            "classification_level_1":"NON_SECURITY_RELATED",
            "classification_level_2":"REDUNDANT_MESSAGE",
            "list_files":"dict_keys(['src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ShippingTrait.php'])",
            "num_files":1.0,
            "patch_content":"From 7559e141d0707f8eeff2f9aeaa5a0ca2e3fe6583 Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Fri, 11 Mar 2022 10:30:42 +0200\nSubject: [PATCH] checkout shipping address validation - max chars allowed\n\n---\n ...\/Http\/Controllers\/Traits\/ShippingTrait.php | 25 ++++++++++++++++---\n 1 file changed, 21 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ShippingTrait.php b\/src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ShippingTrait.php\nindex 1d71607f86e..b6eaecd7786 100644\n--- a\/src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ShippingTrait.php\n+++ b\/src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ShippingTrait.php\n@@ -38,13 +38,30 @@ public function shippingMethodSave(Request $request) {\n \n         if (is_array($request->get('Address'))) {\n             $request->merge([\n-               'city'=>$request->get('Address')['city'],\n-               'zip'=>$request->get('Address')['zip'],\n-               'state'=>$request->get('Address')['state'],\n-               'address'=>$request->get('Address')['address'],\n+                'city'=>$request->get('Address')['city'],\n+                'zip'=>$request->get('Address')['zip'],\n+                'state'=>$request->get('Address')['state'],\n+                'address'=>$request->get('Address')['address'],\n             ]);\n         }\n \n+        $rules = [];\n+        $rules['shipping_gw'] = 'max:500';\n+        $rules['city'] = 'max:500';\n+        $rules['address'] = 'max:500';\n+        $rules['country'] = 'max:500';\n+        $rules['state'] = 'max:500';\n+        $rules['zip'] = 'max:500';\n+        $rules['other_info'] = 'max:500';\n+\n+        $validator = Validator::make($request->all(), $rules);\n+\n+        if ($validator->fails()) {\n+            $errors = $validator->messages()->toArray();\n+            session_set('errors', $errors);\n+            return redirect(route('checkout.shipping_method'));\n+        }\n+\n         session_append_array('checkout_v2', [\n             'shipping_gw'=> $request->get('shipping_gw'),\n             'city'=> $request->get('city'),"
        },
        {
            "index":119,
            "vuln_id":"GHSA-fj93-7wm4-8x2g",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/jquery\/jquery-mobile\/commit\/b0d9cc758a48f13321750d7409fb7655dcdf2b50'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting in jquery-mobile All version of `jquery-mobile` are vulnerable to Cross-Site Scripting. The package checks for content in `location.hash` and if a URL is found it does an XmlHttpRequest (XHR) to the URL and renders the response with `innerHTML`. It fails to validate the `Content-Type` of the response, allowing attackers to include malicious payloads as part of query parameters that are reflected back to the user. A response such as `{\"q\":\"<iframe\/src='javascript:alert(1)'><\/iframe>\",\"results\":[]}` would be parsed as HTML and the JavaScript payload executed.\n\n\n## Recommendation\n\nNo fix is currently available. Consider using an alternative package until a fix is made available.",
            "published_date":"2020-09-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/jquery\/jquery-mobile",
            "commit_href":"https:\/\/github.com\/jquery\/jquery-mobile\/commit\/b0d9cc758a48f13321750d7409fb7655dcdf2b50",
            "commit_sha":"b0d9cc758a48f13321750d7409fb7655dcdf2b50",
            "patch":"SINGLE",
            "chain_ord":"['b0d9cc758a48f13321750d7409fb7655dcdf2b50']",
            "before_first_fix_commit":"{'1f0cec9bcb9d75998e733d580d6f1144c963326e'}",
            "last_fix_commit":"b0d9cc758a48f13321750d7409fb7655dcdf2b50",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/13\/2019, 17:42:26",
            "message":"Check Content-Type header before parsing AJAX response as HTML (#8649)\n\nFix for issue #8640 (possible XSS vulnerability)",
            "author":"Denis Ryabov",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 0, 'total': 9}",
            "files":"{'js\/widgets\/pagecontainer.js': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jquery-archive\/jquery-mobile\/raw\/b0d9cc758a48f13321750d7409fb7655dcdf2b50\/js%2Fwidgets%2Fpagecontainer.js', 'patch': '@@ -564,6 +564,15 @@ $.widget( \"mobile.pagecontainer\", {\\n \\n \\t\\treturn $.proxy( function( html, textStatus, xhr ) {\\n \\n+\\t\\t\\t\/\/ Check that Content-Type is \"text\/html\" (https:\/\/github.com\/jquery\/jquery-mobile\/issues\/8640)\\n+\\t\\t\\tif ( !\/^text\\\\\/html\\\\b\/.test( xhr.getResponseHeader(\\'Content-Type\\') ) ) {\\n+\\t\\t\\t\\t\/\/ Display error message for unsupported content type\\n+\\t\\t\\t\\tif ( settings.showLoadMsg ) {\\n+\\t\\t\\t\\t\\tthis._showError();\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t\\treturn;\\n+\\t\\t\\t}\\n+\\n \\t\\t\\t\/\/ Pre-parse html to check for a data-url, use it as the new fileUrl, base path, etc\\n \\t\\t\\tvar content,'}}",
            "message_norm":"check content-type header before parsing ajax response as html (#8649)\n\nfix for issue #8640 (possible xss vulnerability)",
            "language":"en",
            "entities":"[('#8649', 'ISSUE', ''), ('issue', 'FLAW', ''), ('#8640', 'ISSUE', ''), ('xss', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['js\/widgets\/pagecontainer.js'])",
            "num_files":1.0,
            "patch_content":"From b0d9cc758a48f13321750d7409fb7655dcdf2b50 Mon Sep 17 00:00:00 2001\nFrom: Denis Ryabov <dryabov@yandex.ru>\nDate: Thu, 13 Jun 2019 20:42:26 +0300\nSubject: [PATCH] Check Content-Type header before parsing AJAX response as\n HTML (#8649)\n\nFix for issue #8640 (possible XSS vulnerability)\n---\n js\/widgets\/pagecontainer.js | 9 +++++++++\n 1 file changed, 9 insertions(+)\n\ndiff --git a\/js\/widgets\/pagecontainer.js b\/js\/widgets\/pagecontainer.js\nindex 6e973688caf..5e3272e9779 100644\n--- a\/js\/widgets\/pagecontainer.js\n+++ b\/js\/widgets\/pagecontainer.js\n@@ -564,6 +564,15 @@ $.widget( \"mobile.pagecontainer\", {\n \n \t\treturn $.proxy( function( html, textStatus, xhr ) {\n \n+\t\t\t\/\/ Check that Content-Type is \"text\/html\" (https:\/\/github.com\/jquery\/jquery-mobile\/issues\/8640)\n+\t\t\tif ( !\/^text\\\/html\\b\/.test( xhr.getResponseHeader('Content-Type') ) ) {\n+\t\t\t\t\/\/ Display error message for unsupported content type\n+\t\t\t\tif ( settings.showLoadMsg ) {\n+\t\t\t\t\tthis._showError();\n+\t\t\t\t}\n+\t\t\t\treturn;\n+\t\t\t}\n+\n \t\t\t\/\/ Pre-parse html to check for a data-url, use it as the new fileUrl, base path, etc\n \t\t\tvar content,"
        },
        {
            "index":296,
            "vuln_id":"GHSA-grvw-q343-58wh",
            "cwe_id":"{'CWE-787'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/7e9a2ee60baa95ceb4f48f522f823c812ca90c80', 'https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/95b3e3400afb8fa20743657f3a8057fb451e6f69'}",
            "dataset":"osv",
            "summary":"Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1138, CVE-2019-1217, CVE-2019-1237, CVE-2019-1298.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/chakra-core\/ChakraCore",
            "commit_href":"https:\/\/github.com\/chakra-core\/ChakraCore\/commit\/95b3e3400afb8fa20743657f3a8057fb451e6f69",
            "commit_sha":"95b3e3400afb8fa20743657f3a8057fb451e6f69",
            "patch":"MULTI",
            "chain_ord":"['95b3e3400afb8fa20743657f3a8057fb451e6f69', '7e9a2ee60baa95ceb4f48f522f823c812ca90c80']",
            "before_first_fix_commit":"{'edf5eeef49168bbcc30dac82f57048ad46988295', 'c5297b86536fbf1a02d27cec28fea3c516e6ab84'}",
            "last_fix_commit":"7e9a2ee60baa95ceb4f48f522f823c812ca90c80",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/08\/2019, 15:54:11",
            "message":"[CVE-2019-1300]",
            "author":"Paul Leathers",
            "comments":null,
            "stats":"{'additions': 43, 'deletions': 31, 'total': 74}",
            "files":"{'lib\/Backend\/GlobOpt.cpp': {'additions': 43, 'deletions': 31, 'changes': 74, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chakra-core\/ChakraCore\/raw\/95b3e3400afb8fa20743657f3a8057fb451e6f69\/lib%2FBackend%2FGlobOpt.cpp', 'patch': \"@@ -1167,6 +1167,10 @@ void GlobOpt::InsertValueCompensation(\\n     IR::Instr *insertBeforeInstr = predecessor->GetLastInstr();\\n     Func *const func = insertBeforeInstr->m_func;\\n     bool setLastInstrInPredecessor;\\n+    \/\/ If this is a loop back edge, and the successor has been completed, don't attempt to update its block data.\\n+    \/\/ The update is unnecessary, and the data has likely been freed.\\n+    bool updateSuccessorBlockData = !this->isPerformingLoopBackEdgeCompensation || successor->GetDataUseCount() > 0;\\n+\\n     if(insertBeforeInstr->IsBranchInstr() || insertBeforeInstr->m_opcode == Js::OpCode::BailTarget)\\n     {\\n         \/\/ Don't insert code between the branch and the corresponding ByteCodeUses instructions\\n@@ -1257,29 +1261,33 @@ void GlobOpt::InsertValueCompensation(\\n             \/\/ Merge the head segment length value\\n             Assert(predecessorBlockData.liveVarSyms->Test(predecessorHeadSegmentLengthSym->m_id));\\n             predecessorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\\n-            successorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\\n             Value *const predecessorHeadSegmentLengthValue =\\n                 predecessorBlockData.FindValue(predecessorHeadSegmentLengthSym);\\n             Assert(predecessorHeadSegmentLengthValue);\\n             predecessorBlockData.SetValue(predecessorHeadSegmentLengthValue, mergedHeadSegmentLengthSym);\\n-            Value *const mergedHeadSegmentLengthValue = successorBlockData.FindValue(mergedHeadSegmentLengthSym);\\n-            if(mergedHeadSegmentLengthValue)\\n+\\n+            if (updateSuccessorBlockData)\\n             {\\n-                Assert(mergedHeadSegmentLengthValue->GetValueNumber() != predecessorHeadSegmentLengthValue->GetValueNumber());\\n-                if(predecessorHeadSegmentLengthValue->GetValueInfo() != mergedHeadSegmentLengthValue->GetValueInfo())\\n+                successorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\\n+                Value *const mergedHeadSegmentLengthValue = successorBlockData.FindValue(mergedHeadSegmentLengthSym);\\n+                if(mergedHeadSegmentLengthValue)\\n                 {\\n-                    mergedHeadSegmentLengthValue->SetValueInfo(\\n-                        ValueInfo::MergeLikelyIntValueInfo(\\n-                            this->alloc,\\n-                            mergedHeadSegmentLengthValue,\\n-                            predecessorHeadSegmentLengthValue,\\n-                            mergedHeadSegmentLengthValue->GetValueInfo()->Type()\\n-                                .Merge(predecessorHeadSegmentLengthValue->GetValueInfo()->Type())));\\n+                    Assert(mergedHeadSegmentLengthValue->GetValueNumber() != predecessorHeadSegmentLengthValue->GetValueNumber());\\n+                    if(predecessorHeadSegmentLengthValue->GetValueInfo() != mergedHeadSegmentLengthValue->GetValueInfo())\\n+                    {\\n+                        mergedHeadSegmentLengthValue->SetValueInfo(\\n+                            ValueInfo::MergeLikelyIntValueInfo(\\n+                                this->alloc,\\n+                                mergedHeadSegmentLengthValue,\\n+                                predecessorHeadSegmentLengthValue,\\n+                                mergedHeadSegmentLengthValue->GetValueInfo()->Type()\\n+                                    .Merge(predecessorHeadSegmentLengthValue->GetValueInfo()->Type())));\\n+                    }\\n+                }\\n+                else\\n+                {\\n+                    successorBlockData.SetValue(CopyValue(predecessorHeadSegmentLengthValue), mergedHeadSegmentLengthSym);\\n                 }\\n-            }\\n-            else\\n-            {\\n-                successorBlockData.SetValue(CopyValue(predecessorHeadSegmentLengthValue), mergedHeadSegmentLengthSym);\\n             }\\n         }\\n \\n@@ -1300,27 +1308,31 @@ void GlobOpt::InsertValueCompensation(\\n             \/\/ Merge the length value\\n             Assert(predecessorBlockData.liveVarSyms->Test(predecessorLengthSym->m_id));\\n             predecessorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\\n-            successorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\\n             Value *const predecessorLengthValue = predecessorBlockData.FindValue(predecessorLengthSym);\\n             Assert(predecessorLengthValue);\\n             predecessorBlockData.SetValue(predecessorLengthValue, mergedLengthSym);\\n-            Value *const mergedLengthValue = successorBlockData.FindValue(mergedLengthSym);\\n-            if(mergedLengthValue)\\n+\\n+            if (updateSuccessorBlockData)\\n             {\\n-                Assert(mergedLengthValue->GetValueNumber() != predecessorLengthValue->GetValueNumber());\\n-                if(predecessorLengthValue->GetValueInfo() != mergedLengthValue->GetValueInfo())\\n+                successorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\\n+                Value *const mergedLengthValue = successorBlockData.FindValue(mergedLengthSym);\\n+                if(mergedLengthValue)\\n                 {\\n-                    mergedLengthValue->SetValueInfo(\\n-                        ValueInfo::MergeLikelyIntValueInfo(\\n-                            this->alloc,\\n-                            mergedLengthValue,\\n-                            predecessorLengthValue,\\n-                            mergedLengthValue->GetValueInfo()->Type().Merge(predecessorLengthValue->GetValueInfo()->Type())));\\n+                    Assert(mergedLengthValue->GetValueNumber() != predecessorLengthValue->GetValueNumber());\\n+                    if(predecessorLengthValue->GetValueInfo() != mergedLengthValue->GetValueInfo())\\n+                    {\\n+                        mergedLengthValue->SetValueInfo(\\n+                            ValueInfo::MergeLikelyIntValueInfo(\\n+                                this->alloc,\\n+                                mergedLengthValue,\\n+                                predecessorLengthValue,\\n+                                mergedLengthValue->GetValueInfo()->Type().Merge(predecessorLengthValue->GetValueInfo()->Type())));\\n+                    }\\n+                }\\n+                else\\n+                {\\n+                    successorBlockData.SetValue(CopyValue(predecessorLengthValue), mergedLengthSym);\\n                 }\\n-            }\\n-            else\\n-            {\\n-                successorBlockData.SetValue(CopyValue(predecessorLengthValue), mergedLengthSym);\\n             }\\n         }\"}}",
            "message_norm":"[cve-2019-1300]",
            "language":"ro",
            "entities":"[('cve-2019-1300', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Backend\/GlobOpt.cpp'])",
            "num_files":1.0,
            "patch_content":"From 95b3e3400afb8fa20743657f3a8057fb451e6f69 Mon Sep 17 00:00:00 2001\nFrom: Paul Leathers <pleath@microsoft.com>\nDate: Mon, 8 Jul 2019 08:54:11 -0700\nSubject: [PATCH] [CVE-2019-1300]\n\n---\n lib\/Backend\/GlobOpt.cpp | 74 ++++++++++++++++++++++++-----------------\n 1 file changed, 43 insertions(+), 31 deletions(-)\n\ndiff --git a\/lib\/Backend\/GlobOpt.cpp b\/lib\/Backend\/GlobOpt.cpp\nindex d134594903b..e19eed15127 100644\n--- a\/lib\/Backend\/GlobOpt.cpp\n+++ b\/lib\/Backend\/GlobOpt.cpp\n@@ -1167,6 +1167,10 @@ void GlobOpt::InsertValueCompensation(\n     IR::Instr *insertBeforeInstr = predecessor->GetLastInstr();\n     Func *const func = insertBeforeInstr->m_func;\n     bool setLastInstrInPredecessor;\n+    \/\/ If this is a loop back edge, and the successor has been completed, don't attempt to update its block data.\n+    \/\/ The update is unnecessary, and the data has likely been freed.\n+    bool updateSuccessorBlockData = !this->isPerformingLoopBackEdgeCompensation || successor->GetDataUseCount() > 0;\n+\n     if(insertBeforeInstr->IsBranchInstr() || insertBeforeInstr->m_opcode == Js::OpCode::BailTarget)\n     {\n         \/\/ Don't insert code between the branch and the corresponding ByteCodeUses instructions\n@@ -1257,29 +1261,33 @@ void GlobOpt::InsertValueCompensation(\n             \/\/ Merge the head segment length value\n             Assert(predecessorBlockData.liveVarSyms->Test(predecessorHeadSegmentLengthSym->m_id));\n             predecessorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\n-            successorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\n             Value *const predecessorHeadSegmentLengthValue =\n                 predecessorBlockData.FindValue(predecessorHeadSegmentLengthSym);\n             Assert(predecessorHeadSegmentLengthValue);\n             predecessorBlockData.SetValue(predecessorHeadSegmentLengthValue, mergedHeadSegmentLengthSym);\n-            Value *const mergedHeadSegmentLengthValue = successorBlockData.FindValue(mergedHeadSegmentLengthSym);\n-            if(mergedHeadSegmentLengthValue)\n+\n+            if (updateSuccessorBlockData)\n             {\n-                Assert(mergedHeadSegmentLengthValue->GetValueNumber() != predecessorHeadSegmentLengthValue->GetValueNumber());\n-                if(predecessorHeadSegmentLengthValue->GetValueInfo() != mergedHeadSegmentLengthValue->GetValueInfo())\n+                successorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\n+                Value *const mergedHeadSegmentLengthValue = successorBlockData.FindValue(mergedHeadSegmentLengthSym);\n+                if(mergedHeadSegmentLengthValue)\n                 {\n-                    mergedHeadSegmentLengthValue->SetValueInfo(\n-                        ValueInfo::MergeLikelyIntValueInfo(\n-                            this->alloc,\n-                            mergedHeadSegmentLengthValue,\n-                            predecessorHeadSegmentLengthValue,\n-                            mergedHeadSegmentLengthValue->GetValueInfo()->Type()\n-                                .Merge(predecessorHeadSegmentLengthValue->GetValueInfo()->Type())));\n+                    Assert(mergedHeadSegmentLengthValue->GetValueNumber() != predecessorHeadSegmentLengthValue->GetValueNumber());\n+                    if(predecessorHeadSegmentLengthValue->GetValueInfo() != mergedHeadSegmentLengthValue->GetValueInfo())\n+                    {\n+                        mergedHeadSegmentLengthValue->SetValueInfo(\n+                            ValueInfo::MergeLikelyIntValueInfo(\n+                                this->alloc,\n+                                mergedHeadSegmentLengthValue,\n+                                predecessorHeadSegmentLengthValue,\n+                                mergedHeadSegmentLengthValue->GetValueInfo()->Type()\n+                                    .Merge(predecessorHeadSegmentLengthValue->GetValueInfo()->Type())));\n+                    }\n+                }\n+                else\n+                {\n+                    successorBlockData.SetValue(CopyValue(predecessorHeadSegmentLengthValue), mergedHeadSegmentLengthSym);\n                 }\n-            }\n-            else\n-            {\n-                successorBlockData.SetValue(CopyValue(predecessorHeadSegmentLengthValue), mergedHeadSegmentLengthSym);\n             }\n         }\n \n@@ -1300,27 +1308,31 @@ void GlobOpt::InsertValueCompensation(\n             \/\/ Merge the length value\n             Assert(predecessorBlockData.liveVarSyms->Test(predecessorLengthSym->m_id));\n             predecessorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\n-            successorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\n             Value *const predecessorLengthValue = predecessorBlockData.FindValue(predecessorLengthSym);\n             Assert(predecessorLengthValue);\n             predecessorBlockData.SetValue(predecessorLengthValue, mergedLengthSym);\n-            Value *const mergedLengthValue = successorBlockData.FindValue(mergedLengthSym);\n-            if(mergedLengthValue)\n+\n+            if (updateSuccessorBlockData)\n             {\n-                Assert(mergedLengthValue->GetValueNumber() != predecessorLengthValue->GetValueNumber());\n-                if(predecessorLengthValue->GetValueInfo() != mergedLengthValue->GetValueInfo())\n+                successorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\n+                Value *const mergedLengthValue = successorBlockData.FindValue(mergedLengthSym);\n+                if(mergedLengthValue)\n                 {\n-                    mergedLengthValue->SetValueInfo(\n-                        ValueInfo::MergeLikelyIntValueInfo(\n-                            this->alloc,\n-                            mergedLengthValue,\n-                            predecessorLengthValue,\n-                            mergedLengthValue->GetValueInfo()->Type().Merge(predecessorLengthValue->GetValueInfo()->Type())));\n+                    Assert(mergedLengthValue->GetValueNumber() != predecessorLengthValue->GetValueNumber());\n+                    if(predecessorLengthValue->GetValueInfo() != mergedLengthValue->GetValueInfo())\n+                    {\n+                        mergedLengthValue->SetValueInfo(\n+                            ValueInfo::MergeLikelyIntValueInfo(\n+                                this->alloc,\n+                                mergedLengthValue,\n+                                predecessorLengthValue,\n+                                mergedLengthValue->GetValueInfo()->Type().Merge(predecessorLengthValue->GetValueInfo()->Type())));\n+                    }\n+                }\n+                else\n+                {\n+                    successorBlockData.SetValue(CopyValue(predecessorLengthValue), mergedLengthSym);\n                 }\n-            }\n-            else\n-            {\n-                successorBlockData.SetValue(CopyValue(predecessorLengthValue), mergedLengthSym);\n             }\n         }"
        },
        {
            "index":191,
            "vuln_id":"GHSA-xjrf-8x4f-43h4",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/spring-projects\/spring-framework\/commit\/9982b4c01a8c7be0961e58b58ed83731c40449ff', 'https:\/\/github.com\/spring-projects\/spring-framework\/commit\/7a7df6637478607bef0277bf52a4e0a03e20a248', 'https:\/\/github.com\/spring-projects\/spring-framework\/commit\/f5c9fe69a444607af667911bd4c5074b5b073e7b'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Input During Web Page Generation in Spring Framework The JavaScriptUtils.javaScriptEscape method in web\/util\/JavaScriptUtils.java in Spring MVC in Spring Framework before 3.2.2 does not properly escape certain characters, which allows remote attackers to conduct cross-site scripting (XSS) attacks via a (1) line separator or (2) paragraph separator Unicode character or (3) left or (4) right angle bracket.",
            "published_date":"2022-05-05",
            "chain_len":3,
            "project":"https:\/\/github.com\/spring-projects\/spring-framework",
            "commit_href":"https:\/\/github.com\/spring-projects\/spring-framework\/commit\/9982b4c01a8c7be0961e58b58ed83731c40449ff",
            "commit_sha":"9982b4c01a8c7be0961e58b58ed83731c40449ff",
            "patch":"MULTI",
            "chain_ord":"['9982b4c01a8c7be0961e58b58ed83731c40449ff', 'f5c9fe69a444607af667911bd4c5074b5b073e7b', '7a7df6637478607bef0277bf52a4e0a03e20a248']",
            "before_first_fix_commit":"{'63bff1f068f0c749f938abacba1d38b7d0ca3cf9'}",
            "last_fix_commit":"7a7df6637478607bef0277bf52a4e0a03e20a248",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/23\/2013, 18:35:14",
            "message":"Add BS and VT char escape sequences to JavaScriptUtils\n\nIssue: SPR-9983",
            "author":"Rossen Stoyanchev",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 7, 'total': 21}",
            "files":"{'spring-web\/src\/main\/java\/org\/springframework\/web\/util\/JavaScriptUtils.java': {'additions': 14, 'deletions': 7, 'changes': 21, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/spring-projects\/spring-framework\/raw\/9982b4c01a8c7be0961e58b58ed83731c40449ff\/spring-web%2Fsrc%2Fmain%2Fjava%2Forg%2Fspringframework%2Fweb%2Futil%2FJavaScriptUtils.java', 'patch': '@@ -1,5 +1,5 @@\\n \/*\\n- * Copyright 2002-2008 the original author or authors.\\n+ * Copyright 2002-2013 the original author or authors.\\n  *\\n  * Licensed under the Apache License, Version 2.0 (the \"License\");\\n  * you may not use this file except in compliance with the License.\\n@@ -21,21 +21,21 @@\\n  * Escapes based on the JavaScript 1.5 recommendation.\\n  *\\n  * <p>Reference:\\n- * <a href=\"http:\/\/developer.mozilla.org\/en\/docs\/Core_JavaScript_1.5_Guide:Literals#String_Literals\">\\n- * Core JavaScript 1.5 Guide\\n- * <\/a>\\n+ * <a href=\"https:\/\/developer.mozilla.org\/en-US\/docs\/JavaScript\/Guide\/Values,_variables,_and_literals#String_literals\">\\n+ * JavaScript Guide<\/a> on Mozilla Developer Network.\\n  *\\n  * @author Juergen Hoeller\\n  * @author Rob Harrop\\n+ * @author Rossen Stoyanchev\\n  * @since 1.1.1\\n  *\/\\n public class JavaScriptUtils {\\n \\n \\t\/**\\n-\\t * Turn special characters into escaped characters conforming to JavaScript.\\n-\\t * Handles complete character set defined in HTML 4.01 recommendation.\\n+\\t * Turn JavaScript special characters into escaped characters.\\n+\\t *\\n \\t * @param input the input string\\n-\\t * @return the escaped string\\n+\\t * @return the string with escaped characters\\n \\t *\/\\n \\tpublic static String javaScriptEscape(String input) {\\n \\t\\tif (input == null) {\\n@@ -73,6 +73,13 @@ else if (c == \\'\\\\r\\') {\\n \\t\\t\\telse if (c == \\'\\\\f\\') {\\n \\t\\t\\t\\tfiltered.append(\"\\\\\\\\f\");\\n \\t\\t\\t}\\n+\\t\\t\\telse if (c == \\'\\\\b\\') {\\n+\\t\\t\\t\\tfiltered.append(\"\\\\\\\\b\");\\n+\\t\\t\\t}\\n+\\t\\t\\t\/\/ No \\'\\\\v\\' in Java, use octal value for VT ascii char\\n+\\t\\t\\telse if (c == \\'\\\\013\\') {\\n+\\t\\t\\t\\tfiltered.append(\"\\\\\\\\v\");\\n+\\t\\t\\t}\\n \\t\\t\\telse {\\n \\t\\t\\t\\tfiltered.append(c);\\n \\t\\t\\t}'}}",
            "message_norm":"add bs and vt char escape sequences to javascriptutils\n\nissue: spr-9983",
            "language":"ca",
            "entities":"[('add', 'ACTION', ''), ('escape', 'SECWORD', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['spring-web\/src\/main\/java\/org\/springframework\/web\/util\/JavaScriptUtils.java'])",
            "num_files":1.0,
            "patch_content":"From 9982b4c01a8c7be0961e58b58ed83731c40449ff Mon Sep 17 00:00:00 2001\nFrom: Rossen Stoyanchev <rstoyanchev@vmware.com>\nDate: Wed, 23 Jan 2013 13:35:14 -0500\nSubject: [PATCH] Add BS and VT char escape sequences to JavaScriptUtils\n\nIssue: SPR-9983\n---\n ...\/web\/util\/JavaScriptUtils.java             | 21 ++++++++++++-------\n 1 file changed, 14 insertions(+), 7 deletions(-)\n\ndiff --git a\/spring-web\/src\/main\/java\/org\/springframework\/web\/util\/JavaScriptUtils.java b\/spring-web\/src\/main\/java\/org\/springframework\/web\/util\/JavaScriptUtils.java\nindex b28d398687f1..0ee697f6d9a5 100644\n--- a\/spring-web\/src\/main\/java\/org\/springframework\/web\/util\/JavaScriptUtils.java\n+++ b\/spring-web\/src\/main\/java\/org\/springframework\/web\/util\/JavaScriptUtils.java\n@@ -1,5 +1,5 @@\n \/*\n- * Copyright 2002-2008 the original author or authors.\n+ * Copyright 2002-2013 the original author or authors.\n  *\n  * Licensed under the Apache License, Version 2.0 (the \"License\");\n  * you may not use this file except in compliance with the License.\n@@ -21,21 +21,21 @@\n  * Escapes based on the JavaScript 1.5 recommendation.\n  *\n  * <p>Reference:\n- * <a href=\"http:\/\/developer.mozilla.org\/en\/docs\/Core_JavaScript_1.5_Guide:Literals#String_Literals\">\n- * Core JavaScript 1.5 Guide\n- * <\/a>\n+ * <a href=\"https:\/\/developer.mozilla.org\/en-US\/docs\/JavaScript\/Guide\/Values,_variables,_and_literals#String_literals\">\n+ * JavaScript Guide<\/a> on Mozilla Developer Network.\n  *\n  * @author Juergen Hoeller\n  * @author Rob Harrop\n+ * @author Rossen Stoyanchev\n  * @since 1.1.1\n  *\/\n public class JavaScriptUtils {\n \n \t\/**\n-\t * Turn special characters into escaped characters conforming to JavaScript.\n-\t * Handles complete character set defined in HTML 4.01 recommendation.\n+\t * Turn JavaScript special characters into escaped characters.\n+\t *\n \t * @param input the input string\n-\t * @return the escaped string\n+\t * @return the string with escaped characters\n \t *\/\n \tpublic static String javaScriptEscape(String input) {\n \t\tif (input == null) {\n@@ -73,6 +73,13 @@ else if (c == '\\r') {\n \t\t\telse if (c == '\\f') {\n \t\t\t\tfiltered.append(\"\\\\f\");\n \t\t\t}\n+\t\t\telse if (c == '\\b') {\n+\t\t\t\tfiltered.append(\"\\\\b\");\n+\t\t\t}\n+\t\t\t\/\/ No '\\v' in Java, use octal value for VT ascii char\n+\t\t\telse if (c == '\\013') {\n+\t\t\t\tfiltered.append(\"\\\\v\");\n+\t\t\t}\n \t\t\telse {\n \t\t\t\tfiltered.append(c);\n \t\t\t}"
        },
        {
            "index":20,
            "vuln_id":"GHSA-f78g-q7r4-9wcv",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/548b5eaf23685d86f722233d8fbc21d0a4aecb96'}",
            "dataset":"osv",
            "summary":"Division by 0 in `FractionalAvgPool` ### Impact\nAn attacker can cause a runtime division by zero error and denial of service in `tf.raw_ops.FractionalAvgPool`:\n\n```python\nimport tensorflow as tf\n\nvalue = tf.constant([60], shape=[1, 1, 1, 1], dtype=tf.int32)\npooling_ratio = [1.0, 1.0000014345305555, 1.0, 1.0]\npseudo_random = False\noverlapping = False\ndeterministic = False\nseed = 0\nseed2 = 0\n\ntf.raw_ops.FractionalAvgPool(\n  value=value, pooling_ratio=pooling_ratio, pseudo_random=pseudo_random,\n  overlapping=overlapping, deterministic=deterministic, seed=seed, seed2=seed2)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc#L85-L89) computes a divisor quantity by dividing two user controlled values:\n\n```cc                     \nfor (int i = 0; i < tensor_in_and_out_dims; ++i) {\n  output_size[i] = static_cast<int>(std::floor(input_size[i] \/ pooling_ratio_[i]));\n  DCHECK_GT(output_size[i], 0); \n} \n``` \n    \nThe user controls the values of `input_size[i]` and `pooling_ratio_[i]` (via the `value.shape()` and `pooling_ratio` arguments). If the value in `input_size[i]` is smaller than the `pooling_ratio_[i]`, then the floor operation results in `output_size[i]` being 0. The `DCHECK_GT` line is a no-op outside of debug mode, so in released versions of TF this does not trigger.\n\nLater, these computed values [are used as arguments](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc#L96-L99) to [`GeneratePoolingSequence`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c\/tensorflow\/core\/kernels\/fractional_pool_common.cc#L100-L108). There, the first computation is a division in a modulo operation:\n\n```cc\nstd::vector<int64> GeneratePoolingSequence(int input_length, int output_length,\n                                           GuardedPhiloxRandom* generator,\n                                           bool pseudo_random) {\n  ...\n  if (input_length % output_length == 0) {\n    diff = std::vector<int64>(output_length, input_length \/ output_length);\n  }\n  ...\n}\n```\n\nSince `output_length` can be 0, this results in runtime crashing.\n\n### Patches\nWe have patched the issue in GitHub commit [548b5eaf23685d86f722233d8fbc21d0a4aecb96](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/548b5eaf23685d86f722233d8fbc21d0a4aecb96).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/548b5eaf23685d86f722233d8fbc21d0a4aecb96",
            "commit_sha":"548b5eaf23685d86f722233d8fbc21d0a4aecb96",
            "patch":"SINGLE",
            "chain_ord":"['548b5eaf23685d86f722233d8fbc21d0a4aecb96']",
            "before_first_fix_commit":"{'acc8ee69f5f46f92a3f1f11230f49c6ac266f10c'}",
            "last_fix_commit":"548b5eaf23685d86f722233d8fbc21d0a4aecb96",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/29\/2021, 15:38:16",
            "message":"Fix divide by zero error in `fractional_pool_common.cc`.\n\nPiperOrigin-RevId: 371126221\nChange-Id: Iea4b2f363aaeb116ab460e3bc592c687484af344",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/fractional_avg_pool_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/548b5eaf23685d86f722233d8fbc21d0a4aecb96\/tensorflow%2Fcore%2Fkernels%2Ffractional_avg_pool_op.cc', 'patch': '@@ -80,6 +80,10 @@ class FractionalAvgPoolOp : public OpKernel {\\n     std::vector<int> output_size(tensor_in_and_out_dims);\\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\\n       input_size[i] = tensor_in.dim_size(i);\\n+      OP_REQUIRES(\\n+          context, pooling_ratio_[i] <= input_size[i],\\n+          errors::InvalidArgument(\\n+              \"Pooling ratio cannot be bigger than input tensor dim size.\"));\\n     }\\n     \/\/ Output size.\\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {'}}",
            "message_norm":"fix divide by zero error in `fractional_pool_common.cc`.\n\npiperorigin-revid: 371126221\nchange-id: iea4b2f363aaeb116ab460e3bc592c687484af344",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('divide by zero', 'SECWORD', ''), ('error', 'FLAW', ''), ('371126221', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/fractional_avg_pool_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 548b5eaf23685d86f722233d8fbc21d0a4aecb96 Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Thu, 29 Apr 2021 08:38:16 -0700\nSubject: [PATCH] Fix divide by zero error in `fractional_pool_common.cc`.\n\nPiperOrigin-RevId: 371126221\nChange-Id: Iea4b2f363aaeb116ab460e3bc592c687484af344\n---\n tensorflow\/core\/kernels\/fractional_avg_pool_op.cc | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc b\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc\nindex dfc2382624e3fa..b8a5083e5340f1 100644\n--- a\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc\n+++ b\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc\n@@ -80,6 +80,10 @@ class FractionalAvgPoolOp : public OpKernel {\n     std::vector<int> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n       input_size[i] = tensor_in.dim_size(i);\n+      OP_REQUIRES(\n+          context, pooling_ratio_[i] <= input_size[i],\n+          errors::InvalidArgument(\n+              \"Pooling ratio cannot be bigger than input tensor dim size.\"));\n     }\n     \/\/ Output size.\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {"
        },
        {
            "index":177,
            "vuln_id":"GHSA-6p56-wp2h-9hxr",
            "cwe_id":"{'CWE-120'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/numpy\/numpy\/commit\/ae317fd9ff3e79c0eac357d723bfc29cbd625f2e'}",
            "dataset":"osv",
            "summary":"NumPy Buffer Overflow (Disputed) A Buffer Overflow vulnerability exists in NumPy 1.9.x in the PyArray_NewFromDescr_int function of ctors.c when specifying arrays of large dimensions (over 32) from Python code, which could let a malicious user cause a Denial of Service.\n\nNOTE: The vendor does not agree this is a vulneraility; In (very limited) circumstances a user may be able provoke the buffer overflow, the user is most likely already privileged to at least provoke denial of service by exhausting memory. Triggering this further requires the use of uncommon API (complicated structured dtypes), which is very unlikely to be available to an unprivileged user.",
            "published_date":"2022-01-07",
            "chain_len":1,
            "project":"https:\/\/github.com\/numpy\/numpy",
            "commit_href":"https:\/\/github.com\/numpy\/numpy\/commit\/ae317fd9ff3e79c0eac357d723bfc29cbd625f2e",
            "commit_sha":"ae317fd9ff3e79c0eac357d723bfc29cbd625f2e",
            "patch":"SINGLE",
            "chain_ord":"['ae317fd9ff3e79c0eac357d723bfc29cbd625f2e']",
            "before_first_fix_commit":"{'938fe1f871e22b8f5556b946135fa700e5ebcce1', '16f7824b4d935b6aee98298ca4123d57174a6f2e'}",
            "last_fix_commit":"ae317fd9ff3e79c0eac357d723bfc29cbd625f2e",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/11\/2021, 19:39:32",
            "message":"Merge pull request #18989 from yetanothercheer\/gh-18939-potential_buffer_overflow\n\nBUG: fix potential buffer overflow(#18939)",
            "author":"Charles Harris",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 8, 'total': 16}",
            "files":"{'numpy\/core\/src\/multiarray\/ctors.c': {'additions': 8, 'deletions': 8, 'changes': 16, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/numpy\/numpy\/raw\/ae317fd9ff3e79c0eac357d723bfc29cbd625f2e\/numpy%2Fcore%2Fsrc%2Fmultiarray%2Fctors.c', 'patch': '@@ -668,6 +668,14 @@ PyArray_NewFromDescr_int(\\n     int i;\\n     npy_intp nbytes;\\n \\n+    if ((unsigned int)nd > (unsigned int)NPY_MAXDIMS) {\\n+        PyErr_Format(PyExc_ValueError,\\n+                     \"number of dimensions must be within [0, %d]\",\\n+                     NPY_MAXDIMS);\\n+        Py_DECREF(descr);\\n+        return NULL;\\n+    }\\n+\\n     if (descr->subarray) {\\n         PyObject *ret;\\n         npy_intp newdims[2*NPY_MAXDIMS];\\n@@ -687,14 +695,6 @@ PyArray_NewFromDescr_int(\\n         return ret;\\n     }\\n \\n-    if ((unsigned int)nd > (unsigned int)NPY_MAXDIMS) {\\n-        PyErr_Format(PyExc_ValueError,\\n-                     \"number of dimensions must be within [0, %d]\",\\n-                     NPY_MAXDIMS);\\n-        Py_DECREF(descr);\\n-        return NULL;\\n-    }\\n-\\n     \/* Check datatype element size *\/\\n     nbytes = descr->elsize;\\n     if (PyDataType_ISUNSIZED(descr)) {'}}",
            "message_norm":"merge pull request #18989 from yetanothercheer\/gh-18939-potential_buffer_overflow\n\nbug: fix potential buffer overflow(#18939)",
            "language":"en",
            "entities":"[('#18989', 'ISSUE', ''), ('potential_buffer_overflow', 'SECWORD', ''), ('bug', 'FLAW', ''), ('fix', 'ACTION', ''), ('buffer overflow(#18939', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['numpy\/core\/src\/multiarray\/ctors.c'])",
            "num_files":1.0,
            "patch_content":"From 16f7824b4d935b6aee98298ca4123d57174a6f2e Mon Sep 17 00:00:00 2001\nFrom: yetanothercheer <yetanothercheer@protonmail.com>\nDate: Tue, 11 May 2021 14:28:37 +0800\nSubject: [PATCH] BUG: fix potential buffer overflow(#18939)\n\n---\n numpy\/core\/src\/multiarray\/ctors.c | 16 ++++++++--------\n 1 file changed, 8 insertions(+), 8 deletions(-)\n\ndiff --git a\/numpy\/core\/src\/multiarray\/ctors.c b\/numpy\/core\/src\/multiarray\/ctors.c\nindex 57cfa1e368a8..7907fb93046a 100644\n--- a\/numpy\/core\/src\/multiarray\/ctors.c\n+++ b\/numpy\/core\/src\/multiarray\/ctors.c\n@@ -668,6 +668,14 @@ PyArray_NewFromDescr_int(\n     int i;\n     npy_intp nbytes;\n \n+    if ((unsigned int)nd > (unsigned int)NPY_MAXDIMS) {\n+        PyErr_Format(PyExc_ValueError,\n+                     \"number of dimensions must be within [0, %d]\",\n+                     NPY_MAXDIMS);\n+        Py_DECREF(descr);\n+        return NULL;\n+    }\n+\n     if (descr->subarray) {\n         PyObject *ret;\n         npy_intp newdims[2*NPY_MAXDIMS];\n@@ -687,14 +695,6 @@ PyArray_NewFromDescr_int(\n         return ret;\n     }\n \n-    if ((unsigned int)nd > (unsigned int)NPY_MAXDIMS) {\n-        PyErr_Format(PyExc_ValueError,\n-                     \"number of dimensions must be within [0, %d]\",\n-                     NPY_MAXDIMS);\n-        Py_DECREF(descr);\n-        return NULL;\n-    }\n-\n     \/* Check datatype element size *\/\n     nbytes = descr->elsize;\n     if (PyDataType_ISUNSIZED(descr)) {"
        },
        {
            "index":764,
            "vuln_id":"GHSA-fphq-gw9m-ghrv",
            "cwe_id":"{'CWE-617'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ea3b43e98c32c97b35d52b4c66f9107452ca8fb2'}",
            "dataset":"osv",
            "summary":"CHECK-fail in `CTCGreedyDecoder` ### Impact\nAn attacker can trigger a denial of service via a `CHECK`-fail in `tf.raw_ops.CTCGreedyDecoder`:\n\n```python\nimport tensorflow as tf\n\ninputs = tf.constant([], shape=[18, 2, 0], dtype=tf.float32)\nsequence_length = tf.constant([-100, 17], shape=[2], dtype=tf.int32)\nmerge_repeated = False\n\ntf.raw_ops.CTCGreedyDecoder(inputs=inputs, sequence_length=sequence_length, merge_repeated=merge_repeated)\n```\n  \nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/1615440b17b364b875eb06f43d087381f1460a65\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc#L37-L50) has a `CHECK_LT` inserted to validate some invariants. When this condition is false, the program aborts, instead of returning a valid error to the user. This abnormal termination can be weaponized in denial of service attacks.\n\n### Patches \nWe have patched the issue in GitHub commit [ea3b43e98c32c97b35d52b4c66f9107452ca8fb2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ea3b43e98c32c97b35d52b4c66f9107452ca8fb2).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n                      \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.        \n                      \n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ea3b43e98c32c97b35d52b4c66f9107452ca8fb2",
            "commit_sha":"ea3b43e98c32c97b35d52b4c66f9107452ca8fb2",
            "patch":"SINGLE",
            "chain_ord":"['ea3b43e98c32c97b35d52b4c66f9107452ca8fb2']",
            "before_first_fix_commit":"{'1615440b17b364b875eb06f43d087381f1460a65'}",
            "last_fix_commit":"ea3b43e98c32c97b35d52b4c66f9107452ca8fb2",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/22\/2021, 22:11:05",
            "message":"Fix `tf.raw_ops.CTCGreedyDecoder` CHECK failure.\n\nPiperOrigin-RevId: 369960465\nChange-Id: If0b8b3264d5a47a24ac0970ed7b81ce6b4921fae",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/ctc_decoder_ops.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ea3b43e98c32c97b35d52b4c66f9107452ca8fb2\/tensorflow%2Fcore%2Fkernels%2Fctc_decoder_ops.cc', 'patch': '@@ -232,6 +232,8 @@ class CTCGreedyDecoderOp : public OpKernel {\\n         int prev_indices = -1;\\n         for (int t = 0; t < seq_len_t(b); ++t) {\\n           int max_class_indices;\\n+          OP_REQUIRES(ctx, input_list_t[t].dimension(1) > 0,\\n+                      errors::InvalidArgument(\"Invalid input dimensions.\"));\\n           log_prob_t(b, 0) +=\\n               -RowMax<T>(input_list_t[t], b, &max_class_indices);\\n           if (max_class_indices != blank_index &&'}}",
            "message_norm":"fix `tf.raw_ops.ctcgreedydecoder` check failure.\n\npiperorigin-revid: 369960465\nchange-id: if0b8b3264d5a47a24ac0970ed7b81ce6b4921fae",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('tf.raw_ops.ctcgreedydecoder', 'SECWORD', ''), ('369960465', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ctc_decoder_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From ea3b43e98c32c97b35d52b4c66f9107452ca8fb2 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Thu, 22 Apr 2021 15:11:05 -0700\nSubject: [PATCH] Fix `tf.raw_ops.CTCGreedyDecoder` CHECK failure.\n\nPiperOrigin-RevId: 369960465\nChange-Id: If0b8b3264d5a47a24ac0970ed7b81ce6b4921fae\n---\n tensorflow\/core\/kernels\/ctc_decoder_ops.cc | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc b\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc\nindex d62aef2d03b988..22681f97437f0c 100644\n--- a\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc\n+++ b\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc\n@@ -232,6 +232,8 @@ class CTCGreedyDecoderOp : public OpKernel {\n         int prev_indices = -1;\n         for (int t = 0; t < seq_len_t(b); ++t) {\n           int max_class_indices;\n+          OP_REQUIRES(ctx, input_list_t[t].dimension(1) > 0,\n+                      errors::InvalidArgument(\"Invalid input dimensions.\"));\n           log_prob_t(b, 0) +=\n               -RowMax<T>(input_list_t[t], b, &max_class_indices);\n           if (max_class_indices != blank_index &&"
        },
        {
            "index":148,
            "vuln_id":"GHSA-4mv4-gmmf-q382",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/DataTables\/DataTablesSrc\/commit\/ccf86dc5982bd8e16d11a0815c940f5b256874c9', 'https:\/\/github.com\/DataTables\/DataTablesSrc\/commit\/9780a3693572757d87bf70e48bd7555faf974f28'}",
            "dataset":"osv",
            "summary":"DataTable Vulnerable to Cross-Site Scripting Cross-site scripting (XSS) vulnerability in the DataTables plugin 1.10.8 and earlier for jQuery allows remote attackers to inject arbitrary web script or HTML via the scripts parameter to media\/unit_testing\/templates\/6776.php.\n\n\n## Recommendation\n\nUpdate to a version greater than 1.10.8. A [fix](https:\/\/github.com\/DataTables\/DataTablesSrc\/commit\/ccf86dc5982bd8e16d) appears in [version 1.10.10](https:\/\/github.com\/DataTables\/DataTablesSrc\/commits\/1.10.10?after=9780a3693572757d87bf70e48bd7555faf974f28+34&branch=1.10.10&qualified_name=refs%2Ftags%2F1.10.10).",
            "published_date":"2020-08-31",
            "chain_len":2,
            "project":"https:\/\/github.com\/DataTables\/DataTablesSrc",
            "commit_href":"https:\/\/github.com\/DataTables\/DataTablesSrc\/commit\/9780a3693572757d87bf70e48bd7555faf974f28",
            "commit_sha":"9780a3693572757d87bf70e48bd7555faf974f28",
            "patch":"MULTI",
            "chain_ord":"['ccf86dc5982bd8e16d11a0815c940f5b256874c9', '9780a3693572757d87bf70e48bd7555faf974f28']",
            "before_first_fix_commit":"{'51fa58e1c6baf456fe83fbfc7bfa4082be850365'}",
            "last_fix_commit":"9780a3693572757d87bf70e48bd7555faf974f28",
            "chain_ord_pos":2.0,
            "commit_datetime":"11\/06\/2015, 15:33:43",
            "message":"Version - 1.10.10 ready",
            "author":"Allan Jardine",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 3, 'total': 6}",
            "files":"{'js\/DataTables.js': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DataTables\/DataTablesSrc\/raw\/9780a3693572757d87bf70e48bd7555faf974f28\/js%2FDataTables.js', 'patch': '@@ -1,11 +1,11 @@\\n-\/*! DataTables 1.10.10-dev\\n+\/*! DataTables 1.10.10\\n  * \u00a92008-2015 SpryMedia Ltd - datatables.net\/license\\n  *\/\\n \\n \/**\\n  * @summary     DataTables\\n  * @description Paginate, search and order HTML tables\\n- * @version     1.10.10-dev\\n+ * @version     1.10.10\\n  * @file        jquery.dataTables.js\\n  * @author      SpryMedia Ltd (www.sprymedia.co.uk)\\n  * @contact     www.sprymedia.co.uk\/contact\\n@@ -170,7 +170,7 @@\\n \\t *  @type string\\n \\t *  @default Version number\\n \\t *\/\\n-\\tDataTable.version = \"1.10.10-dev\";\\n+\\tDataTable.version = \"1.10.10\";\\n \\n \\t\/**\\n \\t * Private data store, containing all of the settings objects that are'}}",
            "message_norm":"version - 1.10.10 ready",
            "language":"en",
            "entities":"[('1.10.10', 'VERSION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['js\/DataTables.js'])",
            "num_files":1.0,
            "patch_content":"From 9780a3693572757d87bf70e48bd7555faf974f28 Mon Sep 17 00:00:00 2001\nFrom: Allan Jardine <allan.jardine@sprymedia.co.uk>\nDate: Fri, 6 Nov 2015 15:33:43 +0000\nSubject: [PATCH] Version - 1.10.10 ready\n\n---\n js\/DataTables.js | 6 +++---\n 1 file changed, 3 insertions(+), 3 deletions(-)\n\ndiff --git a\/js\/DataTables.js b\/js\/DataTables.js\nindex 27644401e..24deef67a 100644\n--- a\/js\/DataTables.js\n+++ b\/js\/DataTables.js\n@@ -1,11 +1,11 @@\n-\/*! DataTables 1.10.10-dev\n+\/*! DataTables 1.10.10\n  * \u00a92008-2015 SpryMedia Ltd - datatables.net\/license\n  *\/\n \n \/**\n  * @summary     DataTables\n  * @description Paginate, search and order HTML tables\n- * @version     1.10.10-dev\n+ * @version     1.10.10\n  * @file        jquery.dataTables.js\n  * @author      SpryMedia Ltd (www.sprymedia.co.uk)\n  * @contact     www.sprymedia.co.uk\/contact\n@@ -170,7 +170,7 @@\n \t *  @type string\n \t *  @default Version number\n \t *\/\n-\tDataTable.version = \"1.10.10-dev\";\n+\tDataTable.version = \"1.10.10\";\n \n \t\/**\n \t * Private data store, containing all of the settings objects that are"
        },
        {
            "index":847,
            "vuln_id":"GHSA-q3x2-jvp3-wj78",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/975fc1d6d3fba598ee550849ceb81af23ce72e08'}",
            "dataset":"osv",
            "summary":"Unrestricted XML files leading to cross-site scripting in Microweber Microweber prior to 1.2.12 allows unrestricted upload of XML files, which malicious actors can exploit to cause a stored cross-site scripting attack.",
            "published_date":"2022-03-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/975fc1d6d3fba598ee550849ceb81af23ce72e08",
            "commit_sha":"975fc1d6d3fba598ee550849ceb81af23ce72e08",
            "patch":"SINGLE",
            "chain_ord":"['975fc1d6d3fba598ee550849ceb81af23ce72e08']",
            "before_first_fix_commit":"{'27622f02c39d4cce67c43e5da38a6ab504202e13'}",
            "last_fix_commit":"975fc1d6d3fba598ee550849ceb81af23ce72e08",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2022, 15:29:28",
            "message":"Update Files.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'src\/MicroweberPackages\/Utils\/System\/Files.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/975fc1d6d3fba598ee550849ceb81af23ce72e08\/src%2FMicroweberPackages%2FUtils%2FSystem%2FFiles.php', 'patch': \"@@ -1154,11 +1154,11 @@ function get_allowed_files_extensions_for_upload($fileTypes = 'images', $returnA\\n                 break;\\n             case 'file':\\n             case 'files':\\n-                $are_allowed .= ',doc,docx,pdf,json,rtf,txt,zip,gzip,rar,cad,xml,psd,xlsx,csv,7z';\\n+                $are_allowed .= ',doc,docx,pdf,json,rtf,txt,zip,gzip,rar,cad,psd,xlsx,csv,7z'; \\n                 break;\\n             case 'documents':\\n             case 'doc':\\n-                $are_allowed .= ',doc,docx,pdf,log,msg,odt,pages,rtf,tex,txt,wpd,wps,pps,ppt,pptx,xml,xlr,xls,xlsx';\\n+                $are_allowed .= ',doc,docx,pdf,log,msg,odt,pages,rtf,tex,txt,wpd,wps,pps,ppt,pptx,xlr,xls,xlsx';\\n                 break;\\n             case 'archives':\\n             case 'arc':\"}}",
            "message_norm":"update files.php",
            "language":"fr",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/Utils\/System\/Files.php'])",
            "num_files":1.0,
            "patch_content":"From 975fc1d6d3fba598ee550849ceb81af23ce72e08 Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Mon, 14 Mar 2022 17:29:28 +0200\nSubject: [PATCH] Update Files.php\n\n---\n src\/MicroweberPackages\/Utils\/System\/Files.php | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/MicroweberPackages\/Utils\/System\/Files.php b\/src\/MicroweberPackages\/Utils\/System\/Files.php\nindex b9542762a82..c3567cb2aa0 100644\n--- a\/src\/MicroweberPackages\/Utils\/System\/Files.php\n+++ b\/src\/MicroweberPackages\/Utils\/System\/Files.php\n@@ -1154,11 +1154,11 @@ function get_allowed_files_extensions_for_upload($fileTypes = 'images', $returnA\n                 break;\n             case 'file':\n             case 'files':\n-                $are_allowed .= ',doc,docx,pdf,json,rtf,txt,zip,gzip,rar,cad,xml,psd,xlsx,csv,7z';\n+                $are_allowed .= ',doc,docx,pdf,json,rtf,txt,zip,gzip,rar,cad,psd,xlsx,csv,7z'; \n                 break;\n             case 'documents':\n             case 'doc':\n-                $are_allowed .= ',doc,docx,pdf,log,msg,odt,pages,rtf,tex,txt,wpd,wps,pps,ppt,pptx,xml,xlr,xls,xlsx';\n+                $are_allowed .= ',doc,docx,pdf,log,msg,odt,pages,rtf,tex,txt,wpd,wps,pps,ppt,pptx,xlr,xls,xlsx';\n                 break;\n             case 'archives':\n             case 'arc':"
        },
        {
            "index":638,
            "vuln_id":"GHSA-773q-5334-5gf9",
            "cwe_id":"{'CWE-789'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/rust-blockchain\/evm\/commit\/19ade858c430ab13eb562764a870ac9f8506f8dd'}",
            "dataset":"osv",
            "summary":"Memory over-allocation in evm-core Prior to the patch, when executing specific EVM opcodes related\nto memory operations that use `evm_core::Memory::copy_large`, the\ncrate can over-allocate memory when it is not needed, making it\npossible for an attacker to perform denial-of-service attack.\n\nThe flaw was corrected in commit `19ade85`.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/rust-blockchain\/evm",
            "commit_href":"https:\/\/github.com\/rust-blockchain\/evm\/commit\/19ade858c430ab13eb562764a870ac9f8506f8dd",
            "commit_sha":"19ade858c430ab13eb562764a870ac9f8506f8dd",
            "patch":"SINGLE",
            "chain_ord":"['19ade858c430ab13eb562764a870ac9f8506f8dd']",
            "before_first_fix_commit":"{'2a8a3e967ec265fdc7120ff6b57ceab021ca69f6'}",
            "last_fix_commit":"19ade858c430ab13eb562764a870ac9f8506f8dd",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/11\/2021, 15:33:30",
            "message":"Skip setting memory value if the value vec is empty",
            "author":"Wei Tang",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'core\/src\/memory.rs': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/rust-blockchain\/evm\/raw\/19ade858c430ab13eb562764a870ac9f8506f8dd\/core%2Fsrc%2Fmemory.rs', 'patch': '@@ -105,6 +105,10 @@ impl Memory {\\n \\t\\tvalue: &[u8],\\n \\t\\ttarget_size: Option<usize>\\n \\t) -> Result<(), ExitFatal> {\\n+\\t\\tif value.is_empty() {\\n+\\t\\t\\treturn Ok(())\\n+\\t\\t}\\n+\\t\\t\\n \\t\\tlet target_size = target_size.unwrap_or(value.len());\\n \\n \\t\\tif offset.checked_add(target_size)'}}",
            "message_norm":"skip setting memory value if the value vec is empty",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/src\/memory.rs'])",
            "num_files":1.0,
            "patch_content":"From 19ade858c430ab13eb562764a870ac9f8506f8dd Mon Sep 17 00:00:00 2001\nFrom: Wei Tang <wei@that.world>\nDate: Tue, 11 May 2021 17:33:30 +0200\nSubject: [PATCH] Skip setting memory value if the value vec is empty\n\n---\n core\/src\/memory.rs | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/core\/src\/memory.rs b\/core\/src\/memory.rs\nindex 3d209be0..a2266cf6 100644\n--- a\/core\/src\/memory.rs\n+++ b\/core\/src\/memory.rs\n@@ -105,6 +105,10 @@ impl Memory {\n \t\tvalue: &[u8],\n \t\ttarget_size: Option<usize>\n \t) -> Result<(), ExitFatal> {\n+\t\tif value.is_empty() {\n+\t\t\treturn Ok(())\n+\t\t}\n+\t\t\n \t\tlet target_size = target_size.unwrap_or(value.len());\n \n \t\tif offset.checked_add(target_size)"
        },
        {
            "index":336,
            "vuln_id":"GHSA-ffhg-7mh4-33c4",
            "cwe_id":"{'CWE-347'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/golang\/crypto\/commit\/bac4c82f69751a6dd76e702d54b3ceb88adab236'}",
            "dataset":"osv",
            "summary":"Improper Verification of Cryptographic Signature in golang.org\/x\/crypto golang.org\/x\/crypto before v0.0.0-20200220183623-bac4c82f6975 for Go allows a panic during signature verification in the golang.org\/x\/crypto\/ssh package. A client can attack an SSH server that accepts public keys. Also, a server can attack any SSH client.",
            "published_date":"2021-05-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/golang\/crypto",
            "commit_href":"https:\/\/github.com\/golang\/crypto\/commit\/bac4c82f69751a6dd76e702d54b3ceb88adab236",
            "commit_sha":"bac4c82f69751a6dd76e702d54b3ceb88adab236",
            "patch":"SINGLE",
            "chain_ord":"['bac4c82f69751a6dd76e702d54b3ceb88adab236']",
            "before_first_fix_commit":"{'1ad67e1f0ef495d4014b6ffd8f2cf80f91fffbce'}",
            "last_fix_commit":"bac4c82f69751a6dd76e702d54b3ceb88adab236",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/11\/2020, 23:53:37",
            "message":"ssh: return an error for malformed ed25519 public keys rather than panic\n\nAn attacker can craft an ssh-ed25519 or sk-ssh-ed25519@openssh.com\npublic key, such that the library will panic when trying to verify a\nsignature with it. Clients can deliver such a public key and signature\nto any golang.org\/x\/crypto\/ssh server with a PublicKeyCallback, and\nservers can deliver them to any golang.org\/x\/crypto\/ssh client.\n\nThis issue was discovered and reported by Alex Gaynor, Fish in a Barrel,\nand is tracked as CVE-2020-9283.\n\nChange-Id: Ie25b78a0b0181fbbc8cc7de4f4e27d908777529c\nReviewed-on: https:\/\/go-review.googlesource.com\/c\/crypto\/+\/220357\nRun-TryBot: Filippo Valsorda <filippo@golang.org>\nReviewed-by: Katie Hockman <katie@golang.org>\nTryBot-Result: Gobot Gobot <gobot@golang.org>",
            "author":"Filippo Valsorda",
            "comments":null,
            "stats":"{'additions': 20, 'deletions': 8, 'total': 28}",
            "files":"{'ssh\/keys.go': {'additions': 20, 'deletions': 8, 'changes': 28, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/golang\/crypto\/raw\/bac4c82f69751a6dd76e702d54b3ceb88adab236\/ssh%2Fkeys.go', 'patch': '@@ -562,9 +562,11 @@ func parseED25519(in []byte) (out PublicKey, rest []byte, err error) {\\n \\t\\treturn nil, nil, err\\n \\t}\\n \\n-\\tkey := ed25519.PublicKey(w.KeyBytes)\\n+\\tif l := len(w.KeyBytes); l != ed25519.PublicKeySize {\\n+\\t\\treturn nil, nil, fmt.Errorf(\"invalid size %d for Ed25519 public key\", l)\\n+\\t}\\n \\n-\\treturn (ed25519PublicKey)(key), w.Rest, nil\\n+\\treturn ed25519PublicKey(w.KeyBytes), w.Rest, nil\\n }\\n \\n func (k ed25519PublicKey) Marshal() []byte {\\n@@ -582,9 +584,11 @@ func (k ed25519PublicKey) Verify(b []byte, sig *Signature) error {\\n \\tif sig.Format != k.Type() {\\n \\t\\treturn fmt.Errorf(\"ssh: signature type %s for key type %s\", sig.Format, k.Type())\\n \\t}\\n+\\tif l := len(k); l != ed25519.PublicKeySize {\\n+\\t\\treturn fmt.Errorf(\"ssh: invalid size %d for Ed25519 public key\", l)\\n+\\t}\\n \\n-\\tedKey := (ed25519.PublicKey)(k)\\n-\\tif ok := ed25519.Verify(edKey, b, sig.Blob); !ok {\\n+\\tif ok := ed25519.Verify(ed25519.PublicKey(k), b, sig.Blob); !ok {\\n \\t\\treturn errors.New(\"ssh: signature did not verify\")\\n \\t}\\n \\n@@ -838,6 +842,10 @@ func parseSKEd25519(in []byte) (out PublicKey, rest []byte, err error) {\\n \\t\\treturn nil, nil, err\\n \\t}\\n \\n+\\tif l := len(w.KeyBytes); l != ed25519.PublicKeySize {\\n+\\t\\treturn nil, nil, fmt.Errorf(\"invalid size %d for Ed25519 public key\", l)\\n+\\t}\\n+\\n \\tkey := new(skEd25519PublicKey)\\n \\tkey.application = w.Application\\n \\tkey.PublicKey = ed25519.PublicKey(w.KeyBytes)\\n@@ -862,6 +870,9 @@ func (k *skEd25519PublicKey) Verify(data []byte, sig *Signature) error {\\n \\tif sig.Format != k.Type() {\\n \\t\\treturn fmt.Errorf(\"ssh: signature type %s for key type %s\", sig.Format, k.Type())\\n \\t}\\n+\\tif l := len(k.PublicKey); l != ed25519.PublicKeySize {\\n+\\t\\treturn fmt.Errorf(\"invalid size %d for Ed25519 public key\", l)\\n+\\t}\\n \\n \\th := sha256.New()\\n \\th.Write([]byte(k.application))\\n@@ -898,8 +909,7 @@ func (k *skEd25519PublicKey) Verify(data []byte, sig *Signature) error {\\n \\n \\toriginal := Marshal(blob)\\n \\n-\\tedKey := (ed25519.PublicKey)(k.PublicKey)\\n-\\tif ok := ed25519.Verify(edKey, original, edSig.Signature); !ok {\\n+\\tif ok := ed25519.Verify(k.PublicKey, original, edSig.Signature); !ok {\\n \\t\\treturn errors.New(\"ssh: signature did not verify\")\\n \\t}\\n \\n@@ -1051,7 +1061,10 @@ func NewPublicKey(key interface{}) (PublicKey, error) {\\n \\tcase *dsa.PublicKey:\\n \\t\\treturn (*dsaPublicKey)(key), nil\\n \\tcase ed25519.PublicKey:\\n-\\t\\treturn (ed25519PublicKey)(key), nil\\n+\\t\\tif l := len(key); l != ed25519.PublicKeySize {\\n+\\t\\t\\treturn nil, fmt.Errorf(\"ssh: invalid size %d for Ed25519 public key\", l)\\n+\\t\\t}\\n+\\t\\treturn ed25519PublicKey(key), nil\\n \\tdefault:\\n \\t\\treturn nil, fmt.Errorf(\"ssh: unsupported key type %T\", key)\\n \\t}\\n@@ -1304,7 +1317,6 @@ func parseOpenSSHPrivateKey(key []byte, decrypt openSSHDecryptFunc) (crypto.Priv\\n \\t\\treturn nil, errors.New(\"ssh: malformed OpenSSH key\")\\n \\t}\\n \\n-\\t\/\/ we only handle ed25519 and rsa keys currently\\n \\tswitch pk1.Keytype {\\n \\tcase KeyAlgoRSA:\\n \\t\\t\/\/ https:\/\/github.com\/openssh\/openssh-portable\/blob\/master\/sshkey.c#L2760-L2773'}}",
            "message_norm":"ssh: return an error for malformed ed25519 public keys rather than panic\n\nan attacker can craft an ssh-ed25519 or sk-ssh-ed25519@openssh.com\npublic key, such that the library will panic when trying to verify a\nsignature with it. clients can deliver such a public key and signature\nto any golang.org\/x\/crypto\/ssh server with a publickeycallback, and\nservers can deliver them to any golang.org\/x\/crypto\/ssh client.\n\nthis issue was discovered and reported by alex gaynor, fish in a barrel,\nand is tracked as cve-2020-9283.\n\nchange-id: ie25b78a0b0181fbbc8cc7de4f4e27d908777529c\nreviewed-on: https:\/\/go-review.googlesource.com\/c\/crypto\/+\/220357\nrun-trybot: filippo valsorda <filippo@golang.org>\nreviewed-by: katie hockman <katie@golang.org>\ntrybot-result: gobot gobot <gobot@golang.org>",
            "language":"en",
            "entities":"[('ssh', 'SECWORD', ''), ('error', 'FLAW', ''), ('ed25519', 'SHA', 'generic_sha'), ('public keys', 'SECWORD', ''), ('attacker', 'FLAW', ''), ('ssh', 'SECWORD', ''), ('ed25519', 'SHA', 'generic_sha'), ('public key', 'SECWORD', ''), ('verify', 'ACTION', ''), ('signature', 'SECWORD', ''), ('public key', 'SECWORD', ''), ('signature', 'SECWORD', ''), ('golang.org\/x\/crypto\/ssh', 'SECWORD', ''), ('server', 'SECWORD', ''), ('publickeycallback', 'SECWORD', ''), ('servers', 'SECWORD', ''), ('golang.org\/x\/crypto\/ssh', 'SECWORD', ''), ('issue', 'FLAW', ''), ('cve-2020-9283', 'VULNID', 'CVE'), ('https:\/\/go-review.googlesource.com\/c\/crypto\/+\/220357', 'SECWORD', ''), ('filippo@golang.org', 'EMAIL', ''), ('katie@golang.org', 'EMAIL', ''), ('gobot@golang.org', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['ssh\/keys.go'])",
            "num_files":1.0,
            "patch_content":"From bac4c82f69751a6dd76e702d54b3ceb88adab236 Mon Sep 17 00:00:00 2001\nFrom: Filippo Valsorda <filippo@golang.org>\nDate: Tue, 11 Feb 2020 18:53:37 -0500\nSubject: [PATCH] ssh: return an error for malformed ed25519 public keys rather\n than panic\n\nAn attacker can craft an ssh-ed25519 or sk-ssh-ed25519@openssh.com\npublic key, such that the library will panic when trying to verify a\nsignature with it. Clients can deliver such a public key and signature\nto any golang.org\/x\/crypto\/ssh server with a PublicKeyCallback, and\nservers can deliver them to any golang.org\/x\/crypto\/ssh client.\n\nThis issue was discovered and reported by Alex Gaynor, Fish in a Barrel,\nand is tracked as CVE-2020-9283.\n\nChange-Id: Ie25b78a0b0181fbbc8cc7de4f4e27d908777529c\nReviewed-on: https:\/\/go-review.googlesource.com\/c\/crypto\/+\/220357\nRun-TryBot: Filippo Valsorda <filippo@golang.org>\nReviewed-by: Katie Hockman <katie@golang.org>\nTryBot-Result: Gobot Gobot <gobot@golang.org>\n---\n ssh\/keys.go | 28 ++++++++++++++++++++--------\n 1 file changed, 20 insertions(+), 8 deletions(-)\n\ndiff --git a\/ssh\/keys.go b\/ssh\/keys.go\nindex d63cbf60b7..06f537c135 100644\n--- a\/ssh\/keys.go\n+++ b\/ssh\/keys.go\n@@ -562,9 +562,11 @@ func parseED25519(in []byte) (out PublicKey, rest []byte, err error) {\n \t\treturn nil, nil, err\n \t}\n \n-\tkey := ed25519.PublicKey(w.KeyBytes)\n+\tif l := len(w.KeyBytes); l != ed25519.PublicKeySize {\n+\t\treturn nil, nil, fmt.Errorf(\"invalid size %d for Ed25519 public key\", l)\n+\t}\n \n-\treturn (ed25519PublicKey)(key), w.Rest, nil\n+\treturn ed25519PublicKey(w.KeyBytes), w.Rest, nil\n }\n \n func (k ed25519PublicKey) Marshal() []byte {\n@@ -582,9 +584,11 @@ func (k ed25519PublicKey) Verify(b []byte, sig *Signature) error {\n \tif sig.Format != k.Type() {\n \t\treturn fmt.Errorf(\"ssh: signature type %s for key type %s\", sig.Format, k.Type())\n \t}\n+\tif l := len(k); l != ed25519.PublicKeySize {\n+\t\treturn fmt.Errorf(\"ssh: invalid size %d for Ed25519 public key\", l)\n+\t}\n \n-\tedKey := (ed25519.PublicKey)(k)\n-\tif ok := ed25519.Verify(edKey, b, sig.Blob); !ok {\n+\tif ok := ed25519.Verify(ed25519.PublicKey(k), b, sig.Blob); !ok {\n \t\treturn errors.New(\"ssh: signature did not verify\")\n \t}\n \n@@ -838,6 +842,10 @@ func parseSKEd25519(in []byte) (out PublicKey, rest []byte, err error) {\n \t\treturn nil, nil, err\n \t}\n \n+\tif l := len(w.KeyBytes); l != ed25519.PublicKeySize {\n+\t\treturn nil, nil, fmt.Errorf(\"invalid size %d for Ed25519 public key\", l)\n+\t}\n+\n \tkey := new(skEd25519PublicKey)\n \tkey.application = w.Application\n \tkey.PublicKey = ed25519.PublicKey(w.KeyBytes)\n@@ -862,6 +870,9 @@ func (k *skEd25519PublicKey) Verify(data []byte, sig *Signature) error {\n \tif sig.Format != k.Type() {\n \t\treturn fmt.Errorf(\"ssh: signature type %s for key type %s\", sig.Format, k.Type())\n \t}\n+\tif l := len(k.PublicKey); l != ed25519.PublicKeySize {\n+\t\treturn fmt.Errorf(\"invalid size %d for Ed25519 public key\", l)\n+\t}\n \n \th := sha256.New()\n \th.Write([]byte(k.application))\n@@ -898,8 +909,7 @@ func (k *skEd25519PublicKey) Verify(data []byte, sig *Signature) error {\n \n \toriginal := Marshal(blob)\n \n-\tedKey := (ed25519.PublicKey)(k.PublicKey)\n-\tif ok := ed25519.Verify(edKey, original, edSig.Signature); !ok {\n+\tif ok := ed25519.Verify(k.PublicKey, original, edSig.Signature); !ok {\n \t\treturn errors.New(\"ssh: signature did not verify\")\n \t}\n \n@@ -1051,7 +1061,10 @@ func NewPublicKey(key interface{}) (PublicKey, error) {\n \tcase *dsa.PublicKey:\n \t\treturn (*dsaPublicKey)(key), nil\n \tcase ed25519.PublicKey:\n-\t\treturn (ed25519PublicKey)(key), nil\n+\t\tif l := len(key); l != ed25519.PublicKeySize {\n+\t\t\treturn nil, fmt.Errorf(\"ssh: invalid size %d for Ed25519 public key\", l)\n+\t\t}\n+\t\treturn ed25519PublicKey(key), nil\n \tdefault:\n \t\treturn nil, fmt.Errorf(\"ssh: unsupported key type %T\", key)\n \t}\n@@ -1304,7 +1317,6 @@ func parseOpenSSHPrivateKey(key []byte, decrypt openSSHDecryptFunc) (crypto.Priv\n \t\treturn nil, errors.New(\"ssh: malformed OpenSSH key\")\n \t}\n \n-\t\/\/ we only handle ed25519 and rsa keys currently\n \tswitch pk1.Keytype {\n \tcase KeyAlgoRSA:\n \t\t\/\/ https:\/\/github.com\/openssh\/openssh-portable\/blob\/master\/sshkey.c#L2760-L2773"
        },
        {
            "index":613,
            "vuln_id":"GHSA-rhrq-64mq-hf9h",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e206baedf8bef0334cca3eb92bab134ef525a28'}",
            "dataset":"osv",
            "summary":"FPE in TFLite division operations ### Impact\nThe implementation of division in TFLite is [vulnerable to a division by 0 error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/lite\/kernels\/div.cc)\n\nThere is no check that the divisor tensor does not contain zero elements.\n\n### Patches\nWe have patched the issue in GitHub commit [1e206baedf8bef0334cca3eb92bab134ef525a28](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e206baedf8bef0334cca3eb92bab134ef525a28).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e206baedf8bef0334cca3eb92bab134ef525a28",
            "commit_sha":"1e206baedf8bef0334cca3eb92bab134ef525a28",
            "patch":"SINGLE",
            "chain_ord":"['1e206baedf8bef0334cca3eb92bab134ef525a28']",
            "before_first_fix_commit":"{'9579070c3fe96b4ed3b07c1b294c7a402250fb43'}",
            "last_fix_commit":"1e206baedf8bef0334cca3eb92bab134ef525a28",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/16\/2021, 21:23:21",
            "message":"Prevent a division by 0 in division ops.\n\nPiperOrigin-RevId: 385223169\nChange-Id: Ia4228960b5d2aa44480385f74bdd70d21a3613c3",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 1, 'total': 17}",
            "files":"{'tensorflow\/lite\/kernels\/div.cc': {'additions': 16, 'deletions': 1, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1e206baedf8bef0334cca3eb92bab134ef525a28\/tensorflow%2Flite%2Fkernels%2Fdiv.cc', 'patch': \"@@ -216,9 +216,23 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   TF_LITE_ENSURE_OK(context,\\n                     GetOutputSafe(context, node, kOutputTensor, &output));\\n \\n-  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\\n+  \/\/ TODO(b\/193904910): This can written with C++ templates\\n+#define TF_LITE_CHECK_DIV_NON_ZERO(data_type)                       \\\\\\n+  const auto* input2_data = GetTensorData<data_type>(input2);       \\\\\\n+  const size_t input2_elements = input2->bytes \/ sizeof(data_type); \\\\\\n+  for (size_t i = 0; i < input2_elements; i++) {                    \\\\\\n+    TF_LITE_ENSURE(context, input2_data[i] != 0);                   \\\\\\n+  }\\n+\\n+  if (output->type == kTfLiteFloat32) {\\n+    \/\/ Div by zero seems ok in this case, just like in TF case infinities are\\n+    \/\/ returned. So we don't do a check at this point.\\n+    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\\n+  } else if (output->type == kTfLiteInt32) {\\n+    TF_LITE_CHECK_DIV_NON_ZERO(int32_t);\\n     EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\\n   } else if (output->type == kTfLiteUInt8) {\\n+    TF_LITE_CHECK_DIV_NON_ZERO(uint8_t);\\n     TF_LITE_ENSURE_OK(\\n         context, EvalQuantized<kernel_type>(context, node, params, data, input1,\\n                                             input2, output));\\n@@ -229,6 +243,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n         output->type);\\n     return kTfLiteError;\\n   }\\n+#undef TF_LITE_CHECK_DIV_NON_ZERO\\n \\n   return kTfLiteOk;\\n }\"}}",
            "message_norm":"prevent a division by 0 in division ops.\n\npiperorigin-revid: 385223169\nchange-id: ia4228960b5d2aa44480385f74bdd70d21a3613c3",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('385223169', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/div.cc'])",
            "num_files":1.0,
            "patch_content":"From 1e206baedf8bef0334cca3eb92bab134ef525a28 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 16 Jul 2021 14:23:21 -0700\nSubject: [PATCH] Prevent a division by 0 in division ops.\n\nPiperOrigin-RevId: 385223169\nChange-Id: Ia4228960b5d2aa44480385f74bdd70d21a3613c3\n---\n tensorflow\/lite\/kernels\/div.cc | 17 ++++++++++++++++-\n 1 file changed, 16 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/div.cc b\/tensorflow\/lite\/kernels\/div.cc\nindex f744b4ba1b7f63..51623a969d1b11 100644\n--- a\/tensorflow\/lite\/kernels\/div.cc\n+++ b\/tensorflow\/lite\/kernels\/div.cc\n@@ -216,9 +216,23 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n \n-  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n+  \/\/ TODO(b\/193904910): This can written with C++ templates\n+#define TF_LITE_CHECK_DIV_NON_ZERO(data_type)                       \\\n+  const auto* input2_data = GetTensorData<data_type>(input2);       \\\n+  const size_t input2_elements = input2->bytes \/ sizeof(data_type); \\\n+  for (size_t i = 0; i < input2_elements; i++) {                    \\\n+    TF_LITE_ENSURE(context, input2_data[i] != 0);                   \\\n+  }\n+\n+  if (output->type == kTfLiteFloat32) {\n+    \/\/ Div by zero seems ok in this case, just like in TF case infinities are\n+    \/\/ returned. So we don't do a check at this point.\n+    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n+  } else if (output->type == kTfLiteInt32) {\n+    TF_LITE_CHECK_DIV_NON_ZERO(int32_t);\n     EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n   } else if (output->type == kTfLiteUInt8) {\n+    TF_LITE_CHECK_DIV_NON_ZERO(uint8_t);\n     TF_LITE_ENSURE_OK(\n         context, EvalQuantized<kernel_type>(context, node, params, data, input1,\n                                             input2, output));\n@@ -229,6 +243,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n         output->type);\n     return kTfLiteError;\n   }\n+#undef TF_LITE_CHECK_DIV_NON_ZERO\n \n   return kTfLiteOk;\n }"
        },
        {
            "index":308,
            "vuln_id":"GHSA-j85q-whc9-g4p9",
            "cwe_id":"{'CWE-338'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/4b962c1740311e0d46775023b6acba39ad60e370'}",
            "dataset":"osv",
            "summary":"Use of Cryptographically Weak Pseudo-Random Number Generator in showdoc showdoc is vulnerable to Use of Cryptographically Weak Pseudo-Random Number Generator (PRNG)",
            "published_date":"2021-09-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/4b962c1740311e0d46775023b6acba39ad60e370",
            "commit_sha":"4b962c1740311e0d46775023b6acba39ad60e370",
            "patch":"SINGLE",
            "chain_ord":"['4b962c1740311e0d46775023b6acba39ad60e370']",
            "before_first_fix_commit":"{'db53edb8323dd358dc955e71d8f1fad5dab4ab7b', '034328ab35fc2bf640bf7fef2be40a5d13123b11'}",
            "last_fix_commit":"4b962c1740311e0d46775023b6acba39ad60e370",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/03\/2021, 17:19:35",
            "message":"Merge pull request #1438 from michaellrowley\/security-patch\n\nCVE-2021-3678 Patch",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'server\/Application\/Api\/Controller\/AdminSettingController.class.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/4b962c1740311e0d46775023b6acba39ad60e370\/server%2FApplication%2FApi%2FController%2FAdminSettingController.class.php', 'patch': '@@ -166,7 +166,7 @@ public function getLoginSecretKey(){\\n         $this->checkAdmin();\\n         $login_secret_key = D(\"Options\")->get(\"login_secret_key\") ;\\n         if(!$login_secret_key){\\n-            $login_secret_key = md5(\"rgrsfsrfsrf\".time().rand(1,9000000000000000).uniqid());\\n+            $login_secret_key = bin2hex( random_bytes( 16 ) );\\n             D(\"Options\")->set(\"login_secret_key\",$login_secret_key) ;\\n         }\\n         $this->sendResult(array(\"login_secret_key\"=>$login_secret_key));\\n@@ -176,7 +176,7 @@ public function getLoginSecretKey(){\\n     public function resetLoginSecretKey(){\\n         $login_user = $this->checkLogin();\\n         $this->checkAdmin();\\n-        $login_secret_key = md5(\"rgrsfsrfsrf\".time().rand(1,9000000000000000).uniqid());\\n+        $login_secret_key = bin2hex( random_bytes( 16 ) );\\n         D(\"Options\")->set(\"login_secret_key\",$login_secret_key) ;\\n         $this->sendResult(array(\"login_secret_key\"=>$login_secret_key));'}}",
            "message_norm":"merge pull request #1438 from michaellrowley\/security-patch\n\ncve-2021-3678 patch",
            "language":"en",
            "entities":"[('#1438', 'ISSUE', ''), ('security', 'SECWORD', ''), ('cve-2021-3678', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Controller\/AdminSettingController.class.php'])",
            "num_files":1.0,
            "patch_content":"From db53edb8323dd358dc955e71d8f1fad5dab4ab7b Mon Sep 17 00:00:00 2001\nFrom: Michael Rowley <michaellrowley@protonmail.com>\nDate: Tue, 3 Aug 2021 18:15:28 +0100\nSubject: [PATCH] CVE-2021-3678\n\n---\n ...\/Api\/Controller\/AdminSettingController.class.php           | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/server\/Application\/Api\/Controller\/AdminSettingController.class.php b\/server\/Application\/Api\/Controller\/AdminSettingController.class.php\nindex fc9ade207..d21bd51f0 100644\n--- a\/server\/Application\/Api\/Controller\/AdminSettingController.class.php\n+++ b\/server\/Application\/Api\/Controller\/AdminSettingController.class.php\n@@ -166,7 +166,7 @@ public function getLoginSecretKey(){\n         $this->checkAdmin();\n         $login_secret_key = D(\"Options\")->get(\"login_secret_key\") ;\n         if(!$login_secret_key){\n-            $login_secret_key = md5(\"rgrsfsrfsrf\".time().rand(1,9000000000000000).uniqid());\n+            $login_secret_key = bin2hex( random_bytes( 16 ) );\n             D(\"Options\")->set(\"login_secret_key\",$login_secret_key) ;\n         }\n         $this->sendResult(array(\"login_secret_key\"=>$login_secret_key));\n@@ -176,7 +176,7 @@ public function getLoginSecretKey(){\n     public function resetLoginSecretKey(){\n         $login_user = $this->checkLogin();\n         $this->checkAdmin();\n-        $login_secret_key = md5(\"rgrsfsrfsrf\".time().rand(1,9000000000000000).uniqid());\n+        $login_secret_key = bin2hex( random_bytes( 16 ) );\n         D(\"Options\")->set(\"login_secret_key\",$login_secret_key) ;\n         $this->sendResult(array(\"login_secret_key\"=>$login_secret_key));"
        },
        {
            "index":546,
            "vuln_id":"GHSA-545v-42p7-98fq",
            "cwe_id":"{'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886'}",
            "dataset":"osv",
            "summary":"Heap out of bounds read in `MaxPoolGradWithArgmax` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGradWithArgmax` can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32)\ngrad = tf.constant([10.0, 10.0, 10.0, 10.0], shape=[1, 1, 1, 4], dtype=tf.float32)\nargmax = tf.constant([1], shape=[1], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n  \ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  padding='SAME', include_batch_in_index=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e\/tensorflow\/core\/kernels\/maxpooling_op.cc#L1016-L1017) uses the same value to index in two different arrays but there is no guarantee that the sizes are identical. \n\n### Patches\nWe have patched the issue in GitHub commit [dcd7867de0fea4b72a2b34bd41eb74548dc23886](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "commit_sha":"dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "patch":"SINGLE",
            "chain_ord":"['dcd7867de0fea4b72a2b34bd41eb74548dc23886']",
            "before_first_fix_commit":"{'ef0c008ee84bad91ec6725ddc42091e19a30cf0e'}",
            "last_fix_commit":"dcd7867de0fea4b72a2b34bd41eb74548dc23886",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 15:38:03",
            "message":"Fix heap buffer overflow\n\nPiperOrigin-RevId: 372132844\nChange-Id: Idef9895efaf145f2b1c23d31983601ec980cd5e4",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/maxpooling_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/dcd7867de0fea4b72a2b34bd41eb74548dc23886\/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc', 'patch': '@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\\n         const int input_start = start * input_size_per_batch;\\n         const int input_end = limit * input_size_per_batch;\\n         for (int64 index = input_start; index < input_end; index++) {\\n+          if (index >= argmax.NumElements()) {\\n+            break;\\n+          }\\n           int64 grad_out_index = argmax_flat(index);\\n           if (!include_batch_in_index) {\\n             const int64 cur_batch = index \/ input_size_per_batch;'}}",
            "message_norm":"fix heap buffer overflow\n\npiperorigin-revid: 372132844\nchange-id: idef9895efaf145f2b1c23d31983601ec980cd5e4",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('372132844', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/maxpooling_op.cc'])",
            "num_files":1.0,
            "patch_content":"From dcd7867de0fea4b72a2b34bd41eb74548dc23886 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 5 May 2021 08:38:03 -0700\nSubject: [PATCH] Fix heap buffer overflow\n\nPiperOrigin-RevId: 372132844\nChange-Id: Idef9895efaf145f2b1c23d31983601ec980cd5e4\n---\n tensorflow\/core\/kernels\/maxpooling_op.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/maxpooling_op.cc b\/tensorflow\/core\/kernels\/maxpooling_op.cc\nindex b60d54533be689..003d2e94b99cd5 100644\n--- a\/tensorflow\/core\/kernels\/maxpooling_op.cc\n+++ b\/tensorflow\/core\/kernels\/maxpooling_op.cc\n@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\n         const int input_start = start * input_size_per_batch;\n         const int input_end = limit * input_size_per_batch;\n         for (int64 index = input_start; index < input_end; index++) {\n+          if (index >= argmax.NumElements()) {\n+            break;\n+          }\n           int64 grad_out_index = argmax_flat(index);\n           if (!include_batch_in_index) {\n             const int64 cur_batch = index \/ input_size_per_batch;"
        },
        {
            "index":489,
            "vuln_id":"GHSA-m242-wc86-8768",
            "cwe_id":"{'CWE-601'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/fedora-infra\/python-fedora\/commit\/b27f38a67573f4c989710c9bfb726dd4c1eeb929'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects python-fedora python-fedora 0.8.0 and lower is vulnerable to an open redirect resulting in loss of CSRF protection",
            "published_date":"2018-07-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/fedora-infra\/python-fedora",
            "commit_href":"https:\/\/github.com\/fedora-infra\/python-fedora\/commit\/b27f38a67573f4c989710c9bfb726dd4c1eeb929",
            "commit_sha":"b27f38a67573f4c989710c9bfb726dd4c1eeb929",
            "patch":"SINGLE",
            "chain_ord":"['b27f38a67573f4c989710c9bfb726dd4c1eeb929']",
            "before_first_fix_commit":"{'6cf9094e12361a0aa306752e9d9fd8bfaaf51c85'}",
            "last_fix_commit":"b27f38a67573f4c989710c9bfb726dd4c1eeb929",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/11\/2017, 13:52:01",
            "message":"Disable covert redirects and CSRF token leaking\n\nThis disallows the url() function from returning any remote URLs.\nThis prevents covert redirects, and also prevents us from leaking\nCSRF tokens to outside parties.\n\nSigned-off-by: Patrick Uiterwijk <puiterwijk@redhat.com>",
            "author":"Patrick Uiterwijk",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'fedora\/tg\/utils.py': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/fedora-infra\/python-fedora\/raw\/b27f38a67573f4c989710c9bfb726dd4c1eeb929\/fedora%2Ftg%2Futils.py', 'patch': \"@@ -81,6 +81,11 @@ def url(tgpath, tgparams=None, **kwargs):\\n     '''\\n     if not isinstance(tgpath, six.string_types):\\n         tgpath = '\/'.join(list(tgpath))\\n+    if not tgpath.startswith('\/'):\\n+        # Do not allow the url() function to be used for external urls.\\n+        # This function is primarily used in redirect() calls, so this prevents\\n+        # covert redirects and thus CSRF leaking.\\n+        tgpath = '\/'\\n     if tgpath.startswith('\/'):\\n         webpath = (config.get('server.webpath') or '').rstrip('\/')\\n         if tg_util.request_available():\"}}",
            "message_norm":"disable covert redirects and csrf token leaking\n\nthis disallows the url() function from returning any remote urls.\nthis prevents covert redirects, and also prevents us from leaking\ncsrf tokens to outside parties.\n\nsigned-off-by: patrick uiterwijk <puiterwijk@redhat.com>",
            "language":"en",
            "entities":"[('csrf', 'SECWORD', ''), ('prevents', 'ACTION', ''), ('prevents', 'ACTION', ''), ('csrf', 'SECWORD', ''), ('puiterwijk@redhat.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['fedora\/tg\/utils.py'])",
            "num_files":1.0,
            "patch_content":"From b27f38a67573f4c989710c9bfb726dd4c1eeb929 Mon Sep 17 00:00:00 2001\nFrom: Patrick Uiterwijk <puiterwijk@redhat.com>\nDate: Tue, 11 Apr 2017 15:52:01 +0200\nSubject: [PATCH] Disable covert redirects and CSRF token leaking\n\nThis disallows the url() function from returning any remote URLs.\nThis prevents covert redirects, and also prevents us from leaking\nCSRF tokens to outside parties.\n\nSigned-off-by: Patrick Uiterwijk <puiterwijk@redhat.com>\n---\n fedora\/tg\/utils.py | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/fedora\/tg\/utils.py b\/fedora\/tg\/utils.py\nindex 4f18f31d..9913df70 100644\n--- a\/fedora\/tg\/utils.py\n+++ b\/fedora\/tg\/utils.py\n@@ -81,6 +81,11 @@ def url(tgpath, tgparams=None, **kwargs):\n     '''\n     if not isinstance(tgpath, six.string_types):\n         tgpath = '\/'.join(list(tgpath))\n+    if not tgpath.startswith('\/'):\n+        # Do not allow the url() function to be used for external urls.\n+        # This function is primarily used in redirect() calls, so this prevents\n+        # covert redirects and thus CSRF leaking.\n+        tgpath = '\/'\n     if tgpath.startswith('\/'):\n         webpath = (config.get('server.webpath') or '').rstrip('\/')\n         if tg_util.request_available():"
        },
        {
            "index":496,
            "vuln_id":"GHSA-f8h4-7rgh-q2gm",
            "cwe_id":"{'CWE-787', 'CWE-120'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e0b6e58c328059829c3eb968136f17aa72b6c876'}",
            "dataset":"osv",
            "summary":"Segfault and heap buffer overflow in `{Experimental,}DatasetToTFRecord` ### Impact\nThe implementation for `tf.raw_ops.ExperimentalDatasetToTFRecord` and `tf.raw_ops.DatasetToTFRecord` can trigger heap buffer overflow and segmentation fault:\n\n```python\nimport tensorflow as tf\n\ndataset = tf.data.Dataset.range(3)\ndataset = tf.data.experimental.to_variant(dataset)\ntf.raw_ops.ExperimentalDatasetToTFRecord(\n  input_dataset=dataset,\n  filename='\/tmp\/output',\n  compression_type='')\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc#L93-L102) assumes that all records in the dataset are of string type. However, there is no check for that, and the example given above uses numeric types.\n\n### Patches\nWe have patched the issue in GitHub commit [e0b6e58c328059829c3eb968136f17aa72b6c876](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e0b6e58c328059829c3eb968136f17aa72b6c876).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e0b6e58c328059829c3eb968136f17aa72b6c876",
            "commit_sha":"e0b6e58c328059829c3eb968136f17aa72b6c876",
            "patch":"SINGLE",
            "chain_ord":"['e0b6e58c328059829c3eb968136f17aa72b6c876']",
            "before_first_fix_commit":"{'b5b9ae94a68215d4498ea2b3d1072dc4b2bf5600'}",
            "last_fix_commit":"e0b6e58c328059829c3eb968136f17aa72b6c876",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/29\/2021, 21:58:43",
            "message":"Fix segfault\/heap buffer overflow in `{Experimental,}DatasetToTFRecord` where dataset is numeric.\n\nCode assumes only strings inputs and then interprets numbers as valid `tstring`s. Then, when trying to compute the CRC of the record this results in heap buffer overflow.\n\nPiperOrigin-RevId: 387675909\nChange-Id: I7396b9b8afc1ac744112af7c0b1cd7bb41e0f556",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 1, 'total': 15}",
            "files":"{'tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc': {'additions': 14, 'deletions': 1, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e0b6e58c328059829c3eb968136f17aa72b6c876\/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fto_tf_record_op.cc', 'patch': '@@ -18,6 +18,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/function_handle_cache.h\"\\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n #include \"tensorflow\/core\/framework\/resource_mgr.h\"\\n+#include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/kernels\/ops_util.h\"\\n #include \"tensorflow\/core\/lib\/core\/threadpool.h\"\\n #include \"tensorflow\/core\/lib\/io\/record_writer.h\"\\n@@ -91,8 +92,20 @@ class ToTFRecordOp : public AsyncOpKernel {\\n     TF_RETURN_IF_ERROR(finalized_dataset->MakeIterator(\\n         &iter_ctx, \/*parent=*\/nullptr, \"ToTFRecordOpIterator\", &iterator));\\n \\n+    const int num_output_dtypes = finalized_dataset->output_dtypes().size();\\n+    if (num_output_dtypes != 1) {\\n+      return errors::InvalidArgument(\\n+          \"ToTFRecordOp currently only support datasets of 1 single column, \",\\n+          \"but got \", num_output_dtypes);\\n+    }\\n+    const DataType dt = finalized_dataset->output_dtypes()[0];\\n+    if (dt != DT_STRING) {\\n+      return errors::InvalidArgument(\\n+          \"ToTFRecordOp currently only supports DT_STRING dataypes, but got \",\\n+          DataTypeString(dt));\\n+    }\\n     std::vector<Tensor> components;\\n-    components.reserve(finalized_dataset->output_dtypes().size());\\n+    components.reserve(num_output_dtypes);\\n     bool end_of_sequence;\\n     do {\\n       TF_RETURN_IF_ERROR('}}",
            "message_norm":"fix segfault\/heap buffer overflow in `{experimental,}datasettotfrecord` where dataset is numeric.\n\ncode assumes only strings inputs and then interprets numbers as valid `tstring`s. then, when trying to compute the crc of the record this results in heap buffer overflow.\n\npiperorigin-revid: 387675909\nchange-id: i7396b9b8afc1ac744112af7c0b1cd7bb41e0f556",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('segfault', 'SECWORD', ''), ('buffer overflow', 'SECWORD', ''), ('crc', 'SECWORD', ''), ('buffer overflow', 'SECWORD', ''), ('387675909', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc'])",
            "num_files":1.0,
            "patch_content":"From e0b6e58c328059829c3eb968136f17aa72b6c876 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 14:58:43 -0700\nSubject: [PATCH] Fix segfault\/heap buffer overflow in\n `{Experimental,}DatasetToTFRecord` where dataset is numeric.\n\nCode assumes only strings inputs and then interprets numbers as valid `tstring`s. Then, when trying to compute the CRC of the record this results in heap buffer overflow.\n\nPiperOrigin-RevId: 387675909\nChange-Id: I7396b9b8afc1ac744112af7c0b1cd7bb41e0f556\n---\n ...\/kernels\/data\/experimental\/to_tf_record_op.cc  | 15 ++++++++++++++-\n 1 file changed, 14 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc b\/tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc\nindex 0ba04d0bd94bd1..4f759bede55b61 100644\n--- a\/tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc\n+++ b\/tensorflow\/core\/kernels\/data\/experimental\/to_tf_record_op.cc\n@@ -18,6 +18,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/function_handle_cache.h\"\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\n #include \"tensorflow\/core\/framework\/resource_mgr.h\"\n+#include \"tensorflow\/core\/framework\/types.h\"\n #include \"tensorflow\/core\/kernels\/ops_util.h\"\n #include \"tensorflow\/core\/lib\/core\/threadpool.h\"\n #include \"tensorflow\/core\/lib\/io\/record_writer.h\"\n@@ -91,8 +92,20 @@ class ToTFRecordOp : public AsyncOpKernel {\n     TF_RETURN_IF_ERROR(finalized_dataset->MakeIterator(\n         &iter_ctx, \/*parent=*\/nullptr, \"ToTFRecordOpIterator\", &iterator));\n \n+    const int num_output_dtypes = finalized_dataset->output_dtypes().size();\n+    if (num_output_dtypes != 1) {\n+      return errors::InvalidArgument(\n+          \"ToTFRecordOp currently only support datasets of 1 single column, \",\n+          \"but got \", num_output_dtypes);\n+    }\n+    const DataType dt = finalized_dataset->output_dtypes()[0];\n+    if (dt != DT_STRING) {\n+      return errors::InvalidArgument(\n+          \"ToTFRecordOp currently only supports DT_STRING dataypes, but got \",\n+          DataTypeString(dt));\n+    }\n     std::vector<Tensor> components;\n-    components.reserve(finalized_dataset->output_dtypes().size());\n+    components.reserve(num_output_dtypes);\n     bool end_of_sequence;\n     do {\n       TF_RETURN_IF_ERROR("
        },
        {
            "index":690,
            "vuln_id":"GHSA-cm5x-837x-jf3c",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e86605c0a336c088b638da02135ea6f9f6753618'}",
            "dataset":"osv",
            "summary":"Division by 0 in inplace operations ### Impact\nAn attacker can cause a floating point exception by calling inplace operations with crafted arguments that would result in a division by 0:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.InplaceSub(x=[],i=[-99,-1,-1],v=[1,1,1])\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/inplace_ops.cc#L283) has a logic error: it should skip processing if `x` and `v` are empty but the code uses `||` instead of `&&`.\n\n### Patches\nWe have patched the issue in GitHub commit [e86605c0a336c088b638da02135ea6f9f6753618](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e86605c0a336c088b638da02135ea6f9f6753618).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e86605c0a336c088b638da02135ea6f9f6753618",
            "commit_sha":"e86605c0a336c088b638da02135ea6f9f6753618",
            "patch":"SINGLE",
            "chain_ord":"['e86605c0a336c088b638da02135ea6f9f6753618']",
            "before_first_fix_commit":"{'29e3d6b706a33780b1cb4863200ec7525ff035ce'}",
            "last_fix_commit":"e86605c0a336c088b638da02135ea6f9f6753618",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2021, 21:21:27",
            "message":"Fix FPE in inpace update ops.\n\nPiperOrigin-RevId: 388303197\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/inplace_ops.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e86605c0a336c088b638da02135ea6f9f6753618\/tensorflow%2Fcore%2Fkernels%2Finplace_ops.cc', 'patch': '@@ -225,7 +225,7 @@ class InplaceOpBase : public OpKernel {\\n \\n     Tensor y = x;  \/\/ This creates an alias intentionally.\\n     \/\/ Skip processing if tensors are empty.\\n-    if (x.NumElements() > 0 || v.NumElements() > 0) {\\n+    if (x.NumElements() > 0 && v.NumElements() > 0) {\\n       OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\\n     }\\n     ctx->set_output(0, y);'}}",
            "message_norm":"fix fpe in inpace update ops.\n\npiperorigin-revid: 388303197\nchange-id: ib48309b6213ffe53eba81004b00e889d653e4b83",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('388303197', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/inplace_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From e86605c0a336c088b638da02135ea6f9f6753618 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Mon, 2 Aug 2021 14:21:27 -0700\nSubject: [PATCH] Fix FPE in inpace update ops.\n\nPiperOrigin-RevId: 388303197\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83\n---\n tensorflow\/core\/kernels\/inplace_ops.cc | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/inplace_ops.cc b\/tensorflow\/core\/kernels\/inplace_ops.cc\nindex 2c0b201af3dd81..81027c7e17ee1a 100644\n--- a\/tensorflow\/core\/kernels\/inplace_ops.cc\n+++ b\/tensorflow\/core\/kernels\/inplace_ops.cc\n@@ -225,7 +225,7 @@ class InplaceOpBase : public OpKernel {\n \n     Tensor y = x;  \/\/ This creates an alias intentionally.\n     \/\/ Skip processing if tensors are empty.\n-    if (x.NumElements() > 0 || v.NumElements() > 0) {\n+    if (x.NumElements() > 0 && v.NumElements() > 0) {\n       OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\n     }\n     ctx->set_output(0, y);"
        },
        {
            "index":668,
            "vuln_id":"GHSA-3hw5-q855-g6cw",
            "cwe_id":"{'CWE-94'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/dojo\/dojox\/commit\/47d1b302b5b23d94e875b77b9b9a8c4f5622c9da'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in Dojox The Dojox jQuery wrapper `jqMix` mixin method is vulnerable to Prototype Pollution. \n\nAffected Area:\n```\n\/\/https:\/\/github.com\/dojo\/dojox\/blob\/master\/jq.js#L442\n\t\tvar tobj = {};\n\t\tfor(var x in props){\n\t\t\t\/\/ the \"tobj\" condition avoid copying properties in \"props\"\n\t\t\t\/\/ inherited from Object.prototype.  For example, if obj has a custom\n\t\t\t\/\/ toString() method, don't overwrite it with the toString() method\n\t\t\t\/\/ that props inherited from Object.prototype\n\t\t\tif((tobj[x] === undefined || tobj[x] != props[x]) && props[x] !== undefined && obj != props[x]){\n\t\t\t\tif(dojo.isObject(obj[x]) && dojo.isObject(props[x])){\n\t\t\t\t\tif(dojo.isArray(props[x])){\n\t\t\t\t\t\tobj[x] = props[x];\n\t\t\t\t\t}else{\n\t\t\t\t\t\tobj[x] = jqMix(obj[x], props[x]);\n\t\t\t\t\t}\n\t\t\t\t}else{\n\t\t\t\t\tobj[x] = props[x];\n\t\t\t\t}\n```",
            "published_date":"2020-03-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/dojo\/dojox",
            "commit_href":"https:\/\/github.com\/dojo\/dojox\/commit\/47d1b302b5b23d94e875b77b9b9a8c4f5622c9da",
            "commit_sha":"47d1b302b5b23d94e875b77b9b9a8c4f5622c9da",
            "patch":"SINGLE",
            "chain_ord":"['47d1b302b5b23d94e875b77b9b9a8c4f5622c9da']",
            "before_first_fix_commit":"{'5491effdb1b586f1a5f5b173460fe26e23abcfe6'}",
            "last_fix_commit":"47d1b302b5b23d94e875b77b9b9a8c4f5622c9da",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/10\/2020, 14:25:04",
            "message":"Merge pull request from GHSA-3hw5-q855-g6cw\n\nPrevent the special __proto__ property name from being mixed in to\nprevent polluting the prototoype of the object being mixed into in the\njqMix function in jq.js",
            "author":"Nick Nisi",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'jq.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/dojo\/dojox\/raw\/47d1b302b5b23d94e875b77b9b9a8c4f5622c9da\/jq.js', 'patch': \"@@ -455,7 +455,7 @@ dojo.query differences that cause some tests to fail:\\n \\t\\t\\t\/\/ inherited from Object.prototype.  For example, if obj has a custom\\n \\t\\t\\t\/\/ toString() method, don't overwrite it with the toString() method\\n \\t\\t\\t\/\/ that props inherited from Object.prototype\\n-\\t\\t\\tif((tobj[x] === undefined || tobj[x] != props[x]) && props[x] !== undefined && obj != props[x]){\\n+\\t\\t\\tif(x !== '__proto__ ' && ((tobj[x] === undefined || tobj[x] != props[x])) && props[x] !== undefined && obj != props[x]){\\n \\t\\t\\t\\tif(dojo.isObject(obj[x]) && dojo.isObject(props[x])){\\n \\t\\t\\t\\t\\tif(dojo.isArray(props[x])){\\n \\t\\t\\t\\t\\t\\tobj[x] = props[x];\"}}",
            "message_norm":"merge pull request from ghsa-3hw5-q855-g6cw\n\nprevent the special __proto__ property name from being mixed in to\nprevent polluting the prototoype of the object being mixed into in the\njqmix function in jq.js",
            "language":"en",
            "entities":"[('ghsa-3hw5-q855-g6cw', 'VULNID', 'GHSA'), ('prevent', 'ACTION', ''), ('prevent', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['jq.js'])",
            "num_files":1.0,
            "patch_content":"From 47d1b302b5b23d94e875b77b9b9a8c4f5622c9da Mon Sep 17 00:00:00 2001\nFrom: Nick Nisi <nick@nisi.org>\nDate: Tue, 10 Mar 2020 09:25:04 -0500\nSubject: [PATCH] Merge pull request from GHSA-3hw5-q855-g6cw\n\nPrevent the special __proto__ property name from being mixed in to\nprevent polluting the prototoype of the object being mixed into in the\njqMix function in jq.js\n---\n jq.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/jq.js b\/jq.js\nindex 81d3387c65..b0c2c21ad3 100644\n--- a\/jq.js\n+++ b\/jq.js\n@@ -455,7 +455,7 @@ dojo.query differences that cause some tests to fail:\n \t\t\t\/\/ inherited from Object.prototype.  For example, if obj has a custom\n \t\t\t\/\/ toString() method, don't overwrite it with the toString() method\n \t\t\t\/\/ that props inherited from Object.prototype\n-\t\t\tif((tobj[x] === undefined || tobj[x] != props[x]) && props[x] !== undefined && obj != props[x]){\n+\t\t\tif(x !== '__proto__ ' && ((tobj[x] === undefined || tobj[x] != props[x])) && props[x] !== undefined && obj != props[x]){\n \t\t\t\tif(dojo.isObject(obj[x]) && dojo.isObject(props[x])){\n \t\t\t\t\tif(dojo.isArray(props[x])){\n \t\t\t\t\t\tobj[x] = props[x];"
        },
        {
            "index":157,
            "vuln_id":"GHSA-qc36-q22q-cjw3",
            "cwe_id":"{'CWE-147'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/lettre\/lettre\/pull\/627\/commits\/93458d01fed0ec81c0e7b4e98e6f35961356fae2', 'https:\/\/github.com\/lettre\/lettre\/commit\/8bfc20506cc5e098fe6eb3d1cafe3bea791215ce'}",
            "dataset":"osv",
            "summary":"SMTP command injection in lettre ### Impact\n\nAffected versions of lettre allowed SMTP command injection through an attacker's controlled message body. The module for escaping lines starting with a period wouldn't catch a period that was placed after a double CRLF sequence, allowing the attacker to end the current message and write arbitrary SMTP commands after it.\n\n### Fix\n\nThe flaw is fixed by correctly handling consecutive CRLF sequences.\n\n### References\n\n* [RUSTSEC-2021-0069](https:\/\/rustsec.org\/advisories\/RUSTSEC-2021-0069.html)",
            "published_date":"2021-07-12",
            "chain_len":2,
            "project":"https:\/\/github.com\/lettre\/lettre",
            "commit_href":"https:\/\/github.com\/lettre\/lettre\/commit\/8bfc20506cc5e098fe6eb3d1cafe3bea791215ce",
            "commit_sha":"8bfc20506cc5e098fe6eb3d1cafe3bea791215ce",
            "patch":"MULTI",
            "chain_ord":"['93458d01fed0ec81c0e7b4e98e6f35961356fae2', '8bfc20506cc5e098fe6eb3d1cafe3bea791215ce']",
            "before_first_fix_commit":"{'d930c42d5069e344a9dfa84ebe4b60bf3b11ac64'}",
            "last_fix_commit":"8bfc20506cc5e098fe6eb3d1cafe3bea791215ce",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/22\/2021, 17:58:27",
            "message":"fix(transport-smtp): Fix transparency codec - 0.9.x (#628)\n\nCo-authored-by: Paolo Barbolini <paolo@paolo565.org>",
            "author":"Alexis Mousset",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 2, 'total': 13}",
            "files":"{'lettre\/src\/smtp\/client\/mod.rs': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/lettre\/lettre\/raw\/8bfc20506cc5e098fe6eb3d1cafe3bea791215ce\/lettre%2Fsrc%2Fsmtp%2Fclient%2Fmod.rs', 'patch': '@@ -51,7 +51,15 @@ impl ClientCodec {\\n                     match self.escape_count {\\n                         0 => self.escape_count = if *byte == b\\'\\\\r\\' { 1 } else { 0 },\\n                         1 => self.escape_count = if *byte == b\\'\\\\n\\' { 2 } else { 0 },\\n-                        2 => self.escape_count = if *byte == b\\'.\\' { 3 } else { 0 },\\n+                        2 => {\\n+                            self.escape_count = if *byte == b\\'.\\' {\\n+                                3\\n+                            } else if *byte == b\\'\\\\r\\' {\\n+                                1\\n+                            } else {\\n+                                0\\n+                            }\\n+                        }\\n                         _ => unreachable!(),\\n                     }\\n                     if self.escape_count == 3 {\\n@@ -286,6 +294,7 @@ mod test {\\n         let mut buf: Vec<u8> = vec![];\\n \\n         assert!(codec.encode(b\"test\\\\r\\\\n\", &mut buf).is_ok());\\n+        assert!(codec.encode(b\"test\\\\r\\\\n\\\\r\\\\n\", &mut buf).is_ok());\\n         assert!(codec.encode(b\".\\\\r\\\\n\", &mut buf).is_ok());\\n         assert!(codec.encode(b\"\\\\r\\\\ntest\", &mut buf).is_ok());\\n         assert!(codec.encode(b\"te\\\\r\\\\n.\\\\r\\\\nst\", &mut buf).is_ok());\\n@@ -296,7 +305,7 @@ mod test {\\n         assert!(codec.encode(b\"test\", &mut buf).is_ok());\\n         assert_eq!(\\n             String::from_utf8(buf).unwrap(),\\n-            \"test\\\\r\\\\n..\\\\r\\\\n\\\\r\\\\ntestte\\\\r\\\\n..\\\\r\\\\nsttesttest.test\\\\n.test\\\\ntest\"\\n+            \"test\\\\r\\\\ntest\\\\r\\\\n\\\\r\\\\n..\\\\r\\\\n\\\\r\\\\ntestte\\\\r\\\\n..\\\\r\\\\nsttesttest.test\\\\n.test\\\\ntest\"\\n         );\\n     }'}}",
            "message_norm":"fix(transport-smtp): fix transparency codec - 0.9.x (#628)\n\nco-authored-by: paolo barbolini <paolo@paolo565.org>",
            "language":"en",
            "entities":"[('fix(transport', 'ACTION', ''), ('fix', 'ACTION', ''), ('#628', 'ISSUE', ''), ('paolo@paolo565.org', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lettre\/src\/smtp\/client\/mod.rs'])",
            "num_files":1.0,
            "patch_content":"From 8bfc20506cc5e098fe6eb3d1cafe3bea791215ce Mon Sep 17 00:00:00 2001\nFrom: Alexis Mousset <contact@amousset.me>\nDate: Sat, 22 May 2021 19:58:27 +0200\nSubject: [PATCH] fix(transport-smtp): Fix transparency codec - 0.9.x (#628)\n\nCo-authored-by: Paolo Barbolini <paolo@paolo565.org>\n---\n lettre\/src\/smtp\/client\/mod.rs | 13 +++++++++++--\n 1 file changed, 11 insertions(+), 2 deletions(-)\n\ndiff --git a\/lettre\/src\/smtp\/client\/mod.rs b\/lettre\/src\/smtp\/client\/mod.rs\nindex e91c1a9cb..0c88c3f24 100644\n--- a\/lettre\/src\/smtp\/client\/mod.rs\n+++ b\/lettre\/src\/smtp\/client\/mod.rs\n@@ -51,7 +51,15 @@ impl ClientCodec {\n                     match self.escape_count {\n                         0 => self.escape_count = if *byte == b'\\r' { 1 } else { 0 },\n                         1 => self.escape_count = if *byte == b'\\n' { 2 } else { 0 },\n-                        2 => self.escape_count = if *byte == b'.' { 3 } else { 0 },\n+                        2 => {\n+                            self.escape_count = if *byte == b'.' {\n+                                3\n+                            } else if *byte == b'\\r' {\n+                                1\n+                            } else {\n+                                0\n+                            }\n+                        }\n                         _ => unreachable!(),\n                     }\n                     if self.escape_count == 3 {\n@@ -286,6 +294,7 @@ mod test {\n         let mut buf: Vec<u8> = vec![];\n \n         assert!(codec.encode(b\"test\\r\\n\", &mut buf).is_ok());\n+        assert!(codec.encode(b\"test\\r\\n\\r\\n\", &mut buf).is_ok());\n         assert!(codec.encode(b\".\\r\\n\", &mut buf).is_ok());\n         assert!(codec.encode(b\"\\r\\ntest\", &mut buf).is_ok());\n         assert!(codec.encode(b\"te\\r\\n.\\r\\nst\", &mut buf).is_ok());\n@@ -296,7 +305,7 @@ mod test {\n         assert!(codec.encode(b\"test\", &mut buf).is_ok());\n         assert_eq!(\n             String::from_utf8(buf).unwrap(),\n-            \"test\\r\\n..\\r\\n\\r\\ntestte\\r\\n..\\r\\nsttesttest.test\\n.test\\ntest\"\n+            \"test\\r\\ntest\\r\\n\\r\\n..\\r\\n\\r\\ntestte\\r\\n..\\r\\nsttesttest.test\\n.test\\ntest\"\n         );\n     }"
        },
        {
            "index":609,
            "vuln_id":"GHSA-36vm-xw34-x4pj",
            "cwe_id":"{'CWE-617'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1c56f53be0b722ca657cbc7df461ed676c8642a2'}",
            "dataset":"osv",
            "summary":"CHECK-fail in `tf.raw_ops.IRFFT` ### Impact\nAn attacker can cause a denial of service by exploiting a `CHECK`-failure coming from the implementation of `tf.raw_ops.IRFFT`:\n    \n```python\nimport tensorflow as tf\n\nvalues = [-10.0] * 130\nvalues[0] = -9.999999999999995\ninputs = tf.constant(values, shape=[10, 13], dtype=tf.float32)\ninputs = tf.cast(inputs, dtype=tf.complex64)\nfft_length = tf.constant([0], shape=[1], dtype=tf.int32)\n\ntf.raw_ops.IRFFT(input=inputs, fft_length=fft_length)\n``` \n    \nThe above example causes Eigen code to operate on an empty matrix. This triggers on an assertion and causes program termination.\n\n### Patches\nWe have patched the issue in GitHub commit [1c56f53be0b722ca657cbc7df461ed676c8642a2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1c56f53be0b722ca657cbc7df461ed676c8642a2).\n  \nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1c56f53be0b722ca657cbc7df461ed676c8642a2",
            "commit_sha":"1c56f53be0b722ca657cbc7df461ed676c8642a2",
            "patch":"SINGLE",
            "chain_ord":"['1c56f53be0b722ca657cbc7df461ed676c8642a2']",
            "before_first_fix_commit":"{'8926cbdbbff8b9975d63a41569d51c50a9806d9d'}",
            "last_fix_commit":"1c56f53be0b722ca657cbc7df461ed676c8642a2",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 00:11:46",
            "message":"Fix a check fail in Fast Fourier implementation\n\nPiperOrigin-RevId: 372026629\nChange-Id: Id05c3362aa575271bc3e06b16316c9037085fc11",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/fft_ops.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1c56f53be0b722ca657cbc7df461ed676c8642a2\/tensorflow%2Fcore%2Fkernels%2Ffft_ops.cc', 'patch': '@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\\n limitations under the License.\\n ==============================================================================*\/\\n \\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #define EIGEN_USE_THREADS\\n \\n \/\/ See docs in ..\/ops\/fft_ops.cc.\\n@@ -261,6 +262,9 @@ class FFTCPU : public FFTBase {\\n           i == FFTRank ? fft_shape[i - 1] \/ 2 + 1 : fft_shape[i - 1];\\n       full_fft_shape.AddDim(fft_shape[i - 1]);\\n     }\\n+    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,\\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\\n+                                        full_fft_shape.DebugString()));\\n \\n     Tensor temp;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),'}}",
            "message_norm":"fix a check fail in fast fourier implementation\n\npiperorigin-revid: 372026629\nchange-id: id05c3362aa575271bc3e06b16316c9037085fc11",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('372026629', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/fft_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 1c56f53be0b722ca657cbc7df461ed676c8642a2 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 4 May 2021 17:11:46 -0700\nSubject: [PATCH] Fix a check fail in Fast Fourier implementation\n\nPiperOrigin-RevId: 372026629\nChange-Id: Id05c3362aa575271bc3e06b16316c9037085fc11\n---\n tensorflow\/core\/kernels\/fft_ops.cc | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/fft_ops.cc b\/tensorflow\/core\/kernels\/fft_ops.cc\nindex c3235c1547ff0b..29ca0d2f546a08 100644\n--- a\/tensorflow\/core\/kernels\/fft_ops.cc\n+++ b\/tensorflow\/core\/kernels\/fft_ops.cc\n@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*\/\n \n+#include \"tensorflow\/core\/platform\/errors.h\"\n #define EIGEN_USE_THREADS\n \n \/\/ See docs in ..\/ops\/fft_ops.cc.\n@@ -261,6 +262,9 @@ class FFTCPU : public FFTBase {\n           i == FFTRank ? fft_shape[i - 1] \/ 2 + 1 : fft_shape[i - 1];\n       full_fft_shape.AddDim(fft_shape[i - 1]);\n     }\n+    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n+                                        full_fft_shape.DebugString()));\n \n     Tensor temp;\n     OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),"
        },
        {
            "index":211,
            "vuln_id":"GHSA-hhqj-cfjx-vj25",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/hakimel\/reveal.js\/commit\/32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2'}",
            "dataset":"osv",
            "summary":"Cross site scripting in reveal.js The onmessage event listener in \/plugin\/notes\/speaker-view.html does not check the origin of postMessage before adding the content to the webpage. The vulnerable code allows any origin to postMessage on the browser window and feeds attacker's input to parts using which attacker can execute arbitrary javascript code on victim's browser window hosting reveal.js",
            "published_date":"2022-03-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/hakimel\/reveal.js",
            "commit_href":"https:\/\/github.com\/hakimel\/reveal.js\/commit\/32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2",
            "commit_sha":"32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2",
            "patch":"SINGLE",
            "chain_ord":"['32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2']",
            "before_first_fix_commit":"{'e33c3c72f93d4c70ded3a90f5918f60082c96451'}",
            "last_fix_commit":"32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/26\/2022, 11:46:18",
            "message":"Fix DOM XSS",
            "author":"r0hanSH",
            "comments":"{'com_1': {'author': 'Zhila136', 'datetime': '06\/16\/2022, 03:13:17', 'body': '\u062e\u062f\u0645\u0627\u062a: \u0647\u0645\u0631\u0627\u0647 \u06a9\u0627\u0631\u062a \\r\\n\u0646\u0648\u0639 \u0633\u0631\u0648\u06cc\u0633: \u0647\u0645\u0631\u0627\u0647 \u06a9\u0627\u0631\u062a \u0633\u067e\u0647\\r\\n\u0634\u0645\u0627\u0631\u0647 \u06a9\u0627\u0631\u062a: 9243 3628 1010 5892\\r\\n\u0628\u0646\u0627\u0645: \u0627\u0628\u0631\u0627\u0647\u06cc\u0645 \u0645\u0631\u0627\u062f\u06cc \u0627\u0633\u062a\u06cc\u0627\u0631\\r\\n\u0645\u0648\u062c\u0648\u062f\u06cc \u06a9\u0627\u0631\u062a:\\r\\n147,000,000,000,000\u0631\u06cc\u0627\u0644\\r\\n\u0645\u0628\u0644\u063a \u0642\u0627\u0628\u0644 \u0628\u0631\u062f\u0627\u0634\u062a:\\r\\n147,000,000,000,000\u0631\u06cc\u0627\u0644\\r\\n\u06a9\u062f \u067e\u06cc\u06af\u06cc\u0631\u06cc:963877\\r\\n\u0634\u0645\u0627\u0631\u0647 \u0645\u0631\u062c\u0639:94382963877\\r\\n\u06a9\u062f\u0633\u062f\u0627\u062f:20060530\\r\\nCODETRANSFER:G0956DVY87\\r\\nCOMMON ACCOUNT:947022366\\r\\nISIN:XS2111948803\\r\\nCFI CODE:DBFUFB\\r\\n\\r\\n\u0648\u0636\u0639\u06cc\u062a \u06a9\u0627\u0631\u062a: \u0627\u06a9\u062a\u06cc\u0648 \u0648 \u0642\u0627\u0628\u0644 \u062f\u0633\u062a\u0631\u0633\u06cc\\r\\n            \u0633\u0631\u0648\u0631 \u0628\u0627\u0646\u06a9 \u0633\u067e\u0647'}, 'com_2': {'author': 'Zhila136', 'datetime': '06\/16\/2022, 03:13:31', 'body': '> \u062e\u062f\u0645\u0627\u062a: \u0647\u0645\u0631\u0627\u0647 \u06a9\u0627\u0631\u062a \u0646\u0648\u0639 \u0633\u0631\u0648\u06cc\u0633: \u0647\u0645\u0631\u0627\u0647 \u06a9\u0627\u0631\u062a \u0633\u067e\u0647 \u0634\u0645\u0627\u0631\u0647 \u06a9\u0627\u0631\u062a: 9243 3628 1010 5892 \u0628\u0646\u0627\u0645: \u0627\u0628\u0631\u0627\u0647\u06cc\u0645 \u0645\u0631\u0627\u062f\u06cc \u0627\u0633\u062a\u06cc\u0627\u0631 \u0645\u0648\u062c\u0648\u062f\u06cc \u06a9\u0627\u0631\u062a: 147,000,000,000,000\u0631\u06cc\u0627\u0644 \u0645\u0628\u0644\u063a \u0642\u0627\u0628\u0644 \u0628\u0631\u062f\u0627\u0634\u062a: 147,000,000,000,000\u0631\u06cc\u0627\u0644 \u06a9\u062f \u067e\u06cc\u06af\u06cc\u0631\u06cc:963877 \u0634\u0645\u0627\u0631\u0647 \u0645\u0631\u062c\u0639:94382963877 \u06a9\u062f\u0633\u062f\u0627\u062f:20060530 CODETRANSFER:G0956DVY87 COMMON ACCOUNT: 947022366 ISIN:XS2111948803 \u06a9\u062f CFI:DBFUFB\\r\\n> \\r\\n> \u06a9\u0627\u0631\u062a \u0648\u0636\u0639\u06cc\u062a: \u0627\u06a9\u062a\u06cc\u0648 \u0648 \u0642\u0627\u0628\u0644 \u062f\u0633\u062a\u0631\u0633\u06cc \u0633\u0631\u0648\u0631 \u0628\u0627\u0646\u06a9 \u0633\u067e\u0647'}, 'com_3': {'author': 'Zhila136', 'datetime': '06\/16\/2022, 03:13:50', 'body': '![\u06f2\u06f0\u06f2\u06f2\u06f0\u06f6\u06f1\u06f6_\u06f0\u06f7\u06f3\u06f7\u06f4\u06f0](https:\/\/user-images.githubusercontent.com\/97744031\/173983277-3cf21aef-9310-4a21-b681-3457044107ad.jpg)'}}",
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'plugin\/notes\/speaker-view.html': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hakimel\/reveal.js\/raw\/32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2\/plugin%2Fnotes%2Fspeaker-view.html', 'patch': '@@ -368,6 +368,10 @@ <h4 class=\"label\">Notes<\/h4>\\n \\n \\t\\t\\t\\twindow.addEventListener( \\'message\\', function( event ) {\\n \\n+\\t\\t\\t\\t\\tif (window.location.origin !== event.origin){\\n+\\t\\t\\t\\t\\t\\treturn;\\n+\\t\\t\\t\\t\\t}\\n+\\n \\t\\t\\t\\t\\tclearTimeout( connectionTimeout );\\n \\t\\t\\t\\t\\tconnectionStatus.style.display = \\'none\\';'}}",
            "message_norm":"fix dom xss",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['plugin\/notes\/speaker-view.html'])",
            "num_files":1.0,
            "patch_content":"From 32cdd3b1872ba8e2267c9e87ae216cb55f40f4d2 Mon Sep 17 00:00:00 2001\nFrom: r0hanSH <i.am.lone.survivor@protonmail.com>\nDate: Sat, 26 Feb 2022 17:16:18 +0530\nSubject: [PATCH] Fix DOM XSS\n\n---\n plugin\/notes\/speaker-view.html | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/plugin\/notes\/speaker-view.html b\/plugin\/notes\/speaker-view.html\nindex 3cf492db1a9..0c77390caea 100644\n--- a\/plugin\/notes\/speaker-view.html\n+++ b\/plugin\/notes\/speaker-view.html\n@@ -368,6 +368,10 @@ <h4 class=\"label\">Notes<\/h4>\n \n \t\t\t\twindow.addEventListener( 'message', function( event ) {\n \n+\t\t\t\t\tif (window.location.origin !== event.origin){\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\n \t\t\t\t\tclearTimeout( connectionTimeout );\n \t\t\t\t\tconnectionStatus.style.display = 'none';"
        },
        {
            "index":311,
            "vuln_id":"GHSA-j259-6c58-9m58",
            "cwe_id":"{'CWE-20'}",
            "score":9.3,
            "chain":"{'https:\/\/github.com\/loopbackio\/loopback-connector-postgresql\/commit\/d57406c6737692a3a106b58a35406290cddb23e5'}",
            "dataset":"osv",
            "summary":"loopback-connector-postgresql Vulnerable to Improper Sanitization of `contains` Filter Improper input validation on the `contains` LoopBack filter may allow for arbitrary SQL injection.\n\n### Impact\n\nWhen the extended filter property `contains` is permitted to be interpreted by the Postgres connector, it is possible to inject arbitrary SQL which may affect the confidentiality and integrity of data stored on the connected database.\n\nThis affects users who does any of the following:\n\n- Connect to the database via the DataSource with `allowExtendedProperties: true` setting OR\n- Uses the connector's CRUD methods directly OR\n- Uses the connector's other methods to interpret the LoopBack filter.\n\n### Patches\n\nPatch release `loopback-connector-postgresql@5.5.1` has been published of which resolves this issue.\n\n### Workarounds\n\nUsers who are unable to upgrade should do the following if applicable:\n\n- Remove `allowExtendedProperties: true` DataSource setting\n- Add `allowExtendedProperties: false` DataSource setting\n- When passing directly to the connector functions, manually sanitize the user input for the `contains` LoopBack filter beforehand.",
            "published_date":"2022-08-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/loopbackio\/loopback-connector-postgresql",
            "commit_href":"https:\/\/github.com\/loopbackio\/loopback-connector-postgresql\/commit\/d57406c6737692a3a106b58a35406290cddb23e5",
            "commit_sha":"d57406c6737692a3a106b58a35406290cddb23e5",
            "patch":"SINGLE",
            "chain_ord":"['d57406c6737692a3a106b58a35406290cddb23e5']",
            "before_first_fix_commit":"{'1a863f3df332f1732e8fec519f1d686561313a3e'}",
            "last_fix_commit":"d57406c6737692a3a106b58a35406290cddb23e5",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/04\/2022, 11:27:20",
            "message":"fix: improve filter sanitisation\n\nAdd sanitisation of user-input for `contains` LoopBack filter which may allow for arbitrary SQL injection.\n\nSigned-off-by: Rifa Achrinza <25147899+achrinza@users.noreply.github.com>",
            "author":"Rifa Achrinza",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 3, 'total': 7}",
            "files":"{'lib\/postgresql.js': {'additions': 4, 'deletions': 3, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/loopbackio\/loopback-connector-postgresql\/raw\/d57406c6737692a3a106b58a35406290cddb23e5\/lib%2Fpostgresql.js', 'patch': \"@@ -545,10 +545,11 @@ PostgreSQL.prototype.buildExpression = function(columnName, operator,\\n       return new ParameterizedSQL(columnName + regexOperator,\\n         [operatorValue.source]);\\n     case 'contains':\\n-      return new ParameterizedSQL(columnName + ' @> array[' + operatorValue.map((v) => `'${v}'`) + ']::'\\n-        + propertyDefinition.postgresql.dataType);\\n+      return new ParameterizedSQL(columnName + ' @> array[' + operatorValue.map(() => '?') + ']::'\\n+        + propertyDefinition.postgresql.dataType,\\n+        operatorValue);\\n     case 'match':\\n-      return new ParameterizedSQL(`to_tsvector(${columnName}) @@ to_tsquery('${operatorValue}')`);\\n+      return new ParameterizedSQL(`to_tsvector(${columnName}) @@ to_tsquery(?)`, [operatorValue]);\\n     default:\\n       \/\/ invoke the base implementation of `buildExpression`\\n       return this.invokeSuper('buildExpression', columnName, operator,\"}}",
            "message_norm":"fix: improve filter sanitisation\n\nadd sanitisation of user-input for `contains` loopback filter which may allow for arbitrary sql injection.\n\nsigned-off-by: rifa achrinza <25147899+achrinza@users.noreply.github.com>",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('improve', 'ACTION', ''), ('sanitisation', 'SECWORD', ''), ('add', 'ACTION', ''), ('sanitisation', 'SECWORD', ''), ('sql injection', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/postgresql.js'])",
            "num_files":1.0,
            "patch_content":"From d57406c6737692a3a106b58a35406290cddb23e5 Mon Sep 17 00:00:00 2001\nFrom: Rifa Achrinza <25147899+achrinza@users.noreply.github.com>\nDate: Thu, 4 Aug 2022 19:27:20 +0800\nSubject: [PATCH] fix: improve filter sanitisation\n\nAdd sanitisation of user-input for `contains` LoopBack filter which may allow for arbitrary SQL injection.\n\nSigned-off-by: Rifa Achrinza <25147899+achrinza@users.noreply.github.com>\n---\n lib\/postgresql.js | 7 ++++---\n 1 file changed, 4 insertions(+), 3 deletions(-)\n\ndiff --git a\/lib\/postgresql.js b\/lib\/postgresql.js\nindex 8ba9724e..8cb28a72 100644\n--- a\/lib\/postgresql.js\n+++ b\/lib\/postgresql.js\n@@ -545,10 +545,11 @@ PostgreSQL.prototype.buildExpression = function(columnName, operator,\n       return new ParameterizedSQL(columnName + regexOperator,\n         [operatorValue.source]);\n     case 'contains':\n-      return new ParameterizedSQL(columnName + ' @> array[' + operatorValue.map((v) => `'${v}'`) + ']::'\n-        + propertyDefinition.postgresql.dataType);\n+      return new ParameterizedSQL(columnName + ' @> array[' + operatorValue.map(() => '?') + ']::'\n+        + propertyDefinition.postgresql.dataType,\n+        operatorValue);\n     case 'match':\n-      return new ParameterizedSQL(`to_tsvector(${columnName}) @@ to_tsquery('${operatorValue}')`);\n+      return new ParameterizedSQL(`to_tsvector(${columnName}) @@ to_tsquery(?)`, [operatorValue]);\n     default:\n       \/\/ invoke the base implementation of `buildExpression`\n       return this.invokeSuper('buildExpression', columnName, operator,"
        },
        {
            "index":873,
            "vuln_id":"GHSA-h24f-9mm4-w336",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/omphalos\/crud-file-server\/commit\/4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting (XSS) - Stored in crud-file-server Versions of `crud-file-server` before 0.8.0 are vulnerable to stored cross-site scripting (XSS). This is due to insufficient santiziation of filenames when directory index is served by `crud-file-server`.\n\n\n## Recommendation\n\nUpdate to version 0.8.0 or later.",
            "published_date":"2018-07-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/omphalos\/crud-file-server",
            "commit_href":"https:\/\/github.com\/omphalos\/crud-file-server\/commit\/4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa",
            "commit_sha":"4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa",
            "patch":"SINGLE",
            "chain_ord":"['4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa']",
            "before_first_fix_commit":"{'0c45fc64f0c0aeb23fe515c95e29f6485803de65'}",
            "last_fix_commit":"4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/14\/2018, 23:29:21",
            "message":"Fix not sanitizing file names rendered in html",
            "author":"omphalos",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'crud-file-server.js': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/omphalos\/crud-file-server\/raw\/4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa\/crud-file-server.js', 'patch': '@@ -140,7 +140,9 @@ exports.handleRequest = function(vpath, path, req, res, readOnly, logHeadRequest\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvar name = results[f].name;\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvar normalized = url + \\'\/\\' + name;\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\twhile(normalized[0] == \\'\/\\') { normalized = normalized.slice(1, normalized.length); }\\r\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tres.write(\\'\\\\r\\\\n<p><a href=\"\/\\' + normalized + \\'\">\\' + name + \\'<\/a><\/p>\\');\\r\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tif(normalized.indexOf(\\'\"\\') >= 0) throw new Error(\\'unsupported file name\\')\\r\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname = name.replace(\/&\/g, \\'&amp;\\').replace(\/<\/g, \\'&lt;\\').replace(\/>\/g, \\'&gt;\\');\\r\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tres.write(\\'\\\\r\\\\n<p><a href=\"\/\\' + normalized + \\'\"><span>\\' + name + \\'<\/span><\/a><\/p>\\');\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t}\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tres.end(\\'\\\\r\\\\n<\/body><\/html>\\');\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t}'}}",
            "message_norm":"fix not sanitizing file names rendered in html",
            "language":"en",
            "entities":"[('sanitizing', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['crud-file-server.js'])",
            "num_files":1.0,
            "patch_content":"From 4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa Mon Sep 17 00:00:00 2001\nFrom: omphalos <omph.alos@yahoo.com>\nDate: Wed, 14 Feb 2018 17:29:21 -0600\nSubject: [PATCH] Fix not sanitizing file names rendered in html\n\n---\n crud-file-server.js | 4 +++-\n 1 file changed, 3 insertions(+), 1 deletion(-)\n\ndiff --git a\/crud-file-server.js b\/crud-file-server.js\nindex ad8ae00..c6147c2 100644\n--- a\/crud-file-server.js\n+++ b\/crud-file-server.js\n@@ -140,7 +140,9 @@ exports.handleRequest = function(vpath, path, req, res, readOnly, logHeadRequest\n \t\t\t\t\t\t\t\t\t\t\t\t\t\t\tvar name = results[f].name;\r\n \t\t\t\t\t\t\t\t\t\t\t\t\t\t\tvar normalized = url + '\/' + name;\r\n \t\t\t\t\t\t\t\t\t\t\t\t\t\t\twhile(normalized[0] == '\/') { normalized = normalized.slice(1, normalized.length); }\r\n-\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tres.write('\\r\\n<p><a href=\"\/' + normalized + '\">' + name + '<\/a><\/p>');\r\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif(normalized.indexOf('\"') >= 0) throw new Error('unsupported file name')\r\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tname = name.replace(\/&\/g, '&amp;').replace(\/<\/g, '&lt;').replace(\/>\/g, '&gt;');\r\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tres.write('\\r\\n<p><a href=\"\/' + normalized + '\"><span>' + name + '<\/span><\/a><\/p>');\r\n \t\t\t\t\t\t\t\t\t\t\t\t\t\t}\r\n \t\t\t\t\t\t\t\t\t\t\t\t\t\tres.end('\\r\\n<\/body><\/html>');\r\n \t\t\t\t\t\t\t\t\t\t\t\t\t}"
        },
        {
            "index":723,
            "vuln_id":"GHSA-4wpp-w5r4-7v5v",
            "cwe_id":"{'CWE-918'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/charmbracelet\/charm\/commit\/3c90668f955c7ce5ef721e4fc9faee7053232fd3'}",
            "dataset":"osv",
            "summary":"Server-Side Request Forgery in charm We've discovered a vulnerability in which attackers could forge HTTP requests to manipulate the `charm` data directory to access or delete anything on the server. This has been patched in https:\/\/github.com\/charmbracelet\/charm\/commit\/3c90668f955c7ce5ef721e4fc9faee7053232fd3 and is available in release [v0.12.1](https:\/\/github.com\/charmbracelet\/charm\/releases\/tag\/v0.12.1). We recommend that all users running self-hosted `charm` instances update immediately.\n\nThis vulnerability was found in-house and we haven't been notified of any potential exploiters.\n\n### Additional notes\n\n* Encrypted user data uploaded to the Charm server is safe as Charm servers cannot decrypt user data. This includes filenames, paths, and all key-value data.\n* Users running the official Charm [Docker images](https:\/\/github.com\/charmbracelet\/charm\/blob\/main\/docker.md) are at minimal risk because the exploit is limited to the containerized filesystem.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open a [discussion](https:\/\/github.com\/charmbracelet\/charm\/discussions)\n* Email us at [vt100@charm.sh](mailto:vt100@charm.sh)\n* Chat with us on [Slack](https:\/\/charm.sh\/slack)\n\n* * *\n\n<a href=\"https:\/\/charm.sh\/\"><img alt=\"the Charm logo\" src=\"https:\/\/stuff.charm.sh\/charm-badge.jpg\" width=\"400\"><\/a>\n\nCharm\u70ed\u7231\u5f00\u6e90 \u2022 Charm loves open source",
            "published_date":"2022-05-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/charmbracelet\/charm",
            "commit_href":"https:\/\/github.com\/charmbracelet\/charm\/commit\/3c90668f955c7ce5ef721e4fc9faee7053232fd3",
            "commit_sha":"3c90668f955c7ce5ef721e4fc9faee7053232fd3",
            "patch":"SINGLE",
            "chain_ord":"['3c90668f955c7ce5ef721e4fc9faee7053232fd3']",
            "before_first_fix_commit":"{'9c620ae07e7f7d7f3c0f6e52166b8b5f899d55d1'}",
            "last_fix_commit":"3c90668f955c7ce5ef721e4fc9faee7053232fd3",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2022, 01:23:14",
            "message":"fix: clean path before accessing file store",
            "author":"Christian Muehlhaeuser",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 3, 'total': 7}",
            "files":"{'server\/http.go': {'additions': 4, 'deletions': 3, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/charmbracelet\/charm\/raw\/3c90668f955c7ce5ef721e4fc9faee7053232fd3\/server%2Fhttp.go', 'patch': '@@ -10,6 +10,7 @@ import (\\n \\t\"io\/ioutil\"\\n \\t\"log\"\\n \\t\"net\/http\"\\n+\\t\"path\/filepath\"\\n \\t\"strconv\"\\n \\t\"strings\"\\n \\n@@ -279,7 +280,7 @@ func (s *HTTPServer) handlePostSeq(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handlePostFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\tms := r.URL.Query().Get(\"mode\")\\n \\tm, err := strconv.ParseUint(ms, 10, 32)\\n \\tif err != nil {\\n@@ -316,7 +317,7 @@ func (s *HTTPServer) handlePostFile(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handleGetFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\tf, err := s.cfg.FileStore.Get(u.CharmID, path)\\n \\tif errors.Is(err, fs.ErrNotExist) {\\n \\t\\ts.renderCustomError(w, \"file not found\", http.StatusNotFound)\\n@@ -353,7 +354,7 @@ func (s *HTTPServer) handleGetFile(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handleDeleteFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\terr := s.cfg.FileStore.Delete(u.CharmID, path)\\n \\tif err != nil {\\n \\t\\tlog.Printf(\"cannot delete file: %s\", err)'}}",
            "message_norm":"fix: clean path before accessing file store",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/http.go'])",
            "num_files":1.0,
            "patch_content":"From 3c90668f955c7ce5ef721e4fc9faee7053232fd3 Mon Sep 17 00:00:00 2001\nFrom: Christian Muehlhaeuser <muesli@gmail.com>\nDate: Fri, 6 May 2022 03:23:14 +0200\nSubject: [PATCH] fix: clean path before accessing file store\n\n---\n server\/http.go | 7 ++++---\n 1 file changed, 4 insertions(+), 3 deletions(-)\n\ndiff --git a\/server\/http.go b\/server\/http.go\nindex ea6e0e53..73ae4590 100644\n--- a\/server\/http.go\n+++ b\/server\/http.go\n@@ -10,6 +10,7 @@ import (\n \t\"io\/ioutil\"\n \t\"log\"\n \t\"net\/http\"\n+\t\"path\/filepath\"\n \t\"strconv\"\n \t\"strings\"\n \n@@ -279,7 +280,7 @@ func (s *HTTPServer) handlePostSeq(w http.ResponseWriter, r *http.Request) {\n \n func (s *HTTPServer) handlePostFile(w http.ResponseWriter, r *http.Request) {\n \tu := s.charmUserFromRequest(w, r)\n-\tpath := pattern.Path(r.Context())\n+\tpath := filepath.Clean(pattern.Path(r.Context()))\n \tms := r.URL.Query().Get(\"mode\")\n \tm, err := strconv.ParseUint(ms, 10, 32)\n \tif err != nil {\n@@ -316,7 +317,7 @@ func (s *HTTPServer) handlePostFile(w http.ResponseWriter, r *http.Request) {\n \n func (s *HTTPServer) handleGetFile(w http.ResponseWriter, r *http.Request) {\n \tu := s.charmUserFromRequest(w, r)\n-\tpath := pattern.Path(r.Context())\n+\tpath := filepath.Clean(pattern.Path(r.Context()))\n \tf, err := s.cfg.FileStore.Get(u.CharmID, path)\n \tif errors.Is(err, fs.ErrNotExist) {\n \t\ts.renderCustomError(w, \"file not found\", http.StatusNotFound)\n@@ -353,7 +354,7 @@ func (s *HTTPServer) handleGetFile(w http.ResponseWriter, r *http.Request) {\n \n func (s *HTTPServer) handleDeleteFile(w http.ResponseWriter, r *http.Request) {\n \tu := s.charmUserFromRequest(w, r)\n-\tpath := pattern.Path(r.Context())\n+\tpath := filepath.Clean(pattern.Path(r.Context()))\n \terr := s.cfg.FileStore.Delete(u.CharmID, path)\n \tif err != nil {\n \t\tlog.Printf(\"cannot delete file: %s\", err)"
        },
        {
            "index":468,
            "vuln_id":"GHSA-jpj5-hg26-6jgc",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/Xhofe\/alist\/commit\/6af17e2509a400979420f613fd7f2f9721fdcd6e'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Alist Alist versions 2.0.10 through 2.1.0 were discovered to contain a cross-site scripting (XSS) vulnerability via \/i\/:data\/ipa.plist. This issue was fixed in version 2.1.1.",
            "published_date":"2022-03-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/Xhofe\/alist",
            "commit_href":"https:\/\/github.com\/Xhofe\/alist\/commit\/6af17e2509a400979420f613fd7f2f9721fdcd6e",
            "commit_sha":"6af17e2509a400979420f613fd7f2f9721fdcd6e",
            "patch":"SINGLE",
            "chain_ord":"['6af17e2509a400979420f613fd7f2f9721fdcd6e']",
            "before_first_fix_commit":"{'5193b2aa7df73231ebf68e90b3295f2a5c0916a2'}",
            "last_fix_commit":"6af17e2509a400979420f613fd7f2f9721fdcd6e",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/01\/2022, 12:09:25",
            "message":":lock: fix #645 xss vulnerability",
            "author":"Xhofe",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 0, 'total': 9}",
            "files":"{'server\/controllers\/other.go': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/alist-org\/alist\/raw\/6af17e2509a400979420f613fd7f2f9721fdcd6e\/server%2Fcontrollers%2Fother.go', 'patch': '@@ -7,6 +7,7 @@ import (\\n \\t\"github.com\/Xhofe\/alist\/server\/common\"\\n \\t\"github.com\/Xhofe\/alist\/utils\"\\n \\t\"github.com\/gin-gonic\/gin\"\\n+\\t\"net\/url\"\\n \\t\"strings\"\\n )\\n \\n@@ -24,11 +25,19 @@ func Plist(c *gin.Context) {\\n \\t\\treturn\\n \\t}\\n \\tu := string(bytes)\\n+\\tuUrl, err := url.Parse(u)\\n+\\tif err != nil {\\n+\\t\\tcommon.ErrorResp(c, err, 500)\\n+\\t\\treturn\\n+\\t}\\n \\tname := utils.Base(u)\\n+\\tu = uUrl.String()\\n \\tipaIndex := strings.Index(name, \".ipa\")\\n \\tif ipaIndex != -1 {\\n \\t\\tname = name[:ipaIndex]\\n \\t}\\n+\\tname = strings.ReplaceAll(name, \"<\", \"[\")\\n+\\tname = strings.ReplaceAll(name, \">\", \"]\")\\n \\tplist := fmt.Sprintf(`<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE plist PUBLIC \"-\/\/Apple\/\/DTD PLIST 1.0\/\/EN\" \"http:\/\/www.apple.com\/DTDs\/PropertyList-1.0.dtd\">\\n <plist version=\"1.0\">\\n     <dict>'}}",
            "message_norm":":lock: fix #645 xss vulnerability",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('#645', 'ISSUE', ''), ('xss', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/controllers\/other.go'])",
            "num_files":1.0,
            "patch_content":"From 6af17e2509a400979420f613fd7f2f9721fdcd6e Mon Sep 17 00:00:00 2001\nFrom: Xhofe <i@nn.ci>\nDate: Tue, 1 Mar 2022 20:09:25 +0800\nSubject: [PATCH] :lock: fix #645 xss vulnerability\n\n---\n server\/controllers\/other.go | 9 +++++++++\n 1 file changed, 9 insertions(+)\n\ndiff --git a\/server\/controllers\/other.go b\/server\/controllers\/other.go\nindex 6a4968f3997..79e36840f04 100644\n--- a\/server\/controllers\/other.go\n+++ b\/server\/controllers\/other.go\n@@ -7,6 +7,7 @@ import (\n \t\"github.com\/Xhofe\/alist\/server\/common\"\n \t\"github.com\/Xhofe\/alist\/utils\"\n \t\"github.com\/gin-gonic\/gin\"\n+\t\"net\/url\"\n \t\"strings\"\n )\n \n@@ -24,11 +25,19 @@ func Plist(c *gin.Context) {\n \t\treturn\n \t}\n \tu := string(bytes)\n+\tuUrl, err := url.Parse(u)\n+\tif err != nil {\n+\t\tcommon.ErrorResp(c, err, 500)\n+\t\treturn\n+\t}\n \tname := utils.Base(u)\n+\tu = uUrl.String()\n \tipaIndex := strings.Index(name, \".ipa\")\n \tif ipaIndex != -1 {\n \t\tname = name[:ipaIndex]\n \t}\n+\tname = strings.ReplaceAll(name, \"<\", \"[\")\n+\tname = strings.ReplaceAll(name, \">\", \"]\")\n \tplist := fmt.Sprintf(`<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE plist PUBLIC \"-\/\/Apple\/\/DTD PLIST 1.0\/\/EN\" \"http:\/\/www.apple.com\/DTDs\/PropertyList-1.0.dtd\">\n <plist version=\"1.0\">\n     <dict>"
        },
        {
            "index":189,
            "vuln_id":"GHSA-j86v-p27c-73fm",
            "cwe_id":"{'CWE-824'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f09caa532b6e1ac8d2aa61b7832c78c5b79300c6'}",
            "dataset":"osv",
            "summary":"Unitialized access in `EinsumHelper::ParseEquation` ### Impact\nDuring execution, [`EinsumHelper::ParseEquation()`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e0b6e58c328059829c3eb968136f17aa72b6c876\/tensorflow\/core\/kernels\/linalg\/einsum_op_impl.h#L126-L181) is supposed to set the flags in `input_has_ellipsis` vector and `*output_has_ellipsis` boolean to indicate whether there is ellipsis in the corresponding inputs and output.\n\nHowever, the code only changes these flags to `true` and never assigns `false`.\n\n```cc\nfor (int i = 0; i < num_inputs; ++i) {\n  input_label_counts->at(i).resize(num_labels);\n  for (const int label : input_labels->at(i)) {\n    if (label != kEllipsisLabel)\n      input_label_counts->at(i)[label] += 1;\n    else\n      input_has_ellipsis->at(i) = true;\n  }\n}\noutput_label_counts->resize(num_labels);\nfor (const int label : *output_labels) {\n  if (label != kEllipsisLabel)\n    output_label_counts->at(label) += 1;\n  else\n    *output_has_ellipsis = true;\n}\n```\n\nThis results in unitialized variable access if callers assume that `EinsumHelper::ParseEquation()` always sets these flags.\n\n\n### Patches\nWe have patched the issue in GitHub commit [f09caa532b6e1ac8d2aa61b7832c78c5b79300c6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f09caa532b6e1ac8d2aa61b7832c78c5b79300c6).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2021-11-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
            "commit_sha":"f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
            "patch":"SINGLE",
            "chain_ord":"['f09caa532b6e1ac8d2aa61b7832c78c5b79300c6']",
            "before_first_fix_commit":"{'a81f78d35ecabae6ba61c1a65279bcb5ff9c7d95'}",
            "last_fix_commit":"f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/19\/2021, 16:05:04",
            "message":"Fix EinsumHelper::ParseEquation to avoid uninitialized accesses.\n\nEinsumHelper::ParseEquation is supposed to return true or false in\ninput_has_ellipsis and output_has_ellipsis to indicate whether there is\nellipsis in the inputs and output. Previously, when there is no ellipsis in the\ninputs or output, the routine doesn't assign false to the variables. This\nchange initializes the two variables with false to fix the problem.\nPiperOrigin-RevId: 391772004\nChange-Id: I17b6c88aadef4131470378e48cced054bf252e86",
            "author":"Bixia Zheng",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/linalg\/einsum_op_impl.h': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f09caa532b6e1ac8d2aa61b7832c78c5b79300c6\/tensorflow%2Fcore%2Fkernels%2Flinalg%2Feinsum_op_impl.h', 'patch': '@@ -153,6 +153,7 @@ struct EinsumHelper {\\n     input_has_ellipsis->resize(num_inputs);\\n     for (int i = 0; i < num_inputs; ++i) {\\n       input_label_counts->at(i).resize(num_labels);\\n+      input_has_ellipsis->at(i) = false;\\n       for (const int label : input_labels->at(i)) {\\n         if (label != kEllipsisLabel)\\n           input_label_counts->at(i)[label] += 1;\\n@@ -161,6 +162,7 @@ struct EinsumHelper {\\n       }\\n     }\\n     output_label_counts->resize(num_labels);\\n+    *output_has_ellipsis = false;\\n     for (const int label : *output_labels) {\\n       if (label != kEllipsisLabel)\\n         output_label_counts->at(label) += 1;'}}",
            "message_norm":"fix einsumhelper::parseequation to avoid uninitialized accesses.\n\neinsumhelper::parseequation is supposed to return true or false in\ninput_has_ellipsis and output_has_ellipsis to indicate whether there is\nellipsis in the inputs and output. previously, when there is no ellipsis in the\ninputs or output, the routine doesn't assign false to the variables. this\nchange initializes the two variables with false to fix the problem.\npiperorigin-revid: 391772004\nchange-id: i17b6c88aadef4131470378e48cced054bf252e86",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('uninitialized', 'SECWORD', ''), ('initializes', 'SECWORD', ''), ('fix', 'ACTION', ''), ('problem', 'FLAW', ''), ('391772004', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/linalg\/einsum_op_impl.h'])",
            "num_files":1.0,
            "patch_content":"From f09caa532b6e1ac8d2aa61b7832c78c5b79300c6 Mon Sep 17 00:00:00 2001\nFrom: Bixia Zheng <bixia@google.com>\nDate: Thu, 19 Aug 2021 09:05:04 -0700\nSubject: [PATCH] Fix EinsumHelper::ParseEquation to avoid uninitialized\n accesses.\n\nEinsumHelper::ParseEquation is supposed to return true or false in\ninput_has_ellipsis and output_has_ellipsis to indicate whether there is\nellipsis in the inputs and output. Previously, when there is no ellipsis in the\ninputs or output, the routine doesn't assign false to the variables. This\nchange initializes the two variables with false to fix the problem.\nPiperOrigin-RevId: 391772004\nChange-Id: I17b6c88aadef4131470378e48cced054bf252e86\n---\n tensorflow\/core\/kernels\/linalg\/einsum_op_impl.h | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/linalg\/einsum_op_impl.h b\/tensorflow\/core\/kernels\/linalg\/einsum_op_impl.h\nindex 5c41e38954d626..6f64334555131c 100644\n--- a\/tensorflow\/core\/kernels\/linalg\/einsum_op_impl.h\n+++ b\/tensorflow\/core\/kernels\/linalg\/einsum_op_impl.h\n@@ -153,6 +153,7 @@ struct EinsumHelper {\n     input_has_ellipsis->resize(num_inputs);\n     for (int i = 0; i < num_inputs; ++i) {\n       input_label_counts->at(i).resize(num_labels);\n+      input_has_ellipsis->at(i) = false;\n       for (const int label : input_labels->at(i)) {\n         if (label != kEllipsisLabel)\n           input_label_counts->at(i)[label] += 1;\n@@ -161,6 +162,7 @@ struct EinsumHelper {\n       }\n     }\n     output_label_counts->resize(num_labels);\n+    *output_has_ellipsis = false;\n     for (const int label : *output_labels) {\n       if (label != kEllipsisLabel)\n         output_label_counts->at(label) += 1;"
        },
        {
            "index":454,
            "vuln_id":"GHSA-4fg4-p75j-w5xj",
            "cwe_id":"{'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b'}",
            "dataset":"osv",
            "summary":"Heap out of bounds in `QuantizedBatchNormWithGlobalNormalization` ### Impact\nAn attacker can cause a segfault and denial of service via accessing data outside of bounds in `tf.raw_ops.QuantizedBatchNormWithGlobalNormalization`:\n\n```python\nimport tensorflow as tf\n\nt = tf.constant([1], shape=[1, 1, 1, 1], dtype=tf.quint8)\nt_min = tf.constant([], shape=[0], dtype=tf.float32)\nt_max = tf.constant([], shape=[0], dtype=tf.float32)\nm = tf.constant([1], shape=[1], dtype=tf.quint8)\nm_min = tf.constant([], shape=[0], dtype=tf.float32)\nm_max = tf.constant([], shape=[0], dtype=tf.float32)\nv = tf.constant([1], shape=[1], dtype=tf.quint8)\nv_min = tf.constant([], shape=[0], dtype=tf.float32)\nv_max = tf.constant([], shape=[0], dtype=tf.float32)\nbeta = tf.constant([1], shape=[1], dtype=tf.quint8)\nbeta_min = tf.constant([], shape=[0], dtype=tf.float32)\nbeta_max = tf.constant([], shape=[0], dtype=tf.float32)\ngamma = tf.constant([1], shape=[1], dtype=tf.quint8)\ngamma_min = tf.constant([], shape=[0], dtype=tf.float32)\ngamma_max = tf.constant([], shape=[0], dtype=tf.float32) \n\ntf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n  t=t, t_min=t_min, t_max=t_max, m=m, m_min=m_min, m_max=m_max,\n  v=v, v_min=v_min, v_max=v_max, beta=beta, beta_min=beta_min,\n  beta_max=beta_max, gamma=gamma, gamma_min=gamma_min,\n  gamma_max=gamma_max, out_type=tf.qint32,\n  variance_epsilon=0.1, scale_after_normalization=True)\n```                         \n                            \nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/55a97caa9e99c7f37a0bbbeb414dc55553d3ae7f\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc#L176-L189) assumes the inputs are not empty: \n  \n```cc\nconst float input_min = context->input(1).flat<float>()(0);\nconst float input_max = context->input(2).flat<float>()(0);\n...\nconst float mean_min = context->input(4).flat<float>()(0);\nconst float mean_max = context->input(5).flat<float>()(0);\n...\nconst float var_min = context->input(7).flat<float>()(0);\nconst float var_max = context->input(8).flat<float>()(0);\n...\nconst float beta_min = context->input(10).flat<float>()(0);\nconst float beta_max = context->input(11).flat<float>()(0);\n...\nconst float gamma_min = context->input(13).flat<float>()(0);\nconst float gamma_max = context->input(14).flat<float>()(0);\n```\n\nIf any of these inputs is empty, `.flat<T>()` is an empty buffer, so accessing the element at index 0 is accessing data outside of bounds.\n\n### Patches\nWe have patched the issue in GitHub commit [d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
            "commit_sha":"d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
            "patch":"SINGLE",
            "chain_ord":"['d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b']",
            "before_first_fix_commit":"{'55a97caa9e99c7f37a0bbbeb414dc55553d3ae7f'}",
            "last_fix_commit":"d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2021, 18:40:06",
            "message":"Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 67, 'deletions': 10, 'total': 77}",
            "files":"{'tensorflow\/core\/kernels\/quantized_batch_norm_op.cc': {'additions': 67, 'deletions': 10, 'changes': 77, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b\/tensorflow%2Fcore%2Fkernels%2Fquantized_batch_norm_op.cc', 'patch': '@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* context) override {\\n     const Tensor& input = context->input(0);\\n-    const float input_min = context->input(1).flat<float>()(0);\\n-    const float input_max = context->input(2).flat<float>()(0);\\n+    const auto& input_min_tensor = context->input(1);\\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\\n+    const float input_min = input_min_tensor.flat<float>()(0);\\n+    const auto& input_max_tensor = context->input(2);\\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\\n+    const float input_max = input_max_tensor.flat<float>()(0);\\n     const Tensor& mean = context->input(3);\\n-    const float mean_min = context->input(4).flat<float>()(0);\\n-    const float mean_max = context->input(5).flat<float>()(0);\\n+    const auto& mean_min_tensor = context->input(4);\\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\\n+    const auto& mean_max_tensor = context->input(5);\\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\\n     const Tensor& var = context->input(6);\\n-    const float var_min = context->input(7).flat<float>()(0);\\n-    const float var_max = context->input(8).flat<float>()(0);\\n+    const auto& var_min_tensor = context->input(7);\\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\\n+    const float var_min = var_min_tensor.flat<float>()(0);\\n+    const auto& var_max_tensor = context->input(8);\\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\\n+    const float var_max = var_max_tensor.flat<float>()(0);\\n     const Tensor& beta = context->input(9);\\n-    const float beta_min = context->input(10).flat<float>()(0);\\n-    const float beta_max = context->input(11).flat<float>()(0);\\n+    const auto& beta_min_tensor = context->input(10);\\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\\n+    const auto& beta_max_tensor = context->input(11);\\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\\n     const Tensor& gamma = context->input(12);\\n-    const float gamma_min = context->input(13).flat<float>()(0);\\n-    const float gamma_max = context->input(14).flat<float>()(0);\\n+    const auto& gamma_min_tensor = context->input(13);\\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\\n+    const auto& gamma_max_tensor = context->input(14);\\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\\n \\n     OP_REQUIRES(context, input.dims() == 4,\\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\\n     OP_REQUIRES(context, gamma.dims() == 1,\\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\\n                                         gamma.shape().DebugString()));\\n+    OP_REQUIRES(context, mean.NumElements() > 1,\\n+                errors::InvalidArgument(\"Must have at least a mean value\",\\n+                                        gamma.shape().DebugString()));\\n+    OP_REQUIRES(context, mean.NumElements() > 1,\\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\\n+    const auto last_dim = input.shape().dims() - 1;\\n+    OP_REQUIRES(context,\\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\\n+                errors::InvalidArgument(\"Must provide as many means as the \"\\n+                                        \"last dimension of the input tensor: \",\\n+                                        mean.shape().DebugString(), \" vs. \",\\n+                                        input.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and variance tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and beta tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and gamma tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(context,'}}",
            "message_norm":"add missing validation in `quantizedbatchnormwithglobalnormalization`\n\npiperorigin-revid: 370123451\nchange-id: id234d6dab1ec21230bb8e503dba30f899af87f33",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('370123451', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_batch_norm_op.cc'])",
            "num_files":1.0,
            "patch_content":"From d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 23 Apr 2021 11:40:06 -0700\nSubject: [PATCH] Add missing validation in\n `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33\n---\n ...\/core\/kernels\/quantized_batch_norm_op.cc   | 77 ++++++++++++++++---\n 1 file changed, 67 insertions(+), 10 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc b\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc\nindex b03da7ad17fab4..6dfe07f97a4007 100644\n--- a\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc\n@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float input_min = context->input(1).flat<float>()(0);\n-    const float input_max = context->input(2).flat<float>()(0);\n+    const auto& input_min_tensor = context->input(1);\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\n+    const float input_min = input_min_tensor.flat<float>()(0);\n+    const auto& input_max_tensor = context->input(2);\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\n+    const float input_max = input_max_tensor.flat<float>()(0);\n     const Tensor& mean = context->input(3);\n-    const float mean_min = context->input(4).flat<float>()(0);\n-    const float mean_max = context->input(5).flat<float>()(0);\n+    const auto& mean_min_tensor = context->input(4);\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\n+    const auto& mean_max_tensor = context->input(5);\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\n     const Tensor& var = context->input(6);\n-    const float var_min = context->input(7).flat<float>()(0);\n-    const float var_max = context->input(8).flat<float>()(0);\n+    const auto& var_min_tensor = context->input(7);\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\n+    const float var_min = var_min_tensor.flat<float>()(0);\n+    const auto& var_max_tensor = context->input(8);\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\n+    const float var_max = var_max_tensor.flat<float>()(0);\n     const Tensor& beta = context->input(9);\n-    const float beta_min = context->input(10).flat<float>()(0);\n-    const float beta_max = context->input(11).flat<float>()(0);\n+    const auto& beta_min_tensor = context->input(10);\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\n+    const auto& beta_max_tensor = context->input(11);\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\n     const Tensor& gamma = context->input(12);\n-    const float gamma_min = context->input(13).flat<float>()(0);\n-    const float gamma_max = context->input(14).flat<float>()(0);\n+    const auto& gamma_min_tensor = context->input(13);\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n+    const auto& gamma_max_tensor = context->input(14);\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n \n     OP_REQUIRES(context, input.dims() == 4,\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\n     OP_REQUIRES(context, gamma.dims() == 1,\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                         gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\",\n+                                        gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\n+    const auto last_dim = input.shape().dims() - 1;\n+    OP_REQUIRES(context,\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n+                errors::InvalidArgument(\"Must provide as many means as the \"\n+                                        \"last dimension of the input tensor: \",\n+                                        mean.shape().DebugString(), \" vs. \",\n+                                        input.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and variance tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and beta tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and gamma tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,"
        },
        {
            "index":409,
            "vuln_id":"GHSA-66gw-5xpf-gfp5",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/ipython\/ipython\/commit\/c2078a53543ed502efd968649fee1125e0eb549c', 'https:\/\/github.com\/ipython\/ipython\/commit\/7222bd53ad089a65fd610fab4626f9d0ab47dfce'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Input During Web Page Generation in IPython Cross-site scripting (XSS) vulnerability in IPython before 3.2 allows remote attackers to inject arbitrary web script or HTML via vectors involving JSON error messages and the \/api\/notebooks path.",
            "published_date":"2022-05-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/ipython\/ipython",
            "commit_href":"https:\/\/github.com\/ipython\/ipython\/commit\/c2078a53543ed502efd968649fee1125e0eb549c",
            "commit_sha":"c2078a53543ed502efd968649fee1125e0eb549c",
            "patch":"MULTI",
            "chain_ord":"['7222bd53ad089a65fd610fab4626f9d0ab47dfce', 'c2078a53543ed502efd968649fee1125e0eb549c']",
            "before_first_fix_commit":"{'64966ea2ae0d44a9c059efcb299db66cbc66ef04'}",
            "last_fix_commit":"c2078a53543ed502efd968649fee1125e0eb549c",
            "chain_ord_pos":2.0,
            "commit_datetime":"06\/22\/2015, 04:12:34",
            "message":"Set content type in json_error to application\/json",
            "author":"Kyle Kelley",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
            "files":"{'IPython\/html\/base\/handlers.py': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ipython\/ipython\/raw\/c2078a53543ed502efd968649fee1125e0eb549c\/IPython%2Fhtml%2Fbase%2Fhandlers.py', 'patch': '@@ -339,6 +339,7 @@ def wrapper(self, *args, **kwargs):\\n             message = e.log_message\\n             self.log.warn(message)\\n             self.set_status(e.status_code)\\n+            self.set_header(\\'Content-Type\\', \\'application\/json\\')\\n             self.finish(json.dumps(dict(message=message)))\\n         except Exception:\\n             self.log.error(\"Unhandled error in API request\", exc_info=True)\\n@@ -348,6 +349,7 @@ def wrapper(self, *args, **kwargs):\\n             self.set_status(status)\\n             tb_text = \\'\\'.join(traceback.format_exception(t, value, tb))\\n             reply = dict(message=message, traceback=tb_text)\\n+            self.set_header(\\'Content-Type\\', \\'application\/json\\')\\n             self.finish(json.dumps(reply))\\n         else:\\n             return result'}}",
            "message_norm":"set content type in json_error to application\/json",
            "language":"en",
            "entities":"[('json_error', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['IPython\/html\/base\/handlers.py'])",
            "num_files":1.0,
            "patch_content":"From c2078a53543ed502efd968649fee1125e0eb549c Mon Sep 17 00:00:00 2001\nFrom: Kyle Kelley <rgbkrk@gmail.com>\nDate: Sun, 21 Jun 2015 23:12:34 -0500\nSubject: [PATCH] Set content type in json_error to application\/json\n\n---\n IPython\/html\/base\/handlers.py | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/IPython\/html\/base\/handlers.py b\/IPython\/html\/base\/handlers.py\nindex 0eb7ac71992..40a9a630460 100644\n--- a\/IPython\/html\/base\/handlers.py\n+++ b\/IPython\/html\/base\/handlers.py\n@@ -339,6 +339,7 @@ def wrapper(self, *args, **kwargs):\n             message = e.log_message\n             self.log.warn(message)\n             self.set_status(e.status_code)\n+            self.set_header('Content-Type', 'application\/json')\n             self.finish(json.dumps(dict(message=message)))\n         except Exception:\n             self.log.error(\"Unhandled error in API request\", exc_info=True)\n@@ -348,6 +349,7 @@ def wrapper(self, *args, **kwargs):\n             self.set_status(status)\n             tb_text = ''.join(traceback.format_exception(t, value, tb))\n             reply = dict(message=message, traceback=tb_text)\n+            self.set_header('Content-Type', 'application\/json')\n             self.finish(json.dumps(reply))\n         else:\n             return result"
        },
        {
            "index":833,
            "vuln_id":"GHSA-95xm-g58g-3p88",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4923de56ec94fff7770df259ab7f2288a74feb41'}",
            "dataset":"osv",
            "summary":"Integer division by 0 in sparse reshaping ### Impact\nThe implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.SparseReshape(\n  input_indices = np.ones((1,3)),\n  input_shape = np.array([1,1,0]),\n  new_shape = np.array([1,0]))\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements.\n\nThe [reshape functor](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0.\n  \n### Patches\nWe have patched the issue in GitHub commit [4923de56ec94fff7770df259ab7f2288a74feb41](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4923de56ec94fff7770df259ab7f2288a74feb41).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4923de56ec94fff7770df259ab7f2288a74feb41",
            "commit_sha":"4923de56ec94fff7770df259ab7f2288a74feb41",
            "patch":"SINGLE",
            "chain_ord":"['4923de56ec94fff7770df259ab7f2288a74feb41']",
            "before_first_fix_commit":"{'062534a0e7af9a49e96bc5797851be0e57cad1d6'}",
            "last_fix_commit":"4923de56ec94fff7770df259ab7f2288a74feb41",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2021, 20:52:28",
            "message":"Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232a",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/reshape_util.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/4923de56ec94fff7770df259ab7f2288a74feb41\/tensorflow%2Fcore%2Fkernels%2Freshape_util.cc', 'patch': '@@ -174,6 +174,12 @@ void ReshapeSparseTensor(OpKernelContext *context,\\n                                           TensorShape({nnz, output_rank}),\\n                                           &result_indices));\\n   if (nnz > 0) {\\n+    OP_REQUIRES(\\n+        context, dense_size > 0 && product > 0,\\n+        errors::InvalidArgument(\\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\\n+            input_shape.DebugString(), \") or output shape (\",\\n+            output_shape.DebugString(), \") is empty\"));\\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\\n                                 context, input_shape, output_shape,\\n                                 input_indices_in.matrix<int64>(),'}}",
            "message_norm":"don't do any work when reshaping 0 elements sparse tensor.\n\nif reshaping to 0 elements tensor, check that input has no elements.\nif reshaping no elements input, check that output has no elements.\n\npiperorigin-revid: 388296986\nchange-id: iadc9fe7252e14313ca987e69bf0d7042fd10232a",
            "language":"en",
            "entities":"[('388296986', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/reshape_util.cc'])",
            "num_files":1.0,
            "patch_content":"From 4923de56ec94fff7770df259ab7f2288a74feb41 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Mon, 2 Aug 2021 13:52:28 -0700\nSubject: [PATCH] Don't do any work when reshaping 0 elements sparse tensor.\n\nIf reshaping to 0 elements tensor, check that input has no elements.\nIf reshaping no elements input, check that output has no elements.\n\nPiperOrigin-RevId: 388296986\nChange-Id: Iadc9fe7252e14313ca987e69bf0d7042fd10232a\n---\n tensorflow\/core\/kernels\/reshape_util.cc | 6 ++++++\n 1 file changed, 6 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/reshape_util.cc b\/tensorflow\/core\/kernels\/reshape_util.cc\nindex 6d6c6b3fcf193b..5db8944cebf06b 100644\n--- a\/tensorflow\/core\/kernels\/reshape_util.cc\n+++ b\/tensorflow\/core\/kernels\/reshape_util.cc\n@@ -174,6 +174,12 @@ void ReshapeSparseTensor(OpKernelContext *context,\n                                           TensorShape({nnz, output_rank}),\n                                           &result_indices));\n   if (nnz > 0) {\n+    OP_REQUIRES(\n+        context, dense_size > 0 && product > 0,\n+        errors::InvalidArgument(\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n+            input_shape.DebugString(), \") or output shape (\",\n+            output_shape.DebugString(), \") is empty\"));\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                 context, input_shape, output_shape,\n                                 input_indices_in.matrix<int64>(),"
        },
        {
            "index":228,
            "vuln_id":"GHSA-5fh3-25xr-g85h",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/ff81e6d5366c2cfb15618793ad919ae4cbb3ac57'}",
            "dataset":"osv",
            "summary":"snipe-it is vulnerable to Cross-site Scripting snipe-it is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting').",
            "published_date":"2021-12-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/ff81e6d5366c2cfb15618793ad919ae4cbb3ac57",
            "commit_sha":"ff81e6d5366c2cfb15618793ad919ae4cbb3ac57",
            "patch":"SINGLE",
            "chain_ord":"['ff81e6d5366c2cfb15618793ad919ae4cbb3ac57']",
            "before_first_fix_commit":"{'3b68a6f1befeef504c0a3263e87a2afd55abc430', '00fad35c2a6ddc9813d3322da91086eb06cb7406'}",
            "last_fix_commit":"ff81e6d5366c2cfb15618793ad919ae4cbb3ac57",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/25\/2021, 03:56:36",
            "message":"Merge pull request #10361 from snipe\/fixes\/xss_in_accessories_checkout_notes\n\nEscape notes in transformCheckedOutAccessory",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'app\/Http\/Transformers\/AccessoriesTransformer.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/ff81e6d5366c2cfb15618793ad919ae4cbb3ac57\/app%2FHttp%2FTransformers%2FAccessoriesTransformer.php', 'patch': \"@@ -82,7 +82,7 @@ public function transformCheckedoutAccessory ($accessory, $accessory_users, $tot\\n                 'first_name'=> e($user->first_name),\\n                 'last_name'=> e($user->last_name),\\n                 'employee_number' =>  e($user->employee_num),\\n-                'checkout_notes' => $user->pivot->note,\\n+                'checkout_notes' => e($user->pivot->note),\\n                 'last_checkout' => Helper::getFormattedDateObject($user->pivot->created_at, 'datetime'),\\n                 'type' => 'user',\\n                 'available_actions' => ['checkin' => true]\"}}",
            "message_norm":"merge pull request #10361 from snipe\/fixes\/xss_in_accessories_checkout_notes\n\nescape notes in transformcheckedoutaccessory",
            "language":"en",
            "entities":"[('#10361', 'ISSUE', ''), ('xss_in_accessories_checkout_notes', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Transformers\/AccessoriesTransformer.php'])",
            "num_files":1.0,
            "patch_content":"From 00fad35c2a6ddc9813d3322da91086eb06cb7406 Mon Sep 17 00:00:00 2001\nFrom: snipe <snipe@snipe.net>\nDate: Wed, 24 Nov 2021 19:54:45 -0800\nSubject: [PATCH] Escape notes in transformCheckedOutAccessory\n\nSigned-off-by: snipe <snipe@snipe.net>\n---\n app\/Http\/Transformers\/AccessoriesTransformer.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/app\/Http\/Transformers\/AccessoriesTransformer.php b\/app\/Http\/Transformers\/AccessoriesTransformer.php\nindex d40642d875c6..1bc70f23140f 100644\n--- a\/app\/Http\/Transformers\/AccessoriesTransformer.php\n+++ b\/app\/Http\/Transformers\/AccessoriesTransformer.php\n@@ -82,7 +82,7 @@ public function transformCheckedoutAccessory ($accessory, $accessory_users, $tot\n                 'first_name'=> e($user->first_name),\n                 'last_name'=> e($user->last_name),\n                 'employee_number' =>  e($user->employee_num),\n-                'checkout_notes' => $user->pivot->note,\n+                'checkout_notes' => e($user->pivot->note),\n                 'last_checkout' => Helper::getFormattedDateObject($user->pivot->created_at, 'datetime'),\n                 'type' => 'user',\n                 'available_actions' => ['checkin' => true]"
        },
        {
            "index":727,
            "vuln_id":"GHSA-hm3x-jwwf-jpr9",
            "cwe_id":"{'CWE-200', 'CWE-668'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/openstack\/tripleo-heat-templates\/commit\/160936df134a471cfd245bd60964046027a571ea', 'https:\/\/github.com\/openstack\/tripleo-heat-templates\/commit\/2b9461e97fc5c4ceb0848d1cc4484f656bb85515'}",
            "dataset":"osv",
            "summary":"Exposure of Sensitive Information to an Unauthorized Actor in OpenStack tripleo-heat-templates An information exposure flaw in openstack-tripleo-heat-templates allows an external user to discover the internal IP or hostname. An attacker could exploit this by checking the `www_authenticate_uri parameter` (which is visible to all end users) in configuration files. This would give sensitive information which may aid in additional system exploitation. A patch is available on the `master` branch and anticipated to be part of version 11.6.1.",
            "published_date":"2022-03-24",
            "chain_len":2,
            "project":"https:\/\/github.com\/openstack\/tripleo-heat-templates",
            "commit_href":"https:\/\/github.com\/openstack\/tripleo-heat-templates\/commit\/2b9461e97fc5c4ceb0848d1cc4484f656bb85515",
            "commit_sha":"2b9461e97fc5c4ceb0848d1cc4484f656bb85515",
            "patch":"MULTI",
            "chain_ord":"['160936df134a471cfd245bd60964046027a571ea', '2b9461e97fc5c4ceb0848d1cc4484f656bb85515']",
            "before_first_fix_commit":"{'ea4d002dde779e84c25c983aa3534cf62fe9386f'}",
            "last_fix_commit":"2b9461e97fc5c4ceb0848d1cc4484f656bb85515",
            "chain_ord_pos":2.0,
            "commit_datetime":"01\/06\/2022, 01:32:48",
            "message":"Fix remaining usage of internal url for www_authenticate_uri\n\nThis is follow-up of 160936df134a471cfd245bd60964046027a571ea and fixes\nremaining usage of internal endpoint url for [keystone_authtoken]\nwww_authenticate_uri.\n\nRelated-Bug: #1955397\nChange-Id: Ib2ee7295c7fcda276e4fcf011a9e427e041f4848",
            "author":"Takashi Kajinami",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'deployment\/ironic\/ironic-api-container-puppet.yaml': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/openstack\/tripleo-heat-templates\/raw\/2b9461e97fc5c4ceb0848d1cc4484f656bb85515\/deployment%2Fironic%2Fironic-api-container-puppet.yaml', 'patch': \"@@ -163,7 +163,7 @@ outputs:\\n             ironic::api::authtoken::user_domain_name: 'Default'\\n             ironic::api::authtoken::project_domain_name: 'Default'\\n             ironic::api::authtoken::username: 'ironic'\\n-            ironic::api::authtoken::www_authenticate_uri: {get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]}\\n+            ironic::api::authtoken::www_authenticate_uri: {get_param: [EndpointMap, KeystonePublic, uri_no_suffix]}\\n             ironic::api::authtoken::auth_url: {get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]}\\n             ironic::api::authtoken::region_name: {get_param: KeystoneRegion}\\n             ironic::api::authtoken::interface: 'internal'\"}}",
            "message_norm":"fix remaining usage of internal url for www_authenticate_uri\n\nthis is follow-up of 160936df134a471cfd245bd60964046027a571ea and fixes\nremaining usage of internal endpoint url for [keystone_authtoken]\nwww_authenticate_uri.\n\nrelated-bug: #1955397\nchange-id: ib2ee7295c7fcda276e4fcf011a9e427e041f4848",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('160936df134a471cfd245bd60964046027a571ea', 'SHA', 'generic_sha'), ('fixes', 'ACTION', ''), ('keystone_authtoken', 'SECWORD', ''), ('bug', 'FLAW', ''), ('#1955397', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['deployment\/ironic\/ironic-api-container-puppet.yaml'])",
            "num_files":1.0,
            "patch_content":"From 2b9461e97fc5c4ceb0848d1cc4484f656bb85515 Mon Sep 17 00:00:00 2001\nFrom: Takashi Kajinami <tkajinam@redhat.com>\nDate: Thu, 6 Jan 2022 10:32:48 +0900\nSubject: [PATCH] Fix remaining usage of internal url for www_authenticate_uri\n\nThis is follow-up of 160936df134a471cfd245bd60964046027a571ea and fixes\nremaining usage of internal endpoint url for [keystone_authtoken]\nwww_authenticate_uri.\n\nRelated-Bug: #1955397\nChange-Id: Ib2ee7295c7fcda276e4fcf011a9e427e041f4848\n---\n deployment\/ironic\/ironic-api-container-puppet.yaml | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/deployment\/ironic\/ironic-api-container-puppet.yaml b\/deployment\/ironic\/ironic-api-container-puppet.yaml\nindex eb7eeffaab..ae0039c3b9 100644\n--- a\/deployment\/ironic\/ironic-api-container-puppet.yaml\n+++ b\/deployment\/ironic\/ironic-api-container-puppet.yaml\n@@ -163,7 +163,7 @@ outputs:\n             ironic::api::authtoken::user_domain_name: 'Default'\n             ironic::api::authtoken::project_domain_name: 'Default'\n             ironic::api::authtoken::username: 'ironic'\n-            ironic::api::authtoken::www_authenticate_uri: {get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]}\n+            ironic::api::authtoken::www_authenticate_uri: {get_param: [EndpointMap, KeystonePublic, uri_no_suffix]}\n             ironic::api::authtoken::auth_url: {get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]}\n             ironic::api::authtoken::region_name: {get_param: KeystoneRegion}\n             ironic::api::authtoken::interface: 'internal'"
        },
        {
            "index":470,
            "vuln_id":"GHSA-xg6r-5gx4-qxjm",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/invoiceninja\/invoiceninja\/commit\/1186eaa82375692d01d5ef3369c5b7bc7315b55f'}",
            "dataset":"osv",
            "summary":"invoiceninja is vulnerable to Cross-site Scripting invoiceninja is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/invoiceninja\/invoiceninja",
            "commit_href":"https:\/\/github.com\/invoiceninja\/invoiceninja\/commit\/1186eaa82375692d01d5ef3369c5b7bc7315b55f",
            "commit_sha":"1186eaa82375692d01d5ef3369c5b7bc7315b55f",
            "patch":"SINGLE",
            "chain_ord":"['1186eaa82375692d01d5ef3369c5b7bc7315b55f']",
            "before_first_fix_commit":"{'ac194665de6728e4091f273ef2e01b4c48369fcd'}",
            "last_fix_commit":"1186eaa82375692d01d5ef3369c5b7bc7315b55f",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/10\/2021, 03:00:22",
            "message":"Fixes for client password reset",
            "author":"David Bomba",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 6, 'total': 13}",
            "files":"{'app\/Http\/Controllers\/Auth\/ContactForgotPasswordController.php': {'additions': 7, 'deletions': 6, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/invoiceninja\/invoiceninja\/raw\/1186eaa82375692d01d5ef3369c5b7bc7315b55f\/app%2FHttp%2FControllers%2FAuth%2FContactForgotPasswordController.php', 'patch': \"@@ -93,14 +93,15 @@ public function broker()\\n \\n     public function sendResetLinkEmail(ContactPasswordResetRequest $request)\\n     {\\n-\\n-        if(Ninja::isHosted() && $request->session()->has('company_key'))\\n-            MultiDB::findAndSetDbByCompanyKey($request->session()->get('company_key'));\\n+        if(Ninja::isHosted() && $request->has('company_key'))\\n+            MultiDB::findAndSetDbByCompanyKey($request->input('company_key'));\\n         \\n         $this->validateEmail($request);\\n \\n-        $company = Company::where('company_key', $request->session()->get('company_key'))->first();\\n-        $contact = ClientContact::where(['company_id' => $company->id, 'email' => $request->input('email')])->first();\\n+        \/\/ $company = Company::where('company_key', $request->input('company_key'))->first();\\n+        \/\/ $contact = ClientContact::where(['company_id' => $company->id, 'email' => $request->input('email')])->first();\\n+\\n+        $contact = ClientContact::where(['email' => $request->input('email')])->first();\\n \\n         $response = false;\\n \\n@@ -117,7 +118,7 @@ public function sendResetLinkEmail(ContactPasswordResetRequest $request)\\n             return $this->sendResetLinkFailedResponse($request, Password::INVALID_USER);\\n \\n         \/\/ We will send the password reset link to this user. Once we have attempted\\n-        \/\/ to send the link, we will examine the response then see the message we\\n+        \/\/ to send the link, we will examine thuser@example.ce response then see the message we\\n         \/\/ need to show to the user. Finally, we'll send out a proper response.\\n         \/\/ $response = $this->broker()->sendResetLink(\\n         \/\/     $this->credentials($request)\"}}",
            "message_norm":"fixes for client password reset",
            "language":"en",
            "entities":"[('password', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/Auth\/ContactForgotPasswordController.php'])",
            "num_files":1.0,
            "patch_content":"From 1186eaa82375692d01d5ef3369c5b7bc7315b55f Mon Sep 17 00:00:00 2001\nFrom: David Bomba <turbo124@gmail.com>\nDate: Fri, 10 Dec 2021 14:00:22 +1100\nSubject: [PATCH] Fixes for client password reset\n\n---\n ...\/Auth\/ContactForgotPasswordController.php        | 13 +++++++------\n 1 file changed, 7 insertions(+), 6 deletions(-)\n\ndiff --git a\/app\/Http\/Controllers\/Auth\/ContactForgotPasswordController.php b\/app\/Http\/Controllers\/Auth\/ContactForgotPasswordController.php\nindex bdfe94431c..f88e99a43e 100644\n--- a\/app\/Http\/Controllers\/Auth\/ContactForgotPasswordController.php\n+++ b\/app\/Http\/Controllers\/Auth\/ContactForgotPasswordController.php\n@@ -93,14 +93,15 @@ public function broker()\n \n     public function sendResetLinkEmail(ContactPasswordResetRequest $request)\n     {\n-\n-        if(Ninja::isHosted() && $request->session()->has('company_key'))\n-            MultiDB::findAndSetDbByCompanyKey($request->session()->get('company_key'));\n+        if(Ninja::isHosted() && $request->has('company_key'))\n+            MultiDB::findAndSetDbByCompanyKey($request->input('company_key'));\n         \n         $this->validateEmail($request);\n \n-        $company = Company::where('company_key', $request->session()->get('company_key'))->first();\n-        $contact = ClientContact::where(['company_id' => $company->id, 'email' => $request->input('email')])->first();\n+        \/\/ $company = Company::where('company_key', $request->input('company_key'))->first();\n+        \/\/ $contact = ClientContact::where(['company_id' => $company->id, 'email' => $request->input('email')])->first();\n+\n+        $contact = ClientContact::where(['email' => $request->input('email')])->first();\n \n         $response = false;\n \n@@ -117,7 +118,7 @@ public function sendResetLinkEmail(ContactPasswordResetRequest $request)\n             return $this->sendResetLinkFailedResponse($request, Password::INVALID_USER);\n \n         \/\/ We will send the password reset link to this user. Once we have attempted\n-        \/\/ to send the link, we will examine the response then see the message we\n+        \/\/ to send the link, we will examine thuser@example.ce response then see the message we\n         \/\/ need to show to the user. Finally, we'll send out a proper response.\n         \/\/ $response = $this->broker()->sendResetLink(\n         \/\/     $this->credentials($request)"
        },
        {
            "index":102,
            "vuln_id":"GHSA-2ccx-2gf3-8xvv",
            "cwe_id":"{'CWE-346'}",
            "score":6.8,
            "chain":"{'https:\/\/github.com\/getkirby-v2\/panel\/commit\/7f9ac1876bacb89fd8f142f5e561a02ebb725baa'}",
            "dataset":"osv",
            "summary":"Kirby .dev domains and some reverse proxy setups were treated as local ### Impact\n\n#### About our registration block\n\nIn order to protect new installations on public servers that don't have an admin account for the Panel yet, we block account registration there by default. This is a security feature, which we implemented years ago in Kirby 2. It helps to avoid that you forget registering your first admin account on a public server. \n\nIn this case \u2013 without our security block \u2013 someone else might theoretically be able to find your site, find out it's running on Kirby, find the Panel and then register the account first. It's an unlikely situation, but it's still a certain risk.\n\nTo be able to register the first Panel account on a public server, you have to enforce the installer via a config setting. This helps to push all users to the best practice of registering your first Panel account on your local machine and upload it together with the rest of the site. \n\n#### The issue\n\nAs noted by [Jukka Rautanen](https:\/\/github.com\/jukra), this installation block implementation in Kirby versions before 3.3.6 still assumed that .dev domains are local domains, which is no longer true. In the meantime, those domains became publicly available. This means that our installation block is no longer working as expected if you use a .dev domain for your Kirby site.\n\nIn fixing this issue, we've also found out that the local installation check may also fail if your site is behind a reverse proxy. \n\n#### Am I affected?\n\nYou are only affected if:\n\n1. you use a .dev domain or your site is behind a reverse proxy &\n2. you have not yet registered your first Panel account on the public server & \n3. someone finds your site and tries to login at `yourdomain.dev\/panel` before you register your first account.\n\nYou are not affected if you have already created one or multiple Panel accounts (no matter if on a .dev domain or behind a reverse proxy).\n\n### Patches\n\nThe problem has been patched in [Kirby 2.5.14](https:\/\/github.com\/getkirby-v2\/panel\/releases\/tag\/2.5.14) and [Kirby 3.3.6](https:\/\/github.com\/getkirby\/kirby\/releases\/tag\/3.3.6). Please update to one of these or a [later version](https:\/\/github.com\/getkirby\/kirby\/releases) to fix the vulnerability.\n\n**Note:** Kirby 2 reaches end of life on December 31, 2020. We therefore recommend to upgrade your Kirby 2 sites to Kirby 3. If you cannot upgrade, we still recommend to update to Kirby 2.5.14.\n\n### Workarounds\n\nKirby 2 sites on older releases can also be patched by applying the [changes from this commit](https:\/\/github.com\/getkirby-v2\/panel\/commit\/7f9ac1876bacb89fd8f142f5e561a02ebb725baa).",
            "published_date":"2021-01-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/getkirby-v2\/panel",
            "commit_href":"https:\/\/github.com\/getkirby-v2\/panel\/commit\/7f9ac1876bacb89fd8f142f5e561a02ebb725baa",
            "commit_sha":"7f9ac1876bacb89fd8f142f5e561a02ebb725baa",
            "patch":"SINGLE",
            "chain_ord":"['7f9ac1876bacb89fd8f142f5e561a02ebb725baa']",
            "before_first_fix_commit":"{'5a569d4e3ddaea2b6628d7ec1472a3e8bc410881'}",
            "last_fix_commit":"7f9ac1876bacb89fd8f142f5e561a02ebb725baa",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/01\/2020, 10:11:11",
            "message":"Better check for local environments",
            "author":"Bastian Allgeier",
            "comments":null,
            "stats":"{'additions': 41, 'deletions': 7, 'total': 48}",
            "files":"{'app\/src\/panel.php': {'additions': 41, 'deletions': 7, 'changes': 48, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/getkirby-v2\/panel\/raw\/7f9ac1876bacb89fd8f142f5e561a02ebb725baa\/app%2Fsrc%2Fpanel.php', 'patch': \"@@ -493,13 +493,47 @@ public function license() {\\n   }\\n \\n   public function isLocal() {\\n-    $localhosts = array('::1', '127.0.0.1', '0.0.0.0');\\n-    return (\\n-      in_array(server::get('SERVER_ADDR'), $localhosts) ||\\n-      server::get('SERVER_NAME') == 'localhost' ||\\n-      str::endsWith(server::get('SERVER_NAME'), '.localhost') ||\\n-      str::endsWith(server::get('SERVER_NAME'), '.test')\\n-    );\\n+\\n+    $host = server::get('SERVER_NAME');\\n+    $ip   = server::get('SERVER_ADDR');\\n+\\n+    if ($host === 'localhost') {\\n+      return true;\\n+    }\\n+\\n+    if (str::endsWith($host, '.localhost') === true) {\\n+      return true;\\n+    }\\n+\\n+    if (str::endsWith($host, '.local') === true) {\\n+      return true;\\n+    }\\n+\\n+    if (str::endsWith($host, '.test') === true) {\\n+      return true;\\n+    }\\n+\\n+    if (in_array($ip, ['::1', '127.0.0.1']) === true) {\\n+\\n+      if (\\n+        isset($_SERVER['HTTP_X_FORWARDED_FOR']) === true &&\\n+        in_array($_SERVER['HTTP_X_FORWARDED_FOR'], ['::1', '127.0.0.1']) === false\\n+      ) {\\n+        return false;\\n+      }\\n+\\n+      if (\\n+        isset($_SERVER['HTTP_CLIENT_IP']) === true &&\\n+        in_array($_SERVER['HTTP_CLIENT_IP'], ['::1', '127.0.0.1']) === false\\n+      ) {\\n+        return false;\\n+      }\\n+\\n+      \/\/ no reverse proxy or the real client also comes from localhost\\n+      return true;\\n+    }\\n+\\n+    return false;\\n   }\\n \\n   public function notify($text) {\"}}",
            "message_norm":"better check for local environments",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/src\/panel.php'])",
            "num_files":1.0,
            "patch_content":"From 7f9ac1876bacb89fd8f142f5e561a02ebb725baa Mon Sep 17 00:00:00 2001\nFrom: Bastian Allgeier <mail@bastianallgeier.com>\nDate: Tue, 1 Dec 2020 11:11:11 +0100\nSubject: [PATCH] Better check for local environments\n\n---\n app\/src\/panel.php | 48 ++++++++++++++++++++++++++++++++++++++++-------\n 1 file changed, 41 insertions(+), 7 deletions(-)\n\ndiff --git a\/app\/src\/panel.php b\/app\/src\/panel.php\nindex abcaec42..2030cc87 100644\n--- a\/app\/src\/panel.php\n+++ b\/app\/src\/panel.php\n@@ -493,13 +493,47 @@ public function license() {\n   }\n \n   public function isLocal() {\n-    $localhosts = array('::1', '127.0.0.1', '0.0.0.0');\n-    return (\n-      in_array(server::get('SERVER_ADDR'), $localhosts) ||\n-      server::get('SERVER_NAME') == 'localhost' ||\n-      str::endsWith(server::get('SERVER_NAME'), '.localhost') ||\n-      str::endsWith(server::get('SERVER_NAME'), '.test')\n-    );\n+\n+    $host = server::get('SERVER_NAME');\n+    $ip   = server::get('SERVER_ADDR');\n+\n+    if ($host === 'localhost') {\n+      return true;\n+    }\n+\n+    if (str::endsWith($host, '.localhost') === true) {\n+      return true;\n+    }\n+\n+    if (str::endsWith($host, '.local') === true) {\n+      return true;\n+    }\n+\n+    if (str::endsWith($host, '.test') === true) {\n+      return true;\n+    }\n+\n+    if (in_array($ip, ['::1', '127.0.0.1']) === true) {\n+\n+      if (\n+        isset($_SERVER['HTTP_X_FORWARDED_FOR']) === true &&\n+        in_array($_SERVER['HTTP_X_FORWARDED_FOR'], ['::1', '127.0.0.1']) === false\n+      ) {\n+        return false;\n+      }\n+\n+      if (\n+        isset($_SERVER['HTTP_CLIENT_IP']) === true &&\n+        in_array($_SERVER['HTTP_CLIENT_IP'], ['::1', '127.0.0.1']) === false\n+      ) {\n+        return false;\n+      }\n+\n+      \/\/ no reverse proxy or the real client also comes from localhost\n+      return true;\n+    }\n+\n+    return false;\n   }\n \n   public function notify($text) {"
        },
        {
            "index":509,
            "vuln_id":"GHSA-7fc2-rm35-2pp7",
            "cwe_id":"{'CWE-352'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/ipython\/ipython\/commit\/1415a9710407e7c14900531813c15ba6165f0816', 'https:\/\/github.com\/ipython\/ipython\/commit\/a05fe052a18810e92d9be8c1185952c13fe4e5b0'}",
            "dataset":"osv",
            "summary":"IPython vulnerable to cross site request forgery (CSRF) IPython (Interactive Python) is a command shell. Cross-site request forgery in the REST API is possible in in IPython 2 and 3. Versions 2.4.1 and 3.2.3 contain patches.",
            "published_date":"2022-05-17",
            "chain_len":2,
            "project":"https:\/\/github.com\/ipython\/ipython",
            "commit_href":"https:\/\/github.com\/ipython\/ipython\/commit\/a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "commit_sha":"a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "patch":"MULTI",
            "chain_ord":"['1415a9710407e7c14900531813c15ba6165f0816', 'a05fe052a18810e92d9be8c1185952c13fe4e5b0']",
            "before_first_fix_commit":"{'6884e8b36dc1e2d59e1d8ddb5e95788728d76e6f'}",
            "last_fix_commit":"a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/12\/2015, 15:36:44",
            "message":"backport origin check for API requests",
            "author":"Min RK",
            "comments":null,
            "stats":"{'additions': 48, 'deletions': 0, 'total': 48}",
            "files":"{'IPython\/html\/base\/handlers.py': {'additions': 48, 'deletions': 0, 'changes': 48, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ipython\/ipython\/raw\/a05fe052a18810e92d9be8c1185952c13fe4e5b0\/IPython%2Fhtml%2Fbase%2Fhandlers.py', 'patch': '@@ -29,6 +29,10 @@\\n     from http.client import responses\\n except ImportError:\\n     from httplib import responses\\n+try:\\n+    from urllib.parse import urlparse # Py 3\\n+except ImportError:\\n+    from urlparse import urlparse # Py 2\\n \\n from jinja2 import TemplateNotFound\\n from tornado import web\\n@@ -208,6 +212,50 @@ def get_origin(self):\\n             origin = self.request.headers.get(\"Sec-Websocket-Origin\", None)\\n         return origin\\n \\n+    def check_origin_api(self):\\n+        \"\"\"Check Origin for cross-site API requests.\\n+        \\n+        Copied from WebSocket with changes:\\n+        \\n+        - allow unspecified host\/origin (e.g. scripts)\\n+        \"\"\"\\n+        if self.allow_origin == \\'*\\':\\n+            return True\\n+\\n+        host = self.request.headers.get(\"Host\")\\n+        origin = self.request.headers.get(\"Origin\")\\n+\\n+        # If no header is provided, assume it comes from a script\/curl.\\n+        # We are only concerned with cross-site browser stuff here.\\n+        if origin is None or host is None:\\n+            return True\\n+        \\n+        origin = origin.lower()\\n+        origin_host = urlparse(origin).netloc\\n+        \\n+        # OK if origin matches host\\n+        if origin_host == host:\\n+            return True\\n+        \\n+        # Check CORS headers\\n+        if self.allow_origin:\\n+            allow = self.allow_origin == origin\\n+        elif self.allow_origin_pat:\\n+            allow = bool(self.allow_origin_pat.match(origin))\\n+        else:\\n+            # No CORS headers deny the request\\n+            allow = False\\n+        if not allow:\\n+            self.log.warn(\"Blocking Cross Origin API request.  Origin: %s, Host: %s\",\\n+                origin, host,\\n+            )\\n+        return allow\\n+\\n+    def prepare(self):\\n+        if not self.check_origin_api():\\n+            raise web.HTTPError(404)\\n+        return super(IPythonHandler, self).prepare()\\n+\\n     #---------------------------------------------------------------\\n     # template rendering\\n     #---------------------------------------------------------------'}}",
            "message_norm":"backport origin check for api requests",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['IPython\/html\/base\/handlers.py'])",
            "num_files":1.0,
            "patch_content":"From a05fe052a18810e92d9be8c1185952c13fe4e5b0 Mon Sep 17 00:00:00 2001\nFrom: Min RK <benjaminrk@gmail.com>\nDate: Sun, 12 Jul 2015 10:36:44 -0500\nSubject: [PATCH] backport origin check for API requests\n\n---\n IPython\/html\/base\/handlers.py | 48 +++++++++++++++++++++++++++++++++++\n 1 file changed, 48 insertions(+)\n\ndiff --git a\/IPython\/html\/base\/handlers.py b\/IPython\/html\/base\/handlers.py\nindex 40a9a630460..16fc4aef4a1 100644\n--- a\/IPython\/html\/base\/handlers.py\n+++ b\/IPython\/html\/base\/handlers.py\n@@ -29,6 +29,10 @@\n     from http.client import responses\n except ImportError:\n     from httplib import responses\n+try:\n+    from urllib.parse import urlparse # Py 3\n+except ImportError:\n+    from urlparse import urlparse # Py 2\n \n from jinja2 import TemplateNotFound\n from tornado import web\n@@ -208,6 +212,50 @@ def get_origin(self):\n             origin = self.request.headers.get(\"Sec-Websocket-Origin\", None)\n         return origin\n \n+    def check_origin_api(self):\n+        \"\"\"Check Origin for cross-site API requests.\n+        \n+        Copied from WebSocket with changes:\n+        \n+        - allow unspecified host\/origin (e.g. scripts)\n+        \"\"\"\n+        if self.allow_origin == '*':\n+            return True\n+\n+        host = self.request.headers.get(\"Host\")\n+        origin = self.request.headers.get(\"Origin\")\n+\n+        # If no header is provided, assume it comes from a script\/curl.\n+        # We are only concerned with cross-site browser stuff here.\n+        if origin is None or host is None:\n+            return True\n+        \n+        origin = origin.lower()\n+        origin_host = urlparse(origin).netloc\n+        \n+        # OK if origin matches host\n+        if origin_host == host:\n+            return True\n+        \n+        # Check CORS headers\n+        if self.allow_origin:\n+            allow = self.allow_origin == origin\n+        elif self.allow_origin_pat:\n+            allow = bool(self.allow_origin_pat.match(origin))\n+        else:\n+            # No CORS headers deny the request\n+            allow = False\n+        if not allow:\n+            self.log.warn(\"Blocking Cross Origin API request.  Origin: %s, Host: %s\",\n+                origin, host,\n+            )\n+        return allow\n+\n+    def prepare(self):\n+        if not self.check_origin_api():\n+            raise web.HTTPError(404)\n+        return super(IPythonHandler, self).prepare()\n+\n     #---------------------------------------------------------------\n     # template rendering\n     #---------------------------------------------------------------"
        },
        {
            "index":849,
            "vuln_id":"GHSA-4rcq-jv2f-898j",
            "cwe_id":"{'CWE-684'}",
            "score":3.5,
            "chain":"{'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/d28ed758d077a5bf19ddac4da468f7224114df23', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/4020210b193f77cf1785b21717f6ef7c5de5f0f8', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/f5d801251aa5436aff44660c87d7013e29ac5864', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/6821c236f9ae23adf21d46ce0d56768ac8d0c467', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/a45ca9c788f648d10cccce2af41405bf25ee2948', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/021ab572a319ca3db5907a33a59774f502b3b975', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/9bd1cf585fccdfe8318fff7af793730e74a04db3', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/1b7946ed14b386a24db050f2d6dba81ba6518755', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/2281a205c3e70ec20f35ec8fafecee0d5c4f3478', 'https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/19f01bb42d02da539446a52a25bb0c1232b86327'}",
            "dataset":"osv",
            "summary":"Incorrect Provision of Specified Functionality in qutebrowser # Description\n\nAfter a certificate error was overridden by the user, qutebrowser displays the URL as yellow (`colors.statusbar.url.warn.fg`). However, when the affected website was subsequently loaded again, the URL was mistakenly displayed as green (`colors.statusbar.url.success_https`). While the user already has seen a certificate error prompt at this point (or set `content.ssl_strict` to `false` which is not recommended), this could still provide a false sense of security.\n\n# Affected versions and patches\n\nAll versions of qutebrowser are believed to be affected, though versions before v0.11.x couldn't be tested.\n\nThe issue is fixed in qutebrowser v1.11.1 (pending release) and v1.12.0 (unreleased). Backported patches for older versions are available, but no further releases are planned.\n\n# Mitigation\n\nIf you are unable to upgrade:\n\n- Treat any host with a certificate exception as insecure, ignoring the URL color\n- Or set `content.ssl_strict` to `True` (instead of `'ask'`), preventing certificate exceptions\n\n# References\n\n- qutebrowser issue: https:\/\/github.com\/qutebrowser\/qutebrowser\/issues\/5403\n- Fix (master branch): https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/021ab572a319ca3db5907a33a59774f502b3b975\n- Related issue for KDE Falkon: https:\/\/bugs.kde.org\/show_bug.cgi?id=420902\n- Related issue for eric6 Web Browser: https:\/\/tracker.die-offenbachs.homelinux.org\/eric\/issue328 (fixed in eric6 20.6)",
            "published_date":"2020-05-08",
            "chain_len":10,
            "project":"https:\/\/github.com\/qutebrowser\/qutebrowser",
            "commit_href":"https:\/\/github.com\/qutebrowser\/qutebrowser\/commit\/1b7946ed14b386a24db050f2d6dba81ba6518755",
            "commit_sha":"1b7946ed14b386a24db050f2d6dba81ba6518755",
            "patch":"MULTI",
            "chain_ord":"['d28ed758d077a5bf19ddac4da468f7224114df23', '9bd1cf585fccdfe8318fff7af793730e74a04db3', '6821c236f9ae23adf21d46ce0d56768ac8d0c467', '4020210b193f77cf1785b21717f6ef7c5de5f0f8', 'f5d801251aa5436aff44660c87d7013e29ac5864', 'a45ca9c788f648d10cccce2af41405bf25ee2948', '2281a205c3e70ec20f35ec8fafecee0d5c4f3478', '19f01bb42d02da539446a52a25bb0c1232b86327', '021ab572a319ca3db5907a33a59774f502b3b975', '1b7946ed14b386a24db050f2d6dba81ba6518755']",
            "before_first_fix_commit":"{'e15af6cd92d523b22fe9774b653a859b9e33df41'}",
            "last_fix_commit":"1b7946ed14b386a24db050f2d6dba81ba6518755",
            "chain_ord_pos":10.0,
            "commit_datetime":"05\/02\/2020, 17:03:20",
            "message":"Update changelog",
            "author":"Florian Bruhin",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 1, 'total': 11}",
            "files":"{'doc\/changelog.asciidoc': {'additions': 10, 'deletions': 1, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/qutebrowser\/qutebrowser\/raw\/1b7946ed14b386a24db050f2d6dba81ba6518755\/doc%2Fchangelog.asciidoc', 'patch': '@@ -45,7 +45,16 @@ Fixed\\n v1.11.1 (unreleased)\\n --------------------\\n \\n-No changes yet.\\n+Security\\n+~~~~~~~~\\n+\\n+- After a certificate error was overridden by the user, qutebrowser displays\\n+  the URL as yellow (`colors.statusbar.url.warn.fg`). However, when the\\n+  affected website was subsequently loaded again, the URL was mistakenly\\n+  displayed as green (`colors.statusbar.url.success_https`). While the user\\n+  already has seen a certificate error prompt at this point (or set\\n+  `content.ssl_strict` to `false` which is not recommended), this could still\\n+  provide a false sense of security. This is now fixed.\\n \\n v1.11.0 (2020-04-27)\\n --------------------'}}",
            "message_norm":"update changelog",
            "language":"nl",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['doc\/changelog.asciidoc'])",
            "num_files":1.0,
            "patch_content":"From 1b7946ed14b386a24db050f2d6dba81ba6518755 Mon Sep 17 00:00:00 2001\nFrom: Florian Bruhin <me@the-compiler.org>\nDate: Sat, 2 May 2020 19:03:20 +0200\nSubject: [PATCH] Update changelog\n\n---\n doc\/changelog.asciidoc | 11 ++++++++++-\n 1 file changed, 10 insertions(+), 1 deletion(-)\n\ndiff --git a\/doc\/changelog.asciidoc b\/doc\/changelog.asciidoc\nindex 208d369176f..3d39eec8580 100644\n--- a\/doc\/changelog.asciidoc\n+++ b\/doc\/changelog.asciidoc\n@@ -45,7 +45,16 @@ Fixed\n v1.11.1 (unreleased)\n --------------------\n \n-No changes yet.\n+Security\n+~~~~~~~~\n+\n+- After a certificate error was overridden by the user, qutebrowser displays\n+  the URL as yellow (`colors.statusbar.url.warn.fg`). However, when the\n+  affected website was subsequently loaded again, the URL was mistakenly\n+  displayed as green (`colors.statusbar.url.success_https`). While the user\n+  already has seen a certificate error prompt at this point (or set\n+  `content.ssl_strict` to `false` which is not recommended), this could still\n+  provide a false sense of security. This is now fixed.\n \n v1.11.0 (2020-04-27)\n --------------------"
        },
        {
            "index":890,
            "vuln_id":"GHSA-h4mc-r4f4-hcf4",
            "cwe_id":"{'CWE-311'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/spunjs\/selenium-binaries\/commit\/be37e82a3c43a4f1679d66cf9467085ec9994c47'}",
            "dataset":"osv",
            "summary":"selenium-binaries downloads resources over HTTP Versions of `selenium-binaries` prior to 0.15.0 insecurely download an executable over an unencrypted HTTP connection. \n\nIn scenarios where an attacker has a privileged network position, it is possible to intercept the response and replace the executable with a malicious one, resulting in code execution on the system running `selenium-binaries`.\n\n\n## Recommendation\n\nA fix for this vulnerability is available on the `master` branch of the repository as part of version 0.15.0.\n\nAnother mitigation currently available is to use an alternate package, such as [selenium-webdriver](https:\/\/www.npmjs.com\/package\/selenium-webdriver), the official selenium bindings for node.js.",
            "published_date":"2019-02-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/spunjs\/selenium-binaries",
            "commit_href":"https:\/\/github.com\/spunjs\/selenium-binaries\/commit\/be37e82a3c43a4f1679d66cf9467085ec9994c47",
            "commit_sha":"be37e82a3c43a4f1679d66cf9467085ec9994c47",
            "patch":"SINGLE",
            "chain_ord":"['be37e82a3c43a4f1679d66cf9467085ec9994c47']",
            "before_first_fix_commit":"{'75b0fd18ffd6373fd09d39c48b1df632f9649c08'}",
            "last_fix_commit":"be37e82a3c43a4f1679d66cf9467085ec9994c47",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/22\/2020, 17:20:26",
            "message":"Avoid MiTM by downloading through https (#33)\n\nCo-authored-by: Alejandro Romero Herrera <alromh87@gmail.com>\r\nCo-authored-by: Raj <70631238+418raj@users.noreply.github.com>",
            "author":"huntr-helper",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 3, 'total': 6}",
            "files":"{'lib\/config.js': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/spunjs\/selenium-binaries\/raw\/be37e82a3c43a4f1679d66cf9467085ec9994c47\/lib%2Fconfig.js', 'patch': \"@@ -35,7 +35,7 @@ module.exports = {\\n     seleniumserver: {\\n       version: SELENIUM_BINARIES_SERVER_STANDALONE_VERSION,\\n       url: util.format(\\n-        'http:\/\/selenium-release.storage.googleapis.com\/%s\/',\\n+        'https:\/\/selenium-release.storage.googleapis.com\/%s\/',\\n         getMajorMinorVersion(SELENIUM_BINARIES_SERVER_STANDALONE_VERSION)\\n       ),\\n       path: path.resolve(\\n@@ -55,7 +55,7 @@ module.exports = {\\n     chromedriver: {\\n       version: SELENIUM_BINARIES_CHROMEDRIVER_VERSION,\\n       url: util.format(\\n-        'http:\/\/chromedriver.storage.googleapis.com\/%s\/',\\n+        'https:\/\/chromedriver.storage.googleapis.com\/%s\/',\\n         SELENIUM_BINARIES_CHROMEDRIVER_VERSION\\n       ),\\n       path: path.resolve(\\n@@ -89,7 +89,7 @@ module.exports = {\\n     iedriver: {\\n       version: SELENIUM_BINARIES_IEDRIVER_VERSION,\\n       url: util.format(\\n-        'http:\/\/selenium-release.storage.googleapis.com\/%s\/',\\n+        'https:\/\/selenium-release.storage.googleapis.com\/%s\/',\\n         getMajorMinorVersion(SELENIUM_BINARIES_IEDRIVER_VERSION)\\n       ),\\n       path: path.resolve(\"}}",
            "message_norm":"avoid mitm by downloading through https (#33)\n\nco-authored-by: alejandro romero herrera <alromh87@gmail.com>\r\nco-authored-by: raj <70631238+418raj@users.noreply.github.com>",
            "language":"en",
            "entities":"[('mitm', 'SECWORD', ''), ('#33', 'ISSUE', ''), ('alromh87@gmail.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/config.js'])",
            "num_files":1.0,
            "patch_content":"From be37e82a3c43a4f1679d66cf9467085ec9994c47 Mon Sep 17 00:00:00 2001\nFrom: huntr-helper <admin@418sec.com>\nDate: Tue, 22 Sep 2020 18:20:26 +0100\nSubject: [PATCH] Avoid MiTM by downloading through https (#33)\n\nCo-authored-by: Alejandro Romero Herrera <alromh87@gmail.com>\nCo-authored-by: Raj <70631238+418raj@users.noreply.github.com>\n---\n lib\/config.js | 6 +++---\n 1 file changed, 3 insertions(+), 3 deletions(-)\n\ndiff --git a\/lib\/config.js b\/lib\/config.js\nindex 7193625..cceb39d 100644\n--- a\/lib\/config.js\n+++ b\/lib\/config.js\n@@ -35,7 +35,7 @@ module.exports = {\n     seleniumserver: {\n       version: SELENIUM_BINARIES_SERVER_STANDALONE_VERSION,\n       url: util.format(\n-        'http:\/\/selenium-release.storage.googleapis.com\/%s\/',\n+        'https:\/\/selenium-release.storage.googleapis.com\/%s\/',\n         getMajorMinorVersion(SELENIUM_BINARIES_SERVER_STANDALONE_VERSION)\n       ),\n       path: path.resolve(\n@@ -55,7 +55,7 @@ module.exports = {\n     chromedriver: {\n       version: SELENIUM_BINARIES_CHROMEDRIVER_VERSION,\n       url: util.format(\n-        'http:\/\/chromedriver.storage.googleapis.com\/%s\/',\n+        'https:\/\/chromedriver.storage.googleapis.com\/%s\/',\n         SELENIUM_BINARIES_CHROMEDRIVER_VERSION\n       ),\n       path: path.resolve(\n@@ -89,7 +89,7 @@ module.exports = {\n     iedriver: {\n       version: SELENIUM_BINARIES_IEDRIVER_VERSION,\n       url: util.format(\n-        'http:\/\/selenium-release.storage.googleapis.com\/%s\/',\n+        'https:\/\/selenium-release.storage.googleapis.com\/%s\/',\n         getMajorMinorVersion(SELENIUM_BINARIES_IEDRIVER_VERSION)\n       ),\n       path: path.resolve("
        },
        {
            "index":371,
            "vuln_id":"GHSA-7fc2-rm35-2pp7",
            "cwe_id":"{'CWE-352'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/ipython\/ipython\/commit\/1415a9710407e7c14900531813c15ba6165f0816', 'https:\/\/github.com\/ipython\/ipython\/commit\/a05fe052a18810e92d9be8c1185952c13fe4e5b0'}",
            "dataset":"osv",
            "summary":"IPython vulnerable to cross site request forgery (CSRF) IPython (Interactive Python) is a command shell. Cross-site request forgery in the REST API is possible in in IPython 2 and 3. Versions 2.4.1 and 3.2.3 contain patches.",
            "published_date":"2022-05-17",
            "chain_len":2,
            "project":"https:\/\/github.com\/ipython\/ipython",
            "commit_href":"https:\/\/github.com\/ipython\/ipython\/commit\/1415a9710407e7c14900531813c15ba6165f0816",
            "commit_sha":"1415a9710407e7c14900531813c15ba6165f0816",
            "patch":"MULTI",
            "chain_ord":"['1415a9710407e7c14900531813c15ba6165f0816', 'a05fe052a18810e92d9be8c1185952c13fe4e5b0']",
            "before_first_fix_commit":"{'6884e8b36dc1e2d59e1d8ddb5e95788728d76e6f'}",
            "last_fix_commit":"a05fe052a18810e92d9be8c1185952c13fe4e5b0",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/08\/2015, 07:11:16",
            "message":"check origin of API requests\n\nprotects agains CSRF on POST endpoints via forms.",
            "author":"Min RK",
            "comments":null,
            "stats":"{'additions': 48, 'deletions': 1, 'total': 49}",
            "files":"{'IPython\/html\/base\/handlers.py': {'additions': 48, 'deletions': 1, 'changes': 49, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ipython\/ipython\/raw\/1415a9710407e7c14900531813c15ba6165f0816\/IPython%2Fhtml%2Fbase%2Fhandlers.py', 'patch': '@@ -5,7 +5,6 @@\\n \\n import functools\\n import json\\n-import logging\\n import os\\n import re\\n import sys\\n@@ -15,6 +14,10 @@\\n     from http.client import responses\\n except ImportError:\\n     from httplib import responses\\n+try:\\n+    from urllib.parse import urlparse # Py 3\\n+except ImportError:\\n+    from urlparse import urlparse # Py 2\\n \\n from jinja2 import TemplateNotFound\\n from tornado import web\\n@@ -320,6 +323,50 @@ def write_error(self, status_code, **kwargs):\\n class APIHandler(IPythonHandler):\\n     \"\"\"Base class for API handlers\"\"\"\\n     \\n+    def check_origin(self):\\n+        \"\"\"Check Origin for cross-site API requests.\\n+        \\n+        Copied from WebSocket with changes:\\n+        \\n+        - allow unspecified host\/origin (e.g. scripts)\\n+        \"\"\"\\n+        if self.allow_origin == \\'*\\':\\n+            return True\\n+\\n+        host = self.request.headers.get(\"Host\")\\n+        origin = self.request.headers.get(\"Origin\")\\n+\\n+        # If no header is provided, assume it comes from a script\/curl.\\n+        # We are only concerned with cross-site browser stuff here.\\n+        if origin is None or host is None:\\n+            return True\\n+        \\n+        origin = origin.lower()\\n+        origin_host = urlparse(origin).netloc\\n+        \\n+        # OK if origin matches host\\n+        if origin_host == host:\\n+            return True\\n+        \\n+        # Check CORS headers\\n+        if self.allow_origin:\\n+            allow = self.allow_origin == origin\\n+        elif self.allow_origin_pat:\\n+            allow = bool(self.allow_origin_pat.match(origin))\\n+        else:\\n+            # No CORS headers deny the request\\n+            allow = False\\n+        if not allow:\\n+            self.log.warn(\"Blocking Cross Origin API request.  Origin: %s, Host: %s\",\\n+                origin, host,\\n+            )\\n+        return allow\\n+\\n+    def prepare(self):\\n+        if not self.check_origin():\\n+            raise web.HTTPError(404)\\n+        return super(APIHandler, self).prepare()\\n+\\n     @property\\n     def content_security_policy(self):\\n         csp = \\'; \\'.join(['}}",
            "message_norm":"check origin of api requests\n\nprotects agains csrf on post endpoints via forms.",
            "language":"en",
            "entities":"[('protects', 'ACTION', ''), ('csrf', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['IPython\/html\/base\/handlers.py'])",
            "num_files":1.0,
            "patch_content":"From 1415a9710407e7c14900531813c15ba6165f0816 Mon Sep 17 00:00:00 2001\nFrom: Min RK <benjaminrk@gmail.com>\nDate: Wed, 8 Jul 2015 02:11:16 -0500\nSubject: [PATCH] check origin of API requests\n\nprotects agains CSRF on POST endpoints via forms.\n---\n IPython\/html\/base\/handlers.py | 49 ++++++++++++++++++++++++++++++++++-\n 1 file changed, 48 insertions(+), 1 deletion(-)\n\ndiff --git a\/IPython\/html\/base\/handlers.py b\/IPython\/html\/base\/handlers.py\nindex d6c7b8b54a0..cf65cd8c912 100644\n--- a\/IPython\/html\/base\/handlers.py\n+++ b\/IPython\/html\/base\/handlers.py\n@@ -5,7 +5,6 @@\n \n import functools\n import json\n-import logging\n import os\n import re\n import sys\n@@ -15,6 +14,10 @@\n     from http.client import responses\n except ImportError:\n     from httplib import responses\n+try:\n+    from urllib.parse import urlparse # Py 3\n+except ImportError:\n+    from urlparse import urlparse # Py 2\n \n from jinja2 import TemplateNotFound\n from tornado import web\n@@ -320,6 +323,50 @@ def write_error(self, status_code, **kwargs):\n class APIHandler(IPythonHandler):\n     \"\"\"Base class for API handlers\"\"\"\n     \n+    def check_origin(self):\n+        \"\"\"Check Origin for cross-site API requests.\n+        \n+        Copied from WebSocket with changes:\n+        \n+        - allow unspecified host\/origin (e.g. scripts)\n+        \"\"\"\n+        if self.allow_origin == '*':\n+            return True\n+\n+        host = self.request.headers.get(\"Host\")\n+        origin = self.request.headers.get(\"Origin\")\n+\n+        # If no header is provided, assume it comes from a script\/curl.\n+        # We are only concerned with cross-site browser stuff here.\n+        if origin is None or host is None:\n+            return True\n+        \n+        origin = origin.lower()\n+        origin_host = urlparse(origin).netloc\n+        \n+        # OK if origin matches host\n+        if origin_host == host:\n+            return True\n+        \n+        # Check CORS headers\n+        if self.allow_origin:\n+            allow = self.allow_origin == origin\n+        elif self.allow_origin_pat:\n+            allow = bool(self.allow_origin_pat.match(origin))\n+        else:\n+            # No CORS headers deny the request\n+            allow = False\n+        if not allow:\n+            self.log.warn(\"Blocking Cross Origin API request.  Origin: %s, Host: %s\",\n+                origin, host,\n+            )\n+        return allow\n+\n+    def prepare(self):\n+        if not self.check_origin():\n+            raise web.HTTPError(404)\n+        return super(APIHandler, self).prepare()\n+\n     @property\n     def content_security_policy(self):\n         csp = '; '.join(["
        },
        {
            "index":42,
            "vuln_id":"GHSA-rgvq-pcvf-hx75",
            "cwe_id":"{'CWE-131'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f94ef358bb3e91d517446454edff6535bcfe8e4a', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c4d7afb6a5986b04505aca4466ae1951686c80f6', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b761c9b652af2107cfbc33efd19be0ce41daa33e'}",
            "dataset":"osv",
            "summary":"Heap OOB and null pointer dereference in `RaggedTensorToTensor` ### Impact\nDue to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty:\n\n```python\nimport tensorflow as tf\n\nshape = tf.constant([-1, -1], shape=[2], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\ndefault_value = tf.constant(404, dtype=tf.int64)\nrow = tf.constant([269, 404, 0, 0, 0, 0, 0], shape=[7], dtype=tf.int64)\nrows = [row]\ntypes = ['ROW_SPLITS']\n\ntf.raw_ops.RaggedTensorToTensor(\n  shape=shape, values=values, default_value=default_value, \n  row_partition_tensors=rows, row_partition_types=types)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/656e7673b14acd7835dc778867f84916c6d1cac2\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones.\n\nThere are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything.\n\n### Patches\nWe have patched the issue in GitHub commit [b761c9b652af2107cfbc33efd19be0ce41daa33e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b761c9b652af2107cfbc33efd19be0ce41daa33e) followed by GitHub commit [f94ef358bb3e91d517446454edff6535bcfe8e4a](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f94ef358bb3e91d517446454edff6535bcfe8e4a) and GitHub commit [c4d7afb6a5986b04505aca4466ae1951686c80f6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c4d7afb6a5986b04505aca4466ae1951686c80f6).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":3,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b761c9b652af2107cfbc33efd19be0ce41daa33e",
            "commit_sha":"b761c9b652af2107cfbc33efd19be0ce41daa33e",
            "patch":"MULTI",
            "chain_ord":"['f94ef358bb3e91d517446454edff6535bcfe8e4a', 'b761c9b652af2107cfbc33efd19be0ce41daa33e', 'c4d7afb6a5986b04505aca4466ae1951686c80f6']",
            "before_first_fix_commit":"{'50034ad2d55b10eb9d4593374546710b12f134e1'}",
            "last_fix_commit":"c4d7afb6a5986b04505aca4466ae1951686c80f6",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/15\/2021, 20:28:49",
            "message":"Fix `tf.raw_ops.RaggedTensorToTensor` failing CHECK.\n\nPiperOrigin-RevId: 368706628\nChange-Id: I5c9ea4833f38835ee183ca50d63251dc89c9f3bc",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 9, 'total': 20}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc': {'additions': 11, 'deletions': 9, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b761c9b652af2107cfbc33efd19be0ce41daa33e\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_tensor_op.cc', 'patch': '@@ -208,7 +208,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n   }\\n \\n   void CalculateOutputIndexRowSplit(\\n-      const RowPartitionTensor& row_split,\\n+      OpKernelContext* context, const RowPartitionTensor& row_split,\\n       const vector<INDEX_TYPE>& parent_output_index,\\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\\n       vector<INDEX_TYPE>* result) {\\n@@ -233,7 +233,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n       }\\n     }\\n     if (row_split_size > 0) {\\n-      DCHECK_EQ(result->size(), row_split(row_split_size - 1));\\n+      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\\n+                  errors::InvalidArgument(\"Invalid row split size.\"));\\n     }\\n   }\\n \\n@@ -259,7 +260,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n   \/\/ result[7] = -1 because parent_output_index[value_rowids[6]] == -1\\n   \/\/ result[8] = parent_output_index[value_rowids[7]]\\n   void CalculateOutputIndexValueRowID(\\n-      const RowPartitionTensor& value_rowids,\\n+      OpKernelContext* context, const RowPartitionTensor& value_rowids,\\n       const vector<INDEX_TYPE>& parent_output_index,\\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\\n       vector<INDEX_TYPE>* result) {\\n@@ -293,7 +294,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n       }\\n       result->push_back(current_output_index);\\n     }\\n-    DCHECK_EQ(result->size(), value_rowids.size());\\n+    OP_REQUIRES(context, result->size() == value_rowids.size(),\\n+                errors::InvalidArgument(\"Invalid row ids.\"));\\n   }\\n \\n   Status CalculateOutputIndex(OpKernelContext* context, int dimension,\\n@@ -307,13 +309,13 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n     switch (partition_type) {\\n       case RowPartitionType::VALUE_ROWIDS:\\n         CalculateOutputIndexValueRowID(\\n-            row_partition_tensor, parent_output_index, output_index_multiplier,\\n-            output_size, result);\\n+            context, row_partition_tensor, parent_output_index,\\n+            output_index_multiplier, output_size, result);\\n         return tensorflow::Status::OK();\\n       case RowPartitionType::ROW_SPLITS:\\n-        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,\\n-                                     output_index_multiplier, output_size,\\n-                                     result);\\n+        CalculateOutputIndexRowSplit(\\n+            context, row_partition_tensor, parent_output_index,\\n+            output_index_multiplier, output_size, result);\\n         return tensorflow::Status::OK();\\n       default:\\n         return errors::InvalidArgument('}}",
            "message_norm":"fix `tf.raw_ops.raggedtensortotensor` failing check.\n\npiperorigin-revid: 368706628\nchange-id: i5c9ea4833f38835ee183ca50d63251dc89c9f3bc",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('368706628', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc'])",
            "num_files":1.0,
            "patch_content":"From b761c9b652af2107cfbc33efd19be0ce41daa33e Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Thu, 15 Apr 2021 13:28:49 -0700\nSubject: [PATCH] Fix `tf.raw_ops.RaggedTensorToTensor` failing CHECK.\n\nPiperOrigin-RevId: 368706628\nChange-Id: I5c9ea4833f38835ee183ca50d63251dc89c9f3bc\n---\n ...\/kernels\/ragged_tensor_to_tensor_op.cc     | 20 ++++++++++---------\n 1 file changed, 11 insertions(+), 9 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc b\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc\nindex 433d910f6090cd..434c853b63daa4 100644\n--- a\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc\n+++ b\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc\n@@ -208,7 +208,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n   }\n \n   void CalculateOutputIndexRowSplit(\n-      const RowPartitionTensor& row_split,\n+      OpKernelContext* context, const RowPartitionTensor& row_split,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -233,7 +233,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n       }\n     }\n     if (row_split_size > 0) {\n-      DCHECK_EQ(result->size(), row_split(row_split_size - 1));\n+      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\n+                  errors::InvalidArgument(\"Invalid row split size.\"));\n     }\n   }\n \n@@ -259,7 +260,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n   \/\/ result[7] = -1 because parent_output_index[value_rowids[6]] == -1\n   \/\/ result[8] = parent_output_index[value_rowids[7]]\n   void CalculateOutputIndexValueRowID(\n-      const RowPartitionTensor& value_rowids,\n+      OpKernelContext* context, const RowPartitionTensor& value_rowids,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -293,7 +294,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n       }\n       result->push_back(current_output_index);\n     }\n-    DCHECK_EQ(result->size(), value_rowids.size());\n+    OP_REQUIRES(context, result->size() == value_rowids.size(),\n+                errors::InvalidArgument(\"Invalid row ids.\"));\n   }\n \n   Status CalculateOutputIndex(OpKernelContext* context, int dimension,\n@@ -307,13 +309,13 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n     switch (partition_type) {\n       case RowPartitionType::VALUE_ROWIDS:\n         CalculateOutputIndexValueRowID(\n-            row_partition_tensor, parent_output_index, output_index_multiplier,\n-            output_size, result);\n+            context, row_partition_tensor, parent_output_index,\n+            output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       case RowPartitionType::ROW_SPLITS:\n-        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,\n-                                     output_index_multiplier, output_size,\n-                                     result);\n+        CalculateOutputIndexRowSplit(\n+            context, row_partition_tensor, parent_output_index,\n+            output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       default:\n         return errors::InvalidArgument("
        },
        {
            "index":130,
            "vuln_id":"GHSA-6qgm-fv6v-rfpv",
            "cwe_id":"{'CWE-120', 'CWE-119'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ecf768cbe50cedc0a45ce1ee223146a3d3d26d23'}",
            "dataset":"osv",
            "summary":"Overflow\/denial of service in `tf.raw_ops.ReverseSequence` ### Impact\nThe implementation of `tf.raw_ops.ReverseSequence` allows for stack overflow and\/or `CHECK`-fail based denial of service.\n\n```python\nimport tensorflow as tf\n\ninput = tf.zeros([1, 1, 1], dtype=tf.int32)\nseq_lengths = tf.constant([0], shape=[1], dtype=tf.int32)\n\ntf.raw_ops.ReverseSequence(\n    input=input, seq_lengths=seq_lengths, seq_dim=-2, batch_dim=0)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5b3b071975e01f0d250c928b2a8f901cd53b90a7\/tensorflow\/core\/kernels\/reverse_sequence_op.cc#L114-L118) fails to validate that `seq_dim` and `batch_dim` arguments are valid.\n  \nNegative values for `seq_dim` can result in stack overflow or `CHECK`-failure, depending on the version of Eigen code used to implement the operation. Similar behavior can be exhibited by invalid values of `batch_dim`.\n  \n### Patches\nWe have patched the issue in GitHub commit [ecf768cbe50cedc0a45ce1ee223146a3d3d26d23](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ecf768cbe50cedc0a45ce1ee223146a3d3d26d23).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ecf768cbe50cedc0a45ce1ee223146a3d3d26d23",
            "commit_sha":"ecf768cbe50cedc0a45ce1ee223146a3d3d26d23",
            "patch":"SINGLE",
            "chain_ord":"['ecf768cbe50cedc0a45ce1ee223146a3d3d26d23']",
            "before_first_fix_commit":"{'5b3b071975e01f0d250c928b2a8f901cd53b90a7'}",
            "last_fix_commit":"ecf768cbe50cedc0a45ce1ee223146a3d3d26d23",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 19:07:57",
            "message":"Add missing validations to reverse_sequence_op\n\nPiperOrigin-RevId: 372178683\nChange-Id: Iac97ebab5b342f1262c77a7d9bcb4267b305ce5b",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/reverse_sequence_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ecf768cbe50cedc0a45ce1ee223146a3d3d26d23\/tensorflow%2Fcore%2Fkernels%2Freverse_sequence_op.cc', 'patch': '@@ -115,6 +115,10 @@ class ReverseSequenceOp : public OpKernel {\\n       : OpKernel(context) {\\n     OP_REQUIRES_OK(context, context->GetAttr(\"batch_dim\", &batch_dim_));\\n     OP_REQUIRES_OK(context, context->GetAttr(\"seq_dim\", &seq_dim_));\\n+    OP_REQUIRES(context, batch_dim_ >= 0,\\n+                errors::InvalidArgument(\"Invalid batch_dim \", batch_dim_));\\n+    OP_REQUIRES(context, seq_dim_ >= 0,\\n+                errors::InvalidArgument(\"Invalid seq_dim \", seq_dim_));\\n   }\\n \\n   void Compute(OpKernelContext* context) override {'}}",
            "message_norm":"add missing validations to reverse_sequence_op\n\npiperorigin-revid: 372178683\nchange-id: iac97ebab5b342f1262c77a7d9bcb4267b305ce5b",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validations', 'SECWORD', ''), ('372178683', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/reverse_sequence_op.cc'])",
            "num_files":1.0,
            "patch_content":"From ecf768cbe50cedc0a45ce1ee223146a3d3d26d23 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 5 May 2021 12:07:57 -0700\nSubject: [PATCH] Add missing validations to reverse_sequence_op\n\nPiperOrigin-RevId: 372178683\nChange-Id: Iac97ebab5b342f1262c77a7d9bcb4267b305ce5b\n---\n tensorflow\/core\/kernels\/reverse_sequence_op.cc | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/reverse_sequence_op.cc b\/tensorflow\/core\/kernels\/reverse_sequence_op.cc\nindex b5b62bc76ca524..1282deb26e8cd6 100644\n--- a\/tensorflow\/core\/kernels\/reverse_sequence_op.cc\n+++ b\/tensorflow\/core\/kernels\/reverse_sequence_op.cc\n@@ -115,6 +115,10 @@ class ReverseSequenceOp : public OpKernel {\n       : OpKernel(context) {\n     OP_REQUIRES_OK(context, context->GetAttr(\"batch_dim\", &batch_dim_));\n     OP_REQUIRES_OK(context, context->GetAttr(\"seq_dim\", &seq_dim_));\n+    OP_REQUIRES(context, batch_dim_ >= 0,\n+                errors::InvalidArgument(\"Invalid batch_dim \", batch_dim_));\n+    OP_REQUIRES(context, seq_dim_ >= 0,\n+                errors::InvalidArgument(\"Invalid seq_dim \", seq_dim_));\n   }\n \n   void Compute(OpKernelContext* context) override {"
        },
        {
            "index":62,
            "vuln_id":"GHSA-393f-2jr3-cp69",
            "cwe_id":"{'CWE-754'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b432a38fe0e1b4b904a6c222cbce794c39703e87'}",
            "dataset":"osv",
            "summary":"CHECK-fail in DrawBoundingBoxes ### Impact\nAn attacker can trigger a denial of service via a `CHECK` failure by passing an empty image to `tf.raw_ops.DrawBoundingBoxes`:\n\n```python\nimport tensorflow as tf\n\nimages = tf.fill([53, 0, 48, 1], 0.)\nboxes = tf.fill([53, 31, 4], 0.)\nboxes = tf.Variable(boxes)\nboxes[0, 0, 0].assign(3.90621)\ntf.raw_ops.DrawBoundingBoxes(images=images, boxes=boxes)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ea34a18dc3f5c8d80a40ccca1404f343b5d55f91\/tensorflow\/core\/kernels\/image\/draw_bounding_box_op.cc#L148-L165) uses `CHECK_*` assertions instead of `OP_REQUIRES` to validate user controlled inputs. Whereas `OP_REQUIRES` allows returning an error condition back to the user, the `CHECK_*` macros result in a crash if the condition is false, similar to `assert`.\n\n```cc\nconst int64 max_box_row_clamp = std::min<int64>(max_box_row, height - 1);\n... \nCHECK_GE(max_box_row_clamp, 0);\n``` \n    \nIn this case, `height` is 0 from the `images` input. This results in `max_box_row_clamp` being negative and the assertion being falsified, followed by aborting program execution.\n    \n### Patches\nWe have patched the issue in GitHub commit [b432a38fe0e1b4b904a6c222cbce794c39703e87](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b432a38fe0e1b4b904a6c222cbce794c39703e87).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b432a38fe0e1b4b904a6c222cbce794c39703e87",
            "commit_sha":"b432a38fe0e1b4b904a6c222cbce794c39703e87",
            "patch":"SINGLE",
            "chain_ord":"['b432a38fe0e1b4b904a6c222cbce794c39703e87']",
            "before_first_fix_commit":"{'ea34a18dc3f5c8d80a40ccca1404f343b5d55f91'}",
            "last_fix_commit":"b432a38fe0e1b4b904a6c222cbce794c39703e87",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/21\/2021, 22:57:36",
            "message":"Fix overflow CHECK issue with `tf.raw_ops.DrawBoundingBoxes`.\n\nPiperOrigin-RevId: 369753591\nChange-Id: I3b45fc98ee0d28a3c20b7e9c995aa647c976ec40",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 36, 'deletions': 12, 'total': 48}",
            "files":"{'tensorflow\/core\/kernels\/image\/draw_bounding_box_op.cc': {'additions': 36, 'deletions': 12, 'changes': 48, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b432a38fe0e1b4b904a6c222cbce794c39703e87\/tensorflow%2Fcore%2Fkernels%2Fimage%2Fdraw_bounding_box_op.cc', 'patch': '@@ -147,22 +147,46 @@ class DrawBoundingBoxesOp : public OpKernel {\\n \\n         \/\/ At this point, {min,max}_box_{row,col}_clamp are inside the\\n         \/\/ image.\\n-        CHECK_GE(min_box_row_clamp, 0);\\n-        CHECK_GE(max_box_row_clamp, 0);\\n-        CHECK_LT(min_box_row_clamp, height);\\n-        CHECK_LT(max_box_row_clamp, height);\\n-        CHECK_GE(min_box_col_clamp, 0);\\n-        CHECK_GE(max_box_col_clamp, 0);\\n-        CHECK_LT(min_box_col_clamp, width);\\n-        CHECK_LT(max_box_col_clamp, width);\\n+        OP_REQUIRES(\\n+            context, min_box_row_clamp >= 0,\\n+            errors::InvalidArgument(\"Min box row clamp is less than 0.\"));\\n+        OP_REQUIRES(\\n+            context, max_box_row_clamp >= 0,\\n+            errors::InvalidArgument(\"Max box row clamp is less than 0.\"));\\n+        OP_REQUIRES(context, min_box_row_clamp <= height,\\n+                    errors::InvalidArgument(\\n+                        \"Min box row clamp is greater than height.\"));\\n+        OP_REQUIRES(context, max_box_row_clamp <= height,\\n+                    errors::InvalidArgument(\\n+                        \"Max box row clamp is greater than height.\"));\\n+\\n+        OP_REQUIRES(\\n+            context, min_box_col_clamp >= 0,\\n+            errors::InvalidArgument(\"Min box col clamp is less than 0.\"));\\n+        OP_REQUIRES(\\n+            context, max_box_col_clamp >= 0,\\n+            errors::InvalidArgument(\"Max box col clamp is less than 0.\"));\\n+        OP_REQUIRES(context, min_box_col_clamp <= width,\\n+                    errors::InvalidArgument(\\n+                        \"Min box col clamp is greater than width.\"));\\n+        OP_REQUIRES(context, max_box_col_clamp <= width,\\n+                    errors::InvalidArgument(\\n+                        \"Max box col clamp is greater than width.\"));\\n \\n         \/\/ At this point, the min_box_row and min_box_col are either\\n         \/\/ in the image or above\/left of it, and max_box_row and\\n         \/\/ max_box_col are either in the image or below\/right or it.\\n-        CHECK_LT(min_box_row, height);\\n-        CHECK_GE(max_box_row, 0);\\n-        CHECK_LT(min_box_col, width);\\n-        CHECK_GE(max_box_col, 0);\\n+\\n+        OP_REQUIRES(\\n+            context, min_box_row <= height,\\n+            errors::InvalidArgument(\"Min box row is greater than height.\"));\\n+        OP_REQUIRES(context, max_box_row >= 0,\\n+                    errors::InvalidArgument(\"Max box row is less than 0.\"));\\n+        OP_REQUIRES(\\n+            context, min_box_col <= width,\\n+            errors::InvalidArgument(\"Min box col is greater than width.\"));\\n+        OP_REQUIRES(context, max_box_col >= 0,\\n+                    errors::InvalidArgument(\"Max box col is less than 0.\"));\\n \\n         \/\/ Draw top line.\\n         if (min_box_row >= 0) {'}}",
            "message_norm":"fix overflow check issue with `tf.raw_ops.drawboundingboxes`.\n\npiperorigin-revid: 369753591\nchange-id: i3b45fc98ee0d28a3c20b7e9c995aa647c976ec40",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('369753591', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/image\/draw_bounding_box_op.cc'])",
            "num_files":1.0,
            "patch_content":"From b432a38fe0e1b4b904a6c222cbce794c39703e87 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Wed, 21 Apr 2021 15:57:36 -0700\nSubject: [PATCH] Fix overflow CHECK issue with `tf.raw_ops.DrawBoundingBoxes`.\n\nPiperOrigin-RevId: 369753591\nChange-Id: I3b45fc98ee0d28a3c20b7e9c995aa647c976ec40\n---\n ...\/kernels\/image\/draw_bounding_box_op.cc     | 48 ++++++++++++++-----\n 1 file changed, 36 insertions(+), 12 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/image\/draw_bounding_box_op.cc b\/tensorflow\/core\/kernels\/image\/draw_bounding_box_op.cc\nindex 30de99b7d560a2..73db76333f0862 100644\n--- a\/tensorflow\/core\/kernels\/image\/draw_bounding_box_op.cc\n+++ b\/tensorflow\/core\/kernels\/image\/draw_bounding_box_op.cc\n@@ -147,22 +147,46 @@ class DrawBoundingBoxesOp : public OpKernel {\n \n         \/\/ At this point, {min,max}_box_{row,col}_clamp are inside the\n         \/\/ image.\n-        CHECK_GE(min_box_row_clamp, 0);\n-        CHECK_GE(max_box_row_clamp, 0);\n-        CHECK_LT(min_box_row_clamp, height);\n-        CHECK_LT(max_box_row_clamp, height);\n-        CHECK_GE(min_box_col_clamp, 0);\n-        CHECK_GE(max_box_col_clamp, 0);\n-        CHECK_LT(min_box_col_clamp, width);\n-        CHECK_LT(max_box_col_clamp, width);\n+        OP_REQUIRES(\n+            context, min_box_row_clamp >= 0,\n+            errors::InvalidArgument(\"Min box row clamp is less than 0.\"));\n+        OP_REQUIRES(\n+            context, max_box_row_clamp >= 0,\n+            errors::InvalidArgument(\"Max box row clamp is less than 0.\"));\n+        OP_REQUIRES(context, min_box_row_clamp <= height,\n+                    errors::InvalidArgument(\n+                        \"Min box row clamp is greater than height.\"));\n+        OP_REQUIRES(context, max_box_row_clamp <= height,\n+                    errors::InvalidArgument(\n+                        \"Max box row clamp is greater than height.\"));\n+\n+        OP_REQUIRES(\n+            context, min_box_col_clamp >= 0,\n+            errors::InvalidArgument(\"Min box col clamp is less than 0.\"));\n+        OP_REQUIRES(\n+            context, max_box_col_clamp >= 0,\n+            errors::InvalidArgument(\"Max box col clamp is less than 0.\"));\n+        OP_REQUIRES(context, min_box_col_clamp <= width,\n+                    errors::InvalidArgument(\n+                        \"Min box col clamp is greater than width.\"));\n+        OP_REQUIRES(context, max_box_col_clamp <= width,\n+                    errors::InvalidArgument(\n+                        \"Max box col clamp is greater than width.\"));\n \n         \/\/ At this point, the min_box_row and min_box_col are either\n         \/\/ in the image or above\/left of it, and max_box_row and\n         \/\/ max_box_col are either in the image or below\/right or it.\n-        CHECK_LT(min_box_row, height);\n-        CHECK_GE(max_box_row, 0);\n-        CHECK_LT(min_box_col, width);\n-        CHECK_GE(max_box_col, 0);\n+\n+        OP_REQUIRES(\n+            context, min_box_row <= height,\n+            errors::InvalidArgument(\"Min box row is greater than height.\"));\n+        OP_REQUIRES(context, max_box_row >= 0,\n+                    errors::InvalidArgument(\"Max box row is less than 0.\"));\n+        OP_REQUIRES(\n+            context, min_box_col <= width,\n+            errors::InvalidArgument(\"Min box col is greater than width.\"));\n+        OP_REQUIRES(context, max_box_col >= 0,\n+                    errors::InvalidArgument(\"Max box col is less than 0.\"));\n \n         \/\/ Draw top line.\n         if (min_box_row >= 0) {"
        },
        {
            "index":479,
            "vuln_id":"GHSA-47vg-483w-hp3m",
            "cwe_id":"{'CWE-384'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/filegator\/filegator\/commit\/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225'}",
            "dataset":"osv",
            "summary":"Improper user session handling in filegator FileGator prior to version 7.8.0 is vulnerable to session fixation.",
            "published_date":"2022-05-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/filegator\/filegator",
            "commit_href":"https:\/\/github.com\/filegator\/filegator\/commit\/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
            "commit_sha":"fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
            "patch":"SINGLE",
            "chain_ord":"['fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225']",
            "before_first_fix_commit":"{'6e2b68f17f48cdc1d6a4a93a2369d2069fe64989'}",
            "last_fix_commit":"fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/24\/2022, 11:08:43",
            "message":"regenerate session on user update",
            "author":"Milos Stojanovic",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'backend\/Services\/Auth\/Adapters\/JsonFile.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/filegator\/filegator\/raw\/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225\/backend%2FServices%2FAuth%2FAdapters%2FJsonFile.php', 'patch': \"@@ -53,7 +53,7 @@ public function user(): ?User\\n \\n         if ($user) {\\n             foreach ($this->getUsers() as $u) {\\n-                if ($u['username'] == $user->getUsername() && $hash == $u['password']) {\\n+                if ($u['username'] == $user->getUsername() && $hash == $u['password'].$u['permissions'].$u['homedir'].$u['role']) {\\n                     return $user;\\n                 }\\n             }\\n@@ -70,7 +70,7 @@ public function authenticate($username, $password): bool\\n             if ($u['username'] == $username && $this->verifyPassword($password, $u['password'])) {\\n                 $user = $this->mapToUserObject($u);\\n                 $this->store($user);\\n-                $this->session->set(self::SESSION_HASH, $u['password']);\\n+                $this->session->set(self::SESSION_HASH, $u['password'].$u['permissions'].$u['homedir'].$u['role']);\\n \\n                 return true;\\n             }\"}}",
            "message_norm":"regenerate session on user update",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['backend\/Services\/Auth\/Adapters\/JsonFile.php'])",
            "num_files":1.0,
            "patch_content":"From fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225 Mon Sep 17 00:00:00 2001\nFrom: Milos Stojanovic <alcalbg@gmail.com>\nDate: Tue, 24 May 2022 13:08:43 +0200\nSubject: [PATCH] regenerate session on user update\n\n---\n backend\/Services\/Auth\/Adapters\/JsonFile.php | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/backend\/Services\/Auth\/Adapters\/JsonFile.php b\/backend\/Services\/Auth\/Adapters\/JsonFile.php\nindex b9c38a35..af16d508 100644\n--- a\/backend\/Services\/Auth\/Adapters\/JsonFile.php\n+++ b\/backend\/Services\/Auth\/Adapters\/JsonFile.php\n@@ -53,7 +53,7 @@ public function user(): ?User\n \n         if ($user) {\n             foreach ($this->getUsers() as $u) {\n-                if ($u['username'] == $user->getUsername() && $hash == $u['password']) {\n+                if ($u['username'] == $user->getUsername() && $hash == $u['password'].$u['permissions'].$u['homedir'].$u['role']) {\n                     return $user;\n                 }\n             }\n@@ -70,7 +70,7 @@ public function authenticate($username, $password): bool\n             if ($u['username'] == $username && $this->verifyPassword($password, $u['password'])) {\n                 $user = $this->mapToUserObject($u);\n                 $this->store($user);\n-                $this->session->set(self::SESSION_HASH, $u['password']);\n+                $this->session->set(self::SESSION_HASH, $u['password'].$u['permissions'].$u['homedir'].$u['role']);\n \n                 return true;\n             }"
        },
        {
            "index":832,
            "vuln_id":"GHSA-hm45-mgqm-gjm4",
            "cwe_id":"{'CWE-79'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/commit\/a6b9785338003ec87fb75305e7d1cc2d40c7ab91', 'https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/commit\/99d88b840674674166ce005b784ae8e31e955ab1'}",
            "dataset":"osv",
            "summary":"Remote Code Execution (RCE) Exploit on Cross Site Scripting (XSS) Vulnerability ### Impact\nA RCE exploit has been discovered in the Red Discord Bot - Dashboard Webserver: this exploit allows Discord users with specially crafted Server names and Usernames\/Nicknames to inject code into the webserver front-end code.  By abusing this exploit, it's possible to perform destructive actions and\/or access sensitive information.\n\n### Patches\nThis high severity exploit has been fixed on version `0.1.7a`.\n\n### Workarounds\nThere are no workarounds, bot owners must upgrade their relevant packages (Dashboard module and Dashboard webserver) in order to patch this issue\n\n### References\n- 99d88b8\n- a6b9785\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Cog-Creators\/Red-Dashboard](https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/issues\/new\/choose)\n* Over on the official [Red Server](https:\/\/discord.gg\/red) or at the Third Party Server [Toxic Layer](https:\/\/discord.gg\/vQZTdB9)",
            "published_date":"2020-12-08",
            "chain_len":2,
            "project":"https:\/\/github.com\/Cog-Creators\/Red-Dashboard",
            "commit_href":"https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/commit\/a6b9785338003ec87fb75305e7d1cc2d40c7ab91",
            "commit_sha":"a6b9785338003ec87fb75305e7d1cc2d40c7ab91",
            "patch":"MULTI",
            "chain_ord":"['99d88b840674674166ce005b784ae8e31e955ab1', 'a6b9785338003ec87fb75305e7d1cc2d40c7ab91']",
            "before_first_fix_commit":"{'261f00f52bbfee4db67f624fd7409bf08124a6c4'}",
            "last_fix_commit":"a6b9785338003ec87fb75305e7d1cc2d40c7ab91",
            "chain_ord_pos":2.0,
            "commit_datetime":"12\/01\/2020, 14:15:49",
            "message":"[UI] Fix SelectPicker not rendering properly",
            "author":"NeuroAssassin",
            "comments":null,
            "stats":"{'additions': 41, 'deletions': 16, 'total': 57}",
            "files":"{'reddash\/app\/home\/templates\/guild.html': {'additions': 41, 'deletions': 16, 'changes': 57, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Cog-Creators\/Red-Dashboard\/raw\/a6b9785338003ec87fb75305e7d1cc2d40c7ab91\/reddash%2Fapp%2Fhome%2Ftemplates%2Fguild.html', 'patch': '@@ -930,20 +930,20 @@ <h5>{{ data[\\'message\\'] }}<\/h5>\\n             img.attr(\"src\", `${img.attr(\"data-src-url\")}png`)\\r\\n         }\\r\\n     }\\r\\n+\\r\\n+    function safe(str) {\\r\\n+        return String(str).replace(\/&\/g, \\'&amp;\\').replace(\/<\/g, \\'&lt;\\').replace(\/>\/g, \\'&gt;\\').replace(\/\"\/g, \\'&quot;\\');\\r\\n+    }\\r\\n <\/script>\\r\\n \\r\\n {% if data[\\'status\\'] == 1 and data[\\'data\\'][\\'status\\'] == 1 %}\\r\\n \\r\\n-{% if \\'aliascc\\' in data[\\'data\\'][\\'permslist\\'] %}\\r\\n+{% if \\'aliascc\\' in data[\\'data\\'][\\'permslist\\'] and false%}\\r\\n <script>\\r\\n     \/* ---------------------------------------------------------------------------------------------------------------------\\r\\n                                                         Aliases group\\r\\n        --------------------------------------------------------------------------------------------------------------------- *\/\\r\\n \\r\\n-    function safe(str) {\\r\\n-        return String(str).replace(\/&\/g, \\'&amp;\\').replace(\/<\/g, \\'&lt;\\').replace(\/>\/g, \\'&gt;\\').replace(\/\"\/g, \\'&quot;\\');\\r\\n-    }\\r\\n-\\r\\n     \/\/ Alias modal\\r\\n     $(document).on(\\'click\\', \\'.editaliasbutton\\', function () {\\r\\n         var command = $(this).parent().parent().data(\"command\")\\r\\n@@ -1186,28 +1186,35 @@ <h5>{{ data[\\'message\\'] }}<\/h5>\\n             } else if (json.status === 1 && json.data.status === 0) {\\r\\n                 $(\"#targetstatus\").html(`{{ _(\\'Failed to fetch targets\\') }}: ${json.data.message}`)\\r\\n             } else {\\r\\n+                let big_ol_dict = {}\\r\\n                 select.html(\"\")\\r\\n \\r\\n                 var chopt = [`<optgroup label=\"{{ _(\\'Channels\\') }}\">`]\\r\\n                 for (let [id, name] of json.data.CHANNELS) {\\r\\n-                    chopt.push(`<option value=${id}>${name}<\/option>`)\\r\\n+                    chopt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...<\/option>`)\\r\\n+                    big_ol_dict[id] = name\\r\\n                 }\\r\\n                 chopt.push(\"<\/optgroup>\")\\r\\n                 select.append(chopt.join(\"\"))\\r\\n \\r\\n                 var ropt = [`<optgroup label=\"{{ _(\\'Roles\\') }}\">`]\\r\\n                 for (let [id, name] of json.data.ROLES) {\\r\\n-                    ropt.push(`<option value=${id}>${name}<\/option>`)\\r\\n+                    ropt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...<\/option>`)\\r\\n+                    big_ol_dict[id] = name\\r\\n                 }\\r\\n                 ropt.push(\"<\/optgroup>\")\\r\\n                 select.append(ropt.join(\"\"))\\r\\n \\r\\n                 var uopt = [`<optgroup label=\"{{ _(\\'Users\\') }}\">`]\\r\\n                 for (let [id, name] of json.data.USERS) {\\r\\n-                    uopt.push(`<option value=${id}>${name}<\/option>`)\\r\\n+                    uopt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...<\/option>`)\\r\\n+                    big_ol_dict[id] = name\\r\\n                 }\\r\\n                 uopt.push(\"<\/optgroup>\")\\r\\n                 select.append(uopt.join(\"\"))\\r\\n+                for (let [id, name] of Object.entries(big_ol_dict)) {\\r\\n+                    $(`.selectpicker-element-${id}`).text(name)\\r\\n+                }\\r\\n             }\\r\\n             select.selectpicker({ title: \"{{ _(\\'Choose target\\') }}\" })\\r\\n             select.removeAttr(\"disabled\")\\r\\n@@ -1299,18 +1306,24 @@ <h5>{{ data[\\'message\\'] }}<\/h5>\\n                 $(\"#rulesdiv\").html(\"\")\\r\\n                 var overall = [\\'<h3 style=\"margin-bottom: 10px\">{{ _(\"Cog rules\") }}<\/h3>\\']\\r\\n                 var allcoglines = [\"<ul>\"]\\r\\n+\\r\\n+                let big_ol_dict_two = {}\\r\\n+                let cog_counter = 0\\r\\n+\\r\\n                 for (let [cog, rules] of Object.entries(json.data.COG)) {\\r\\n                     var coglines = []\\r\\n                     for (let rule of rules) {\\r\\n                         if (rule.type === \"Default\") {\\r\\n                             coglines.unshift(`<li>{{ _(\\'By default, users are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}<\/code> {{ _(\\'cog\\') }}.<\/li>`)\\r\\n                         } else if (rule.type === \"Role\") {\\r\\n-                            coglines.push(`<li>{{ _(\\'Users with the\\') }} <code>${rule.name}<\/code> {{ _(\\'role\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}<\/code> {{ _(\\'cog\\') }}.<\/li>`)\\r\\n+                            coglines.push(`<li>{{ _(\\'Users with the\\') }} <code id=\"cog-rules-${cog_counter}\">Loading...<\/code> {{ _(\\'role\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}<\/code> {{ _(\\'cog\\') }}.<\/li>`)\\r\\n                         } else if (rule.type === \"Channel\") {\\r\\n-                            coglines.push(`<li>{{ _(\\'Users in the\\') }} <code>${rule.name}<\/code> {{ _(\\'channel\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}<\/code> {{ _(\\'cog\\') }}.<\/li>`)\\r\\n+                            coglines.push(`<li>{{ _(\\'Users in the\\') }} <code id=\"cog-rules-${cog_counter}\">Loading...<\/code> {{ _(\\'channel\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}<\/code> {{ _(\\'cog\\') }}.<\/li>`)\\r\\n                         } else {\\r\\n-                            coglines.push(`<li>{{ _(\\'User\\') }} <code>${rule.name}<\/code> (${rule.id}) {{ _(\\'is\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}<\/code> {{ _(\\'cog\\') }}.<\/li>`)\\r\\n+                            coglines.push(`<li>{{ _(\\'User\\') }} <code id=\"cog-rules-${cog_counter}\">Loading...<\/code> (${rule.id}) {{ _(\\'is\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}<\/code> {{ _(\\'cog\\') }}.<\/li>`)\\r\\n                         }\\r\\n+                        big_ol_dict_two[`cog-rules-${cog_counter}`] = rule.name\\r\\n+                        cog_counter += 1\\r\\n                     }\\r\\n                     if (coglines) {\\r\\n                         allcoglines = allcoglines.concat(coglines)\\r\\n@@ -1324,18 +1337,23 @@ <h5>{{ data[\\'message\\'] }}<\/h5>\\n \\r\\n                 overall.push(\\'<h3 style=\"margin-bottom: 10px\">{{ _(\"Command rules\") }}<\/h3>\\')\\r\\n                 var allcmdlines = [\"<ul>\"]\\r\\n+\\r\\n+                let cmd_counter = 0\\r\\n+\\r\\n                 for (let [cmd, rules] of Object.entries(json.data.COMMAND)) {\\r\\n                     var cmdlines = []\\r\\n                     for (let rule of rules) {\\r\\n                         if (rule.type === \"Default\") {\\r\\n                             cmdlines.unshift(`<li>{{ _(\\'By default, users are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}<\/code> {{ _(\\'command\\') }}.<\/li>`)\\r\\n                         } else if (rule.type === \"Role\") {\\r\\n-                            cmdlines.push(`<li>{{ _(\\'Users with the\\') }} <code>${rule.name}<\/code> {{ _(\\'role\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}<\/code> {{ _(\\'command\\') }}.<\/li>`)\\r\\n+                            cmdlines.push(`<li>{{ _(\\'Users with the\\') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...<\/code> {{ _(\\'role\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}<\/code> {{ _(\\'command\\') }}.<\/li>`)\\r\\n                         } else if (rule.type === \"Channel\") {\\r\\n-                            cmdlines.push(`<li>{{ _(\\'Users in the\\') }} <code>${rule.name}<\/code> {{ _(\\'channel\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}<\/code> {{ _(\\'command\\') }}.<\/li>`)\\r\\n+                            cmdlines.push(`<li>{{ _(\\'Users in the\\') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...<\/code> {{ _(\\'channel\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}<\/code> {{ _(\\'command\\') }}.<\/li>`)\\r\\n                         } else {\\r\\n-                            cmdlines.push(`<li>{{ _(\\'User\\') }} <code>${rule.name}<\/code> (${rule.id}) {{ _(\\'is\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}<\/code> {{ _(\\'command\\') }}.<\/li>`)\\r\\n+                            cmdlines.push(`<li>{{ _(\\'User\\') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...<\/code> (${rule.id}) {{ _(\\'is\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}<\/code> {{ _(\\'command\\') }}.<\/li>`)\\r\\n                         }\\r\\n+                        big_ol_dict_two[`cmd-rules-${cmd_counter}`] = rule.name\\r\\n+                        cmd_counter += 1\\r\\n                     }\\r\\n                     if (cmdlines) {\\r\\n                         allcmdlines = allcmdlines.concat(cmdlines)\\r\\n@@ -1347,6 +1365,9 @@ <h5>{{ data[\\'message\\'] }}<\/h5>\\n                 }\\r\\n                 overall = overall.concat(allcmdlines)\\r\\n                 $(\"#rulesdiv\").html(overall.join(\"\"))\\r\\n+                for (let [id, name] of Object.entries(big_ol_dict_two)) {\\r\\n+                    $(`#${id}`).text(name)\\r\\n+                }\\r\\n                 $(\"#fetchrulesstatus\").html(\"{{ _(\\'Refreshed rules\\') }}.\")\\r\\n             }\\r\\n         }\\r\\n@@ -1378,18 +1399,20 @@ <h5>{{ data[\\'message\\'] }}<\/h5>\\n \\r\\n     $(document).on(\\'click\\', \\'.adminroleoption\\', function () {\\r\\n         var elm = $(this)\\r\\n+        let random_number = Math.floor(Math.random() * Math.floor(100000))\\r\\n         $(\"#adminrolelist\").append(`\\r\\n                 <li>\\r\\n                     <div class=\"row\">\\r\\n                         <div class=\"col-md-10 col-8\">\\r\\n-                            <input class=\"form-control adminroleinput\" value=\"${elm.text()}\" disabled=True data-id=\"${elm.attr(\"data-id\")}\">\\r\\n+                            <input class=\"form-control adminroleinput\" value=\"Loading...\" disabled=True data-id=\"${elm.attr(\"data-id\")}\" id=\"admin-role-${random_number}\">\\r\\n                         <\/div>\\r\\n                         <div class=\"col-md-1 col-1\">\\r\\n                             <span class=\"admin-role-x clickable\"><i class=\"tim-icons icon-simple-remove\" style=\"float: right; margin-top: 10px;\"><\/i><\/span>\\r\\n                         <\/div>\\r\\n                     <\/div>\\r\\n                 <\/li>\\r\\n             `)\\r\\n+        $(`#admin-role-${random_number}`).val(elm.text())\\r\\n         elm.remove()\\r\\n     })\\r\\n \\r\\n@@ -1442,18 +1465,20 @@ <h5>{{ data[\\'message\\'] }}<\/h5>\\n \\r\\n     $(document).on(\\'click\\', \\'.modroleoption\\', function () {\\r\\n         var elm = $(this)\\r\\n+        let random_number = Math.floor(Math.random() * Math.floor(100000))\\r\\n         $(\"#modrolelist\").append(`\\r\\n                 <li>\\r\\n                     <div class=\"row\">\\r\\n                         <div class=\"col-md-10 col-8\">\\r\\n-                            <input class=\"form-control modroleinput\" value=\"${elm.text()}\" disabled=True data-id=\"${elm.attr(\"data-id\")}\">\\r\\n+                            <input class=\"form-control modroleinput\" value=\"Loading...\" disabled=True data-id=\"${elm.attr(\"data-id\")}\" id=\"mod-role-${random_number}\">\\r\\n                         <\/div>\\r\\n                         <div class=\"col-md-1 col-1\">\\r\\n                             <span class=\"mod-role-x clickable\"><i class=\"tim-icons icon-simple-remove\" style=\"float: right; margin-top: 10px;\"><\/i><\/span>\\r\\n                         <\/div>\\r\\n                     <\/div>\\r\\n                 <\/li>\\r\\n             `)\\r\\n+        $(`#mod-role-${random_number}`).val(elm.text())\\r\\n         elm.remove()\\r\\n     })'}}",
            "message_norm":"[ui] fix selectpicker not rendering properly",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['reddash\/app\/home\/templates\/guild.html'])",
            "num_files":1.0,
            "patch_content":"From a6b9785338003ec87fb75305e7d1cc2d40c7ab91 Mon Sep 17 00:00:00 2001\nFrom: NeuroAssassin <42872277+NeuroAssassin@users.noreply.github.com>\nDate: Tue, 1 Dec 2020 14:15:49 +0000\nSubject: [PATCH] [UI] Fix SelectPicker not rendering properly\n\n---\n reddash\/app\/home\/templates\/guild.html | 57 +++++++++++++++++++--------\n 1 file changed, 41 insertions(+), 16 deletions(-)\n\ndiff --git a\/reddash\/app\/home\/templates\/guild.html b\/reddash\/app\/home\/templates\/guild.html\nindex ac6d206..ef1aed5 100755\n--- a\/reddash\/app\/home\/templates\/guild.html\n+++ b\/reddash\/app\/home\/templates\/guild.html\n@@ -930,20 +930,20 @@ <h5>{{ data['message'] }}<\/h5>\n             img.attr(\"src\", `${img.attr(\"data-src-url\")}png`)\r\n         }\r\n     }\r\n+\r\n+    function safe(str) {\r\n+        return String(str).replace(\/&\/g, '&amp;').replace(\/<\/g, '&lt;').replace(\/>\/g, '&gt;').replace(\/\"\/g, '&quot;');\r\n+    }\r\n <\/script>\r\n \r\n {% if data['status'] == 1 and data['data']['status'] == 1 %}\r\n \r\n-{% if 'aliascc' in data['data']['permslist'] %}\r\n+{% if 'aliascc' in data['data']['permslist'] and false%}\r\n <script>\r\n     \/* ---------------------------------------------------------------------------------------------------------------------\r\n                                                         Aliases group\r\n        --------------------------------------------------------------------------------------------------------------------- *\/\r\n \r\n-    function safe(str) {\r\n-        return String(str).replace(\/&\/g, '&amp;').replace(\/<\/g, '&lt;').replace(\/>\/g, '&gt;').replace(\/\"\/g, '&quot;');\r\n-    }\r\n-\r\n     \/\/ Alias modal\r\n     $(document).on('click', '.editaliasbutton', function () {\r\n         var command = $(this).parent().parent().data(\"command\")\r\n@@ -1186,28 +1186,35 @@ <h5>{{ data['message'] }}<\/h5>\n             } else if (json.status === 1 && json.data.status === 0) {\r\n                 $(\"#targetstatus\").html(`{{ _('Failed to fetch targets') }}: ${json.data.message}`)\r\n             } else {\r\n+                let big_ol_dict = {}\r\n                 select.html(\"\")\r\n \r\n                 var chopt = [`<optgroup label=\"{{ _('Channels') }}\">`]\r\n                 for (let [id, name] of json.data.CHANNELS) {\r\n-                    chopt.push(`<option value=${id}>${name}<\/option>`)\r\n+                    chopt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...<\/option>`)\r\n+                    big_ol_dict[id] = name\r\n                 }\r\n                 chopt.push(\"<\/optgroup>\")\r\n                 select.append(chopt.join(\"\"))\r\n \r\n                 var ropt = [`<optgroup label=\"{{ _('Roles') }}\">`]\r\n                 for (let [id, name] of json.data.ROLES) {\r\n-                    ropt.push(`<option value=${id}>${name}<\/option>`)\r\n+                    ropt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...<\/option>`)\r\n+                    big_ol_dict[id] = name\r\n                 }\r\n                 ropt.push(\"<\/optgroup>\")\r\n                 select.append(ropt.join(\"\"))\r\n \r\n                 var uopt = [`<optgroup label=\"{{ _('Users') }}\">`]\r\n                 for (let [id, name] of json.data.USERS) {\r\n-                    uopt.push(`<option value=${id}>${name}<\/option>`)\r\n+                    uopt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...<\/option>`)\r\n+                    big_ol_dict[id] = name\r\n                 }\r\n                 uopt.push(\"<\/optgroup>\")\r\n                 select.append(uopt.join(\"\"))\r\n+                for (let [id, name] of Object.entries(big_ol_dict)) {\r\n+                    $(`.selectpicker-element-${id}`).text(name)\r\n+                }\r\n             }\r\n             select.selectpicker({ title: \"{{ _('Choose target') }}\" })\r\n             select.removeAttr(\"disabled\")\r\n@@ -1299,18 +1306,24 @@ <h5>{{ data['message'] }}<\/h5>\n                 $(\"#rulesdiv\").html(\"\")\r\n                 var overall = ['<h3 style=\"margin-bottom: 10px\">{{ _(\"Cog rules\") }}<\/h3>']\r\n                 var allcoglines = [\"<ul>\"]\r\n+\r\n+                let big_ol_dict_two = {}\r\n+                let cog_counter = 0\r\n+\r\n                 for (let [cog, rules] of Object.entries(json.data.COG)) {\r\n                     var coglines = []\r\n                     for (let rule of rules) {\r\n                         if (rule.type === \"Default\") {\r\n                             coglines.unshift(`<li>{{ _('By default, users are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cog}<\/code> {{ _('cog') }}.<\/li>`)\r\n                         } else if (rule.type === \"Role\") {\r\n-                            coglines.push(`<li>{{ _('Users with the') }} <code>${rule.name}<\/code> {{ _('role') }} (${rule.id}) {{ _('are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cog}<\/code> {{ _('cog') }}.<\/li>`)\r\n+                            coglines.push(`<li>{{ _('Users with the') }} <code id=\"cog-rules-${cog_counter}\">Loading...<\/code> {{ _('role') }} (${rule.id}) {{ _('are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cog}<\/code> {{ _('cog') }}.<\/li>`)\r\n                         } else if (rule.type === \"Channel\") {\r\n-                            coglines.push(`<li>{{ _('Users in the') }} <code>${rule.name}<\/code> {{ _('channel') }} (${rule.id}) {{ _('are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cog}<\/code> {{ _('cog') }}.<\/li>`)\r\n+                            coglines.push(`<li>{{ _('Users in the') }} <code id=\"cog-rules-${cog_counter}\">Loading...<\/code> {{ _('channel') }} (${rule.id}) {{ _('are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cog}<\/code> {{ _('cog') }}.<\/li>`)\r\n                         } else {\r\n-                            coglines.push(`<li>{{ _('User') }} <code>${rule.name}<\/code> (${rule.id}) {{ _('is') }} ${rule.permission} {{ _('permission to use the') }} <code>${cog}<\/code> {{ _('cog') }}.<\/li>`)\r\n+                            coglines.push(`<li>{{ _('User') }} <code id=\"cog-rules-${cog_counter}\">Loading...<\/code> (${rule.id}) {{ _('is') }} ${rule.permission} {{ _('permission to use the') }} <code>${cog}<\/code> {{ _('cog') }}.<\/li>`)\r\n                         }\r\n+                        big_ol_dict_two[`cog-rules-${cog_counter}`] = rule.name\r\n+                        cog_counter += 1\r\n                     }\r\n                     if (coglines) {\r\n                         allcoglines = allcoglines.concat(coglines)\r\n@@ -1324,18 +1337,23 @@ <h5>{{ data['message'] }}<\/h5>\n \r\n                 overall.push('<h3 style=\"margin-bottom: 10px\">{{ _(\"Command rules\") }}<\/h3>')\r\n                 var allcmdlines = [\"<ul>\"]\r\n+\r\n+                let cmd_counter = 0\r\n+\r\n                 for (let [cmd, rules] of Object.entries(json.data.COMMAND)) {\r\n                     var cmdlines = []\r\n                     for (let rule of rules) {\r\n                         if (rule.type === \"Default\") {\r\n                             cmdlines.unshift(`<li>{{ _('By default, users are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cmd}<\/code> {{ _('command') }}.<\/li>`)\r\n                         } else if (rule.type === \"Role\") {\r\n-                            cmdlines.push(`<li>{{ _('Users with the') }} <code>${rule.name}<\/code> {{ _('role') }} (${rule.id}) {{ _('are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cmd}<\/code> {{ _('command') }}.<\/li>`)\r\n+                            cmdlines.push(`<li>{{ _('Users with the') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...<\/code> {{ _('role') }} (${rule.id}) {{ _('are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cmd}<\/code> {{ _('command') }}.<\/li>`)\r\n                         } else if (rule.type === \"Channel\") {\r\n-                            cmdlines.push(`<li>{{ _('Users in the') }} <code>${rule.name}<\/code> {{ _('channel') }} (${rule.id}) {{ _('are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cmd}<\/code> {{ _('command') }}.<\/li>`)\r\n+                            cmdlines.push(`<li>{{ _('Users in the') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...<\/code> {{ _('channel') }} (${rule.id}) {{ _('are') }} ${rule.permission} {{ _('permission to use the') }} <code>${cmd}<\/code> {{ _('command') }}.<\/li>`)\r\n                         } else {\r\n-                            cmdlines.push(`<li>{{ _('User') }} <code>${rule.name}<\/code> (${rule.id}) {{ _('is') }} ${rule.permission} {{ _('permission to use the') }} <code>${cmd}<\/code> {{ _('command') }}.<\/li>`)\r\n+                            cmdlines.push(`<li>{{ _('User') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...<\/code> (${rule.id}) {{ _('is') }} ${rule.permission} {{ _('permission to use the') }} <code>${cmd}<\/code> {{ _('command') }}.<\/li>`)\r\n                         }\r\n+                        big_ol_dict_two[`cmd-rules-${cmd_counter}`] = rule.name\r\n+                        cmd_counter += 1\r\n                     }\r\n                     if (cmdlines) {\r\n                         allcmdlines = allcmdlines.concat(cmdlines)\r\n@@ -1347,6 +1365,9 @@ <h5>{{ data['message'] }}<\/h5>\n                 }\r\n                 overall = overall.concat(allcmdlines)\r\n                 $(\"#rulesdiv\").html(overall.join(\"\"))\r\n+                for (let [id, name] of Object.entries(big_ol_dict_two)) {\r\n+                    $(`#${id}`).text(name)\r\n+                }\r\n                 $(\"#fetchrulesstatus\").html(\"{{ _('Refreshed rules') }}.\")\r\n             }\r\n         }\r\n@@ -1378,11 +1399,12 @@ <h5>{{ data['message'] }}<\/h5>\n \r\n     $(document).on('click', '.adminroleoption', function () {\r\n         var elm = $(this)\r\n+        let random_number = Math.floor(Math.random() * Math.floor(100000))\r\n         $(\"#adminrolelist\").append(`\r\n                 <li>\r\n                     <div class=\"row\">\r\n                         <div class=\"col-md-10 col-8\">\r\n-                            <input class=\"form-control adminroleinput\" value=\"${elm.text()}\" disabled=True data-id=\"${elm.attr(\"data-id\")}\">\r\n+                            <input class=\"form-control adminroleinput\" value=\"Loading...\" disabled=True data-id=\"${elm.attr(\"data-id\")}\" id=\"admin-role-${random_number}\">\r\n                         <\/div>\r\n                         <div class=\"col-md-1 col-1\">\r\n                             <span class=\"admin-role-x clickable\"><i class=\"tim-icons icon-simple-remove\" style=\"float: right; margin-top: 10px;\"><\/i><\/span>\r\n@@ -1390,6 +1412,7 @@ <h5>{{ data['message'] }}<\/h5>\n                     <\/div>\r\n                 <\/li>\r\n             `)\r\n+        $(`#admin-role-${random_number}`).val(elm.text())\r\n         elm.remove()\r\n     })\r\n \r\n@@ -1442,11 +1465,12 @@ <h5>{{ data['message'] }}<\/h5>\n \r\n     $(document).on('click', '.modroleoption', function () {\r\n         var elm = $(this)\r\n+        let random_number = Math.floor(Math.random() * Math.floor(100000))\r\n         $(\"#modrolelist\").append(`\r\n                 <li>\r\n                     <div class=\"row\">\r\n                         <div class=\"col-md-10 col-8\">\r\n-                            <input class=\"form-control modroleinput\" value=\"${elm.text()}\" disabled=True data-id=\"${elm.attr(\"data-id\")}\">\r\n+                            <input class=\"form-control modroleinput\" value=\"Loading...\" disabled=True data-id=\"${elm.attr(\"data-id\")}\" id=\"mod-role-${random_number}\">\r\n                         <\/div>\r\n                         <div class=\"col-md-1 col-1\">\r\n                             <span class=\"mod-role-x clickable\"><i class=\"tim-icons icon-simple-remove\" style=\"float: right; margin-top: 10px;\"><\/i><\/span>\r\n@@ -1454,6 +1478,7 @@ <h5>{{ data['message'] }}<\/h5>\n                     <\/div>\r\n                 <\/li>\r\n             `)\r\n+        $(`#mod-role-${random_number}`).val(elm.text())\r\n         elm.remove()\r\n     })"
        },
        {
            "index":671,
            "vuln_id":"GHSA-6hjc-m38h-7jhh",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/4e46b792ce973ac0c652fb330055f41aca1981c8', 'https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in SEOmatic plugin A cross-site scripting (XSS) vulnerability in the SEOmatic plugin 3.4.10 for Craft CMS 3 allows remote attackers to inject arbitrary web script via a GET to \/index.php?action=seomatic\/file\/seo-file-link with url parameter containing the base64 encoded URL of a malicious web page \/ file and fileName parameter containing an arbitrary filename with the intended content-type to be rendered in the user's browser as the extension.",
            "published_date":"2022-06-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/nystudio107\/craft-seomatic",
            "commit_href":"https:\/\/github.com\/nystudio107\/craft-seomatic\/commit\/5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873",
            "commit_sha":"5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873",
            "patch":"MULTI",
            "chain_ord":"['5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873', '4e46b792ce973ac0c652fb330055f41aca1981c8']",
            "before_first_fix_commit":"{'8c0dc48d026fd076cd0a8fae917bdadc8d67cfa6'}",
            "last_fix_commit":"4e46b792ce973ac0c652fb330055f41aca1981c8",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/24\/2021, 01:25:40",
            "message":"Ensure that only files with the extensions listed in `allowedFileExtensions` General Config setting can be used with the SEO File Link controller\n\nSigned-off-by: Andrew Welch <andrew@nystudio107.com>",
            "author":"Andrew Welch",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'src\/controllers\/FileController.php': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nystudio107\/craft-seomatic\/raw\/5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873\/src%2Fcontrollers%2FFileController.php', 'patch': '@@ -15,12 +15,15 @@\\n use nystudio107\\\\seomatic\\\\Seomatic;\\n \\n use Craft;\\n+use craft\\\\elements\\\\Asset;\\n use craft\\\\helpers\\\\FileHelper;\\n+use craft\\\\helpers\\\\Assets as AssetsHelper;\\n use craft\\\\web\\\\Controller;\\n \\n use yii\\\\web\\\\NotFoundHttpException;\\n use yii\\\\web\\\\HttpException;\\n use yii\\\\web\\\\Response;\\n+use yii\\\\web\\\\ServerErrorHttpException;\\n \\n \/**\\n  * @author    nystudio107\\n@@ -87,6 +90,15 @@ public function actionSeoFileLink($url, $robots = \\'\\', $canonical = \\'\\', $inline =\\n                 $headerValue = \\'<\\'.$canonical.\\'>; rel=\"canonical\"\\';\\n                 $response->headers->add(\\'Link\\', $headerValue);\\n             }\\n+            \/\/ Ensure the file type is allowed\\n+            \/\/ ref: https:\/\/craftcms.com\/docs\/3.x\/config\/config-settings.html#allowedfileextensions\\n+            $allowedExtensions = Craft::$app->getConfig()->getGeneral()->allowedFileExtensions;\\n+            if (($ext = pathinfo($fileName, PATHINFO_EXTENSION)) !== \\'\\') {\\n+                $ext = strtolower($ext);\\n+            }\\n+            if ($ext === \\'\\' || !in_array($ext, $allowedExtensions, true)) {\\n+                throw new ServerErrorHttpException(Craft::t(\\'seomatic\\', \\'File format not allowed.\\'));\\n+            }\\n             \/\/ Send the file as a stream, so it can exist anywhere\\n             $response->sendContentAsFile(\\n                 $contents,'}}",
            "message_norm":"ensure that only files with the extensions listed in `allowedfileextensions` general config setting can be used with the seo file link controller\n\nsigned-off-by: andrew welch <andrew@nystudio107.com>",
            "language":"en",
            "entities":"[('ensure', 'ACTION', ''), ('andrew@nystudio107.com', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/controllers\/FileController.php'])",
            "num_files":1.0,
            "patch_content":"From 5f2cdc7c39e0a4bfb60d2f84131508f0a87b2873 Mon Sep 17 00:00:00 2001\nFrom: Andrew Welch <andrew@nystudio107.com>\nDate: Thu, 23 Sep 2021 21:25:40 -0400\nSubject: [PATCH] Ensure that only files with the extensions listed in\n `allowedFileExtensions` General Config setting can be used with the SEO File\n Link controller\n\nSigned-off-by: Andrew Welch <andrew@nystudio107.com>\n---\n src\/controllers\/FileController.php | 12 ++++++++++++\n 1 file changed, 12 insertions(+)\n\ndiff --git a\/src\/controllers\/FileController.php b\/src\/controllers\/FileController.php\nindex 1e1f1b1d2..33d7f0582 100644\n--- a\/src\/controllers\/FileController.php\n+++ b\/src\/controllers\/FileController.php\n@@ -15,12 +15,15 @@\n use nystudio107\\seomatic\\Seomatic;\n \n use Craft;\n+use craft\\elements\\Asset;\n use craft\\helpers\\FileHelper;\n+use craft\\helpers\\Assets as AssetsHelper;\n use craft\\web\\Controller;\n \n use yii\\web\\NotFoundHttpException;\n use yii\\web\\HttpException;\n use yii\\web\\Response;\n+use yii\\web\\ServerErrorHttpException;\n \n \/**\n  * @author    nystudio107\n@@ -87,6 +90,15 @@ public function actionSeoFileLink($url, $robots = '', $canonical = '', $inline =\n                 $headerValue = '<'.$canonical.'>; rel=\"canonical\"';\n                 $response->headers->add('Link', $headerValue);\n             }\n+            \/\/ Ensure the file type is allowed\n+            \/\/ ref: https:\/\/craftcms.com\/docs\/3.x\/config\/config-settings.html#allowedfileextensions\n+            $allowedExtensions = Craft::$app->getConfig()->getGeneral()->allowedFileExtensions;\n+            if (($ext = pathinfo($fileName, PATHINFO_EXTENSION)) !== '') {\n+                $ext = strtolower($ext);\n+            }\n+            if ($ext === '' || !in_array($ext, $allowedExtensions, true)) {\n+                throw new ServerErrorHttpException(Craft::t('seomatic', 'File format not allowed.'));\n+            }\n             \/\/ Send the file as a stream, so it can exist anywhere\n             $response->sendContentAsFile(\n                 $contents,"
        },
        {
            "index":675,
            "vuln_id":"GHSA-8r7c-3cm2-3h8f",
            "cwe_id":"{'CWE-401'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd'}",
            "dataset":"osv",
            "summary":"Memory leak in Tensorflow ### Impact\nIf a graph node is invalid, TensorFlow can leak memory in the [implementation of `ImmutableExecutorState::Initialize`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/common_runtime\/immutable_executor_state.cc#L84-L262):\n\n```cc\nStatus s = params_.create_kernel(n->properties(), &item->kernel);\nif (!s.ok()) {\n  item->kernel = nullptr;\n  s = AttachDef(s, *n);\n  return s;           \n}                     \n```\n\nHere, we set `item->kernel` to `nullptr` but it is a simple `OpKernel*` pointer so the memory that was previously allocated to it would leak.\n\n### Patches\nWe have patched the issue in GitHub commit [c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd",
            "commit_sha":"c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd",
            "patch":"SINGLE",
            "chain_ord":"['c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd']",
            "before_first_fix_commit":"{'d781eab54947e82ebf182f28dcdd5b02e6925d46'}",
            "last_fix_commit":"c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/10\/2021, 21:51:15",
            "message":"Fix memory leak when a graph node is invalid.\n\nIf a graph node is invalid but a kernel is created then we set the kernel back to `nullptr` but we forget to delete it. Hence, we get a memory leak.\n\nPiperOrigin-RevId: 408968108\nChange-Id: I1d8a9d0d8988ed5e08be8b9f2004ce1b4cd11b7c",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/core\/common_runtime\/immutable_executor_state.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd\/tensorflow%2Fcore%2Fcommon_runtime%2Fimmutable_executor_state.cc', 'patch': '@@ -131,6 +131,7 @@ Status ImmutableExecutorState::Initialize(const Graph& graph) {\\n \\n     Status s = params_.create_kernel(n->properties(), &item->kernel);\\n     if (!s.ok()) {\\n+      params_.delete_kernel(item->kernel);\\n       item->kernel = nullptr;\\n       s = AttachDef(s, *n);\\n       return s;'}}",
            "message_norm":"fix memory leak when a graph node is invalid.\n\nif a graph node is invalid but a kernel is created then we set the kernel back to `nullptr` but we forget to delete it. hence, we get a memory leak.\n\npiperorigin-revid: 408968108\nchange-id: i1d8a9d0d8988ed5e08be8b9f2004ce1b4cd11b7c",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('memory leak', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('memory leak', 'SECWORD', ''), ('408968108', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/common_runtime\/immutable_executor_state.cc'])",
            "num_files":1.0,
            "patch_content":"From c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 10 Nov 2021 13:51:15 -0800\nSubject: [PATCH] Fix memory leak when a graph node is invalid.\n\nIf a graph node is invalid but a kernel is created then we set the kernel back to `nullptr` but we forget to delete it. Hence, we get a memory leak.\n\nPiperOrigin-RevId: 408968108\nChange-Id: I1d8a9d0d8988ed5e08be8b9f2004ce1b4cd11b7c\n---\n tensorflow\/core\/common_runtime\/immutable_executor_state.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/core\/common_runtime\/immutable_executor_state.cc b\/tensorflow\/core\/common_runtime\/immutable_executor_state.cc\nindex 1f728334e2b7ee..25822540f024ae 100644\n--- a\/tensorflow\/core\/common_runtime\/immutable_executor_state.cc\n+++ b\/tensorflow\/core\/common_runtime\/immutable_executor_state.cc\n@@ -131,6 +131,7 @@ Status ImmutableExecutorState::Initialize(const Graph& graph) {\n \n     Status s = params_.create_kernel(n->properties(), &item->kernel);\n     if (!s.ok()) {\n+      params_.delete_kernel(item->kernel);\n       item->kernel = nullptr;\n       s = AttachDef(s, *n);\n       return s;"
        },
        {
            "index":500,
            "vuln_id":"GHSA-f5cx-5wr3-5qrc",
            "cwe_id":"{'CWE-824'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in boosted trees ### Impact\nAn attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesCalculateBestGainsPerFeature(\n  node_id_range=[],\n  stats_summary_list=[[1,2,3]],\n  l1=[1.0],\n  l2=[1.0],\n  tree_complexity =[1.0],\n  min_node_weight =[1.17],\n  max_splits=5)\n```\n\nA similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`:\n\n```python\nimport tensorflow as tf\n                                                                                                                                                                                                                                                                                          \ntf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2(\n  node_id_range=[],\n  stats_summaries_list=[[1,2,3]],\n  split_types=[''],\n  candidate_feature_ids=[1,2,3,4],\n  l1=[1],     \n  l2=[1],\n  tree_complexity=[1.0],\n  min_node_weight=[1.17],\n  logits_dimension=5)\n```     \n    \nThe  [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc) does not validate the input values.\n\n### Patches\nWe have patched the issue in GitHub commit [9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad) and in commit. [429f009d2b2c09028647dd4bb7b3f6f414bbaad7](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "commit_sha":"429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "patch":"MULTI",
            "chain_ord":"['9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', '429f009d2b2c09028647dd4bb7b3f6f414bbaad7']",
            "before_first_fix_commit":"{'4f8db85aa9ab71a71e95d5acce7de52a0b195661'}",
            "last_fix_commit":"429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/28\/2021, 20:25:18",
            "message":"Add remaining missing validation to `BoostedTreesCalculateBestFeatureSplit`\n\nPiperOrigin-RevId: 387423006\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 1, 'total': 20}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc': {'additions': 19, 'deletions': 1, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -14,6 +14,7 @@ limitations under the License.\\n ==============================================================================*\/\\n \\n #include <limits>\\n+#include <string>\\n #include <vector>\\n \\n #include \"third_party\/eigen3\/Eigen\/Core\"\\n@@ -22,6 +23,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n #include \"tensorflow\/core\/kernels\/boosted_trees\/boosted_trees.pb.h\"\\n #include \"tensorflow\/core\/kernels\/boosted_trees\/tree_helper.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/platform\/logging.h\"\\n \\n namespace tensorflow {\\n@@ -254,12 +256,18 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n     \/\/ node_id_range\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->NumElements() == 2,\\n+        errors::InvalidArgument(\"node_id_range argument must have shape [2]\"));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n     const int32_t node_id_first = node_id_range(0);  \/\/ inclusive\\n     const int32_t node_id_last = node_id_range(1);   \/\/ exclusive\\n \\n     const Tensor* stats_summary_t;\\n     OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\\n+    OP_REQUIRES(\\n+        context, stats_summary_t->shape().dims() == 4,\\n+        errors::InvalidArgument(\"stats_summary argument must have rank 4\"));\\n     TTypes<float, 4>::ConstTensor stats_summary =\\n         stats_summary_t->tensor<float, 4>();\\n     const int32_t feature_dims = stats_summary_t->dim_size(1);\\n@@ -272,6 +280,8 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n \\n     const Tensor* l1_t;\\n     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\\n+    OP_REQUIRES(context, l1_t->NumElements() == 1,\\n+                errors::InvalidArgument(\"l1 argument must be a scalar\"));\\n     const auto l1 = l1_t->scalar<float>()();\\n     DCHECK_GE(l1, 0);\\n     if (logits_dim_ > 1) {\\n@@ -281,17 +291,25 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n \\n     const Tensor* l2_t;\\n     OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\\n+    OP_REQUIRES(context, l2_t->NumElements() == 1,\\n+                errors::InvalidArgument(\"l2 argument must be a scalar\"));\\n     const auto l2 = l2_t->scalar<float>()();\\n     DCHECK_GE(l2, 0);\\n \\n     const Tensor* tree_complexity_t;\\n     OP_REQUIRES_OK(context,\\n                    context->input(\"tree_complexity\", &tree_complexity_t));\\n+    OP_REQUIRES(\\n+        context, tree_complexity_t->NumElements() == 1,\\n+        errors::InvalidArgument(\"tree_complexity argument must be a scalar\"));\\n     const auto tree_complexity = tree_complexity_t->scalar<float>()();\\n \\n     const Tensor* min_node_weight_t;\\n     OP_REQUIRES_OK(context,\\n                    context->input(\"min_node_weight\", &min_node_weight_t));\\n+    OP_REQUIRES(\\n+        context, min_node_weight_t->NumElements() == 1,\\n+        errors::InvalidArgument(\"min_node_weight argument must be a scalar\"));\\n     const auto min_node_weight = min_node_weight_t->scalar<float>()();\\n \\n     std::vector<int32> output_node_ids;\\n@@ -300,7 +318,7 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n     std::vector<int32> output_thresholds;\\n     std::vector<Eigen::VectorXf> output_left_node_contribs;\\n     std::vector<Eigen::VectorXf> output_right_node_contribs;\\n-    std::vector<string> output_split_types;\\n+    std::vector<std::string> output_split_types;\\n \\n     \/\/ TODO(tanzheny) parallelize the computation.\\n     \/\/ Iterate each node and find the best gain per node.'}}",
            "message_norm":"add remaining missing validation to `boostedtreescalculatebestfeaturesplit`\n\npiperorigin-revid: 387423006\nchange-id: i8eaf30efb223011519e60707bfa751b275d3a443",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('387423006', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From 429f009d2b2c09028647dd4bb7b3f6f414bbaad7 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 28 Jul 2021 13:25:18 -0700\nSubject: [PATCH] Add remaining missing validation to\n `BoostedTreesCalculateBestFeatureSplit`\n\nPiperOrigin-RevId: 387423006\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443\n---\n ...\/core\/kernels\/boosted_trees\/stats_ops.cc   | 20 ++++++++++++++++++-\n 1 file changed, 19 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc b\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\nindex 2636909855a386..60c1d191f5232c 100644\n--- a\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\n+++ b\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\n@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*\/\n \n #include <limits>\n+#include <string>\n #include <vector>\n \n #include \"third_party\/eigen3\/Eigen\/Core\"\n@@ -22,6 +23,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\n #include \"tensorflow\/core\/kernels\/boosted_trees\/boosted_trees.pb.h\"\n #include \"tensorflow\/core\/kernels\/boosted_trees\/tree_helper.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/logging.h\"\n \n namespace tensorflow {\n@@ -254,12 +256,18 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n     \/\/ node_id_range\n     const Tensor* node_id_range_t;\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n+    OP_REQUIRES(\n+        context, node_id_range_t->NumElements() == 2,\n+        errors::InvalidArgument(\"node_id_range argument must have shape [2]\"));\n     const auto node_id_range = node_id_range_t->vec<int32>();\n     const int32_t node_id_first = node_id_range(0);  \/\/ inclusive\n     const int32_t node_id_last = node_id_range(1);   \/\/ exclusive\n \n     const Tensor* stats_summary_t;\n     OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\n+    OP_REQUIRES(\n+        context, stats_summary_t->shape().dims() == 4,\n+        errors::InvalidArgument(\"stats_summary argument must have rank 4\"));\n     TTypes<float, 4>::ConstTensor stats_summary =\n         stats_summary_t->tensor<float, 4>();\n     const int32_t feature_dims = stats_summary_t->dim_size(1);\n@@ -272,6 +280,8 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n \n     const Tensor* l1_t;\n     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\n+    OP_REQUIRES(context, l1_t->NumElements() == 1,\n+                errors::InvalidArgument(\"l1 argument must be a scalar\"));\n     const auto l1 = l1_t->scalar<float>()();\n     DCHECK_GE(l1, 0);\n     if (logits_dim_ > 1) {\n@@ -281,17 +291,25 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n \n     const Tensor* l2_t;\n     OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\n+    OP_REQUIRES(context, l2_t->NumElements() == 1,\n+                errors::InvalidArgument(\"l2 argument must be a scalar\"));\n     const auto l2 = l2_t->scalar<float>()();\n     DCHECK_GE(l2, 0);\n \n     const Tensor* tree_complexity_t;\n     OP_REQUIRES_OK(context,\n                    context->input(\"tree_complexity\", &tree_complexity_t));\n+    OP_REQUIRES(\n+        context, tree_complexity_t->NumElements() == 1,\n+        errors::InvalidArgument(\"tree_complexity argument must be a scalar\"));\n     const auto tree_complexity = tree_complexity_t->scalar<float>()();\n \n     const Tensor* min_node_weight_t;\n     OP_REQUIRES_OK(context,\n                    context->input(\"min_node_weight\", &min_node_weight_t));\n+    OP_REQUIRES(\n+        context, min_node_weight_t->NumElements() == 1,\n+        errors::InvalidArgument(\"min_node_weight argument must be a scalar\"));\n     const auto min_node_weight = min_node_weight_t->scalar<float>()();\n \n     std::vector<int32> output_node_ids;\n@@ -300,7 +318,7 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n     std::vector<int32> output_thresholds;\n     std::vector<Eigen::VectorXf> output_left_node_contribs;\n     std::vector<Eigen::VectorXf> output_right_node_contribs;\n-    std::vector<string> output_split_types;\n+    std::vector<std::string> output_split_types;\n \n     \/\/ TODO(tanzheny) parallelize the computation.\n     \/\/ Iterate each node and find the best gain per node."
        },
        {
            "index":740,
            "vuln_id":"GHSA-wh98-p28r-vrc9",
            "cwe_id":"{'CWE-200'}",
            "score":7.4,
            "chain":"{'https:\/\/github.com\/rails\/rails\/commit\/f9a2ad03943d5c2ba54e1d45f155442b519c75da'}",
            "dataset":"osv",
            "summary":"Exposure of information in Action Pack ### Impact\n\nUnder certain circumstances response bodies will not be closed, for example a [bug in a webserver](https:\/\/github.com\/puma\/puma\/pull\/2812) or a bug in a Rack middleware.  In the event a response is *not* notified of a `close`, `ActionDispatch::Executor` will not know to reset thread local state for the next request.  This can lead to data being leaked to subsequent requests, especially when interacting with `ActiveSupport::CurrentAttributes`.\n\nUpgrading to the FIXED versions of Rails will ensure mitigation of this issue even in the context of a buggy webserver or middleware implementation.\n\n### Patches\n\nThis has been fixed in Rails 7.0.2.2, 6.1.4.6, 6.0.4.6, and 5.2.6.2.\n\n### Workarounds\n\nUpgrading is highly recommended, but to work around this problem the following middleware can be used:\n\n```ruby\nclass GuardedExecutor < ActionDispatch::Executor\n  def call(env)\n    ensure_completed!\n    super\n  end\n\n  private\n\n    def ensure_completed!\n      @executor.new.complete! if @executor.active?\n    end\nend\n\n# Ensure the guard is inserted before ActionDispatch::Executor\nRails.application.configure do\n  config.middleware.swap ActionDispatch::Executor, GuardedExecutor, executor\nend\n```",
            "published_date":"2022-02-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/rails\/rails",
            "commit_href":"https:\/\/github.com\/rails\/rails\/commit\/f9a2ad03943d5c2ba54e1d45f155442b519c75da",
            "commit_sha":"f9a2ad03943d5c2ba54e1d45f155442b519c75da",
            "patch":"SINGLE",
            "chain_ord":"['f9a2ad03943d5c2ba54e1d45f155442b519c75da']",
            "before_first_fix_commit":"{'761a2e25520566d932c41c740b8a5c513d839de8'}",
            "last_fix_commit":"f9a2ad03943d5c2ba54e1d45f155442b519c75da",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/11\/2022, 19:23:01",
            "message":"Fix reloader to work with new Executor signature\n\nThis is a follow up to [CVE-2022-23633].",
            "author":"Aaron Patterson",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'activesupport\/lib\/active_support\/reloader.rb': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/rails\/rails\/raw\/f9a2ad03943d5c2ba54e1d45f155442b519c75da\/activesupport%2Flib%2Factive_support%2Freloader.rb', 'patch': '@@ -58,7 +58,7 @@ def self.reload!\\n       prepare!\\n     end\\n \\n-    def self.run! # :nodoc:\\n+    def self.run!(reset: false) # :nodoc:\\n       if check!\\n         super\\n       else'}}",
            "message_norm":"fix reloader to work with new executor signature\n\nthis is a follow up to [cve-2022-23633].",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('signature', 'SECWORD', ''), ('cve-2022-23633', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['activesupport\/lib\/active_support\/reloader.rb'])",
            "num_files":1.0,
            "patch_content":"From f9a2ad03943d5c2ba54e1d45f155442b519c75da Mon Sep 17 00:00:00 2001\nFrom: Aaron Patterson <aaron@rubyonrails.org>\nDate: Fri, 11 Feb 2022 11:23:01 -0800\nSubject: [PATCH] Fix reloader to work with new Executor signature\n\nThis is a follow up to [CVE-2022-23633].\n---\n activesupport\/lib\/active_support\/reloader.rb | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/activesupport\/lib\/active_support\/reloader.rb b\/activesupport\/lib\/active_support\/reloader.rb\nindex 2f81cd4f80b8b..e751866a270f8 100644\n--- a\/activesupport\/lib\/active_support\/reloader.rb\n+++ b\/activesupport\/lib\/active_support\/reloader.rb\n@@ -58,7 +58,7 @@ def self.reload!\n       prepare!\n     end\n \n-    def self.run! # :nodoc:\n+    def self.run!(reset: false) # :nodoc:\n       if check!\n         super\n       else"
        },
        {
            "index":451,
            "vuln_id":"GHSA-5f9h-9pjv-v6j7",
            "cwe_id":"{'CWE-22', 'CWE-548'}",
            "score":8.6,
            "chain":"{'https:\/\/github.com\/rack\/rack\/commit\/dddb7ad18ed79ca6ab06ccc417a169fde451246e'}",
            "dataset":"osv",
            "summary":"Directory traversal in Rack::Directory app bundled with Rack A directory traversal vulnerability exists in rack < 2.2.0 that allows an attacker perform directory traversal vulnerability in the Rack::Directory app that is bundled with Rack which could result in information disclosure.",
            "published_date":"2020-07-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/rack\/rack",
            "commit_href":"https:\/\/github.com\/rack\/rack\/commit\/dddb7ad18ed79ca6ab06ccc417a169fde451246e",
            "commit_sha":"dddb7ad18ed79ca6ab06ccc417a169fde451246e",
            "patch":"SINGLE",
            "chain_ord":"['dddb7ad18ed79ca6ab06ccc417a169fde451246e']",
            "before_first_fix_commit":"{'16a51d8e0b64964323c3719b8154106af5cc0feb'}",
            "last_fix_commit":"dddb7ad18ed79ca6ab06ccc417a169fde451246e",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/12\/2020, 16:23:33",
            "message":"Use Dir.entries instead of Dir[glob] to prevent user-specified glob metacharacters\n\n[CVE-2020-8161]",
            "author":"Jack McCracken",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 2, 'total': 3}",
            "files":"{'lib\/rack\/directory.rb': {'additions': 1, 'deletions': 2, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/rack\/rack\/raw\/dddb7ad18ed79ca6ab06ccc417a169fde451246e\/lib%2Frack%2Fdirectory.rb', 'patch': \"@@ -106,13 +106,12 @@ def check_forbidden(path_info)\\n \\n     def list_directory(path_info, path, script_name)\\n       files = [['..\/', 'Parent Directory', '', '', '']]\\n-      glob = ::File.join(path, '*')\\n \\n       url_head = (script_name.split('\/') + path_info.split('\/')).map do |part|\\n         Rack::Utils.escape_path part\\n       end\\n \\n-      Dir[glob].sort.each do |node|\\n+      Dir.entries(path).reject { |e| e.start_with?('.') }.sort.each do |node|\\n         stat = stat(node)\\n         next unless stat\\n         basename = ::File.basename(node)\"}}",
            "message_norm":"use dir.entries instead of dir[glob] to prevent user-specified glob metacharacters\n\n[cve-2020-8161]",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('cve-2020-8161', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/rack\/directory.rb'])",
            "num_files":1.0,
            "patch_content":"From dddb7ad18ed79ca6ab06ccc417a169fde451246e Mon Sep 17 00:00:00 2001\nFrom: Jack McCracken <jack.mccracken@shopify.com>\nDate: Tue, 12 May 2020 12:23:33 -0400\nSubject: [PATCH] Use Dir.entries instead of Dir[glob] to prevent\n user-specified glob metacharacters\n\n[CVE-2020-8161]\n---\n lib\/rack\/directory.rb | 3 +--\n 1 file changed, 1 insertion(+), 2 deletions(-)\n\ndiff --git a\/lib\/rack\/directory.rb b\/lib\/rack\/directory.rb\nindex b08f59490..d68f36a9f 100644\n--- a\/lib\/rack\/directory.rb\n+++ b\/lib\/rack\/directory.rb\n@@ -106,13 +106,12 @@ def check_forbidden(path_info)\n \n     def list_directory(path_info, path, script_name)\n       files = [['..\/', 'Parent Directory', '', '', '']]\n-      glob = ::File.join(path, '*')\n \n       url_head = (script_name.split('\/') + path_info.split('\/')).map do |part|\n         Rack::Utils.escape_path part\n       end\n \n-      Dir[glob].sort.each do |node|\n+      Dir.entries(path).reject { |e| e.start_with?('.') }.sort.each do |node|\n         stat = stat(node)\n         next unless stat\n         basename = ::File.basename(node)"
        },
        {
            "index":396,
            "vuln_id":"GHSA-v2p6-4mp7-3r9v",
            "cwe_id":"{'CWE-400'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/epeli\/underscore.string\/commit\/f486cd684c94c12db48b45d52b1472a1b9661029'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in underscore.string Versions of `underscore.string` prior to *3.3.5* are vulnerable to Regular Expression Denial of Service (ReDoS).\n\nThe function `unescapeHTML` is vulnerable to ReDoS due to an overly-broad regex. The slowdown is approximately 2s for 50,000 characters but grows exponentially with larger inputs.\n\n\n## Recommendation\n\nUpgrade to version 3.3.5 or higher.",
            "published_date":"2019-06-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/epeli\/underscore.string",
            "commit_href":"https:\/\/github.com\/epeli\/underscore.string\/commit\/f486cd684c94c12db48b45d52b1472a1b9661029",
            "commit_sha":"f486cd684c94c12db48b45d52b1472a1b9661029",
            "patch":"SINGLE",
            "chain_ord":"['f486cd684c94c12db48b45d52b1472a1b9661029']",
            "before_first_fix_commit":"{'2f78f0d6e36d553484a1bf5fe5ed1998f013dea5'}",
            "last_fix_commit":"f486cd684c94c12db48b45d52b1472a1b9661029",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/03\/2018, 21:34:42",
            "message":"Try to fix regexp redos\n\nfixes  #510",
            "author":"Esa-Matti Suuronen",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'unescapeHTML.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/esamattis\/underscore.string\/raw\/f486cd684c94c12db48b45d52b1472a1b9661029\/unescapeHTML.js', 'patch': \"@@ -2,7 +2,7 @@ var makeString = require('.\/helper\/makeString');\\n var htmlEntities = require('.\/helper\/htmlEntities');\\n \\n module.exports = function unescapeHTML(str) {\\n-  return makeString(str).replace(\/\\\\&([^;]+);\/g, function(entity, entityCode) {\\n+  return makeString(str).replace(\/\\\\&([^;]{1,10});\/g, function(entity, entityCode) {\\n     var match;\\n \\n     if (entityCode in htmlEntities) {\"}}",
            "message_norm":"try to fix regexp redos\n\nfixes  #510",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#510', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['unescapeHTML.js'])",
            "num_files":1.0,
            "patch_content":"From f486cd684c94c12db48b45d52b1472a1b9661029 Mon Sep 17 00:00:00 2001\nFrom: Esa-Matti Suuronen <esa-matti@suuronen.org>\nDate: Thu, 4 Oct 2018 00:34:42 +0300\nSubject: [PATCH] Try to fix regexp redos\n\nfixes  #510\n---\n unescapeHTML.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/unescapeHTML.js b\/unescapeHTML.js\nindex 78b59c28..df1d18ef 100644\n--- a\/unescapeHTML.js\n+++ b\/unescapeHTML.js\n@@ -2,7 +2,7 @@ var makeString = require('.\/helper\/makeString');\n var htmlEntities = require('.\/helper\/htmlEntities');\n \n module.exports = function unescapeHTML(str) {\n-  return makeString(str).replace(\/\\&([^;]+);\/g, function(entity, entityCode) {\n+  return makeString(str).replace(\/\\&([^;]{1,10});\/g, function(entity, entityCode) {\n     var match;\n \n     if (entityCode in htmlEntities) {"
        },
        {
            "index":955,
            "vuln_id":"GHSA-hpx4-xjp7-m4vr",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/f623d05d0c3487ae24c4f13907e4709484e5bf41'}",
            "dataset":"osv",
            "summary":"Stored cross-site scripting in Snipe-IT Snipe-IT prior to version 5.4.3 is vulnerable to stored cross-site scripting because the input to the `checked_out_to` parameter is not escaped. The vulnerability is capable of stealing a user's cookie.",
            "published_date":"2022-04-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/f623d05d0c3487ae24c4f13907e4709484e5bf41",
            "commit_sha":"f623d05d0c3487ae24c4f13907e4709484e5bf41",
            "patch":"SINGLE",
            "chain_ord":"['f623d05d0c3487ae24c4f13907e4709484e5bf41']",
            "before_first_fix_commit":"{'ef7f21e3ba01f13da2e656358343ba1236a122de'}",
            "last_fix_commit":"f623d05d0c3487ae24c4f13907e4709484e5bf41",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/24\/2022, 14:27:11",
            "message":"Escape checkout target name\n\nSigned-off-by: snipe <snipe@snipe.net>",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'app\/Http\/Transformers\/DepreciationReportTransformer.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/f623d05d0c3487ae24c4f13907e4709484e5bf41\/app%2FHttp%2FTransformers%2FDepreciationReportTransformer.php', 'patch': \"@@ -98,7 +98,7 @@ public function transformAsset(Asset $asset)\\n             'purchase_cost' => Helper::formatCurrencyOutput($asset->purchase_cost),\\n             'book_value' => Helper::formatCurrencyOutput($depreciated_value),\\n             'monthly_depreciation' => $monthly_depreciation,\\n-            'checked_out_to' => $checkout_target,\\n+            'checked_out_to' => ($checkout_target) ? e($checkout_target) : null,\\n             'diff' =>  Helper::formatCurrencyOutput($diff),\\n             'number_of_months' =>  ($asset->model && $asset->model->depreciation) ? e($asset->model->depreciation->months) : null,\\n             'depreciation' => (($asset->model) && ($asset->model->depreciation)) ?  e($asset->model->depreciation->name) : null,\"}}",
            "message_norm":"escape checkout target name\n\nsigned-off-by: snipe <snipe@snipe.net>",
            "language":"en",
            "entities":"[('escape', 'SECWORD', ''), ('snipe@snipe.net', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Transformers\/DepreciationReportTransformer.php'])",
            "num_files":1.0,
            "patch_content":"From f623d05d0c3487ae24c4f13907e4709484e5bf41 Mon Sep 17 00:00:00 2001\nFrom: snipe <snipe@snipe.net>\nDate: Sun, 24 Apr 2022 15:27:11 +0100\nSubject: [PATCH] Escape checkout target name\n\nSigned-off-by: snipe <snipe@snipe.net>\n---\n app\/Http\/Transformers\/DepreciationReportTransformer.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/app\/Http\/Transformers\/DepreciationReportTransformer.php b\/app\/Http\/Transformers\/DepreciationReportTransformer.php\nindex 73c970504b06..a5fb118c4035 100644\n--- a\/app\/Http\/Transformers\/DepreciationReportTransformer.php\n+++ b\/app\/Http\/Transformers\/DepreciationReportTransformer.php\n@@ -98,7 +98,7 @@ public function transformAsset(Asset $asset)\n             'purchase_cost' => Helper::formatCurrencyOutput($asset->purchase_cost),\n             'book_value' => Helper::formatCurrencyOutput($depreciated_value),\n             'monthly_depreciation' => $monthly_depreciation,\n-            'checked_out_to' => $checkout_target,\n+            'checked_out_to' => ($checkout_target) ? e($checkout_target) : null,\n             'diff' =>  Helper::formatCurrencyOutput($diff),\n             'number_of_months' =>  ($asset->model && $asset->model->depreciation) ? e($asset->model->depreciation->months) : null,\n             'depreciation' => (($asset->model) && ($asset->model->depreciation)) ?  e($asset->model->depreciation->name) : null,"
        },
        {
            "index":67,
            "vuln_id":"GHSA-4rmr-c2jx-vx27",
            "cwe_id":"{'CWE-1336'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/bobthecow\/mustache.php\/commit\/579ffa5c96e1d292c060b3dd62811ff01ad8c24e'}",
            "dataset":"osv",
            "summary":"Mustache remote code injection vulnerability In Mustache.php v2.0.0 through v2.14.0, Sections tag can lead to arbitrary php code execution even if strict_callables is true when section value is controllable.",
            "published_date":"2022-01-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/bobthecow\/mustache.php",
            "commit_href":"https:\/\/github.com\/bobthecow\/mustache.php\/commit\/579ffa5c96e1d292c060b3dd62811ff01ad8c24e",
            "commit_sha":"579ffa5c96e1d292c060b3dd62811ff01ad8c24e",
            "patch":"SINGLE",
            "chain_ord":"['579ffa5c96e1d292c060b3dd62811ff01ad8c24e']",
            "before_first_fix_commit":"{'076209772dda21cbfdbf5ef99d202a0937da4826'}",
            "last_fix_commit":"579ffa5c96e1d292c060b3dd62811ff01ad8c24e",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/21\/2022, 06:08:36",
            "message":"Fix CVE-2022-0323 (improper neutralization of section names) \n\n- Fixes possible RCE when rendering untrusted user templates.\n- Remove unnecessary comments in generated source.",
            "author":"Justin Hileman",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 4, 'total': 6}",
            "files":"{'src\/Mustache\/Compiler.php': {'additions': 2, 'deletions': 4, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/bobthecow\/mustache.php\/raw\/579ffa5c96e1d292c060b3dd62811ff01ad8c24e\/src%2FMustache%2FCompiler.php', 'patch': \"@@ -320,7 +320,6 @@ private function block($nodes)\\n     }\\n \\n     const SECTION_CALL = '\\n-        \/\/ %s section\\n         $value = $context->%s(%s);%s\\n         $buffer .= $this->section%s($context, $indent, $value);\\n     ';\\n@@ -391,11 +390,10 @@ private function section($nodes, $id, $filters, $start, $end, $otag, $ctag, $lev\\n         $id      = var_export($id, true);\\n         $filters = $this->getFilters($filters, $level);\\n \\n-        return sprintf($this->prepare(self::SECTION_CALL, $level), $id, $method, $id, $filters, $key);\\n+        return sprintf($this->prepare(self::SECTION_CALL, $level), $method, $id, $filters, $key);\\n     }\\n \\n     const INVERTED_SECTION = '\\n-        \/\/ %s inverted section\\n         $value = $context->%s(%s);%s\\n         if (empty($value)) {\\n             %s\\n@@ -418,7 +416,7 @@ private function invertedSection($nodes, $id, $filters, $level)\\n         $id      = var_export($id, true);\\n         $filters = $this->getFilters($filters, $level);\\n \\n-        return sprintf($this->prepare(self::INVERTED_SECTION, $level), $id, $method, $id, $filters, $this->walk($nodes, $level));\\n+        return sprintf($this->prepare(self::INVERTED_SECTION, $level), $method, $id, $filters, $this->walk($nodes, $level));\\n     }\\n \\n     const PARTIAL_INDENT = ', $indent . %s';\"}}",
            "message_norm":"fix cve-2022-0323 (improper neutralization of section names) \n\n- fixes possible rce when rendering untrusted user templates.\n- remove unnecessary comments in generated source.",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('cve-2022-0323', 'VULNID', 'CVE'), ('improper neutralization', 'SECWORD', ''), ('untrusted', 'SECWORD', ''), ('remove', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Mustache\/Compiler.php'])",
            "num_files":1.0,
            "patch_content":"From 579ffa5c96e1d292c060b3dd62811ff01ad8c24e Mon Sep 17 00:00:00 2001\nFrom: Justin Hileman <justin@justinhileman.info>\nDate: Fri, 21 Jan 2022 01:08:36 -0500\nSubject: [PATCH] Fix CVE-2022-0323 (improper neutralization of section names)\n\n- Fixes possible RCE when rendering untrusted user templates.\n- Remove unnecessary comments in generated source.\n---\n src\/Mustache\/Compiler.php | 6 ++----\n 1 file changed, 2 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/Mustache\/Compiler.php b\/src\/Mustache\/Compiler.php\nindex 2fa1a736..93a295ae 100644\n--- a\/src\/Mustache\/Compiler.php\n+++ b\/src\/Mustache\/Compiler.php\n@@ -320,7 +320,6 @@ private function block($nodes)\n     }\n \n     const SECTION_CALL = '\n-        \/\/ %s section\n         $value = $context->%s(%s);%s\n         $buffer .= $this->section%s($context, $indent, $value);\n     ';\n@@ -391,11 +390,10 @@ private function section($nodes, $id, $filters, $start, $end, $otag, $ctag, $lev\n         $id      = var_export($id, true);\n         $filters = $this->getFilters($filters, $level);\n \n-        return sprintf($this->prepare(self::SECTION_CALL, $level), $id, $method, $id, $filters, $key);\n+        return sprintf($this->prepare(self::SECTION_CALL, $level), $method, $id, $filters, $key);\n     }\n \n     const INVERTED_SECTION = '\n-        \/\/ %s inverted section\n         $value = $context->%s(%s);%s\n         if (empty($value)) {\n             %s\n@@ -418,7 +416,7 @@ private function invertedSection($nodes, $id, $filters, $level)\n         $id      = var_export($id, true);\n         $filters = $this->getFilters($filters, $level);\n \n-        return sprintf($this->prepare(self::INVERTED_SECTION, $level), $id, $method, $id, $filters, $this->walk($nodes, $level));\n+        return sprintf($this->prepare(self::INVERTED_SECTION, $level), $method, $id, $filters, $this->walk($nodes, $level));\n     }\n \n     const PARTIAL_INDENT = ', $indent . %s';"
        },
        {
            "index":343,
            "vuln_id":"GHSA-6898-wx94-8jq8",
            "cwe_id":"{'CWE-74'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/mytrile\/node-libnotify\/commit\/dfe7801d73a0dda10663a0ff3d0ec8b4d5f0d448'}",
            "dataset":"osv",
            "summary":"Potential Command Injection in libnotify Versions 1.0.3 and earlier of libnotify are affected by a shell command injection vulnerability. This may result in execution of arbitrary shell commands, if user input is passed into libnotify.notify.\n\nUntrusted input passed in the call to libnotify.notify could result in execution of shell commands. Callers may be unaware of this.\n\n### Example\n```\nvar libnotify = require('libnotify')\nlibnotify.notify('UNTRUSTED INPUT', { title: \\\"\\\" }, function () {\n    console.log(arguments);\n})\n```\n\nSpecial thanks to Neal Poole for submitting the pull request to fix this issue.\n\n\n## Recommendation\n\nUpdate to version 1.0.4 or greater",
            "published_date":"2020-08-31",
            "chain_len":1,
            "project":"https:\/\/github.com\/mytrile\/node-libnotify",
            "commit_href":"https:\/\/github.com\/mytrile\/node-libnotify\/commit\/dfe7801d73a0dda10663a0ff3d0ec8b4d5f0d448",
            "commit_sha":"dfe7801d73a0dda10663a0ff3d0ec8b4d5f0d448",
            "patch":"SINGLE",
            "chain_ord":"['dfe7801d73a0dda10663a0ff3d0ec8b4d5f0d448']",
            "before_first_fix_commit":"{'8e2e7306088624503ba5eec592b502c4f97d8846', '688e135134c4e45abf18d42ddb85a7ab8c9a7ab8'}",
            "last_fix_commit":"dfe7801d73a0dda10663a0ff3d0ec8b4d5f0d448",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/14\/2013, 19:46:34",
            "message":"Merge pull request #4 from nealpoole\/exec-fix\n\nReplacing call to exec with execFile.",
            "author":"Dimitar Kostov",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 5, 'total': 9}",
            "files":"{'lib\/libnotify.js': {'additions': 4, 'deletions': 5, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mytrile\/node-libnotify\/raw\/dfe7801d73a0dda10663a0ff3d0ec8b4d5f0d448\/lib%2Flibnotify.js', 'patch': '@@ -55,18 +55,17 @@ exports.binVersion = function(callback) {\\n \\n exports.notify = function(msg, options, callback) {\\n   var image,\\n-      args = [\\'notify-send\\',\\'\"\\' + msg + \\'\"\\'],\\n+      args = [msg],\\n       options = options || {}\\n   this.binVersion(function(err, version){\\n     if (err) return callback(err)\\n-    if (image = options.image) args.push(\\'-i \\' + image)\\n+    if (image = options.image) args.push(\\'-i\\', image)\\n     if (options.time) args.push(\\'-t\\', options.time)\\n     if (options.category) args.push(\\'-c\\', options.category)\\n     if (options.urgency) args.push(\\'-u\\', options.urgency)\\n     if (options.title) {\\n-      args.shift()\\n-      args.unshift(\\'notify-send\\', \\'\"\\'+ options.title +\\'\"\\')\\n+      args.unshift(options.title)\\n     }\\n-    child_process.exec(args.join(\\' \\'), callback)\\n+    child_process.execFile(\\'notify-send\\', args, {}, callback)\\n   })\\n }'}}",
            "message_norm":"merge pull request #4 from nealpoole\/exec-fix\n\nreplacing call to exec with execfile.",
            "language":"en",
            "entities":"[('#4', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/libnotify.js'])",
            "num_files":1.0,
            "patch_content":"From 8e2e7306088624503ba5eec592b502c4f97d8846 Mon Sep 17 00:00:00 2001\nFrom: Neal Poole <neal@cs.brown.edu>\nDate: Tue, 14 May 2013 15:39:05 -0400\nSubject: [PATCH] Replacing call to exec with execFile.\n\n---\n lib\/libnotify.js | 9 ++++-----\n 1 file changed, 4 insertions(+), 5 deletions(-)\n\ndiff --git a\/lib\/libnotify.js b\/lib\/libnotify.js\nindex 2c1567b..7e59267 100644\n--- a\/lib\/libnotify.js\n+++ b\/lib\/libnotify.js\n@@ -55,18 +55,17 @@ exports.binVersion = function(callback) {\n \n exports.notify = function(msg, options, callback) {\n   var image,\n-      args = ['notify-send','\"' + msg + '\"'],\n+      args = [msg],\n       options = options || {}\n   this.binVersion(function(err, version){\n     if (err) return callback(err)\n-    if (image = options.image) args.push('-i ' + image)\n+    if (image = options.image) args.push('-i', image)\n     if (options.time) args.push('-t', options.time)\n     if (options.category) args.push('-c', options.category)\n     if (options.urgency) args.push('-u', options.urgency)\n     if (options.title) {\n-      args.shift()\n-      args.unshift('notify-send', '\"'+ options.title +'\"')\n+      args.unshift(options.title)\n     }\n-    child_process.exec(args.join(' '), callback)\n+    child_process.execFile('notify-send', args, {}, callback)\n   })\n }"
        },
        {
            "index":295,
            "vuln_id":"GHSA-cv3f-px9r-54hm",
            "cwe_id":"{'CWE-200'}",
            "score":4.7,
            "chain":"{'https:\/\/github.com\/phusion\/passenger\/commit\/4043718264095cde6623c2cbe8c644541036d7bf'}",
            "dataset":"osv",
            "summary":"Phusion Passenger information disclosure In agent\/Core\/SpawningKit\/Spawner.h in Phusion Passenger 5.1.10 (fixed in Passenger Open Source 5.1.11 and Passenger Enterprise 5.1.10), if Passenger is running as root, it is possible to list the contents of arbitrary files on a system by symlinking a file named REVISION from the application root folder to a file of choice and querying passenger-status --show=xml.",
            "published_date":"2022-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/phusion\/passenger",
            "commit_href":"https:\/\/github.com\/phusion\/passenger\/commit\/4043718264095cde6623c2cbe8c644541036d7bf",
            "commit_sha":"4043718264095cde6623c2cbe8c644541036d7bf",
            "patch":"SINGLE",
            "chain_ord":"['4043718264095cde6623c2cbe8c644541036d7bf']",
            "before_first_fix_commit":"{'a63f1e9cd8148dfaac08b00d74ef2b59bc2c9dd4'}",
            "last_fix_commit":"4043718264095cde6623c2cbe8c644541036d7bf",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/11\/2017, 13:55:07",
            "message":"Disable unused feature.",
            "author":"Daniel Knoppel (Phusion)",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'src\/agent\/Core\/SpawningKit\/Spawner.h': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/phusion\/passenger\/raw\/4043718264095cde6623c2cbe8c644541036d7bf\/src%2Fagent%2FCore%2FSpawningKit%2FSpawner.h', 'patch': '@@ -721,7 +721,6 @@ class Spawner {\\n \\t\\tprepareChroot(info, options);\\n \\t\\tinfo.userSwitching = prepareUserSwitching(options);\\n \\t\\tprepareSwitchingWorkingDirectory(info, options);\\n-\\t\\tinferApplicationInfo(info);\\n \\t\\treturn info;\\n \\t}\\n \\n@@ -775,6 +774,7 @@ class Spawner {\\n \\t\\tassert(info.appRootPathsInsideChroot.back() == info.appRootInsideChroot);\\n \\t}\\n \\n+#ifdef false\\n \\tvoid inferApplicationInfo(SpawnPreparationInfo &info) const {\\n \\t\\tinfo.codeRevision = readFromRevisionFile(info);\\n \\t\\tif (info.codeRevision.empty()) {\\n@@ -817,6 +817,7 @@ class Spawner {\\n \\t\\t\\treturn string();\\n \\t\\t}\\n \\t}\\n+#endif\\n \\n \\tbool shouldLoadShellEnvvars(const Options &options, const SpawnPreparationInfo &preparation) const {\\n \\t\\tif (options.loadShellEnvvars) {'}}",
            "message_norm":"disable unused feature.",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/agent\/Core\/SpawningKit\/Spawner.h'])",
            "num_files":1.0,
            "patch_content":"From 4043718264095cde6623c2cbe8c644541036d7bf Mon Sep 17 00:00:00 2001\nFrom: \"Daniel Knoppel (Phusion)\" <daniel@phusion.nl>\nDate: Wed, 11 Oct 2017 15:55:07 +0200\nSubject: [PATCH] Disable unused feature.\n\n---\n src\/agent\/Core\/SpawningKit\/Spawner.h | 3 ++-\n 1 file changed, 2 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/agent\/Core\/SpawningKit\/Spawner.h b\/src\/agent\/Core\/SpawningKit\/Spawner.h\nindex e65034ae91..99dedb852f 100644\n--- a\/src\/agent\/Core\/SpawningKit\/Spawner.h\n+++ b\/src\/agent\/Core\/SpawningKit\/Spawner.h\n@@ -721,7 +721,6 @@ class Spawner {\n \t\tprepareChroot(info, options);\n \t\tinfo.userSwitching = prepareUserSwitching(options);\n \t\tprepareSwitchingWorkingDirectory(info, options);\n-\t\tinferApplicationInfo(info);\n \t\treturn info;\n \t}\n \n@@ -775,6 +774,7 @@ class Spawner {\n \t\tassert(info.appRootPathsInsideChroot.back() == info.appRootInsideChroot);\n \t}\n \n+#ifdef false\n \tvoid inferApplicationInfo(SpawnPreparationInfo &info) const {\n \t\tinfo.codeRevision = readFromRevisionFile(info);\n \t\tif (info.codeRevision.empty()) {\n@@ -817,6 +817,7 @@ class Spawner {\n \t\t\treturn string();\n \t\t}\n \t}\n+#endif\n \n \tbool shouldLoadShellEnvvars(const Options &options, const SpawnPreparationInfo &preparation) const {\n \t\tif (options.loadShellEnvvars) {"
        },
        {
            "index":954,
            "vuln_id":"GHSA-g6ww-v8xp-vmwg",
            "cwe_id":"{'CWE-1321', 'CWE-20'}",
            "score":7.2,
            "chain":"{'https:\/\/github.com\/chaijs\/pathval\/pull\/58\/commits\/21a9046cfa0c2697cb41990f3b4316db410e6c8a'}",
            "dataset":"osv",
            "summary":"Prototype pollution in pathval A prototype pollution vulnerability affects all versions of package pathval under 1.1.1.",
            "published_date":"2022-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/chaijs\/pathval",
            "commit_href":"https:\/\/github.com\/chaijs\/pathval\/pull\/58\/commits\/21a9046cfa0c2697cb41990f3b4316db410e6c8a",
            "commit_sha":"21a9046cfa0c2697cb41990f3b4316db410e6c8a",
            "patch":"SINGLE",
            "chain_ord":"['21a9046cfa0c2697cb41990f3b4316db410e6c8a']",
            "before_first_fix_commit":"{'a1230184a33a18f4eb3a92817e9b7492e8082903'}",
            "last_fix_commit":"21a9046cfa0c2697cb41990f3b4316db410e6c8a",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/25\/2020, 12:37:44",
            "message":"fix: \ud83d\udc1b fix prototype pollution",
            "author":"Adam Gold",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'index.js': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/chaijs\/pathval\/raw\/21a9046cfa0c2697cb41990f3b4316db410e6c8a\/index.js', 'patch': '@@ -76,6 +76,9 @@ function parsePath(path) {\\n   var str = path.replace(\/([^\\\\\\\\])\\\\[\/g, \\'$1.[\\');\\n   var parts = str.match(\/(\\\\\\\\\\\\.|[^.]+?)+\/g);\\n   return parts.map(function mapMatches(value) {\\n+    if (value === \"constructor\" || value === \"__proto__\" || value === \"prototype\") {\\n+      return {}\\n+    }\\n     var regexp = \/^\\\\[(\\\\d+)\\\\]$\/;\\n     var mArr = regexp.exec(value);\\n     var parsed = null;'}}",
            "message_norm":"fix: \ud83d\udc1b fix prototype pollution",
            "language":"fr",
            "entities":"[('fix', 'ACTION', ''), ('prototype pollution', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From 21a9046cfa0c2697cb41990f3b4316db410e6c8a Mon Sep 17 00:00:00 2001\nFrom: Adam Gold <adamgold7@gmail.com>\nDate: Tue, 25 Aug 2020 15:37:44 +0300\nSubject: [PATCH] =?UTF-8?q?fix:=20=F0=9F=90=9B=20fix=20prototype=20polluti?=\n =?UTF-8?q?on?=\nMIME-Version: 1.0\nContent-Type: text\/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\n\n---\n index.js | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/index.js b\/index.js\nindex 1ec2148..a5b46c3 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -76,6 +76,9 @@ function parsePath(path) {\n   var str = path.replace(\/([^\\\\])\\[\/g, '$1.[');\n   var parts = str.match(\/(\\\\\\.|[^.]+?)+\/g);\n   return parts.map(function mapMatches(value) {\n+    if (value === \"constructor\" || value === \"__proto__\" || value === \"prototype\") {\n+      return {}\n+    }\n     var regexp = \/^\\[(\\d+)\\]$\/;\n     var mArr = regexp.exec(value);\n     var parsed = null;"
        },
        {
            "index":359,
            "vuln_id":"GHSA-23f2-vgr6-fwv7",
            "cwe_id":"{'CWE-74'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/librenms\/librenms\/commit\/8b82341cb742e7bd4966964b399012f7ba017e0b'}",
            "dataset":"osv",
            "summary":"Command injection in librenms LibreNMS v22.3.0 was discovered to contain multiple command injection vulnerabilities via the service_ip, hostname, and service_param parameters.",
            "published_date":"2022-06-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/librenms\/librenms",
            "commit_href":"https:\/\/github.com\/librenms\/librenms\/commit\/8b82341cb742e7bd4966964b399012f7ba017e0b",
            "commit_sha":"8b82341cb742e7bd4966964b399012f7ba017e0b",
            "patch":"SINGLE",
            "chain_ord":"['8b82341cb742e7bd4966964b399012f7ba017e0b']",
            "before_first_fix_commit":"{'3d0e095eb777845c39ed11d0981e0cef143d9f66'}",
            "last_fix_commit":"8b82341cb742e7bd4966964b399012f7ba017e0b",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/21\/2022, 02:32:36",
            "message":"Fix services command injection (#13932)\n\n* fix services command injection\r\n\r\n* Clean more variables\r\n\r\n* Update services.inc.php\r\n\r\n* Update services.inc.php",
            "author":"Tony Murray",
            "comments":"{'com_1': {'author': 'bakerds', 'datetime': '04\/22\/2022, 11:25:17', 'body': 'Hey @murrant, it looks like this breaks using IPv6 literals in the IP field of a service'}}",
            "stats":"{'additions': 6, 'deletions': 1, 'total': 7}",
            "files":"{'includes\/services.inc.php': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/librenms\/librenms\/raw\/8b82341cb742e7bd4966964b399012f7ba017e0b\/includes%2Fservices.inc.php', 'patch': \"@@ -4,6 +4,7 @@\\n use LibreNMS\\\\Alert\\\\AlertRules;\\n use LibreNMS\\\\Config;\\n use LibreNMS\\\\RRD\\\\RrdDefinition;\\n+use LibreNMS\\\\Util\\\\Clean;\\n \\n function get_service_status($device = null)\\n {\\n@@ -120,6 +121,10 @@ function poll_service($service)\\n {\\n     $update = [];\\n     $old_status = $service['service_status'];\\n+    $service['service_type'] = Clean::fileName($service['service_type']);\\n+    $service['service_ip'] = Clean::fileName($service['service_ip']);\\n+    $service['hostname'] = Clean::fileName($service['hostname']);\\n+    $service['overwrite_ip'] = Clean::fileName($service['overwrite_ip']);\\n     $check_cmd = '';\\n \\n     \/\/ if we have a script for this check, use it.\\n@@ -130,7 +135,7 @@ function poll_service($service)\\n \\n     \/\/ If we do not have a cmd from the check script, build one.\\n     if ($check_cmd == '') {\\n-        $check_cmd = Config::get('nagios_plugins') . '\/check_' . $service['service_type'] . ' -H ' . ($service['service_ip'] ? $service['service_ip'] : $service['hostname']);\\n+        $check_cmd = Config::get('nagios_plugins') . '\/check_' . $service['service_type'] . ' -H ' . ($service['service_ip'] ?: $service['hostname']);\\n         $check_cmd .= ' ' . $service['service_param'];\\n     }\"}}",
            "message_norm":"fix services command injection (#13932)\n\n* fix services command injection\r\n\r\n* clean more variables\r\n\r\n* update services.inc.php\r\n\r\n* update services.inc.php",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('command injection', 'SECWORD', ''), ('#13932', 'ISSUE', ''), ('command injection', 'SECWORD', ''), ('update', 'ACTION', ''), ('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['includes\/services.inc.php'])",
            "num_files":1.0,
            "patch_content":"From 8b82341cb742e7bd4966964b399012f7ba017e0b Mon Sep 17 00:00:00 2001\nFrom: Tony Murray <murraytony@gmail.com>\nDate: Wed, 20 Apr 2022 21:32:36 -0500\nSubject: [PATCH] Fix services command injection (#13932)\n\n* fix services command injection\n\n* Clean more variables\n\n* Update services.inc.php\n\n* Update services.inc.php\n---\n includes\/services.inc.php | 7 ++++++-\n 1 file changed, 6 insertions(+), 1 deletion(-)\n\ndiff --git a\/includes\/services.inc.php b\/includes\/services.inc.php\nindex a4c33161c10a..ddfaf638382b 100644\n--- a\/includes\/services.inc.php\n+++ b\/includes\/services.inc.php\n@@ -4,6 +4,7 @@\n use LibreNMS\\Alert\\AlertRules;\n use LibreNMS\\Config;\n use LibreNMS\\RRD\\RrdDefinition;\n+use LibreNMS\\Util\\Clean;\n \n function get_service_status($device = null)\n {\n@@ -120,6 +121,10 @@ function poll_service($service)\n {\n     $update = [];\n     $old_status = $service['service_status'];\n+    $service['service_type'] = Clean::fileName($service['service_type']);\n+    $service['service_ip'] = Clean::fileName($service['service_ip']);\n+    $service['hostname'] = Clean::fileName($service['hostname']);\n+    $service['overwrite_ip'] = Clean::fileName($service['overwrite_ip']);\n     $check_cmd = '';\n \n     \/\/ if we have a script for this check, use it.\n@@ -130,7 +135,7 @@ function poll_service($service)\n \n     \/\/ If we do not have a cmd from the check script, build one.\n     if ($check_cmd == '') {\n-        $check_cmd = Config::get('nagios_plugins') . '\/check_' . $service['service_type'] . ' -H ' . ($service['service_ip'] ? $service['service_ip'] : $service['hostname']);\n+        $check_cmd = Config::get('nagios_plugins') . '\/check_' . $service['service_type'] . ' -H ' . ($service['service_ip'] ?: $service['hostname']);\n         $check_cmd .= ' ' . $service['service_param'];\n     }"
        },
        {
            "index":471,
            "vuln_id":"GHSA-r33q-22hv-j29q",
            "cwe_id":"{'CWE-400'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/ethereum\/go-ethereum\/commit\/bddd103a9f0af27ef533f04e06ea429cf76b6d46'}",
            "dataset":"osv",
            "summary":"Denial of service in github.com\/ethereum\/go-ethereum ### Impact\n\nA DoS vulnerability can make a LES server crash via malicious `GetProofsV2` request from a connected LES client.\n\n### Patches\n\nThe vulnerability was patched in https:\/\/github.com\/ethereum\/go-ethereum\/pull\/21896. \n\n### Workarounds\n\nThis vulnerability only concerns users explicitly enabling `les` server; disabling `les` prevents the exploit. \nIt can also be patched by manually applying the patch in https:\/\/github.com\/ethereum\/go-ethereum\/pull\/21896. \n\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [go-ethereum](https:\/\/github.com\/ethereum\/go-ethereum)\n* Email us at [security@ethereum.org](mailto:security@ethereum.org)",
            "published_date":"2021-06-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/ethereum\/go-ethereum",
            "commit_href":"https:\/\/github.com\/ethereum\/go-ethereum\/commit\/bddd103a9f0af27ef533f04e06ea429cf76b6d46",
            "commit_sha":"bddd103a9f0af27ef533f04e06ea429cf76b6d46",
            "patch":"SINGLE",
            "chain_ord":"['bddd103a9f0af27ef533f04e06ea429cf76b6d46']",
            "before_first_fix_commit":"{'6b5840961407960a06ed20cb5dd1b782080653ff'}",
            "last_fix_commit":"bddd103a9f0af27ef533f04e06ea429cf76b6d46",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/24\/2020, 09:55:17",
            "message":"les: fix GetProofsV2 bug (#21896)",
            "author":"Felf\u00f6ldi Zsolt",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 4, 'total': 6}",
            "files":"{'les\/server_handler.go': {'additions': 2, 'deletions': 4, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ethereum\/go-ethereum\/raw\/bddd103a9f0af27ef533f04e06ea429cf76b6d46\/les%2Fserver_handler.go', 'patch': '@@ -610,6 +610,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\\n \\t\\tvar (\\n \\t\\t\\tlastBHash common.Hash\\n \\t\\t\\troot      common.Hash\\n+\\t\\t\\theader    *types.Header\\n \\t\\t)\\n \\t\\treqCnt := len(req.Reqs)\\n \\t\\tif accept(req.ReqID, uint64(reqCnt), MaxProofsFetch) {\\n@@ -624,10 +625,6 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\\n \\t\\t\\t\\t\\t\\treturn\\n \\t\\t\\t\\t\\t}\\n \\t\\t\\t\\t\\t\/\/ Look up the root hash belonging to the request\\n-\\t\\t\\t\\t\\tvar (\\n-\\t\\t\\t\\t\\t\\theader *types.Header\\n-\\t\\t\\t\\t\\t\\ttrie   state.Trie\\n-\\t\\t\\t\\t\\t)\\n \\t\\t\\t\\t\\tif request.BHash != lastBHash {\\n \\t\\t\\t\\t\\t\\troot, lastBHash = common.Hash{}, request.BHash\\n \\n@@ -654,6 +651,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\\n \\t\\t\\t\\t\\t\/\/ Open the account or storage trie for the request\\n \\t\\t\\t\\t\\tstatedb := h.blockchain.StateCache()\\n \\n+\\t\\t\\t\\t\\tvar trie state.Trie\\n \\t\\t\\t\\t\\tswitch len(request.AccKey) {\\n \\t\\t\\t\\t\\tcase 0:\\n \\t\\t\\t\\t\\t\\t\/\/ No account key specified, open an account trie'}}",
            "message_norm":"les: fix getproofsv2 bug (#21896)",
            "language":"af",
            "entities":"[('bug', 'FLAW', ''), ('#21896', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['les\/server_handler.go'])",
            "num_files":1.0,
            "patch_content":"From bddd103a9f0af27ef533f04e06ea429cf76b6d46 Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Felf=C3=B6ldi=20Zsolt?= <zsfelfoldi@gmail.com>\nDate: Tue, 24 Nov 2020 10:55:17 +0100\nSubject: [PATCH] les: fix GetProofsV2 bug (#21896)\n\n---\n les\/server_handler.go | 6 ++----\n 1 file changed, 2 insertions(+), 4 deletions(-)\n\ndiff --git a\/les\/server_handler.go b\/les\/server_handler.go\nindex d3e2c956b3ea..c0600b3686d3 100644\n--- a\/les\/server_handler.go\n+++ b\/les\/server_handler.go\n@@ -610,6 +610,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\tvar (\n \t\t\tlastBHash common.Hash\n \t\t\troot      common.Hash\n+\t\t\theader    *types.Header\n \t\t)\n \t\treqCnt := len(req.Reqs)\n \t\tif accept(req.ReqID, uint64(reqCnt), MaxProofsFetch) {\n@@ -624,10 +625,6 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\t\t\t\t\treturn\n \t\t\t\t\t}\n \t\t\t\t\t\/\/ Look up the root hash belonging to the request\n-\t\t\t\t\tvar (\n-\t\t\t\t\t\theader *types.Header\n-\t\t\t\t\t\ttrie   state.Trie\n-\t\t\t\t\t)\n \t\t\t\t\tif request.BHash != lastBHash {\n \t\t\t\t\t\troot, lastBHash = common.Hash{}, request.BHash\n \n@@ -654,6 +651,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\t\t\t\t\/\/ Open the account or storage trie for the request\n \t\t\t\t\tstatedb := h.blockchain.StateCache()\n \n+\t\t\t\t\tvar trie state.Trie\n \t\t\t\t\tswitch len(request.AccKey) {\n \t\t\t\t\tcase 0:\n \t\t\t\t\t\t\/\/ No account key specified, open an account trie"
        },
        {
            "index":117,
            "vuln_id":"GHSA-hmg3-c7xj-6qwm",
            "cwe_id":"{'CWE-131'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e922ccdf6bf46a3a52641f99fd47d54c1decd13'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `SparseTensorToCSRSparseMatrix` ### Impact\nAn attacker can trigger a denial of service via a `CHECK`-fail in converting sparse tensors to CSR Sparse matrices:\n\n```python\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\n\nindices_array = np.array([[0, 0]])\nvalue_array = np.array([0.0], dtype=np.float32)\ndense_shape = [0, 0]\n\nst = tf.SparseTensor(indices_array, value_array, dense_shape)\n\nvalues_tensor = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n       st.indices, st.values, st.dense_shape)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/800346f2c03a27e182dd4fba48295f65e7790739\/tensorflow\/core\/kernels\/sparse\/kernels.cc#L66) does a double redirection to access an element of an array allocated on the heap:\n\n```cc\ncsr_row_ptr(indices(i, 0) + 1) += 1;\n```\n                      \nIf the value at `indices(i, 0)` is such that `indices(i, 0) + 1` is outside the bounds of `csr_row_ptr`, this results in writing outside of bounds of heap allocated data.\n\n### Patches\nWe have patched the issue in GitHub commit [1e922ccdf6bf46a3a52641f99fd47d54c1decd13](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e922ccdf6bf46a3a52641f99fd47d54c1decd13).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e922ccdf6bf46a3a52641f99fd47d54c1decd13",
            "commit_sha":"1e922ccdf6bf46a3a52641f99fd47d54c1decd13",
            "patch":"SINGLE",
            "chain_ord":"['1e922ccdf6bf46a3a52641f99fd47d54c1decd13']",
            "before_first_fix_commit":"{'800346f2c03a27e182dd4fba48295f65e7790739'}",
            "last_fix_commit":"1e922ccdf6bf46a3a52641f99fd47d54c1decd13",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2021, 17:41:12",
            "message":"Fix crash in `SparseTensorToCSRSparseMatrixCPUFunctor`\n\nPiperOrigin-RevId: 370110290\nChange-Id: I4451e92661a55c2180f80d38b67a9b50bf5edec5",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/sparse\/kernels.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1e922ccdf6bf46a3a52641f99fd47d54c1decd13\/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fkernels.cc', 'patch': '@@ -22,6 +22,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/tensor_types.h\"\\n #include \"tensorflow\/core\/lib\/core\/errors.h\"\\n #include \"tensorflow\/core\/lib\/core\/status.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n \\n namespace tensorflow {\\n namespace functor {\\n@@ -63,6 +64,11 @@ Status SparseTensorToCSRSparseMatrixCPUFunctor::operator()(\\n \\n     for (int64 i = 0; i < total_nnz; ++i) {\\n       \/\/ For now, the rows pointers store the corresponding row counts.\\n+      int64 ix = indices(i, 0) + 1;\\n+      if (ix >= csr_row_ptr.size()) {\\n+        return errors::InvalidArgument(\"Got an index \", ix,\\n+                                       \" that is outside of csr_row_ptr\");\\n+      }\\n       csr_row_ptr(indices(i, 0) + 1) += 1;\\n       csr_col_ind(i) = indices(i, 1);\\n     }'}}",
            "message_norm":"fix crash in `sparsetensortocsrsparsematrixcpufunctor`\n\npiperorigin-revid: 370110290\nchange-id: i4451e92661a55c2180f80d38b67a9b50bf5edec5",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('370110290', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse\/kernels.cc'])",
            "num_files":1.0,
            "patch_content":"From 1e922ccdf6bf46a3a52641f99fd47d54c1decd13 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 23 Apr 2021 10:41:12 -0700\nSubject: [PATCH] Fix crash in `SparseTensorToCSRSparseMatrixCPUFunctor`\n\nPiperOrigin-RevId: 370110290\nChange-Id: I4451e92661a55c2180f80d38b67a9b50bf5edec5\n---\n tensorflow\/core\/kernels\/sparse\/kernels.cc | 6 ++++++\n 1 file changed, 6 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse\/kernels.cc b\/tensorflow\/core\/kernels\/sparse\/kernels.cc\nindex 0eea9f1feed5c3..dff9aeb83ccfec 100644\n--- a\/tensorflow\/core\/kernels\/sparse\/kernels.cc\n+++ b\/tensorflow\/core\/kernels\/sparse\/kernels.cc\n@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/tensor_types.h\"\n #include \"tensorflow\/core\/lib\/core\/errors.h\"\n #include \"tensorflow\/core\/lib\/core\/status.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n \n namespace tensorflow {\n namespace functor {\n@@ -63,6 +64,11 @@ Status SparseTensorToCSRSparseMatrixCPUFunctor::operator()(\n \n     for (int64 i = 0; i < total_nnz; ++i) {\n       \/\/ For now, the rows pointers store the corresponding row counts.\n+      int64 ix = indices(i, 0) + 1;\n+      if (ix >= csr_row_ptr.size()) {\n+        return errors::InvalidArgument(\"Got an index \", ix,\n+                                       \" that is outside of csr_row_ptr\");\n+      }\n       csr_row_ptr(indices(i, 0) + 1) += 1;\n       csr_col_ind(i) = indices(i, 1);\n     }"
        },
        {
            "index":137,
            "vuln_id":"GHSA-wg8p-w946-c482",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/56e450c3adf75c707500d7231a78c9fc894c7f13'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in ShowDoc ShowDoc prior to 2.10.4 is vulnerable to stored cross-site scripting via file upload.",
            "published_date":"2022-03-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/56e450c3adf75c707500d7231a78c9fc894c7f13",
            "commit_sha":"56e450c3adf75c707500d7231a78c9fc894c7f13",
            "patch":"SINGLE",
            "chain_ord":"['56e450c3adf75c707500d7231a78c9fc894c7f13']",
            "before_first_fix_commit":"{'237ac6d43bf3728bf3587c486a23b4a48ea7acb3'}",
            "last_fix_commit":"56e450c3adf75c707500d7231a78c9fc894c7f13",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2022, 12:15:13",
            "message":"file upload bug",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'server\/Application\/Api\/Model\/AttachmentModel.class.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/56e450c3adf75c707500d7231a78c9fc894c7f13\/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -329,7 +329,7 @@ public function isAllowedFilename($filename){\\n \\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso','.bz2','.epub',\\n \\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n \\t\\t\\t'.doc','.docx','.odt','.rtf','.docm','.dotm','.dot','.dotx','.wps','.wpt',\\n-\\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.md','.psd','.csv',\\n+\\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\\n \\t\\t\\t'.cer','.ppt','.pub','.properties','.json','.css',\\n \\t\\t\\t) ;\"}}",
            "message_norm":"file upload bug",
            "language":"ro",
            "entities":"[('bug', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Model\/AttachmentModel.class.php'])",
            "num_files":1.0,
            "patch_content":"From 56e450c3adf75c707500d7231a78c9fc894c7f13 Mon Sep 17 00:00:00 2001\nFrom: star7th <xing7th@gmail.com>\nDate: Mon, 14 Mar 2022 20:15:13 +0800\nSubject: [PATCH] file upload bug\n\n---\n server\/Application\/Api\/Model\/AttachmentModel.class.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/server\/Application\/Api\/Model\/AttachmentModel.class.php b\/server\/Application\/Api\/Model\/AttachmentModel.class.php\nindex 7f69b3cba..3ce94ceaf 100644\n--- a\/server\/Application\/Api\/Model\/AttachmentModel.class.php\n+++ b\/server\/Application\/Api\/Model\/AttachmentModel.class.php\n@@ -329,7 +329,7 @@ public function isAllowedFilename($filename){\n \t\t\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso','.bz2','.epub',\n \t\t\t'.pdf','.ofd','.swf','.epub','.xps',\n \t\t\t'.doc','.docx','.odt','.rtf','.docm','.dotm','.dot','.dotx','.wps','.wpt',\n-\t\t\t'.ppt','.pptx','.xls','.xlsx','.txt','.md','.psd','.csv',\n+\t\t\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\n \t\t\t'.cer','.ppt','.pub','.properties','.json','.css',\n \t\t\t) ;"
        },
        {
            "index":879,
            "vuln_id":"GHSA-vc5r-xfc4-4x22",
            "cwe_id":"{'CWE-79'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/pimcore\/data-hub\/commit\/15d5b57af2466eebd3bbc531ead5dafa35d0a36e'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Pimcore Datahub Pimcore Datahub prior to 1.2.4 is vulnerable to stored cross-site scripting. An admin user accessing Datahub triggers the attack, which may result in the user's cookie being stolen.",
            "published_date":"2022-03-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/data-hub",
            "commit_href":"https:\/\/github.com\/pimcore\/data-hub\/commit\/15d5b57af2466eebd3bbc531ead5dafa35d0a36e",
            "commit_sha":"15d5b57af2466eebd3bbc531ead5dafa35d0a36e",
            "patch":"SINGLE",
            "chain_ord":"['15d5b57af2466eebd3bbc531ead5dafa35d0a36e']",
            "before_first_fix_commit":"{'1561fa5cda0d1a79139efbd2113e42a63d5602e4'}",
            "last_fix_commit":"15d5b57af2466eebd3bbc531ead5dafa35d0a36e",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/16\/2022, 13:24:41",
            "message":"follow up to https:\/\/github.com\/pimcore\/data-hub\/pull\/462",
            "author":"dpahuja",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/Controller\/ConfigController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/data-hub\/raw\/15d5b57af2466eebd3bbc531ead5dafa35d0a36e\/src%2FController%2FConfigController.php', 'patch': \"@@ -50,7 +50,7 @@ private function buildItem($configuration): array\\n \\n         return [\\n             'id' => $name,\\n-            'text' => $name,\\n+            'text' => htmlspecialchars($name),\\n             'type' => 'config',\\n             'iconCls' => 'plugin_pimcore_datahub_icon_' . $type,\\n             'expandable' => false,\"}}",
            "message_norm":"follow up to https:\/\/github.com\/pimcore\/data-hub\/pull\/462",
            "language":"en",
            "entities":"[('https:\/\/github.com\/pimcore\/data-hub\/pull\/462', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Controller\/ConfigController.php'])",
            "num_files":1.0,
            "patch_content":"From 15d5b57af2466eebd3bbc531ead5dafa35d0a36e Mon Sep 17 00:00:00 2001\nFrom: dpahuja <divesh.pahuja@gmail.com>\nDate: Wed, 16 Mar 2022 14:24:41 +0100\nSubject: [PATCH] follow up to https:\/\/github.com\/pimcore\/data-hub\/pull\/462\n\n---\n src\/Controller\/ConfigController.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/Controller\/ConfigController.php b\/src\/Controller\/ConfigController.php\nindex 286ba4e6d..1d248114a 100644\n--- a\/src\/Controller\/ConfigController.php\n+++ b\/src\/Controller\/ConfigController.php\n@@ -50,7 +50,7 @@ private function buildItem($configuration): array\n \n         return [\n             'id' => $name,\n-            'text' => $name,\n+            'text' => htmlspecialchars($name),\n             'type' => 'config',\n             'iconCls' => 'plugin_pimcore_datahub_icon_' . $type,\n             'expandable' => false,"
        },
        {
            "index":682,
            "vuln_id":"GHSA-4278-2v5v-65r4",
            "cwe_id":"{'CWE-787', 'CWE-120'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eebb96c2830d48597d055d247c0e9aebaea94cd5'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `RaggedBinCount` ### Impact\nIf the `splits` argument of `RaggedBincount` does not specify a valid [`SparseTensor`](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/sparse\/SparseTensor), then an attacker can trigger a heap buffer overflow:\n\n```python\nimport tensorflow as tf\ntf.raw_ops.RaggedBincount(splits=[0], values=[1,1,1,1,1], size=5, weights=[1,2,3,4], binary_output=False)\n```\n\nThis will cause a read from outside the bounds of the `splits` tensor buffer in the [implementation of the `RaggedBincount` op](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8b677d79167799f71c42fd3fa074476e0295413a\/tensorflow\/core\/kernels\/bincount_op.cc#L430-L433):\n\n```cc\n    for (int idx = 0; idx < num_values; ++idx) {\n      while (idx >= splits(batch_idx)) {\n        batch_idx++;\n      }\n      ...\n    }\n```\n\nBefore the `for` loop, `batch_idx` is set to 0. The user controls the `splits` array, making it contain only one element, 0. Thus, the code in the `while` loop would increment `batch_idx` and then try to read `splits(1)`, which is outside of bounds.\n\n### Patches\nWe have patched the issue in GitHub commit [eebb96c2830d48597d055d247c0e9aebaea94cd5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eebb96c2830d48597d055d247c0e9aebaea94cd5).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2 and TensorFlow 2.3.3, as these are also affected.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eebb96c2830d48597d055d247c0e9aebaea94cd5",
            "commit_sha":"eebb96c2830d48597d055d247c0e9aebaea94cd5",
            "patch":"SINGLE",
            "chain_ord":"['eebb96c2830d48597d055d247c0e9aebaea94cd5']",
            "before_first_fix_commit":"{'8b677d79167799f71c42fd3fa074476e0295413a'}",
            "last_fix_commit":"eebb96c2830d48597d055d247c0e9aebaea94cd5",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2021, 21:18:51",
            "message":"Fix an invalid address vulnerability in `tf.raw_ops.RaggedBincount`.\n\nPiperOrigin-RevId: 368293153\nChange-Id: I4b4e493d3fd05e7dc55a55de3a041a80a4f275c3",
            "author":"Amit Patankar",
            "comments":"{'com_1': {'author': 'Rayyan335', 'datetime': '05\/14\/2021, 19:00:36', 'body': 'tensorflow\/core\/kernels\/bincount_op.cc'}}",
            "stats":"{'additions': 9, 'deletions': 0, 'total': 9}",
            "files":"{'tensorflow\/core\/kernels\/bincount_op.cc': {'additions': 9, 'deletions': 0, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/eebb96c2830d48597d055d247c0e9aebaea94cd5\/tensorflow%2Fcore%2Fkernels%2Fbincount_op.cc', 'patch': '@@ -420,6 +420,15 @@ class RaggedBincountOp : public OpKernel {\\n     int num_values = values.size();\\n     int batch_idx = 0;\\n \\n+    OP_REQUIRES(ctx, splits(0) == 0,\\n+                errors::InvalidArgument(\"Splits must start with 0, not with \",\\n+                                        splits(0)));\\n+\\n+    OP_REQUIRES(ctx, splits(num_rows) == num_values,\\n+                errors::InvalidArgument(\\n+                    \"Splits must end with the number of values, got \",\\n+                    splits(num_rows), \" instead of \", num_values));\\n+\\n     Tensor* out_t;\\n     OP_REQUIRES_OK(\\n         ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));'}}",
            "message_norm":"fix an invalid address vulnerability in `tf.raw_ops.raggedbincount`.\n\npiperorigin-revid: 368293153\nchange-id: i4b4e493d3fd05e7dc55a55de3a041a80a4f275c3",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('368293153', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/bincount_op.cc'])",
            "num_files":1.0,
            "patch_content":"From eebb96c2830d48597d055d247c0e9aebaea94cd5 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Tue, 13 Apr 2021 14:18:51 -0700\nSubject: [PATCH] Fix an invalid address vulnerability in\n `tf.raw_ops.RaggedBincount`.\n\nPiperOrigin-RevId: 368293153\nChange-Id: I4b4e493d3fd05e7dc55a55de3a041a80a4f275c3\n---\n tensorflow\/core\/kernels\/bincount_op.cc | 9 +++++++++\n 1 file changed, 9 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/bincount_op.cc b\/tensorflow\/core\/kernels\/bincount_op.cc\nindex 35911ee5d5540a..258266ab29d33f 100644\n--- a\/tensorflow\/core\/kernels\/bincount_op.cc\n+++ b\/tensorflow\/core\/kernels\/bincount_op.cc\n@@ -420,6 +420,15 @@ class RaggedBincountOp : public OpKernel {\n     int num_values = values.size();\n     int batch_idx = 0;\n \n+    OP_REQUIRES(ctx, splits(0) == 0,\n+                errors::InvalidArgument(\"Splits must start with 0, not with \",\n+                                        splits(0)));\n+\n+    OP_REQUIRES(ctx, splits(num_rows) == num_values,\n+                errors::InvalidArgument(\n+                    \"Splits must end with the number of values, got \",\n+                    splits(num_rows), \" instead of \", num_values));\n+\n     Tensor* out_t;\n     OP_REQUIRES_OK(\n         ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));"
        },
        {
            "index":154,
            "vuln_id":"GHSA-9cq5-xgg4-x477",
            "cwe_id":"{'CWE-89'}",
            "score":6.7,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/2b34e267e4186125f99bfa420140634ad45801fb'}",
            "dataset":"osv",
            "summary":"SQL Injection in showdoc Showdoc verions 2.10.2 and prior is vulnerable to SQL injection. A patch is available in the `master` branch of the repository.",
            "published_date":"2022-01-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/2b34e267e4186125f99bfa420140634ad45801fb",
            "commit_sha":"2b34e267e4186125f99bfa420140634ad45801fb",
            "patch":"SINGLE",
            "chain_ord":"['2b34e267e4186125f99bfa420140634ad45801fb']",
            "before_first_fix_commit":"{'409c8a1208bbb847046a9496303192980f2e6219'}",
            "last_fix_commit":"2b34e267e4186125f99bfa420140634ad45801fb",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/25\/2022, 12:34:52",
            "message":"bug",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'server\/Application\/Api\/Controller\/AdminUserController.class.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/2b34e267e4186125f99bfa420140634ad45801fb\/server%2FApplication%2FApi%2FController%2FAdminUserController.class.php', 'patch': '@@ -76,7 +76,7 @@ public function addUser(){\\n         $this->checkAdmin();\\n         $username = I(\"post.username\");\\n         $password = I(\"post.password\");\\n-        $uid = I(\"post.uid\");\\n+        $uid = I(\"post.uid\/d\");\\n         $name = I(\"post.name\");\\n         if(!$username){\\n             $this->sendError(10101,\\'\u7528\u6237\u540d\u4e0d\u5141\u8bb8\u4e3a\u7a7a\\');'}}",
            "message_norm":"bug",
            "language":"id",
            "entities":"[('bug', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Controller\/AdminUserController.class.php'])",
            "num_files":1.0,
            "patch_content":"From 2b34e267e4186125f99bfa420140634ad45801fb Mon Sep 17 00:00:00 2001\nFrom: star7th <xing7th@gmail.com>\nDate: Tue, 25 Jan 2022 20:34:52 +0800\nSubject: [PATCH] bug\n\n---\n server\/Application\/Api\/Controller\/AdminUserController.class.php | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/server\/Application\/Api\/Controller\/AdminUserController.class.php b\/server\/Application\/Api\/Controller\/AdminUserController.class.php\nindex edf0f559c..9e966b8cd 100644\n--- a\/server\/Application\/Api\/Controller\/AdminUserController.class.php\n+++ b\/server\/Application\/Api\/Controller\/AdminUserController.class.php\n@@ -76,7 +76,7 @@ public function addUser(){\n         $this->checkAdmin();\n         $username = I(\"post.username\");\n         $password = I(\"post.password\");\n-        $uid = I(\"post.uid\");\n+        $uid = I(\"post.uid\/d\");\n         $name = I(\"post.name\");\n         if(!$username){\n             $this->sendError(10101,'\u7528\u6237\u540d\u4e0d\u5141\u8bb8\u4e3a\u7a7a');"
        },
        {
            "index":397,
            "vuln_id":"GHSA-rh9j-f5f8-rvgc",
            "cwe_id":"{'CWE-295', 'CWE-287'}",
            "score":8.6,
            "chain":"{'https:\/\/github.com\/parse-community\/parse-server\/commit\/ba2b0a9cb9a568817a114b132a4c2e0911d76df1', 'https:\/\/github.com\/parse-community\/parse-server\/pull\/8054\/commits\/0cc299f82e367518f2fe7a53b99f3f801a338cf4', 'https:\/\/github.com\/parse-community\/parse-server\/pull\/8054\/commits\/2084b7c569697a5230e42511799eeac9219db5a9'}",
            "dataset":"osv",
            "summary":"Authentication bypass vulnerability in Apple Game Center auth adapter  ### Impact\nThe certificate in Apple Game Center auth adapter not validated. As a result, authentication could potentially be bypassed by making a fake certificate accessible via certain Apple domains and providing the URL to that certificate in an authData object.\n\n### Patches\nTo prevent this, a new `rootCertificateUrl` property is introduced to the Parse Server Apple Game Center auth adapter which takes the URL to the root certificate of Apple's Game Center authentication certificate. If no value is set, the `rootCertificateUrl` property defaults to the URL of the [current root certificate](https:\/\/developer.apple.com\/news\/?id=stttq465) as of May 27, 2022.\n\nKeep in mind that the root certificate can change at any time (expected to be announced by Apple) and that it is the developer's responsibility to keep the root certificate URL up-to-date when using the Parse Server Apple Game Center auth adapter.\n\n### Workarounds\nNone.\n\n### References\n- https:\/\/github.com\/parse-community\/parse-server\/security\/advisories\/GHSA-rh9j-f5f8-rvgc\n- https:\/\/developer.apple.com\/news\/?id=stttq465\n- https:\/\/github.com\/parse-community\/parse-server\n\n### More information\n* For questions or comments about this vulnerability visit our [community forum](http:\/\/community.parseplatform.org) or [community chat](http:\/\/chat.parseplatform.org)\n* Report other vulnerabilities at [report.parseplatform.org](https:\/\/report.parseplatform.org)",
            "published_date":"2022-06-17",
            "chain_len":3,
            "project":"https:\/\/github.com\/parse-community\/parse-server",
            "commit_href":"https:\/\/github.com\/parse-community\/parse-server\/pull\/8054\/commits\/2084b7c569697a5230e42511799eeac9219db5a9",
            "commit_sha":"2084b7c569697a5230e42511799eeac9219db5a9",
            "patch":"MULTI",
            "chain_ord":"['2084b7c569697a5230e42511799eeac9219db5a9', '0cc299f82e367518f2fe7a53b99f3f801a338cf4', 'ba2b0a9cb9a568817a114b132a4c2e0911d76df1']",
            "before_first_fix_commit":"{'a8aef820afa2c8d87683668c2961e523016bad9b'}",
            "last_fix_commit":"ba2b0a9cb9a568817a114b132a4c2e0911d76df1",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/17\/2022, 14:16:52",
            "message":"Create game_center.pem",
            "author":"Manuel Trezza",
            "comments":null,
            "stats":"{'additions': 28, 'deletions': 0, 'total': 28}",
            "files":"{'spec\/support\/cert\/game_center.pem': {'additions': 28, 'deletions': 0, 'changes': 28, 'status': 'added', 'raw_url': 'https:\/\/github.com\/parse-community\/parse-server\/raw\/2084b7c569697a5230e42511799eeac9219db5a9\/spec%2Fsupport%2Fcert%2Fgame_center.pem', 'patch': '@@ -0,0 +1,28 @@\\n+-----BEGIN CERTIFICATE-----\\n+MIIEvDCCA6SgAwIBAgIQXRHxNXkw1L9z5\/3EZ\/T\/hDANBgkqhkiG9w0BAQsFADB\/\\n+MQswCQYDVQQGEwJVUzEdMBsGA1UEChMUU3ltYW50ZWMgQ29ycG9yYXRpb24xHzAd\\n+BgNVBAsTFlN5bWFudGVjIFRydXN0IE5ldHdvcmsxMDAuBgNVBAMTJ1N5bWFudGVj\\n+IENsYXNzIDMgU0hBMjU2IENvZGUgU2lnbmluZyBDQTAeFw0xODA5MTcwMDAwMDBa\\n+Fw0xOTA5MTcyMzU5NTlaMHMxCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9y\\n+bmlhMRIwEAYDVQQHDAlDdXBlcnRpbm8xFDASBgNVBAoMC0FwcGxlLCBJbmMuMQ8w\\n+DQYDVQQLDAZHQyBTUkUxFDASBgNVBAMMC0FwcGxlLCBJbmMuMIIBIjANBgkqhkiG\\n+9w0BAQEFAAOCAQ8AMIIBCgKCAQEA06fwIi8fgKrTQu7cBcFkJVF6+Tqvkg7MKJTM\\n+IOYPPQtPF3AZYPsbUoRKAD7\/JXrxxOSVJ7vU1mP77tYG8TcUteZ3sAwvt2dkRbm7\\n+ZO6DcmSggv1Dg4k3goNw4GYyCY4Z2\/8JSmsQ80Iv\/UOOwynpBziEeZmJ4uck6zlA\\n+17cDkH48LBpKylaqthym5bFs9gj11pto7mvyb5BTcVuohwi6qosvbs\/4VGbC2Nsz\\n+ie416nUZfv+xxoXH995gxR2mw5cDdeCew7pSKxEhvYjT2nVdQF0q\/hnPMFnOaEyT\\n+q79n3gwFXyt0dy8eP6KBF7EW9J6b7ubu\/j7h+tQfxPM+gTXOBQIDAQABo4IBPjCC\\n+ATowCQYDVR0TBAIwADAOBgNVHQ8BAf8EBAMCB4AwEwYDVR0lBAwwCgYIKwYBBQUH\\n+AwMwYQYDVR0gBFowWDBWBgZngQwBBAEwTDAjBggrBgEFBQcCARYXaHR0cHM6Ly9k\\n+LnN5bWNiLmNvbS9jcHMwJQYIKwYBBQUHAgIwGQwXaHR0cHM6Ly9kLnN5bWNiLmNv\\n+bS9ycGEwHwYDVR0jBBgwFoAUljtT8Hkzl699g+8uK8zKt4YecmYwKwYDVR0fBCQw\\n+IjAgoB6gHIYaaHR0cDovL3N2LnN5bWNiLmNvbS9zdi5jcmwwVwYIKwYBBQUHAQEE\\n+SzBJMB8GCCsGAQUFBzABhhNodHRwOi8vc3Yuc3ltY2QuY29tMCYGCCsGAQUFBzAC\\n+hhpodHRwOi8vc3Yuc3ltY2IuY29tL3N2LmNydDANBgkqhkiG9w0BAQsFAAOCAQEA\\n+I\/j\/PcCNPebSAGrcqSFBSa2mmbusOX01eVBg8X0G\/z8Z+ZWUfGFzDG0GQf89MPxV\\n+woec+nZuqui7o9Bg8s8JbHV0TC52X14CbTj9w\/qBF748WbH9gAaTkrJYPm+MlNhu\\n+tjEuQdNl\/YXVMvQW4O8UMHTi09GyJQ0NC4q92Wxvx1m\/qzjvTLvrXHGQ9pEHhPyz\\n+vfBLxQkWpNoCNKU7UeESyH06XOrGc9MsII9deeKsDJp9a0jtx+pP4MFVtFME9SSQ\\n+tMBs0It7WwEf7qcRLpialxKwY2EzQ9g4WnANHqo18PrDBE10TFpZPzUh7JhMViVr\\n+EEbl0YdElmF8Hlamah\/yNw==\\n+-----END CERTIFICATE-----'}}",
            "message_norm":"create game_center.pem",
            "language":"ro",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['spec\/support\/cert\/game_center.pem'])",
            "num_files":1.0,
            "patch_content":"From 2084b7c569697a5230e42511799eeac9219db5a9 Mon Sep 17 00:00:00 2001\nFrom: Manuel Trezza <5673677+mtrezza@users.noreply.github.com>\nDate: Fri, 17 Jun 2022 16:16:52 +0200\nSubject: [PATCH] Create game_center.pem\n\n---\n spec\/support\/cert\/game_center.pem | 28 ++++++++++++++++++++++++++++\n 1 file changed, 28 insertions(+)\n create mode 100644 spec\/support\/cert\/game_center.pem\n\ndiff --git a\/spec\/support\/cert\/game_center.pem b\/spec\/support\/cert\/game_center.pem\nnew file mode 100644\nindex 0000000000..b5dffcd832\n--- \/dev\/null\n+++ b\/spec\/support\/cert\/game_center.pem\n@@ -0,0 +1,28 @@\n+-----BEGIN CERTIFICATE-----\n+MIIEvDCCA6SgAwIBAgIQXRHxNXkw1L9z5\/3EZ\/T\/hDANBgkqhkiG9w0BAQsFADB\/\n+MQswCQYDVQQGEwJVUzEdMBsGA1UEChMUU3ltYW50ZWMgQ29ycG9yYXRpb24xHzAd\n+BgNVBAsTFlN5bWFudGVjIFRydXN0IE5ldHdvcmsxMDAuBgNVBAMTJ1N5bWFudGVj\n+IENsYXNzIDMgU0hBMjU2IENvZGUgU2lnbmluZyBDQTAeFw0xODA5MTcwMDAwMDBa\n+Fw0xOTA5MTcyMzU5NTlaMHMxCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9y\n+bmlhMRIwEAYDVQQHDAlDdXBlcnRpbm8xFDASBgNVBAoMC0FwcGxlLCBJbmMuMQ8w\n+DQYDVQQLDAZHQyBTUkUxFDASBgNVBAMMC0FwcGxlLCBJbmMuMIIBIjANBgkqhkiG\n+9w0BAQEFAAOCAQ8AMIIBCgKCAQEA06fwIi8fgKrTQu7cBcFkJVF6+Tqvkg7MKJTM\n+IOYPPQtPF3AZYPsbUoRKAD7\/JXrxxOSVJ7vU1mP77tYG8TcUteZ3sAwvt2dkRbm7\n+ZO6DcmSggv1Dg4k3goNw4GYyCY4Z2\/8JSmsQ80Iv\/UOOwynpBziEeZmJ4uck6zlA\n+17cDkH48LBpKylaqthym5bFs9gj11pto7mvyb5BTcVuohwi6qosvbs\/4VGbC2Nsz\n+ie416nUZfv+xxoXH995gxR2mw5cDdeCew7pSKxEhvYjT2nVdQF0q\/hnPMFnOaEyT\n+q79n3gwFXyt0dy8eP6KBF7EW9J6b7ubu\/j7h+tQfxPM+gTXOBQIDAQABo4IBPjCC\n+ATowCQYDVR0TBAIwADAOBgNVHQ8BAf8EBAMCB4AwEwYDVR0lBAwwCgYIKwYBBQUH\n+AwMwYQYDVR0gBFowWDBWBgZngQwBBAEwTDAjBggrBgEFBQcCARYXaHR0cHM6Ly9k\n+LnN5bWNiLmNvbS9jcHMwJQYIKwYBBQUHAgIwGQwXaHR0cHM6Ly9kLnN5bWNiLmNv\n+bS9ycGEwHwYDVR0jBBgwFoAUljtT8Hkzl699g+8uK8zKt4YecmYwKwYDVR0fBCQw\n+IjAgoB6gHIYaaHR0cDovL3N2LnN5bWNiLmNvbS9zdi5jcmwwVwYIKwYBBQUHAQEE\n+SzBJMB8GCCsGAQUFBzABhhNodHRwOi8vc3Yuc3ltY2QuY29tMCYGCCsGAQUFBzAC\n+hhpodHRwOi8vc3Yuc3ltY2IuY29tL3N2LmNydDANBgkqhkiG9w0BAQsFAAOCAQEA\n+I\/j\/PcCNPebSAGrcqSFBSa2mmbusOX01eVBg8X0G\/z8Z+ZWUfGFzDG0GQf89MPxV\n+woec+nZuqui7o9Bg8s8JbHV0TC52X14CbTj9w\/qBF748WbH9gAaTkrJYPm+MlNhu\n+tjEuQdNl\/YXVMvQW4O8UMHTi09GyJQ0NC4q92Wxvx1m\/qzjvTLvrXHGQ9pEHhPyz\n+vfBLxQkWpNoCNKU7UeESyH06XOrGc9MsII9deeKsDJp9a0jtx+pP4MFVtFME9SSQ\n+tMBs0It7WwEf7qcRLpialxKwY2EzQ9g4WnANHqo18PrDBE10TFpZPzUh7JhMViVr\n+EEbl0YdElmF8Hlamah\/yNw==\n+-----END CERTIFICATE-----"
        },
        {
            "index":874,
            "vuln_id":"GHSA-5fxf-x22x-5q38",
            "cwe_id":"{'CWE-79'}",
            "score":6.8,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/de6d17b52d261902653fbdd2ecefcaac82e54256'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in microweber XSS on dynamic_text module in GitHub repository microweber\/microweber prior to 1.2.12.",
            "published_date":"2022-03-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/de6d17b52d261902653fbdd2ecefcaac82e54256",
            "commit_sha":"de6d17b52d261902653fbdd2ecefcaac82e54256",
            "patch":"SINGLE",
            "chain_ord":"['de6d17b52d261902653fbdd2ecefcaac82e54256']",
            "before_first_fix_commit":"{'095b1bcea7a4384f0d0513906100212df136a1e4'}",
            "last_fix_commit":"de6d17b52d261902653fbdd2ecefcaac82e54256",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/11\/2022, 13:38:50",
            "message":"Update build-and-upload.yml",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 0, 'deletions': 1, 'total': 1}",
            "files":"{'.github\/workflows\/build-and-upload.yml': {'additions': 0, 'deletions': 1, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/de6d17b52d261902653fbdd2ecefcaac82e54256\/.github%2Fworkflows%2Fbuild-and-upload.yml', 'patch': '@@ -6,7 +6,6 @@ on:\\n jobs:\\n   microweber-test-before-build:\\n     runs-on: ubuntu-latest\\n-    needs: stop-previous-runs\\n     steps:\\n       - uses: actions\/checkout@v2'}}",
            "message_norm":"update build-and-upload.yml",
            "language":"en",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['.github\/workflows\/build-and-upload.yml'])",
            "num_files":1.0,
            "patch_content":"From de6d17b52d261902653fbdd2ecefcaac82e54256 Mon Sep 17 00:00:00 2001\nFrom: Bozhidar Slaveykov <bobi@microweber.com>\nDate: Fri, 11 Mar 2022 15:38:50 +0200\nSubject: [PATCH] Update build-and-upload.yml\n\n---\n .github\/workflows\/build-and-upload.yml | 1 -\n 1 file changed, 1 deletion(-)\n\ndiff --git a\/.github\/workflows\/build-and-upload.yml b\/.github\/workflows\/build-and-upload.yml\nindex 259ee2be29d..74b2a62a441 100644\n--- a\/.github\/workflows\/build-and-upload.yml\n+++ b\/.github\/workflows\/build-and-upload.yml\n@@ -6,7 +6,6 @@ on:\n jobs:\n   microweber-test-before-build:\n     runs-on: ubuntu-latest\n-    needs: stop-previous-runs\n     steps:\n       - uses: actions\/checkout@v2"
        },
        {
            "index":190,
            "vuln_id":"GHSA-2598-2f59-rmhq",
            "cwe_id":"{'CWE-89'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/sequelize\/sequelize\/commit\/ee4017379db0059566ecb5424274ad4e2d66bc68'}",
            "dataset":"osv",
            "summary":"SQL Injection in sequelize Versions of `sequelize` prior to 3.35.1 are vulnerable to SQL Injection. The package fails to sanitize JSON path keys in the Postgres dialect,  which may allow attackers to inject SQL statements and execute arbitrary SQL queries.\n\n\n## Recommendation\n\nUpgrade to version 3.35.1 or later.",
            "published_date":"2019-11-08",
            "chain_len":1,
            "project":"https:\/\/github.com\/sequelize\/sequelize",
            "commit_href":"https:\/\/github.com\/sequelize\/sequelize\/commit\/ee4017379db0059566ecb5424274ad4e2d66bc68",
            "commit_sha":"ee4017379db0059566ecb5424274ad4e2d66bc68",
            "patch":"SINGLE",
            "chain_ord":"['ee4017379db0059566ecb5424274ad4e2d66bc68']",
            "before_first_fix_commit":"{'75c1fdbc676d73a28a5e0bca49b2a6d4a9f8708c'}",
            "last_fix_commit":"ee4017379db0059566ecb5424274ad4e2d66bc68",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/20\/2019, 05:26:22",
            "message":"fix(postgres): json path key quoting (#11088)",
            "author":"Sushant",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'lib\/dialects\/abstract\/query-generator.js': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sequelize\/sequelize\/raw\/ee4017379db0059566ecb5424274ad4e2d66bc68\/lib%2Fdialects%2Fabstract%2Fquery-generator.js', 'patch': \"@@ -2198,7 +2198,8 @@ var QueryGenerator = {\\n             path[path.length - 1] = $tmp[0];\\n           }\\n \\n-          $baseKey = self.quoteIdentifier(key)+'#>>\\\\'{'+path.join(', ')+'}\\\\'';\\n+          var pathKey = self.escape('{' + path.join(', ') + '}');\\n+          $baseKey = self.quoteIdentifier(key)+'#>>'+pathKey;\\n \\n           if (options.prefix) {\\n             if (options.prefix instanceof Utils.literal) {\"}}",
            "message_norm":"fix(postgres): json path key quoting (#11088)",
            "language":"en",
            "entities":"[('fix(postgres', 'ACTION', ''), ('key', 'SECWORD', ''), ('#11088', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/dialects\/abstract\/query-generator.js'])",
            "num_files":1.0,
            "patch_content":"From ee4017379db0059566ecb5424274ad4e2d66bc68 Mon Sep 17 00:00:00 2001\nFrom: Sushant <sushantdhiman@outlook.com>\nDate: Thu, 20 Jun 2019 10:56:22 +0530\nSubject: [PATCH] fix(postgres): json path key quoting (#11088)\n\n---\n lib\/dialects\/abstract\/query-generator.js | 3 ++-\n 1 file changed, 2 insertions(+), 1 deletion(-)\n\ndiff --git a\/lib\/dialects\/abstract\/query-generator.js b\/lib\/dialects\/abstract\/query-generator.js\nindex 0298381093eb..392e962021ab 100644\n--- a\/lib\/dialects\/abstract\/query-generator.js\n+++ b\/lib\/dialects\/abstract\/query-generator.js\n@@ -2198,7 +2198,8 @@ var QueryGenerator = {\n             path[path.length - 1] = $tmp[0];\n           }\n \n-          $baseKey = self.quoteIdentifier(key)+'#>>\\'{'+path.join(', ')+'}\\'';\n+          var pathKey = self.escape('{' + path.join(', ') + '}');\n+          $baseKey = self.quoteIdentifier(key)+'#>>'+pathKey;\n \n           if (options.prefix) {\n             if (options.prefix instanceof Utils.literal) {"
        },
        {
            "index":517,
            "vuln_id":"GHSA-3pg8-c473-w6rr",
            "cwe_id":"{'CWE-79'}",
            "score":6.9,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/3caa32334db0c277b84e993eaca2036f5d1dbef8'}",
            "dataset":"osv",
            "summary":"Stored Cross-site Scripting in showdoc ShowDoc is a tool for an IT team to share documents online. showdoc contains a stored cross-site scripting vulnerability in the File Library page when uploading a file in .ofd format in versions prior to 2.10.4. At this time, there is no known workaround. Users should update to version 2.10.4.",
            "published_date":"2022-03-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/3caa32334db0c277b84e993eaca2036f5d1dbef8",
            "commit_sha":"3caa32334db0c277b84e993eaca2036f5d1dbef8",
            "patch":"SINGLE",
            "chain_ord":"['3caa32334db0c277b84e993eaca2036f5d1dbef8']",
            "before_first_fix_commit":"{'92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f'}",
            "last_fix_commit":"3caa32334db0c277b84e993eaca2036f5d1dbef8",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2022, 15:26:49",
            "message":"Upload file vulnerability",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 7, 'total': 12}",
            "files":"{'server\/Application\/Api\/Model\/AttachmentModel.class.php': {'additions': 5, 'deletions': 7, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/3caa32334db0c277b84e993eaca2036f5d1dbef8\/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -54,10 +54,10 @@ public function deleteFile($file_id){\\n \\t}\\n \\n \\t\/\/\u4e0a\u4f20\u6587\u4ef6\uff0c\u8fd4\u56deurl\\n-\\tpublic function upload($_files , $file_key , $uid , $item_id = 0  , $page_id = 0  ){\\n+\\tpublic function upload($_files , $file_key , $uid , $item_id = 0  , $page_id = 0 , $check_filename = true  ){\\n \\t\\t$uploadFile = $_files[$file_key] ;\\n \\n-\\t\\tif( !$this->isAllowedFilename($_files[$file_key]['name']) ){\\n+\\t\\tif( $check_filename && !$this->isAllowedFilename($_files[$file_key]['name']) ){\\n \\t\\t\\treturn false;\\n \\t\\t}\\n \\n@@ -324,14 +324,12 @@ public function isDangerFilename($filename){\\n \\tpublic function isAllowedFilename($filename){\\n \\t\\t$allow_array = array(\\n \\t\\t\\t'.jpg','.jpeg','.png','.bmp','.gif','.ico','.webp',\\n-\\t\\t\\t'.mp3','.wav','.mp4',\\n-\\t\\t\\t'.mov','.webmv','.flac','.mkv',\\n+\\t\\t\\t'.mp3','.wav','.mp4','.mov','.flac','.mkv',\\n \\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso',\\n-\\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n-\\t\\t\\t'.doc','.docx','.wps',\\n+\\t\\t\\t'.pdf','.epub','.xps','.doc','.docx','.wps',\\n \\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\\n \\t\\t\\t'.cer','.ppt','.pub','.json','.css',\\n-\\t\\t\\t) ;\\n+\\t\\t) ;\\n \\n \\t\\t$ext = strtolower(substr($filename,strripos($filename,'.')) ); \/\/\u83b7\u53d6\u6587\u4ef6\u6269\u5c55\u540d\uff08\u8f6c\u4e3a\u5c0f\u5199\u540e\uff09\\n \\t\\tif(in_array( $ext , $allow_array ) ){\"}}",
            "message_norm":"upload file vulnerability",
            "language":"ro",
            "entities":"[('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Model\/AttachmentModel.class.php'])",
            "num_files":1.0,
            "patch_content":"From 3caa32334db0c277b84e993eaca2036f5d1dbef8 Mon Sep 17 00:00:00 2001\nFrom: star7th <xing7th@gmail.com>\nDate: Mon, 14 Mar 2022 23:26:49 +0800\nSubject: [PATCH] Upload file vulnerability\n\n---\n ...\/Application\/Api\/Model\/AttachmentModel.class.php  | 12 +++++-------\n 1 file changed, 5 insertions(+), 7 deletions(-)\n\ndiff --git a\/server\/Application\/Api\/Model\/AttachmentModel.class.php b\/server\/Application\/Api\/Model\/AttachmentModel.class.php\nindex 965db2e60..b79090dc4 100644\n--- a\/server\/Application\/Api\/Model\/AttachmentModel.class.php\n+++ b\/server\/Application\/Api\/Model\/AttachmentModel.class.php\n@@ -54,10 +54,10 @@ public function deleteFile($file_id){\n \t}\n \n \t\/\/\u4e0a\u4f20\u6587\u4ef6\uff0c\u8fd4\u56deurl\n-\tpublic function upload($_files , $file_key , $uid , $item_id = 0  , $page_id = 0  ){\n+\tpublic function upload($_files , $file_key , $uid , $item_id = 0  , $page_id = 0 , $check_filename = true  ){\n \t\t$uploadFile = $_files[$file_key] ;\n \n-\t\tif( !$this->isAllowedFilename($_files[$file_key]['name']) ){\n+\t\tif( $check_filename && !$this->isAllowedFilename($_files[$file_key]['name']) ){\n \t\t\treturn false;\n \t\t}\n \n@@ -324,14 +324,12 @@ public function isDangerFilename($filename){\n \tpublic function isAllowedFilename($filename){\n \t\t$allow_array = array(\n \t\t\t'.jpg','.jpeg','.png','.bmp','.gif','.ico','.webp',\n-\t\t\t'.mp3','.wav','.mp4',\n-\t\t\t'.mov','.webmv','.flac','.mkv',\n+\t\t\t'.mp3','.wav','.mp4','.mov','.flac','.mkv',\n \t\t\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso',\n-\t\t\t'.pdf','.ofd','.swf','.epub','.xps',\n-\t\t\t'.doc','.docx','.wps',\n+\t\t\t'.pdf','.epub','.xps','.doc','.docx','.wps',\n \t\t\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\n \t\t\t'.cer','.ppt','.pub','.json','.css',\n-\t\t\t) ;\n+\t\t) ;\n \n \t\t$ext = strtolower(substr($filename,strripos($filename,'.')) ); \/\/\u83b7\u53d6\u6587\u4ef6\u6269\u5c55\u540d\uff08\u8f6c\u4e3a\u5c0f\u5199\u540e\uff09\n \t\tif(in_array( $ext , $allow_array ) ){"
        },
        {
            "index":356,
            "vuln_id":"GHSA-68gr-cmcp-g3mj",
            "cwe_id":"{'CWE-22'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/RetireJS\/retire.js\/commit\/800c8140884eaa5753a49308f560c925fe97b9a5'}",
            "dataset":"osv",
            "summary":"Directory Traversal in lactate A crafted `GET` request can be leveraged to traverse the directory structure of a host using the lactate web server package, and request arbitrary files outside of the specified web root. This allows for a remote attacker to gain access to arbitrary files on the filesystem that the process has access to read.\n\nMitigating factors:\nOnly files that the user running `lactate` has permission to read will be accessible via this vulnerability.\n\n\n[Proof of concept](https:\/\/hackerone.com\/reports\/296645):\nPlease globally install the `lactate` package and `cd` to a directory you wish to serve assets from. Next, run `lactate -p 8081` to start serving files from this location.\n\nThe following cURL request can be used to demonstrate this vulnerability by requesting the target `\/etc\/passwd` file:\n\n```\ncurl \"http:\/\/127.0.0.1:8081\/%2e%2e\/%2e%2e\/%2e%2e\/%2e%2e\/%2e%2e\/etc\/passwd\"\n```\n```\nroot:x:0:0:root:\/root:\/bin\/bash\ndaemon:x:1:1:daemon:\/usr\/sbin:\/usr\/sbin\/nologin\nbin:x:2:2:bin:\/bin:\/usr\/sbin\/nologin\nsys:x:3:3:sys:\/dev:\/usr\/sbin\/nologin\n[...]\n```\n\n\n## Recommendation\n\nAs there is currently no fix for this issue selecting an alternative static web server would be the best choice.",
            "published_date":"2019-06-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/RetireJS\/retire.js",
            "commit_href":"https:\/\/github.com\/RetireJS\/retire.js\/commit\/800c8140884eaa5753a49308f560c925fe97b9a5",
            "commit_sha":"800c8140884eaa5753a49308f560c925fe97b9a5",
            "patch":"SINGLE",
            "chain_ord":"['800c8140884eaa5753a49308f560c925fe97b9a5']",
            "before_first_fix_commit":"{'ed3512729af76583b28611a4a1b6a8797d7f074c'}",
            "last_fix_commit":"800c8140884eaa5753a49308f560c925fe97b9a5",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/05\/2018, 06:47:18",
            "message":"HackerOne Node.js Ecosystem Bug Bounty Program - January 2018 disclosures (#199)",
            "author":"Rafal Janicki",
            "comments":null,
            "stats":"{'additions': 104, 'deletions': 8, 'total': 112}",
            "files":"{'repository\/npmrepository.json': {'additions': 104, 'deletions': 8, 'changes': 112, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/RetireJS\/retire.js\/raw\/800c8140884eaa5753a49308f560c925fe97b9a5\/repository%2Fnpmrepository.json', 'patch': '@@ -4461,16 +4461,112 @@\\n         ]\\n       }\\n     ]\\n+  },\\n+  \"fastify\": {\\n+    \"vulnerabilities\": [\\n+      {\\n+        \"below\": \"0.38.0\",\\n+        \"severity\": \"critical\",\\n+        \"identifiers\": {\\n+          \"CVE\": [\\n+            \"CVE-2018-3711\"\\n+          ],\\n+          \"summary\": \"denial-of-service vulnerability with large JSON payloads\"\\n+        },\\n+        \"info\": [\\n+          \"https:\/\/hackerone.com\/reports\/303632\"\\n+        ]\\n+      }\\n+    ]\\n+  },\\n+  \"serve\": {\\n+    \"vulnerabilities\": [\\n+      {\\n+        \"below\": \"6.4.9\",\\n+        \"severity\": \"critical\",\\n+        \"identifiers\": {\\n+          \"CVE\": [\\n+            \"CVE-2018-3712\"\\n+          ],\\n+          \"summary\": \"Path Traversal\"\\n+        },\\n+        \"info\": [\\n+          \"https:\/\/hackerone.com\/reports\/307666\"\\n+        ]\\n+      }\\n+    ]\\n+  },\\n+  \"augustine\": {\\n+    \"vulnerabilities\": [\\n+      {\\n+        \"below\": \"0.2.4\",\\n+        \"severity\": \"critical\",\\n+        \"identifiers\": {\\n+          \"summary\": \"Path Traversal\"\\n+        },\\n+        \"info\": [\\n+          \"https:\/\/hackerone.com\/reports\/296282\"\\n+        ]\\n+      }\\n+    ]\\n+  },\\n+  \"lactate\": {\\n+    \"vulnerabilities\": [\\n+      {\\n+        \"below\": \"0.13.13\",\\n+        \"severity\": \"medium\",\\n+        \"identifiers\": {\\n+          \"summary\": \"Path Traversal\"\\n+        },\\n+        \"info\": [\\n+          \"https:\/\/hackerone.com\/reports\/296645\"\\n+        ]\\n+      }\\n+    ]\\n+  },\\n+  \"redis-commander\": {\\n+    \"vulnerabilities\": [\\n+      {\\n+        \"below\": \"0.4.6\",\\n+        \"severity\": \"low\",\\n+        \"identifiers\": {\\n+          \"summary\": \"Reflected XSS\"\\n+        },\\n+        \"info\": [\\n+          \"https:\/\/hackerone.com\/reports\/296377\"\\n+        ]\\n+      }\\n+    ]\\n+  },\\n+  \"featurebook\": {\\n+    \"vulnerabilities\": [\\n+      {\\n+        \"below\": \"0.0.33\",\\n+        \"severity\": \"medium\",\\n+        \"identifiers\": {\\n+          \"summary\": \"Path Traversal\"\\n+        },\\n+        \"info\": [\\n+          \"https:\/\/hackerone.com\/reports\/296305\"\\n+        ]\\n+      }\\n+    ]\\n+  },\\n+  \"serve-here\": {\\n+    \"vulnerabilities\": [\\n+      {\\n+        \"below\": \"3.2.2\",\\n+        \"severity\": \"medium\",\\n+        \"identifiers\": {\\n+          \"summary\": \"Path Traversal\"\\n+        },\\n+        \"info\": [\\n+          \"https:\/\/hackerone.com\/reports\/296254\"\\n+        ]\\n+      }\\n+    ]\\n   }\\n \\n \\n \\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n }'}}",
            "message_norm":"hackerone node.js ecosystem bug bounty program - january 2018 disclosures (#199)",
            "language":"en",
            "entities":"[('bug', 'FLAW', ''), ('#199', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['repository\/npmrepository.json'])",
            "num_files":1.0,
            "patch_content":"From 800c8140884eaa5753a49308f560c925fe97b9a5 Mon Sep 17 00:00:00 2001\nFrom: Rafal Janicki <bloorq@gmail.com>\nDate: Mon, 5 Feb 2018 06:47:18 +0000\nSubject: [PATCH] HackerOne Node.js Ecosystem Bug Bounty Program - January 2018\n disclosures (#199)\n\n---\n repository\/npmrepository.json | 112 +++++++++++++++++++++++++++++++---\n 1 file changed, 104 insertions(+), 8 deletions(-)\n\ndiff --git a\/repository\/npmrepository.json b\/repository\/npmrepository.json\nindex 6159e62d5..8e77515e4 100644\n--- a\/repository\/npmrepository.json\n+++ b\/repository\/npmrepository.json\n@@ -4461,16 +4461,112 @@\n         ]\n       }\n     ]\n+  },\n+  \"fastify\": {\n+    \"vulnerabilities\": [\n+      {\n+        \"below\": \"0.38.0\",\n+        \"severity\": \"critical\",\n+        \"identifiers\": {\n+          \"CVE\": [\n+            \"CVE-2018-3711\"\n+          ],\n+          \"summary\": \"denial-of-service vulnerability with large JSON payloads\"\n+        },\n+        \"info\": [\n+          \"https:\/\/hackerone.com\/reports\/303632\"\n+        ]\n+      }\n+    ]\n+  },\n+  \"serve\": {\n+    \"vulnerabilities\": [\n+      {\n+        \"below\": \"6.4.9\",\n+        \"severity\": \"critical\",\n+        \"identifiers\": {\n+          \"CVE\": [\n+            \"CVE-2018-3712\"\n+          ],\n+          \"summary\": \"Path Traversal\"\n+        },\n+        \"info\": [\n+          \"https:\/\/hackerone.com\/reports\/307666\"\n+        ]\n+      }\n+    ]\n+  },\n+  \"augustine\": {\n+    \"vulnerabilities\": [\n+      {\n+        \"below\": \"0.2.4\",\n+        \"severity\": \"critical\",\n+        \"identifiers\": {\n+          \"summary\": \"Path Traversal\"\n+        },\n+        \"info\": [\n+          \"https:\/\/hackerone.com\/reports\/296282\"\n+        ]\n+      }\n+    ]\n+  },\n+  \"lactate\": {\n+    \"vulnerabilities\": [\n+      {\n+        \"below\": \"0.13.13\",\n+        \"severity\": \"medium\",\n+        \"identifiers\": {\n+          \"summary\": \"Path Traversal\"\n+        },\n+        \"info\": [\n+          \"https:\/\/hackerone.com\/reports\/296645\"\n+        ]\n+      }\n+    ]\n+  },\n+  \"redis-commander\": {\n+    \"vulnerabilities\": [\n+      {\n+        \"below\": \"0.4.6\",\n+        \"severity\": \"low\",\n+        \"identifiers\": {\n+          \"summary\": \"Reflected XSS\"\n+        },\n+        \"info\": [\n+          \"https:\/\/hackerone.com\/reports\/296377\"\n+        ]\n+      }\n+    ]\n+  },\n+  \"featurebook\": {\n+    \"vulnerabilities\": [\n+      {\n+        \"below\": \"0.0.33\",\n+        \"severity\": \"medium\",\n+        \"identifiers\": {\n+          \"summary\": \"Path Traversal\"\n+        },\n+        \"info\": [\n+          \"https:\/\/hackerone.com\/reports\/296305\"\n+        ]\n+      }\n+    ]\n+  },\n+  \"serve-here\": {\n+    \"vulnerabilities\": [\n+      {\n+        \"below\": \"3.2.2\",\n+        \"severity\": \"medium\",\n+        \"identifiers\": {\n+          \"summary\": \"Path Traversal\"\n+        },\n+        \"info\": [\n+          \"https:\/\/hackerone.com\/reports\/296254\"\n+        ]\n+      }\n+    ]\n   }\n \n \n \n-\n-\n-\n-\n-\n-\n-\n-\n }"
        },
        {
            "index":861,
            "vuln_id":"GHSA-rphc-h572-2x9f",
            "cwe_id":"{'CWE-434', 'CWE-79'}",
            "score":9.0,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in showdoc\/showdoc ShowDoc is a tool greatly applicable for an IT team to share documents online. showdoc\/showdoc allows .properties files to upload which lead to stored XSS in versions prior to 2.10.4. This allows attackers to execute malicious scripts in the user's browser. This issue was patched in version 2.10.4. There is currently no known workaround.",
            "published_date":"2022-03-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f",
            "commit_sha":"92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f",
            "patch":"SINGLE",
            "chain_ord":"['92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f']",
            "before_first_fix_commit":"{'cd258a0de6fad53a5f41beaf2645f3f6f092f216'}",
            "last_fix_commit":"92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2022, 14:36:28",
            "message":"file upload bug",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'server\/Application\/Api\/Model\/AttachmentModel.class.php': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f\/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -324,13 +324,13 @@ public function isDangerFilename($filename){\\n \\tpublic function isAllowedFilename($filename){\\n \\t\\t$allow_array = array(\\n \\t\\t\\t'.jpg','.jpeg','.png','.bmp','.gif','.ico','.webp',\\n-\\t\\t\\t'.mp3','.wav','.m4a','.ogg','.webma','.mp4','.flv',\\n+\\t\\t\\t'.mp3','.wav','.mp4',\\n \\t\\t\\t'.mov','.webmv','.flac','.mkv',\\n-\\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso','.bz2','.epub',\\n+\\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso',\\n \\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n-\\t\\t\\t'.doc','.docx','.odt','.rtf','.docm','.dotm','.dot','.dotx','.wps',\\n+\\t\\t\\t'.doc','.docx','.wps',\\n \\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\\n-\\t\\t\\t'.cer','.ppt','.pub','.properties','.json','.css',\\n+\\t\\t\\t'.cer','.ppt','.pub','.json','.css',\\n \\t\\t\\t) ;\\n \\n \\t\\t$ext = strtolower(substr($filename,strripos($filename,'.')) ); \/\/\u83b7\u53d6\u6587\u4ef6\u6269\u5c55\u540d\uff08\u8f6c\u4e3a\u5c0f\u5199\u540e\uff09\"}}",
            "message_norm":"file upload bug",
            "language":"ro",
            "entities":"[('bug', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Model\/AttachmentModel.class.php'])",
            "num_files":1.0,
            "patch_content":"From 92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f Mon Sep 17 00:00:00 2001\nFrom: star7th <xing7th@gmail.com>\nDate: Mon, 14 Mar 2022 22:36:28 +0800\nSubject: [PATCH] file upload bug\n\n---\n server\/Application\/Api\/Model\/AttachmentModel.class.php | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/server\/Application\/Api\/Model\/AttachmentModel.class.php b\/server\/Application\/Api\/Model\/AttachmentModel.class.php\nindex c1b62cf28..965db2e60 100644\n--- a\/server\/Application\/Api\/Model\/AttachmentModel.class.php\n+++ b\/server\/Application\/Api\/Model\/AttachmentModel.class.php\n@@ -324,13 +324,13 @@ public function isDangerFilename($filename){\n \tpublic function isAllowedFilename($filename){\n \t\t$allow_array = array(\n \t\t\t'.jpg','.jpeg','.png','.bmp','.gif','.ico','.webp',\n-\t\t\t'.mp3','.wav','.m4a','.ogg','.webma','.mp4','.flv',\n+\t\t\t'.mp3','.wav','.mp4',\n \t\t\t'.mov','.webmv','.flac','.mkv',\n-\t\t\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso','.bz2','.epub',\n+\t\t\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso',\n \t\t\t'.pdf','.ofd','.swf','.epub','.xps',\n-\t\t\t'.doc','.docx','.odt','.rtf','.docm','.dotm','.dot','.dotx','.wps',\n+\t\t\t'.doc','.docx','.wps',\n \t\t\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\n-\t\t\t'.cer','.ppt','.pub','.properties','.json','.css',\n+\t\t\t'.cer','.ppt','.pub','.json','.css',\n \t\t\t) ;\n \n \t\t$ext = strtolower(substr($filename,strripos($filename,'.')) ); \/\/\u83b7\u53d6\u6587\u4ef6\u6269\u5c55\u540d\uff08\u8f6c\u4e3a\u5c0f\u5199\u540e\uff09"
        },
        {
            "index":215,
            "vuln_id":"GHSA-6g85-3hm8-83f9",
            "cwe_id":"{'CWE-754'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/20431e9044cf2ad3c0323c34888b192f3289af6b'}",
            "dataset":"osv",
            "summary":"CHECK-fail in `QuantizeAndDequantizeV4Grad` ### Impact\nAn attacker can trigger a denial of service via a `CHECK`-fail in `tf.raw_ops.QuantizeAndDequantizeV4Grad`:\n\n```python\nimport tensorflow as tf\n\ngradient_tensor = tf.constant([0.0], shape=[1])\ninput_tensor = tf.constant([0.0], shape=[1])\ninput_min = tf.constant([[0.0]], shape=[1, 1])\ninput_max = tf.constant([[0.0]], shape=[1, 1])\n\ntf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=gradient_tensor, input=input_tensor,\n  input_min=input_min, input_max=input_max, axis=0)\n```                     \n                        \nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/95078c145b5a7a43ee046144005f733092756ab5\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc#L162-L163) does not validate the rank of the `input_*` tensors. In turn, this results in the tensors being passes as they are to [`QuantizeAndDequantizePerChannelGradientImpl`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/95078c145b5a7a43ee046144005f733092756ab5\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.h#L295-L306):\n\n```cc \ntemplate <typename Device, typename T>\nstruct QuantizeAndDequantizePerChannelGradientImpl {\n  static void Compute(const Device& d,\n                      typename TTypes<T, 3>::ConstTensor gradient,\n                      typename TTypes<T, 3>::ConstTensor input,\n                      const Tensor* input_min_tensor,\n                      const Tensor* input_max_tensor,\n                      typename TTypes<T, 3>::Tensor input_backprop,\n                      typename TTypes<T>::Flat input_min_backprop,\n                      typename TTypes<T>::Flat input_max_backprop) {\n    ...\n    auto input_min = input_min_tensor->vec<T>();\n    auto input_max = input_max_tensor->vec<T>();\n    ...\n}\n```\n\nHowever, the `vec<T>` method, requires the rank to 1 and triggers a `CHECK` failure otherwise.\n\n### Patches\nWe have patched the issue in GitHub commit [20431e9044cf2ad3c0323c34888b192f3289af6b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/20431e9044cf2ad3c0323c34888b192f3289af6b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2 as this is the only other affected version.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/20431e9044cf2ad3c0323c34888b192f3289af6b",
            "commit_sha":"20431e9044cf2ad3c0323c34888b192f3289af6b",
            "patch":"SINGLE",
            "chain_ord":"['20431e9044cf2ad3c0323c34888b192f3289af6b']",
            "before_first_fix_commit":"{'95078c145b5a7a43ee046144005f733092756ab5'}",
            "last_fix_commit":"20431e9044cf2ad3c0323c34888b192f3289af6b",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/26\/2021, 20:43:59",
            "message":"Fix `tf.raw_ops.QuantizeAndDequantizeV4Grad` CHECK failure.\n\nPiperOrigin-RevId: 370532425\nChange-Id: I767721be266851b63d8fe55e7ac6be0af6017f6c",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 0, 'total': 10}",
            "files":"{'tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/20431e9044cf2ad3c0323c34888b192f3289af6b\/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -160,7 +160,17 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\\n         errors::InvalidArgument(\"gradient and input must be the same size\"));\\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\\n     const Tensor& input_min_tensor = ctx->input(2);\\n+    OP_REQUIRES(ctx,\\n+                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\\n+                errors::InvalidArgument(\\n+                    \"Input min tensor must have dimension 1. Recieved \",\\n+                    input_min_tensor.dims(), \".\"));\\n     const Tensor& input_max_tensor = ctx->input(3);\\n+    OP_REQUIRES(ctx,\\n+                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\\n+                errors::InvalidArgument(\\n+                    \"Input max tensor must have dimension 1. Recieved \",\\n+                    input_max_tensor.dims(), \".\"));\\n     if (axis_ != -1) {\\n       OP_REQUIRES(\\n           ctx, input_min_tensor.dim_size(0) == depth,'}}",
            "message_norm":"fix `tf.raw_ops.quantizeanddequantizev4grad` check failure.\n\npiperorigin-revid: 370532425\nchange-id: i767721be266851b63d8fe55e7ac6be0af6017f6c",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('370532425', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 20431e9044cf2ad3c0323c34888b192f3289af6b Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Mon, 26 Apr 2021 13:43:59 -0700\nSubject: [PATCH] Fix `tf.raw_ops.QuantizeAndDequantizeV4Grad` CHECK failure.\n\nPiperOrigin-RevId: 370532425\nChange-Id: I767721be266851b63d8fe55e7ac6be0af6017f6c\n---\n tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc | 10 ++++++++++\n 1 file changed, 10 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\nindex 675bdaec225bd7..c2a7a90d8713d8 100644\n--- a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n@@ -160,7 +160,17 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\n         errors::InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     const Tensor& input_min_tensor = ctx->input(2);\n+    OP_REQUIRES(ctx,\n+                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n+                errors::InvalidArgument(\n+                    \"Input min tensor must have dimension 1. Recieved \",\n+                    input_min_tensor.dims(), \".\"));\n     const Tensor& input_max_tensor = ctx->input(3);\n+    OP_REQUIRES(ctx,\n+                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n+                errors::InvalidArgument(\n+                    \"Input max tensor must have dimension 1. Recieved \",\n+                    input_max_tensor.dims(), \".\"));\n     if (axis_ != -1) {\n       OP_REQUIRES(\n           ctx, input_min_tensor.dim_size(0) == depth,"
        },
        {
            "index":158,
            "vuln_id":"GHSA-pmpr-55fj-r229",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6841e522a3e7d48706a02e8819836e809f738682'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite's implementation of `SVDF` ### Impact\nThe implementation of the `SVDF` TFLite operator is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/7f283ff806b2031f407db64c4d3edcda8fb9f9f5\/tensorflow\/lite\/kernels\/svdf.cc#L99-L102):\n\n```cc\nconst int rank = params->rank;\n...\nTF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n```\n\nAn attacker can craft a model such that `params->rank` would be 0.\n\n### Patches\nWe have patched the issue in GitHub commit [6841e522a3e7d48706a02e8819836e809f738682](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6841e522a3e7d48706a02e8819836e809f738682).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6841e522a3e7d48706a02e8819836e809f738682",
            "commit_sha":"6841e522a3e7d48706a02e8819836e809f738682",
            "patch":"SINGLE",
            "chain_ord":"['6841e522a3e7d48706a02e8819836e809f738682']",
            "before_first_fix_commit":"{'7f283ff806b2031f407db64c4d3edcda8fb9f9f5'}",
            "last_fix_commit":"6841e522a3e7d48706a02e8819836e809f738682",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2021, 22:13:03",
            "message":"Prevent division by 0\n\nPiperOrigin-RevId: 370995582\nChange-Id: I670ffaf52d1ff8823ec31ea5f438f9125b402223",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/lite\/kernels\/svdf.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6841e522a3e7d48706a02e8819836e809f738682\/tensorflow%2Flite%2Fkernels%2Fsvdf.cc', 'patch': '@@ -99,6 +99,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   const int rank = params->rank;\\n   const int batch_size = input->dims->data[0];\\n   const int num_filters = weights_feature->dims->data[0];\\n+  TF_LITE_ENSURE(context, rank != 0);\\n   TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\\n   const int num_units = num_filters \/ rank;\\n   const int memory_size = weights_time->dims->data[1];'}}",
            "message_norm":"prevent division by 0\n\npiperorigin-revid: 370995582\nchange-id: i670ffaf52d1ff8823ec31ea5f438f9125b402223",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('370995582', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/svdf.cc'])",
            "num_files":1.0,
            "patch_content":"From 6841e522a3e7d48706a02e8819836e809f738682 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 28 Apr 2021 15:13:03 -0700\nSubject: [PATCH] Prevent division by 0\n\nPiperOrigin-RevId: 370995582\nChange-Id: I670ffaf52d1ff8823ec31ea5f438f9125b402223\n---\n tensorflow\/lite\/kernels\/svdf.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/svdf.cc b\/tensorflow\/lite\/kernels\/svdf.cc\nindex 8f5c9a86bff5c6..73024fd1e587a2 100644\n--- a\/tensorflow\/lite\/kernels\/svdf.cc\n+++ b\/tensorflow\/lite\/kernels\/svdf.cc\n@@ -99,6 +99,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   const int rank = params->rank;\n   const int batch_size = input->dims->data[0];\n   const int num_filters = weights_feature->dims->data[0];\n+  TF_LITE_ENSURE(context, rank != 0);\n   TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n   const int num_units = num_filters \/ rank;\n   const int memory_size = weights_time->dims->data[1];"
        },
        {
            "index":368,
            "vuln_id":"GHSA-q263-fvxm-m5mw",
            "cwe_id":"{'CWE-908', 'CWE-125'}",
            "score":4.4,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0cc38aaa4064fd9e79101994ce9872c6d91f816b'}",
            "dataset":"osv",
            "summary":"Heap out of bounds access in MakeEdge in TensorFlow ### Impact\nUnder certain cases, loading a saved model can result in accessing uninitialized memory while building the computation graph. The [`MakeEdge` function](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/3616708cb866365301d8e67b43b32b46d94b08a0\/tensorflow\/core\/common_runtime\/graph_constructor.cc#L1426-L1438) creates an edge between one output tensor of the `src` node (given by `output_index`) and the input slot of the `dst` node (given by `input_index`). This is only possible if the types of the tensors on both sides coincide, so the function begins by obtaining the corresponding `DataType` values and comparing these for equality:\n\n```cc\n  DataType src_out = src->output_type(output_index);\n  DataType dst_in = dst->input_type(input_index);\n  \/\/...\n```\n\nHowever, there is no check that the indices point to inside of the arrays they index into. Thus, this can result in accessing data out of bounds of the corresponding heap allocated arrays.\n\nIn most scenarios, this can manifest as unitialized data access, but if the index points far away from the boundaries of the arrays this can be used to leak addresses from the library.\n\n### Patches\nWe have patched the issue in GitHub commit [0cc38aaa4064fd9e79101994ce9872c6d91f816b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0cc38aaa4064fd9e79101994ce9872c6d91f816b) and will release TensorFlow 2.4.0 containing the patch. TensorFlow nightly packages after this commit will also have the issue resolved.\n\nSince this issue also impacts TF versions before 2.4, we will patch all releases between 1.15 and 2.3 inclusive.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2020-12-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0cc38aaa4064fd9e79101994ce9872c6d91f816b",
            "commit_sha":"0cc38aaa4064fd9e79101994ce9872c6d91f816b",
            "patch":"SINGLE",
            "chain_ord":"['0cc38aaa4064fd9e79101994ce9872c6d91f816b']",
            "before_first_fix_commit":"{'3616708cb866365301d8e67b43b32b46d94b08a0'}",
            "last_fix_commit":"0cc38aaa4064fd9e79101994ce9872c6d91f816b",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/08\/2020, 17:31:57",
            "message":"Prevent unitialized memory access in `GraphConstructor::MakeEdge`\n\nThe `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\n\nPiperOrigin-RevId: 346343288\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'tensorflow\/core\/common_runtime\/graph_constructor.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/0cc38aaa4064fd9e79101994ce9872c6d91f816b\/tensorflow%2Fcore%2Fcommon_runtime%2Fgraph_constructor.cc', 'patch': '@@ -44,6 +44,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\\n #include \"tensorflow\/core\/lib\/strings\/scanner.h\"\\n #include \"tensorflow\/core\/lib\/strings\/str_util.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/platform\/logging.h\"\\n #include \"tensorflow\/core\/platform\/macros.h\"\\n #include \"tensorflow\/core\/public\/version.h\"\\n@@ -1425,6 +1426,17 @@ void GraphConstructor::Undo() {\\n \\n Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\\n                                   int input_index) {\\n+  if (output_index >= src->num_outputs()) {\\n+    return errors::InvalidArgument(\\n+        \"Output \", output_index, \" of node \", src->name(),\\n+        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\\n+  }\\n+  if (input_index >= dst->num_inputs()) {\\n+    return errors::InvalidArgument(\\n+        \"Input \", input_index, \" of node \", dst->name(),\\n+        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\\n+  }\\n+\\n   DataType src_out = src->output_type(output_index);\\n   DataType dst_in = dst->input_type(input_index);\\n   if (!TypesCompatible(dst_in, src_out)) {'}}",
            "message_norm":"prevent unitialized memory access in `graphconstructor::makeedge`\n\nthe `makeedge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. however, if this is not the case this results in accessing data out of bounds. because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. however, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\n\npiperorigin-revid: 346343288\nchange-id: i2127da27c2023d27f26efd39afa6c853385cab6f",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('out of bounds', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('manipulate', 'ACTION', ''), ('information leakage', 'SECWORD', ''), ('exploits', 'SECWORD', ''), ('346343288', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/common_runtime\/graph_constructor.cc'])",
            "num_files":1.0,
            "patch_content":"From 0cc38aaa4064fd9e79101994ce9872c6d91f816b Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 8 Dec 2020 09:31:57 -0800\nSubject: [PATCH] Prevent unitialized memory access in\n `GraphConstructor::MakeEdge`\n\nThe `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\n\nPiperOrigin-RevId: 346343288\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f\n---\n tensorflow\/core\/common_runtime\/graph_constructor.cc | 12 ++++++++++++\n 1 file changed, 12 insertions(+)\n\ndiff --git a\/tensorflow\/core\/common_runtime\/graph_constructor.cc b\/tensorflow\/core\/common_runtime\/graph_constructor.cc\nindex 92b07682d76cd8..639739e9cac8c2 100644\n--- a\/tensorflow\/core\/common_runtime\/graph_constructor.cc\n+++ b\/tensorflow\/core\/common_runtime\/graph_constructor.cc\n@@ -44,6 +44,7 @@ limitations under the License.\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\n #include \"tensorflow\/core\/lib\/strings\/scanner.h\"\n #include \"tensorflow\/core\/lib\/strings\/str_util.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/logging.h\"\n #include \"tensorflow\/core\/platform\/macros.h\"\n #include \"tensorflow\/core\/public\/version.h\"\n@@ -1425,6 +1426,17 @@ void GraphConstructor::Undo() {\n \n Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                   int input_index) {\n+  if (output_index >= src->num_outputs()) {\n+    return errors::InvalidArgument(\n+        \"Output \", output_index, \" of node \", src->name(),\n+        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\n+  }\n+  if (input_index >= dst->num_inputs()) {\n+    return errors::InvalidArgument(\n+        \"Input \", input_index, \" of node \", dst->name(),\n+        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\n+  }\n+\n   DataType src_out = src->output_type(output_index);\n   DataType dst_in = dst->input_type(input_index);\n   if (!TypesCompatible(dst_in, src_out)) {"
        },
        {
            "index":743,
            "vuln_id":"GHSA-ph5x-h23x-7q5q",
            "cwe_id":"{'CWE-79', 'CWE-116'}",
            "score":7.4,
            "chain":"{'https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/27f839133d41877e538d35fa88274b50a1c00b9b'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in wiki manager join wiki page ### Impact\nWe found a possible XSS vector in the `WikiManager.JoinWiki ` wiki page related to the \"requestJoin\" field.\n\n### Patches\nThe issue is patched in versions 12.10.11, 14.0-rc-1, 13.4.7, 13.10.3.\n\n### Workarounds\nThe easiest workaround is to edit the wiki page `WikiManager.JoinWiki` (with wiki editor) and change the line\n\n```\n<input type='hidden' name='requestJoin' value=\"$!request.requestJoin\"\/>\n```\n\ninto\n\n```\n<input type='hidden' name='requestJoin' value=\"$escapetool.xml($!request.requestJoin)\">\n```\n\n### References\n  * https:\/\/jira.xwiki.org\/browse\/XWIKI-19292\n  * https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/27f839133d41877e538d35fa88274b50a1c00b9b\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Jira XWiki](https:\/\/jira.xwiki.org)\n* Email us at [security mailing list](mailto:security@xwiki.org)",
            "published_date":"2022-05-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/xwiki\/xwiki-platform",
            "commit_href":"https:\/\/github.com\/xwiki\/xwiki-platform\/commit\/27f839133d41877e538d35fa88274b50a1c00b9b",
            "commit_sha":"27f839133d41877e538d35fa88274b50a1c00b9b",
            "patch":"SINGLE",
            "chain_ord":"['27f839133d41877e538d35fa88274b50a1c00b9b']",
            "before_first_fix_commit":"{'bd935320bee3c27cf7548351b1d0f935f116d437'}",
            "last_fix_commit":"27f839133d41877e538d35fa88274b50a1c00b9b",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/04\/2022, 10:35:46",
            "message":"XWIKI-19292: Fix bad escaping",
            "author":"Thomas Mortagne",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'xwiki-platform-core\/xwiki-platform-wiki\/xwiki-platform-wiki-ui\/xwiki-platform-wiki-ui-mainwiki\/src\/main\/resources\/WikiManager\/JoinWiki.xml': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/xwiki\/xwiki-platform\/raw\/27f839133d41877e538d35fa88274b50a1c00b9b\/xwiki-platform-core%2Fxwiki-platform-wiki%2Fxwiki-platform-wiki-ui%2Fxwiki-platform-wiki-ui-mainwiki%2Fsrc%2Fmain%2Fresources%2FWikiManager%2FJoinWiki.xml', 'patch': '@@ -245,7 +245,7 @@\\n                   &lt;a href=\"$backUrl\" class=\\'button secondary\\'&gt;{{translation key=\"platform.wiki.users.join.request.cancel.label\"\/}}&lt;\/a&gt;\\n                 &lt;\/span&gt;\\n                 &lt;input type=\\'hidden\\' name=\\'wikiId\\' value=\"$!wikiId\"\/&gt;\\n-                &lt;input type=\\'hidden\\' name=\\'requestJoin\\' value=\"$!request.requestJoin\"\/&gt;\\n+                &lt;input type=\\'hidden\\' name=\\'requestJoin\\' value=\"$escapetool.xml($!request.requestJoin)\"\/&gt;\\n                 &lt;input type=\"hidden\" name=\"form_token\" value=\"$!escapetool.xml($services.csrf.getToken())\" \/&gt;\\n               &lt;\/dl&gt;\\n             &lt;\/form&gt;'}}",
            "message_norm":"xwiki-19292: fix bad escaping",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('escaping', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['xwiki-platform-core\/xwiki-platform-wiki\/xwiki-platform-wiki-ui\/xwiki-platform-wiki-ui-mainwiki\/src\/main\/resources\/WikiManager\/JoinWiki.xml'])",
            "num_files":1.0,
            "patch_content":"From 27f839133d41877e538d35fa88274b50a1c00b9b Mon Sep 17 00:00:00 2001\nFrom: Thomas Mortagne <thomas.mortagne@gmail.com>\nDate: Tue, 4 Jan 2022 11:35:46 +0100\nSubject: [PATCH] XWIKI-19292: Fix bad escaping\n\n---\n ...\/src\/main\/resources\/WikiManager\/JoinWiki.xml                 | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/xwiki-platform-core\/xwiki-platform-wiki\/xwiki-platform-wiki-ui\/xwiki-platform-wiki-ui-mainwiki\/src\/main\/resources\/WikiManager\/JoinWiki.xml b\/xwiki-platform-core\/xwiki-platform-wiki\/xwiki-platform-wiki-ui\/xwiki-platform-wiki-ui-mainwiki\/src\/main\/resources\/WikiManager\/JoinWiki.xml\nindex ca408851faa3..3a717b2100c4 100644\n--- a\/xwiki-platform-core\/xwiki-platform-wiki\/xwiki-platform-wiki-ui\/xwiki-platform-wiki-ui-mainwiki\/src\/main\/resources\/WikiManager\/JoinWiki.xml\n+++ b\/xwiki-platform-core\/xwiki-platform-wiki\/xwiki-platform-wiki-ui\/xwiki-platform-wiki-ui-mainwiki\/src\/main\/resources\/WikiManager\/JoinWiki.xml\n@@ -245,7 +245,7 @@\n                   &lt;a href=\"$backUrl\" class='button secondary'&gt;{{translation key=\"platform.wiki.users.join.request.cancel.label\"\/}}&lt;\/a&gt;\n                 &lt;\/span&gt;\n                 &lt;input type='hidden' name='wikiId' value=\"$!wikiId\"\/&gt;\n-                &lt;input type='hidden' name='requestJoin' value=\"$!request.requestJoin\"\/&gt;\n+                &lt;input type='hidden' name='requestJoin' value=\"$escapetool.xml($!request.requestJoin)\"\/&gt;\n                 &lt;input type=\"hidden\" name=\"form_token\" value=\"$!escapetool.xml($services.csrf.getToken())\" \/&gt;\n               &lt;\/dl&gt;\n             &lt;\/form&gt;"
        },
        {
            "index":794,
            "vuln_id":"GHSA-4gw3-8f77-f72c",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/codemirror\/CodeMirror\/commit\/55d0333907117c9231ffdf555ae8824705993bbb'}",
            "dataset":"osv",
            "summary":"Regular expression denial of service in codemirror This affects the package codemirror before 5.58.2; the package org.apache.marmotta.webjars:codemirror before 5.58.2.\n The vulnerable regular expression is located in https:\/\/github.com\/codemirror\/CodeMirror\/blob\/cdb228ac736369c685865b122b736cd0d397836c\/mode\/javascript\/javascript.jsL129. The ReDOS vulnerability of the regex is mainly due to the sub-pattern (s|\/*.*?*\/)*",
            "published_date":"2021-05-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/codemirror\/CodeMirror",
            "commit_href":"https:\/\/github.com\/codemirror\/CodeMirror\/commit\/55d0333907117c9231ffdf555ae8824705993bbb",
            "commit_sha":"55d0333907117c9231ffdf555ae8824705993bbb",
            "patch":"SINGLE",
            "chain_ord":"['55d0333907117c9231ffdf555ae8824705993bbb']",
            "before_first_fix_commit":"{'cdb228ac736369c685865b122b736cd0d397836c'}",
            "last_fix_commit":"55d0333907117c9231ffdf555ae8824705993bbb",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/09\/2020, 13:38:39",
            "message":"[javascript mode] Fix potentially-exponential regexp",
            "author":"Marijn Haverbeke",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'mode\/javascript\/javascript.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/codemirror\/codemirror5\/raw\/55d0333907117c9231ffdf555ae8824705993bbb\/mode%2Fjavascript%2Fjavascript.js', 'patch': '@@ -126,7 +126,7 @@ CodeMirror.defineMode(\"javascript\", function(config, parserConfig) {\\n           var kw = keywords[word]\\n           return ret(kw.type, kw.style, word)\\n         }\\n-        if (word == \"async\" && stream.match(\/^(\\\\s|\\\\\/\\\\*.*?\\\\*\\\\\/)*[\\\\[\\\\(\\\\w]\/, false))\\n+        if (word == \"async\" && stream.match(\/^(\\\\s|\\\\\/\\\\*([^*]|\\\\*(?!\\\\\/))*?\\\\*\\\\\/)*[\\\\[\\\\(\\\\w]\/, false))\\n           return ret(\"async\", \"keyword\", word)\\n       }\\n       return ret(\"variable\", \"variable\", word)'}}",
            "message_norm":"[javascript mode] fix potentially-exponential regexp",
            "language":"ca",
            "entities":"[('fix', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['mode\/javascript\/javascript.js'])",
            "num_files":1.0,
            "patch_content":"From 55d0333907117c9231ffdf555ae8824705993bbb Mon Sep 17 00:00:00 2001\nFrom: Marijn Haverbeke <marijn@haverbeke.nl>\nDate: Fri, 9 Oct 2020 15:38:39 +0200\nSubject: [PATCH] [javascript mode] Fix potentially-exponential regexp\n\n---\n mode\/javascript\/javascript.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/mode\/javascript\/javascript.js b\/mode\/javascript\/javascript.js\nindex 66e5a308d4..3139fd00d2 100644\n--- a\/mode\/javascript\/javascript.js\n+++ b\/mode\/javascript\/javascript.js\n@@ -126,7 +126,7 @@ CodeMirror.defineMode(\"javascript\", function(config, parserConfig) {\n           var kw = keywords[word]\n           return ret(kw.type, kw.style, word)\n         }\n-        if (word == \"async\" && stream.match(\/^(\\s|\\\/\\*.*?\\*\\\/)*[\\[\\(\\w]\/, false))\n+        if (word == \"async\" && stream.match(\/^(\\s|\\\/\\*([^*]|\\*(?!\\\/))*?\\*\\\/)*[\\[\\(\\w]\/, false))\n           return ret(\"async\", \"keyword\", word)\n       }\n       return ret(\"variable\", \"variable\", word)"
        },
        {
            "index":562,
            "vuln_id":"GHSA-2xgj-xhgf-ggjv",
            "cwe_id":"{'CWE-120'}",
            "score":3.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `BandedTriangularSolve` ### Impact\nAn attacker can trigger a heap buffer overflow in Eigen implementation of `tf.raw_ops.BandedTriangularSolve`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n  \nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_array = np.array([1,1])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)\ntf.raw_ops.BandedTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc#L269-L278) calls `ValidateInputTensors` for input validation but fails to validate that the two tensors are not empty:\n  \n```cc\nvoid ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0, const Tensor& in1) {\n  OP_REQUIRES(\n      ctx, in0.dims() >= 2, \n      errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n\n  OP_REQUIRES(\n      ctx, in1.dims() >= 2,\n      errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1.dims()));\n}\n``` \n\nFurthermore, since `OP_REQUIRES` macro only stops execution of current function after setting `ctx->status()` to a non-OK value, callers of helper functions that use `OP_REQUIRES` must check value of `ctx->status()` before continuing. This doesn't happen [in this op's implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eccb7ec454e6617738554a255d77f08e60ee0808\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc#L219), hence the validation that is present is also not effective.\n\n### Patches\nWe have patched the issue in GitHub commit [ba6822bd7b7324ba201a28b2f278c29a98edbef2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ba6822bd7b7324ba201a28b2f278c29a98edbef2) followed by GitHub commit [0ab290774f91a23bebe30a358fde4e53ab4876a0](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ye Zhang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0ab290774f91a23bebe30a358fde4e53ab4876a0",
            "commit_sha":"0ab290774f91a23bebe30a358fde4e53ab4876a0",
            "patch":"MULTI",
            "chain_ord":"['ba6822bd7b7324ba201a28b2f278c29a98edbef2', '0ab290774f91a23bebe30a358fde4e53ab4876a0']",
            "before_first_fix_commit":"{'327ef310be67923824814e85e13007e9699f4e0d'}",
            "last_fix_commit":"0ab290774f91a23bebe30a358fde4e53ab4876a0",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/12\/2021, 01:36:43",
            "message":"Ensure validation sticks in banded_triangular_solve_op\n\nPiperOrigin-RevId: 373275480\nChange-Id: Id7717cf275b2d6fdb9441fbbe166d555182d2e79",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/0ab290774f91a23bebe30a358fde4e53ab4876a0\/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fbanded_triangular_solve_op.cc', 'patch': '@@ -217,6 +217,7 @@ class BandedTriangularSolveOpCpu : public OpKernel {\\n     const Tensor& in1 = ctx->input(1);\\n \\n     ValidateInputTensors(ctx, in0, in1);\\n+    if (!ctx->status().ok()) return;\\n \\n     MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\\n     OP_REQUIRES('}}",
            "message_norm":"ensure validation sticks in banded_triangular_solve_op\n\npiperorigin-revid: 373275480\nchange-id: id7717cf275b2d6fdb9441fbbe166d555182d2e79",
            "language":"en",
            "entities":"[('ensure', 'ACTION', ''), ('373275480', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 0ab290774f91a23bebe30a358fde4e53ab4876a0 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 11 May 2021 18:36:43 -0700\nSubject: [PATCH] Ensure validation sticks in banded_triangular_solve_op\n\nPiperOrigin-RevId: 373275480\nChange-Id: Id7717cf275b2d6fdb9441fbbe166d555182d2e79\n---\n tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc b\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc\nindex c079c63b778ac7..b719f55b507b02 100644\n--- a\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc\n+++ b\/tensorflow\/core\/kernels\/linalg\/banded_triangular_solve_op.cc\n@@ -217,6 +217,7 @@ class BandedTriangularSolveOpCpu : public OpKernel {\n     const Tensor& in1 = ctx->input(1);\n \n     ValidateInputTensors(ctx, in0, in1);\n+    if (!ctx->status().ok()) return;\n \n     MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\n     OP_REQUIRES("
        },
        {
            "index":53,
            "vuln_id":"GHSA-9c8h-vvrj-w2p8",
            "cwe_id":"{'CWE-125'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a2b743f6017d7b97af1fe49087ae15f0ac634373'}",
            "dataset":"osv",
            "summary":"Heap OOB in `RaggedGather` ### Impact\nIf the arguments to `tf.raw_ops.RaggedGather` don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers.\n                                                                                                                                                                                                                                                                                          \n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedGather(\n  params_nested_splits = [0,0,0],\n  params_dense_values = [1,1],\n  indices = [0,0,9,0,0],\n  OUTPUT_RAGGED_RANK=0)\n```\n\nIn debug mode, the same code triggers a `CHECK` failure.\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/ragged_gather_op.cc#L70) directly reads the first dimension of a tensor shape before checking that said tensor has rank of at least 1 (i.e., it is not a scalar). Furthermore, the implementation does not check that the list given by `params_nested_splits` is not an empty list of tensors.\n\n### Patches\nWe have patched the issue in GitHub commit [a2b743f6017d7b97af1fe49087ae15f0ac634373](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a2b743f6017d7b97af1fe49087ae15f0ac634373).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a2b743f6017d7b97af1fe49087ae15f0ac634373",
            "commit_sha":"a2b743f6017d7b97af1fe49087ae15f0ac634373",
            "patch":"SINGLE",
            "chain_ord":"['a2b743f6017d7b97af1fe49087ae15f0ac634373']",
            "before_first_fix_commit":"{'4979e3b104cede96958ea88be5ce5fc584949340'}",
            "last_fix_commit":"a2b743f6017d7b97af1fe49087ae15f0ac634373",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/03\/2021, 02:05:27",
            "message":"Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 1, 'total': 8}",
            "files":"{'tensorflow\/core\/kernels\/ragged_gather_op.cc': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a2b743f6017d7b97af1fe49087ae15f0ac634373\/tensorflow%2Fcore%2Fkernels%2Fragged_gather_op.cc', 'patch': '@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\\n \\n   void Compute(OpKernelContext* context) override {\\n     \/\/ Get the input Tensors.\\n+\\n     OpInputList params_nested_splits_in;\\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\\n                                                 &params_nested_splits_in));\\n+    OP_REQUIRES(\\n+        context, params_nested_splits_in.size() > 0,\\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\\n+\\n     const Tensor& params_dense_values_in =\\n         context->input(params_nested_splits_in.size());\\n     const Tensor& indices_in =\\n         context->input(params_nested_splits_in.size() + 1);\\n \\n-    DCHECK_GT(params_nested_splits_in.size(), 0);  \/\/ Enforced by REGISTER_OP.\\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));'}}",
            "message_norm":"fix heap oob in `tf.raw_ops.raggedgather`\n\npiperorigin-revid: 388355464\nchange-id: if14d96231d1cd7aad7c4d1c22c1bab1576b75717",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('388355464', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_gather_op.cc'])",
            "num_files":1.0,
            "patch_content":"From a2b743f6017d7b97af1fe49087ae15f0ac634373 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Mon, 2 Aug 2021 19:05:27 -0700\nSubject: [PATCH] Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717\n---\n tensorflow\/core\/kernels\/ragged_gather_op.cc | 8 +++++++-\n 1 file changed, 7 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/ragged_gather_op.cc b\/tensorflow\/core\/kernels\/ragged_gather_op.cc\nindex 3bf82cba050e3b..d6d51c770bbb7a 100644\n--- a\/tensorflow\/core\/kernels\/ragged_gather_op.cc\n+++ b\/tensorflow\/core\/kernels\/ragged_gather_op.cc\n@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     \/\/ Get the input Tensors.\n+\n     OpInputList params_nested_splits_in;\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                 &params_nested_splits_in));\n+    OP_REQUIRES(\n+        context, params_nested_splits_in.size() > 0,\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\n+\n     const Tensor& params_dense_values_in =\n         context->input(params_nested_splits_in.size());\n     const Tensor& indices_in =\n         context->input(params_nested_splits_in.size() + 1);\n \n-    DCHECK_GT(params_nested_splits_in.size(), 0);  \/\/ Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));"
        },
        {
            "index":622,
            "vuln_id":"GHSA-hx9q-2mx4-m4pg",
            "cwe_id":"{'CWE-191', 'CWE-20'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/20cb18724b0bf6c09071a3f53434c4eec53cc147', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/84563f265f28b3c36a15335c8b005d405260e943'}",
            "dataset":"osv",
            "summary":"Missing validation causes denial of service via `Conv3DBackpropFilterV2` ### Impact\nThe implementation of [`tf.raw_ops.UnsortedSegmentJoin`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f3b9bf4c3c0597563b289c0512e98d4ce81f886e\/tensorflow\/core\/kernels\/unsorted_segment_join_op.cc#L83-L148) does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack:\n\n```python\nimport tensorflow as tf\n\ntf.strings.unsorted_segment_join(\n  inputs=['123'],\n  segment_ids=[0],\n  num_segments=-1)\n```\n\nThe code assumes `num_segments` is a positive scalar but there is no validation:\n\n```cc\nconst Tensor& num_segments_tensor = context->input(2);\nauto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n\/\/ ...\nTensor* output_tensor = nullptr;\nTensorShape output_shape =\n    GetOutputShape(input_shape, segment_id_shape, num_segments);\n```\n\nSince this value is used to allocate the output tensor, a negative value would result in a `CHECK`-failure (assertion failure), as per [TFSA-2021-198](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/tensorflow\/security\/advisory\/tfsa-2021-198.md).\n\n### Patches \nWe have patched the issue in GitHub commit [84563f265f28b3c36a15335c8b005d405260e943](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/84563f265f28b3c36a15335c8b005d405260e943) and GitHub commit [20cb18724b0bf6c09071a3f53434c4eec53cc147](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/20cb18724b0bf6c09071a3f53434c4eec53cc147).\n  \nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n      \n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n                       \n### Attribution \nThis vulnerability has been reported externally via a [GitHub issue](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/55305).",
            "published_date":"2022-05-24",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/20cb18724b0bf6c09071a3f53434c4eec53cc147",
            "commit_sha":"20cb18724b0bf6c09071a3f53434c4eec53cc147",
            "patch":"MULTI",
            "chain_ord":"['84563f265f28b3c36a15335c8b005d405260e943', '20cb18724b0bf6c09071a3f53434c4eec53cc147']",
            "before_first_fix_commit":"{'3f30e4965889b1b86b1d56392e437ccc08907f65'}",
            "last_fix_commit":"20cb18724b0bf6c09071a3f53434c4eec53cc147",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/20\/2022, 19:05:26",
            "message":"Allow 0 for number of segments in `unsorted_segment_join_op.cc`\n\nRelated to the fix for #55305\n\nPiperOrigin-RevId: 443157549",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/unsorted_segment_join_op.cc': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/20cb18724b0bf6c09071a3f53434c4eec53cc147\/tensorflow%2Fcore%2Fkernels%2Funsorted_segment_join_op.cc', 'patch': '@@ -94,8 +94,10 @@ class UnsortedSegmentJoinOp : public OpKernel {\\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\\n \\n-    OP_REQUIRES(context, num_segments > 0,\\n-                errors::InvalidArgument(\"Number of segments must be positive\"));\\n+    OP_REQUIRES(\\n+        context, num_segments >= 0,\\n+        errors::InvalidArgument(\\n+            \"Number of segments must be non-negative but got \", num_segments));\\n     OP_REQUIRES(context, segment_dims != 0,\\n                 errors::InvalidArgument(\"Segment_id cannot have rank 0\"));'}}",
            "message_norm":"allow 0 for number of segments in `unsorted_segment_join_op.cc`\n\nrelated to the fix for #55305\n\npiperorigin-revid: 443157549",
            "language":"en",
            "entities":"[('#55305', 'ISSUE', ''), ('443157549', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/unsorted_segment_join_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 20cb18724b0bf6c09071a3f53434c4eec53cc147 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 20 Apr 2022 12:05:26 -0700\nSubject: [PATCH] Allow 0 for number of segments in\n `unsorted_segment_join_op.cc`\n\nRelated to the fix for #55305\n\nPiperOrigin-RevId: 443157549\n---\n tensorflow\/core\/kernels\/unsorted_segment_join_op.cc | 6 ++++--\n 1 file changed, 4 insertions(+), 2 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/unsorted_segment_join_op.cc b\/tensorflow\/core\/kernels\/unsorted_segment_join_op.cc\nindex 860cec8010042c..c8445ca4c4c596 100644\n--- a\/tensorflow\/core\/kernels\/unsorted_segment_join_op.cc\n+++ b\/tensorflow\/core\/kernels\/unsorted_segment_join_op.cc\n@@ -94,8 +94,10 @@ class UnsortedSegmentJoinOp : public OpKernel {\n                 errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n-    OP_REQUIRES(context, num_segments > 0,\n-                errors::InvalidArgument(\"Number of segments must be positive\"));\n+    OP_REQUIRES(\n+        context, num_segments >= 0,\n+        errors::InvalidArgument(\n+            \"Number of segments must be non-negative but got \", num_segments));\n     OP_REQUIRES(context, segment_dims != 0,\n                 errors::InvalidArgument(\"Segment_id cannot have rank 0\"));"
        },
        {
            "index":763,
            "vuln_id":"GHSA-9jjr-qqfp-ppwx",
            "cwe_id":"{'CWE-94'}",
            "score":9.6,
            "chain":"{'https:\/\/github.com\/jupyterhub\/binderhub\/commit\/195caac172690456dcdc8cc7a6ca50e05abf8182'}",
            "dataset":"osv",
            "summary":"remote code execution via git repo provider ### Impact\n\nA remote code execution vulnerability has been identified in BinderHub, where providing BinderHub with maliciously crafted input could execute code in the BinderHub context, with the potential to egress credentials of the BinderHub deployment, including JupyterHub API tokens, kubernetes service accounts, and docker registry credentials. This may provide the ability to manipulate images and other user created pods in the deployment, with the potential to escalate to the host depending on the underlying kubernetes configuration.\n\n### Patches\n\nPatch below, or [on GitHub](https:\/\/github.com\/jupyterhub\/binderhub\/commit\/195caac172690456dcdc8cc7a6ca50e05abf8182.patch)\n\n```diff\nFrom 9f4043d9dddc1174920e687773f27b7933f48ab6 Mon Sep 17 00:00:00 2001\nFrom: Riccardo Castellotti <rcastell@cern.ch>\nDate: Thu, 19 Aug 2021 15:49:43 +0200\nSubject: [PATCH] Explicitly separate git-ls-remote options from positional\n arguments\n\n---\n binderhub\/repoproviders.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/binderhub\/repoproviders.py b\/binderhub\/repoproviders.py\nindex f33347b..5d4b87c 100755\n--- a\/binderhub\/repoproviders.py\n+++ b\/binderhub\/repoproviders.py\n@@ -484,7 +484,7 @@ class GitRepoProvider(RepoProvider):\n             self.sha1_validate(self.unresolved_ref)\n         except ValueError:\n             # The ref is a head\/tag and we resolve it using `git ls-remote`\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n             if result.returncode:\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))\n-- \n2.25.1\n\n```\n\n### Workarounds\n\nDisable the git repo provider by specifying the `BinderHub.repo_providers` config, e.g.:\n\n```python\nfrom binderhub.repoproviders import (GitHubRepoProvider,\n                            GitLabRepoProvider, GistRepoProvider,\n                            ZenodoProvider, FigshareProvider, HydroshareProvider,\n                            DataverseProvider)\n\nc.BinderHub.repo_providers =  {\n            'gh': GitHubRepoProvider,\n            'gist': GistRepoProvider,\n            'gl': GitLabRepoProvider,\n            'zenodo': ZenodoProvider,\n            'figshare': FigshareProvider,\n            'hydroshare': HydroshareProvider,\n            'dataverse': DataverseProvider,\n        }\n```\n\n### References\n\nCredit: Jose Carlos Luna Duran (CERN) and Riccardo Castellotti (CERN).\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Email us at [security@ipython.org](mailto:security@ipython.org)",
            "published_date":"2021-08-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/jupyterhub\/binderhub",
            "commit_href":"https:\/\/github.com\/jupyterhub\/binderhub\/commit\/195caac172690456dcdc8cc7a6ca50e05abf8182",
            "commit_sha":"195caac172690456dcdc8cc7a6ca50e05abf8182",
            "patch":"SINGLE",
            "chain_ord":"['195caac172690456dcdc8cc7a6ca50e05abf8182']",
            "before_first_fix_commit":"{'034430adc8ed379135f3ef46ee6ca650781ef67c'}",
            "last_fix_commit":"195caac172690456dcdc8cc7a6ca50e05abf8182",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/19\/2021, 13:49:43",
            "message":"Explicitly separate git-ls-remote options from positional arguments",
            "author":"Riccardo Castellotti",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'binderhub\/repoproviders.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jupyterhub\/binderhub\/raw\/195caac172690456dcdc8cc7a6ca50e05abf8182\/binderhub%2Frepoproviders.py', 'patch': '@@ -484,7 +484,7 @@ async def get_resolved_ref(self):\\n             self.sha1_validate(self.unresolved_ref)\\n         except ValueError:\\n             # The ref is a head\/tag and we resolve it using `git ls-remote`\\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n             if result.returncode:\\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))'}}",
            "message_norm":"explicitly separate git-ls-remote options from positional arguments",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['binderhub\/repoproviders.py'])",
            "num_files":1.0,
            "patch_content":"From 195caac172690456dcdc8cc7a6ca50e05abf8182 Mon Sep 17 00:00:00 2001\nFrom: Riccardo Castellotti <rcastell@cern.ch>\nDate: Thu, 19 Aug 2021 15:49:43 +0200\nSubject: [PATCH] Explicitly separate git-ls-remote options from positional\n arguments\n\n---\n binderhub\/repoproviders.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/binderhub\/repoproviders.py b\/binderhub\/repoproviders.py\nindex f33347b94..5d4b87c27 100755\n--- a\/binderhub\/repoproviders.py\n+++ b\/binderhub\/repoproviders.py\n@@ -484,7 +484,7 @@ async def get_resolved_ref(self):\n             self.sha1_validate(self.unresolved_ref)\n         except ValueError:\n             # The ref is a head\/tag and we resolve it using `git ls-remote`\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n             if result.returncode:\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))"
        },
        {
            "index":705,
            "vuln_id":"GHSA-c545-c4f9-rf6v",
            "cwe_id":"{'CWE-125'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d94ffe08a65400f898241c0374e9edc6fa8ed257'}",
            "dataset":"osv",
            "summary":"Heap OOB in TFLite ### Impact\nTFLite's [`expand_dims.cc`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/expand_dims.cc#L36-L50) contains a vulnerability which allows reading one element outside of bounds of heap allocated data:\n\n```cc\n  if (axis < 0) { \n    axis = input_dims.size + 1 + axis;\n  }   \n  TF_LITE_ENSURE(context, axis <= input_dims.size);\n\n  TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\n  for (int i = 0; i < output_dims->size; ++i) {\n    if (i < axis) {\n      output_dims->data[i] = input_dims.data[i];\n    } else if (i == axis) {\n      output_dims->data[i] = 1;\n    } else {\n      output_dims->data[i] = input_dims.data[i - 1];\n    }\n  }\n```\n\nIf `axis` is a large negative value (e.g., `-100000`), then after the first `if` it would still be negative. The check following the `if` statement will pass and the `for` loop would read one element before the start of `input_dims.data` (when `i = 0`).\n\n### Patches\nWe have patched the issue in GitHub commit [d94ffe08a65400f898241c0374e9edc6fa8ed257](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d94ffe08a65400f898241c0374e9edc6fa8ed257).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d94ffe08a65400f898241c0374e9edc6fa8ed257",
            "commit_sha":"d94ffe08a65400f898241c0374e9edc6fa8ed257",
            "patch":"SINGLE",
            "chain_ord":"['d94ffe08a65400f898241c0374e9edc6fa8ed257']",
            "before_first_fix_commit":"{'e95fc647063378993ec84d41cbbda6dcb60bad4e'}",
            "last_fix_commit":"d94ffe08a65400f898241c0374e9edc6fa8ed257",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 21:42:54",
            "message":"Prevent an OOB read in `expand_dims.cc`\n\nThe for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. If user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in Python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\nPiperOrigin-RevId: 387200206\nChange-Id: I162f4feba12d547c3a4340833ae682016a2ebfab",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/lite\/kernels\/expand_dims.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/d94ffe08a65400f898241c0374e9edc6fa8ed257\/tensorflow%2Flite%2Fkernels%2Fexpand_dims.cc', 'patch': '@@ -37,6 +37,7 @@ TfLiteStatus ExpandTensorDim(TfLiteContext* context, const TfLiteTensor& input,\\n     axis = input_dims.size + 1 + axis;\\n   }\\n   TF_LITE_ENSURE(context, axis <= input_dims.size);\\n+  TF_LITE_ENSURE(context, axis >= 0);\\n \\n   TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\\n   for (int i = 0; i < output_dims->size; ++i) {'}}",
            "message_norm":"prevent an oob read in `expand_dims.cc`\n\nthe for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. if user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\npiperorigin-revid: 387200206\nchange-id: i162f4feba12d547c3a4340833ae682016a2ebfab",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('oob', 'SECWORD', ''), ('387200206', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/expand_dims.cc'])",
            "num_files":1.0,
            "patch_content":"From d94ffe08a65400f898241c0374e9edc6fa8ed257 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 27 Jul 2021 14:42:54 -0700\nSubject: [PATCH] Prevent an OOB read in `expand_dims.cc`\n\nThe for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. If user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in Python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\nPiperOrigin-RevId: 387200206\nChange-Id: I162f4feba12d547c3a4340833ae682016a2ebfab\n---\n tensorflow\/lite\/kernels\/expand_dims.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/expand_dims.cc b\/tensorflow\/lite\/kernels\/expand_dims.cc\nindex 231ba6df8ba735..c8d0270551c192 100644\n--- a\/tensorflow\/lite\/kernels\/expand_dims.cc\n+++ b\/tensorflow\/lite\/kernels\/expand_dims.cc\n@@ -37,6 +37,7 @@ TfLiteStatus ExpandTensorDim(TfLiteContext* context, const TfLiteTensor& input,\n     axis = input_dims.size + 1 + axis;\n   }\n   TF_LITE_ENSURE(context, axis <= input_dims.size);\n+  TF_LITE_ENSURE(context, axis >= 0);\n \n   TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\n   for (int i = 0; i < output_dims->size; ++i) {"
        },
        {
            "index":906,
            "vuln_id":"GHSA-mr7p-25v2-35wr",
            "cwe_id":"{'CWE-22'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/nltk\/nltk\/commit\/f59d7ed8df2e0e957f7f247fe218032abdbe9a10'}",
            "dataset":"osv",
            "summary":"Path Traversal in nltk NLTK Downloader before 3.4.5 is vulnerable to a directory traversal, allowing attackers to write arbitrary files via a ..\/ (dot dot slash) in an NLTK package (ZIP archive) that is mishandled during extraction.",
            "published_date":"2019-08-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/nltk\/nltk",
            "commit_href":"https:\/\/github.com\/nltk\/nltk\/commit\/f59d7ed8df2e0e957f7f247fe218032abdbe9a10",
            "commit_sha":"f59d7ed8df2e0e957f7f247fe218032abdbe9a10",
            "patch":"SINGLE",
            "chain_ord":"['f59d7ed8df2e0e957f7f247fe218032abdbe9a10']",
            "before_first_fix_commit":"{'2554ff48feed878ba7e830ada9825196f3eaa86a'}",
            "last_fix_commit":"f59d7ed8df2e0e957f7f247fe218032abdbe9a10",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/20\/2019, 10:35:00",
            "message":"CVE-2019-14751:\nFixed security bug in downloader\n(https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2019-14751)",
            "author":"Steven Bird",
            "comments":"{'com_1': {'author': 'greysteil', 'datetime': '08\/26\/2019, 11:01:35', 'body': \"Thanks for this @stevenbird, and for all your work on `nltk`.\\r\\n\\r\\nHave you got 5 minutes to talk me through the process you went through fixing this, and any way GitHub can help? I'm on GitHub's security team and am working to make it easier for maintainers to alert users of security vulnerabilities.\\r\\n\\r\\nCurrently we have the security alert emails (which we're working to improve) and Security Advisories (the security tab on this repo). In future we're planning to make it easy for maintainers to apply for CVEs through GitHub (via creating Security Advisories).\\r\\n\\r\\nWas there any part of the flow of finding, fixing, and alerting users of this vulnerability that GitHub could have helped with? Or anything we're doing now that you'd like us to do differently?\\r\\n\\r\\nAny feedback very much appreciated. I'm on greysteil@github.com if you'd rather email it privately.\\r\\n\\r\\nThanks for all your do, and please don't hesitate to reach out if there's ever any way GitHub can help.\"}}",
            "stats":"{'additions': 1, 'deletions': 35, 'total': 36}",
            "files":"{'nltk\/downloader.py': {'additions': 1, 'deletions': 35, 'changes': 36, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nltk\/nltk\/raw\/f59d7ed8df2e0e957f7f247fe218032abdbe9a10\/nltk%2Fdownloader.py', 'patch': \"@@ -2260,42 +2260,8 @@ def _unzip_iter(filename, root, verbose=True):\\n         yield ErrorMessage(filename, e)\\n         return\\n \\n-    # Get lists of directories & files\\n-    namelist = zf.namelist()\\n-    dirlist = set()\\n-    for x in namelist:\\n-        if x.endswith('\/'):\\n-            dirlist.add(x)\\n-        else:\\n-            dirlist.add(x.rsplit('\/', 1)[0] + '\/')\\n-    filelist = [x for x in namelist if not x.endswith('\/')]\\n-\\n-    # Create the target directory if it doesn't exist\\n-    if not os.path.exists(root):\\n-        os.mkdir(root)\\n-\\n-    # Create the directory structure\\n-    for dirname in sorted(dirlist):\\n-        pieces = dirname[:-1].split('\/')\\n-        for i in range(len(pieces)):\\n-            dirpath = os.path.join(root, *pieces[: i + 1])\\n-            if not os.path.exists(dirpath):\\n-                os.mkdir(dirpath)\\n-\\n-    # Extract files.\\n-    for i, filename in enumerate(filelist):\\n-        filepath = os.path.join(root, *filename.split('\/'))\\n-\\n-        try:\\n-            with open(filepath, 'wb') as dstfile, zf.open(filename) as srcfile:\\n-                shutil.copyfileobj(srcfile, dstfile)\\n-        except Exception as e:\\n-            yield ErrorMessage(filename, e)\\n-            return\\n+    zf.extractall(root)\\n \\n-        if verbose and (i * 10 \/ len(filelist) > (i - 1) * 10 \/ len(filelist)):\\n-            sys.stdout.write('.')\\n-            sys.stdout.flush()\\n     if verbose:\\n         print()\"}}",
            "message_norm":"cve-2019-14751:\nfixed security bug in downloader\n(https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=cve-2019-14751)",
            "language":"en",
            "entities":"[('cve-2019-14751', 'VULNID', 'CVE'), ('fixed', 'ACTION', ''), ('security', 'SECWORD', ''), ('bug', 'FLAW', ''), ('https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=cve-2019-14751', 'VULNID', 'CVE')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['nltk\/downloader.py'])",
            "num_files":1.0,
            "patch_content":"From f59d7ed8df2e0e957f7f247fe218032abdbe9a10 Mon Sep 17 00:00:00 2001\nFrom: Steven Bird <stevenbird1@gmail.com>\nDate: Tue, 20 Aug 2019 20:05:00 +0930\nSubject: [PATCH] CVE-2019-14751: Fixed security bug in downloader\n (https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2019-14751)\n\n---\n nltk\/downloader.py | 36 +-----------------------------------\n 1 file changed, 1 insertion(+), 35 deletions(-)\n\ndiff --git a\/nltk\/downloader.py b\/nltk\/downloader.py\nindex 8874e7c948..e6831f977f 100644\n--- a\/nltk\/downloader.py\n+++ b\/nltk\/downloader.py\n@@ -2260,42 +2260,8 @@ def _unzip_iter(filename, root, verbose=True):\n         yield ErrorMessage(filename, e)\n         return\n \n-    # Get lists of directories & files\n-    namelist = zf.namelist()\n-    dirlist = set()\n-    for x in namelist:\n-        if x.endswith('\/'):\n-            dirlist.add(x)\n-        else:\n-            dirlist.add(x.rsplit('\/', 1)[0] + '\/')\n-    filelist = [x for x in namelist if not x.endswith('\/')]\n-\n-    # Create the target directory if it doesn't exist\n-    if not os.path.exists(root):\n-        os.mkdir(root)\n-\n-    # Create the directory structure\n-    for dirname in sorted(dirlist):\n-        pieces = dirname[:-1].split('\/')\n-        for i in range(len(pieces)):\n-            dirpath = os.path.join(root, *pieces[: i + 1])\n-            if not os.path.exists(dirpath):\n-                os.mkdir(dirpath)\n-\n-    # Extract files.\n-    for i, filename in enumerate(filelist):\n-        filepath = os.path.join(root, *filename.split('\/'))\n-\n-        try:\n-            with open(filepath, 'wb') as dstfile, zf.open(filename) as srcfile:\n-                shutil.copyfileobj(srcfile, dstfile)\n-        except Exception as e:\n-            yield ErrorMessage(filename, e)\n-            return\n+    zf.extractall(root)\n \n-        if verbose and (i * 10 \/ len(filelist) > (i - 1) * 10 \/ len(filelist)):\n-            sys.stdout.write('.')\n-            sys.stdout.flush()\n     if verbose:\n         print()"
        },
        {
            "index":28,
            "vuln_id":"GHSA-43f8-2h32-f4cj",
            "cwe_id":"{'CWE-400'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/npm\/hosted-git-info\/commit\/bede0dc38e1785e732bf0a48ba6f81a4a908eba3', 'https:\/\/github.com\/npm\/hosted-git-info\/commit\/8d4b3697d79bcd89cdb36d1db165e3696c783a01', 'https:\/\/github.com\/npm\/hosted-git-info\/commit\/29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in hosted-git-info The npm package `hosted-git-info` before 3.0.8 are vulnerable to Regular Expression Denial of Service (ReDoS) via regular expression shortcutMatch in the fromUrl function in index.js. The affected regular expression exhibits polynomial worst-case time complexity",
            "published_date":"2021-05-06",
            "chain_len":3,
            "project":"https:\/\/github.com\/npm\/hosted-git-info",
            "commit_href":"https:\/\/github.com\/npm\/hosted-git-info\/commit\/bede0dc38e1785e732bf0a48ba6f81a4a908eba3",
            "commit_sha":"bede0dc38e1785e732bf0a48ba6f81a4a908eba3",
            "patch":"MULTI",
            "chain_ord":"['bede0dc38e1785e732bf0a48ba6f81a4a908eba3', '29adfe5ef789784c861b2cdeb15051ec2ba651a7', '8d4b3697d79bcd89cdb36d1db165e3696c783a01']",
            "before_first_fix_commit":"{'29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
            "last_fix_commit":"8d4b3697d79bcd89cdb36d1db165e3696c783a01",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/28\/2021, 17:22:16",
            "message":"fix: simplify the regular expression for shortcut matching\n\nPR-URL: https:\/\/github.com\/npm\/hosted-git-info\/pull\/76\nCredit: @nlf\nClose: #76\nReviewed-by: @isaacs",
            "author":"nlf",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/npm\/hosted-git-info\/raw\/bede0dc38e1785e732bf0a48ba6f81a4a908eba3\/index.js', 'patch': \"@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\\n   )\\n   var parsed = parseGitUrl(url)\\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\\\/)?([^#]+)\/)\\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\\n     try {\\n       var gitHostInfo = gitHosts[gitHostName]\\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\\n       var defaultRepresentation = null\\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\\n-        project = decodeURIComponent(shortcutMatch[3])\\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\\\.git$\/, ''))\\n         defaultRepresentation = 'shortcut'\\n       } else {\\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return\"}}",
            "message_norm":"fix: simplify the regular expression for shortcut matching\n\npr-url: https:\/\/github.com\/npm\/hosted-git-info\/pull\/76\ncredit: @nlf\nclose: #76\nreviewed-by: @isaacs",
            "language":"en",
            "entities":"[('https:\/\/github.com\/npm\/hosted-git-info\/pull\/76', 'URL', ''), ('#76', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0,
            "patch_content":"From bede0dc38e1785e732bf0a48ba6f81a4a908eba3 Mon Sep 17 00:00:00 2001\nFrom: nlf <quitlahok@gmail.com>\nDate: Thu, 28 Jan 2021 09:22:16 -0800\nSubject: [PATCH] fix: simplify the regular expression for shortcut matching\n\nPR-URL: https:\/\/github.com\/npm\/hosted-git-info\/pull\/76\nCredit: @nlf\nClose: #76\nReviewed-by: @isaacs\n---\n index.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/index.js b\/index.js\nindex 0b08be1..8b3eaba 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\n   )\n   var parsed = parseGitUrl(url)\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\/)?([^#]+)\/)\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\n     try {\n       var gitHostInfo = gitHosts[gitHostName]\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\n       var defaultRepresentation = null\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\n-        project = decodeURIComponent(shortcutMatch[3])\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\.git$\/, ''))\n         defaultRepresentation = 'shortcut'\n       } else {\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return"
        },
        {
            "index":223,
            "vuln_id":"GHSA-cv3v-7846-6pxm",
            "cwe_id":"{'CWE-552'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/gabrielcsapo\/node-git-server\/commit\/ac26650f69bc445d71e4f2c55328676d10a4be43'}",
            "dataset":"osv",
            "summary":"Unauthorized File Access in node-git-server Versions of `node-git-server` prior to 0.6.1 are vulnerable to Unauthorized File Access. It is possible to access any git repository by using absolute paths, which may allow attackers to access private repositories.\n\n\n## Recommendation\n\nUpgrade to version 0.6.1 or later.",
            "published_date":"2020-09-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/gabrielcsapo\/node-git-server",
            "commit_href":"https:\/\/github.com\/gabrielcsapo\/node-git-server\/commit\/ac26650f69bc445d71e4f2c55328676d10a4be43",
            "commit_sha":"ac26650f69bc445d71e4f2c55328676d10a4be43",
            "patch":"SINGLE",
            "chain_ord":"['ac26650f69bc445d71e4f2c55328676d10a4be43']",
            "before_first_fix_commit":"{'e3ae3737fc9de848856e56a3cf624fe014803f25'}",
            "last_fix_commit":"ac26650f69bc445d71e4f2c55328676d10a4be43",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/29\/2020, 17:45:58",
            "message":"Security Issue (#62)\n\nIt is currently possible to overwrite the `repoDir` by sending a repository name that starts with a \"\/\", the `path.resolve` method prioritizes the second argument see the example below.\r\n\r\npath.resolve(\"\/my\/repo\/folder\",\"\/etc\"); \/\/ \/etc\r\n\r\nThis behavior gives an attacker the ability to create\/write\/pull repositories from an arbitrary absolute path, this issue could also impact authentication in some cases as it corrupts the repository name.",
            "author":"Ron Masas",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/git.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/gabrielcsapo\/node-git-server\/raw\/ac26650f69bc445d71e4f2c55328676d10a4be43\/lib%2Fgit.js', 'patch': '@@ -143,7 +143,7 @@ class Git extends EventEmitter {\\n         this.dirMap = repoDir;\\n     } else {\\n         this.dirMap = (dir) => {\\n-            return (path.normalize(dir ? path.resolve(repoDir, dir) : repoDir));\\n+            return (path.normalize(dir ? path.join(repoDir, dir) : repoDir));\\n         };\\n     }'}}",
            "message_norm":"security issue (#62)\n\nit is currently possible to overwrite the `repodir` by sending a repository name that starts with a \"\/\", the `path.resolve` method prioritizes the second argument see the example below.\r\n\r\npath.resolve(\"\/my\/repo\/folder\",\"\/etc\"); \/\/ \/etc\r\n\r\nthis behavior gives an attacker the ability to create\/write\/pull repositories from an arbitrary absolute path, this issue could also impact authentication in some cases as it corrupts the repository name.",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('#62', 'ISSUE', ''), ('attacker', 'FLAW', ''), ('issue', 'FLAW', ''), ('authentication', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/git.js'])",
            "num_files":1.0,
            "patch_content":"From ac26650f69bc445d71e4f2c55328676d10a4be43 Mon Sep 17 00:00:00 2001\nFrom: Ron Masas <ronmasas@gmail.com>\nDate: Sun, 29 Mar 2020 20:45:58 +0300\nSubject: [PATCH] Security Issue (#62)\n\nIt is currently possible to overwrite the `repoDir` by sending a repository name that starts with a \"\/\", the `path.resolve` method prioritizes the second argument see the example below.\n\npath.resolve(\"\/my\/repo\/folder\",\"\/etc\"); \/\/ \/etc\n\nThis behavior gives an attacker the ability to create\/write\/pull repositories from an arbitrary absolute path, this issue could also impact authentication in some cases as it corrupts the repository name.\n---\n lib\/git.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/git.js b\/lib\/git.js\nindex 7a49585..cc61fcc 100644\n--- a\/lib\/git.js\n+++ b\/lib\/git.js\n@@ -143,7 +143,7 @@ class Git extends EventEmitter {\n         this.dirMap = repoDir;\n     } else {\n         this.dirMap = (dir) => {\n-            return (path.normalize(dir ? path.resolve(repoDir, dir) : repoDir));\n+            return (path.normalize(dir ? path.join(repoDir, dir) : repoDir));\n         };\n     }"
        },
        {
            "index":560,
            "vuln_id":"GHSA-3v6h-hqm4-2rg6",
            "cwe_id":"{'CWE-22'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/cthackers\/adm-zip\/commit\/62f64004fefb894c523a7143e8a88ebe6c84df25'}",
            "dataset":"osv",
            "summary":"Arbitrary File Write in adm-zip Versions of `adm-zip` before 0.4.9 are vulnerable to arbitrary file write when used to extract a specifically crafted archive that contains path traversal filenames (`..\/..\/file.txt` for example).\n\n\n## Recommendation\n\nUpdate to version 0.4.9 or later.",
            "published_date":"2018-07-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/cthackers\/adm-zip",
            "commit_href":"https:\/\/github.com\/cthackers\/adm-zip\/commit\/62f64004fefb894c523a7143e8a88ebe6c84df25",
            "commit_sha":"62f64004fefb894c523a7143e8a88ebe6c84df25",
            "patch":"SINGLE",
            "chain_ord":"['62f64004fefb894c523a7143e8a88ebe6c84df25']",
            "before_first_fix_commit":"{'e116bc18df51e4e50c493cede82ae7696954b511', '6f4dfeb9a2166e93207443879988f97d88a37cde'}",
            "last_fix_commit":"62f64004fefb894c523a7143e8a88ebe6c84df25",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2018, 07:20:56",
            "message":"Merge pull request #212 from aviadatsnyk\/master\n\nfix: prevent extracting archived files outside of target path.  Credit to Snyk Security Research Team for disclosure and fixing the issue.",
            "author":"The Brain",
            "comments":"{'com_1': {'author': 'Shubham-9798', 'datetime': '08\/27\/2018, 04:25:44', 'body': 'adding adm-zip'}}",
            "stats":"{'additions': 11, 'deletions': 0, 'total': 11}",
            "files":"{'adm-zip.js': {'additions': 11, 'deletions': 0, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/cthackers\/adm-zip\/raw\/62f64004fefb894c523a7143e8a88ebe6c84df25\/adm-zip.js', 'patch': '@@ -354,6 +354,9 @@ module.exports = function(\/*String*\/input) {\\n \\n \\n             var target = pth.resolve(targetPath, maintainEntryPath ? entryName : pth.basename(entryName));\\n+            if(!target.startsWith(targetPath)) {\\n+                throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\\n+            }\\n \\n             if (item.isDirectory) {\\n                 target = pth.resolve(target, \"..\");\\n@@ -429,6 +432,10 @@ module.exports = function(\/*String*\/input) {\\n             _zip.entries.forEach(function(entry) {\\n                 entryName = entry.entryName.toString();\\n \\n+                if(!pth.resolve(targetPath, entryName).startsWith(targetPath)) {\\n+                    throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\\n+                }\\n+\\n                 if(isWin){\\n                     entryName = escapeFileName(entryName)\\n                 }\\n@@ -471,6 +478,10 @@ module.exports = function(\/*String*\/input) {\\n                     entryName = escapeFileName(entryName)\\n                 }\\n \\n+                if(!pth.resolve(targetPath, entryName).startsWith(targetPath)) {\\n+                  throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\\n+                }\\n+\\n                 if (entry.isDirectory) {\\n                     Utils.makeDir(pth.resolve(targetPath, entryName));\\n                     if(--i == 0)'}}",
            "message_norm":"merge pull request #212 from aviadatsnyk\/master\n\nfix: prevent extracting archived files outside of target path.  credit to snyk security research team for disclosure and fixing the issue.",
            "language":"en",
            "entities":"[('#212', 'ISSUE', ''), ('prevent', 'ACTION', ''), ('security', 'SECWORD', ''), ('disclosure', 'SECWORD', ''), ('fixing', 'ACTION', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['adm-zip.js'])",
            "num_files":1.0,
            "patch_content":"From 6f4dfeb9a2166e93207443879988f97d88a37cde Mon Sep 17 00:00:00 2001\nFrom: Aviad Reich <aviad@snyk.io>\nDate: Sun, 22 Apr 2018 11:22:24 +0300\nSubject: [PATCH] fix: prevent extracting archived files outside of target path\n\n---\n adm-zip.js | 11 +++++++++++\n 1 file changed, 11 insertions(+)\n\ndiff --git a\/adm-zip.js b\/adm-zip.js\nindex 972608f..634a96e 100644\n--- a\/adm-zip.js\n+++ b\/adm-zip.js\n@@ -354,6 +354,9 @@ module.exports = function(\/*String*\/input) {\n \n \n             var target = pth.resolve(targetPath, maintainEntryPath ? entryName : pth.basename(entryName));\n+            if(!target.startsWith(targetPath)) {\n+                throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\n+            }\n \n             if (item.isDirectory) {\n                 target = pth.resolve(target, \"..\");\n@@ -429,6 +432,10 @@ module.exports = function(\/*String*\/input) {\n             _zip.entries.forEach(function(entry) {\n                 entryName = entry.entryName.toString();\n \n+                if(!pth.resolve(targetPath, entryName).startsWith(targetPath)) {\n+                    throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\n+                }\n+\n                 if(isWin){\n                     entryName = escapeFileName(entryName)\n                 }\n@@ -471,6 +478,10 @@ module.exports = function(\/*String*\/input) {\n                     entryName = escapeFileName(entryName)\n                 }\n \n+                if(!pth.resolve(targetPath, entryName).startsWith(targetPath)) {\n+                  throw Utils.Errors.INVALID_FILENAME + \": \" + entryName;\n+                }\n+\n                 if (entry.isDirectory) {\n                     Utils.makeDir(pth.resolve(targetPath, entryName));\n                     if(--i == 0)"
        },
        {
            "index":916,
            "vuln_id":"GHSA-662x-fhqg-9p8v",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/faisalman\/ua-parser-js\/commit\/233d3bae22a795153a7e6638887ce159c63e557d'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service in ua-parser-js The package ua-parser-js before 0.7.22 are vulnerable to Regular Expression Denial of Service (ReDoS) via the regex for Redmi Phones and Mi Pad Tablets UA.",
            "published_date":"2021-05-07",
            "chain_len":1,
            "project":"https:\/\/github.com\/faisalman\/ua-parser-js",
            "commit_href":"https:\/\/github.com\/faisalman\/ua-parser-js\/commit\/233d3bae22a795153a7e6638887ce159c63e557d",
            "commit_sha":"233d3bae22a795153a7e6638887ce159c63e557d",
            "patch":"SINGLE",
            "chain_ord":"['233d3bae22a795153a7e6638887ce159c63e557d']",
            "before_first_fix_commit":"{'5230745280ba8aee775b0f5d2c8a2332f8ef2c4e'}",
            "last_fix_commit":"233d3bae22a795153a7e6638887ce159c63e557d",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/12\/2020, 08:47:15",
            "message":"Fix potential ReDoS vulnerability",
            "author":"Faisal Salman",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'src\/ua-parser.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/faisalman\/ua-parser-js\/raw\/233d3bae22a795153a7e6638887ce159c63e557d\/src%2Fua-parser.js', 'patch': \"@@ -585,9 +585,9 @@\\n             \/android.+(hm[\\\\s\\\\-_]*note?[\\\\s_]*(?:\\\\d\\\\w)?)\\\\s+build\/i,               \/\/ Xiaomi Hongmi\\n             \/android.+(mi[\\\\s\\\\-_]*(?:a\\\\d|one|one[\\\\s_]plus|note lte)?[\\\\s_]*(?:\\\\d?\\\\w?)[\\\\s_]*(?:plus)?)\\\\s+build\/i,    \\n                                                                                 \/\/ Xiaomi Mi\\n-            \/android.+(redmi[\\\\s\\\\-_]*(?:note)?(?:[\\\\s_]*[\\\\w\\\\s]+))\\\\s+build\/i       \/\/ Redmi Phones\\n+            \/android.+(redmi[\\\\s\\\\-_]*(?:note)?(?:[\\\\s_]?[\\\\w\\\\s]+))\\\\s+build\/i       \/\/ Redmi Phones\\n             ], [[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, MOBILE]], [\\n-            \/android.+(mi[\\\\s\\\\-_]*(?:pad)(?:[\\\\s_]*[\\\\w\\\\s]+))\\\\s+build\/i            \/\/ Mi Pad tablets\\n+            \/android.+(mi[\\\\s\\\\-_]*(?:pad)(?:[\\\\s_]?[\\\\w\\\\s]+))\\\\s+build\/i            \/\/ Mi Pad tablets\\n             ],[[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, TABLET]], [\\n             \/android.+;\\\\s(m[1-5]\\\\snote)\\\\sbuild\/i                                \/\/ Meizu\\n             ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], [\"}}",
            "message_norm":"fix potential redos vulnerability",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/ua-parser.js'])",
            "num_files":1.0,
            "patch_content":"From 233d3bae22a795153a7e6638887ce159c63e557d Mon Sep 17 00:00:00 2001\nFrom: Faisal Salman <f@faisalman.com>\nDate: Sat, 12 Sep 2020 15:47:15 +0700\nSubject: [PATCH] Fix potential ReDoS vulnerability\n\n---\n src\/ua-parser.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/ua-parser.js b\/src\/ua-parser.js\nindex d89312c60..3d807e1a7 100755\n--- a\/src\/ua-parser.js\n+++ b\/src\/ua-parser.js\n@@ -585,9 +585,9 @@\n             \/android.+(hm[\\s\\-_]*note?[\\s_]*(?:\\d\\w)?)\\s+build\/i,               \/\/ Xiaomi Hongmi\n             \/android.+(mi[\\s\\-_]*(?:a\\d|one|one[\\s_]plus|note lte)?[\\s_]*(?:\\d?\\w?)[\\s_]*(?:plus)?)\\s+build\/i,    \n                                                                                 \/\/ Xiaomi Mi\n-            \/android.+(redmi[\\s\\-_]*(?:note)?(?:[\\s_]*[\\w\\s]+))\\s+build\/i       \/\/ Redmi Phones\n+            \/android.+(redmi[\\s\\-_]*(?:note)?(?:[\\s_]?[\\w\\s]+))\\s+build\/i       \/\/ Redmi Phones\n             ], [[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, MOBILE]], [\n-            \/android.+(mi[\\s\\-_]*(?:pad)(?:[\\s_]*[\\w\\s]+))\\s+build\/i            \/\/ Mi Pad tablets\n+            \/android.+(mi[\\s\\-_]*(?:pad)(?:[\\s_]?[\\w\\s]+))\\s+build\/i            \/\/ Mi Pad tablets\n             ],[[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, TABLET]], [\n             \/android.+;\\s(m[1-5]\\snote)\\sbuild\/i                                \/\/ Meizu\n             ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], ["
        },
        {
            "index":911,
            "vuln_id":"GHSA-cpgw-2wxr-pww3",
            "cwe_id":"{'CWE-601'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/gogs\/gogs\/commit\/1f247cf8139cb483276cd8dd06385a800ce9d4b2'}",
            "dataset":"osv",
            "summary":"Open Redirect Open redirect vulnerability in Gogs before 0.12 allows remote attackers to redirect users to arbitrary websites and conduct phishing attacks via an initial \/\\ substring in the user\/login redirect_to parameter, related to the function isValidRedirect in routes\/user\/auth.go.",
            "published_date":"2021-06-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/gogs\/gogs",
            "commit_href":"https:\/\/github.com\/gogs\/gogs\/commit\/1f247cf8139cb483276cd8dd06385a800ce9d4b2",
            "commit_sha":"1f247cf8139cb483276cd8dd06385a800ce9d4b2",
            "patch":"SINGLE",
            "chain_ord":"['1f247cf8139cb483276cd8dd06385a800ce9d4b2']",
            "before_first_fix_commit":"{'c9bb33afc3ae35db21b26fd914bd80ca277a4e0d'}",
            "last_fix_commit":"1f247cf8139cb483276cd8dd06385a800ce9d4b2",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/06\/2018, 09:10:16",
            "message":"routes: fix open redirect vulnerability #5364 (#5365)",
            "author":"chromium1337",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'routes\/user\/auth.go': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/gogs\/gogs\/raw\/1f247cf8139cb483276cd8dd06385a800ce9d4b2\/routes%2Fuser%2Fauth.go', 'patch': \"@@ -73,10 +73,10 @@ func AutoLogin(c *context.Context) (bool, error) {\\n }\\n \\n \/\/ isValidRedirect returns false if the URL does not redirect to same site.\\n-\/\/ False: \/\/url, http:\/\/url\\n+\/\/ False: \/\/url, http:\/\/url, \/\\\\url\\n \/\/ True: \/url\\n func isValidRedirect(url string) bool {\\n-\\treturn len(url) >= 2 && url[0] == '\/' && url[1] != '\/'\\n+\\treturn len(url) >= 2 && url[0] == '\/' && url[1] != '\/' && url[1] != '\\\\\\\\'\\n }\\n \\n func Login(c *context.Context) {\"}}",
            "message_norm":"routes: fix open redirect vulnerability #5364 (#5365)",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('open redirect', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('#5364', 'ISSUE', ''), ('#5365', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['routes\/user\/auth.go'])",
            "num_files":1.0,
            "patch_content":"From 1f247cf8139cb483276cd8dd06385a800ce9d4b2 Mon Sep 17 00:00:00 2001\nFrom: chromium1337 <CurseRed@Gmail.com>\nDate: Mon, 6 Aug 2018 17:10:16 +0800\nSubject: [PATCH] routes: fix open redirect vulnerability #5364 (#5365)\n\n---\n routes\/user\/auth.go | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/routes\/user\/auth.go b\/routes\/user\/auth.go\nindex 16e8bd2d738..76e51c36699 100644\n--- a\/routes\/user\/auth.go\n+++ b\/routes\/user\/auth.go\n@@ -73,10 +73,10 @@ func AutoLogin(c *context.Context) (bool, error) {\n }\n \n \/\/ isValidRedirect returns false if the URL does not redirect to same site.\n-\/\/ False: \/\/url, http:\/\/url\n+\/\/ False: \/\/url, http:\/\/url, \/\\url\n \/\/ True: \/url\n func isValidRedirect(url string) bool {\n-\treturn len(url) >= 2 && url[0] == '\/' && url[1] != '\/'\n+\treturn len(url) >= 2 && url[0] == '\/' && url[1] != '\/' && url[1] != '\\\\'\n }\n \n func Login(c *context.Context) {"
        },
        {
            "index":552,
            "vuln_id":"GHSA-mj63-64x7-57xf",
            "cwe_id":"{'CWE-22'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/49c643bf66620646884ed141c94e5fdd85bcdd2f', 'https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/99bd29e3995c254e2d6f6c2e3454e4271665955a'}",
            "dataset":"osv",
            "summary":"Path traversal in impacket Multiple path traversal vulnerabilities exist in smbserver.py in Impacket before 0.9.23. An attacker that connects to a running smbserver instance can list and write to arbitrary files via ..\/ directory traversal. This could potentially be abused to achieve arbitrary code execution by replacing \/etc\/shadow or an SSH authorized key.",
            "published_date":"2021-06-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/SecureAuthCorp\/impacket",
            "commit_href":"https:\/\/github.com\/SecureAuthCorp\/impacket\/commit\/99bd29e3995c254e2d6f6c2e3454e4271665955a",
            "commit_sha":"99bd29e3995c254e2d6f6c2e3454e4271665955a",
            "patch":"MULTI",
            "chain_ord":"['99bd29e3995c254e2d6f6c2e3454e4271665955a', '49c643bf66620646884ed141c94e5fdd85bcdd2f']",
            "before_first_fix_commit":"{'6688da5d97592269aae72b3a00dc1ab186c0b33d', '91902eafb68fea932cf2350cab329f15afa554e5'}",
            "last_fix_commit":"49c643bf66620646884ed141c94e5fdd85bcdd2f",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/25\/2021, 11:06:02",
            "message":"Fix Path Traversal vulnerabilities by checking path prefix against incoming filename",
            "author":"OmriI",
            "comments":null,
            "stats":"{'additions': 2011, 'deletions': 1936, 'total': 3947}",
            "files":"{'impacket\/smbserver.py': {'additions': 2011, 'deletions': 1936, 'changes': 3947, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/SecureAuthCorp\/impacket\/raw\/99bd29e3995c254e2d6f6c2e3454e4271665955a\/impacket%2Fsmbserver.py', 'patch': None}}",
            "message_norm":"fix path traversal vulnerabilities by checking path prefix against incoming filename",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('path traversal', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['impacket\/smbserver.py'])",
            "num_files":1.0,
            "patch_content":"From 99bd29e3995c254e2d6f6c2e3454e4271665955a Mon Sep 17 00:00:00 2001\nFrom: OmriI <omri.inbar@checkmarx.com>\nDate: Sun, 25 Apr 2021 14:06:02 +0300\nSubject: [PATCH] Fix Path Traversal vulnerabilities by checking path prefix\n against incoming filename\n\n---\n impacket\/smbserver.py | 3947 +++++++++++++++++++++--------------------\n 1 file changed, 2011 insertions(+), 1936 deletions(-)\n\ndiff --git a\/impacket\/smbserver.py b\/impacket\/smbserver.py\nindex d51704d126..a10b79fecd 100644\n--- a\/impacket\/smbserver.py\n+++ b\/impacket\/smbserver.py\n@@ -46,7 +46,8 @@\n # For signing\n from impacket import smb, nmb, ntlm, uuid\n from impacket import smb3structs as smb2\n-from impacket.spnego import SPNEGO_NegTokenInit, TypesMech, MechTypes, SPNEGO_NegTokenResp, ASN1_AID, ASN1_SUPPORTED_MECH\n+from impacket.spnego import SPNEGO_NegTokenInit, TypesMech, MechTypes, SPNEGO_NegTokenResp, ASN1_AID, \\\n+    ASN1_SUPPORTED_MECH\n from impacket.nt_errors import STATUS_NO_MORE_FILES, STATUS_NETWORK_NAME_DELETED, STATUS_INVALID_PARAMETER, \\\n     STATUS_FILE_CLOSED, STATUS_MORE_PROCESSING_REQUIRED, STATUS_OBJECT_PATH_NOT_FOUND, STATUS_DIRECTORY_NOT_EMPTY, \\\n     STATUS_FILE_IS_A_DIRECTORY, STATUS_NOT_IMPLEMENTED, STATUS_INVALID_HANDLE, STATUS_OBJECT_NAME_COLLISION, \\\n@@ -61,16 +62,16 @@\n STATUS_SMB_BAD_UID = 0x005B0002\n STATUS_SMB_BAD_TID = 0x00050002\n \n+\n # Utility functions\n-# and general functions. \n-# There are some common functions that can be accessed from more than one SMB \n+# and general functions.\n+# There are some common functions that can be accessed from more than one SMB\n # command (or either TRANSACTION). That's why I'm putting them here\n # TODO: Return NT ERROR Codes\n \n def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage, ntlmChallenge, type1):\n     # Let's calculate the NTLMv2 Response\n \n-\n     responseKeyNT = ntlm.NTOWFv2(identity, '', authenticateMessage['domain_name'].decode('utf-16le'), nthash)\n     responseKeyLM = ntlm.LMOWFv2(identity, '', authenticateMessage['domain_name'].decode('utf-16le'), lmhash)\n \n@@ -103,8 +104,8 @@ def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage\n         responseFlags &= 0xffffffff ^ ntlm.NTLMSSP_NEGOTIATE_ALWAYS_SIGN\n \n     keyExchangeKey = ntlm.KXKEY(ntlmChallenge['flags'], sessionBaseKey, lmChallengeResponse,\n-                           ntlmChallenge['challenge'], '',\n-                           lmhash, nthash, True)\n+                                ntlmChallenge['challenge'], '',\n+                                lmhash, nthash, True)\n \n     # If we set up key exchange, let's fill the right variables\n     if ntlmChallenge['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:\n@@ -124,9 +125,9 @@ def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage\n \n \n def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):\n-# We don't want to add a possible failure here, since this is an\n-# extra bonus. We try, if it fails, returns nothing\n-# ToDo: Document the parameter's types (bytes \/ string) and check all the places where it's called\n+    # We don't want to add a possible failure here, since this is an\n+    # extra bonus. We try, if it fails, returns nothing\n+    # ToDo: Document the parameter's types (bytes \/ string) and check all the places where it's called\n     ret_value = ''\n     if type(challenge) is not bytes:\n         challenge = challenge.decode('latin-1')\n@@ -137,13 +138,13 @@ def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):\n             ret_value = {'hash_string': '%s::%s:%s:%s:%s' % (\n                 username.decode('utf-16le'), domain.decode('utf-16le'), hexlify(challenge).decode('latin-1'),\n                 hexlify(ntresponse).decode('latin-1')[:32],\n-            hexlify(ntresponse).decode()[32:]), 'hash_version': 'ntlmv2'}\n+                hexlify(ntresponse).decode()[32:]), 'hash_version': 'ntlmv2'}\n         else:\n             # NTLMv1\n             ret_value = {'hash_string': '%s::%s:%s:%s:%s' % (\n                 username.decode('utf-16le'), domain.decode('utf-16le'), hexlify(lmresponse).decode('latin-1'),\n                 hexlify(ntresponse).decode('latin-1'),\n-            hexlify(challenge).decode()), 'hash_version': 'ntlm'}\n+                hexlify(challenge).decode()), 'hash_version': 'ntlm'}\n     except:\n         # Let's try w\/o decoding Unicode\n         try:\n@@ -166,6 +167,7 @@ def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):\n \n     return ret_value\n \n+\n def writeJohnOutputToFile(hash_string, hash_version, file_name):\n     fn_data = os.path.splitext(file_name)\n     if hash_version == \"ntlmv2\":\n@@ -173,33 +175,37 @@ def writeJohnOutputToFile(hash_string, hash_version, file_name):\n     else:\n         output_filename = fn_data[0] + \"_ntlm\" + fn_data[1]\n \n-    with open(output_filename,\"a\") as f:\n-            f.write(hash_string)\n-            f.write('\\n')\t\t        \n+    with open(output_filename, \"a\") as f:\n+        f.write(hash_string)\n+        f.write('\\n')\n \n \n-def decodeSMBString( flags, text ):\n+def decodeSMBString(flags, text):\n     if flags & smb.SMB.FLAGS2_UNICODE:\n         return text.decode('utf-16le')\n     else:\n         return text\n \n-def encodeSMBString( flags, text ):\n+\n+def encodeSMBString(flags, text):\n     if flags & smb.SMB.FLAGS2_UNICODE:\n         return (text).encode('utf-16le')\n     else:\n         return text.encode('ascii')\n-    \n+\n+\n def getFileTime(t):\n     t *= 10000000\n     t += 116444736000000000\n     return t\n \n+\n def getUnixTime(t):\n     t -= 116444736000000000\n     t \/\/= 10000000\n     return t\n \n+\n def getSMBDate(t):\n     # TODO: Fix this :P\n     d = datetime.date.fromtimestamp(t)\n@@ -207,35 +213,39 @@ def getSMBDate(t):\n     ret = (year << 8) + (d.month << 4) + d.day\n     return ret\n \n+\n def getSMBTime(t):\n     # TODO: Fix this :P\n     d = datetime.datetime.fromtimestamp(t)\n-    return (d.hour << 8) + (d.minute << 4) + d.second \n+    return (d.hour << 8) + (d.minute << 4) + d.second\n+\n \n def getShares(connId, smbServer):\n     config = smbServer.getServerConfig()\n     sections = config.sections()\n     # Remove the global one\n-    del(sections[sections.index('global')])\n+    del (sections[sections.index('global')])\n     shares = {}\n     for i in sections:\n         shares[i] = dict(config.items(i))\n     return shares\n \n+\n def searchShare(connId, share, smbServer):\n     config = smbServer.getServerConfig()\n     if config.has_section(share):\n-       return dict(config.items(share))\n+        return dict(config.items(share))\n     else:\n-       return None\n+        return None\n+\n \n-def openFile(path,fileName, accessMode, fileAttributes, openMode):\n-    fileName = os.path.normpath(fileName.replace('\\\\','\/'))\n+def openFile(path, fileName, accessMode, fileAttributes, openMode):\n+    fileName = os.path.normpath(fileName.replace('\\\\', '\/'))\n     errorCode = 0\n     if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n-       # strip leading '\/'\n-       fileName = fileName[1:]\n-    pathName = os.path.join(path,fileName)\n+        # strip leading '\/'\n+        fileName = fileName[1:]\n+    pathName = os.path.join(path, fileName)\n     mode = 0\n     # Check the Open Mode\n     if openMode & 0x10:\n@@ -245,61 +255,61 @@ def openFile(path,fileName, accessMode, fileAttributes, openMode):\n         # If file does not exist, return an error\n         if os.path.exists(pathName) is not True:\n             errorCode = STATUS_NO_SUCH_FILE\n-            return 0,mode, pathName, errorCode\n+            return 0, mode, pathName, errorCode\n \n     if os.path.isdir(pathName) and (fileAttributes & smb.ATTR_DIRECTORY) == 0:\n         # Request to open a normal file and this is actually a directory\n-            errorCode = STATUS_FILE_IS_A_DIRECTORY\n-            return 0, mode, pathName, errorCode\n+        errorCode = STATUS_FILE_IS_A_DIRECTORY\n+        return 0, mode, pathName, errorCode\n     # Check the Access Mode\n     if accessMode & 0x7 == 1:\n-       mode |= os.O_WRONLY\n+        mode |= os.O_WRONLY\n     elif accessMode & 0x7 == 2:\n-       mode |= os.O_RDWR\n+        mode |= os.O_RDWR\n     else:\n-       mode = os.O_RDONLY\n+        mode = os.O_RDONLY\n \n     try:\n         if sys.platform == 'win32':\n             mode |= os.O_BINARY\n         fid = os.open(pathName, mode)\n     except Exception as e:\n-        LOG.error(\"openFile: %s,%s\" % (pathName, mode) ,e)\n+        LOG.error(\"openFile: %s,%s\" % (pathName, mode), e)\n         fid = 0\n         errorCode = STATUS_ACCESS_DENIED\n \n     return fid, mode, pathName, errorCode\n \n-def queryFsInformation(path, filename, level=0, pktFlags = smb.SMB.FLAGS2_UNICODE):\n \n+def queryFsInformation(path, filename, level=0, pktFlags=smb.SMB.FLAGS2_UNICODE):\n     if pktFlags & smb.SMB.FLAGS2_UNICODE:\n-         encoding = 'utf-16le'\n+        encoding = 'utf-16le'\n     else:\n-         encoding = 'ascii'\n+        encoding = 'ascii'\n \n-    fileName = os.path.normpath(filename.replace('\\\\','\/'))\n+    fileName = os.path.normpath(filename.replace('\\\\', '\/'))\n     if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n-       # strip leading '\/'\n-       fileName = fileName[1:]\n-    pathName = os.path.join(path,fileName)\n+        # strip leading '\/'\n+        fileName = fileName[1:]\n+    pathName = os.path.join(path, fileName)\n     fileSize = os.path.getsize(pathName)\n     (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n     if level == smb.SMB_QUERY_FS_ATTRIBUTE_INFO or level == smb2.SMB2_FILESYSTEM_ATTRIBUTE_INFO:\n         data = smb.SMBQueryFsAttributeInfo()\n-        data['FileSystemAttributes']      = smb.FILE_CASE_SENSITIVE_SEARCH | smb.FILE_CASE_PRESERVED_NAMES\n+        data['FileSystemAttributes'] = smb.FILE_CASE_SENSITIVE_SEARCH | smb.FILE_CASE_PRESERVED_NAMES\n         data['MaxFilenNameLengthInBytes'] = 255\n-        data['LengthOfFileSystemName']    = len('XTFS')*2\n-        data['FileSystemName']            = 'XTFS'.encode('utf-16le')\n+        data['LengthOfFileSystemName'] = len('XTFS') * 2\n+        data['FileSystemName'] = 'XTFS'.encode('utf-16le')\n         return data.getData()\n     elif level == smb.SMB_INFO_VOLUME:\n-        data = smb.SMBQueryFsInfoVolume( flags = pktFlags )\n-        data['VolumeLabel']               = 'SHARE'.encode(encoding)\n+        data = smb.SMBQueryFsInfoVolume(flags=pktFlags)\n+        data['VolumeLabel'] = 'SHARE'.encode(encoding)\n         return data.getData()\n     elif level == smb.SMB_QUERY_FS_VOLUME_INFO or level == smb2.SMB2_FILESYSTEM_VOLUME_INFO:\n         data = smb.SMBQueryFsVolumeInfo()\n-        data['VolumeLabel']               = ''\n-        data['VolumeCreationTime']        = getFileTime(ctime)\n-        return data.getData() \n+        data['VolumeLabel'] = ''\n+        data['VolumeCreationTime'] = getFileTime(ctime)\n+        return data.getData()\n     elif level == smb.SMB_QUERY_FS_SIZE_INFO:\n         data = smb.SMBQueryFsSizeInfo()\n         return data.getData()\n@@ -319,225 +329,241 @@ def queryFsInformation(path, filename, level=0, pktFlags = smb.SMB.FLAGS2_UNICOD\n         fileAttributes = attribs\n         return fileSize, lastWriteTime, fileAttributes\n \n-def findFirst2(path, fileName, level, searchAttributes, pktFlags = smb.SMB.FLAGS2_UNICODE, isSMB2 = False):\n-     # TODO: Depending on the level, this could be done much simpler\n-     \n-     #print \"FindFirs2 path:%s, filename:%s\" % (path, fileName)\n-     fileName = os.path.normpath(fileName.replace('\\\\','\/'))\n-     # Let's choose the right encoding depending on the request\n-     if pktFlags & smb.SMB.FLAGS2_UNICODE:\n-         encoding = 'utf-16le'\n-     else:\n-         encoding = 'ascii'\n-\n-     if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+\n+def findFirst2(path, fileName, level, searchAttributes, pktFlags=smb.SMB.FLAGS2_UNICODE, isSMB2=False):\n+    # TODO: Depending on the level, this could be done much simpler\n+\n+    # print \"FindFirs2 path:%s, filename:%s\" % (path, fileName)\n+    fileName = os.path.normpath(fileName.replace('\\\\', '\/'))\n+    # Let's choose the right encoding depending on the request\n+    if pktFlags & smb.SMB.FLAGS2_UNICODE:\n+        encoding = 'utf-16le'\n+    else:\n+        encoding = 'ascii'\n+\n+    if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n         # strip leading '\/'\n         fileName = fileName[1:]\n \n-     pathName = os.path.join(path,fileName)\n-     files = []\n-\n-     if pathName.find('*') == -1 and pathName.find('?') == -1:\n-         # No search patterns\n-         pattern = ''\n-     else:\n-         pattern = os.path.basename(pathName)\n-         dirName = os.path.dirname(pathName)\n-\n-     # Always add . and .. Not that important for Windows, but Samba whines if \n-     # not present (for * search only)\n-     if pattern == '*':\n-         files.append(os.path.join(dirName,'.'))\n-         files.append(os.path.join(dirName,'..'))\n-\n-     if pattern != '':\n-         for file in os.listdir(dirName):\n-             if fnmatch.fnmatch(file.lower(),pattern.lower()):\n+    if not isInFileJail(path, fileName):\n+        LOG.error(\"Path not in current working directory\")\n+        return [], 0, STATUS_NOT_SUPPORTED\n+\n+    pathName = os.path.join(path, fileName)\n+    files = []\n+\n+    if pathName.find('*') == -1 and pathName.find('?') == -1:\n+        # No search patterns\n+        pattern = ''\n+    else:\n+        pattern = os.path.basename(pathName)\n+        dirName = os.path.dirname(pathName)\n+\n+    # Always add . and .. Not that important for Windows, but Samba whines if\n+    # not present (for * search only)\n+    if pattern == '*':\n+        files.append(os.path.join(dirName, '.'))\n+        files.append(os.path.join(dirName, '..'))\n+\n+    if pattern != '':\n+        for file in os.listdir(dirName):\n+            if fnmatch.fnmatch(file.lower(), pattern.lower()):\n                 entry = os.path.join(dirName, file)\n                 if os.path.isdir(entry):\n                     if searchAttributes & smb.ATTR_DIRECTORY:\n                         files.append(entry)\n                 else:\n                     files.append(entry)\n-     else:\n-         if os.path.exists(pathName):\n-             files.append(pathName)\n+    else:\n+        if os.path.exists(pathName):\n+            files.append(pathName)\n \n-     searchResult = []\n-     searchCount = len(files)\n-     errorCode = STATUS_SUCCESS\n+    searchResult = []\n+    searchCount = len(files)\n+    errorCode = STATUS_SUCCESS\n \n-     for i in files:\n+    for i in files:\n         if level == smb.SMB_FIND_FILE_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_BOTH_DIRECTORY_INFO:\n-            item = smb.SMBFindFileBothDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileBothDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_DIRECTORY_INFO or level == smb2.SMB2_FILE_DIRECTORY_INFO:\n-            item = smb.SMBFindFileDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_FULL_DIRECTORY_INFO or level == smb2.SMB2_FULL_DIRECTORY_INFO:\n-            item = smb.SMBFindFileFullDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileFullDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_INFO_STANDARD:\n-            item = smb.SMBFindInfoStandard( flags = pktFlags )\n+            item = smb.SMBFindInfoStandard(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_ID_FULL_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_FULL_DIRECTORY_INFO:\n-            item = smb.SMBFindFileIdFullDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileIdFullDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_BOTH_DIRECTORY_INFO:\n-            item = smb.SMBFindFileIdBothDirectoryInfo( flags = pktFlags )\n+            item = smb.SMBFindFileIdBothDirectoryInfo(flags=pktFlags)\n         elif level == smb.SMB_FIND_FILE_NAMES_INFO or level == smb2.SMB2_FILE_NAMES_INFO:\n-            item = smb.SMBFindFileNamesInfo( flags = pktFlags )\n+            item = smb.SMBFindFileNamesInfo(flags=pktFlags)\n         else:\n             LOG.error(\"Wrong level %d!\" % level)\n-            return  searchResult, searchCount, STATUS_NOT_SUPPORTED\n-            \n+            return searchResult, searchCount, STATUS_NOT_SUPPORTED\n+\n         (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(i)\n         if os.path.isdir(i):\n-           item['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n+            item['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n         else:\n-           item['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n+            item['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n \n         item['FileName'] = os.path.basename(i).encode(encoding)\n \n         if level == smb.SMB_FIND_FILE_BOTH_DIRECTORY_INFO or level == smb.SMB_FIND_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_BOTH_DIRECTORY_INFO:\n-           item['EaSize']            = 0\n-           item['EndOfFile']         = size\n-           item['AllocationSize']    = size\n-           item['CreationTime']      = getFileTime(ctime)\n-           item['LastAccessTime']    = getFileTime(atime)\n-           item['LastWriteTime']     = getFileTime(mtime)\n-           item['LastChangeTime']    = getFileTime(mtime)\n-           item['ShortName']         = '\\x00'*24\n-           item['FileName']          = os.path.basename(i).encode(encoding)\n-           padLen = (8-(len(item) % 8)) % 8\n-           item['NextEntryOffset']   = len(item) + padLen\n+            item['EaSize'] = 0\n+            item['EndOfFile'] = size\n+            item['AllocationSize'] = size\n+            item['CreationTime'] = getFileTime(ctime)\n+            item['LastAccessTime'] = getFileTime(atime)\n+            item['LastWriteTime'] = getFileTime(mtime)\n+            item['LastChangeTime'] = getFileTime(mtime)\n+            item['ShortName'] = '\\x00' * 24\n+            item['FileName'] = os.path.basename(i).encode(encoding)\n+            padLen = (8 - (len(item) % 8)) % 8\n+            item['NextEntryOffset'] = len(item) + padLen\n         elif level == smb.SMB_FIND_FILE_DIRECTORY_INFO:\n-           item['EndOfFile']         = size\n-           item['AllocationSize']    = size\n-           item['CreationTime']      = getFileTime(ctime)\n-           item['LastAccessTime']    = getFileTime(atime)\n-           item['LastWriteTime']     = getFileTime(mtime)\n-           item['LastChangeTime']    = getFileTime(mtime)\n-           item['FileName']          = os.path.basename(i).encode(encoding)\n-           padLen = (8-(len(item) % 8)) % 8\n-           item['NextEntryOffset']   = len(item) + padLen\n+            item['EndOfFile'] = size\n+            item['AllocationSize'] = size\n+            item['CreationTime'] = getFileTime(ctime)\n+            item['LastAccessTime'] = getFileTime(atime)\n+            item['LastWriteTime'] = getFileTime(mtime)\n+            item['LastChangeTime'] = getFileTime(mtime)\n+            item['FileName'] = os.path.basename(i).encode(encoding)\n+            padLen = (8 - (len(item) % 8)) % 8\n+            item['NextEntryOffset'] = len(item) + padLen\n         elif level == smb.SMB_FIND_FILE_FULL_DIRECTORY_INFO or level == smb.SMB_FIND_FILE_ID_FULL_DIRECTORY_INFO or level == smb2.SMB2_FULL_DIRECTORY_INFO:\n-           item['EaSize']            = 0\n-           item['EndOfFile']         = size\n-           item['AllocationSize']    = size\n-           item['CreationTime']      = getFileTime(ctime)\n-           item['LastAccessTime']    = getFileTime(atime)\n-           item['LastWriteTime']     = getFileTime(mtime)\n-           item['LastChangeTime']    = getFileTime(mtime)\n-           padLen = (8-(len(item) % 8)) % 8\n-           item['NextEntryOffset']   = len(item) + padLen\n+            item['EaSize'] = 0\n+            item['EndOfFile'] = size\n+            item['AllocationSize'] = size\n+            item['CreationTime'] = getFileTime(ctime)\n+            item['LastAccessTime'] = getFileTime(atime)\n+            item['LastWriteTime'] = getFileTime(mtime)\n+            item['LastChangeTime'] = getFileTime(mtime)\n+            padLen = (8 - (len(item) % 8)) % 8\n+            item['NextEntryOffset'] = len(item) + padLen\n         elif level == smb.SMB_FIND_INFO_STANDARD:\n-           item['EaSize']            = size\n-           item['CreationDate']      = getSMBDate(ctime)\n-           item['CreationTime']      = getSMBTime(ctime)\n-           item['LastAccessDate']    = getSMBDate(atime)\n-           item['LastAccessTime']    = getSMBTime(atime)\n-           item['LastWriteDate']     = getSMBDate(mtime)\n-           item['LastWriteTime']     = getSMBTime(mtime)\n+            item['EaSize'] = size\n+            item['CreationDate'] = getSMBDate(ctime)\n+            item['CreationTime'] = getSMBTime(ctime)\n+            item['LastAccessDate'] = getSMBDate(atime)\n+            item['LastAccessTime'] = getSMBTime(atime)\n+            item['LastWriteDate'] = getSMBDate(mtime)\n+            item['LastWriteTime'] = getSMBTime(mtime)\n         searchResult.append(item)\n \n-     # No more files\n-     if (level >= smb.SMB_FIND_FILE_DIRECTORY_INFO or isSMB2 is True) and searchCount > 0:\n-         searchResult[-1]['NextEntryOffset'] = 0\n+    # No more files\n+    if (level >= smb.SMB_FIND_FILE_DIRECTORY_INFO or isSMB2 is True) and searchCount > 0:\n+        searchResult[-1]['NextEntryOffset'] = 0\n+\n+    return searchResult, searchCount, errorCode\n \n-     return searchResult, searchCount, errorCode\n \n def queryFileInformation(path, filename, level):\n-    #print \"queryFileInfo path: %s, filename: %s, level:0x%x\" % (path,filename,level)\n-    return queryPathInformation(path,filename, level)\n+    # print \"queryFileInfo path: %s, filename: %s, level:0x%x\" % (path,filename,level)\n+    return queryPathInformation(path, filename, level)\n+\n \n def queryPathInformation(path, filename, level):\n     # TODO: Depending on the level, this could be done much simpler\n-  #print(\"queryPathInfo path: %s, filename: %s, level:0x%x\" % (path,filename,level))\n-  try:\n-    errorCode = 0\n-    fileName = os.path.normpath(filename.replace('\\\\','\/'))\n-    if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\') and path != '':\n-       # strip leading '\/'\n-       fileName = fileName[1:]\n-    pathName = os.path.join(path,fileName)\n-    if os.path.exists(pathName):\n-        (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n-        if level == smb.SMB_QUERY_FILE_BASIC_INFO:\n-            infoRecord = smb.SMBQueryFileBasicInfo()\n-            infoRecord['CreationTime']         = getFileTime(ctime)\n-            infoRecord['LastAccessTime']       = getFileTime(atime)\n-            infoRecord['LastWriteTime']        = getFileTime(mtime)\n-            infoRecord['LastChangeTime']       = getFileTime(mtime)\n-            if os.path.isdir(pathName):\n-               infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n-            else:\n-               infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n-        elif level == smb.SMB_QUERY_FILE_STANDARD_INFO:\n-            infoRecord = smb.SMBQueryFileStandardInfo()\n-            infoRecord['AllocationSize']       = size\n-            infoRecord['EndOfFile']            = size\n-            if os.path.isdir(pathName):\n-               infoRecord['Directory']         = 1\n-            else:\n-               infoRecord['Directory']         = 0\n-        elif level == smb.SMB_QUERY_FILE_ALL_INFO or level == smb2.SMB2_FILE_ALL_INFO:\n-            infoRecord = smb.SMBQueryFileAllInfo()\n-            infoRecord['CreationTime']         = getFileTime(ctime)\n-            infoRecord['LastAccessTime']       = getFileTime(atime)\n-            infoRecord['LastWriteTime']        = getFileTime(mtime)\n-            infoRecord['LastChangeTime']       = getFileTime(mtime)\n-            if os.path.isdir(pathName):\n-               infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n-            else:\n-               infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n-            infoRecord['AllocationSize']       = size\n-            infoRecord['EndOfFile']            = size\n-            if os.path.isdir(pathName):\n-               infoRecord['Directory']         = 1\n-            else:\n-               infoRecord['Directory']         = 0\n-            infoRecord['FileName']             = filename.encode('utf-16le')\n-        elif level == smb2.SMB2_FILE_NETWORK_OPEN_INFO:\n-            infoRecord = smb.SMBFileNetworkOpenInfo()\n-            infoRecord['CreationTime']         = getFileTime(ctime)\n-            infoRecord['LastAccessTime']       = getFileTime(atime)\n-            infoRecord['LastWriteTime']        = getFileTime(mtime)\n-            infoRecord['ChangeTime']           = getFileTime(mtime)\n-            infoRecord['AllocationSize']       = size\n-            infoRecord['EndOfFile']            = size\n-            if os.path.isdir(pathName):\n-               infoRecord['FileAttributes'] = smb.ATTR_DIRECTORY\n+    # print(\"queryPathInfo path: %s, filename: %s, level:0x%x\" % (path,filename,level))\n+    try:\n+        errorCode = 0\n+        fileName = os.path.normpath(filename.replace('\\\\', '\/'))\n+        if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\') and path != '':\n+            # strip leading '\/'\n+            fileName = fileName[1:]\n+        pathName = os.path.join(path, fileName)\n+        if os.path.exists(pathName):\n+            (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n+            if level == smb.SMB_QUERY_FILE_BASIC_INFO:\n+                infoRecord = smb.SMBQueryFileBasicInfo()\n+                infoRecord['CreationTime'] = getFileTime(ctime)\n+                infoRecord['LastAccessTime'] = getFileTime(atime)\n+                infoRecord['LastWriteTime'] = getFileTime(mtime)\n+                infoRecord['LastChangeTime'] = getFileTime(mtime)\n+                if os.path.isdir(pathName):\n+                    infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n+                else:\n+                    infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n+            elif level == smb.SMB_QUERY_FILE_STANDARD_INFO:\n+                infoRecord = smb.SMBQueryFileStandardInfo()\n+                infoRecord['AllocationSize'] = size\n+                infoRecord['EndOfFile'] = size\n+                if os.path.isdir(pathName):\n+                    infoRecord['Directory'] = 1\n+                else:\n+                    infoRecord['Directory'] = 0\n+            elif level == smb.SMB_QUERY_FILE_ALL_INFO or level == smb2.SMB2_FILE_ALL_INFO:\n+                infoRecord = smb.SMBQueryFileAllInfo()\n+                infoRecord['CreationTime'] = getFileTime(ctime)\n+                infoRecord['LastAccessTime'] = getFileTime(atime)\n+                infoRecord['LastWriteTime'] = getFileTime(mtime)\n+                infoRecord['LastChangeTime'] = getFileTime(mtime)\n+                if os.path.isdir(pathName):\n+                    infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY\n+                else:\n+                    infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n+                infoRecord['AllocationSize'] = size\n+                infoRecord['EndOfFile'] = size\n+                if os.path.isdir(pathName):\n+                    infoRecord['Directory'] = 1\n+                else:\n+                    infoRecord['Directory'] = 0\n+                infoRecord['FileName'] = filename.encode('utf-16le')\n+            elif level == smb2.SMB2_FILE_NETWORK_OPEN_INFO:\n+                infoRecord = smb.SMBFileNetworkOpenInfo()\n+                infoRecord['CreationTime'] = getFileTime(ctime)\n+                infoRecord['LastAccessTime'] = getFileTime(atime)\n+                infoRecord['LastWriteTime'] = getFileTime(mtime)\n+                infoRecord['ChangeTime'] = getFileTime(mtime)\n+                infoRecord['AllocationSize'] = size\n+                infoRecord['EndOfFile'] = size\n+                if os.path.isdir(pathName):\n+                    infoRecord['FileAttributes'] = smb.ATTR_DIRECTORY\n+                else:\n+                    infoRecord['FileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n+            elif level == smb.SMB_QUERY_FILE_EA_INFO or level == smb2.SMB2_FILE_EA_INFO:\n+                infoRecord = smb.SMBQueryFileEaInfo()\n+            elif level == smb2.SMB2_FILE_STREAM_INFO:\n+                infoRecord = smb.SMBFileStreamInformation()\n             else:\n-               infoRecord['FileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE\n-        elif level == smb.SMB_QUERY_FILE_EA_INFO or level == smb2.SMB2_FILE_EA_INFO: \n-            infoRecord = smb.SMBQueryFileEaInfo()\n-        elif level == smb2.SMB2_FILE_STREAM_INFO:\n-            infoRecord = smb.SMBFileStreamInformation()\n+                LOG.error('Unknown level for query path info! 0x%x' % level)\n+                # UNSUPPORTED\n+                return None, STATUS_NOT_SUPPORTED\n+\n+            return infoRecord, errorCode\n         else:\n-            LOG.error('Unknown level for query path info! 0x%x' % level)\n-            # UNSUPPORTED\n-            return None, STATUS_NOT_SUPPORTED\n+            # NOT FOUND\n+            return None, STATUS_OBJECT_NAME_NOT_FOUND\n+    except Exception as e:\n+        LOG.error('queryPathInfo: %s' % e)\n+        raise\n \n-        return infoRecord, errorCode\n-    else:\n-        # NOT FOUND\n-        return None, STATUS_OBJECT_NAME_NOT_FOUND\n-  except Exception as e:\n-      LOG.error('queryPathInfo: %s' % e)\n-      raise\n \n def queryDiskInformation(path):\n-# TODO: Do something useful here :)\n-# For now we just return fake values\n-   totalUnits = 65535\n-   freeUnits = 65535\n-   return totalUnits, freeUnits\n+    # TODO: Do something useful here :)\n+    # For now we just return fake values\n+    totalUnits = 65535\n+    freeUnits = 65535\n+    return totalUnits, freeUnits\n+\n+\n+def isInFileJail(path, fileName):\n+    pathName = os.path.join(path, fileName)\n+    share_real_path = os.path.realpath(path)\n+    return os.path.commonprefix((os.path.realpath(pathName), share_real_path)) == share_real_path\n+\n \n # Here we implement the NT transaction handlers\n class NTTRANSCommands:\n-    def default(self, connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def default(self, connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         pass\n \n+\n # Here we implement the NT transaction handlers\n class TRANSCommands:\n     @staticmethod\n-    def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         # Minimal [MS-RAP] implementation, just to return the shares\n         connData = smbServer.getConnectionData(connId)\n \n@@ -545,20 +571,20 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n         respParameters = b''\n         respData = b''\n         errorCode = STATUS_SUCCESS\n-        if struct.unpack('<H',parameters[:2])[0] == 0:\n+        if struct.unpack('<H', parameters[:2])[0] == 0:\n             # NetShareEnum Request\n             netShareEnum = smb.SMBNetShareEnum(parameters)\n             if netShareEnum['InfoLevel'] == 1:\n                 shares = getShares(connId, smbServer)\n                 respParameters = smb.SMBNetShareEnumResponse()\n-                respParameters['EntriesReturned']  = len(shares)\n+                respParameters['EntriesReturned'] = len(shares)\n                 respParameters['EntriesAvailable'] = len(shares)\n                 tailData = ''\n                 for i in shares:\n                     # NetShareInfo1 len == 20\n                     entry = smb.NetShareInfo1()\n-                    entry['NetworkName'] = i + '\\x00'*(13-len(i))\n-                    entry['Type']        = int(shares[i]['share type'])\n+                    entry['NetworkName'] = i + '\\x00' * (13 - len(i))\n+                    entry['Type'] = int(shares[i]['share type'])\n                     # (beto) If offset == 0 it crashes explorer.exe on windows 7\n                     entry['RemarkOffsetLow'] = 20 * len(shares) + len(tailData)\n                     respData += entry.getData()\n@@ -570,28 +596,28 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n             else:\n                 # We don't support other info levels\n                 errorCode = STATUS_NOT_SUPPORTED\n-        elif struct.unpack('<H',parameters[:2])[0] == 13:\n+        elif struct.unpack('<H', parameters[:2])[0] == 13:\n             # NetrServerGetInfo Request\n             respParameters = smb.SMBNetServerGetInfoResponse()\n             netServerInfo = smb.SMBNetServerInfo1()\n             netServerInfo['ServerName'] = smbServer.getServerName()\n             respData = netServerInfo.getData()\n             respParameters['TotalBytesAvailable'] = len(respData)\n-        elif struct.unpack('<H',parameters[:2])[0] == 1:\n+        elif struct.unpack('<H', parameters[:2])[0] == 1:\n             # NetrShareGetInfo Request\n             request = smb.SMBNetShareGetInfo(parameters)\n             respParameters = smb.SMBNetShareGetInfoResponse()\n             shares = getShares(connId, smbServer)\n             share = shares[request['ShareName'].upper()]\n-            shareInfo = smb.NetShareInfo1() \n+            shareInfo = smb.NetShareInfo1()\n             shareInfo['NetworkName'] = request['ShareName'].upper() + '\\x00'\n-            shareInfo['Type']        = int(share['share type'])\n+            shareInfo['Type'] = int(share['share type'])\n             respData = shareInfo.getData()\n             if 'comment' in share:\n                 shareInfo['RemarkOffsetLow'] = len(respData)\n                 respData += share['comment'] + '\\x00'\n             respParameters['TotalBytesAvailable'] = len(respData)\n-     \n+\n         else:\n             # We don't know how to handle anything else\n             errorCode = STATUS_NOT_SUPPORTED\n@@ -601,15 +627,15 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n         return respSetup, respParameters, respData, errorCode\n \n     @staticmethod\n-    def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n         respParameters = b''\n         respData = b''\n         errorCode = STATUS_SUCCESS\n-        SMBCommand  = smb.SMBCommand(recvPacket['Data'][0])\n-        transParameters= smb.SMBTransaction_Parameters(SMBCommand['Parameters'])\n+        SMBCommand = smb.SMBCommand(recvPacket['Data'][0])\n+        transParameters = smb.SMBTransaction_Parameters(SMBCommand['Parameters'])\n \n         # Extract the FID\n         fid = struct.unpack('<H', transParameters['Setup'][2:])[0]\n@@ -617,8 +643,8 @@ def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCo\n         if fid in connData['OpenedFiles']:\n             fileHandle = connData['OpenedFiles'][fid]['FileHandle']\n             if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                os.write(fileHandle,data)\n-                respData = os.read(fileHandle,data)\n+                os.write(fileHandle, data)\n+                respData = os.read(fileHandle, data)\n             else:\n                 sock = connData['OpenedFiles'][fid]['Socket']\n                 sock.send(data)\n@@ -630,26 +656,27 @@ def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCo\n \n         return respSetup, respParameters, respData, errorCode\n \n+\n # Here we implement the transaction2 handlers\n class TRANS2Commands:\n     # All these commands return setup, parameters, data, errorCode\n     @staticmethod\n-    def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n         respParameters = b''\n         respData = b''\n         errorCode = STATUS_SUCCESS\n-        setPathInfoParameters = smb.SMBSetPathInformation_Parameters(flags = recvPacket['Flags2'], data = parameters)\n+        setPathInfoParameters = smb.SMBSetPathInformation_Parameters(flags=recvPacket['Flags2'], data=parameters)\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-            path     = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n             fileName = decodeSMBString(recvPacket['Flags2'], setPathInfoParameters['FileName'])\n-            fileName = os.path.normpath(fileName.replace('\\\\','\/'))\n+            fileName = os.path.normpath(fileName.replace('\\\\', '\/'))\n             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\') and path != '':\n-               # strip leading '\/'\n-               fileName = fileName[1:]\n-            pathName = os.path.join(path,fileName)\n+                # strip leading '\/'\n+                fileName = fileName[1:]\n+            pathName = os.path.join(path, fileName)\n             if os.path.exists(pathName):\n                 informationLevel = setPathInfoParameters['InformationLevel']\n                 if informationLevel == smb.SMB_SET_FILE_BASIC_INFO:\n@@ -666,11 +693,12 @@ def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n                     else:\n                         mtime = getUnixTime(mtime)\n                     if mtime != -1 or atime != -1:\n-                        os.utime(pathName,(atime,mtime))\n+                        os.utime(pathName, (atime, mtime))\n                 else:\n-                    smbServer.log('Unknown level for set path info! 0x%x' % setPathInfoParameters['InformationLevel'], logging.ERROR)\n+                    smbServer.log('Unknown level for set path info! 0x%x' % setPathInfoParameters['InformationLevel'],\n+                                  logging.ERROR)\n                     # UNSUPPORTED\n-                    errorCode =  STATUS_NOT_SUPPORTED\n+                    errorCode = STATUS_NOT_SUPPORTED\n             else:\n                 errorCode = STATUS_OBJECT_NAME_NOT_FOUND\n \n@@ -684,9 +712,8 @@ def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n \n         return respSetup, respParameters, respData, errorCode\n \n-\n     @staticmethod\n-    def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n@@ -702,9 +729,9 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n                 if informationLevel == smb.SMB_SET_FILE_DISPOSITION_INFO:\n                     infoRecord = smb.SMBSetFileDispositionInfo(parameters)\n                     if infoRecord['DeletePending'] > 0:\n-                       # Mark this file for removal after closed\n-                       connData['OpenedFiles'][setFileInfoParameters['FID']]['DeleteOnClose'] = True\n-                       respParameters = smb.SMBSetFileInformationResponse_Parameters()\n+                        # Mark this file for removal after closed\n+                        connData['OpenedFiles'][setFileInfoParameters['FID']]['DeleteOnClose'] = True\n+                        respParameters = smb.SMBSetFileInformationResponse_Parameters()\n                 elif informationLevel == smb.SMB_SET_FILE_BASIC_INFO:\n                     infoRecord = smb.SMBSetFileBasicInfo(data)\n                     # Creation time won't be set,  the other ones we play with.\n@@ -718,17 +745,18 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n                         mtime = -1\n                     else:\n                         mtime = getUnixTime(mtime)\n-                    os.utime(fileName,(atime,mtime))\n+                    os.utime(fileName, (atime, mtime))\n                 elif informationLevel == smb.SMB_SET_FILE_END_OF_FILE_INFO:\n                     fileHandle = connData['OpenedFiles'][setFileInfoParameters['FID']]['FileHandle']\n                     infoRecord = smb.SMBSetFileEndOfFileInfo(data)\n                     if infoRecord['EndOfFile'] > 0:\n-                        os.lseek(fileHandle, infoRecord['EndOfFile']-1, 0)\n+                        os.lseek(fileHandle, infoRecord['EndOfFile'] - 1, 0)\n                         os.write(fileHandle, b'\\x00')\n                 else:\n-                    smbServer.log('Unknown level for set file info! 0x%x' % setFileInfoParameters['InformationLevel'], logging.ERROR)\n+                    smbServer.log('Unknown level for set file info! 0x%x' % setFileInfoParameters['InformationLevel'],\n+                                  logging.ERROR)\n                     # UNSUPPORTED\n-                    errorCode =  STATUS_NOT_SUPPORTED\n+                    errorCode = STATUS_NOT_SUPPORTED\n             else:\n                 errorCode = STATUS_NO_SUCH_FILE\n \n@@ -742,7 +770,7 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC\n         return respSetup, respParameters, respData, errorCode\n \n     @staticmethod\n-    def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n@@ -770,7 +798,7 @@ def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDat\n         return respSetup, respParameters, respData, errorCode\n \n     @staticmethod\n-    def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n \n         respSetup = b''\n@@ -778,7 +806,7 @@ def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDat\n         respData = b''\n         errorCode = 0\n \n-        queryPathInfoParameters = smb.SMBQueryPathInformation_Parameters(flags = recvPacket['Flags2'], data = parameters)\n+        queryPathInfoParameters = smb.SMBQueryPathInformation_Parameters(flags=recvPacket['Flags2'], data=parameters)\n \n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n@@ -787,30 +815,30 @@ def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDat\n                                                                                    queryPathInfoParameters['FileName']),\n                                                              queryPathInfoParameters['InformationLevel'])\n             except Exception as e:\n-               smbServer.log(\"queryPathInformation: %s\" % e,logging.ERROR)\n+                smbServer.log(\"queryPathInformation: %s\" % e, logging.ERROR)\n \n             if infoRecord is not None:\n                 respParameters = smb.SMBQueryPathInformationResponse_Parameters()\n                 respData = infoRecord\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n-           \n+\n         smbServer.setConnectionData(connId, connData)\n \n         return respSetup, respParameters, respData, errorCode\n \n     @staticmethod\n-    def queryFsInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):\n+    def queryFsInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):\n         connData = smbServer.getConnectionData(connId)\n         errorCode = 0\n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             data = queryFsInformation(connData['ConnectedShares'][recvPacket['Tid']]['path'], '',\n-                                      struct.unpack('<H',parameters)[0], pktFlags = recvPacket['Flags2'])\n+                                      struct.unpack('<H', parameters)[0], pktFlags=recvPacket['Flags2'])\n \n         smbServer.setConnectionData(connId, connData)\n \n-        return b'',b'', data, errorCode\n+        return b'', b'', data, errorCode\n \n     @staticmethod\n     def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):\n@@ -820,7 +848,7 @@ def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):\n         respParameters = b''\n         respData = b''\n         errorCode = STATUS_SUCCESS\n-        findNext2Parameters = smb.SMBFindNext2_Parameters(flags = recvPacket['Flags2'], data = parameters)\n+        findNext2Parameters = smb.SMBFindNext2_Parameters(flags=recvPacket['Flags2'], data=parameters)\n \n         sid = findNext2Parameters['SID']\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n@@ -833,28 +861,28 @@ def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):\n                 for i in enumerate(searchResult):\n                     data = i[1].getData()\n                     lenData = len(data)\n-                    if (totalData+lenData) >= maxDataCount or (i[0]+1) >= findNext2Parameters['SearchCount']:\n+                    if (totalData + lenData) >= maxDataCount or (i[0] + 1) >= findNext2Parameters['SearchCount']:\n                         # We gotta stop here and continue on a find_next2\n                         endOfSearch = 0\n                         connData['SIDs'][sid] = searchResult[i[0]:]\n                         respParameters['LastNameOffset'] = totalData\n                         break\n                     else:\n-                        searchCount +=1\n+                        searchCount += 1\n                         respData += data\n                         totalData += lenData\n-                    \n+\n                 # Have we reached the end of the search or still stuff to send?\n                 if endOfSearch > 0:\n                     # Let's remove the SID from our ConnData\n-                    del(connData['SIDs'][sid])\n+                    del (connData['SIDs'][sid])\n \n                 respParameters['EndOfSearch'] = endOfSearch\n                 respParameters['SearchCount'] = searchCount\n-            else: \n+            else:\n                 errorCode = STATUS_INVALID_HANDLE\n         else:\n-            errorCode = STATUS_SMB_BAD_TID   \n+            errorCode = STATUS_SMB_BAD_TID\n \n         smbServer.setConnectionData(connId, connData)\n \n@@ -867,55 +895,58 @@ def findFirst2(connId, smbServer, recvPacket, parameters, data, maxDataCount):\n         respSetup = b''\n         respParameters = b''\n         respData = b''\n-        findFirst2Parameters = smb.SMBFindFirst2_Parameters( recvPacket['Flags2'], data = parameters)\n+        findFirst2Parameters = smb.SMBFindFirst2_Parameters(recvPacket['Flags2'], data=parameters)\n \n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n \n-            searchResult, searchCount, errorCode = findFirst2(path, \n-                          decodeSMBString( recvPacket['Flags2'], findFirst2Parameters['FileName'] ), \n-                          findFirst2Parameters['InformationLevel'], \n-                          findFirst2Parameters['SearchAttributes'] , pktFlags = recvPacket['Flags2'])\n+            searchResult, searchCount, errorCode = findFirst2(path,\n+                                                              decodeSMBString(recvPacket['Flags2'],\n+                                                                              findFirst2Parameters['FileName']),\n+                                                              findFirst2Parameters['InformationLevel'],\n+                                                              findFirst2Parameters['SearchAttributes'],\n+                                                              pktFlags=recvPacket['Flags2'])\n \n             respParameters = smb.SMBFindFirst2Response_Parameters()\n             endOfSearch = 1\n-            sid = 0x80 # default SID\n+            sid = 0x80  # default SID\n             searchCount = 0\n             totalData = 0\n             for i in enumerate(searchResult):\n-                #i[1].dump()\n+                # i[1].dump()\n                 data = i[1].getData()\n                 lenData = len(data)\n-                if (totalData+lenData) >= maxDataCount or (i[0]+1) > findFirst2Parameters['SearchCount']:\n+                if (totalData + lenData) >= maxDataCount or (i[0] + 1) > findFirst2Parameters['SearchCount']:\n                     # We gotta stop here and continue on a find_next2\n                     endOfSearch = 0\n                     # Simple way to generate a fid\n                     if len(connData['SIDs']) == 0:\n-                       sid = 1\n+                        sid = 1\n                     else:\n-                       sid = list(connData['SIDs'].keys())[-1] + 1\n+                        sid = list(connData['SIDs'].keys())[-1] + 1\n                     # Store the remaining search results in the ConnData SID\n                     connData['SIDs'][sid] = searchResult[i[0]:]\n                     respParameters['LastNameOffset'] = totalData\n                     break\n                 else:\n-                    searchCount +=1\n+                    searchCount += 1\n                     respData += data\n \n-                    padLen = (8-(lenData % 8)) %8\n-                    respData += b'\\xaa'*padLen\n+                    padLen = (8 - (lenData % 8)) % 8\n+                    respData += b'\\xaa' * padLen\n                     totalData += lenData + padLen\n \n             respParameters['SID'] = sid\n             respParameters['EndOfSearch'] = endOfSearch\n             respParameters['SearchCount'] = searchCount\n         else:\n-            errorCode = STATUS_SMB_BAD_TID   \n+            errorCode = STATUS_SMB_BAD_TID\n \n         smbServer.setConnectionData(connId, connData)\n \n         return respSetup, respParameters, respData, errorCode\n \n+\n # Here we implement the commands handlers\n class SMBCommands:\n \n@@ -925,16 +956,16 @@ def smbTransaction(connId, smbServer, SMBCommand, recvPacket, transCommands):\n \n         respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n \n-        transParameters= smb.SMBTransaction_Parameters(SMBCommand['Parameters'])\n+        transParameters = smb.SMBTransaction_Parameters(SMBCommand['Parameters'])\n \n         # Do the stuff\n         if transParameters['ParameterCount'] != transParameters['TotalParameterCount']:\n-            # TODO: Handle partial parameters \n+            # TODO: Handle partial parameters\n             raise Exception(\"Unsupported partial parameters in TRANSACT2!\")\n         else:\n-            transData = smb.SMBTransaction_SData(flags = recvPacket['Flags2'])\n-            # Standard says servers shouldn't trust Parameters and Data comes \n-            # in order, so we have to parse the offsets, ugly   \n+            transData = smb.SMBTransaction_SData(flags=recvPacket['Flags2'])\n+            # Standard says servers shouldn't trust Parameters and Data comes\n+            # in order, so we have to parse the offsets, ugly\n \n             paramCount = transParameters['ParameterCount']\n             transData['Trans_ParametersLength'] = paramCount\n@@ -943,142 +974,141 @@ def smbTransaction(connId, smbServer, SMBCommand, recvPacket, transCommands):\n             transData.fromString(SMBCommand['Data'])\n             if transParameters['ParameterOffset'] > 0:\n                 paramOffset = transParameters['ParameterOffset'] - 63 - transParameters['SetupLength']\n-                transData['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]\n+                transData['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]\n             else:\n                 transData['Trans_Parameters'] = b''\n \n             if transParameters['DataOffset'] > 0:\n                 dataOffset = transParameters['DataOffset'] - 63 - transParameters['SetupLength']\n                 transData['Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]\n-            else: \n+            else:\n                 transData['Trans_Data'] = b''\n-            \n+\n             # Call the handler for this TRANSACTION\n             if transParameters['SetupCount'] == 0:\n                 # No subcommand, let's play with the Name\n-                command = decodeSMBString(recvPacket['Flags2'],transData['Name'])\n+                command = decodeSMBString(recvPacket['Flags2'], transData['Name'])\n             else:\n                 command = struct.unpack('<H', transParameters['Setup'][:2])[0]\n-            \n+\n             if command in transCommands:\n-               # Call the TRANS subcommand\n-               setup = b''\n-               parameters = b''\n-               data = b''\n-               try: \n-                   setup, parameters, data, errorCode = transCommands[command](connId,\n-                                smbServer, \n-                                recvPacket, \n-                                transData['Trans_Parameters'], \n-                                transData['Trans_Data'],\n-                                transParameters['MaxDataCount'])\n-               except Exception as e:\n-                   #print 'Transaction: %s' % e,e\n-                   smbServer.log('Transaction: (%r,%s)' % (command, e), logging.ERROR)\n-                   errorCode = STATUS_ACCESS_DENIED\n-                   #raise\n-\n-               if setup == b'' and parameters == b'' and data == b'':\n-                   # Something wen't wrong\n-                   respParameters = b''\n-                   respData = b''\n-               else:\n-                   # Build the answer\n-                   if hasattr(data, 'getData'):\n-                       data = data.getData()\n-                   remainingData = len(data)\n-                   if hasattr(parameters, 'getData'):\n-                       parameters = parameters.getData()\n-                   remainingParameters = len(parameters)\n-                   commands = []\n-                   dataDisplacement = 0\n-                   while remainingData > 0 or remainingParameters > 0: \n-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n-                       respParameters = smb.SMBTransactionResponse_Parameters()\n-                       respData       = smb.SMBTransaction2Response_Data()\n-\n-                       respParameters['TotalParameterCount'] = len(parameters)\n-                       respParameters['ParameterCount']      = len(parameters)\n-                       respData['Trans_ParametersLength']    = len(parameters)\n-                       respParameters['TotalDataCount']      = len(data)\n-                       respParameters['DataDisplacement']    = dataDisplacement\n-\n-                       # TODO: Do the same for parameters\n-                       if len(data) >  transParameters['MaxDataCount']:\n-                           # Answer doesn't fit in this packet\n-                           LOG.debug(\"Lowering answer from %d to %d\" % (len(data),transParameters['MaxDataCount']) )\n-                           respParameters['DataCount'] = transParameters['MaxDataCount']\n-                       else:\n-                           respParameters['DataCount'] = len(data)\n-\n-                       respData['Trans_DataLength']          = respParameters['DataCount']\n-                       respParameters['SetupCount']          = len(setup)\n-                       respParameters['Setup']               = setup\n-                       # TODO: Make sure we're calculating the pad right\n-                       if len(parameters) > 0:\n-                           #padLen = 4 - (55 + len(setup)) % 4 \n-                           padLen = (4 - (55 + len(setup)) % 4 ) % 4\n-                           padBytes = b'\\xFF' * padLen\n-                           respData['Pad1'] = padBytes\n-                           respParameters['ParameterOffset'] = 55 + len(setup) + padLen \n-                       else:\n-                           padLen = 0\n-                           respParameters['ParameterOffset'] = 0\n-                           respData['Pad1']                  = b''\n-\n-                       if len(data) > 0:\n-                           #pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4\n-                           pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4\n-                           respData['Pad2'] = b'\\xFF' * pad2Len\n-                           respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len\n-                       else:\n-                           respParameters['DataOffset'] = 0\n-                           respData['Pad2']             = b''\n-\n-                       respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n-                       respData['Trans_Data']       = data[:respParameters['DataCount']] \n-                       respSMBCommand['Parameters'] = respParameters\n-                       respSMBCommand['Data']       = respData \n-\n-                       data = data[respParameters['DataCount']:]\n-                       remainingData -= respParameters['DataCount']\n-                       dataDisplacement += respParameters['DataCount'] + 1\n-\n-                       parameters = parameters[respParameters['ParameterCount']:]\n-                       remainingParameters -= respParameters['ParameterCount']\n-                       commands.append(respSMBCommand)\n-\n-                   smbServer.setConnectionData(connId, connData)\n-                   return commands, None, errorCode\n+                # Call the TRANS subcommand\n+                setup = b''\n+                parameters = b''\n+                data = b''\n+                try:\n+                    setup, parameters, data, errorCode = transCommands[command](connId,\n+                                                                                smbServer,\n+                                                                                recvPacket,\n+                                                                                transData['Trans_Parameters'],\n+                                                                                transData['Trans_Data'],\n+                                                                                transParameters['MaxDataCount'])\n+                except Exception as e:\n+                    # print 'Transaction: %s' % e,e\n+                    smbServer.log('Transaction: (%r,%s)' % (command, e), logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n+                    # raise\n+\n+                if setup == b'' and parameters == b'' and data == b'':\n+                    # Something wen't wrong\n+                    respParameters = b''\n+                    respData = b''\n+                else:\n+                    # Build the answer\n+                    if hasattr(data, 'getData'):\n+                        data = data.getData()\n+                    remainingData = len(data)\n+                    if hasattr(parameters, 'getData'):\n+                        parameters = parameters.getData()\n+                    remainingParameters = len(parameters)\n+                    commands = []\n+                    dataDisplacement = 0\n+                    while remainingData > 0 or remainingParameters > 0:\n+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n+                        respParameters = smb.SMBTransactionResponse_Parameters()\n+                        respData = smb.SMBTransaction2Response_Data()\n+\n+                        respParameters['TotalParameterCount'] = len(parameters)\n+                        respParameters['ParameterCount'] = len(parameters)\n+                        respData['Trans_ParametersLength'] = len(parameters)\n+                        respParameters['TotalDataCount'] = len(data)\n+                        respParameters['DataDisplacement'] = dataDisplacement\n+\n+                        # TODO: Do the same for parameters\n+                        if len(data) > transParameters['MaxDataCount']:\n+                            # Answer doesn't fit in this packet\n+                            LOG.debug(\"Lowering answer from %d to %d\" % (len(data), transParameters['MaxDataCount']))\n+                            respParameters['DataCount'] = transParameters['MaxDataCount']\n+                        else:\n+                            respParameters['DataCount'] = len(data)\n+\n+                        respData['Trans_DataLength'] = respParameters['DataCount']\n+                        respParameters['SetupCount'] = len(setup)\n+                        respParameters['Setup'] = setup\n+                        # TODO: Make sure we're calculating the pad right\n+                        if len(parameters) > 0:\n+                            # padLen = 4 - (55 + len(setup)) % 4\n+                            padLen = (4 - (55 + len(setup)) % 4) % 4\n+                            padBytes = b'\\xFF' * padLen\n+                            respData['Pad1'] = padBytes\n+                            respParameters['ParameterOffset'] = 55 + len(setup) + padLen\n+                        else:\n+                            padLen = 0\n+                            respParameters['ParameterOffset'] = 0\n+                            respData['Pad1'] = b''\n+\n+                        if len(data) > 0:\n+                            # pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4\n+                            pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4\n+                            respData['Pad2'] = b'\\xFF' * pad2Len\n+                            respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len\n+                        else:\n+                            respParameters['DataOffset'] = 0\n+                            respData['Pad2'] = b''\n+\n+                        respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n+                        respData['Trans_Data'] = data[:respParameters['DataCount']]\n+                        respSMBCommand['Parameters'] = respParameters\n+                        respSMBCommand['Data'] = respData\n+\n+                        data = data[respParameters['DataCount']:]\n+                        remainingData -= respParameters['DataCount']\n+                        dataDisplacement += respParameters['DataCount'] + 1\n+\n+                        parameters = parameters[respParameters['ParameterCount']:]\n+                        remainingParameters -= respParameters['ParameterCount']\n+                        commands.append(respSMBCommand)\n+\n+                    smbServer.setConnectionData(connId, connData)\n+                    return commands, None, errorCode\n \n             else:\n-               smbServer.log(\"Unsupported Transact command %r\" % command, logging.ERROR)\n-               respParameters = b''\n-               respData = b''\n-               errorCode = STATUS_NOT_IMPLEMENTED\n+                smbServer.log(\"Unsupported Transact command %r\" % command, logging.ERROR)\n+                respParameters = b''\n+                respData = b''\n+                errorCode = STATUS_NOT_IMPLEMENTED\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smbNTTransact(connId, smbServer, SMBCommand, recvPacket, transCommands):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n \n-        NTTransParameters= smb.SMBNTTransaction_Parameters(SMBCommand['Parameters'])\n+        NTTransParameters = smb.SMBNTTransaction_Parameters(SMBCommand['Parameters'])\n         # Do the stuff\n         if NTTransParameters['ParameterCount'] != NTTransParameters['TotalParameterCount']:\n-            # TODO: Handle partial parameters \n+            # TODO: Handle partial parameters\n             raise Exception(\"Unsupported partial parameters in NTTrans!\")\n         else:\n             NTTransData = smb.SMBNTTransaction_Data()\n-            # Standard says servers shouldn't trust Parameters and Data comes \n-            # in order, so we have to parse the offsets, ugly   \n+            # Standard says servers shouldn't trust Parameters and Data comes\n+            # in order, so we have to parse the offsets, ugly\n \n             paramCount = NTTransParameters['ParameterCount']\n             NTTransData['NT_Trans_ParametersLength'] = paramCount\n@@ -1087,139 +1117,138 @@ def smbNTTransact(connId, smbServer, SMBCommand, recvPacket, transCommands):\n \n             if NTTransParameters['ParameterOffset'] > 0:\n                 paramOffset = NTTransParameters['ParameterOffset'] - 73 - NTTransParameters['SetupLength']\n-                NTTransData['NT_Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]\n+                NTTransData['NT_Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]\n             else:\n                 NTTransData['NT_Trans_Parameters'] = b''\n \n             if NTTransParameters['DataOffset'] > 0:\n                 dataOffset = NTTransParameters['DataOffset'] - 73 - NTTransParameters['SetupLength']\n                 NTTransData['NT_Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]\n-            else: \n+            else:\n                 NTTransData['NT_Trans_Data'] = b''\n \n             # Call the handler for this TRANSACTION\n             command = NTTransParameters['Function']\n             if command in transCommands:\n-               # Call the NT TRANS subcommand\n-               setup = b''\n-               parameters = b''\n-               data = b''\n-               try: \n-                   setup, parameters, data, errorCode = transCommands[command](connId,\n-                                smbServer, \n-                                recvPacket, \n-                                NTTransData['NT_Trans_Parameters'], \n-                                NTTransData['NT_Trans_Data'],\n-                                NTTransParameters['MaxDataCount'])\n-               except Exception as e:\n-                   smbServer.log('NTTransaction: (0x%x,%s)' % (command, e), logging.ERROR)\n-                   errorCode = STATUS_ACCESS_DENIED\n-                   #raise\n-\n-               if setup == b'' and parameters == b'' and data == b'':\n-                   # Something wen't wrong\n-                   respParameters = b''\n-                   respData = b''\n-                   if errorCode == STATUS_SUCCESS:\n-                       errorCode = STATUS_ACCESS_DENIED \n-               else:\n-                   # Build the answer\n-                   if hasattr(data, 'getData'):\n-                       data = data.getData()\n-                   remainingData = len(data)\n-                   if hasattr(parameters, 'getData'):\n-                       parameters = parameters.getData()\n-                   remainingParameters = len(parameters)\n-                   commands = []\n-                   dataDisplacement = 0\n-                   while remainingData > 0 or remainingParameters > 0: \n-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n-                       respParameters = smb.SMBNTTransactionResponse_Parameters()\n-                       respData       = smb.SMBNTTransactionResponse_Data()\n-\n-                       respParameters['TotalParameterCount'] = len(parameters)\n-                       respParameters['ParameterCount']      = len(parameters)\n-                       respData['Trans_ParametersLength']    = len(parameters)\n-                       respParameters['TotalDataCount']      = len(data)\n-                       respParameters['DataDisplacement']    = dataDisplacement\n-                       # TODO: Do the same for parameters\n-                       if len(data) >  NTTransParameters['MaxDataCount']:\n-                           # Answer doesn't fit in this packet\n-                           LOG.debug(\"Lowering answer from %d to %d\" % (len(data),NTTransParameters['MaxDataCount']) )\n-                           respParameters['DataCount'] = NTTransParameters['MaxDataCount']\n-                       else:\n-                           respParameters['DataCount'] = len(data)\n-\n-                       respData['NT_Trans_DataLength']          = respParameters['DataCount']\n-                       respParameters['SetupCount']          = len(setup)\n-                       respParameters['Setup']               = setup\n-                       # TODO: Make sure we're calculating the pad right\n-                       if len(parameters) > 0:\n-                           #padLen = 4 - (71 + len(setup)) % 4 \n-                           padLen = (4 - (73 + len(setup)) % 4 ) % 4\n-                           padBytes = b'\\xFF' * padLen\n-                           respData['Pad1'] = padBytes\n-                           respParameters['ParameterOffset'] = 73 + len(setup) + padLen \n-                       else:\n-                           padLen = 0\n-                           respParameters['ParameterOffset'] = 0\n-                           respData['Pad1']                  = b''\n-\n-                       if len(data) > 0:\n-                           #pad2Len = 4 - (71 + len(setup) + padLen + len(parameters)) % 4\n-                           pad2Len = (4 - (73 + len(setup) + padLen + len(parameters)) % 4) % 4\n-                           respData['Pad2'] = b'\\xFF' * pad2Len\n-                           respParameters['DataOffset'] = 73 + len(setup) + padLen + len(parameters) + pad2Len\n-                       else:\n-                           respParameters['DataOffset'] = 0\n-                           respData['Pad2']             = b''\n-\n-                       respData['NT_Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n-                       respData['NT_Trans_Data']       = data[:respParameters['DataCount']] \n-                       respSMBCommand['Parameters'] = respParameters\n-                       respSMBCommand['Data']       = respData \n-\n-                       data = data[respParameters['DataCount']:]\n-                       remainingData -= respParameters['DataCount']\n-                       dataDisplacement += respParameters['DataCount'] + 1\n-\n-                       parameters = parameters[respParameters['ParameterCount']:]\n-                       remainingParameters -= respParameters['ParameterCount']\n-                       commands.append(respSMBCommand)\n-\n-                   smbServer.setConnectionData(connId, connData)\n-                   return commands, None, errorCode\n+                # Call the NT TRANS subcommand\n+                setup = b''\n+                parameters = b''\n+                data = b''\n+                try:\n+                    setup, parameters, data, errorCode = transCommands[command](connId,\n+                                                                                smbServer,\n+                                                                                recvPacket,\n+                                                                                NTTransData['NT_Trans_Parameters'],\n+                                                                                NTTransData['NT_Trans_Data'],\n+                                                                                NTTransParameters['MaxDataCount'])\n+                except Exception as e:\n+                    smbServer.log('NTTransaction: (0x%x,%s)' % (command, e), logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n+                    # raise\n+\n+                if setup == b'' and parameters == b'' and data == b'':\n+                    # Something wen't wrong\n+                    respParameters = b''\n+                    respData = b''\n+                    if errorCode == STATUS_SUCCESS:\n+                        errorCode = STATUS_ACCESS_DENIED\n+                else:\n+                    # Build the answer\n+                    if hasattr(data, 'getData'):\n+                        data = data.getData()\n+                    remainingData = len(data)\n+                    if hasattr(parameters, 'getData'):\n+                        parameters = parameters.getData()\n+                    remainingParameters = len(parameters)\n+                    commands = []\n+                    dataDisplacement = 0\n+                    while remainingData > 0 or remainingParameters > 0:\n+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n+                        respParameters = smb.SMBNTTransactionResponse_Parameters()\n+                        respData = smb.SMBNTTransactionResponse_Data()\n+\n+                        respParameters['TotalParameterCount'] = len(parameters)\n+                        respParameters['ParameterCount'] = len(parameters)\n+                        respData['Trans_ParametersLength'] = len(parameters)\n+                        respParameters['TotalDataCount'] = len(data)\n+                        respParameters['DataDisplacement'] = dataDisplacement\n+                        # TODO: Do the same for parameters\n+                        if len(data) > NTTransParameters['MaxDataCount']:\n+                            # Answer doesn't fit in this packet\n+                            LOG.debug(\"Lowering answer from %d to %d\" % (len(data), NTTransParameters['MaxDataCount']))\n+                            respParameters['DataCount'] = NTTransParameters['MaxDataCount']\n+                        else:\n+                            respParameters['DataCount'] = len(data)\n+\n+                        respData['NT_Trans_DataLength'] = respParameters['DataCount']\n+                        respParameters['SetupCount'] = len(setup)\n+                        respParameters['Setup'] = setup\n+                        # TODO: Make sure we're calculating the pad right\n+                        if len(parameters) > 0:\n+                            # padLen = 4 - (71 + len(setup)) % 4\n+                            padLen = (4 - (73 + len(setup)) % 4) % 4\n+                            padBytes = b'\\xFF' * padLen\n+                            respData['Pad1'] = padBytes\n+                            respParameters['ParameterOffset'] = 73 + len(setup) + padLen\n+                        else:\n+                            padLen = 0\n+                            respParameters['ParameterOffset'] = 0\n+                            respData['Pad1'] = b''\n+\n+                        if len(data) > 0:\n+                            # pad2Len = 4 - (71 + len(setup) + padLen + len(parameters)) % 4\n+                            pad2Len = (4 - (73 + len(setup) + padLen + len(parameters)) % 4) % 4\n+                            respData['Pad2'] = b'\\xFF' * pad2Len\n+                            respParameters['DataOffset'] = 73 + len(setup) + padLen + len(parameters) + pad2Len\n+                        else:\n+                            respParameters['DataOffset'] = 0\n+                            respData['Pad2'] = b''\n+\n+                        respData['NT_Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n+                        respData['NT_Trans_Data'] = data[:respParameters['DataCount']]\n+                        respSMBCommand['Parameters'] = respParameters\n+                        respSMBCommand['Data'] = respData\n+\n+                        data = data[respParameters['DataCount']:]\n+                        remainingData -= respParameters['DataCount']\n+                        dataDisplacement += respParameters['DataCount'] + 1\n+\n+                        parameters = parameters[respParameters['ParameterCount']:]\n+                        remainingParameters -= respParameters['ParameterCount']\n+                        commands.append(respSMBCommand)\n+\n+                    smbServer.setConnectionData(connId, connData)\n+                    return commands, None, errorCode\n \n             else:\n-               #smbServer.log(\"Unsupported NTTransact command 0x%x\" % command, logging.ERROR)\n-               respParameters = b''\n-               respData = b''\n-               errorCode = STATUS_NOT_IMPLEMENTED\n+                # smbServer.log(\"Unsupported NTTransact command 0x%x\" % command, logging.ERROR)\n+                respParameters = b''\n+                respData = b''\n+                errorCode = STATUS_NOT_IMPLEMENTED\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n \n-        trans2Parameters= smb.SMBTransaction2_Parameters(SMBCommand['Parameters'])\n+        trans2Parameters = smb.SMBTransaction2_Parameters(SMBCommand['Parameters'])\n \n         # Do the stuff\n         if trans2Parameters['ParameterCount'] != trans2Parameters['TotalParameterCount']:\n-            # TODO: Handle partial parameters \n-            #print \"Unsupported partial parameters in TRANSACT2!\"\n+            # TODO: Handle partial parameters\n+            # print \"Unsupported partial parameters in TRANSACT2!\"\n             raise Exception(\"Unsupported partial parameters in TRANSACT2!\")\n         else:\n             trans2Data = smb.SMBTransaction2_Data()\n-            # Standard says servers shouldn't trust Parameters and Data comes \n-            # in order, so we have to parse the offsets, ugly   \n+            # Standard says servers shouldn't trust Parameters and Data comes\n+            # in order, so we have to parse the offsets, ugly\n \n             paramCount = trans2Parameters['ParameterCount']\n             trans2Data['Trans_ParametersLength'] = paramCount\n@@ -1228,113 +1257,113 @@ def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):\n \n             if trans2Parameters['ParameterOffset'] > 0:\n                 paramOffset = trans2Parameters['ParameterOffset'] - 63 - trans2Parameters['SetupLength']\n-                trans2Data['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]\n+                trans2Data['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]\n             else:\n                 trans2Data['Trans_Parameters'] = b''\n \n             if trans2Parameters['DataOffset'] > 0:\n                 dataOffset = trans2Parameters['DataOffset'] - 63 - trans2Parameters['SetupLength']\n                 trans2Data['Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]\n-            else: \n+            else:\n                 trans2Data['Trans_Data'] = b''\n \n             # Call the handler for this TRANSACTION\n             command = struct.unpack('<H', trans2Parameters['Setup'])[0]\n             if command in transCommands:\n-               # Call the TRANS2 subcommand\n-               try:\n-                   setup, parameters, data, errorCode = transCommands[command](connId,\n-                                smbServer, \n-                                recvPacket, \n-                                trans2Data['Trans_Parameters'], \n-                                trans2Data['Trans_Data'],\n-                                trans2Parameters['MaxDataCount'])\n-               except Exception as e:\n-                   smbServer.log('Transaction2: (0x%x,%s)' % (command, e), logging.ERROR)\n-                   #import traceback\n-                   #traceback.print_exc()\n-                   raise\n-\n-               if setup == b'' and parameters == b'' and data == b'':\n-                   # Something wen't wrong\n-                   respParameters = b''\n-                   respData = b''\n-               else:\n-                   # Build the answer\n-                   if hasattr(data, 'getData'):\n-                       data = data.getData()\n-                   remainingData = len(data)\n-                   if hasattr(parameters, 'getData'):\n-                       parameters = parameters.getData()\n-                   remainingParameters = len(parameters)\n-                   commands = []\n-                   dataDisplacement = 0\n-                   while remainingData > 0 or remainingParameters > 0: \n-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n-                       respParameters = smb.SMBTransaction2Response_Parameters()\n-                       respData       = smb.SMBTransaction2Response_Data()\n-\n-                       respParameters['TotalParameterCount'] = len(parameters)\n-                       respParameters['ParameterCount']      = len(parameters)\n-                       respData['Trans_ParametersLength']    = len(parameters)\n-                       respParameters['TotalDataCount']      = len(data)\n-                       respParameters['DataDisplacement']    = dataDisplacement\n-                       # TODO: Do the same for parameters\n-                       if len(data) >  trans2Parameters['MaxDataCount']:\n-                           # Answer doesn't fit in this packet\n-                           LOG.debug(\"Lowering answer from %d to %d\" % (len(data),trans2Parameters['MaxDataCount']) )\n-                           respParameters['DataCount'] = trans2Parameters['MaxDataCount']\n-                       else:\n-                           respParameters['DataCount'] = len(data)\n-\n-                       respData['Trans_DataLength']          = respParameters['DataCount']\n-                       respParameters['SetupCount']          = len(setup)\n-                       respParameters['Setup']               = setup\n-                       # TODO: Make sure we're calculating the pad right\n-                       if len(parameters) > 0:\n-                           #padLen = 4 - (55 + len(setup)) % 4 \n-                           padLen = (4 - (55 + len(setup)) % 4 ) % 4\n-                           padBytes = b'\\xFF' * padLen\n-                           respData['Pad1'] = padBytes\n-                           respParameters['ParameterOffset'] = 55 + len(setup) + padLen \n-                       else:\n-                           padLen = 0\n-                           respParameters['ParameterOffset'] = 0\n-                           respData['Pad1']                  = b''\n-\n-                       if len(data) > 0:\n-                           #pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4\n-                           pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4\n-                           respData['Pad2'] = b'\\xFF' * pad2Len\n-                           respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len\n-                       else:\n-                           respParameters['DataOffset'] = 0\n-                           respData['Pad2']             = b''\n-\n-                       respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n-                       respData['Trans_Data']       = data[:respParameters['DataCount']] \n-                       respSMBCommand['Parameters'] = respParameters\n-                       respSMBCommand['Data']       = respData \n-\n-                       data = data[respParameters['DataCount']:]\n-                       remainingData -= respParameters['DataCount']\n-                       dataDisplacement += respParameters['DataCount'] + 1\n-\n-                       parameters = parameters[respParameters['ParameterCount']:]\n-                       remainingParameters -= respParameters['ParameterCount']\n-                       commands.append(respSMBCommand)\n-\n-                   smbServer.setConnectionData(connId, connData)\n-                   return commands, None, errorCode\n+                # Call the TRANS2 subcommand\n+                try:\n+                    setup, parameters, data, errorCode = transCommands[command](connId,\n+                                                                                smbServer,\n+                                                                                recvPacket,\n+                                                                                trans2Data['Trans_Parameters'],\n+                                                                                trans2Data['Trans_Data'],\n+                                                                                trans2Parameters['MaxDataCount'])\n+                except Exception as e:\n+                    smbServer.log('Transaction2: (0x%x,%s)' % (command, e), logging.ERROR)\n+                    # import traceback\n+                    # traceback.print_exc()\n+                    raise\n+\n+                if setup == b'' and parameters == b'' and data == b'':\n+                    # Something wen't wrong\n+                    respParameters = b''\n+                    respData = b''\n+                else:\n+                    # Build the answer\n+                    if hasattr(data, 'getData'):\n+                        data = data.getData()\n+                    remainingData = len(data)\n+                    if hasattr(parameters, 'getData'):\n+                        parameters = parameters.getData()\n+                    remainingParameters = len(parameters)\n+                    commands = []\n+                    dataDisplacement = 0\n+                    while remainingData > 0 or remainingParameters > 0:\n+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])\n+                        respParameters = smb.SMBTransaction2Response_Parameters()\n+                        respData = smb.SMBTransaction2Response_Data()\n+\n+                        respParameters['TotalParameterCount'] = len(parameters)\n+                        respParameters['ParameterCount'] = len(parameters)\n+                        respData['Trans_ParametersLength'] = len(parameters)\n+                        respParameters['TotalDataCount'] = len(data)\n+                        respParameters['DataDisplacement'] = dataDisplacement\n+                        # TODO: Do the same for parameters\n+                        if len(data) > trans2Parameters['MaxDataCount']:\n+                            # Answer doesn't fit in this packet\n+                            LOG.debug(\"Lowering answer from %d to %d\" % (len(data), trans2Parameters['MaxDataCount']))\n+                            respParameters['DataCount'] = trans2Parameters['MaxDataCount']\n+                        else:\n+                            respParameters['DataCount'] = len(data)\n+\n+                        respData['Trans_DataLength'] = respParameters['DataCount']\n+                        respParameters['SetupCount'] = len(setup)\n+                        respParameters['Setup'] = setup\n+                        # TODO: Make sure we're calculating the pad right\n+                        if len(parameters) > 0:\n+                            # padLen = 4 - (55 + len(setup)) % 4\n+                            padLen = (4 - (55 + len(setup)) % 4) % 4\n+                            padBytes = b'\\xFF' * padLen\n+                            respData['Pad1'] = padBytes\n+                            respParameters['ParameterOffset'] = 55 + len(setup) + padLen\n+                        else:\n+                            padLen = 0\n+                            respParameters['ParameterOffset'] = 0\n+                            respData['Pad1'] = b''\n+\n+                        if len(data) > 0:\n+                            # pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4\n+                            pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4\n+                            respData['Pad2'] = b'\\xFF' * pad2Len\n+                            respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len\n+                        else:\n+                            respParameters['DataOffset'] = 0\n+                            respData['Pad2'] = b''\n+\n+                        respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]\n+                        respData['Trans_Data'] = data[:respParameters['DataCount']]\n+                        respSMBCommand['Parameters'] = respParameters\n+                        respSMBCommand['Data'] = respData\n+\n+                        data = data[respParameters['DataCount']:]\n+                        remainingData -= respParameters['DataCount']\n+                        dataDisplacement += respParameters['DataCount'] + 1\n+\n+                        parameters = parameters[respParameters['ParameterCount']:]\n+                        remainingParameters -= respParameters['ParameterCount']\n+                        commands.append(respSMBCommand)\n+\n+                    smbServer.setConnectionData(connId, connData)\n+                    return commands, None, errorCode\n \n             else:\n-               smbServer.log(\"Unsupported Transact\/2 command 0x%x\" % command, logging.ERROR)\n-               respParameters = b''\n-               respData = b''\n-               errorCode = STATUS_NOT_IMPLEMENTED\n+                smbServer.log(\"Unsupported Transact\/2 command 0x%x\" % command, logging.ERROR)\n+                respParameters = b''\n+                respData = b''\n+                errorCode = STATUS_NOT_IMPLEMENTED\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n@@ -1343,59 +1372,58 @@ def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):\n     def smbComLockingAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_LOCKING_ANDX)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_LOCKING_ANDX)\n+        respParameters = b''\n+        respData = b''\n \n         # I'm actually doing nothing.. just make MacOS happy ;)\n         errorCode = STATUS_SUCCESS\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smbComClose(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_CLOSE)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_CLOSE)\n+        respParameters = b''\n+        respData = b''\n \n-        comClose =  smb.SMBClose_Parameters(SMBCommand['Parameters'])\n+        comClose = smb.SMBClose_Parameters(SMBCommand['Parameters'])\n \n         if comClose['FID'] in connData['OpenedFiles']:\n-             errorCode = STATUS_SUCCESS\n-             fileHandle = connData['OpenedFiles'][comClose['FID']]['FileHandle']\n-             try:\n-                 if fileHandle == PIPE_FILE_DESCRIPTOR:\n-                     connData['OpenedFiles'][comClose['FID']]['Socket'].close()\n-                 elif fileHandle != VOID_FILE_DESCRIPTOR:\n-                     os.close(fileHandle)\n-             except Exception as e:\n-                 smbServer.log(\"comClose %s\" % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n-             else:\n-                 # Check if the file was marked for removal\n-                 if connData['OpenedFiles'][comClose['FID']]['DeleteOnClose'] is True:\n-                     try:\n-                         os.remove(connData['OpenedFiles'][comClose['FID']]['FileName'])\n-                     except Exception as e:\n-                         smbServer.log(\"comClose %s\" % e, logging.ERROR)\n-                         errorCode = STATUS_ACCESS_DENIED\n-                 del(connData['OpenedFiles'][comClose['FID']])\n+            errorCode = STATUS_SUCCESS\n+            fileHandle = connData['OpenedFiles'][comClose['FID']]['FileHandle']\n+            try:\n+                if fileHandle == PIPE_FILE_DESCRIPTOR:\n+                    connData['OpenedFiles'][comClose['FID']]['Socket'].close()\n+                elif fileHandle != VOID_FILE_DESCRIPTOR:\n+                    os.close(fileHandle)\n+            except Exception as e:\n+                smbServer.log(\"comClose %s\" % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n+            else:\n+                # Check if the file was marked for removal\n+                if connData['OpenedFiles'][comClose['FID']]['DeleteOnClose'] is True:\n+                    try:\n+                        os.remove(connData['OpenedFiles'][comClose['FID']]['FileName'])\n+                    except Exception as e:\n+                        smbServer.log(\"comClose %s\" % e, logging.ERROR)\n+                        errorCode = STATUS_ACCESS_DENIED\n+                del (connData['OpenedFiles'][comClose['FID']])\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1404,310 +1432,308 @@ def smbComClose(connId, smbServer, SMBCommand, recvPacket):\n     def smbComWrite(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_WRITE)\n-        respParameters        = smb.SMBWriteResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_WRITE)\n+        respParameters = smb.SMBWriteResponse_Parameters()\n+        respData = b''\n \n-        comWriteParameters =  smb.SMBWrite_Parameters(SMBCommand['Parameters'])\n+        comWriteParameters = smb.SMBWrite_Parameters(SMBCommand['Parameters'])\n         comWriteData = smb.SMBWrite_Data(SMBCommand['Data'])\n \n         if comWriteParameters['Fid'] in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][comWriteParameters['Fid']]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     # TODO: Handle big size files\n-                     # If we're trying to write past the file end we just skip the write call (Vista does this)\n-                     if os.lseek(fileHandle, 0, 2) >= comWriteParameters['Offset']: \n-                         os.lseek(fileHandle,comWriteParameters['Offset'],0)\n-                         os.write(fileHandle,comWriteData['Data'])\n-                 else:\n-                     sock = connData['OpenedFiles'][comWriteParameters['Fid']]['Socket']\n-                     sock.send(comWriteData['Data'])\n-                 respParameters['Count']    = comWriteParameters['Count']\n-             except Exception as e:\n-                 smbServer.log('smbComWrite: %s' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][comWriteParameters['Fid']]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    # TODO: Handle big size files\n+                    # If we're trying to write past the file end we just skip the write call (Vista does this)\n+                    if os.lseek(fileHandle, 0, 2) >= comWriteParameters['Offset']:\n+                        os.lseek(fileHandle, comWriteParameters['Offset'], 0)\n+                        os.write(fileHandle, comWriteData['Data'])\n+                else:\n+                    sock = connData['OpenedFiles'][comWriteParameters['Fid']]['Socket']\n+                    sock.send(comWriteData['Data'])\n+                respParameters['Count'] = comWriteParameters['Count']\n+            except Exception as e:\n+                smbServer.log('smbComWrite: %s' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n-\n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n     @staticmethod\n-    def smbComFlush(connId, smbServer, SMBCommand,recvPacket ):\n+    def smbComFlush(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_FLUSH)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_FLUSH)\n+        respParameters = b''\n+        respData = b''\n \n-        comFlush =  smb.SMBFlush_Parameters(SMBCommand['Parameters'])\n+        comFlush = smb.SMBFlush_Parameters(SMBCommand['Parameters'])\n \n         if comFlush['FID'] in connData['OpenedFiles']:\n-             errorCode = STATUS_SUCCESS\n-             fileHandle = connData['OpenedFiles'][comFlush['FID']]['FileHandle']\n-             try:\n-                 os.fsync(fileHandle)\n-             except Exception as e:\n-                 smbServer.log(\"comFlush %s\" % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            errorCode = STATUS_SUCCESS\n+            fileHandle = connData['OpenedFiles'][comFlush['FID']]['FileHandle']\n+            try:\n+                os.fsync(fileHandle)\n+            except Exception as e:\n+                smbServer.log(\"comFlush %s\" % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n-    def smbComCreateDirectory(connId, smbServer, SMBCommand,recvPacket ):\n+    def smbComCreateDirectory(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_CREATE_DIRECTORY)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_CREATE_DIRECTORY)\n+        respParameters = b''\n+        respData = b''\n \n-        comCreateDirectoryData=  smb.SMBCreateDirectory_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        comCreateDirectoryData = smb.SMBCreateDirectory_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             errorCode = STATUS_SUCCESS\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comCreateDirectoryData['DirectoryName']).replace('\\\\','\/'))\n-             if len(fileName) > 0:\n+            errorCode = STATUS_SUCCESS\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            fileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comCreateDirectoryData['DirectoryName']).replace('\\\\', '\/'))\n+            if len(fileName) > 0:\n                 if fileName[0] == '\/' or fileName[0] == '\\\\':\n                     # strip leading '\/'\n                     fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             if os.path.exists(pathName):\n+            pathName = os.path.join(path, fileName)\n+            if os.path.exists(pathName):\n                 errorCode = STATUS_OBJECT_NAME_COLLISION\n \n-             # TODO: More checks here in the future.. Specially when we support\n-             # user access\n-             else:\n-                 try:\n-                     os.mkdir(pathName)\n-                 except Exception as e:\n-                     smbServer.log(\"smbComCreateDirectory: %s\" % e, logging.ERROR)\n-                     errorCode = STATUS_ACCESS_DENIED\n+            # TODO: More checks here in the future.. Specially when we support\n+            # user access\n+            else:\n+                try:\n+                    os.mkdir(pathName)\n+                except Exception as e:\n+                    smbServer.log(\"smbComCreateDirectory: %s\" % e, logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n     @staticmethod\n-    def smbComRename(connId, smbServer, SMBCommand, recvPacket ):\n+    def smbComRename(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_RENAME)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_RENAME)\n+        respParameters = b''\n+        respData = b''\n \n-        comRenameData      =  smb.SMBRename_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        comRenameData = smb.SMBRename_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             errorCode = STATUS_SUCCESS\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             oldFileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comRenameData['OldFileName']).replace('\\\\','\/'))\n-             newFileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comRenameData['NewFileName']).replace('\\\\','\/'))\n-             if len(oldFileName) > 0 and (oldFileName[0] == '\/' or oldFileName[0] == '\\\\'):\n+            errorCode = STATUS_SUCCESS\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            oldFileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comRenameData['OldFileName']).replace('\\\\', '\/'))\n+            newFileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comRenameData['NewFileName']).replace('\\\\', '\/'))\n+            if len(oldFileName) > 0 and (oldFileName[0] == '\/' or oldFileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 oldFileName = oldFileName[1:]\n-             oldPathName = os.path.join(path,oldFileName)\n-             if len(newFileName) > 0 and (newFileName[0] == '\/' or newFileName[0] == '\\\\'):\n+            oldPathName = os.path.join(path, oldFileName)\n+            if len(newFileName) > 0 and (newFileName[0] == '\/' or newFileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 newFileName = newFileName[1:]\n-             newPathName = os.path.join(path,newFileName)\n+            newPathName = os.path.join(path, newFileName)\n \n-             if os.path.exists(oldPathName) is not True:\n+            if os.path.exists(oldPathName) is not True:\n                 errorCode = STATUS_NO_SUCH_FILE\n \n-             # TODO: More checks here in the future.. Specially when we support\n-             # user access\n-             else:\n-                 try:\n-                     os.rename(oldPathName,newPathName)\n-                 except OSError as e:\n-                     smbServer.log(\"smbComRename: %s\" % e, logging.ERROR)\n-                     errorCode = STATUS_ACCESS_DENIED\n+            # TODO: More checks here in the future.. Specially when we support\n+            # user access\n+            else:\n+                try:\n+                    os.rename(oldPathName, newPathName)\n+                except OSError as e:\n+                    smbServer.log(\"smbComRename: %s\" % e, logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n     @staticmethod\n-    def smbComDelete(connId, smbServer, SMBCommand, recvPacket ):\n+    def smbComDelete(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_DELETE)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_DELETE)\n+        respParameters = b''\n+        respData = b''\n \n-        comDeleteData         =  smb.SMBDelete_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        comDeleteData = smb.SMBDelete_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             errorCode = STATUS_SUCCESS\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comDeleteData['FileName']).replace('\\\\','\/'))\n-             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+            errorCode = STATUS_SUCCESS\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            fileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comDeleteData['FileName']).replace('\\\\', '\/'))\n+            if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             if os.path.exists(pathName) is not True:\n+            pathName = os.path.join(path, fileName)\n+            if os.path.exists(pathName) is not True:\n                 errorCode = STATUS_NO_SUCH_FILE\n \n-             # TODO: More checks here in the future.. Specially when we support\n-             # user access\n-             else:\n-                 try:\n-                     os.remove(pathName)\n-                 except OSError as e:\n-                     smbServer.log(\"smbComDelete: %s\" % e, logging.ERROR)\n-                     errorCode = STATUS_ACCESS_DENIED\n+            # TODO: More checks here in the future.. Specially when we support\n+            # user access\n+            else:\n+                try:\n+                    os.remove(pathName)\n+                except OSError as e:\n+                    smbServer.log(\"smbComDelete: %s\" % e, logging.ERROR)\n+                    errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n-    def smbComDeleteDirectory(connId, smbServer, SMBCommand, recvPacket ):\n+    def smbComDeleteDirectory(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_DELETE_DIRECTORY)\n-        respParameters        = b''\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_DELETE_DIRECTORY)\n+        respParameters = b''\n+        respData = b''\n \n-        comDeleteDirectoryData=  smb.SMBDeleteDirectory_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        comDeleteDirectoryData = smb.SMBDeleteDirectory_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             errorCode = STATUS_SUCCESS\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comDeleteDirectoryData['DirectoryName']).replace('\\\\','\/'))\n-             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+            errorCode = STATUS_SUCCESS\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            fileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], comDeleteDirectoryData['DirectoryName']).replace('\\\\', '\/'))\n+            if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             if os.path.exists(pathName) is not True:\n+            pathName = os.path.join(path, fileName)\n+            if os.path.exists(pathName) is not True:\n                 errorCode = STATUS_NO_SUCH_FILE\n \n-             # TODO: More checks here in the future.. Specially when we support\n-             # user access\n-             else:\n-                 try:\n-                     os.rmdir(pathName)\n-                 except OSError as e:\n-                     smbServer.log(\"smbComDeleteDirectory: %s\" % e,logging.ERROR)\n-                     if e.errno == errno.ENOTEMPTY:\n-                         errorCode = STATUS_DIRECTORY_NOT_EMPTY\n-                     else:\n-                         errorCode = STATUS_ACCESS_DENIED\n+            # TODO: More checks here in the future.. Specially when we support\n+            # user access\n+            else:\n+                try:\n+                    os.rmdir(pathName)\n+                except OSError as e:\n+                    smbServer.log(\"smbComDeleteDirectory: %s\" % e, logging.ERROR)\n+                    if e.errno == errno.ENOTEMPTY:\n+                        errorCode = STATUS_DIRECTORY_NOT_EMPTY\n+                    else:\n+                        errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smbComWriteAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_WRITE_ANDX)\n-        respParameters        = smb.SMBWriteAndXResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_WRITE_ANDX)\n+        respParameters = smb.SMBWriteAndXResponse_Parameters()\n+        respData = b''\n \n         if SMBCommand['WordCount'] == 0x0C:\n-            writeAndX =  smb.SMBWriteAndX_Parameters_Short(SMBCommand['Parameters'])\n+            writeAndX = smb.SMBWriteAndX_Parameters_Short(SMBCommand['Parameters'])\n             writeAndXData = smb.SMBWriteAndX_Data_Short()\n         else:\n-            writeAndX =  smb.SMBWriteAndX_Parameters(SMBCommand['Parameters'])\n+            writeAndX = smb.SMBWriteAndX_Parameters(SMBCommand['Parameters'])\n             writeAndXData = smb.SMBWriteAndX_Data()\n         writeAndXData['DataLength'] = writeAndX['DataLength']\n         writeAndXData['DataOffset'] = writeAndX['DataOffset']\n         writeAndXData.fromString(SMBCommand['Data'])\n-        \n \n         if writeAndX['Fid'] in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][writeAndX['Fid']]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     offset = writeAndX['Offset']\n-                     if 'HighOffset' in writeAndX.fields:\n-                         offset += (writeAndX['HighOffset'] << 32)\n-                     # If we're trying to write past the file end we just skip the write call (Vista does this)\n-                     if os.lseek(fileHandle, 0, 2) >= offset:\n-                         os.lseek(fileHandle,offset,0)\n-                         os.write(fileHandle,writeAndXData['Data'])\n-                 else:\n-                     sock = connData['OpenedFiles'][writeAndX['Fid']]['Socket']\n-                     sock.send(writeAndXData['Data'])\n-\n-                 respParameters['Count']    = writeAndX['DataLength']\n-                 respParameters['Available']= 0xff\n-             except Exception as e:\n-                 smbServer.log('smbComWriteAndx: %s' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][writeAndX['Fid']]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    offset = writeAndX['Offset']\n+                    if 'HighOffset' in writeAndX.fields:\n+                        offset += (writeAndX['HighOffset'] << 32)\n+                    # If we're trying to write past the file end we just skip the write call (Vista does this)\n+                    if os.lseek(fileHandle, 0, 2) >= offset:\n+                        os.lseek(fileHandle, offset, 0)\n+                        os.write(fileHandle, writeAndXData['Data'])\n+                else:\n+                    sock = connData['OpenedFiles'][writeAndX['Fid']]['Socket']\n+                    sock.send(writeAndXData['Data'])\n+\n+                respParameters['Count'] = writeAndX['DataLength']\n+                respParameters['Available'] = 0xff\n+            except Exception as e:\n+                smbServer.log('smbComWriteAndx: %s' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1716,38 +1742,38 @@ def smbComWriteAndX(connId, smbServer, SMBCommand, recvPacket):\n     def smbComRead(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_READ)\n-        respParameters        = smb.SMBReadResponse_Parameters()\n-        respData              = smb.SMBReadResponse_Data()\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_READ)\n+        respParameters = smb.SMBReadResponse_Parameters()\n+        respData = smb.SMBReadResponse_Data()\n \n-        comReadParameters =  smb.SMBRead_Parameters(SMBCommand['Parameters'])\n+        comReadParameters = smb.SMBRead_Parameters(SMBCommand['Parameters'])\n \n         if comReadParameters['Fid'] in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][comReadParameters['Fid']]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     # TODO: Handle big size files\n-                     os.lseek(fileHandle,comReadParameters['Offset'],0)\n-                     content = os.read(fileHandle,comReadParameters['Count'])\n-                 else:\n-                     sock = connData['OpenedFiles'][comReadParameters['Fid']]['Socket']\n-                     content = sock.recv(comReadParameters['Count'])\n-                 respParameters['Count']    = len(content)\n-                 respData['DataLength']     = len(content)\n-                 respData['Data']           = content\n-             except Exception as e:\n-                 smbServer.log('smbComRead: %s ' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][comReadParameters['Fid']]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    # TODO: Handle big size files\n+                    os.lseek(fileHandle, comReadParameters['Offset'], 0)\n+                    content = os.read(fileHandle, comReadParameters['Count'])\n+                else:\n+                    sock = connData['OpenedFiles'][comReadParameters['Fid']]['Socket']\n+                    content = sock.recv(comReadParameters['Count'])\n+                respParameters['Count'] = len(content)\n+                respData['DataLength'] = len(content)\n+                respData['Data'] = content\n+            except Exception as e:\n+                smbServer.log('smbComRead: %s ' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1756,45 +1782,45 @@ def smbComRead(connId, smbServer, SMBCommand, recvPacket):\n     def smbComReadAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_READ_ANDX)\n-        respParameters        = smb.SMBReadAndXResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_READ_ANDX)\n+        respParameters = smb.SMBReadAndXResponse_Parameters()\n+        respData = b''\n \n         if SMBCommand['WordCount'] == 0x0A:\n-            readAndX =  smb.SMBReadAndX_Parameters2(SMBCommand['Parameters'])\n+            readAndX = smb.SMBReadAndX_Parameters2(SMBCommand['Parameters'])\n         else:\n-            readAndX =  smb.SMBReadAndX_Parameters(SMBCommand['Parameters'])\n+            readAndX = smb.SMBReadAndX_Parameters(SMBCommand['Parameters'])\n \n         if readAndX['Fid'] in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][readAndX['Fid']]['FileHandle']\n-             errorCode = 0\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     offset = readAndX['Offset']\n-                     if 'HighOffset' in readAndX.fields:\n-                         offset += (readAndX['HighOffset'] << 32)\n-                     os.lseek(fileHandle,offset,0)\n-                     content = os.read(fileHandle,readAndX['MaxCount'])\n-                 else:\n-                     sock = connData['OpenedFiles'][readAndX['Fid']]['Socket']\n-                     content = sock.recv(readAndX['MaxCount'])\n-                 respParameters['Remaining']    = 0xffff\n-                 respParameters['DataCount']    = len(content)\n-                 respParameters['DataOffset']   = 59\n-                 respParameters['DataCount_Hi'] = 0\n-                 respData = content\n-             except Exception as e:\n-                 smbServer.log('smbComReadAndX: %s ' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][readAndX['Fid']]['FileHandle']\n+            errorCode = 0\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    offset = readAndX['Offset']\n+                    if 'HighOffset' in readAndX.fields:\n+                        offset += (readAndX['HighOffset'] << 32)\n+                    os.lseek(fileHandle, offset, 0)\n+                    content = os.read(fileHandle, readAndX['MaxCount'])\n+                else:\n+                    sock = connData['OpenedFiles'][readAndX['Fid']]['Socket']\n+                    content = sock.recv(readAndX['MaxCount'])\n+                respParameters['Remaining'] = 0xffff\n+                respParameters['DataCount'] = len(content)\n+                respParameters['DataOffset'] = 59\n+                respParameters['DataCount_Hi'] = 0\n+                respData = content\n+            except Exception as e:\n+                smbServer.log('smbComReadAndX: %s ' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1805,28 +1831,28 @@ def smbQueryInformation(connId, smbServer, SMBCommand, recvPacket):\n \n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION)\n         respParameters = smb.SMBQueryInformationResponse_Parameters()\n-        respData       = b''\n+        respData = b''\n \n-        queryInformation= smb.SMBQueryInformation_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        queryInformation = smb.SMBQueryInformation_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             fileSize, lastWriteTime, fileAttributes = queryFsInformation(\n-                connData['ConnectedShares'][recvPacket['Tid']]['path'], \n-                decodeSMBString(recvPacket['Flags2'],queryInformation['FileName']), pktFlags = recvPacket['Flags2'])\n+                connData['ConnectedShares'][recvPacket['Tid']]['path'],\n+                decodeSMBString(recvPacket['Flags2'], queryInformation['FileName']), pktFlags=recvPacket['Flags2'])\n \n-            respParameters['FileSize']       = fileSize\n-            respParameters['LastWriteTime']  = lastWriteTime\n+            respParameters['FileSize'] = fileSize\n+            respParameters['LastWriteTime'] = lastWriteTime\n             respParameters['FileAttributes'] = fileAttributes\n             errorCode = STATUS_SUCCESS\n         else:\n             # STATUS_SMB_BAD_TID\n             errorCode = STATUS_SMB_BAD_TID\n-            respParameters  = b''\n-            respData        = b''\n+            respParameters = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n@@ -1837,27 +1863,26 @@ def smbQueryInformationDisk(connId, smbServer, SMBCommand, recvPacket):\n \n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION_DISK)\n         respParameters = smb.SMBQueryInformationDiskResponse_Parameters()\n-        respData       = b''\n+        respData = b''\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n             totalUnits, freeUnits = queryDiskInformation(\n-                        connData['ConnectedShares'][recvPacket['Tid']]['path'])\n+                connData['ConnectedShares'][recvPacket['Tid']]['path'])\n \n-            respParameters['TotalUnits']    = totalUnits\n+            respParameters['TotalUnits'] = totalUnits\n             respParameters['BlocksPerUnit'] = 1\n-            respParameters['BlockSize']     = 1\n-            respParameters['FreeUnits']     = freeUnits\n+            respParameters['BlockSize'] = 1\n+            respParameters['FreeUnits'] = freeUnits\n             errorCode = STATUS_SUCCESS\n         else:\n             # STATUS_SMB_BAD_TID\n-            respData  = b''\n+            respData = b''\n             respParameters = b''\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n@@ -1868,15 +1893,15 @@ def smbComEcho(connId, smbServer, SMBCommand, recvPacket):\n \n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_ECHO)\n         respParameters = smb.SMBEchoResponse_Parameters()\n-        respData       = smb.SMBEchoResponse_Data()\n+        respData = smb.SMBEchoResponse_Data()\n \n-        echoData       = smb.SMBEcho_Data(SMBCommand['Data'])\n+        echoData = smb.SMBEcho_Data(SMBCommand['Data'])\n \n         respParameters['SequenceNumber'] = 1\n-        respData['Data']                 = echoData['Data']\n+        respData['Data'] = echoData['Data']\n \n-        respSMBCommand['Parameters']     = respParameters\n-        respSMBCommand['Data']           = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         errorCode = STATUS_SUCCESS\n         smbServer.setConnectionData(connId, connData)\n@@ -1893,15 +1918,16 @@ def smbComTreeDisconnect(connId, smbServer, SMBCommand, recvPacket):\n         respData = b''\n \n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-            smbServer.log(\"Disconnecting Share(%d:%s)\" % (recvPacket['Tid'],connData['ConnectedShares'][recvPacket['Tid']]['shareName']))\n-            del(connData['ConnectedShares'][recvPacket['Tid']])\n+            smbServer.log(\"Disconnecting Share(%d:%s)\" % (\n+            recvPacket['Tid'], connData['ConnectedShares'][recvPacket['Tid']]['shareName']))\n+            del (connData['ConnectedShares'][recvPacket['Tid']])\n             errorCode = STATUS_SUCCESS\n         else:\n             # STATUS_SMB_BAD_TID\n             errorCode = STATUS_SMB_BAD_TID\n \n         respSMBCommand['Parameters'] = respParameters\n-        respSMBCommand['Data']       = respData \n+        respSMBCommand['Data'] = respData\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n@@ -1910,7 +1936,7 @@ def smbComTreeDisconnect(connId, smbServer, SMBCommand, recvPacket):\n     def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_LOGOFF_ANDX)\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_LOGOFF_ANDX)\n \n         # Check if the Uid matches the user trying to logoff\n         respParameters = b''\n@@ -1921,8 +1947,8 @@ def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):\n         else:\n             errorCode = STATUS_SUCCESS\n \n-        respSMBCommand['Parameters']   = respParameters\n-        respSMBCommand['Data']         = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         connData['Uid'] = 0\n         connData['Authenticated'] = False\n \n@@ -1934,41 +1960,41 @@ def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):\n     def smbComQueryInformation2(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION2)\n-        respParameters        = smb.SMBQueryInformation2Response_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION2)\n+        respParameters = smb.SMBQueryInformation2Response_Parameters()\n+        respData = b''\n \n         queryInformation2 = smb.SMBQueryInformation2_Parameters(SMBCommand['Parameters'])\n         errorCode = 0xFF\n         if queryInformation2['Fid'] in connData['OpenedFiles']:\n-             errorCode = STATUS_SUCCESS\n-             pathName = connData['OpenedFiles'][queryInformation2['Fid']]['FileName']\n-             try:\n-                 (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n-                 respParameters['CreateDate']         = getSMBDate(ctime)\n-                 respParameters['CreationTime']       = getSMBTime(ctime)\n-                 respParameters['LastAccessDate']     = getSMBDate(atime)\n-                 respParameters['LastAccessTime']     = getSMBTime(atime)\n-                 respParameters['LastWriteDate']      = getSMBDate(mtime)\n-                 respParameters['LastWriteTime']      = getSMBTime(mtime)\n-                 respParameters['FileDataSize']       = size\n-                 respParameters['FileAllocationSize'] = size\n-                 attribs = 0\n-                 if os.path.isdir(pathName):\n-                     attribs = smb.SMB_FILE_ATTRIBUTE_DIRECTORY\n-                 if os.path.isfile(pathName):\n-                     attribs = smb.SMB_FILE_ATTRIBUTE_NORMAL\n-                 respParameters['FileAttributes'] = attribs\n-             except Exception as e:\n-                 smbServer.log('smbComQueryInformation2 %s' % e,logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            errorCode = STATUS_SUCCESS\n+            pathName = connData['OpenedFiles'][queryInformation2['Fid']]['FileName']\n+            try:\n+                (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)\n+                respParameters['CreateDate'] = getSMBDate(ctime)\n+                respParameters['CreationTime'] = getSMBTime(ctime)\n+                respParameters['LastAccessDate'] = getSMBDate(atime)\n+                respParameters['LastAccessTime'] = getSMBTime(atime)\n+                respParameters['LastWriteDate'] = getSMBDate(mtime)\n+                respParameters['LastWriteTime'] = getSMBTime(mtime)\n+                respParameters['FileDataSize'] = size\n+                respParameters['FileAllocationSize'] = size\n+                attribs = 0\n+                if os.path.isdir(pathName):\n+                    attribs = smb.SMB_FILE_ATTRIBUTE_DIRECTORY\n+                if os.path.isfile(pathName):\n+                    attribs = smb.SMB_FILE_ATTRIBUTE_NORMAL\n+                respParameters['FileAttributes'] = attribs\n+            except Exception as e:\n+                smbServer.log('smbComQueryInformation2 %s' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n \n         if errorCode > 0:\n             respParameters = b''\n-            respData       = b''\n+            respData = b''\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -1978,136 +2004,145 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n         # TODO: Fully implement this\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_NT_CREATE_ANDX)\n-        respParameters        = smb.SMBNtCreateAndXResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_NT_CREATE_ANDX)\n+        respParameters = smb.SMBNtCreateAndXResponse_Parameters()\n+        respData = b''\n \n         ntCreateAndXParameters = smb.SMBNtCreateAndX_Parameters(SMBCommand['Parameters'])\n-        ntCreateAndXData       = smb.SMBNtCreateAndX_Data( flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        ntCreateAndXData = smb.SMBNtCreateAndX_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n-        #if ntCreateAndXParameters['CreateFlags'] & 0x10:  # NT_CREATE_REQUEST_EXTENDED_RESPONSE\n+        # if ntCreateAndXParameters['CreateFlags'] & 0x10:  # NT_CREATE_REQUEST_EXTENDED_RESPONSE\n         #    respParameters        = smb.SMBNtCreateAndXExtendedResponse_Parameters()\n         #    respParameters['VolumeGUID'] = '\\x00'\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             # If we have a rootFid, the path is relative to that fid\n-             errorCode = STATUS_SUCCESS\n-             if ntCreateAndXParameters['RootFid'] > 0:\n-                 path = connData['OpenedFiles'][ntCreateAndXParameters['RootFid']]['FileName']\n-                 LOG.debug(\"RootFid present %s!\" % path)\n-             else:\n-                 if 'path' in connData['ConnectedShares'][recvPacket['Tid']]:\n-                     path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-                 else:\n-                     path = 'NONE'\n-                     errorCode = STATUS_ACCESS_DENIED\n-\n-             deleteOnClose = False\n-\n-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],ntCreateAndXData['FileName']).replace('\\\\','\/'))\n-             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+            # If we have a rootFid, the path is relative to that fid\n+            errorCode = STATUS_SUCCESS\n+            if ntCreateAndXParameters['RootFid'] > 0:\n+                path = connData['OpenedFiles'][ntCreateAndXParameters['RootFid']]['FileName']\n+                LOG.debug(\"RootFid present %s!\" % path)\n+            else:\n+                if 'path' in connData['ConnectedShares'][recvPacket['Tid']]:\n+                    path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+                else:\n+                    path = 'NONE'\n+                    errorCode = STATUS_ACCESS_DENIED\n+\n+            deleteOnClose = False\n+\n+            fileName = os.path.normpath(\n+                decodeSMBString(recvPacket['Flags2'], ntCreateAndXData['FileName']).replace('\\\\', '\/'))\n+            if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             createDisposition = ntCreateAndXParameters['Disposition']\n-             mode = 0\n-\n-             if createDisposition == smb.FILE_SUPERSEDE:\n-                 mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb.FILE_OVERWRITE_IF == smb.FILE_OVERWRITE_IF:\n-                 mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb.FILE_OVERWRITE == smb.FILE_OVERWRITE:\n-                 if os.path.exists(pathName) is True:\n-                     mode |= os.O_TRUNC \n-                 else:\n-                     errorCode = STATUS_NO_SUCH_FILE\n-             elif createDisposition & smb.FILE_OPEN_IF == smb.FILE_OPEN_IF:\n-                 if os.path.exists(pathName) is True:\n-                     mode |= os.O_TRUNC \n-                 else:\n-                     mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb.FILE_CREATE == smb.FILE_CREATE:\n-                 if os.path.exists(pathName) is True:\n-                     errorCode = STATUS_OBJECT_NAME_COLLISION\n-                 else:\n-                     mode |= os.O_CREAT\n-             elif createDisposition & smb.FILE_OPEN == smb.FILE_OPEN:\n-                 if os.path.exists(pathName) is not True and (str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:\n-                     errorCode = STATUS_NO_SUCH_FILE\n-\n-             if errorCode == STATUS_SUCCESS:\n-                 desiredAccess = ntCreateAndXParameters['AccessMask']\n-                 if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):\n-                     mode |= os.O_RDONLY\n-                 if (desiredAccess & smb.FILE_WRITE_DATA) or (desiredAccess & smb.GENERIC_WRITE):\n-                     if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):\n-                         mode |= os.O_RDWR #| os.O_APPEND\n-                     else: \n-                         mode |= os.O_WRONLY #| os.O_APPEND\n-                 if desiredAccess & smb.GENERIC_ALL:\n-                     mode |= os.O_RDWR #| os.O_APPEND\n-\n-                 createOptions =  ntCreateAndXParameters['CreateOptions']\n-                 if mode & os.O_CREAT == os.O_CREAT:\n-                     if createOptions & smb.FILE_DIRECTORY_FILE == smb.FILE_DIRECTORY_FILE: \n-                         try:\n-                             # Let's create the directory\n-                             os.mkdir(pathName)\n-                             mode = os.O_RDONLY\n-                         except Exception as e:\n-                             smbServer.log(\"NTCreateAndX: %s,%s,%s\" % (pathName,mode,e),logging.ERROR)\n-                             errorCode = STATUS_ACCESS_DENIED\n-                 if createOptions & smb.FILE_NON_DIRECTORY_FILE == smb.FILE_NON_DIRECTORY_FILE:\n-                     # If the file being opened is a directory, the server MUST fail the request with\n-                     # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server\n-                     # response.\n-                     if os.path.isdir(pathName) is True:\n+\n+            if not isInFileJail(path, fileName):\n+                LOG.error(\"Path not in current working directory\")\n+                respSMBCommand['Parameters'] = b''\n+                respSMBCommand['Data'] = b''\n+                return [respSMBCommand], None, STATUS_ACCESS_DENIED\n+\n+            pathName = os.path.join(path, fileName)\n+            createDisposition = ntCreateAndXParameters['Disposition']\n+            mode = 0\n+\n+            if createDisposition == smb.FILE_SUPERSEDE:\n+                mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb.FILE_OVERWRITE_IF == smb.FILE_OVERWRITE_IF:\n+                mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb.FILE_OVERWRITE == smb.FILE_OVERWRITE:\n+                if os.path.exists(pathName) is True:\n+                    mode |= os.O_TRUNC\n+                else:\n+                    errorCode = STATUS_NO_SUCH_FILE\n+            elif createDisposition & smb.FILE_OPEN_IF == smb.FILE_OPEN_IF:\n+                if os.path.exists(pathName) is True:\n+                    mode |= os.O_TRUNC\n+                else:\n+                    mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb.FILE_CREATE == smb.FILE_CREATE:\n+                if os.path.exists(pathName) is True:\n+                    errorCode = STATUS_OBJECT_NAME_COLLISION\n+                else:\n+                    mode |= os.O_CREAT\n+            elif createDisposition & smb.FILE_OPEN == smb.FILE_OPEN:\n+                if os.path.exists(pathName) is not True and (\n+                        str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:\n+                    errorCode = STATUS_NO_SUCH_FILE\n+\n+            if errorCode == STATUS_SUCCESS:\n+                desiredAccess = ntCreateAndXParameters['AccessMask']\n+                if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):\n+                    mode |= os.O_RDONLY\n+                if (desiredAccess & smb.FILE_WRITE_DATA) or (desiredAccess & smb.GENERIC_WRITE):\n+                    if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):\n+                        mode |= os.O_RDWR  # | os.O_APPEND\n+                    else:\n+                        mode |= os.O_WRONLY  # | os.O_APPEND\n+                if desiredAccess & smb.GENERIC_ALL:\n+                    mode |= os.O_RDWR  # | os.O_APPEND\n+\n+                createOptions = ntCreateAndXParameters['CreateOptions']\n+                if mode & os.O_CREAT == os.O_CREAT:\n+                    if createOptions & smb.FILE_DIRECTORY_FILE == smb.FILE_DIRECTORY_FILE:\n+                        try:\n+                            # Let's create the directory\n+                            os.mkdir(pathName)\n+                            mode = os.O_RDONLY\n+                        except Exception as e:\n+                            smbServer.log(\"NTCreateAndX: %s,%s,%s\" % (pathName, mode, e), logging.ERROR)\n+                            errorCode = STATUS_ACCESS_DENIED\n+                if createOptions & smb.FILE_NON_DIRECTORY_FILE == smb.FILE_NON_DIRECTORY_FILE:\n+                    # If the file being opened is a directory, the server MUST fail the request with\n+                    # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server\n+                    # response.\n+                    if os.path.isdir(pathName) is True:\n                         errorCode = STATUS_FILE_IS_A_DIRECTORY\n \n-                 if createOptions & smb.FILE_DELETE_ON_CLOSE == smb.FILE_DELETE_ON_CLOSE:\n-                     deleteOnClose = True\n-                 \n-                 if errorCode == STATUS_SUCCESS:\n-                     try:\n-                         if os.path.isdir(pathName) and sys.platform == 'win32':\n+                if createOptions & smb.FILE_DELETE_ON_CLOSE == smb.FILE_DELETE_ON_CLOSE:\n+                    deleteOnClose = True\n+\n+                if errorCode == STATUS_SUCCESS:\n+                    try:\n+                        if os.path.isdir(pathName) and sys.platform == 'win32':\n                             fid = VOID_FILE_DESCRIPTOR\n-                         else:\n+                        else:\n                             if sys.platform == 'win32':\n-                               mode |= os.O_BINARY\n+                                mode |= os.O_BINARY\n                             if str(pathName) in smbServer.getRegisteredNamedPipes():\n                                 fid = PIPE_FILE_DESCRIPTOR\n                                 sock = socket.socket()\n                                 sock.connect(smbServer.getRegisteredNamedPipes()[str(pathName)])\n                             else:\n                                 fid = os.open(pathName, mode)\n-                     except Exception as e:\n-                         smbServer.log(\"NTCreateAndX: %s,%s,%s\" % (pathName,mode,e),logging.ERROR)\n-                         #print e\n-                         fid = 0\n-                         errorCode = STATUS_ACCESS_DENIED\n+                    except Exception as e:\n+                        smbServer.log(\"NTCreateAndX: %s,%s,%s\" % (pathName, mode, e), logging.ERROR)\n+                        # print e\n+                        fid = 0\n+                        errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n         if errorCode == STATUS_SUCCESS:\n             # Simple way to generate a fid\n             if len(connData['OpenedFiles']) == 0:\n-               fakefid = 1\n+                fakefid = 1\n             else:\n-               fakefid = list(connData['OpenedFiles'].keys())[-1] + 1\n+                fakefid = list(connData['OpenedFiles'].keys())[-1] + 1\n             respParameters['Fid'] = fakefid\n             respParameters['CreateAction'] = createDisposition\n             if fid == PIPE_FILE_DESCRIPTOR:\n                 respParameters['FileAttributes'] = 0x80\n                 respParameters['IsDirectory'] = 0\n-                respParameters['CreateTime']     = 0\n+                respParameters['CreateTime'] = 0\n                 respParameters['LastAccessTime'] = 0\n-                respParameters['LastWriteTime']  = 0\n+                respParameters['LastWriteTime'] = 0\n                 respParameters['LastChangeTime'] = 0\n                 respParameters['AllocationSize'] = 4096\n-                respParameters['EndOfFile']      = 0\n-                respParameters['FileType']       = 2\n-                respParameters['IPCState']       = 0x5ff\n+                respParameters['EndOfFile'] = 0\n+                respParameters['FileType'] = 2\n+                respParameters['IPCState'] = 0x5ff\n             else:\n                 if os.path.isdir(pathName):\n                     respParameters['FileAttributes'] = smb.SMB_FILE_ATTRIBUTE_DIRECTORY\n@@ -2116,18 +2151,18 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n                     respParameters['IsDirectory'] = 0\n                     respParameters['FileAttributes'] = ntCreateAndXParameters['FileAttributes']\n                 # Let's get this file's information\n-                respInfo, errorCode = queryPathInformation('',pathName,level= smb.SMB_QUERY_FILE_ALL_INFO)\n+                respInfo, errorCode = queryPathInformation('', pathName, level=smb.SMB_QUERY_FILE_ALL_INFO)\n                 if errorCode == STATUS_SUCCESS:\n-                    respParameters['CreateTime']     = respInfo['CreationTime']\n+                    respParameters['CreateTime'] = respInfo['CreationTime']\n                     respParameters['LastAccessTime'] = respInfo['LastAccessTime']\n-                    respParameters['LastWriteTime']  = respInfo['LastWriteTime']\n+                    respParameters['LastWriteTime'] = respInfo['LastWriteTime']\n                     respParameters['LastChangeTime'] = respInfo['LastChangeTime']\n                     respParameters['FileAttributes'] = respInfo['ExtFileAttributes']\n                     respParameters['AllocationSize'] = respInfo['AllocationSize']\n-                    respParameters['EndOfFile']      = respInfo['EndOfFile']\n+                    respParameters['EndOfFile'] = respInfo['EndOfFile']\n                 else:\n                     respParameters = b''\n-                    respData       = b''\n+                    respData = b''\n \n             if errorCode == STATUS_SUCCESS:\n                 # Let's store the fid for the connection\n@@ -2135,15 +2170,15 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n                 connData['OpenedFiles'][fakefid] = {}\n                 connData['OpenedFiles'][fakefid]['FileHandle'] = fid\n                 connData['OpenedFiles'][fakefid]['FileName'] = pathName\n-                connData['OpenedFiles'][fakefid]['DeleteOnClose']  = deleteOnClose\n+                connData['OpenedFiles'][fakefid]['DeleteOnClose'] = deleteOnClose\n                 if fid == PIPE_FILE_DESCRIPTOR:\n                     connData['OpenedFiles'][fakefid]['Socket'] = sock\n         else:\n             respParameters = b''\n-            respData       = b''\n-        \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+            respData = b''\n+\n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -2152,31 +2187,32 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):\n     def smbComOpenAndX(connId, smbServer, SMBCommand, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_OPEN_ANDX)\n-        respParameters        = smb.SMBOpenAndXResponse_Parameters()\n-        respData              = b''\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_OPEN_ANDX)\n+        respParameters = smb.SMBOpenAndXResponse_Parameters()\n+        respData = b''\n \n         openAndXParameters = smb.SMBOpenAndX_Parameters(SMBCommand['Parameters'])\n-        openAndXData       = smb.SMBOpenAndX_Data( flags = recvPacket['Flags2'], data = SMBCommand['Data'])\n+        openAndXData = smb.SMBOpenAndX_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])\n \n         # Get the Tid associated\n         if recvPacket['Tid'] in connData['ConnectedShares']:\n-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n-             openedFile, mode, pathName, errorCode = openFile(path,\n-                     decodeSMBString(recvPacket['Flags2'],openAndXData['FileName']), \n-                     openAndXParameters['DesiredAccess'], \n-                     openAndXParameters['FileAttributes'], \n-                     openAndXParameters['OpenMode'])\n+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']\n+            openedFile, mode, pathName, errorCode = openFile(path,\n+                                                             decodeSMBString(recvPacket['Flags2'],\n+                                                                             openAndXData['FileName']),\n+                                                             openAndXParameters['DesiredAccess'],\n+                                                             openAndXParameters['FileAttributes'],\n+                                                             openAndXParameters['OpenMode'])\n         else:\n-           errorCode = STATUS_SMB_BAD_TID\n+            errorCode = STATUS_SMB_BAD_TID\n \n         if errorCode == STATUS_SUCCESS:\n             # Simple way to generate a fid\n-            fid = len(connData['OpenedFiles']) + 1 \n+            fid = len(connData['OpenedFiles']) + 1\n             if len(connData['OpenedFiles']) == 0:\n-               fid = 1\n+                fid = 1\n             else:\n-               fid = list(connData['OpenedFiles'].keys())[-1] + 1\n+                fid = list(connData['OpenedFiles'].keys())[-1] + 1\n             respParameters['Fid'] = fid\n             if mode & os.O_CREAT:\n                 # File did not exist and was created\n@@ -2190,19 +2226,19 @@ def smbComOpenAndX(connId, smbServer, SMBCommand, recvPacket):\n             else:\n                 # File existed and was truncated\n                 respParameters['Action'] = 0x3\n-            \n+\n             # Let's store the fid for the connection\n-            #smbServer.log('Opening file %s' % pathName)\n+            # smbServer.log('Opening file %s' % pathName)\n             connData['OpenedFiles'][fid] = {}\n             connData['OpenedFiles'][fid]['FileHandle'] = openedFile\n             connData['OpenedFiles'][fid]['FileName'] = pathName\n-            connData['OpenedFiles'][fid]['DeleteOnClose']  = False\n+            connData['OpenedFiles'][fid]['DeleteOnClose'] = False\n         else:\n             respParameters = b''\n-            respData       = b''\n-        \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+            respData = b''\n+\n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -2213,22 +2249,23 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):\n \n         resp = smb.NewSMBPacket()\n         resp['Flags1'] = smb.SMB.FLAGS1_REPLY\n-        resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | recvPacket['Flags2'] & smb.SMB.FLAGS2_UNICODE\n+        resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | \\\n+                         recvPacket['Flags2'] & smb.SMB.FLAGS2_UNICODE\n \n         resp['Tid'] = recvPacket['Tid']\n         resp['Mid'] = recvPacket['Mid']\n         resp['Pid'] = connData['Pid']\n \n-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_TREE_CONNECT_ANDX)\n-        respParameters        = smb.SMBTreeConnectAndXResponse_Parameters()\n-        respData              = smb.SMBTreeConnectAndXResponse_Data()\n+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_TREE_CONNECT_ANDX)\n+        respParameters = smb.SMBTreeConnectAndXResponse_Parameters()\n+        respData = smb.SMBTreeConnectAndXResponse_Data()\n \n         treeConnectAndXParameters = smb.SMBTreeConnectAndX_Parameters(SMBCommand['Parameters'])\n \n         if treeConnectAndXParameters['Flags'] & 0x8:\n-            respParameters        = smb.SMBTreeConnectAndXExtendedResponse_Parameters()\n+            respParameters = smb.SMBTreeConnectAndXExtendedResponse_Parameters()\n \n-        treeConnectAndXData                    = smb.SMBTreeConnectAndX_Data( flags = recvPacket['Flags2'] )\n+        treeConnectAndXData = smb.SMBTreeConnectAndX_Data(flags=recvPacket['Flags2'])\n         treeConnectAndXData['_PasswordLength'] = treeConnectAndXParameters['PasswordLength']\n         treeConnectAndXData.fromString(SMBCommand['Data'])\n \n@@ -2243,34 +2280,34 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):\n         else:\n             path = ntpath.basename(UNCOrShare)\n \n-        share = searchShare(connId, path, smbServer) \n+        share = searchShare(connId, path, smbServer)\n         if share is not None:\n             # Simple way to generate a Tid\n             if len(connData['ConnectedShares']) == 0:\n-               tid = 1\n+                tid = 1\n             else:\n-               tid = list(connData['ConnectedShares'].keys())[-1] + 1\n+                tid = list(connData['ConnectedShares'].keys())[-1] + 1\n             connData['ConnectedShares'][tid] = share\n             connData['ConnectedShares'][tid]['shareName'] = path\n             resp['Tid'] = tid\n-            #smbServer.log(\"Connecting Share(%d:%s)\" % (tid,path))\n+            # smbServer.log(\"Connecting Share(%d:%s)\" % (tid,path))\n         else:\n             smbServer.log(\"TreeConnectAndX not found %s\" % path, logging.ERROR)\n             errorCode = STATUS_OBJECT_PATH_NOT_FOUND\n-            resp['ErrorCode']   = errorCode >> 16\n-            resp['ErrorClass']  = errorCode & 0xff\n+            resp['ErrorCode'] = errorCode >> 16\n+            resp['ErrorClass'] = errorCode & 0xff\n         ##\n         respParameters['OptionalSupport'] = smb.SMB.SMB_SUPPORT_SEARCH_BITS\n \n         if path == 'IPC$':\n-            respData['Service']               = 'IPC'\n+            respData['Service'] = 'IPC'\n         else:\n-            respData['Service']               = path\n-        respData['PadLen']                = 0\n-        respData['NativeFileSystem']      = encodeSMBString(recvPacket['Flags2'], 'NTFS' ).decode()\n+            respData['Service'] = path\n+        respData['PadLen'] = 0\n+        respData['NativeFileSystem'] = encodeSMBString(recvPacket['Flags2'], 'NTFS').decode()\n \n-        respSMBCommand['Parameters']             = respParameters\n-        respSMBCommand['Data']                   = respData \n+        respSMBCommand['Parameters'] = respParameters\n+        respSMBCommand['Data'] = respData\n \n         resp['Uid'] = connData['Uid']\n         resp.addCommand(respSMBCommand)\n@@ -2284,19 +2321,19 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):\n \n     @staticmethod\n     def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n-        connData = smbServer.getConnectionData(connId, checkStatus = False)\n+        connData = smbServer.getConnectionData(connId, checkStatus=False)\n \n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_SESSION_SETUP_ANDX)\n \n         # From [MS-SMB]\n-        # When extended security is being used (see section 3.2.4.2.4), the \n+        # When extended security is being used (see section 3.2.4.2.4), the\n         # request MUST take the following form\n         # [..]\n         # WordCount (1 byte): The value of this field MUST be 0x0C.\n         if SMBCommand['WordCount'] == 12:\n             # Extended security. Here we deal with all SPNEGO stuff\n             respParameters = smb.SMBSessionSetupAndX_Extended_Response_Parameters()\n-            respData       = smb.SMBSessionSetupAndX_Extended_Response_Data(flags = recvPacket['Flags2'])\n+            respData = smb.SMBSessionSetupAndX_Extended_Response_Data(flags=recvPacket['Flags2'])\n             sessionSetupParameters = smb.SMBSessionSetupAndX_Extended_Parameters(SMBCommand['Parameters'])\n             sessionSetupData = smb.SMBSessionSetupAndX_Extended_Data()\n             sessionSetupData['SecurityBlobLength'] = sessionSetupParameters['SecurityBlobLength']\n@@ -2304,45 +2341,45 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n             connData['Capabilities'] = sessionSetupParameters['Capabilities']\n \n             rawNTLM = False\n-            if struct.unpack('B',sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_AID:\n-               # NEGOTIATE packet\n-               blob =  SPNEGO_NegTokenInit(sessionSetupData['SecurityBlob'])\n-               token = blob['MechToken']\n-               if len(blob['MechTypes'][0]) > 0:\n-                   # Is this GSSAPI NTLM or something else we don't support?\n-                   mechType = blob['MechTypes'][0]\n-                   if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:\n-                       # Nope, do we know it?\n-                       if mechType in MechTypes:\n-                           mechStr = MechTypes[mechType]\n-                       else:\n-                           mechStr = hexlify(mechType)\n-                       smbServer.log(\"Unsupported MechType '%s'\" % mechStr, logging.CRITICAL)\n-                       # We don't know the token, we answer back again saying \n-                       # we just support NTLM.\n-                       # ToDo: Build this into a SPNEGO_NegTokenResp()\n-                       respToken = b'\\xa1\\x15\\x30\\x13\\xa0\\x03\\x0a\\x01\\x03\\xa1\\x0c\\x06\\x0a\\x2b\\x06\\x01\\x04\\x01\\x82\\x37\\x02\\x02\\x0a'\n-                       respParameters['SecurityBlobLength'] = len(respToken)\n-                       respData['SecurityBlobLength'] = respParameters['SecurityBlobLength'] \n-                       respData['SecurityBlob']       = respToken\n-                       respData['NativeOS']     = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n-                       respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n-                       respSMBCommand['Parameters'] = respParameters\n-                       respSMBCommand['Data']       = respData \n-                       return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED\n-\n-            elif struct.unpack('B',sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_SUPPORTED_MECH:\n-               # AUTH packet\n-               blob = SPNEGO_NegTokenResp(sessionSetupData['SecurityBlob'])\n-               token = blob['ResponseToken']\n+            if struct.unpack('B', sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_AID:\n+                # NEGOTIATE packet\n+                blob = SPNEGO_NegTokenInit(sessionSetupData['SecurityBlob'])\n+                token = blob['MechToken']\n+                if len(blob['MechTypes'][0]) > 0:\n+                    # Is this GSSAPI NTLM or something else we don't support?\n+                    mechType = blob['MechTypes'][0]\n+                    if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:\n+                        # Nope, do we know it?\n+                        if mechType in MechTypes:\n+                            mechStr = MechTypes[mechType]\n+                        else:\n+                            mechStr = hexlify(mechType)\n+                        smbServer.log(\"Unsupported MechType '%s'\" % mechStr, logging.CRITICAL)\n+                        # We don't know the token, we answer back again saying\n+                        # we just support NTLM.\n+                        # ToDo: Build this into a SPNEGO_NegTokenResp()\n+                        respToken = b'\\xa1\\x15\\x30\\x13\\xa0\\x03\\x0a\\x01\\x03\\xa1\\x0c\\x06\\x0a\\x2b\\x06\\x01\\x04\\x01\\x82\\x37\\x02\\x02\\x0a'\n+                        respParameters['SecurityBlobLength'] = len(respToken)\n+                        respData['SecurityBlobLength'] = respParameters['SecurityBlobLength']\n+                        respData['SecurityBlob'] = respToken\n+                        respData['NativeOS'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n+                        respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n+                        respSMBCommand['Parameters'] = respParameters\n+                        respSMBCommand['Data'] = respData\n+                        return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED\n+\n+            elif struct.unpack('B', sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_SUPPORTED_MECH:\n+                # AUTH packet\n+                blob = SPNEGO_NegTokenResp(sessionSetupData['SecurityBlob'])\n+                token = blob['ResponseToken']\n             else:\n-               # No GSSAPI stuff, raw NTLMSSP\n-               rawNTLM = True\n-               token = sessionSetupData['SecurityBlob']\n+                # No GSSAPI stuff, raw NTLMSSP\n+                rawNTLM = True\n+                token = sessionSetupData['SecurityBlob']\n \n-            # Here we only handle NTLMSSP, depending on what stage of the \n+            # Here we only handle NTLMSSP, depending on what stage of the\n             # authentication we are, we act on it\n-            messageType = struct.unpack('<L',token[len('NTLMSSP\\x00'):len('NTLMSSP\\x00')+4])[0]\n+            messageType = struct.unpack('<L', token[len('NTLMSSP\\x00'):len('NTLMSSP\\x00') + 4])[0]\n \n             if messageType == 0x01:\n                 # NEGOTIATE_MESSAGE\n@@ -2351,45 +2388,48 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                 # Let's store it in the connection data\n                 connData['NEGOTIATE_MESSAGE'] = negotiateMessage\n                 # Let's build the answer flags\n-                # TODO: Parse all the flags. With this we're leaving some clients out \n+                # TODO: Parse all the flags. With this we're leaving some clients out\n \n                 ansFlags = 0\n \n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_56:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56\n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_128:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128\n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH\n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_UNICODE:\n-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE\n+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE\n                 if negotiateMessage['flags'] & ntlm.NTLM_NEGOTIATE_OEM:\n-                   ansFlags |= ntlm.NTLM_NEGOTIATE_OEM\n+                    ansFlags |= ntlm.NTLM_NEGOTIATE_OEM\n \n                 ansFlags |= ntlm.NTLMSSP_NEGOTIATE_VERSION | ntlm.NTLMSSP_NEGOTIATE_TARGET_INFO | ntlm.NTLMSSP_TARGET_TYPE_SERVER | ntlm.NTLMSSP_NEGOTIATE_NTLM | ntlm.NTLMSSP_REQUEST_TARGET\n \n                 # Generate the AV_PAIRS\n                 av_pairs = ntlm.AV_PAIRS()\n                 # TODO: Put the proper data from SMBSERVER config\n-                av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')\n-                av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')\n-                av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (116444736000000000 + calendar.timegm(time.gmtime()) * 10000000) )\n+                av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[\n+                    ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')\n+                av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[\n+                    ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')\n+                av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (\n+                            116444736000000000 + calendar.timegm(time.gmtime()) * 10000000))\n \n                 challengeMessage = ntlm.NTLMAuthChallenge()\n-                challengeMessage['flags']            = ansFlags\n-                challengeMessage['domain_len']       = len(smbServer.getServerDomain().encode('utf-16le'))\n-                challengeMessage['domain_max_len']   = challengeMessage['domain_len']\n-                challengeMessage['domain_offset']    = 40 + 16\n-                challengeMessage['challenge']        = smbServer.getSMBChallenge()\n-                challengeMessage['domain_name']      = smbServer.getServerDomain().encode('utf-16le')\n-                challengeMessage['TargetInfoFields_len']     = len(av_pairs)\n+                challengeMessage['flags'] = ansFlags\n+                challengeMessage['domain_len'] = len(smbServer.getServerDomain().encode('utf-16le'))\n+                challengeMessage['domain_max_len'] = challengeMessage['domain_len']\n+                challengeMessage['domain_offset'] = 40 + 16\n+                challengeMessage['challenge'] = smbServer.getSMBChallenge()\n+                challengeMessage['domain_name'] = smbServer.getServerDomain().encode('utf-16le')\n+                challengeMessage['TargetInfoFields_len'] = len(av_pairs)\n                 challengeMessage['TargetInfoFields_max_len'] = len(av_pairs)\n                 challengeMessage['TargetInfoFields'] = av_pairs\n-                challengeMessage['TargetInfoFields_offset']  = 40 + 16 + len(challengeMessage['domain_name'])\n-                challengeMessage['Version']          = b'\\xff'*8\n-                challengeMessage['VersionLen']       = 8\n+                challengeMessage['TargetInfoFields_offset'] = 40 + 16 + len(challengeMessage['domain_name'])\n+                challengeMessage['Version'] = b'\\xff' * 8\n+                challengeMessage['VersionLen'] = 8\n \n                 if rawNTLM is False:\n                     respToken = SPNEGO_NegTokenResp()\n@@ -2403,7 +2443,7 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n \n                 # Setting the packet to STATUS_MORE_PROCESSING\n                 errorCode = STATUS_MORE_PROCESSING_REQUIRED\n-                # Let's set up an UID for this connection and store it \n+                # Let's set up an UID for this connection and store it\n                 # in the connection's data\n                 # Picking a fixed value\n                 # TODO: Manage more UIDs for the same session\n@@ -2419,9 +2459,9 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                 authenticateMessage = ntlm.NTLMAuthChallengeResponse()\n                 authenticateMessage.fromString(token)\n                 smbServer.log(\"AUTHENTICATE_MESSAGE (%s\\\\%s,%s)\" % (\n-                authenticateMessage['domain_name'].decode('utf-16le'),\n-                authenticateMessage['user_name'].decode('utf-16le'),\n-                authenticateMessage['host_name'].decode('utf-16le')))\n+                    authenticateMessage['domain_name'].decode('utf-16le'),\n+                    authenticateMessage['user_name'].decode('utf-16le'),\n+                    authenticateMessage['host_name'].decode('utf-16le')))\n                 # Do we have credentials to check?\n                 if len(smbServer.getCredentials()) > 0:\n                     identity = authenticateMessage['user_name'].decode('utf-16le').lower()\n@@ -2432,7 +2472,8 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                         uid, lmhash, nthash = smbServer.getCredentials()[identity]\n \n                         errorCode, sessionKey = computeNTLMv2(identity, lmhash, nthash, smbServer.getSMBChallenge(),\n-                                             authenticateMessage, connData['CHALLENGE_MESSAGE'], connData['NEGOTIATE_MESSAGE'])\n+                                                              authenticateMessage, connData['CHALLENGE_MESSAGE'],\n+                                                              connData['NEGOTIATE_MESSAGE'])\n \n                         if sessionKey is not None:\n                             connData['SignatureEnabled'] = False\n@@ -2450,8 +2491,10 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                     # accept-completed\n                     respToken['NegState'] = b'\\x00'\n \n-                    smbServer.log('User %s\\\\%s authenticated successfully' % (authenticateMessage['host_name'].decode('utf-16le'),\n-                                                                              authenticateMessage['user_name'].decode('utf-16le')))\n+                    smbServer.log(\n+                        'User %s\\\\%s authenticated successfully' % (authenticateMessage['host_name'].decode('utf-16le'),\n+                                                                    authenticateMessage['user_name'].decode(\n+                                                                        'utf-16le')))\n                     # Let's store it in the connection data\n                     connData['AUTHENTICATE_MESSAGE'] = authenticateMessage\n                     try:\n@@ -2462,7 +2505,8 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                                                             authenticateMessage['lanman'], authenticateMessage['ntlm'])\n                         smbServer.log(ntlm_hash_data['hash_string'])\n                         if jtr_dump_path != '':\n-                            writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'], jtr_dump_path)\n+                            writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'],\n+                                                  jtr_dump_path)\n                     except:\n                         smbServer.log(\"Could not write NTLM Hashes to the specified JTR_Dump_Path %s\" % jtr_dump_path)\n                 else:\n@@ -2473,13 +2517,13 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n                 raise Exception(\"Unknown NTLMSSP MessageType %d\" % messageType)\n \n             respParameters['SecurityBlobLength'] = len(respToken)\n-            respData['SecurityBlobLength'] = respParameters['SecurityBlobLength'] \n-            respData['SecurityBlob']       = respToken.getData()\n+            respData['SecurityBlobLength'] = respParameters['SecurityBlobLength']\n+            respData['SecurityBlob'] = respToken.getData()\n \n         else:\n             # Process Standard Security\n             respParameters = smb.SMBSessionSetupAndXResponse_Parameters()\n-            respData       = smb.SMBSessionSetupAndXResponse_Data()\n+            respData = smb.SMBSessionSetupAndXResponse_Data()\n             sessionSetupParameters = smb.SMBSessionSetupAndX_Parameters(SMBCommand['Parameters'])\n             sessionSetupData = smb.SMBSessionSetupAndX_Data()\n             sessionSetupData['AnsiPwdLength'] = sessionSetupParameters['AnsiPwdLength']\n@@ -2492,38 +2536,41 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):\n             connData['Uid'] = 10\n             connData['Authenticated'] = True\n             respParameters['Action'] = 0\n-            smbServer.log('User %s\\\\%s authenticated successfully (basic)' % (sessionSetupData['PrimaryDomain'], sessionSetupData['Account']))\n+            smbServer.log('User %s\\\\%s authenticated successfully (basic)' % (\n+            sessionSetupData['PrimaryDomain'], sessionSetupData['Account']))\n             try:\n                 jtr_dump_path = smbServer.getJTRdumpPath()\n-                ntlm_hash_data = outputToJohnFormat( b'', b(sessionSetupData['Account']), b(sessionSetupData['PrimaryDomain']), sessionSetupData['AnsiPwd'], sessionSetupData['UnicodePwd'] )\n+                ntlm_hash_data = outputToJohnFormat(b'', b(sessionSetupData['Account']),\n+                                                    b(sessionSetupData['PrimaryDomain']), sessionSetupData['AnsiPwd'],\n+                                                    sessionSetupData['UnicodePwd'])\n                 smbServer.log(ntlm_hash_data['hash_string'])\n                 if jtr_dump_path != '':\n                     writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'], jtr_dump_path)\n             except:\n                 smbServer.log(\"Could not write NTLM Hashes to the specified JTR_Dump_Path %s\" % jtr_dump_path)\n \n-        respData['NativeOS']     = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n+        respData['NativeOS'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n         respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())\n         respSMBCommand['Parameters'] = respParameters\n-        respSMBCommand['Data']       = respData \n+        respSMBCommand['Data'] = respData\n \n         # From now on, the client can ask for other commands\n         connData['Authenticated'] = True\n         # For now, just switching to nobody\n-        #os.setregid(65534,65534)\n-        #os.setreuid(65534,65534)\n+        # os.setregid(65534,65534)\n+        # os.setreuid(65534,65534)\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n \n     @staticmethod\n-    def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket ):\n-        connData = smbServer.getConnectionData(connId, checkStatus = False)\n+    def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket):\n+        connData = smbServer.getConnectionData(connId, checkStatus=False)\n         connData['Pid'] = recvPacket['Pid']\n \n         SMBCommand = smb.SMBCommand(recvPacket['Data'][0])\n         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_NEGOTIATE)\n-        \n+\n         resp = smb.NewSMBPacket()\n         resp['Flags1'] = smb.SMB.FLAGS1_REPLY\n         resp['Pid'] = connData['Pid']\n@@ -2532,108 +2579,107 @@ def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket ):\n \n         # TODO: We support more dialects, and parse them accordingly\n         dialects = SMBCommand['Data'].split(b'\\x02')\n-        try: \n-           index = dialects.index(b'NT LM 0.12\\x00') - 1\n-           # Let's fill the data for NTLM\n-           if recvPacket['Flags2'] & smb.SMB.FLAGS2_EXTENDED_SECURITY:\n-                    resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE\n-                    #resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS \n-                    _dialects_data = smb.SMBExtended_Security_Data()\n-                    _dialects_data['ServerGUID'] = b'A'*16\n-                    blob = SPNEGO_NegTokenInit()\n-                    blob['MechTypes'] = [TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']]\n-                    _dialects_data['SecurityBlob'] = blob.getData()\n-        \n-                    _dialects_parameters = smb.SMBExtended_Security_Parameters()\n-                    _dialects_parameters['Capabilities']    = smb.SMB.CAP_EXTENDED_SECURITY | smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS | smb.SMB.CAP_UNICODE \n-                    _dialects_parameters['ChallengeLength'] = 0\n-\n-           else:\n-                    resp['Flags2'] = smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE\n-                    _dialects_parameters = smb.SMBNTLMDialect_Parameters()\n-                    _dialects_data= smb.SMBNTLMDialect_Data()\n-                    _dialects_data['Payload'] = ''\n-                    if 'EncryptionKey' in connData:\n-                        _dialects_data['Challenge'] = connData['EncryptionKey']\n-                        _dialects_parameters['ChallengeLength'] = len(_dialects_data.getData())\n-                    else:\n-                        # TODO: Handle random challenges, now one that can be used with rainbow tables\n-                        _dialects_data['Challenge'] = b'\\x11\\x22\\x33\\x44\\x55\\x66\\x77\\x88'\n-                        _dialects_parameters['ChallengeLength'] = 8\n-                    _dialects_parameters['Capabilities']    = smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS \n-\n-           # Let's see if we need to support RPC_REMOTE_APIS\n-           config = smbServer.getServerConfig()\n-           if config.has_option('global','rpc_apis'):\n-               if config.getboolean('global', 'rpc_apis') is True:\n-                  _dialects_parameters['Capabilities'] |= smb.SMB.CAP_RPC_REMOTE_APIS\n-\n-           _dialects_parameters['DialectIndex']    = index\n-           #_dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER | smb.SMB.SECURITY_SIGNATURES_REQUIRED\n-           _dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER\n-           _dialects_parameters['MaxMpxCount']     = 1\n-           _dialects_parameters['MaxNumberVcs']    = 1\n-           _dialects_parameters['MaxBufferSize']   = 64000\n-           _dialects_parameters['MaxRawSize']      = 65536\n-           _dialects_parameters['SessionKey']      = 0\n-           _dialects_parameters['LowDateTime']     = 0\n-           _dialects_parameters['HighDateTime']    = 0\n-           _dialects_parameters['ServerTimeZone']  = 0 \n-\n-\n-           respSMBCommand['Data']           = _dialects_data\n-           respSMBCommand['Parameters']     = _dialects_parameters\n-           connData['_dialects_data']       = _dialects_data\n-           connData['_dialects_parameters'] = _dialects_parameters\n+        try:\n+            index = dialects.index(b'NT LM 0.12\\x00') - 1\n+            # Let's fill the data for NTLM\n+            if recvPacket['Flags2'] & smb.SMB.FLAGS2_EXTENDED_SECURITY:\n+                resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE\n+                # resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS\n+                _dialects_data = smb.SMBExtended_Security_Data()\n+                _dialects_data['ServerGUID'] = b'A' * 16\n+                blob = SPNEGO_NegTokenInit()\n+                blob['MechTypes'] = [TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']]\n+                _dialects_data['SecurityBlob'] = blob.getData()\n+\n+                _dialects_parameters = smb.SMBExtended_Security_Parameters()\n+                _dialects_parameters[\n+                    'Capabilities'] = smb.SMB.CAP_EXTENDED_SECURITY | smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS | smb.SMB.CAP_UNICODE\n+                _dialects_parameters['ChallengeLength'] = 0\n+\n+            else:\n+                resp['Flags2'] = smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE\n+                _dialects_parameters = smb.SMBNTLMDialect_Parameters()\n+                _dialects_data = smb.SMBNTLMDialect_Data()\n+                _dialects_data['Payload'] = ''\n+                if 'EncryptionKey' in connData:\n+                    _dialects_data['Challenge'] = connData['EncryptionKey']\n+                    _dialects_parameters['ChallengeLength'] = len(_dialects_data.getData())\n+                else:\n+                    # TODO: Handle random challenges, now one that can be used with rainbow tables\n+                    _dialects_data['Challenge'] = b'\\x11\\x22\\x33\\x44\\x55\\x66\\x77\\x88'\n+                    _dialects_parameters['ChallengeLength'] = 8\n+                _dialects_parameters['Capabilities'] = smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS\n+\n+                # Let's see if we need to support RPC_REMOTE_APIS\n+            config = smbServer.getServerConfig()\n+            if config.has_option('global', 'rpc_apis'):\n+                if config.getboolean('global', 'rpc_apis') is True:\n+                    _dialects_parameters['Capabilities'] |= smb.SMB.CAP_RPC_REMOTE_APIS\n+\n+            _dialects_parameters['DialectIndex'] = index\n+            # _dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER | smb.SMB.SECURITY_SIGNATURES_REQUIRED\n+            _dialects_parameters['SecurityMode'] = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER\n+            _dialects_parameters['MaxMpxCount'] = 1\n+            _dialects_parameters['MaxNumberVcs'] = 1\n+            _dialects_parameters['MaxBufferSize'] = 64000\n+            _dialects_parameters['MaxRawSize'] = 65536\n+            _dialects_parameters['SessionKey'] = 0\n+            _dialects_parameters['LowDateTime'] = 0\n+            _dialects_parameters['HighDateTime'] = 0\n+            _dialects_parameters['ServerTimeZone'] = 0\n+\n+            respSMBCommand['Data'] = _dialects_data\n+            respSMBCommand['Parameters'] = _dialects_parameters\n+            connData['_dialects_data'] = _dialects_data\n+            connData['_dialects_parameters'] = _dialects_parameters\n \n         except Exception as e:\n-           # No NTLM throw an error\n-           smbServer.log('smbComNegotiate: %s' % e, logging.ERROR)\n-           respSMBCommand['Data'] = struct.pack('<H',0xffff) \n+            # No NTLM throw an error\n+            smbServer.log('smbComNegotiate: %s' % e, logging.ERROR)\n+            respSMBCommand['Data'] = struct.pack('<H', 0xffff)\n \n-       \n         smbServer.setConnectionData(connId, connData)\n \n         resp.addCommand(respSMBCommand)\n-        \n+\n         return None, [resp], STATUS_SUCCESS\n \n     @staticmethod\n     def default(connId, smbServer, SMBCommand, recvPacket):\n         # By default we return an SMB Packet with error not implemented\n-        smbServer.log(\"Not implemented command: 0x%x\" % recvPacket['Command'],logging.DEBUG)\n+        smbServer.log(\"Not implemented command: 0x%x\" % recvPacket['Command'], logging.DEBUG)\n         packet = smb.NewSMBPacket()\n-        packet['Flags1']  = smb.SMB.FLAGS1_REPLY\n-        packet['Flags2']  = smb.SMB.FLAGS2_NT_STATUS \n+        packet['Flags1'] = smb.SMB.FLAGS1_REPLY\n+        packet['Flags2'] = smb.SMB.FLAGS2_NT_STATUS\n         packet['Command'] = recvPacket['Command']\n-        packet['Pid']     = recvPacket['Pid']\n-        packet['Tid']     = recvPacket['Tid']\n-        packet['Mid']     = recvPacket['Mid']\n-        packet['Uid']     = recvPacket['Uid']\n-        packet['Data']    = b'\\x00\\x00\\x00'\n+        packet['Pid'] = recvPacket['Pid']\n+        packet['Tid'] = recvPacket['Tid']\n+        packet['Mid'] = recvPacket['Mid']\n+        packet['Uid'] = recvPacket['Uid']\n+        packet['Data'] = b'\\x00\\x00\\x00'\n         errorCode = STATUS_NOT_IMPLEMENTED\n-        packet['ErrorCode']   = errorCode >> 16\n-        packet['ErrorClass']  = errorCode & 0xff\n+        packet['ErrorCode'] = errorCode >> 16\n+        packet['ErrorClass'] = errorCode & 0xff\n \n         return None, [packet], errorCode\n \n+\n class SMB2Commands:\n     @staticmethod\n-    def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n-        connData = smbServer.getConnectionData(connId, checkStatus = False)\n+    def smb2Negotiate(connId, smbServer, recvPacket, isSMB1=False):\n+        connData = smbServer.getConnectionData(connId, checkStatus=False)\n \n         respPacket = smb2.SMB2Packet()\n-        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n-        respPacket['Status']    = STATUS_SUCCESS\n+        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n+        respPacket['Status'] = STATUS_SUCCESS\n         respPacket['CreditRequestResponse'] = 1\n-        respPacket['Command']   = smb2.SMB2_NEGOTIATE\n+        respPacket['Command'] = smb2.SMB2_NEGOTIATE\n         respPacket['SessionID'] = 0\n         if isSMB1 is False:\n             respPacket['MessageID'] = recvPacket['MessageID']\n         else:\n             respPacket['MessageID'] = 0\n-        respPacket['TreeID']    = 0\n-\n+        respPacket['TreeID'] = 0\n \n         respSMBCommand = smb2.SMB2Negotiate_Response()\n \n@@ -2641,7 +2687,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n         if isSMB1 is True:\n             # Let's first parse the packet to see if the client supports SMB2\n             SMBCommand = smb.SMBCommand(recvPacket['Data'][0])\n-        \n+\n             dialects = SMBCommand['Data'].split(b'\\x02')\n             if b'SMB 2.002\\x00' in dialects or b'SMB 2.???\\x00' in dialects:\n                 respSMBCommand['DialectRevision'] = smb2.SMB2_DIALECT_002\n@@ -2650,7 +2696,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n                 raise Exception('SMB2 not supported, fallbacking')\n         else:\n             respSMBCommand['DialectRevision'] = smb2.SMB2_DIALECT_002\n-        respSMBCommand['ServerGuid'] = b'A'*16\n+        respSMBCommand['ServerGuid'] = b'A' * 16\n         respSMBCommand['Capabilities'] = 0\n         respSMBCommand['MaxTransactSize'] = 65536\n         respSMBCommand['MaxReadSize'] = 65536\n@@ -2665,7 +2711,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n         respSMBCommand['Buffer'] = blob.getData()\n         respSMBCommand['SecurityBufferLength'] = len(respSMBCommand['Buffer'])\n \n-        respPacket['Data']      = respSMBCommand\n+        respPacket['Data'] = respSMBCommand\n \n         smbServer.setConnectionData(connId, connData)\n \n@@ -2673,7 +2719,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):\n \n     @staticmethod\n     def smb2SessionSetup(connId, smbServer, recvPacket):\n-        connData = smbServer.getConnectionData(connId, checkStatus = False)\n+        connData = smbServer.getConnectionData(connId, checkStatus=False)\n \n         respSMBCommand = smb2.SMB2SessionSetup_Response()\n \n@@ -2684,41 +2730,41 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n         securityBlob = sessionSetupData['Buffer']\n \n         rawNTLM = False\n-        if struct.unpack('B',securityBlob[0:1])[0] == ASN1_AID:\n-           # NEGOTIATE packet\n-           blob =  SPNEGO_NegTokenInit(securityBlob)\n-           token = blob['MechToken']\n-           if len(blob['MechTypes'][0]) > 0:\n-               # Is this GSSAPI NTLM or something else we don't support?\n-               mechType = blob['MechTypes'][0]\n-               if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:\n-                   # Nope, do we know it?\n-                   if mechType in MechTypes:\n-                       mechStr = MechTypes[mechType]\n-                   else:\n-                       mechStr = hexlify(mechType)\n-                   smbServer.log(\"Unsupported MechType '%s'\" % mechStr, logging.CRITICAL)\n-                   # We don't know the token, we answer back again saying \n-                   # we just support NTLM.\n-                   # ToDo: Build this into a SPNEGO_NegTokenResp()\n-                   respToken = b'\\xa1\\x15\\x30\\x13\\xa0\\x03\\x0a\\x01\\x03\\xa1\\x0c\\x06\\x0a\\x2b\\x06\\x01\\x04\\x01\\x82\\x37\\x02\\x02\\x0a'\n-                   respSMBCommand['SecurityBufferOffset'] = 0x48\n-                   respSMBCommand['SecurityBufferLength'] = len(respToken)\n-                   respSMBCommand['Buffer'] = respToken\n-\n-                   return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED\n-        elif struct.unpack('B',securityBlob[0:1])[0] == ASN1_SUPPORTED_MECH:\n-           # AUTH packet\n-           blob = SPNEGO_NegTokenResp(securityBlob)\n-           token = blob['ResponseToken']\n+        if struct.unpack('B', securityBlob[0:1])[0] == ASN1_AID:\n+            # NEGOTIATE packet\n+            blob = SPNEGO_NegTokenInit(securityBlob)\n+            token = blob['MechToken']\n+            if len(blob['MechTypes'][0]) > 0:\n+                # Is this GSSAPI NTLM or something else we don't support?\n+                mechType = blob['MechTypes'][0]\n+                if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:\n+                    # Nope, do we know it?\n+                    if mechType in MechTypes:\n+                        mechStr = MechTypes[mechType]\n+                    else:\n+                        mechStr = hexlify(mechType)\n+                    smbServer.log(\"Unsupported MechType '%s'\" % mechStr, logging.CRITICAL)\n+                    # We don't know the token, we answer back again saying\n+                    # we just support NTLM.\n+                    # ToDo: Build this into a SPNEGO_NegTokenResp()\n+                    respToken = b'\\xa1\\x15\\x30\\x13\\xa0\\x03\\x0a\\x01\\x03\\xa1\\x0c\\x06\\x0a\\x2b\\x06\\x01\\x04\\x01\\x82\\x37\\x02\\x02\\x0a'\n+                    respSMBCommand['SecurityBufferOffset'] = 0x48\n+                    respSMBCommand['SecurityBufferLength'] = len(respToken)\n+                    respSMBCommand['Buffer'] = respToken\n+\n+                    return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED\n+        elif struct.unpack('B', securityBlob[0:1])[0] == ASN1_SUPPORTED_MECH:\n+            # AUTH packet\n+            blob = SPNEGO_NegTokenResp(securityBlob)\n+            token = blob['ResponseToken']\n         else:\n-           # No GSSAPI stuff, raw NTLMSSP\n-           rawNTLM = True\n-           token = securityBlob\n+            # No GSSAPI stuff, raw NTLMSSP\n+            rawNTLM = True\n+            token = securityBlob\n \n-        # Here we only handle NTLMSSP, depending on what stage of the \n+        # Here we only handle NTLMSSP, depending on what stage of the\n         # authentication we are, we act on it\n-        messageType = struct.unpack('<L',token[len('NTLMSSP\\x00'):len('NTLMSSP\\x00')+4])[0]\n+        messageType = struct.unpack('<L', token[len('NTLMSSP\\x00'):len('NTLMSSP\\x00') + 4])[0]\n \n         if messageType == 0x01:\n             # NEGOTIATE_MESSAGE\n@@ -2727,45 +2773,48 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n             # Let's store it in the connection data\n             connData['NEGOTIATE_MESSAGE'] = negotiateMessage\n             # Let's build the answer flags\n-            # TODO: Parse all the flags. With this we're leaving some clients out \n+            # TODO: Parse all the flags. With this we're leaving some clients out\n \n             ansFlags = 0\n \n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_56:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56\n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_128:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128\n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH\n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY\n             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_UNICODE:\n-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE\n+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE\n             if negotiateMessage['flags'] & ntlm.NTLM_NEGOTIATE_OEM:\n-               ansFlags |= ntlm.NTLM_NEGOTIATE_OEM\n+                ansFlags |= ntlm.NTLM_NEGOTIATE_OEM\n \n             ansFlags |= ntlm.NTLMSSP_NEGOTIATE_VERSION | ntlm.NTLMSSP_NEGOTIATE_TARGET_INFO | ntlm.NTLMSSP_TARGET_TYPE_SERVER | ntlm.NTLMSSP_NEGOTIATE_NTLM | ntlm.NTLMSSP_REQUEST_TARGET\n \n             # Generate the AV_PAIRS\n             av_pairs = ntlm.AV_PAIRS()\n             # TODO: Put the proper data from SMBSERVER config\n-            av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')\n-            av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')\n-            av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (116444736000000000 + calendar.timegm(time.gmtime()) * 10000000) )\n+            av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[\n+                ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')\n+            av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[\n+                ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')\n+            av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (\n+                        116444736000000000 + calendar.timegm(time.gmtime()) * 10000000))\n \n             challengeMessage = ntlm.NTLMAuthChallenge()\n-            challengeMessage['flags']            = ansFlags\n-            challengeMessage['domain_len']       = len(smbServer.getServerDomain().encode('utf-16le'))\n-            challengeMessage['domain_max_len']   = challengeMessage['domain_len']\n-            challengeMessage['domain_offset']    = 40 + 16\n-            challengeMessage['challenge']        = smbServer.getSMBChallenge()\n-            challengeMessage['domain_name']      = smbServer.getServerDomain().encode('utf-16le')\n-            challengeMessage['TargetInfoFields_len']     = len(av_pairs)\n+            challengeMessage['flags'] = ansFlags\n+            challengeMessage['domain_len'] = len(smbServer.getServerDomain().encode('utf-16le'))\n+            challengeMessage['domain_max_len'] = challengeMessage['domain_len']\n+            challengeMessage['domain_offset'] = 40 + 16\n+            challengeMessage['challenge'] = smbServer.getSMBChallenge()\n+            challengeMessage['domain_name'] = smbServer.getServerDomain().encode('utf-16le')\n+            challengeMessage['TargetInfoFields_len'] = len(av_pairs)\n             challengeMessage['TargetInfoFields_max_len'] = len(av_pairs)\n             challengeMessage['TargetInfoFields'] = av_pairs\n-            challengeMessage['TargetInfoFields_offset']  = 40 + 16 + len(challengeMessage['domain_name'])\n-            challengeMessage['Version']          = b'\\xff'*8\n-            challengeMessage['VersionLen']       = 8\n+            challengeMessage['TargetInfoFields_offset'] = 40 + 16 + len(challengeMessage['domain_name'])\n+            challengeMessage['Version'] = b'\\xff' * 8\n+            challengeMessage['VersionLen'] = 8\n \n             if rawNTLM is False:\n                 respToken = SPNEGO_NegTokenResp()\n@@ -2779,11 +2828,11 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n \n             # Setting the packet to STATUS_MORE_PROCESSING\n             errorCode = STATUS_MORE_PROCESSING_REQUIRED\n-            # Let's set up an UID for this connection and store it \n+            # Let's set up an UID for this connection and store it\n             # in the connection's data\n             # Picking a fixed value\n             # TODO: Manage more UIDs for the same session\n-            connData['Uid'] = random.randint(1,0xffffffff)\n+            connData['Uid'] = random.randint(1, 0xffffffff)\n             # Let's store it in the connection data\n             connData['CHALLENGE_MESSAGE'] = challengeMessage\n \n@@ -2795,8 +2844,9 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n             authenticateMessage = ntlm.NTLMAuthChallengeResponse()\n             authenticateMessage.fromString(token)\n             smbServer.log(\"AUTHENTICATE_MESSAGE (%s\\\\%s,%s)\" % (\n-            authenticateMessage['domain_name'].decode('utf-16le'), authenticateMessage['user_name'].decode('utf-16le'),\n-            authenticateMessage['host_name'].decode('utf-16le')))\n+                authenticateMessage['domain_name'].decode('utf-16le'),\n+                authenticateMessage['user_name'].decode('utf-16le'),\n+                authenticateMessage['host_name'].decode('utf-16le')))\n             # TODO: Check the credentials! Now granting permissions\n             # Do we have credentials to check?\n             if len(smbServer.getCredentials()) > 0:\n@@ -2829,7 +2879,8 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n                 # accept-completed\n                 respToken['NegState'] = b'\\x00'\n                 smbServer.log('User %s\\\\%s authenticated successfully' % (\n-                authenticateMessage['host_name'].decode('utf-16le'), authenticateMessage['user_name'].decode('utf-16le')))\n+                    authenticateMessage['host_name'].decode('utf-16le'),\n+                    authenticateMessage['user_name'].decode('utf-16le')))\n                 # Let's store it in the connection data\n                 connData['AUTHENTICATE_MESSAGE'] = authenticateMessage\n                 try:\n@@ -2862,8 +2913,8 @@ def smb2SessionSetup(connId, smbServer, recvPacket):\n         # From now on, the client can ask for other commands\n         connData['Authenticated'] = True\n         # For now, just switching to nobody\n-        #os.setregid(65534,65534)\n-        #os.setreuid(65534,65534)\n+        # os.setregid(65534,65534)\n+        # os.setreuid(65534,65534)\n         smbServer.setConnectionData(connId, connData)\n \n         return [respSMBCommand], None, errorCode\n@@ -2873,16 +2924,16 @@ def smb2TreeConnect(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respPacket = smb2.SMB2Packet()\n-        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n-        respPacket['Status']    = STATUS_SUCCESS\n+        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n+        respPacket['Status'] = STATUS_SUCCESS\n         respPacket['CreditRequestResponse'] = 1\n-        respPacket['Command']   = recvPacket['Command']\n+        respPacket['Command'] = recvPacket['Command']\n         respPacket['SessionID'] = connData['Uid']\n-        respPacket['Reserved']  = recvPacket['Reserved']\n+        respPacket['Reserved'] = recvPacket['Reserved']\n         respPacket['MessageID'] = recvPacket['MessageID']\n-        respPacket['TreeID']    = recvPacket['TreeID']\n+        respPacket['TreeID'] = recvPacket['TreeID']\n \n-        respSMBCommand        = smb2.SMB2TreeConnect_Response()\n+        respSMBCommand = smb2.SMB2TreeConnect_Response()\n \n         treeConnectRequest = smb2.SMB2TreeConnect(recvPacket['Data'])\n \n@@ -2902,13 +2953,13 @@ def smb2TreeConnect(connId, smbServer, recvPacket):\n         if share is not None:\n             # Simple way to generate a Tid\n             if len(connData['ConnectedShares']) == 0:\n-               tid = 1\n+                tid = 1\n             else:\n-               tid = list(connData['ConnectedShares'].keys())[-1] + 1\n+                tid = list(connData['ConnectedShares'].keys())[-1] + 1\n             connData['ConnectedShares'][tid] = share\n             connData['ConnectedShares'][tid]['shareName'] = path\n-            respPacket['TreeID']    = tid\n-            smbServer.log(\"Connecting Share(%d:%s)\" % (tid,path))\n+            respPacket['TreeID'] = tid\n+            smbServer.log(\"Connecting Share(%d:%s)\" % (tid, path))\n         else:\n             smbServer.log(\"SMB2_TREE_CONNECT not found %s\" % path, logging.ERROR)\n             errorCode = STATUS_OBJECT_PATH_NOT_FOUND\n@@ -2938,104 +2989,111 @@ def smb2TreeConnect(connId, smbServer, recvPacket):\n     def smb2Create(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb2.SMB2Create_Response()\n+        respSMBCommand = smb2.SMB2Create_Response()\n \n-        ntCreateRequest       = smb2.SMB2Create(recvPacket['Data'])\n+        ntCreateRequest = smb2.SMB2Create(recvPacket['Data'])\n \n         respSMBCommand['Buffer'] = b'\\x00'\n         # Get the Tid associated\n         if recvPacket['TreeID'] in connData['ConnectedShares']:\n-             # If we have a rootFid, the path is relative to that fid\n-             errorCode = STATUS_SUCCESS\n-             if 'path' in connData['ConnectedShares'][recvPacket['TreeID']]:\n-                 path = connData['ConnectedShares'][recvPacket['TreeID']]['path']\n-             else:\n-                 path = 'NONE'\n-                 errorCode = STATUS_ACCESS_DENIED\n-\n-             deleteOnClose = False\n-\n-             fileName = os.path.normpath(ntCreateRequest['Buffer'][:ntCreateRequest['NameLength']].decode('utf-16le').replace('\\\\','\/'))\n-             if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n+            # If we have a rootFid, the path is relative to that fid\n+            errorCode = STATUS_SUCCESS\n+            if 'path' in connData['ConnectedShares'][recvPacket['TreeID']]:\n+                path = connData['ConnectedShares'][recvPacket['TreeID']]['path']\n+            else:\n+                path = 'NONE'\n+                errorCode = STATUS_ACCESS_DENIED\n+\n+            deleteOnClose = False\n+\n+            fileName = os.path.normpath(\n+                ntCreateRequest['Buffer'][:ntCreateRequest['NameLength']].decode('utf-16le').replace('\\\\', '\/'))\n+            if len(fileName) > 0 and (fileName[0] == '\/' or fileName[0] == '\\\\'):\n                 # strip leading '\/'\n                 fileName = fileName[1:]\n-             pathName = os.path.join(path,fileName)\n-             createDisposition = ntCreateRequest['CreateDisposition']\n-             mode = 0\n-\n-             if createDisposition == smb2.FILE_SUPERSEDE:\n-                 mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb2.FILE_OVERWRITE_IF == smb2.FILE_OVERWRITE_IF:\n-                 mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb2.FILE_OVERWRITE == smb2.FILE_OVERWRITE:\n-                 if os.path.exists(pathName) is True:\n-                     mode |= os.O_TRUNC \n-                 else:\n-                     errorCode = STATUS_NO_SUCH_FILE\n-             elif createDisposition & smb2.FILE_OPEN_IF == smb2.FILE_OPEN_IF:\n-                 if os.path.exists(pathName) is True:\n-                     mode |= os.O_TRUNC \n-                 else:\n-                     mode |= os.O_TRUNC | os.O_CREAT\n-             elif createDisposition & smb2.FILE_CREATE == smb2.FILE_CREATE:\n-                 if os.path.exists(pathName) is True:\n-                     errorCode = STATUS_OBJECT_NAME_COLLISION\n-                 else:\n-                     mode |= os.O_CREAT\n-             elif createDisposition & smb2.FILE_OPEN == smb2.FILE_OPEN:\n-                 if os.path.exists(pathName) is not True and (str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:\n-                     errorCode = STATUS_NO_SUCH_FILE\n-\n-             if errorCode == STATUS_SUCCESS:\n-                 desiredAccess = ntCreateRequest['DesiredAccess']\n-                 if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):\n-                     mode |= os.O_RDONLY\n-                 if (desiredAccess & smb2.FILE_WRITE_DATA) or (desiredAccess & smb2.GENERIC_WRITE):\n-                     if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):\n-                         mode |= os.O_RDWR #| os.O_APPEND\n-                     else: \n-                         mode |= os.O_WRONLY #| os.O_APPEND\n-                 if desiredAccess & smb2.GENERIC_ALL:\n-                     mode |= os.O_RDWR #| os.O_APPEND\n-\n-                 createOptions =  ntCreateRequest['CreateOptions']\n-                 if mode & os.O_CREAT == os.O_CREAT:\n-                     if createOptions & smb2.FILE_DIRECTORY_FILE == smb2.FILE_DIRECTORY_FILE: \n-                         try:\n-                             # Let's create the directory\n-                             os.mkdir(pathName)\n-                             mode = os.O_RDONLY\n-                         except Exception as e:\n-                             smbServer.log(\"SMB2_CREATE: %s,%s,%s\" % (pathName,mode,e),logging.ERROR)\n-                             errorCode = STATUS_ACCESS_DENIED\n-                 if createOptions & smb2.FILE_NON_DIRECTORY_FILE == smb2.FILE_NON_DIRECTORY_FILE:\n-                     # If the file being opened is a directory, the server MUST fail the request with\n-                     # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server\n-                     # response.\n-                     if os.path.isdir(pathName) is True:\n+\n+            if not isInFileJail(path, fileName):\n+                LOG.error(\"Path not in current working directory\")\n+                return [smb2.SMB2Error()], None, STATUS_ACCESS_DENIED\n+\n+            pathName = os.path.join(path, fileName)\n+            createDisposition = ntCreateRequest['CreateDisposition']\n+            mode = 0\n+\n+            if createDisposition == smb2.FILE_SUPERSEDE:\n+                mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb2.FILE_OVERWRITE_IF == smb2.FILE_OVERWRITE_IF:\n+                mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb2.FILE_OVERWRITE == smb2.FILE_OVERWRITE:\n+                if os.path.exists(pathName) is True:\n+                    mode |= os.O_TRUNC\n+                else:\n+                    errorCode = STATUS_NO_SUCH_FILE\n+            elif createDisposition & smb2.FILE_OPEN_IF == smb2.FILE_OPEN_IF:\n+                if os.path.exists(pathName) is True:\n+                    mode |= os.O_TRUNC\n+                else:\n+                    mode |= os.O_TRUNC | os.O_CREAT\n+            elif createDisposition & smb2.FILE_CREATE == smb2.FILE_CREATE:\n+                if os.path.exists(pathName) is True:\n+                    errorCode = STATUS_OBJECT_NAME_COLLISION\n+                else:\n+                    mode |= os.O_CREAT\n+            elif createDisposition & smb2.FILE_OPEN == smb2.FILE_OPEN:\n+                if os.path.exists(pathName) is not True and (\n+                        str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:\n+                    errorCode = STATUS_NO_SUCH_FILE\n+\n+            if errorCode == STATUS_SUCCESS:\n+                desiredAccess = ntCreateRequest['DesiredAccess']\n+                if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):\n+                    mode |= os.O_RDONLY\n+                if (desiredAccess & smb2.FILE_WRITE_DATA) or (desiredAccess & smb2.GENERIC_WRITE):\n+                    if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):\n+                        mode |= os.O_RDWR  # | os.O_APPEND\n+                    else:\n+                        mode |= os.O_WRONLY  # | os.O_APPEND\n+                if desiredAccess & smb2.GENERIC_ALL:\n+                    mode |= os.O_RDWR  # | os.O_APPEND\n+\n+                createOptions = ntCreateRequest['CreateOptions']\n+                if mode & os.O_CREAT == os.O_CREAT:\n+                    if createOptions & smb2.FILE_DIRECTORY_FILE == smb2.FILE_DIRECTORY_FILE:\n+                        try:\n+                            # Let's create the directory\n+                            os.mkdir(pathName)\n+                            mode = os.O_RDONLY\n+                        except Exception as e:\n+                            smbServer.log(\"SMB2_CREATE: %s,%s,%s\" % (pathName, mode, e), logging.ERROR)\n+                            errorCode = STATUS_ACCESS_DENIED\n+                if createOptions & smb2.FILE_NON_DIRECTORY_FILE == smb2.FILE_NON_DIRECTORY_FILE:\n+                    # If the file being opened is a directory, the server MUST fail the request with\n+                    # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server\n+                    # response.\n+                    if os.path.isdir(pathName) is True:\n                         errorCode = STATUS_FILE_IS_A_DIRECTORY\n \n-                 if createOptions & smb2.FILE_DELETE_ON_CLOSE == smb2.FILE_DELETE_ON_CLOSE:\n-                     deleteOnClose = True\n-                 \n-                 if errorCode == STATUS_SUCCESS:\n-                     try:\n-                         if os.path.isdir(pathName) and sys.platform == 'win32':\n+                if createOptions & smb2.FILE_DELETE_ON_CLOSE == smb2.FILE_DELETE_ON_CLOSE:\n+                    deleteOnClose = True\n+\n+                if errorCode == STATUS_SUCCESS:\n+                    try:\n+                        if os.path.isdir(pathName) and sys.platform == 'win32':\n                             fid = VOID_FILE_DESCRIPTOR\n-                         else:\n+                        else:\n                             if sys.platform == 'win32':\n-                               mode |= os.O_BINARY\n+                                mode |= os.O_BINARY\n                             if str(pathName) in smbServer.getRegisteredNamedPipes():\n                                 fid = PIPE_FILE_DESCRIPTOR\n                                 sock = socket.socket()\n                                 sock.connect(smbServer.getRegisteredNamedPipes()[str(pathName)])\n                             else:\n                                 fid = os.open(pathName, mode)\n-                     except Exception as e:\n-                         smbServer.log(\"SMB2_CREATE: %s,%s,%s\" % (pathName,mode,e),logging.ERROR)\n-                         #print e\n-                         fid = 0\n-                         errorCode = STATUS_ACCESS_DENIED\n+                    except Exception as e:\n+                        smbServer.log(\"SMB2_CREATE: %s,%s,%s\" % (pathName, mode, e), logging.ERROR)\n+                        # print e\n+                        fid = 0\n+                        errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n@@ -3047,12 +3105,12 @@ def smb2Create(connId, smbServer, recvPacket):\n             respSMBCommand['CreateAction'] = createDisposition\n \n             if fid == PIPE_FILE_DESCRIPTOR:\n-                respSMBCommand['CreationTime']   = 0\n+                respSMBCommand['CreationTime'] = 0\n                 respSMBCommand['LastAccessTime'] = 0\n-                respSMBCommand['LastWriteTime']  = 0\n-                respSMBCommand['ChangeTime']     = 0\n+                respSMBCommand['LastWriteTime'] = 0\n+                respSMBCommand['ChangeTime'] = 0\n                 respSMBCommand['AllocationSize'] = 4096\n-                respSMBCommand['EndOfFile']      = 0\n+                respSMBCommand['EndOfFile'] = 0\n                 respSMBCommand['FileAttributes'] = 0x80\n \n             else:\n@@ -3061,15 +3119,15 @@ def smb2Create(connId, smbServer, recvPacket):\n                 else:\n                     respSMBCommand['FileAttributes'] = ntCreateRequest['FileAttributes']\n                 # Let's get this file's information\n-                respInfo, errorCode = queryPathInformation('',pathName,level= smb.SMB_QUERY_FILE_ALL_INFO)\n+                respInfo, errorCode = queryPathInformation('', pathName, level=smb.SMB_QUERY_FILE_ALL_INFO)\n                 if errorCode == STATUS_SUCCESS:\n-                    respSMBCommand['CreationTime']   = respInfo['CreationTime']\n+                    respSMBCommand['CreationTime'] = respInfo['CreationTime']\n                     respSMBCommand['LastAccessTime'] = respInfo['LastAccessTime']\n-                    respSMBCommand['LastWriteTime']  = respInfo['LastWriteTime']\n+                    respSMBCommand['LastWriteTime'] = respInfo['LastWriteTime']\n                     respSMBCommand['LastChangeTime'] = respInfo['LastChangeTime']\n                     respSMBCommand['FileAttributes'] = respInfo['ExtFileAttributes']\n                     respSMBCommand['AllocationSize'] = respInfo['AllocationSize']\n-                    respSMBCommand['EndOfFile']      = respInfo['EndOfFile']\n+                    respSMBCommand['EndOfFile'] = respInfo['EndOfFile']\n \n             if errorCode == STATUS_SUCCESS:\n                 # Let's store the fid for the connection\n@@ -3077,15 +3135,15 @@ def smb2Create(connId, smbServer, recvPacket):\n                 connData['OpenedFiles'][fakefid] = {}\n                 connData['OpenedFiles'][fakefid]['FileHandle'] = fid\n                 connData['OpenedFiles'][fakefid]['FileName'] = pathName\n-                connData['OpenedFiles'][fakefid]['DeleteOnClose']  = deleteOnClose\n-                connData['OpenedFiles'][fakefid]['Open']  = {}\n+                connData['OpenedFiles'][fakefid]['DeleteOnClose'] = deleteOnClose\n+                connData['OpenedFiles'][fakefid]['Open'] = {}\n                 connData['OpenedFiles'][fakefid]['Open']['EnumerationLocation'] = 0\n                 connData['OpenedFiles'][fakefid]['Open']['EnumerationSearchPattern'] = ''\n                 if fid == PIPE_FILE_DESCRIPTOR:\n                     connData['OpenedFiles'][fakefid]['Socket'] = sock\n         else:\n             respSMBCommand = smb2.SMB2Error()\n-        \n+\n         if errorCode == STATUS_SUCCESS:\n             connData['LastRequest']['SMB2_CREATE'] = respSMBCommand\n         smbServer.setConnectionData(connId, connData)\n@@ -3096,13 +3154,13 @@ def smb2Create(connId, smbServer, recvPacket):\n     def smb2Close(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb2.SMB2Close_Response()\n+        respSMBCommand = smb2.SMB2Close_Response()\n \n         closeRequest = smb2.SMB2Close(recvPacket['Data'])\n \n-        if closeRequest['FileID'].getData() == b'\\xff'*16:\n+        if closeRequest['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = closeRequest['FileID'].getData()\n@@ -3110,42 +3168,43 @@ def smb2Close(connId, smbServer, recvPacket):\n             fileID = closeRequest['FileID'].getData()\n \n         if fileID in connData['OpenedFiles']:\n-             errorCode = STATUS_SUCCESS\n-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n-             pathName = connData['OpenedFiles'][fileID]['FileName']\n-             infoRecord = None\n-             try:\n-                 if fileHandle == PIPE_FILE_DESCRIPTOR:\n-                     connData['OpenedFiles'][fileID]['Socket'].close()\n-                 elif fileHandle != VOID_FILE_DESCRIPTOR:\n-                     os.close(fileHandle)\n-                     infoRecord, errorCode = queryFileInformation(os.path.dirname(pathName), os.path.basename(pathName), smb2.SMB2_FILE_NETWORK_OPEN_INFO)\n-             except Exception as e:\n-                 smbServer.log(\"SMB2_CLOSE %s\" % e, logging.ERROR)\n-                 errorCode = STATUS_INVALID_HANDLE\n-             else:\n-                 # Check if the file was marked for removal\n-                 if connData['OpenedFiles'][fileID]['DeleteOnClose'] is True:\n-                     try:\n-                         if os.path.isdir(pathName):\n-                             shutil.rmtree(connData['OpenedFiles'][fileID]['FileName'])\n-                         else:\n-                             os.remove(connData['OpenedFiles'][fileID]['FileName'])\n-                     except Exception as e:\n-                         smbServer.log(\"SMB2_CLOSE %s\" % e, logging.ERROR)\n-                         errorCode = STATUS_ACCESS_DENIED\n-    \n-                 # Now fill out the response\n-                 if infoRecord is not None:\n-                     respSMBCommand['CreationTime']   = infoRecord['CreationTime']\n-                     respSMBCommand['LastAccessTime'] = infoRecord['LastAccessTime']\n-                     respSMBCommand['LastWriteTime']  = infoRecord['LastWriteTime']\n-                     respSMBCommand['ChangeTime']     = infoRecord['ChangeTime']\n-                     respSMBCommand['AllocationSize'] = infoRecord['AllocationSize']\n-                     respSMBCommand['EndofFile']      = infoRecord['EndOfFile']\n-                     respSMBCommand['FileAttributes'] = infoRecord['FileAttributes']\n-                 if errorCode == STATUS_SUCCESS:\n-                     del(connData['OpenedFiles'][fileID])\n+            errorCode = STATUS_SUCCESS\n+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n+            pathName = connData['OpenedFiles'][fileID]['FileName']\n+            infoRecord = None\n+            try:\n+                if fileHandle == PIPE_FILE_DESCRIPTOR:\n+                    connData['OpenedFiles'][fileID]['Socket'].close()\n+                elif fileHandle != VOID_FILE_DESCRIPTOR:\n+                    os.close(fileHandle)\n+                    infoRecord, errorCode = queryFileInformation(os.path.dirname(pathName), os.path.basename(pathName),\n+                                                                 smb2.SMB2_FILE_NETWORK_OPEN_INFO)\n+            except Exception as e:\n+                smbServer.log(\"SMB2_CLOSE %s\" % e, logging.ERROR)\n+                errorCode = STATUS_INVALID_HANDLE\n+            else:\n+                # Check if the file was marked for removal\n+                if connData['OpenedFiles'][fileID]['DeleteOnClose'] is True:\n+                    try:\n+                        if os.path.isdir(pathName):\n+                            shutil.rmtree(connData['OpenedFiles'][fileID]['FileName'])\n+                        else:\n+                            os.remove(connData['OpenedFiles'][fileID]['FileName'])\n+                    except Exception as e:\n+                        smbServer.log(\"SMB2_CLOSE %s\" % e, logging.ERROR)\n+                        errorCode = STATUS_ACCESS_DENIED\n+\n+                # Now fill out the response\n+                if infoRecord is not None:\n+                    respSMBCommand['CreationTime'] = infoRecord['CreationTime']\n+                    respSMBCommand['LastAccessTime'] = infoRecord['LastAccessTime']\n+                    respSMBCommand['LastWriteTime'] = infoRecord['LastWriteTime']\n+                    respSMBCommand['ChangeTime'] = infoRecord['ChangeTime']\n+                    respSMBCommand['AllocationSize'] = infoRecord['AllocationSize']\n+                    respSMBCommand['EndofFile'] = infoRecord['EndOfFile']\n+                    respSMBCommand['FileAttributes'] = infoRecord['FileAttributes']\n+                if errorCode == STATUS_SUCCESS:\n+                    del (connData['OpenedFiles'][fileID])\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n@@ -3156,18 +3215,18 @@ def smb2Close(connId, smbServer, recvPacket):\n     def smb2QueryInfo(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb2.SMB2QueryInfo_Response()\n+        respSMBCommand = smb2.SMB2QueryInfo_Response()\n \n         queryInfo = smb2.SMB2QueryInfo(recvPacket['Data'])\n-       \n-        errorCode = STATUS_SUCCESS \n+\n+        errorCode = STATUS_SUCCESS\n \n         respSMBCommand['OutputBufferOffset'] = 0x48\n         respSMBCommand['Buffer'] = b'\\x00'\n \n-        if queryInfo['FileID'].getData() == b'\\xff'*16:\n+        if queryInfo['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = queryInfo['FileID'].getData()\n@@ -3189,15 +3248,16 @@ def smb2QueryInfo(connId, smbServer, recvPacket):\n                                                                      queryInfo['FileInfoClass'])\n                 elif queryInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:\n                     if queryInfo['FileInfoClass'] == smb2.SMB2_FILE_EA_INFO:\n-                        infoRecord = b'\\x00'*4\n+                        infoRecord = b'\\x00' * 4\n                     else:\n-                        infoRecord = queryFsInformation(os.path.dirname(fileName), os.path.basename(fileName), queryInfo['FileInfoClass'])\n+                        infoRecord = queryFsInformation(os.path.dirname(fileName), os.path.basename(fileName),\n+                                                        queryInfo['FileInfoClass'])\n                 elif queryInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:\n                     # Failing for now, until we support it\n                     infoRecord = None\n                     errorCode = STATUS_ACCESS_DENIED\n                 else:\n-                    smbServer.log(\"queryInfo not supported (%x)\" %  queryInfo['InfoType'], logging.ERROR)\n+                    smbServer.log(\"queryInfo not supported (%x)\" % queryInfo['InfoType'], logging.ERROR)\n \n                 if infoRecord is not None:\n                     respSMBCommand['OutputBufferLength'] = len(infoRecord)\n@@ -3207,7 +3267,6 @@ def smb2QueryInfo(connId, smbServer, recvPacket):\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n@@ -3215,15 +3274,15 @@ def smb2QueryInfo(connId, smbServer, recvPacket):\n     def smb2SetInfo(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n-        respSMBCommand        = smb2.SMB2SetInfo_Response()\n+        respSMBCommand = smb2.SMB2SetInfo_Response()\n \n         setInfo = smb2.SMB2SetInfo(recvPacket['Data'])\n-       \n-        errorCode = STATUS_SUCCESS \n \n-        if setInfo['FileID'].getData() == b'\\xff'*16:\n+        errorCode = STATUS_SUCCESS\n+\n+        if setInfo['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = setInfo['FileID'].getData()\n@@ -3231,7 +3290,7 @@ def smb2SetInfo(connId, smbServer, recvPacket):\n             fileID = setInfo['FileID'].getData()\n \n         if recvPacket['TreeID'] in connData['ConnectedShares']:\n-            path     = connData['ConnectedShares'][recvPacket['TreeID']]['path']\n+            path = connData['ConnectedShares'][recvPacket['TreeID']]['path']\n             if fileID in connData['OpenedFiles']:\n                 pathName = connData['OpenedFiles'][fileID]['FileName']\n \n@@ -3241,8 +3300,8 @@ def smb2SetInfo(connId, smbServer, recvPacket):\n                     if informationLevel == smb2.SMB2_FILE_DISPOSITION_INFO:\n                         infoRecord = smb.SMBSetFileDispositionInfo(setInfo['Buffer'])\n                         if infoRecord['DeletePending'] > 0:\n-                           # Mark this file for removal after closed\n-                           connData['OpenedFiles'][fileID]['DeleteOnClose'] = True\n+                            # Mark this file for removal after closed\n+                            connData['OpenedFiles'][fileID]['DeleteOnClose'] = True\n                     elif informationLevel == smb2.SMB2_FILE_BASIC_INFO:\n                         infoRecord = smb.SMBSetFileBasicInfo(setInfo['Buffer'])\n                         # Creation time won't be set,  the other ones we play with.\n@@ -3257,48 +3316,47 @@ def smb2SetInfo(connId, smbServer, recvPacket):\n                         else:\n                             mtime = getUnixTime(mtime)\n                         if atime > 0 and mtime > 0:\n-                            os.utime(pathName,(atime,mtime))\n+                            os.utime(pathName, (atime, mtime))\n                     elif informationLevel == smb2.SMB2_FILE_END_OF_FILE_INFO:\n                         fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n                         infoRecord = smb.SMBSetFileEndOfFileInfo(setInfo['Buffer'])\n                         if infoRecord['EndOfFile'] > 0:\n-                            os.lseek(fileHandle, infoRecord['EndOfFile']-1, 0)\n+                            os.lseek(fileHandle, infoRecord['EndOfFile'] - 1, 0)\n                             os.write(fileHandle, b'\\x00')\n                     elif informationLevel == smb2.SMB2_FILE_RENAME_INFO:\n                         renameInfo = smb2.FILE_RENAME_INFORMATION_TYPE_2(setInfo['Buffer'])\n-                        newPathName = os.path.join(path,renameInfo['FileName'].decode('utf-16le').replace('\\\\', '\/')) \n+                        newPathName = os.path.join(path, renameInfo['FileName'].decode('utf-16le').replace('\\\\', '\/'))\n                         if renameInfo['ReplaceIfExists'] == 0 and os.path.exists(newPathName):\n                             return [smb2.SMB2Error()], None, STATUS_OBJECT_NAME_COLLISION\n                         try:\n-                             os.rename(pathName,newPathName)\n-                             connData['OpenedFiles'][fileID]['FileName'] = newPathName\n+                            os.rename(pathName, newPathName)\n+                            connData['OpenedFiles'][fileID]['FileName'] = newPathName\n                         except Exception as e:\n-                             smbServer.log(\"smb2SetInfo: %s\" % e, logging.ERROR)\n-                             errorCode = STATUS_ACCESS_DENIED\n+                            smbServer.log(\"smb2SetInfo: %s\" % e, logging.ERROR)\n+                            errorCode = STATUS_ACCESS_DENIED\n                     else:\n                         smbServer.log('Unknown level for set file info! 0x%x' % informationLevel, logging.ERROR)\n                         # UNSUPPORTED\n-                        errorCode =  STATUS_NOT_SUPPORTED\n-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:\n+                        errorCode = STATUS_NOT_SUPPORTED\n+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:\n                 #    # The underlying object store information is being set.\n                 #    setInfo = queryFsInformation('\/', fileName, queryInfo['FileInfoClass'])\n-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:\n+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:\n                 #    # The security information is being set.\n                 #    # Failing for now, until we support it\n                 #    infoRecord = None\n                 #    errorCode = STATUS_ACCESS_DENIED\n-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_QUOTA:\n+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_QUOTA:\n                 #    # The underlying object store quota information is being set.\n                 #    setInfo = queryFsInformation('\/', fileName, queryInfo['FileInfoClass'])\n                 else:\n-                    smbServer.log(\"setInfo not supported (%x)\" %  setInfo['InfoType'], logging.ERROR)\n+                    smbServer.log(\"setInfo not supported (%x)\" % setInfo['InfoType'], logging.ERROR)\n \n             else:\n                 errorCode = STATUS_INVALID_HANDLE\n         else:\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n@@ -3307,13 +3365,13 @@ def smb2Write(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb2.SMB2Write_Response()\n-        writeRequest   = smb2.SMB2Write(recvPacket['Data'])\n+        writeRequest = smb2.SMB2Write(recvPacket['Data'])\n \n         respSMBCommand['Buffer'] = b'\\x00'\n \n-        if writeRequest['FileID'].getData() == b'\\xff'*16:\n+        if writeRequest['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = writeRequest['FileID'].getData()\n@@ -3321,24 +3379,24 @@ def smb2Write(connId, smbServer, recvPacket):\n             fileID = writeRequest['FileID'].getData()\n \n         if fileID in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     offset = writeRequest['Offset']\n-                     # If we're trying to write past the file end we just skip the write call (Vista does this)\n-                     if os.lseek(fileHandle, 0, 2) >= offset:\n-                         os.lseek(fileHandle,offset,0)\n-                         os.write(fileHandle,writeRequest['Buffer'])\n-                 else:\n-                     sock = connData['OpenedFiles'][fileID]['Socket']\n-                     sock.send(writeRequest['Buffer'])\n-\n-                 respSMBCommand['Count']    = writeRequest['Length']\n-                 respSMBCommand['Remaining']= 0xff\n-             except Exception as e:\n-                 smbServer.log('SMB2_WRITE: %s' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    offset = writeRequest['Offset']\n+                    # If we're trying to write past the file end we just skip the write call (Vista does this)\n+                    if os.lseek(fileHandle, 0, 2) >= offset:\n+                        os.lseek(fileHandle, offset, 0)\n+                        os.write(fileHandle, writeRequest['Buffer'])\n+                else:\n+                    sock = connData['OpenedFiles'][fileID]['Socket']\n+                    sock.send(writeRequest['Buffer'])\n+\n+                respSMBCommand['Count'] = writeRequest['Length']\n+                respSMBCommand['Remaining'] = 0xff\n+            except Exception as e:\n+                smbServer.log('SMB2_WRITE: %s' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n@@ -3350,13 +3408,13 @@ def smb2Read(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb2.SMB2Read_Response()\n-        readRequest   = smb2.SMB2Read(recvPacket['Data'])\n+        readRequest = smb2.SMB2Read(recvPacket['Data'])\n \n         respSMBCommand['Buffer'] = b'\\x00'\n \n-        if readRequest['FileID'].getData() == b'\\xff'*16:\n+        if readRequest['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = readRequest['FileID'].getData()\n@@ -3364,24 +3422,24 @@ def smb2Read(connId, smbServer, recvPacket):\n             fileID = readRequest['FileID'].getData()\n \n         if fileID in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n-             errorCode = 0\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     offset = readRequest['Offset']\n-                     os.lseek(fileHandle,offset,0)\n-                     content = os.read(fileHandle,readRequest['Length'])\n-                 else:\n-                     sock = connData['OpenedFiles'][fileID]['Socket']\n-                     content = sock.recv(readRequest['Length'])\n-\n-                 respSMBCommand['DataOffset']   = 0x50\n-                 respSMBCommand['DataLength']   = len(content)\n-                 respSMBCommand['DataRemaining']= 0\n-                 respSMBCommand['Buffer']       = content\n-             except Exception as e:\n-                 smbServer.log('SMB2_READ: %s ' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']\n+            errorCode = 0\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    offset = readRequest['Offset']\n+                    os.lseek(fileHandle, offset, 0)\n+                    content = os.read(fileHandle, readRequest['Length'])\n+                else:\n+                    sock = connData['OpenedFiles'][fileID]['Socket']\n+                    content = sock.recv(readRequest['Length'])\n+\n+                respSMBCommand['DataOffset'] = 0x50\n+                respSMBCommand['DataLength'] = len(content)\n+                respSMBCommand['DataRemaining'] = 0\n+                respSMBCommand['Buffer'] = content\n+            except Exception as e:\n+                smbServer.log('SMB2_READ: %s ' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n@@ -3393,40 +3451,39 @@ def smb2Flush(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb2.SMB2Flush_Response()\n-        flushRequest   = smb2.SMB2Flush(recvPacket['Data'])\n+        flushRequest = smb2.SMB2Flush(recvPacket['Data'])\n \n         if flushRequest['FileID'].getData() in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][flushRequest['FileID'].getData()]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 os.fsync(fileHandle)\n-             except Exception as e:\n-                 smbServer.log(\"SMB2_FLUSH %s\" % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][flushRequest['FileID'].getData()]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                os.fsync(fileHandle)\n+            except Exception as e:\n+                smbServer.log(\"SMB2_FLUSH %s\" % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_HANDLE\n \n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n-\n     @staticmethod\n     def smb2QueryDirectory(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n         respSMBCommand = smb2.SMB2QueryDirectory_Response()\n-        queryDirectoryRequest   = smb2.SMB2QueryDirectory(recvPacket['Data'])\n+        queryDirectoryRequest = smb2.SMB2QueryDirectory(recvPacket['Data'])\n \n         respSMBCommand['Buffer'] = b'\\x00'\n \n         # The server MUST locate the tree connection, as specified in section 3.3.5.2.11.\n         if (recvPacket['TreeID'] in connData['ConnectedShares']) is False:\n             return [smb2.SMB2Error()], None, STATUS_NETWORK_NAME_DELETED\n-       \n-        # Next, the server MUST locate the open for the directory to be queried \n+\n+        # Next, the server MUST locate the open for the directory to be queried\n         # If no open is found, the server MUST fail the request with STATUS_FILE_CLOSED\n-        if queryDirectoryRequest['FileID'].getData() == b'\\xff'*16:\n+        if queryDirectoryRequest['FileID'].getData() == b'\\xff' * 16:\n             # Let's take the data from the lastRequest\n-            if  'SMB2_CREATE' in connData['LastRequest']:\n+            if 'SMB2_CREATE' in connData['LastRequest']:\n                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']\n             else:\n                 fileID = queryDirectoryRequest['FileID'].getData()\n@@ -3436,57 +3493,59 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):\n         if (fileID in connData['OpenedFiles']) is False:\n             return [smb2.SMB2Error()], None, STATUS_FILE_CLOSED\n \n-        # If the open is not an open to a directory, the request MUST be failed \n+        # If the open is not an open to a directory, the request MUST be failed\n         # with STATUS_INVALID_PARAMETER.\n         if os.path.isdir(connData['OpenedFiles'][fileID]['FileName']) is False:\n             return [smb2.SMB2Error()], None, STATUS_INVALID_PARAMETER\n \n-        # If any other information class is specified in the FileInformationClass \n-        # field of the SMB2 QUERY_DIRECTORY Request, the server MUST fail the \n-        # operation with STATUS_INVALID_INFO_CLASS. \n+        # If any other information class is specified in the FileInformationClass\n+        # field of the SMB2 QUERY_DIRECTORY Request, the server MUST fail the\n+        # operation with STATUS_INVALID_INFO_CLASS.\n         if queryDirectoryRequest['FileInformationClass'] not in (\n-        smb2.FILE_DIRECTORY_INFORMATION, smb2.FILE_FULL_DIRECTORY_INFORMATION, smb2.FILEID_FULL_DIRECTORY_INFORMATION,\n-        smb2.FILE_BOTH_DIRECTORY_INFORMATION, smb2.FILEID_BOTH_DIRECTORY_INFORMATION, smb2.FILENAMES_INFORMATION):\n+                smb2.FILE_DIRECTORY_INFORMATION, smb2.FILE_FULL_DIRECTORY_INFORMATION,\n+                smb2.FILEID_FULL_DIRECTORY_INFORMATION,\n+                smb2.FILE_BOTH_DIRECTORY_INFORMATION, smb2.FILEID_BOTH_DIRECTORY_INFORMATION,\n+                smb2.FILENAMES_INFORMATION):\n             return [smb2.SMB2Error()], None, STATUS_INVALID_INFO_CLASS\n \n-        # If SMB2_REOPEN is set in the Flags field of the SMB2 QUERY_DIRECTORY \n-        # Request, the server SHOULD<326> set Open.EnumerationLocation to 0 \n+        # If SMB2_REOPEN is set in the Flags field of the SMB2 QUERY_DIRECTORY\n+        # Request, the server SHOULD<326> set Open.EnumerationLocation to 0\n         # and Open.EnumerationSearchPattern to an empty string.\n         if queryDirectoryRequest['Flags'] & smb2.SMB2_REOPEN:\n             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = 0\n             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = ''\n-        \n-        # If SMB2_RESTART_SCANS is set in the Flags field of the SMB2 \n-        # QUERY_DIRECTORY Request, the server MUST set \n+\n+        # If SMB2_RESTART_SCANS is set in the Flags field of the SMB2\n+        # QUERY_DIRECTORY Request, the server MUST set\n         # Open.EnumerationLocation to 0.\n         if queryDirectoryRequest['Flags'] & smb2.SMB2_RESTART_SCANS:\n             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = 0\n \n-        # If Open.EnumerationLocation is 0 and Open.EnumerationSearchPattern \n-        # is an empty string, then Open.EnumerationSearchPattern MUST be set \n-        # to the search pattern specified in the SMB2 QUERY_DIRECTORY by \n-        # FileNameOffset and FileNameLength. If FileNameLength is 0, the server \n+        # If Open.EnumerationLocation is 0 and Open.EnumerationSearchPattern\n+        # is an empty string, then Open.EnumerationSearchPattern MUST be set\n+        # to the search pattern specified in the SMB2 QUERY_DIRECTORY by\n+        # FileNameOffset and FileNameLength. If FileNameLength is 0, the server\n         # SHOULD<327> set Open.EnumerationSearchPattern as \"*\" to search all entries.\n \n         pattern = queryDirectoryRequest['Buffer'].decode('utf-16le')\n-        if  connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0 and \\\n-            connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] == '':\n+        if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0 and \\\n+                connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] == '':\n             if pattern == '':\n                 pattern = '*'\n             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = pattern\n \n-        # If SMB2_INDEX_SPECIFIED is set and FileNameLength is not zero, \n-        # the server MUST set Open.EnumerationSearchPattern to the search pattern \n+        # If SMB2_INDEX_SPECIFIED is set and FileNameLength is not zero,\n+        # the server MUST set Open.EnumerationSearchPattern to the search pattern\n         # specified in the request by FileNameOffset and FileNameLength.\n         if queryDirectoryRequest['Flags'] & smb2.SMB2_INDEX_SPECIFIED and \\\n-           queryDirectoryRequest['FileNameLength'] > 0:\n+                queryDirectoryRequest['FileNameLength'] > 0:\n             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = pattern\n \n-        pathName = os.path.join(os.path.normpath(connData['OpenedFiles'][fileID]['FileName']),pattern)\n+        pathName = os.path.join(os.path.normpath(connData['OpenedFiles'][fileID]['FileName']), pattern)\n         searchResult, searchCount, errorCode = findFirst2(os.path.dirname(pathName),\n-                  os.path.basename(pathName),\n-                  queryDirectoryRequest['FileInformationClass'], \n-                  smb.ATTR_DIRECTORY, isSMB2 = True )\n+                                                          os.path.basename(pathName),\n+                                                          queryDirectoryRequest['FileInformationClass'],\n+                                                          smb.ATTR_DIRECTORY, isSMB2=True)\n \n         if errorCode != STATUS_SUCCESS:\n             return [smb2.SMB2Error()], None, errorCode\n@@ -3499,7 +3558,7 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):\n         if searchCount == 0 and connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0:\n             return [smb2.SMB2Error()], None, STATUS_NO_SUCH_FILE\n \n-        if  connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] < 0:\n+        if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] < 0:\n             return [smb2.SMB2Error()], None, STATUS_NO_MORE_FILES\n \n         totalData = 0\n@@ -3511,20 +3570,20 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):\n                 searchResult[nItem]['NextEntryOffset'] = 0\n             data = searchResult[nItem].getData()\n             lenData = len(data)\n-            padLen = (8-(lenData % 8)) %8\n- \n-            if (totalData+lenData) >= queryDirectoryRequest['OutputBufferLength']:\n+            padLen = (8 - (lenData % 8)) % 8\n+\n+            if (totalData + lenData) >= queryDirectoryRequest['OutputBufferLength']:\n                 connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] -= 1\n                 break\n             else:\n-                respData += data + b'\\x00'*padLen\n+                respData += data + b'\\x00' * padLen\n                 totalData += lenData + padLen\n \n             if queryDirectoryRequest['Flags'] & smb2.SL_RETURN_SINGLE_ENTRY:\n                 break\n \n         if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] >= searchCount:\n-             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = -1\n+            connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = -1\n \n         respSMBCommand['OutputBufferOffset'] = 0x48\n         respSMBCommand['OutputBufferLength'] = totalData\n@@ -3553,14 +3612,13 @@ def smb2TreeDisconnect(connId, smbServer, recvPacket):\n \n         if recvPacket['TreeID'] in connData['ConnectedShares']:\n             smbServer.log(\"Disconnecting Share(%d:%s)\" % (\n-            recvPacket['TreeID'], connData['ConnectedShares'][recvPacket['TreeID']]['shareName']))\n-            del(connData['ConnectedShares'][recvPacket['TreeID']])\n+                recvPacket['TreeID'], connData['ConnectedShares'][recvPacket['TreeID']]['shareName']))\n+            del (connData['ConnectedShares'][recvPacket['TreeID']])\n             errorCode = STATUS_SUCCESS\n         else:\n             # STATUS_SMB_BAD_TID\n             errorCode = STATUS_SMB_BAD_TID\n \n-\n         smbServer.setConnectionData(connId, connData)\n         return [respSMBCommand], None, errorCode\n \n@@ -3587,24 +3645,24 @@ def smb2Ioctl(connId, smbServer, recvPacket):\n         connData = smbServer.getConnectionData(connId)\n \n         respSMBCommand = smb2.SMB2Ioctl_Response()\n-        ioctlRequest   = smb2.SMB2Ioctl(recvPacket['Data'])\n+        ioctlRequest = smb2.SMB2Ioctl(recvPacket['Data'])\n \n         ioctls = smbServer.getIoctls()\n         if ioctlRequest['CtlCode'] in ioctls:\n             outputData, errorCode = ioctls[ioctlRequest['CtlCode']](connId, smbServer, ioctlRequest)\n             if errorCode == STATUS_SUCCESS:\n-                respSMBCommand['CtlCode']      = ioctlRequest['CtlCode']\n-                respSMBCommand['FileID']       = ioctlRequest['FileID']\n-                respSMBCommand['InputOffset']  = 0\n-                respSMBCommand['InputCount']   = 0\n+                respSMBCommand['CtlCode'] = ioctlRequest['CtlCode']\n+                respSMBCommand['FileID'] = ioctlRequest['FileID']\n+                respSMBCommand['InputOffset'] = 0\n+                respSMBCommand['InputCount'] = 0\n                 respSMBCommand['OutputOffset'] = 0x70\n-                respSMBCommand['OutputCount']  = len(outputData)\n-                respSMBCommand['Flags']        = 0\n-                respSMBCommand['Buffer']       = outputData\n+                respSMBCommand['OutputCount'] = len(outputData)\n+                respSMBCommand['Flags'] = 0\n+                respSMBCommand['Buffer'] = outputData\n             else:\n                 respSMBCommand = outputData\n         else:\n-            smbServer.log(\"Ioctl not implemented command: 0x%x\" % ioctlRequest['CtlCode'],logging.DEBUG)\n+            smbServer.log(\"Ioctl not implemented command: 0x%x\" % ioctlRequest['CtlCode'], logging.DEBUG)\n             errorCode = STATUS_INVALID_DEVICE_REQUEST\n             respSMBCommand = smb2.SMB2Error()\n \n@@ -3631,49 +3689,50 @@ def smb2Cancel(connId, smbServer, recvPacket):\n     @staticmethod\n     def default(connId, smbServer, recvPacket):\n         # By default we return an SMB Packet with error not implemented\n-        smbServer.log(\"Not implemented command: 0x%x\" % recvPacket['Command'],logging.DEBUG)\n+        smbServer.log(\"Not implemented command: 0x%x\" % recvPacket['Command'], logging.DEBUG)\n         return [smb2.SMB2Error()], None, STATUS_NOT_SUPPORTED\n \n+\n class Ioctls:\n-   @staticmethod\n-   def fsctlDfsGetReferrals(connId, smbServer, ioctlRequest):\n+    @staticmethod\n+    def fsctlDfsGetReferrals(connId, smbServer, ioctlRequest):\n         return smb2.SMB2Error(), STATUS_FS_DRIVER_REQUIRED\n \n-   @staticmethod\n-   def fsctlPipeTransceive(connId, smbServer, ioctlRequest):\n+    @staticmethod\n+    def fsctlPipeTransceive(connId, smbServer, ioctlRequest):\n         connData = smbServer.getConnectionData(connId)\n-        \n+\n         ioctlResponse = ''\n \n         if ioctlRequest['FileID'].getData() in connData['OpenedFiles']:\n-             fileHandle = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['FileHandle']\n-             errorCode = STATUS_SUCCESS\n-             try:\n-                 if fileHandle != PIPE_FILE_DESCRIPTOR:\n-                     errorCode = STATUS_INVALID_DEVICE_REQUEST\n-                 else:\n-                     sock = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['Socket']\n-                     sock.sendall(ioctlRequest['Buffer'])\n-                     ioctlResponse = sock.recv(ioctlRequest['MaxOutputResponse'])\n-             except Exception as e:\n-                 smbServer.log('fsctlPipeTransceive: %s ' % e, logging.ERROR)\n-                 errorCode = STATUS_ACCESS_DENIED\n+            fileHandle = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['FileHandle']\n+            errorCode = STATUS_SUCCESS\n+            try:\n+                if fileHandle != PIPE_FILE_DESCRIPTOR:\n+                    errorCode = STATUS_INVALID_DEVICE_REQUEST\n+                else:\n+                    sock = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['Socket']\n+                    sock.sendall(ioctlRequest['Buffer'])\n+                    ioctlResponse = sock.recv(ioctlRequest['MaxOutputResponse'])\n+            except Exception as e:\n+                smbServer.log('fsctlPipeTransceive: %s ' % e, logging.ERROR)\n+                errorCode = STATUS_ACCESS_DENIED\n         else:\n             errorCode = STATUS_INVALID_DEVICE_REQUEST\n \n         smbServer.setConnectionData(connId, connData)\n         return ioctlResponse, errorCode\n \n-   @staticmethod\n-   def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):\n+    @staticmethod\n+    def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):\n         connData = smbServer.getConnectionData(connId)\n-        \n+\n         errorCode = STATUS_SUCCESS\n \n         validateNegotiateInfo = smb2.VALIDATE_NEGOTIATE_INFO(ioctlRequest['Buffer'])\n         validateNegotiateInfoResponse = smb2.VALIDATE_NEGOTIATE_INFO_RESPONSE()\n         validateNegotiateInfoResponse['Capabilities'] = 0\n-        validateNegotiateInfoResponse['Guid'] = b'A'*16\n+        validateNegotiateInfoResponse['Guid'] = b'A' * 16\n         validateNegotiateInfoResponse['SecurityMode'] = 1\n         validateNegotiateInfoResponse['Dialect'] = smb2.SMB2_DIALECT_002\n \n@@ -3682,15 +3741,15 @@ def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):\n \n \n class SMBSERVERHandler(socketserver.BaseRequestHandler):\n-    def __init__(self, request, client_address, server, select_poll = False):\n+    def __init__(self, request, client_address, server, select_poll=False):\n         self.__SMB = server\n         # In case of AF_INET6 the client_address contains 4 items, ignore the last 2\n         self.__ip, self.__port = client_address[:2]\n         self.__request = request\n         self.__connId = threading.currentThread().getName()\n-        self.__timeOut = 60*5\n+        self.__timeOut = 60 * 5\n         self.__select_poll = select_poll\n-        #self.__connId = os.getpid()\n+        # self.__connId = os.getpid()\n         socketserver.BaseRequestHandler.__init__(self, request, client_address, server)\n \n     def handle(self):\n@@ -3706,31 +3765,32 @@ def handle(self):\n                 except nmb.NetBIOSTimeout:\n                     raise\n                 except nmb.NetBIOSError:\n-                    break                 \n+                    break\n \n                 if p.get_type() == nmb.NETBIOS_SESSION_REQUEST:\n-                   # Someone is requesting a session, we're gonna accept them all :)\n-                   _, rn, my = p.get_trailer().split(b' ')\n-                   remote_name = nmb.decode_name(b'\\x20'+rn)\n-                   myname = nmb.decode_name(b'\\x20'+my)\n-                   self.__SMB.log(\"NetBIOS Session request (%s,%s,%s)\" % (self.__ip, remote_name[1].strip(), myname[1])) \n-                   r = nmb.NetBIOSSessionPacket()\n-                   r.set_type(nmb.NETBIOS_SESSION_POSITIVE_RESPONSE)\n-                   r.set_trailer(p.get_trailer())\n-                   self.__request.send(r.rawData())\n+                    # Someone is requesting a session, we're gonna accept them all :)\n+                    _, rn, my = p.get_trailer().split(b' ')\n+                    remote_name = nmb.decode_name(b'\\x20' + rn)\n+                    myname = nmb.decode_name(b'\\x20' + my)\n+                    self.__SMB.log(\n+                        \"NetBIOS Session request (%s,%s,%s)\" % (self.__ip, remote_name[1].strip(), myname[1]))\n+                    r = nmb.NetBIOSSessionPacket()\n+                    r.set_type(nmb.NETBIOS_SESSION_POSITIVE_RESPONSE)\n+                    r.set_trailer(p.get_trailer())\n+                    self.__request.send(r.rawData())\n                 else:\n-                   resp = self.__SMB.processRequest(self.__connId, p.get_trailer())\n-                   # Send all the packets received. Except for big transactions this should be\n-                   # a single packet\n-                   for i in resp:\n-                       if hasattr(i, 'getData'):\n-                           session.send_packet(i.getData())\n-                       else:\n-                           session.send_packet(i)\n+                    resp = self.__SMB.processRequest(self.__connId, p.get_trailer())\n+                    # Send all the packets received. Except for big transactions this should be\n+                    # a single packet\n+                    for i in resp:\n+                        if hasattr(i, 'getData'):\n+                            session.send_packet(i.getData())\n+                        else:\n+                            session.send_packet(i)\n             except Exception as e:\n                 self.__SMB.log(\"Handle: %s\" % e)\n-                #import traceback\n-                #traceback.print_exc()\n+                # import traceback\n+                # traceback.print_exc()\n                 break\n \n     def finish(self):\n@@ -3739,18 +3799,19 @@ def finish(self):\n         self.__SMB.removeConnection(self.__connId)\n         return socketserver.BaseRequestHandler.finish(self)\n \n+\n class SMBSERVER(socketserver.ThreadingMixIn, socketserver.TCPServer):\n-#class SMBSERVER(socketserver.ForkingMixIn, socketserver.TCPServer):\n-    def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser = None):\n+    # class SMBSERVER(socketserver.ForkingMixIn, socketserver.TCPServer):\n+    def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser=None):\n         socketserver.TCPServer.allow_reuse_address = True\n         socketserver.TCPServer.__init__(self, server_address, handler_class)\n \n         # Server name and OS to be presented whenever is necessary\n-        self.__serverName   = ''\n-        self.__serverOS     = ''\n+        self.__serverName = ''\n+        self.__serverOS = ''\n         self.__serverDomain = ''\n-        self.__challenge    = ''\n-        self.__log          = None\n+        self.__challenge = ''\n+        self.__log = None\n \n         # Our ConfigParser data\n         self.__serverConfig = config_parser\n@@ -3769,108 +3830,108 @@ def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser\n \n         # SMB2 Support flag = default not active\n         self.__SMB2Support = False\n- \n+\n         # Our list of commands we will answer, by default the NOT IMPLEMENTED one\n         self.__smbCommandsHandler = SMBCommands()\n-        self.__smbTrans2Handler   = TRANS2Commands()\n-        self.__smbTransHandler    = TRANSCommands()\n-        self.__smbNTTransHandler  = NTTRANSCommands()\n+        self.__smbTrans2Handler = TRANS2Commands()\n+        self.__smbTransHandler = TRANSCommands()\n+        self.__smbNTTransHandler = NTTRANSCommands()\n         self.__smb2CommandsHandler = SMB2Commands()\n-        self.__IoctlHandler       = Ioctls()\n+        self.__IoctlHandler = Ioctls()\n \n         self.__smbNTTransCommands = {\n-        # NT IOCTL, can't find doc for this\n-        0xff                               :self.__smbNTTransHandler.default\n+            # NT IOCTL, can't find doc for this\n+            0xff: self.__smbNTTransHandler.default\n         }\n \n-        self.__smbTransCommands  = {\n-'\\\\PIPE\\\\LANMAN'                       :self.__smbTransHandler.lanMan,\n-smb.SMB.TRANS_TRANSACT_NMPIPE          :self.__smbTransHandler.transactNamedPipe,\n+        self.__smbTransCommands = {\n+            '\\\\PIPE\\\\LANMAN': self.__smbTransHandler.lanMan,\n+            smb.SMB.TRANS_TRANSACT_NMPIPE: self.__smbTransHandler.transactNamedPipe,\n         }\n         self.__smbTrans2Commands = {\n- smb.SMB.TRANS2_FIND_FIRST2            :self.__smbTrans2Handler.findFirst2,\n- smb.SMB.TRANS2_FIND_NEXT2             :self.__smbTrans2Handler.findNext2,\n- smb.SMB.TRANS2_QUERY_FS_INFORMATION   :self.__smbTrans2Handler.queryFsInformation,\n- smb.SMB.TRANS2_QUERY_PATH_INFORMATION :self.__smbTrans2Handler.queryPathInformation,\n- smb.SMB.TRANS2_QUERY_FILE_INFORMATION :self.__smbTrans2Handler.queryFileInformation,\n- smb.SMB.TRANS2_SET_FILE_INFORMATION   :self.__smbTrans2Handler.setFileInformation,\n- smb.SMB.TRANS2_SET_PATH_INFORMATION   :self.__smbTrans2Handler.setPathInformation\n+            smb.SMB.TRANS2_FIND_FIRST2: self.__smbTrans2Handler.findFirst2,\n+            smb.SMB.TRANS2_FIND_NEXT2: self.__smbTrans2Handler.findNext2,\n+            smb.SMB.TRANS2_QUERY_FS_INFORMATION: self.__smbTrans2Handler.queryFsInformation,\n+            smb.SMB.TRANS2_QUERY_PATH_INFORMATION: self.__smbTrans2Handler.queryPathInformation,\n+            smb.SMB.TRANS2_QUERY_FILE_INFORMATION: self.__smbTrans2Handler.queryFileInformation,\n+            smb.SMB.TRANS2_SET_FILE_INFORMATION: self.__smbTrans2Handler.setFileInformation,\n+            smb.SMB.TRANS2_SET_PATH_INFORMATION: self.__smbTrans2Handler.setPathInformation\n         }\n \n-        self.__smbCommands = { \n- #smb.SMB.SMB_COM_FLUSH:              self.__smbCommandsHandler.smbComFlush, \n- smb.SMB.SMB_COM_CREATE_DIRECTORY:   self.__smbCommandsHandler.smbComCreateDirectory, \n- smb.SMB.SMB_COM_DELETE_DIRECTORY:   self.__smbCommandsHandler.smbComDeleteDirectory, \n- smb.SMB.SMB_COM_RENAME:             self.__smbCommandsHandler.smbComRename, \n- smb.SMB.SMB_COM_DELETE:             self.__smbCommandsHandler.smbComDelete, \n- smb.SMB.SMB_COM_NEGOTIATE:          self.__smbCommandsHandler.smbComNegotiate, \n- smb.SMB.SMB_COM_SESSION_SETUP_ANDX: self.__smbCommandsHandler.smbComSessionSetupAndX,\n- smb.SMB.SMB_COM_LOGOFF_ANDX:        self.__smbCommandsHandler.smbComLogOffAndX,\n- smb.SMB.SMB_COM_TREE_CONNECT_ANDX:  self.__smbCommandsHandler.smbComTreeConnectAndX,\n- smb.SMB.SMB_COM_TREE_DISCONNECT:    self.__smbCommandsHandler.smbComTreeDisconnect,\n- smb.SMB.SMB_COM_ECHO:               self.__smbCommandsHandler.smbComEcho,\n- smb.SMB.SMB_COM_QUERY_INFORMATION:  self.__smbCommandsHandler.smbQueryInformation,\n- smb.SMB.SMB_COM_TRANSACTION2:       self.__smbCommandsHandler.smbTransaction2,\n- smb.SMB.SMB_COM_TRANSACTION:        self.__smbCommandsHandler.smbTransaction,\n- # Not needed for now\n- smb.SMB.SMB_COM_NT_TRANSACT:        self.__smbCommandsHandler.smbNTTransact,\n- smb.SMB.SMB_COM_QUERY_INFORMATION_DISK: self.__smbCommandsHandler.smbQueryInformationDisk,\n- smb.SMB.SMB_COM_OPEN_ANDX:          self.__smbCommandsHandler.smbComOpenAndX,\n- smb.SMB.SMB_COM_QUERY_INFORMATION2: self.__smbCommandsHandler.smbComQueryInformation2,\n- smb.SMB.SMB_COM_READ_ANDX:          self.__smbCommandsHandler.smbComReadAndX,\n- smb.SMB.SMB_COM_READ:               self.__smbCommandsHandler.smbComRead,\n- smb.SMB.SMB_COM_WRITE_ANDX:         self.__smbCommandsHandler.smbComWriteAndX,\n- smb.SMB.SMB_COM_WRITE:              self.__smbCommandsHandler.smbComWrite,\n- smb.SMB.SMB_COM_CLOSE:              self.__smbCommandsHandler.smbComClose,\n- smb.SMB.SMB_COM_LOCKING_ANDX:       self.__smbCommandsHandler.smbComLockingAndX,\n- smb.SMB.SMB_COM_NT_CREATE_ANDX:     self.__smbCommandsHandler.smbComNtCreateAndX,\n- 0xFF:                               self.__smbCommandsHandler.default\n-}\n-\n-        self.__smb2Ioctls = { \n- smb2.FSCTL_DFS_GET_REFERRALS:            self.__IoctlHandler.fsctlDfsGetReferrals, \n-# smb2.FSCTL_PIPE_PEEK:                    self.__IoctlHandler.fsctlPipePeek, \n-# smb2.FSCTL_PIPE_WAIT:                    self.__IoctlHandler.fsctlPipeWait, \n- smb2.FSCTL_PIPE_TRANSCEIVE:              self.__IoctlHandler.fsctlPipeTransceive, \n-# smb2.FSCTL_SRV_COPYCHUNK:                self.__IoctlHandler.fsctlSrvCopyChunk, \n-# smb2.FSCTL_SRV_ENUMERATE_SNAPSHOTS:      self.__IoctlHandler.fsctlSrvEnumerateSnapshots, \n-# smb2.FSCTL_SRV_REQUEST_RESUME_KEY:       self.__IoctlHandler.fsctlSrvRequestResumeKey, \n-# smb2.FSCTL_SRV_READ_HASH:                self.__IoctlHandler.fsctlSrvReadHash, \n-# smb2.FSCTL_SRV_COPYCHUNK_WRITE:          self.__IoctlHandler.fsctlSrvCopyChunkWrite, \n-# smb2.FSCTL_LMR_REQUEST_RESILIENCY:       self.__IoctlHandler.fsctlLmrRequestResiliency, \n-# smb2.FSCTL_QUERY_NETWORK_INTERFACE_INFO: self.__IoctlHandler.fsctlQueryNetworkInterfaceInfo, \n-# smb2.FSCTL_SET_REPARSE_POINT:            self.__IoctlHandler.fsctlSetReparsePoint, \n-# smb2.FSCTL_DFS_GET_REFERRALS_EX:         self.__IoctlHandler.fsctlDfsGetReferralsEx, \n-# smb2.FSCTL_FILE_LEVEL_TRIM:              self.__IoctlHandler.fsctlFileLevelTrim, \n- smb2.FSCTL_VALIDATE_NEGOTIATE_INFO:      self.__IoctlHandler.fsctlValidateNegotiateInfo, \n-}\n-\n-        self.__smb2Commands = { \n- smb2.SMB2_NEGOTIATE:       self.__smb2CommandsHandler.smb2Negotiate, \n- smb2.SMB2_SESSION_SETUP:   self.__smb2CommandsHandler.smb2SessionSetup, \n- smb2.SMB2_LOGOFF:          self.__smb2CommandsHandler.smb2Logoff, \n- smb2.SMB2_TREE_CONNECT:    self.__smb2CommandsHandler.smb2TreeConnect, \n- smb2.SMB2_TREE_DISCONNECT: self.__smb2CommandsHandler.smb2TreeDisconnect, \n- smb2.SMB2_CREATE:          self.__smb2CommandsHandler.smb2Create, \n- smb2.SMB2_CLOSE:           self.__smb2CommandsHandler.smb2Close, \n- smb2.SMB2_FLUSH:           self.__smb2CommandsHandler.smb2Flush, \n- smb2.SMB2_READ:            self.__smb2CommandsHandler.smb2Read, \n- smb2.SMB2_WRITE:           self.__smb2CommandsHandler.smb2Write, \n- smb2.SMB2_LOCK:            self.__smb2CommandsHandler.smb2Lock, \n- smb2.SMB2_IOCTL:           self.__smb2CommandsHandler.smb2Ioctl, \n- smb2.SMB2_CANCEL:          self.__smb2CommandsHandler.smb2Cancel, \n- smb2.SMB2_ECHO:            self.__smb2CommandsHandler.smb2Echo, \n- smb2.SMB2_QUERY_DIRECTORY: self.__smb2CommandsHandler.smb2QueryDirectory, \n- smb2.SMB2_CHANGE_NOTIFY:   self.__smb2CommandsHandler.smb2ChangeNotify, \n- smb2.SMB2_QUERY_INFO:      self.__smb2CommandsHandler.smb2QueryInfo, \n- smb2.SMB2_SET_INFO:        self.__smb2CommandsHandler.smb2SetInfo, \n-# smb2.SMB2_OPLOCK_BREAK:    self.__smb2CommandsHandler.smb2SessionSetup, \n- 0xFF:                      self.__smb2CommandsHandler.default\n-}\n+        self.__smbCommands = {\n+            # smb.SMB.SMB_COM_FLUSH:              self.__smbCommandsHandler.smbComFlush,\n+            smb.SMB.SMB_COM_CREATE_DIRECTORY: self.__smbCommandsHandler.smbComCreateDirectory,\n+            smb.SMB.SMB_COM_DELETE_DIRECTORY: self.__smbCommandsHandler.smbComDeleteDirectory,\n+            smb.SMB.SMB_COM_RENAME: self.__smbCommandsHandler.smbComRename,\n+            smb.SMB.SMB_COM_DELETE: self.__smbCommandsHandler.smbComDelete,\n+            smb.SMB.SMB_COM_NEGOTIATE: self.__smbCommandsHandler.smbComNegotiate,\n+            smb.SMB.SMB_COM_SESSION_SETUP_ANDX: self.__smbCommandsHandler.smbComSessionSetupAndX,\n+            smb.SMB.SMB_COM_LOGOFF_ANDX: self.__smbCommandsHandler.smbComLogOffAndX,\n+            smb.SMB.SMB_COM_TREE_CONNECT_ANDX: self.__smbCommandsHandler.smbComTreeConnectAndX,\n+            smb.SMB.SMB_COM_TREE_DISCONNECT: self.__smbCommandsHandler.smbComTreeDisconnect,\n+            smb.SMB.SMB_COM_ECHO: self.__smbCommandsHandler.smbComEcho,\n+            smb.SMB.SMB_COM_QUERY_INFORMATION: self.__smbCommandsHandler.smbQueryInformation,\n+            smb.SMB.SMB_COM_TRANSACTION2: self.__smbCommandsHandler.smbTransaction2,\n+            smb.SMB.SMB_COM_TRANSACTION: self.__smbCommandsHandler.smbTransaction,\n+            # Not needed for now\n+            smb.SMB.SMB_COM_NT_TRANSACT: self.__smbCommandsHandler.smbNTTransact,\n+            smb.SMB.SMB_COM_QUERY_INFORMATION_DISK: self.__smbCommandsHandler.smbQueryInformationDisk,\n+            smb.SMB.SMB_COM_OPEN_ANDX: self.__smbCommandsHandler.smbComOpenAndX,\n+            smb.SMB.SMB_COM_QUERY_INFORMATION2: self.__smbCommandsHandler.smbComQueryInformation2,\n+            smb.SMB.SMB_COM_READ_ANDX: self.__smbCommandsHandler.smbComReadAndX,\n+            smb.SMB.SMB_COM_READ: self.__smbCommandsHandler.smbComRead,\n+            smb.SMB.SMB_COM_WRITE_ANDX: self.__smbCommandsHandler.smbComWriteAndX,\n+            smb.SMB.SMB_COM_WRITE: self.__smbCommandsHandler.smbComWrite,\n+            smb.SMB.SMB_COM_CLOSE: self.__smbCommandsHandler.smbComClose,\n+            smb.SMB.SMB_COM_LOCKING_ANDX: self.__smbCommandsHandler.smbComLockingAndX,\n+            smb.SMB.SMB_COM_NT_CREATE_ANDX: self.__smbCommandsHandler.smbComNtCreateAndX,\n+            0xFF: self.__smbCommandsHandler.default\n+        }\n+\n+        self.__smb2Ioctls = {\n+            smb2.FSCTL_DFS_GET_REFERRALS: self.__IoctlHandler.fsctlDfsGetReferrals,\n+            # smb2.FSCTL_PIPE_PEEK:                    self.__IoctlHandler.fsctlPipePeek,\n+            # smb2.FSCTL_PIPE_WAIT:                    self.__IoctlHandler.fsctlPipeWait,\n+            smb2.FSCTL_PIPE_TRANSCEIVE: self.__IoctlHandler.fsctlPipeTransceive,\n+            # smb2.FSCTL_SRV_COPYCHUNK:                self.__IoctlHandler.fsctlSrvCopyChunk,\n+            # smb2.FSCTL_SRV_ENUMERATE_SNAPSHOTS:      self.__IoctlHandler.fsctlSrvEnumerateSnapshots,\n+            # smb2.FSCTL_SRV_REQUEST_RESUME_KEY:       self.__IoctlHandler.fsctlSrvRequestResumeKey,\n+            # smb2.FSCTL_SRV_READ_HASH:                self.__IoctlHandler.fsctlSrvReadHash,\n+            # smb2.FSCTL_SRV_COPYCHUNK_WRITE:          self.__IoctlHandler.fsctlSrvCopyChunkWrite,\n+            # smb2.FSCTL_LMR_REQUEST_RESILIENCY:       self.__IoctlHandler.fsctlLmrRequestResiliency,\n+            # smb2.FSCTL_QUERY_NETWORK_INTERFACE_INFO: self.__IoctlHandler.fsctlQueryNetworkInterfaceInfo,\n+            # smb2.FSCTL_SET_REPARSE_POINT:            self.__IoctlHandler.fsctlSetReparsePoint,\n+            # smb2.FSCTL_DFS_GET_REFERRALS_EX:         self.__IoctlHandler.fsctlDfsGetReferralsEx,\n+            # smb2.FSCTL_FILE_LEVEL_TRIM:              self.__IoctlHandler.fsctlFileLevelTrim,\n+            smb2.FSCTL_VALIDATE_NEGOTIATE_INFO: self.__IoctlHandler.fsctlValidateNegotiateInfo,\n+        }\n+\n+        self.__smb2Commands = {\n+            smb2.SMB2_NEGOTIATE: self.__smb2CommandsHandler.smb2Negotiate,\n+            smb2.SMB2_SESSION_SETUP: self.__smb2CommandsHandler.smb2SessionSetup,\n+            smb2.SMB2_LOGOFF: self.__smb2CommandsHandler.smb2Logoff,\n+            smb2.SMB2_TREE_CONNECT: self.__smb2CommandsHandler.smb2TreeConnect,\n+            smb2.SMB2_TREE_DISCONNECT: self.__smb2CommandsHandler.smb2TreeDisconnect,\n+            smb2.SMB2_CREATE: self.__smb2CommandsHandler.smb2Create,\n+            smb2.SMB2_CLOSE: self.__smb2CommandsHandler.smb2Close,\n+            smb2.SMB2_FLUSH: self.__smb2CommandsHandler.smb2Flush,\n+            smb2.SMB2_READ: self.__smb2CommandsHandler.smb2Read,\n+            smb2.SMB2_WRITE: self.__smb2CommandsHandler.smb2Write,\n+            smb2.SMB2_LOCK: self.__smb2CommandsHandler.smb2Lock,\n+            smb2.SMB2_IOCTL: self.__smb2CommandsHandler.smb2Ioctl,\n+            smb2.SMB2_CANCEL: self.__smb2CommandsHandler.smb2Cancel,\n+            smb2.SMB2_ECHO: self.__smb2CommandsHandler.smb2Echo,\n+            smb2.SMB2_QUERY_DIRECTORY: self.__smb2CommandsHandler.smb2QueryDirectory,\n+            smb2.SMB2_CHANGE_NOTIFY: self.__smb2CommandsHandler.smb2ChangeNotify,\n+            smb2.SMB2_QUERY_INFO: self.__smb2CommandsHandler.smb2QueryInfo,\n+            smb2.SMB2_SET_INFO: self.__smb2CommandsHandler.smb2SetInfo,\n+            # smb2.SMB2_OPLOCK_BREAK:    self.__smb2CommandsHandler.smb2SessionSetup,\n+            0xFF: self.__smb2CommandsHandler.default\n+        }\n \n         # List of active connections\n         self.__activeConnections = {}\n-  \n+\n     def getIoctls(self):\n         return self.__smb2Ioctls\n \n@@ -3879,39 +3940,39 @@ def getCredentials(self):\n \n     def removeConnection(self, name):\n         try:\n-           del(self.__activeConnections[name])\n+            del (self.__activeConnections[name])\n         except:\n-           pass\n+            pass\n         self.log(\"Remaining connections %s\" % list(self.__activeConnections.keys()))\n \n     def addConnection(self, name, ip, port):\n         self.__activeConnections[name] = {}\n         # Let's init with some know stuff we will need to have\n         # TODO: Document what's in there\n-        #print \"Current Connections\", self.__activeConnections.keys()\n-        self.__activeConnections[name]['PacketNum']       = 0\n-        self.__activeConnections[name]['ClientIP']        = ip\n-        self.__activeConnections[name]['ClientPort']      = port\n-        self.__activeConnections[name]['Uid']             = 0\n+        # print \"Current Connections\", self.__activeConnections.keys()\n+        self.__activeConnections[name]['PacketNum'] = 0\n+        self.__activeConnections[name]['ClientIP'] = ip\n+        self.__activeConnections[name]['ClientPort'] = port\n+        self.__activeConnections[name]['Uid'] = 0\n         self.__activeConnections[name]['ConnectedShares'] = {}\n-        self.__activeConnections[name]['OpenedFiles']     = {}\n+        self.__activeConnections[name]['OpenedFiles'] = {}\n         # SID results for findfirst2\n-        self.__activeConnections[name]['SIDs']            = {}\n-        self.__activeConnections[name]['LastRequest']     = {}\n-        self.__activeConnections[name]['SignatureEnabled']= False\n-        self.__activeConnections[name]['SigningChallengeResponse']= ''\n-        self.__activeConnections[name]['SigningSessionKey']= b''\n-        self.__activeConnections[name]['Authenticated']= False\n+        self.__activeConnections[name]['SIDs'] = {}\n+        self.__activeConnections[name]['LastRequest'] = {}\n+        self.__activeConnections[name]['SignatureEnabled'] = False\n+        self.__activeConnections[name]['SigningChallengeResponse'] = ''\n+        self.__activeConnections[name]['SigningSessionKey'] = b''\n+        self.__activeConnections[name]['Authenticated'] = False\n \n     def getActiveConnections(self):\n         return self.__activeConnections\n \n     def setConnectionData(self, connId, data):\n         self.__activeConnections[connId] = data\n-        #print \"setConnectionData\" \n-        #print self.__activeConnections\n+        # print \"setConnectionData\"\n+        # print self.__activeConnections\n \n-    def getConnectionData(self, connId, checkStatus = True):\n+    def getConnectionData(self, connId, checkStatus=True):\n         conn = self.__activeConnections[connId]\n         if checkStatus is True:\n             if ('Authenticated' in conn) is not True:\n@@ -3928,16 +3989,16 @@ def registerNamedPipe(self, pipeName, address):\n \n     def unregisterNamedPipe(self, pipeName):\n         if pipeName in self.__registeredNamedPipes:\n-            del(self.__registeredNamedPipes[str(pipeName)])\n+            del (self.__registeredNamedPipes[str(pipeName)])\n             return True\n         return False\n \n     def unregisterTransaction(self, transCommand):\n         if transCommand in self.__smbTransCommands:\n-           del(self.__smbTransCommands[transCommand])\n+            del (self.__smbTransCommands[transCommand])\n \n     def hookTransaction(self, transCommand, callback):\n-        # If you call this function, callback will replace \n+        # If you call this function, callback will replace\n         # the current Transaction sub command.\n         # (don't get confused with the Transaction smbCommand)\n         # If the transaction sub command doesn't not exist, it is added\n@@ -3948,14 +4009,14 @@ def hookTransaction(self, transCommand, callback):\n         #\n         # WHERE:\n         #\n-        # connId      : the connection Id, used to grab\/update information about \n+        # connId      : the connection Id, used to grab\/update information about\n         #               the current connection\n-        # smbServer   : the SMBServer instance available for you to ask \n+        # smbServer   : the SMBServer instance available for you to ask\n         #               configuration data\n         # recvPacket  : the full SMBPacket that triggered this command\n         # parameters  : the transaction parameters\n         # data        : the transaction data\n-        # maxDataCount: the max amount of data that can be transferred agreed \n+        # maxDataCount: the max amount of data that can be transferred agreed\n         #               with the client\n         #\n         # and MUST return:\n@@ -3966,53 +4027,53 @@ def hookTransaction(self, transCommand, callback):\n         # respSetup: the setup response of the transaction\n         # respParameters: the parameters response of the transaction\n         # respData: the data response of the transaction\n-        # errorCode: the NT error code \n+        # errorCode: the NT error code\n \n         if transCommand in self.__smbTransCommands:\n-           originalCommand = self.__smbTransCommands[transCommand]\n+            originalCommand = self.__smbTransCommands[transCommand]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smbTransCommands[transCommand] = callback\n         return originalCommand\n \n     def unregisterTransaction2(self, transCommand):\n         if transCommand in self.__smbTrans2Commands:\n-           del(self.__smbTrans2Commands[transCommand])\n+            del (self.__smbTrans2Commands[transCommand])\n \n     def hookTransaction2(self, transCommand, callback):\n         # Here we should add to __smbTrans2Commands\n         # Same description as Transaction\n         if transCommand in self.__smbTrans2Commands:\n-           originalCommand = self.__smbTrans2Commands[transCommand]\n+            originalCommand = self.__smbTrans2Commands[transCommand]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smbTrans2Commands[transCommand] = callback\n         return originalCommand\n \n     def unregisterNTTransaction(self, transCommand):\n         if transCommand in self.__smbNTTransCommands:\n-           del(self.__smbNTTransCommands[transCommand])\n+            del (self.__smbNTTransCommands[transCommand])\n \n     def hookNTTransaction(self, transCommand, callback):\n         # Here we should add to __smbNTTransCommands\n         # Same description as Transaction\n         if transCommand in self.__smbNTTransCommands:\n-           originalCommand = self.__smbNTTransCommands[transCommand]\n+            originalCommand = self.__smbNTTransCommands[transCommand]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smbNTTransCommands[transCommand] = callback\n         return originalCommand\n \n     def unregisterSmbCommand(self, smbCommand):\n         if smbCommand in self.__smbCommands:\n-           del(self.__smbCommands[smbCommand])\n+            del (self.__smbCommands[smbCommand])\n \n     def hookSmbCommand(self, smbCommand, callback):\n         # Here we should add to self.__smbCommands\n-        # If you call this function, callback will replace \n+        # If you call this function, callback will replace\n         # the current smbCommand.\n         # If smbCommand doesn't not exist, it is added\n         # If SMB command exists, it returns the original function replaced\n@@ -4022,19 +4083,19 @@ def hookSmbCommand(self, smbCommand, callback):\n         #\n         # WHERE:\n         #\n-        # connId    : the connection Id, used to grab\/update information about \n+        # connId    : the connection Id, used to grab\/update information about\n         #             the current connection\n-        # smbServer : the SMBServer instance available for you to ask \n+        # smbServer : the SMBServer instance available for you to ask\n         #             configuration data\n-        # SMBCommand: the SMBCommand itself, with its data and parameters. \n+        # SMBCommand: the SMBCommand itself, with its data and parameters.\n         #             Check smb.py:SMBCommand() for a reference\n         # recvPacket: the full SMBPacket that triggered this command\n         #\n         # and MUST return:\n         # <list of respSMBCommands>, <list of packets>, errorCode\n-        # <list of packets> has higher preference over commands, in case you \n-        # want to change the whole packet \n-        # errorCode: the NT error code \n+        # <list of packets> has higher preference over commands, in case you\n+        # want to change the whole packet\n+        # errorCode: the NT error code\n         #\n         # For SMB_COM_TRANSACTION2, SMB_COM_TRANSACTION and SMB_COM_NT_TRANSACT\n         # the callback function is slightly different:\n@@ -4042,46 +4103,46 @@ def hookSmbCommand(self, smbCommand, callback):\n         # callback(connId, smbServer, SMBCommand, recvPacket, transCommands)\n         #\n         # WHERE:\n-        # \n+        #\n         # transCommands: a list of transaction subcommands already registered\n         #\n \n         if smbCommand in self.__smbCommands:\n-           originalCommand = self.__smbCommands[smbCommand]\n+            originalCommand = self.__smbCommands[smbCommand]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smbCommands[smbCommand] = callback\n         return originalCommand\n-  \n+\n     def unregisterSmb2Command(self, smb2Command):\n         if smb2Command in self.__smb2Commands:\n-           del(self.__smb2Commands[smb2Command])\n+            del (self.__smb2Commands[smb2Command])\n \n     def hookSmb2Command(self, smb2Command, callback):\n         if smb2Command in self.__smb2Commands:\n-           originalCommand = self.__smb2Commands[smb2Command]\n+            originalCommand = self.__smb2Commands[smb2Command]\n         else:\n-           originalCommand = None \n+            originalCommand = None\n \n         self.__smb2Commands[smb2Command] = callback\n         return originalCommand\n \n     def log(self, msg, level=logging.INFO):\n-        self.__log.log(level,msg)\n+        self.__log.log(level, msg)\n \n     def getServerName(self):\n         return self.__serverName\n \n     def getServerOS(self):\n         return self.__serverOS\n-  \n+\n     def getServerDomain(self):\n         return self.__serverDomain\n \n     def getSMBChallenge(self):\n         return self.__challenge\n-  \n+\n     def getServerConfig(self):\n         return self.__serverConfig\n \n@@ -4116,47 +4177,47 @@ def signSMBv1(self, connData, packet, signingSessionKey, signingChallengeRespons\n         # The resulting 8-byte signature MUST be copied into the SecuritySignature field of the SMB Header,\n         # after which the message can be transmitted.\n \n-        #print \"seq(%d) signingSessionKey %r, signingChallengeResponse %r\" % (connData['SignSequenceNumber'], signingSessionKey, signingChallengeResponse)\n-        packet['SecurityFeatures'] = struct.pack('<q',connData['SignSequenceNumber'])\n+        # print \"seq(%d) signingSessionKey %r, signingChallengeResponse %r\" % (connData['SignSequenceNumber'], signingSessionKey, signingChallengeResponse)\n+        packet['SecurityFeatures'] = struct.pack('<q', connData['SignSequenceNumber'])\n         # Sign with the sequence\n         m = hashlib.md5()\n-        m.update( signingSessionKey )\n-        m.update( signingChallengeResponse )\n+        m.update(signingSessionKey)\n+        m.update(signingChallengeResponse)\n         if hasattr(packet, 'getData'):\n-            m.update( packet.getData() )\n+            m.update(packet.getData())\n         else:\n-            m.update( packet )\n+            m.update(packet)\n         # Replace sequence with acual hash\n         packet['SecurityFeatures'] = m.digest()[:8]\n-        connData['SignSequenceNumber'] +=2\n+        connData['SignSequenceNumber'] += 2\n \n     def signSMBv2(self, packet, signingSessionKey):\n-        packet['Signature'] = b'\\x00'*16\n+        packet['Signature'] = b'\\x00' * 16\n         packet['Flags'] |= smb2.SMB2_FLAGS_SIGNED\n         signature = hmac.new(signingSessionKey, packet.getData(), hashlib.sha256).digest()\n         packet['Signature'] = signature[:16]\n-        #print \"%s\" % packet['Signature'].encode('hex')\n+        # print \"%s\" % packet['Signature'].encode('hex')\n \n     def processRequest(self, connId, data):\n \n         # TODO: Process batched commands.\n-        isSMB2      = False\n-        SMBCommand  = None\n+        isSMB2 = False\n+        SMBCommand = None\n         try:\n-            packet = smb.NewSMBPacket(data = data)\n-            SMBCommand  = smb.SMBCommand(packet['Data'][0])\n+            packet = smb.NewSMBPacket(data=data)\n+            SMBCommand = smb.SMBCommand(packet['Data'][0])\n         except:\n             # Maybe a SMB2 packet?\n-            packet = smb2.SMB2Packet(data = data)\n+            packet = smb2.SMB2Packet(data=data)\n             connData = self.getConnectionData(connId, False)\n             self.signSMBv2(packet, connData['SigningSessionKey'])\n             isSMB2 = True\n \n-        connData    = self.getConnectionData(connId, False)\n+        connData = self.getConnectionData(connId, False)\n \n         # We might have compound requests\n         compoundedPacketsResponse = []\n-        compoundedPackets         = []\n+        compoundedPackets = []\n         try:\n             # Search out list of implemented commands\n             # We provide them with:\n@@ -4173,7 +4234,8 @@ def processRequest(self, connId, data):\n             # errorCode   : self explanatory\n             if isSMB2 is False:\n                 # Is the client authenticated already?\n-                if connData['Authenticated'] is False and packet['Command'] not in (smb.SMB.SMB_COM_NEGOTIATE, smb.SMB.SMB_COM_SESSION_SETUP_ANDX):\n+                if connData['Authenticated'] is False and packet['Command'] not in (\n+                smb.SMB.SMB_COM_NEGOTIATE, smb.SMB.SMB_COM_SESSION_SETUP_ANDX):\n                     # Nope.. in that case he should only ask for a few commands, if not throw him out.\n                     errorCode = STATUS_ACCESS_DENIED\n                     respPackets = None\n@@ -4181,65 +4243,68 @@ def processRequest(self, connId, data):\n                 else:\n                     if packet['Command'] == smb.SMB.SMB_COM_TRANSACTION2:\n                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                      connId,\n-                                      self,\n-                                      SMBCommand,\n-                                      packet,\n-                                      self.__smbTrans2Commands)\n+                            connId,\n+                            self,\n+                            SMBCommand,\n+                            packet,\n+                            self.__smbTrans2Commands)\n                     elif packet['Command'] == smb.SMB.SMB_COM_NT_TRANSACT:\n                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                      connId,\n-                                      self,\n-                                      SMBCommand,\n-                                      packet,\n-                                      self.__smbNTTransCommands)\n+                            connId,\n+                            self,\n+                            SMBCommand,\n+                            packet,\n+                            self.__smbNTTransCommands)\n                     elif packet['Command'] == smb.SMB.SMB_COM_TRANSACTION:\n                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                      connId,\n-                                      self,\n-                                      SMBCommand,\n-                                      packet,\n-                                      self.__smbTransCommands)\n+                            connId,\n+                            self,\n+                            SMBCommand,\n+                            packet,\n+                            self.__smbTransCommands)\n                     else:\n                         if packet['Command'] in self.__smbCommands:\n-                           if self.__SMB2Support is True:\n-                               if packet['Command'] == smb.SMB.SMB_COM_NEGOTIATE:\n-                                   try:\n-                                       respCommands, respPackets, errorCode = self.__smb2Commands[smb2.SMB2_NEGOTIATE](connId, self, packet, True)\n-                                       isSMB2 = True\n-                                   except Exception as e:\n-                                       import traceback\n-                                       traceback.print_exc()\n-                                       self.log('SMB2_NEGOTIATE: %s' % e, logging.ERROR)\n-                                       # If something went wrong, let's fallback to SMB1\n-                                       respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                           connId,\n-                                           self,\n-                                           SMBCommand,\n-                                           packet)\n-                                       #self.__SMB2Support = False\n-                                       pass\n-                               else:\n-                                   respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                           connId,\n-                                           self,\n-                                           SMBCommand,\n-                                           packet)\n-                           else:\n-                               respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n-                                           connId,\n-                                           self,\n-                                           SMBCommand,\n-                                           packet)\n+                            if self.__SMB2Support is True:\n+                                if packet['Command'] == smb.SMB.SMB_COM_NEGOTIATE:\n+                                    try:\n+                                        respCommands, respPackets, errorCode = self.__smb2Commands[smb2.SMB2_NEGOTIATE](\n+                                            connId, self, packet, True)\n+                                        isSMB2 = True\n+                                    except Exception as e:\n+                                        import traceback\n+                                        traceback.print_exc()\n+                                        self.log('SMB2_NEGOTIATE: %s' % e, logging.ERROR)\n+                                        # If something went wrong, let's fallback to SMB1\n+                                        respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n+                                            connId,\n+                                            self,\n+                                            SMBCommand,\n+                                            packet)\n+                                        # self.__SMB2Support = False\n+                                        pass\n+                                else:\n+                                    respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n+                                        connId,\n+                                        self,\n+                                        SMBCommand,\n+                                        packet)\n+                            else:\n+                                respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](\n+                                    connId,\n+                                    self,\n+                                    SMBCommand,\n+                                    packet)\n                         else:\n-                           respCommands, respPackets, errorCode = self.__smbCommands[255](connId, self, SMBCommand, packet)\n+                            respCommands, respPackets, errorCode = self.__smbCommands[255](connId, self, SMBCommand,\n+                                                                                           packet)\n \n                 compoundedPacketsResponse.append((respCommands, respPackets, errorCode))\n                 compoundedPackets.append(packet)\n \n             else:\n                 # Is the client authenticated already?\n-                if connData['Authenticated'] is False and packet['Command'] not in (smb2.SMB2_NEGOTIATE, smb2.SMB2_SESSION_SETUP):\n+                if connData['Authenticated'] is False and packet['Command'] not in (\n+                smb2.SMB2_NEGOTIATE, smb2.SMB2_SESSION_SETUP):\n                     # Nope.. in that case he should only ask for a few commands, if not throw him out.\n                     errorCode = STATUS_ACCESS_DENIED\n                     respPackets = None\n@@ -4250,37 +4315,37 @@ def processRequest(self, connId, data):\n                     done = False\n                     while not done:\n                         if packet['Command'] in self.__smb2Commands:\n-                           if self.__SMB2Support is True:\n-                               respCommands, respPackets, errorCode = self.__smb2Commands[packet['Command']](\n-                                       connId,\n-                                       self,\n-                                       packet)\n-                           else:\n-                               respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)\n+                            if self.__SMB2Support is True:\n+                                respCommands, respPackets, errorCode = self.__smb2Commands[packet['Command']](\n+                                    connId,\n+                                    self,\n+                                    packet)\n+                            else:\n+                                respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)\n                         else:\n-                           respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)\n+                            respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)\n                         # Let's store the result for this compounded packet\n                         compoundedPacketsResponse.append((respCommands, respPackets, errorCode))\n                         compoundedPackets.append(packet)\n                         if packet['NextCommand'] != 0:\n                             data = data[packet['NextCommand']:]\n-                            packet = smb2.SMB2Packet(data = data)\n+                            packet = smb2.SMB2Packet(data=data)\n                         else:\n                             done = True\n \n         except Exception as e:\n-            #import traceback\n-            #traceback.print_exc()\n+            # import traceback\n+            # traceback.print_exc()\n             # Something wen't wrong, defaulting to Bad user ID\n-            self.log('processRequest (0x%x,%s)' % (packet['Command'],e), logging.ERROR)\n+            self.log('processRequest (0x%x,%s)' % (packet['Command'], e), logging.ERROR)\n             raise\n \n         # We prepare the response packet to commands don't need to bother about that.\n-        connData    = self.getConnectionData(connId, False)\n+        connData = self.getConnectionData(connId, False)\n \n         # Force reconnection loop.. This is just a test.. client will send me back credentials :)\n-        #connData['PacketNum'] += 1\n-        #if connData['PacketNum'] == 15:\n+        # connData['PacketNum'] += 1\n+        # if connData['PacketNum'] == 15:\n         #    connData['PacketNum'] = 0\n         #    # Something wen't wrong, defaulting to Bad user ID\n         #    self.log('Sending BAD USER ID!', logging.ERROR)\n@@ -4292,7 +4357,7 @@ def processRequest(self, connId, data):\n         #    packet['ErrorClass']  = errorCode & 0xff\n         #    return [packet]\n \n-        self.setConnectionData(connId, connData)    \n+        self.setConnectionData(connId, connData)\n \n         packetsToSend = []\n         for packetNum in range(len(compoundedPacketsResponse)):\n@@ -4301,49 +4366,51 @@ def processRequest(self, connId, data):\n             if respPackets is None:\n                 for respCommand in respCommands:\n                     if isSMB2 is False:\n-                        respPacket           = smb.NewSMBPacket()\n+                        respPacket = smb.NewSMBPacket()\n                         respPacket['Flags1'] = smb.SMB.FLAGS1_REPLY\n \n                         # TODO this should come from a per session configuration\n-                        respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | packet['Flags2'] & smb.SMB.FLAGS2_UNICODE\n-                        #respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES \n-                        #respPacket['Flags1'] = 0x98\n-                        #respPacket['Flags2'] = 0xc807\n-                \n-\n-                        respPacket['Tid']    = packet['Tid']\n-                        respPacket['Mid']    = packet['Mid']\n-                        respPacket['Pid']    = packet['Pid']\n-                        respPacket['Uid']    = connData['Uid']\n-        \n-                        respPacket['ErrorCode']   = errorCode >> 16\n-                        respPacket['_reserved']   = errorCode >> 8 & 0xff\n-                        respPacket['ErrorClass']  = errorCode & 0xff\n+                        respPacket[\n+                            'Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | \\\n+                                        packet['Flags2'] & smb.SMB.FLAGS2_UNICODE\n+                        # respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES\n+                        # respPacket['Flags1'] = 0x98\n+                        # respPacket['Flags2'] = 0xc807\n+\n+                        respPacket['Tid'] = packet['Tid']\n+                        respPacket['Mid'] = packet['Mid']\n+                        respPacket['Pid'] = packet['Pid']\n+                        respPacket['Uid'] = connData['Uid']\n+\n+                        respPacket['ErrorCode'] = errorCode >> 16\n+                        respPacket['_reserved'] = errorCode >> 8 & 0xff\n+                        respPacket['ErrorClass'] = errorCode & 0xff\n                         respPacket.addCommand(respCommand)\n \n                         if connData['SignatureEnabled']:\n                             respPacket['Flags2'] |= smb.SMB.FLAGS2_SMB_SECURITY_SIGNATURE\n-                            self.signSMBv1(connData, respPacket, connData['SigningSessionKey'], connData['SigningChallengeResponse'])\n-            \n+                            self.signSMBv1(connData, respPacket, connData['SigningSessionKey'],\n+                                           connData['SigningChallengeResponse'])\n+\n                         packetsToSend.append(respPacket)\n                     else:\n                         respPacket = smb2.SMB2Packet()\n-                        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n+                        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR\n                         if packetNum > 0:\n                             respPacket['Flags'] |= smb2.SMB2_FLAGS_RELATED_OPERATIONS\n-                        respPacket['Status']    = errorCode\n+                        respPacket['Status'] = errorCode\n                         respPacket['CreditRequestResponse'] = packet['CreditRequestResponse']\n-                        respPacket['Command']   = packet['Command']\n+                        respPacket['Command'] = packet['Command']\n                         respPacket['CreditCharge'] = packet['CreditCharge']\n-                        #respPacket['CreditCharge'] = 0\n-                        respPacket['Reserved']  = packet['Reserved']\n+                        # respPacket['CreditCharge'] = 0\n+                        respPacket['Reserved'] = packet['Reserved']\n                         respPacket['SessionID'] = connData['Uid']\n                         respPacket['MessageID'] = packet['MessageID']\n-                        respPacket['TreeID']    = packet['TreeID']\n+                        respPacket['TreeID'] = packet['TreeID']\n                         if hasattr(respCommand, 'getData'):\n-                            respPacket['Data']      = respCommand.getData()\n+                            respPacket['Data'] = respCommand.getData()\n                         else:\n-                            respPacket['Data']      = str(respCommand)\n+                            respPacket['Data'] = str(respCommand)\n \n                         if connData['SignatureEnabled']:\n                             self.signSMBv2(respPacket, connData['SigningSessionKey'])\n@@ -4357,21 +4424,21 @@ def processRequest(self, connId, data):\n             # Let's build a compound answer\n             finalData = b''\n             i = 0\n-            for i in range(len(packetsToSend)-1):\n+            for i in range(len(packetsToSend) - 1):\n                 packet = packetsToSend[i]\n                 # Align to 8-bytes\n-                padLen = (8 - (len(packet) % 8) ) % 8\n+                padLen = (8 - (len(packet) % 8)) % 8\n                 packet['NextCommand'] = len(packet) + padLen\n                 if hasattr(packet, 'getData'):\n-                    finalData += packet.getData() + padLen*b'\\x00'\n+                    finalData += packet.getData() + padLen * b'\\x00'\n                 else:\n-                    finalData += packet + padLen*b'\\x00'\n+                    finalData += packet + padLen * b'\\x00'\n \n             # Last one\n-            if hasattr(packetsToSend[len(packetsToSend)-1], 'getData'):\n-                finalData += packetsToSend[len(packetsToSend)-1].getData()\n+            if hasattr(packetsToSend[len(packetsToSend) - 1], 'getData'):\n+                finalData += packetsToSend[len(packetsToSend) - 1].getData()\n             else:\n-                finalData += packetsToSend[len(packetsToSend)-1]\n+                finalData += packetsToSend[len(packetsToSend) - 1]\n             packetsToSend = [finalData]\n \n         # We clear the compound requests\n@@ -4379,7 +4446,7 @@ def processRequest(self, connId, data):\n \n         return packetsToSend\n \n-    def processConfigFile(self, configFile = None):\n+    def processConfigFile(self, configFile=None):\n         # TODO: Do a real config parser\n         if self.__serverConfig is None:\n             if configFile is None:\n@@ -4387,32 +4454,32 @@ def processConfigFile(self, configFile = None):\n             self.__serverConfig = configparser.ConfigParser()\n             self.__serverConfig.read(configFile)\n \n-        self.__serverName   = self.__serverConfig.get('global','server_name')\n-        self.__serverOS     = self.__serverConfig.get('global','server_os')\n-        self.__serverDomain = self.__serverConfig.get('global','server_domain')\n-        self.__logFile      = self.__serverConfig.get('global','log_file')\n+        self.__serverName = self.__serverConfig.get('global', 'server_name')\n+        self.__serverOS = self.__serverConfig.get('global', 'server_os')\n+        self.__serverDomain = self.__serverConfig.get('global', 'server_domain')\n+        self.__logFile = self.__serverConfig.get('global', 'log_file')\n         if self.__serverConfig.has_option('global', 'challenge'):\n-            self.__challenge    = unhexlify(self.__serverConfig.get('global', 'challenge'))\n+            self.__challenge = unhexlify(self.__serverConfig.get('global', 'challenge'))\n         else:\n-            self.__challenge    = b'A'*16\n+            self.__challenge = b'A' * 16\n \n         if self.__serverConfig.has_option(\"global\", \"jtr_dump_path\"):\n             self.__jtr_dump_path = self.__serverConfig.get(\"global\", \"jtr_dump_path\")\n \n         if self.__serverConfig.has_option(\"global\", \"SMB2Support\"):\n-            self.__SMB2Support = self.__serverConfig.getboolean(\"global\",\"SMB2Support\")\n+            self.__SMB2Support = self.__serverConfig.getboolean(\"global\", \"SMB2Support\")\n         else:\n             self.__SMB2Support = False\n \n         if self.__logFile != 'None':\n-            logging.basicConfig(filename = self.__logFile, \n-                             level = logging.DEBUG, \n-                             format=\"%(asctime)s: %(levelname)s: %(message)s\", \n-                             datefmt = '%m\/%d\/%Y %I:%M:%S %p')\n-        self.__log        = LOG\n+            logging.basicConfig(filename=self.__logFile,\n+                                level=logging.DEBUG,\n+                                format=\"%(asctime)s: %(levelname)s: %(message)s\",\n+                                datefmt='%m\/%d\/%Y %I:%M:%S %p')\n+        self.__log = LOG\n \n         # Process the credentials\n-        credentials_fname = self.__serverConfig.get('global','credentials_file')\n+        credentials_fname = self.__serverConfig.get('global', 'credentials_file')\n         if credentials_fname != \"\":\n             cred = open(credentials_fname)\n             line = cred.readline()\n@@ -4430,13 +4497,14 @@ def addCredential(self, name, uid, lmhash, nthash):\n                 lmhash = '0%s' % lmhash\n             if len(nthash) % 2:\n                 nthash = '0%s' % nthash\n-            try: # just in case they were converted already\n+            try:  # just in case they were converted already\n                 lmhash = a2b_hex(lmhash)\n                 nthash = a2b_hex(nthash)\n             except:\n                 pass\n         self.__credentials[name.lower()] = (uid, lmhash, nthash)\n \n+\n # For windows platforms, opening a directory is not an option, so we set a void FD\n VOID_FILE_DESCRIPTOR = -1\n PIPE_FILE_DESCRIPTOR = -2\n@@ -4447,19 +4515,21 @@ def addCredential(self, name, uid, lmhash, nthash):\n \n from impacket.dcerpc.v5.rpcrt import DCERPCServer\n from impacket.dcerpc.v5.dtypes import NULL\n-from impacket.dcerpc.v5.srvs import NetrShareEnum, NetrShareEnumResponse, SHARE_INFO_1, NetrServerGetInfo, NetrServerGetInfoResponse, NetrShareGetInfo, NetrShareGetInfoResponse\n+from impacket.dcerpc.v5.srvs import NetrShareEnum, NetrShareEnumResponse, SHARE_INFO_1, NetrServerGetInfo, \\\n+    NetrServerGetInfoResponse, NetrShareGetInfo, NetrShareGetInfoResponse\n from impacket.dcerpc.v5.wkst import NetrWkstaGetInfo, NetrWkstaGetInfoResponse\n from impacket.system_errors import ERROR_INVALID_LEVEL\n \n+\n class WKSTServer(DCERPCServer):\n     def __init__(self):\n         DCERPCServer.__init__(self)\n         self.wkssvcCallBacks = {\n             0: self.NetrWkstaGetInfo,\n         }\n-        self.addCallbacks(('6BFFD098-A112-3610-9833-46C3F87E345A', '1.0'),'\\\\PIPE\\\\wkssvc', self.wkssvcCallBacks)\n+        self.addCallbacks(('6BFFD098-A112-3610-9833-46C3F87E345A', '1.0'), '\\\\PIPE\\\\wkssvc', self.wkssvcCallBacks)\n \n-    def NetrWkstaGetInfo(self,data):\n+    def NetrWkstaGetInfo(self, data):\n         request = NetrWkstaGetInfo(data)\n         self.log(\"NetrWkstaGetInfo Level: %d\" % request['Level'])\n \n@@ -4489,6 +4559,7 @@ def NetrWkstaGetInfo(self,data):\n \n         return answer\n \n+\n class SRVSServer(DCERPCServer):\n     def __init__(self):\n         DCERPCServer.__init__(self)\n@@ -4503,86 +4574,87 @@ def __init__(self):\n             21: self.NetrServerGetInfo,\n         }\n \n-        self.addCallbacks(('4B324FC8-1670-01D3-1278-5A47BF6EE188', '3.0'),'\\\\PIPE\\\\srvsvc', self.srvsvcCallBacks)\n+        self.addCallbacks(('4B324FC8-1670-01D3-1278-5A47BF6EE188', '3.0'), '\\\\PIPE\\\\srvsvc', self.srvsvcCallBacks)\n \n     def setServerConfig(self, config):\n         self.__serverConfig = config\n \n     def processConfigFile(self, configFile=None):\n-       if configFile is not None:\n-           self.__serverConfig = configparser.ConfigParser()\n-           self.__serverConfig.read(configFile)\n-       sections = self.__serverConfig.sections()\n-       # Let's check the log file\n-       self.__logFile      = self.__serverConfig.get('global','log_file')\n-       if self.__logFile != 'None':\n-            logging.basicConfig(filename = self.__logFile, \n-                             level = logging.DEBUG, \n-                             format=\"%(asctime)s: %(levelname)s: %(message)s\", \n-                             datefmt = '%m\/%d\/%Y %I:%M:%S %p')\n-\n-       # Remove the global one\n-       del(sections[sections.index('global')])\n-       self._shares = {}\n-       for i in sections:\n-           self._shares[i] = dict(self.__serverConfig.items(i))\n-\n-    def NetrShareGetInfo(self,data):\n-       request = NetrShareGetInfo(data)\n-       self.log(\"NetrGetShareInfo Level: %d\" % request['Level'])\n-\n-       s = request['NetName'][:-1].upper()\n-       answer = NetrShareGetInfoResponse()\n-       if s in self._shares:\n-           share  = self._shares[s]\n-\n-           answer['InfoStruct']['tag'] = 1\n-           answer['InfoStruct']['ShareInfo1']['shi1_netname']= s+'\\x00'\n-           answer['InfoStruct']['ShareInfo1']['shi1_type']   = share['share type']\n-           answer['InfoStruct']['ShareInfo1']['shi1_remark'] = share['comment']+'\\x00' \n-           answer['ErrorCode'] = 0\n-       else:\n-           answer['InfoStruct']['tag'] = 1\n-           answer['InfoStruct']['ShareInfo1']= NULL\n-           answer['ErrorCode'] = 0x0906 #WERR_NET_NAME_NOT_FOUND\n-\n-       return answer\n-\n-    def NetrServerGetInfo(self,data):\n-       request = NetrServerGetInfo(data)\n-       self.log(\"NetrServerGetInfo Level: %d\" % request['Level'])\n-       answer = NetrServerGetInfoResponse()\n-       answer['InfoStruct']['tag'] = 101\n-       # PLATFORM_ID_NT = 500\n-       answer['InfoStruct']['ServerInfo101']['sv101_platform_id'] = 500\n-       answer['InfoStruct']['ServerInfo101']['sv101_name'] = request['ServerName']\n-       # Windows 7 = 6.1\n-       answer['InfoStruct']['ServerInfo101']['sv101_version_major'] = 6\n-       answer['InfoStruct']['ServerInfo101']['sv101_version_minor'] = 1\n-       # Workstation = 1\n-       answer['InfoStruct']['ServerInfo101']['sv101_type'] = 1\n-       answer['InfoStruct']['ServerInfo101']['sv101_comment'] = NULL\n-       answer['ErrorCode'] = 0\n-       return answer\n+        if configFile is not None:\n+            self.__serverConfig = configparser.ConfigParser()\n+            self.__serverConfig.read(configFile)\n+        sections = self.__serverConfig.sections()\n+        # Let's check the log file\n+        self.__logFile = self.__serverConfig.get('global', 'log_file')\n+        if self.__logFile != 'None':\n+            logging.basicConfig(filename=self.__logFile,\n+                                level=logging.DEBUG,\n+                                format=\"%(asctime)s: %(levelname)s: %(message)s\",\n+                                datefmt='%m\/%d\/%Y %I:%M:%S %p')\n+\n+        # Remove the global one\n+        del (sections[sections.index('global')])\n+        self._shares = {}\n+        for i in sections:\n+            self._shares[i] = dict(self.__serverConfig.items(i))\n+\n+    def NetrShareGetInfo(self, data):\n+        request = NetrShareGetInfo(data)\n+        self.log(\"NetrGetShareInfo Level: %d\" % request['Level'])\n+\n+        s = request['NetName'][:-1].upper()\n+        answer = NetrShareGetInfoResponse()\n+        if s in self._shares:\n+            share = self._shares[s]\n+\n+            answer['InfoStruct']['tag'] = 1\n+            answer['InfoStruct']['ShareInfo1']['shi1_netname'] = s + '\\x00'\n+            answer['InfoStruct']['ShareInfo1']['shi1_type'] = share['share type']\n+            answer['InfoStruct']['ShareInfo1']['shi1_remark'] = share['comment'] + '\\x00'\n+            answer['ErrorCode'] = 0\n+        else:\n+            answer['InfoStruct']['tag'] = 1\n+            answer['InfoStruct']['ShareInfo1'] = NULL\n+            answer['ErrorCode'] = 0x0906  # WERR_NET_NAME_NOT_FOUND\n+\n+        return answer\n+\n+    def NetrServerGetInfo(self, data):\n+        request = NetrServerGetInfo(data)\n+        self.log(\"NetrServerGetInfo Level: %d\" % request['Level'])\n+        answer = NetrServerGetInfoResponse()\n+        answer['InfoStruct']['tag'] = 101\n+        # PLATFORM_ID_NT = 500\n+        answer['InfoStruct']['ServerInfo101']['sv101_platform_id'] = 500\n+        answer['InfoStruct']['ServerInfo101']['sv101_name'] = request['ServerName']\n+        # Windows 7 = 6.1\n+        answer['InfoStruct']['ServerInfo101']['sv101_version_major'] = 6\n+        answer['InfoStruct']['ServerInfo101']['sv101_version_minor'] = 1\n+        # Workstation = 1\n+        answer['InfoStruct']['ServerInfo101']['sv101_type'] = 1\n+        answer['InfoStruct']['ServerInfo101']['sv101_comment'] = NULL\n+        answer['ErrorCode'] = 0\n+        return answer\n \n     def NetrShareEnum(self, data):\n-       request = NetrShareEnum(data)\n-       self.log(\"NetrShareEnum Level: %d\" % request['InfoStruct']['Level'])\n-       shareEnum = NetrShareEnumResponse()\n-       shareEnum['InfoStruct']['Level'] = 1\n-       shareEnum['InfoStruct']['ShareInfo']['tag'] = 1\n-       shareEnum['TotalEntries'] = len(self._shares)\n-       shareEnum['InfoStruct']['ShareInfo']['Level1']['EntriesRead'] = len(self._shares)\n-       shareEnum['ErrorCode'] = 0\n-\n-       for i in self._shares:\n-           shareInfo = SHARE_INFO_1()\n-           shareInfo['shi1_netname'] = i+'\\x00'\n-           shareInfo['shi1_type'] = self._shares[i]['share type']\n-           shareInfo['shi1_remark'] = self._shares[i]['comment']+'\\x00'\n-           shareEnum['InfoStruct']['ShareInfo']['Level1']['Buffer'].append(shareInfo)\n-\n-       return shareEnum\n+        request = NetrShareEnum(data)\n+        self.log(\"NetrShareEnum Level: %d\" % request['InfoStruct']['Level'])\n+        shareEnum = NetrShareEnumResponse()\n+        shareEnum['InfoStruct']['Level'] = 1\n+        shareEnum['InfoStruct']['ShareInfo']['tag'] = 1\n+        shareEnum['TotalEntries'] = len(self._shares)\n+        shareEnum['InfoStruct']['ShareInfo']['Level1']['EntriesRead'] = len(self._shares)\n+        shareEnum['ErrorCode'] = 0\n+\n+        for i in self._shares:\n+            shareInfo = SHARE_INFO_1()\n+            shareInfo['shi1_netname'] = i + '\\x00'\n+            shareInfo['shi1_type'] = self._shares[i]['share type']\n+            shareInfo['shi1_remark'] = self._shares[i]['comment'] + '\\x00'\n+            shareEnum['InfoStruct']['ShareInfo']['Level1']['Buffer'].append(shareInfo)\n+\n+        return shareEnum\n+\n \n class SimpleSMBServer:\n     \"\"\"\n@@ -4592,44 +4664,47 @@ class SimpleSMBServer:\n     :param integer listenPort: the port number you want the server to listen on\n     :param string configFile: a file with all the servers' configuration. If no file specified, this class will create the basic parameters needed to run. You will need to add your shares manually tho. See addShare() method\n     \"\"\"\n-    def __init__(self, listenAddress = '0.0.0.0', listenPort=445, configFile=''):\n+\n+    def __init__(self, listenAddress='0.0.0.0', listenPort=445, configFile=''):\n         if configFile != '':\n-            self.__server = SMBSERVER((listenAddress,listenPort))\n+            self.__server = SMBSERVER((listenAddress, listenPort))\n             self.__server.processConfigFile(configFile)\n             self.__smbConfig = None\n         else:\n             # Here we write a mini config for the server\n             self.__smbConfig = configparser.ConfigParser()\n             self.__smbConfig.add_section('global')\n-            self.__smbConfig.set('global','server_name',''.join([random.choice(string.ascii_letters) for _ in range(8)]))\n-            self.__smbConfig.set('global','server_os',''.join([random.choice(string.ascii_letters) for _ in range(8)])\n-)\n-            self.__smbConfig.set('global','server_domain',''.join([random.choice(string.ascii_letters) for _ in range(8)])\n-)\n-            self.__smbConfig.set('global','log_file','None')\n-            self.__smbConfig.set('global','rpc_apis','yes')\n-            self.__smbConfig.set('global','credentials_file','')\n-            self.__smbConfig.set('global', 'challenge', \"A\"*16)\n+            self.__smbConfig.set('global', 'server_name',\n+                                 ''.join([random.choice(string.ascii_letters) for _ in range(8)]))\n+            self.__smbConfig.set('global', 'server_os', ''.join([random.choice(string.ascii_letters) for _ in range(8)])\n+                                 )\n+            self.__smbConfig.set('global', 'server_domain',\n+                                 ''.join([random.choice(string.ascii_letters) for _ in range(8)])\n+                                 )\n+            self.__smbConfig.set('global', 'log_file', 'None')\n+            self.__smbConfig.set('global', 'rpc_apis', 'yes')\n+            self.__smbConfig.set('global', 'credentials_file', '')\n+            self.__smbConfig.set('global', 'challenge', \"A\" * 16)\n \n             # IPC always needed\n             self.__smbConfig.add_section('IPC$')\n-            self.__smbConfig.set('IPC$','comment','')\n-            self.__smbConfig.set('IPC$','read only','yes')\n-            self.__smbConfig.set('IPC$','share type','3')\n-            self.__smbConfig.set('IPC$','path','')\n-            self.__server = SMBSERVER((listenAddress,listenPort), config_parser = self.__smbConfig)\n+            self.__smbConfig.set('IPC$', 'comment', '')\n+            self.__smbConfig.set('IPC$', 'read only', 'yes')\n+            self.__smbConfig.set('IPC$', 'share type', '3')\n+            self.__smbConfig.set('IPC$', 'path', '')\n+            self.__server = SMBSERVER((listenAddress, listenPort), config_parser=self.__smbConfig)\n             self.__server.processConfigFile()\n \n-        # Now we have to register the MS-SRVS server. This specially important for \n-        # Windows 7+ and Mavericks clients since they WON'T (specially OSX) \n+        # Now we have to register the MS-SRVS server. This specially important for\n+        # Windows 7+ and Mavericks clients since they WON'T (specially OSX)\n         # ask for shares using MS-RAP.\n \n         self.__srvsServer = SRVSServer()\n         self.__srvsServer.daemon = True\n         self.__wkstServer = WKSTServer()\n         self.__wkstServer.daemon = True\n-        self.__server.registerNamedPipe('srvsvc',('127.0.0.1',self.__srvsServer.getListenPort()))\n-        self.__server.registerNamedPipe('wkssvc',('127.0.0.1',self.__wkstServer.getListenPort()))\n+        self.__server.registerNamedPipe('srvsvc', ('127.0.0.1', self.__srvsServer.getListenPort()))\n+        self.__server.registerNamedPipe('wkssvc', ('127.0.0.1', self.__wkstServer.getListenPort()))\n \n     def start(self):\n         self.__srvsServer.start()\n@@ -4645,7 +4720,7 @@ def unregisterNamedPipe(self, pipeName):\n     def getRegisteredNamedPipes(self):\n         return self.__server.getRegisteredNamedPipes()\n \n-    def addShare(self, shareName, sharePath, shareComment='', shareType = '0', readOnly = 'no'):\n+    def addShare(self, shareName, sharePath, shareComment='', shareType='0', readOnly='no'):\n         share = shareName.upper()\n         self.__smbConfig.add_section(share)\n         self.__smbConfig.set(share, 'comment', shareComment)\n@@ -4669,14 +4744,14 @@ def setSMBChallenge(self, challenge):\n             self.__smbConfig.set('global', 'challenge', challenge)\n             self.__server.setServerConfig(self.__smbConfig)\n             self.__server.processConfigFile()\n-        \n+\n     def setLogFile(self, logFile):\n-        self.__smbConfig.set('global','log_file',logFile)\n+        self.__smbConfig.set('global', 'log_file', logFile)\n         self.__server.setServerConfig(self.__smbConfig)\n         self.__server.processConfigFile()\n \n     def setCredentialsFile(self, logFile):\n-        self.__smbConfig.set('global','credentials_file',logFile)\n+        self.__smbConfig.set('global', 'credentials_file', logFile)\n         self.__server.setServerConfig(self.__smbConfig)\n         self.__server.processConfigFile()"
        },
        {
            "index":224,
            "vuln_id":"GHSA-vmm6-w4cf-7f3x",
            "cwe_id":"{'CWE-285'}",
            "score":8.7,
            "chain":"{'https:\/\/github.com\/opencast\/opencast\/commit\/b157e1fb3b35991ca7bf59f0730329fbe7ce82e8'}",
            "dataset":"osv",
            "summary":"Authentication Bypass For Endpoints With Anonymous Access in Opencast ### Impact\n\nUsing a remember-me cookie with an arbitrary username can cause Opencast to assume proper authentication for that user even if the remember-me cookie was incorrect given that the attacked endpoint also allows anonymous access.\n\nThis way, an attacker can, for example, fake a remember-me token, assume the identity of the global system administrator and request non-public content from the search service without ever providing any proper authentication.\n\n\n### Patches\n\nThis problem is fixed in Opencast 7.6 and Opencast 8.1\n\n\n### Workarounds\n\nAs a workaround for older, unpatched versions, disabling remember-me cookies in `etc\/security\/mh_default_org.xml` will mitigate the problem but will obviously also disable this feature without obvious indication. To deactivate this, remove the following line from the security configuration:\n\n```xml\n<sec:remember-me \u2026 \/>\n```\n\n### References\n\n- [Remember-me cookie in the security configuration file](https:\/\/github.com\/opencast\/opencast\/blob\/161ee619382f144dc35eea211fc6b556025b98e1\/etc\/security\/mh_default_org.xml#L335-L336)\n\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n- Open an issue in [opencast\/opencast](https:\/\/github.com\/opencast\/opencast\/issues)\n- For security-relevant information, email us at security@opencast.org",
            "published_date":"2020-01-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/opencast\/opencast",
            "commit_href":"https:\/\/github.com\/opencast\/opencast\/commit\/b157e1fb3b35991ca7bf59f0730329fbe7ce82e8",
            "commit_sha":"b157e1fb3b35991ca7bf59f0730329fbe7ce82e8",
            "patch":"SINGLE",
            "chain_ord":"['b157e1fb3b35991ca7bf59f0730329fbe7ce82e8']",
            "before_first_fix_commit":"{'1a7172c95af8d542a77ae5b153e4c834dd4788a6'}",
            "last_fix_commit":"b157e1fb3b35991ca7bf59f0730329fbe7ce82e8",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/13\/2020, 22:55:50",
            "message":"Authentication Bypass For Endpoints With Anonymous Access\n\nUsing a remember-me cookie with an arbitrary username can cause Opencast\nto assume proper authentication for that user even if the remember-me\ncookie was incorrect given that the attacked endpoint also allows\nanonymous access.\n\nThis way, an attacker can, for example, fake a remember-me token, assume\nthe identity of the global system administrator and request non-public\ncontent from the search service without ever providing any proper\nauthentication.\n\nThe reason for this problem is that using a remember-me cookie will\nalways cause the user in the request context to be populated, even if\nthe cookie is invalid by now. This is usually no problem, except in\ncombination with anonymous access where anonymous authentication is\ngranted and the request may continue.\n\nIn such a case, Opencast's security service would just check that a user\nexisted in the request context and assume proper authentication of this\nuser, never checking if it's actually anonymous authentication.\n\nThis patch adds this additional check, falling back to the anonymous\nuser in case of anonymous authentication.",
            "author":"Lars Kiesow",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 6, 'total': 16}",
            "files":"{'modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/security\/SecurityServiceSpringImpl.java': {'additions': 10, 'deletions': 6, 'changes': 16, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencast\/opencast\/raw\/b157e1fb3b35991ca7bf59f0730329fbe7ce82e8\/modules%2Fkernel%2Fsrc%2Fmain%2Fjava%2Forg%2Fopencastproject%2Fkernel%2Fsecurity%2FSecurityServiceSpringImpl.java', 'patch': '@@ -32,6 +32,7 @@\\n \\n import org.slf4j.Logger;\\n import org.slf4j.LoggerFactory;\\n+import org.springframework.security.authentication.AnonymousAuthenticationToken;\\n import org.springframework.security.core.Authentication;\\n import org.springframework.security.core.GrantedAuthority;\\n import org.springframework.security.core.context.SecurityContextHolder;\\n@@ -94,15 +95,19 @@ public User getUser() throws IllegalStateException {\\n \\n     User delegatedUser = delegatedUserHolder.get();\\n \\n+    Authentication auth = SecurityContextHolder.getContext().getAuthentication();\\n+    if (auth instanceof AnonymousAuthenticationToken) {\\n+      return SecurityUtil.createAnonymousUser(org);\\n+    }\\n+\\n     if (delegatedUser != null) {\\n       return delegatedUser;\\n     }\\n \\n-    Authentication auth = SecurityContextHolder.getContext().getAuthentication();\\n     JaxbOrganization jaxbOrganization = JaxbOrganization.fromOrganization(org);\\n     if (auth != null) {\\n       Object principal = auth.getPrincipal();\\n-      if ((principal != null) && (principal instanceof UserDetails)) {\\n+      if ((principal instanceof UserDetails)) {\\n         UserDetails userDetails = (UserDetails) principal;\\n \\n         User user = null;\\n@@ -111,16 +116,15 @@ public User getUser() throws IllegalStateException {\\n         if (userDirectory != null) {\\n           user = userDirectory.loadUser(userDetails.getUsername());\\n           if (user == null) {\\n-            logger.debug(\\n-                    \"Authenticated user \\'{}\\' could not be found in any of the current UserProviders. Continuing anyway...\",\\n-                    userDetails.getUsername());\\n+            logger.debug(\"Authenticated user \\'{}\\' could not be found in any of the current UserProviders. \"\\n+                + \"Continuing anyway...\", userDetails.getUsername());\\n           }\\n         } else {\\n           logger.debug(\"No UserDirectory was found when trying to search for user \\'{}\\'\", userDetails.getUsername());\\n         }\\n \\n         \/\/ Add the roles (authorities) in the security context\\n-        Set<JaxbRole> roles = new HashSet<JaxbRole>();\\n+        Set<JaxbRole> roles = new HashSet<>();\\n         Collection<? extends GrantedAuthority> authorities = auth.getAuthorities();\\n         if (authorities != null) {\\n           for (GrantedAuthority ga : authorities) {'}}",
            "message_norm":"authentication bypass for endpoints with anonymous access\n\nusing a remember-me cookie with an arbitrary username can cause opencast\nto assume proper authentication for that user even if the remember-me\ncookie was incorrect given that the attacked endpoint also allows\nanonymous access.\n\nthis way, an attacker can, for example, fake a remember-me token, assume\nthe identity of the global system administrator and request non-public\ncontent from the search service without ever providing any proper\nauthentication.\n\nthe reason for this problem is that using a remember-me cookie will\nalways cause the user in the request context to be populated, even if\nthe cookie is invalid by now. this is usually no problem, except in\ncombination with anonymous access where anonymous authentication is\ngranted and the request may continue.\n\nin such a case, opencast's security service would just check that a user\nexisted in the request context and assume proper authentication of this\nuser, never checking if it's actually anonymous authentication.\n\nthis patch adds this additional check, falling back to the anonymous\nuser in case of anonymous authentication.",
            "language":"en",
            "entities":"[('authentication bypass', 'SECWORD', ''), ('cookie', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('cookie', 'SECWORD', ''), ('attacked', 'SECWORD', ''), ('attacker', 'FLAW', ''), ('administrator', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('problem', 'FLAW', ''), ('cookie', 'SECWORD', ''), ('cookie', 'SECWORD', ''), ('problem', 'FLAW', ''), ('authentication', 'SECWORD', ''), ('security', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('adds', 'ACTION', ''), ('authentication', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/security\/SecurityServiceSpringImpl.java'])",
            "num_files":1.0,
            "patch_content":"From b157e1fb3b35991ca7bf59f0730329fbe7ce82e8 Mon Sep 17 00:00:00 2001\nFrom: Lars Kiesow <lkiesow@uos.de>\nDate: Mon, 13 Jan 2020 23:55:50 +0100\nSubject: [PATCH] Authentication Bypass For Endpoints With Anonymous Access\n\nUsing a remember-me cookie with an arbitrary username can cause Opencast\nto assume proper authentication for that user even if the remember-me\ncookie was incorrect given that the attacked endpoint also allows\nanonymous access.\n\nThis way, an attacker can, for example, fake a remember-me token, assume\nthe identity of the global system administrator and request non-public\ncontent from the search service without ever providing any proper\nauthentication.\n\nThe reason for this problem is that using a remember-me cookie will\nalways cause the user in the request context to be populated, even if\nthe cookie is invalid by now. This is usually no problem, except in\ncombination with anonymous access where anonymous authentication is\ngranted and the request may continue.\n\nIn such a case, Opencast's security service would just check that a user\nexisted in the request context and assume proper authentication of this\nuser, never checking if it's actually anonymous authentication.\n\nThis patch adds this additional check, falling back to the anonymous\nuser in case of anonymous authentication.\n---\n ...\/security\/SecurityServiceSpringImpl.java      | 16 ++++++++++------\n 1 file changed, 10 insertions(+), 6 deletions(-)\n\ndiff --git a\/modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/security\/SecurityServiceSpringImpl.java b\/modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/security\/SecurityServiceSpringImpl.java\nindex d6b9dbc5f31..3b643d4f5e4 100644\n--- a\/modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/security\/SecurityServiceSpringImpl.java\n+++ b\/modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/security\/SecurityServiceSpringImpl.java\n@@ -32,6 +32,7 @@\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.springframework.security.authentication.AnonymousAuthenticationToken;\n import org.springframework.security.core.Authentication;\n import org.springframework.security.core.GrantedAuthority;\n import org.springframework.security.core.context.SecurityContextHolder;\n@@ -94,15 +95,19 @@ public User getUser() throws IllegalStateException {\n \n     User delegatedUser = delegatedUserHolder.get();\n \n+    Authentication auth = SecurityContextHolder.getContext().getAuthentication();\n+    if (auth instanceof AnonymousAuthenticationToken) {\n+      return SecurityUtil.createAnonymousUser(org);\n+    }\n+\n     if (delegatedUser != null) {\n       return delegatedUser;\n     }\n \n-    Authentication auth = SecurityContextHolder.getContext().getAuthentication();\n     JaxbOrganization jaxbOrganization = JaxbOrganization.fromOrganization(org);\n     if (auth != null) {\n       Object principal = auth.getPrincipal();\n-      if ((principal != null) && (principal instanceof UserDetails)) {\n+      if ((principal instanceof UserDetails)) {\n         UserDetails userDetails = (UserDetails) principal;\n \n         User user = null;\n@@ -111,16 +116,15 @@ public User getUser() throws IllegalStateException {\n         if (userDirectory != null) {\n           user = userDirectory.loadUser(userDetails.getUsername());\n           if (user == null) {\n-            logger.debug(\n-                    \"Authenticated user '{}' could not be found in any of the current UserProviders. Continuing anyway...\",\n-                    userDetails.getUsername());\n+            logger.debug(\"Authenticated user '{}' could not be found in any of the current UserProviders. \"\n+                + \"Continuing anyway...\", userDetails.getUsername());\n           }\n         } else {\n           logger.debug(\"No UserDirectory was found when trying to search for user '{}'\", userDetails.getUsername());\n         }\n \n         \/\/ Add the roles (authorities) in the security context\n-        Set<JaxbRole> roles = new HashSet<JaxbRole>();\n+        Set<JaxbRole> roles = new HashSet<>();\n         Collection<? extends GrantedAuthority> authorities = auth.getAuthorities();\n         if (authorities != null) {\n           for (GrantedAuthority ga : authorities) {"
        },
        {
            "index":654,
            "vuln_id":"GHSA-4wm8-c2vv-xrpq",
            "cwe_id":"{'CWE-79'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/DSpace\/DSpace\/commit\/28eb8158210d41168a62ed5f9e044f754513bc37', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/f7758457b7ec3489d525e39aa753cc70809d9ad9'}",
            "dataset":"osv",
            "summary":"JSPUI Possible Cross Site Scripting in \"Request a Copy\" Feature ### Impact\nThe JSPUI \"Request a Copy\" feature does not properly escape values submitted and stored from the \"Request a Copy\" form.  This means that item requests could be vulnerable to XSS attacks.  This vulnerability only impacts the JSPUI.\n\n_This vulnerability does NOT impact the XMLUI or 7.x._\n\n### Patches\n\n_DSpace 6.x:_ \n* Fixed in 6.4 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/503a6af57fd720c37b0d86c34de63baa5dd85819\n* 6.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/503a6af57fd720c37b0d86c34de63baa5dd85819.patch (may be applied manually if an immediate upgrade to 6.4 is not possible)\n\n_DSpace 5.x:_\n* Fixed in 5.11 via commit: https:\/\/github.com\/DSpace\/DSpace\/commit\/28eb8158210d41168a62ed5f9e044f754513bc37\n* 5.x patch file: https:\/\/github.com\/DSpace\/DSpace\/commit\/28eb8158210d41168a62ed5f9e044f754513bc37.patch (may be applied manually if an immediate upgrade to 5.11 or 6.4 is not possible)\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs \/ configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### Workarounds\nAs a workaround, you can temporarily disable the \"Request a Copy\" feature by either commenting out the below configuration (or setting its value to empty):\n```\n# Comment out this default value\n# request.item.type = all\n```\nOnce your JSPUI site is patched, you can re-enable this setting. See https:\/\/wiki.lyrasis.org\/display\/DSDOC6x\/Request+a+Copy for more information on this setting.\n\n### References\nDiscovered & reported by Andrea Bollini of 4Science\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
            "published_date":"2022-08-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/DSpace\/DSpace",
            "commit_href":"https:\/\/github.com\/DSpace\/DSpace\/commit\/f7758457b7ec3489d525e39aa753cc70809d9ad9",
            "commit_sha":"f7758457b7ec3489d525e39aa753cc70809d9ad9",
            "patch":"MULTI",
            "chain_ord":"['f7758457b7ec3489d525e39aa753cc70809d9ad9', '28eb8158210d41168a62ed5f9e044f754513bc37']",
            "before_first_fix_commit":"{'56e76049185bbd87c994128a9d77735ad7af0199'}",
            "last_fix_commit":"28eb8158210d41168a62ed5f9e044f754513bc37",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/08\/2020, 00:48:56",
            "message":"[DS-4133] Improve URL handling in Controlled Vocab JSPUI servlet",
            "author":"Kim Shepherd",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 2, 'total': 12}",
            "files":"{'dspace-jspui\/src\/main\/java\/org\/dspace\/app\/webui\/servlet\/ControlledVocabularyServlet.java': {'additions': 10, 'deletions': 2, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DSpace\/DSpace\/raw\/f7758457b7ec3489d525e39aa753cc70809d9ad9\/dspace-jspui%2Fsrc%2Fmain%2Fjava%2Forg%2Fdspace%2Fapp%2Fwebui%2Fservlet%2FControlledVocabularyServlet.java', 'patch': '@@ -14,6 +14,7 @@\\n import javax.servlet.http.HttpServletRequest;\\n import javax.servlet.http.HttpServletResponse;\\n \\n+import org.apache.log4j.Logger;\\n import org.dspace.authorize.AuthorizeException;\\n import org.dspace.core.Context;\\n \\n@@ -25,8 +26,8 @@\\n  *\/\\n public class ControlledVocabularyServlet extends DSpaceServlet\\n {\\n-    \/\/ private static Logger log =\\n-    \/\/ Logger.getLogger(ControlledVocabularyServlet.class);\\n+    private static Logger log =\\n+    Logger.getLogger(ControlledVocabularyServlet.class);\\n \\n     protected void doDSGet(Context context, HttpServletRequest request,\\n             HttpServletResponse response) throws ServletException, IOException,\\n@@ -37,6 +38,13 @@ protected void doDSGet(Context context, HttpServletRequest request,\\n         String filter = \"\";\\n         String callerUrl = request.getParameter(\"callerUrl\");\\n \\n+        \/\/ callerUrl must starts with URL outside DSpace request context path\\n+        if(!callerUrl.startsWith(request.getContextPath())) {\\n+            log.error(\"Controlled vocabulary caller URL would result in redirect outside DSpace web app: \" + callerUrl + \". Rejecting request with 400 Bad Request.\");\\n+            response.sendError(400, \"The caller URL must be within the DSpace base URL of \" + request.getContextPath());\\n+            return;\\n+        }\\n+\\n         if (request.getParameter(\"ID\") != null)\\n         {\\n             ID = request.getParameter(\"ID\");'}}",
            "message_norm":"[ds-4133] improve url handling in controlled vocab jspui servlet",
            "language":"en",
            "entities":"[('improve', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dspace-jspui\/src\/main\/java\/org\/dspace\/app\/webui\/servlet\/ControlledVocabularyServlet.java'])",
            "num_files":1.0,
            "patch_content":"From f7758457b7ec3489d525e39aa753cc70809d9ad9 Mon Sep 17 00:00:00 2001\nFrom: Kim Shepherd <kim@shepherd.nz>\nDate: Wed, 8 Apr 2020 12:48:56 +1200\nSubject: [PATCH] [DS-4133] Improve URL handling in Controlled Vocab JSPUI\n servlet\n\n---\n ...\/webui\/servlet\/ControlledVocabularyServlet.java   | 12 ++++++++++--\n 1 file changed, 10 insertions(+), 2 deletions(-)\n\ndiff --git a\/dspace-jspui\/src\/main\/java\/org\/dspace\/app\/webui\/servlet\/ControlledVocabularyServlet.java b\/dspace-jspui\/src\/main\/java\/org\/dspace\/app\/webui\/servlet\/ControlledVocabularyServlet.java\nindex 0736418e8c51..70a1d62f4313 100644\n--- a\/dspace-jspui\/src\/main\/java\/org\/dspace\/app\/webui\/servlet\/ControlledVocabularyServlet.java\n+++ b\/dspace-jspui\/src\/main\/java\/org\/dspace\/app\/webui\/servlet\/ControlledVocabularyServlet.java\n@@ -14,6 +14,7 @@\n import javax.servlet.http.HttpServletRequest;\n import javax.servlet.http.HttpServletResponse;\n \n+import org.apache.log4j.Logger;\n import org.dspace.authorize.AuthorizeException;\n import org.dspace.core.Context;\n \n@@ -25,8 +26,8 @@\n  *\/\n public class ControlledVocabularyServlet extends DSpaceServlet\n {\n-    \/\/ private static Logger log =\n-    \/\/ Logger.getLogger(ControlledVocabularyServlet.class);\n+    private static Logger log =\n+    Logger.getLogger(ControlledVocabularyServlet.class);\n \n     protected void doDSGet(Context context, HttpServletRequest request,\n             HttpServletResponse response) throws ServletException, IOException,\n@@ -37,6 +38,13 @@ protected void doDSGet(Context context, HttpServletRequest request,\n         String filter = \"\";\n         String callerUrl = request.getParameter(\"callerUrl\");\n \n+        \/\/ callerUrl must starts with URL outside DSpace request context path\n+        if(!callerUrl.startsWith(request.getContextPath())) {\n+            log.error(\"Controlled vocabulary caller URL would result in redirect outside DSpace web app: \" + callerUrl + \". Rejecting request with 400 Bad Request.\");\n+            response.sendError(400, \"The caller URL must be within the DSpace base URL of \" + request.getContextPath());\n+            return;\n+        }\n+\n         if (request.getParameter(\"ID\") != null)\n         {\n             ID = request.getParameter(\"ID\");"
        },
        {
            "index":947,
            "vuln_id":"GHSA-c5r5-7pfh-6qg6",
            "cwe_id":"{'CWE-78'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/inukshuk\/bibtex-ruby\/commit\/14406f4460f4e1ecabd25ca94f809b3ea7c5fb11'}",
            "dataset":"osv",
            "summary":"OS command injection in BibTeX-Ruby BibTeX-ruby before 5.1.0 allows shell command injection due to unsanitized user input being passed directly to the built-in Ruby Kernel.open method through BibTeX.open.",
            "published_date":"2020-02-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/inukshuk\/bibtex-ruby",
            "commit_href":"https:\/\/github.com\/inukshuk\/bibtex-ruby\/commit\/14406f4460f4e1ecabd25ca94f809b3ea7c5fb11",
            "commit_sha":"14406f4460f4e1ecabd25ca94f809b3ea7c5fb11",
            "patch":"SINGLE",
            "chain_ord":"['14406f4460f4e1ecabd25ca94f809b3ea7c5fb11']",
            "before_first_fix_commit":"{'707b9303e4ed9a7e136dd1268e21d73d5faab817'}",
            "last_fix_commit":"14406f4460f4e1ecabd25ca94f809b3ea7c5fb11",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/17\/2020, 13:34:37",
            "message":"Use File.read instead of Kernel.open\n\nTo avoid command injection with | strings",
            "author":"Sylvester Keil",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/bibtex\/bibliography.rb': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/inukshuk\/bibtex-ruby\/raw\/14406f4460f4e1ecabd25ca94f809b3ea7c5fb11\/lib%2Fbibtex%2Fbibliography.rb', 'patch': \"@@ -47,7 +47,7 @@ class << self\\n       # -:filter: convert all entries using the sepcified filter (not set by default)\\n       #\\n       def open(path, options = {})\\n-        b = parse(Kernel.open(path, 'r:UTF-8').read, options)\\n+        b = parse(File.read(path), options)\\n         b.path = path\\n         return b unless block_given?\"}}",
            "message_norm":"use file.read instead of kernel.open\n\nto avoid command injection with | strings",
            "language":"en",
            "entities":"[('command injection', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/bibtex\/bibliography.rb'])",
            "num_files":1.0,
            "patch_content":"From 14406f4460f4e1ecabd25ca94f809b3ea7c5fb11 Mon Sep 17 00:00:00 2001\nFrom: Sylvester Keil <sylvester@keil.or.at>\nDate: Fri, 17 Jan 2020 14:34:37 +0100\nSubject: [PATCH] Use File.read instead of Kernel.open\n\nTo avoid command injection with | strings\n---\n lib\/bibtex\/bibliography.rb | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/bibtex\/bibliography.rb b\/lib\/bibtex\/bibliography.rb\nindex 95688c8..97cb37c 100644\n--- a\/lib\/bibtex\/bibliography.rb\n+++ b\/lib\/bibtex\/bibliography.rb\n@@ -47,7 +47,7 @@ class << self\n       # -:filter: convert all entries using the sepcified filter (not set by default)\n       #\n       def open(path, options = {})\n-        b = parse(Kernel.open(path, 'r:UTF-8').read, options)\n+        b = parse(File.read(path), options)\n         b.path = path\n         return b unless block_given?"
        },
        {
            "index":610,
            "vuln_id":"GHSA-vq2r-5xvm-3hc3",
            "cwe_id":"{'CWE-908'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1b323042264740c398140da32e93fb9c2c9f33e'}",
            "dataset":"osv",
            "summary":"Segfault in `CTCBeamSearchDecoder` ### Impact\nDue to lack of validation in `tf.raw_ops.CTCBeamSearchDecoder`, an attacker can trigger denial of service via segmentation faults:\n\n```python\nimport tensorflow as tf\n\ninputs = tf.constant([], shape=[18, 8, 0], dtype=tf.float32)\nsequence_length = tf.constant([11, -43, -92, 11, -89, -83, -35, -100],\nshape=[8], dtype=tf.int32)\nbeam_width = 10\ntop_paths = 3\nmerge_repeated = True\n\ntf.raw_ops.CTCBeamSearchDecoder(\n  inputs=inputs, sequence_length=sequence_length, beam_width=beam_width,\n  top_paths=top_paths, merge_repeated=merge_repeated)\n``` \n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a74768f8e4efbda4def9f16ee7e13cf3922ac5f7\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc#L68-L79) fails to detect cases when the input tensor is empty and proceeds to read data from a null buffer.\n  \n### Patches\nWe have patched the issue in GitHub commit [b1b323042264740c398140da32e93fb9c2c9f33e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1b323042264740c398140da32e93fb9c2c9f33e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1b323042264740c398140da32e93fb9c2c9f33e",
            "commit_sha":"b1b323042264740c398140da32e93fb9c2c9f33e",
            "patch":"SINGLE",
            "chain_ord":"['b1b323042264740c398140da32e93fb9c2c9f33e']",
            "before_first_fix_commit":"{'a74768f8e4efbda4def9f16ee7e13cf3922ac5f7'}",
            "last_fix_commit":"b1b323042264740c398140da32e93fb9c2c9f33e",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2021, 21:51:41",
            "message":"Fix SEGV in CTC ops\n\nPiperOrigin-RevId: 372430279\nChange-Id: I7ec2ad9d6f4d0980c33de45d27c6b17df5c6e26f",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/ctc_decoder_ops.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b1b323042264740c398140da32e93fb9c2c9f33e\/tensorflow%2Fcore%2Fkernels%2Fctc_decoder_ops.cc', 'patch': '@@ -70,6 +70,9 @@ class CTCDecodeHelper {\\n     if (inputs_shape.dims() != 3) {\\n       return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\\n     }\\n+    if (inputs_shape.num_elements() == 0) {\\n+      return errors::InvalidArgument(\"inputs must not be empty\");\\n+    }\\n \\n     const int64 max_time = inputs_shape.dim_size(0);\\n     const int64 batch_size = inputs_shape.dim_size(1);'}}",
            "message_norm":"fix segv in ctc ops\n\npiperorigin-revid: 372430279\nchange-id: i7ec2ad9d6f4d0980c33de45d27c6b17df5c6e26f",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('372430279', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ctc_decoder_ops.cc'])",
            "num_files":1.0,
            "patch_content":"From b1b323042264740c398140da32e93fb9c2c9f33e Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 6 May 2021 14:51:41 -0700\nSubject: [PATCH] Fix SEGV in CTC ops\n\nPiperOrigin-RevId: 372430279\nChange-Id: I7ec2ad9d6f4d0980c33de45d27c6b17df5c6e26f\n---\n tensorflow\/core\/kernels\/ctc_decoder_ops.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc b\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc\nindex 22681f97437f0c..9efdac60e369c2 100644\n--- a\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc\n+++ b\/tensorflow\/core\/kernels\/ctc_decoder_ops.cc\n@@ -70,6 +70,9 @@ class CTCDecodeHelper {\n     if (inputs_shape.dims() != 3) {\n       return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\n     }\n+    if (inputs_shape.num_elements() == 0) {\n+      return errors::InvalidArgument(\"inputs must not be empty\");\n+    }\n \n     const int64 max_time = inputs_shape.dim_size(0);\n     const int64 batch_size = inputs_shape.dim_size(1);"
        },
        {
            "index":876,
            "vuln_id":"GHSA-qhxx-j73r-qpm2",
            "cwe_id":"{'CWE-908'}",
            "score":4.4,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2'}",
            "dataset":"osv",
            "summary":"Uninitialized memory access in TensorFlow ### Impact\nUnder certain cases, a saved model can trigger use of uninitialized values during code execution. This is caused by having tensor buffers be filled with the default value of the type but forgetting to [default initialize the quantized floating point types in Eigen](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f70160322a579144950dff1537dcbe3c7c09d6f5\/third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h#L61-L104):\n\n```cc\nstruct QUInt8 {\n  QUInt8() {}\n  \/\/ ...\n  uint8_t value;\n};\n\nstruct QInt16 {\n  QInt16() {}\n  \/\/ ...\n  int16_t value;\n};\n\nstruct QUInt16 {\n  QUInt16() {}\n  \/\/ ...\n  uint16_t value;\n};\n\nstruct QInt32 {\n  QInt32() {}\n  \/\/ ...\n  int32_t value;\n};\n```\n\n### Patches\nWe have patched the issue in GitHub commit [ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2) and will release TensorFlow 2.4.0 containing the patch. TensorFlow nightly packages after this commit will also have the issue resolved.\n\nSince this issue also impacts TF versions before 2.4, we will patch all releases between 1.15 and 2.3 inclusive.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2020-12-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
            "commit_sha":"ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
            "patch":"SINGLE",
            "chain_ord":"['ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2']",
            "before_first_fix_commit":"{'f70160322a579144950dff1537dcbe3c7c09d6f5'}",
            "last_fix_commit":"ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/24\/2020, 19:40:42",
            "message":"Default initialize fixed point Eigen types.\n\nIn certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.\n\nPiperOrigin-RevId: 344101137\nChange-Id: I14555fda74dca3b5f1582da9008901937e3f14e2",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 5, 'total': 10}",
            "files":"{'third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2\/third_party%2Feigen3%2Funsupported%2FEigen%2FCXX11%2Fsrc%2FFixedPoint%2FFixedPointTypes.h', 'patch': '@@ -49,7 +49,7 @@ struct scalar_product_traits<QInt32, double> {\\n \/\/ the compiler from silently type cast the mantissa into a bigger or a smaller\\n \/\/ representation.\\n struct QInt8 {\\n-  QInt8() {}\\n+  QInt8() : value(0) {}\\n   QInt8(const int8_t v) : value(v) {}\\n   QInt8(const QInt32 v);\\n \\n@@ -59,7 +59,7 @@ struct QInt8 {\\n };\\n \\n struct QUInt8 {\\n-  QUInt8() {}\\n+  QUInt8() : value(0) {}\\n   QUInt8(const uint8_t v) : value(v) {}\\n   QUInt8(const QInt32 v);\\n \\n@@ -69,7 +69,7 @@ struct QUInt8 {\\n };\\n \\n struct QInt16 {\\n-  QInt16() {}\\n+  QInt16() : value(0) {}\\n   QInt16(const int16_t v) : value(v) {}\\n   QInt16(const QInt32 v);\\n   operator int() const { return static_cast<int>(value); }\\n@@ -78,7 +78,7 @@ struct QInt16 {\\n };\\n \\n struct QUInt16 {\\n-  QUInt16() {}\\n+  QUInt16() : value(0) {}\\n   QUInt16(const uint16_t v) : value(v) {}\\n   QUInt16(const QInt32 v);\\n   operator int() const { return static_cast<int>(value); }\\n@@ -87,7 +87,7 @@ struct QUInt16 {\\n };\\n \\n struct QInt32 {\\n-  QInt32() {}\\n+  QInt32() : value(0) {}\\n   QInt32(const int8_t v) : value(v) {}\\n   QInt32(const int32_t v) : value(v) {}\\n   QInt32(const uint32_t v) : value(static_cast<int32_t>(v)) {}'}}",
            "message_norm":"default initialize fixed point eigen types.\n\nin certain cases, tensors are filled with default values of the type. but, for these fixed point types, these values were uninitialized. thus, we would have uninitialized memory access bugs, some of which were caught by msan.\n\npiperorigin-revid: 344101137\nchange-id: i14555fda74dca3b5f1582da9008901937e3f14e2",
            "language":"en",
            "entities":"[('initialize', 'SECWORD', ''), ('fixed', 'ACTION', ''), ('fixed', 'ACTION', ''), ('uninitialized', 'SECWORD', ''), ('uninitialized memory', 'SECWORD', ''), ('bugs', 'FLAW', ''), ('344101137', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h'])",
            "num_files":1.0,
            "patch_content":"From ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 24 Nov 2020 11:40:42 -0800\nSubject: [PATCH] Default initialize fixed point Eigen types.\n\nIn certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.\n\nPiperOrigin-RevId: 344101137\nChange-Id: I14555fda74dca3b5f1582da9008901937e3f14e2\n---\n ...\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h       | 10 +++++-----\n 1 file changed, 5 insertions(+), 5 deletions(-)\n\ndiff --git a\/third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h b\/third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h\nindex ff359cedced961..fd35360da28208 100644\n--- a\/third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h\n+++ b\/third_party\/eigen3\/unsupported\/Eigen\/CXX11\/src\/FixedPoint\/FixedPointTypes.h\n@@ -49,7 +49,7 @@ struct scalar_product_traits<QInt32, double> {\n \/\/ the compiler from silently type cast the mantissa into a bigger or a smaller\n \/\/ representation.\n struct QInt8 {\n-  QInt8() {}\n+  QInt8() : value(0) {}\n   QInt8(const int8_t v) : value(v) {}\n   QInt8(const QInt32 v);\n \n@@ -59,7 +59,7 @@ struct QInt8 {\n };\n \n struct QUInt8 {\n-  QUInt8() {}\n+  QUInt8() : value(0) {}\n   QUInt8(const uint8_t v) : value(v) {}\n   QUInt8(const QInt32 v);\n \n@@ -69,7 +69,7 @@ struct QUInt8 {\n };\n \n struct QInt16 {\n-  QInt16() {}\n+  QInt16() : value(0) {}\n   QInt16(const int16_t v) : value(v) {}\n   QInt16(const QInt32 v);\n   operator int() const { return static_cast<int>(value); }\n@@ -78,7 +78,7 @@ struct QInt16 {\n };\n \n struct QUInt16 {\n-  QUInt16() {}\n+  QUInt16() : value(0) {}\n   QUInt16(const uint16_t v) : value(v) {}\n   QUInt16(const QInt32 v);\n   operator int() const { return static_cast<int>(value); }\n@@ -87,7 +87,7 @@ struct QUInt16 {\n };\n \n struct QInt32 {\n-  QInt32() {}\n+  QInt32() : value(0) {}\n   QInt32(const int8_t v) : value(v) {}\n   QInt32(const int32_t v) : value(v) {}\n   QInt32(const uint32_t v) : value(static_cast<int32_t>(v)) {}"
        },
        {
            "index":281,
            "vuln_id":"GHSA-hxf9-7h4c-f5jv",
            "cwe_id":"{'CWE-200'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/anymail\/django-anymail\/commit\/db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'https:\/\/github.com\/anymail\/django-anymail\/commit\/c07998304b4a31df4c61deddcb03d3607a04691b'}",
            "dataset":"osv",
            "summary":"Django-Anymail prone to a timing attack webhooks\/base.py in Anymail (aka django-anymail) before 1.2.1 is prone to a timing attack vulnerability on the WEBHOOK_AUTHORIZATION secret, which allows remote attackers to post arbitrary e-mail tracking events.",
            "published_date":"2018-07-12",
            "chain_len":2,
            "project":"https:\/\/github.com\/anymail\/django-anymail",
            "commit_href":"https:\/\/github.com\/anymail\/django-anymail\/commit\/c07998304b4a31df4c61deddcb03d3607a04691b",
            "commit_sha":"c07998304b4a31df4c61deddcb03d3607a04691b",
            "patch":"MULTI",
            "chain_ord":"['db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'c07998304b4a31df4c61deddcb03d3607a04691b']",
            "before_first_fix_commit":"{'7029298b930620b1655dab2548f72d6640a5905e'}",
            "last_fix_commit":"c07998304b4a31df4c61deddcb03d3607a04691b",
            "chain_ord_pos":2.0,
            "commit_datetime":"02\/02\/2018, 19:41:14",
            "message":"Security: prevent timing attack on WEBHOOK_AUTHORIZATION secret\n\nAnymail's webhook validation was vulnerable to a timing attack.\nAn attacker could have used this to recover your WEBHOOK_AUTHORIZATION\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nThere have not been any reports of attempted exploit in the wild. (The\nvulnerability was discovered through code review.) Attempts would be\nvisible in http logs as a very large number of 400 responses on\nAnymail's webhook urls, or in Python error monitoring as a very large\nnumber of AnymailWebhookValidationFailure exceptions.\n\nIf you are using Anymail's webhooks, you should upgrade to this release.\nIn addition, you may want to rotate to a new WEBHOOK_AUTHORIZATION\nsecret ([docs](http:\/\/anymail.readthedocs.io\/en\/stable\/tips\/securing_webhooks\/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.\n\n(cherry picked from commit db586ede1fbb41dce21310ea28ae15a1cf1286c5)",
            "author":"medmunds",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 3, 'total': 15}",
            "files":"{'anymail\/webhooks\/base.py': {'additions': 12, 'deletions': 3, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/anymail\/django-anymail\/raw\/c07998304b4a31df4c61deddcb03d3607a04691b\/anymail%2Fwebhooks%2Fbase.py', 'patch': '@@ -3,6 +3,7 @@\\n \\n import six\\n from django.http import HttpResponse\\n+from django.utils.crypto import constant_time_compare\\n from django.utils.decorators import method_decorator\\n from django.views.decorators.csrf import csrf_exempt\\n from django.views.generic import View\\n@@ -41,8 +42,13 @@ def __init__(self, **kwargs):\\n     def validate_request(self, request):\\n         \"\"\"If configured for webhook basic auth, validate request has correct auth.\"\"\"\\n         if self.basic_auth:\\n-            basic_auth = get_request_basic_auth(request)\\n-            if basic_auth is None or basic_auth not in self.basic_auth:\\n+            request_auth = get_request_basic_auth(request)\\n+            # Use constant_time_compare to avoid timing attack on basic auth. (It\\'s OK that any()\\n+            # can terminate early: we\\'re not trying to protect how many auth strings are allowed,\\n+            # just the contents of each individual auth string.)\\n+            auth_ok = any(constant_time_compare(request_auth, allowed_auth)\\n+                          for allowed_auth in self.basic_auth)\\n+            if not auth_ok:\\n                 # noinspection PyUnresolvedReferences\\n                 raise AnymailWebhookValidationFailure(\\n                     \"Missing or invalid basic auth in Anymail %s webhook\" % self.esp_name)\\n@@ -78,8 +84,11 @@ def validate_request(self, request):\\n         *All* definitions of this method in the class chain (including mixins)\\n         will be called. There is no need to chain to the superclass.\\n         (See self.run_validators and collect_all_methods.)\\n+\\n+        Security note: use django.utils.crypto.constant_time_compare for string\\n+        comparisons, to avoid exposing your validation to a timing attack.\\n         \"\"\"\\n-        # if request.POST[\\'signature\\'] != expected_signature:\\n+        # if not constant_time_compare(request.POST[\\'signature\\'], expected_signature):\\n         #     raise AnymailWebhookValidationFailure(\"...message...\")\\n         # (else just do nothing)\\n         pass'}}",
            "message_norm":"security: prevent timing attack on webhook_authorization secret\n\nanymail's webhook validation was vulnerable to a timing attack.\nan attacker could have used this to recover your webhook_authorization\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nthere have not been any reports of attempted exploit in the wild. (the\nvulnerability was discovered through code review.) attempts would be\nvisible in http logs as a very large number of 400 responses on\nanymail's webhook urls, or in python error monitoring as a very large\nnumber of anymailwebhookvalidationfailure exceptions.\n\nif you are using anymail's webhooks, you should upgrade to this release.\nin addition, you may want to rotate to a new webhook_authorization\nsecret ([docs](http:\/\/anymail.readthedocs.io\/en\/stable\/tips\/securing_webhooks\/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.\n\n(cherry picked from commit db586ede1fbb41dce21310ea28ae15a1cf1286c5)",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('attack', 'SECWORD', ''), ('vulnerable', 'SECWORD', ''), ('attack', 'FLAW', ''), ('attacker', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('exploit', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('error', 'FLAW', ''), ('upgrade', 'ACTION', ''), ('docs](http:\/\/anymail.readthedocs.io', 'URL', ''), ('exploit', 'SECWORD', ''), ('commit db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'SHA', 'prefix_colon_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['anymail\/webhooks\/base.py'])",
            "num_files":1.0,
            "patch_content":"From c07998304b4a31df4c61deddcb03d3607a04691b Mon Sep 17 00:00:00 2001\nFrom: medmunds <medmunds@gmail.com>\nDate: Fri, 2 Feb 2018 11:41:14 -0800\nSubject: [PATCH] Security: prevent timing attack on WEBHOOK_AUTHORIZATION\n secret\n\nAnymail's webhook validation was vulnerable to a timing attack.\nAn attacker could have used this to recover your WEBHOOK_AUTHORIZATION\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nThere have not been any reports of attempted exploit in the wild. (The\nvulnerability was discovered through code review.) Attempts would be\nvisible in http logs as a very large number of 400 responses on\nAnymail's webhook urls, or in Python error monitoring as a very large\nnumber of AnymailWebhookValidationFailure exceptions.\n\nIf you are using Anymail's webhooks, you should upgrade to this release.\nIn addition, you may want to rotate to a new WEBHOOK_AUTHORIZATION\nsecret ([docs](http:\/\/anymail.readthedocs.io\/en\/stable\/tips\/securing_webhooks\/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.\n\n(cherry picked from commit db586ede1fbb41dce21310ea28ae15a1cf1286c5)\n---\n anymail\/webhooks\/base.py | 15 ++++++++++++---\n 1 file changed, 12 insertions(+), 3 deletions(-)\n\ndiff --git a\/anymail\/webhooks\/base.py b\/anymail\/webhooks\/base.py\nindex 1f98bc66..c54bfc96 100644\n--- a\/anymail\/webhooks\/base.py\n+++ b\/anymail\/webhooks\/base.py\n@@ -3,6 +3,7 @@\n \n import six\n from django.http import HttpResponse\n+from django.utils.crypto import constant_time_compare\n from django.utils.decorators import method_decorator\n from django.views.decorators.csrf import csrf_exempt\n from django.views.generic import View\n@@ -41,8 +42,13 @@ def __init__(self, **kwargs):\n     def validate_request(self, request):\n         \"\"\"If configured for webhook basic auth, validate request has correct auth.\"\"\"\n         if self.basic_auth:\n-            basic_auth = get_request_basic_auth(request)\n-            if basic_auth is None or basic_auth not in self.basic_auth:\n+            request_auth = get_request_basic_auth(request)\n+            # Use constant_time_compare to avoid timing attack on basic auth. (It's OK that any()\n+            # can terminate early: we're not trying to protect how many auth strings are allowed,\n+            # just the contents of each individual auth string.)\n+            auth_ok = any(constant_time_compare(request_auth, allowed_auth)\n+                          for allowed_auth in self.basic_auth)\n+            if not auth_ok:\n                 # noinspection PyUnresolvedReferences\n                 raise AnymailWebhookValidationFailure(\n                     \"Missing or invalid basic auth in Anymail %s webhook\" % self.esp_name)\n@@ -78,8 +84,11 @@ def validate_request(self, request):\n         *All* definitions of this method in the class chain (including mixins)\n         will be called. There is no need to chain to the superclass.\n         (See self.run_validators and collect_all_methods.)\n+\n+        Security note: use django.utils.crypto.constant_time_compare for string\n+        comparisons, to avoid exposing your validation to a timing attack.\n         \"\"\"\n-        # if request.POST['signature'] != expected_signature:\n+        # if not constant_time_compare(request.POST['signature'], expected_signature):\n         #     raise AnymailWebhookValidationFailure(\"...message...\")\n         # (else just do nothing)\n         pass"
        },
        {
            "index":697,
            "vuln_id":"GHSA-vp56-6g26-6827",
            "cwe_id":"{'CWE-400'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/node-fetch\/node-fetch\/commit\/28802387292baee467e042e168d92597b5bbbe3d'}",
            "dataset":"osv",
            "summary":"node-fetch Inefficient Regular Expression Complexity  [node-fetch](https:\/\/www.npmjs.com\/package\/node-fetch) is a light-weight module that brings window.fetch to node.js.\n\nAffected versions of this package are vulnerable to Regular Expression Denial of Service (ReDoS) in the `isOriginPotentiallyTrustworthy()` function in `referrer.js`, when processing a URL string with alternating letters and periods, such as `'http:\/\/' + 'a.a.'.repeat(i) + 'a'`.",
            "published_date":"2022-08-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/node-fetch\/node-fetch",
            "commit_href":"https:\/\/github.com\/node-fetch\/node-fetch\/commit\/28802387292baee467e042e168d92597b5bbbe3d",
            "commit_sha":"28802387292baee467e042e168d92597b5bbbe3d",
            "patch":"SINGLE",
            "chain_ord":"['28802387292baee467e042e168d92597b5bbbe3d']",
            "before_first_fix_commit":"{'e87b093fd678a9ea39c5b17b2a1bdfc4691eedc7'}",
            "last_fix_commit":"28802387292baee467e042e168d92597b5bbbe3d",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/31\/2022, 08:01:29",
            "message":"fix: ReDoS referrer (#1611)\n\n* fix ReDoS referrer\r\n\r\n* Update src\/utils\/referrer.js\r\n\r\nEliminate regex and use string matcher\r\n\r\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>\r\n\r\nCo-authored-by: Khang. V\u00f5 V\u0129 <khangvv@vng.com.vn>\r\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>",
            "author":"Khang Vo (doublevkay)",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/utils\/referrer.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/node-fetch\/node-fetch\/raw\/28802387292baee467e042e168d92597b5bbbe3d\/src%2Futils%2Freferrer.js', 'patch': '@@ -119,7 +119,7 @@ export function isOriginPotentiallyTrustworthy(url) {\\n \\t\/\/ 5. If origin\\'s host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\\n \\t\/\/ We are returning FALSE here because we cannot ensure conformance to\\n \\t\/\/ let-localhost-be-loalhost (https:\/\/tools.ietf.org\/html\/draft-west-let-localhost-be-localhost)\\n-\\tif (\/^(.+\\\\.)*localhost$\/.test(url.host)) {\\n+\\tif (url.host === \\'localhost\\' || url.host.endsWith(\\'.localhost\\')) {\\n \\t\\treturn false;\\n \\t}'}}",
            "message_norm":"fix: redos referrer (#1611)\n\n* fix redos referrer\r\n\r\n* update src\/utils\/referrer.js\r\n\r\neliminate regex and use string matcher\r\n\r\nco-authored-by: linus unneb\u00e4ck <linus@folkdatorn.se>\r\n\r\nco-authored-by: khang. v\u00f5 v\u0129 <khangvv@vng.com.vn>\r\nco-authored-by: linus unneb\u00e4ck <linus@folkdatorn.se>",
            "language":"en",
            "entities":"[('redos', 'SECWORD', ''), ('#1611', 'ISSUE', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('linus@folkdatorn.se', 'EMAIL', ''), ('linus@folkdatorn.se', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/utils\/referrer.js'])",
            "num_files":1.0,
            "patch_content":"From 28802387292baee467e042e168d92597b5bbbe3d Mon Sep 17 00:00:00 2001\nFrom: \"Khang Vo (doublevkay)\" <45411113+vovikhangcdv@users.noreply.github.com>\nDate: Sun, 31 Jul 2022 15:01:29 +0700\nSubject: [PATCH] fix: ReDoS referrer (#1611)\nMIME-Version: 1.0\nContent-Type: text\/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\n\n* fix ReDoS referrer\n\n* Update src\/utils\/referrer.js\n\nEliminate regex and use string matcher\n\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>\n\nCo-authored-by: Khang. V\u00f5 V\u0129 <khangvv@vng.com.vn>\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>\n---\n src\/utils\/referrer.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/utils\/referrer.js b\/src\/utils\/referrer.js\nindex c8c668671..6741f2fcc 100644\n--- a\/src\/utils\/referrer.js\n+++ b\/src\/utils\/referrer.js\n@@ -119,7 +119,7 @@ export function isOriginPotentiallyTrustworthy(url) {\n \t\/\/ 5. If origin's host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\n \t\/\/ We are returning FALSE here because we cannot ensure conformance to\n \t\/\/ let-localhost-be-loalhost (https:\/\/tools.ietf.org\/html\/draft-west-let-localhost-be-localhost)\n-\tif (\/^(.+\\.)*localhost$\/.test(url.host)) {\n+\tif (url.host === 'localhost' || url.host.endsWith('.localhost')) {\n \t\treturn false;\n \t}"
        },
        {
            "index":737,
            "vuln_id":"GHSA-fcwc-p4fc-c5cc",
            "cwe_id":"{'CWE-476'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/482da92095c4d48f8784b1f00dda4f81c28d2988'}",
            "dataset":"osv",
            "summary":"Null pointer dereference in `MatrixDiagPartOp` ### Impact\nIf a user does not provide a valid padding value to `tf.raw_ops.MatrixDiagPartOp`, then the code triggers a null pointer dereference (if input is empty) or produces invalid behavior, ignoring all values after the first:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.MatrixDiagPartV2(\n  input=tf.ones(2,dtype=tf.int32),\n  k=tf.ones(2,dtype=tf.int32),\n  padding_value=[])\n```\n\nAlthough this example is given for `MatrixDiagPartV2`, all versions of the operation are affected.\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/linalg\/matrix_diag_op.cc#L89) reads the first value from a tensor buffer without first checking that the tensor has values to read from.\n\n### Patches\nWe have patched the issue in GitHub commit [482da92095c4d48f8784b1f00dda4f81c28d2988](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/482da92095c4d48f8784b1f00dda4f81c28d2988).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/482da92095c4d48f8784b1f00dda4f81c28d2988",
            "commit_sha":"482da92095c4d48f8784b1f00dda4f81c28d2988",
            "patch":"SINGLE",
            "chain_ord":"['482da92095c4d48f8784b1f00dda4f81c28d2988']",
            "before_first_fix_commit":"{'3b4351cc2d8ebf31d28dd78fb2730069d6716ad4'}",
            "last_fix_commit":"482da92095c4d48f8784b1f00dda4f81c28d2988",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2021, 22:07:31",
            "message":"Ensure non-empty padding_value input to tf.raw_ops.MatrixDiagPartV2, if a padding_value is input\n\nPiperOrigin-RevId: 388314614\nChange-Id: If0b51ad58d5d8543a6be6ce8f42ae4755c80d55f",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 1, 'total': 5}",
            "files":"{'tensorflow\/core\/kernels\/linalg\/matrix_diag_op.cc': {'additions': 4, 'deletions': 1, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/482da92095c4d48f8784b1f00dda4f81c28d2988\/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_diag_op.cc', 'patch': '@@ -89,7 +89,10 @@ class MatrixDiagPartOp : public OpKernel {\\n           upper_diag_index = diag_index.flat<int32>()(1);\\n         }\\n       }\\n-      padding_value = context->input(2).flat<T>()(0);\\n+      const Tensor& padding_in = context->input(2);\\n+      OP_REQUIRES(context, padding_in.NumElements() == 1,\\n+                  errors::InvalidArgument(\"Padding must be scalar.\"));\\n+      padding_value = padding_in.flat<T>()(0);\\n     }\\n     const TensorShape& input_shape = input.shape();'}}",
            "message_norm":"ensure non-empty padding_value input to tf.raw_ops.matrixdiagpartv2, if a padding_value is input\n\npiperorigin-revid: 388314614\nchange-id: if0b51ad58d5d8543a6be6ce8f42ae4755c80d55f",
            "language":"en",
            "entities":"[('ensure', 'ACTION', ''), ('388314614', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/linalg\/matrix_diag_op.cc'])",
            "num_files":1.0,
            "patch_content":"From 482da92095c4d48f8784b1f00dda4f81c28d2988 Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Mon, 2 Aug 2021 15:07:31 -0700\nSubject: [PATCH] Ensure non-empty padding_value input to\n tf.raw_ops.MatrixDiagPartV2, if a padding_value is input\n\nPiperOrigin-RevId: 388314614\nChange-Id: If0b51ad58d5d8543a6be6ce8f42ae4755c80d55f\n---\n tensorflow\/core\/kernels\/linalg\/matrix_diag_op.cc | 5 ++++-\n 1 file changed, 4 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/linalg\/matrix_diag_op.cc b\/tensorflow\/core\/kernels\/linalg\/matrix_diag_op.cc\nindex b61dbe96a5d6a5..1506df17121387 100644\n--- a\/tensorflow\/core\/kernels\/linalg\/matrix_diag_op.cc\n+++ b\/tensorflow\/core\/kernels\/linalg\/matrix_diag_op.cc\n@@ -89,7 +89,10 @@ class MatrixDiagPartOp : public OpKernel {\n           upper_diag_index = diag_index.flat<int32>()(1);\n         }\n       }\n-      padding_value = context->input(2).flat<T>()(0);\n+      const Tensor& padding_in = context->input(2);\n+      OP_REQUIRES(context, padding_in.NumElements() == 1,\n+                  errors::InvalidArgument(\"Padding must be scalar.\"));\n+      padding_value = padding_in.flat<T>()(0);\n     }\n     const TensorShape& input_shape = input.shape();"
        },
        {
            "index":202,
            "vuln_id":"GHSA-xcwj-wfcm-m23c",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd'}",
            "dataset":"osv",
            "summary":"Invalid validation in `SparseMatrixSparseCholesky` ### Impact\nAn attacker can trigger a null pointer dereference by providing an invalid `permutation` to `tf.raw_ops.SparseMatrixSparseCholesky`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\n\nindices_array = np.array([[0, 0]])\nvalue_array = np.array([-10.0], dtype=np.float32)\ndense_shape = [1, 1]\nst = tf.SparseTensor(indices_array, value_array, dense_shape)\n\ninput = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n       st.indices, st.values, st.dense_shape)\n\npermutation = tf.constant([], shape=[1, 0], dtype=tf.int32)\n \ntf.raw_ops.SparseMatrixSparseCholesky(input=input, permutation=permutation, type=tf.float32)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/080f1d9e257589f78b3ffb75debf584168aa6062\/tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc#L85-L86) fails to properly validate the input arguments: \n                          \n```cc \nvoid Compute(OpKernelContext* ctx) final {\n  ...\n  const Tensor& input_permutation_indices = ctx->input(1);\n  ...\n  ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size, &num_rows);\n  ...\n}\n\nvoid ValidateInputs(OpKernelContext* ctx,\n    const CSRSparseMatrix& sparse_matrix,\n    const Tensor& permutation_indices, int* batch_size,\n    int64* num_rows) {\n  OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value, ...)\n  ...\n}\n```\nAlthough `ValidateInputs` is called and there are checks in the body of this function, the code proceeds to the next line in `ValidateInputs` since [`OP_REQUIRES`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/080f1d9e257589f78b3ffb75debf584168aa6062\/tensorflow\/core\/framework\/op_requires.h#L41-L48) is a macro that only exits the current function.\n\n```cc\n#define OP_REQUIRES(CTX, EXP, STATUS)                     \\\n  do {                                                    \\\n    if (!TF_PREDICT_TRUE(EXP)) {                          \\\n      CheckNotInComputeAsync((CTX), \"OP_REQUIRES_ASYNC\"); \\\n      (CTX)->CtxFailure(__FILE__, __LINE__, (STATUS));    \\\n      return;                                             \\\n    }                                                     \\\n  } while (0)\n```\n\nThus, the first validation condition that fails in `ValidateInputs` will cause an early return from that function. However, the caller will continue execution from the next line. The fix is to either explicitly check `context->status()` or to convert `ValidateInputs` to return a `Status`.\n\n### Patches\nWe have patched the issue in GitHub commit [e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd",
            "commit_sha":"e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd",
            "patch":"SINGLE",
            "chain_ord":"['e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd']",
            "before_first_fix_commit":"{'080f1d9e257589f78b3ffb75debf584168aa6062'}",
            "last_fix_commit":"e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/20\/2021, 21:45:33",
            "message":"Remove `OP_REQUIRES` call from helper function.\n\nSince `OP_REQUIRES` macro expands to a `return;` (among other), calling it in a helper function only ends the helper function's execution earlier, but the kernel will still run from start to end. Thus, all the expected validations are actually broken\/useless as the code ploughs through the next crash anyway.\n\nPiperOrigin-RevId: 369524386\nChange-Id: I54f6cf9328445675ccc392e661b04336b229c9da",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 34, 'deletions': 33, 'total': 67}",
            "files":"{'tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc': {'additions': 34, 'deletions': 33, 'changes': 67, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd\/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_cholesky_op.cc', 'patch': '@@ -17,6 +17,8 @@ limitations under the License.\\n #include <numeric>\\n #include <vector>\\n \\n+#include \"tensorflow\/core\/framework\/op_requires.h\"\\n+\\n #define EIGEN_USE_THREADS\\n \\n #include \"third_party\/eigen3\/Eigen\/Core\"\\n@@ -82,8 +84,8 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\\n \\n     int64 num_rows;\\n     int batch_size;\\n-    ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size,\\n-                   &num_rows);\\n+    OP_REQUIRES_OK(ctx, ValidateInputs(*input_matrix, input_permutation_indices,\\n+                                       &batch_size, &num_rows));\\n \\n     \/\/ Allocate batch pointers.\\n     Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\\n@@ -226,49 +228,48 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\\n   }\\n \\n  private:\\n-  void ValidateInputs(OpKernelContext* ctx,\\n-                      const CSRSparseMatrix& sparse_matrix,\\n-                      const Tensor& permutation_indices, int* batch_size,\\n-                      int64* num_rows) {\\n-    OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value,\\n-                errors::InvalidArgument(\\n-                    \"Asked for a CSRSparseMatrix of type \",\\n-                    DataTypeString(DataTypeToEnum<T>::value),\\n-                    \" but saw dtype: \", DataTypeString(sparse_matrix.dtype())));\\n+  Status ValidateInputs(const CSRSparseMatrix& sparse_matrix,\\n+                        const Tensor& permutation_indices, int* batch_size,\\n+                        int64* num_rows) {\\n+    if (sparse_matrix.dtype() != DataTypeToEnum<T>::value)\\n+      return errors::InvalidArgument(\\n+          \"Asked for a CSRSparseMatrix of type \",\\n+          DataTypeString(DataTypeToEnum<T>::value),\\n+          \" but saw dtype: \", DataTypeString(sparse_matrix.dtype()));\\n \\n     const Tensor& dense_shape = sparse_matrix.dense_shape();\\n     const int rank = dense_shape.dim_size(0);\\n-    OP_REQUIRES(ctx, rank == 2 || rank == 3,\\n-                errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\\n-                                        \"but dense_shape has size \", rank));\\n+    if (rank < 2 || rank > 3)\\n+      return errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\\n+                                     \"but dense_shape has size \", rank);\\n     const int row_dim = (rank == 2) ? 0 : 1;\\n     auto dense_shape_vec = dense_shape.vec<int64>();\\n     *num_rows = dense_shape_vec(row_dim);\\n     const int64 num_cols = dense_shape_vec(row_dim + 1);\\n-    OP_REQUIRES(ctx, *num_rows == num_cols,\\n-                errors::InvalidArgument(\"sparse matrix must be square; got: \",\\n-                                        *num_rows, \" != \", num_cols));\\n+    if (*num_rows != num_cols)\\n+      return errors::InvalidArgument(\\n+          \"sparse matrix must be square; got: \", *num_rows, \" != \", num_cols);\\n     const TensorShape& perm_shape = permutation_indices.shape();\\n-    OP_REQUIRES(\\n-        ctx, perm_shape.dims() + 1 == rank,\\n-        errors::InvalidArgument(\\n-            \"sparse matrix must have the same rank as permutation; got: \", rank,\\n-            \" != \", perm_shape.dims(), \" + 1.\"));\\n-    OP_REQUIRES(\\n-        ctx, perm_shape.dim_size(rank - 2) == *num_rows,\\n-        errors::InvalidArgument(\\n-            \"permutation must have the same number of elements in each batch \"\\n-            \"as the number of rows in sparse matrix; got: \",\\n-            perm_shape.dim_size(rank - 2), \" != \", *num_rows));\\n+    if (perm_shape.dims() + 1 != rank)\\n+      return errors::InvalidArgument(\\n+          \"sparse matrix must have the same rank as permutation; got: \", rank,\\n+          \" != \", perm_shape.dims(), \" + 1.\");\\n+    if (perm_shape.dim_size(rank - 2) != *num_rows)\\n+      return errors::InvalidArgument(\\n+          \"permutation must have the same number of elements in each batch \"\\n+          \"as the number of rows in sparse matrix; got: \",\\n+          perm_shape.dim_size(rank - 2), \" != \", *num_rows);\\n \\n     *batch_size = sparse_matrix.batch_size();\\n     if (*batch_size > 1) {\\n-      OP_REQUIRES(\\n-          ctx, perm_shape.dim_size(0) == *batch_size,\\n-          errors::InvalidArgument(\"permutation must have the same batch size \"\\n-                                  \"as sparse matrix; got: \",\\n-                                  perm_shape.dim_size(0), \" != \", *batch_size));\\n+      if (perm_shape.dim_size(0) != *batch_size)\\n+        return errors::InvalidArgument(\\n+            \"permutation must have the same batch size \"\\n+            \"as sparse matrix; got: \",\\n+            perm_shape.dim_size(0), \" != \", *batch_size);\\n     }\\n+\\n+    return Status::OK();\\n   }\\n };'}}",
            "message_norm":"remove `op_requires` call from helper function.\n\nsince `op_requires` macro expands to a `return;` (among other), calling it in a helper function only ends the helper function's execution earlier, but the kernel will still run from start to end. thus, all the expected validations are actually broken\/useless as the code ploughs through the next crash anyway.\n\npiperorigin-revid: 369524386\nchange-id: i54f6cf9328445675ccc392e661b04336b229c9da",
            "language":"en",
            "entities":"[('remove', 'ACTION', ''), ('369524386', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc'])",
            "num_files":1.0,
            "patch_content":"From e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 20 Apr 2021 14:45:33 -0700\nSubject: [PATCH] Remove `OP_REQUIRES` call from helper function.\n\nSince `OP_REQUIRES` macro expands to a `return;` (among other), calling it in a helper function only ends the helper function's execution earlier, but the kernel will still run from start to end. Thus, all the expected validations are actually broken\/useless as the code ploughs through the next crash anyway.\n\nPiperOrigin-RevId: 369524386\nChange-Id: I54f6cf9328445675ccc392e661b04336b229c9da\n---\n ...\/core\/kernels\/sparse\/sparse_cholesky_op.cc | 67 ++++++++++---------\n 1 file changed, 34 insertions(+), 33 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc b\/tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc\nindex 9a939276f0b6cb..47ab252317de5e 100644\n--- a\/tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc\n+++ b\/tensorflow\/core\/kernels\/sparse\/sparse_cholesky_op.cc\n@@ -17,6 +17,8 @@ limitations under the License.\n #include <numeric>\n #include <vector>\n \n+#include \"tensorflow\/core\/framework\/op_requires.h\"\n+\n #define EIGEN_USE_THREADS\n \n #include \"third_party\/eigen3\/Eigen\/Core\"\n@@ -82,8 +84,8 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\n \n     int64 num_rows;\n     int batch_size;\n-    ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size,\n-                   &num_rows);\n+    OP_REQUIRES_OK(ctx, ValidateInputs(*input_matrix, input_permutation_indices,\n+                                       &batch_size, &num_rows));\n \n     \/\/ Allocate batch pointers.\n     Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\n@@ -226,49 +228,48 @@ class CSRSparseCholeskyCPUOp : public OpKernel {\n   }\n \n  private:\n-  void ValidateInputs(OpKernelContext* ctx,\n-                      const CSRSparseMatrix& sparse_matrix,\n-                      const Tensor& permutation_indices, int* batch_size,\n-                      int64* num_rows) {\n-    OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value,\n-                errors::InvalidArgument(\n-                    \"Asked for a CSRSparseMatrix of type \",\n-                    DataTypeString(DataTypeToEnum<T>::value),\n-                    \" but saw dtype: \", DataTypeString(sparse_matrix.dtype())));\n+  Status ValidateInputs(const CSRSparseMatrix& sparse_matrix,\n+                        const Tensor& permutation_indices, int* batch_size,\n+                        int64* num_rows) {\n+    if (sparse_matrix.dtype() != DataTypeToEnum<T>::value)\n+      return errors::InvalidArgument(\n+          \"Asked for a CSRSparseMatrix of type \",\n+          DataTypeString(DataTypeToEnum<T>::value),\n+          \" but saw dtype: \", DataTypeString(sparse_matrix.dtype()));\n \n     const Tensor& dense_shape = sparse_matrix.dense_shape();\n     const int rank = dense_shape.dim_size(0);\n-    OP_REQUIRES(ctx, rank == 2 || rank == 3,\n-                errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n-                                        \"but dense_shape has size \", rank));\n+    if (rank < 2 || rank > 3)\n+      return errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n+                                     \"but dense_shape has size \", rank);\n     const int row_dim = (rank == 2) ? 0 : 1;\n     auto dense_shape_vec = dense_shape.vec<int64>();\n     *num_rows = dense_shape_vec(row_dim);\n     const int64 num_cols = dense_shape_vec(row_dim + 1);\n-    OP_REQUIRES(ctx, *num_rows == num_cols,\n-                errors::InvalidArgument(\"sparse matrix must be square; got: \",\n-                                        *num_rows, \" != \", num_cols));\n+    if (*num_rows != num_cols)\n+      return errors::InvalidArgument(\n+          \"sparse matrix must be square; got: \", *num_rows, \" != \", num_cols);\n     const TensorShape& perm_shape = permutation_indices.shape();\n-    OP_REQUIRES(\n-        ctx, perm_shape.dims() + 1 == rank,\n-        errors::InvalidArgument(\n-            \"sparse matrix must have the same rank as permutation; got: \", rank,\n-            \" != \", perm_shape.dims(), \" + 1.\"));\n-    OP_REQUIRES(\n-        ctx, perm_shape.dim_size(rank - 2) == *num_rows,\n-        errors::InvalidArgument(\n-            \"permutation must have the same number of elements in each batch \"\n-            \"as the number of rows in sparse matrix; got: \",\n-            perm_shape.dim_size(rank - 2), \" != \", *num_rows));\n+    if (perm_shape.dims() + 1 != rank)\n+      return errors::InvalidArgument(\n+          \"sparse matrix must have the same rank as permutation; got: \", rank,\n+          \" != \", perm_shape.dims(), \" + 1.\");\n+    if (perm_shape.dim_size(rank - 2) != *num_rows)\n+      return errors::InvalidArgument(\n+          \"permutation must have the same number of elements in each batch \"\n+          \"as the number of rows in sparse matrix; got: \",\n+          perm_shape.dim_size(rank - 2), \" != \", *num_rows);\n \n     *batch_size = sparse_matrix.batch_size();\n     if (*batch_size > 1) {\n-      OP_REQUIRES(\n-          ctx, perm_shape.dim_size(0) == *batch_size,\n-          errors::InvalidArgument(\"permutation must have the same batch size \"\n-                                  \"as sparse matrix; got: \",\n-                                  perm_shape.dim_size(0), \" != \", *batch_size));\n+      if (perm_shape.dim_size(0) != *batch_size)\n+        return errors::InvalidArgument(\n+            \"permutation must have the same batch size \"\n+            \"as sparse matrix; got: \",\n+            perm_shape.dim_size(0), \" != \", *batch_size);\n     }\n+\n+    return Status::OK();\n   }\n };"
        }
    ]
}