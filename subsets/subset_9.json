{
    "schema":{
        "fields":[
            {
                "name":"index",
                "type":"integer"
            },
            {
                "name":"vuln_id",
                "type":"string"
            },
            {
                "name":"cwe_id",
                "type":"string"
            },
            {
                "name":"score",
                "type":"number"
            },
            {
                "name":"chain",
                "type":"string"
            },
            {
                "name":"dataset",
                "type":"string"
            },
            {
                "name":"summary",
                "type":"string"
            },
            {
                "name":"published_date",
                "type":"string"
            },
            {
                "name":"chain_len",
                "type":"integer"
            },
            {
                "name":"project",
                "type":"string"
            },
            {
                "name":"commit_href",
                "type":"string"
            },
            {
                "name":"commit_sha",
                "type":"string"
            },
            {
                "name":"patch",
                "type":"string"
            },
            {
                "name":"chain_ord",
                "type":"string"
            },
            {
                "name":"before_first_fix_commit",
                "type":"string"
            },
            {
                "name":"last_fix_commit",
                "type":"string"
            },
            {
                "name":"chain_ord_pos",
                "type":"number"
            },
            {
                "name":"commit_datetime",
                "type":"string"
            },
            {
                "name":"message",
                "type":"string"
            },
            {
                "name":"author",
                "type":"string"
            },
            {
                "name":"comments",
                "type":"string"
            },
            {
                "name":"stats",
                "type":"string"
            },
            {
                "name":"files",
                "type":"string"
            },
            {
                "name":"message_norm",
                "type":"string"
            },
            {
                "name":"language",
                "type":"string"
            },
            {
                "name":"entities",
                "type":"string"
            },
            {
                "name":"classification_level_1",
                "type":"string"
            },
            {
                "name":"classification_level_2",
                "type":"string"
            },
            {
                "name":"list_files",
                "type":"string"
            },
            {
                "name":"num_files",
                "type":"number"
            }
        ],
        "primaryKey":[
            "index"
        ],
        "pandas_version":"1.4.0"
    },
    "data":[
        {
            "index":2467,
            "vuln_id":"GHSA-mv78-g7wq-mhp4",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/49847ae69a4e1a97ae7f2db5e217c77721e37948'}",
            "dataset":"osv",
            "summary":"Division by zero in padding computation in TFLite ### Impact\nThe TFLite computation for size of output after padding, [`ComputeOutSize`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0c9692ae7b1671c983569e5d3de5565843d500cf\/tensorflow\/lite\/kernels\/padding.h#L43-L55), does not check that the `stride` argument is not 0 before doing the division.\n\n```cc\ninline int ComputeOutSize(TfLitePadding padding, int image_size,\n                          int filter_size, int stride, int dilation_rate = 1) {\n  int effective_filter_size = (filter_size - 1) * dilation_rate + 1;\n  switch (padding) {\n    case kTfLitePaddingSame:\n      return (image_size + stride - 1) \/ stride;\n    case kTfLitePaddingValid:\n      return (image_size + stride - effective_filter_size) \/ stride;\n    default:\n      return 0;\n  }\n}\n```\n  \nUsers can craft special models such that `ComputeOutSize` is called with `stride` set to 0.\n\n### Patches\nWe have patched the issue in GitHub commit [49847ae69a4e1a97ae7f2db5e217c77721e37948](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/49847ae69a4e1a97ae7f2db5e217c77721e37948).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/49847ae69a4e1a97ae7f2db5e217c77721e37948",
            "commit_sha":"49847ae69a4e1a97ae7f2db5e217c77721e37948",
            "patch":"SINGLE",
            "chain_ord":"['49847ae69a4e1a97ae7f2db5e217c77721e37948']",
            "before_first_fix_commit":"{'b0e85b5b3859d060a42364c79fe664b07299a0e9'}",
            "last_fix_commit":"49847ae69a4e1a97ae7f2db5e217c77721e37948",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/27\/2021, 22:37:08",
            "message":"Fix division by zero in TFLite padding.\n\nPiperOrigin-RevId: 370777494\nChange-Id: Ic1331e4a1603b9e4c8aa183012a6c8237410aa0f",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'tensorflow\/lite\/kernels\/padding.h': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/49847ae69a4e1a97ae7f2db5e217c77721e37948\/tensorflow%2Flite%2Fkernels%2Fpadding.h', 'patch': '@@ -44,6 +44,11 @@ inline int ComputePaddingWithOffset(int stride, int dilation_rate, int in_size,\\n inline int ComputeOutSize(TfLitePadding padding, int image_size,\\n                           int filter_size, int stride, int dilation_rate = 1) {\\n   int effective_filter_size = (filter_size - 1) * dilation_rate + 1;\\n+\\n+  \/\/ TODO(b\/186448822): This uses 0 since the function has no other way to\\n+  \/\/ report error case\\n+  if (stride == 0) return 0;\\n+\\n   switch (padding) {\\n     case kTfLitePaddingSame:\\n       return (image_size + stride - 1) \/ stride;'}}",
            "message_norm":"fix division by zero in tflite padding.\n\npiperorigin-revid: 370777494\nchange-id: ic1331e4a1603b9e4c8aa183012a6c8237410aa0f",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('division by zero', 'SECWORD', ''), ('370777494', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/padding.h'])",
            "num_files":1.0
        },
        {
            "index":2937,
            "vuln_id":"GHSA-rg3m-hqc5-344v",
            "cwe_id":"{'CWE-125'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67bfd9feeecfb3c61d80f0e46d89c170fbee682b'}",
            "dataset":"osv",
            "summary":"`SparseFillEmptyRows` heap OOB ### Impact\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e71b86d47f8bc1816bf54d7bddc4170e47670b97\/tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc#L194-L241) of `SparseFillEmptyRows` can be made to trigger a heap OOB access:\n\n```python\nimport tensorflow as tf\n  \ndata=tf.raw_ops.SparseFillEmptyRows(\n  indices=[[0,0],[0,0],[0,0]],\n  values=['sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss'],\n  dense_shape=[5,3],\n  default_value='o')\n```\n  \nThis occurs whenever the size of `indices` does not match the size of `values`.\n\n### Patches\nWe have patched the issue in GitHub commit [67bfd9feeecfb3c61d80f0e46d89c170fbee682b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67bfd9feeecfb3c61d80f0e46d89c170fbee682b).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-11-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
            "commit_sha":"67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
            "patch":"SINGLE",
            "chain_ord":"['67bfd9feeecfb3c61d80f0e46d89c170fbee682b']",
            "before_first_fix_commit":"{'421fba8888bb8f8724bc2e35ca2fdcde16e1bfe5'}",
            "last_fix_commit":"67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/30\/2021, 17:44:33",
            "message":"Make SparseFillEmptyRows validate that the length of `values` must be equal to the number of index tuples.\n\nPiperOrigin-RevId: 399969549\nChange-Id: I3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8",
            "author":"Penporn Koanantakool",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
            "files":"{'tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/67bfd9feeecfb3c61d80f0e46d89c170fbee682b\/tensorflow%2Fcore%2Fkernels%2Fsparse_fill_empty_rows_op.cc', 'patch': '@@ -24,11 +24,13 @@ limitations under the License.\\n #include <vector>\\n \\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n+#include \"tensorflow\/core\/framework\/op_requires.h\"\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_util.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/util\/sparse\/sparse_tensor.h\"\\n \\n namespace tensorflow {\\n@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\\n                     errors::InvalidArgument(\"values must be a vector, saw: \",\\n                                             values_t.shape().DebugString()),\\n                     done);\\n+  OP_REQUIRES_ASYNC(\\n+      context, indices_t.dim_size(0) == values_t.dim_size(0),\\n+      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\\n+                              \") must match the first dimension of `indices` (\",\\n+                              indices_t.dim_size(0), \").\"),\\n+      done);\\n   OP_REQUIRES_ASYNC(\\n       context, TensorShapeUtils::IsScalar(default_value_t.shape()),\\n       errors::InvalidArgument(\"default_value must be a scalar, saw: \",'}}",
            "message_norm":"make sparsefillemptyrows validate that the length of `values` must be equal to the number of index tuples.\n\npiperorigin-revid: 399969549\nchange-id: i3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8",
            "language":"en",
            "entities":"[('validate', 'ACTION', ''), ('399969549', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc'])",
            "num_files":1.0
        },
        {
            "index":42,
            "vuln_id":"GHSA-26cm-qrc6-mfgj",
            "cwe_id":"{'CWE-74', 'CWE-90'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/StevenWeathers\/thunderdome-planning-poker\/commit\/f1524d01e8a0f2d6c3db5461c742456c692dd8c1'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Special Elements used in an LDAP Query in stevenweathers\/thunderdome-planning-poker ### Impact\nLDAP injection vulnerability, only affects instances with LDAP authentication enabled.\n\n### Patches\nPatch for vulnerability released with v1.16.3.\n\n### Workarounds\nDisable LDAP feature if in use\n\n### References\n[OWASP LDAP Injection Prevention Cheat Sheet](https:\/\/cheatsheetseries.owasp.org\/cheatsheets\/LDAP_Injection_Prevention_Cheat_Sheet.html\n)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Thunderdome Github Repository](https:\/\/github.com\/StevenWeathers\/thunderdome-planning-poker)\n* Email us at [steven@weathers.me](mailto:steven@weathers.me)",
            "published_date":"2021-11-08",
            "chain_len":1,
            "project":"https:\/\/github.com\/StevenWeathers\/thunderdome-planning-poker",
            "commit_href":"https:\/\/github.com\/StevenWeathers\/thunderdome-planning-poker\/commit\/f1524d01e8a0f2d6c3db5461c742456c692dd8c1",
            "commit_sha":"f1524d01e8a0f2d6c3db5461c742456c692dd8c1",
            "patch":"SINGLE",
            "chain_ord":"['f1524d01e8a0f2d6c3db5461c742456c692dd8c1']",
            "before_first_fix_commit":"{'2b9ae2e1e70e0fde47d459aa0c16b768c253e51d'}",
            "last_fix_commit":"f1524d01e8a0f2d6c3db5461c742456c692dd8c1",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/02\/2021, 00:48:52",
            "message":"Fix LDAP vulnerability",
            "author":"Steven Weathers",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'auth.go': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/StevenWeathers\/thunderdome-planning-poker\/raw\/f1524d01e8a0f2d6c3db5461c742456c692dd8c1\/auth.go', 'patch': '@@ -68,7 +68,7 @@ func (s *server) authAndCreateUserLdap(UserName string, UserPassword string) (*d\\n \\n \\tsearchRequest := ldap.NewSearchRequest(viper.GetString(\"auth.ldap.basedn\"),\\n \\t\\tldap.ScopeWholeSubtree, ldap.NeverDerefAliases, 0, 0, false,\\n-\\t\\tfmt.Sprintf(viper.GetString(\"auth.ldap.filter\"), UserName),\\n+\\t\\tfmt.Sprintf(viper.GetString(\"auth.ldap.filter\"), ldap.EscapeFilter(UserName)),\\n \\t\\t[]string{\"dn\", viper.GetString(\"auth.ldap.mail_attr\"), viper.GetString(\"auth.ldap.cn_attr\")},\\n \\t\\tnil,\\n \\t)'}}",
            "message_norm":"fix ldap vulnerability",
            "language":"ca",
            "entities":"[('ldap', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['auth.go'])",
            "num_files":1.0
        },
        {
            "index":1670,
            "vuln_id":"GHSA-f5cx-5wr3-5qrc",
            "cwe_id":"{'CWE-824'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in boosted trees ### Impact\nAn attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesCalculateBestGainsPerFeature(\n  node_id_range=[],\n  stats_summary_list=[[1,2,3]],\n  l1=[1.0],\n  l2=[1.0],\n  tree_complexity =[1.0],\n  min_node_weight =[1.17],\n  max_splits=5)\n```\n\nA similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`:\n\n```python\nimport tensorflow as tf\n                                                                                                                                                                                                                                                                                          \ntf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2(\n  node_id_range=[],\n  stats_summaries_list=[[1,2,3]],\n  split_types=[''],\n  candidate_feature_ids=[1,2,3,4],\n  l1=[1],     \n  l2=[1],\n  tree_complexity=[1.0],\n  min_node_weight=[1.17],\n  logits_dimension=5)\n```     \n    \nThe  [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc) does not validate the input values.\n\n### Patches\nWe have patched the issue in GitHub commit [9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad) and in commit. [429f009d2b2c09028647dd4bb7b3f6f414bbaad7](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "commit_sha":"429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "patch":"MULTI",
            "chain_ord":"['9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', '429f009d2b2c09028647dd4bb7b3f6f414bbaad7']",
            "before_first_fix_commit":"{'4f8db85aa9ab71a71e95d5acce7de52a0b195661'}",
            "last_fix_commit":"429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/28\/2021, 20:25:18",
            "message":"Add remaining missing validation to `BoostedTreesCalculateBestFeatureSplit`\n\nPiperOrigin-RevId: 387423006\nChange-Id: I8eaf30efb223011519e60707bfa751b275d3a443",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 1, 'total': 20}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc': {'additions': 19, 'deletions': 1, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -14,6 +14,7 @@ limitations under the License.\\n ==============================================================================*\/\\n \\n #include <limits>\\n+#include <string>\\n #include <vector>\\n \\n #include \"third_party\/eigen3\/Eigen\/Core\"\\n@@ -22,6 +23,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n #include \"tensorflow\/core\/kernels\/boosted_trees\/boosted_trees.pb.h\"\\n #include \"tensorflow\/core\/kernels\/boosted_trees\/tree_helper.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/platform\/logging.h\"\\n \\n namespace tensorflow {\\n@@ -254,12 +256,18 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n     \/\/ node_id_range\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->NumElements() == 2,\\n+        errors::InvalidArgument(\"node_id_range argument must have shape [2]\"));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n     const int32_t node_id_first = node_id_range(0);  \/\/ inclusive\\n     const int32_t node_id_last = node_id_range(1);   \/\/ exclusive\\n \\n     const Tensor* stats_summary_t;\\n     OP_REQUIRES_OK(context, context->input(\"stats_summary\", &stats_summary_t));\\n+    OP_REQUIRES(\\n+        context, stats_summary_t->shape().dims() == 4,\\n+        errors::InvalidArgument(\"stats_summary argument must have rank 4\"));\\n     TTypes<float, 4>::ConstTensor stats_summary =\\n         stats_summary_t->tensor<float, 4>();\\n     const int32_t feature_dims = stats_summary_t->dim_size(1);\\n@@ -272,6 +280,8 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n \\n     const Tensor* l1_t;\\n     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\\n+    OP_REQUIRES(context, l1_t->NumElements() == 1,\\n+                errors::InvalidArgument(\"l1 argument must be a scalar\"));\\n     const auto l1 = l1_t->scalar<float>()();\\n     DCHECK_GE(l1, 0);\\n     if (logits_dim_ > 1) {\\n@@ -281,17 +291,25 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n \\n     const Tensor* l2_t;\\n     OP_REQUIRES_OK(context, context->input(\"l2\", &l2_t));\\n+    OP_REQUIRES(context, l2_t->NumElements() == 1,\\n+                errors::InvalidArgument(\"l2 argument must be a scalar\"));\\n     const auto l2 = l2_t->scalar<float>()();\\n     DCHECK_GE(l2, 0);\\n \\n     const Tensor* tree_complexity_t;\\n     OP_REQUIRES_OK(context,\\n                    context->input(\"tree_complexity\", &tree_complexity_t));\\n+    OP_REQUIRES(\\n+        context, tree_complexity_t->NumElements() == 1,\\n+        errors::InvalidArgument(\"tree_complexity argument must be a scalar\"));\\n     const auto tree_complexity = tree_complexity_t->scalar<float>()();\\n \\n     const Tensor* min_node_weight_t;\\n     OP_REQUIRES_OK(context,\\n                    context->input(\"min_node_weight\", &min_node_weight_t));\\n+    OP_REQUIRES(\\n+        context, min_node_weight_t->NumElements() == 1,\\n+        errors::InvalidArgument(\"min_node_weight argument must be a scalar\"));\\n     const auto min_node_weight = min_node_weight_t->scalar<float>()();\\n \\n     std::vector<int32> output_node_ids;\\n@@ -300,7 +318,7 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\\n     std::vector<int32> output_thresholds;\\n     std::vector<Eigen::VectorXf> output_left_node_contribs;\\n     std::vector<Eigen::VectorXf> output_right_node_contribs;\\n-    std::vector<string> output_split_types;\\n+    std::vector<std::string> output_split_types;\\n \\n     \/\/ TODO(tanzheny) parallelize the computation.\\n     \/\/ Iterate each node and find the best gain per node.'}}",
            "message_norm":"add remaining missing validation to `boostedtreescalculatebestfeaturesplit`\n\npiperorigin-revid: 387423006\nchange-id: i8eaf30efb223011519e60707bfa751b275d3a443",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('387423006', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":1870,
            "vuln_id":"GHSA-gfh2-7jg5-653p",
            "cwe_id":"{'CWE-835'}",
            "score":4.0,
            "chain":"{'https:\/\/github.com\/appc\/docker2aci\/pull\/204\/commits\/54331ec7020e102935c31096f336d31f6400064f'}",
            "dataset":"osv",
            "summary":"Denial of Service in docker2aci docker2aci <= 0.12.3 has an infinite loop when handling local images with cyclic dependency chain.",
            "published_date":"2022-02-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/appc\/docker2aci",
            "commit_href":"https:\/\/github.com\/appc\/docker2aci\/pull\/204\/commits\/54331ec7020e102935c31096f336d31f6400064f",
            "commit_sha":"54331ec7020e102935c31096f336d31f6400064f",
            "patch":"SINGLE",
            "chain_ord":"['54331ec7020e102935c31096f336d31f6400064f']",
            "before_first_fix_commit":"{'8a4173c3067a557fba64a03c6efac613dfbba6ac'}",
            "last_fix_commit":"54331ec7020e102935c31096f336d31f6400064f",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/10\/2016, 13:23:55",
            "message":"backend\/file: fix an infinite loop in deps walking (CVE-2016-8579)\n\nThis commit fixes a possible infinite loop while traversing\nthe dependency ancestry of a malformed local image file.\n\nThis has been assigned CVE-2016-8579:\nhttps:\/\/github.com\/appc\/docker2aci\/issues\/203#issuecomment-253494006",
            "author":"Luca Bruno",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 0, 'total': 11}",
            "files":"{'lib\/internal\/backend\/file\/file.go': {'additions': 11, 'deletions': 0, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/appc\/docker2aci\/raw\/54331ec7020e102935c31096f336d31f6400064f\/lib%2Finternal%2Fbackend%2Ffile%2Ffile.go', 'patch': '@@ -279,14 +279,24 @@ func extractEmbeddedLayer(file *os.File, layerID string, outputPath string) (*os\\n \\treturn layerFile, nil\\n }\\n \\n+\/\/ getAncestry computes an image ancestry, returning an ordered list\\n+\/\/ of dependencies starting from the topmost image to the base.\\n+\/\/ It checks for dependency loops via duplicate detection in the image\\n+\/\/ chain and errors out in such cases.\\n func getAncestry(file *os.File, imgID string) ([]string, error) {\\n \\tvar ancestry []string\\n+\\tdeps := make(map[string]bool)\\n \\n \\tcurImgID := imgID\\n \\n \\tvar err error\\n \\tfor curImgID != \"\" {\\n+\\t\\tif deps[curImgID] {\\n+\\t\\t\\treturn nil, fmt.Errorf(\"dependency loop detected at image %q\", curImgID)\\n+\\t\\t}\\n+\\t\\tdeps[curImgID] = true\\n \\t\\tancestry = append(ancestry, curImgID)\\n+\\t\\tlog.Debug(fmt.Sprintf(\"Getting ancestry for layer %q\", curImgID))\\n \\t\\tcurImgID, err = getParent(file, curImgID)\\n \\t\\tif err != nil {\\n \\t\\t\\treturn nil, err\\n@@ -328,5 +338,6 @@ func getParent(file *os.File, imgID string) (string, error) {\\n \\t\\treturn \"\", err\\n \\t}\\n \\n+\\tlog.Debug(fmt.Sprintf(\"Layer %q depends on layer %q\", imgID, parent))\\n \\treturn parent, nil\\n }'}}",
            "message_norm":"backend\/file: fix an infinite loop in deps walking (cve-2016-8579)\n\nthis commit fixes a possible infinite loop while traversing\nthe dependency ancestry of a malformed local image file.\n\nthis has been assigned cve-2016-8579:\nhttps:\/\/github.com\/appc\/docker2aci\/issues\/203#issuecomment-253494006",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('infinite loop', 'SECWORD', ''), ('cve-2016-8579', 'VULNID', 'CVE'), ('fixes', 'ACTION', ''), ('infinite loop', 'SECWORD', ''), ('cve-2016-8579', 'VULNID', 'CVE'), ('https:\/\/github.com\/appc\/docker2aci\/issues\/203#issuecomment-253494006', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/internal\/backend\/file\/file.go'])",
            "num_files":1.0
        },
        {
            "index":401,
            "vuln_id":"GHSA-4c4g-crqm-xrxw",
            "cwe_id":"{'CWE-908'}",
            "score":4.4,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8933b8a21280696ab119b63263babdb54c298538', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/537bc7c723439b9194a358f64d871dd326c18887'}",
            "dataset":"osv",
            "summary":"Use of unitialized value in TFLite ### Impact\nAll TFLite operations that use quantization can be made to use unitialized values. [For example](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/lite\/kernels\/depthwise_conv.cc#L198-L200):\n\n```cc\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n```\n\nThe issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code.\n\n### Patches\nWe have patched the issue in GitHub commits [537bc7c723439b9194a358f64d871dd326c18887](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/537bc7c723439b9194a358f64d871dd326c18887),\n[4a91f2069f7145aab6ba2d8cfe41be8a110c18a5](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5) and [8933b8a21280696ab119b63263babdb54c298538](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8933b8a21280696ab119b63263babdb54c298538).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":3,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8933b8a21280696ab119b63263babdb54c298538",
            "commit_sha":"8933b8a21280696ab119b63263babdb54c298538",
            "patch":"MULTI",
            "chain_ord":"['537bc7c723439b9194a358f64d871dd326c18887', '4a91f2069f7145aab6ba2d8cfe41be8a110c18a5', '8933b8a21280696ab119b63263babdb54c298538']",
            "before_first_fix_commit":"{'e35be978351a8578549d30b6f483825d36dc0f8b'}",
            "last_fix_commit":"8933b8a21280696ab119b63263babdb54c298538",
            "chain_ord_pos":3.0,
            "commit_datetime":"07\/16\/2021, 17:22:37",
            "message":"Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/lite\/kernels\/depthwise_conv.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/8933b8a21280696ab119b63263babdb54c298538\/tensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc', 'patch': '@@ -176,6 +176,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   if (data_type != kTfLiteFloat32) {\\n     TF_LITE_ENSURE_EQ(context, filter->quantization.type,\\n                       kTfLiteAffineQuantization);\\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n     const auto* affine_quantization =\\n         reinterpret_cast<TfLiteAffineQuantization*>(\\n             filter->quantization.params);\\n@@ -195,6 +196,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n   }\\n \\n   if (is_hybrid) {\\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n     const auto* affine_quantization =\\n         reinterpret_cast<TfLiteAffineQuantization*>(\\n             filter->quantization.params);\\n@@ -495,6 +497,7 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\\n   op_params.weights_offset = 0;\\n   op_params.float_activation_min = output_activation_min;\\n   op_params.float_activation_max = output_activation_max;\\n+  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\\n   const auto* affine_quantization =\\n       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\\n   if (kernel_type == kReference) {'}}",
            "message_norm":"fix a null pointer exception caused by branching on uninitialized data.\n\nthis is due to not checking that the params for the quantization exists. if there is no quantization, we should not access the `.params` field.\n\npiperorigin-revid: 385173491\nchange-id: i8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('null pointer exception', 'SECWORD', ''), ('uninitialized', 'SECWORD', ''), ('385173491', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/depthwise_conv.cc'])",
            "num_files":1.0
        },
        {
            "index":3440,
            "vuln_id":"GHSA-xhp9-4947-rq78",
            "cwe_id":"{'CWE-755'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/bottlepy\/bottle\/commit\/a2b0ee6bb4ce88895429ec4aca856616244c4c4c', 'https:\/\/github.com\/bottlepy\/bottle\/commit\/e140e1b54da721a660f2eb9d58a106b7b3ff2f00'}",
            "dataset":"osv",
            "summary":"Denial of service in bottle Bottle before 0.12.20 mishandles errors during early request binding.",
            "published_date":"2022-06-03",
            "chain_len":2,
            "project":"https:\/\/github.com\/bottlepy\/bottle",
            "commit_href":"https:\/\/github.com\/bottlepy\/bottle\/commit\/a2b0ee6bb4ce88895429ec4aca856616244c4c4c",
            "commit_sha":"a2b0ee6bb4ce88895429ec4aca856616244c4c4c",
            "patch":"MULTI",
            "chain_ord":"['e140e1b54da721a660f2eb9d58a106b7b3ff2f00', 'a2b0ee6bb4ce88895429ec4aca856616244c4c4c']",
            "before_first_fix_commit":"{'04b27f185412250f9389a6a14d1e1c516c87e13c'}",
            "last_fix_commit":"a2b0ee6bb4ce88895429ec4aca856616244c4c4c",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/26\/2022, 13:36:31",
            "message":"Release of 0.12.20\n\nThis release contains a security fix.\nThanks Elton Nokaj for responsibly reporting this issue.",
            "author":"Marcel Hellkamp",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'bottle.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/bottlepy\/bottle\/raw\/a2b0ee6bb4ce88895429ec4aca856616244c4c4c\/bottle.py', 'patch': \"@@ -16,7 +16,7 @@\\n from __future__ import with_statement\\n \\n __author__ = 'Marcel Hellkamp'\\n-__version__ = '0.12.19'\\n+__version__ = '0.12.20'\\n __license__ = 'MIT'\\n \\n # The gevent server adapter needs to patch some modules before they are imported\"}}",
            "message_norm":"release of 0.12.20\n\nthis release contains a security fix.\nthanks elton nokaj for responsibly reporting this issue.",
            "language":"en",
            "entities":"[('0.12.20', 'VERSION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bottle.py'])",
            "num_files":1.0
        },
        {
            "index":525,
            "vuln_id":"GHSA-4xfp-4pfp-89wg",
            "cwe_id":"{'CWE-824'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1071f554dbd09f7e101324d366eec5f4fe5a3ece'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in `RaggedTensorToSparse` ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToSparse`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedTensorToSparse(\n  rt_nested_splits=[[0, 38, 0]],\n  rt_dense_values=[])\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc#L30) has an incomplete validation of the splits values: it does not check that they are in increasing order.\n\n### Patches\nWe have patched the issue in GitHub commit [1071f554dbd09f7e101324d366eec5f4fe5a3ece](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1071f554dbd09f7e101324d366eec5f4fe5a3ece).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1071f554dbd09f7e101324d366eec5f4fe5a3ece",
            "commit_sha":"1071f554dbd09f7e101324d366eec5f4fe5a3ece",
            "patch":"SINGLE",
            "chain_ord":"['1071f554dbd09f7e101324d366eec5f4fe5a3ece']",
            "before_first_fix_commit":"{'0f387ffa5cc7d30fa1574d12f875ffbb2d1826b4'}",
            "last_fix_commit":"1071f554dbd09f7e101324d366eec5f4fe5a3ece",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/30\/2021, 01:23:29",
            "message":"Add missing validation to `RaggedTensorToSparse`.\n\nThere needs to be a check that the splits allow for valid ragged tensors.\n\nPiperOrigin-RevId: 387712169\nChange-Id: I2499175324b82b65d159a260c7f83b98ceb5cc7d",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 1, 'total': 12}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc': {'additions': 11, 'deletions': 1, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1071f554dbd09f7e101324d366eec5f4fe5a3ece\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_sparse_kernel.cc', 'patch': '@@ -21,6 +21,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n \\n namespace tensorflow {\\n \\n@@ -38,7 +39,8 @@ class RaggedTensorToSparseOp : public OpKernel {\\n     OP_REQUIRES_OK(\\n         context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));\\n     const int rt_nested_splits_len = rt_nested_splits_in.size();\\n-    DCHECK_GT(rt_nested_splits_len, 0);  \/\/ Enforced by REGISTER_OP.\\n+    OP_REQUIRES(context, rt_nested_splits_len > 0,\\n+                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));\\n     std::vector<ConstFlatSplits> rt_nested_splits;\\n     rt_nested_splits.reserve(rt_nested_splits_len);\\n     for (int i = 0; i < rt_nested_splits_len; ++i) {\\n@@ -162,6 +164,14 @@ class RaggedTensorToSparseOp : public OpKernel {\\n       if (rt_nested_splits[i](0) != 0) {\\n         return InvalidArgument(\"First value of ragged splits must be 0.\");\\n       }\\n+      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {\\n+        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {\\n+          return InvalidArgument(\\n+              \"Ragged splits should be non decreasing, but we got \",\\n+              rt_nested_splits[i](j - 1), \" followed by \",\\n+              rt_nested_splits[i](j));\\n+        }\\n+      }\\n       if (i > 0) {\\n         SPLITS_TYPE last_split =\\n             rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);'}}",
            "message_norm":"add missing validation to `raggedtensortosparse`.\n\nthere needs to be a check that the splits allow for valid ragged tensors.\n\npiperorigin-revid: 387712169\nchange-id: i2499175324b82b65d159a260c7f83b98ceb5cc7d",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('387712169', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_sparse_kernel.cc'])",
            "num_files":1.0
        },
        {
            "index":3148,
            "vuln_id":"GHSA-vmm6-w4cf-7f3x",
            "cwe_id":"{'CWE-285'}",
            "score":8.7,
            "chain":"{'https:\/\/github.com\/opencast\/opencast\/commit\/b157e1fb3b35991ca7bf59f0730329fbe7ce82e8'}",
            "dataset":"osv",
            "summary":"Authentication Bypass For Endpoints With Anonymous Access in Opencast ### Impact\n\nUsing a remember-me cookie with an arbitrary username can cause Opencast to assume proper authentication for that user even if the remember-me cookie was incorrect given that the attacked endpoint also allows anonymous access.\n\nThis way, an attacker can, for example, fake a remember-me token, assume the identity of the global system administrator and request non-public content from the search service without ever providing any proper authentication.\n\n\n### Patches\n\nThis problem is fixed in Opencast 7.6 and Opencast 8.1\n\n\n### Workarounds\n\nAs a workaround for older, unpatched versions, disabling remember-me cookies in `etc\/security\/mh_default_org.xml` will mitigate the problem but will obviously also disable this feature without obvious indication. To deactivate this, remove the following line from the security configuration:\n\n```xml\n<sec:remember-me \u2026 \/>\n```\n\n### References\n\n- [Remember-me cookie in the security configuration file](https:\/\/github.com\/opencast\/opencast\/blob\/161ee619382f144dc35eea211fc6b556025b98e1\/etc\/security\/mh_default_org.xml#L335-L336)\n\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n- Open an issue in [opencast\/opencast](https:\/\/github.com\/opencast\/opencast\/issues)\n- For security-relevant information, email us at security@opencast.org",
            "published_date":"2020-01-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/opencast\/opencast",
            "commit_href":"https:\/\/github.com\/opencast\/opencast\/commit\/b157e1fb3b35991ca7bf59f0730329fbe7ce82e8",
            "commit_sha":"b157e1fb3b35991ca7bf59f0730329fbe7ce82e8",
            "patch":"SINGLE",
            "chain_ord":"['b157e1fb3b35991ca7bf59f0730329fbe7ce82e8']",
            "before_first_fix_commit":"{'1a7172c95af8d542a77ae5b153e4c834dd4788a6'}",
            "last_fix_commit":"b157e1fb3b35991ca7bf59f0730329fbe7ce82e8",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/13\/2020, 22:55:50",
            "message":"Authentication Bypass For Endpoints With Anonymous Access\n\nUsing a remember-me cookie with an arbitrary username can cause Opencast\nto assume proper authentication for that user even if the remember-me\ncookie was incorrect given that the attacked endpoint also allows\nanonymous access.\n\nThis way, an attacker can, for example, fake a remember-me token, assume\nthe identity of the global system administrator and request non-public\ncontent from the search service without ever providing any proper\nauthentication.\n\nThe reason for this problem is that using a remember-me cookie will\nalways cause the user in the request context to be populated, even if\nthe cookie is invalid by now. This is usually no problem, except in\ncombination with anonymous access where anonymous authentication is\ngranted and the request may continue.\n\nIn such a case, Opencast's security service would just check that a user\nexisted in the request context and assume proper authentication of this\nuser, never checking if it's actually anonymous authentication.\n\nThis patch adds this additional check, falling back to the anonymous\nuser in case of anonymous authentication.",
            "author":"Lars Kiesow",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 6, 'total': 16}",
            "files":"{'modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/security\/SecurityServiceSpringImpl.java': {'additions': 10, 'deletions': 6, 'changes': 16, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencast\/opencast\/raw\/b157e1fb3b35991ca7bf59f0730329fbe7ce82e8\/modules%2Fkernel%2Fsrc%2Fmain%2Fjava%2Forg%2Fopencastproject%2Fkernel%2Fsecurity%2FSecurityServiceSpringImpl.java', 'patch': '@@ -32,6 +32,7 @@\\n \\n import org.slf4j.Logger;\\n import org.slf4j.LoggerFactory;\\n+import org.springframework.security.authentication.AnonymousAuthenticationToken;\\n import org.springframework.security.core.Authentication;\\n import org.springframework.security.core.GrantedAuthority;\\n import org.springframework.security.core.context.SecurityContextHolder;\\n@@ -94,15 +95,19 @@ public User getUser() throws IllegalStateException {\\n \\n     User delegatedUser = delegatedUserHolder.get();\\n \\n+    Authentication auth = SecurityContextHolder.getContext().getAuthentication();\\n+    if (auth instanceof AnonymousAuthenticationToken) {\\n+      return SecurityUtil.createAnonymousUser(org);\\n+    }\\n+\\n     if (delegatedUser != null) {\\n       return delegatedUser;\\n     }\\n \\n-    Authentication auth = SecurityContextHolder.getContext().getAuthentication();\\n     JaxbOrganization jaxbOrganization = JaxbOrganization.fromOrganization(org);\\n     if (auth != null) {\\n       Object principal = auth.getPrincipal();\\n-      if ((principal != null) && (principal instanceof UserDetails)) {\\n+      if ((principal instanceof UserDetails)) {\\n         UserDetails userDetails = (UserDetails) principal;\\n \\n         User user = null;\\n@@ -111,16 +116,15 @@ public User getUser() throws IllegalStateException {\\n         if (userDirectory != null) {\\n           user = userDirectory.loadUser(userDetails.getUsername());\\n           if (user == null) {\\n-            logger.debug(\\n-                    \"Authenticated user \\'{}\\' could not be found in any of the current UserProviders. Continuing anyway...\",\\n-                    userDetails.getUsername());\\n+            logger.debug(\"Authenticated user \\'{}\\' could not be found in any of the current UserProviders. \"\\n+                + \"Continuing anyway...\", userDetails.getUsername());\\n           }\\n         } else {\\n           logger.debug(\"No UserDirectory was found when trying to search for user \\'{}\\'\", userDetails.getUsername());\\n         }\\n \\n         \/\/ Add the roles (authorities) in the security context\\n-        Set<JaxbRole> roles = new HashSet<JaxbRole>();\\n+        Set<JaxbRole> roles = new HashSet<>();\\n         Collection<? extends GrantedAuthority> authorities = auth.getAuthorities();\\n         if (authorities != null) {\\n           for (GrantedAuthority ga : authorities) {'}}",
            "message_norm":"authentication bypass for endpoints with anonymous access\n\nusing a remember-me cookie with an arbitrary username can cause opencast\nto assume proper authentication for that user even if the remember-me\ncookie was incorrect given that the attacked endpoint also allows\nanonymous access.\n\nthis way, an attacker can, for example, fake a remember-me token, assume\nthe identity of the global system administrator and request non-public\ncontent from the search service without ever providing any proper\nauthentication.\n\nthe reason for this problem is that using a remember-me cookie will\nalways cause the user in the request context to be populated, even if\nthe cookie is invalid by now. this is usually no problem, except in\ncombination with anonymous access where anonymous authentication is\ngranted and the request may continue.\n\nin such a case, opencast's security service would just check that a user\nexisted in the request context and assume proper authentication of this\nuser, never checking if it's actually anonymous authentication.\n\nthis patch adds this additional check, falling back to the anonymous\nuser in case of anonymous authentication.",
            "language":"en",
            "entities":"[('authentication bypass', 'SECWORD', ''), ('cookie', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('cookie', 'SECWORD', ''), ('attacked', 'SECWORD', ''), ('attacker', 'FLAW', ''), ('administrator', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('problem', 'FLAW', ''), ('cookie', 'SECWORD', ''), ('cookie', 'SECWORD', ''), ('problem', 'FLAW', ''), ('authentication', 'SECWORD', ''), ('security', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('adds', 'ACTION', ''), ('authentication', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/security\/SecurityServiceSpringImpl.java'])",
            "num_files":1.0
        },
        {
            "index":1160,
            "vuln_id":"GHSA-874w-m2v2-mj64",
            "cwe_id":"{'CWE-415'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/adplug\/adplug\/commit\/1a282a486a8e33fef3e15998bf6408d3515dc07e', 'https:\/\/github.com\/miller-alex\/adplug\/commit\/8abb9328bf27dcbdafc67ade3e75af0ffd8f7633'}",
            "dataset":"osv",
            "summary":"Double Free in Adplug AdPlug 2.3.1 has a double free in the Cu6mPlayer class in u6m.h.",
            "published_date":"2021-03-29",
            "chain_len":2,
            "project":"https:\/\/github.com\/miller-alex\/adplug",
            "commit_href":"https:\/\/github.com\/miller-alex\/adplug\/commit\/8abb9328bf27dcbdafc67ade3e75af0ffd8f7633",
            "commit_sha":"8abb9328bf27dcbdafc67ade3e75af0ffd8f7633",
            "patch":"MULTI",
            "chain_ord":"['8abb9328bf27dcbdafc67ade3e75af0ffd8f7633', '1a282a486a8e33fef3e15998bf6408d3515dc07e']",
            "before_first_fix_commit":"{'a8903d884e2c900e77af5c70ef440e72626646ad'}",
            "last_fix_commit":"1a282a486a8e33fef3e15998bf6408d3515dc07e",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/24\/2020, 14:43:22",
            "message":"Fix double free in Cu6mPlayer::~Cu6mPlayer() (issue #91)\n\nLeave deallocation of song_data to destructor when\ndecompression fails, just like on success.\n\nThis fixes CVE-2019-15151.\n\nEven though load() is apparently not supposed to be called\ntwice (and bad things happen in many players if you do),\nlet's also avoid leaking song_data's memory in that case.\n\nFixes: https:\/\/github.com\/adplug\/adplug\/issues\/91",
            "author":"Alexander Miller",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 2, 'total': 3}",
            "files":"{'src\/u6m.cpp': {'additions': 1, 'deletions': 2, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/miller-alex\/adplug\/raw\/8abb9328bf27dcbdafc67ade3e75af0ffd8f7633\/src%2Fu6m.cpp', 'patch': '@@ -66,6 +66,7 @@ bool Cu6mPlayer::load(const std::string &filename, const CFileProvider &fp)\\n     }\\n \\n   \/\/ load section\\n+  delete[] song_data;\\n   song_data = new unsigned char[decompressed_filesize];\\n   unsigned char* compressed_song_data = new unsigned char[filesize-3];\\n \\n@@ -74,7 +75,6 @@ bool Cu6mPlayer::load(const std::string &filename, const CFileProvider &fp)\\n   fp.close(f);\\n \\n   \/\/ attempt to decompress the song data\\n-  \/\/ if unsuccessful, deallocate song_data[] on the spot, and return(false)\\n   data_block source, destination;\\n   source.size = filesize-4;\\n   source.data = compressed_song_data;\\n@@ -84,7 +84,6 @@ bool Cu6mPlayer::load(const std::string &filename, const CFileProvider &fp)\\n   if (!lzw_decompress(source,destination))\\n     {\\n       delete[] compressed_song_data;\\n-      delete[] song_data;\\n       return(false);\\n     }'}}",
            "message_norm":"fix double free in cu6mplayer::~cu6mplayer() (issue #91)\n\nleave deallocation of song_data to destructor when\ndecompression fails, just like on success.\n\nthis fixes cve-2019-15151.\n\neven though load() is apparently not supposed to be called\ntwice (and bad things happen in many players if you do),\nlet's also avoid leaking song_data's memory in that case.\n\nfixes: https:\/\/github.com\/adplug\/adplug\/issues\/91",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('double free', 'SECWORD', ''), ('#91', 'ISSUE', ''), ('decompression', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('cve-2019-15151', 'VULNID', 'CVE'), ('fixes', 'ACTION', ''), ('https:\/\/github.com\/adplug\/adplug\/issues\/91', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/u6m.cpp'])",
            "num_files":1.0
        },
        {
            "index":2338,
            "vuln_id":"GHSA-m3f9-w3p3-p669",
            "cwe_id":"{'CWE-787', 'CWE-131'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/efea03b38fb8d3b81762237dc85e579cc5fc6e87'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `QuantizedMul` ### Impact\nAn attacker can cause a heap buffer overflow in `QuantizedMul` by passing in invalid thresholds for the quantization:\n\n```python\nimport tensorflow as tf\n\nx = tf.constant([256, 328], shape=[1, 2], dtype=tf.quint8)\ny = tf.constant([256, 328], shape=[1, 2], dtype=tf.quint8)\nmin_x = tf.constant([], dtype=tf.float32)\nmax_x = tf.constant([], dtype=tf.float32)\nmin_y = tf.constant([], dtype=tf.float32)\nmax_y = tf.constant([], dtype=tf.float32)\n\ntf.raw_ops.QuantizedMul(x=x, y=y, min_x=min_x, max_x=max_x, min_y=min_y, max_y=max_y)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/87cf4d3ea9949051e50ca3f071fc909538a51cd0\/tensorflow\/core\/kernels\/quantized_mul_op.cc#L287-L290) assumes that the 4 arguments are always valid scalars and tries to access the numeric value directly:\n\n```cc \nconst float min_x = context->input(2).flat<float>()(0);\nconst float max_x = context->input(3).flat<float>()(0);\nconst float min_y = context->input(4).flat<float>()(0);\nconst float max_y = context->input(5).flat<float>()(0);\n```\n\nHowever, if any of these tensors is empty, then `.flat<T>()` is an empty buffer and accessing the element at position 0 results in overflow.\n\n### Patches\nWe have patched the issue in GitHub commit [efea03b38fb8d3b81762237dc85e579cc5fc6e87](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/efea03b38fb8d3b81762237dc85e579cc5fc6e87).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/efea03b38fb8d3b81762237dc85e579cc5fc6e87",
            "commit_sha":"efea03b38fb8d3b81762237dc85e579cc5fc6e87",
            "patch":"SINGLE",
            "chain_ord":"['efea03b38fb8d3b81762237dc85e579cc5fc6e87']",
            "before_first_fix_commit":"{'87cf4d3ea9949051e50ca3f071fc909538a51cd0'}",
            "last_fix_commit":"efea03b38fb8d3b81762237dc85e579cc5fc6e87",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/21\/2021, 23:15:46",
            "message":"Validate inputs to `QuantizedMul`\n\nPiperOrigin-RevId: 369756982\nChange-Id: I00d960cc3b9316fd7a86bd37a44e341c96e17624",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 4, 'total': 20}",
            "files":"{'tensorflow\/core\/kernels\/quantized_mul_op.cc': {'additions': 16, 'deletions': 4, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/efea03b38fb8d3b81762237dc85e579cc5fc6e87\/tensorflow%2Fcore%2Fkernels%2Fquantized_mul_op.cc', 'patch': '@@ -284,10 +284,22 @@ class QuantizedMulOp : public OpKernel {\\n   void Compute(OpKernelContext* context) override {\\n     const Tensor& x = context->input(0);\\n     const Tensor& y = context->input(1);\\n-    const float min_x = context->input(2).flat<float>()(0);\\n-    const float max_x = context->input(3).flat<float>()(0);\\n-    const float min_y = context->input(4).flat<float>()(0);\\n-    const float max_y = context->input(5).flat<float>()(0);\\n+    auto& min_x_tensor = context->input(2);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\\n+                errors::InvalidArgument(\"min_x must be a scalar\"));\\n+    const float min_x = min_x_tensor.flat<float>()(0);\\n+    auto& max_x_tensor = context->input(3);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\\n+                errors::InvalidArgument(\"max_x must be a scalar\"));\\n+    const float max_x = max_x_tensor.flat<float>()(0);\\n+    auto& min_y_tensor = context->input(4);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\\n+                errors::InvalidArgument(\"min_y must be a scalar\"));\\n+    const float min_y = min_y_tensor.flat<float>()(0);\\n+    auto& max_y_tensor = context->input(5);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\\n+                errors::InvalidArgument(\"max_y must be a scalar\"));\\n+    const float max_y = max_y_tensor.flat<float>()(0);\\n \\n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\\n     if (!bcast.IsValid()) {'}}",
            "message_norm":"validate inputs to `quantizedmul`\n\npiperorigin-revid: 369756982\nchange-id: i00d960cc3b9316fd7a86bd37a44e341c96e17624",
            "language":"it",
            "entities":"[('validate', 'ACTION', ''), ('369756982', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_mul_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3274,
            "vuln_id":"GHSA-wg8p-w946-c482",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/56e450c3adf75c707500d7231a78c9fc894c7f13'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in ShowDoc ShowDoc prior to 2.10.4 is vulnerable to stored cross-site scripting via file upload.",
            "published_date":"2022-03-16",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/56e450c3adf75c707500d7231a78c9fc894c7f13",
            "commit_sha":"56e450c3adf75c707500d7231a78c9fc894c7f13",
            "patch":"SINGLE",
            "chain_ord":"['56e450c3adf75c707500d7231a78c9fc894c7f13']",
            "before_first_fix_commit":"{'237ac6d43bf3728bf3587c486a23b4a48ea7acb3'}",
            "last_fix_commit":"56e450c3adf75c707500d7231a78c9fc894c7f13",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/14\/2022, 12:15:13",
            "message":"file upload bug",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'server\/Application\/Api\/Model\/AttachmentModel.class.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/56e450c3adf75c707500d7231a78c9fc894c7f13\/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -329,7 +329,7 @@ public function isAllowedFilename($filename){\\n \\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso','.bz2','.epub',\\n \\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n \\t\\t\\t'.doc','.docx','.odt','.rtf','.docm','.dotm','.dot','.dotx','.wps','.wpt',\\n-\\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.md','.psd','.csv',\\n+\\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\\n \\t\\t\\t'.cer','.ppt','.pub','.properties','.json','.css',\\n \\t\\t\\t) ;\"}}",
            "message_norm":"file upload bug",
            "language":"ro",
            "entities":"[('bug', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Model\/AttachmentModel.class.php'])",
            "num_files":1.0
        },
        {
            "index":1567,
            "vuln_id":"GHSA-cm5x-837x-jf3c",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e86605c0a336c088b638da02135ea6f9f6753618'}",
            "dataset":"osv",
            "summary":"Division by 0 in inplace operations ### Impact\nAn attacker can cause a floating point exception by calling inplace operations with crafted arguments that would result in a division by 0:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.InplaceSub(x=[],i=[-99,-1,-1],v=[1,1,1])\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/inplace_ops.cc#L283) has a logic error: it should skip processing if `x` and `v` are empty but the code uses `||` instead of `&&`.\n\n### Patches\nWe have patched the issue in GitHub commit [e86605c0a336c088b638da02135ea6f9f6753618](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e86605c0a336c088b638da02135ea6f9f6753618).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e86605c0a336c088b638da02135ea6f9f6753618",
            "commit_sha":"e86605c0a336c088b638da02135ea6f9f6753618",
            "patch":"SINGLE",
            "chain_ord":"['e86605c0a336c088b638da02135ea6f9f6753618']",
            "before_first_fix_commit":"{'29e3d6b706a33780b1cb4863200ec7525ff035ce'}",
            "last_fix_commit":"e86605c0a336c088b638da02135ea6f9f6753618",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2021, 21:21:27",
            "message":"Fix FPE in inpace update ops.\n\nPiperOrigin-RevId: 388303197\nChange-Id: Ib48309b6213ffe53eba81004b00e889d653e4b83",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/inplace_ops.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e86605c0a336c088b638da02135ea6f9f6753618\/tensorflow%2Fcore%2Fkernels%2Finplace_ops.cc', 'patch': '@@ -225,7 +225,7 @@ class InplaceOpBase : public OpKernel {\\n \\n     Tensor y = x;  \/\/ This creates an alias intentionally.\\n     \/\/ Skip processing if tensors are empty.\\n-    if (x.NumElements() > 0 || v.NumElements() > 0) {\\n+    if (x.NumElements() > 0 && v.NumElements() > 0) {\\n       OP_REQUIRES_OK(ctx, DoCompute(ctx, i, v, &y));\\n     }\\n     ctx->set_output(0, y);'}}",
            "message_norm":"fix fpe in inpace update ops.\n\npiperorigin-revid: 388303197\nchange-id: ib48309b6213ffe53eba81004b00e889d653e4b83",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('388303197', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/inplace_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":9,
            "vuln_id":"GHSA-23cm-x6j7-6hq3",
            "cwe_id":"{'CWE-200'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/matrix-org\/matrix-js-sdk\/commit\/894c24880da0e1cc81818f51c0db80e3c9fb2be9'}",
            "dataset":"osv",
            "summary":"matrix-js-sdk can be tricked into disclosing E2EE room keys to a participating homeserver ### Impact\n\nA logic error in the room key sharing functionality of matrix-js-sdk before 12.4.1 allows a malicious Matrix homeserver\u2020 participating in an encrypted room to steal room encryption keys from affected Matrix clients participating in that room. This allows the homeserver to decrypt end-to-end encrypted messages sent by affected clients.\n\n\u2020 Or anyone with access to the account of the original recipient of an encrypted message.\n\nKnown clients affected (via their use of vulnerable versions of matrix-js-sdk):\n\n- Element Web (1.8.2 and earlier)\n- Element Desktop (1.8.2 and earlier)\n- SchildiChat Web (1.7.32-sc1 and earlier)\n- SchildiChat Desktop (1.7.32-sc1 and earlier)\n- Cinny (1.2.0 and earlier)\n\n### Patch\n\nThis was fixed in https:\/\/github.com\/matrix-org\/matrix-js-sdk\/commit\/894c24880da0e1cc81818f51c0db80e3c9fb2be9.\n\n### Workarounds\nTo prevent a homeserver from being able to steal the room keys, vulnerable clients can be taken offline or signed out. If signing out, care should be taken to either set up Secure Backup or export E2E room keys in order to preserve access to past messages.",
            "published_date":"2021-09-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/matrix-org\/matrix-js-sdk",
            "commit_href":"https:\/\/github.com\/matrix-org\/matrix-js-sdk\/commit\/894c24880da0e1cc81818f51c0db80e3c9fb2be9",
            "commit_sha":"894c24880da0e1cc81818f51c0db80e3c9fb2be9",
            "patch":"SINGLE",
            "chain_ord":"['894c24880da0e1cc81818f51c0db80e3c9fb2be9']",
            "before_first_fix_commit":"{'f8186add92dd5f0ca2f6a1cda10bc0ece3730f86'}",
            "last_fix_commit":"894c24880da0e1cc81818f51c0db80e3c9fb2be9",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/13\/2021, 11:34:48",
            "message":"Verify target device key on reshare",
            "author":"RiotRobot",
            "comments":null,
            "stats":"{'additions': 29, 'deletions': 9, 'total': 38}",
            "files":"{'src\/crypto\/algorithms\/megolm.ts': {'additions': 29, 'deletions': 9, 'changes': 38, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/matrix-org\/matrix-js-sdk\/raw\/894c24880da0e1cc81818f51c0db80e3c9fb2be9\/src%2Fcrypto%2Falgorithms%2Fmegolm.ts', 'patch': '@@ -101,6 +101,13 @@ interface IPayload extends Partial<IMessage> {\\n }\\n \/* eslint-enable camelcase *\/\\n \\n+interface SharedWithData {\\n+    \/\/ The identity key of the device we shared with\\n+    deviceKey: string;\\n+    \/\/ The message index of the ratchet we shared with that device\\n+    messageIndex: number;\\n+}\\n+\\n \/**\\n  * @private\\n  * @constructor\\n@@ -115,12 +122,12 @@ interface IPayload extends Partial<IMessage> {\\n  *\\n  * @property {object} sharedWithDevices\\n  *    devices with which we have shared the session key\\n- *        userId -> {deviceId -> msgindex}\\n+ *        userId -> {deviceId -> SharedWithData}\\n  *\/\\n class OutboundSessionInfo {\\n     public useCount = 0;\\n     public creationTime: number;\\n-    public sharedWithDevices: Record<string, Record<string, number>> = {};\\n+    public sharedWithDevices: Record<string, Record<string, SharedWithData>> = {};\\n     public blockedDevicesNotified: Record<string, Record<string, boolean>> = {};\\n \\n     constructor(public readonly sessionId: string, public readonly sharedHistory = false) {\\n@@ -150,11 +157,11 @@ class OutboundSessionInfo {\\n         return false;\\n     }\\n \\n-    public markSharedWithDevice(userId: string, deviceId: string, chainIndex: number): void {\\n+    public markSharedWithDevice(userId: string, deviceId: string, deviceKey: string, chainIndex: number): void {\\n         if (!this.sharedWithDevices[userId]) {\\n             this.sharedWithDevices[userId] = {};\\n         }\\n-        this.sharedWithDevices[userId][deviceId] = chainIndex;\\n+        this.sharedWithDevices[userId][deviceId] = { deviceKey, messageIndex: chainIndex };\\n     }\\n \\n     public markNotifiedBlockedDevice(userId: string, deviceId: string): void {\\n@@ -572,6 +579,7 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n         payload: IPayload,\\n     ): Promise<void> {\\n         const contentMap = {};\\n+        const deviceInfoByDeviceId = new Map<string, DeviceInfo>();\\n \\n         const promises = [];\\n         for (let i = 0; i < userDeviceMap.length; i++) {\\n@@ -584,6 +592,7 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n             const userId = val.userId;\\n             const deviceInfo = val.deviceInfo;\\n             const deviceId = deviceInfo.deviceId;\\n+            deviceInfoByDeviceId.set(deviceId, deviceInfo);\\n \\n             if (!contentMap[userId]) {\\n                 contentMap[userId] = {};\\n@@ -636,7 +645,10 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n                 for (const userId of Object.keys(contentMap)) {\\n                     for (const deviceId of Object.keys(contentMap[userId])) {\\n                         session.markSharedWithDevice(\\n-                            userId, deviceId, chainIndex,\\n+                            userId,\\n+                            deviceId,\\n+                            deviceInfoByDeviceId.get(deviceId).getIdentityKey(),\\n+                            chainIndex,\\n                         );\\n                     }\\n                 }\\n@@ -719,19 +731,27 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n             logger.debug(`megolm session ${sessionId} never shared with user ${userId}`);\\n             return;\\n         }\\n-        const sentChainIndex = obSessionInfo.sharedWithDevices[userId][device.deviceId];\\n-        if (sentChainIndex === undefined) {\\n+        const sessionSharedData = obSessionInfo.sharedWithDevices[userId][device.deviceId];\\n+        if (sessionSharedData === undefined) {\\n             logger.debug(\\n                 \"megolm session ID \" + sessionId + \" never shared with device \" +\\n                 userId + \":\" + device.deviceId,\\n             );\\n             return;\\n         }\\n \\n+        if (sessionSharedData.deviceKey !== device.getIdentityKey()) {\\n+            logger.warn(\\n+                `Session has been shared with device ${device.deviceId} but with identity ` +\\n+                `key ${sessionSharedData.deviceKey}. Key is now ${device.getIdentityKey()}!`,\\n+            );\\n+            return;\\n+        }\\n+\\n         \/\/ get the key from the inbound session: the outbound one will already\\n         \/\/ have been ratcheted to the next chain index.\\n         const key = await this.olmDevice.getInboundGroupSessionKey(\\n-            this.roomId, senderKey, sessionId, sentChainIndex,\\n+            this.roomId, senderKey, sessionId, sessionSharedData.messageIndex,\\n         );\\n \\n         if (!key) {\\n@@ -882,7 +902,7 @@ class MegolmEncryption extends EncryptionAlgorithm {\\n             const deviceId = deviceInfo.deviceId;\\n \\n             session.markSharedWithDevice(\\n-                userId, deviceId, key.chain_index,\\n+                userId, deviceId, deviceInfo.getIdentityKey(), key.chain_index,\\n             );\\n         }'}}",
            "message_norm":"verify target device key on reshare",
            "language":"en",
            "entities":"[('verify', 'ACTION', ''), ('key', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/crypto\/algorithms\/megolm.ts'])",
            "num_files":1.0
        },
        {
            "index":1298,
            "vuln_id":"GHSA-92vm-wfm5-mxvv",
            "cwe_id":"{'CWE-362'}",
            "score":4.4,
            "chain":"{'https:\/\/github.com\/tj\/node-cookie-signature\/commit\/39791081692e9e14aa62855369e1c7f80fbfd50e', 'https:\/\/github.com\/tj\/node-cookie-signature\/commit\/2c4df6b6cee540f30876198cd0b5bebf28528c07', 'https:\/\/github.com\/tj\/node-cookie-signature\/commit\/4cc5e21e7f59a4ea0b51cd5e9634772d48fab590'}",
            "dataset":"osv",
            "summary":"cookie-signature Timing Attack Affected versions of `cookie-signature` are vulnerable to timing attacks as a result of using a fail-early comparison instead of a constant-time comparison. \n\nTiming attacks remove the exponential increase in entropy gained from increased secret length, by providing per-character feedback on the correctness of a guess via miniscule timing differences.\n\nUnder favorable network conditions, an attacker can exploit this to guess the secret in no more than `charset*length` guesses, instead of `charset^length` guesses required were the timing attack not present. \n\n\n\n## Recommendation\n\nUpdate to 1.0.4 or later.",
            "published_date":"2020-01-06",
            "chain_len":3,
            "project":"https:\/\/github.com\/tj\/node-cookie-signature",
            "commit_href":"https:\/\/github.com\/tj\/node-cookie-signature\/commit\/4cc5e21e7f59a4ea0b51cd5e9634772d48fab590",
            "commit_sha":"4cc5e21e7f59a4ea0b51cd5e9634772d48fab590",
            "patch":"MULTI",
            "chain_ord":"['4cc5e21e7f59a4ea0b51cd5e9634772d48fab590', '39791081692e9e14aa62855369e1c7f80fbfd50e', '2c4df6b6cee540f30876198cd0b5bebf28528c07']",
            "before_first_fix_commit":"{'39791081692e9e14aa62855369e1c7f80fbfd50e'}",
            "last_fix_commit":"2c4df6b6cee540f30876198cd0b5bebf28528c07",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/25\/2014, 22:09:31",
            "message":"Merge pull request #17 from tenbits\/patch-1\n\nFix #15: use sha1 hashes for double signing",
            "author":"Nathan Vander Wilt",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 1, 'total': 10}",
            "files":"{'index.js': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tj\/node-cookie-signature\/raw\/4cc5e21e7f59a4ea0b51cd5e9634772d48fab590\/index.js', 'patch': \"@@ -39,5 +39,13 @@ exports.unsign = function(val, secret){\\n   var str = val.slice(0, val.lastIndexOf('.'))\\n     , mac = exports.sign(str, secret);\\n   \\n-  return exports.sign(mac, secret) == exports.sign(val, secret) ? str : false;\\n+  return sha1(mac) == sha1(val) ? str : false;\\n };\\n+\\n+\/**\\n+ * Private\\n+ *\/\\n+\\n+function sha1(str){\\n+  return crypto.createHash('sha1').update(str).digest('hex');\\n+}\"}}",
            "message_norm":"merge pull request #17 from tenbits\/patch-1\n\nfix #15: use sha1 hashes for double signing",
            "language":"en",
            "entities":"[('#17', 'ISSUE', ''), ('fix', 'ACTION', ''), ('#15', 'ISSUE', ''), ('signing', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['index.js'])",
            "num_files":1.0
        },
        {
            "index":3151,
            "vuln_id":"GHSA-vp56-6g26-6827",
            "cwe_id":"{'CWE-400'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/node-fetch\/node-fetch\/commit\/28802387292baee467e042e168d92597b5bbbe3d'}",
            "dataset":"osv",
            "summary":"node-fetch Inefficient Regular Expression Complexity  [node-fetch](https:\/\/www.npmjs.com\/package\/node-fetch) is a light-weight module that brings window.fetch to node.js.\n\nAffected versions of this package are vulnerable to Regular Expression Denial of Service (ReDoS) in the `isOriginPotentiallyTrustworthy()` function in `referrer.js`, when processing a URL string with alternating letters and periods, such as `'http:\/\/' + 'a.a.'.repeat(i) + 'a'`.",
            "published_date":"2022-08-02",
            "chain_len":1,
            "project":"https:\/\/github.com\/node-fetch\/node-fetch",
            "commit_href":"https:\/\/github.com\/node-fetch\/node-fetch\/commit\/28802387292baee467e042e168d92597b5bbbe3d",
            "commit_sha":"28802387292baee467e042e168d92597b5bbbe3d",
            "patch":"SINGLE",
            "chain_ord":"['28802387292baee467e042e168d92597b5bbbe3d']",
            "before_first_fix_commit":"{'e87b093fd678a9ea39c5b17b2a1bdfc4691eedc7'}",
            "last_fix_commit":"28802387292baee467e042e168d92597b5bbbe3d",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/31\/2022, 08:01:29",
            "message":"fix: ReDoS referrer (#1611)\n\n* fix ReDoS referrer\r\n\r\n* Update src\/utils\/referrer.js\r\n\r\nEliminate regex and use string matcher\r\n\r\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>\r\n\r\nCo-authored-by: Khang. V\u00f5 V\u0129 <khangvv@vng.com.vn>\r\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>",
            "author":"Khang Vo (doublevkay)",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/utils\/referrer.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/node-fetch\/node-fetch\/raw\/28802387292baee467e042e168d92597b5bbbe3d\/src%2Futils%2Freferrer.js', 'patch': '@@ -119,7 +119,7 @@ export function isOriginPotentiallyTrustworthy(url) {\\n \\t\/\/ 5. If origin\\'s host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\\n \\t\/\/ We are returning FALSE here because we cannot ensure conformance to\\n \\t\/\/ let-localhost-be-loalhost (https:\/\/tools.ietf.org\/html\/draft-west-let-localhost-be-localhost)\\n-\\tif (\/^(.+\\\\.)*localhost$\/.test(url.host)) {\\n+\\tif (url.host === \\'localhost\\' || url.host.endsWith(\\'.localhost\\')) {\\n \\t\\treturn false;\\n \\t}'}}",
            "message_norm":"fix: redos referrer (#1611)\n\n* fix redos referrer\r\n\r\n* update src\/utils\/referrer.js\r\n\r\neliminate regex and use string matcher\r\n\r\nco-authored-by: linus unneb\u00e4ck <linus@folkdatorn.se>\r\n\r\nco-authored-by: khang. v\u00f5 v\u0129 <khangvv@vng.com.vn>\r\nco-authored-by: linus unneb\u00e4ck <linus@folkdatorn.se>",
            "language":"en",
            "entities":"[('redos', 'SECWORD', ''), ('#1611', 'ISSUE', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('linus@folkdatorn.se', 'EMAIL', ''), ('linus@folkdatorn.se', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/utils\/referrer.js'])",
            "num_files":1.0
        },
        {
            "index":3457,
            "vuln_id":"GHSA-xm9f-vxmx-4m58",
            "cwe_id":"{'CWE-20'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/OpenMage\/magento-lts\/commit\/34709ac642d554aa1824892059186dd329db744b'}",
            "dataset":"osv",
            "summary":"Data Flow Sanitation Issue Fix  ### Impact\nDue to missing sanitation in data flow it was possible for admin users to upload arbitrary executable files to the server.",
            "published_date":"2021-08-30",
            "chain_len":1,
            "project":"https:\/\/github.com\/OpenMage\/magento-lts",
            "commit_href":"https:\/\/github.com\/OpenMage\/magento-lts\/commit\/34709ac642d554aa1824892059186dd329db744b",
            "commit_sha":"34709ac642d554aa1824892059186dd329db744b",
            "patch":"SINGLE",
            "chain_ord":"['34709ac642d554aa1824892059186dd329db744b']",
            "before_first_fix_commit":"{'b99307d00b59c4a226a1e3e4083f02cf2fc8fce7'}",
            "last_fix_commit":"34709ac642d554aa1824892059186dd329db744b",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/26\/2021, 01:13:20",
            "message":"Merge pull request from GHSA-xm9f-vxmx-4m58\n\nCo-authored-by: Mark Lewis <markwlewis@Marks-MacBook-Pro.local>",
            "author":"Mark Lewis",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'app\/code\/core\/Mage\/Dataflow\/Model\/Convert\/Adapter\/Io.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/OpenMage\/magento-lts\/raw\/34709ac642d554aa1824892059186dd329db744b\/app%2Fcode%2Fcore%2FMage%2FDataflow%2FModel%2FConvert%2FAdapter%2FIo.php', 'patch': \"@@ -49,7 +49,7 @@ public function getResource($forWrite = false)\\n             $isError = false;\\n \\n             $ioConfig = $this->getVars();\\n-            switch ($this->getVar('type', 'file')) {\\n+            switch (strtolower($this->getVar('type', 'file'))) {\\n                 case 'file':\\n                     \/\/validate export\/import path\\n                     $path = rtrim($ioConfig['path'], '\\\\\\\\\/')\"}}",
            "message_norm":"merge pull request from ghsa-xm9f-vxmx-4m58\n\nco-authored-by: mark lewis <markwlewis@marks-macbook-pro.local>",
            "language":"en",
            "entities":"[('ghsa-xm9f-vxmx-4m58', 'VULNID', 'GHSA')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/code\/core\/Mage\/Dataflow\/Model\/Convert\/Adapter\/Io.php'])",
            "num_files":1.0
        },
        {
            "index":3172,
            "vuln_id":"GHSA-vvg4-vgrv-xfr7",
            "cwe_id":"{'CWE-665'}",
            "score":6.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4504a081af71514bb1828048363e6540f797005b', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/14607c0707040d775e06b6817325640cb4b5864c'}",
            "dataset":"osv",
            "summary":"Incomplete validation in `tf.raw_ops.CTCLoss` ### Impact \nIncomplete validation in `tf.raw_ops.CTCLoss` allows an attacker to trigger an OOB read from heap:\n\n```python\nimport tensorflow as tf\n\ninputs = tf.constant([], shape=[10, 16, 0], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[8, 0], dtype=tf.int64)\nlabels_values = tf.constant([-100] * 8, shape=[8], dtype=tf.int32)\nsequence_length = tf.constant([-100] * 16, shape=[16], dtype=tf.int32)\n  \ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=True, ctc_merge_repeated=False,\n                   ignore_longer_outputs_than_inputs=True)\n```   \n      \nAn attacker can also trigger a heap buffer overflow:\n\n```python\nimport tensorflow as tf\n\ninputs = tf.constant([], shape=[7, 2, 0], dtype=tf.float32)\nlabels_indices = tf.constant([-100, -100], shape=[2, 1], dtype=tf.int64)\nlabels_values = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ignore_longer_outputs_than_inputs=False)\n```\n\nFinally, an attacker can trigger a null pointer dereference:\n\n```python \nimport tensorflow as tf\n\ninputs = tf.constant([], shape=[0, 2, 11], dtype=tf.float32)\nlabels_indices = tf.constant([], shape=[0, 2], dtype=tf.int64)\nlabels_values = tf.constant([], shape=[0], dtype=tf.int32)\nsequence_length = tf.constant([-100, -100], shape=[2], dtype=tf.int32)\n\ntf.raw_ops.CTCLoss(inputs=inputs, labels_indices=labels_indices,\n                   labels_values=labels_values, sequence_length=sequence_length,\n                   preprocess_collapse_repeated=False, ctc_merge_repeated=False,\n                   ignore_longer_outputs_than_inputs=False)\n```\n\n### Patches\nWe have patched the issue in GitHub commit[14607c0707040d775e06b6817325640cb4b5864c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/14607c0707040d775e06b6817325640cb4b5864c) followed by GitHub commit [4504a081af71514bb1828048363e6540f797005b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/4504a081af71514bb1828048363e6540f797005b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/14607c0707040d775e06b6817325640cb4b5864c",
            "commit_sha":"14607c0707040d775e06b6817325640cb4b5864c",
            "patch":"MULTI",
            "chain_ord":"['4504a081af71514bb1828048363e6540f797005b', '14607c0707040d775e06b6817325640cb4b5864c']",
            "before_first_fix_commit":"{'8410ce671b48e96965a1e4a97017f8a5bbd03d3a'}",
            "last_fix_commit":"14607c0707040d775e06b6817325640cb4b5864c",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/06\/2021, 04:09:21",
            "message":"Fix nullptr deref in `tf.raw_ops.CTCLoss`.\n\nPiperOrigin-RevId: 372266334\nChange-Id: Ic52c3e9f13a38f54482d670907eda1688450862b",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/ctc_loss_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/14607c0707040d775e06b6817325640cb4b5864c\/tensorflow%2Fcore%2Fkernels%2Fctc_loss_op.cc', 'patch': '@@ -109,6 +109,9 @@ class CTCLossOp : public OpKernel {\\n \\n     const TensorShape& inputs_shape = inputs->shape();\\n     const int64 max_time = inputs_shape.dim_size(0);\\n+    OP_REQUIRES(ctx, max_time != 0,\\n+                errors::InvalidArgument(\\n+                    \"Max time or first dimension of input cannot be 0.\"));\\n     const int64 batch_size = inputs_shape.dim_size(1);\\n     const int64 num_classes_raw = inputs_shape.dim_size(2);\\n     OP_REQUIRES('}}",
            "message_norm":"fix nullptr deref in `tf.raw_ops.ctcloss`.\n\npiperorigin-revid: 372266334\nchange-id: ic52c3e9f13a38f54482d670907eda1688450862b",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('372266334', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ctc_loss_op.cc'])",
            "num_files":1.0
        },
        {
            "index":2871,
            "vuln_id":"GHSA-r5jw-62xg-j433",
            "cwe_id":"{'CWE-79'}",
            "score":6.4,
            "chain":"{'https:\/\/github.com\/kaminari\/kaminari\/commit\/8dd52a1aed3d2fa2835d836de23fc0d8c4ff5db8'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting in Kaminari ### Impact\nIn Kaminari before 1.2.1, there is a vulnerability that would allow an attacker to inject arbitrary code into pages with pagination links. This has been fixed in 1.2.1.\n\n### Releases\nThe 1.2.1 gem including the patch has already been released.\nAll past released versions are affected by this vulnerability.\n\n### Workarounds\nApplication developers who can't update the gem can workaround by overriding the `PARAM_KEY_EXCEPT_LIST` constant.\n\n```ruby\nmodule Kaminari::Helpers\n  PARAM_KEY_EXCEPT_LIST = [:authenticity_token, :commit, :utf8, :_method, :script_name, :original_script_name].freeze\nend\n```\n\n### Credits\nThanks to Daniel Mircea for finding the issue and sending a patch via GitHub. Also thanks to Aditya Prakash for reporting the vulnerability.",
            "published_date":"2020-05-28",
            "chain_len":1,
            "project":"https:\/\/github.com\/kaminari\/kaminari",
            "commit_href":"https:\/\/github.com\/kaminari\/kaminari\/commit\/8dd52a1aed3d2fa2835d836de23fc0d8c4ff5db8",
            "commit_sha":"8dd52a1aed3d2fa2835d836de23fc0d8c4ff5db8",
            "patch":"SINGLE",
            "chain_ord":"['8dd52a1aed3d2fa2835d836de23fc0d8c4ff5db8']",
            "before_first_fix_commit":"{'04d86ed3f2537aff620941413e5fca254e87aebe'}",
            "last_fix_commit":"8dd52a1aed3d2fa2835d836de23fc0d8c4ff5db8",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/21\/2020, 21:02:59",
            "message":"Blacklist \"original_script_name\" get param",
            "author":"Daniel Mircea",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'kaminari-core\/lib\/kaminari\/helpers\/tags.rb': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/kaminari\/kaminari\/raw\/8dd52a1aed3d2fa2835d836de23fc0d8c4ff5db8\/kaminari-core%2Flib%2Fkaminari%2Fhelpers%2Ftags.rb', 'patch': '@@ -2,7 +2,7 @@\\n \\n module Kaminari\\n   module Helpers\\n-    PARAM_KEY_EXCEPT_LIST = [:authenticity_token, :commit, :utf8, :_method, :script_name].freeze\\n+    PARAM_KEY_EXCEPT_LIST = [:authenticity_token, :commit, :utf8, :_method, :script_name, :original_script_name].freeze\\n \\n     # A tag stands for an HTML tag inside the paginator.\\n     # Basically, a tag has its own partial template file, so every tag can be'}}",
            "message_norm":"blacklist \"original_script_name\" get param",
            "language":"ca",
            "entities":"[('blacklist', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['kaminari-core\/lib\/kaminari\/helpers\/tags.rb'])",
            "num_files":1.0
        },
        {
            "index":255,
            "vuln_id":"GHSA-3h8m-483j-7xxm",
            "cwe_id":"{'CWE-125'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e'}",
            "dataset":"osv",
            "summary":"Heap out of bounds read in `RequantizationRange` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGradWithArgmax` can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([1], shape=[1], dtype=tf.qint32) \ninput_max = tf.constant([], dtype=tf.float32)\ninput_min = tf.constant([], dtype=tf.float32)\n\ntf.raw_ops.RequantizationRange(input=input, input_min=input_min, input_max=input_max)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ac328eaa3870491ababc147822cd04e91a790643\/tensorflow\/core\/kernels\/requantization_range_op.cc#L49-L50) assumes that the `input_min` and `input_max` tensors have at least one element, as it accesses the first element in two arrays:\n\n```cc\nconst float input_min_float = ctx->input(1).flat<float>()(0);\nconst float input_max_float = ctx->input(2).flat<float>()(0);\n```\n\nIf the tensors are empty, `.flat<T>()` is an empty object, backed by an empty array. Hence, accesing even the 0th element is a read outside the bounds.\n\n### Patches\nWe have patched the issue in GitHub commit [ef0c008ee84bad91ec6725ddc42091e19a30cf0e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e",
            "commit_sha":"ef0c008ee84bad91ec6725ddc42091e19a30cf0e",
            "patch":"SINGLE",
            "chain_ord":"['ef0c008ee84bad91ec6725ddc42091e19a30cf0e']",
            "before_first_fix_commit":"{'ac328eaa3870491ababc147822cd04e91a790643'}",
            "last_fix_commit":"ef0c008ee84bad91ec6725ddc42091e19a30cf0e",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 15:16:13",
            "message":"Fix out of bound read in requantization_range_op.cc\n\nPiperOrigin-RevId: 372129031\nChange-Id: Ie684ab98a3840c5186ead3eafffc0e0ed0e8030d",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/requantization_range_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e\/tensorflow%2Fcore%2Fkernels%2Frequantization_range_op.cc', 'patch': '@@ -46,6 +46,10 @@ class RequantizationRangeOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& input = ctx->input(0);\\n+    OP_REQUIRES(ctx, ctx->input(1).NumElements() > 0,\\n+                errors::InvalidArgument(\"Input min must not be empty.\"));\\n+    OP_REQUIRES(ctx, ctx->input(2).NumElements() > 0,\\n+                errors::InvalidArgument(\"Input max must not be empty.\"));\\n     const float input_min_float = ctx->input(1).flat<float>()(0);\\n     const float input_max_float = ctx->input(2).flat<float>()(0);\\n     Tensor* output_min = nullptr;'}}",
            "message_norm":"fix out of bound read in requantization_range_op.cc\n\npiperorigin-revid: 372129031\nchange-id: ie684ab98a3840c5186ead3eafffc0e0ed0e8030d",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('out of bound read', 'SECWORD', ''), ('372129031', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/requantization_range_op.cc'])",
            "num_files":1.0
        },
        {
            "index":518,
            "vuln_id":"GHSA-4wpp-w5r4-7v5v",
            "cwe_id":"{'CWE-918'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/charmbracelet\/charm\/commit\/3c90668f955c7ce5ef721e4fc9faee7053232fd3'}",
            "dataset":"osv",
            "summary":"Server-Side Request Forgery in charm We've discovered a vulnerability in which attackers could forge HTTP requests to manipulate the `charm` data directory to access or delete anything on the server. This has been patched in https:\/\/github.com\/charmbracelet\/charm\/commit\/3c90668f955c7ce5ef721e4fc9faee7053232fd3 and is available in release [v0.12.1](https:\/\/github.com\/charmbracelet\/charm\/releases\/tag\/v0.12.1). We recommend that all users running self-hosted `charm` instances update immediately.\n\nThis vulnerability was found in-house and we haven't been notified of any potential exploiters.\n\n### Additional notes\n\n* Encrypted user data uploaded to the Charm server is safe as Charm servers cannot decrypt user data. This includes filenames, paths, and all key-value data.\n* Users running the official Charm [Docker images](https:\/\/github.com\/charmbracelet\/charm\/blob\/main\/docker.md) are at minimal risk because the exploit is limited to the containerized filesystem.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open a [discussion](https:\/\/github.com\/charmbracelet\/charm\/discussions)\n* Email us at [vt100@charm.sh](mailto:vt100@charm.sh)\n* Chat with us on [Slack](https:\/\/charm.sh\/slack)\n\n* * *\n\n<a href=\"https:\/\/charm.sh\/\"><img alt=\"the Charm logo\" src=\"https:\/\/stuff.charm.sh\/charm-badge.jpg\" width=\"400\"><\/a>\n\nCharm\u70ed\u7231\u5f00\u6e90 \u2022 Charm loves open source",
            "published_date":"2022-05-24",
            "chain_len":1,
            "project":"https:\/\/github.com\/charmbracelet\/charm",
            "commit_href":"https:\/\/github.com\/charmbracelet\/charm\/commit\/3c90668f955c7ce5ef721e4fc9faee7053232fd3",
            "commit_sha":"3c90668f955c7ce5ef721e4fc9faee7053232fd3",
            "patch":"SINGLE",
            "chain_ord":"['3c90668f955c7ce5ef721e4fc9faee7053232fd3']",
            "before_first_fix_commit":"{'9c620ae07e7f7d7f3c0f6e52166b8b5f899d55d1'}",
            "last_fix_commit":"3c90668f955c7ce5ef721e4fc9faee7053232fd3",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2022, 01:23:14",
            "message":"fix: clean path before accessing file store",
            "author":"Christian Muehlhaeuser",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 3, 'total': 7}",
            "files":"{'server\/http.go': {'additions': 4, 'deletions': 3, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/charmbracelet\/charm\/raw\/3c90668f955c7ce5ef721e4fc9faee7053232fd3\/server%2Fhttp.go', 'patch': '@@ -10,6 +10,7 @@ import (\\n \\t\"io\/ioutil\"\\n \\t\"log\"\\n \\t\"net\/http\"\\n+\\t\"path\/filepath\"\\n \\t\"strconv\"\\n \\t\"strings\"\\n \\n@@ -279,7 +280,7 @@ func (s *HTTPServer) handlePostSeq(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handlePostFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\tms := r.URL.Query().Get(\"mode\")\\n \\tm, err := strconv.ParseUint(ms, 10, 32)\\n \\tif err != nil {\\n@@ -316,7 +317,7 @@ func (s *HTTPServer) handlePostFile(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handleGetFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\tf, err := s.cfg.FileStore.Get(u.CharmID, path)\\n \\tif errors.Is(err, fs.ErrNotExist) {\\n \\t\\ts.renderCustomError(w, \"file not found\", http.StatusNotFound)\\n@@ -353,7 +354,7 @@ func (s *HTTPServer) handleGetFile(w http.ResponseWriter, r *http.Request) {\\n \\n func (s *HTTPServer) handleDeleteFile(w http.ResponseWriter, r *http.Request) {\\n \\tu := s.charmUserFromRequest(w, r)\\n-\\tpath := pattern.Path(r.Context())\\n+\\tpath := filepath.Clean(pattern.Path(r.Context()))\\n \\terr := s.cfg.FileStore.Delete(u.CharmID, path)\\n \\tif err != nil {\\n \\t\\tlog.Printf(\"cannot delete file: %s\", err)'}}",
            "message_norm":"fix: clean path before accessing file store",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/http.go'])",
            "num_files":1.0
        },
        {
            "index":35,
            "vuln_id":"GHSA-25xj-89g5-fm6h",
            "cwe_id":"{'CWE-532', 'CWE-200'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/hashicorp\/vault\/commit\/87f47c216cf1a28f4054b80cff40de8c9e00e36c', 'https:\/\/github.com\/hashicorp\/vault\/commit\/e52f34772affb69f3239b2cdf6523cb7cfd67a92'}",
            "dataset":"osv",
            "summary":"Information Disclosure in HashiCorp Vault HashiCorp Vault and Vault Enterprise before 1.3.6, and 1.4.2 before 1.4.2, insert Sensitive Information into a Log File.",
            "published_date":"2021-05-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/hashicorp\/vault",
            "commit_href":"https:\/\/github.com\/hashicorp\/vault\/commit\/87f47c216cf1a28f4054b80cff40de8c9e00e36c",
            "commit_sha":"87f47c216cf1a28f4054b80cff40de8c9e00e36c",
            "patch":"MULTI",
            "chain_ord":"['e52f34772affb69f3239b2cdf6523cb7cfd67a92', '87f47c216cf1a28f4054b80cff40de8c9e00e36c']",
            "before_first_fix_commit":"{'01a682aa48ede581e12813314e64a75e314e500e'}",
            "last_fix_commit":"87f47c216cf1a28f4054b80cff40de8c9e00e36c",
            "chain_ord_pos":2.0,
            "commit_datetime":"05\/21\/2020, 21:21:48",
            "message":"changelog++\n\nUpdated with CVE numbers for 1.4.2 and 1.3.6.",
            "author":"Meggie",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 2, 'total': 5}",
            "files":"{'CHANGELOG.md': {'additions': 3, 'deletions': 2, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hashicorp\/vault\/raw\/87f47c216cf1a28f4054b80cff40de8c9e00e36c\/CHANGELOG.md', 'patch': '@@ -29,7 +29,8 @@ BUG FIXES:\\n ## 1.4.2 (May 21st, 2020)\\n \\n SECURITY:\\n-* core: proxy environment variables are now redacted before being logged, in case the URLs include a username:password [[GH-9022](https:\/\/github.com\/hashicorp\/vault\/pull\/9022)]\\n+* core: proxy environment variables are now redacted before being logged, in case the URLs include a username:password. This vulnerability, CVE-2020-13223, is fixed in 1.3.6 and 1.4.2, but affects 1.4 and 1.4.2, as well as older versions of Vault [[GH-9022](https:\/\/github.com\/hashicorp\/vault\/pull\/9022)]\\n+* secrets\/gcp: Fix a regression in 1.4.0 where the system TTLs were being used instead of the configured backend TTLs for dynamic service accounts. This vulnerability is CVE-2020-12757. [[GH-85](https:\/\/github.com\/hashicorp\/vault-plugin-secrets-gcp\/pull\/85)]\\n \\n IMPROVEMENTS:\\n \\n@@ -216,7 +217,7 @@ BUG FIXES:\\n ## 1.3.6 (May 21st, 2020)\\n \\n SECURITY:\\n-* core: proxy environment variables are now redacted before being logged, in case the URLs include a username:password [[GH-9022](https:\/\/github.com\/hashicorp\/vault\/pull\/9022)]\\n+* core: proxy environment variables are now redacted before being logged, in case the URLs include a username:password. This vulnerability, CVE-2020-13223, is fixed in 1.3.6 and 1.4.2, but affects 1.4 and 1.4.2, as well as older versions of Vault [[GH-9022](https:\/\/github.com\/hashicorp\/vault\/pull\/9022)]\\n \\n BUG FIXES:'}}",
            "message_norm":"changelog++\n\nupdated with cve numbers for 1.4.2 and 1.3.6.",
            "language":"en",
            "entities":"[('updated', 'ACTION', ''), ('cve', 'SECWORD', ''), ('1.4.2', 'VERSION', ''), ('1.3.6', 'VERSION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['CHANGELOG.md'])",
            "num_files":1.0
        },
        {
            "index":3328,
            "vuln_id":"GHSA-ww4x-rwq6-qpgf",
            "cwe_id":"{'CWE-352'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/rubysec\/ruby-advisory-db\/commit\/aef9f623c0be838234d53baf18977564804da397'}",
            "dataset":"osv",
            "summary":"Cross-site Request Forgery in OmniAuth The request phase of the OmniAuth Ruby gem (1.9.1 and earlier) is vulnerable to Cross-Site Request Forgery when used as part of the Ruby on Rails framework, allowing accounts to be connected without user intent, user interaction, or feedback to the user. This permits a secondary account to be able to sign into the web application as the primary account.\n\nAs of v2 OmniAuth no longer has the vulnerable configuration by default, but it is still possible to configure OmniAuth in such a way that the web application becomes vulnerable to Cross-Site Request Forgery. There is a recommended remediation described [here](https:\/\/github.com\/omniauth\/omniauth\/wiki\/Resolving-CVE-2015-9284).",
            "published_date":"2019-05-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/rubysec\/ruby-advisory-db",
            "commit_href":"https:\/\/github.com\/rubysec\/ruby-advisory-db\/commit\/aef9f623c0be838234d53baf18977564804da397",
            "commit_sha":"aef9f623c0be838234d53baf18977564804da397",
            "patch":"SINGLE",
            "chain_ord":"['aef9f623c0be838234d53baf18977564804da397']",
            "before_first_fix_commit":"{'f05618a2eac8817b13e31f15940fe32c5d4ff6b6'}",
            "last_fix_commit":"aef9f623c0be838234d53baf18977564804da397",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/11\/2021, 22:02:34",
            "message":"Add v2.0.0 as a patched version for CVE-2015-9284\n\nhttps:\/\/github.com\/omniauth\/omniauth\/releases\/tag\/v2.0.0",
            "author":"Reed Loden",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'gems\/omniauth\/CVE-2015-9284.yml': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/rubysec\/ruby-advisory-db\/raw\/aef9f623c0be838234d53baf18977564804da397\/gems%2Fomniauth%2FCVE-2015-9284.yml', 'patch': '@@ -20,6 +20,9 @@ description: |\\n cvss_v2: 6.8\\n cvss_v3: 8.8\\n \\n+patched_versions:\\n+  - \">= 2.0.0\"\\n+\\n related:\\n   url:\\n     - https:\/\/github.com\/omniauth\/omniauth\/pull\/809'}}",
            "message_norm":"add v2.0.0 as a patched version for cve-2015-9284\n\nhttps:\/\/github.com\/omniauth\/omniauth\/releases\/tag\/v2.0.0",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('v2.0.0', 'VERSION', ''), ('patched', 'ACTION', ''), ('cve-2015-9284', 'VULNID', 'CVE'), ('https:\/\/github.com\/omniauth\/omniauth\/releases\/tag\/v2.0.0', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['gems\/omniauth\/CVE-2015-9284.yml'])",
            "num_files":1.0
        },
        {
            "index":3339,
            "vuln_id":"GHSA-wxj7-97fp-j53j",
            "cwe_id":"{'CWE-29', 'CWE-668'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/Mostafa-Samir\/zip-local\/commit\/949446a95a660c0752b1db0c654f0fd619ae6085'}",
            "dataset":"osv",
            "summary":"Exposure of Resource to Wrong Sphere in Zip-Local The package zip-local before 0.3.5 are vulnerable to Arbitrary File Write via Archive Extraction (Zip Slip) which can lead to an extraction of a crafted file outside the intended extraction directory.",
            "published_date":"2022-02-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/Mostafa-Samir\/zip-local",
            "commit_href":"https:\/\/github.com\/Mostafa-Samir\/zip-local\/commit\/949446a95a660c0752b1db0c654f0fd619ae6085",
            "commit_sha":"949446a95a660c0752b1db0c654f0fd619ae6085",
            "patch":"SINGLE",
            "chain_ord":"['949446a95a660c0752b1db0c654f0fd619ae6085']",
            "before_first_fix_commit":"{'6bb9b59733df379ac168aa705790bd8339b4bf9b'}",
            "last_fix_commit":"949446a95a660c0752b1db0c654f0fd619ae6085",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/30\/2021, 16:05:29",
            "message":"add test for sync unzipping a zip-slip attack file",
            "author":"Mostafa Samir",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
            "files":"{'tests\/unzip.sync.test.js': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Mostafa-Samir\/zip-local\/raw\/949446a95a660c0752b1db0c654f0fd619ae6085\/tests%2Funzip.sync.test.js', 'patch': '@@ -27,6 +27,13 @@ describe(\"Unzipping synchronously\", function () {\\n         zipper.sync.unzip(\".\/tests\/assets\/hello.zip\").save(\".\/tests\/assets\/hello-sync-unzip\/\");\\n     });\\n \\n+    it(\"should raise an error when an entry is outside extraction path\", function () {\\n+        fs.mkdirSync(\".\/tests\/assets\/zip-slip-sync\");\\n+        expect(\\n+            zipper.sync.unzip(\".\/tests\/assets\/zip-slip.zip\").save(\".\/tests\/assets\/zip-slip-sync\")\\n+        ).to.throw(\"Entry is outside the extraction path\")\\n+    });\\n+\\n     it(\"checks if unzipped files on disk contain correct data\", function (done) {\\n \\n         fs.readFile(\".\/tests\/assets\/hello-sync-unzip\/hello\/says-hello\", \\'utf8\\', function (err, data) {'}}",
            "message_norm":"add test for sync unzipping a zip-slip attack file",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('attack', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tests\/unzip.sync.test.js'])",
            "num_files":1.0
        },
        {
            "index":390,
            "vuln_id":"GHSA-49j7-qghp-5wj8",
            "cwe_id":"{'CWE-94'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/fusesource\/hawtjni\/commit\/92c266170ce98edc200c656bd034a237098b8aa5'}",
            "dataset":"osv",
            "summary":"Improper Control of Generation of Code in HawtJNI Race condition in hawtjni-runtime\/src\/main\/java\/org\/fusesource\/hawtjni\/runtime\/Library.java in HawtJNI before 1.8, when a custom library path is not specified, allows local users to execute arbitrary Java code by overwriting a temporary JAR file with a predictable name in \/tmp.",
            "published_date":"2022-05-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/fusesource\/hawtjni",
            "commit_href":"https:\/\/github.com\/fusesource\/hawtjni\/commit\/92c266170ce98edc200c656bd034a237098b8aa5",
            "commit_sha":"92c266170ce98edc200c656bd034a237098b8aa5",
            "patch":"SINGLE",
            "chain_ord":"['92c266170ce98edc200c656bd034a237098b8aa5']",
            "before_first_fix_commit":"{'357bb279b0c8c67b7d357c1363efe86870ad9a81'}",
            "last_fix_commit":"92c266170ce98edc200c656bd034a237098b8aa5",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/06\/2013, 13:49:55",
            "message":"Simplify shared lib extraction.",
            "author":"Hiram Chirino",
            "comments":null,
            "stats":"{'additions': 29, 'deletions': 50, 'total': 79}",
            "files":"{'hawtjni-runtime\/src\/main\/java\/org\/fusesource\/hawtjni\/runtime\/Library.java': {'additions': 29, 'deletions': 50, 'changes': 79, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/fusesource\/hawtjni\/raw\/92c266170ce98edc200c656bd034a237098b8aa5\/hawtjni-runtime%2Fsrc%2Fmain%2Fjava%2Forg%2Ffusesource%2Fhawtjni%2Fruntime%2FLibrary.java', 'patch': '@@ -9,13 +9,11 @@\\n  *******************************************************************************\/\\n package org.fusesource.hawtjni.runtime;\\n \\n-import java.io.File;\\n-import java.io.FileOutputStream;\\n-import java.io.IOException;\\n-import java.io.InputStream;\\n+import java.io.*;\\n import java.net.MalformedURLException;\\n import java.net.URL;\\n import java.util.ArrayList;\\n+import java.util.Random;\\n import java.util.regex.Pattern;\\n \\n \/**\\n@@ -206,16 +204,19 @@ final public String getLibraryFileName() {\\n     private boolean exractAndLoad(ArrayList<String> errors, String version, String customPath, String resourcePath) {\\n         URL resource = classLoader.getResource(resourcePath);\\n         if( resource !=null ) {\\n-            \\n+\\n             String libName = name + \"-\" + getBitModel();\\n             if( version !=null) {\\n                 libName += \"-\" + version;\\n             }\\n-            \\n+            String []libNameParts = map(libName).split(\"\\\\\\\\.\");\\n+            String prefix = libNameParts[0]+\"-\";\\n+            String suffix = \".\"+libNameParts[1];\\n+\\n             if( customPath!=null ) {\\n                 \/\/ Try to extract it to the custom path...\\n-                File target = file(customPath, map(libName));\\n-                if( extract(errors, resource, target) ) {\\n+                File target = extract(errors, resource, prefix, suffix, file(customPath));\\n+                if( target!=null ) {\\n                     if( load(errors, target) ) {\\n                         return true;\\n                     }\\n@@ -224,8 +225,8 @@ private boolean exractAndLoad(ArrayList<String> errors, String version, String c\\n             \\n             \/\/ Fall back to extracting to the tmp dir\\n             customPath = System.getProperty(\"java.io.tmpdir\");\\n-            File target = file(customPath, map(libName));\\n-            if( extract(errors, resource, target) ) {\\n+            File target = extract(errors, resource, prefix, suffix, file(customPath));\\n+            if( target!=null ) {\\n                 if( load(errors, target) ) {\\n                     return true;\\n                 }\\n@@ -259,67 +260,45 @@ private String map(String libName) {\\n         return libName;\\n     }\\n \\n-    private boolean extract(ArrayList<String> errors, URL source, File target) {\\n-        FileOutputStream os = null;\\n-        InputStream is = null;\\n-        boolean extracting = false;\\n+    private File extract(ArrayList<String> errors, URL source, String prefix, String suffix, File directory) {\\n+        File target = null;\\n         try {\\n-            if (!target.exists() || isStale(source, target) ) {\\n+            FileOutputStream os = null;\\n+            InputStream is = null;\\n+            try {\\n+                target = File.createTempFile(prefix, suffix, directory);\\n                 is = source.openStream();\\n                 if (is != null) {\\n                     byte[] buffer = new byte[4096];\\n                     os = new FileOutputStream(target);\\n-                    extracting = true;\\n                     int read;\\n                     while ((read = is.read(buffer)) != -1) {\\n                         os.write(buffer, 0, read);\\n                     }\\n-                    os.close();\\n-                    is.close();\\n                     chmod(\"755\", target);\\n                 }\\n+                target.deleteOnExit();\\n+                return target;\\n+            } finally {\\n+                close(os);\\n+                close(is);\\n             }\\n         } catch (Throwable e) {\\n-            try {\\n-                if (os != null)\\n-                    os.close();\\n-            } catch (IOException e1) {\\n-            }\\n-            try {\\n-                if (is != null)\\n-                    is.close();\\n-            } catch (IOException e1) {\\n-            }\\n-            if (extracting && target.exists())\\n+            if( target!=null ) {\\n                 target.delete();\\n+            }\\n             errors.add(e.getMessage());\\n-            return false;\\n         }\\n-        return true;\\n+        return null;\\n     }\\n \\n-    private boolean isStale(URL source, File target) {\\n-        \\n-        if( source.getProtocol().equals(\"jar\") ) {\\n-            \/\/ unwrap the jar protocol...\\n+    static private void close(Closeable file) {\\n+        if(file!=null) {\\n             try {\\n-                String parts[] = source.getFile().split(Pattern.quote(\"!\"));\\n-                source = new URL(parts[0]);\\n-            } catch (MalformedURLException e) {\\n-                return false;\\n-            }\\n-        }\\n-        \\n-        File sourceFile=null;\\n-        if( source.getProtocol().equals(\"file\") ) {\\n-            sourceFile = new File(source.getFile());\\n-        }\\n-        if( sourceFile!=null && sourceFile.exists() ) {\\n-            if( sourceFile.lastModified() > target.lastModified() ) {\\n-                return true;\\n+                file.close();\\n+            } catch (Exception ignore) {\\n             }\\n         }\\n-        return false;\\n     }\\n \\n     private void chmod(String permision, File path) {'}}",
            "message_norm":"simplify shared lib extraction.",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['hawtjni-runtime\/src\/main\/java\/org\/fusesource\/hawtjni\/runtime\/Library.java'])",
            "num_files":1.0
        },
        {
            "index":2096,
            "vuln_id":"GHSA-hmg3-c7xj-6qwm",
            "cwe_id":"{'CWE-131'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e922ccdf6bf46a3a52641f99fd47d54c1decd13'}",
            "dataset":"osv",
            "summary":"Heap buffer overflow in `SparseTensorToCSRSparseMatrix` ### Impact\nAn attacker can trigger a denial of service via a `CHECK`-fail in converting sparse tensors to CSR Sparse matrices:\n\n```python\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\n\nindices_array = np.array([[0, 0]])\nvalue_array = np.array([0.0], dtype=np.float32)\ndense_shape = [0, 0]\n\nst = tf.SparseTensor(indices_array, value_array, dense_shape)\n\nvalues_tensor = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n       st.indices, st.values, st.dense_shape)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/800346f2c03a27e182dd4fba48295f65e7790739\/tensorflow\/core\/kernels\/sparse\/kernels.cc#L66) does a double redirection to access an element of an array allocated on the heap:\n\n```cc\ncsr_row_ptr(indices(i, 0) + 1) += 1;\n```\n                      \nIf the value at `indices(i, 0)` is such that `indices(i, 0) + 1` is outside the bounds of `csr_row_ptr`, this results in writing outside of bounds of heap allocated data.\n\n### Patches\nWe have patched the issue in GitHub commit [1e922ccdf6bf46a3a52641f99fd47d54c1decd13](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e922ccdf6bf46a3a52641f99fd47d54c1decd13).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1e922ccdf6bf46a3a52641f99fd47d54c1decd13",
            "commit_sha":"1e922ccdf6bf46a3a52641f99fd47d54c1decd13",
            "patch":"SINGLE",
            "chain_ord":"['1e922ccdf6bf46a3a52641f99fd47d54c1decd13']",
            "before_first_fix_commit":"{'800346f2c03a27e182dd4fba48295f65e7790739'}",
            "last_fix_commit":"1e922ccdf6bf46a3a52641f99fd47d54c1decd13",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/23\/2021, 17:41:12",
            "message":"Fix crash in `SparseTensorToCSRSparseMatrixCPUFunctor`\n\nPiperOrigin-RevId: 370110290\nChange-Id: I4451e92661a55c2180f80d38b67a9b50bf5edec5",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/sparse\/kernels.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1e922ccdf6bf46a3a52641f99fd47d54c1decd13\/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fkernels.cc', 'patch': '@@ -22,6 +22,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/tensor_types.h\"\\n #include \"tensorflow\/core\/lib\/core\/errors.h\"\\n #include \"tensorflow\/core\/lib\/core\/status.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n \\n namespace tensorflow {\\n namespace functor {\\n@@ -63,6 +64,11 @@ Status SparseTensorToCSRSparseMatrixCPUFunctor::operator()(\\n \\n     for (int64 i = 0; i < total_nnz; ++i) {\\n       \/\/ For now, the rows pointers store the corresponding row counts.\\n+      int64 ix = indices(i, 0) + 1;\\n+      if (ix >= csr_row_ptr.size()) {\\n+        return errors::InvalidArgument(\"Got an index \", ix,\\n+                                       \" that is outside of csr_row_ptr\");\\n+      }\\n       csr_row_ptr(indices(i, 0) + 1) += 1;\\n       csr_col_ind(i) = indices(i, 1);\\n     }'}}",
            "message_norm":"fix crash in `sparsetensortocsrsparsematrixcpufunctor`\n\npiperorigin-revid: 370110290\nchange-id: i4451e92661a55c2180f80d38b67a9b50bf5edec5",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('370110290', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse\/kernels.cc'])",
            "num_files":1.0
        },
        {
            "index":2440,
            "vuln_id":"GHSA-mmhj-4w6j-76h7",
            "cwe_id":"{'CWE-913'}",
            "score":8.0,
            "chain":"{'https:\/\/github.com\/laverdet\/isolated-vm\/commit\/2646e6c1558bac66285daeab54c7d490ed332b15', 'https:\/\/github.com\/laverdet\/isolated-vm\/commit\/27151bfecc260e96714443613880e3b2e6596704'}",
            "dataset":"osv",
            "summary":"Misuse of `Reference` and other transferable APIs may lead to access to nodejs isolate Versions of `isolated-vm` before v4.0.0, and especially before v3.0.0, have API pitfalls which may make it easy for implementers to expose supposed secure isolates to the permissions of the main nodejs isolate.\n\n`Reference` objects allow access to the underlying reference's full prototype chain. In an environment where the implementer has exposed a `Reference` instance to an attacker they would be able to use it to acquire a `Reference` to the nodejs context's `Function` object.\n\nSimilar application-specific attacks could be possible by modifying the local prototype of other API objects.\n\nAccess to `NativeModule` objects could allow an attacker to load and run native code from anywhere on the filesystem. If combined with, for example, a file upload API this would allow for arbitrary code execution.\n\nTo address these issues the following changes were made in v4.0.0:\n- Documentation was updated with more explicit guidelines on building secure applications.\n- `Reference` instances will no longer follow prototype chains by default, nor will they invoke accessors or proxies.\n- All `isolated-vm` API prototypes are now immutable.\n- `NativeModule` constructor may only be invoked from a nodejs isolate.",
            "published_date":"2021-04-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/laverdet\/isolated-vm",
            "commit_href":"https:\/\/github.com\/laverdet\/isolated-vm\/commit\/27151bfecc260e96714443613880e3b2e6596704",
            "commit_sha":"27151bfecc260e96714443613880e3b2e6596704",
            "patch":"MULTI",
            "chain_ord":"['27151bfecc260e96714443613880e3b2e6596704', '2646e6c1558bac66285daeab54c7d490ed332b15']",
            "before_first_fix_commit":"{'3a2408a2b42ac51c64a6c10f9388a6f7cc311156'}",
            "last_fix_commit":"2646e6c1558bac66285daeab54c7d490ed332b15",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/18\/2021, 20:20:24",
            "message":"Disallow NativeModule creation unless main isolate",
            "author":"Marcel Laverdet",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'src\/module\/native_module_handle.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/laverdet\/isolated-vm\/raw\/27151bfecc260e96714443613880e3b2e6596704\/src%2Fmodule%2Fnative_module_handle.cc', 'patch': '@@ -15,6 +15,9 @@ namespace ivm {\\n  * RAII wrapper around libuv dlopen\\n  *\/\\n NativeModule::NativeModule(const std::string& filename) : init(nullptr) {\\n+\\tif (!IsolateEnvironment::GetCurrent()->IsDefault()) {\\n+\\t\\tthrow RuntimeGenericError(\"NativeModule may only be instantiated from default nodejs isolate\");\\n+\\t}\\n \\tif (uv_dlopen(filename.c_str(), &lib) != 0) {\\n \\t\\tthrow RuntimeGenericError(\"Failed to load module\");\\n \\t}'}}",
            "message_norm":"disallow nativemodule creation unless main isolate",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/module\/native_module_handle.cc'])",
            "num_files":1.0
        },
        {
            "index":180,
            "vuln_id":"GHSA-32wx-4gxx-h48f",
            "cwe_id":"{'CWE-639'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/flarum\/tags\/commit\/c8fcd000857493f1e4cc00b6f2771ce388b93e9d'}",
            "dataset":"osv",
            "summary":"Users can edit the tags of any discussion This advisory concerns a vulnerability which was patched and publicly released on October 5, 2020.\n\n### Impact\nThis vulnerability allowed any registered user to edit the tags of any discussion for which they have READ access using the REST API.\n\nUsers were able to remove any existing tag, and add any tag in which they are allowed to create discussions. The chosen tags still had to match the configured Tags minimums and maximums.\n\nBy moving the discussion to new tags, users were able to go around permissions applied to restricted tags. Depending on the setup, this can include publicly exposing content that was only visible to certain groups, or gain the ability to interact with content where such interaction was limited.\n\nThe full impact varies depending on the configuration of permissions and restricted tags, and which community extensions are being used. All tag-scoped permissions offered by extensions are impacted by this ability to go around them.\n\nForums that don't use restricted tags and don't use any extension that relies on tags for access control should not see any security impact. An update is still required to stop users from being able to change any discussion's tags.\n\nForums that don't use the Tags extension are unaffected.\n\n### Patches\nThe fix will be available in version v0.1.0-beta.14 with Flarum beta 14. The fix has already been back-ported to Flarum beta 13 as version v0.1.0-beta.13.2 of the Tags extension.\n\n### Workarounds\nVersion v0.1.0-beta.13.2 of the Tags extension allows existing Flarum beta 13 forums to fix the issue without the need to update to beta 14.\n\nForums that have not yet updated to Flarum beta 13 are encouraged to update as soon as possible.\n\n### References\n\n- [Release announcement](https:\/\/discuss.flarum.org\/d\/25059-security-update-to-flarum-tags-010-beta132)\n- [GitHub issue](https:\/\/github.com\/flarum\/core\/issues\/2355)\n\n### For more information\nIf you have any questions or comments about this advisory, please start a new discussion on our [support forum](https:\/\/discuss.flarum.org\/t\/support).\n\nIf you discover a security vulnerability within Flarum, please send an e-mail to [security@flarum.org](mailto:security@flarum.org). All security vulnerabilities will be promptly addressed. More details can be found in our [security policy](https:\/\/github.com\/flarum\/core\/security\/policy).",
            "published_date":"2021-01-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/flarum\/tags",
            "commit_href":"https:\/\/github.com\/flarum\/tags\/commit\/c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
            "commit_sha":"c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
            "patch":"SINGLE",
            "chain_ord":"['c8fcd000857493f1e4cc00b6f2771ce388b93e9d']",
            "before_first_fix_commit":"{'c207faa17ffc496d5ce0161923f19556a0ac4c5b'}",
            "last_fix_commit":"c8fcd000857493f1e4cc00b6f2771ce388b93e9d",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/03\/2020, 22:37:56",
            "message":"Fix Editing Discussion Tags Permission (#95)",
            "author":"Sami Mazouz",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'src\/Listener\/SaveTagsToDatabase.php': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/flarum\/tags\/raw\/c8fcd000857493f1e4cc00b6f2771ce388b93e9d\/src%2FListener%2FSaveTagsToDatabase.php', 'patch': \"@@ -59,6 +59,10 @@ public function handle(Saving $event)\\n \\n         \/\/ TODO: clean up, prevent discussion from being created without tags\\n         if (isset($event->data['relationships']['tags']['data'])) {\\n+            if ($discussion->exists) {\\n+                $actor->assertCan('tag', $discussion);\\n+            }\\n+\\n             $linkage = (array) $event->data['relationships']['tags']['data'];\\n \\n             $newTagIds = [];\"}}",
            "message_norm":"fix editing discussion tags permission (#95)",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('permission', 'SECWORD', ''), ('#95', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/Listener\/SaveTagsToDatabase.php'])",
            "num_files":1.0
        },
        {
            "index":2760,
            "vuln_id":"GHSA-qhmp-h54x-38qr",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/caronc\/apprise\/commit\/e20fce630d55e4ca9b0a1e325a5fea6997489831'}",
            "dataset":"osv",
            "summary":"CWE-730 Regex injection with IFTTT Plugin ### Impact\r\nAnyone _publicly_ hosting the Apprise library and granting them access to the IFTTT notification service.\r\n\r\n### Patches\r\nUpdate to Apprise v0.9.5.1\r\n   ```bash\r\n   # Install Apprise v0.9.5.1 from PyPI\r\n   pip install apprise==0.9.5.1\r\n   ```\r\n\r\nThe patch to the problem was performed [here](https:\/\/github.com\/caronc\/apprise\/pull\/436\/files).\r\n\r\n### Workarounds\r\nAlternatively, if upgrading is not an option, you can safely remove the following file:\r\n- `apprise\/plugins\/NotifyIFTTT.py` \r\n\r\nThe above will eliminate the ability to use IFTTT, but everything else will work smoothly.\r\n\r\n### For more information\r\nIf you have any questions or comments about this advisory:\r\n* Open an issue in [Apprise](https:\/\/github.com\/caronc\/apprise\/issues)\r\n* Email me at [lead2gold@gmail.com](mailto:lead2gold@gmail.com)\r\n\r\n### Additional Credit\r\nGithub would not allow me to additionally credit **Rasmus Petersen**, but I would like to put that here at the very least - thank you for finding and reporting this issue along with those already credited\r\n\r\n## Additional Notes:\r\n- Github would not allow me to add\/tag the 2 CWE's this issue is applicable to (only CWE-400).  The other is: CWE-730 (placed in the title)",
            "published_date":"2021-09-20",
            "chain_len":1,
            "project":"https:\/\/github.com\/caronc\/apprise",
            "commit_href":"https:\/\/github.com\/caronc\/apprise\/commit\/e20fce630d55e4ca9b0a1e325a5fea6997489831",
            "commit_sha":"e20fce630d55e4ca9b0a1e325a5fea6997489831",
            "patch":"SINGLE",
            "chain_ord":"['e20fce630d55e4ca9b0a1e325a5fea6997489831']",
            "before_first_fix_commit":"{'81d1ea72bcee4441278a809a95fc0f91dc916402'}",
            "last_fix_commit":"e20fce630d55e4ca9b0a1e325a5fea6997489831",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/06\/2021, 17:51:32",
            "message":"Slight bulletproofing to IFTTT regex handling (#436)",
            "author":"Chris Caron",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'apprise\/plugins\/NotifyIFTTT.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/caronc\/apprise\/raw\/e20fce630d55e4ca9b0a1e325a5fea6997489831\/apprise%2Fplugins%2FNotifyIFTTT.py', 'patch': \"@@ -355,7 +355,7 @@ def parse_native_url(url):\\n         result = re.match(\\n             r'^https?:\/\/maker\\\\.ifttt\\\\.com\/use\/'\\n             r'(?P<webhook_id>[A-Z0-9_-]+)'\\n-            r'\/?(?P<events>([A-Z0-9_-]+\/?)+)?'\\n+            r'((?P<events>(\/[A-Z0-9_-]+)+))?'\\n             r'\/?(?P<params>\\\\?.+)?$', url, re.I)\\n \\n         if result:\"}}",
            "message_norm":"slight bulletproofing to ifttt regex handling (#436)",
            "language":"no",
            "entities":"[('#436', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['apprise\/plugins\/NotifyIFTTT.py'])",
            "num_files":1.0
        },
        {
            "index":1073,
            "vuln_id":"GHSA-7r8m-45gc-m2c8",
            "cwe_id":"{'CWE-311'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/Janpot\/mongodb-instance\/commit\/c8fea750f8020ace8410c442b2684b33a9fddd3b'}",
            "dataset":"osv",
            "summary":"Downloads Resources over HTTP in mongodb-instance Affected versions of `mongodb-instance` insecurely download an executable over an unencrypted HTTP connection. \n\nIn scenarios where an attacker has a privileged network position, it is possible to intercept the response and replace the executable with a malicious one, resulting in code execution on the system running `mongodb-instance`.\n\n\n## Recommendation\n\nUpdate to version 0.0.3 or later.",
            "published_date":"2019-02-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/Janpot\/mongodb-instance",
            "commit_href":"https:\/\/github.com\/Janpot\/mongodb-instance\/commit\/c8fea750f8020ace8410c442b2684b33a9fddd3b",
            "commit_sha":"c8fea750f8020ace8410c442b2684b33a9fddd3b",
            "patch":"SINGLE",
            "chain_ord":"['c8fea750f8020ace8410c442b2684b33a9fddd3b']",
            "before_first_fix_commit":"{'02ce5a3c48d7ac1f6c33819b0c79afecbacace70'}",
            "last_fix_commit":"c8fea750f8020ace8410c442b2684b33a9fddd3b",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/02\/2016, 14:19:21",
            "message":"use https",
            "author":"Jan Potoms",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'install.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Janpot\/mongodb-instance\/raw\/c8fea750f8020ace8410c442b2684b33a9fddd3b\/install.js', 'patch': \"@@ -37,7 +37,7 @@ if (process.platform === 'linux' && process.arch === 'x64') {\\n \\n \\n var downloadUrl = util.format(\\n-  'http:\/\/downloads.mongodb.org\/osx\/mongodb-%s-%s.%s',\\n+  'https:\/\/fastdl.mongodb.org\/osx\/mongodb-%s-%s.%s',\\n   platformPart,\\n   versionPart,\\n   extension\"}}",
            "message_norm":"use https",
            "language":"et",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['install.js'])",
            "num_files":1.0
        },
        {
            "index":1486,
            "vuln_id":"GHSA-c558-5gfm-p2r8",
            "cwe_id":"{'CWE-79'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7', 'https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a'}",
            "dataset":"osv",
            "summary":"JSPUI spellcheck and autocomplete tools vulnerable to Cross Site Scripting ### Impact\nThe JSPUI spellcheck \"Did you mean\" HTML escapes the data-spell attribute in the link, but not the actual displayed text.  Similarly, the JSPUI autocomplete HTML does not properly escape text passed to it. Both are vulnerable to XSS.  This vulnerability only impacts the JSPUI.\n\n_This vulnerability does NOT impact the XMLUI or 7.x._\n\n### Patches\n_DSpace 6.x:_\n* Fixed in 6.4 via two commits: \n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7\n* 6.x patch files available (may be applied manually if an immediate upgrade to 6.4 or above is not possible)\n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/ebb83a75234d3de9be129464013e998dc929b68d.patch\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7.patch\n\n_DSpace 5.x:_\n* Fixed in 5.11 via two commits: \n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5\n* 5.x patch files available (may be applied manually if an immediate upgrade to 5.11 or 6.4 is not possible)\n    * Fix for spellcheck: https:\/\/github.com\/DSpace\/DSpace\/commit\/c89e493e517b424dea6175caba54e91d3847fc3a.patch\n    * Fix for autocomplete: https:\/\/github.com\/DSpace\/DSpace\/commit\/6f75bb084ab1937d094208c55cd84340040bcbb5.patch\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs \/ configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### References\nDiscovered & reported by Hassan Bhuiyan (Brunel University London)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
            "published_date":"2022-08-06",
            "chain_len":4,
            "project":"https:\/\/github.com\/DSpace\/DSpace",
            "commit_href":"https:\/\/github.com\/DSpace\/DSpace\/commit\/35030a23e48b5946f5853332c797e1c4adea7bb7",
            "commit_sha":"35030a23e48b5946f5853332c797e1c4adea7bb7",
            "patch":"MULTI",
            "chain_ord":"['ebb83a75234d3de9be129464013e998dc929b68d', '35030a23e48b5946f5853332c797e1c4adea7bb7', 'c89e493e517b424dea6175caba54e91d3847fc3a', '6f75bb084ab1937d094208c55cd84340040bcbb5']",
            "before_first_fix_commit":"{'d1dd7d23329ef055069759df15cfa200c8e32e54'}",
            "last_fix_commit":"6f75bb084ab1937d094208c55cd84340040bcbb5",
            "chain_ord_pos":2.0,
            "commit_datetime":"04\/08\/2020, 01:19:14",
            "message":"[DS-4453] Fix XSS handling in JSPUI discovery autocomplete",
            "author":"Kim Shepherd",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 1, 'total': 7}",
            "files":"{'dspace-jspui\/src\/main\/webapp\/search\/discovery.jsp': {'additions': 6, 'deletions': 1, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/DSpace\/DSpace\/raw\/35030a23e48b5946f5853332c797e1c4adea7bb7\/dspace-jspui%2Fsrc%2Fmain%2Fwebapp%2Fsearch%2Fdiscovery.jsp', 'patch': '@@ -147,7 +147,7 @@\\n \\t\\t\\t\\t\\t\\t\\t\\t\\ttmp_val = item.displayedValue;\\n \\t\\t\\t\\t\\t\\t\\t\\t}\\n \\t\\t\\t\\t\\t\\t\\t\\treturn {\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\tlabel: item.displayedValue + \" (\" + item.count + \")\",\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\tlabel: escapeHtml(item.displayedValue) + \" (\" + item.count + \")\",\\n \\t\\t\\t\\t\\t\\t\\t\\t\\tvalue: tmp_val\\n \\t\\t\\t\\t\\t\\t\\t\\t};\\n \\t\\t\\t\\t\\t\\t\\t}))\\t\\t\\t\\n@@ -159,6 +159,11 @@\\n \\tfunction validateFilters() {\\n \\t\\treturn document.getElementById(\"filterquery\").value.length > 0;\\n \\t}\\n+\\t\/\/ Generic HTML escape utility\\n+\\tvar escapeHtml = s => (s + \\'\\').replace(\/[&<>\"\\']\/g, m => ({\\n+\\t\\t\\'&\\': \\'&amp;\\', \\'<\\': \\'&lt;\\', \\'>\\': \\'&gt;\\',\\n+\\t\\t\\'\"\\': \\'&quot;\\', \"\\'\": \\'&#39;\\'\\n+\\t})[m]);\\n <\/script>\\t\\t\\n <\/c:set>'}}",
            "message_norm":"[ds-4453] fix xss handling in jspui discovery autocomplete",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['dspace-jspui\/src\/main\/webapp\/search\/discovery.jsp'])",
            "num_files":1.0
        },
        {
            "index":36,
            "vuln_id":"GHSA-25xj-89g5-fm6h",
            "cwe_id":"{'CWE-532', 'CWE-200'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/hashicorp\/vault\/commit\/87f47c216cf1a28f4054b80cff40de8c9e00e36c', 'https:\/\/github.com\/hashicorp\/vault\/commit\/e52f34772affb69f3239b2cdf6523cb7cfd67a92'}",
            "dataset":"osv",
            "summary":"Information Disclosure in HashiCorp Vault HashiCorp Vault and Vault Enterprise before 1.3.6, and 1.4.2 before 1.4.2, insert Sensitive Information into a Log File.",
            "published_date":"2021-05-18",
            "chain_len":2,
            "project":"https:\/\/github.com\/hashicorp\/vault",
            "commit_href":"https:\/\/github.com\/hashicorp\/vault\/commit\/e52f34772affb69f3239b2cdf6523cb7cfd67a92",
            "commit_sha":"e52f34772affb69f3239b2cdf6523cb7cfd67a92",
            "patch":"MULTI",
            "chain_ord":"['e52f34772affb69f3239b2cdf6523cb7cfd67a92', '87f47c216cf1a28f4054b80cff40de8c9e00e36c']",
            "before_first_fix_commit":"{'01a682aa48ede581e12813314e64a75e314e500e'}",
            "last_fix_commit":"87f47c216cf1a28f4054b80cff40de8c9e00e36c",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/19\/2020, 14:07:46",
            "message":"Don't include username or password of proxy env vars when logging them. (#9022)",
            "author":"ncabatoff",
            "comments":null,
            "stats":"{'additions': 27, 'deletions': 7, 'total': 34}",
            "files":"{'command\/server.go': {'additions': 27, 'deletions': 7, 'changes': 34, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hashicorp\/vault\/raw\/e52f34772affb69f3239b2cdf6523cb7cfd67a92\/command%2Fserver.go', 'patch': '@@ -445,9 +445,7 @@ func (c *ServerCommand) runRecoveryMode() int {\\n \\t\\tvault.DefaultMaxRequestDuration = config.DefaultMaxRequestDuration\\n \\t}\\n \\n-\\tproxyCfg := httpproxy.FromEnvironment()\\n-\\tc.logger.Info(\"proxy environment\", \"http_proxy\", proxyCfg.HTTPProxy,\\n-\\t\\t\"https_proxy\", proxyCfg.HTTPSProxy, \"no_proxy\", proxyCfg.NoProxy)\\n+\\tlogProxyEnvironmentVariables(c.logger)\\n \\n \\t\/\/ Initialize the storage backend\\n \\tfactory, exists := c.PhysicalBackends[config.Storage.Type]\\n@@ -684,6 +682,31 @@ func (c *ServerCommand) runRecoveryMode() int {\\n \\treturn 0\\n }\\n \\n+func logProxyEnvironmentVariables(logger hclog.Logger) {\\n+\\tproxyCfg := httpproxy.FromEnvironment()\\n+\\tcfgMap := map[string]string{\\n+\\t\\t\"http_proxy\":  proxyCfg.HTTPProxy,\\n+\\t\\t\"https_proxy\": proxyCfg.HTTPSProxy,\\n+\\t\\t\"no_proxy\":    proxyCfg.NoProxy,\\n+\\t}\\n+\\tfor k, v := range cfgMap {\\n+\\t\\tu, err := url.Parse(v)\\n+\\t\\tif err != nil {\\n+\\t\\t\\t\/\/ Env vars may contain URLs or host:port values.  We only care\\n+\\t\\t\\t\/\/ about the former.\\n+\\t\\t\\tcontinue\\n+\\t\\t}\\n+\\t\\tif _, ok := u.User.Password(); ok {\\n+\\t\\t\\tu.User = url.UserPassword(\"redacted-username\", \"redacted-password\")\\n+\\t\\t} else if user := u.User.Username(); user != \"\" {\\n+\\t\\t\\tu.User = url.User(\"redacted-username\")\\n+\\t\\t}\\n+\\t\\tcfgMap[k] = u.String()\\n+\\t}\\n+\\tlogger.Info(\"proxy environment\", \"http_proxy\", cfgMap[\"http_proxy\"],\\n+\\t\\t\"https_proxy\", cfgMap[\"https_proxy\"], \"no_proxy\", cfgMap[\"no_proxy\"])\\n+}\\n+\\n func (c *ServerCommand) adjustLogLevel(config *server.Config, logLevelWasNotSet bool) (string, error) {\\n \\tvar logLevelString string\\n \\tif config.LogLevel != \"\" && logLevelWasNotSet {\\n@@ -894,10 +917,7 @@ func (c *ServerCommand) Run(args []string) int {\\n \\t\\tvault.DefaultMaxRequestDuration = config.DefaultMaxRequestDuration\\n \\t}\\n \\n-\\t\/\/ log proxy settings\\n-\\tproxyCfg := httpproxy.FromEnvironment()\\n-\\tc.logger.Info(\"proxy environment\", \"http_proxy\", proxyCfg.HTTPProxy,\\n-\\t\\t\"https_proxy\", proxyCfg.HTTPSProxy, \"no_proxy\", proxyCfg.NoProxy)\\n+\\tlogProxyEnvironmentVariables(c.logger)\\n \\n \\t\/\/ If mlockall(2) isn\\'t supported, show a warning. We disable this in dev\\n \\t\/\/ because it is quite scary to see when first using Vault. We also disable'}}",
            "message_norm":"don't include username or password of proxy env vars when logging them. (#9022)",
            "language":"en",
            "entities":"[('password', 'SECWORD', ''), ('#9022', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['command\/server.go'])",
            "num_files":1.0
        },
        {
            "index":724,
            "vuln_id":"GHSA-5xvc-vgmp-jgc3",
            "cwe_id":"{'CWE-284'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/jupyterhub\/firstuseauthenticator\/pull\/38\/commits\/9e200d974e0cb85d828a6afedb8ab90a37878f28', 'https:\/\/github.com\/jupyterhub\/firstuseauthenticator\/pull\/38\/commits\/32b21898fb2b53b1a2e36270de6854ad70e9e9bf'}",
            "dataset":"osv",
            "summary":"Improper Access Control in jupyterhub-firstuseauthenticator ### Impact\n\nWhen JupyterHub is used with FirstUseAuthenticator, the vulnerability allows unauthorized access to any user's account if `create_users=True` and the username is known or guessed.\n\n### Patches\n\nUpgrade to jupyterhub-firstuseauthenticator to 1.0, or apply patch https:\/\/github.com\/jupyterhub\/firstuseauthenticator\/pull\/38.patch\n\n### Workarounds\n\nIf you cannot upgrade, there is no complete workaround, but it can be mitigated.\n\nIf you cannot upgrade yet, you can disable user creation with `c.FirstUseAuthenticator.create_users = False`, which will only allow login with fully normalized usernames for already existing users prior to jupyterhub-firstuserauthenticator 1.0. If any users have never logged in with their normalized username (i.e. lowercase), they will still be vulnerable until you can patch or upgrade.",
            "published_date":"2021-10-28",
            "chain_len":2,
            "project":"https:\/\/github.com\/jupyterhub\/firstuseauthenticator",
            "commit_href":"https:\/\/github.com\/jupyterhub\/firstuseauthenticator\/pull\/38\/commits\/32b21898fb2b53b1a2e36270de6854ad70e9e9bf",
            "commit_sha":"32b21898fb2b53b1a2e36270de6854ad70e9e9bf",
            "patch":"MULTI",
            "chain_ord":"['32b21898fb2b53b1a2e36270de6854ad70e9e9bf', '9e200d974e0cb85d828a6afedb8ab90a37878f28']",
            "before_first_fix_commit":"{'32b21898fb2b53b1a2e36270de6854ad70e9e9bf'}",
            "last_fix_commit":"9e200d974e0cb85d828a6afedb8ab90a37878f28",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/02\/2021, 20:23:22",
            "message":"lowercase username to lock password",
            "author":"George Hunt",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'firstuseauthenticator\/firstuseauthenticator.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jupyterhub\/firstuseauthenticator\/raw\/32b21898fb2b53b1a2e36270de6854ad70e9e9bf\/firstuseauthenticator%2Ffirstuseauthenticator.py', 'patch': \"@@ -138,7 +138,7 @@ def validate_username(self, name):\\n \\n     @gen.coroutine\\n     def authenticate(self, handler, data):\\n-        username = data['username']\\n+        username = data['username'].lower()\\n \\n         if not self.create_users:\\n             if not self._user_exists(username):\"}}",
            "message_norm":"lowercase username to lock password",
            "language":"en",
            "entities":"[('password', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['firstuseauthenticator\/firstuseauthenticator.py'])",
            "num_files":1.0
        },
        {
            "index":1037,
            "vuln_id":"GHSA-7hmh-8gwv-mfvq",
            "cwe_id":"{'CWE-89'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/apache\/kylin\/commit\/e373c64c96a54a7abfe4bccb82e8feb60db04749'}",
            "dataset":"osv",
            "summary":"SQL Injection in Kylin Kylin has some restful apis which will concatenate SQLs with the user input string, a user is likely to be able to run malicious database queries.",
            "published_date":"2020-07-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/kylin",
            "commit_href":"https:\/\/github.com\/apache\/kylin\/commit\/e373c64c96a54a7abfe4bccb82e8feb60db04749",
            "commit_sha":"e373c64c96a54a7abfe4bccb82e8feb60db04749",
            "patch":"SINGLE",
            "chain_ord":"['e373c64c96a54a7abfe4bccb82e8feb60db04749']",
            "before_first_fix_commit":"{'ebfc745dd681d7e0c129ded50bd50ff509d2a393'}",
            "last_fix_commit":"e373c64c96a54a7abfe4bccb82e8feb60db04749",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/07\/2020, 12:22:59",
            "message":"Fix sql injection issue",
            "author":"nichunen",
            "comments":null,
            "stats":"{'additions': 51, 'deletions': 30, 'total': 81}",
            "files":"{'server-base\/src\/main\/java\/org\/apache\/kylin\/rest\/service\/CubeService.java': {'additions': 51, 'deletions': 30, 'changes': 81, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/kylin\/raw\/e373c64c96a54a7abfe4bccb82e8feb60db04749\/server-base%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fkylin%2Frest%2Fservice%2FCubeService.java', 'patch': '@@ -71,6 +71,7 @@\\n import org.apache.kylin.metadata.project.RealizationEntry;\\n import org.apache.kylin.metadata.realization.RealizationStatusEnum;\\n import org.apache.kylin.metadata.realization.RealizationType;\\n+import org.apache.kylin.metrics.MetricsManager;\\n import org.apache.kylin.metrics.property.QueryCubePropertyEnum;\\n import org.apache.kylin.rest.constant.Constant;\\n import org.apache.kylin.rest.exception.BadRequestException;\\n@@ -79,6 +80,7 @@\\n import org.apache.kylin.rest.msg.Message;\\n import org.apache.kylin.rest.msg.MsgPicker;\\n import org.apache.kylin.rest.request.MetricsRequest;\\n+import org.apache.kylin.rest.request.PrepareSqlRequest;\\n import org.apache.kylin.rest.response.CubeInstanceResponse;\\n import org.apache.kylin.rest.response.CuboidTreeResponse;\\n import org.apache.kylin.rest.response.CuboidTreeResponse.NodeInfo;\\n@@ -544,7 +546,8 @@ public HBaseResponse getHTableInfo(String cubeName, String tableName) throws IOE\\n \\n         hr = new HBaseResponse();\\n         CubeInstance cube = CubeManager.getInstance(getConfig()).getCube(cubeName);\\n-        if (cube.getStorageType() == IStorageAware.ID_HBASE || cube.getStorageType() == IStorageAware.ID_SHARDED_HBASE || cube.getStorageType() == IStorageAware.ID_REALTIME_AND_HBASE) {\\n+        if (cube.getStorageType() == IStorageAware.ID_HBASE || cube.getStorageType() == IStorageAware.ID_SHARDED_HBASE\\n+                || cube.getStorageType() == IStorageAware.ID_REALTIME_AND_HBASE) {\\n             try {\\n                 logger.debug(\"Loading HTable info \" + cubeName + \", \" + tableName);\\n \\n@@ -633,7 +636,8 @@ private void cleanSegmentStorage(List<CubeSegment> toRemoveSegs) throws IOExcept\\n             List<String> toDelHDFSPaths = Lists.newArrayListWithCapacity(toRemoveSegs.size());\\n             for (CubeSegment seg : toRemoveSegs) {\\n                 toDropHTables.add(seg.getStorageLocationIdentifier());\\n-                toDelHDFSPaths.add(JobBuilderSupport.getJobWorkingDir(seg.getConfig().getHdfsWorkingDirectory(), seg.getLastBuildJobID()));\\n+                toDelHDFSPaths.add(JobBuilderSupport.getJobWorkingDir(seg.getConfig().getHdfsWorkingDirectory(),\\n+                        seg.getLastBuildJobID()));\\n             }\\n \\n             StorageCleanUtil.dropHTables(new HBaseAdmin(HBaseConnection.getCurrentHBaseConfiguration()), toDropHTables);\\n@@ -763,10 +767,12 @@ public String mergeCubeSegment(String cubeName) {\\n     }\\n \\n     \/\/Don\\'t merge the job that has been discarded manually before\\n-    private boolean isMergingJobBeenDiscarded(CubeInstance cubeInstance, String cubeName, String projectName, SegmentRange offsets) {\\n+    private boolean isMergingJobBeenDiscarded(CubeInstance cubeInstance, String cubeName, String projectName,\\n+            SegmentRange offsets) {\\n         SegmentRange.TSRange tsRange = new SegmentRange.TSRange((Long) offsets.start.v, (Long) offsets.end.v);\\n         String segmentName = CubeSegment.makeSegmentName(tsRange, null, cubeInstance.getModel());\\n-        final List<CubingJob> jobInstanceList = jobService.listJobsByRealizationName(cubeName, projectName, EnumSet.of(ExecutableState.DISCARDED));\\n+        final List<CubingJob> jobInstanceList = jobService.listJobsByRealizationName(cubeName, projectName,\\n+                EnumSet.of(ExecutableState.DISCARDED));\\n         for (CubingJob cubingJob : jobInstanceList) {\\n             if (cubingJob.getSegmentName().equals(segmentName)) {\\n                 logger.debug(\"Merge job {} has been discarded before, will not merge.\", segmentName);\\n@@ -777,7 +783,6 @@ private boolean isMergingJobBeenDiscarded(CubeInstance cubeInstance, String cube\\n         return false;\\n     }\\n \\n-\\n     public void validateCubeDesc(CubeDesc desc, boolean isDraft) {\\n         Message msg = MsgPicker.getMsg();\\n \\n@@ -931,24 +936,6 @@ public void afterPropertiesSet() throws Exception {\\n         Broadcaster.getInstance(getConfig()).registerStaticListener(new HTableInfoSyncListener(), \"cube\");\\n     }\\n \\n-    private class HTableInfoSyncListener extends Broadcaster.Listener {\\n-        @Override\\n-        public void onClearAll(Broadcaster broadcaster) throws IOException {\\n-            htableInfoCache.invalidateAll();\\n-        }\\n-\\n-        @Override\\n-        public void onEntityChange(Broadcaster broadcaster, String entity, Broadcaster.Event event, String cacheKey)\\n-                throws IOException {\\n-            String cubeName = cacheKey;\\n-            String keyPrefix = cubeName + \"\/\";\\n-            for (String k : htableInfoCache.asMap().keySet()) {\\n-                if (k.startsWith(keyPrefix))\\n-                    htableInfoCache.invalidate(k);\\n-            }\\n-        }\\n-    }\\n-\\n     public CubeInstanceResponse createCubeInstanceResponse(CubeInstance cube) {\\n         return new CubeInstanceResponse(cube, projectService.getProjectOfCube(cube.getName()));\\n     }\\n@@ -995,7 +982,7 @@ private NodeInfo generateNodeInfo(long cuboidId, int dimensionCount, long cubeQu\\n         long queryExactlyMatchCount = queryMatchMap == null || queryMatchMap.get(cuboidId) == null ? 0L\\n                 : queryMatchMap.get(cuboidId);\\n         boolean ifExist = currentCuboidSet.contains(cuboidId);\\n-        long rowCount = rowCountMap == null ? 0L : rowCountMap.get(cuboidId);\\n+        long rowCount = (rowCountMap == null || rowCountMap.size() == 0) ? 0L : rowCountMap.get(cuboidId);\\n \\n         NodeInfo node = new NodeInfo();\\n         node.setId(cuboidId);\\n@@ -1044,9 +1031,10 @@ public Map<Long, Long> getCuboidHitFrequency(String cubeName, boolean isCuboidSo\\n         String table = getMetricsManager().getSystemTableFromSubject(getConfig().getKylinMetricsSubjectQueryCube());\\n         String sql = \"select \" + cuboidColumn + \", sum(\" + hitMeasure + \")\" \/\/\\n                 + \" from \" + table\/\/\\n-                + \" where \" + QueryCubePropertyEnum.CUBE.toString() + \" = \\'\" + cubeName + \"\\'\" \/\/\\n+                + \" where \" + QueryCubePropertyEnum.CUBE.toString() + \" = ?\" \/\/\\n                 + \" group by \" + cuboidColumn;\\n-        List<List<String>> orgHitFrequency = queryService.querySystemCube(sql).getResults();\\n+\\n+        List<List<String>> orgHitFrequency = getPrepareQueryResult(cubeName, sql);\\n         return formatQueryCount(orgHitFrequency);\\n     }\\n \\n@@ -1058,9 +1046,10 @@ public Map<Long, Map<Long, Pair<Long, Long>>> getCuboidRollingUpStats(String cub\\n         String table = getMetricsManager().getSystemTableFromSubject(getConfig().getKylinMetricsSubjectQueryCube());\\n         String sql = \"select \" + cuboidSource + \", \" + cuboidTgt + \", avg(\" + aggCount + \"), avg(\" + returnCount + \")\"\/\/\\n                 + \" from \" + table \/\/\\n-                + \" where \" + QueryCubePropertyEnum.CUBE.toString() + \" = \\'\" + cubeName + \"\\' \" \/\/\\n+                + \" where \" + QueryCubePropertyEnum.CUBE.toString() + \" = ?\" \/\/\\n                 + \" group by \" + cuboidSource + \", \" + cuboidTgt;\\n-        List<List<String>> orgRollingUpCount = queryService.querySystemCube(sql).getResults();\\n+\\n+        List<List<String>> orgRollingUpCount = getPrepareQueryResult(cubeName, sql);\\n         return formatRollingUpStats(orgRollingUpCount);\\n     }\\n \\n@@ -1070,13 +1059,27 @@ public Map<Long, Long> getCuboidQueryMatchCount(String cubeName) {\\n         String table = getMetricsManager().getSystemTableFromSubject(getConfig().getKylinMetricsSubjectQueryCube());\\n         String sql = \"select \" + cuboidSource + \", sum(\" + hitMeasure + \")\" \/\/\\n                 + \" from \" + table \/\/\\n-                + \" where \" + QueryCubePropertyEnum.CUBE.toString() + \" = \\'\" + cubeName + \"\\'\" \/\/\\n+                + \" where \" + QueryCubePropertyEnum.CUBE.toString() + \" = ?\" \/\/\\n                 + \" and \" + QueryCubePropertyEnum.IF_MATCH.toString() + \" = true\" \/\/\\n                 + \" group by \" + cuboidSource;\\n-        List<List<String>> orgMatchHitFrequency = queryService.querySystemCube(sql).getResults();\\n+\\n+        List<List<String>> orgMatchHitFrequency = getPrepareQueryResult(cubeName, sql);\\n         return formatQueryCount(orgMatchHitFrequency);\\n     }\\n \\n+    private List<List<String>> getPrepareQueryResult(String cubeName, String sql) {\\n+        PrepareSqlRequest sqlRequest = new PrepareSqlRequest();\\n+        sqlRequest.setProject(MetricsManager.SYSTEM_PROJECT);\\n+        PrepareSqlRequest.StateParam[] params = new PrepareSqlRequest.StateParam[1];\\n+        params[0] = new PrepareSqlRequest.StateParam();\\n+        params[0].setClassName(\"java.lang.String\");\\n+        params[0].setValue(cubeName);\\n+        sqlRequest.setParams(params);\\n+        sqlRequest.setSql(sql);\\n+\\n+        return queryService.doQueryWithCache(sqlRequest, false).getResults();\\n+    }\\n+\\n     @PreAuthorize(Constant.ACCESS_HAS_ROLE_ADMIN\\n             + \" or hasPermission(#cube, \\'ADMINISTRATION\\') or hasPermission(#cube, \\'MANAGEMENT\\')\")\\n     public void migrateCube(CubeInstance cube, String projectName) {\\n@@ -1114,4 +1117,22 @@ public void migrateCube(CubeInstance cube, String projectName) {\\n             throw new InternalErrorException(\"Failed to perform one-click migrating\", e);\\n         }\\n     }\\n+\\n+    private class HTableInfoSyncListener extends Broadcaster.Listener {\\n+        @Override\\n+        public void onClearAll(Broadcaster broadcaster) throws IOException {\\n+            htableInfoCache.invalidateAll();\\n+        }\\n+\\n+        @Override\\n+        public void onEntityChange(Broadcaster broadcaster, String entity, Broadcaster.Event event, String cacheKey)\\n+                throws IOException {\\n+            String cubeName = cacheKey;\\n+            String keyPrefix = cubeName + \"\/\";\\n+            for (String k : htableInfoCache.asMap().keySet()) {\\n+                if (k.startsWith(keyPrefix))\\n+                    htableInfoCache.invalidate(k);\\n+            }\\n+        }\\n+    }\\n }'}}",
            "message_norm":"fix sql injection issue",
            "language":"fr",
            "entities":"[('fix', 'ACTION', ''), ('sql injection', 'SECWORD', ''), ('issue', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server-base\/src\/main\/java\/org\/apache\/kylin\/rest\/service\/CubeService.java'])",
            "num_files":1.0
        },
        {
            "index":218,
            "vuln_id":"GHSA-3872-f48p-pxqj",
            "cwe_id":"{'CWE-88', 'CWE-77'}",
            "score":8.8,
            "chain":"{'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/d83672a3e7415da1490334e2c9431e5da1966842', 'https:\/\/github.com\/WeblateOrg\/weblate\/commit\/35d59f1f040541c358cece0a8d4a63183ca919b8'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Special Elements used in a Command ('Command Injection') in Weblate ### Impact\nWeblate didn't correctly sanitize some arguments passed to Git and Mercurial, which allowed changing their behavior in an unintended way.\n\n### Patches\n\nThe issues were fixed in the 4.11.1 release. The following commits are addressing it:\n\n* 35d59f1f040541c358cece0a8d4a63183ca919b8\n* d83672a3e7415da1490334e2c9431e5da1966842\n\n### Workarounds\n\nInstances in which untrusted users cannot create new components are not affected.\n\n### References\n* [SNYK-PYTHON-WEBLATE-2414088](https:\/\/security.snyk.io\/vuln\/SNYK-PYTHON-WEBLATE-2414088)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open a topic in [discussions](https:\/\/github.com\/WeblateOrg\/weblate\/discussions)\n* Email us at [care@weblate.org](mailto:care@weblate.org)",
            "published_date":"2022-03-04",
            "chain_len":2,
            "project":"https:\/\/github.com\/WeblateOrg\/weblate",
            "commit_href":"https:\/\/github.com\/WeblateOrg\/weblate\/commit\/d83672a3e7415da1490334e2c9431e5da1966842",
            "commit_sha":"d83672a3e7415da1490334e2c9431e5da1966842",
            "patch":"MULTI",
            "chain_ord":"['35d59f1f040541c358cece0a8d4a63183ca919b8', 'd83672a3e7415da1490334e2c9431e5da1966842']",
            "before_first_fix_commit":"{'9a5a09781e5a19ab9a24878afb08c9fcafb21ca7'}",
            "last_fix_commit":"d83672a3e7415da1490334e2c9431e5da1966842",
            "chain_ord_pos":2.0,
            "commit_datetime":"03\/03\/2022, 07:45:16",
            "message":"vcs: Improve git parameters handling\n\nMake sure that all user provided input is handled as expected.",
            "author":"Michal \u010ciha\u0159",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 3, 'total': 8}",
            "files":"{'weblate\/vcs\/git.py': {'additions': 5, 'deletions': 3, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/WeblateOrg\/weblate\/raw\/d83672a3e7415da1490334e2c9431e5da1966842\/weblate%2Fvcs%2Fgit.py', 'patch': '@@ -85,7 +85,7 @@ def get_remote_branch(cls, repo: str):\\n         if not repo:\\n             return super().get_remote_branch(repo)\\n         try:\\n-            result = cls._popen([\"ls-remote\", \"--symref\", repo, \"HEAD\"])\\n+            result = cls._popen([\"ls-remote\", \"--symref\", \"--\", repo, \"HEAD\"])\\n         except RepositoryException:\\n             report_error(cause=\"Listing remote branch\")\\n             return super().get_remote_branch(repo)\\n@@ -149,7 +149,9 @@ def get_depth():\\n     @classmethod\\n     def _clone(cls, source: str, target: str, branch: str):\\n         \"\"\"Clone repository.\"\"\"\\n-        cls._popen([\"clone\"] + cls.get_depth() + [\"--branch\", branch, source, target])\\n+        cls._popen(\\n+            [\"clone\"] + cls.get_depth() + [\"--branch\", branch, \"--\", source, target]\\n+        )\\n \\n     def get_config(self, path):\\n         \"\"\"Read entry from configuration.\"\"\"\\n@@ -572,7 +574,7 @@ def get_last_repo_revision(cls, url):\\n \\n     @classmethod\\n     def get_remote_args(cls, source, target):\\n-        result = [\"--prefix=origin\/\", source, target]\\n+        result = [\"--prefix=origin\/\", \"--\", source, target]\\n         if cls.is_stdlayout(source):\\n             result.insert(0, \"--stdlayout\")\\n             revision = cls.get_last_repo_revision(source + \"\/trunk\/\")'}}",
            "message_norm":"vcs: improve git parameters handling\n\nmake sure that all user provided input is handled as expected.",
            "language":"en",
            "entities":"[('improve', 'ACTION', ''), ('user provided input', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['weblate\/vcs\/git.py'])",
            "num_files":1.0
        },
        {
            "index":1754,
            "vuln_id":"GHSA-fpcp-9h7m-ffpx",
            "cwe_id":"{'CWE-476'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e21af685e1828f7ca65038307df5cc06de4479e8'}",
            "dataset":"osv",
            "summary":"Null pointer dereference in TensorFlow  ### Impact\nWhen [building an XLA compilation cache](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/274df9b02330b790aa8de1cee164b70f72b9b244\/tensorflow\/compiler\/jit\/xla_platform_info.cc#L43-L104), if default settings are used, TensorFlow triggers a null pointer dereference:\n\n```cc \n  string allowed_gpus =\n      flr->config_proto()->gpu_options().visible_device_list();\n``` \n    \nIn the default scenario, all devices are allowed, so `flr->config_proto` is `nullptr`.\n    \n### Patches\nWe have patched the issue in GitHub commit [e21af685e1828f7ca65038307df5cc06de4479e8](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e21af685e1828f7ca65038307df5cc06de4479e8).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e21af685e1828f7ca65038307df5cc06de4479e8",
            "commit_sha":"e21af685e1828f7ca65038307df5cc06de4479e8",
            "patch":"SINGLE",
            "chain_ord":"['e21af685e1828f7ca65038307df5cc06de4479e8']",
            "before_first_fix_commit":"{'30f8e5c460629a9f8dbb04dc562c7b579c07f11b'}",
            "last_fix_commit":"e21af685e1828f7ca65038307df5cc06de4479e8",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/08\/2022, 00:20:27",
            "message":"Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be",
            "author":"Smit Hinsu",
            "comments":null,
            "stats":"{'additions': 7, 'deletions': 5, 'total': 12}",
            "files":"{'tensorflow\/compiler\/jit\/xla_platform_info.cc': {'additions': 7, 'deletions': 5, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e21af685e1828f7ca65038307df5cc06de4479e8\/tensorflow%2Fcompiler%2Fjit%2Fxla_platform_info.cc', 'patch': '@@ -82,11 +82,13 @@ Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\\n   client_options.set_intra_op_parallelism_threads(\\n       device->tensorflow_cpu_worker_threads()->num_threads);\\n \\n-  string allowed_gpus =\\n-      flr->config_proto()->gpu_options().visible_device_list();\\n-  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\\n-                      ParseVisibleDeviceList(allowed_gpus));\\n-  client_options.set_allowed_devices(gpu_ids);\\n+  if (flr->config_proto()) {\\n+    string allowed_gpus =\\n+        flr->config_proto()->gpu_options().visible_device_list();\\n+    TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\\n+                        ParseVisibleDeviceList(allowed_gpus));\\n+    client_options.set_allowed_devices(gpu_ids);\\n+  }\\n \\n   auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\\n   if (!client.ok()) {'}}",
            "message_norm":"fix null-pointer dereference in buildxlacompilationcache\n\nif configproto is not used, then use the default settings which is to allow all devices.\n\npiperorigin-revid: 420391800\nchange-id: i88161ad7042990aef678e77b597a2fb2c8f815be",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('null-pointer dereference', 'SECWORD', ''), ('420391800', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/compiler\/jit\/xla_platform_info.cc'])",
            "num_files":1.0
        },
        {
            "index":441,
            "vuln_id":"GHSA-4jqc-8m5r-9rpr",
            "cwe_id":"{'CWE-1321', 'CWE-843'}",
            "score":7.3,
            "chain":"{'https:\/\/github.com\/jonschlinkert\/set-value\/commit\/7cf8073bb06bf0c15e08475f9f952823b4576452'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in set-value This affects the package `set-value` before 2.0.1, and starting with 3.0.0 but prior to 4.0.1. A type confusion vulnerability can lead to a bypass of CVE-2019-10747 when the user-provided keys used in the path parameter are arrays.",
            "published_date":"2021-09-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/jonschlinkert\/set-value",
            "commit_href":"https:\/\/github.com\/jonschlinkert\/set-value\/commit\/7cf8073bb06bf0c15e08475f9f952823b4576452",
            "commit_sha":"7cf8073bb06bf0c15e08475f9f952823b4576452",
            "patch":"SINGLE",
            "chain_ord":"['7cf8073bb06bf0c15e08475f9f952823b4576452']",
            "before_first_fix_commit":"{'17ac6b7baa01f328a41987e02c73b71b5b82bc3a'}",
            "last_fix_commit":"7cf8073bb06bf0c15e08475f9f952823b4576452",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/12\/2021, 07:36:46",
            "message":"4.0.1\n\nFixes https:\/\/github.com\/jonschlinkert\/set-value\/pull\/33 thanks to @ready-research.",
            "author":"Jon Schlinkert",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'package.json': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jonschlinkert\/set-value\/raw\/7cf8073bb06bf0c15e08475f9f952823b4576452\/package.json', 'patch': '@@ -1,6 +1,6 @@\\n {\\n   \"name\": \"set-value\",\\n-  \"version\": \"4.0.0\",\\n+  \"version\": \"4.0.1\",\\n   \"description\": \"Set nested properties on an object using dot notation.\",\\n   \"license\": \"MIT\",\\n   \"repository\": \"jonschlinkert\/set-value\",\\n@@ -122,4 +122,4 @@\\n       \"update\"\\n     ]\\n   }\\n-}\\n\\\\ No newline at end of file\\n+}'}}",
            "message_norm":"4.0.1\n\nfixes https:\/\/github.com\/jonschlinkert\/set-value\/pull\/33 thanks to @ready-research.",
            "language":"en",
            "entities":"[('4.0.1', 'VERSION', ''), ('https:\/\/github.com\/jonschlinkert\/set-value\/pull\/33', 'URL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['package.json'])",
            "num_files":1.0
        },
        {
            "index":3041,
            "vuln_id":"GHSA-v3mr-gp7j-pw5w",
            "cwe_id":"{'CWE-89'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/terminal42\/contao-tablelookupwizard\/commit\/a5e723a28f110b7df8ffc4175cef9b061d3cc717'}",
            "dataset":"osv",
            "summary":"Possible SQL injection in tablelookupwizard Contao Extension ### Impact\nThe currently selected widget values were not correctly sanitized before passing it to the database, leading to an SQL injection possibility.\n\n### Patches\nThe issue has been patched in `tablelookupwizard` version 3.3.5 and version 4.0.0.\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in https:\/\/github.com\/terminal42\/contao-tablelookupwizard\n* Email us at [info@terminal42.ch](mailto:info@terminal42.ch)",
            "published_date":"2022-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/terminal42\/contao-tablelookupwizard",
            "commit_href":"https:\/\/github.com\/terminal42\/contao-tablelookupwizard\/commit\/a5e723a28f110b7df8ffc4175cef9b061d3cc717",
            "commit_sha":"a5e723a28f110b7df8ffc4175cef9b061d3cc717",
            "patch":"SINGLE",
            "chain_ord":"['a5e723a28f110b7df8ffc4175cef9b061d3cc717']",
            "before_first_fix_commit":"{'ae6c82f10b0f1e87226079ebaa78ac630b05279a'}",
            "last_fix_commit":"a5e723a28f110b7df8ffc4175cef9b061d3cc717",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/04\/2022, 07:13:15",
            "message":"Fixed SQL query for current field value",
            "author":"Andreas Schempp",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'TableLookupWizard.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/terminal42\/contao-tablelookupwizard\/raw\/a5e723a28f110b7df8ffc4175cef9b061d3cc717\/TableLookupWizard.php', 'patch': '@@ -407,9 +407,9 @@ protected function prepareWhere()\\n \\n         \/\/ Filter those that have already been chosen\\n         if (\\'checkbox\\' === $this->fieldType && \\\\is_array($varData) && !empty($varData)) {\\n-            $this->arrWhereProcedure[] = $this->foreignTable.\\'.id NOT IN (\\'.implode(\\',\\', $varData).\\')\\';\\n+            $this->arrWhereProcedure[] = $this->foreignTable.\\'.id NOT IN (\\'.implode(\\',\\', array_map(\\'intval\\', $varData)).\\')\\';\\n         } elseif (\\'radio\\' === $this->fieldType && \\'\\' !== $varData) {\\n-            $this->arrWhereProcedure[] = \"{$this->foreignTable}.id!=\\'$varData\\'\";\\n+            $this->arrWhereProcedure[] = $this->foreignTable.\\'.id!=\\'.(int) $varData;\\n         }\\n \\n         \/\/ If custom WHERE is set, add it to the statement'}}",
            "message_norm":"fixed sql query for current field value",
            "language":"ca",
            "entities":"[('fixed', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['TableLookupWizard.php'])",
            "num_files":1.0
        },
        {
            "index":428,
            "vuln_id":"GHSA-4h47-h3cr-23wh",
            "cwe_id":"{'CWE-285'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/01157a699f611ca7492e872103ac01526a982cf2'}",
            "dataset":"osv",
            "summary":"Improper Authorization in Jenkins A denial of service vulnerability exists in Jenkins 2.145 and earlier, LTS 2.138.1 and earlier in core\/src\/main\/java\/hudson\/security\/HudsonPrivateSecurityRealm.java that allows attackers without Overall\/Read permission to access a specific URL on instances using the built-in Jenkins user database security realm that results in the creation of an ephemeral user record in memory.",
            "published_date":"2022-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/01157a699f611ca7492e872103ac01526a982cf2",
            "commit_sha":"01157a699f611ca7492e872103ac01526a982cf2",
            "patch":"SINGLE",
            "chain_ord":"['01157a699f611ca7492e872103ac01526a982cf2']",
            "before_first_fix_commit":"{'df87e12ddcfeafdba6e0de0e07b3e21f8473ece6'}",
            "last_fix_commit":"01157a699f611ca7492e872103ac01526a982cf2",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/27\/2018, 09:18:42",
            "message":"[SECURITY-1128]",
            "author":"Daniel Beck",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'core\/src\/main\/java\/hudson\/security\/HudsonPrivateSecurityRealm.java': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/01157a699f611ca7492e872103ac01526a982cf2\/core%2Fsrc%2Fmain%2Fjava%2Fhudson%2Fsecurity%2FHudsonPrivateSecurityRealm.java', 'patch': '@@ -475,8 +475,9 @@ public List<User> getAllUsers() {\\n      * This is to map users under the security realm URL.\\n      * This in turn helps us set up the right navigation breadcrumb.\\n      *\/\\n+    @Restricted(NoExternalUse.class)\\n     public User getUser(String id) {\\n-        return User.getById(id, true);\\n+        return User.getById(id, User.ALLOW_USER_CREATION_VIA_URL && hasPermission(Jenkins.ADMINISTER));\\n     }\\n \\n     \/\/ TODO'}}",
            "message_norm":"[security-1128]",
            "language":"en",
            "entities":"[('security-1128', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['core\/src\/main\/java\/hudson\/security\/HudsonPrivateSecurityRealm.java'])",
            "num_files":1.0
        },
        {
            "index":983,
            "vuln_id":"GHSA-772j-h9xw-ffp5",
            "cwe_id":"{'CWE-843'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025'}",
            "dataset":"osv",
            "summary":"CHECK-fail in SparseCross due to type confusion ### Impact\nThe API of `tf.raw_ops.SparseCross` allows combinations which would result in a `CHECK`-failure and denial of service:\n\n```python\nimport tensorflow as tf\n\nhashed_output = False\nnum_buckets = 1949315406\nhash_key = 1869835877\nout_type = tf.string \ninternal_type = tf.string\n\nindices_1 = tf.constant([0, 6], shape=[1, 2], dtype=tf.int64)\nindices_2 = tf.constant([0, 0], shape=[1, 2], dtype=tf.int64)\nindices = [indices_1, indices_2]\n\nvalues_1 = tf.constant([0], dtype=tf.int64)\nvalues_2 = tf.constant([72], dtype=tf.int64)\nvalues = [values_1, values_2]\n\nbatch_size = 4\nshape_1 = tf.constant([4, 122], dtype=tf.int64)\nshape_2 = tf.constant([4, 188], dtype=tf.int64)\nshapes = [shape_1, shape_2]\n\ndense_1 = tf.constant([188, 127, 336, 0], shape=[4, 1], dtype=tf.int64)\ndense_2 = tf.constant([341, 470, 470, 470], shape=[4, 1], dtype=tf.int64)\ndense_3 = tf.constant([188, 188, 341, 922], shape=[4, 1], dtype=tf.int64)\ndenses = [dense_1, dense_2, dense_3]\n\ntf.raw_ops.SparseCross(indices=indices, values=values, shapes=shapes, dense_inputs=denses, hashed_output=hashed_output,\n                       num_buckets=num_buckets, hash_key=hash_key, out_type=out_type, internal_type=internal_type)\n```\n\nThe above code will result in a `CHECK` fail in [`tensor.cc`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/3d782b7d47b1bf2ed32bd4a246d6d6cadc4c903d\/tensorflow\/core\/framework\/tensor.cc#L670-L675):\n\n```cc\nvoid Tensor::CheckTypeAndIsAligned(DataType expected_dtype) const {\n  CHECK_EQ(dtype(), expected_dtype)\n      << \" \" << DataTypeString(expected_dtype) << \" expected, got \"\n      << DataTypeString(dtype());\n  ...\n}\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/3d782b7d47b1bf2ed32bd4a246d6d6cadc4c903d\/tensorflow\/core\/kernels\/sparse_cross_op.cc#L114-L116) is tricked to consider a tensor of type `tstring` which in fact contains integral elements:\n\n```cc\n  if (DT_STRING == values_.dtype())\n      return Fingerprint64(values_.vec<tstring>().data()[start + n]);\n  return values_.vec<int64>().data()[start + n];\n```\n\nFixing the type confusion by preventing mixing `DT_STRING` and `DT_INT64` types solves this issue.\n\n### Patches\nWe have patched the issue in GitHub commit [b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025",
            "commit_sha":"b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025",
            "patch":"SINGLE",
            "chain_ord":"['b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025']",
            "before_first_fix_commit":"{'3d782b7d47b1bf2ed32bd4a246d6d6cadc4c903d'}",
            "last_fix_commit":"b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/15\/2021, 20:03:19",
            "message":"Fix `tf.raw_ops.SparseCross` failing CHECK.\n\nPiperOrigin-RevId: 368701671\nChange-Id: Id805729dd9ba0bda36e4bb309408129b55fb649d",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 48, 'deletions': 7, 'total': 55}",
            "files":"{'tensorflow\/core\/kernels\/sparse_cross_op.cc': {'additions': 48, 'deletions': 7, 'changes': 55, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/b1cc5e5a50e7cee09f2c6eb48eb40ee9c4125025\/tensorflow%2Fcore%2Fkernels%2Fsparse_cross_op.cc', 'patch': '@@ -27,6 +27,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n+#include \"tensorflow\/core\/framework\/types.pb.h\"\\n #include \"tensorflow\/core\/lib\/core\/stringpiece.h\"\\n #include \"tensorflow\/core\/lib\/strings\/str_util.h\"\\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\\n@@ -460,10 +461,19 @@ int64 CalculateBatchSize(const OpInputList& shapes_list_in,\\n Status ValidateInput(const OpInputList& indices_list_in,\\n                      const OpInputList& values_list_in,\\n                      const OpInputList& shapes_list_in,\\n-                     const OpInputList& dense_list_in) {\\n+                     const OpInputList& dense_list_in,\\n+                     const DataType& internal_type) {\\n   const auto size = indices_list_in.size();\\n+  \/\/ Only perform internal_type check for SparseCrossOp.\\n+  \/\/ Check if the internal_type is not invalid before doing so.\\n+  bool check_type = internal_type != DT_INVALID;\\n   \/\/ Validates indices_list_in OpInputList.\\n   for (int i = 0; i < size; i++) {\\n+    if (check_type && indices_list_in[i].dtype() != DT_INT64) {\\n+      return errors::InvalidArgument(\"Input indices should be of type \",\\n+                                     DT_INT64, \" but received \",\\n+                                     indices_list_in[i].dtype());\\n+    }\\n     if (!TensorShapeUtils::IsMatrix(indices_list_in[i].shape())) {\\n       return errors::InvalidArgument(\\n           \"Input indices should be a matrix but received shape \",\\n@@ -482,6 +492,14 @@ Status ValidateInput(const OpInputList& indices_list_in,\\n                                    values_list_in.size());\\n   }\\n   for (int i = 0; i < size; i++) {\\n+    \/\/ Make sure to avoid the expected type to be string, but input values to be\\n+    \/\/ int64.\\n+    if (check_type && internal_type == DT_STRING &&\\n+        values_list_in[i].dtype() == DT_INT64) {\\n+      return errors::InvalidArgument(\"Input values should be of internal type \",\\n+                                     internal_type, \" but received \",\\n+                                     values_list_in[i].dtype());\\n+    }\\n     if (!TensorShapeUtils::IsVector(values_list_in[i].shape())) {\\n       return errors::InvalidArgument(\\n           \"Input values should be a vector but received shape \",\\n@@ -502,6 +520,11 @@ Status ValidateInput(const OpInputList& indices_list_in,\\n                                    shapes_list_in.size());\\n   }\\n   for (int i = 0; i < size; i++) {\\n+    if (check_type && shapes_list_in[i].dtype() != DT_INT64) {\\n+      return errors::InvalidArgument(\"Input shape should be of type \", DT_INT64,\\n+                                     \" but received \",\\n+                                     shapes_list_in[i].dtype());\\n+    }\\n     if (!TensorShapeUtils::IsVector(shapes_list_in[i].shape())) {\\n       return errors::InvalidArgument(\\n           \"Input shapes should be a vector but received shape \",\\n@@ -517,6 +540,14 @@ Status ValidateInput(const OpInputList& indices_list_in,\\n \\n   \/\/ Validates dense_list_in OpInputList\\n   for (int i = 0; i < dense_list_in.size(); ++i) {\\n+    \/\/ Make sure to avoid the expected type to be string, but input values to be\\n+    \/\/ int64.\\n+    if (check_type && internal_type == DT_STRING &&\\n+        dense_list_in[i].dtype() == DT_INT64) {\\n+      return errors::InvalidArgument(\"Dense inputs should be of internal type \",\\n+                                     internal_type, \" but received \",\\n+                                     dense_list_in[i].dtype());\\n+    }\\n     if (!TensorShapeUtils::IsMatrix(dense_list_in[i].shape())) {\\n       return errors::InvalidArgument(\\n           \"Dense inputs should be a matrix but received shape \",\\n@@ -698,6 +729,7 @@ class SparseCrossOp : public OpKernel {\\n     int64 signed_hash_key_;\\n     OP_REQUIRES_OK(context, context->GetAttr(\"hash_key\", &signed_hash_key_));\\n     hash_key_ = static_cast<uint64>(signed_hash_key_);\\n+    OP_REQUIRES_OK(context, context->GetAttr(\"internal_type\", &internal_type_));\\n   }\\n \\n   void Compute(OpKernelContext* context) override {\\n@@ -711,8 +743,10 @@ class SparseCrossOp : public OpKernel {\\n     OP_REQUIRES_OK(context,\\n                    context->input_list(\"dense_inputs\", &dense_list_in));\\n \\n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\\n-                                          shapes_list_in, dense_list_in));\\n+    DataType internal_type = internal_type_;\\n+    OP_REQUIRES_OK(\\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\\n+                               dense_list_in, internal_type));\\n \\n     std::vector<std::unique_ptr<ColumnInterface<InternalType>>> columns =\\n         GenerateColumnsFromInput<InternalType>(indices_list_in, values_list_in,\\n@@ -756,6 +790,7 @@ class SparseCrossOp : public OpKernel {\\n  private:\\n   int64 num_buckets_;\\n   uint64 hash_key_;\\n+  DataType internal_type_;\\n };\\n \\n class SparseCrossV2Op : public OpKernel {\\n@@ -773,8 +808,11 @@ class SparseCrossV2Op : public OpKernel {\\n     OP_REQUIRES_OK(context,\\n                    context->input_list(\"dense_inputs\", &dense_list_in));\\n \\n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\\n-                                          shapes_list_in, dense_list_in));\\n+    \/\/ Set internal_type to invalid_type so that the check will be ignored.\\n+    DataType internal_type = DT_INVALID;\\n+    OP_REQUIRES_OK(\\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\\n+                               dense_list_in, internal_type));\\n \\n     const Tensor* sep_t;\\n     OP_REQUIRES_OK(context, context->input(\"sep\", &sep_t));\\n@@ -832,8 +870,11 @@ class SparseCrossHashedOp : public OpKernel {\\n     OP_REQUIRES_OK(context,\\n                    context->input_list(\"dense_inputs\", &dense_list_in));\\n \\n-    OP_REQUIRES_OK(context, ValidateInput(indices_list_in, values_list_in,\\n-                                          shapes_list_in, dense_list_in));\\n+    \/\/ Set internal_type to invalid_type so that the check will be ignored.\\n+    DataType internal_type = DT_INVALID;\\n+    OP_REQUIRES_OK(\\n+        context, ValidateInput(indices_list_in, values_list_in, shapes_list_in,\\n+                               dense_list_in, internal_type));\\n \\n     const Tensor* num_buckets_t;\\n     OP_REQUIRES_OK(context, context->input(\"num_buckets\", &num_buckets_t));'}}",
            "message_norm":"fix `tf.raw_ops.sparsecross` failing check.\n\npiperorigin-revid: 368701671\nchange-id: id805729dd9ba0bda36e4bb309408129b55fb649d",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('368701671', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_cross_op.cc'])",
            "num_files":1.0
        },
        {
            "index":2313,
            "vuln_id":"GHSA-jwf9-w5xm-f437",
            "cwe_id":"{'CWE-125'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f'}",
            "dataset":"osv",
            "summary":"Heap OOB in TFLite's `Gather*` implementations ### Impact\nTFLite's [`GatherNd` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation.\n\nHence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`.\n\nSimilar issue exists in [`Gather` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/gather.cc).\n\n```python\nimport tensorflow as tf\nimport numpy as np\ntf.compat.v1.disable_v2_behavior()\n\nparams = tf.compat.v1.placeholder(name=\"params\", dtype=tf.int64, shape=(1,))\nindices = tf.compat.v1.placeholder(name=\"indices\", dtype=tf.int64, shape=())\n\nout = tf.gather(params, indices, name='out')\n\nwith tf.compat.v1.Session() as sess:\n   converter = tf.compat.v1.lite.TFLiteConverter.from_session(sess, [params, indices], [out])\n   tflite_model = converter.convert()\n\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nparams_data = np.reshape(np.array([1], dtype=np.int64), newshape=(1,))\nindices_data = np.reshape(np.array(-10, dtype=np.int64), newshape=())\ninterpreter.set_tensor(input_details[0]['index'], params_data)\ninterpreter.set_tensor(input_details[1]['index'], indices_data)\n\ninterpreter.invoke()\n```\n\n### Patches\nWe have patched the issue in GitHub commits [bb6a0383ed553c286f87ca88c207f6774d5c4a8f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f) and [eb921122119a6b6e470ee98b89e65d721663179d](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security  guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d",
            "commit_sha":"eb921122119a6b6e470ee98b89e65d721663179d",
            "patch":"MULTI",
            "chain_ord":"['bb6a0383ed553c286f87ca88c207f6774d5c4a8f', 'eb921122119a6b6e470ee98b89e65d721663179d']",
            "before_first_fix_commit":"{'ac72971cc6fbbfe4df7e67a8347ef1b6ab63b5fd'}",
            "last_fix_commit":"eb921122119a6b6e470ee98b89e65d721663179d",
            "chain_ord_pos":2.0,
            "commit_datetime":"07\/28\/2021, 00:11:14",
            "message":"Prevent heap OOB read in TFLite's `gather.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387231300\nChange-Id: I3111b54b2f232638d795be17efc46abe4ede6bf8",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 53, 'deletions': 16, 'total': 69}",
            "files":"{'tensorflow\/lite\/kernels\/gather.cc': {'additions': 53, 'deletions': 16, 'changes': 69, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/eb921122119a6b6e470ee98b89e65d721663179d\/tensorflow%2Flite%2Fkernels%2Fgather.cc', 'patch': '@@ -117,8 +117,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n }\\n \\n template <typename InputT, typename PositionsT>\\n-TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,\\n-                    const TfLiteTensor* positions, TfLiteTensor* output) {\\n+TfLiteStatus Gather(TfLiteContext* context, const TfLiteGatherParams& params,\\n+                    const TfLiteTensor* input, const TfLiteTensor* positions,\\n+                    TfLiteTensor* output) {\\n+  const PositionsT* indexes = GetTensorData<PositionsT>(positions);\\n+  bool indices_has_only_positive_elements = true;\\n+  const size_t num_indices = positions->bytes \/ sizeof(PositionsT);\\n+  for (size_t i = 0; i < num_indices; i++) {\\n+    if (indexes[i] < 0) {\\n+      indices_has_only_positive_elements = false;\\n+      break;\\n+    }\\n+  }\\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\\n+\\n   tflite::GatherParams op_params;\\n   op_params.axis = params.axis;\\n   op_params.batch_dims = params.batch_dims;\\n@@ -134,7 +146,18 @@ TfLiteStatus GatherStrings(TfLiteContext* context, const TfLiteTensor* input,\\n                            const TfLiteTensor* positions,\\n                            TfLiteTensor* output) {\\n   DynamicBuffer buffer;\\n+\\n   const PositionT* indexes = GetTensorData<PositionT>(positions);\\n+  bool indices_has_only_positive_elements = true;\\n+  const size_t num_indices = positions->bytes \/ sizeof(PositionT);\\n+  for (size_t i = 0; i < num_indices; i++) {\\n+    if (indexes[i] < 0) {\\n+      indices_has_only_positive_elements = false;\\n+      break;\\n+    }\\n+  }\\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\\n+\\n   const PositionT num_strings = GetStringCount(input);\\n   const int num_indexes = NumElements(positions);\\n \\n@@ -163,19 +186,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   if (positions->type == kTfLiteInt32) {\\n     switch (input->type) {\\n       case kTfLiteFloat32:\\n-        return Gather<float, int32_t>(*params, input, positions, output);\\n+        return Gather<float, int32_t>(context, *params, input, positions,\\n+                                      output);\\n       case kTfLiteUInt8:\\n-        return Gather<uint8_t, int32_t>(*params, input, positions, output);\\n+        return Gather<uint8_t, int32_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt8:\\n-        return Gather<int8_t, int32_t>(*params, input, positions, output);\\n+        return Gather<int8_t, int32_t>(context, *params, input, positions,\\n+                                       output);\\n       case kTfLiteInt16:\\n-        return Gather<int16_t, int32_t>(*params, input, positions, output);\\n+        return Gather<int16_t, int32_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt32:\\n-        return Gather<int32_t, int32_t>(*params, input, positions, output);\\n+        return Gather<int32_t, int32_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt64:\\n-        return Gather<int64_t, int32_t>(*params, input, positions, output);\\n+        return Gather<int64_t, int32_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteBool:\\n-        return Gather<bool, int32_t>(*params, input, positions, output);\\n+        return Gather<bool, int32_t>(context, *params, input, positions,\\n+                                     output);\\n       case kTfLiteString:\\n         return GatherStrings<int32_t>(context, input, positions, output);\\n       default:\\n@@ -187,19 +217,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   if (positions->type == kTfLiteInt64) {\\n     switch (input->type) {\\n       case kTfLiteFloat32:\\n-        return Gather<float, int64_t>(*params, input, positions, output);\\n+        return Gather<float, int64_t>(context, *params, input, positions,\\n+                                      output);\\n       case kTfLiteUInt8:\\n-        return Gather<uint8_t, int64_t>(*params, input, positions, output);\\n+        return Gather<uint8_t, int64_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt8:\\n-        return Gather<int8_t, int64_t>(*params, input, positions, output);\\n+        return Gather<int8_t, int64_t>(context, *params, input, positions,\\n+                                       output);\\n       case kTfLiteInt16:\\n-        return Gather<int16_t, int64_t>(*params, input, positions, output);\\n+        return Gather<int16_t, int64_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt32:\\n-        return Gather<int32_t, int64_t>(*params, input, positions, output);\\n+        return Gather<int32_t, int64_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt64:\\n-        return Gather<int64_t, int64_t>(*params, input, positions, output);\\n+        return Gather<int64_t, int64_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteBool:\\n-        return Gather<bool, int64_t>(*params, input, positions, output);\\n+        return Gather<bool, int64_t>(context, *params, input, positions,\\n+                                     output);\\n       case kTfLiteString:\\n         return GatherStrings<int64_t>(context, input, positions, output);\\n       default:'}}",
            "message_norm":"prevent heap oob read in tflite's `gather.cc`.\n\npassing negative indices is illegal but there was a missing check so that resulted in oob accesses.\n\npiperorigin-revid: 387231300\nchange-id: i3111b54b2f232638d795be17efc46abe4ede6bf8",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('missing check', 'SECWORD', ''), ('oob', 'SECWORD', ''), ('387231300', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/gather.cc'])",
            "num_files":1.0
        },
        {
            "index":2261,
            "vuln_id":"GHSA-jjcx-999m-35hc",
            "cwe_id":"{'CWE-20'}",
            "score":3.3,
            "chain":"{'https:\/\/github.com\/firefly-iii\/firefly-iii\/commit\/e80d616ef4397e6e764f6b7b7a5b30121244933c'}",
            "dataset":"osv",
            "summary":"Improper Input Validation in Firefly III Firefly III 4.7.17.3 is vulnerable to local file enumeration. An attacker can enumerate local files due to the lack of protocol scheme sanitization, such as for file:\/\/\/ URLs. This is related to fints_url to import\/job\/configuration, and import\/create\/fints.",
            "published_date":"2021-09-08",
            "chain_len":1,
            "project":"https:\/\/github.com\/firefly-iii\/firefly-iii",
            "commit_href":"https:\/\/github.com\/firefly-iii\/firefly-iii\/commit\/e80d616ef4397e6e764f6b7b7a5b30121244933c",
            "commit_sha":"e80d616ef4397e6e764f6b7b7a5b30121244933c",
            "patch":"SINGLE",
            "chain_ord":"['e80d616ef4397e6e764f6b7b7a5b30121244933c']",
            "before_first_fix_commit":"{'2ddf48f15cbdbb475221c299872420f625c3bc3f'}",
            "last_fix_commit":"e80d616ef4397e6e764f6b7b7a5b30121244933c",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/02\/2019, 15:05:54",
            "message":"Fix #2367",
            "author":"James Cole",
            "comments":null,
            "stats":"{'additions': 20, 'deletions': 0, 'total': 20}",
            "files":"{'app\/Support\/Import\/JobConfiguration\/FinTS\/NewFinTSJobHandler.php': {'additions': 20, 'deletions': 0, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/firefly-iii\/firefly-iii\/raw\/e80d616ef4397e6e764f6b7b7a5b30121244933c\/app%2FSupport%2FImport%2FJobConfiguration%2FFinTS%2FNewFinTSJobHandler.php', 'patch': \"@@ -60,6 +60,9 @@ public function configureJob(array $data): MessageBag\\n         $config['fints_password']  = (string)(Crypt::encrypt($data['fints_password']) ?? '');\\n         $config['apply-rules']     = 1 === (int)$data['apply_rules'];\\n \\n+        \/\/ sanitize FinTS URL.\\n+        $config['fints_url'] = $this->validURI($config['fints_url']) ? $config['fints_url'] : '';\\n+\\n         $this->repository->setConfiguration($this->importJob, $config);\\n \\n \\n@@ -108,4 +111,21 @@ public function setImportJob(ImportJob $importJob): void\\n         $this->repository->setUser($importJob->user);\\n     }\\n \\n+    \/**\\n+     * @param string $fints_url\\n+     *\\n+     * @return bool\\n+     *\/\\n+    private function validURI(string $fintsUri): bool\\n+    {\\n+        $res = filter_var($fintsUri, FILTER_VALIDATE_URL);\\n+        if (false === $res) {\\n+            return false;\\n+        }\\n+        $scheme = parse_url($fintsUri, PHP_URL_SCHEME);\\n+\\n+        return 'https' === $scheme;\\n+    }\\n+\\n+\\n }\"}}",
            "message_norm":"fix #2367",
            "language":"ca",
            "entities":"[('fix', 'ACTION', ''), ('#2367', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Support\/Import\/JobConfiguration\/FinTS\/NewFinTSJobHandler.php'])",
            "num_files":1.0
        },
        {
            "index":205,
            "vuln_id":"GHSA-36p3-wjmg-h94x",
            "cwe_id":"{'CWE-74', 'CWE-94'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/spring-projects\/spring-framework\/commit\/002546b3e4b8d791ea6acccb81eb3168f51abb15'}",
            "dataset":"osv",
            "summary":"Remote Code Execution in Spring Framework Spring Framework prior to versions 5.2.20 and 5.3.18 contains a remote code execution vulnerability known as `Spring4Shell`. \n\n## Impact\n\nA Spring MVC or Spring WebFlux application running on JDK 9+ may be vulnerable to remote code execution (RCE) via data binding. The specific exploit requires the application to run on Tomcat as a WAR deployment. If the application is deployed as a Spring Boot executable jar, i.e. the default, it is not vulnerable to the exploit. However, the nature of the vulnerability is more general, and there may be other ways to exploit it.\n\nThese are the prerequisites for the exploit:\n- JDK 9 or higher\n- Apache Tomcat as the Servlet container\n- Packaged as WAR\n- `spring-webmvc` or `spring-webflux` dependency\n\n## Patches\n\n- Spring Framework [5.3.18](https:\/\/github.com\/spring-projects\/spring-framework\/releases\/tag\/v5.3.18) and [5.2.20](https:\/\/github.com\/spring-projects\/spring-framework\/releases\/tag\/v5.2.20.RELEASE)\n- Spring Boot [2.6.6](https:\/\/github.com\/spring-projects\/spring-boot\/releases\/tag\/v2.6.6) and [2.5.12](https:\/\/github.com\/spring-projects\/spring-boot\/releases\/tag\/v2.5.12)\n\n## Workarounds\n\nFor those who are unable to upgrade, leaked reports recommend setting `disallowedFields` on `WebDataBinder` through an `@ControllerAdvice`. This works generally, but as a centrally applied workaround fix, may leave some loopholes, in particular if a controller sets `disallowedFields` locally through its own `@InitBinder` method, which overrides the global setting.\n\nTo apply the workaround in a more fail-safe way, applications could extend `RequestMappingHandlerAdapter` to update the `WebDataBinder` at the end after all other initialization. In order to do that, a Spring Boot application can declare a `WebMvcRegistrations` bean (Spring MVC) or a `WebFluxRegistrations` bean (Spring WebFlux).",
            "published_date":"2022-03-31",
            "chain_len":1,
            "project":"https:\/\/github.com\/spring-projects\/spring-framework",
            "commit_href":"https:\/\/github.com\/spring-projects\/spring-framework\/commit\/002546b3e4b8d791ea6acccb81eb3168f51abb15",
            "commit_sha":"002546b3e4b8d791ea6acccb81eb3168f51abb15",
            "patch":"SINGLE",
            "chain_ord":"['002546b3e4b8d791ea6acccb81eb3168f51abb15']",
            "before_first_fix_commit":"{'1627f57f1f77abe17dd607c75476b9e4cb22ffbb'}",
            "last_fix_commit":"002546b3e4b8d791ea6acccb81eb3168f51abb15",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/31\/2022, 07:34:51",
            "message":"Refine PropertyDescriptor filtering\n\nRestrict property paths under `Class` and properties of types\n`ClassLoader` or `ProtectionDomain`.",
            "author":"Brian Clozel",
            "comments":null,
            "stats":"{'additions': 14, 'deletions': 4, 'total': 18}",
            "files":"{'spring-beans\/src\/main\/java\/org\/springframework\/beans\/CachedIntrospectionResults.java': {'additions': 14, 'deletions': 4, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/spring-projects\/spring-framework\/raw\/002546b3e4b8d791ea6acccb81eb3168f51abb15\/spring-beans%2Fsrc%2Fmain%2Fjava%2Forg%2Fspringframework%2Fbeans%2FCachedIntrospectionResults.java', 'patch': '@@ -1,5 +1,5 @@\\n \/*\\n- * Copyright 2002-2020 the original author or authors.\\n+ * Copyright 2002-2022 the original author or authors.\\n  *\\n  * Licensed under the Apache License, Version 2.0 (the \"License\");\\n  * you may not use this file except in compliance with the License.\\n@@ -22,6 +22,7 @@\\n import java.beans.PropertyDescriptor;\\n import java.lang.reflect.Method;\\n import java.lang.reflect.Modifier;\\n+import java.security.ProtectionDomain;\\n import java.util.Collections;\\n import java.util.HashSet;\\n import java.util.LinkedHashMap;\\n@@ -286,9 +287,13 @@ private CachedIntrospectionResults(Class<?> beanClass) throws BeansException {\\n \\t\\t\\t\/\/ This call is slow so we do it once.\\n \\t\\t\\tPropertyDescriptor[] pds = this.beanInfo.getPropertyDescriptors();\\n \\t\\t\\tfor (PropertyDescriptor pd : pds) {\\n-\\t\\t\\t\\tif (Class.class == beanClass &&\\n-\\t\\t\\t\\t\\t\\t(\"classLoader\".equals(pd.getName()) ||  \"protectionDomain\".equals(pd.getName()))) {\\n-\\t\\t\\t\\t\\t\/\/ Ignore Class.getClassLoader() and getProtectionDomain() methods - nobody needs to bind to those\\n+\\t\\t\\t\\tif (Class.class == beanClass && (!\"name\".equals(pd.getName()) && !pd.getName().endsWith(\"Name\"))) {\\n+\\t\\t\\t\\t\\t\/\/ Only allow all name variants of Class properties\\n+\\t\\t\\t\\t\\tcontinue;\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t\\tif (pd.getPropertyType() != null && (ClassLoader.class.isAssignableFrom(pd.getPropertyType())\\n+\\t\\t\\t\\t\\t\\t|| ProtectionDomain.class.isAssignableFrom(pd.getPropertyType()))) {\\n+\\t\\t\\t\\t\\t\/\/ Ignore ClassLoader and ProtectionDomain types - nobody needs to bind to those\\n \\t\\t\\t\\t\\tcontinue;\\n \\t\\t\\t\\t}\\n \\t\\t\\t\\tif (logger.isTraceEnabled()) {\\n@@ -337,6 +342,11 @@ private void introspectInterfaces(Class<?> beanClass, Class<?> currClass, Set<St\\n \\t\\t\\t\\t\\t\\t\/\/ GenericTypeAwarePropertyDescriptor leniently resolves a set* write method\\n \\t\\t\\t\\t\\t\\t\/\/ against a declared read method, so we prefer read method descriptors here.\\n \\t\\t\\t\\t\\t\\tpd = buildGenericTypeAwarePropertyDescriptor(beanClass, pd);\\n+\\t\\t\\t\\t\\t\\tif (pd.getPropertyType() != null && (ClassLoader.class.isAssignableFrom(pd.getPropertyType())\\n+\\t\\t\\t\\t\\t\\t\\t\\t|| ProtectionDomain.class.isAssignableFrom(pd.getPropertyType()))) {\\n+\\t\\t\\t\\t\\t\\t\\t\/\/ Ignore ClassLoader and ProtectionDomain types - nobody needs to bind to those\\n+\\t\\t\\t\\t\\t\\t\\tcontinue;\\n+\\t\\t\\t\\t\\t\\t}\\n \\t\\t\\t\\t\\t\\tthis.propertyDescriptors.put(pd.getName(), pd);\\n \\t\\t\\t\\t\\t\\tMethod readMethod = pd.getReadMethod();\\n \\t\\t\\t\\t\\t\\tif (readMethod != null) {'}}",
            "message_norm":"refine propertydescriptor filtering\n\nrestrict property paths under `class` and properties of types\n`classloader` or `protectiondomain`.",
            "language":"en",
            "entities":"[('protectiondomain', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['spring-beans\/src\/main\/java\/org\/springframework\/beans\/CachedIntrospectionResults.java'])",
            "num_files":1.0
        },
        {
            "index":339,
            "vuln_id":"GHSA-434h-p4gx-jm89",
            "cwe_id":"{'CWE-203'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/dpgaspar\/Flask-AppBuilder\/commit\/780bd0e8fbf2d36ada52edb769477e0a4edae580'}",
            "dataset":"osv",
            "summary":"Observable Response Discrepancy in Flask-AppBuilder ### Impact\nUser enumeration in database authentication in Flask-AppBuilder <= 3.2.3. Allows for a non authenticated user to enumerate existing accounts by timing the response time from the server when you are logging in.\n\n### Patches\nUpgrade to 3.3.0\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Flask-AppBuilder](https:\/\/github.com\/dpgaspar\/Flask-AppBuilder)",
            "published_date":"2021-05-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/dpgaspar\/Flask-AppBuilder",
            "commit_href":"https:\/\/github.com\/dpgaspar\/Flask-AppBuilder\/commit\/780bd0e8fbf2d36ada52edb769477e0a4edae580",
            "commit_sha":"780bd0e8fbf2d36ada52edb769477e0a4edae580",
            "patch":"SINGLE",
            "chain_ord":"['780bd0e8fbf2d36ada52edb769477e0a4edae580']",
            "before_first_fix_commit":"{'b60dea9cedf98b56c926ba41020c73f287d5826e'}",
            "last_fix_commit":"780bd0e8fbf2d36ada52edb769477e0a4edae580",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/10\/2021, 08:37:55",
            "message":"fix: auth balance (#1634)",
            "author":"Daniel Vaz Gaspar",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'flask_appbuilder\/security\/manager.py': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/dpgaspar\/Flask-AppBuilder\/raw\/780bd0e8fbf2d36ada52edb769477e0a4edae580\/flask_appbuilder%2Fsecurity%2Fmanager.py', 'patch': '@@ -833,6 +833,12 @@ def auth_user_db(self, username, password):\\n         if user is None:\\n             user = self.find_user(email=username)\\n         if user is None or (not user.is_active):\\n+            # Balance failure and success\\n+            check_password_hash(\\n+                \"pbkdf2:sha256:150000$Z3t6fmj2$22da622d94a1f8118\"\\n+                \"c0976a03d2f18f680bfff877c9a965db9eedc51bc0be87c\",\\n+                \"password\",\\n+            )\\n             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED.format(username))\\n             return None\\n         elif check_password_hash(user.password, password):'}}",
            "message_norm":"fix: auth balance (#1634)",
            "language":"en",
            "entities":"[('auth', 'SECWORD', ''), ('#1634', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['flask_appbuilder\/security\/manager.py'])",
            "num_files":1.0
        },
        {
            "index":756,
            "vuln_id":"GHSA-65mj-7c86-79jf",
            "cwe_id":"{'CWE-305', 'CWE-287'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/ADOdb\/ADOdb\/commit\/952de6c4273d9b1e91c2b838044f8c2111150c29', 'https:\/\/github.com\/ADOdb\/ADOdb\/commit\/b4d5ce70034c5aac3a1d51d317d93c037a0938d2'}",
            "dataset":"osv",
            "summary":"Authentication Bypass in ADOdb\/ADOdb ### Impact\n\nAn attacker can inject values into a PostgreSQL connection string by providing a parameter surrounded by single quotes.\n\nDepending on how the library is used in the client software, this may allow an attacker to bypass the login process, gain access to the server's IP address, etc.\n\n### Patches\n\nThe vulnerability is fixed in ADOdb versions 5.20.21 (952de6c4273d9b1e91c2b838044f8c2111150c29) and 5.21.4 or later (b4d5ce70034c5aac3a1d51d317d93c037a0938d2).\n\nThe simplest patch is to delete line 29 in `drivers\/adodb-postgres64.inc.php`:\n\n```php\ndiff --git a\/drivers\/adodb-postgres64.inc.php b\/drivers\/adodb-postgres64.inc.php\nindex d04b7f67..729d7141 100644\n--- a\/drivers\/adodb-postgres64.inc.php\n+++ b\/drivers\/adodb-postgres64.inc.php\n@@ -26,7 +26,6 @@ function adodb_addslashes($s)\n {\n    $len = strlen($s);\n    if ($len == 0) return \"''\";\n-   if (strncmp($s,\"'\",1) === 0 && substr($s,$len-1) == \"'\") return $s; \/\/ already quoted\n \n    return \"'\".addslashes($s).\"'\";\n }\n```\n\n### Workarounds\n\nEnsure the parameters passed to *ADOConnection::connect()* or related functions (_nConnect()_, _pConnect()_) are not surrounded by single quotes.\n\n### Credits\n\nThanks to **Emmet Leahy** (@meme-lord) of Sorcery Ltd for reporting this vulnerability, and to the [huntr](https:\/\/huntr.dev\/) team for their support.\n\n### References\n\n- Original issue report https:\/\/huntr.dev\/bounties\/bdf5f216-4499-4225-a737-b28bc6f5801c\/\n- ADOdb reference issue #793 \n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Add a note in issue #793\n* Contact the maintainers on [Gitter](https:\/\/gitter.im\/adodb\/adodb)",
            "published_date":"2022-01-27",
            "chain_len":2,
            "project":"https:\/\/github.com\/ADOdb\/ADOdb",
            "commit_href":"https:\/\/github.com\/ADOdb\/ADOdb\/commit\/b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
            "commit_sha":"b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
            "patch":"MULTI",
            "chain_ord":"['952de6c4273d9b1e91c2b838044f8c2111150c29', 'b4d5ce70034c5aac3a1d51d317d93c037a0938d2']",
            "before_first_fix_commit":"{'c5415722049f36c446a4034d15f1d17943f11458'}",
            "last_fix_commit":"b4d5ce70034c5aac3a1d51d317d93c037a0938d2",
            "chain_ord_pos":2.0,
            "commit_datetime":"01\/10\/2022, 09:00:33",
            "message":"Prevent auth bypass with PostgreSQL connections\n\nThanks to Emmet Leahy of Sorcery Ltd for reporting this vulnerability\n(CVE-2021-3850).\n\nRefactoring ADODB_postgres64::_connect():\n- Remove adodb_addslashes() function, which did not escape the\n  connection parameters when they are wrapped in single quotes\n  (root cause for the identified security issue).\n- Use addcslashes() instead of addslashes() to only escape `'` and `\\`,\n  to strictly follow pg_connect() documentation (addslashes() also\n  escapes `\"`)\n- Use an array and a foreach loop to build the connection string when\n  given individual parameters for host:port, user, password and dbname\n\nFixes #793",
            "author":"Damien Regad",
            "comments":null,
            "stats":"{'additions': 25, 'deletions': 22, 'total': 47}",
            "files":"{'drivers\/adodb-postgres64.inc.php': {'additions': 25, 'deletions': 22, 'changes': 47, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ADOdb\/ADOdb\/raw\/b4d5ce70034c5aac3a1d51d317d93c037a0938d2\/drivers%2Fadodb-postgres64.inc.php', 'patch': '@@ -22,15 +22,6 @@\\n \/\/ security - hide paths\\n if (!defined(\\'ADODB_DIR\\')) die();\\n \\n-function adodb_addslashes($s)\\n-{\\n-\\t$len = strlen($s);\\n-\\tif ($len == 0) return \"\\'\\'\";\\n-\\tif (strncmp($s,\"\\'\",1) === 0 && substr($s,$len-1) == \"\\'\") return $s; \/\/ already quoted\\n-\\n-\\treturn \"\\'\".addslashes($s).\"\\'\";\\n-}\\n-\\n class ADODB_postgres64 extends ADOConnection{\\n \\tvar $databaseType = \\'postgres64\\';\\n \\tvar $dataProvider = \\'postgres\\';\\n@@ -693,21 +684,33 @@ function _connect($str,$user=\\'\\',$pwd=\\'\\',$db=\\'\\',$ctype=0)\\n \\n \\t\\t$this->_errorMsg = false;\\n \\n+\\t\\t\/\/ If $user, $pwd and $db are all null, then $str is a pg_connect()\\n+\\t\\t\/\/ connection string. Otherwise we expect it to be a hostname,\\n+\\t\\t\/\/ with optional port separated by \\':\\'\\n \\t\\tif ($user || $pwd || $db) {\\n-\\t\\t\\t$user = adodb_addslashes($user);\\n-\\t\\t\\t$pwd = adodb_addslashes($pwd);\\n-\\t\\t\\tif (strlen($db) == 0) $db = \\'template1\\';\\n-\\t\\t\\t$db = adodb_addslashes($db);\\n-\\t\\t\\tif ($str)  {\\n-\\t\\t\\t\\t$host = explode(\":\", $str);\\n-\\t\\t\\t\\tif ($host[0]) $str = \"host=\".adodb_addslashes($host[0]);\\n-\\t\\t\\t\\telse $str = \\'\\';\\n-\\t\\t\\t\\tif (isset($host[1])) $str .= \" port=$host[1]\";\\n-\\t\\t\\t\\telse if (!empty($this->port)) $str .= \" port=\".$this->port;\\n+\\t\\t\\t\/\/ Hostname & port\\n+\\t\\t\\tif ($str) {\\n+\\t\\t\\t\\t$host = explode(\\':\\', $str);\\n+\\t\\t\\t\\tif ($host[0]) {\\n+\\t\\t\\t\\t\\t$conn[\\'host\\'] = $host[0];\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t\\tif (isset($host[1])) {\\n+\\t\\t\\t\\t\\t$conn[\\'port\\'] = (int)$host[1];\\n+\\t\\t\\t\\t} elseif (!empty($this->port)) {\\n+\\t\\t\\t\\t\\t$conn[\\'port\\'] = $this->port;\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t}\\n+\\t\\t\\t$conn[\\'user\\'] = $user;\\n+\\t\\t\\t$conn[\\'password\\'] = $pwd;\\n+\\t\\t\\t\/\/ @TODO not sure why we default to \\'template1\\', pg_connect() uses the username when dbname is empty\\n+\\t\\t\\t$conn[\\'dbname\\'] = $db ?: \\'template1\\';\\n+\\n+\\t\\t\\t\/\/ Generate connection string\\n+\\t\\t\\t$str = \\'\\';\\n+\\t\\t\\tforeach ($conn as $param => $value) {\\n+\\t\\t\\t\\t\/\/ Escaping single quotes and backslashes per pg_connect() documentation\\n+\\t\\t\\t\\t$str .= $param . \"=\\'\" . addcslashes($value, \"\\'\\\\\\\\\") . \"\\' \";\\n \\t\\t\\t}\\n-\\t\\t\\tif ($user) $str .= \" user=\".$user;\\n-\\t\\t\\tif ($pwd)  $str .= \" password=\".$pwd;\\n-\\t\\t\\tif ($db)   $str .= \" dbname=\".$db;\\n \\t\\t}\\n \\n \\t\\t\/\/if ($user) $linea = \"user=$user host=$linea password=$pwd dbname=$db port=5432\";'}}",
            "message_norm":"prevent auth bypass with postgresql connections\n\nthanks to emmet leahy of sorcery ltd for reporting this vulnerability\n(cve-2021-3850).\n\nrefactoring adodb_postgres64::_connect():\n- remove adodb_addslashes() function, which did not escape the\n  connection parameters when they are wrapped in single quotes\n  (root cause for the identified security issue).\n- use addcslashes() instead of addslashes() to only escape `'` and `\\`,\n  to strictly follow pg_connect() documentation (addslashes() also\n  escapes `\"`)\n- use an array and a foreach loop to build the connection string when\n  given individual parameters for host:port, user, password and dbname\n\nfixes #793",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('auth', 'SECWORD', ''), ('bypass', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('cve-2021-3850', 'VULNID', 'CVE'), ('remove', 'ACTION', ''), ('escape', 'SECWORD', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('escape', 'SECWORD', ''), ('escapes', 'SECWORD', ''), ('password', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#793', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['drivers\/adodb-postgres64.inc.php'])",
            "num_files":1.0
        },
        {
            "index":1680,
            "vuln_id":"GHSA-f78g-q7r4-9wcv",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/548b5eaf23685d86f722233d8fbc21d0a4aecb96'}",
            "dataset":"osv",
            "summary":"Division by 0 in `FractionalAvgPool` ### Impact\nAn attacker can cause a runtime division by zero error and denial of service in `tf.raw_ops.FractionalAvgPool`:\n\n```python\nimport tensorflow as tf\n\nvalue = tf.constant([60], shape=[1, 1, 1, 1], dtype=tf.int32)\npooling_ratio = [1.0, 1.0000014345305555, 1.0, 1.0]\npseudo_random = False\noverlapping = False\ndeterministic = False\nseed = 0\nseed2 = 0\n\ntf.raw_ops.FractionalAvgPool(\n  value=value, pooling_ratio=pooling_ratio, pseudo_random=pseudo_random,\n  overlapping=overlapping, deterministic=deterministic, seed=seed, seed2=seed2)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc#L85-L89) computes a divisor quantity by dividing two user controlled values:\n\n```cc                     \nfor (int i = 0; i < tensor_in_and_out_dims; ++i) {\n  output_size[i] = static_cast<int>(std::floor(input_size[i] \/ pooling_ratio_[i]));\n  DCHECK_GT(output_size[i], 0); \n} \n``` \n    \nThe user controls the values of `input_size[i]` and `pooling_ratio_[i]` (via the `value.shape()` and `pooling_ratio` arguments). If the value in `input_size[i]` is smaller than the `pooling_ratio_[i]`, then the floor operation results in `output_size[i]` being 0. The `DCHECK_GT` line is a no-op outside of debug mode, so in released versions of TF this does not trigger.\n\nLater, these computed values [are used as arguments](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc#L96-L99) to [`GeneratePoolingSequence`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c\/tensorflow\/core\/kernels\/fractional_pool_common.cc#L100-L108). There, the first computation is a division in a modulo operation:\n\n```cc\nstd::vector<int64> GeneratePoolingSequence(int input_length, int output_length,\n                                           GuardedPhiloxRandom* generator,\n                                           bool pseudo_random) {\n  ...\n  if (input_length % output_length == 0) {\n    diff = std::vector<int64>(output_length, input_length \/ output_length);\n  }\n  ...\n}\n```\n\nSince `output_length` can be 0, this results in runtime crashing.\n\n### Patches\nWe have patched the issue in GitHub commit [548b5eaf23685d86f722233d8fbc21d0a4aecb96](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/548b5eaf23685d86f722233d8fbc21d0a4aecb96).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/548b5eaf23685d86f722233d8fbc21d0a4aecb96",
            "commit_sha":"548b5eaf23685d86f722233d8fbc21d0a4aecb96",
            "patch":"SINGLE",
            "chain_ord":"['548b5eaf23685d86f722233d8fbc21d0a4aecb96']",
            "before_first_fix_commit":"{'acc8ee69f5f46f92a3f1f11230f49c6ac266f10c'}",
            "last_fix_commit":"548b5eaf23685d86f722233d8fbc21d0a4aecb96",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/29\/2021, 15:38:16",
            "message":"Fix divide by zero error in `fractional_pool_common.cc`.\n\nPiperOrigin-RevId: 371126221\nChange-Id: Iea4b2f363aaeb116ab460e3bc592c687484af344",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'tensorflow\/core\/kernels\/fractional_avg_pool_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/548b5eaf23685d86f722233d8fbc21d0a4aecb96\/tensorflow%2Fcore%2Fkernels%2Ffractional_avg_pool_op.cc', 'patch': '@@ -80,6 +80,10 @@ class FractionalAvgPoolOp : public OpKernel {\\n     std::vector<int> output_size(tensor_in_and_out_dims);\\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\\n       input_size[i] = tensor_in.dim_size(i);\\n+      OP_REQUIRES(\\n+          context, pooling_ratio_[i] <= input_size[i],\\n+          errors::InvalidArgument(\\n+              \"Pooling ratio cannot be bigger than input tensor dim size.\"));\\n     }\\n     \/\/ Output size.\\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {'}}",
            "message_norm":"fix divide by zero error in `fractional_pool_common.cc`.\n\npiperorigin-revid: 371126221\nchange-id: iea4b2f363aaeb116ab460e3bc592c687484af344",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('divide by zero', 'SECWORD', ''), ('error', 'FLAW', ''), ('371126221', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/fractional_avg_pool_op.cc'])",
            "num_files":1.0
        },
        {
            "index":1973,
            "vuln_id":"GHSA-h3fg-h5v3-vf8m",
            "cwe_id":"{'CWE-352'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/solidusio\/solidus\/commit\/a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6', 'https:\/\/github.com\/solidusio\/solidus\/commit\/4d17cacf066d9492fc04eb3a0b16084b47376d81'}",
            "dataset":"osv",
            "summary":"CSRF forgery protection bypass in solidus_frontend ### Impact\nCSRF vulnerability that allows a malicious site to add an item to the user's cart without their knowledge.\n\nAll `solidus_frontend` versions are affected. If you're using your own storefront, please, follow along to make sure you're not affected.\n\nTo reproduce the issue:\n\n- Pick the id for a variant with available stock. From the rails console:\n\n  ```ruby\n  Spree::Variant.in_stock.pluck(:id)\n  ```\n\n  Say we pick variant id `2`.\n\n- Launch your application, for instance, on `http:\/\/localhost:3000`:\n\n  ```bash\n  bin\/rails server\n  ```\n\n- Open your browser dev tools.\n\n- Click on whatever link in your store.\n\n- Copy the value of the `Cookie` request header sent for the previous request from your browser dev tools.\n\n- Execute the following, using your previously selected variant id and the value of the `Cookie` header (notice how it doesn't contain any authentication token):\n\n  ```bash\n  curl -X POST -d \"variant_id=2&quantity=1\" -H \"Cookie: guest_token=eyJfcmFpbHMiOnsibWVzc2FnZSI6IklrWlRVMWRQWnpKMVZVdFNXRzlPVW1aaWJHTjZZa0VpIiwiZXhwIjpudWxsLCJwdXIiOiJjb29raWUuZ3Vlc3RfdG9rZW4ifX0%3D--5006ba5d346f621c760a29b6a797bf351d17d1b8; _sandbox_session=vhutu5%2FL9NmWrUpGc3DxrFA%2FFsQD1dHn1cNsD7nvE84zcjWf17Af4%2F%2F2Vab3md71b6KTb9NP6WktdXktpwH4eU01jEGIBXG5%2BMzW5nL0nb4W269qk1io4LYljvoOg8%2BZVll7oJCVkJLKKh0sSoS0Kg8j%2FCHHs%2BsShohP%2BGnA%2Bfr9Ub8H6HofpSmloSpsfHHygmX0ho03fEgzHJ4DD5wJctaNKwg7NhVikHh5kgIPPHl84OGCgv3p2oe9jR19HTxOKq7BtyvDd7XZsecWhkcfS8BPnvDDUWZG6qpAEFI5kWo81KkpSJ%2Bp6Q1HOo8%3D--n3G2vgaDG7VS%2B%2FhF--ZTjxBAkfGG3hpr4GRQ2S1Q%3D%3D; __profilin=p%3Dt\" http:\/\/localhost:3000\/orders\/populate\n  ```\n\n- Reload your browser and look at how your cart got updated.\n\n### Patches\n\nPlease, upgrade `solidus` to versions `3.1.5`, `3.0.5` or `2.11.14`.\n\nAfter upgrading, make sure you read the \"Upgrade notes\"  section below.\n\n### Upgrade notes\n\nThe patch adds CSRF token verification to the \"Add to cart\" action. Adding forgery protection to a form that missed it can have some side effects.\n\n#### `InvalidAuthenticityToken` errors\n\nIf you're using the `:exception` strategy, it's likely that after upgrading, you'll see more `ActionController::InvalidAuthenticityToken` errors popping out in your logs. Due to browser-side cache, a form can be re-rendered and sent without any attached request cookie (for instance, when re-opening a mobile browser). That will cause an authentication error, as the sent token won't match with the one in the session (none in this case). That's a known problem in the Rails community (see https:\/\/github.com\/rails\/rails\/issues\/21948), and, at this point, there's no perfect solution.\n\nAny attempt to mitigate the issue should be seen at the application level. For an excellent survey of all the available options, take a look at https:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md. The latter is a third-party link. As the information is relevant here, we're going to copy it below, but it should be clear that all the credit goes to @kemenaran:\n\n> # Protecting against request forgery using CRSF tokens\n> \n> ## Context\n> \n> Rails has CSRF protection enabled by default, to protect against POST-based CSRF attacks.\n> \n> To protect from this, Rails stores two copies of a random token (the so-named CSRF token) on each request:\n> - one copy embedded in each HTML page,\n> - another copy in the user session.\n> \n> When performing a POST request, Rails checks that the two copies match \u2013 and otherwise denies the request. This protects against an attacker that would generate a form secretly pointing to our website: the attacker can't read the token in the session, and so can't post a form with a valid token.\n> \n> The problem is that, much more often, this has false positives. There are several cases for that, including:\n> \n> 1. The web browser (often mobile) loads a page containing a form, then is closed by the user. Later, when the browser is re-opened, it restores the page from the cache. But the session cookie has expired, and so is not restored \u2013 so the copy of the CSRF token stored in the session is missing. When the user submits the form, they get an \"InvalidAuthenticityToken\" exception.\n> \n> 2. The user attempts to fill a form, and gets an error message (usually in response to a POST request). They close the browser. When the browser is re-opened, it attempts to restore the page. On Chrome this is blocked by the browser, because the browser denies retrying a (probably non-idempotent) POST request. Safari however happily retries the POST request \u2013 but without sending any cookies (in an attempt to avoid having unexpected side-effects). So the copy of the CSRF token in the session is missing (because no cookie was sent), and the user get an \"InvalidAuthenticityToken\" exception.\n> \n> ## Options considered\n> \n> ### Extend the session cookie duration\n> \n> We can configure the session cookie to be valid for a longer time (like 2 weeks).\n> \n> Pros:\n> - It solves 1., because when the browser restores the page, the session cookie is still valid.\n> \n> Cons:\n> - Users would be signed-in for a much longer time by default, which has unacceptable security implications.\n> - It doesn't solve 2. (because Safari doesn't send any cookie when restoring a page from a POST request)\n> \n> ### Change the cache parameters\n> \n> We can send a HTTP cache header stating 'Cache-Control: no-store, no-cache'. This instructs the browser to never keep any copy of the page, and to always make a request to the server to restore it.\n> \n> This solution was attempted during a year in production, and solved 1. \u2013 but also introduced another type of InvalidAuthenticityToken errors. In that scenario, the user attempts to fill a form, and gets an error message (usually in response to a POST request). They then navigate on another domain (like France Connect), then hit the \"Back\" button. Crossing back the domain boundary may cause the browser to either block the request or retry an invalid POST request.\n> \n> Pros:\n> - It solves 1., because on relaunch the browser requests a fresh page again (instead of serving it from its cache), thus retrieving a fresh session and a fresh matching CSRF token.\n> \n> Cons:\n> - It doesn't solve 2.\n> - It causes another type of InvalidAuthenticityToken errors.\n> \n> ### Using a null-session strategy\n> \n> We can change the default protect_from_forgery strategy to :null_session. This makes the current request use an empty session for the request duration.\n> \n> Pros:\n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted.\n> \n> Cons:\n> - The user is asked to sign-in only after filling and submitting the form, losing their time and data\n> - The user will not be redirected to their original page after signing-in\n> - It has potential security implications: as the (potentically malicious) request runs anyway, variables cached by a controller before the Null session is created may allow the form submission to succeed anyway (https:\/\/www.veracode.com\/blog\/managing-appsec\/when-rails-protectfromforgery-fails)\n> \n> ### Using a reset-session strategy\n> \n> We can change the default protect_from_forgery strategy to :reset_session. This clears the user session permanently, logging them out until they log in again.\n> \n> Pros: \n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted.\n> \n> Cons:\n> - A forgery error in a browser tab will disconnect the user in all its open tabs\n> - It has potential security implications: as the (potentically malicious) request runs anyway, variables cached by a controller before the Null session is created may allow the form submission to succeed anyway (https:\/\/www.veracode.com\/blog\/managing-appsec\/when-rails-protectfromforgery-fails)\n> - It allows an attacker to disconnect an user on demand, which is not only inconvenient, but also has security implication (the attacker could then log the user on it's own attacker account, pretending to be the user account)\n> \n> ### Redirect to login form\n> \n> When a forgery error occurs, we can instead redirect to the login form.\n> \n> Pros:\n> - It kind of solves 1., by redirecting to a \"Please sign-in\" page when a stale form is submitted (but the user data is lost).\n> - It kind of solves 2., by redirecting to a \"Please sign-in\" page when a previously POSTed form is reloaded.\n> \n> Cons:\n> - Not all forms require authentication \u2013 so for public forms there is no point redirecting to the login form. \n> - The user will not be redirected to their original page after signing-in (because setting the redirect path is a state-changing action, and it is dangerous to let an unauthorized request changing the state \u2013 an attacker could control the path where an user is automatically redirected to.)\n> - The implementation is finicky, and may introduce security errors. For instance, a naive implementation that catches the exception and redirect_to the sign-in page will prevent Devise from running a cleanup code \u2013 which means the user will still be logged, and the CSRF protection is bypassed. However a well-tested implementation that lets Devise code run should avoid these pittfalls.\n> \n> ### Using a long-lived cookie for CSRF tokens\n> \n> Instead of storing the CSRF token in the session cookie (which is deleted when the browser is closed), we can instead store it in a longer-lived cookie. For this we need to patch Rails.\n> \n> Pros:\n> - It solves 1., because when the user submits a stale form, even if the session cookie because stale, the long-lived CSRF cookie is still valid.\n> \n> Cons:\n> - It doesn't solve 2., because when Safari retries a POST request, it sends none of the cookies (not even long-lived ones).\n> - Patching Rails may introduce security issues (now or in the future)\n\n#### Broken behavior due to session expiration + template cache\n\nAlthough pretty unlikely, you should make sure that your current setup for cache\/session expiration is compatible. The upgrade can break the addition of products to the cart if both:\n\n- The \"Add to cart\" form is being cached (usually along with the variant information).\n\n- A user session is reset at every or every few requests.\n\nThe token validation depends on the issuing and consuming sessions being the same. If a product page is cached with the token in it, it can become stale on a subsequent rendering if the session changes.\n\nTo check that you're safe, after having upgraded locally, go through the following steps:\n\n- Enable cache on dev mode:\n\n  ```bash\n  bin\/rails dev:cache\n  ```\n\n- Visit the page for a variant with stock.\n\n- Reload that page several times.\n\n- Click on the \"Add to cart\"  button.\n\n- Remember to rerun `bin\/rails dev:cache` to turn off cache again.\n\nNo error or session reset should happen.\n\nOtherwise, you can try with:\n\n- Revisiting how your session gets expired.\n- Changing the caching strategy to exclude the token.\n\n#### Using weaker CSRF protection strategies\n\nIt's also important to understand that a complete fix will only be in place when using the `:exception` forgery protection strategy. The `solidus_frontend` engine can't do pretty much anything otherwise. Using weaker CSRF strategies should be an informed and limited decision made by the application team. After the upgrade:\n\n- An app using `:null_session` should also be safe, but there will be side effects. That strategy runs with a null object session. As such, no order and no user is found on it. A new `cart` state order is created in the database, associated with no user. Next time the user visits the site, they won't find any difference in its cart state.\n\n- An app using `:reset_session` is not entirely safe. That strategy resets the session. That means that registered users will be logged out. Next time a user visits, they'll see the cart with the items added during the CSRF attack, although it won't be associated with their account in the case of registered users.\n\n#### Reversing the update\n\nIf you still want to deploy the upgraded version before changing your application code (if the latter is needed), you can add the following workaround to your `config\/application.rb` (however, take into account that you'll keep being vulnerable):\n\n```ruby\nconfig.after_initialize do\n  Spree::OrdersController.skip_before_action :verify_authenticity_token, only: [:populate]\nend\n```\n\n### Workarounds\n\nIf an upgrade is not an option, you can work around the issue by adding the following to `config\/application.rb`:\n\n```ruby\nconfig.after_initialize do\n  Spree::OrdersController.protect_from_forgery with: ApplicationController.forgery_protection_strategy.name.demodulize.underscore.to_sym, only: [:populate]\nend\n```\n\nHowever, go through the same safety check detailed on \"Upgrade notes\" above.\n\n### References\n\n- [CSRF on the Rails guides](https:\/\/guides.rubyonrails.org\/security.html#cross-site-request-forgery-csrf)\n- [How CSRF tokens are generated and validated on Rails](https:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef)\n- [Solidus security](https:\/\/solidus.io\/security\/)\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Open an [issue](https:\/\/github.com\/solidusio\/solidus\/issues) or a [discussion](https:\/\/github.com\/solidusio\/solidus\/discussions) in Solidus.\n* Email us at [security@solidus.io](mailto:security@soliidus.io)\n* Contact the core team on [Slack](http:\/\/slack.solidus.io\/)",
            "published_date":"2022-01-06",
            "chain_len":2,
            "project":"https:\/\/github.com\/solidusio\/solidus",
            "commit_href":"https:\/\/github.com\/solidusio\/solidus\/commit\/4d17cacf066d9492fc04eb3a0b16084b47376d81",
            "commit_sha":"4d17cacf066d9492fc04eb3a0b16084b47376d81",
            "patch":"MULTI",
            "chain_ord":"['4d17cacf066d9492fc04eb3a0b16084b47376d81', 'a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6']",
            "before_first_fix_commit":"{'4d17cacf066d9492fc04eb3a0b16084b47376d81', 'c6b892696881f88d209efaedd8bb378e8261953f'}",
            "last_fix_commit":"a1b9bf7f24f9b8684fc4d943eacb02b1926c77c6",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/14\/2021, 09:36:44",
            "message":"Protect `Spree::OrdersController#populate` against CSRF attacks\n\nSee\nhttps:\/\/github.com\/solidusio\/solidus\/security\/advisories\/GHSA-h3fg-h5v3-vf8m\nfor all the details.\n\nSome time ago, all order actions were left out of CSRF protection (see\n95ea57058ab1c5e722b327b10747cd41e68a4deb). The reason given was that the\nauthentication token got stale after the second rendering because the\nproduct page is cached. That was limited to `#populate` in\ncb797542c6948ef33d2cc9e6076c88f4cc927fb2 (see also\nhttps:\/\/github.com\/spree\/spree\/pull\/5601).\n\nHowever, those assumptions are not correct. Although the authenticity\ntoken changes at every request, that doesn't mean that the old ones are\nno longer valid. The variation comes from a one-time pad added to a\nsession-dependant token (and meant to avoid timing attacks). However,\nbefore validation, that one-time pad is removed. That means the token\nremains valid as long as the session has not been reset. Think about\nsubmitting a form from one browser tab after opening another with the\nsame URL. Even if both tokens differ, the submission from the first tab\nwill still be valid. You can read\nhttps:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef\nfor an in-deep understanding.\n\nThe initial confusion could come because of\nhttps:\/\/github.com\/rails\/rails\/issues\/21948. Due to browser-side cache,\na form can be re-rendered and sent without any attached request cookie.\nThat will cause an authentication error, as the sent token won't match\nwith the one in the session (none in this case). There's no perfect\nsolution for that, and all partial fixes should be seen at the\napplication level. From our side, we must provide a safe default. For an\nexcellent survey of all the available options, take a look at\nhttps:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md.\nThe information given in that link is third-party but it's very\nrelevant here. For that reason we've copied it in the security advisory\n(see link above), but all the credit goes to @kemenaran.",
            "author":"Marc Busqu\u00e9",
            "comments":null,
            "stats":"{'additions': 0, 'deletions': 1, 'total': 1}",
            "files":"{'frontend\/app\/controllers\/spree\/orders_controller.rb': {'additions': 0, 'deletions': 1, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/solidusio\/solidus\/raw\/4d17cacf066d9492fc04eb3a0b16084b47376d81\/frontend%2Fapp%2Fcontrollers%2Fspree%2Forders_controller.rb', 'patch': \"@@ -10,7 +10,6 @@ class OrdersController < Spree::StoreController\\n     before_action :assign_order, only: :update\\n     # note: do not lock the #edit action because that's where we redirect when we fail to acquire a lock\\n     around_action :lock_order, only: :update\\n-    skip_before_action :verify_authenticity_token, only: [:populate]\\n \\n     def show\\n       @order = Spree::Order.find_by!(number: params[:id])\"}}",
            "message_norm":"protect `spree::orderscontroller#populate` against csrf attacks\n\nsee\nhttps:\/\/github.com\/solidusio\/solidus\/security\/advisories\/ghsa-h3fg-h5v3-vf8m\nfor all the details.\n\nsome time ago, all order actions were left out of csrf protection (see\n95ea57058ab1c5e722b327b10747cd41e68a4deb). the reason given was that the\nauthentication token got stale after the second rendering because the\nproduct page is cached. that was limited to `#populate` in\ncb797542c6948ef33d2cc9e6076c88f4cc927fb2 (see also\nhttps:\/\/github.com\/spree\/spree\/pull\/5601).\n\nhowever, those assumptions are not correct. although the authenticity\ntoken changes at every request, that doesn't mean that the old ones are\nno longer valid. the variation comes from a one-time pad added to a\nsession-dependant token (and meant to avoid timing attacks). however,\nbefore validation, that one-time pad is removed. that means the token\nremains valid as long as the session has not been reset. think about\nsubmitting a form from one browser tab after opening another with the\nsame url. even if both tokens differ, the submission from the first tab\nwill still be valid. you can read\nhttps:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef\nfor an in-deep understanding.\n\nthe initial confusion could come because of\nhttps:\/\/github.com\/rails\/rails\/issues\/21948. due to browser-side cache,\na form can be re-rendered and sent without any attached request cookie.\nthat will cause an authentication error, as the sent token won't match\nwith the one in the session (none in this case). there's no perfect\nsolution for that, and all partial fixes should be seen at the\napplication level. from our side, we must provide a safe default. for an\nexcellent survey of all the available options, take a look at\nhttps:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md.\nthe information given in that link is third-party but it's very\nrelevant here. for that reason we've copied it in the security advisory\n(see link above), but all the credit goes to @kemenaran.",
            "language":"en",
            "entities":"[('protect', 'ACTION', ''), ('csrf', 'SECWORD', ''), ('attacks', 'FLAW', ''), ('https:\/\/github.com\/solidusio\/solidus\/security\/advisories\/ghsa-h3fg-h5v3-vf8m', 'VULNID', 'GHSA'), ('csrf', 'SECWORD', ''), ('protection', 'SECWORD', ''), ('95ea57058ab1c5e722b327b10747cd41e68a4deb', 'SHA', 'generic_sha'), ('authentication', 'SECWORD', ''), ('cb797542c6948ef33d2cc9e6076c88f4cc927fb2', 'SHA', 'generic_sha'), ('https:\/\/github.com\/spree\/spree\/pull\/5601', 'URL', ''), ('added', 'ACTION', ''), ('attacks', 'SECWORD', ''), ('removed', 'ACTION', ''), ('https:\/\/medium.com\/rubyinside\/a-deep-dive-into-csrf-protection-in-rails-19fa0a42c0ef', 'SECWORD', ''), ('https:\/\/github.com\/rails\/rails\/issues\/21948', 'URL', ''), ('cookie', 'SECWORD', ''), ('authentication', 'SECWORD', ''), ('error', 'FLAW', ''), ('safe', 'SECWORD', ''), ('https:\/\/github.com\/betagouv\/demarches-simplifiees.fr\/blob\/5b4f7f9ae9eaf0ac94008b62f7047e4714626cf9\/doc\/adr-csrf-forgery.md', 'SECWORD', ''), ('security', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['frontend\/app\/controllers\/spree\/orders_controller.rb'])",
            "num_files":1.0
        },
        {
            "index":1098,
            "vuln_id":"GHSA-7x2h-3v2v-24p9",
            "cwe_id":"{'CWE-352'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/63447b369973724f0d352a006f25af6ff71ae292'}",
            "dataset":"osv",
            "summary":"Cross-Site Request Forgery in microweber microweber version 1.2.10 and prior is vulnerable to cross-site request forgery.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/63447b369973724f0d352a006f25af6ff71ae292",
            "commit_sha":"63447b369973724f0d352a006f25af6ff71ae292",
            "patch":"SINGLE",
            "chain_ord":"['63447b369973724f0d352a006f25af6ff71ae292']",
            "before_first_fix_commit":"{'d61ad9db07ef09652a3deb24c26274da2ded1493'}",
            "last_fix_commit":"63447b369973724f0d352a006f25af6ff71ae292",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/02\/2022, 11:06:34",
            "message":"Update api.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'src\/MicroweberPackages\/Content\/routes\/api.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/63447b369973724f0d352a006f25af6ff71ae292\/src%2FMicroweberPackages%2FContent%2Froutes%2Fapi.php', 'patch': \"@@ -75,7 +75,7 @@\\n \\n         Route::post('content\/delete', function (\\\\Illuminate\\\\Http\\\\Request $request) {\\n             return mw()->content_manager->helpers->delete($request->all());\\n-        });\\n+        }); \\n \\n         Route::get('content\/get_link_admin', function (\\\\Illuminate\\\\Http\\\\Request $request) {\"}}",
            "message_norm":"update api.php",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/Content\/routes\/api.php'])",
            "num_files":1.0
        },
        {
            "index":1730,
            "vuln_id":"GHSA-fh37-cx83-q542",
            "cwe_id":"{'CWE-306', 'CWE-269', 'CWE-287'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/apache\/airflow\/commit\/21cedff205e7d62675949fda2aa4616d77232b76'}",
            "dataset":"osv",
            "summary":"Improper Authentication in Apache Airflow The lineage endpoint of the deprecated Experimental API was not protected by authentication in Airflow 2.0.0. This allowed unauthenticated users to hit that endpoint. This is low-severity issue as the attacker needs to be aware of certain parameters to pass to that endpoint and even after can just get some metadata about a DAG and a Task. This issue only affects Apache Airflow 2.0.0.",
            "published_date":"2021-06-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/airflow",
            "commit_href":"https:\/\/github.com\/apache\/airflow\/commit\/21cedff205e7d62675949fda2aa4616d77232b76",
            "commit_sha":"21cedff205e7d62675949fda2aa4616d77232b76",
            "patch":"SINGLE",
            "chain_ord":"['21cedff205e7d62675949fda2aa4616d77232b76']",
            "before_first_fix_commit":"{'4b1a6f78d132e42f1c946f53eca89789d21bdc1d'}",
            "last_fix_commit":"21cedff205e7d62675949fda2aa4616d77232b76",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/27\/2021, 21:47:45",
            "message":"Add authentication to lineage endpoint for experimental API (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)",
            "author":"Ian Carroll",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'airflow\/www\/api\/experimental\/endpoints.py': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/airflow\/raw\/21cedff205e7d62675949fda2aa4616d77232b76\/airflow%2Fwww%2Fapi%2Fexperimental%2Fendpoints.py', 'patch': '@@ -389,6 +389,7 @@ def delete_pool(name):\\n \\n \\n @api_experimental.route(\\'\/lineage\/<string:dag_id>\/<string:execution_date>\\', methods=[\\'GET\\'])\\n+@requires_authentication\\n def get_lineage(dag_id: str, execution_date: str):\\n     \"\"\"Get Lineage details for a DagRun\"\"\"\\n     # Convert string datetime into actual datetime'}}",
            "message_norm":"add authentication to lineage endpoint for experimental api (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)",
            "language":"en",
            "entities":"[('add', 'ACTION', ''), ('authentication', 'SECWORD', ''), ('#13870', 'ISSUE', ''), ('commit 24a54242d56058846c7978130b3f37ca045d5142', 'SHA', 'prefix_colon_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['airflow\/www\/api\/experimental\/endpoints.py'])",
            "num_files":1.0
        },
        {
            "index":85,
            "vuln_id":"GHSA-2cqg-q7jm-j35c",
            "cwe_id":"{'CWE-79'}",
            "score":3.9,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/9ed1442bd124710f4178992cc4eca5236c7396b9'}",
            "dataset":"osv",
            "summary":"snipe-it is vulnerable to Cross-site Scripting snipe-it is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting').",
            "published_date":"2021-11-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/9ed1442bd124710f4178992cc4eca5236c7396b9",
            "commit_sha":"9ed1442bd124710f4178992cc4eca5236c7396b9",
            "patch":"SINGLE",
            "chain_ord":"['9ed1442bd124710f4178992cc4eca5236c7396b9']",
            "before_first_fix_commit":"{'edf98cb7951a922cdef7505e1efd115f92d1afd9', '3ea209a507fbcc992e0a9152e2074709e8459b47'}",
            "last_fix_commit":"9ed1442bd124710f4178992cc4eca5236c7396b9",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/09\/2021, 04:32:02",
            "message":"Merge pull request #10286 from uberbrady\/fix_bulk_audit_xss\n\nEscape asset_tag attribute at controller level for bulk checkout",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'app\/Http\/Controllers\/Api\/AssetsController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/9ed1442bd124710f4178992cc4eca5236c7396b9\/app%2FHttp%2FControllers%2FApi%2FAssetsController.php', 'patch': \"@@ -910,7 +910,7 @@ public function audit(Request $request) {\\n             }\\n         }\\n \\n-        return response()->json(Helper::formatStandardApiResponse('error', ['asset_tag'=> e($request->input('asset_tag'))], 'Asset with tag '.$request->input('asset_tag').' not found'));\\n+        return response()->json(Helper::formatStandardApiResponse('error', ['asset_tag'=> e($request->input('asset_tag'))], 'Asset with tag '.e($request->input('asset_tag')).' not found'));\"}}",
            "message_norm":"merge pull request #10286 from uberbrady\/fix_bulk_audit_xss\n\nescape asset_tag attribute at controller level for bulk checkout",
            "language":"en",
            "entities":"[('#10286', 'ISSUE', ''), ('fix_bulk_audit_xss', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/Api\/AssetsController.php'])",
            "num_files":1.0
        },
        {
            "index":3419,
            "vuln_id":"GHSA-xfhp-gmh8-r8v2",
            "cwe_id":"{'CWE-400'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/adaltas\/node-printf\/commit\/a8502e7c9b0b22555696a2d8ef67722086413a68'}",
            "dataset":"osv",
            "summary":"Regular Expression Denial of Service (ReDoS) The package printf before 0.6.1 are vulnerable to Regular Expression Denial of Service (ReDoS) via the regex string \/\\%(?:\\(([\\w_.]+)\\)|([1-9]\\d*)\\$)?([0 +\\-\\]*)(\\*|\\d+)?(\\.)?(\\*|\\d+)?[hlL]?([\\%bscdeEfFgGioOuxX])\/g in lib\/printf.js. The vulnerable regular expression has cubic worst-case time complexity.",
            "published_date":"2021-03-19",
            "chain_len":1,
            "project":"https:\/\/github.com\/adaltas\/node-printf",
            "commit_href":"https:\/\/github.com\/adaltas\/node-printf\/commit\/a8502e7c9b0b22555696a2d8ef67722086413a68",
            "commit_sha":"a8502e7c9b0b22555696a2d8ef67722086413a68",
            "patch":"SINGLE",
            "chain_ord":"['a8502e7c9b0b22555696a2d8ef67722086413a68']",
            "before_first_fix_commit":"{'1456b115685791329c6fa6ca4237b7965f10cf82'}",
            "last_fix_commit":"a8502e7c9b0b22555696a2d8ef67722086413a68",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/10\/2021, 13:28:56",
            "message":"Fix ReDoS",
            "author":"Yeting Li",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/printf.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/adaltas\/node-printf\/raw\/a8502e7c9b0b22555696a2d8ef67722086413a68\/lib%2Fprintf.js', 'patch': '@@ -41,7 +41,7 @@ var Formatter = function(\/*String*\/ format){\\n   this._tokens = tokenize(format, this._re, this._parseDelim, this);\\n };\\n \\n-Formatter.prototype._re = \/\\\\%(?:\\\\(([\\\\w_.]+)\\\\)|([1-9]\\\\d*)\\\\$)?([0 +\\\\-\\\\#]*)([\\\\*1-9]0*)*(?:(\\\\.)(\\\\*|\\\\d+)?)?[hlL]?([\\\\%bscdeEfFgGioOuxX])\/g;\\n+Formatter.prototype._re = \/\\\\%(?:\\\\(([\\\\w_.]+)\\\\)|([1-9]\\\\d*)\\\\$)?([0 +\\\\-\\\\#]*)(\\\\*|\\\\d+)?(?:(\\\\.)(\\\\*|\\\\d+)?)?[hlL]?([\\\\%bscdeEfFgGioOuxX])\/g;\\n Formatter.prototype._parseDelim = function(mapping, intmapping, flags, minWidth, period, precision, specifier){\\n   if(mapping){\\n     this._mapped = true;'}}",
            "message_norm":"fix redos",
            "language":"pt",
            "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/printf.js'])",
            "num_files":1.0
        },
        {
            "index":1472,
            "vuln_id":"GHSA-c442-3278-rhrg",
            "cwe_id":"{'CWE-434'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/star7th\/showdoc\/commit\/49b992d4c548c8c615a92b6efe8a50c8f1083abf'}",
            "dataset":"osv",
            "summary":"Unrestricted File Upload in ShowDoc v2.9.5 Unrestricted File Upload in ShowDoc v2.9.5 allows remote attackers to execute arbitrary code via the 'file_url' parameter in the component AdminUpdateController.class.php'.",
            "published_date":"2021-09-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/star7th\/showdoc",
            "commit_href":"https:\/\/github.com\/star7th\/showdoc\/commit\/49b992d4c548c8c615a92b6efe8a50c8f1083abf",
            "commit_sha":"49b992d4c548c8c615a92b6efe8a50c8f1083abf",
            "patch":"SINGLE",
            "chain_ord":"['49b992d4c548c8c615a92b6efe8a50c8f1083abf']",
            "before_first_fix_commit":"{'8db2d13196df7067fdf2e37cf1e5e2d7aba3d748'}",
            "last_fix_commit":"49b992d4c548c8c615a92b6efe8a50c8f1083abf",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/24\/2021, 15:25:43",
            "message":"Fix security vulnerabilities",
            "author":"star7th",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'server\/Application\/Api\/Controller\/AdminUpdateController.class.php': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/star7th\/showdoc\/raw\/49b992d4c548c8c615a92b6efe8a50c8f1083abf\/server%2FApplication%2FApi%2FController%2FAdminUpdateController.class.php', 'patch': '@@ -24,6 +24,8 @@ public function checkUpdate(){\\n \\n     \/\/ \u4e0b\u8f7d\u66f4\u65b0\u4ee3\u7801\u5305\\n     public function download(){\\n+        $this->checkLogin();\\n+        $this->checkAdmin();\\n         set_time_limit(1000);\\n         ini_set(\\'memory_limit\\',\\'500M\\');\\n         $new_version = I(\"new_version\") ;\\n@@ -78,6 +80,8 @@ public function download(){\\n \\n     \/\/ \u6267\u884c\u5347\u7ea7\u64cd\u4f5c\uff0c\u5347\u7ea7\u8986\u76d6\u6587\u4ef6\\n     public function updateFiles(){\\n+        $this->checkLogin();\\n+        $this->checkAdmin();\\n         set_time_limit(1000);\\n         ini_set(\\'memory_limit\\',\\'500M\\');'}}",
            "message_norm":"fix security vulnerabilities",
            "language":"ro",
            "entities":"[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['server\/Application\/Api\/Controller\/AdminUpdateController.class.php'])",
            "num_files":1.0
        },
        {
            "index":1669,
            "vuln_id":"GHSA-f5cx-5wr3-5qrc",
            "cwe_id":"{'CWE-824'}",
            "score":7.1,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in boosted trees ### Impact\nAn attacker can generate undefined behavior via a reference binding to nullptr in `BoostedTreesCalculateBestGainsPerFeature`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesCalculateBestGainsPerFeature(\n  node_id_range=[],\n  stats_summary_list=[[1,2,3]],\n  l1=[1.0],\n  l2=[1.0],\n  tree_complexity =[1.0],\n  min_node_weight =[1.17],\n  max_splits=5)\n```\n\nA similar attack can occur in `BoostedTreesCalculateBestFeatureSplitV2`:\n\n```python\nimport tensorflow as tf\n                                                                                                                                                                                                                                                                                          \ntf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2(\n  node_id_range=[],\n  stats_summaries_list=[[1,2,3]],\n  split_types=[''],\n  candidate_feature_ids=[1,2,3,4],\n  l1=[1],     \n  l2=[1],\n  tree_complexity=[1.0],\n  min_node_weight=[1.17],\n  logits_dimension=5)\n```     \n    \nThe  [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc) does not validate the input values.\n\n### Patches\nWe have patched the issue in GitHub commit [9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad) and in commit. [429f009d2b2c09028647dd4bb7b3f6f414bbaad7](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/429f009d2b2c09028647dd4bb7b3f6f414bbaad7).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad",
            "commit_sha":"9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad",
            "patch":"MULTI",
            "chain_ord":"['9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad', '429f009d2b2c09028647dd4bb7b3f6f414bbaad7']",
            "before_first_fix_commit":"{'4f8db85aa9ab71a71e95d5acce7de52a0b195661'}",
            "last_fix_commit":"429f009d2b2c09028647dd4bb7b3f6f414bbaad7",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 19:11:33",
            "message":"Disallow empty node_id_range in tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2 and tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature\n\nPiperOrigin-RevId: 387165936\nChange-Id: I2f70341af96236b2776c2a592c917d549c1fc1e2",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 20, 'deletions': 0, 'total': 20}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc': {'additions': 20, 'deletions': 0, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/9c87c32c710d0b5b53dc6fd3bfde4046e1f7a5ad\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -51,6 +51,16 @@ class BoostedTreesCalculateBestGainsPerFeatureOp : public OpKernel {\\n     \/\/ node_id_range\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->dims() == 1,\\n+        errors::InvalidArgument(\"node_id_range must be a rank 1 tensor, but \"\\n+                                \"given node_id_range has dims of \",\\n+                                node_id_range_t->dims()));\\n+    OP_REQUIRES(context, node_id_range_t->dim_size(0) == 2,\\n+                errors::InvalidArgument(\\n+                    \"node_id_range must be a rank 1 tensor with shape=[2], but \"\\n+                    \"given node_id_range has shape \",\\n+                    node_id_range_t->dim_size(0), \" on its first dim\"));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n     const int32_t node_id_first = node_id_range(0);  \/\/ inclusive\\n     const int32_t node_id_last = node_id_range(1);   \/\/ exclusive\\n@@ -570,6 +580,16 @@ class BoostedTreesCalculateBestFeatureSplitV2 : public OpKernel {\\n     const Tensor* node_id_range_t;\\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\\n     const auto node_id_range = node_id_range_t->vec<int32>();\\n+    OP_REQUIRES(\\n+        context, node_id_range_t->dims() == 1,\\n+        errors::InvalidArgument(\"node_id_range must be a rank 1 tensor, but \"\\n+                                \"given node_id_range has dims of \",\\n+                                node_id_range_t->dims()));\\n+    OP_REQUIRES(context, node_id_range_t->dim_size(0) == 2,\\n+                errors::InvalidArgument(\\n+                    \"node_id_range must be a rank 1 tensor with shape=[2], but \"\\n+                    \"given node_id_range has shape \",\\n+                    node_id_range_t->dim_size(0), \" on its first dim\"));\\n     const int32_t node_id_first = node_id_range(0);  \/\/ Inclusive.\\n     const int32_t node_id_last = node_id_range(1);   \/\/ Exclusive.'}}",
            "message_norm":"disallow empty node_id_range in tf.raw_ops.boostedtreescalculatebestfeaturesplitv2 and tf.raw_ops.boostedtreescalculatebestgainsperfeature\n\npiperorigin-revid: 387165936\nchange-id: i2f70341af96236b2776c2a592c917d549c1fc1e2",
            "language":"en",
            "entities":"[('387165936', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":1546,
            "vuln_id":"GHSA-cfpj-3q4c-jhvr",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/718721986aa137691ee23f03638867151f74935f'}",
            "dataset":"osv",
            "summary":"Division by zero in TFLite ### Impact\nThe implementation of fully connected layers in TFLite is [vulnerable to a division by zero error](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/lite\/kernels\/fully_connected.cc#L226):\n\n```cc\nconst int batch_size = input_size \/ filter->dims->data[1];\n```\n\nAn attacker can craft a model such that `filter->dims->data[1]` is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [718721986aa137691ee23f03638867151f74935f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/718721986aa137691ee23f03638867151f74935f).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360. Concurrently, it has also been reported by Yakun Zhang of Baidu Security.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/718721986aa137691ee23f03638867151f74935f",
            "commit_sha":"718721986aa137691ee23f03638867151f74935f",
            "patch":"SINGLE",
            "chain_ord":"['718721986aa137691ee23f03638867151f74935f']",
            "before_first_fix_commit":"{'985f07145a0cab0fd6018fdfc0b221b17e0c5a88'}",
            "last_fix_commit":"718721986aa137691ee23f03638867151f74935f",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/16\/2021, 13:49:45",
            "message":"Prevent division by 0 in `fully_connected.cc`\n\nPiperOrigin-RevId: 385137282\nChange-Id: If201e69b6e0048f0be001330b4b977e2b46db2cb",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'tensorflow\/lite\/kernels\/fully_connected.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/718721986aa137691ee23f03638867151f74935f\/tensorflow%2Flite%2Fkernels%2Ffully_connected.cc', 'patch': '@@ -223,6 +223,7 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\\n   }\\n \\n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);\\n+  TF_LITE_ENSURE(context, filter->dims->data[1] != 0);\\n   const int batch_size = input_size \/ filter->dims->data[1];\\n   const int num_units = filter->dims->data[0];'}}",
            "message_norm":"prevent division by 0 in `fully_connected.cc`\n\npiperorigin-revid: 385137282\nchange-id: if201e69b6e0048f0be001330b4b977e2b46db2cb",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('385137282', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/lite\/kernels\/fully_connected.cc'])",
            "num_files":1.0
        },
        {
            "index":1945,
            "vuln_id":"GHSA-gwp4-hfv6-p7hw",
            "cwe_id":"{'CWE-502'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/ad418eeb974e357f2797aef64aa0e3ffaaa6125b'}",
            "dataset":"osv",
            "summary":"Deserialization of untrusted data in FasterXML jackson-databind A Polymorphic Typing issue was discovered in FasterXML jackson-databind 2.x before 2.9.9.2. This occurs when Default Typing is enabled (either globally or for a specific property) for an externally exposed JSON endpoint and the service has the logback jar in the classpath.",
            "published_date":"2019-08-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/FasterXML\/jackson-databind",
            "commit_href":"https:\/\/github.com\/FasterXML\/jackson-databind\/commit\/ad418eeb974e357f2797aef64aa0e3ffaaa6125b",
            "commit_sha":"ad418eeb974e357f2797aef64aa0e3ffaaa6125b",
            "patch":"SINGLE",
            "chain_ord":"['ad418eeb974e357f2797aef64aa0e3ffaaa6125b']",
            "before_first_fix_commit":"{'322ae225cbcd07178a634e548d991b0aec6b47bf'}",
            "last_fix_commit":"ad418eeb974e357f2797aef64aa0e3ffaaa6125b",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/26\/2019, 04:58:11",
            "message":"Backport #2387, #2389 fixes",
            "author":"Tatu Saloranta",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'src\/main\/java\/com\/fasterxml\/jackson\/databind\/jsontype\/impl\/SubTypeValidator.java': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/FasterXML\/jackson-databind\/raw\/ad418eeb974e357f2797aef64aa0e3ffaaa6125b\/src%2Fmain%2Fjava%2Fcom%2Ffasterxml%2Fjackson%2Fdatabind%2Fjsontype%2Fimpl%2FSubTypeValidator.java', 'patch': '@@ -89,6 +89,12 @@\\n         s.add(\"org.jdom.transform.XSLTransformer\");\\n         s.add(\"org.jdom2.transform.XSLTransformer\");\\n \\n+        \/\/ [databind#2387]: EHCache\\n+        s.add(\"net.sf.ehcache.transaction.manager.DefaultTransactionManagerLookup\");\\n+\\n+        \/\/ [databind#2389]: logback\/jndi\\n+        s.add(\"ch.qos.logback.core.db.JNDIConnectionSource\");\\n+\\n         DEFAULT_NO_DESER_CLASS_NAMES = Collections.unmodifiableSet(s);\\n     }'}}",
            "message_norm":"backport #2387, #2389 fixes",
            "language":"en",
            "entities":"[('#2387', 'ISSUE', ''), ('#2389', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/com\/fasterxml\/jackson\/databind\/jsontype\/impl\/SubTypeValidator.java'])",
            "num_files":1.0
        },
        {
            "index":1504,
            "vuln_id":"GHSA-c7fh-chf7-jr5x",
            "cwe_id":"{'CWE-770'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/fracpete\/vfsjfilechooser2\/commit\/9c9f2c317f3de5ece60a3ae28c371e9796e3909b'}",
            "dataset":"osv",
            "summary":"ReDOS in Vfsjfilechooser2 A Regular Expression Denial of Service (ReDOS) vulnerability was discovered in Vfsjfilechooser2 which occurs when the application attempts to validate crafted URIs.",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/fracpete\/vfsjfilechooser2",
            "commit_href":"https:\/\/github.com\/fracpete\/vfsjfilechooser2\/commit\/9c9f2c317f3de5ece60a3ae28c371e9796e3909b",
            "commit_sha":"9c9f2c317f3de5ece60a3ae28c371e9796e3909b",
            "patch":"SINGLE",
            "chain_ord":"['9c9f2c317f3de5ece60a3ae28c371e9796e3909b']",
            "before_first_fix_commit":"{'5a5f3487dd44066beb2351a332751932df39973b'}",
            "last_fix_commit":"9c9f2c317f3de5ece60a3ae28c371e9796e3909b",
            "chain_ord_pos":1.0,
            "commit_datetime":"10\/06\/2020, 21:18:37",
            "message":"incorporated Yeting Li's fix for Potential Regex Denial of Service (ReDoS), see https:\/\/github.com\/fracpete\/vfsjfilechooser2\/issues\/7\npasswords can now also contain special characters (eg :), which have to be URL encoded (ie %3A)",
            "author":"Peter Reutemann",
            "comments":null,
            "stats":"{'additions': 95, 'deletions': 73, 'total': 168}",
            "files":"{'src\/main\/java\/com\/googlecode\/vfsjfilechooser2\/utils\/VFSURIValidator.java': {'additions': 95, 'deletions': 73, 'changes': 168, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/fracpete\/vfsjfilechooser2\/raw\/9c9f2c317f3de5ece60a3ae28c371e9796e3909b\/src%2Fmain%2Fjava%2Fcom%2Fgooglecode%2Fvfsjfilechooser2%2Futils%2FVFSURIValidator.java', 'patch': '@@ -2,6 +2,8 @@\\n  * VFS URIs validator\\n  *\\n  * Copyright (C) 2008 Stan Love\\n+ * Copyright (C) 2020 University of Waikato, Hamilton, NZ\\n+ * Copyright (C) 2020 Yeting Li\\n  *\\n  * Licensed under the Apache License, Version 2.0 (the \"License\");\\n  * you may not use this file except in compliance with the License.\\n@@ -233,11 +235,11 @@ else if ((drive != null) && (file == null)) {\\n \\t\\t\/\/        \"(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB):\/\/(.*?:.*?@)*([^:]+)([ \\t]*:[0-9]+)*([ \\t]*:)*(\/.*)\");\\n \\t\\t\/\/\"(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB):\/\/(.+:.+@)*([^:]+)([ \\t]*:[0-9]+)*([ \\t]*:)*(\/.*)\");\\n \\t\\tPattern p_ftp2 = Pattern\\n-\\t\\t\\t\\t.compile(\"(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB):\/\/(.+:.+@)*([^:]+?\/*)([ \\t]*:[0-9]+)*([ \\t]*:)*(\/.*)\");\\n+\\t\\t\\t\\t.compile(\"(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB):\/\/([^:@]+:[^:@]+@)*([^:]+?\/*)([ ]*:[0-9]+)*([ ]*:)*(\/.*)\");\\n \\t\\tMatcher m_ftp2 = p_ftp2.matcher(_uri);\\n \\n \\t\\tPattern p_ftp3 = Pattern\\n-\\t\\t\\t\\t.compile(\"(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB):\/\/(.+:.+@)*([^:]+)([ \\t]*:[0-9]+)*([ \\t]*:)*(\/*?.*)\");\\n+\\t\\t\\t\\t.compile(\"(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB):\/\/([^:@]+:[^:@]+@)*([^:]+)([ \\t]*:[0-9]+)*([ \\t]*:)*(\/*?.*)\");\\n \\t\\tMatcher m_ftp3 = p_ftp3.matcher(_uri);\\n \\n \\t\\tif (m_ftp2.matches()) {\\n@@ -344,6 +346,26 @@ else if ((drive != null) && (file == null)) {\\n \\t\\t\\tif (local_pass.startsWith(\":\")) {\\n \\t\\t\\t\\tlocal_pass = local_pass.substring(1);\\n \\t\\t\\t}\\n+\\t\\t\\t\/\/ decode specials chars (URL encoded %XY)\\n+\\t\\t\\tif (local_pass.contains(\"%\")) {\\n+\\t\\t\\t\\tString tmp_local_pass = local_pass;\\n+\\t\\t\\t\\tStringBuilder new_local_pass = new StringBuilder();\\n+\\t\\t\\t\\twhile (tmp_local_pass.contains(\"%\")) {\\n+\\t\\t\\t\\t\\tnew_local_pass.append(tmp_local_pass.substring(0, tmp_local_pass.indexOf(\\'%\\')));\\n+\\t\\t\\t\\t\\ttmp_local_pass = tmp_local_pass.substring(tmp_local_pass.indexOf(\\'%\\'));\\n+\\t\\t\\t\\t\\tif (tmp_local_pass.length() >= 3) {\\n+\\t\\t\\t\\t\\t\\tchar c = (char) Integer.parseInt(tmp_local_pass.substring(1, 3), 16);\\n+\\t\\t\\t\\t\\t\\tnew_local_pass.append(c);\\n+\\t\\t\\t\\t\\t\\ttmp_local_pass = tmp_local_pass.substring(3);\\n+\\t\\t\\t\\t\\t}\\n+\\t\\t\\t\\t\\telse {\\n+\\t\\t\\t\\t\\t\\tbreak;\\n+\\t\\t\\t\\t\\t}\\n+\\t\\t\\t\\t}\\n+\\t\\t\\t\\tif (!tmp_local_pass.isEmpty())\\n+\\t\\t\\t\\t\\tnew_local_pass.append(tmp_local_pass);\\n+\\t\\t\\t\\tlocal_pass = new_local_pass.toString();\\n+\\t\\t\\t}\\n \\t\\t}\\n \\t\\tlocal_hostname = hostname;\\n \\t\\tlocal_port = port;\\n@@ -823,26 +845,26 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"ftp:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"ftp:\/\/user:pass%3Aa@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n \\t\\t}\\n \\t\\tv.assertEquals(v.getProtocol(), \"ftp\");\\n \\t\\tv.assertEquals(v.getUser(), \"user\");\\n-\\t\\tv.assertEquals(v.getPassword(), \"pass:\");\\n+\\t\\tv.assertEquals(v.getPassword(), \"pass:a\");\\n \\t\\tv.assertEquals(v.getHostname(), \"machine\");\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"ftp:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"ftp:\/\/user:pass%3A%3a@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n \\t\\t}\\n \\t\\tv.assertEquals(v.getProtocol(), \"ftp\");\\n \\t\\tv.assertEquals(v.getUser(), \"user\");\\n-\\t\\tv.assertEquals(v.getPassword(), \"pass:\");\\n+\\t\\tv.assertEquals(v.getPassword(), \"pass::\");\\n \\t\\tv.assertEquals(v.getHostname(), \"machine\");\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n@@ -992,7 +1014,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"FTP:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"FTP:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1004,7 +1026,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"FTP:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"FTP:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1161,7 +1183,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"sftp:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"sftp:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1173,7 +1195,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"sftp:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"sftp:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1185,7 +1207,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n \\n-\\t\\ts = \"sftp: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"sftp: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1197,7 +1219,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"sftp:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"sftp:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1209,7 +1231,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"sftp:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"sftp:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1221,7 +1243,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"sftp:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"sftp:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1233,7 +1255,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"sftp:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"sftp:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1329,7 +1351,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"SFTP:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"SFTP:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1341,7 +1363,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"SFTP:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"SFTP:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1498,7 +1520,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"http:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"http:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1510,7 +1532,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"http:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"http:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1522,7 +1544,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n \\n-\\t\\ts = \"http: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"http: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1534,7 +1556,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"http:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"http:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1546,7 +1568,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"http:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"http:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1558,7 +1580,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"http:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"http:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1570,7 +1592,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"http:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"http:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1666,7 +1688,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTP:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"HTTP:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1678,7 +1700,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"HTTP:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"HTTP:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1690,7 +1712,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n \\n-\\t\\ts = \"HTTP: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"HTTP: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1702,7 +1724,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTP:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"HTTP:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1714,7 +1736,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTP:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"HTTP:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1726,7 +1748,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTP:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"HTTP:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1738,7 +1760,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTP:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"HTTP:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1835,7 +1857,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"https:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"https:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1847,7 +1869,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"https:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"https:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1859,7 +1881,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n \\n-\\t\\ts = \"https: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"https: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1871,7 +1893,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"https:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"https:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1883,7 +1905,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"https:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"https:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1895,7 +1917,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"https:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"https:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -1907,7 +1929,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"https:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"https:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2003,7 +2025,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTPS:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"HTTPS:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2015,7 +2037,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"HTTPS:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"HTTPS:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2027,7 +2049,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n \\n-\\t\\ts = \"HTTPS: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"HTTPS: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2039,7 +2061,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTPS:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"HTTPS:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2051,7 +2073,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTPS:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"HTTPS:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2063,7 +2085,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTPS:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"HTTPS:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2075,7 +2097,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"HTTPS:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"HTTPS:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2172,7 +2194,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"webdav:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"webdav:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2184,13 +2206,13 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"webdav:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"webdav:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n \\t\\t}\\n \\n-\\t\\ts = \"webdav: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"webdav: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2202,7 +2224,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"webdav:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"webdav:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2214,7 +2236,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"webdav:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"webdav:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2226,7 +2248,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"webdav:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"webdav:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2238,7 +2260,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"webdav:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"webdav:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2334,7 +2356,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"WEBDAV:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"WEBDAV:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2346,7 +2368,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"WEBDAV:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"WEBDAV:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2358,7 +2380,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n \\n-\\t\\ts = \"WEBDAV: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"WEBDAV: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2370,7 +2392,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"WEBDAV:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"WEBDAV:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2382,7 +2404,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"WEBDAV:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"WEBDAV:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2394,7 +2416,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"WEBDAV:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"WEBDAV:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2406,7 +2428,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"WEBDAV:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"WEBDAV:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2503,7 +2525,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"smb:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"smb:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2515,7 +2537,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"smb:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"smb:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2527,7 +2549,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n \\n-\\t\\ts = \"smb: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"smb: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2539,7 +2561,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"smb:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"smb:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2551,7 +2573,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"smb:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"smb:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2563,7 +2585,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"smb:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"smb:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2575,7 +2597,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"smb:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"smb:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2671,7 +2693,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"SMB:\/\/user:pass:@machine\/the_file\"; \/\/can \":\" be part of a password?\\n+\\t\\ts = \"SMB:\/\/user:pass%3A@machine\/the_file\"; \/\/if \":\" is part of a password, it must be encoded (: -> %3A)\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2683,7 +2705,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_file\");\\n \\n-\\t\\ts = \"SMB:\/\/user:pass:@machine\/the_dir\/\";\\n+\\t\\ts = \"SMB:\/\/user:pass%3A@machine\/the_dir\/\";\\n \\n \\t\\tif (!v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2695,7 +2717,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertEquals(v.getFile(), \"\/the_dir\/\");\\n \\n-\\t\\ts = \"SMB: \/\/user:pass:@machine\/the_file\"; \/\/failure tests\\n+\\t\\ts = \"SMB: \/\/user:pass%3A@machine\/the_file\"; \/\/failure tests\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2707,7 +2729,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"SMB:\/ \/user:pass:@machine\/the_file\";\\n+\\t\\ts = \"SMB:\/ \/user:pass%3A@machine\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2719,7 +2741,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"SMB:\/ \/user:pass:@machine\";\\n+\\t\\ts = \"SMB:\/ \/user:pass%3A@machine\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2731,7 +2753,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"SMB:\/\/user:pass:@:123\/a\";\\n+\\t\\ts = \"SMB:\/\/user:pass%3A@:123\/a\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);\\n@@ -2743,7 +2765,7 @@ public static void main(String[] args) {\\n \\t\\tv.assertNull(v.getPort());\\n \\t\\tv.assertNull(v.getFile());\\n \\n-\\t\\ts = \"SMB:\/\/user:pass:@machine:a\/the_file\";\\n+\\t\\ts = \"SMB:\/\/user:pass%3A@machine:a\/the_file\";\\n \\n \\t\\tif (v.isValid(s)) {\\n \\t\\t\\tv.error_msg(s);'}}",
            "message_norm":"incorporated yeting li's fix for potential regex denial of service (redos), see https:\/\/github.com\/fracpete\/vfsjfilechooser2\/issues\/7\npasswords can now also contain special characters (eg :), which have to be url encoded (ie %3a)",
            "language":"en",
            "entities":"[('denial of service', 'SECWORD', ''), ('redos', 'SECWORD', ''), ('https:\/\/github.com\/fracpete\/vfsjfilechooser2\/issues\/7', 'URL', ''), ('passwords', 'SECWORD', ''), ('encoded', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/java\/com\/googlecode\/vfsjfilechooser2\/utils\/VFSURIValidator.java'])",
            "num_files":1.0
        },
        {
            "index":2771,
            "vuln_id":"GHSA-qjj8-32p7-h289",
            "cwe_id":"{'CWE-369'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11'}",
            "dataset":"osv",
            "summary":"Division by 0 in `ResourceGather` ### Impact\nAn attacker can trigger a crash via a floating point exception in `tf.raw_ops.ResourceGather`:\n\n```python\nimport tensorflow as tf\n\ntensor = tf.constant(value=[[]],shape=(0,1),dtype=tf.uint32)\nv = tf.Variable(tensor)\ntf.raw_ops.ResourceGather(\n  resource=v.handle,\n  indices=[0],\n  dtype=tf.uint32,\n  batch_dims=1,\n  validate_indices=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/resource_variable_ops.cc#L725-L731) computes the value of a value, `batch_size`, and then divides by it without checking that this value is not 0. \n\n### Patches\nWe have patched the issue in GitHub commit  [ac117ee8a8ea57b73d34665cdf00ef3303bc0b11](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11",
            "commit_sha":"ac117ee8a8ea57b73d34665cdf00ef3303bc0b11",
            "patch":"SINGLE",
            "chain_ord":"['ac117ee8a8ea57b73d34665cdf00ef3303bc0b11']",
            "before_first_fix_commit":"{'3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d'}",
            "last_fix_commit":"ac117ee8a8ea57b73d34665cdf00ef3303bc0b11",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/31\/2021, 05:23:28",
            "message":"Prevent division by 0 in `resource_variable_ops.cc`\n\nPiperOrigin-RevId: 387939939\nChange-Id: Ib04902d63756633999959a70613f2eaa30c2c151",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 2, 'total': 11}",
            "files":"{'tensorflow\/core\/kernels\/resource_variable_ops.cc': {'additions': 9, 'deletions': 2, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11\/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.cc', 'patch': '@@ -710,7 +710,8 @@ class ResourceGatherOp : public OpKernel {\\n         copy_functor(c->eigen_device<Device>(), tmp_indices.flat<Index>(),\\n                      indices.flat<Index>());\\n \\n-        AddBatchOffsets(&tmp_indices, params);\\n+        AddBatchOffsets(c, &tmp_indices, params);\\n+        if (!c->status().ok()) return;\\n         op_indices = &tmp_indices;\\n       }\\n \\n@@ -742,11 +743,17 @@ class ResourceGatherOp : public OpKernel {\\n   \/\/ Example: batch_dims = 1, indices = [[0, 1, 2], [0, 1, 2]]\\n   \/\/ If indexing into a params dimension of size 4, then the indices will become\\n   \/\/ [0, 1, 2, 4, 5, 6]\\n-  void AddBatchOffsets(Tensor* indices, const Tensor& params) {\\n+  void AddBatchOffsets(OpKernelContext* ctx, Tensor* indices,\\n+                       const Tensor& params) {\\n     int64_t batch_size = 1;  \/\/ The size of all batch dimensions.\\n     for (int idx = 0; idx < batch_dims_; ++idx) {\\n       batch_size *= params.dim_size(idx);\\n     }\\n+    OP_REQUIRES(\\n+        ctx, batch_size != 0,\\n+        errors::InvalidArgument(\\n+            \"Inner size of indices would result in batch_size of 0 and a \",\\n+            \"division by 0 in the implementation. This is illegal\"));\\n \\n     auto indices_flat = indices->flat<Index>();\\n     int64_t const index_inner_size = indices->NumElements() \/ batch_size;'}}",
            "message_norm":"prevent division by 0 in `resource_variable_ops.cc`\n\npiperorigin-revid: 387939939\nchange-id: ib04902d63756633999959a70613f2eaa30c2c151",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('387939939', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/resource_variable_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":1416,
            "vuln_id":"GHSA-9px9-73fg-3fqp",
            "cwe_id":"{'CWE-476'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/045deec1cbdebb27d817008ad5df94d96a08b1bf', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0a365c029e437be0349c31f8d4c9926b69fa3fa1'}",
            "dataset":"osv",
            "summary":"Null pointer dereference in Grappler's `IsConstant` ### Impact\nUnder certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place):\n\nFirst, during [constant folding](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/grappler\/optimizers\/constant_folding.cc#L3466-L3497), the `GraphDef` might not have the required nodes for the binary operation:\n\n```cc\n  NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n  NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n  \/\/ One child must be constant, and the second must be Conv op.\n  const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n  const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n```\n\nIf a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect.\n\nWe have a similar issue during [`IsIdentityConsumingSwitch`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/grappler\/mutable_graph_view.cc#L59-L74):\n\n```cc\n  NodeDef* input_node = graph.GetNode(tensor_id.node());\n  return IsSwitch(*input_node);\n```\n\n### Patches\nWe have patched the issue in GitHub commits [0a365c029e437be0349c31f8d4c9926b69fa3fa1](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0a365c029e437be0349c31f8d4c9926b69fa3fa1) and [045deec1cbdebb27d817008ad5df94d96a08b1bf](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/045deec1cbdebb27d817008ad5df94d96a08b1bf).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0a365c029e437be0349c31f8d4c9926b69fa3fa1",
            "commit_sha":"0a365c029e437be0349c31f8d4c9926b69fa3fa1",
            "patch":"MULTI",
            "chain_ord":"['0a365c029e437be0349c31f8d4c9926b69fa3fa1', '045deec1cbdebb27d817008ad5df94d96a08b1bf']",
            "before_first_fix_commit":"{'0a365c029e437be0349c31f8d4c9926b69fa3fa1'}",
            "last_fix_commit":"045deec1cbdebb27d817008ad5df94d96a08b1bf",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/13\/2021, 18:05:59",
            "message":"Prevent null pointer dereference in constant folding.\n\nUnder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\n\nPiperOrigin-RevId: 409683530\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/grappler\/optimizers\/constant_folding.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/0a365c029e437be0349c31f8d4c9926b69fa3fa1\/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fconstant_folding.cc', 'patch': '@@ -3505,6 +3505,9 @@ bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\\n \\n   NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\\n   NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\\n+  if (mul_left_child == nullptr || mul_right_child == nullptr) {\\n+    return false;\\n+  }\\n   \/\/ One child must be constant, and the second must be Conv op.\\n   const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\\n   const bool right_child_is_constant = IsReallyConstant(*mul_right_child);'}}",
            "message_norm":"prevent null pointer dereference in constant folding.\n\nunder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. during optimization phase, grappler optimizer will then dereference a null pointer.\n\npiperorigin-revid: 409683530\nchange-id: i1f10340a7ec384bc9bc587300390f1078cf5caa0",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('null pointer dereference', 'SECWORD', ''), ('409683530', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/grappler\/optimizers\/constant_folding.cc'])",
            "num_files":1.0
        },
        {
            "index":354,
            "vuln_id":"GHSA-44cw-p2hm-gpf6",
            "cwe_id":"{'CWE-297'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/opencast\/opencast\/commit\/4225bf90af74557deaf8fb6b80b0705c9621acfc'}",
            "dataset":"osv",
            "summary":"Disabled Hostname Verification in Opencast Opencast before version 8.9 and 7.9 disables HTTPS hostname verification of its HTTP client used for a large portion of Opencast's HTTP requests.\n\nHostname verification is an important part when using HTTPS to ensure that the presented certificate is valid for the host. Disabling it can allow for man-in-the-middle attacks.\n\n### Patches\n\nThis problem is fixed in Opencast 7.9 and Opencast 8.9\n\n### Self-Signed Certificates\n\nPlease be aware that fixing the problem means that Opencast will not simply accept any self-signed certificates any longer without properly importing them. If you need those, please make sure to import them into the Java key store. Better yet, get a valid certificate e.g. from [Let's Encrypt](https:\/\/letsencrypt.org).",
            "published_date":"2020-12-08",
            "chain_len":1,
            "project":"https:\/\/github.com\/opencast\/opencast",
            "commit_href":"https:\/\/github.com\/opencast\/opencast\/commit\/4225bf90af74557deaf8fb6b80b0705c9621acfc",
            "commit_sha":"4225bf90af74557deaf8fb6b80b0705c9621acfc",
            "patch":"SINGLE",
            "chain_ord":"['4225bf90af74557deaf8fb6b80b0705c9621acfc']",
            "before_first_fix_commit":"{'4b905437e90bd19700a6a6688f227f9efb20e153'}",
            "last_fix_commit":"4225bf90af74557deaf8fb6b80b0705c9621acfc",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/17\/2020, 17:03:36",
            "message":"Re-Enable Hostname Verification\n\nThis patch is a minimal change to re-enable HTTPS hostname verification\nof Opencast's HTTP client used for a large portion its HTTP requests.\n\nHostname verification is an important part when using HTTPS to ensure\nthat the presented certificate is valid for the host. Disabling it can\nallow for man-in-the-middle attacks.",
            "author":"Lars Kiesow",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 136, 'total': 137}",
            "files":"{'modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/http\/impl\/HttpClientImpl.java': {'additions': 1, 'deletions': 136, 'changes': 137, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencast\/opencast\/raw\/4225bf90af74557deaf8fb6b80b0705c9621acfc\/modules%2Fkernel%2Fsrc%2Fmain%2Fjava%2Forg%2Fopencastproject%2Fkernel%2Fhttp%2Fimpl%2FHttpClientImpl.java', 'patch': '@@ -27,28 +27,12 @@\\n import org.apache.http.client.CredentialsProvider;\\n import org.apache.http.client.methods.HttpUriRequest;\\n import org.apache.http.conn.ClientConnectionManager;\\n-import org.apache.http.conn.scheme.Scheme;\\n-import org.apache.http.conn.scheme.SchemeRegistry;\\n-import org.apache.http.conn.ssl.SSLSocketFactory;\\n-import org.apache.http.conn.ssl.X509HostnameVerifier;\\n import org.apache.http.impl.client.DefaultHttpClient;\\n import org.apache.http.params.HttpParams;\\n import org.slf4j.Logger;\\n import org.slf4j.LoggerFactory;\\n \\n import java.io.IOException;\\n-import java.security.KeyManagementException;\\n-import java.security.NoSuchAlgorithmException;\\n-import java.security.SecureRandom;\\n-import java.security.cert.CertificateException;\\n-import java.security.cert.X509Certificate;\\n-\\n-import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLException;\\n-import javax.net.ssl.SSLSession;\\n-import javax.net.ssl.SSLSocket;\\n-import javax.net.ssl.TrustManager;\\n-import javax.net.ssl.X509TrustManager;\\n \\n \/** Implementation of HttpClient that makes http requests. *\/\\n public class HttpClientImpl implements HttpClient {\\n@@ -57,7 +41,7 @@ public class HttpClientImpl implements HttpClient {\\n   private static final Logger logger = LoggerFactory.getLogger(HttpClientImpl.class);\\n \\n   \/** client used for all http requests. *\/\\n-  private DefaultHttpClient defaultHttpClient = makeHttpClient();\\n+  private DefaultHttpClient defaultHttpClient = new DefaultHttpClient();\\n \\n   \/** See org.opencastproject.kernel.http.api.HttpClient *\/\\n   @Override\\n@@ -83,123 +67,4 @@ public ClientConnectionManager getConnectionManager() {\\n     return defaultHttpClient.getConnectionManager();\\n   }\\n \\n-  \/**\\n-   * Creates a new client that can deal with all kinds of oddities with regards to http\/https connections.\\n-   *\\n-   * @return the client\\n-   *\/\\n-  private DefaultHttpClient makeHttpClient() {\\n-\\n-    DefaultHttpClient defaultHttpClient = new DefaultHttpClient();\\n-    try {\\n-      logger.debug(\"Installing forgiving hostname verifier and trust managers\");\\n-      X509TrustManager trustManager = createTrustManager();\\n-      X509HostnameVerifier hostNameVerifier = createHostNameVerifier();\\n-      SSLContext sslContext = SSLContext.getInstance(\"TLS\");\\n-      sslContext.init(null, new TrustManager[] { trustManager }, new SecureRandom());\\n-      SSLSocketFactory ssf = new SSLSocketFactory(sslContext, hostNameVerifier);\\n-      ClientConnectionManager ccm = defaultHttpClient.getConnectionManager();\\n-      SchemeRegistry sr = ccm.getSchemeRegistry();\\n-      sr.register(new Scheme(\"https\", 443, ssf));\\n-    } catch (NoSuchAlgorithmException e) {\\n-      logger.error(\"Error creating context to handle TLS connections: {}\", e.getMessage());\\n-    } catch (KeyManagementException e) {\\n-      logger.error(\"Error creating context to handle TLS connections: {}\", e.getMessage());\\n-    }\\n-\\n-    return defaultHttpClient;\\n-  }\\n-\\n-  \/**\\n-   * Returns a new trust manager which will be in charge of checking the SSL certificates that are being presented by\\n-   * SSL enabled hosts.\\n-   *\\n-   * @return the trust manager\\n-   *\/\\n-  private X509TrustManager createTrustManager() {\\n-    X509TrustManager trustManager = new X509TrustManager() {\\n-\\n-      \/**\\n-       * {@InheritDoc}\\n-       *\\n-       * @see javax.net.ssl.X509TrustManager#checkClientTrusted(java.security.cert.X509Certificate[], java.lang.String)\\n-       *\/\\n-      public void checkClientTrusted(X509Certificate[] xcs, String string) throws CertificateException {\\n-        logger.trace(\"Skipping trust check on client certificate {}\", string);\\n-      }\\n-\\n-      \/**\\n-       * {@InheritDoc}\\n-       *\\n-       * @see javax.net.ssl.X509TrustManager#checkServerTrusted(java.security.cert.X509Certificate[], java.lang.String)\\n-       *\/\\n-      public void checkServerTrusted(X509Certificate[] xcs, String string) throws CertificateException {\\n-        logger.trace(\"Skipping trust check on server certificate {}\", string);\\n-      }\\n-\\n-      \/**\\n-       * {@InheritDoc}\\n-       *\\n-       * @see javax.net.ssl.X509TrustManager#getAcceptedIssuers()\\n-       *\/\\n-      public X509Certificate[] getAcceptedIssuers() {\\n-        logger.trace(\"Returning empty list of accepted issuers\");\\n-        return null;\\n-      }\\n-\\n-    };\\n-\\n-    return trustManager;\\n-  }\\n-\\n-  \/**\\n-   * Creates a host name verifier that will make sure the SSL host\\'s name matches the name in the SSL certificate.\\n-   *\\n-   * @return the host name verifier\\n-   *\/\\n-  private X509HostnameVerifier createHostNameVerifier() {\\n-    X509HostnameVerifier verifier = new X509HostnameVerifier() {\\n-\\n-      \/**\\n-       * {@InheritDoc}\\n-       *\\n-       * @see org.apache.http.conn.ssl.X509HostnameVerifier#verify(java.lang.String, javax.net.ssl.SSLSocket)\\n-       *\/\\n-      public void verify(String host, SSLSocket ssl) throws IOException {\\n-        logger.trace(\"Skipping SSL host name check on {}\", host);\\n-      }\\n-\\n-      \/**\\n-       * {@InheritDoc}\\n-       *\\n-       * @see org.apache.http.conn.ssl.X509HostnameVerifier#verify(java.lang.String, java.security.cert.X509Certificate)\\n-       *\/\\n-      public void verify(String host, X509Certificate xc) throws SSLException {\\n-        logger.trace(\"Skipping X509 certificate host name check on {}\", host);\\n-      }\\n-\\n-      \/**\\n-       * {@InheritDoc}\\n-       *\\n-       * @see org.apache.http.conn.ssl.X509HostnameVerifier#verify(java.lang.String, java.lang.String[],\\n-       *      java.lang.String[])\\n-       *\/\\n-      public void verify(String host, String[] cns, String[] subjectAlts) throws SSLException {\\n-        logger.trace(\"Skipping DNS host name check on {}\", host);\\n-      }\\n-\\n-      \/**\\n-       * {@InheritDoc}\\n-       *\\n-       * @see javax.net.ssl.HostnameVerifier#verify(java.lang.String, javax.net.ssl.SSLSession)\\n-       *\/\\n-      public boolean verify(String host, SSLSession ssl) {\\n-        logger.trace(\"Skipping SSL session host name check on {}\", host);\\n-        return true;\\n-      }\\n-    };\\n-\\n-    return verifier;\\n-  }\\n-\\n }'}}",
            "message_norm":"re-enable hostname verification\n\nthis patch is a minimal change to re-enable https hostname verification\nof opencast's http client used for a large portion its http requests.\n\nhostname verification is an important part when using https to ensure\nthat the presented certificate is valid for the host. disabling it can\nallow for man-in-the-middle attacks.",
            "language":"en",
            "entities":"[('hostname', 'SECWORD', ''), ('hostname', 'SECWORD', ''), ('hostname', 'SECWORD', ''), ('ensure', 'ACTION', ''), ('certificate', 'SECWORD', ''), ('man-in-the-middle', 'SECWORD', ''), ('attacks', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/kernel\/src\/main\/java\/org\/opencastproject\/kernel\/http\/impl\/HttpClientImpl.java'])",
            "num_files":1.0
        },
        {
            "index":1675,
            "vuln_id":"GHSA-f655-xhvm-cwp4",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/jenkinsci\/gitlab-plugin\/commit\/24e9a99d8151b5345109ef12cddc1ab323baa4ee'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in Jenkins GitLab Plugin Jenkins GitLab Plugin 1.5.34 and earlier does not escape multiple fields inserted into the description of webhook-triggered builds, resulting in a stored cross-site scripting (XSS) vulnerability exploitable by attackers with Item\/Configure permission.",
            "published_date":"2022-07-01",
            "chain_len":1,
            "project":"https:\/\/github.com\/jenkinsci\/gitlab-plugin",
            "commit_href":"https:\/\/github.com\/jenkinsci\/gitlab-plugin\/commit\/24e9a99d8151b5345109ef12cddc1ab323baa4ee",
            "commit_sha":"24e9a99d8151b5345109ef12cddc1ab323baa4ee",
            "patch":"SINGLE",
            "chain_ord":"['24e9a99d8151b5345109ef12cddc1ab323baa4ee']",
            "before_first_fix_commit":"{'316f8aa1190c646e0cddf6614e3d881d1490be7f'}",
            "last_fix_commit":"24e9a99d8151b5345109ef12cddc1ab323baa4ee",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/29\/2022, 15:15:16",
            "message":"[SECURITY-2316]",
            "author":"Daniel Beck",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'src\/main\/resources\/com\/dabsquared\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/gitlab-plugin\/raw\/24e9a99d8151b5345109ef12cddc1ab323baa4ee\/src%2Fmain%2Fresources%2Fcom%2Fdabsquared%2Fgitlabjenkins%2Fcause%2FGitLabWebHookCause%2Fdescription.jelly', 'patch': '@@ -1,4 +1,5 @@\\n <?jelly escape-by-default=\\'true\\'?>\\n <j:jelly xmlns:j=\"jelly:core\">\\n-  <span><j:out value=\"${it.shortDescription}\" \/><\/span>\\n+  <!-- SECURITY-2316: This used to show the HTML-formatted it.shortDescription, but that does not properly neutralize user-provided input -->\\n+  <span>Triggered by GitLab Webhook<\/span>\\n <\/j:jelly>'}}",
            "message_norm":"[security-2316]",
            "language":"en",
            "entities":"[('security-2316', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/main\/resources\/com\/dabsquared\/gitlabjenkins\/cause\/GitLabWebHookCause\/description.jelly'])",
            "num_files":1.0
        },
        {
            "index":571,
            "vuln_id":"GHSA-579h-mv94-g4gp",
            "cwe_id":"{'CWE-269'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/kubernetes\/kubernetes\/commit\/2257c1ecbe3c0cf71dd50b82752ae189c94ec905'}",
            "dataset":"osv",
            "summary":"Privilege Escalation in Kubernetes In all Kubernetes versions prior to v1.10.11, v1.11.5, and v1.12.3, incorrect handling of error responses to proxied upgrade requests in the kube-apiserver allowed specially crafted requests to establish a connection through the Kubernetes API server to backend servers, then send arbitrary requests over the same connection directly to the backend, authenticated with the Kubernetes API server's TLS credentials used to establish the backend connection.",
            "published_date":"2022-02-15",
            "chain_len":1,
            "project":"https:\/\/github.com\/kubernetes\/kubernetes",
            "commit_href":"https:\/\/github.com\/kubernetes\/kubernetes\/commit\/2257c1ecbe3c0cf71dd50b82752ae189c94ec905",
            "commit_sha":"2257c1ecbe3c0cf71dd50b82752ae189c94ec905",
            "patch":"SINGLE",
            "chain_ord":"['2257c1ecbe3c0cf71dd50b82752ae189c94ec905']",
            "before_first_fix_commit":"{'b84e3dd6f80af4016acfd891ef6cc50ce05d4b5b', '396271cf52af70bc96ed378dd9ce1a865cc99647'}",
            "last_fix_commit":"2257c1ecbe3c0cf71dd50b82752ae189c94ec905",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/26\/2018, 12:26:22",
            "message":"Merge pull request #71412 from liggitt\/backend-error\n\nHandle error responses from backends",
            "author":"k8s-ci-robot",
            "comments":null,
            "stats":"{'additions': 37, 'deletions': 0, 'total': 37}",
            "files":"{'staging\/src\/k8s.io\/apimachinery\/pkg\/util\/proxy\/upgradeaware.go': {'additions': 37, 'deletions': 0, 'changes': 37, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/kubernetes\/kubernetes\/raw\/2257c1ecbe3c0cf71dd50b82752ae189c94ec905\/staging%2Fsrc%2Fk8s.io%2Fapimachinery%2Fpkg%2Futil%2Fproxy%2Fupgradeaware.go', 'patch': '@@ -17,6 +17,7 @@ limitations under the License.\\n package proxy\\n \\n import (\\n+\\t\"bufio\"\\n \\t\"bytes\"\\n \\t\"context\"\\n \\t\"fmt\"\\n@@ -271,6 +272,18 @@ func (h *UpgradeAwareHandler) tryUpgrade(w http.ResponseWriter, req *http.Reques\\n \\t}\\n \\tdefer backendConn.Close()\\n \\n+\\t\/\/ determine the http response code from the backend by reading from rawResponse+backendConn\\n+\\trawResponseCode, headerBytes, err := getResponseCode(io.MultiReader(bytes.NewReader(rawResponse), backendConn))\\n+\\tif err != nil {\\n+\\t\\tklog.V(6).Infof(\"Proxy connection error: %v\", err)\\n+\\t\\th.Responder.Error(w, req, err)\\n+\\t\\treturn true\\n+\\t}\\n+\\tif len(headerBytes) > len(rawResponse) {\\n+\\t\\t\/\/ we read beyond the bytes stored in rawResponse, update rawResponse to the full set of bytes read from the backend\\n+\\t\\trawResponse = headerBytes\\n+\\t}\\n+\\n \\t\/\/ Once the connection is hijacked, the ErrorResponder will no longer work, so\\n \\t\/\/ hijacking should be the last step in the upgrade.\\n \\trequestHijacker, ok := w.(http.Hijacker)\\n@@ -295,6 +308,17 @@ func (h *UpgradeAwareHandler) tryUpgrade(w http.ResponseWriter, req *http.Reques\\n \\t\\t}\\n \\t}\\n \\n+\\tif rawResponseCode != http.StatusSwitchingProtocols {\\n+\\t\\t\/\/ If the backend did not upgrade the request, finish echoing the response from the backend to the client and return, closing the connection.\\n+\\t\\tklog.V(6).Infof(\"Proxy upgrade error, status code %d\", rawResponseCode)\\n+\\t\\t_, err := io.Copy(requestHijackedConn, backendConn)\\n+\\t\\tif err != nil && !strings.Contains(err.Error(), \"use of closed network connection\") {\\n+\\t\\t\\tklog.Errorf(\"Error proxying data from backend to client: %v\", err)\\n+\\t\\t}\\n+\\t\\t\/\/ Indicate we handled the request\\n+\\t\\treturn true\\n+\\t}\\n+\\n \\t\/\/ Proxy the connection. This is bidirectional, so we need a goroutine\\n \\t\/\/ to copy in each direction. Once one side of the connection exits, we\\n \\t\/\/ exit the function which performs cleanup and in the process closes\\n@@ -356,6 +380,19 @@ func (h *UpgradeAwareHandler) DialForUpgrade(req *http.Request) (net.Conn, error\\n \\treturn dial(updatedReq, h.UpgradeTransport)\\n }\\n \\n+\/\/ getResponseCode reads a http response from the given reader, returns the status code,\\n+\/\/ the bytes read from the reader, and any error encountered\\n+func getResponseCode(r io.Reader) (int, []byte, error) {\\n+\\trawResponse := bytes.NewBuffer(make([]byte, 0, 256))\\n+\\t\/\/ Save the bytes read while reading the response headers into the rawResponse buffer\\n+\\tresp, err := http.ReadResponse(bufio.NewReader(io.TeeReader(r, rawResponse)), nil)\\n+\\tif err != nil {\\n+\\t\\treturn 0, nil, err\\n+\\t}\\n+\\t\/\/ return the http status code and the raw bytes consumed from the reader in the process\\n+\\treturn resp.StatusCode, rawResponse.Bytes(), nil\\n+}\\n+\\n \/\/ dial dials the backend at req.URL and writes req to it.\\n func dial(req *http.Request, transport http.RoundTripper) (net.Conn, error) {\\n \\tconn, err := DialURL(req.Context(), req.URL, transport)'}}",
            "message_norm":"merge pull request #71412 from liggitt\/backend-error\n\nhandle error responses from backends",
            "language":"no",
            "entities":"[('#71412', 'ISSUE', ''), ('error', 'FLAW', ''), ('error', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['staging\/src\/k8s.io\/apimachinery\/pkg\/util\/proxy\/upgradeaware.go'])",
            "num_files":1.0
        },
        {
            "index":7,
            "vuln_id":"GHSA-23c7-6444-399m",
            "cwe_id":"{'CWE-284', 'CWE-20'}",
            "score":7.6,
            "chain":"{'https:\/\/github.com\/MirahezeBots\/sopel-channelmgnt\/commit\/643388365f28c5cc682254ab913c401f0e53260a', 'https:\/\/github.com\/MirahezeBots\/sopel-channelmgnt\/commit\/7c96d400358221e59135f0a0be0744f3fad73856'}",
            "dataset":"osv",
            "summary":"Improper Input Validation in sopel-plugins.channelmgnt ### Impact\nOn some IRC servers, restrictions around the removal of the bot using the kick\/kickban command could be bypassed when kicking multiple users at once.\nWe also believe it may have been possible to remove users from other channels but due to the wonder that is IRC and following RfCs, We have no POC for that.\n\nFreenode is not affected.\n\n### Patches\nUpgrade to 2.0.1 or higher\n\n### Workarounds\nDo not use this plugin on networks where TARGMAX > 1.\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue on [phab](https:\/\/phab.mirahezebots.org\/maniphest\/task\/edit\/form\/1\/).\n* Email us at [staff(at)mirahezebots(dot)org](mailto:staff@mirahezebots.org)",
            "published_date":"2021-04-09",
            "chain_len":2,
            "project":"https:\/\/github.com\/MirahezeBots\/sopel-channelmgnt",
            "commit_href":"https:\/\/github.com\/MirahezeBots\/sopel-channelmgnt\/commit\/643388365f28c5cc682254ab913c401f0e53260a",
            "commit_sha":"643388365f28c5cc682254ab913c401f0e53260a",
            "patch":"MULTI",
            "chain_ord":"['643388365f28c5cc682254ab913c401f0e53260a', '7c96d400358221e59135f0a0be0744f3fad73856']",
            "before_first_fix_commit":"{'2f191af1a14fd5fbea7cba6b4ff078af253d3a05'}",
            "last_fix_commit":"7c96d400358221e59135f0a0be0744f3fad73856",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/08\/2021, 17:08:28",
            "message":"Merge pull request from GHSA-23c7-6444-399m\n\n* ban use of , & # when kicking\n\n* Update __init__.py",
            "author":"RhinosF1",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'sopel_channelmgnt\/channelmgnt\/__init__.py': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/FOSSBots\/sopel-channelmgnt\/raw\/643388365f28c5cc682254ab913c401f0e53260a\/sopel_channelmgnt%2Fchannelmgnt%2F__init__.py', 'patch': '@@ -216,6 +216,10 @@ def kick(bot, trigger):\\n             return\\n         nick = Identifier(text[1])\\n         reason = \\' \\'.join(text[2:])\\n+        if \\',\\' in str(nick):\\n+            return bot.reply(\\'Unable to kick. Kicking multiple users is not allowed.\\') \\n+        if \\'#\\' in str(nick):\\n+            return bot.reply(\\'Unable to kick. Use of # when kicking is not expected.\\')\\n         if nick != bot.config.core.nick and trigger.account in chanops:\\n             bot.write([\\'KICK\\', trigger.sender, nick, \\':\\' + reason])\\n             if dodeop:\\n@@ -263,6 +267,10 @@ def parse_host_mask(text):\\n @example(\\'.ban nick\\')\\n def ban(bot, trigger):\\n     \"\"\"Ban a user from the channel. The bot must be a channel operator for this command to work.\"\"\"\\n+    if \\',\\' in str(nick):\\n+        return bot.reply(\\'Unable to ban. Banning multiple users is not allowed.\\') \\n+    if \\'#\\' in str(nick):\\n+        return bot.reply(\\'Unable to ban. Use of # when banning is not expected.\\')\\n     makemodechange(bot, trigger, \\'+b\\', isbqmode=True)\\n \\n \\n@@ -312,6 +320,10 @@ def kickban(bot, trigger):\\n                 deopbot(trigger.sender, bot)\\n             return\\n         nick = Identifier(text[1])\\n+        if \\',\\' in str(nick):\\n+            return bot.reply(\\'Unable to kickban. Kickbanning multiple users is not allowed.\\') \\n+        if \\'#\\' in str(nick):\\n+            return bot.reply(\\'Unable to kickban. Use of # when kickbanning is not expected.\\')\\n         mask = text[2] if any(s in text[2] for s in \\'!@*\\') else \\'\\'\\n         reasonidx = 3 if mask != \\'\\' else 2\\n         reason = \\' \\'.join(text[reasonidx:])'}}",
            "message_norm":"merge pull request from ghsa-23c7-6444-399m\n\n* ban use of , & # when kicking\n\n* update __init__.py",
            "language":"en",
            "entities":"[('ghsa-23c7-6444-399m', 'VULNID', 'GHSA')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['sopel_channelmgnt\/channelmgnt\/__init__.py'])",
            "num_files":1.0
        },
        {
            "index":616,
            "vuln_id":"GHSA-5f2r-qp73-37mr",
            "cwe_id":"{'CWE-617'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/92dba16749fae36c246bec3f9ba474d9ddeb7662'}",
            "dataset":"osv",
            "summary":"`CHECK`-failures during Grappler's `SafeToRemoveIdentity` in Tensorflow ### Impact\nThe Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that [`SafeToRemoveIdentity`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc#L59-L98) would trigger `CHECK` failures.\n\n### Patches\nWe have patched the issue in GitHub commit [92dba16749fae36c246bec3f9ba474d9ddeb7662](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/92dba16749fae36c246bec3f9ba474d9ddeb7662).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-10",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/92dba16749fae36c246bec3f9ba474d9ddeb7662",
            "commit_sha":"92dba16749fae36c246bec3f9ba474d9ddeb7662",
            "patch":"SINGLE",
            "chain_ord":"['92dba16749fae36c246bec3f9ba474d9ddeb7662']",
            "before_first_fix_commit":"{'1cda4d4a26acea3814d06e7d9525772ab357fc1c'}",
            "last_fix_commit":"92dba16749fae36c246bec3f9ba474d9ddeb7662",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/11\/2021, 18:43:29",
            "message":"Prevent a null-pointer dereference \/ `CHECK`-fail in grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/92dba16749fae36c246bec3f9ba474d9ddeb7662\/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdependency_optimizer.cc', 'patch': '@@ -75,8 +75,10 @@ bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\\n   }\\n \\n   const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\\n-  CHECK(input != nullptr) << \"node = \" << node.name()\\n-                          << \" input = \" << node.input(0);\\n+  if (input == nullptr) {\\n+    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\\n+    return false;\\n+  }\\n   \/\/ Don\\'t remove Identity nodes corresponding to Variable reads or following\\n   \/\/ Recv.\\n   if (IsVariable(*input) || IsRecv(*input)) {'}}",
            "message_norm":"prevent a null-pointer dereference \/ `check`-fail in grappler.\n\npiperorigin-revid: 409187354\nchange-id: i369c249cca32e6c56ec193f0ebbf2f2768fc7d43",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('null-pointer dereference', 'SECWORD', ''), ('409187354', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/grappler\/optimizers\/dependency_optimizer.cc'])",
            "num_files":1.0
        },
        {
            "index":1942,
            "vuln_id":"GHSA-gvmf-wcx6-p974",
            "cwe_id":"{'CWE-89'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/21559c6bf0e4e828d33ff7af6e88caecb5ac6549'}",
            "dataset":"osv",
            "summary":"Improper quoting of columns when using setOrderBy() or setGroupBy() on listing classes in Pimcore ### Impact\nPimcore offers developers listing classes to make querying data easier. This listing classes also allow to order or group the results based on one or more columns which should be quoted by default. \nThe actual issue is that quoting is not done properly in both cases, so there's the theoretical possibility to inject custom SQL if the developer is using this methods with input data and not doing proper input validation in advance and  so relies on the auto-quoting being done by the listing classes. \n\n##### Example: \n```php\n\/\/ request url: https:\/\/example.com\/foo?groupBy=o_id`; SELECT SLEEP(20);--\n\n$list = new DataObject\\Car\\Listing();\n$list->setOrderKey($request->get('orderBy'));\n$list->setGroupBy($request->get('groupBy'));\n$list->load();\n```\n\n### Patches\nUpgrade to >= 10.4.4 or apply the following patch manually: \nhttps:\/\/github.com\/pimcore\/pimcore\/commit\/21559c6bf0e4e828d33ff7af6e88caecb5ac6549.patch\n\n### Workarounds\nApply this patch manually: \nhttps:\/\/github.com\/pimcore\/pimcore\/commit\/21559c6bf0e4e828d33ff7af6e88caecb5ac6549.patch\n\n### References\nhttps:\/\/github.com\/pimcore\/pimcore\/pull\/12444",
            "published_date":"2022-06-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/21559c6bf0e4e828d33ff7af6e88caecb5ac6549",
            "commit_sha":"21559c6bf0e4e828d33ff7af6e88caecb5ac6549",
            "patch":"SINGLE",
            "chain_ord":"['21559c6bf0e4e828d33ff7af6e88caecb5ac6549']",
            "before_first_fix_commit":"{'4c66ac7305ee0a5027ade88020d811761555148b'}",
            "last_fix_commit":"21559c6bf0e4e828d33ff7af6e88caecb5ac6549",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/20\/2022, 13:37:31",
            "message":"[Security] SQL Injection in Data Hub GraphQL (#12444)\n\n* [Security] SQL Injection in Data Hub GraphQL (AbstractListing)\r\n\r\n* Update lib\/Model\/Listing\/AbstractListing.php\r\n\r\nCo-authored-by: Jacob Dreesen <j.dreesen@neusta.de>\r\n\r\n* Update lib\/Model\/Listing\/AbstractListing.php\r\n\r\nCo-authored-by: mcop1 <89011527+mcop1@users.noreply.github.com>\r\n\r\nCo-authored-by: Jacob Dreesen <j.dreesen@neusta.de>\r\nCo-authored-by: Bernhard Rusch <brusch@users.noreply.github.com>",
            "author":"mcop1",
            "comments":null,
            "stats":"{'additions': 16, 'deletions': 3, 'total': 19}",
            "files":"{'lib\/Model\/Listing\/AbstractListing.php': {'additions': 16, 'deletions': 3, 'changes': 19, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/21559c6bf0e4e828d33ff7af6e88caecb5ac6549\/lib%2FModel%2FListing%2FAbstractListing.php', 'patch': '@@ -235,7 +235,7 @@ public function setOrderKey($orderKey, $quote = true)\\n                 if ($quote === false) {\\n                     $this->orderKey[] = $o;\\n                 } elseif ($this->isValidOrderKey($o)) {\\n-                    $this->orderKey[] = \\'`\\' . $o . \\'`\\';\\n+                    $this->orderKey[] = $this->quoteIdentifier($o);\\n                 }\\n             }\\n         }\\n@@ -411,8 +411,14 @@ public function setGroupBy($groupBy, $qoute = true)\\n         if ($groupBy) {\\n             $this->groupBy = $groupBy;\\n \\n-            if ($qoute && strpos($groupBy, \\'`\\') !== 0) {\\n-                $this->groupBy = \\'`\\' . $this->groupBy . \\'`\\';\\n+          if ($qoute) {\\n+                $quotedParts = [];\\n+                $parts = explode(\",\", trim($groupBy, \\'`\\'));\\n+                foreach($parts as $part) {\\n+                    $quotedParts[] = $this->quoteIdentifier(trim($part));\\n+                }\\n+\\n+                $this->groupBy = implode(\", \", $quotedParts);\\n             }\\n         }\\n \\n@@ -431,6 +437,13 @@ public function setValidOrders($validOrders)\\n         return $this;\\n     }\\n \\n+    public function quoteIdentifier(string $value): string\\n+    {\\n+        $db = Db::get();\\n+\\n+        return $db->quoteIdentifier($value);\\n+    }\\n+\\n     \/**\\n      * @param mixed $value\\n      * @param int|null $type'}}",
            "message_norm":"[security] sql injection in data hub graphql (#12444)\n\n* [security] sql injection in data hub graphql (abstractlisting)\r\n\r\n* update lib\/model\/listing\/abstractlisting.php\r\n\r\nco-authored-by: jacob dreesen <j.dreesen@neusta.de>\r\n\r\n* update lib\/model\/listing\/abstractlisting.php\r\n\r\nco-authored-by: mcop1 <89011527+mcop1@users.noreply.github.com>\r\n\r\nco-authored-by: jacob dreesen <j.dreesen@neusta.de>\r\nco-authored-by: bernhard rusch <brusch@users.noreply.github.com>",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('sql injection', 'SECWORD', ''), ('#12444', 'ISSUE', ''), ('security', 'SECWORD', ''), ('sql injection', 'SECWORD', ''), ('j.dreesen@neusta.de', 'EMAIL', ''), ('j.dreesen@neusta.de', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/Model\/Listing\/AbstractListing.php'])",
            "num_files":1.0
        },
        {
            "index":1959,
            "vuln_id":"GHSA-h24f-9mm4-w336",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/omphalos\/crud-file-server\/commit\/4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting (XSS) - Stored in crud-file-server Versions of `crud-file-server` before 0.8.0 are vulnerable to stored cross-site scripting (XSS). This is due to insufficient santiziation of filenames when directory index is served by `crud-file-server`.\n\n\n## Recommendation\n\nUpdate to version 0.8.0 or later.",
            "published_date":"2018-07-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/omphalos\/crud-file-server",
            "commit_href":"https:\/\/github.com\/omphalos\/crud-file-server\/commit\/4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa",
            "commit_sha":"4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa",
            "patch":"SINGLE",
            "chain_ord":"['4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa']",
            "before_first_fix_commit":"{'0c45fc64f0c0aeb23fe515c95e29f6485803de65'}",
            "last_fix_commit":"4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/14\/2018, 23:29:21",
            "message":"Fix not sanitizing file names rendered in html",
            "author":"omphalos",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'crud-file-server.js': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/omphalos\/crud-file-server\/raw\/4155bfe068bf211b49a0b3ffd06e78cbaf1b40fa\/crud-file-server.js', 'patch': '@@ -140,7 +140,9 @@ exports.handleRequest = function(vpath, path, req, res, readOnly, logHeadRequest\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvar name = results[f].name;\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tvar normalized = url + \\'\/\\' + name;\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\twhile(normalized[0] == \\'\/\\') { normalized = normalized.slice(1, normalized.length); }\\r\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tres.write(\\'\\\\r\\\\n<p><a href=\"\/\\' + normalized + \\'\">\\' + name + \\'<\/a><\/p>\\');\\r\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tif(normalized.indexOf(\\'\"\\') >= 0) throw new Error(\\'unsupported file name\\')\\r\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tname = name.replace(\/&\/g, \\'&amp;\\').replace(\/<\/g, \\'&lt;\\').replace(\/>\/g, \\'&gt;\\');\\r\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tres.write(\\'\\\\r\\\\n<p><a href=\"\/\\' + normalized + \\'\"><span>\\' + name + \\'<\/span><\/a><\/p>\\');\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t}\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tres.end(\\'\\\\r\\\\n<\/body><\/html>\\');\\r\\n \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t}'}}",
            "message_norm":"fix not sanitizing file names rendered in html",
            "language":"en",
            "entities":"[('sanitizing', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['crud-file-server.js'])",
            "num_files":1.0
        },
        {
            "index":96,
            "vuln_id":"GHSA-2h63-qp69-fwvw",
            "cwe_id":"{'CWE-918', 'CWE-20'}",
            "score":8.2,
            "chain":"{'https:\/\/github.com\/apache\/xmlgraphics-batik\/commit\/0ef5b661a1f77772d1110877ea9e0287987098f6'}",
            "dataset":"osv",
            "summary":"Server-side request forgery (SSRF) in Apache Batik Apache Batik 1.13 is vulnerable to server-side request forgery, caused by improper input validation by the NodePickerPanel. By using a specially-crafted argument, an attacker could exploit this vulnerability to cause the underlying server to make arbitrary GET requests.",
            "published_date":"2022-01-06",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/xmlgraphics-batik",
            "commit_href":"https:\/\/github.com\/apache\/xmlgraphics-batik\/commit\/0ef5b661a1f77772d1110877ea9e0287987098f6",
            "commit_sha":"0ef5b661a1f77772d1110877ea9e0287987098f6",
            "patch":"SINGLE",
            "chain_ord":"['0ef5b661a1f77772d1110877ea9e0287987098f6']",
            "before_first_fix_commit":"{'f16e092d0c2ccee07360446e0d4adaa4be5daa1b'}",
            "last_fix_commit":"0ef5b661a1f77772d1110877ea9e0287987098f6",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/02\/2020, 13:59:37",
            "message":"BATIK-1284: Dont load DTDs in NodePickerPanel\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/xmlgraphics\/batik\/trunk@1878396 13f79535-47bb-0310-9956-ffa450edef68",
            "author":"Simon Steiner",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'batik-svgbrowser\/src\/main\/java\/org\/apache\/batik\/apps\/svgbrowser\/NodePickerPanel.java': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/xmlgraphics-batik\/raw\/0ef5b661a1f77772d1110877ea9e0287987098f6\/batik-svgbrowser%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fbatik%2Fapps%2Fsvgbrowser%2FNodePickerPanel.java', 'patch': '@@ -847,8 +847,10 @@ private Element parseXml(String xmlString) {\\n         Document doc = null;\\n         DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\\n         try {\\n-            javax.xml.parsers.DocumentBuilder parser = factory\\n-                    .newDocumentBuilder();\\n+            factory.setFeature(\"http:\/\/xml.org\/sax\/features\/external-general-entities\", false);\\n+            factory.setFeature(\"http:\/\/xml.org\/sax\/features\/external-parameter-entities\", false);\\n+            factory.setFeature(\"http:\/\/apache.org\/xml\/features\/nonvalidating\/load-external-dtd\", false);\\n+            javax.xml.parsers.DocumentBuilder parser = factory.newDocumentBuilder();\\n             parser.setErrorHandler(new ErrorHandler() {\\n                 public void error(SAXParseException exception)\\n                         throws SAXException {'}}",
            "message_norm":"batik-1284: dont load dtds in nodepickerpanel\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/xmlgraphics\/batik\/trunk@1878396 13f79535-47bb-0310-9956-ffa450edef68",
            "language":"da",
            "entities":"[('https:\/\/svn.apache.org\/repos\/asf\/xmlgraphics\/batik\/trunk@1878396', 'URL', ''), ('13f79535', 'SHA', 'generic_sha'), ('ffa450edef68', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['batik-svgbrowser\/src\/main\/java\/org\/apache\/batik\/apps\/svgbrowser\/NodePickerPanel.java'])",
            "num_files":1.0
        },
        {
            "index":3363,
            "vuln_id":"GHSA-x4g7-fvjj-prg8",
            "cwe_id":"{'CWE-369'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cfa91be9863a91d5105a3b4941096044ab32036b'}",
            "dataset":"osv",
            "summary":"Division by 0 in `QuantizedConv2D` ### Impact\nAn attacker can trigger a division by 0 in `tf.raw_ops.QuantizedConv2D`:\n\n```python\nimport tensorflow as tf\n\ninput = tf.zeros([1, 1, 1, 1], dtype=tf.quint8)\nfilter = tf.constant([], shape=[1, 0, 1, 1], dtype=tf.quint8)\nmin_input = tf.constant(0.0)\nmax_input = tf.constant(0.0001)\nmin_filter = tf.constant(0.0)\nmax_filter = tf.constant(0.0001)\nstrides = [1, 1, 1, 1]\npadding = \"SAME\"               \n                               \n\ntf.raw_ops.QuantizedConv2D(input=input, filter=filter, min_input=min_input, max_input=max_input, min_filter=min_filter, max_filter=max_filter, strides=strides, padding=padding)\n```\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/00e9a4d67d76703fa1aee33dac582acf317e0e81\/tensorflow\/core\/kernels\/quantized_conv_ops.cc#L257-L259) does a division by a quantity that is controlled by the caller: \n\n```cc\nconst int filter_value_count = filter_width * filter_height * input_depth;\nconst int64 patches_per_chunk = kMaxChunkSize \/ (filter_value_count * sizeof(T1));\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [cfa91be9863a91d5105a3b4941096044ab32036b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cfa91be9863a91d5105a3b4941096044ab32036b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cfa91be9863a91d5105a3b4941096044ab32036b",
            "commit_sha":"cfa91be9863a91d5105a3b4941096044ab32036b",
            "patch":"SINGLE",
            "chain_ord":"['cfa91be9863a91d5105a3b4941096044ab32036b']",
            "before_first_fix_commit":"{'00e9a4d67d76703fa1aee33dac582acf317e0e81'}",
            "last_fix_commit":"cfa91be9863a91d5105a3b4941096044ab32036b",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/20\/2021, 01:58:47",
            "message":"Fix one FPE and remove two CHECK-fails.\n\nPiperOrigin-RevId: 369349640\nChange-Id: I1fedbfc2b5bab635c5cb51f103d7c9176f79831a",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 11, 'deletions': 2, 'total': 13}",
            "files":"{'tensorflow\/core\/kernels\/quantized_conv_ops.cc': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/cfa91be9863a91d5105a3b4941096044ab32036b\/tensorflow%2Fcore%2Fkernels%2Fquantized_conv_ops.cc', 'patch': '@@ -18,6 +18,8 @@ limitations under the License.\\n #include <algorithm>\\n #include <vector>\\n \\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n+\\n #define EIGEN_USE_THREADS\\n \\n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\\n@@ -227,8 +229,12 @@ class Im2ColConvFunctor {\\n       return;\\n     }\\n \\n-    CHECK_GT(output_width, 0);\\n-    CHECK_GT(output_height, 0);\\n+    OP_REQUIRES(\\n+        context, output_width > 0,\\n+        errors::InvalidArgument(\"output_width must be strictly positive\"));\\n+    OP_REQUIRES(\\n+        context, output_height > 0,\\n+        errors::InvalidArgument(\"output_height must be strictly positive\"));\\n     int filter_left_offset;\\n     int filter_top_offset;\\n     if (padding == VALID) {\\n@@ -255,6 +261,9 @@ class Im2ColConvFunctor {\\n     \/\/ by the width, then the height. This is the standard memory order in the\\n     \/\/ image world if it helps to visualize it.\\n     const int filter_value_count = filter_width * filter_height * input_depth;\\n+    OP_REQUIRES(context, filter_value_count > 0,\\n+                errors::InvalidArgument(\\n+                    \"filter patch must contain at least one element\"));\\n     const int64 patches_per_chunk =\\n         kMaxChunkSize \/ (filter_value_count * sizeof(T1));\\n     const int64 chunk_value_count ='}}",
            "message_norm":"fix one fpe and remove two check-fails.\n\npiperorigin-revid: 369349640\nchange-id: i1fedbfc2b5bab635c5cb51f103d7c9176f79831a",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('remove', 'ACTION', ''), ('369349640', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_conv_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":1443,
            "vuln_id":"GHSA-9w9f-6mg8-jp7w",
            "cwe_id":"{'CWE-306'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/blevesearch\/bleve\/commit\/1c7509d6a17d36f265c90b4e8f4e3a3182fe79ff'}",
            "dataset":"osv",
            "summary":"Missing Role Based Access Control for the REST handlers in bleve\/http package ### Impact\n_What kind of vulnerability is it? Who is impacted?_\n\nBleve includes HTTP utilities under bleve\/http package, that are used by its sample application. \n(https:\/\/github.com\/blevesearch\/bleve-explorer)\nThese HTTP methods paves way for exploitation of a node\u2019s filesystem where the bleve index resides, \nif the user has used bleve\u2019s own HTTP (bleve\/http) handlers for exposing the access to the indexes. \nFor instance, the CreateIndexHandler (http\/index_create.go) and DeleteIndexHandler (http\/index_delete.go) \nenable an attacker to create a bleve index (directory structure) anywhere where the user running the server \nhas the write permissions and to delete recursively any directory owned by the same user account.\n \nUsers who have used the bleve\/http package for exposing access to bleve index without the explicit \nhandling for the Role Based Access Controls(RBAC) of the index assets would be impacted.\n\n\n### Patches\n_Has the problem been patched? What versions should users upgrade to?_\n\n**No**. The http package is purely intended to be used for demonstration purposes. \nAnd bleve is never designed to be handling the RBACs or it was ever advertised to be used in that way. \nHence the collaborators of this project have decided to stay away from adding any authentication or \nauthorization to bleve project at the moment.\n\n### Workarounds\n_Is there a way for users to fix or remediate the vulnerability without upgrading?_\n\nThe bleve\/http package is mainly for demonstration purposes and it lacks exhaustive validation of the user \ninputs as well as any authentication and authorization measures. \nSo it is recommended to not use that in production use cases.\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue [here](https:\/\/github.com\/blevesearch\/bleve\/issues).\n* Email us at [mailto:security@couchbase.com, fts-team@couchbase.com].",
            "published_date":"2022-06-03",
            "chain_len":1,
            "project":"https:\/\/github.com\/blevesearch\/bleve",
            "commit_href":"https:\/\/github.com\/blevesearch\/bleve\/commit\/1c7509d6a17d36f265c90b4e8f4e3a3182fe79ff",
            "commit_sha":"1c7509d6a17d36f265c90b4e8f4e3a3182fe79ff",
            "patch":"SINGLE",
            "chain_ord":"['1c7509d6a17d36f265c90b4e8f4e3a3182fe79ff']",
            "before_first_fix_commit":"{'3b8127049e42df67c204bfac1d0b037b952e9a55'}",
            "last_fix_commit":"1c7509d6a17d36f265c90b4e8f4e3a3182fe79ff",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/01\/2022, 15:49:02",
            "message":"Link security advisory to README (#1694)",
            "author":"Abhinav Dangeti",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 4, 'total': 10}",
            "files":"{'http\/README.md': {'additions': 6, 'deletions': 4, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/blevesearch\/bleve\/raw\/1c7509d6a17d36f265c90b4e8f4e3a3182fe79ff\/http%2FREADME.md', 'patch': '@@ -3,8 +3,10 @@\\n This http package is purely for the demonstration purposes and is used by sample\\n applications like https:\/\/github.com\/blevesearch\/bleve-explorer.\\n \\n-Please be aware that the http handler implementations neither provide exhaustive \\n-user input validations nor authentication or authorization of the user access. \\n+Please be aware that the http handler implementations neither provide exhaustive\\n+user input validations nor authentication or authorization of the user access.\\n \\n-So, it is recommended to remain cautious against the use of the http package in \\n-production use cases.\\n\\\\ No newline at end of file\\n+So, it is strongly recommended that users exercise caution while using the http\\n+package in production situations.\\n+\\n+[Here](https:\/\/github.com\/blevesearch\/bleve\/security\/advisories\/GHSA-9w9f-6mg8-jp7w) is the security advisory on this.'}}",
            "message_norm":"link security advisory to readme (#1694)",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('#1694', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['http\/README.md'])",
            "num_files":1.0
        },
        {
            "index":3502,
            "vuln_id":"GHSA-xw79-hhv6-578c",
            "cwe_id":"{'CWE-79'}",
            "score":0.0,
            "chain":"{'https:\/\/github.com\/zeit\/serve-handler\/commit\/65b4d4183a31a8076c78c40118acb0ca1b64f620'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting in serve Versions of `serve` prior to 10.0.2 are vulnerable to Cross-Site Scripting (XSS). The package does not encode output, allowing attackers to execute arbitrary JavaScript in the victim's browser if user-supplied input is rendered.\n\n\n## Recommendation\n\nUpgrade to version 10.0.2 or later.",
            "published_date":"2020-09-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/zeit\/serve-handler",
            "commit_href":"https:\/\/github.com\/zeit\/serve-handler\/commit\/65b4d4183a31a8076c78c40118acb0ca1b64f620",
            "commit_sha":"65b4d4183a31a8076c78c40118acb0ca1b64f620",
            "patch":"SINGLE",
            "chain_ord":"['65b4d4183a31a8076c78c40118acb0ca1b64f620']",
            "before_first_fix_commit":"{'2b3be81a46e09fc5f8bc2c69a5311d439dac74af'}",
            "last_fix_commit":"65b4d4183a31a8076c78c40118acb0ca1b64f620",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/24\/2018, 17:05:10",
            "message":"Interpolate template variables correctly (#64)",
            "author":"Leo Lamprecht",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
            "files":"{'src\/directory.jst': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/vercel\/serve-handler\/raw\/65b4d4183a31a8076c78c40118acb0ca1b64f620\/src%2Fdirectory.jst', 'patch': '@@ -4,7 +4,7 @@\\n     <meta charset=\"utf-8\">\\n     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n \\n-    <title>Files within {{=it.directory}}<\/title>\\n+    <title>Files within {{!it.directory}}<\/title>\\n \\n \\t<style>\\n \\t\\tbody {\\n@@ -187,7 +187,7 @@\\n           <i>Index of&nbsp;<\/i>\\n \\n           {{~it.paths :value:index}}\\n-            <a href=\"\/{{=value.url}}\">{{=value.name}}<\/a>\\n+            <a href=\"\/{{!value.url}}\">{{!value.name}}<\/a>\\n           {{~}}\\n         <\/h1>\\n \\n@@ -197,9 +197,9 @@\\n       <ul id=\"files\">\\n         {{~it.files :value:index}}\\n           <li>\\n-            <a href=\"{{=value.relative}}\" title=\"{{=value.title}}\" class=\"{{=value.ext}}\">{{=value.base}}<\/a>\\n+            <a href=\"{{!value.relative}}\" title=\"{{!value.title}}\" class=\"{{!value.ext}}\">{{!value.base}}<\/a>\\n \\t\\t\\t{{? value.size}}\\n-\\t\\t\\t\\t<i>{{=value.size}}<\/i>\\n+\\t\\t\\t\\t<i>{{!value.size}}<\/i>\\n \\t\\t\\t{{?}}\\n           <\/li>\\n         {{~}}'}}",
            "message_norm":"interpolate template variables correctly (#64)",
            "language":"en",
            "entities":"[('#64', 'ISSUE', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/directory.jst'])",
            "num_files":1.0
        },
        {
            "index":1429,
            "vuln_id":"GHSA-9rpc-5v9q-5r7f",
            "cwe_id":"{'CWE-665', 'CWE-20'}",
            "score":3.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1d04d7d93f4ed3854abf75d6b712d72c3f70d6b6'}",
            "dataset":"osv",
            "summary":"Incomplete validation in `SparseReshape` ### Impact\nIncomplete validation in `SparseReshape` results in a denial of service based on a `CHECK`-failure.\n\n```python\nimport tensorflow as tf\n\ninput_indices = tf.constant(41, shape=[1, 1], dtype=tf.int64)\ninput_shape = tf.zeros([11], dtype=tf.int64)\nnew_shape = tf.zeros([1], dtype=tf.int64)\n\ntf.raw_ops.SparseReshape(input_indices=input_indices,\n    input_shape=input_shape,\n    new_shape=new_shape)\n``` \n    \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e87b51ce05c3eb172065a6ea5f48415854223285\/tensorflow\/core\/kernels\/sparse_reshape_op.cc#L40) has no validation that the input arguments specify a valid sparse tensor.\n\n### Patches \nWe have patched the issue in GitHub commit [1d04d7d93f4ed3854abf75d6b712d72c3f70d6b6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1d04d7d93f4ed3854abf75d6b712d72c3f70d6b6).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2 and TensorFlow 2.3.3, as these are the only affected versions.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1d04d7d93f4ed3854abf75d6b712d72c3f70d6b6",
            "commit_sha":"1d04d7d93f4ed3854abf75d6b712d72c3f70d6b6",
            "patch":"SINGLE",
            "chain_ord":"['1d04d7d93f4ed3854abf75d6b712d72c3f70d6b6']",
            "before_first_fix_commit":"{'8d78df9997a8537a2f389adc2cfdc36e71da0665'}",
            "last_fix_commit":"1d04d7d93f4ed3854abf75d6b712d72c3f70d6b6",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/29\/2021, 22:30:30",
            "message":"Fix heap-buffer-overflow issue with `tf.raw_ops.SparseReshape`.\n\nPiperOrigin-RevId: 371218558\nChange-Id: I6a6dc5bf15b50a1d05bdd95e9ba347cb39f40f45",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'tensorflow\/core\/kernels\/sparse_reshape_op.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1d04d7d93f4ed3854abf75d6b712d72c3f70d6b6\/tensorflow%2Fcore%2Fkernels%2Fsparse_reshape_op.cc', 'patch': '@@ -26,6 +26,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/kernels\/reshape_util.h\"\\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n \\n namespace tensorflow {\\n \\n@@ -38,6 +39,17 @@ class SparseReshapeOp : public OpKernel {\\n   explicit SparseReshapeOp(OpKernelConstruction* context) : OpKernel(context) {}\\n \\n   void Compute(OpKernelContext* context) override {\\n+    const Tensor& input_indices_in = context->input(0);\\n+    const Tensor& input_shape_in = context->input(1);\\n+\\n+    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\\n+                errors::InvalidArgument(\"Input must be a matrix.\"));\\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\\n+                errors::InvalidArgument(\"Input shape must be a vector.\"));\\n+    OP_REQUIRES(context,\\n+                input_indices_in.dim_size(1) == input_shape_in.dim_size(0),\\n+                errors::InvalidArgument(\\n+                    \"Input tensor rank must match input shape length.\"));\\n     ReshapeSparseTensor<Device>(context, context->input(0), context->input(1),\\n                                 context->input(2), 0 \/* output indices index *\/,\\n                                 1 \/* output shape index *\/);'}}",
            "message_norm":"fix heap-buffer-overflow issue with `tf.raw_ops.sparsereshape`.\n\npiperorigin-revid: 371218558\nchange-id: i6a6dc5bf15b50a1d05bdd95e9ba347cb39f40f45",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371218558', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_reshape_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3071,
            "vuln_id":"GHSA-v7m9-9497-p9gr",
            "cwe_id":"{'CWE-863'}",
            "score":6.8,
            "chain":"{'https:\/\/github.com\/jupyterhub\/kubespawner\/commit\/3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0'}",
            "dataset":"osv",
            "summary":"Possible pod name collisions in jupyterhub-kubespawner ### Impact\n_What kind of vulnerability is it? Who is impacted?_\n\nJupyterHub deployments using:\n\n- KubeSpawner <= 0.11.1 (e.g. zero-to-jupyterhub 0.9.0) and\n- enabled named_servers (not default), and\n- an Authenticator that allows:\n  - usernames with hyphens or other characters that require escape (e.g. `user-hyphen` or `user@email`), and\n  - usernames which may match other usernames up to but not including the escaped character (e.g. `user` in the above cases)\n\nIn this circumstance, certain usernames will be able to craft particular server names which will grant them access to the default server of other users who have matching usernames.\n\n### Patches\n_Has the problem been patched? What versions should users upgrade to?_\n\nPatch will be released in kubespawner 0.12 and zero-to-jupyterhub 0.9.1\n\n### Workarounds\n_Is there a way for users to fix or remediate the vulnerability without upgrading?_\n\n#### KubeSpawner\n\nSpecify configuration:\n\nfor KubeSpawner\n```python\nfrom traitlets import default\nfrom kubespawner import KubeSpawner\n\nclass PatchedKubeSpawner(KubeSpawner):\n    @default(\"pod_name_template\")\n    def _default_pod_name_template(self):\n        if self.name:\n            return \"jupyter-{username}-{servername}\"\n        else:\n            return \"jupyter-{username}\"\n\n    @default(\"pvc_name_template\")\n    def _default_pvc_name_template(self):\n        if self.name:\n            return \"claim-{username}-{servername}\"\n        else:\n            return \"claim-{username}\"\n\nc.JupyterHub.spawner_class = PatchedKubeSpawner\n```\n\n**Note for KubeSpawner:** this configuration will behave differently before and after the upgrade, so will need to be removed when upgrading. Only apply this configuration while still using KubeSpawner \u2264 0.11.1 and remove it after upgrade to ensure consistent pod and pvc naming.\n\nChanging the name template means pvcs for named servers will have different names. This will result in orphaned PVCs for named servers across Hub upgrade! This may appear as data loss for users, depending on configuration, but the orphaned PVCs will still be around and data can be migrated manually (or new PVCs created manually to reference existing PVs) before deleting the old PVCs and\/or PVs.\n\n### References\n_Are there any links users can visit to find out more?_\n\n### For more information\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [kubespawner](https:\/\/github.com\/jupyterhub\/kubespawner)\n* Email us at [security@ipython.org](mailto:security@ipython.org)\n\nCredit: Jining Huang",
            "published_date":"2020-07-22",
            "chain_len":1,
            "project":"https:\/\/github.com\/jupyterhub\/kubespawner",
            "commit_href":"https:\/\/github.com\/jupyterhub\/kubespawner\/commit\/3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0",
            "commit_sha":"3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0",
            "patch":"SINGLE",
            "chain_ord":"['3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0']",
            "before_first_fix_commit":"{'b7f55eae3d5afb6ac9f2facf76f46239e2f2a38a'}",
            "last_fix_commit":"3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/03\/2020, 07:48:42",
            "message":"move delimiter to pvc\/pod name templates\n\nand note version change",
            "author":"Min RK",
            "comments":null,
            "stats":"{'additions': 28, 'deletions': 16, 'total': 44}",
            "files":"{'kubespawner\/spawner.py': {'additions': 28, 'deletions': 16, 'changes': 44, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jupyterhub\/kubespawner\/raw\/3dfe870a7f5e98e2e398b01996ca6b8eff4bb1d0\/kubespawner%2Fspawner.py', 'patch': '@@ -307,16 +307,25 @@ def _namespace_default(self):\\n     )\\n \\n     pod_name_template = Unicode(\\n-        \\'jupyter-{username}{servername}\\',\\n+        \\'jupyter-{username}--{servername}\\',\\n         config=True,\\n         help=\"\"\"\\n         Template to use to form the name of user\\'s pods.\\n \\n-        `{username}` is expanded to the escaped, dns-label safe username.\\n+        `{username}` is expanded to the escaped, dns-label-safe username.\\n+        `{servername}` is expanded to the escaped, dns-label-safe server name, if any.\\n+\\n+        Trailing `-` characters are stripped for safe handling of empty server names (user default servers).\\n \\n         This must be unique within the namespace the pods are being spawned\\n         in, so if you are running multiple jupyterhubs spawning in the\\n         same namespace, consider setting this to be something more unique.\\n+\\n+        .. versionchanged:: 0.12\\n+            `--` delimiter added to the template,\\n+            where it was implicitly added to the `servername` field before.\\n+            Additionally, `username--servername` delimiter was `-` instead of `--`,\\n+            allowing collisions in certain circumstances.\\n         \"\"\"\\n     )\\n \\n@@ -332,16 +341,25 @@ def _namespace_default(self):\\n     )\\n \\n     pvc_name_template = Unicode(\\n-        \\'claim-{username}{servername}\\',\\n+        \\'claim-{username}--{servername}\\',\\n         config=True,\\n         help=\"\"\"\\n         Template to use to form the name of user\\'s pvc.\\n \\n         `{username}` is expanded to the escaped, dns-label safe username.\\n+        `{servername}` is expanded to the escaped, dns-label-safe server name, if any.\\n+\\n+        Trailing `-` characters are stripped for safe handling of empty server names (user default servers).\\n \\n         This must be unique within the namespace the pvc are being spawned\\n         in, so if you are running multiple jupyterhubs spawning in the\\n         same namespace, consider setting this to be something more unique.\\n+\\n+        .. versionchanged:: 0.12\\n+            `--` delimiter added to the template,\\n+            where it was implicitly added to the `servername` field before.\\n+            Additionally, `username--servername` delimiter was `-` instead of `--`,\\n+            allowing collisions in certain circumstances.\\n         \"\"\"\\n     )\\n \\n@@ -1313,28 +1331,22 @@ def _expand_user_properties(self, template):\\n         # Note: \\'-\\' is not in safe_chars, as it is being used as escape character\\n         safe_chars = set(string.ascii_lowercase + string.digits)\\n \\n-        # Set servername based on whether named-server initialised\\n-        if self.name:\\n-            # use two -- to ensure no collision possibilities\\n-            # are created by an ambiguous boundary between username and\\n-            # servername.\\n-            # -- cannot occur in a string where - is the escape char.\\n-            servername = \\'--{}\\'.format(self.name)\\n-            safe_servername = \\'--{}\\'.format(escapism.escape(self.name, safe=safe_chars, escape_char=\\'-\\').lower())\\n-        else:\\n-            servername = \\'\\'\\n-            safe_servername = \\'\\'\\n+        raw_servername = self.name or \\'\\'\\n+        safe_servername = escapism.escape(raw_servername, safe=safe_chars, escape_char=\\'-\\').lower()\\n \\n         legacy_escaped_username = \\'\\'.join([s if s in safe_chars else \\'-\\' for s in self.user.name.lower()])\\n         safe_username = escapism.escape(self.user.name, safe=safe_chars, escape_char=\\'-\\').lower()\\n-        return template.format(\\n+        rendered = template.format(\\n             userid=self.user.id,\\n             username=safe_username,\\n             unescaped_username=self.user.name,\\n             legacy_escape_username=legacy_escaped_username,\\n             servername=safe_servername,\\n-            unescaped_servername=servername,\\n+            unescaped_servername=raw_servername,\\n         )\\n+        # strip trailing - delimiter in case of empty servername.\\n+        # k8s object names cannot have trailing -\\n+        return rendered.rstrip(\"-\")\\n \\n     def _expand_all(self, src):\\n         if isinstance(src, list):'}}",
            "message_norm":"move delimiter to pvc\/pod name templates\n\nand note version change",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['kubespawner\/spawner.py'])",
            "num_files":1.0
        },
        {
            "index":2001,
            "vuln_id":"GHSA-h6fg-mjxg-hqq4",
            "cwe_id":"{'CWE-197', 'CWE-754'}",
            "score":9.0,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ca8c013b5e97b1373b3bb1c97ea655e69f31a575', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/27b417360cbd671ef55915e4bb6bb06af8b8a832'}",
            "dataset":"osv",
            "summary":"Integer truncation in Shard API usage ### Impact\nThe `Shard` API in TensorFlow expects the last argument to be a function taking two `int64` (i.e., `long long`) arguments:\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/core\/util\/work_sharder.h#L59-L60\n\nHowever, there are several places in TensorFlow where a lambda taking `int` or `int32` arguments is being used:\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/core\/kernels\/random_op.cc#L204-L205\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/core\/kernels\/random_op.cc#L317-L318\n\nIn these cases, if the amount of work to be parallelized is large enough, integer truncation occurs. Depending on how the two arguments of the lambda are used, this can result in segfaults, read\/write outside of heap allocated arrays, stack overflows, or data corruption.\n\n### Patches\nWe have patched the issue in 27b417360cbd671ef55915e4bb6bb06af8b8a832 and ca8c013b5e97b1373b3bb1c97ea655e69f31a575. We will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2020-09-25",
            "chain_len":2,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/27b417360cbd671ef55915e4bb6bb06af8b8a832",
            "commit_sha":"27b417360cbd671ef55915e4bb6bb06af8b8a832",
            "patch":"MULTI",
            "chain_ord":"['27b417360cbd671ef55915e4bb6bb06af8b8a832', 'ca8c013b5e97b1373b3bb1c97ea655e69f31a575']",
            "before_first_fix_commit":"{'b9465214656c42204d86945eca80d211f50043a1'}",
            "last_fix_commit":"ca8c013b5e97b1373b3bb1c97ea655e69f31a575",
            "chain_ord_pos":1.0,
            "commit_datetime":"09\/19\/2020, 00:21:24",
            "message":"Prevent `int64` to `int` truncation in `Shard` API usage.\n\nThe function argument in `Shard` must be a function of two `int64` arguments. However, we are passing in a function with two `int` arguments. Thus, for large workloads, these arguments get truncated from positive `int64` values to negative `int` ones, resulting in a buffer out of bounds write.\n\nPiperOrigin-RevId: 332557334\nChange-Id: I236c9a2e7f53580e520571da8ba941a3aa9fa0b5",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'tensorflow\/core\/kernels\/random_op.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/27b417360cbd671ef55915e4bb6bb06af8b8a832\/tensorflow%2Fcore%2Fkernels%2Frandom_op.cc', 'patch': '@@ -202,7 +202,7 @@ class RandomGammaOp : public OpKernel {\\n     \/\/ avoid a couple flops which can be done on a per-alpha basis.\\n \\n     auto DoWork = [samples_per_alpha, num_alphas, &rng, samples_flat,\\n-                   alpha_flat](int start_output, int limit_output) {\\n+                   alpha_flat](int64 start_output, int64 limit_output) {\\n       using Eigen::numext::exp;\\n       using Eigen::numext::log;\\n       using Eigen::numext::log1p;'}}",
            "message_norm":"prevent `int64` to `int` truncation in `shard` api usage.\n\nthe function argument in `shard` must be a function of two `int64` arguments. however, we are passing in a function with two `int` arguments. thus, for large workloads, these arguments get truncated from positive `int64` values to negative `int` ones, resulting in a buffer out of bounds write.\n\npiperorigin-revid: 332557334\nchange-id: i236c9a2e7f53580e520571da8ba941a3aa9fa0b5",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('out of bounds write', 'SECWORD', ''), ('332557334', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/random_op.cc'])",
            "num_files":1.0
        },
        {
            "index":239,
            "vuln_id":"GHSA-3cgf-9m6x-pwwr",
            "cwe_id":"{'CWE-362'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/rusqlite\/rusqlite\/commit\/45fd77ee43c38eea4d6f4e2e56c1667a55ec654f'}",
            "dataset":"osv",
            "summary":"Data races in rusqlite An issue was discovered in the rusqlite crate before 0.23.0 for Rust. Memory safety can be violated via UnlockNotification.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/rusqlite\/rusqlite",
            "commit_href":"https:\/\/github.com\/rusqlite\/rusqlite\/commit\/45fd77ee43c38eea4d6f4e2e56c1667a55ec654f",
            "commit_sha":"45fd77ee43c38eea4d6f4e2e56c1667a55ec654f",
            "patch":"SINGLE",
            "chain_ord":"['45fd77ee43c38eea4d6f4e2e56c1667a55ec654f']",
            "before_first_fix_commit":"{'c9ef5bd63cad5c0c123344c072b490a1a9bcbe1f'}",
            "last_fix_commit":"45fd77ee43c38eea4d6f4e2e56c1667a55ec654f",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/15\/2020, 19:05:31",
            "message":"UnlockNotification should hold mutex when calling condvar",
            "author":"Thom Chiovoloni",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 11, 'total': 20}",
            "files":"{'src\/unlock_notify.rs': {'additions': 9, 'deletions': 11, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/rusqlite\/rusqlite\/raw\/45fd77ee43c38eea4d6f4e2e56c1667a55ec654f\/src%2Funlock_notify.rs', 'patch': '@@ -26,12 +26,13 @@ impl UnlockNotification {\\n         }\\n     }\\n \\n-    fn fired(&mut self) {\\n-        *self.mutex.lock().unwrap() = true;\\n+    fn fired(&self) {\\n+        let mut flag = self.mutex.lock().unwrap();\\n+        *flag = true;\\n         self.cond.notify_one();\\n     }\\n \\n-    fn wait(&mut self) {\\n+    fn wait(&self) {\\n         let mut fired = self.mutex.lock().unwrap();\\n         while !*fired {\\n             fired = self.cond.wait(fired).unwrap();\\n@@ -43,12 +44,9 @@ impl UnlockNotification {\\n #[cfg(feature = \"unlock_notify\")]\\n unsafe extern \"C\" fn unlock_notify_cb(ap_arg: *mut *mut c_void, n_arg: c_int) {\\n     use std::slice::from_raw_parts;\\n-    let args = from_raw_parts(ap_arg, n_arg as usize);\\n-    for arg in args {\\n-        let _ = catch_unwind(|| {\\n-            let un: &mut UnlockNotification = &mut *(*arg as *mut UnlockNotification);\\n-            un.fired()\\n-        });\\n+    let args = from_raw_parts(ap_arg as *const &UnlockNotification, n_arg as usize);\\n+    for un in args {\\n+        let _ = catch_unwind(std::panic::AssertUnwindSafe(|| un.fired()));\\n     }\\n }\\n \\n@@ -73,12 +71,12 @@ pub unsafe fn is_locked(db: *mut ffi::sqlite3, rc: c_int) -> bool {\\n \/\/\/ back the current transaction (if any).\\n #[cfg(feature = \"unlock_notify\")]\\n pub unsafe fn wait_for_unlock_notify(db: *mut ffi::sqlite3) -> c_int {\\n-    let mut un = UnlockNotification::new();\\n+    let un = UnlockNotification::new();\\n     \/* Register for an unlock-notify callback. *\/\\n     let rc = ffi::sqlite3_unlock_notify(\\n         db,\\n         Some(unlock_notify_cb),\\n-        &mut un as *mut UnlockNotification as *mut c_void,\\n+        &un as *const UnlockNotification as *mut c_void,\\n     );\\n     debug_assert!(\\n         rc == ffi::SQLITE_LOCKED || rc == ffi::SQLITE_LOCKED_SHAREDCACHE || rc == ffi::SQLITE_OK'}}",
            "message_norm":"unlocknotification should hold mutex when calling condvar",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/unlock_notify.rs'])",
            "num_files":1.0
        },
        {
            "index":1548,
            "vuln_id":"GHSA-cg3h-rc9q-g8v9",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/pimcore\/pimcore\/commit\/6ccb5c12fc1be065ebce9c89c4677ee939b88597'}",
            "dataset":"osv",
            "summary":"Cross-site Scripting in pimcore pimcore version 10.3.0 and prior is vulnerable to cross-site scripting.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/pimcore\/pimcore",
            "commit_href":"https:\/\/github.com\/pimcore\/pimcore\/commit\/6ccb5c12fc1be065ebce9c89c4677ee939b88597",
            "commit_sha":"6ccb5c12fc1be065ebce9c89c4677ee939b88597",
            "patch":"SINGLE",
            "chain_ord":"['6ccb5c12fc1be065ebce9c89c4677ee939b88597']",
            "before_first_fix_commit":"{'7b6b2229ed3f19da1632afcbf9b8fec6d768faad'}",
            "last_fix_commit":"6ccb5c12fc1be065ebce9c89c4677ee939b88597",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/07\/2022, 12:03:58",
            "message":"[Admin] Website Settings - Escape grid values properly",
            "author":"dpahuja",
            "comments":null,
            "stats":"{'additions': 19, 'deletions': 7, 'total': 26}",
            "files":"{'bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/settings\/website.js': {'additions': 19, 'deletions': 7, 'changes': 26, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pimcore\/pimcore\/raw\/6ccb5c12fc1be065ebce9c89c4677ee939b88597\/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Fsettings%2Fwebsite.js', 'patch': '@@ -36,7 +36,7 @@ pimcore.settings.website = Class.create({\\n                 border:false,\\n                 layout:\"fit\",\\n                 closable:true,\\n-                items:[this.getRowEditor()]\\n+                items:[this.getRowEditor()],\\n             });\\n \\n             var tabPanel = Ext.getCmp(\"pimcore_panel_tabs\");\\n@@ -133,6 +133,7 @@ pimcore.settings.website = Class.create({\\n                 dataIndex: \\'data\\',\\n                 flex: 300,\\n                 editable: true,\\n+                editor: new Ext.form.TextField({}),\\n                 renderer: this.getCellRenderer.bind(this),\\n             },\\n             {text: t(\"site\"), flex: 100, sortable:true, dataIndex: \"siteId\",\\n@@ -303,7 +304,10 @@ pimcore.settings.website = Class.create({\\n             bodyCls: \"pimcore_editable_grid\",\\n             stripeRows:true,\\n             columns : {\\n-                items: typesColumns\\n+                items: typesColumns,\\n+                defaults: {\\n+                    renderer: Ext.util.Format.htmlEncode\\n+                },\\n             },\\n             sm:  Ext.create(\\'Ext.selection.RowModel\\', {}),\\n             bbar:this.pagingtoolbar,\\n@@ -359,15 +363,23 @@ pimcore.settings.website = Class.create({\\n     },\\n \\n     getCellEditor: function (record) {\\n-        var data = record.data;\\n+        let data = record.data;\\n \\n-        var type = data.type;\\n-        var property;\\n+        let type = data.type;\\n+        let property;\\n \\n         if (type === \"text\") {\\n-            property = Ext.create(\\'Ext.form.TextField\\');\\n+            property = {\\n+                xtype: \\'textfield\\',\\n+                flex: 1,\\n+                value: data.data\\n+            }\\n         } else if (type == \"textarea\") {\\n-            property = Ext.create(\\'Ext.form.TextArea\\');\\n+            property = {\\n+                xtype: \"textarea\",\\n+                flex: 1,\\n+                value: data.data\\n+            }\\n         } else if (type == \"document\" || type == \"asset\" || type == \"object\") {\\n             property = {\\n                 xtype: \\'textfield\\','}}",
            "message_norm":"[admin] website settings - escape grid values properly",
            "language":"af",
            "entities":"[('admin', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['bundles\/AdminBundle\/Resources\/public\/js\/pimcore\/settings\/website.js'])",
            "num_files":1.0
        },
        {
            "index":1761,
            "vuln_id":"GHSA-fq6p-6334-8gr4",
            "cwe_id":"{'CWE-401'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ab51e5b813573dc9f51efa335aebcf2994125ee9'}",
            "dataset":"osv",
            "summary":"Memory leak in decoding PNG images ### Impact\nWhen [decoding PNG images](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/kernels\/image\/decode_image_op.cc#L322-L416) TensorFlow can produce a memory leak if the image is invalid.\nAfter calling `png::CommonInitDecode(..., &decode)`, the `decode` value contains allocated buffers which can only be freed by calling `png::CommonFreeDecode(&decode)`. However, several error case in the function implementation invoke the `OP_REQUIRES` macro which immediately terminates the execution of the function, without allowing for the memory free to occur.\n  \n### Patches   \nWe have patched the issue in GitHub commit [ab51e5b813573dc9f51efa335aebcf2994125ee9](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ab51e5b813573dc9f51efa335aebcf2994125ee9).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ab51e5b813573dc9f51efa335aebcf2994125ee9",
            "commit_sha":"ab51e5b813573dc9f51efa335aebcf2994125ee9",
            "patch":"SINGLE",
            "chain_ord":"['ab51e5b813573dc9f51efa335aebcf2994125ee9']",
            "before_first_fix_commit":"{'fb5ce99505358985ace9e811fd25a57047471d6f'}",
            "last_fix_commit":"ab51e5b813573dc9f51efa335aebcf2994125ee9",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/12\/2021, 03:24:32",
            "message":"Prevent memory leak in decoding PNG images.\n\nPiperOrigin-RevId: 409300653\nChange-Id: I6182124c545989cef80cefd439b659095920763b",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
            "files":"{'tensorflow\/core\/kernels\/image\/decode_image_op.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ab51e5b813573dc9f51efa335aebcf2994125ee9\/tensorflow%2Fcore%2Fkernels%2Fimage%2Fdecode_image_op.cc', 'patch': '@@ -18,6 +18,8 @@ limitations under the License.\\n #include <cstdint>\\n #include <memory>\\n \\n+#include \"tensorflow\/core\/lib\/gtl\/cleanup.h\"\\n+\\n #define EIGEN_USE_THREADS\\n \\n #include \"absl\/strings\/escaping.h\"\\n@@ -326,6 +328,16 @@ class DecodeImageV2Op : public OpKernel {\\n         context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\\n         errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\\n \\n+    \/\/ If we reach this point, then there is data in `decode` which must be\\n+    \/\/ freed by the time we end execution in this function. We cannot call\\n+    \/\/ `png::CommonFreeDecode()` before an `OP_REQUIRES` because if\\n+    \/\/ `OP_REQUIRES` constraint is satisfied then the data would be freed\\n+    \/\/ prematurely. Instead, let\\'s use a `Cleanup` object.\\n+    auto cleanup = gtl::MakeCleanup([&decode]() {\\n+      std::cerr << \"Cleanup called...\\\\n\";\\n+      png::CommonFreeDecode(&decode);\\n+    });\\n+\\n     \/\/ Verify that width and height are not too large:\\n     \/\/ - verify width and height don\\'t overflow int.\\n     \/\/ - width can later be multiplied by channels_ and sizeof(uint16), so'}}",
            "message_norm":"prevent memory leak in decoding png images.\n\npiperorigin-revid: 409300653\nchange-id: i6182124c545989cef80cefd439b659095920763b",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('memory leak', 'SECWORD', ''), ('decoding', 'SECWORD', ''), ('409300653', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/image\/decode_image_op.cc'])",
            "num_files":1.0
        },
        {
            "index":1868,
            "vuln_id":"GHSA-gf88-j2mg-cc82",
            "cwe_id":"{'CWE-681'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992'}",
            "dataset":"osv",
            "summary":"Crash caused by integer conversion to unsigned ### Impact\nAn attacker can cause a denial of service in `boosted_trees_create_quantile_stream_resource` by using negative arguments:\n\n```python\nimport tensorflow as tf\nfrom tensorflow.python.ops import gen_boosted_trees_ops\nimport numpy as np\n\nv= tf.Variable([0.0, 0.0, 0.0, 0.0, 0.0])\ngen_boosted_trees_ops.boosted_trees_create_quantile_stream_resource(\n  quantile_stream_resource_handle = v.handle,\n  epsilon = [74.82224],\n  num_streams = [-49], \n  max_elements = np.int32(586))\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/quantile_ops.cc#L96) does not validate that `num_streams` only contains non-negative numbers. In turn, [this results in using this value to allocate memory](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/quantiles\/quantile_stream_resource.h#L31-L40):\n\n```cc\nclass BoostedTreesQuantileStreamResource : public ResourceBase {\n public:\n  BoostedTreesQuantileStreamResource(const float epsilon,\n                                     const int64 max_elements,\n                                     const int64 num_streams)\n      : are_buckets_ready_(false),\n        epsilon_(epsilon),\n        num_streams_(num_streams),\n        max_elements_(max_elements) {\n    streams_.reserve(num_streams_);\n    ...\n  }\n}\n```\n\nHowever, `reserve` receives an unsigned integer so there is an implicit conversion from a negative value to a large positive unsigned. This results in a crash from the standard library.\n\n### Patches\nWe have patched the issue in GitHub commit [8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992",
            "commit_sha":"8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992",
            "patch":"SINGLE",
            "chain_ord":"['8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992']",
            "before_first_fix_commit":"{'f8a1ac8d75f9b3d00c90148ca1e91b735b6d542c'}",
            "last_fix_commit":"8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/28\/2021, 22:34:04",
            "message":"Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStreamResource\n\nPiperOrigin-RevId: 387452765\nChange-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'tensorflow\/core\/kernels\/boosted_trees\/quantile_ops.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fquantile_ops.cc', 'patch': '@@ -116,6 +116,9 @@ class BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {\\n     const Tensor* num_streams_t;\\n     OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\\n     int64_t num_streams = num_streams_t->scalar<int64>()();\\n+    OP_REQUIRES(context, num_streams >= 0,\\n+                errors::InvalidArgument(\\n+                    \"Num_streams input cannot be a negative integer\"));\\n \\n     auto result =\\n         new QuantileStreamResource(epsilon, max_elements_, num_streams);'}}",
            "message_norm":"ensure num_streams >= 0 in tf.raw_ops.boostedtreescreatequantilestreamresource\n\npiperorigin-revid: 387452765\nchange-id: i9990c760e177fabca6a3b9b4612ceeaeeba51495",
            "language":"en",
            "entities":"[('ensure', 'ACTION', ''), ('387452765', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/quantile_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":378,
            "vuln_id":"GHSA-47vg-483w-hp3m",
            "cwe_id":"{'CWE-384'}",
            "score":4.3,
            "chain":"{'https:\/\/github.com\/filegator\/filegator\/commit\/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225'}",
            "dataset":"osv",
            "summary":"Improper user session handling in filegator FileGator prior to version 7.8.0 is vulnerable to session fixation.",
            "published_date":"2022-05-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/filegator\/filegator",
            "commit_href":"https:\/\/github.com\/filegator\/filegator\/commit\/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
            "commit_sha":"fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
            "patch":"SINGLE",
            "chain_ord":"['fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225']",
            "before_first_fix_commit":"{'6e2b68f17f48cdc1d6a4a93a2369d2069fe64989'}",
            "last_fix_commit":"fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/24\/2022, 11:08:43",
            "message":"regenerate session on user update",
            "author":"Milos Stojanovic",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'backend\/Services\/Auth\/Adapters\/JsonFile.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/filegator\/filegator\/raw\/fcd3995f64f5dfc6a4c2c059cc22a2fef1e81225\/backend%2FServices%2FAuth%2FAdapters%2FJsonFile.php', 'patch': \"@@ -53,7 +53,7 @@ public function user(): ?User\\n \\n         if ($user) {\\n             foreach ($this->getUsers() as $u) {\\n-                if ($u['username'] == $user->getUsername() && $hash == $u['password']) {\\n+                if ($u['username'] == $user->getUsername() && $hash == $u['password'].$u['permissions'].$u['homedir'].$u['role']) {\\n                     return $user;\\n                 }\\n             }\\n@@ -70,7 +70,7 @@ public function authenticate($username, $password): bool\\n             if ($u['username'] == $username && $this->verifyPassword($password, $u['password'])) {\\n                 $user = $this->mapToUserObject($u);\\n                 $this->store($user);\\n-                $this->session->set(self::SESSION_HASH, $u['password']);\\n+                $this->session->set(self::SESSION_HASH, $u['password'].$u['permissions'].$u['homedir'].$u['role']);\\n \\n                 return true;\\n             }\"}}",
            "message_norm":"regenerate session on user update",
            "language":"en",
            "entities":null,
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['backend\/Services\/Auth\/Adapters\/JsonFile.php'])",
            "num_files":1.0
        },
        {
            "index":903,
            "vuln_id":"GHSA-6vqp-h455-42mr",
            "cwe_id":"{'CWE-789'}",
            "score":5.5,
            "chain":"{'https:\/\/github.com\/apache\/pdfbox\/commit\/8c47be1011c11dc47300faecffd8ab32fba3646f'}",
            "dataset":"osv",
            "summary":"Uncontrolled Memory Allocation in Apache PDFBox A carefully crafted PDF file can trigger an OutOfMemory-Exception while loading the file. This issue affects Apache PDFBox version 2.0.22 and prior 2.0.x versions.",
            "published_date":"2021-05-13",
            "chain_len":1,
            "project":"https:\/\/github.com\/apache\/pdfbox",
            "commit_href":"https:\/\/github.com\/apache\/pdfbox\/commit\/8c47be1011c11dc47300faecffd8ab32fba3646f",
            "commit_sha":"8c47be1011c11dc47300faecffd8ab32fba3646f",
            "patch":"SINGLE",
            "chain_ord":"['8c47be1011c11dc47300faecffd8ab32fba3646f']",
            "before_first_fix_commit":"{'ef53b45f111c4e391faf1c331c4e81a21e24c0b8'}",
            "last_fix_commit":"8c47be1011c11dc47300faecffd8ab32fba3646f",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/07\/2021, 13:18:31",
            "message":"PDFBOX-5112: SonarCube fix, throw NoSuchElementException if no more elements are available\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/pdfbox\/branches\/2.0@1887295 13f79535-47bb-0310-9956-ffa450edef68",
            "author":"Andreas Lehmk\u00fchler",
            "comments":null,
            "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
            "files":"{'pdfbox\/src\/main\/java\/org\/apache\/pdfbox\/pdfparser\/PDFXrefStreamParser.java': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/pdfbox\/raw\/8c47be1011c11dc47300faecffd8ab32fba3646f\/pdfbox%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fpdfbox%2Fpdfparser%2FPDFXrefStreamParser.java', 'patch': '@@ -19,6 +19,7 @@\\n import java.io.IOException;\\n import java.util.Arrays;\\n import java.util.Iterator;\\n+import java.util.NoSuchElementException;\\n \\n import org.apache.pdfbox.cos.COSArray;\\n import org.apache.pdfbox.cos.COSBase;\\n@@ -212,6 +213,10 @@ public boolean hasNext()\\n         @Override\\n         public Long next()\\n         {\\n+            if (currentNumber >= maxValue)\\n+            {\\n+                throw new NoSuchElementException();\\n+            }\\n             if (currentNumber < currentEnd)\\n             {\\n                 return currentNumber++;'}}",
            "message_norm":"pdfbox-5112: sonarcube fix, throw nosuchelementexception if no more elements are available\n\ngit-svn-id: https:\/\/svn.apache.org\/repos\/asf\/pdfbox\/branches\/2.0@1887295 13f79535-47bb-0310-9956-ffa450edef68",
            "language":"en",
            "entities":"[('sonarcube', 'DETECTION', ''), ('https:\/\/svn.apache.org\/repos\/asf\/pdfbox\/branches\/2.0@1887295', 'URL', ''), ('13f79535', 'SHA', 'generic_sha'), ('ffa450edef68', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['pdfbox\/src\/main\/java\/org\/apache\/pdfbox\/pdfparser\/PDFXrefStreamParser.java'])",
            "num_files":1.0
        },
        {
            "index":732,
            "vuln_id":"GHSA-62gx-355r-9fhg",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ff70c47a396ef1e3cb73c90513da4f5cb71bebba'}",
            "dataset":"osv",
            "summary":"Session operations in eager mode lead to null pointer dereferences ### Impact\nIn eager mode (default in TF 2.0 and later), session operations are invalid. However, users could still call the raw ops associated with them and trigger a null pointer dereference:\n\n```python\nimport tensorflow as tf\ntf.raw_ops.GetSessionTensor(handle=['\\x12\\x1a\\x07'],dtype=4)\n```\n```python\nimport tensorflow as tf\ntf.raw_ops.DeleteSessionTensor(handle=['\\x12\\x1a\\x07'])\n``` \n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/eebb96c2830d48597d055d247c0e9aebaea94cd5\/tensorflow\/core\/kernels\/session_ops.cc#L104) dereferences the session state pointer without checking if it is valid:\n  \n```cc\n  OP_REQUIRES_OK(ctx, ctx->session_state()->GetTensor(name, &val));\n```\n\nThus, in eager mode, `ctx->session_state()` is nullptr and the call of the member function is undefined behavior.\n\n### Patches\nWe have patched the issue in GitHub commit [ff70c47a396ef1e3cb73c90513da4f5cb71bebba](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ff70c47a396ef1e3cb73c90513da4f5cb71bebba).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ff70c47a396ef1e3cb73c90513da4f5cb71bebba",
            "commit_sha":"ff70c47a396ef1e3cb73c90513da4f5cb71bebba",
            "patch":"SINGLE",
            "chain_ord":"['ff70c47a396ef1e3cb73c90513da4f5cb71bebba']",
            "before_first_fix_commit":"{'eebb96c2830d48597d055d247c0e9aebaea94cd5'}",
            "last_fix_commit":"ff70c47a396ef1e3cb73c90513da4f5cb71bebba",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/13\/2021, 21:24:00",
            "message":"Fix `tf.raw_ops.GetSessionTensor` and `tf.raw_ops.DeleteSessionTensor` null pointer dereferences.\n\nPiperOrigin-RevId: 368294154\nChange-Id: Ie10f07a0a9a1c2b685e08153d48a0ca4b93f9fc9",
            "author":"Amit Patankar",
            "comments":null,
            "stats":"{'additions': 10, 'deletions': 4, 'total': 14}",
            "files":"{'tensorflow\/core\/kernels\/session_ops.cc': {'additions': 10, 'deletions': 4, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ff70c47a396ef1e3cb73c90513da4f5cb71bebba\/tensorflow%2Fcore%2Fkernels%2Fsession_ops.cc', 'patch': '@@ -91,7 +91,6 @@ TF_CALL_NUMBER_TYPES(REGISTER_GPU_KERNEL);\\n REGISTER_GPU_KERNEL(bool);\\n #undef REGISTER_GPU_KERNEL\\n \\n-\\n class GetSessionTensorOp : public OpKernel {\\n  public:\\n   explicit GetSessionTensorOp(OpKernelConstruction* context)\\n@@ -101,7 +100,11 @@ class GetSessionTensorOp : public OpKernel {\\n     const Tensor& handle = ctx->input(0);\\n     const string& name = handle.scalar<tstring>()();\\n     Tensor val;\\n-    OP_REQUIRES_OK(ctx, ctx->session_state()->GetTensor(name, &val));\\n+    auto session_state = ctx->session_state();\\n+    OP_REQUIRES(ctx, session_state != nullptr,\\n+                errors::FailedPrecondition(\\n+                    \"GetSessionTensor called on null session state\"));\\n+    OP_REQUIRES_OK(ctx, session_state->GetTensor(name, &val));\\n     ctx->set_output(0, val);\\n   }\\n \\n@@ -122,7 +125,6 @@ TF_CALL_NUMBER_TYPES(REGISTER_GPU_KERNEL);\\n REGISTER_GPU_KERNEL(bool);\\n #undef REGISTER_GPU_KERNEL\\n \\n-\\n class DeleteSessionTensorOp : public OpKernel {\\n  public:\\n   explicit DeleteSessionTensorOp(OpKernelConstruction* context)\\n@@ -131,7 +133,11 @@ class DeleteSessionTensorOp : public OpKernel {\\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& handle = ctx->input(0);\\n     const string& name = handle.scalar<tstring>()();\\n-    OP_REQUIRES_OK(ctx, ctx->session_state()->DeleteTensor(name));\\n+    auto session_state = ctx->session_state();\\n+    OP_REQUIRES(ctx, session_state != nullptr,\\n+                errors::FailedPrecondition(\\n+                    \"DeleteSessionTensor called on null session state\"));\\n+    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));\\n   }\\n \\n   TF_DISALLOW_COPY_AND_ASSIGN(DeleteSessionTensorOp);'}}",
            "message_norm":"fix `tf.raw_ops.getsessiontensor` and `tf.raw_ops.deletesessiontensor` null pointer dereferences.\n\npiperorigin-revid: 368294154\nchange-id: ie10f07a0a9a1c2b685e08153d48a0ca4b93f9fc9",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('null pointer dereferences', 'SECWORD', ''), ('368294154', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/session_ops.cc'])",
            "num_files":1.0
        },
        {
            "index":369,
            "vuln_id":"GHSA-46c5-pfj8-fv65",
            "cwe_id":"{'CWE-704'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/pmmp\/PocketMine-MP\/commit\/c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1'}",
            "dataset":"osv",
            "summary":"Improperly checked metadata on tools\/armour itemstacks received from the client ### Impact\nDue to a workaround applied in 1.13, an attacker may send a negative damage\/meta value in a tool or armour item's NBT, which `TypeConverter` then blindly uses as if it was valid without being checked.\n\nWhen this invalid metadata value reaches `Durable->setDamage()`, an exception is thrown because the metadata is not within the expected range for damage values.\n\nThis can be reproduced with either a too-large damage value, or a negative one.\n\n### Patches\nc8e1cfcbee4945fd4b63d2a7e96025c59744d4f1\n\n### Workarounds\nIn theory this can be checked by plugins using a custom `TypeConverter`, but this is likely to be very cumbersome.\n\n### For more information\n* Email us at [team@pmmp.io](mailto:team@pmmp.io)",
            "published_date":"2022-03-18",
            "chain_len":1,
            "project":"https:\/\/github.com\/pmmp\/PocketMine-MP",
            "commit_href":"https:\/\/github.com\/pmmp\/PocketMine-MP\/commit\/c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1",
            "commit_sha":"c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1",
            "patch":"SINGLE",
            "chain_ord":"['c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1']",
            "before_first_fix_commit":"{'869dda9a45a12028243cae590552458ce970ec18'}",
            "last_fix_commit":"c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/15\/2022, 23:44:41",
            "message":"TypeConverter: account for possible out-of-range meta in items",
            "author":"Dylan K. Taylor",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'src\/network\/mcpe\/convert\/TypeConverter.php': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pmmp\/PocketMine-MP\/raw\/c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1\/src%2Fnetwork%2Fmcpe%2Fconvert%2FTypeConverter.php', 'patch': '@@ -232,6 +232,9 @@ public function netItemStackToCore(ItemStack $itemStack) : Item{\\n \\t\\t\\t\\t$compound = null;\\n \\t\\t\\t}\\n \\t\\t}\\n+\\t\\tif($meta < 0 || $meta >= 0x7fff){ \/\/this meta value may have been restored from the NBT\\n+\\t\\t\\tthrow new TypeConversionException(\"Item meta must be in range 0 ... \" . 0x7fff . \" (received $meta)\");\\n+\\t\\t}\\n \\n \\t\\ttry{\\n \\t\\t\\treturn ItemFactory::getInstance()->get('}}",
            "message_norm":"typeconverter: account for possible out-of-range meta in items",
            "language":"en",
            "entities":"[('out-of-range', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/network\/mcpe\/convert\/TypeConverter.php'])",
            "num_files":1.0
        },
        {
            "index":1988,
            "vuln_id":"GHSA-h4mx-xv96-2jgm",
            "cwe_id":"{'CWE-79'}",
            "score":5.4,
            "chain":"{'https:\/\/github.com\/TYPO3\/typo3\/commit\/da611775f92102d7602713003f4c79606c8a445d'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting in TYPO3's Frontend Login Mailer > ### Meta\n> * CVSS: `CVSS:3.1\/AV:N\/AC:L\/PR:L\/UI:R\/S:C\/C:L\/I:L\/A:N\/E:F\/RL:O\/RC:C` (4.9)\n\n### Problem\nUser submitted content was used without being properly encoded in HTML emails sent to users. The actually affected components were mail clients used to view those messages.\n\n### Solution\nUpdate to TYPO3 versions 9.5.35 ELTS, 10.4.29, 11.5.11 that fix the problem described above.\n\n### Credits\nThanks to Christian Seifert who reported this issue and to TYPO3 framework merger Andreas Fernandez who fixed the issue.\n\n### References\n* [TYPO3-CORE-SA-2022-004](https:\/\/typo3.org\/security\/advisory\/typo3-core-sa-2022-004)",
            "published_date":"2022-06-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/TYPO3\/typo3",
            "commit_href":"https:\/\/github.com\/TYPO3\/typo3\/commit\/da611775f92102d7602713003f4c79606c8a445d",
            "commit_sha":"da611775f92102d7602713003f4c79606c8a445d",
            "patch":"SINGLE",
            "chain_ord":"['da611775f92102d7602713003f4c79606c8a445d']",
            "before_first_fix_commit":"{'6f2554dc4ea0b670fd5599c54fd788d4db96c4a0'}",
            "last_fix_commit":"da611775f92102d7602713003f4c79606c8a445d",
            "chain_ord_pos":1.0,
            "commit_datetime":"06\/14\/2022, 07:18:04",
            "message":"[SECURITY] Avoid HTML injection in password recovery mail\n\nThe `receiverName` variable used in the password recovery mail of the\nExtbase felogin plugin was susceptible to HTML injection due to\nmissing sanitization. The variable is now passed thru the\n`f:format.htmlspecialchars` ViewHelper.\n\nResolves: #96559\nReleases: main, 11.5, 10.4\nChange-Id: I60e23c161f7f2fcc87b8870345b10a4c31d7b8db\nSecurity-Bulletin: TYPO3-CORE-SA-2022-004\nSecurity-References: CVE-2022-31049\nReviewed-on: https:\/\/review.typo3.org\/c\/Packages\/TYPO3.CMS\/+\/74904\nTested-by: Oliver Hader <oliver.hader@typo3.org>\nReviewed-by: Oliver Hader <oliver.hader@typo3.org>",
            "author":"Andreas Fernandez",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'typo3\/sysext\/felogin\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/TYPO3\/typo3\/raw\/da611775f92102d7602713003f4c79606c8a445d\/typo3%2Fsysext%2Ffelogin%2FResources%2FPrivate%2FEmail%2FTemplates%2FPasswordRecovery.html', 'patch': '@@ -9,7 +9,7 @@\\n         {f:translate(\\n         key: \\'forgot_validate_reset_password_html\\',\\n         extensionName: \\'felogin\\',\\n-        arguments: \\'{ 0: receiverName, 1: recoveryLink, 2: validUntil }\\'\\n+        arguments: \\'{ 0: \"{receiverName -> f:format.htmlspecialchars()}\", 1: recoveryLink, 2: validUntil }\\'\\n         ) -> f:format.html()}\\n     <\/f:spaceless>\\n <\/f:section>'}}",
            "message_norm":"[security] avoid html injection in password recovery mail\n\nthe `receivername` variable used in the password recovery mail of the\nextbase felogin plugin was susceptible to html injection due to\nmissing sanitization. the variable is now passed thru the\n`f:format.htmlspecialchars` viewhelper.\n\nresolves: #96559\nreleases: main, 11.5, 10.4\nchange-id: i60e23c161f7f2fcc87b8870345b10a4c31d7b8db\nsecurity-bulletin: typo3-core-sa-2022-004\nsecurity-references: cve-2022-31049\nreviewed-on: https:\/\/review.typo3.org\/c\/packages\/typo3.cms\/+\/74904\ntested-by: oliver hader <oliver.hader@typo3.org>\nreviewed-by: oliver hader <oliver.hader@typo3.org>",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('injection', 'SECWORD', ''), ('password', 'SECWORD', ''), ('password', 'SECWORD', ''), ('injection', 'SECWORD', ''), ('sanitization', 'SECWORD', ''), ('format.htmlspecialchars', 'SECWORD', ''), ('#96559', 'ISSUE', ''), ('security', 'SECWORD', ''), ('security', 'SECWORD', ''), ('cve-2022-31049', 'VULNID', 'CVE'), ('https:\/\/review.typo3.org\/c\/packages\/typo3.cms\/+\/74904', 'URL', ''), ('oliver.hader@typo3.org', 'EMAIL', ''), ('oliver.hader@typo3.org', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['typo3\/sysext\/felogin\/Resources\/Private\/Email\/Templates\/PasswordRecovery.html'])",
            "num_files":1.0
        },
        {
            "index":2009,
            "vuln_id":"GHSA-h6wm-mr85-4h9g",
            "cwe_id":"{'CWE-79'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/neorazorx\/facturascripts\/commit\/73a6595ca85984d65f656c6356fabb23d1936c54'}",
            "dataset":"osv",
            "summary":"Cross site scripting in facturascripts A Cross-site Scripting (XSS) vulnerability exists in the fsNick parameter in facturascripts prior to version 2022.06",
            "published_date":"2022-06-14",
            "chain_len":1,
            "project":"https:\/\/github.com\/neorazorx\/facturascripts",
            "commit_href":"https:\/\/github.com\/neorazorx\/facturascripts\/commit\/73a6595ca85984d65f656c6356fabb23d1936c54",
            "commit_sha":"73a6595ca85984d65f656c6356fabb23d1936c54",
            "patch":"SINGLE",
            "chain_ord":"['73a6595ca85984d65f656c6356fabb23d1936c54']",
            "before_first_fix_commit":"{'298eb4b1a94c5898fde5a21e412955fc77a3ef93'}",
            "last_fix_commit":"73a6595ca85984d65f656c6356fabb23d1936c54",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 09:29:31",
            "message":"Sanitized username when showing user not found message.\n------\nSaneado nombre de usuario al mostrar el mensaje de usuario no encontrado.",
            "author":"Carlos Garcia Gomez",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'Core\/App\/AppController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/NeoRazorX\/facturascripts\/raw\/73a6595ca85984d65f656c6356fabb23d1936c54\/Core%2FApp%2FAppController.php', 'patch': \"@@ -287,7 +287,7 @@ private function userAuth()\\n         }\\n \\n         $this->ipWarning();\\n-        ToolBox::i18nLog()->warning('login-user-not-found', ['%nick%' => $nick]);\\n+        ToolBox::i18nLog()->warning('login-user-not-found', ['%nick%' => htmlspecialchars($nick)]);\\n         return false;\\n     }\"}}",
            "message_norm":"sanitized username when showing user not found message.\n------\nsaneado nombre de usuario al mostrar el mensaje de usuario no encontrado.",
            "language":"en",
            "entities":"[('sanitized', 'SECWORD', ''), ('found', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['Core\/App\/AppController.php'])",
            "num_files":1.0
        },
        {
            "index":1120,
            "vuln_id":"GHSA-83rh-hx5x-q9p5",
            "cwe_id":"{'CWE-125'}",
            "score":7.5,
            "chain":"{'https:\/\/github.com\/opencv\/opencv\/pull\/10480\/commits\/4ca89db22dea962690f31c1781bce5937ee91837'}",
            "dataset":"osv",
            "summary":"Out-of-bounds Read in OpenCV In OpenCV 3.3.1 (corresponding with OpenCV-Python 3.3.1.11), a heap-based buffer over-read exists in the function cv::HdrDecoder::checkSignature in modules\/imgcodecs\/src\/grfmt_hdr.cpp.",
            "published_date":"2021-10-12",
            "chain_len":1,
            "project":"https:\/\/github.com\/opencv\/opencv",
            "commit_href":"https:\/\/github.com\/opencv\/opencv\/pull\/10480\/commits\/4ca89db22dea962690f31c1781bce5937ee91837",
            "commit_sha":"4ca89db22dea962690f31c1781bce5937ee91837",
            "patch":"SINGLE",
            "chain_ord":"['4ca89db22dea962690f31c1781bce5937ee91837']",
            "before_first_fix_commit":"{'30373d2566a3ec097f0418dc2661ec03fcfb71d6'}",
            "last_fix_commit":"4ca89db22dea962690f31c1781bce5937ee91837",
            "chain_ord_pos":1.0,
            "commit_datetime":"01\/01\/2018, 13:12:21",
            "message":"imgproc(hdr): fix bounds check in HdrDecoder::checkSignature()",
            "author":"Alexander Alekhin",
            "comments":null,
            "stats":"{'additions': 8, 'deletions': 4, 'total': 12}",
            "files":"{'modules\/imgcodecs\/src\/grfmt_hdr.cpp': {'additions': 8, 'deletions': 4, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencv\/opencv\/raw\/4ca89db22dea962690f31c1781bce5937ee91837\/modules%2Fimgcodecs%2Fsrc%2Fgrfmt_hdr.cpp', 'patch': '@@ -101,10 +101,14 @@ bool HdrDecoder::readData(Mat& _img)\\n \\n bool HdrDecoder::checkSignature( const String& signature ) const\\n {\\n-    if(signature.size() >= m_signature.size() &&\\n-       (!memcmp(signature.c_str(), m_signature.c_str(), m_signature.size()) ||\\n-       !memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())))\\n-       return true;\\n+    if (signature.size() >= m_signature.size() &&\\n+        0 == memcmp(signature.c_str(), m_signature.c_str(), m_signature.size())\\n+    )\\n+        return true;\\n+    if (signature.size() >= m_signature_alt.size() &&\\n+        0 == memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())\\n+    )\\n+        return true;\\n     return false;\\n }'}}",
            "message_norm":"imgproc(hdr): fix bounds check in hdrdecoder::checksignature()",
            "language":"en",
            "entities":"[('bounds check', 'SECWORD', ''), ('hdrdecoder::checksignature', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['modules\/imgcodecs\/src\/grfmt_hdr.cpp'])",
            "num_files":1.0
        },
        {
            "index":349,
            "vuln_id":"GHSA-43m5-c88r-cjvv",
            "cwe_id":"{'CWE-352'}",
            "score":6.8,
            "chain":"{'https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/commit\/cf43beedb05131937ef46f365ab0a0c6fa6ac618'}",
            "dataset":"osv",
            "summary":"XSS due to lack of CSRF validation for replying\/publishing ### Impact\nDue to lack of CSRF validation, a logged in user is potentially vulnerable to an XSS attack which could allow a third party to post on their behalf on the forum.\n\n### Patches\nUpgrade to the latest version v0.7.0\n\n### Workarounds\nYou can cherry-pick the following commit: [https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/commit\/cf43beedb05131937ef46f365ab0a0c6fa6ac618](https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/commit\/cf43beedb05131937ef46f365ab0a0c6fa6ac618)\n\n### References\nVisit https:\/\/community.nodebb.org if you have any questions about this issue or on how to patch \/ upgrade your instance.",
            "published_date":"2020-08-26",
            "chain_len":1,
            "project":"https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments",
            "commit_href":"https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/commit\/cf43beedb05131937ef46f365ab0a0c6fa6ac618",
            "commit_sha":"cf43beedb05131937ef46f365ab0a0c6fa6ac618",
            "patch":"SINGLE",
            "chain_ord":"['cf43beedb05131937ef46f365ab0a0c6fa6ac618']",
            "before_first_fix_commit":"{'ed0156594a44c6429743e314e9b5a313fad60730'}",
            "last_fix_commit":"cf43beedb05131937ef46f365ab0a0c6fa6ac618",
            "chain_ord_pos":1.0,
            "commit_datetime":"08\/20\/2020, 05:11:57",
            "message":"fix: CSRF issues",
            "author":"psychobunny",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
            "files":"{'library.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/psychobunny\/nodebb-plugin-blog-comments\/raw\/cf43beedb05131937ef46f365ab0a0c6fa6ac618\/library.js', 'patch': \"@@ -248,8 +248,8 @@\\n \\t\\t});\\n \\n \\t\\tapp.get('\/comments\/get\/:id\/:pagination?', middleware.applyCSRF, Comments.getCommentData);\\n-\\t\\tapp.post('\/comments\/reply', Comments.replyToComment);\\n-\\t\\tapp.post('\/comments\/publish', Comments.publishArticle);\\n+\\t\\tapp.post('\/comments\/reply', middleware.applyCSRF, Comments.replyToComment);\\n+\\t\\tapp.post('\/comments\/publish', middleware.applyCSRF, Comments.publishArticle);\\n \\n \\t\\tapp.get('\/admin\/blog-comments', middleware.admin.buildHeader, renderAdmin);\\n \\t\\tapp.get('\/api\/admin\/blog-comments', renderAdmin);\"}}",
            "message_norm":"fix: csrf issues",
            "language":"en",
            "entities":"[('csrf', 'SECWORD', ''), ('issues', 'FLAW', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['library.js'])",
            "num_files":1.0
        },
        {
            "index":2717,
            "vuln_id":"GHSA-q85f-69q7-55h2",
            "cwe_id":"{'CWE-908'}",
            "score":7.6,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef1d027be116f25e25bb94a60da491c2cf55bd0b'}",
            "dataset":"osv",
            "summary":"Uninitialized variable access in Tensorflow ### Impact\nThe [implementation of `AssignOp`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/kernels\/assign_op.h#L30-L143) can result in copying unitialized data to a new tensor. This later results in undefined behavior.\n\nThe implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized.\n  \n### Patches\nWe have patched the issue in GitHub commit [ef1d027be116f25e25bb94a60da491c2cf55bd0b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef1d027be116f25e25bb94a60da491c2cf55bd0b).\n    \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
            "published_date":"2022-02-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef1d027be116f25e25bb94a60da491c2cf55bd0b",
            "commit_sha":"ef1d027be116f25e25bb94a60da491c2cf55bd0b",
            "patch":"SINGLE",
            "chain_ord":"['ef1d027be116f25e25bb94a60da491c2cf55bd0b']",
            "before_first_fix_commit":"{'eeb5e2168a5b3a701656b7366e3bc60d5234471e'}",
            "last_fix_commit":"ef1d027be116f25e25bb94a60da491c2cf55bd0b",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/09\/2021, 19:04:04",
            "message":"Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan\/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/assign_op.h': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ef1d027be116f25e25bb94a60da491c2cf55bd0b\/tensorflow%2Fcore%2Fkernels%2Fassign_op.h', 'patch': '@@ -50,6 +50,12 @@ class AssignOp : public OpKernel {\\n     \/\/ We always return the input ref.\\n     context->forward_ref_input_to_ref_output(0, 0);\\n \\n+    \/\/ Prevent copying uninitialized data, to solve harder to debug undefined\\n+    \/\/ behaviors that cannot be traced back to the original tensor.\\n+    OP_REQUIRES(\\n+        context, rhs.IsInitialized(),\\n+        errors::Internal(\"Right hand side of AssignOp is not initialized\"));\\n+\\n     \/\/ We can\\'t always know how this value will be used downstream, so make\\n     \/\/ conservative assumptions in specifying constraints on the memory\\n     \/\/ allocation attributes, unless the Grappler graph analysis determined that'}}",
            "message_norm":"prevent copying uninitialized data in `assignop`.\n\nthis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan\/asan.\n\npiperorigin-revid: 408654780\nchange-id: iad2ec40d43f5fd7ea016c20283356c12d5ddeab1",
            "language":"en",
            "entities":"[('prevent', 'ACTION', ''), ('uninitialized', 'SECWORD', ''), ('prevents', 'ACTION', ''), ('408654780', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/assign_op.h'])",
            "num_files":1.0
        },
        {
            "index":2306,
            "vuln_id":"GHSA-jvfv-hrrc-6q72",
            "cwe_id":"{'CWE-611'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/liquibase\/liquibase\/commit\/33d9d925082097fb1a3d2fc8e44423d964cd9381'}",
            "dataset":"osv",
            "summary":"Improper Restriction of XML External Entity Reference in Liquibase The XMLChangeLogSAXParser() function in Liquibase prior to version 4.8.0 contains an issue that may lead to to Improper Restriction of XML External Entity Reference.",
            "published_date":"2022-03-05",
            "chain_len":1,
            "project":"https:\/\/github.com\/liquibase\/liquibase",
            "commit_href":"https:\/\/github.com\/liquibase\/liquibase\/commit\/33d9d925082097fb1a3d2fc8e44423d964cd9381",
            "commit_sha":"33d9d925082097fb1a3d2fc8e44423d964cd9381",
            "patch":"SINGLE",
            "chain_ord":"['33d9d925082097fb1a3d2fc8e44423d964cd9381']",
            "before_first_fix_commit":"{'8d90124793d0053520365b7686688a1af7cc5102'}",
            "last_fix_commit":"33d9d925082097fb1a3d2fc8e44423d964cd9381",
            "chain_ord_pos":1.0,
            "commit_datetime":"02\/04\/2022, 17:43:43",
            "message":"Added liquibase.secureParsing test",
            "author":"Nathan Voxland",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 3, 'total': 6}",
            "files":"{'liquibase-core\/src\/test\/groovy\/liquibase\/parser\/core\/xml\/XMLChangeLogSAXParserTest.groovy': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/liquibase\/liquibase\/raw\/33d9d925082097fb1a3d2fc8e44423d964cd9381\/liquibase-core%2Fsrc%2Ftest%2Fgroovy%2Fliquibase%2Fparser%2Fcore%2Fxml%2FXMLChangeLogSAXParserTest.groovy', 'patch': '@@ -23,7 +23,7 @@ class XMLChangeLogSAXParserTest extends Specification {\\n \\n     def INSECURE_XML = \"\"\"\\n <!DOCTYPE databaseChangeLog [\\n-        <!ENTITY insecure SYSTEM \"https:\/\/localhost\/insecure\">\\n+        <!ENTITY insecure SYSTEM \"file:\/\/invalid.txt\">\\n         ]>\\n \\n <databaseChangeLog xmlns=\"http:\/\/www.liquibase.org\/xml\/ns\/dbchangelog\"\\n@@ -83,7 +83,7 @@ class XMLChangeLogSAXParserTest extends Specification {\\n \\n         then:\\n         def e = thrown(ChangeLogParseException)\\n-        e.message.contains(\"Failed to read external document \\'insecure\\'\")\\n+        e.message.contains(\"access is not allowed due to restriction set by the accessExternalDTD property\")\\n     }\\n \\n     def \"allows liquibase.secureParsing=false to disable secure parsing\"() {\\n@@ -97,7 +97,7 @@ class XMLChangeLogSAXParserTest extends Specification {\\n \\n         then:\\n         def e = thrown(ChangeLogParseException)\\n-        e.message.contains(\"Connection refused\")\\n+        e.message.contains(\"Error Reading Changelog File: invalid.txt\")\\n     }\\n \\n }'}}",
            "message_norm":"added liquibase.secureparsing test",
            "language":"en",
            "entities":"[('added', 'ACTION', ''), ('liquibase.secureparsing', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['liquibase-core\/src\/test\/groovy\/liquibase\/parser\/core\/xml\/XMLChangeLogSAXParserTest.groovy'])",
            "num_files":1.0
        },
        {
            "index":1985,
            "vuln_id":"GHSA-h4j5-c7cj-74xg",
            "cwe_id":"{'CWE-94'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/mjwwit\/node-XMLHttpRequest\/commit\/ee1e81fc67729c7c0eba5537ed7fe1e30a6b3291', 'https:\/\/github.com\/driverdan\/node-XMLHttpRequest\/commit\/983cfc244c7567ad6a59e366e55a8037e0497fe6'}",
            "dataset":"osv",
            "summary":"Arbitrary Code Injection This affects the package xmlhttprequest before 1.7.0; all versions of package xmlhttprequest-ssl. Provided requests are sent synchronously (async=False on xhr.open), malicious user input flowing into xhr.send could result in arbitrary code being injected and run.",
            "published_date":"2021-05-04",
            "chain_len":2,
            "project":"https:\/\/github.com\/driverdan\/node-XMLHttpRequest",
            "commit_href":"https:\/\/github.com\/driverdan\/node-XMLHttpRequest\/commit\/983cfc244c7567ad6a59e366e55a8037e0497fe6",
            "commit_sha":"983cfc244c7567ad6a59e366e55a8037e0497fe6",
            "patch":"MULTI",
            "chain_ord":"['983cfc244c7567ad6a59e366e55a8037e0497fe6', 'ee1e81fc67729c7c0eba5537ed7fe1e30a6b3291']",
            "before_first_fix_commit":"{'bf53329b61ca6afc5d28f6b8d2dc2e3ca740a9b2'}",
            "last_fix_commit":"ee1e81fc67729c7c0eba5537ed7fe1e30a6b3291",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/19\/2013, 02:34:33",
            "message":"fix for backslashes in data not encoding correctly",
            "author":"Kris Nye",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'lib\/XMLHttpRequest.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/driverdan\/node-XMLHttpRequest\/raw\/983cfc244c7567ad6a59e366e55a8037e0497fe6\/lib%2FXMLHttpRequest.js', 'patch': '@@ -477,7 +477,7 @@ exports.XMLHttpRequest = function() {\\n         + \"fs.writeFileSync(\\'\" + contentFile + \"\\', \\'NODE-XMLHTTPREQUEST-ERROR:\\' + JSON.stringify(error), \\'utf8\\');\"\\n         + \"fs.unlinkSync(\\'\" + syncFile + \"\\');\"\\n         + \"});\"\\n-        + (data ? \"req.write(\\'\" + data.replace(\/\\'\/g, \"\\\\\\\\\\'\") + \"\\');\":\"\")\\n+        + (data ? \"req.write(\\'\" + JSON.stringify(data).slice(1,-1).replace(\/\\'\/g, \"\\\\\\\\\\'\") + \"\\');\":\"\")\\n         + \"req.end();\";\\n       \/\/ Start the other Node Process, executing this string\\n       var syncProc = spawn(process.argv[0], [\"-e\", execString]);'}}",
            "message_norm":"fix for backslashes in data not encoding correctly",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('encoding', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/XMLHttpRequest.js'])",
            "num_files":1.0
        },
        {
            "index":3059,
            "vuln_id":"GHSA-v659-54cx-g4qr",
            "cwe_id":"{'CWE-1321'}",
            "score":9.8,
            "chain":"{'https:\/\/github.com\/ASaiAnudeep\/deep-override\/commit\/2aced17651fb684959a6e04b1465a8329b3d5268'}",
            "dataset":"osv",
            "summary":"Prototype Pollution in deep-override Prototype pollution vulnerability in 'deep-override' versions 1.0.0 through 1.0.1 allows an attacker to cause a denial of service and may lead to remote code execution.",
            "published_date":"2021-05-17",
            "chain_len":1,
            "project":"https:\/\/github.com\/ASaiAnudeep\/deep-override",
            "commit_href":"https:\/\/github.com\/ASaiAnudeep\/deep-override\/commit\/2aced17651fb684959a6e04b1465a8329b3d5268",
            "commit_sha":"2aced17651fb684959a6e04b1465a8329b3d5268",
            "patch":"SINGLE",
            "chain_ord":"['2aced17651fb684959a6e04b1465a8329b3d5268']",
            "before_first_fix_commit":"{'393135641fb0891409ac2a53783c553a7ed749a9'}",
            "last_fix_commit":"2aced17651fb684959a6e04b1465a8329b3d5268",
            "chain_ord_pos":1.0,
            "commit_datetime":"12\/17\/2020, 17:01:18",
            "message":"Security fix for Prototype Pollution",
            "author":"Arjun Shibu",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 1, 'total': 4}",
            "files":"{'src\/index.js': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ASaiAnudeep\/deep-override\/raw\/2aced17651fb684959a6e04b1465a8329b3d5268\/src%2Findex.js', 'patch': \"@@ -46,6 +46,8 @@ function override(...rawArgs) {\\n       });\\n     } else {\\n       Object.keys(obj).forEach(key => {\\n+        if (key == '__proto__' || key == 'constructor' || key == 'prototype')\\n+          return\\n         src = target[key];\\n         val = obj[key];\\n         if (val === target) {\\n@@ -69,4 +71,4 @@ function override(...rawArgs) {\\n   return target;\\n }\\n \\n-module.exports = override;\\n\\\\ No newline at end of file\\n+module.exports = override;\"}}",
            "message_norm":"security fix for prototype pollution",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('prototype pollution', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/index.js'])",
            "num_files":1.0
        },
        {
            "index":3591,
            "vuln_id":"GHSA-qpg9-83fv-x9ch",
            "cwe_id":"{'CWE-79'}",
            "score":null,
            "chain":"{'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/d393c7e9ba3ec44953ef1f8b11839421e2649ee7', 'https:\/\/github.com\/jenkinsci\/jenkins\/commit\/8eb632dda219ec8796420ce58d9564cddf8f8f93'}",
            "dataset":"osv",
            "summary":"Improper Neutralization of Input During Web Page Generation in Jenkins The f:validateButton form control for the Jenkins UI did not properly escape job URLs in Jenkins 2.171 and earlier and Jenkins LTS 2.164.1 and earlier, resulting in a cross-site scripting (XSS) vulnerability exploitable by users with the ability to control job names.",
            "published_date":"2022-05-13",
            "chain_len":2,
            "project":"https:\/\/github.com\/jenkinsci\/jenkins",
            "commit_href":"https:\/\/github.com\/jenkinsci\/jenkins\/commit\/d393c7e9ba3ec44953ef1f8b11839421e2649ee7",
            "commit_sha":"d393c7e9ba3ec44953ef1f8b11839421e2649ee7",
            "patch":"MULTI",
            "chain_ord":"['8eb632dda219ec8796420ce58d9564cddf8f8f93', 'd393c7e9ba3ec44953ef1f8b11839421e2649ee7']",
            "before_first_fix_commit":"{'bcb8ae87d5d9d348abf80039de2921eb3ced8959'}",
            "last_fix_commit":"d393c7e9ba3ec44953ef1f8b11839421e2649ee7",
            "chain_ord_pos":2.0,
            "commit_datetime":"03\/26\/2019, 20:54:27",
            "message":"[SECURITY-1327] Adapt test to new HTML Unit",
            "author":"Daniel Beck",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'test\/src\/test\/java\/lib\/form\/ValidateButtonSEC1327Test.java': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jenkinsci\/jenkins\/raw\/d393c7e9ba3ec44953ef1f8b11839421e2649ee7\/test%2Fsrc%2Ftest%2Fjava%2Flib%2Fform%2FValidateButtonSEC1327Test.java', 'patch': '@@ -24,7 +24,9 @@\\n package lib.form;\\n \\n import com.gargoylesoftware.htmlunit.html.HtmlButton;\\n+import com.gargoylesoftware.htmlunit.html.HtmlElement;\\n import com.gargoylesoftware.htmlunit.html.HtmlPage;\\n+import com.gargoylesoftware.htmlunit.html.DomNodeList;\\n import hudson.model.FreeStyleProject;\\n import hudson.model.Job;\\n import hudson.model.JobProperty;\\n@@ -72,8 +74,8 @@ private void checkValidateButtonWork(String projectName) throws Exception {\\n         HtmlPage htmlPage = wc.goTo(p.getUrl() + \"\/configure\");\\n         assertThat(htmlPage.getWebResponse().getStatusCode(), is(200));\\n \\n-        List<HtmlButton> inputs = htmlPage.getDocumentElement().getHtmlElementsByTagName(\"button\");\\n-        HtmlButton validateButton = inputs.stream()\\n+         DomNodeList<HtmlElement> inputs = htmlPage.getDocumentElement().getElementsByTagName(\"button\");\\n+         HtmlButton validateButton = (HtmlButton) inputs.stream()\\n                 .filter(i -> i.getTextContent().contains(\"testInjection\"))\\n                 .findFirst()\\n                 .orElseThrow(() -> new AssertionError(\"Validate button not found\"));'}}",
            "message_norm":"[security-1327] adapt test to new html unit",
            "language":"en",
            "entities":"[('security-1327', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['test\/src\/test\/java\/lib\/form\/ValidateButtonSEC1327Test.java'])",
            "num_files":1.0
        },
        {
            "index":965,
            "vuln_id":"GHSA-75f6-78jr-4656",
            "cwe_id":"{'CWE-476'}",
            "score":2.5,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f4c364a5d6880557f6f5b6eb5cee2c407f0186b3'}",
            "dataset":"osv",
            "summary":"Null pointer dereference in `EditDistance` ### Impact\nAn attacker can trigger a null pointer dereference in the implementation of `tf.raw_ops.EditDistance`: \n    \n```python\nimport tensorflow as tf\n\nhypothesis_indices = tf.constant([247, 247, 247], shape=[1, 3], dtype=tf.int64)\nhypothesis_values = tf.constant([-9.9999], shape=[1], dtype=tf.float32)\nhypothesis_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\ntruth_indices = tf.constant([], shape=[0, 3], dtype=tf.int64)\ntruth_values = tf.constant([], shape=[0], dtype=tf.float32)\ntruth_shape = tf.constant([0, 0, 0], shape=[3], dtype=tf.int64)\n\ntf.raw_ops.EditDistance(\n    hypothesis_indices=hypothesis_indices, hypothesis_values=hypothesis_values,\n    hypothesis_shape=hypothesis_shape, truth_indices=truth_indices,\n    truth_values=truth_values, truth_shape=truth_shape, normalize=True)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/79865b542f9ffdc9caeb255631f7c56f1d4b6517\/tensorflow\/core\/kernels\/edit_distance_op.cc#L103-L159) has incomplete validation of the input parameters.\n\nIn the above scenario, an attacker causes an allocation of an empty tensor for the output:\n\n```cc\nOP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\nauto output_t = output->flat<float>();\noutput_t.setZero();\n```\n\nBecause `output_shape` has 0 elements, the result of `output->flat<T>()` has an empty buffer, so calling `setZero` would result in a null dereference.\n\n### Patches\nWe have patched the issue in GitHub commit [f4c364a5d6880557f6f5b6eb5cee2c407f0186b3](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f4c364a5d6880557f6f5b6eb5cee2c407f0186b3).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
            "published_date":"2021-05-21",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f4c364a5d6880557f6f5b6eb5cee2c407f0186b3",
            "commit_sha":"f4c364a5d6880557f6f5b6eb5cee2c407f0186b3",
            "patch":"SINGLE",
            "chain_ord":"['f4c364a5d6880557f6f5b6eb5cee2c407f0186b3']",
            "before_first_fix_commit":"{'79865b542f9ffdc9caeb255631f7c56f1d4b6517'}",
            "last_fix_commit":"f4c364a5d6880557f6f5b6eb5cee2c407f0186b3",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/05\/2021, 01:06:03",
            "message":"Fix multiple issues in EditDistance\n\nPiperOrigin-RevId: 372033948\nChange-Id: Ieb957c29894af05bdfeb1a0402fced808dfcfd7b",
            "author":"Mihai Maruseac",
            "comments":null,
            "stats":"{'additions': 47, 'deletions': 0, 'total': 47}",
            "files":"{'tensorflow\/core\/kernels\/edit_distance_op.cc': {'additions': 47, 'deletions': 0, 'changes': 47, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f4c364a5d6880557f6f5b6eb5cee2c407f0186b3\/tensorflow%2Fcore%2Fkernels%2Fedit_distance_op.cc', 'patch': '@@ -64,6 +64,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\\n     return errors::InvalidArgument(\\n         \"truth_shape should be a vector, but got shape: \",\\n         truth_shape.shape().DebugString());\\n+  if (hypothesis_values.NumElements() != hypothesis_indices.dim_size(0))\\n+    return errors::InvalidArgument(\\n+        \"Expected hypothesis_values.NumElements == \"\\n+        \"#rows(hypothesis_indices), their shapes are: \",\\n+        hypothesis_values.shape().DebugString(), \" and \",\\n+        hypothesis_indices.shape().DebugString());\\n   if (hypothesis_shape.NumElements() != hypothesis_indices.dim_size(1))\\n     return errors::InvalidArgument(\\n         \"Expected hypothesis_shape.NumElements == \"\\n@@ -75,6 +81,12 @@ Status ValidateShapes(OpKernelContext* ctx, const Tensor& hypothesis_indices,\\n         \"Input SparseTensors must have rank at least 2, but truth_shape \"\\n         \"rank is: \",\\n         truth_shape.NumElements());\\n+  if (truth_values.NumElements() != truth_indices.dim_size(0))\\n+    return errors::InvalidArgument(\\n+        \"Expected truth_values.NumElements == \"\\n+        \"#rows(truth_indices), their shapes are: \",\\n+        truth_values.shape().DebugString(), \" and \",\\n+        truth_indices.shape().DebugString());\\n   if (truth_shape.NumElements() != truth_indices.dim_size(1))\\n     return errors::InvalidArgument(\\n         \"Expected truth_shape.NumElements == \"\\n@@ -153,6 +165,11 @@ class EditDistanceOp : public OpKernel {\\n       output_shape.AddDim(std::max(hypothesis_st_shape.dim_size(d),\\n                                    truth_st_shape.dim_size(d)));\\n     }\\n+    const auto output_elements = output_shape.num_elements();\\n+    OP_REQUIRES(\\n+        ctx, output_elements > 0,\\n+        errors::InvalidArgument(\"Got output shape \", output_shape.DebugString(),\\n+                                \" which has 0 elements\"));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(\"output\", output_shape, &output));\\n@@ -185,6 +202,12 @@ class EditDistanceOp : public OpKernel {\\n       if (g_truth == g_hypothesis) {\\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\\n                                       output_strides.begin(), int64{0});\\n+        OP_REQUIRES(\\n+            ctx, loc < output_elements,\\n+            errors::Internal(\"Got an inner product \", loc,\\n+                             \" which would require in writing to outside of \"\\n+                             \"the buffer for the output tensor (max elements \",\\n+                             output_elements, \")\"));\\n         output_t(loc) =\\n             gtl::LevenshteinDistance<T>(truth_seq, hypothesis_seq, cmp);\\n         if (normalize_) output_t(loc) \/= truth_seq.size();\\n@@ -194,6 +217,12 @@ class EditDistanceOp : public OpKernel {\\n       } else if (g_truth > g_hypothesis) {  \/\/ zero-length truth\\n         auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\\n                                       output_strides.begin(), int64{0});\\n+        OP_REQUIRES(\\n+            ctx, loc < output_elements,\\n+            errors::Internal(\"Got an inner product \", loc,\\n+                             \" which would require in writing to outside of \"\\n+                             \"the buffer for the output tensor (max elements \",\\n+                             output_elements, \")\"));\\n         output_t(loc) = hypothesis_seq.size();\\n         if (normalize_ && output_t(loc) != 0.0f) {\\n           output_t(loc) = std::numeric_limits<float>::infinity();\\n@@ -202,6 +231,12 @@ class EditDistanceOp : public OpKernel {\\n       } else {  \/\/ zero-length hypothesis\\n         auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\\n                                       output_strides.begin(), int64{0});\\n+        OP_REQUIRES(\\n+            ctx, loc < output_elements,\\n+            errors::Internal(\"Got an inner product \", loc,\\n+                             \" which would require in writing to outside of \"\\n+                             \"the buffer for the output tensor (max elements \",\\n+                             output_elements, \")\"));\\n         output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\\n         ++truth_iter;\\n       }\\n@@ -212,6 +247,12 @@ class EditDistanceOp : public OpKernel {\\n       auto hypothesis_seq = hypothesis_j.values<T>();\\n       auto loc = std::inner_product(g_hypothesis.begin(), g_hypothesis.end(),\\n                                     output_strides.begin(), int64{0});\\n+      OP_REQUIRES(\\n+          ctx, loc < output_elements,\\n+          errors::Internal(\"Got an inner product \", loc,\\n+                           \" which would require in writing to outside of the \"\\n+                           \"buffer for the output tensor (max elements \",\\n+                           output_elements, \")\"));\\n       output_t(loc) = hypothesis_seq.size();\\n       if (normalize_ && output_t(loc) != 0.0f) {\\n         output_t(loc) = std::numeric_limits<float>::infinity();\\n@@ -224,6 +265,12 @@ class EditDistanceOp : public OpKernel {\\n       auto truth_seq = truth_i.values<T>();\\n       auto loc = std::inner_product(g_truth.begin(), g_truth.end(),\\n                                     output_strides.begin(), int64{0});\\n+      OP_REQUIRES(\\n+          ctx, loc < output_elements,\\n+          errors::Internal(\"Got an inner product \", loc,\\n+                           \" which would require in writing to outside of the \"\\n+                           \"buffer for the output tensor (max elements \",\\n+                           output_elements, \")\"));\\n       output_t(loc) = (normalize_) ? 1.0 : truth_seq.size();\\n       ++truth_iter;\\n     }'}}",
            "message_norm":"fix multiple issues in editdistance\n\npiperorigin-revid: 372033948\nchange-id: ieb957c29894af05bdfeb1a0402fced808dfcfd7b",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('issues', 'FLAW', ''), ('372033948', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/edit_distance_op.cc'])",
            "num_files":1.0
        },
        {
            "index":1737,
            "vuln_id":"GHSA-fj59-f6c3-3vw4",
            "cwe_id":"{'CWE-78'}",
            "score":5.9,
            "chain":"{'https:\/\/github.com\/sebhildebrandt\/systeminformation\/commit\/bad372e654cdd549e7d786acbba0035ded54c607'}",
            "dataset":"osv",
            "summary":"Command Injection in systeminformation ### Impact\ncommand injection vulnerability\n\n### Patches\nProblem was fixed with a shell string sanitation fix. Please upgrade to version >= 4.26.2\n\n### Workarounds\nIf you cannot upgrade, be sure to check or sanitize service parameter strings that are passed to `is.services()`, `is.inetChecksite()`, `si.inetLatency()`, `si.networkStats()`, `is.services()` and `si.processLoad()`\n\n### References\n_Are there any links users can visit to find out more?_\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [systeminformation](https:\/\/github.com\/sebhildebrandt\/systeminformation)",
            "published_date":"2020-10-27",
            "chain_len":1,
            "project":"https:\/\/github.com\/sebhildebrandt\/systeminformation",
            "commit_href":"https:\/\/github.com\/sebhildebrandt\/systeminformation\/commit\/bad372e654cdd549e7d786acbba0035ded54c607",
            "commit_sha":"bad372e654cdd549e7d786acbba0035ded54c607",
            "patch":"SINGLE",
            "chain_ord":"['bad372e654cdd549e7d786acbba0035ded54c607']",
            "before_first_fix_commit":"{'147550532ab11cac4b609844a519a1d945f5c103'}",
            "last_fix_commit":"bad372e654cdd549e7d786acbba0035ded54c607",
            "chain_ord_pos":1.0,
            "commit_datetime":"05\/19\/2020, 15:02:51",
            "message":"improved shell sanitation",
            "author":"Sebastian Hildebrandt",
            "comments":null,
            "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
            "files":"{'lib\/util.js': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sebhildebrandt\/systeminformation\/raw\/bad372e654cdd549e7d786acbba0035ded54c607\/lib%2Futil.js', 'patch': '@@ -503,6 +503,9 @@ function sanitizeShellString(str) {\\n   result = result.replace(\/\\\\$\/g, \"\");\\n   result = result.replace(\/#\/g, \"\");\\n   result = result.replace(\/\\\\\\\\\/g, \"\");\\n+  result = result.replace(\/\\\\t\/g, \"\");\\n+  result = result.replace(\/\\\\n\/g, \"\");\\n+  result = result.replace(\/\\\\\"\/g, \"\");\\n   return result\\n }'}}",
            "message_norm":"improved shell sanitation",
            "language":"en",
            "entities":"[('improved', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['lib\/util.js'])",
            "num_files":1.0
        },
        {
            "index":1768,
            "vuln_id":"GHSA-fqq2-xp7m-xvm8",
            "cwe_id":"{'CWE-362', 'CWE-119'}",
            "score":8.1,
            "chain":"{'https:\/\/github.com\/RusPiRo\/ruspiro-singleton\/commit\/b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e'}",
            "dataset":"osv",
            "summary":"Data race in ruspiro-singleton `Singleton<T>` is meant to be a static object that can be initialized lazily. In\norder to satisfy the requirement that `static` items must implement `Sync`,\n`Singleton` implemented both `Sync` and `Send` unconditionally.\n\nThis allows for a bug where non-`Sync` types such as `Cell` can be used in\nsingletons and cause data races in concurrent programs.\n\nThe flaw was corrected in commit `b0d2bd20e` by adding trait bounds, requiring\nthe contaiend type to implement `Sync`.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/RusPiRo\/ruspiro-singleton",
            "commit_href":"https:\/\/github.com\/RusPiRo\/ruspiro-singleton\/commit\/b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e",
            "commit_sha":"b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e",
            "patch":"SINGLE",
            "chain_ord":"['b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e']",
            "before_first_fix_commit":"{'0565f8ef459bd336eda8a6a63d1d50cdb581c2b3'}",
            "last_fix_commit":"b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e",
            "chain_ord_pos":1.0,
            "commit_datetime":"11\/16\/2020, 20:32:29",
            "message":"fix soundness",
            "author":"2ndTaleStudio",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
            "files":"{'src\/lib.rs': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/RusPiRo\/ruspiro-singleton\/raw\/b0d2bd20eb40b9cbc2958b981ba2dcd9e6f9396e\/src%2Flib.rs', 'patch': \"@@ -81,8 +81,10 @@ pub struct Singleton<T: 'static> {\\n \\n \/\/ The Singleton need to implement Send & Sync to ensure cross core compile check mechanics\\n \/\/ this is safe as the inner RWLock ensures cross core safety\\n-unsafe impl<T> Sync for Singleton<T> {}\\n-unsafe impl<T> Send for Singleton<T> {}\\n+\/\/ but we need to be conditional on the inner type to prevent interior mutable types beeing used\\n+\/\/ inside a singleton\\n+unsafe impl<T> Sync for Singleton<T> where T: Sync {}\\n+unsafe impl<T> Send for Singleton<T> where T: Send {}\\n \\n impl<T: 'static> Singleton<T> {\\n     \/\/\/ Create a new [Singleton] instance to be used in a static variable. Only ``const fn`` constructors are allowed\"}}",
            "message_norm":"fix soundness",
            "language":"en",
            "entities":"[('fix', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/lib.rs'])",
            "num_files":1.0
        },
        {
            "index":2047,
            "vuln_id":"GHSA-hf4q-52x6-4p57",
            "cwe_id":"{'CWE-79'}",
            "score":4.8,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/d9bae9df873c2d2a13a2eb08d512019d49ebca68'}",
            "dataset":"osv",
            "summary":"Unrestricted file upload leads to stored cross-site scripting in Microweber Microweber prior to version 1.2.12 allows unrestricted file upload, which could lead to stored cross-site scripting.",
            "published_date":"2022-03-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/d9bae9df873c2d2a13a2eb08d512019d49ebca68",
            "commit_sha":"d9bae9df873c2d2a13a2eb08d512019d49ebca68",
            "patch":"SINGLE",
            "chain_ord":"['d9bae9df873c2d2a13a2eb08d512019d49ebca68']",
            "before_first_fix_commit":"{'8902c415144823c48b056f881aa00ceb1f5d350f'}",
            "last_fix_commit":"d9bae9df873c2d2a13a2eb08d512019d49ebca68",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/09\/2022, 14:55:02",
            "message":"update",
            "author":"Peter Ivanov",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'src\/MicroweberPackages\/Utils\/System\/Files.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/d9bae9df873c2d2a13a2eb08d512019d49ebca68\/src%2FMicroweberPackages%2FUtils%2FSystem%2FFiles.php', 'patch': \"@@ -591,6 +591,7 @@ function get_dangerous_files_extentions()\\n             'py',\\n             'alfa',\\n             'asp',\\n+            'aspx',\\n             'htaccess',\\n             'exe',\\n             'msi',\"}}",
            "message_norm":"update",
            "language":"ro",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/Utils\/System\/Files.php'])",
            "num_files":1.0
        },
        {
            "index":1713,
            "vuln_id":"GHSA-fc38-mxwr-pfhx",
            "cwe_id":"{'CWE-79'}",
            "score":8.0,
            "chain":"{'https:\/\/github.com\/shopware\/platform\/commit\/abe9f69e1f667800f974acccd3047b4930e4b423'}",
            "dataset":"osv",
            "summary":"Cross-Site Scripting via SVG media files ### Impact\nCross-Site Scripting via SVG media files\n\n### Patches\nWe recommend updating to the current version 6.4.3.1. You can get the update to 6.4.3.1 regularly via the Auto-Updater or directly via the download overview.\n\nhttps:\/\/www.shopware.com\/en\/download\/#shopware-6\n\n### Workarounds\nFor older versions of 6.1, 6.2, and 6.3, corresponding security measures are also available via a plugin. For the full range of functions, we recommend updating to the latest Shopware version.",
            "published_date":"2021-08-23",
            "chain_len":1,
            "project":"https:\/\/github.com\/shopware\/platform",
            "commit_href":"https:\/\/github.com\/shopware\/platform\/commit\/abe9f69e1f667800f974acccd3047b4930e4b423",
            "commit_sha":"abe9f69e1f667800f974acccd3047b4930e4b423",
            "patch":"SINGLE",
            "chain_ord":"['abe9f69e1f667800f974acccd3047b4930e4b423']",
            "before_first_fix_commit":"{'912b96de3b839c6c5525c98cbb58f537c2d838be'}",
            "last_fix_commit":"abe9f69e1f667800f974acccd3047b4930e4b423",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/27\/2021, 13:31:10",
            "message":"NEXT-15677 - Fix XSS for SVG files",
            "author":"Jonas Elfering",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
            "files":"{'public\/.htaccess.dist': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/shopware\/platform\/raw\/abe9f69e1f667800f974acccd3047b4930e4b423\/public%2F.htaccess.dist', 'patch': '@@ -36,7 +36,7 @@ DirectoryIndex index.php\\n <\/IfModule>\\n \\n <IfModule mod_headers.c>\\n-    <FilesMatch \"\\\\.svg$\">\\n+    <FilesMatch \"\\\\.(?i:svg)$\">\\n         Header set Content-Security-Policy \"script-src \\'none\\'\"\\n     <\/FilesMatch>\\n <\/IfModule>'}}",
            "message_norm":"next-15677 - fix xss for svg files",
            "language":"en",
            "entities":"[('fix', 'ACTION', ''), ('xss', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['public\/.htaccess.dist'])",
            "num_files":1.0
        },
        {
            "index":565,
            "vuln_id":"GHSA-56cx-wf47-hx7w",
            "cwe_id":"{'CWE-307'}",
            "score":5.3,
            "chain":"{'https:\/\/github.com\/firefly-iii\/firefly-iii\/commit\/afc9f4b7ebc8a240c85864a6e1abda62bfeefae8'}",
            "dataset":"osv",
            "summary":" Improper Restriction of Excessive Authentication Attempts firefly-iii is vulnerable to Improper Restriction of Excessive Authentication Attempts",
            "published_date":"2021-08-09",
            "chain_len":1,
            "project":"https:\/\/github.com\/firefly-iii\/firefly-iii",
            "commit_href":"https:\/\/github.com\/firefly-iii\/firefly-iii\/commit\/afc9f4b7ebc8a240c85864a6e1abda62bfeefae8",
            "commit_sha":"afc9f4b7ebc8a240c85864a6e1abda62bfeefae8",
            "patch":"SINGLE",
            "chain_ord":"['afc9f4b7ebc8a240c85864a6e1abda62bfeefae8']",
            "before_first_fix_commit":"{'cb759e5c21118cf18b29cb4619d7a2a540a9c76f'}",
            "last_fix_commit":"afc9f4b7ebc8a240c85864a6e1abda62bfeefae8",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/23\/2021, 04:26:42",
            "message":"Add missing rate limiter.",
            "author":"James Cole",
            "comments":null,
            "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
            "files":"{'app\/Http\/Controllers\/Auth\/LoginController.php': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/firefly-iii\/firefly-iii\/raw\/afc9f4b7ebc8a240c85864a6e1abda62bfeefae8\/app%2FHttp%2FControllers%2FAuth%2FLoginController.php', 'patch': '@@ -29,6 +29,7 @@\\n use FireflyIII\\\\Providers\\\\RouteServiceProvider;\\n use Illuminate\\\\Contracts\\\\View\\\\Factory;\\n use Illuminate\\\\Foundation\\\\Auth\\\\AuthenticatesUsers;\\n+use Illuminate\\\\Foundation\\\\Auth\\\\ThrottlesLogins;\\n use Illuminate\\\\Http\\\\JsonResponse;\\n use Illuminate\\\\Http\\\\RedirectResponse;\\n use Illuminate\\\\Http\\\\Request;\\n@@ -47,7 +48,7 @@\\n  *\/\\n class LoginController extends Controller\\n {\\n-    use AuthenticatesUsers;\\n+    use AuthenticatesUsers, ThrottlesLogins;\\n \\n     \/**\\n      * Where to redirect users after login.'}}",
            "message_norm":"add missing rate limiter.",
            "language":"et",
            "entities":"[('add', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/Auth\/LoginController.php'])",
            "num_files":1.0
        },
        {
            "index":3344,
            "vuln_id":"GHSA-x28w-hvwc-mp75",
            "cwe_id":"{'CWE-94', 'CWE-96'}",
            "score":7.7,
            "chain":"{'https:\/\/github.com\/microweber\/microweber\/commit\/b2baab6e582b2efe63788d367a2bb61a2fa26470'}",
            "dataset":"osv",
            "summary":"Static Code Injection in Microweber Microweber is a new generation CMS with drag and drop. Prior to version 1.3, Microweber is vulnerable to static code injection.",
            "published_date":"2022-03-11",
            "chain_len":1,
            "project":"https:\/\/github.com\/microweber\/microweber",
            "commit_href":"https:\/\/github.com\/microweber\/microweber\/commit\/b2baab6e582b2efe63788d367a2bb61a2fa26470",
            "commit_sha":"b2baab6e582b2efe63788d367a2bb61a2fa26470",
            "patch":"SINGLE",
            "chain_ord":"['b2baab6e582b2efe63788d367a2bb61a2fa26470']",
            "before_first_fix_commit":"{'a15da374af81c3cd312ee1639e4c6f56c4839f7e'}",
            "last_fix_commit":"b2baab6e582b2efe63788d367a2bb61a2fa26470",
            "chain_ord_pos":1.0,
            "commit_datetime":"03\/09\/2022, 11:13:43",
            "message":"Update ContactInformationTrait.php",
            "author":"Bozhidar Slaveykov",
            "comments":null,
            "stats":"{'additions': 9, 'deletions': 4, 'total': 13}",
            "files":"{'src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ContactInformationTrait.php': {'additions': 9, 'deletions': 4, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/microweber\/microweber\/raw\/b2baab6e582b2efe63788d367a2bb61a2fa26470\/src%2FMicroweberPackages%2FCheckout%2FHttp%2FControllers%2FTraits%2FContactInformationTrait.php', 'patch': \"@@ -36,11 +36,16 @@ public function contactInformation() {\\n \\n     public function contactInformationSave(Request $request) {\\n \\n+        $firstName = strip_tags($request->get('first_name'));\\n+        $lastName = strip_tags($request->get('last_name'));\\n+        $email = strip_tags($request->get('email'));\\n+        $phone = strip_tags($request->get('phone'));\\n+\\n         session_append_array('checkout_v2', [\\n-            'first_name'=> $request->get('first_name'),\\n-            'last_name'=> $request->get('last_name'),\\n-            'email'=> $request->get('email'),\\n-            'phone'=> $request->get('phone')\\n+            'first_name'=> $firstName,\\n+            'last_name'=> $lastName,\\n+            'email'=> $email,\\n+            'phone'=> $phone\\n         ]);\\n \\n         $validate = $this->_validateContactInformation($request->all());\"}}",
            "message_norm":"update contactinformationtrait.php",
            "language":"fr",
            "entities":"[('update', 'ACTION', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['src\/MicroweberPackages\/Checkout\/Http\/Controllers\/Traits\/ContactInformationTrait.php'])",
            "num_files":1.0
        },
        {
            "index":3225,
            "vuln_id":"GHSA-w4xf-2pqw-5mq7",
            "cwe_id":"{'CWE-824'}",
            "score":7.8,
            "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/be7a4de6adfbd303ce08be4332554dff70362612'}",
            "dataset":"osv",
            "summary":"Reference binding to nullptr in `RaggedTensorToVariant` ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToVariant`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedTensorToVariant(\n  rt_nested_splits=[],\n  rt_dense_values=[1,2,3],\n  batched_input=True)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc#L129) has an incomplete validation of the splits values, missing the case when the argument would be empty.\n\n### Patches\nWe have patched the issue in GitHub commit [be7a4de6adfbd303ce08be4332554dff70362612](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/be7a4de6adfbd303ce08be4332554dff70362612).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
            "published_date":"2021-08-25",
            "chain_len":1,
            "project":"https:\/\/github.com\/tensorflow\/tensorflow",
            "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/be7a4de6adfbd303ce08be4332554dff70362612",
            "commit_sha":"be7a4de6adfbd303ce08be4332554dff70362612",
            "patch":"SINGLE",
            "chain_ord":"['be7a4de6adfbd303ce08be4332554dff70362612']",
            "before_first_fix_commit":"{'ffbdacfce0c9c8f627d0ce89d9d4db8fd0a7cfd1'}",
            "last_fix_commit":"be7a4de6adfbd303ce08be4332554dff70362612",
            "chain_ord_pos":1.0,
            "commit_datetime":"07\/29\/2021, 21:05:34",
            "message":"Ensure non-empty rt_nested_splits in tf.raw_ops.RaggedTensorToVariant\n\nPiperOrigin-RevId: 387664237\nChange-Id: Ia1700c34b5610873d63561abc86e23b46ead93b3",
            "author":"Laura Pak",
            "comments":null,
            "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
            "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/be7a4de6adfbd303ce08be4332554dff70362612\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_variant_op.cc', 'patch': '@@ -157,6 +157,12 @@ class RaggedTensorToVariantOp : public OpKernel {\\n       return;\\n     }\\n \\n+    \/\/ Checked here instead of at input in case batched_input_ is false\\n+    OP_REQUIRES(context, ragged_nested_splits_len > 0,\\n+                errors::InvalidArgument(\\n+                    \"rt_nested_splits must be a list of one or more, but \"\\n+                    \"received rt_nested_splits of length 0.\"));\\n+\\n     \/\/ Unbatch the Ragged Tensor and encode the components.\\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\\n     auto batched_splits_top_vec ='}}",
            "message_norm":"ensure non-empty rt_nested_splits in tf.raw_ops.raggedtensortovariant\n\npiperorigin-revid: 387664237\nchange-id: ia1700c34b5610873d63561abc86e23b46ead93b3",
            "language":"en",
            "entities":"[('ensure', 'ACTION', ''), ('387664237', 'SHA', 'generic_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_variant_op.cc'])",
            "num_files":1.0
        },
        {
            "index":3010,
            "vuln_id":"GHSA-rv62-4pmj-xw6h",
            "cwe_id":"{'CWE-601'}",
            "score":6.1,
            "chain":"{'https:\/\/github.com\/jupyter\/notebook\/commit\/08c4c898182edbe97aadef1815cce50448f975cb', 'https:\/\/github.com\/jupyter\/notebook\/commit\/70fe9f0ddb3023162ece21fbb77d5564306b913b', 'https:\/\/github.com\/jupyter\/notebook\/commit\/d65328d4841892b412aef9015165db1eb029a8ed'}",
            "dataset":"osv",
            "summary":"Moderate severity vulnerability that affects jupyterhub and notebook An Open Redirect vulnerability for all browsers in Jupyter Notebook before 5.7.8 and some browsers (Chrome, Firefox) in JupyterHub before 0.9.6 allows crafted links to the login page, which will redirect to a malicious site after successful login. Servers running on a base_url prefix are not affected.",
            "published_date":"2019-04-02",
            "chain_len":3,
            "project":"https:\/\/github.com\/jupyter\/notebook",
            "commit_href":"https:\/\/github.com\/jupyter\/notebook\/commit\/08c4c898182edbe97aadef1815cce50448f975cb",
            "commit_sha":"08c4c898182edbe97aadef1815cce50448f975cb",
            "patch":"MULTI",
            "chain_ord":"['70fe9f0ddb3023162ece21fbb77d5564306b913b', 'd65328d4841892b412aef9015165db1eb029a8ed', '08c4c898182edbe97aadef1815cce50448f975cb']",
            "before_first_fix_commit":"{'d65328d4841892b412aef9015165db1eb029a8ed'}",
            "last_fix_commit":"08c4c898182edbe97aadef1815cce50448f975cb",
            "chain_ord_pos":3.0,
            "commit_datetime":"03\/27\/2019, 20:43:40",
            "message":"protect against chrome mishandling backslash as slash in URLs",
            "author":"Min RK",
            "comments":null,
            "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
            "files":"{'notebook\/auth\/login.py': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jupyter\/notebook\/raw\/08c4c898182edbe97aadef1815cce50448f975cb\/notebook%2Fauth%2Flogin.py', 'patch': '@@ -39,6 +39,10 @@ def _redirect_safe(self, url, default=None):\\n         \"\"\"\\n         if default is None:\\n             default = self.base_url\\n+        # protect chrome users from mishandling unescaped backslashes.\\n+        # \\\\ is not valid in urls, but some browsers treat it as \/\\n+        # instead of %5C, causing `\\\\\\\\` to behave as `\/\/`\\n+        url = url.replace(\"\\\\\\\\\", \"%5C\")\\n         parsed = urlparse(url)\\n         if parsed.netloc or not (parsed.path + \\'\/\\').startswith(self.base_url):\\n             # require that next_url be absolute path within our path'}}",
            "message_norm":"protect against chrome mishandling backslash as slash in urls",
            "language":"en",
            "entities":"[('protect', 'SECWORD', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['notebook\/auth\/login.py'])",
            "num_files":1.0
        },
        {
            "index":2492,
            "vuln_id":"GHSA-p2vw-f87c-q597",
            "cwe_id":"{'CWE-863'}",
            "score":6.5,
            "chain":"{'https:\/\/github.com\/snipe\/snipe-it\/commit\/2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c'}",
            "dataset":"osv",
            "summary":"Improper Access Control in snipe\/snipe-it Improper Access Control in GitHub repository snipe\/snipe-it prior to 5.4.4.",
            "published_date":"2022-04-29",
            "chain_len":1,
            "project":"https:\/\/github.com\/snipe\/snipe-it",
            "commit_href":"https:\/\/github.com\/snipe\/snipe-it\/commit\/2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c",
            "commit_sha":"2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c",
            "patch":"SINGLE",
            "chain_ord":"['2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c']",
            "before_first_fix_commit":"{'126bb486b5146975f562d51b8f75dd2e30bee74d'}",
            "last_fix_commit":"2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c",
            "chain_ord_pos":1.0,
            "commit_datetime":"04\/28\/2022, 14:45:37",
            "message":"Added access gate to the requested assets index\n\nSigned-off-by: snipe <snipe@snipe.net>",
            "author":"snipe",
            "comments":null,
            "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
            "files":"{'app\/Http\/Controllers\/Assets\/AssetsController.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/snipe\/snipe-it\/raw\/2e9cf8fa87a025c0eac9f79f4864b3fdd33a950c\/app%2FHttp%2FControllers%2FAssets%2FAssetsController.php', 'patch': \"@@ -861,6 +861,7 @@ public function auditStore(Request $request, $id)\\n \\n     public function getRequestedIndex($user_id = null)\\n     {\\n+        $this->authorize('index', Asset::class);\\n         $requestedItems = CheckoutRequest::with('user', 'requestedItem')->whereNull('canceled_at')->with('user', 'requestedItem');\\n \\n         if ($user_id) {\"}}",
            "message_norm":"added access gate to the requested assets index\n\nsigned-off-by: snipe <snipe@snipe.net>",
            "language":"en",
            "entities":"[('added', 'ACTION', ''), ('snipe@snipe.net', 'EMAIL', '')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['app\/Http\/Controllers\/Assets\/AssetsController.php'])",
            "num_files":1.0
        },
        {
            "index":2162,
            "vuln_id":"GHSA-hxf9-7h4c-f5jv",
            "cwe_id":"{'CWE-200'}",
            "score":9.1,
            "chain":"{'https:\/\/github.com\/anymail\/django-anymail\/commit\/db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'https:\/\/github.com\/anymail\/django-anymail\/commit\/c07998304b4a31df4c61deddcb03d3607a04691b'}",
            "dataset":"osv",
            "summary":"Django-Anymail prone to a timing attack webhooks\/base.py in Anymail (aka django-anymail) before 1.2.1 is prone to a timing attack vulnerability on the WEBHOOK_AUTHORIZATION secret, which allows remote attackers to post arbitrary e-mail tracking events.",
            "published_date":"2018-07-12",
            "chain_len":2,
            "project":"https:\/\/github.com\/anymail\/django-anymail",
            "commit_href":"https:\/\/github.com\/anymail\/django-anymail\/commit\/c07998304b4a31df4c61deddcb03d3607a04691b",
            "commit_sha":"c07998304b4a31df4c61deddcb03d3607a04691b",
            "patch":"MULTI",
            "chain_ord":"['db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'c07998304b4a31df4c61deddcb03d3607a04691b']",
            "before_first_fix_commit":"{'7029298b930620b1655dab2548f72d6640a5905e'}",
            "last_fix_commit":"c07998304b4a31df4c61deddcb03d3607a04691b",
            "chain_ord_pos":2.0,
            "commit_datetime":"02\/02\/2018, 19:41:14",
            "message":"Security: prevent timing attack on WEBHOOK_AUTHORIZATION secret\n\nAnymail's webhook validation was vulnerable to a timing attack.\nAn attacker could have used this to recover your WEBHOOK_AUTHORIZATION\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nThere have not been any reports of attempted exploit in the wild. (The\nvulnerability was discovered through code review.) Attempts would be\nvisible in http logs as a very large number of 400 responses on\nAnymail's webhook urls, or in Python error monitoring as a very large\nnumber of AnymailWebhookValidationFailure exceptions.\n\nIf you are using Anymail's webhooks, you should upgrade to this release.\nIn addition, you may want to rotate to a new WEBHOOK_AUTHORIZATION\nsecret ([docs](http:\/\/anymail.readthedocs.io\/en\/stable\/tips\/securing_webhooks\/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.\n\n(cherry picked from commit db586ede1fbb41dce21310ea28ae15a1cf1286c5)",
            "author":"medmunds",
            "comments":null,
            "stats":"{'additions': 12, 'deletions': 3, 'total': 15}",
            "files":"{'anymail\/webhooks\/base.py': {'additions': 12, 'deletions': 3, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/anymail\/django-anymail\/raw\/c07998304b4a31df4c61deddcb03d3607a04691b\/anymail%2Fwebhooks%2Fbase.py', 'patch': '@@ -3,6 +3,7 @@\\n \\n import six\\n from django.http import HttpResponse\\n+from django.utils.crypto import constant_time_compare\\n from django.utils.decorators import method_decorator\\n from django.views.decorators.csrf import csrf_exempt\\n from django.views.generic import View\\n@@ -41,8 +42,13 @@ def __init__(self, **kwargs):\\n     def validate_request(self, request):\\n         \"\"\"If configured for webhook basic auth, validate request has correct auth.\"\"\"\\n         if self.basic_auth:\\n-            basic_auth = get_request_basic_auth(request)\\n-            if basic_auth is None or basic_auth not in self.basic_auth:\\n+            request_auth = get_request_basic_auth(request)\\n+            # Use constant_time_compare to avoid timing attack on basic auth. (It\\'s OK that any()\\n+            # can terminate early: we\\'re not trying to protect how many auth strings are allowed,\\n+            # just the contents of each individual auth string.)\\n+            auth_ok = any(constant_time_compare(request_auth, allowed_auth)\\n+                          for allowed_auth in self.basic_auth)\\n+            if not auth_ok:\\n                 # noinspection PyUnresolvedReferences\\n                 raise AnymailWebhookValidationFailure(\\n                     \"Missing or invalid basic auth in Anymail %s webhook\" % self.esp_name)\\n@@ -78,8 +84,11 @@ def validate_request(self, request):\\n         *All* definitions of this method in the class chain (including mixins)\\n         will be called. There is no need to chain to the superclass.\\n         (See self.run_validators and collect_all_methods.)\\n+\\n+        Security note: use django.utils.crypto.constant_time_compare for string\\n+        comparisons, to avoid exposing your validation to a timing attack.\\n         \"\"\"\\n-        # if request.POST[\\'signature\\'] != expected_signature:\\n+        # if not constant_time_compare(request.POST[\\'signature\\'], expected_signature):\\n         #     raise AnymailWebhookValidationFailure(\"...message...\")\\n         # (else just do nothing)\\n         pass'}}",
            "message_norm":"security: prevent timing attack on webhook_authorization secret\n\nanymail's webhook validation was vulnerable to a timing attack.\nan attacker could have used this to recover your webhook_authorization\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nthere have not been any reports of attempted exploit in the wild. (the\nvulnerability was discovered through code review.) attempts would be\nvisible in http logs as a very large number of 400 responses on\nanymail's webhook urls, or in python error monitoring as a very large\nnumber of anymailwebhookvalidationfailure exceptions.\n\nif you are using anymail's webhooks, you should upgrade to this release.\nin addition, you may want to rotate to a new webhook_authorization\nsecret ([docs](http:\/\/anymail.readthedocs.io\/en\/stable\/tips\/securing_webhooks\/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.\n\n(cherry picked from commit db586ede1fbb41dce21310ea28ae15a1cf1286c5)",
            "language":"en",
            "entities":"[('security', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('attack', 'SECWORD', ''), ('vulnerable', 'SECWORD', ''), ('attack', 'FLAW', ''), ('attacker', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('exploit', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('error', 'FLAW', ''), ('upgrade', 'ACTION', ''), ('docs](http:\/\/anymail.readthedocs.io', 'URL', ''), ('exploit', 'SECWORD', ''), ('commit db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'SHA', 'prefix_colon_sha')]",
            "classification_level_1":null,
            "classification_level_2":null,
            "list_files":"dict_keys(['anymail\/webhooks\/base.py'])",
            "num_files":1.0
        }
    ]
}