{
  "schema": {
    "fields": [
      {
        "name": "index",
        "type": "integer"
      },
      {
        "name": "vuln_id",
        "type": "string"
      },
      {
        "name": "cwe_id",
        "type": "string"
      },
      {
        "name": "score",
        "type": "number"
      },
      {
        "name": "chain",
        "type": "string"
      },
      {
        "name": "dataset",
        "type": "string"
      },
      {
        "name": "summary",
        "type": "string"
      },
      {
        "name": "published_date",
        "type": "string"
      },
      {
        "name": "chain_len",
        "type": "integer"
      },
      {
        "name": "project",
        "type": "string"
      },
      {
        "name": "commit_href",
        "type": "string"
      },
      {
        "name": "commit_sha",
        "type": "string"
      },
      {
        "name": "patch",
        "type": "string"
      },
      {
        "name": "chain_ord",
        "type": "string"
      },
      {
        "name": "before_first_fix_commit",
        "type": "string"
      },
      {
        "name": "last_fix_commit",
        "type": "string"
      },
      {
        "name": "chain_ord_pos",
        "type": "number"
      },
      {
        "name": "commit_datetime",
        "type": "string"
      },
      {
        "name": "message",
        "type": "string"
      },
      {
        "name": "author",
        "type": "string"
      },
      {
        "name": "comments",
        "type": "string"
      },
      {
        "name": "stats",
        "type": "string"
      },
      {
        "name": "files",
        "type": "string"
      },
      {
        "name": "message_norm",
        "type": "string"
      },
      {
        "name": "language",
        "type": "string"
      },
      {
        "name": "entities",
        "type": "string"
      },
      {
        "name": "classification_level_1",
        "type": "string"
      },
      {
        "name": "classification_level_2",
        "type": "string"
      },
      {
        "name": "list_files",
        "type": "string"
      },
      {
        "name": "num_files",
        "type": "number"
      }
    ],
    "primaryKey": [
      "index"
    ],
    "pandas_version": "1.4.0"
  },
  "data": [
    {
      "index": 2011,
      "vuln_id": "GHSA-h6xx-pmxh-3wgp",
      "cwe_id": "{'CWE-285', 'CWE-287'}",
      "score": 8.1,
      "chain": "{'https://github.com/etcd-io/etcd/commit/bf9d0d8291dc71ecbfb2690612954e1a298154b2', 'https://github.com/etcd-io/etcd/commit/0191509637546621d6f2e18e074e955ab8ef374d'}",
      "dataset": "osv",
      "summary": "Improper Authentication in etcd etcd versions 3.2.x before 3.2.26 and 3.3.x before 3.3.11 are vulnerable to an improper authentication issue when role-based access control (RBAC) is used and client-cert-auth is enabled. If an etcd client server TLS certificate contains a Common Name (CN) which matches a valid RBAC username, a remote attacker may authenticate as that user with any valid (trusted) client certificate in a REST API request to the gRPC-gateway.",
      "published_date": "2022-02-15",
      "chain_len": 2,
      "project": "https://github.com/etcd-io/etcd",
      "commit_href": "https://github.com/etcd-io/etcd/commit/bf9d0d8291dc71ecbfb2690612954e1a298154b2",
      "commit_sha": "bf9d0d8291dc71ecbfb2690612954e1a298154b2",
      "patch": "MULTI",
      "chain_ord": "['0191509637546621d6f2e18e074e955ab8ef374d', 'bf9d0d8291dc71ecbfb2690612954e1a298154b2']",
      "before_first_fix_commit": "{'9c6b407e7d45b89c72c45a065294b6eac91888ab'}",
      "last_fix_commit": "bf9d0d8291dc71ecbfb2690612954e1a298154b2",
      "chain_ord_pos": 2.0,
      "commit_datetime": "01/02/2019, 20:54:40",
      "message": "auth: disable CommonName auth for gRPC-gateway\n\nSigned-off-by: Sam Batschelet <sbatsche@redhat.com>",
      "author": "Sam Batschelet",
      "comments": null,
      "stats": "{'additions': 21, 'deletions': 0, 'total': 21}",
      "files": "{'auth/store.go': {'additions': 21, 'deletions': 0, 'changes': 21, 'status': 'modified', 'raw_url': 'https://github.com/etcd-io/etcd/raw/bf9d0d8291dc71ecbfb2690612954e1a298154b2/auth%2Fstore.go', 'patch': '@@ -1166,6 +1166,27 @@ func (as *authStore) AuthInfoFromTLS(ctx context.Context) (ai *AuthInfo) {\\n \\t\\t\\tUsername: chains[0].Subject.CommonName,\\n \\t\\t\\tRevision: as.Revision(),\\n \\t\\t}\\n+\\t\\tmd, ok := metadata.FromIncomingContext(ctx)\\n+\\t\\tif !ok {\\n+\\t\\t\\treturn nil\\n+\\t\\t}\\n+\\n+\\t\\t// gRPC-gateway proxy request to etcd server includes Grpcgateway-Accept\\n+\\t\\t// header. The proxy uses etcd client server certificate. If the certificate\\n+\\t\\t// has a CommonName we should never use this for authentication.\\n+\\t\\tif gw := md[\"grpcgateway-accept\"]; len(gw) > 0 {\\n+\\t\\t\\tif as.lg != nil {\\n+\\t\\t\\t\\tas.lg.Warn(\\n+\\t\\t\\t\\t\\t\"ignoring common name in gRPC-gateway proxy request\",\\n+\\t\\t\\t\\t\\tzap.String(\"common-name\", ai.Username),\\n+\\t\\t\\t\\t\\tzap.String(\"user-name\", ai.Username),\\n+\\t\\t\\t\\t\\tzap.Uint64(\"revision\", ai.Revision),\\n+\\t\\t\\t\\t)\\n+\\t\\t\\t} else {\\n+\\t\\t\\t\\tplog.Warningf(\"ignoring common name in gRPC-gateway proxy request %s\", ai.Username)\\n+\\t\\t\\t}\\n+\\t\\t\\treturn nil\\n+\\t\\t}\\n \\t\\tif as.lg != nil {\\n \\t\\t\\tas.lg.Debug(\\n \\t\\t\\t\\t\"found command name\",'}}",
      "message_norm": "auth: disable commonname auth for grpc-gateway\n\nsigned-off-by: sam batschelet <sbatsche@redhat.com>",
      "language": "en",
      "entities": "[('auth', 'SECWORD', ''), ('auth', 'SECWORD', ''), ('sbatsche@redhat.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['auth/store.go'])",
      "num_files": 1.0
    },
    {
      "index": 394,
      "vuln_id": "GHSA-49qr-xh3w-h436",
      "cwe_id": "{'CWE-79'}",
      "score": 6.1,
      "chain": "{'https://github.com/jupyter/notebook/commit/107a89fce5f413fb5728c1c5d2c7788e1fb17491'}",
      "dataset": "osv",
      "summary": "Moderate severity vulnerability that affects notebook Jupyter Notebook before 5.7.1 allows XSS via an untrusted notebook because nbconvert responses are considered to have the same origin as the notebook server. In other words, nbconvert endpoints can execute JavaScript with access to the server API. In notebook/nbconvert/handlers.py, NbconvertFileHandler and NbconvertPostHandler do not set a Content Security Policy to prevent this.",
      "published_date": "2018-11-21",
      "chain_len": 1,
      "project": "https://github.com/jupyter/notebook",
      "commit_href": "https://github.com/jupyter/notebook/commit/107a89fce5f413fb5728c1c5d2c7788e1fb17491",
      "commit_sha": "107a89fce5f413fb5728c1c5d2c7788e1fb17491",
      "patch": "SINGLE",
      "chain_ord": "['107a89fce5f413fb5728c1c5d2c7788e1fb17491']",
      "before_first_fix_commit": "{'04a686dbaf9dfe553324a03cb9e6f778cf1e3da1'}",
      "last_fix_commit": "107a89fce5f413fb5728c1c5d2c7788e1fb17491",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/22/2018, 13:52:36",
      "message": "Apply CSP sandboxing for nbconvert responses\n\nThese may contain untrusted content, so they should be treated as being\nfrom a different domain to the notebook server.",
      "author": "Thomas Kluyver",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 0, 'total': 14}",
      "files": "{'notebook/nbconvert/handlers.py': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https://github.com/jupyter/notebook/raw/107a89fce5f413fb5728c1c5d2c7788e1fb17491/notebook%2Fnbconvert%2Fhandlers.py', 'patch': '@@ -78,6 +78,13 @@ class NbconvertFileHandler(IPythonHandler):\\n \\n     SUPPORTED_METHODS = (\\'GET\\',)\\n \\n+    @property\\n+    def content_security_policy(self):\\n+        # In case we\\'re serving HTML/SVG, confine any Javascript to a unique\\n+        # origin so it can\\'t interact with the notebook server.\\n+        return super(NbconvertFileHandler, self).content_security_policy + \\\\\\n+               \"; sandbox allow-scripts\"\\n+\\n     @web.authenticated\\n     def get(self, format, path):\\n \\n@@ -145,6 +152,13 @@ def get(self, format, path):\\n class NbconvertPostHandler(IPythonHandler):\\n     SUPPORTED_METHODS = (\\'POST\\',)\\n \\n+    @property\\n+    def content_security_policy(self):\\n+        # In case we\\'re serving HTML/SVG, confine any Javascript to a unique\\n+        # origin so it can\\'t interact with the notebook server.\\n+        return super(NbconvertPostHandler, self).content_security_policy + \\\\\\n+               \"; sandbox allow-scripts\"\\n+\\n     @web.authenticated\\n     def post(self, format):\\n         exporter = get_exporter(format, config=self.config)'}}",
      "message_norm": "apply csp sandboxing for nbconvert responses\n\nthese may contain untrusted content, so they should be treated as being\nfrom a different domain to the notebook server.",
      "language": "en",
      "entities": "[('untrusted', 'SECWORD', ''), ('server', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['notebook/nbconvert/handlers.py'])",
      "num_files": 1.0
    },
    {
      "index": 2320,
      "vuln_id": "GHSA-jxqv-jcvh-7gr4",
      "cwe_id": "{'CWE-208', 'CWE-203'}",
      "score": 7.5,
      "chain": "{'https://github.com/runatlantis/atlantis/commit/48870911974adddaa4c99c8089e79b7d787fa820'}",
      "dataset": "osv",
      "summary": "Atlantis Events prior to 0.19.7 vulnerable to Timing Attack The package github.com/runatlantis/atlantis/server/controllers/events before 0.19.7 are vulnerable to Timing Attack in the webhook event validator code, which does not use a constant-time comparison function to validate the webhook secret. It can allow an attacker to recover this secret as an attacker and then forge webhook events.",
      "published_date": "2022-07-30",
      "chain_len": 1,
      "project": "https://github.com/runatlantis/atlantis",
      "commit_href": "https://github.com/runatlantis/atlantis/commit/48870911974adddaa4c99c8089e79b7d787fa820",
      "commit_sha": "48870911974adddaa4c99c8089e79b7d787fa820",
      "patch": "SINGLE",
      "chain_ord": "['48870911974adddaa4c99c8089e79b7d787fa820']",
      "before_first_fix_commit": "{'e153cea2bf1305e71c4f6a958c1378e22caa0211'}",
      "last_fix_commit": "48870911974adddaa4c99c8089e79b7d787fa820",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/15/2022, 16:54:36",
      "message": "fix: use constant time comparison of webhook secret in gitlab event validator (#2392)",
      "author": "Connor Edwards",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'server/controllers/events/gitlab_request_parser_validator.go': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/runatlantis/atlantis/raw/48870911974adddaa4c99c8089e79b7d787fa820/server%2Fcontrollers%2Fevents%2Fgitlab_request_parser_validator.go', 'patch': '@@ -14,6 +14,7 @@\\n package events\\n \\n import (\\n+\\t\"crypto/subtle\"\\n \\t\"encoding/json\"\\n \\t\"fmt\"\\n \\t\"io\"\\n@@ -61,8 +62,7 @@ func (d *DefaultGitlabRequestParserValidator) ParseAndValidate(r *http.Request,\\n \\n \\t// Validate secret if specified.\\n \\theaderSecret := r.Header.Get(secretHeader)\\n-\\tsecretStr := string(secret)\\n-\\tif len(secret) != 0 && headerSecret != secretStr {\\n+\\tif len(secret) != 0 && subtle.ConstantTimeCompare(secret, []byte(headerSecret)) != 1 {\\n \\t\\treturn nil, fmt.Errorf(\"header %s=%s did not match expected secret\", secretHeader, headerSecret)\\n \\t}'}}",
      "message_norm": "fix: use constant time comparison of webhook secret in gitlab event validator (#2392)",
      "language": "en",
      "entities": "[('#2392', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/controllers/events/gitlab_request_parser_validator.go'])",
      "num_files": 1.0
    },
    {
      "index": 987,
      "vuln_id": "GHSA-773q-5334-5gf9",
      "cwe_id": "{'CWE-789'}",
      "score": 0.0,
      "chain": "{'https://github.com/rust-blockchain/evm/commit/19ade858c430ab13eb562764a870ac9f8506f8dd'}",
      "dataset": "osv",
      "summary": "Memory over-allocation in evm-core Prior to the patch, when executing specific EVM opcodes related\nto memory operations that use `evm_core::Memory::copy_large`, the\ncrate can over-allocate memory when it is not needed, making it\npossible for an attacker to perform denial-of-service attack.\n\nThe flaw was corrected in commit `19ade85`.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/rust-blockchain/evm",
      "commit_href": "https://github.com/rust-blockchain/evm/commit/19ade858c430ab13eb562764a870ac9f8506f8dd",
      "commit_sha": "19ade858c430ab13eb562764a870ac9f8506f8dd",
      "patch": "SINGLE",
      "chain_ord": "['19ade858c430ab13eb562764a870ac9f8506f8dd']",
      "before_first_fix_commit": "{'2a8a3e967ec265fdc7120ff6b57ceab021ca69f6'}",
      "last_fix_commit": "19ade858c430ab13eb562764a870ac9f8506f8dd",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/11/2021, 15:33:30",
      "message": "Skip setting memory value if the value vec is empty",
      "author": "Wei Tang",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'core/src/memory.rs': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/rust-blockchain/evm/raw/19ade858c430ab13eb562764a870ac9f8506f8dd/core%2Fsrc%2Fmemory.rs', 'patch': '@@ -105,6 +105,10 @@ impl Memory {\\n \\t\\tvalue: &[u8],\\n \\t\\ttarget_size: Option<usize>\\n \\t) -> Result<(), ExitFatal> {\\n+\\t\\tif value.is_empty() {\\n+\\t\\t\\treturn Ok(())\\n+\\t\\t}\\n+\\t\\t\\n \\t\\tlet target_size = target_size.unwrap_or(value.len());\\n \\n \\t\\tif offset.checked_add(target_size)'}}",
      "message_norm": "skip setting memory value if the value vec is empty",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['core/src/memory.rs'])",
      "num_files": 1.0
    },
    {
      "index": 1439,
      "vuln_id": "GHSA-9w2p-5mgw-p94c",
      "cwe_id": "{'CWE-681'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/96f364a1ca3009f98980021c4b32be5fdcca33a1'}",
      "dataset": "osv",
      "summary": "Integer overflow due to conversion to unsigned ### Impact\nThe implementation of `tf.raw_ops.QuantizeAndDequantizeV4Grad` is vulnerable to an integer overflow issue caused by converting a signed integer value to an unsigned one and then allocating memory based on this value.\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeAndDequantizeV4Grad(\n  gradients=[1.0,2.0],\n  input=[1.0,1.0],\n  input_min=[0.0],\n  input_max=[10.0],\n  axis=-100)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/quantize_and_dequantize_op.cc#L126) uses the `axis` value as the size argument to `absl::InlinedVector` constructor. But, the constructor uses an unsigned type for the argument, so the implicit conversion transforms the negative value to a large integer.\n\n### Patches\nWe have patched the issue in GitHub commit [96f364a1ca3009f98980021c4b32be5fdcca33a1](https://github.com/tensorflow/tensorflow/commit/96f364a1ca3009f98980021c4b32be5fdcca33a1).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, and TensorFlow 2.4.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/96f364a1ca3009f98980021c4b32be5fdcca33a1",
      "commit_sha": "96f364a1ca3009f98980021c4b32be5fdcca33a1",
      "patch": "SINGLE",
      "chain_ord": "['96f364a1ca3009f98980021c4b32be5fdcca33a1']",
      "before_first_fix_commit": "{'10fe168385e67aca66427910ba6942eb14d31c5a'}",
      "last_fix_commit": "96f364a1ca3009f98980021c4b32be5fdcca33a1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/02/2021, 20:27:01",
      "message": "Validate axis input in tf.raw_ops.QuantizeAndDequantizeV4Grad\n\nPiperOrigin-RevId: 388291385\nChange-Id: I3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 0, 'total': 7}",
      "files": "{'tensorflow/core/kernels/quantize_and_dequantize_op.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/96f364a1ca3009f98980021c4b32be5fdcca33a1/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -158,6 +158,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {\\n     Tensor* input_backprop = nullptr;\\n     OP_REQUIRES_OK(ctx,\\n                    ctx->allocate_output(0, input.shape(), &input_backprop));\\n+    OP_REQUIRES(\\n+        ctx, axis_ >= -1,\\n+        errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));\\n+    OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),\\n+                errors::InvalidArgument(\\n+                    \"Axis should be -1 or 0 or a positive value less than \",\\n+                    input.shape().dims(), \"but given axis value was \", axis_));\\n \\n     OP_REQUIRES(\\n         ctx, input.IsSameSize(gradient),'}}",
      "message_norm": "validate axis input in tf.raw_ops.quantizeanddequantizev4grad\n\npiperorigin-revid: 388291385\nchange-id: i3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
      "language": "ca",
      "entities": "[('validate', 'ACTION', ''), ('388291385', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/quantize_and_dequantize_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1072,
      "vuln_id": "GHSA-7r87-cj48-wj45",
      "cwe_id": "{'CWE-253', 'CWE-394', 'CWE-754'}",
      "score": 5.3,
      "chain": "{'https://github.com/Tethik/flask-session-captcha/commit/2811ae23a38d33b620fb7a07de8837c6d65c13e4'}",
      "dataset": "osv",
      "summary": "Potential Captcha Validate Bypass in flask-session-captcha ### Impact\nflask-session-captcha is a package which allows users to extend Flask by adding an image based captcha stored in a server side session.\n\nThe `captcha.validate()` function would return `None` if passed no value (e.g. by submitting a request with an empty form).\n\nIf implementing users were checking the return value to be **False**, the captcha verification check could be bypassed.\n\nSample vulnerable code:\n```python\nif captcha.validate() == False:\n    ... # abort\nelse:\n   ... # do stuff\n```\n\n### Patches\nA new version (1.2.1) is available that fixes the issue.\n\n### Workarounds\nUsers can workaround the issue by not explicitly checking that the value is False. \n\nChecking the return value less explicitly should still work. \n\n```python\nif not captcha.validate():\n    ... # abort\nelse:\n   ... # do stuff\n```\n\n```python\nif captcha.validate():\n    ... # do stuff\nelse:\n   ... # abort\n```\n\n### References\nhttps://github.com/Tethik/flask-session-captcha/pull/27\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [the github repo](https://github.com/Tethik/flask-session-captcha)",
      "published_date": "2022-04-26",
      "chain_len": 1,
      "project": "https://github.com/Tethik/flask-session-captcha",
      "commit_href": "https://github.com/Tethik/flask-session-captcha/commit/2811ae23a38d33b620fb7a07de8837c6d65c13e4",
      "commit_sha": "2811ae23a38d33b620fb7a07de8837c6d65c13e4",
      "patch": "SINGLE",
      "chain_ord": "['2811ae23a38d33b620fb7a07de8837c6d65c13e4']",
      "before_first_fix_commit": "{'50b4053766b89e9322cfbd281c91cb4e8898d3f7'}",
      "last_fix_commit": "2811ae23a38d33b620fb7a07de8837c6d65c13e4",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/23/2022, 21:40:14",
      "message": "add some extra tests to ensure False is returned",
      "author": "Joakim Uddholm",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 1, 'total': 8}",
      "files": "{'test_flask_session_captcha.py': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/Tethik/flask-session-captcha/raw/2811ae23a38d33b620fb7a07de8837c6d65c13e4/test_flask_session_captcha.py', 'patch': '@@ -98,7 +98,13 @@ def test_captcha_validate_value(self):\\n         with self.app.test_request_context(\\'/\\'):\\n             captcha.generate()\\n             answer = captcha.get_answer()\\n-            assert not captcha.validate(value=\"wrong\")\\n+            assert captcha.validate(value=None) == False\\n+            captcha.generate()\\n+            answer = captcha.get_answer()\\n+            assert captcha.validate(value=\"\") == False\\n+            captcha.generate()\\n+            answer = captcha.get_answer()\\n+            assert captcha.validate(value=\"wrong\") == False\\n             captcha.generate()\\n             answer = captcha.get_answer()\\n             assert captcha.validate(value=answer)'}}",
      "message_norm": "add some extra tests to ensure false is returned",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('ensure', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['test_flask_session_captcha.py'])",
      "num_files": 1.0
    },
    {
      "index": 1018,
      "vuln_id": "GHSA-7f62-4887-cfv5",
      "cwe_id": "{'CWE-269'}",
      "score": 8.8,
      "chain": "{'https://github.com/alextselegidis/easyappointments/commit/63dbb51decfcc1631c398ecd6d30e3a337845526'}",
      "dataset": "osv",
      "summary": "Privilege escalation in easyappointments The Easy!Appointments API authorization is checked against the user's existence, without validating the permissions. As a result, a low privileged user (eg. provider) can create a new admin user via the \"/api/v1/admins/\" endpoint and take over the system. A [patch](https://github.com/alextselegidis/easyappointments/commit/63dbb51decfcc1631c398ecd6d30e3a337845526) is available on the `develop` branch of the repository.",
      "published_date": "2022-05-11",
      "chain_len": 1,
      "project": "https://github.com/alextselegidis/easyappointments",
      "commit_href": "https://github.com/alextselegidis/easyappointments/commit/63dbb51decfcc1631c398ecd6d30e3a337845526",
      "commit_sha": "63dbb51decfcc1631c398ecd6d30e3a337845526",
      "patch": "SINGLE",
      "chain_ord": "['63dbb51decfcc1631c398ecd6d30e3a337845526']",
      "before_first_fix_commit": "{'f0e976c9ac9be2a7e7626d2112c71042ba087dfa'}",
      "last_fix_commit": "63dbb51decfcc1631c398ecd6d30e3a337845526",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/09/2022, 21:26:28",
      "message": "Check the role slug in Api.php",
      "author": "Alex Tselegidis",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 1, 'total': 4}",
      "files": "{'application/libraries/Api.php': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/alextselegidis/easyappointments/raw/63dbb51decfcc1631c398ecd6d30e3a337845526/application%2Flibraries%2FApi.php', 'patch': \"@@ -77,7 +77,9 @@ public function auth()\\n \\n             $password = $_SERVER['PHP_AUTH_PW'];\\n \\n-            if ( ! $this->CI->accounts->check_login($username, $password))\\n+            $userdata = $this->CI->accounts->check_login($username, $password);\\n+\\n+            if (empty($userdata['role_slug']) || $userdata['role_slug'] !== DB_SLUG_ADMIN)\\n             {\\n                 throw new RuntimeException('The provided credentials do not match any admin user!', 401, 'Unauthorized');\\n             }\"}}",
      "message_norm": "check the role slug in api.php",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['application/libraries/Api.php'])",
      "num_files": 1.0
    },
    {
      "index": 1251,
      "vuln_id": "GHSA-8rm6-75mf-7r7r",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/5117e0851348065ed59c991562c0ec80d9193db2'}",
      "dataset": "osv",
      "summary": "Division by zero in TFLite's implementation of hashtable lookup ### Impact\nThe TFLite implementation of hashtable lookup is [vulnerable to a division by zero error](https://github.com/tensorflow/tensorflow/blob/1a8e885b864c818198a5b2c0cbbeca5a1e833bc8/tensorflow/lite/kernels/hashtable_lookup.cc#L114-L115):\n\n```cc\nconst int num_rows = SizeOfDimension(value, 0); \nconst int row_bytes = value->bytes / num_rows; \n```\n\nAn attacker can craft a model such that `values`'s first dimension would be 0.\n\n### Patches\nWe have patched the issue in GitHub commit [5117e0851348065ed59c991562c0ec80d9193db2](https://github.com/tensorflow/tensorflow/commit/5117e0851348065ed59c991562c0ec80d9193db2).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/5117e0851348065ed59c991562c0ec80d9193db2",
      "commit_sha": "5117e0851348065ed59c991562c0ec80d9193db2",
      "patch": "SINGLE",
      "chain_ord": "['5117e0851348065ed59c991562c0ec80d9193db2']",
      "before_first_fix_commit": "{'ba6822bd7b7324ba201a28b2f278c29a98edbef2'}",
      "last_fix_commit": "5117e0851348065ed59c991562c0ec80d9193db2",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 23:16:56",
      "message": "Prevent a division by 0\n\nPiperOrigin-RevId: 371007407\nChange-Id: Iecf2718de48d6bf5a69b02a9df9deda8ec1b19d3",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'tensorflow/lite/kernels/hashtable_lookup.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/5117e0851348065ed59c991562c0ec80d9193db2/tensorflow%2Flite%2Fkernels%2Fhashtable_lookup.cc', 'patch': '@@ -112,6 +112,7 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\\n \\n   const int num_rows = SizeOfDimension(value, 0);\\n+  TF_LITE_ENSURE(context, num_rows != 0);\\n   const int row_bytes = value->bytes / num_rows;\\n   void* pointer = nullptr;\\n   DynamicBuffer buf;'}}",
      "message_norm": "prevent a division by 0\n\npiperorigin-revid: 371007407\nchange-id: iecf2718de48d6bf5a69b02a9df9deda8ec1b19d3",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('371007407', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/hashtable_lookup.cc'])",
      "num_files": 1.0
    },
    {
      "index": 345,
      "vuln_id": "GHSA-43f8-2h32-f4cj",
      "cwe_id": "{'CWE-400'}",
      "score": 5.3,
      "chain": "{'https://github.com/npm/hosted-git-info/commit/bede0dc38e1785e732bf0a48ba6f81a4a908eba3', 'https://github.com/npm/hosted-git-info/commit/8d4b3697d79bcd89cdb36d1db165e3696c783a01', 'https://github.com/npm/hosted-git-info/commit/29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service in hosted-git-info The npm package `hosted-git-info` before 3.0.8 are vulnerable to Regular Expression Denial of Service (ReDoS) via regular expression shortcutMatch in the fromUrl function in index.js. The affected regular expression exhibits polynomial worst-case time complexity",
      "published_date": "2021-05-06",
      "chain_len": 3,
      "project": "https://github.com/npm/hosted-git-info",
      "commit_href": "https://github.com/npm/hosted-git-info/commit/29adfe5ef789784c861b2cdeb15051ec2ba651a7",
      "commit_sha": "29adfe5ef789784c861b2cdeb15051ec2ba651a7",
      "patch": "MULTI",
      "chain_ord": "['bede0dc38e1785e732bf0a48ba6f81a4a908eba3', '29adfe5ef789784c861b2cdeb15051ec2ba651a7', '8d4b3697d79bcd89cdb36d1db165e3696c783a01']",
      "before_first_fix_commit": "{'29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
      "last_fix_commit": "8d4b3697d79bcd89cdb36d1db165e3696c783a01",
      "chain_ord_pos": 2.0,
      "commit_datetime": "04/07/2021, 19:31:52",
      "message": "fix: backport regex fix from #76\n\nPR-URL: https://github.com/npm/hosted-git-info/pull/84\nCredit: @nlf\nClose: #84\nReviewed-by: @wraithgar",
      "author": "nlf",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/npm/hosted-git-info/raw/29adfe5ef789784c861b2cdeb15051ec2ba651a7/index.js', 'patch': \"@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\\n   )\\n   var parsed = parseGitUrl(url)\\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^/]*))[/](.+?)(?:[.]git)?($|#)'))\\n+  var shortcutMatch = url.match(/^([^:]+):(?:[^@]+@)?(?:([^/]*)\\\\/)?([^#]+)/)\\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\\n     try {\\n       var gitHostInfo = gitHosts[gitHostName]\\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\\n       var defaultRepresentation = null\\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\\n-        project = decodeURIComponent(shortcutMatch[3])\\n+        project = decodeURIComponent(shortcutMatch[3].replace(/\\\\.git$/, ''))\\n         defaultRepresentation = 'shortcut'\\n       } else {\\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(/^www[.]/, '') !== gitHostInfo.domain) return\"}}",
      "message_norm": "fix: backport regex fix from #76\n\npr-url: https://github.com/npm/hosted-git-info/pull/84\ncredit: @nlf\nclose: #84\nreviewed-by: @wraithgar",
      "language": "en",
      "entities": "[('#76', 'ISSUE', ''), ('https://github.com/npm/hosted-git-info/pull/84', 'URL', ''), ('#84', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 648,
      "vuln_id": "GHSA-5jgj-h9wp-53fr",
      "cwe_id": "{'CWE-79'}",
      "score": 6.1,
      "chain": "{'https://github.com/idno/known/commit/80b716a8392fb71cfce84d03aaf7c045c62f6350'}",
      "dataset": "osv",
      "summary": "Known vulnerable to code execution via SVG file in v1.3.1 An issue in the isSVG() function of Known v1.3.1 allows attackers to execute arbitrary code via a crafted SVG file.\n\nThe researcher report indicates that versions 1.3.1 and prior are vulnerable. Version 1.2.2 is the last version tagged on GitHub and in Packagist, and development related to the 1.3.x branch is currently on the `dev` branch of the idno/known repository.",
      "published_date": "2022-07-09",
      "chain_len": 1,
      "project": "https://github.com/idno/known",
      "commit_href": "https://github.com/idno/known/commit/80b716a8392fb71cfce84d03aaf7c045c62f6350",
      "commit_sha": "80b716a8392fb71cfce84d03aaf7c045c62f6350",
      "patch": "SINGLE",
      "chain_ord": "['80b716a8392fb71cfce84d03aaf7c045c62f6350']",
      "before_first_fix_commit": "{'e86e779cf1db93cd488ee578e92a16008132a114'}",
      "last_fix_commit": "80b716a8392fb71cfce84d03aaf7c045c62f6350",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/18/2021, 15:44:26",
      "message": "Checking for script tags in GIFs etc (#3017)",
      "author": "Ben Werdmuller",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 0, 'total': 14}",
      "files": "{'Idno/Entities/File.php': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https://github.com/idno/known/raw/80b716a8392fb71cfce84d03aaf7c045c62f6350/Idno%2FEntities%2FFile.php', 'patch': \"@@ -285,6 +285,20 @@ public static function isImage($file_path)\\n             return false;\\n         }\\n \\n+        /**\\n+         * Detects whether the file contains PHP or script tags, eg to check for embedded code in GIFs\\n+         * @param $file_path\\n+         * @return bool\\n+         */\\n+        public static function isFileFreeFromScriptTags($file_path)\\n+        {\\n+            if ($contents = file_get_contents($file_path)) {\\n+                if (stripos($contents, '<script') || strpos($contents, '<?')) return false;\\n+                return true;\\n+            }\\n+            return false;\\n+        }\\n+\\n         /**\\n          * Retrieve a file by ID\\n          *\"}}",
      "message_norm": "checking for script tags in gifs etc (#3017)",
      "language": "en",
      "entities": "[('#3017', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['Idno/Entities/File.php'])",
      "num_files": 1.0
    },
    {
      "index": 325,
      "vuln_id": "GHSA-3x62-x456-q2vm",
      "cwe_id": "{'CWE-77', 'CWE-78'}",
      "score": 9.8,
      "chain": "{'https://github.com/feross/git-pull-or-clone/commit/f9ce092be13cc32e685dfa26e7705e9c6e3108a3'}",
      "dataset": "osv",
      "summary": "OS Command Injection in git-pull-or-clone The package git-pull-or-clone before 2.0.2 is vulnerable to Command Injection due to the use of the --upload-pack feature of git which is also supported for git clone. The source includes the use of the secure child process API spawn(). However, the outpath parameter passed to it may be a command-line argument to the git clone command and result in arbitrary command injection.",
      "published_date": "2022-05-03",
      "chain_len": 1,
      "project": "https://github.com/feross/git-pull-or-clone",
      "commit_href": "https://github.com/feross/git-pull-or-clone/commit/f9ce092be13cc32e685dfa26e7705e9c6e3108a3",
      "commit_sha": "f9ce092be13cc32e685dfa26e7705e9c6e3108a3",
      "patch": "SINGLE",
      "chain_ord": "['f9ce092be13cc32e685dfa26e7705e9c6e3108a3']",
      "before_first_fix_commit": "{'4f8b9baf295e6d2e5dd987abca820987afb7643c'}",
      "last_fix_commit": "f9ce092be13cc32e685dfa26e7705e9c6e3108a3",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/06/2022, 10:13:53",
      "message": "fix: fix command injection vector",
      "author": "Liran Tal",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/feross/git-pull-or-clone/raw/f9ce092be13cc32e685dfa26e7705e9c6e3108a3/index.js', 'patch': \"@@ -28,7 +28,7 @@ function gitPullOrClone (url, outPath, opts, cb) {\\n   function gitClone () {\\n     // --depth implies --single-branch\\n     const flag = depth < Infinity ? '--depth=' + depth : '--single-branch'\\n-    const args = ['clone', flag, url, outPath]\\n+    const args = ['clone', flag, '--', url, outPath]\\n     debug('git ' + args.join(' '))\\n     spawn('git', args, {}, function (err) {\\n       if (err) err.message += ' (git clone) (' + url + ')'\"}}",
      "message_norm": "fix: fix command injection vector",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('command injection', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1484,
      "vuln_id": "GHSA-c558-5gfm-p2r8",
      "cwe_id": "{'CWE-79'}",
      "score": 7.1,
      "chain": "{'https://github.com/DSpace/DSpace/commit/6f75bb084ab1937d094208c55cd84340040bcbb5', 'https://github.com/DSpace/DSpace/commit/ebb83a75234d3de9be129464013e998dc929b68d', 'https://github.com/DSpace/DSpace/commit/35030a23e48b5946f5853332c797e1c4adea7bb7', 'https://github.com/DSpace/DSpace/commit/c89e493e517b424dea6175caba54e91d3847fc3a'}",
      "dataset": "osv",
      "summary": "JSPUI spellcheck and autocomplete tools vulnerable to Cross Site Scripting ### Impact\nThe JSPUI spellcheck \"Did you mean\" HTML escapes the data-spell attribute in the link, but not the actual displayed text.  Similarly, the JSPUI autocomplete HTML does not properly escape text passed to it. Both are vulnerable to XSS.  This vulnerability only impacts the JSPUI.\n\n_This vulnerability does NOT impact the XMLUI or 7.x._\n\n### Patches\n_DSpace 6.x:_\n* Fixed in 6.4 via two commits: \n    * Fix for spellcheck: https://github.com/DSpace/DSpace/commit/ebb83a75234d3de9be129464013e998dc929b68d\n    * Fix for autocomplete: https://github.com/DSpace/DSpace/commit/35030a23e48b5946f5853332c797e1c4adea7bb7\n* 6.x patch files available (may be applied manually if an immediate upgrade to 6.4 or above is not possible)\n    * Fix for spellcheck: https://github.com/DSpace/DSpace/commit/ebb83a75234d3de9be129464013e998dc929b68d.patch\n    * Fix for autocomplete: https://github.com/DSpace/DSpace/commit/35030a23e48b5946f5853332c797e1c4adea7bb7.patch\n\n_DSpace 5.x:_\n* Fixed in 5.11 via two commits: \n    * Fix for spellcheck: https://github.com/DSpace/DSpace/commit/c89e493e517b424dea6175caba54e91d3847fc3a\n    * Fix for autocomplete: https://github.com/DSpace/DSpace/commit/6f75bb084ab1937d094208c55cd84340040bcbb5\n* 5.x patch files available (may be applied manually if an immediate upgrade to 5.11 or 6.4 is not possible)\n    * Fix for spellcheck: https://github.com/DSpace/DSpace/commit/c89e493e517b424dea6175caba54e91d3847fc3a.patch\n    * Fix for autocomplete: https://github.com/DSpace/DSpace/commit/6f75bb084ab1937d094208c55cd84340040bcbb5.patch\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs / configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### References\nDiscovered & reported by Hassan Bhuiyan (Brunel University London)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
      "published_date": "2022-08-06",
      "chain_len": 4,
      "project": "https://github.com/DSpace/DSpace",
      "commit_href": "https://github.com/DSpace/DSpace/commit/6f75bb084ab1937d094208c55cd84340040bcbb5",
      "commit_sha": "6f75bb084ab1937d094208c55cd84340040bcbb5",
      "patch": "MULTI",
      "chain_ord": "['ebb83a75234d3de9be129464013e998dc929b68d', '35030a23e48b5946f5853332c797e1c4adea7bb7', 'c89e493e517b424dea6175caba54e91d3847fc3a', '6f75bb084ab1937d094208c55cd84340040bcbb5']",
      "before_first_fix_commit": "{'d1dd7d23329ef055069759df15cfa200c8e32e54'}",
      "last_fix_commit": "6f75bb084ab1937d094208c55cd84340040bcbb5",
      "chain_ord_pos": 4.0,
      "commit_datetime": "07/26/2022, 21:12:22",
      "message": "[DS-4453] Discovery autocomplete HTML escaping (JSPUI)",
      "author": "Kim Shepherd",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 2, 'total': 9}",
      "files": "{'dspace-jspui/src/main/webapp/search/discovery.jsp': {'additions': 7, 'deletions': 2, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/DSpace/DSpace/raw/6f75bb084ab1937d094208c55cd84340040bcbb5/dspace-jspui%2Fsrc%2Fmain%2Fwebapp%2Fsearch%2Fdiscovery.jsp', 'patch': '@@ -141,7 +141,7 @@\\n \\t\\t\\t\\t\\t\\t\\t\\t\\ttmp_val = item.displayedValue;\\n \\t\\t\\t\\t\\t\\t\\t\\t}\\n \\t\\t\\t\\t\\t\\t\\t\\treturn {\\n-\\t\\t\\t\\t\\t\\t\\t\\t\\tlabel: item.displayedValue + \" (\" + item.count + \")\",\\n+\\t\\t\\t\\t\\t\\t\\t\\t\\tlabel: escapeHtml(item.displayedValue) + \" (\" + item.count + \")\",\\n \\t\\t\\t\\t\\t\\t\\t\\t\\tvalue: tmp_val\\n \\t\\t\\t\\t\\t\\t\\t\\t};\\n \\t\\t\\t\\t\\t\\t\\t}))\\t\\t\\t\\n@@ -153,7 +153,12 @@\\n \\tfunction validateFilters() {\\n \\t\\treturn document.getElementById(\"filterquery\").value.length > 0;\\n \\t}\\n-</script>\\t\\t\\n+\\t// Generic HTML escape utility\\n+\\tvar escapeHtml = s => (s + \\'\\').replace(/[&<>\"\\']/g, m => ({\\n+\\t\\t\\'&\\': \\'&amp;\\', \\'<\\': \\'&lt;\\', \\'>\\': \\'&gt;\\',\\n+\\t\\t\\'\"\\': \\'&quot;\\', \"\\'\": \\'&#39;\\'\\n+\\t})[m]);\\n+</script>\\n </c:set>\\n \\n <dspace:layout titlekey=\"jsp.search.title\">'}}",
      "message_norm": "[ds-4453] discovery autocomplete html escaping (jspui)",
      "language": "it",
      "entities": "[('escaping', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['dspace-jspui/src/main/webapp/search/discovery.jsp'])",
      "num_files": 1.0
    },
    {
      "index": 1676,
      "vuln_id": "GHSA-f6g6-54hm-fhxv",
      "cwe_id": "{'CWE-362', 'CWE-119'}",
      "score": 8.1,
      "chain": "{'https://github.com/mvertescher/libsbc-rs/commit/a34d6e10f6f5654ed01a35288cf683d014ebc9c4'}",
      "dataset": "osv",
      "summary": "Data races in libsbc Affected versions of this crate implements `Send` for `Decoder<R>` for any `R: Read`. This allows `Decoder<R>` to contain `R: !Send` and carry (move) it to another thread.\n\nThis can result in undefined behavior such as memory corruption from data race on `R`, or dropping `R = MutexGuard<_>` from a thread that didn't lock the mutex.\n\nThe flaw was corrected in commit a34d6e1 by adding trait bound `R: Send` to the `Send` impl for `Decoder<R>`.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/mvertescher/libsbc-rs",
      "commit_href": "https://github.com/mvertescher/libsbc-rs/commit/a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
      "commit_sha": "a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
      "patch": "SINGLE",
      "chain_ord": "['a34d6e10f6f5654ed01a35288cf683d014ebc9c4']",
      "before_first_fix_commit": "{'7278b23901f93d956d9739fdfc4ced147cc3f242'}",
      "last_fix_commit": "a34d6e10f6f5654ed01a35288cf683d014ebc9c4",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/23/2021, 02:06:34",
      "message": "Add R: Send bound to Send impl of Decoder<R>\nfixes issue #4",
      "author": "JOE1994",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/lib.rs': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/mvertescher/libsbc-rs/raw/a34d6e10f6f5654ed01a35288cf683d014ebc9c4/src%2Flib.rs', 'patch': '@@ -33,7 +33,7 @@ where\\n \\n unsafe impl<R> Send for Decoder<R>\\n where\\n-        R: Read,\\n+        R: Read + Send,\\n {\\n }'}}",
      "message_norm": "add r: send bound to send impl of decoder<r>\nfixes issue #4",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('decoder', 'SECWORD', ''), ('#4', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/lib.rs'])",
      "num_files": 1.0
    },
    {
      "index": 24,
      "vuln_id": "GHSA-24x4-6qmh-88qg",
      "cwe_id": "{'CWE-416'}",
      "score": 7.6,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b'}",
      "dataset": "osv",
      "summary": "Use after free in `DecodePng` kernel ### Impact\nA malicious user can cause a use after free behavior when [decoding PNG images](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/core/kernels/image/decode_image_op.cc#L339-L346):\n```cc\nif (/* ... error conditions ... */) {\n  png::CommonFreeDecode(&decode);\n  OP_REQUIRES(context, false,\n              errors::InvalidArgument(\"PNG size too large for int: \",\n                                      decode.width, \" by \", decode.height));\n}   \n```\nAfter `png::CommonFreeDecode(&decode)` gets called, the values of `decode.width` and `decode.height` are in an unspecified state.\n\n### Patches\nWe have patched the issue in GitHub commit [e746adbfcfee15e9cfdb391ff746c765b99bdf9b](https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b",
      "commit_sha": "e746adbfcfee15e9cfdb391ff746c765b99bdf9b",
      "patch": "SINGLE",
      "chain_ord": "['e746adbfcfee15e9cfdb391ff746c765b99bdf9b']",
      "before_first_fix_commit": "{'3098fd96f45207b030c48ac78922d6221a4c421a'}",
      "last_fix_commit": "e746adbfcfee15e9cfdb391ff746c765b99bdf9b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/12/2021, 03:12:19",
      "message": "Prevent use after free in `DecodePng` kernel.\n\nWe are cleaning up the memory in `decode` and then we are using an `OP_REQUIRES` to check an invariant on the `decode` data.\n\nPiperOrigin-RevId: 409299145\nChange-Id: I4eb93aaca52483eb202e89b78df07fbb2f6cb254",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 0, 'deletions': 1, 'total': 1}",
      "files": "{'tensorflow/core/kernels/image/decode_image_op.cc': {'additions': 0, 'deletions': 1, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/e746adbfcfee15e9cfdb391ff746c765b99bdf9b/tensorflow%2Fcore%2Fkernels%2Fimage%2Fdecode_image_op.cc', 'patch': '@@ -339,7 +339,6 @@ class DecodeImageV2Op : public OpKernel {\\n     if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\\n         width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\\n         height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\\n-      png::CommonFreeDecode(&decode);\\n       OP_REQUIRES(context, false,\\n                   errors::InvalidArgument(\"PNG size too large for int: \",\\n                                           decode.width, \" by \", decode.height));'}}",
      "message_norm": "prevent use after free in `decodepng` kernel.\n\nwe are cleaning up the memory in `decode` and then we are using an `op_requires` to check an invariant on the `decode` data.\n\npiperorigin-revid: 409299145\nchange-id: i4eb93aaca52483eb202e89b78df07fbb2f6cb254",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('use after free', 'SECWORD', ''), ('decodepng', 'SECWORD', ''), ('decode', 'SECWORD', ''), ('decode', 'SECWORD', ''), ('409299145', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/image/decode_image_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 815,
      "vuln_id": "GHSA-6cf8-qhqj-vjqm",
      "cwe_id": "{'CWE-400'}",
      "score": 0.0,
      "chain": "{'https://github.com/totaljs/framework/commit/b3f901561d66ab799a4a99279893b94cad7ae4ff'}",
      "dataset": "osv",
      "summary": "Prototype pollution in total.js There is a prototype pollution vulnerability in the package total.js before version 3.4.7. The set function can be used to set a value into the object according to the path. However the keys of the path being set are not properly sanitized, leading to a prototype pollution vulnerability. The impact depends on the application. In some cases it is possible to achieve Denial of service (DoS), Remote Code Execution or Property Injection.",
      "published_date": "2021-02-05",
      "chain_len": 1,
      "project": "https://github.com/totaljs/framework",
      "commit_href": "https://github.com/totaljs/framework/commit/b3f901561d66ab799a4a99279893b94cad7ae4ff",
      "commit_sha": "b3f901561d66ab799a4a99279893b94cad7ae4ff",
      "patch": "SINGLE",
      "chain_ord": "['b3f901561d66ab799a4a99279893b94cad7ae4ff']",
      "before_first_fix_commit": "{'1e1faeb20d2291038e10b98f2046a4058135e767'}",
      "last_fix_commit": "b3f901561d66ab799a4a99279893b94cad7ae4ff",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/31/2020, 10:41:21",
      "message": "Fixed `U.set()` by adding check for `Prototype pollution`.",
      "author": "Peter Sirka",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'utils.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/totaljs/framework/raw/b3f901561d66ab799a4a99279893b94cad7ae4ff/utils.js', 'patch': \"@@ -6621,6 +6621,10 @@ exports.set = function(obj, path, value) {\\n \\tvar v = arr[arr.length - 1];\\n \\tvar ispush = v.lastIndexOf('[]') !== -1;\\n \\tvar a = builder.join(';') + ';var v=typeof(a)===\\\\'function\\\\'?a(U.get(b)):a;w' + (v[0] === '[' ? '' : '.') + (ispush ? v.replace(REGREPLACEARR, '.push(v)') : (v + '=v')) + ';return v';\\n+\\n+\\tif ((/__proto__|constructor|prototype/).test(a))\\n+\\t\\tthrow new Error('Prototype pollution');\\n+\\n \\tvar fn = new Function('w', 'a', 'b', a);\\n \\tF.temporary.other[cachekey] = fn;\\n \\tfn(obj, value, path);\"}}",
      "message_norm": "fixed `u.set()` by adding check for `prototype pollution`.",
      "language": "en",
      "entities": "[('fixed', 'ACTION', ''), ('adding', 'ACTION', ''), ('prototype pollution', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['utils.js'])",
      "num_files": 1.0
    },
    {
      "index": 98,
      "vuln_id": "GHSA-2hjr-fg6c-v2h6",
      "cwe_id": "{'CWE-200'}",
      "score": 6.5,
      "chain": "{'https://github.com/HubSpot/jinjava/pull/435/commits/1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165', 'https://github.com/HubSpot/jinjava/pull/426/commits/5dfa5b87318744a4d020b66d5f7747acc36b213b'}",
      "dataset": "osv",
      "summary": "Unauthorized access to Class instance in Jinjava Jinjava before 2.5.4 allow access to arbitrary classes by calling Java methods on objects passed into a Jinjava context. This could allow for abuse of the application class loader, including Arbitrary File Disclosure.",
      "published_date": "2022-02-09",
      "chain_len": 2,
      "project": "https://github.com/HubSpot/jinjava",
      "commit_href": "https://github.com/HubSpot/jinjava/pull/426/commits/5dfa5b87318744a4d020b66d5f7747acc36b213b",
      "commit_sha": "5dfa5b87318744a4d020b66d5f7747acc36b213b",
      "patch": "MULTI",
      "chain_ord": "['5dfa5b87318744a4d020b66d5f7747acc36b213b', '1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165']",
      "before_first_fix_commit": "{'bfc6ecde3a98db02a00c87a3b905a0af907188f0'}",
      "last_fix_commit": "1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/13/2020, 17:49:08",
      "message": "add method to blacklist",
      "author": "Matt Coley",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 1, 'total': 8}",
      "files": "{'src/main/java/com/hubspot/jinjava/el/ext/JinjavaBeanELResolver.java': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/HubSpot/jinjava/raw/5dfa5b87318744a4d020b66d5f7747acc36b213b/src%2Fmain%2Fjava%2Fcom%2Fhubspot%2Fjinjava%2Fel%2Fext%2FJinjavaBeanELResolver.java', 'patch': '@@ -2,6 +2,7 @@\\n \\n import com.google.common.base.CaseFormat;\\n import com.google.common.collect.ImmutableSet;\\n+import java.lang.reflect.Method;\\n import java.util.Set;\\n import javax.el.BeanELResolver;\\n import javax.el.ELContext;\\n@@ -111,7 +112,12 @@ private String transformPropertyName(Object property) {\\n   }\\n \\n   private void checkRestrictedClass(Object o, Object method) {\\n-    if (o instanceof Class || o instanceof ClassLoader || o instanceof Thread) {\\n+    if (\\n+      o instanceof Class ||\\n+      o instanceof ClassLoader ||\\n+      o instanceof Thread ||\\n+      o instanceof Method\\n+    ) {\\n       throw new MethodNotFoundException(\\n         \"Cannot find method \\'\" + method + \"\\' in \" + o.getClass()\\n       );'}}",
      "message_norm": "add method to blacklist",
      "language": "cy",
      "entities": "[('add', 'ACTION', ''), ('blacklist', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/main/java/com/hubspot/jinjava/el/ext/JinjavaBeanELResolver.java'])",
      "num_files": 1.0
    },
    {
      "index": 1003,
      "vuln_id": "GHSA-79fv-9865-4qcv",
      "cwe_id": "{'CWE-787', 'CWE-119'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/a74768f8e4efbda4def9f16ee7e13cf3922ac5f7'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `MaxPoolGrad` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGrad` is vulnerable to a heap buffer overflow:\n  \n```python\nimport tensorflow as tf\n\norig_input = tf.constant([0.0], shape=[1, 1, 1, 1], dtype=tf.float32)\norig_output = tf.constant([0.0], shape=[1, 1, 1, 1], dtype=tf.float32)\ngrad = tf.constant([], shape=[0, 0, 0, 0], dtype=tf.float32)\nksize = [1, 1, 1, 1] \nstrides = [1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.MaxPoolGrad(\n  orig_input=orig_input, orig_output=orig_output, grad=grad, ksize=ksize,\n  strides=strides, padding=padding, explicit_paddings=[])\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/ab1e644b48c82cb71493f4362b4dd38f4577a1cf/tensorflow/core/kernels/maxpooling_op.cc#L194-L203) fails to validate that indices used to access elements of input/output arrays are valid:\n\n```cc\nfor (int index = out_start; index < out_end; ++index) {\n  int input_backprop_index = out_arg_max_flat(index);\n  FastBoundsCheck(input_backprop_index - in_start, in_end - in_start);\n  input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n}\n```\n\nWhereas accesses to `input_backprop_flat` are guarded by `FastBoundsCheck`, the indexing in `out_backprop_flat` can result in OOB access.\n\n### Patches\nWe have patched the issue in GitHub commit [a74768f8e4efbda4def9f16ee7e13cf3922ac5f7](https://github.com/tensorflow/tensorflow/commit/a74768f8e4efbda4def9f16ee7e13cf3922ac5f7).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/a74768f8e4efbda4def9f16ee7e13cf3922ac5f7",
      "commit_sha": "a74768f8e4efbda4def9f16ee7e13cf3922ac5f7",
      "patch": "SINGLE",
      "chain_ord": "['a74768f8e4efbda4def9f16ee7e13cf3922ac5f7']",
      "before_first_fix_commit": "{'ab1e644b48c82cb71493f4362b4dd38f4577a1cf'}",
      "last_fix_commit": "a74768f8e4efbda4def9f16ee7e13cf3922ac5f7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/06/2021, 21:24:09",
      "message": "Prevent heap OOB error in `MaxPoolGrad`\n\nPiperOrigin-RevId: 372424854\nChange-Id: Idac0f23867ad8b0601cafbaaa52d5e64269e63a7",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 1, 'total': 4}",
      "files": "{'tensorflow/core/kernels/maxpooling_op.cc': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/a74768f8e4efbda4def9f16ee7e13cf3922ac5f7/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc', 'patch': '@@ -199,7 +199,9 @@ static void SpatialMaxPoolWithArgMaxHelper(\\n         // CHECK(input_backprop_index >= in_start && input_backprop_index <\\n         // in_end)\\n         FastBoundsCheck(input_backprop_index - in_start, in_end - in_start);\\n-        input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\\n+        if (index < out_backprop.NumElements()) {\\n+          input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\\n+        }\\n       }\\n     }\\n   };'}}",
      "message_norm": "prevent heap oob error in `maxpoolgrad`\n\npiperorigin-revid: 372424854\nchange-id: idac0f23867ad8b0601cafbaaa52d5e64269e63a7",
      "language": "nl",
      "entities": "[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('error', 'FLAW', ''), ('372424854', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/maxpooling_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1230,
      "vuln_id": "GHSA-8m9g-647g-5pxw",
      "cwe_id": "{'CWE-835'}",
      "score": 5.4,
      "chain": "{'https://github.com/Yubico/yubihsm-connector/commit/82bdf202c53460bac9106cc9b4b34a0a16cae0ed'}",
      "dataset": "osv",
      "summary": "Infinite loop in Yubico yubihsm-connector An issue was discovered in the /api/connector endpoint handler in Yubico yubihsm-connector before 3.0.1 (in YubiHSM SDK before 2021.04). The handler did not validate the length of the request, which can lead to a state where yubihsm-connector becomes stuck in a loop waiting for the YubiHSM to send it data, preventing any further operations until the yubihsm-connector is restarted. An attacker can send 0, 1, or 2 bytes to trigger this.",
      "published_date": "2022-02-15",
      "chain_len": 1,
      "project": "https://github.com/Yubico/yubihsm-connector",
      "commit_href": "https://github.com/Yubico/yubihsm-connector/commit/82bdf202c53460bac9106cc9b4b34a0a16cae0ed",
      "commit_sha": "82bdf202c53460bac9106cc9b4b34a0a16cae0ed",
      "patch": "SINGLE",
      "chain_ord": "['82bdf202c53460bac9106cc9b4b34a0a16cae0ed']",
      "before_first_fix_commit": "{'33e94e9034ffc52e29639386a191abd9b455d84b'}",
      "last_fix_commit": "82bdf202c53460bac9106cc9b4b34a0a16cae0ed",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/15/2021, 13:00:39",
      "message": "Check content-length to avoid denial-of-service",
      "author": "Per Nilsson",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 6, 'total': 12}",
      "files": "{'api.go': {'additions': 6, 'deletions': 6, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/Yubico/yubihsm-connector/raw/82bdf202c53460bac9106cc9b4b34a0a16cae0ed/api.go', 'patch': '@@ -177,19 +177,19 @@ func apiHandler(w http.ResponseWriter, r *http.Request, timeout time.Duration, s\\n \\t\\treturn\\n \\t}\\n \\n+\\tif r.ContentLength < 3 || r.ContentLength > 2048 {\\n+\\t\\thttp.Error(w, http.StatusText(http.StatusBadRequest),\\n+\\t\\t\\thttp.StatusBadRequest)\\n+\\t\\treturn\\n+\\t}\\n+\\n \\tif buf, err = ioutil.ReadAll(r.Body); err != nil {\\n \\t\\tclog.WithError(err).Error(\"failed reading incoming request\")\\n \\t\\thttp.Error(w, http.StatusText(http.StatusInternalServerError),\\n \\t\\t\\thttp.StatusInternalServerError)\\n \\t\\treturn\\n \\t}\\n \\n-\\tif len(buf) < 3 || len(buf) > 2048 {\\n-\\t\\thttp.Error(w, http.StatusText(http.StatusBadRequest),\\n-\\t\\t\\thttp.StatusBadRequest)\\n-\\t\\treturn\\n-\\t}\\n-\\n \\tif buf, err = usbProxy(buf, cid, timeout, serial); err != nil {\\n \\t\\tclog.WithError(err).Error(\"failed usb proxy\")\\n \\t\\thttp.Error(w, http.StatusText(http.StatusInternalServerError),'}}",
      "message_norm": "check content-length to avoid denial-of-service",
      "language": "en",
      "entities": "[('denial-of-service', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['api.go'])",
      "num_files": 1.0
    },
    {
      "index": 336,
      "vuln_id": "GHSA-428x-9xc2-m8mj",
      "cwe_id": "{'CWE-369'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/e5b0eec199c2d03de54fd6a7fd9275692218e2bc'}",
      "dataset": "osv",
      "summary": "Division by zero in TFLite ### Impact \nAn attacker can craft a TFLite model that would trigger a division by zero in [the implementation of depthwise convolutions](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/depthwise_conv.cc#L96).\n\nThe parameters of the convolution can be user controlled and are also used within a division operation to determine the size of the padding that needs to be added before applying the convolution. There is no check before this division that the divisor is stricly positive.\n\n### Patches              \nWe have patched the issue in GitHub commit [e5b0eec199c2d03de54fd6a7fd9275692218e2bc](https://github.com/tensorflow/tensorflow/commit/e5b0eec199c2d03de54fd6a7fd9275692218e2bc).\n  \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/e5b0eec199c2d03de54fd6a7fd9275692218e2bc",
      "commit_sha": "e5b0eec199c2d03de54fd6a7fd9275692218e2bc",
      "patch": "SINGLE",
      "chain_ord": "['e5b0eec199c2d03de54fd6a7fd9275692218e2bc']",
      "before_first_fix_commit": "{'ece78f4001dd87f50daab1d1b43f70a51726b8fb'}",
      "last_fix_commit": "e5b0eec199c2d03de54fd6a7fd9275692218e2bc",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/15/2021, 01:04:19",
      "message": "[lite] Add validation check for dilation height/width to be positive integers.\n\nPiperOrigin-RevId: 416429178\nChange-Id: If7cdcddca54486434d9b2f06e7e2b401d7c3ee25",
      "author": "Karim Nosir",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'tensorflow/lite/kernels/depthwise_conv.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/e5b0eec199c2d03de54fd6a7fd9275692218e2bc/tensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc', 'patch': '@@ -115,6 +115,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n \\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\\n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\\n+  TF_LITE_ENSURE(context, params->dilation_height_factor > 0);\\n+  TF_LITE_ENSURE(context, params->dilation_width_factor > 0);\\n \\n   const TfLiteType data_type = input->type;'}}",
      "message_norm": "[lite] add validation check for dilation height/width to be positive integers.\n\npiperorigin-revid: 416429178\nchange-id: if7cdcddca54486434d9b2f06e7e2b401d7c3ee25",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('416429178', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/depthwise_conv.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2161,
      "vuln_id": "GHSA-hxf9-7h4c-f5jv",
      "cwe_id": "{'CWE-200'}",
      "score": 9.1,
      "chain": "{'https://github.com/anymail/django-anymail/commit/db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'https://github.com/anymail/django-anymail/commit/c07998304b4a31df4c61deddcb03d3607a04691b'}",
      "dataset": "osv",
      "summary": "Django-Anymail prone to a timing attack webhooks/base.py in Anymail (aka django-anymail) before 1.2.1 is prone to a timing attack vulnerability on the WEBHOOK_AUTHORIZATION secret, which allows remote attackers to post arbitrary e-mail tracking events.",
      "published_date": "2018-07-12",
      "chain_len": 2,
      "project": "https://github.com/anymail/django-anymail",
      "commit_href": "https://github.com/anymail/django-anymail/commit/db586ede1fbb41dce21310ea28ae15a1cf1286c5",
      "commit_sha": "db586ede1fbb41dce21310ea28ae15a1cf1286c5",
      "patch": "MULTI",
      "chain_ord": "['db586ede1fbb41dce21310ea28ae15a1cf1286c5', 'c07998304b4a31df4c61deddcb03d3607a04691b']",
      "before_first_fix_commit": "{'7029298b930620b1655dab2548f72d6640a5905e'}",
      "last_fix_commit": "c07998304b4a31df4c61deddcb03d3607a04691b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/02/2018, 19:41:14",
      "message": "Security: prevent timing attack on WEBHOOK_AUTHORIZATION secret\n\nAnymail's webhook validation was vulnerable to a timing attack.\nAn attacker could have used this to recover your WEBHOOK_AUTHORIZATION\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nThere have not been any reports of attempted exploit in the wild. (The\nvulnerability was discovered through code review.) Attempts would be\nvisible in http logs as a very large number of 400 responses on\nAnymail's webhook urls, or in Python error monitoring as a very large\nnumber of AnymailWebhookValidationFailure exceptions.\n\nIf you are using Anymail's webhooks, you should upgrade to this release.\nIn addition, you may want to rotate to a new WEBHOOK_AUTHORIZATION\nsecret ([docs](http://anymail.readthedocs.io/en/stable/tips/securing_webhooks/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.",
      "author": "medmunds",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 3, 'total': 15}",
      "files": "{'anymail/webhooks/base.py': {'additions': 12, 'deletions': 3, 'changes': 15, 'status': 'modified', 'raw_url': 'https://github.com/anymail/django-anymail/raw/db586ede1fbb41dce21310ea28ae15a1cf1286c5/anymail%2Fwebhooks%2Fbase.py', 'patch': '@@ -2,6 +2,7 @@\\n \\n import six\\n from django.http import HttpResponse\\n+from django.utils.crypto import constant_time_compare\\n from django.utils.decorators import method_decorator\\n from django.views.decorators.csrf import csrf_exempt\\n from django.views.generic import View\\n@@ -40,8 +41,13 @@ def __init__(self, **kwargs):\\n     def validate_request(self, request):\\n         \"\"\"If configured for webhook basic auth, validate request has correct auth.\"\"\"\\n         if self.basic_auth:\\n-            basic_auth = get_request_basic_auth(request)\\n-            if basic_auth is None or basic_auth not in self.basic_auth:\\n+            request_auth = get_request_basic_auth(request)\\n+            # Use constant_time_compare to avoid timing attack on basic auth. (It\\'s OK that any()\\n+            # can terminate early: we\\'re not trying to protect how many auth strings are allowed,\\n+            # just the contents of each individual auth string.)\\n+            auth_ok = any(constant_time_compare(request_auth, allowed_auth)\\n+                          for allowed_auth in self.basic_auth)\\n+            if not auth_ok:\\n                 # noinspection PyUnresolvedReferences\\n                 raise AnymailWebhookValidationFailure(\\n                     \"Missing or invalid basic auth in Anymail %s webhook\" % self.esp_name)\\n@@ -77,8 +83,11 @@ def validate_request(self, request):\\n         *All* definitions of this method in the class chain (including mixins)\\n         will be called. There is no need to chain to the superclass.\\n         (See self.run_validators and collect_all_methods.)\\n+\\n+        Security note: use django.utils.crypto.constant_time_compare for string\\n+        comparisons, to avoid exposing your validation to a timing attack.\\n         \"\"\"\\n-        # if request.POST[\\'signature\\'] != expected_signature:\\n+        # if not constant_time_compare(request.POST[\\'signature\\'], expected_signature):\\n         #     raise AnymailWebhookValidationFailure(\"...message...\")\\n         # (else just do nothing)\\n         pass'}}",
      "message_norm": "security: prevent timing attack on webhook_authorization secret\n\nanymail's webhook validation was vulnerable to a timing attack.\nan attacker could have used this to recover your webhook_authorization\nshared secret, potentially allowing them to post fabricated or malicious\nemail tracking events to your app.\n\nthere have not been any reports of attempted exploit in the wild. (the\nvulnerability was discovered through code review.) attempts would be\nvisible in http logs as a very large number of 400 responses on\nanymail's webhook urls, or in python error monitoring as a very large\nnumber of anymailwebhookvalidationfailure exceptions.\n\nif you are using anymail's webhooks, you should upgrade to this release.\nin addition, you may want to rotate to a new webhook_authorization\nsecret ([docs](http://anymail.readthedocs.io/en/stable/tips/securing_webhooks/#use-a-shared-authorization-secret)),\nparticularly if your logs indicate attempted exploit.",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('attack', 'SECWORD', ''), ('vulnerable', 'SECWORD', ''), ('attack', 'FLAW', ''), ('attacker', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('exploit', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('error', 'FLAW', ''), ('upgrade', 'ACTION', ''), ('docs](http://anymail.readthedocs.io', 'URL', ''), ('exploit', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['anymail/webhooks/base.py'])",
      "num_files": 1.0
    },
    {
      "index": 2405,
      "vuln_id": "GHSA-mc8v-mgrf-8f4m",
      "cwe_id": "{'CWE-843'}",
      "score": 3.0,
      "chain": "{'https://github.com/opencontainers/distribution-spec/commit/ac28cac0557bcd3084714ab09f9f2356fe504923'}",
      "dataset": "osv",
      "summary": "Clarify Content-Type handling ### Impact\nIn the OCI Distribution Specification version 1.0.0 and prior, the Content-Type header alone was used to determine the type of document during push and pull operations. Documents that contain both \u201cmanifests\u201d and \u201clayers\u201d fields could be interpreted as either a manifest or an index in the absence of an accompanying Content-Type header. If a Content-Type header changed between two pulls of the same digest, a client may interpret the resulting content differently.\n\n### Patches\nThe OCI Distribution Specification will be updated to require that a `mediaType` value present in a manifest or index match the Content-Type header used during the push and pull operations.\n\n### Workarounds\nClients pulling from a registry may distrust the Content-Type header and reject an ambiguous document that contains both \u201cmanifests\u201d and \u201clayers\u201d fields or \u201cmanifests\u201d and \u201cconfig\u201d fields.\n\n### References\nhttps://github.com/opencontainers/image-spec/security/advisories/GHSA-77vh-xpmg-72qh\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in https://github.com/opencontainers/distribution-spec/\n* Email us at security@opencontainers.org",
      "published_date": "2021-11-18",
      "chain_len": 1,
      "project": "https://github.com/opencontainers/distribution-spec",
      "commit_href": "https://github.com/opencontainers/distribution-spec/commit/ac28cac0557bcd3084714ab09f9f2356fe504923",
      "commit_sha": "ac28cac0557bcd3084714ab09f9f2356fe504923",
      "patch": "SINGLE",
      "chain_ord": "['ac28cac0557bcd3084714ab09f9f2356fe504923']",
      "before_first_fix_commit": "{'13bd0834858f16049a4f7cb3f7ee0675f34beac4'}",
      "last_fix_commit": "ac28cac0557bcd3084714ab09f9f2356fe504923",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/27/2021, 20:01:43",
      "message": "spec: clarify handling regarding Content-type header\n\nSigned-off-by: Vincent Batts <vbatts@hashbangbash.com>",
      "author": "Vincent Batts",
      "comments": "{'com_1': {'author': 'Daoh1', 'datetime': '01/31/2022, 22:47:39', 'body': 'ACADD22323435 acdbdbat2t2'}}",
      "stats": "{'additions': 13, 'deletions': 2, 'total': 15}",
      "files": "{'spec.md': {'additions': 13, 'deletions': 2, 'changes': 15, 'status': 'modified', 'raw_url': 'https://github.com/opencontainers/distribution-spec/raw/ac28cac0557bcd3084714ab09f9f2356fe504923/spec.md', 'patch': '@@ -142,7 +142,9 @@ The `<reference>` MUST NOT be in any other format. Throughout this document, `<n\\n \\n The client SHOULD include an `Accept` header indicating which manifest content types it supports.\\n In a successful response, the `Content-Type` header will indicate the type of the returned manifest.\\n-For more information on the use of `Accept` headers and content negotiation, please see [Content Negotiation](./content-negotiation.md)\\n+The `Content-Type` header SHOULD match what the client [pushed as the manifest\\'s `Content-Type`](#pushing-manifests).\\n+If the manifest has a `mediaType` field, clients SHOULD reject unless the `mediaType` field\\'s value matches the type specified by the `Content-Type` header.\\n+For more information on the use of `Accept` headers and content negotiation, please see [Content Negotiation](./content-negotiation.md).\\n \\n A GET request to an existing manifest URL MUST provide the expected manifest, with a response code that MUST be `200 OK`.\\n A successful response SHOULD contain the digest of the uploaded blob in the header `Docker-Content-Digest`.\\n@@ -380,11 +382,20 @@ it SHOULD return a `202`. This indicates that the upload session has begun and t\\n To push a manifest, perform a `PUT` request to a path in the following format, and with the following headers\\n and body:\\n `/v2/<name>/manifests/<reference>` <sup>[end-7](#endpoints)</sup>\\n+\\n+Clients SHOULD set the `Content-Type` header to the type of the manifest being pushed.\\n+All manifests SHOULD include a `mediaType` field declaring the type of the manifest being pushed.\\n+If a manifest includes a `mediaType` field, clients MUST set the `Content-Type` header to the value specified by the `mediaType` field.\\n+\\n ```\\n Content-Type: application/vnd.oci.image.manifest.v1+json\\n ```\\n+Manifest byte stream:\\n ```\\n-<manifest byte stream>\\n+{\\n+  \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\\n+  ...\\n+}\\n ```\\n \\n `<name>` is the namespace of the repository, and the `<reference>` MUST be either a) a digest or b) a tag.'}}",
      "message_norm": "spec: clarify handling regarding content-type header\n\nsigned-off-by: vincent batts <vbatts@hashbangbash.com>",
      "language": "en",
      "entities": "[('vbatts@hashbangbash.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['spec.md'])",
      "num_files": 1.0
    },
    {
      "index": 2826,
      "vuln_id": "GHSA-qwpp-fgrj-h78q",
      "cwe_id": "{'CWE-209', 'CWE-200'}",
      "score": 5.3,
      "chain": "{'https://github.com/shopware/shopware/commit/dcb24eb5ec757c991b5a4e2ddced379e5820744d'}",
      "dataset": "osv",
      "summary": "Exposure of Sensitive Information to an Unauthorized Actor Shopware is an open source eCommerce platform. Versions prior to 5.6.10 are vulnerable to system information leakage in error handling. Users are recommend to update to version 5.6.10. You can get the update to 5.6.10 regularly via the Auto-Updater or directly via the download overview.",
      "published_date": "2021-09-08",
      "chain_len": 1,
      "project": "https://github.com/shopware/shopware",
      "commit_href": "https://github.com/shopware/shopware/commit/dcb24eb5ec757c991b5a4e2ddced379e5820744d",
      "commit_sha": "dcb24eb5ec757c991b5a4e2ddced379e5820744d",
      "patch": "SINGLE",
      "chain_ord": "['dcb24eb5ec757c991b5a4e2ddced379e5820744d']",
      "before_first_fix_commit": "{'a0d02194b3c255bc28661daa090656aecacf8608'}",
      "last_fix_commit": "dcb24eb5ec757c991b5a4e2ddced379e5820744d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/15/2021, 13:25:37",
      "message": "SW-26001 - Adjust error controller",
      "author": "Philip Gatzka",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 4, 'total': 5}",
      "files": "{'engine/Shopware/Controllers/Frontend/Error.php': {'additions': 1, 'deletions': 4, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/shopware/shopware/raw/dcb24eb5ec757c991b5a4e2ddced379e5820744d/engine%2FShopware%2FControllers%2FFrontend%2FError.php', 'patch': \"@@ -50,10 +50,7 @@ public function preDispatch()\\n             $this->enableBackendTheme();\\n         }\\n \\n-        if (strpos($this->Request()->getHeader('Content-Type'), 'application/json') === 0) {\\n-            $this->Front()->Plugins()->Json()->setRenderer();\\n-            $this->View()->assign('success', false);\\n-        } elseif ($this->Request()->isXmlHttpRequest() || !Shopware()->Container()->initialized('db')) {\\n+        if ($this->Request()->isXmlHttpRequest() || !Shopware()->Container()->initialized('db')) {\\n             $this->View()->loadTemplate($templateModule . '/error/exception.tpl');\\n         } elseif (isset($_ENV['SHELL']) || PHP_SAPI === 'cli') {\\n             $this->View()->loadTemplate($templateModule . '/error/cli.tpl');\"}}",
      "message_norm": "sw-26001 - adjust error controller",
      "language": "fr",
      "entities": "[('error', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['engine/Shopware/Controllers/Frontend/Error.php'])",
      "num_files": 1.0
    },
    {
      "index": 13,
      "vuln_id": "GHSA-23hm-7w47-xw72",
      "cwe_id": "{'CWE-125'}",
      "score": 8.1,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/23968a8bf65b009120c43b5ebcceaf52dbc9e943'}",
      "dataset": "osv",
      "summary": "Out of bounds read in Tensorflow ### Impact \nThe [implementation of `Dequantize`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/kernels/dequantize_op.cc#L92-L153) does not fully validate the value of `axis` and can result in heap OOB accesses:\n\n```python\nimport tensorflow as tf\n\n@tf.function\ndef test():\n  y = tf.raw_ops.Dequantize(\n    input=tf.constant([1,1],dtype=tf.qint32),\n    min_range=[1.0],\n    max_range=[10.0],\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=2**31-1,\n    dtype=tf.bfloat16)\n  return y\n\ntest()\n```\n\nThe `axis` argument can be `-1` (the default value for the optional argument) or any other positive value at most the number of dimensions of the input. Unfortunately, the upper bound is not checked and this results in reading past the end of the array containing the dimensions of the input tensor:\n    \n```cc   \n  if (axis_ > -1) {\n    num_slices = input.dim_size(axis_);\n  }\n  // ...\n  int64_t pre_dim = 1, post_dim = 1;\n  for (int i = 0; i < axis_; ++i) {\n    pre_dim *= float_output.dim_size(i);\n  }\n  for (int i = axis_ + 1; i < float_output.dims(); ++i) {\n    post_dim *= float_output.dim_size(i);\n  }\n``` \n      \n### Patches\nWe have patched the issue in GitHub commit [23968a8bf65b009120c43b5ebcceaf52dbc9e943](https://github.com/tensorflow/tensorflow/commit/23968a8bf65b009120c43b5ebcceaf52dbc9e943).\n  \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n      \n### Attribution\nThis vulnerability has been reported by Yu Tian of Qihoo 360 AIVul Team.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/23968a8bf65b009120c43b5ebcceaf52dbc9e943",
      "commit_sha": "23968a8bf65b009120c43b5ebcceaf52dbc9e943",
      "patch": "SINGLE",
      "chain_ord": "['23968a8bf65b009120c43b5ebcceaf52dbc9e943']",
      "before_first_fix_commit": "{'566576746f47ebf42c38ebe01cca6dbb8832a9ef'}",
      "last_fix_commit": "23968a8bf65b009120c43b5ebcceaf52dbc9e943",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/20/2021, 07:16:11",
      "message": "Fix out of bound access in DequantizeOp by adding check for axis < input dimension\n\nPiperOrigin-RevId: 411214268\nChange-Id: I3249d2a69ddc82f182c589a3a5bbfb71543f4b29",
      "author": "Isha Arkatkar",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/dequantize_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/23968a8bf65b009120c43b5ebcceaf52dbc9e943/tensorflow%2Fcore%2Fkernels%2Fdequantize_op.cc', 'patch': '@@ -94,6 +94,11 @@ class DequantizeOp : public OpKernel {\\n     const Tensor& input_min_tensor = ctx->input(1);\\n     const Tensor& input_max_tensor = ctx->input(2);\\n \\n+    OP_REQUIRES(\\n+        ctx, axis_ < input.dims(),\\n+        errors::InvalidArgument(\"Axis must be less than input dimension(\",\\n+                                input.dims(), \"), got \", axis_));\\n+\\n     int num_slices = 1;\\n     if (axis_ > -1) {\\n       num_slices = input.dim_size(axis_);'}}",
      "message_norm": "fix out of bound access in dequantizeop by adding check for axis < input dimension\n\npiperorigin-revid: 411214268\nchange-id: i3249d2a69ddc82f182c589a3a5bbfb71543f4b29",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('out of bound access', 'SECWORD', ''), ('adding', 'ACTION', ''), ('411214268', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/dequantize_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1570,
      "vuln_id": "GHSA-cmc7-mfmr-xqrx",
      "cwe_id": "{'CWE-480', 'CWE-287'}",
      "score": 7.5,
      "chain": "{'https://github.com/abhinavsingh/proxy.py/pull/482/commits/9b00093288237f5073c403f2c4f62acfdfa8ed46'}",
      "dataset": "osv",
      "summary": "Logic error in authentication in proxy.py before_upstream_connection in AuthPlugin in http/proxy/auth.py in proxy.py before 2.3.1 accepts incorrect Proxy-Authorization header data because of a boolean confusion (and versus or).",
      "published_date": "2021-04-07",
      "chain_len": 1,
      "project": "https://github.com/abhinavsingh/proxy.py",
      "commit_href": "https://github.com/abhinavsingh/proxy.py/pull/482/commits/9b00093288237f5073c403f2c4f62acfdfa8ed46",
      "commit_sha": "9b00093288237f5073c403f2c4f62acfdfa8ed46",
      "patch": "SINGLE",
      "chain_ord": "['9b00093288237f5073c403f2c4f62acfdfa8ed46']",
      "before_first_fix_commit": "{'0f78e74705e295bbfccfba342bf9fd34a9aa9103'}",
      "last_fix_commit": "9b00093288237f5073c403f2c4f62acfdfa8ed46",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/10/2021, 16:30:14",
      "message": "Fix basic auth condition",
      "author": "Abhinav Singh",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'proxy/http/proxy/auth.py': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/abhinavsingh/proxy.py/raw/9b00093288237f5073c403f2c4f62acfdfa8ed46/proxy%2Fhttp%2Fproxy%2Fauth.py', 'patch': \"@@ -35,8 +35,8 @@ def before_upstream_connection(\\n                 raise ProxyAuthenticationFailed()\\n             parts = request.headers[b'proxy-authorization'][1].split()\\n             if len(parts) != 2 \\\\\\n-                    and parts[0].lower() != b'basic' \\\\\\n-                    and parts[1] != self.flags.auth_code:\\n+                    or parts[0].lower() != b'basic' \\\\\\n+                    or parts[1] != self.flags.auth_code:\\n                 raise ProxyAuthenticationFailed()\\n         return request\"}}",
      "message_norm": "fix basic auth condition",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('auth', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['proxy/http/proxy/auth.py'])",
      "num_files": 1.0
    },
    {
      "index": 2711,
      "vuln_id": "GHSA-q73m-3q7r-fpf7",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/star7th/showdoc/commit/d1c9ed0d77ea5d56f09be0c492361dca8af745bb'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in ShowDoc ShowDoc prior to 2.10.4 is vulnerable to stored cross-site scripting via file upload.",
      "published_date": "2022-03-16",
      "chain_len": 1,
      "project": "https://github.com/star7th/showdoc",
      "commit_href": "https://github.com/star7th/showdoc/commit/d1c9ed0d77ea5d56f09be0c492361dca8af745bb",
      "commit_sha": "d1c9ed0d77ea5d56f09be0c492361dca8af745bb",
      "patch": "SINGLE",
      "chain_ord": "['d1c9ed0d77ea5d56f09be0c492361dca8af745bb']",
      "before_first_fix_commit": "{'56e450c3adf75c707500d7231a78c9fc894c7f13', 'aa41c83e0cc5079fb39e04d9f630571ffb8bbf22'}",
      "last_fix_commit": "d1c9ed0d77ea5d56f09be0c492361dca8af745bb",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2022, 12:29:34",
      "message": "Merge pull request #1632 from ajaysenr/master\n\nUpdate AttachmentModel.class.php",
      "author": "star7th",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'server/Application/Api/Model/AttachmentModel.class.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/star7th/showdoc/raw/d1c9ed0d77ea5d56f09be0c492361dca8af745bb/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -325,7 +325,7 @@ public function isAllowedFilename($filename){\\n \\t\\t$allow_array = array(\\n \\t\\t\\t'.jpg','.jpeg','.png','.bmp','.gif','.ico','.webp',\\n \\t\\t\\t'.mp3','.wav','.m4a','.ogg','.webma','.mp4','.flv',\\n-\\t\\t\\t'.mov','.webmv','.m3u8a','.flac','.mkv',\\n+\\t\\t\\t'.mov','.webmv','.flac','.mkv',\\n \\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso','.bz2','.epub',\\n \\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n \\t\\t\\t'.doc','.docx','.odt','.rtf','.docm','.dotm','.dot','.dotx','.wps','.wpt',\"}}",
      "message_norm": "merge pull request #1632 from ajaysenr/master\n\nupdate attachmentmodel.class.php",
      "language": "en",
      "entities": "[('#1632', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/Application/Api/Model/AttachmentModel.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 231,
      "vuln_id": "GHSA-39q4-p535-c852",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/locutusjs/locutus/commit/eb863321990e7e5514aa14f68b8d9978ece9e65e'}",
      "dataset": "osv",
      "summary": "Uncontrolled Resource Consumption in locutus The package locutus before 2.0.15 are vulnerable to Regular Expression Denial of Service (ReDoS) via the gopher_parsedir function.",
      "published_date": "2021-06-10",
      "chain_len": 1,
      "project": "https://github.com/locutusjs/locutus",
      "commit_href": "https://github.com/locutusjs/locutus/commit/eb863321990e7e5514aa14f68b8d9978ece9e65e",
      "commit_sha": "eb863321990e7e5514aa14f68b8d9978ece9e65e",
      "patch": "SINGLE",
      "chain_ord": "['eb863321990e7e5514aa14f68b8d9978ece9e65e']",
      "before_first_fix_commit": "{'243b723896c3c82f5496b6008f9aa1be52741899'}",
      "last_fix_commit": "eb863321990e7e5514aa14f68b8d9978ece9e65e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/27/2021, 06:46:30",
      "message": "Prevent ReDos issue with regex inside gopher_parsedir (#446)",
      "author": "Rafa\u0142 Kukawski",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/php/net-gopher/gopher_parsedir.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/locutusjs/locutus/raw/eb863321990e7e5514aa14f68b8d9978ece9e65e/src%2Fphp%2Fnet-gopher%2Fgopher_parsedir.js', 'patch': '@@ -22,7 +22,7 @@ module.exports = function gopher_parsedir (dirent) { // eslint-disable-line came\\n    * s = Audio file format, primarily a WAV file\\n    */\\n \\n-  const entryPattern = /^(.)(.*?)\\\\t(.*?)\\\\t(.*?)\\\\t(.*?)\\\\u000d\\\\u000a$/\\n+  const entryPattern = /^(.)([^\\\\t]*)\\\\t([^\\\\t]*)\\\\t([^\\\\t]*)\\\\t([^\\\\t]*)\\\\r\\\\n$/\\n   const entry = dirent.match(entryPattern)\\n \\n   if (entry === null) {'}}",
      "message_norm": "prevent redos issue with regex inside gopher_parsedir (#446)",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('redos', 'SECWORD', ''), ('issue', 'FLAW', ''), ('#446', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/php/net-gopher/gopher_parsedir.js'])",
      "num_files": 1.0
    },
    {
      "index": 545,
      "vuln_id": "GHSA-545v-42p7-98fq",
      "cwe_id": "{'CWE-125'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/dcd7867de0fea4b72a2b34bd41eb74548dc23886'}",
      "dataset": "osv",
      "summary": "Heap out of bounds read in `MaxPoolGradWithArgmax` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGradWithArgmax` can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32)\ngrad = tf.constant([10.0, 10.0, 10.0, 10.0], shape=[1, 1, 1, 4], dtype=tf.float32)\nargmax = tf.constant([1], shape=[1], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n  \ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  padding='SAME', include_batch_in_index=False)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/ef0c008ee84bad91ec6725ddc42091e19a30cf0e/tensorflow/core/kernels/maxpooling_op.cc#L1016-L1017) uses the same value to index in two different arrays but there is no guarantee that the sizes are identical. \n\n### Patches\nWe have patched the issue in GitHub commit [dcd7867de0fea4b72a2b34bd41eb74548dc23886](https://github.com/tensorflow/tensorflow/commit/dcd7867de0fea4b72a2b34bd41eb74548dc23886).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/dcd7867de0fea4b72a2b34bd41eb74548dc23886",
      "commit_sha": "dcd7867de0fea4b72a2b34bd41eb74548dc23886",
      "patch": "SINGLE",
      "chain_ord": "['dcd7867de0fea4b72a2b34bd41eb74548dc23886']",
      "before_first_fix_commit": "{'ef0c008ee84bad91ec6725ddc42091e19a30cf0e'}",
      "last_fix_commit": "dcd7867de0fea4b72a2b34bd41eb74548dc23886",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/05/2021, 15:38:03",
      "message": "Fix heap buffer overflow\n\nPiperOrigin-RevId: 372132844\nChange-Id: Idef9895efaf145f2b1c23d31983601ec980cd5e4",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'tensorflow/core/kernels/maxpooling_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/dcd7867de0fea4b72a2b34bd41eb74548dc23886/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc', 'patch': '@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\\n         const int input_start = start * input_size_per_batch;\\n         const int input_end = limit * input_size_per_batch;\\n         for (int64 index = input_start; index < input_end; index++) {\\n+          if (index >= argmax.NumElements()) {\\n+            break;\\n+          }\\n           int64 grad_out_index = argmax_flat(index);\\n           if (!include_batch_in_index) {\\n             const int64 cur_batch = index / input_size_per_batch;'}}",
      "message_norm": "fix heap buffer overflow\n\npiperorigin-revid: 372132844\nchange-id: idef9895efaf145f2b1c23d31983601ec980cd5e4",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('372132844', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/maxpooling_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1995,
      "vuln_id": "GHSA-h5g4-ppwx-48q2",
      "cwe_id": "{'CWE-20'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/cff267650c6a1b266e4b4500f69fbc49cdd773c5'}",
      "dataset": "osv",
      "summary": "Missing validation causes denial of service via `DeleteSessionTensor` ### Impact\nThe implementation of [`tf.raw_ops.DeleteSessionTensor`](https://github.com/tensorflow/tensorflow/blob/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/core/kernels/session_ops.cc#L128-L144) does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack:\n\n```python\nimport tensorflow as tf\n\nhandle = tf.constant(\"[]\", shape=[0], dtype=tf.string)\ntf.raw_ops.DeleteSessionTensor(handle=handle)\n```\n  \nThe code assumes `handle` is a scalar but there is no validation for this:\n  \n```cc\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n```\n\n### Patches\nWe have patched the issue in GitHub commit [cff267650c6a1b266e4b4500f69fbc49cdd773c5](https://github.com/tensorflow/tensorflow/commit/cff267650c6a1b266e4b4500f69fbc49cdd773c5).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Neophytos Christou from Secure Systems Lab at Brown University.",
      "published_date": "2022-05-24",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/cff267650c6a1b266e4b4500f69fbc49cdd773c5",
      "commit_sha": "cff267650c6a1b266e4b4500f69fbc49cdd773c5",
      "patch": "SINGLE",
      "chain_ord": "['cff267650c6a1b266e4b4500f69fbc49cdd773c5']",
      "before_first_fix_commit": "{'339d5de981acaa8580da62c5de8c0da64ae88ad4'}",
      "last_fix_commit": "cff267650c6a1b266e4b4500f69fbc49cdd773c5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2022, 20:08:57",
      "message": "Fix tf.raw_ops.DeleteSessionTensor vulnerability with invalid `handle`.\n\nCheck that `handle` input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445228994",
      "author": "Alan Liu",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'tensorflow/core/kernels/session_ops.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/cff267650c6a1b266e4b4500f69fbc49cdd773c5/tensorflow%2Fcore%2Fkernels%2Fsession_ops.cc', 'patch': '@@ -134,6 +134,8 @@ class DeleteSessionTensorOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& handle = ctx->input(0);\\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\\n+                errors::InvalidArgument(\"`handle` must be scalar\"));\\n     const string& name = handle.scalar<tstring>()();\\n     auto session_state = ctx->session_state();\\n     OP_REQUIRES(ctx, session_state != nullptr,'}}",
      "message_norm": "fix tf.raw_ops.deletesessiontensor vulnerability with invalid `handle`.\n\ncheck that `handle` input is actually a scalar before treating it as such.\n\npiperorigin-revid: 445228994",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('445228994', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/session_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 863,
      "vuln_id": "GHSA-6jv7-28mv-qp9c",
      "cwe_id": "{'CWE-862'}",
      "score": 4.3,
      "chain": "{'https://github.com/jenkinsci/autonomiq-plugin/commit/e06b1ff67664a90819c9561bbc12f4c6e593d1dc'}",
      "dataset": "osv",
      "summary": "Missing permission check in Jenkins autonomiq Plugin A missing permission check in Jenkins autonomiq Plugin 1.15 and earlier allows attackers with Overall/Read permission to connect to an attacker-specified URL using attacker-specified credentials.",
      "published_date": "2022-02-16",
      "chain_len": 1,
      "project": "https://github.com/jenkinsci/autonomiq-plugin",
      "commit_href": "https://github.com/jenkinsci/autonomiq-plugin/commit/e06b1ff67664a90819c9561bbc12f4c6e593d1dc",
      "commit_sha": "e06b1ff67664a90819c9561bbc12f4c6e593d1dc",
      "patch": "SINGLE",
      "chain_ord": "['e06b1ff67664a90819c9561bbc12f4c6e593d1dc']",
      "before_first_fix_commit": "{'abfbe8a84d54ec7708c8ef073d56b128baffb1f5'}",
      "last_fix_commit": "e06b1ff67664a90819c9561bbc12f4c6e593d1dc",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/09/2022, 07:16:27",
      "message": "added permission and csrf protection",
      "author": "jameeluddin",
      "comments": null,
      "stats": "{'additions': 17, 'deletions': 0, 'total': 17}",
      "files": "{'src/main/java/io/jenkins/plugins/autonomiq/AutonomiqBuilder.java': {'additions': 17, 'deletions': 0, 'changes': 17, 'status': 'modified', 'raw_url': 'https://github.com/jenkinsci/autonomiq-plugin/raw/e06b1ff67664a90819c9561bbc12f4c6e593d1dc/src%2Fmain%2Fjava%2Fio%2Fjenkins%2Fplugins%2Fautonomiq%2FAutonomiqBuilder.java', 'patch': '@@ -653,6 +653,7 @@ public String getDisplayName() {\\n         }\\n \\n         @SuppressWarnings(\"unused\")\\n+        @POST\\n         public ListBoxModel doFillProjectItems(@QueryParameter String aiqUrl,\\n                                                @QueryParameter String login,\\n                                                @QueryParameter Secret password,\\n@@ -661,6 +662,8 @@ public ListBoxModel doFillProjectItems(@QueryParameter String aiqUrl,\\n                                                @QueryParameter String proxyUser,\\n                                                @QueryParameter Secret proxyPassword,\\n                                                @QueryParameter Boolean httpProxy) {\\n+        \\tJenkins.get().checkPermission(Jenkins.ADMINISTER);\\n+\\n \\n             // make sure other fields have been filled in\\n             if (aiqUrl.length() > 0 && login.length() > 0 && Secret.toString(password).length() > 0) {\\n@@ -681,7 +684,10 @@ public ListBoxModel doFillProjectItems(@QueryParameter String aiqUrl,\\n         }\\n \\n         @SuppressWarnings(\"unused\")\\n+        @POST\\n         public ListBoxModel doFillPlatformTestCasesItems() {\\n+        \\tJenkins.get().checkPermission(Jenkins.ADMINISTER);\\n+\\n \\n             String[] values = {\"Linux\"};  //, \"Windows\"};\\n \\n@@ -690,7 +696,10 @@ public ListBoxModel doFillPlatformTestCasesItems() {\\n             return new ListBoxModel(options);\\n         }\\n         @SuppressWarnings(\"unused\")\\n+        @POST\\n         public ListBoxModel doFillPlatformTestSuitesItems() {\\n+        \\tJenkins.get().checkPermission(Jenkins.ADMINISTER);\\n+\\n \\n             String[] values = {\"Linux\"};  //, \"Windows\"};\\n \\n@@ -701,7 +710,10 @@ public ListBoxModel doFillPlatformTestSuitesItems() {\\n \\n \\n         @SuppressWarnings(\"unused\")\\n+        @POST\\n         public ListBoxModel doFillBrowserTestCasesItems() {\\n+        \\tJenkins.get().checkPermission(Jenkins.ADMINISTER);\\n+\\n \\n             String[] values = {\"Chrome\", \"Firefox\"};\\n \\n@@ -710,7 +722,9 @@ public ListBoxModel doFillBrowserTestCasesItems() {\\n             return new ListBoxModel(options);\\n         }\\n         @SuppressWarnings(\"unused\")\\n+        @POST\\n         public ListBoxModel doFillBrowserTestSuitesItems() {\\n+        \\tJenkins.get().checkPermission(Jenkins.ADMINISTER);\\n \\n             String[] values = {\"Chrome\", \"Firefox\"};\\n \\n@@ -720,7 +734,10 @@ public ListBoxModel doFillBrowserTestSuitesItems() {\\n         }\\n \\n         @SuppressWarnings(\"unused\")\\n+        @POST\\n         public ListBoxModel doFillExecutionModeItems() {\\n+        \\tJenkins.get().checkPermission(Jenkins.ADMINISTER);\\n+\\n \\n             String[] values = {\"serial\", \"parallel\"};'}}",
      "message_norm": "added permission and csrf protection",
      "language": "en",
      "entities": "[('added', 'ACTION', ''), ('permission', 'SECWORD', ''), ('csrf', 'SECWORD', ''), ('protection', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/main/java/io/jenkins/plugins/autonomiq/AutonomiqBuilder.java'])",
      "num_files": 1.0
    },
    {
      "index": 1548,
      "vuln_id": "GHSA-cg3h-rc9q-g8v9",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/pimcore/pimcore/commit/6ccb5c12fc1be065ebce9c89c4677ee939b88597'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in pimcore pimcore version 10.3.0 and prior is vulnerable to cross-site scripting.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/pimcore/pimcore",
      "commit_href": "https://github.com/pimcore/pimcore/commit/6ccb5c12fc1be065ebce9c89c4677ee939b88597",
      "commit_sha": "6ccb5c12fc1be065ebce9c89c4677ee939b88597",
      "patch": "SINGLE",
      "chain_ord": "['6ccb5c12fc1be065ebce9c89c4677ee939b88597']",
      "before_first_fix_commit": "{'7b6b2229ed3f19da1632afcbf9b8fec6d768faad'}",
      "last_fix_commit": "6ccb5c12fc1be065ebce9c89c4677ee939b88597",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/07/2022, 12:03:58",
      "message": "[Admin] Website Settings - Escape grid values properly",
      "author": "dpahuja",
      "comments": null,
      "stats": "{'additions': 19, 'deletions': 7, 'total': 26}",
      "files": "{'bundles/AdminBundle/Resources/public/js/pimcore/settings/website.js': {'additions': 19, 'deletions': 7, 'changes': 26, 'status': 'modified', 'raw_url': 'https://github.com/pimcore/pimcore/raw/6ccb5c12fc1be065ebce9c89c4677ee939b88597/bundles%2FAdminBundle%2FResources%2Fpublic%2Fjs%2Fpimcore%2Fsettings%2Fwebsite.js', 'patch': '@@ -36,7 +36,7 @@ pimcore.settings.website = Class.create({\\n                 border:false,\\n                 layout:\"fit\",\\n                 closable:true,\\n-                items:[this.getRowEditor()]\\n+                items:[this.getRowEditor()],\\n             });\\n \\n             var tabPanel = Ext.getCmp(\"pimcore_panel_tabs\");\\n@@ -133,6 +133,7 @@ pimcore.settings.website = Class.create({\\n                 dataIndex: \\'data\\',\\n                 flex: 300,\\n                 editable: true,\\n+                editor: new Ext.form.TextField({}),\\n                 renderer: this.getCellRenderer.bind(this),\\n             },\\n             {text: t(\"site\"), flex: 100, sortable:true, dataIndex: \"siteId\",\\n@@ -303,7 +304,10 @@ pimcore.settings.website = Class.create({\\n             bodyCls: \"pimcore_editable_grid\",\\n             stripeRows:true,\\n             columns : {\\n-                items: typesColumns\\n+                items: typesColumns,\\n+                defaults: {\\n+                    renderer: Ext.util.Format.htmlEncode\\n+                },\\n             },\\n             sm:  Ext.create(\\'Ext.selection.RowModel\\', {}),\\n             bbar:this.pagingtoolbar,\\n@@ -359,15 +363,23 @@ pimcore.settings.website = Class.create({\\n     },\\n \\n     getCellEditor: function (record) {\\n-        var data = record.data;\\n+        let data = record.data;\\n \\n-        var type = data.type;\\n-        var property;\\n+        let type = data.type;\\n+        let property;\\n \\n         if (type === \"text\") {\\n-            property = Ext.create(\\'Ext.form.TextField\\');\\n+            property = {\\n+                xtype: \\'textfield\\',\\n+                flex: 1,\\n+                value: data.data\\n+            }\\n         } else if (type == \"textarea\") {\\n-            property = Ext.create(\\'Ext.form.TextArea\\');\\n+            property = {\\n+                xtype: \"textarea\",\\n+                flex: 1,\\n+                value: data.data\\n+            }\\n         } else if (type == \"document\" || type == \"asset\" || type == \"object\") {\\n             property = {\\n                 xtype: \\'textfield\\','}}",
      "message_norm": "[admin] website settings - escape grid values properly",
      "language": "af",
      "entities": "[('admin', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['bundles/AdminBundle/Resources/public/js/pimcore/settings/website.js'])",
      "num_files": 1.0
    },
    {
      "index": 1167,
      "vuln_id": "GHSA-88cw-3m6x-49f7",
      "cwe_id": "{'CWE-787'}",
      "score": 7.5,
      "chain": "{'https://github.com/chakra-core/ChakraCore/pull/6528/commits/e81e8a51ec7ba3d0dfb6089254f166c2733216e1'}",
      "dataset": "osv",
      "summary": "Out-of-bounds Write in ChakraCore Chakra Scripting Engine Memory Corruption Vulnerability This CVE ID is unique from CVE-2020-17048.",
      "published_date": "2021-08-02",
      "chain_len": 1,
      "project": "https://github.com/chakra-core/ChakraCore",
      "commit_href": "https://github.com/chakra-core/ChakraCore/pull/6528/commits/e81e8a51ec7ba3d0dfb6089254f166c2733216e1",
      "commit_sha": "e81e8a51ec7ba3d0dfb6089254f166c2733216e1",
      "patch": "SINGLE",
      "chain_ord": "['e81e8a51ec7ba3d0dfb6089254f166c2733216e1']",
      "before_first_fix_commit": "{'90e222e9a9ba64bd808666f44e6a0913d6318f78'}",
      "last_fix_commit": "e81e8a51ec7ba3d0dfb6089254f166c2733216e1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/30/2020, 22:00:01",
      "message": "[CVE-2020-17054]",
      "author": "Paul Leathers",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 2, 'total': 7}",
      "files": "{'lib/Backend/Lower.cpp': {'additions': 5, 'deletions': 2, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/chakra-core/ChakraCore/raw/e81e8a51ec7ba3d0dfb6089254f166c2733216e1/lib%2FBackend%2FLower.cpp', 'patch': '@@ -27152,8 +27152,11 @@ void Lowerer::LowerLdFrameDisplay(IR::Instr *instr, bool doStackFrameDisplay)\\n         if (instr->m_func != this->m_func && this->m_func->DoStackFrameDisplay())\\n         {\\n             StackSym * inlineeFrameDisplaySym = instr->m_func->GetLocalFrameDisplaySym();\\n-            Assert(inlineeFrameDisplaySym->IsAllocated());\\n-            InsertMove(IR::SymOpnd::New(inlineeFrameDisplaySym, TyMachReg, m_func), dstOpnd, instr);\\n+            Assert((inlineeFrameDisplaySym && inlineeFrameDisplaySym->IsAllocated()) || this->m_func->IsLoopBody());\\n+            if (inlineeFrameDisplaySym && inlineeFrameDisplaySym->IsAllocated())\\n+            {\\n+                InsertMove(IR::SymOpnd::New(inlineeFrameDisplaySym, TyMachReg, m_func), dstOpnd, instr);\\n+            }\\n         }\\n     }'}}",
      "message_norm": "[cve-2020-17054]",
      "language": "ro",
      "entities": "[('cve-2020-17054', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/Backend/Lower.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 1254,
      "vuln_id": "GHSA-8rq8-f485-7v8x",
      "cwe_id": "{'CWE-502'}",
      "score": 9.8,
      "chain": "{'https://github.com/abersheeran/rpc.py/commit/491e7a841ed9a754796d6ab047a9fb16e23bf8bd'}",
      "dataset": "osv",
      "summary": "rpc.py 0.6.0 vulnerable to Deserialization of Untrusted Data rpc.py through 0.6.0 allows Remote Code Execution because an unpickle occurs when the \"serializer: pickle\" HTTP header is sent. In other words, although JSON (not Pickle) is the default data format, an unauthenticated client can cause the data to be processed with unpickle.\n\n[Per the maintainer](https://github.com/abersheeran/rpc.py/issues/22), rpc.py is not designed for an API that is open to the outside world, and external requests cannot reach rpc.py in real world use.\n\nA [fix](https://github.com/abersheeran/rpc.py/commit/491e7a841ed9a754796d6ab047a9fb16e23bf8bd) exists on the `master` branch. As a workaround, use the following code to turn off pickle in older versions:\n```\ndel SERIALIZER_NAMES[PickleSerializer.name]\ndel SERIALIZER_TYPES[PickleSerializer.content_type]",
      "published_date": "2022-07-09",
      "chain_len": 1,
      "project": "https://github.com/abersheeran/rpc.py",
      "commit_href": "https://github.com/abersheeran/rpc.py/commit/491e7a841ed9a754796d6ab047a9fb16e23bf8bd",
      "commit_sha": "491e7a841ed9a754796d6ab047a9fb16e23bf8bd",
      "patch": "SINGLE",
      "chain_ord": "['491e7a841ed9a754796d6ab047a9fb16e23bf8bd']",
      "before_first_fix_commit": "{'3d5c31916a597f8bdd3260c50d6ec398da1c421c'}",
      "last_fix_commit": "491e7a841ed9a754796d6ab047a9fb16e23bf8bd",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/06/2022, 04:55:59",
      "message": "PickleSerializer is turned off by default",
      "author": "Aber",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 2, 'total': 9}",
      "files": "{'rpcpy/serializers.py': {'additions': 7, 'deletions': 2, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/abersheeran/rpc.py/raw/491e7a841ed9a754796d6ab047a9fb16e23bf8bd/rpcpy%2Fserializers.py', 'patch': '@@ -108,16 +108,21 @@ def decode(self, data: bytes) -> typing.Any:\\n         return cbor.loads(data)\\n \\n \\n+# Since the release of pickle to the external network may lead to\\n+# arbitrary code execution vulnerabilities, this serialization\\n+# method is not enabled by default. It is recommended to turn it on\\n+# when there is physical isolation from the outside.\\n+\\n SERIALIZER_NAMES = {\\n     JSONSerializer.name: JSONSerializer(),\\n-    PickleSerializer.name: PickleSerializer(),\\n+    # PickleSerializer.name: PickleSerializer(),\\n     MsgpackSerializer.name: MsgpackSerializer(),\\n     CBORSerializer.name: CBORSerializer(),\\n }\\n \\n SERIALIZER_TYPES = {\\n     JSONSerializer.content_type: JSONSerializer(),\\n-    PickleSerializer.content_type: PickleSerializer(),\\n+    # PickleSerializer.content_type: PickleSerializer(),\\n     MsgpackSerializer.content_type: MsgpackSerializer(),\\n     CBORSerializer.content_type: CBORSerializer(),\\n }'}}",
      "message_norm": "pickleserializer is turned off by default",
      "language": "en",
      "entities": "[('pickleserializer', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['rpcpy/serializers.py'])",
      "num_files": 1.0
    },
    {
      "index": 1184,
      "vuln_id": "GHSA-8c89-2vwr-chcq",
      "cwe_id": "{'CWE-787', 'CWE-131'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/f6c40f0c6cbf00d46c7717a26419f2062f2f8694'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `QuantizedResizeBilinear` ### Impact\nAn attacker can cause a heap buffer overflow in `QuantizedResizeBilinear` by passing in invalid thresholds for the quantization:\n\n```python\nimport tensorflow as tf\n\nimages = tf.constant([], shape=[0], dtype=tf.qint32)\nsize = tf.constant([], shape=[0], dtype=tf.int32) \nmin = tf.constant([], dtype=tf.float32)\nmax = tf.constant([], dtype=tf.float32)\n\ntf.raw_ops.QuantizedResizeBilinear(images=images, size=size, min=min, max=max, align_corners=False, half_pixel_centers=False)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/50711818d2e61ccce012591eeb4fdf93a8496726/tensorflow/core/kernels/quantized_resize_bilinear_op.cc#L705-L706) assumes that the 2 arguments are always valid scalars and tries to access the numeric value directly:\n\n```cc\nconst float in_min = context->input(2).flat<float>()(0);\nconst float in_max = context->input(3).flat<float>()(0);\n```\n\nHowever, if any of these tensors is empty, then `.flat<T>()` is an empty buffer and accessing the element at position 0 results in overflow.\n\n### Patches \nWe have patched the issue in GitHub commit [f6c40f0c6cbf00d46c7717a26419f2062f2f8694](https://github.com/tensorflow/tensorflow/commit/f6c40f0c6cbf00d46c7717a26419f2062f2f8694).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/f6c40f0c6cbf00d46c7717a26419f2062f2f8694",
      "commit_sha": "f6c40f0c6cbf00d46c7717a26419f2062f2f8694",
      "patch": "SINGLE",
      "chain_ord": "['f6c40f0c6cbf00d46c7717a26419f2062f2f8694']",
      "before_first_fix_commit": "{'50711818d2e61ccce012591eeb4fdf93a8496726'}",
      "last_fix_commit": "f6c40f0c6cbf00d46c7717a26419f2062f2f8694",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/22/2021, 00:00:39",
      "message": "Validate min and max arguments to `QuantizedResizeBilinear`.\n\nPiperOrigin-RevId: 369765091\nChange-Id: I33be8b78273ab7d08b97541692fe05cb7f94963a",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 2, 'total': 10}",
      "files": "{'tensorflow/core/kernels/quantized_resize_bilinear_op.cc': {'additions': 8, 'deletions': 2, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/f6c40f0c6cbf00d46c7717a26419f2062f2f8694/tensorflow%2Fcore%2Fkernels%2Fquantized_resize_bilinear_op.cc', 'patch': '@@ -702,8 +702,14 @@ class QuantizedResizeBilinearOp : public OpKernel {\\n   }\\n \\n   void Compute(OpKernelContext* context) override {\\n-    const float in_min = context->input(2).flat<float>()(0);\\n-    const float in_max = context->input(3).flat<float>()(0);\\n+    const auto& in_min_tensor = context->input(2);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_min_tensor.shape()),\\n+                errors::InvalidArgument(\"min must be a scalar\"));\\n+    const float in_min = in_min_tensor.flat<float>()(0);\\n+    const auto& in_max_tensor = context->input(3);\\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_max_tensor.shape()),\\n+                errors::InvalidArgument(\"max must be a scalar\"));\\n+    const float in_max = in_max_tensor.flat<float>()(0);\\n \\n     ImageResizerState st(align_corners_, false);\\n     st.ValidateAndCreateOutput(context);'}}",
      "message_norm": "validate min and max arguments to `quantizedresizebilinear`.\n\npiperorigin-revid: 369765091\nchange-id: i33be8b78273ab7d08b97541692fe05cb7f94963a",
      "language": "en",
      "entities": "[('validate', 'ACTION', ''), ('369765091', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/quantized_resize_bilinear_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 847,
      "vuln_id": "GHSA-6hfq-h8hq-87mf",
      "cwe_id": "{'CWE-444'}",
      "score": 4.8,
      "chain": "{'https://github.com/hyperium/hyper/commit/8f93123efef5c1361086688fe4f34c83c89cec02'}",
      "dataset": "osv",
      "summary": "HTTP Request Smuggling in hyper ### Summary\n\nhyper's HTTP server code had a flaw that incorrectly understands some requests with multiple transfer-encoding headers to have a chunked payload, when it should have been rejected as illegal. This combined with an upstream HTTP proxy that understands the request payload boundary differently can result in \"request smuggling\" or \"desync attacks\".\n\n### Vulnerability\n\nThe flaw was introduced in https://github.com/hyperium/hyper/commit/26417fc24a7d05df538e0f39239b373c5c3d61f6, released in v0.12.0.\n\nConsider this example request:\n\n```\nPOST /yolo HTTP/1.1\nTransfer-Encoding: chunked\nTransfer-Encoding: cow\n```\n\nThis request *should* be rejected, according to RFC 7230, since it has a `Transfer-Encoding` header, but after folding, it does not end in `chunked`. hyper would notice the `chunked` in the first line, and then check the second line, and thanks to a missing boolean assignment, *not* set the error condition. hyper would treat the payload as being `chunked`. By differing from the spec, it is possible to send requests like these to endpoints that have different HTTP implementations, with different interpretations of the payload semantics, and cause \"desync attacks\".\n\nThere are several parts of the spec that must also be checked, and hyper correctly handles all of those. Additionally, hyper's *client* does not allow sending requests with improper headers, so the misunderstanding cannot be propagated further.\n\nRead more about desync attacks: https://portswigger.net/research/http-desync-attacks-request-smuggling-reborn\n\n### Impact\n\nTo determine if vulnerable, all these things must be true:\n\n- **Using hyper as an HTTP *server*.** The client is not affected.\n- **Using HTTP/1.1.** HTTP/2 does not use `transfer-encoding`.\n- **Using a vulnerable HTTP proxy upstream to hyper.** If an upstream proxy correctly rejects the illegal transfer-encoding headers, the desync attack cannot succeed. If there is *no* proxy upstream of hyper, hyper cannot *start* the desync attack, as the client will repair the headers before forwarding.\n\n### Patches\n\nWe have released and backported the following patch versions:\n\n- v0.14.3\n- v0.13.10\n\n### Workarounds\n\nBesides upgrading hyper, you can take the following options:\n\n- Reject requests that contain a `transfer-encoding` header.\n- Ensure any upstream proxy handles `transfer-encoding` correctly.\n\n### Credits\n\nThis issue was initially reported by ZeddYu Lu From Qi An Xin Technology Research Institute.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/hyperium/hyper",
      "commit_href": "https://github.com/hyperium/hyper/commit/8f93123efef5c1361086688fe4f34c83c89cec02",
      "commit_sha": "8f93123efef5c1361086688fe4f34c83c89cec02",
      "patch": "SINGLE",
      "chain_ord": "['8f93123efef5c1361086688fe4f34c83c89cec02']",
      "before_first_fix_commit": "{'4d2125c67c8087de863f74278a017c4caf37e6a9'}",
      "last_fix_commit": "8f93123efef5c1361086688fe4f34c83c89cec02",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/05/2021, 21:27:30",
      "message": "fix(http1): fix server misinterpretting multiple Transfer-Encoding headers\n\nWhen a request arrived with multiple `Transfer-Encoding` headers, hyper\nwould check each if they ended with `chunked`. It should have only\nchecked if the *last* header ended with `chunked`.\n\nSee https://github.com/hyperium/hyper/security/advisories/GHSA-6hfq-h8hq-87mf",
      "author": "Sean McArthur",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 0, 'total': 12}",
      "files": "{'src/proto/h1/role.rs': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/hyperium/hyper/raw/8f93123efef5c1361086688fe4f34c83c89cec02/src%2Fproto%2Fh1%2Frole.rs', 'patch': '@@ -213,6 +213,8 @@ impl Http1Transaction for Server {\\n                     if headers::is_chunked_(&value) {\\n                         is_te_chunked = true;\\n                         decoder = DecodedLength::CHUNKED;\\n+                    } else {\\n+                        is_te_chunked = false;\\n                     }\\n                 }\\n                 header::CONTENT_LENGTH => {\\n@@ -1444,6 +1446,16 @@ mod tests {\\n             \"transfer-encoding doesn\\'t end in chunked\",\\n         );\\n \\n+        parse_err(\\n+            \"\\\\\\n+             POST / HTTP/1.1\\\\r\\\\n\\\\\\n+             transfer-encoding: chunked\\\\r\\\\n\\\\\\n+             transfer-encoding: afterlol\\\\r\\\\n\\\\\\n+             \\\\r\\\\n\\\\\\n+             \",\\n+            \"transfer-encoding multiple lines doesn\\'t end in chunked\",\\n+        );\\n+\\n         // http/1.0\\n \\n         assert_eq!('}}",
      "message_norm": "fix(http1): fix server misinterpretting multiple transfer-encoding headers\n\nwhen a request arrived with multiple `transfer-encoding` headers, hyper\nwould check each if they ended with `chunked`. it should have only\nchecked if the *last* header ended with `chunked`.\n\nsee https://github.com/hyperium/hyper/security/advisories/ghsa-6hfq-h8hq-87mf",
      "language": "en",
      "entities": "[('fix(http1', 'ACTION', ''), ('fix', 'ACTION', ''), ('server', 'SECWORD', ''), ('encoding', 'SECWORD', ''), ('encoding', 'SECWORD', ''), ('https://github.com/hyperium/hyper/security/advisories/ghsa-6hfq-h8hq-87mf', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/proto/h1/role.rs'])",
      "num_files": 1.0
    },
    {
      "index": 2593,
      "vuln_id": "GHSA-pjc4-3w99-j7v4",
      "cwe_id": "{'CWE-601'}",
      "score": 5.4,
      "chain": "{'https://github.com/briancappello/flask-unchained/commit/2bfeedf1bc31df851cab8c66df0c432b10406aad', 'https://github.com/briancappello/flask-unchained/commit/71e36b28166f9ffbe0a991f51127f0984f7e6a40'}",
      "dataset": "osv",
      "summary": "Open redirect in Flask-Unchained This affects the package Flask-Unchained before 0.9.0. When using the the _validate_redirect_url function, it is possible to bypass URL validation and redirect a user to an arbitrary URL by providing multiple back slashes such as \\\\\\evil.com/path. This vulnerability is only exploitable if an alternative WSGI server other than Werkzeug is used, or the default behaviour of Werkzeug is modified using 'autocorrect_location_header=False.",
      "published_date": "2021-06-15",
      "chain_len": 2,
      "project": "https://github.com/briancappello/flask-unchained",
      "commit_href": "https://github.com/briancappello/flask-unchained/commit/2bfeedf1bc31df851cab8c66df0c432b10406aad",
      "commit_sha": "2bfeedf1bc31df851cab8c66df0c432b10406aad",
      "patch": "MULTI",
      "chain_ord": "['2bfeedf1bc31df851cab8c66df0c432b10406aad', '71e36b28166f9ffbe0a991f51127f0984f7e6a40']",
      "before_first_fix_commit": "{'2bfeedf1bc31df851cab8c66df0c432b10406aad'}",
      "last_fix_commit": "71e36b28166f9ffbe0a991f51127f0984f7e6a40",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/27/2021, 17:47:52",
      "message": "security fixes",
      "author": "Brian Cappello",
      "comments": null,
      "stats": "{'additions': 27, 'deletions': 8, 'total': 35}",
      "files": "{'flask_unchained/bundles/controller/utils.py': {'additions': 27, 'deletions': 8, 'changes': 35, 'status': 'modified', 'raw_url': 'https://github.com/briancappello/flask-unchained/raw/2bfeedf1bc31df851cab8c66df0c432b10406aad/flask_unchained%2Fbundles%2Fcontroller%2Futils.py', 'patch': '@@ -6,7 +6,7 @@\\n from flask_unchained._compat import is_local_proxy\\n from py_meta_utils import _missing\\n from typing import *\\n-from urllib.parse import urlsplit\\n+from urllib.parse import urlsplit, quote as urlquote\\n from werkzeug.routing import BuildError, UnicodeConverter\\n \\n from .attr_constants import CONTROLLER_ROUTES_ATTR, REMOVE_SUFFIXES_ATTR\\n@@ -183,6 +183,11 @@ def method_name_to_url(method_name) -> str:\\n     return \\'/\\' + kebab_case(method_name).strip(\\'-\\')\\n \\n \\n+def encode_non_url_reserved_characters(url):\\n+    # safe url reserved characters: https://datatracker.ietf.org/doc/html/rfc3986#section-2.2\\n+    return urlquote(url, safe=\":/?#[]@!$&\\'()*+,;=\")\\n+\\n+\\n # modified from flask_security.utils.get_post_action_redirect\\n def redirect(where: Optional[str] = None,\\n              default: Optional[str] = None,\\n@@ -235,7 +240,7 @@ def redirect(where: Optional[str] = None,\\n \\n     for url in urls:\\n         if _validate_redirect_url(url, _external_host):\\n-            return flask_redirect(url)\\n+            return flask_redirect(encode_non_url_reserved_characters(url))\\n     return flask_redirect(\\'/\\')\\n \\n \\n@@ -289,15 +294,29 @@ def _url_for(endpoint: str, **values) -> Union[str, None]:\\n \\n # modified from flask_security.utils.validate_redirect_url\\n def _validate_redirect_url(url, _external_host=None):\\n-    if url is None or url.strip() == \\'\\':\\n+    url = (url or \\'\\').strip().replace(\\'\\\\\\\\\\', \\'/\\')\\n+\\n+    # reject empty urls and urls starting with 3+ slashes or a control character\\n+    if not url or url.startswith(\\'///\\') or ord(url[0]) <= 32:\\n         return False\\n+\\n     url_next = urlsplit(url)\\n     url_base = urlsplit(request.host_url)\\n-    external_host = _external_host or current_app.config.get(\\'EXTERNAL_SERVER_NAME\\', \\'\\')\\n-    if ((url_next.netloc or url_next.scheme)\\n-            and url_next.netloc != url_base.netloc\\n-            and url_next.netloc not in external_host):\\n-        return False\\n+    if url_next.netloc or url_next.scheme:\\n+        # require both netloc and scheme\\n+        if not url_next.netloc or not url_next.scheme:\\n+            return False\\n+\\n+        # if external host, require same netloc and scheme\\n+        external_host = _external_host or current_app.config.get(\\'EXTERNAL_SERVER_NAME\\', \\'\\')\\n+        if external_host:\\n+            url_external = urlsplit(external_host)\\n+            if url_next.netloc == url_external.netloc and url_next.scheme == url_external.scheme:\\n+                return True\\n+\\n+        # require same netloc and scheme\\n+        if url_next.netloc != url_base.netloc or url_next.scheme != url_base.scheme:\\n+            return False\\n     return True'}}",
      "message_norm": "security fixes",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('fixes', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['flask_unchained/bundles/controller/utils.py'])",
      "num_files": 1.0
    },
    {
      "index": 367,
      "vuln_id": "GHSA-465w-gg5p-85c9",
      "cwe_id": "{'CWE-613', 'CWE-384', 'CWE-295'}",
      "score": 8.6,
      "chain": "{'https://github.com/kiali/kiali/commit/93f5cd0b6698e8fe8772afb8f35816f6c086aef1', 'https://github.com/kiali/kiali/commit/c91a0949683976f621cca213c1193831d63b381c'}",
      "dataset": "osv",
      "summary": "Insufficient Session Expiration in Kiali An insufficient JWT validation vulnerability was found in Kiali versions 0.4.0 to 1.15.0 and was fixed in Kiali version 1.15.1, wherein a remote attacker could abuse this flaw by stealing a valid JWT cookie and using that to spoof a user session, possibly gaining privileges to view and alter the Istio configuration.",
      "published_date": "2021-05-18",
      "chain_len": 2,
      "project": "https://github.com/kiali/kiali",
      "commit_href": "https://github.com/kiali/kiali/commit/c91a0949683976f621cca213c1193831d63b381c",
      "commit_sha": "c91a0949683976f621cca213c1193831d63b381c",
      "patch": "MULTI",
      "chain_ord": "['c91a0949683976f621cca213c1193831d63b381c', '93f5cd0b6698e8fe8772afb8f35816f6c086aef1']",
      "before_first_fix_commit": "{'a660a80b2add1fd2fcfb5662c63824ca1dff95b9'}",
      "last_fix_commit": "93f5cd0b6698e8fe8772afb8f35816f6c086aef1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/17/2020, 18:05:17",
      "message": "Fix security issues around 'token' strategy\n\n* Require presence of sid claim",
      "author": "Edgar Hern\u00e1ndez",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'handlers/authentication.go': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/kiali/kiali/raw/c91a0949683976f621cca213c1193831d63b381c/handlers%2Fauthentication.go', 'patch': '@@ -425,6 +425,12 @@ func checkTokenSession(w http.ResponseWriter, r *http.Request) (int, string) {\\n \\tif claims, err := config.GetTokenClaimsIfValid(tokenString); err != nil {\\n \\t\\tlog.Warningf(\"Token is invalid: %s\", err.Error())\\n \\t} else {\\n+\\t\\t// Session ID claim must be present\\n+\\t\\tif len(claims.SessionId) == 0 {\\n+\\t\\t\\tlog.Warning(\"Token is invalid: sid claim is required\")\\n+\\t\\t\\treturn http.StatusUnauthorized, \"\"\\n+\\t\\t}\\n+\\n \\t\\tbusiness, err := business.Get(claims.SessionId)\\n \\t\\tif err != nil {\\n \\t\\t\\tlog.Warning(\"Could not get the business layer : \", err)'}}",
      "message_norm": "fix security issues around 'token' strategy\n\n* require presence of sid claim",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issues', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['handlers/authentication.go'])",
      "num_files": 1.0
    },
    {
      "index": 1133,
      "vuln_id": "GHSA-84mw-34w6-2q43",
      "cwe_id": "{'CWE-476'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/b055b9c474cd376259dde8779908f9eeaf097d93'}",
      "dataset": "osv",
      "summary": "Null pointer dereference via invalid Ragged Tensors ### Impact\nCalling `tf.raw_ops.RaggedTensorToVariant` with arguments specifying an invalid ragged tensor results in a null pointer dereference:\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 0, 0, 0], dtype=tf.float32)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 56, 56, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 23, 1])\n```\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[2, 2, 2, 2, 0], dtype=tf.float32)\nfilter_tensor = tf.constant([], shape=[0, 0, 2, 6, 2], dtype=tf.float32)\n\ntf.raw_ops.Conv3D(input=input_tensor, filter=filter_tensor, strides=[1, 56, 39, 34, 1], padding='VALID', data_format='NDHWC', dilations=[1, 1, 1, 1, 1])\n```\n\nThe implementation of [`RaggedTensorToVariant` operations](https://github.com/tensorflow/tensorflow/blob/904b3926ed1c6c70380d5313d282d248a776baa1/tensorflow/core/kernels/ragged_tensor_to_variant_op.cc#L39-L40) does not validate that the ragged tensor argument is non-empty:\n\n```cc\n  int ragged_rank = batched_ragged.ragged_rank();\n  auto batched_splits_top_vec = batched_ragged.splits(0).vec<SPLIT_TYPE>();\n```\n\nSince `batched_ragged` contains no elements, `batched_ragged.splits` is a null vector, thus `batched_ragged.splits(0)` will result in  dereferencing `nullptr`.\n\n### Patches\nWe have patched the issue in GitHub commit [b055b9c474cd376259dde8779908f9eeaf097d93](https://github.com/tensorflow/tensorflow/commit/b055b9c474cd376259dde8779908f9eeaf097d93).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/b055b9c474cd376259dde8779908f9eeaf097d93",
      "commit_sha": "b055b9c474cd376259dde8779908f9eeaf097d93",
      "patch": "SINGLE",
      "chain_ord": "['b055b9c474cd376259dde8779908f9eeaf097d93']",
      "before_first_fix_commit": "{'904b3926ed1c6c70380d5313d282d248a776baa1'}",
      "last_fix_commit": "b055b9c474cd376259dde8779908f9eeaf097d93",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/13/2021, 21:49:50",
      "message": "Fix `tf.raw_ops.RaggedTensorToVariant` invalid resize.\n\nPiperOrigin-RevId: 368299574\nChange-Id: I751c186325aa0bab397928845e790e60c2d90918",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/ragged_tensor_to_variant_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/b055b9c474cd376259dde8779908f9eeaf097d93/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_variant_op.cc', 'patch': '@@ -159,6 +159,11 @@ class RaggedTensorToVariantOp : public OpKernel {\\n \\n     // Unbatch the Ragged Tensor and encode the components.\\n     std::vector<RaggedTensorVariant> unbatched_ragged_input;\\n+    auto batched_splits_top_vec =\\n+        batched_ragged_input.splits(0).vec<SPLIT_TYPE>();\\n+    int num_components = batched_splits_top_vec.size() - 1;\\n+    OP_REQUIRES(context, num_components >= 0,\\n+                errors::Internal(\"Invalid split argument.\"));\\n     OP_REQUIRES_OK(context, UnbatchRaggedZerothDim<VALUE_TYPE, SPLIT_TYPE>(\\n                                 batched_ragged_input, &unbatched_ragged_input));'}}",
      "message_norm": "fix `tf.raw_ops.raggedtensortovariant` invalid resize.\n\npiperorigin-revid: 368299574\nchange-id: i751c186325aa0bab397928845e790e60c2d90918",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('368299574', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/ragged_tensor_to_variant_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1536,
      "vuln_id": "GHSA-cf66-xwfp-gvc4",
      "cwe_id": "{'CWE-20'}",
      "score": 7.5,
      "chain": "{'https://github.com/webpack/webpack-dev-server/commit/f18e5adf123221a1015be63e1ca2491ca45b8d10'}",
      "dataset": "osv",
      "summary": "Missing Origin Validation in webpack-dev-server Versions of `webpack-dev-server` before 3.1.10 are missing origin validation on the websocket server. This vulnerability allows a remote attacker to steal a developer's source code because the origin of requests to the websocket server that is used for Hot Module Replacement (HMR) are not validated.\n\n\n## Recommendation\nFor `webpack-dev-server` update to version 3.1.11 or later.",
      "published_date": "2019-01-04",
      "chain_len": 1,
      "project": "https://github.com/webpack/webpack-dev-server",
      "commit_href": "https://github.com/webpack/webpack-dev-server/commit/f18e5adf123221a1015be63e1ca2491ca45b8d10",
      "commit_sha": "f18e5adf123221a1015be63e1ca2491ca45b8d10",
      "patch": "SINGLE",
      "chain_ord": "['f18e5adf123221a1015be63e1ca2491ca45b8d10']",
      "before_first_fix_commit": "{'e1bd264b9ce5fb0a05a62754883f6c8a36fbc51b'}",
      "last_fix_commit": "f18e5adf123221a1015be63e1ca2491ca45b8d10",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/24/2018, 16:57:43",
      "message": "check origin header for websocket connection",
      "author": "Tobias Koppers",
      "comments": "{'com_1': {'author': 'hackel', 'datetime': '11/09/2018, 05:45:42', 'body': 'Any chance this security fix could be backported to 2.x?\\r\\nJust noticed this.  https://nodesecurity.io/advisories/725'}, 'com_2': {'author': 'alexander-akait', 'datetime': '11/09/2018, 10:14:03', 'body': 'No, please update to `3` version, `2` is deprecated'}, 'com_3': {'author': 'aeegvk', 'datetime': '01/02/2019, 08:33:02', 'body': 'Updated to suggested version 3.1.11 and latest version 3.1.14 but still getting a vulnerability report. How come?'}, 'com_4': {'author': 'oles', 'datetime': '01/02/2019, 10:54:04', 'body': 'Experiencing the same as @aeegvk.\\r\\n\\r\\nSeems like the error is in https://www.npmjs.com/advisories/725 though.'}, 'com_5': {'author': 'charlesfaustin', 'datetime': '01/02/2019, 13:35:57', 'body': '> Updated to suggested version 3.1.11 and latest version 3.1.14 but still getting a vulnerability report. How come?\\r\\n\\r\\nthere appears to be a typo in the npm vulnerability database\\r\\nhttps://npm.community/t/npm-audit-sweems-to-get-semver-wrong/4352/4'}}",
      "stats": "{'additions': 9, 'deletions': 2, 'total': 11}",
      "files": "{'lib/Server.js': {'additions': 9, 'deletions': 2, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/webpack/webpack-dev-server/raw/f18e5adf123221a1015be63e1ca2491ca45b8d10/lib%2FServer.js', 'patch': '@@ -513,13 +513,15 @@ Server.prototype.setContentHeaders = function (req, res, next) {\\n   next();\\n };\\n \\n-Server.prototype.checkHost = function (headers) {\\n+Server.prototype.checkHost = function (headers, headerToCheck) {\\n   // allow user to opt-out this security check, at own risk\\n   if (this.disableHostCheck) return true;\\n \\n+  if (!headerToCheck) headerToCheck = \"host\";\\n+\\n   // get the Host header and extract hostname\\n   // we don\\'t care about port not matching\\n-  const hostHeader = headers.host;\\n+  const hostHeader = headers[headerToCheck];\\n   if (!hostHeader) return false;\\n \\n   // use the node url-parser to retrieve the hostname from the host-header.\\n@@ -589,6 +591,11 @@ Server.prototype.listen = function (port, hostname, fn) {\\n         conn.close();\\n         return;\\n       }\\n+      if (!this.checkHost(conn.headers, \"origin\")) {\\n+        this.sockWrite([conn], \\'error\\', \\'Invalid Origin header\\');\\n+        conn.close();\\n+        return;\\n+      }\\n       this.sockets.push(conn);\\n \\n       conn.on(\\'close\\', () => {'}}",
      "message_norm": "check origin header for websocket connection",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/Server.js'])",
      "num_files": 1.0
    },
    {
      "index": 3075,
      "vuln_id": "GHSA-v82p-hv3v-p6qp",
      "cwe_id": "{'CWE-20'}",
      "score": 7.8,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9', 'https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69'}",
      "dataset": "osv",
      "summary": "Incomplete validation in MKL requantization ### Impact\nDue to incomplete validation in MKL implementation of requantization, an  attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.RequantizationRangePerChannel(\n  input=[],\n  input_min=[0,0,0,0,0],\n  input_max=[1,1,1,1,1],\n  clip_value_max=1)\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor.\n\nA similar issue occurs in `MklRequantizePerChannelOp`:\n\n```python\nimport tensorflow as tf \nfrom tensorflow.python.ops import gen_math_ops\n\ngen_math_ops.requantize_per_channel(\n  input=[],\n  input_min=[-100,-100,-100,-100,-100],\n  input_max=[-100,-100,-100],\n  requested_output_min=[-100,-100,-100,-100,-100],\n  requested_output_max=[],\n  out_type=tf.int)\n``` \n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments.\n\n### Patches\nWe have patched the issue in GitHub commit [9e62869465573cb2d9b5053f1fa02a81fce21d69](https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69) and in the Github commit [203214568f5bc237603dbab6e1fd389f1572f5c9](https://github.com/tensorflow/tensorflow/commit/203214568f5bc237603dbab6e1fd389f1572f5c9).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69",
      "commit_sha": "9e62869465573cb2d9b5053f1fa02a81fce21d69",
      "patch": "MULTI",
      "chain_ord": "['9e62869465573cb2d9b5053f1fa02a81fce21d69', '203214568f5bc237603dbab6e1fd389f1572f5c9']",
      "before_first_fix_commit": "{'aff0d5b2883ea3de9b52f9e7cd996a34b299bf06'}",
      "last_fix_commit": "203214568f5bc237603dbab6e1fd389f1572f5c9",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/29/2021, 23:29:20",
      "message": "Add more validation to `RequantizationRangePerChannel`.\n\nPiperOrigin-RevId: 387693946\nChange-Id: Ife8dcbdb021bec4787eef6a4361dd08f17c14bd6",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 0, 'total': 14}",
      "files": "{'tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/9e62869465573cb2d9b5053f1fa02a81fce21d69/tensorflow%2Fcore%2Fkernels%2Fmkl%2Fmkl_requantization_range_per_channel_op.cc', 'patch': '@@ -57,6 +57,20 @@ class MklRequantizationRangePerChannelOp : public OpKernel {\\n         ctx, input_max.dim_size(0) == depth,\\n         errors::InvalidArgument(\"input_max has incorrect size, expected \",\\n                                 depth, \" was \", input_max.dim_size(0)));\\n+    OP_REQUIRES(\\n+        ctx, input_min.NumElements() == depth,\\n+        errors::InvalidArgument(\"input_min must have the same number of \"\\n+                                \"elements as input_max, got \",\\n+                                input_min.NumElements(), \" and \", depth));\\n+    OP_REQUIRES(ctx, input.NumElements() > 0,\\n+                errors::InvalidArgument(\"input must not be empty\"));\\n+    OP_REQUIRES(ctx, input.dims() == 4,\\n+                errors::InvalidArgument(\"input must be in NHWC format\"));\\n+    OP_REQUIRES(\\n+        ctx, input.dim_size(3) == depth,\\n+        errors::InvalidArgument(\\n+            \"input must have same number of channels as length of input_min: \",\\n+            input.dim_size(3), \" vs \", depth));\\n \\n     const float* input_min_data = input_min.flat<float>().data();\\n     const float* input_max_data = input_max.flat<float>().data();'}}",
      "message_norm": "add more validation to `requantizationrangeperchannel`.\n\npiperorigin-revid: 387693946\nchange-id: ife8dcbdb021bec4787eef6a4361dd08f17c14bd6",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('387693946', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1684,
      "vuln_id": "GHSA-f7f6-xrwc-9c57",
      "cwe_id": "{'CWE-20'}",
      "score": 7.5,
      "chain": "{'https://github.com/jenkinsci/jenkins/commit/ea981a029cb985b71f3a0dc0f9ce3b3e3e6c001b'}",
      "dataset": "osv",
      "summary": "Improper Input Validation in Jenkins Jenkins 2.73.1 and earlier, 2.83 and earlier bundled a version of the commons-fileupload library with the denial-of-service vulnerability known as CVE-2016-3092. The fix for that vulnerability has been backported to the version of the library bundled with Jenkins.",
      "published_date": "2022-05-14",
      "chain_len": 1,
      "project": "https://github.com/jenkinsci/jenkins",
      "commit_href": "https://github.com/jenkinsci/jenkins/commit/ea981a029cb985b71f3a0dc0f9ce3b3e3e6c001b",
      "commit_sha": "ea981a029cb985b71f3a0dc0f9ce3b3e3e6c001b",
      "patch": "SINGLE",
      "chain_ord": "['ea981a029cb985b71f3a0dc0f9ce3b3e3e6c001b']",
      "before_first_fix_commit": "{'fe77d1c3dbf91ddf2a9f8e5ed882611455ab00d0'}",
      "last_fix_commit": "ea981a029cb985b71f3a0dc0f9ce3b3e3e6c001b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/29/2017, 13:41:00",
      "message": "[SECURITY-490] Patch Commons File Upload 1.3.x.",
      "author": "Jesse Glick",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'core/pom.xml': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/jenkinsci/jenkins/raw/ea981a029cb985b71f3a0dc0f9ce3b3e3e6c001b/core%2Fpom.xml', 'patch': '@@ -588,7 +588,7 @@ THE SOFTWARE.\\n     <dependency>\\n       <groupId>commons-fileupload</groupId>\\n       <artifactId>commons-fileupload</artifactId>\\n-      <version>1.3.1-jenkins-1</version>\\n+      <version>1.3.1-jenkins-2</version> \\n     </dependency>\\n \\n     <!-- offline profiler API to put in the classpath if we need it -->'}}",
      "message_norm": "[security-490] patch commons file upload 1.3.x.",
      "language": "en",
      "entities": "[('security-490', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['core/pom.xml'])",
      "num_files": 1.0
    },
    {
      "index": 519,
      "vuln_id": "GHSA-4wv4-mgfq-598v",
      "cwe_id": "{'CWE-94'}",
      "score": 0.0,
      "chain": "{'https://github.com/AnneTheDev/nobelprize/commit/00639d375b0efd097bc1eca18d9dc021691b9286'}",
      "dataset": "osv",
      "summary": "Code injection in nobelprizeparser Code injection through use of eval.",
      "published_date": "2021-03-12",
      "chain_len": 1,
      "project": "https://github.com/AnneTheDev/nobelprize",
      "commit_href": "https://github.com/AnneTheDev/nobelprize/commit/00639d375b0efd097bc1eca18d9dc021691b9286",
      "commit_sha": "00639d375b0efd097bc1eca18d9dc021691b9286",
      "patch": "SINGLE",
      "chain_ord": "['00639d375b0efd097bc1eca18d9dc021691b9286']",
      "before_first_fix_commit": "{'23abc78c8bf9eddce8ec40f0ec7bbb586a3ebe9f', '29126617df6f313d81588d695d94982cba03d82e'}",
      "last_fix_commit": "00639d375b0efd097bc1eca18d9dc021691b9286",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/23/2021, 09:03:46",
      "message": "Merge pull request from GHSA-4wv4-mgfq-598v\n\nReplace eval with JSON.parse",
      "author": "AnneTheDev",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'lib/index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/AnneTheDev/nobelprize/raw/00639d375b0efd097bc1eca18d9dc021691b9286/lib%2Findex.js', 'patch': '@@ -10,7 +10,7 @@ function output(laureate) {\\n class Parser {\\n     // Parse JSON data\\n     constructor(data) {\\n-        this.laureates = eval(`(${data})`).laureates;\\n+        this.laureates = JSON.parse(data}).laureates;\\n     }\\n \\n     inYear(year) {'}}",
      "message_norm": "merge pull request from ghsa-4wv4-mgfq-598v\n\nreplace eval with json.parse",
      "language": "en",
      "entities": "[('ghsa-4wv4-mgfq-598v', 'VULNID', 'GHSA'), ('eval', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/index.js'])",
      "num_files": 1.0
    },
    {
      "index": 3034,
      "vuln_id": "GHSA-v2p6-4mp7-3r9v",
      "cwe_id": "{'CWE-400'}",
      "score": 0.0,
      "chain": "{'https://github.com/epeli/underscore.string/commit/f486cd684c94c12db48b45d52b1472a1b9661029'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service in underscore.string Versions of `underscore.string` prior to *3.3.5* are vulnerable to Regular Expression Denial of Service (ReDoS).\n\nThe function `unescapeHTML` is vulnerable to ReDoS due to an overly-broad regex. The slowdown is approximately 2s for 50,000 characters but grows exponentially with larger inputs.\n\n\n## Recommendation\n\nUpgrade to version 3.3.5 or higher.",
      "published_date": "2019-06-14",
      "chain_len": 1,
      "project": "https://github.com/epeli/underscore.string",
      "commit_href": "https://github.com/epeli/underscore.string/commit/f486cd684c94c12db48b45d52b1472a1b9661029",
      "commit_sha": "f486cd684c94c12db48b45d52b1472a1b9661029",
      "patch": "SINGLE",
      "chain_ord": "['f486cd684c94c12db48b45d52b1472a1b9661029']",
      "before_first_fix_commit": "{'2f78f0d6e36d553484a1bf5fe5ed1998f013dea5'}",
      "last_fix_commit": "f486cd684c94c12db48b45d52b1472a1b9661029",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/03/2018, 21:34:42",
      "message": "Try to fix regexp redos\n\nfixes  #510",
      "author": "Esa-Matti Suuronen",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'unescapeHTML.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/esamattis/underscore.string/raw/f486cd684c94c12db48b45d52b1472a1b9661029/unescapeHTML.js', 'patch': \"@@ -2,7 +2,7 @@ var makeString = require('./helper/makeString');\\n var htmlEntities = require('./helper/htmlEntities');\\n \\n module.exports = function unescapeHTML(str) {\\n-  return makeString(str).replace(/\\\\&([^;]+);/g, function(entity, entityCode) {\\n+  return makeString(str).replace(/\\\\&([^;]{1,10});/g, function(entity, entityCode) {\\n     var match;\\n \\n     if (entityCode in htmlEntities) {\"}}",
      "message_norm": "try to fix regexp redos\n\nfixes  #510",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#510', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['unescapeHTML.js'])",
      "num_files": 1.0
    },
    {
      "index": 25,
      "vuln_id": "GHSA-24x6-8c7m-hv3f",
      "cwe_id": "{'CWE-125'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/953f28dca13c92839ba389c055587cfe6c723578'}",
      "dataset": "osv",
      "summary": "Heap OOB read in TFLite's implementation of `Minimum` or `Maximum` ### Impact\nThe implementations of the `Minimum` and `Maximum` TFLite operators can be used to read data outside of bounds of heap allocated objects, if any of the two input tensor arguments are empty.\n\nThis is because [the broadcasting implementation](https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/internal/reference/maximum_minimum.h#L52-L56) indexes in both tensors with the same index but does not validate that the index is within bounds:\n\n```cc\nauto maxmin_func = [&](int indexes[N]) {\n  output_data[SubscriptToIndex(output_desc, indexes)] =\n    op(input1_data[SubscriptToIndex(desc1, indexes)],\n        input2_data[SubscriptToIndex(desc2, indexes)]);\n};\n```\n\n### Patches\nWe have patched the issue in GitHub commit [953f28dca13c92839ba389c055587cfe6c723578](https://github.com/tensorflow/tensorflow/commit/953f28dca13c92839ba389c055587cfe6c723578).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/953f28dca13c92839ba389c055587cfe6c723578",
      "commit_sha": "953f28dca13c92839ba389c055587cfe6c723578",
      "patch": "SINGLE",
      "chain_ord": "['953f28dca13c92839ba389c055587cfe6c723578']",
      "before_first_fix_commit": "{'801c1c6be5324219689c98e1bd3e0ca365ee834d'}",
      "last_fix_commit": "953f28dca13c92839ba389c055587cfe6c723578",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 00:46:38",
      "message": "Prevent a null pointer exception in TFLite\n\nPiperOrigin-RevId: 370800206\nChange-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 31, 'deletions': 29, 'total': 60}",
      "files": "{'tensorflow/lite/kernels/maximum_minimum.cc': {'additions': 31, 'deletions': 29, 'changes': 60, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/953f28dca13c92839ba389c055587cfe6c723578/tensorflow%2Flite%2Fkernels%2Fmaximum_minimum.cc', 'patch': '@@ -157,35 +157,37 @@ template <KernelType kernel_type, typename OpType>\\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   OpContext op_context(context, node);\\n \\n-    switch (op_context.output->type) {\\n-      case kTfLiteFloat32:\\n-        TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\\n-        break;\\n-      case kTfLiteUInt8:\\n-        TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,\\n-                                                      op_context);\\n-        break;\\n-      case kTfLiteInt8:\\n-        TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\\n-        break;\\n-      case kTfLiteInt32:\\n-        TFLiteOperation<kernel_type, int32_t, OpType>(context, node,\\n-                                                      op_context);\\n-        break;\\n-      case kTfLiteInt64:\\n-        TFLiteOperation<kernel_type, int64_t, OpType>(context, node,\\n-                                                      op_context);\\n-        break;\\n-      case kTfLiteInt16:\\n-        TFLiteOperation<kernel_type, int16_t, OpType>(context, node,\\n-                                                      op_context);\\n-        break;\\n-      default:\\n-        context->ReportError(context,\\n-                             \"Type %d is currently not supported by Maximum.\",\\n-                             op_context.output->type);\\n-        return kTfLiteError;\\n-    }\\n+  // If inputs have no element, shortcircuit.\\n+  if (NumElements(op_context.input1) == 0 ||\\n+      NumElements(op_context.input2) == 0) {\\n+    return kTfLiteOk;\\n+  }\\n+\\n+  switch (op_context.output->type) {\\n+    case kTfLiteFloat32:\\n+      TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteUInt8:\\n+      TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteInt8:\\n+      TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteInt32:\\n+      TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteInt64:\\n+      TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteInt16:\\n+      TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);\\n+      break;\\n+    default:\\n+      context->ReportError(context,\\n+                           \"Type %d is currently not supported by Maximum.\",\\n+                           op_context.output->type);\\n+      return kTfLiteError;\\n+  }\\n   return kTfLiteOk;\\n }'}}",
      "message_norm": "prevent a null pointer exception in tflite\n\npiperorigin-revid: 370800206\nchange-id: idd437ebce4ff224120d8eefc1c14c062173b71d6",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('null pointer exception', 'SECWORD', ''), ('370800206', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/maximum_minimum.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1257,
      "vuln_id": "GHSA-8v5f-hp78-jgxq",
      "cwe_id": "{'CWE-347'}",
      "score": 0.0,
      "chain": "{'https://github.com/hokaccha/node-jwt-simple/commit/ead36e1d687645da9c3be8befdaaef622ea33106'}",
      "dataset": "osv",
      "summary": "Signature Verification Bypass in jwt-simple Versions of `jwt-simple` prior to 0.5.3 are vulnerable to Signature Verification Bypass. If no algorithm is specified in the `decode()` function, the packages uses the algorithm in the JWT to decode tokens. This allows an attacker to create a HS256 (symmetric algorithm) JWT with the server's public key as secret, and the package will verify it as HS256 instead of RS256 (asymmetric algorithm).\n\n\n## Recommendation\n\nUpgrade to version 0.5.3 or later.",
      "published_date": "2019-06-06",
      "chain_len": 1,
      "project": "https://github.com/hokaccha/node-jwt-simple",
      "commit_href": "https://github.com/hokaccha/node-jwt-simple/commit/ead36e1d687645da9c3be8befdaaef622ea33106",
      "commit_sha": "ead36e1d687645da9c3be8befdaaef622ea33106",
      "patch": "SINGLE",
      "chain_ord": "['ead36e1d687645da9c3be8befdaaef622ea33106']",
      "before_first_fix_commit": "{'ecb19a046432f3e9d9490c10c74c1d6f123c18e0'}",
      "last_fix_commit": "ead36e1d687645da9c3be8befdaaef622ea33106",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/14/2017, 01:56:51",
      "message": "Use RS256 if algorithm is undefined but key is RSA",
      "author": "Daniel",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'lib/jwt.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/hokaccha/node-jwt-simple/raw/ead36e1d687645da9c3be8befdaaef622ea33106/lib%2Fjwt.js', 'patch': \"@@ -76,6 +76,10 @@ jwt.decode = function jwt_decode(token, key, noVerify, algorithm) {\\n   var payload = JSON.parse(base64urlDecode(payloadSeg));\\n \\n   if (!noVerify) {\\n+    if (!algorithm && /BEGIN( RSA)? PUBLIC KEY/.test(key.toString())) {\\n+      algorithm = 'RS256';\\n+    }\\n+\\n     var signingMethod = algorithmMap[algorithm || header.alg];\\n     var signingType = typeMap[algorithm || header.alg];\\n     if (!signingMethod || !signingType) {\"}}",
      "message_norm": "use rs256 if algorithm is undefined but key is rsa",
      "language": "en",
      "entities": "[('key', 'SECWORD', ''), ('rsa', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/jwt.js'])",
      "num_files": 1.0
    },
    {
      "index": 202,
      "vuln_id": "GHSA-35m5-8cvj-8783",
      "cwe_id": "{'CWE-916', 'CWE-327', 'CWE-328'}",
      "score": 7.5,
      "chain": "{'https://github.com/Morgan-Phoenix/EnroCrypt/commit/e652d56ac60eadfc26489ab83927af13a9b9d8ce'}",
      "dataset": "osv",
      "summary": "Improper hashing in enrocrypt ### Impact\nThe vulnerability is we used MD5 hashing Algorithm In our hashing file. If anyone who is a beginner(and doesn't know about hashes)  can face problems as MD5 is considered a Insecure Hashing Algorithm. \n\n### Patches\nThe vulnerability is patched in v1.1.4 of the product, the users can upgrade to version 1.1.4.\n\n### Workarounds\nIf u specifically want a version and don't want to upgrade, you can remove the `MD5` hashing function from the file `hashing.py` and this vulnerability will be gone\n\n### References\nhttps://www.cybersecurity-help.cz/vdb/cwe/916/\nhttps://www.cybersecurity-help.cz/vdb/cwe/327/\nhttps://www.cybersecurity-help.cz/vdb/cwe/328/\nhttps://www.section.io/engineering-education/what-is-md5/\nhttps://www.johndcook.com/blog/2019/01/24/reversing-an-md5-hash/\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [**Enrocrypt's Official Repo**](http://www.github.com/Morgan-Phoenix/EnroCrypt)\n* Create a Discussion in  [**Enrocrypt's Official Repo**](http://www.github.com/Morgan-Phoenix/EnroCrypt)",
      "published_date": "2021-11-10",
      "chain_len": 1,
      "project": "https://github.com/Morgan-Phoenix/EnroCrypt",
      "commit_href": "https://github.com/Morgan-Phoenix/EnroCrypt/commit/e652d56ac60eadfc26489ab83927af13a9b9d8ce",
      "commit_sha": "e652d56ac60eadfc26489ab83927af13a9b9d8ce",
      "patch": "SINGLE",
      "chain_ord": "['e652d56ac60eadfc26489ab83927af13a9b9d8ce']",
      "before_first_fix_commit": "{'d02050267cecbe4f2877a07ca8a930129528ac05'}",
      "last_fix_commit": "e652d56ac60eadfc26489ab83927af13a9b9d8ce",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/06/2021, 14:04:45",
      "message": "Fixed GHSA-35m5-8cvj-8783",
      "author": "Morgan-Phoenix",
      "comments": null,
      "stats": "{'additions': 0, 'deletions': 5, 'total': 5}",
      "files": "{'enrocrypt/hashing.py': {'additions': 0, 'deletions': 5, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/Morgan-Phoenix/EnroCrypt/raw/e652d56ac60eadfc26489ab83927af13a9b9d8ce/enrocrypt%2Fhashing.py', 'patch': '@@ -66,11 +66,6 @@ def SHA244(self,data:str):\\n         hash = str(sha.digest())\\n         return self.__Salt(hash,salt=self.salt)\\n \\n-    def MD5(self,data:str):\\n-        sha = hashlib.md5(bytes(data.encode()))\\n-        hash = str(sha.digest())\\n-        return self.__Salt(hash,salt=self.salt)\\n-\\n     def SHA384(self,data:str):\\n         sha = hashlib.sha384(bytes(data.encode()))\\n         hash = str(sha.digest())'}}",
      "message_norm": "fixed ghsa-35m5-8cvj-8783",
      "language": "ca",
      "entities": "[('fixed', 'ACTION', ''), ('ghsa-35m5-8cvj-8783', 'VULNID', 'GHSA')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['enrocrypt/hashing.py'])",
      "num_files": 1.0
    },
    {
      "index": 1954,
      "vuln_id": "GHSA-gxg6-rc6c-v673",
      "cwe_id": "{'CWE-20'}",
      "score": 8.1,
      "chain": "{'https://github.com/beanshell/beanshell/commit/7c68fde2d6fc65e362f20863d868c112a90a9b49', 'https://github.com/beanshell/beanshell/commit/1ccc66bb693d4e46a34a904db8eeff07808d2ced'}",
      "dataset": "osv",
      "summary": "Improper Input Validation in BeanShell BeanShell (bsh) before 2.0b6, when included on the classpath by an application that uses Java serialization or XStream, allows remote attackers to execute arbitrary code via crafted serialized data, related to XThis.Handler.",
      "published_date": "2022-05-13",
      "chain_len": 2,
      "project": "https://github.com/beanshell/beanshell",
      "commit_href": "https://github.com/beanshell/beanshell/commit/7c68fde2d6fc65e362f20863d868c112a90a9b49",
      "commit_sha": "7c68fde2d6fc65e362f20863d868c112a90a9b49",
      "patch": "MULTI",
      "chain_ord": "['1ccc66bb693d4e46a34a904db8eeff07808d2ced', '7c68fde2d6fc65e362f20863d868c112a90a9b49']",
      "before_first_fix_commit": "{'1ccc66bb693d4e46a34a904db8eeff07808d2ced'}",
      "last_fix_commit": "7c68fde2d6fc65e362f20863d868c112a90a9b49",
      "chain_ord_pos": 2.0,
      "commit_datetime": "02/03/2016, 01:03:20",
      "message": "Prevent deserialization of Handler",
      "author": "Stian Soiland-Reyes",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'src/bsh/XThis.java': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/beanshell/beanshell/raw/7c68fde2d6fc65e362f20863d868c112a90a9b49/src%2Fbsh%2FXThis.java', 'patch': '@@ -118,6 +118,10 @@ interface from JDK1.2 VM...\\n \\t*/\\n \\tclass Handler implements InvocationHandler\\n \\t{\\n+\\t\\tprivate Object readResolve() throws ObjectStreamException {\\n+\\t\\t\\tthrow new NotSerializableException();\\n+\\t\\t}\\n+\\n \\t\\tpublic Object invoke( Object proxy, Method method, Object[] args )\\n \\t\\t\\tthrows Throwable\\n \\t\\t{'}}",
      "message_norm": "prevent deserialization of handler",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('deserialization', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/bsh/XThis.java'])",
      "num_files": 1.0
    },
    {
      "index": 498,
      "vuln_id": "GHSA-4vrf-ff7v-hpgr",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/f61c57bd425878be108ec787f4d96390579fb83e'}",
      "dataset": "osv",
      "summary": "Division by zero in TFLite's implementation of `EmbeddingLookup` The implementation of the `EmbeddingLookup` TFLite operator is [vulnerable to a division by zero error](https://github.com/tensorflow/tensorflow/blob/e4b29809543b250bc9b19678ec4776299dd569ba/tensorflow/lite/kernels/embedding_lookup.cc#L73-L74):\n\n```cc\nconst int row_size = SizeOfDimension(value, 0);\nconst int row_bytes = value->bytes / row_size;\n```\n\nAn attacker can craft a model such that the first dimension of the `value` input is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [f61c57bd425878be108ec787f4d96390579fb83e](https://github.com/tensorflow/tensorflow/commit/f61c57bd425878be108ec787f4d96390579fb83e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/f61c57bd425878be108ec787f4d96390579fb83e",
      "commit_sha": "f61c57bd425878be108ec787f4d96390579fb83e",
      "patch": "SINGLE",
      "chain_ord": "['f61c57bd425878be108ec787f4d96390579fb83e']",
      "before_first_fix_commit": "{'e4b29809543b250bc9b19678ec4776299dd569ba'}",
      "last_fix_commit": "f61c57bd425878be108ec787f4d96390579fb83e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 19:57:00",
      "message": "Prevent division by 0\n\nPiperOrigin-RevId: 370966645\nChange-Id: I831bfd96c7eb77b02d7ebb744335f59f6e5728cb",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'tensorflow/lite/kernels/embedding_lookup.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/f61c57bd425878be108ec787f4d96390579fb83e/tensorflow%2Flite%2Fkernels%2Fembedding_lookup.cc', 'patch': '@@ -71,6 +71,10 @@ TfLiteStatus EvalSimple(TfLiteContext* context, TfLiteNode* node,\\n                         const TfLiteTensor* lookup, const TfLiteTensor* value,\\n                         TfLiteTensor* output) {\\n   const int row_size = SizeOfDimension(value, 0);\\n+  if (row_size == 0) {\\n+    // Propagate empty tensor if input is empty\\n+    return kTfLiteOk;\\n+  }\\n   const int row_bytes = value->bytes / row_size;\\n \\n   char* output_raw = GetTensorData<char>(output);'}}",
      "message_norm": "prevent division by 0\n\npiperorigin-revid: 370966645\nchange-id: i831bfd96c7eb77b02d7ebb744335f59f6e5728cb",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('370966645', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/embedding_lookup.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2996,
      "vuln_id": "GHSA-rr8m-29g8-8cgc",
      "cwe_id": "{'CWE-89'}",
      "score": 8.8,
      "chain": "{'https://github.com/forkcms/forkcms/commit/6aca30e10b4181534f73f96d6e2ebeb45ec15069'}",
      "dataset": "osv",
      "summary": "SQL Injection in Fork CMS Fork CMS is vulnerable to SQL injection through marking blog comments on bulk as spam in versions prior to 5.11.1.",
      "published_date": "2022-03-26",
      "chain_len": 1,
      "project": "https://github.com/forkcms/forkcms",
      "commit_href": "https://github.com/forkcms/forkcms/commit/6aca30e10b4181534f73f96d6e2ebeb45ec15069",
      "commit_sha": "6aca30e10b4181534f73f96d6e2ebeb45ec15069",
      "patch": "SINGLE",
      "chain_ord": "['6aca30e10b4181534f73f96d6e2ebeb45ec15069']",
      "before_first_fix_commit": "{'1b38e33a98992793e998a937b717355212346993'}",
      "last_fix_commit": "6aca30e10b4181534f73f96d6e2ebeb45ec15069",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/23/2022, 12:21:47",
      "message": "Prevent sql injection through the ids of the blog comments",
      "author": "Jelmer Prins",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/Backend/Modules/Blog/Engine/Model.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/forkcms/forkcms/raw/6aca30e10b4181534f73f96d6e2ebeb45ec15069/src%2FBackend%2FModules%2FBlog%2FEngine%2FModel.php', 'patch': \"@@ -501,7 +501,7 @@ public static function getComments(array $ids): array\\n             'SELECT *\\n              FROM blog_comments AS i\\n              WHERE i.id IN (' . implode(', ', array_fill(0, count($ids), '?')) . ')',\\n-            $ids\\n+            array_map('intval', $ids)\\n         );\\n     }\"}}",
      "message_norm": "prevent sql injection through the ids of the blog comments",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('sql injection', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Backend/Modules/Blog/Engine/Model.php'])",
      "num_files": 1.0
    },
    {
      "index": 1032,
      "vuln_id": "GHSA-7ggw-h8pp-r95r",
      "cwe_id": "{'CWE-613'}",
      "score": 0.0,
      "chain": "{'https://github.com/octobercms/library/commit/642f597489e6f644d4bd9a0c267e864cabead024'}",
      "dataset": "osv",
      "summary": "Session ID not invalidated after logout ### Impact\nWhen logging out, the session ID was not invalidated. This is not a problem while the user is logged out, but as soon as the user logs back in the old session ID would be valid again; which means that anyone that gained access to the old session cookie would be able to act as the logged in user. This is not a major concern for the majority of cases, since it requires a malicious party gaining access to the session cookie in the first place, but nevertheless has been fixed.\n\n### Patches\nIssue has been patched in Build 472 (v1.0.472) and v1.1.2.\n\n### Workarounds\nApply https://github.com/octobercms/library/commit/642f597489e6f644d4bd9a0c267e864cabead024 to your installation manually if unable to upgrade to Build 472 or v1.1.2.\n\n### References\n- Reported by Anisio (Brazilian Information Security Analyst)\n- http://cve.circl.lu/cve/CVE-2021-3311\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at [hello@octobercms.com](mailto:hello@octobercms.com)\n\n### Threat assessment:\n<img width=\"699\" alt=\"Screen Shot 2021-02-07 at 11 50 35 PM\" src=\"https://user-images.githubusercontent.com/7253840/107180881-51eaf000-699f-11eb-8828-333128faf2a6.png\">",
      "published_date": "2021-02-10",
      "chain_len": 1,
      "project": "https://github.com/octobercms/library",
      "commit_href": "https://github.com/octobercms/library/commit/642f597489e6f644d4bd9a0c267e864cabead024",
      "commit_sha": "642f597489e6f644d4bd9a0c267e864cabead024",
      "patch": "SINGLE",
      "chain_ord": "['642f597489e6f644d4bd9a0c267e864cabead024']",
      "before_first_fix_commit": "{'e292d79ef2090f4d67a7d913d89c9d3597b0d334'}",
      "last_fix_commit": "642f597489e6f644d4bd9a0c267e864cabead024",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/30/2021, 00:47:39",
      "message": "Invalidate the session ID to prevent reuse\n\n1. Good logs in\n2. Bad captures Good's session cookie\n3. Good logs out\n4. Session cookie no longer works\n5. Good logs in a second time\n6. ORIGINAL session cookie works (Bad is also signed in)",
      "author": "Samuel Georges",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/Auth/Manager.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/octobercms/library/raw/642f597489e6f644d4bd9a0c267e864cabead024/src%2FAuth%2FManager.php', 'patch': '@@ -686,7 +686,7 @@ public function logout()\\n \\n         $this->user = null;\\n \\n-        Session::flush();\\n+        Session::invalidate();\\n         Cookie::queue(Cookie::forget($this->sessionKey));\\n     }'}}",
      "message_norm": "invalidate the session id to prevent reuse\n\n1. good logs in\n2. bad captures good's session cookie\n3. good logs out\n4. session cookie no longer works\n5. good logs in a second time\n6. original session cookie works (bad is also signed in)",
      "language": "en",
      "entities": "[('invalidate', 'ACTION', ''), ('prevent', 'ACTION', ''), ('cookie', 'SECWORD', ''), ('cookie', 'SECWORD', ''), ('cookie', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Auth/Manager.php'])",
      "num_files": 1.0
    },
    {
      "index": 3091,
      "vuln_id": "GHSA-vc3x-gx6c-g99f",
      "cwe_id": "{'CWE-190'}",
      "score": 7.5,
      "chain": "{'https://github.com/Bytom/bytom/commit/1ac3c8ac4f2b1e1df9675228290bda6b9586ba42'}",
      "dataset": "osv",
      "summary": "Denial of Service in Bytom In the client in Bytom before 1.0.6, checkTopicRegister in p2p/discover/net.go does not prevent negative idx values, leading to a crash.",
      "published_date": "2022-02-15",
      "chain_len": 1,
      "project": "https://github.com/Bytom/bytom",
      "commit_href": "https://github.com/Bytom/bytom/commit/1ac3c8ac4f2b1e1df9675228290bda6b9586ba42",
      "commit_sha": "1ac3c8ac4f2b1e1df9675228290bda6b9586ba42",
      "patch": "SINGLE",
      "chain_ord": "['1ac3c8ac4f2b1e1df9675228290bda6b9586ba42']",
      "before_first_fix_commit": "{'69b3d4c7cf41c6628efb34ed79ad35e9e22bbf82'}",
      "last_fix_commit": "1ac3c8ac4f2b1e1df9675228290bda6b9586ba42",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/31/2018, 05:48:40",
      "message": "p2p/discv5: fix idx can be negative after uint convert to int(can cause crash) (#1307)",
      "author": "yahtoo",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'p2p/discover/net.go': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/Bytom/bytom/raw/1ac3c8ac4f2b1e1df9675228290bda6b9586ba42/p2p%2Fdiscover%2Fnet.go', 'patch': '@@ -1221,7 +1221,7 @@ func (net *Network) checkTopicRegister(data *topicRegister) (*pong, error) {\\n \\tif hash != pongpkt.data.(*pong).TopicHash {\\n \\t\\treturn nil, errors.New(\"topic hash mismatch\")\\n \\t}\\n-\\tif data.Idx < 0 || int(data.Idx) >= len(data.Topics) {\\n+\\tif int(data.Idx) < 0 || int(data.Idx) >= len(data.Topics) {\\n \\t\\treturn nil, errors.New(\"topic index out of range\")\\n \\t}\\n \\treturn pongpkt.data.(*pong), nil'}}",
      "message_norm": "p2p/discv5: fix idx can be negative after uint convert to int(can cause crash) (#1307)",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('#1307', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['p2p/discover/net.go'])",
      "num_files": 1.0
    },
    {
      "index": 2548,
      "vuln_id": "GHSA-pc54-pchm-xcw6",
      "cwe_id": "{'CWE-611', 'CWE-20'}",
      "score": 0.0,
      "chain": "{'https://github.com/resteasy/resteasy/pull/611/commits/3ab999c899c455a0b0a00bf5e455ed3e8d9ae347', 'https://github.com/resteasy/resteasy/pull/611/commits/8b5d8cfc963794a74636d9a840e899408ec8fdc6'}",
      "dataset": "osv",
      "summary": "XML External Entity Reference in RESTEasy DocumentProvider in RESTEasy 2.3.7 and 3.0.9 does not configure the (1) external-general-entities or (2) external-parameter-entities features, which allows remote attackers to conduct XML external entity (XXE) attacks via unspecified vectors.",
      "published_date": "2022-05-17",
      "chain_len": 2,
      "project": "https://github.com/resteasy/resteasy",
      "commit_href": "https://github.com/resteasy/resteasy/pull/611/commits/3ab999c899c455a0b0a00bf5e455ed3e8d9ae347",
      "commit_sha": "3ab999c899c455a0b0a00bf5e455ed3e8d9ae347",
      "patch": "MULTI",
      "chain_ord": "['8b5d8cfc963794a74636d9a840e899408ec8fdc6', '3ab999c899c455a0b0a00bf5e455ed3e8d9ae347']",
      "before_first_fix_commit": "{'8b5d8cfc963794a74636d9a840e899408ec8fdc6'}",
      "last_fix_commit": "3ab999c899c455a0b0a00bf5e455ed3e8d9ae347",
      "chain_ord_pos": 2.0,
      "commit_datetime": "11/18/2014, 06:26:03",
      "message": "RESTEASY-1130: Added test for Red Hat version of Xerces in\nTestSecureProcessing.",
      "author": "rsigal",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 0, 'total': 8}",
      "files": "{'resteasy-jaxrs-test/src/test/java/org/jboss/resteasy/test/xxe/TestSecureProcessing.java': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/resteasy/resteasy/raw/3ab999c899c455a0b0a00bf5e455ed3e8d9ae347/resteasy-jaxrs-test%2Fsrc%2Ftest%2Fjava%2Forg%2Fjboss%2Fresteasy%2Ftest%2Fxxe%2FTestSecureProcessing.java', 'patch': '@@ -7,6 +7,7 @@\\n import javax.ws.rs.Consumes;\\r\\n import javax.ws.rs.POST;\\r\\n import javax.ws.rs.Path;\\r\\n+import javax.xml.parsers.DocumentBuilderFactory;\\r\\n \\r\\n import junit.framework.Assert;\\r\\n \\r\\n@@ -373,6 +374,13 @@ void doEntityExpansionPasses() throws Exception\\n    \\r\\n    void doMaxAttributesFails() throws Exception\\r\\n    {\\r\\n+      DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();\\r\\n+      System.out.println(\"dbf.getClass(): \" + dbf.getClass());\\r\\n+      if (\"org.apache.xerces.jaxp.DocumentBuilderFactoryImpl\".equals(dbf.getClass().getName()))\\r\\n+      {\\r\\n+         System.out.println(\"Testing with Red Hat version of Xerces, skipping max attributes test\");\\r\\n+         return;\\r\\n+      }\\r\\n       System.out.println(\"entering doMaxAttributesFails()\");\\r\\n       ClientRequest request = new ClientRequest(generateURL(\"/test\"));\\r\\n       request.body(\"application/xml\", bigAttributeDoc);'}}",
      "message_norm": "resteasy-1130: added test for red hat version of xerces in\ntestsecureprocessing.",
      "language": "en",
      "entities": "[('added', 'ACTION', ''), ('testsecureprocessing', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['resteasy-jaxrs-test/src/test/java/org/jboss/resteasy/test/xxe/TestSecureProcessing.java'])",
      "num_files": 1.0
    },
    {
      "index": 75,
      "vuln_id": "GHSA-29vr-79w7-p649",
      "cwe_id": "{'CWE-863'}",
      "score": 9.8,
      "chain": "{'https://github.com/Gerapy/Gerapy/commit/49bcb19be5e0320e7e1535f34fe00f16a3cf3b28'}",
      "dataset": "osv",
      "summary": "Incorrect Authorization in Gerapy An Access Control vunerabiity exists in Gerapy v 0.9.7 via the spider parameter in project_configure function.",
      "published_date": "2022-03-11",
      "chain_len": 1,
      "project": "https://github.com/Gerapy/Gerapy",
      "commit_href": "https://github.com/Gerapy/Gerapy/commit/49bcb19be5e0320e7e1535f34fe00f16a3cf3b28",
      "commit_sha": "49bcb19be5e0320e7e1535f34fe00f16a3cf3b28",
      "patch": "SINGLE",
      "chain_ord": "['49bcb19be5e0320e7e1535f34fe00f16a3cf3b28']",
      "before_first_fix_commit": "{'f1cd46d80328497c016fbac12c9239b9dcaef047'}",
      "last_fix_commit": "49bcb19be5e0320e7e1535f34fe00f16a3cf3b28",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/26/2021, 09:50:00",
      "message": "fix remote execute",
      "author": "Germey",
      "comments": null,
      "stats": "{'additions': 56, 'deletions': 40, 'total': 96}",
      "files": "{'gerapy/server/core/views.py': {'additions': 56, 'deletions': 40, 'changes': 96, 'status': 'modified', 'raw_url': 'https://github.com/Gerapy/Gerapy/raw/49bcb19be5e0320e7e1535f34fe00f16a3cf3b28/gerapy%2Fserver%2Fcore%2Fviews.py', 'patch': '@@ -2,7 +2,12 @@\\n from pathlib import Path\\n from urllib.parse import unquote\\n import base64\\n-import json, os, requests, time, pytz, pymongo\\n+import json\\n+import os\\n+import requests\\n+import time\\n+import pytz\\n+import pymongo\\n from shutil import rmtree\\n from requests.exceptions import ConnectionError\\n from os.path import join, exists\\n@@ -173,7 +178,8 @@ def spider_list(request, client_id, project_name):\\n         client = Client.objects.get(id=client_id)\\n         scrapyd = get_scrapyd(client)\\n         spiders = scrapyd.list_spiders(project_name)\\n-        spiders = [{\\'name\\': spider, \\'id\\': index + 1} for index, spider in enumerate(spiders)]\\n+        spiders = [{\\'name\\': spider, \\'id\\': index + 1}\\n+                   for index, spider in enumerate(spiders)]\\n         return JsonResponse(spiders)\\n \\n \\n@@ -242,23 +248,25 @@ def project_configure(request, project_name):\\n     if request.method == \\'GET\\':\\n         project = Project.objects.get(name=project_name)\\n         project = model_to_dict(project)\\n-        project[\\'configuration\\'] = json.loads(project[\\'configuration\\']) if project[\\'configuration\\'] else None\\n+        project[\\'configuration\\'] = json.loads(\\n+            project[\\'configuration\\']) if project[\\'configuration\\'] else None\\n         return JsonResponse(project)\\n-    \\n+\\n     # update configuration\\n     elif request.method == \\'POST\\':\\n         project = Project.objects.filter(name=project_name)\\n         data = json.loads(request.body)\\n-        configuration = json.dumps(data.get(\\'configuration\\'), ensure_ascii=False)\\n+        configuration = json.dumps(\\n+            data.get(\\'configuration\\'), ensure_ascii=False)\\n         project.update(**{\\'configuration\\': configuration})\\n-        \\n         # for safe protection\\n-        project_name = re.sub(\\'[\\\\!\\\\@\\\\#\\\\$\\\\;\\\\&\\\\*\\\\~\\\\\"\\\\\\'\\\\{\\\\}\\\\]\\\\[\\\\-\\\\+\\\\%\\\\^]+\\', \\'\\', project_name)\\n+        project_name = re.sub(\\n+            \\'[\\\\s\\\\!\\\\@\\\\#\\\\$\\\\;\\\\&\\\\*\\\\~\\\\\"\\\\\\'\\\\{\\\\}\\\\]\\\\[\\\\-\\\\+\\\\%\\\\^]+\\', \\'\\', project_name)\\n         # execute generate cmd\\n-        cmd = \\' \\'.join([\\'gerapy\\', \\'generate\\', project_name])\\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n+        cmd = [\\'gerapy\\', \\'generate\\', project_name]\\n+        p = Popen(cmd, shell=False, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\\n-        \\n+\\n         if not stderr:\\n             return JsonResponse({\\'status\\': \\'1\\'})\\n         else:\\n@@ -294,7 +302,8 @@ def project_create(request):\\n         data[\\'configurable\\'] = 1\\n         project, result = Project.objects.update_or_create(**data)\\n         # generate a single project folder\\n-        path = join(os.path.abspath(join(os.getcwd(), PROJECTS_FOLDER)), data[\\'name\\'])\\n+        path = join(os.path.abspath(\\n+            join(os.getcwd(), PROJECTS_FOLDER)), data[\\'name\\'])\\n         os.mkdir(path)\\n         return JsonResponse(model_to_dict(project))\\n \\n@@ -334,12 +343,13 @@ def project_clone(request):\\n         if not address.startswith(\\'http\\'):\\n             return JsonResponse({\\'status\\': False})\\n         address = address + \\'.git\\' if not address.endswith(\\'.git\\') else address\\n-        cmd = \\'git clone {address} {target}\\'.format(address=address, target=join(PROJECTS_FOLDER, Path(address).stem))\\n+        cmd = [\\'git\\', \\'clone\\', \\'address\\', join(PROJECTS_FOLDER, Path(address).stem)]\\n         logger.debug(\\'clone cmd %s\\', cmd)\\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n+        p = Popen(cmd, shell=False, stdin=PIPE, stdout=PIPE, stderr=PIPE)\\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\\n         logger.debug(\\'clone run result %s\\', stdout)\\n-        if stderr: logger.error(stderr)\\n+        if stderr:\\n+            logger.error(stderr)\\n         return JsonResponse({\\'status\\': True}) if not stderr else JsonResponse({\\'status\\': False})\\n \\n \\n@@ -393,10 +403,12 @@ def project_version(request, client_id, project_name):\\n                 return JsonResponse({\\'message\\': \\'Connect Error\\'}, status=500)\\n             if len(versions) > 0:\\n                 version = versions[-1]\\n-                deployed_at = timezone.datetime.fromtimestamp(int(version), tz=pytz.timezone(TIME_ZONE))\\n+                deployed_at = timezone.datetime.fromtimestamp(\\n+                    int(version), tz=pytz.timezone(TIME_ZONE))\\n             else:\\n                 deployed_at = None\\n-            deploy, result = Deploy.objects.update_or_create(client=client, project=project, deployed_at=deployed_at)\\n+            deploy, result = Deploy.objects.update_or_create(\\n+                client=client, project=project, deployed_at=deployed_at)\\n         # return deploy json info\\n         return JsonResponse(model_to_dict(deploy))\\n \\n@@ -446,7 +458,7 @@ def project_build(request, project_name):\\n     # get project folder\\n     path = os.path.abspath(join(os.getcwd(), PROJECTS_FOLDER))\\n     project_path = join(path, project_name)\\n-    \\n+\\n     # get build version\\n     if request.method == \\'GET\\':\\n         egg = find_egg(project_path)\\n@@ -470,7 +482,7 @@ def project_build(request, project_name):\\n         # transfer model to dict then dumps it to json\\n         data = model_to_dict(model)\\n         return JsonResponse(data)\\n-    \\n+\\n     # build operation manually by clicking button\\n     elif request.method == \\'POST\\':\\n         data = json.loads(request.body)\\n@@ -483,7 +495,8 @@ def project_build(request, project_name):\\n         built_at = timezone.now()\\n         # if project does not exists in db, create it\\n         if not Project.objects.filter(name=project_name):\\n-            Project(name=project_name, description=description, built_at=built_at, egg=egg).save()\\n+            Project(name=project_name, description=description,\\n+                    built_at=built_at, egg=egg).save()\\n             model = Project.objects.get(name=project_name)\\n         # if project exists, update egg, description, built_at info\\n         else:\\n@@ -526,17 +539,16 @@ def project_parse(request, project_name):\\n         body = data.get(\\'body\\', \\'\\')\\n         if args.get(\\'method\\').lower() != \\'get\\':\\n             args[\\'body\\'] = \"\\'\" + json.dumps(body, ensure_ascii=False) + \"\\'\"\\n-        \\n-        args_cmd = \\' \\'.join(\\n-            [\\'--{arg} {value}\\'.format(arg=arg, value=value) for arg, value in args.items()])\\n-        logger.debug(\\'args cmd %s\\', args_cmd)\\n-        cmd = \\'gerapy parse {args_cmd} {project_path} {spider_name}\\'.format(\\n-            args_cmd=args_cmd,\\n-            project_path=project_path,\\n-            spider_name=spider_name\\n-        )\\n+\\n+        args_array = []\\n+        for arg, value in args.items():\\n+            args_array.append(f\\'--{arg}\\')\\n+            args_array.append(f\\'{value}\\')\\n+        cmd = [\\'gerapy\\', \\'parse\\'] + args_array + [project_path] + [spider_name]\\n+        print(\\'cmd\\', cmd)\\n         logger.debug(\\'parse cmd %s\\', cmd)\\n-        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)\\n+        p = Popen(cmd, shell=False, stdin=PIPE,\\n+                         stdout=PIPE, stderr=PIPE, close_fds=True)\\n         stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\\n         logger.debug(\\'stdout %s, stderr %s\\', stdout, stderr)\\n         if not stderr:\\n@@ -645,7 +657,6 @@ def job_list(request, client_id, project_name):\\n                 job[\\'status\\'] = status\\n                 jobs.append(job)\\n         return JsonResponse(jobs)\\n-    \\n \\n \\n @api_view([\\'GET\\'])\\n@@ -663,7 +674,8 @@ def job_log(request, client_id, project_name, spider_name, job_id):\\n     if request.method == \\'GET\\':\\n         client = Client.objects.get(id=client_id)\\n         # get log url\\n-        url = log_url(client.ip, client.port, project_name, spider_name, job_id)\\n+        url = log_url(client.ip, client.port,\\n+                      project_name, spider_name, job_id)\\n         # get last 1000 bytes of log\\n         response = requests.get(url, timeout=5, headers={\\n             \\'Range\\': \\'bytes=-1000\\'\\n@@ -765,7 +777,8 @@ def monitor_create(request):\\n     if request.method == \\'POST\\':\\n         data = json.loads(request.body)\\n         data = data[\\'form\\']\\n-        data[\\'configuration\\'] = json.dumps(data[\\'configuration\\'], ensure_ascii=False)\\n+        data[\\'configuration\\'] = json.dumps(\\n+            data[\\'configuration\\'], ensure_ascii=False)\\n         monitor = Monitor.objects.create(**data)\\n         return JsonResponse(model_to_dict(monitor))\\n \\n@@ -785,7 +798,8 @@ def task_create(request):\\n                                    name=data.get(\\'name\\'),\\n                                    spider=data.get(\\'spider\\'),\\n                                    trigger=data.get(\\'trigger\\'),\\n-                                   configuration=json.dumps(data.get(\\'configuration\\'), ensure_ascii=False),\\n+                                   configuration=json.dumps(\\n+                                       data.get(\\'configuration\\'), ensure_ascii=False),\\n                                    modified=1)\\n         return JsonResponse({\\'result\\': \\'1\\', \\'data\\': model_to_dict(task)})\\n \\n@@ -803,7 +817,8 @@ def task_update(request, task_id):\\n         task = Task.objects.filter(id=task_id)\\n         data = json.loads(request.body)\\n         data[\\'clients\\'] = json.dumps(data.get(\\'clients\\'), ensure_ascii=False)\\n-        data[\\'configuration\\'] = json.dumps(data.get(\\'configuration\\'), ensure_ascii=False)\\n+        data[\\'configuration\\'] = json.dumps(\\n+            data.get(\\'configuration\\'), ensure_ascii=False)\\n         data[\\'modified\\'] = 1\\n         task.update(**data)\\n         return JsonResponse(model_to_dict(Task.objects.get(id=task_id)))\\n@@ -823,11 +838,10 @@ def task_remove(request, task_id):\\n         clients = clients_of_task(task)\\n         for client in clients:\\n             job_id = get_job_id(client, task)\\n-            DjangoJob.objects.filter(name=job_id).delete()\\n+            DjangoJob.objects.filter(id=job_id).delete()\\n         # delete task\\n         Task.objects.filter(id=task_id).delete()\\n         return JsonResponse({\\'result\\': \\'1\\'})\\n-    \\n \\n \\n @api_view([\\'GET\\'])\\n@@ -875,12 +889,14 @@ def task_status(request, task_id):\\n         clients = clients_of_task(task)\\n         for client in clients:\\n             job_id = get_job_id(client, task)\\n-            jobs = DjangoJob.objects.filter(name=job_id)\\n+            jobs = DjangoJob.objects.filter(id=job_id)\\n             logger.debug(\\'jobs from djangojob %s\\', jobs)\\n             # if job does not exist, for date mode exceed time\\n-            if not jobs: continue\\n-            job = DjangoJob.objects.get(name=job_id)\\n-            executions = serialize(\\'json\\', DjangoJobExecution.objects.filter(job=job))\\n+            if not jobs:\\n+                continue\\n+            job = DjangoJob.objects.get(id=job_id)\\n+            executions = serialize(\\n+                \\'json\\', DjangoJobExecution.objects.filter(job=job))\\n             result.append({\\n                 \\'client\\': model_to_dict(client),\\n                 \\'next\\': job.next_run_time,'}}",
      "message_norm": "fix remote execute",
      "language": "ro",
      "entities": "[('fix', 'ACTION', ''), ('remote execute', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['gerapy/server/core/views.py'])",
      "num_files": 1.0
    },
    {
      "index": 1321,
      "vuln_id": "GHSA-95hx-62rh-gg96",
      "cwe_id": "{'CWE-79'}",
      "score": 8.0,
      "chain": "{'https://github.com/PrestaShop/contactform/commit/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09'}",
      "dataset": "osv",
      "summary": "Potential XSS injection In PrestaShop contactform ### Impact\nAn attacker is able to inject javascript while using the contact form. \n\n### Patches\nThe problem is fixed in v4.3.0\n\n### References\n[Cross-site Scripting (XSS) - Stored (CWE-79)](https://cwe.mitre.org/data/definitions/79.html)",
      "published_date": "2020-09-15",
      "chain_len": 1,
      "project": "https://github.com/PrestaShop/contactform",
      "commit_href": "https://github.com/PrestaShop/contactform/commit/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
      "commit_sha": "ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
      "patch": "SINGLE",
      "chain_ord": "['ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09']",
      "before_first_fix_commit": "{'a883e56240357b4aaaf594ade573bb596e518078', 'aa3c77923734854bb7168f30db43544e42638202'}",
      "last_fix_commit": "ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/15/2020, 08:03:00",
      "message": "Merge pull request from GHSA-95hx-62rh-gg96\n\nDo not unescape form message data",
      "author": "GoT",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 8, 'total': 17}",
      "files": "{'contactform.php': {'additions': 9, 'deletions': 8, 'changes': 17, 'status': 'modified', 'raw_url': 'https://github.com/PrestaShop/contactform/raw/ecd9f5d14920ec00885766a7cb41bcc5ed8bfa09/contactform.php', 'patch': \"@@ -317,7 +317,7 @@ public function getWidgetVariables($hookName = null, array $configuration = [])\\n             }\\n         }\\n         $this->contact['contacts'] = $this->getTemplateVarContact();\\n-        $this->contact['message'] = html_entity_decode(Tools::getValue('message'));\\n+        $this->contact['message'] = Tools::getValue('message');\\n         $this->contact['allow_file_upload'] = (bool) Configuration::get('PS_CUSTOMER_SERVICE_FILE_UPLOAD');\\n \\n         if (!(bool)Configuration::isCatalogMode()) {\\n@@ -388,9 +388,10 @@ public function getTemplateVarOrders()\\n     {\\n         $orders = [];\\n \\n-        if (!isset($this->customer_thread['id_order'])\\n+        if (empty($this->customer_thread['id_order'])\\n             && isset($this->context->customer)\\n-            && $this->context->customer->isLogged()) {\\n+            && $this->context->customer->isLogged()\\n+        ) {\\n             $customer_orders = Order::getCustomerOrders($this->context->customer->id);\\n \\n             foreach ($customer_orders as $customer_order) {\\n@@ -401,7 +402,7 @@ public function getTemplateVarOrders()\\n                     $orders[$customer_order['id_order']]['products'] = $myOrder->getProducts();\\n                 }\\n             }\\n-        } elseif (isset($this->customer_thread['id_order']) && (int)$this->customer_thread['id_order'] > 0) {\\n+        } elseif (isset($this->customer_thread['id_order']) && (int) $this->customer_thread['id_order'] > 0) {\\n             $myOrder = new Order($this->customer_thread['id_order']);\\n \\n             if (Validate::isLoadedObject($myOrder)) {\\n@@ -411,13 +412,13 @@ public function getTemplateVarOrders()\\n             }\\n         }\\n \\n-        if (isset($this->customer_thread['id_product'])) {\\n+        if (!empty($this->customer_thread['id_product'])) {\\n             $id_order = isset($this->customer_thread['id_order']) ?\\n-                      (int)$this->customer_thread['id_order'] :\\n+                      (int) $this->customer_thread['id_order'] :\\n                       0;\\n \\n             $orders[$id_order]['products'][(int)$this->customer_thread['id_product']] = $this->context->controller->objectPresenter->present(\\n-                new Product((int)$this->customer_thread['id_product'])\\n+                new Product((int) $this->customer_thread['id_product'])\\n             );\\n         }\\n \\n@@ -586,7 +587,7 @@ public function sendMessage()\\n                     '{lastname}' => '',\\n                     '{order_name}' => '-',\\n                     '{attached_file}' => '-',\\n-                    '{message}' => Tools::nl2br(Tools::stripslashes($message)),\\n+                    '{message}' => Tools::nl2br(Tools::htmlentitiesUTF8(Tools::stripslashes($message))),\\n                     '{email}' =>  $from,\\n                     '{product_name}' => '',\\n                 ];\"}}",
      "message_norm": "merge pull request from ghsa-95hx-62rh-gg96\n\ndo not unescape form message data",
      "language": "fr",
      "entities": "[('ghsa-95hx-62rh-gg96', 'VULNID', 'GHSA'), ('unescape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['contactform.php'])",
      "num_files": 1.0
    },
    {
      "index": 872,
      "vuln_id": "GHSA-6p56-wp2h-9hxr",
      "cwe_id": "{'CWE-120'}",
      "score": 5.3,
      "chain": "{'https://github.com/numpy/numpy/commit/ae317fd9ff3e79c0eac357d723bfc29cbd625f2e'}",
      "dataset": "osv",
      "summary": "NumPy Buffer Overflow (Disputed) A Buffer Overflow vulnerability exists in NumPy 1.9.x in the PyArray_NewFromDescr_int function of ctors.c when specifying arrays of large dimensions (over 32) from Python code, which could let a malicious user cause a Denial of Service.\n\nNOTE: The vendor does not agree this is a vulneraility; In (very limited) circumstances a user may be able provoke the buffer overflow, the user is most likely already privileged to at least provoke denial of service by exhausting memory. Triggering this further requires the use of uncommon API (complicated structured dtypes), which is very unlikely to be available to an unprivileged user.",
      "published_date": "2022-01-07",
      "chain_len": 1,
      "project": "https://github.com/numpy/numpy",
      "commit_href": "https://github.com/numpy/numpy/commit/ae317fd9ff3e79c0eac357d723bfc29cbd625f2e",
      "commit_sha": "ae317fd9ff3e79c0eac357d723bfc29cbd625f2e",
      "patch": "SINGLE",
      "chain_ord": "['ae317fd9ff3e79c0eac357d723bfc29cbd625f2e']",
      "before_first_fix_commit": "{'938fe1f871e22b8f5556b946135fa700e5ebcce1', '16f7824b4d935b6aee98298ca4123d57174a6f2e'}",
      "last_fix_commit": "ae317fd9ff3e79c0eac357d723bfc29cbd625f2e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/11/2021, 19:39:32",
      "message": "Merge pull request #18989 from yetanothercheer/gh-18939-potential_buffer_overflow\n\nBUG: fix potential buffer overflow(#18939)",
      "author": "Charles Harris",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 8, 'total': 16}",
      "files": "{'numpy/core/src/multiarray/ctors.c': {'additions': 8, 'deletions': 8, 'changes': 16, 'status': 'modified', 'raw_url': 'https://github.com/numpy/numpy/raw/ae317fd9ff3e79c0eac357d723bfc29cbd625f2e/numpy%2Fcore%2Fsrc%2Fmultiarray%2Fctors.c', 'patch': '@@ -668,6 +668,14 @@ PyArray_NewFromDescr_int(\\n     int i;\\n     npy_intp nbytes;\\n \\n+    if ((unsigned int)nd > (unsigned int)NPY_MAXDIMS) {\\n+        PyErr_Format(PyExc_ValueError,\\n+                     \"number of dimensions must be within [0, %d]\",\\n+                     NPY_MAXDIMS);\\n+        Py_DECREF(descr);\\n+        return NULL;\\n+    }\\n+\\n     if (descr->subarray) {\\n         PyObject *ret;\\n         npy_intp newdims[2*NPY_MAXDIMS];\\n@@ -687,14 +695,6 @@ PyArray_NewFromDescr_int(\\n         return ret;\\n     }\\n \\n-    if ((unsigned int)nd > (unsigned int)NPY_MAXDIMS) {\\n-        PyErr_Format(PyExc_ValueError,\\n-                     \"number of dimensions must be within [0, %d]\",\\n-                     NPY_MAXDIMS);\\n-        Py_DECREF(descr);\\n-        return NULL;\\n-    }\\n-\\n     /* Check datatype element size */\\n     nbytes = descr->elsize;\\n     if (PyDataType_ISUNSIZED(descr)) {'}}",
      "message_norm": "merge pull request #18989 from yetanothercheer/gh-18939-potential_buffer_overflow\n\nbug: fix potential buffer overflow(#18939)",
      "language": "en",
      "entities": "[('#18989', 'ISSUE', ''), ('potential_buffer_overflow', 'SECWORD', ''), ('bug', 'FLAW', ''), ('fix', 'ACTION', ''), ('buffer overflow(#18939', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['numpy/core/src/multiarray/ctors.c'])",
      "num_files": 1.0
    },
    {
      "index": 2669,
      "vuln_id": "GHSA-pxcf-v868-m492",
      "cwe_id": "{'CWE-74', 'CWE-79'}",
      "score": 7.6,
      "chain": "{'https://github.com/jperelli/osm-static-maps/commit/97355d29e08753d1cfe99b1281dbaa06f4e651b0'}",
      "dataset": "osv",
      "summary": "Injection and Cross-site Scripting in osm-static-maps This affects all versions of package osm-static-maps under 3.9.0. User input given to the package is passed directly to a template without escaping ({{{ ... }}}). As such, it is possible for an attacker to inject arbitrary HTML/JS code and depending on the context. It will be outputted as an HTML on the page which gives opportunity for XSS or rendered on the server (puppeteer) which also gives opportunity for SSRF and Local File Read.",
      "published_date": "2021-05-10",
      "chain_len": 1,
      "project": "https://github.com/jperelli/osm-static-maps",
      "commit_href": "https://github.com/jperelli/osm-static-maps/commit/97355d29e08753d1cfe99b1281dbaa06f4e651b0",
      "commit_sha": "97355d29e08753d1cfe99b1281dbaa06f4e651b0",
      "patch": "SINGLE",
      "chain_ord": "['97355d29e08753d1cfe99b1281dbaa06f4e651b0']",
      "before_first_fix_commit": "{'6bce2e2a8dd4cbbbbe083820e494ba858be74b16'}",
      "last_fix_commit": "97355d29e08753d1cfe99b1281dbaa06f4e651b0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/11/2020, 23:25:42",
      "message": "fix: escape special characters before insertion to template",
      "author": "snoopysecurity",
      "comments": null,
      "stats": "{'additions': 25, 'deletions': 6, 'total': 31}",
      "files": "{'src/server.js': {'additions': 25, 'deletions': 6, 'changes': 31, 'status': 'modified', 'raw_url': 'https://github.com/jperelli/osm-static-maps/raw/97355d29e08753d1cfe99b1281dbaa06f4e651b0/src%2Fserver.js', 'patch': '@@ -19,6 +19,23 @@ app.use((req, res, next) => {\\n   next();\\n });\\n \\n+\\n+function htmlEscape(text) {\\n+  return text.replace(/&/g, \\'&amp;\\').\\n+  replace(/</g, \\'&lt;\\').\\n+  replace(/\"/g, \\'&quot;\\').\\n+  replace(/\\'/g, \\'&#039;\\');\\n+}\\n+\\n+\\n+function sanitize(params) {\\n+  result = {}\\n+  for (let [key, value] of Object.entries(params)) {\\n+      result[key] = htmlEscape(value)\\n+  }\\n+  return result;\\n+}\\n+\\n app.get(\"/health\", (req, res) => res.sendStatus(200));\\n \\n const handler = (res, params) => {\\n@@ -40,12 +57,14 @@ const handler = (res, params) => {\\n app.get(\"/\", (req, res) => handler(res, req.query));\\n app.post(\"/\", (req, res) => handler(res, req.body));\\n \\n-app.get(\"/dynamic\", (req, res) =>\\n-  handler(res, { ...req.query, renderToHtml: true })\\n-);\\n+app.get(\"/dynamic\", (req, res) => {\\n+  var sanitized = sanitize(req.query)\\n+  handler(res, { ...sanitized, renderToHtml: true })\\n+})\\n \\n-app.post(\"/dynamic\", (req, res) =>\\n-  handler(res, { ...req.body, renderToHtml: true })\\n-);\\n+app.post(\"/dynamic\", (req, res) => {\\n+  var sanitized = sanitize(req.body)\\n+  handler(res, { ...sanitized, renderToHtml: true })\\n+})\\n \\n module.exports = http.createServer(app);'}}",
      "message_norm": "fix: escape special characters before insertion to template",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/server.js'])",
      "num_files": 1.0
    },
    {
      "index": 637,
      "vuln_id": "GHSA-5gqf-456p-4836",
      "cwe_id": "{'CWE-476'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb'}",
      "dataset": "osv",
      "summary": "Reference binding to nullptr in `SdcaOptimizer` ### Impact\nThe implementation of `tf.raw_ops.SdcaOptimizer` triggers undefined behavior due to dereferencing a null pointer:\n\n```python\nimport tensorflow as tf\n\nsparse_example_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_indices = [tf.constant([], shape=[0, 0, 0, 0], dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_feature_values = []\n\ndense_features = []\ndense_weights = []\n\nexample_weights = tf.constant((0.0), dtype=tf.float32)\nexample_labels = tf.constant((0.0), dtype=tf.float32)\n\nsparse_indices = [tf.constant((0), dtype=tf.int64), tf.constant((0), dtype=tf.int64)]\nsparse_weights = [tf.constant((0.0), dtype=tf.float32), tf.constant((0.0), dtype=tf.float32)]\n  \nexample_state_data = tf.constant([0.0, 0.0, 0.0, 0.0], shape=[1, 4], dtype=tf.float32)\n  \ntf.raw_ops.SdcaOptimizer(\n  sparse_example_indices=sparse_example_indices,\n  sparse_feature_indices=sparse_feature_indices,\n  sparse_feature_values=sparse_feature_values, dense_features=dense_features,\n  example_weights=example_weights, example_labels=example_labels, \n  sparse_indices=sparse_indices, sparse_weights=sparse_weights, \n  dense_weights=dense_weights, example_state_data=example_state_data,\n  loss_type=\"logistic_loss\", l1=0.0, l2=0.0, num_loss_partitions=1,\n  num_inner_iterations=1, adaptative=False)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/60a45c8b6192a4699f2e2709a2645a751d435cc3/tensorflow/core/kernels/sdca_internal.cc) does not validate that the user supplied arguments satisfy all [constraints expected by the op](https://www.tensorflow.org/api_docs/python/tf/raw_ops/SdcaOptimizer).\n\n### Patches\nWe have patched the issue in GitHub commit [f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb](https://github.com/tensorflow/tensorflow/commit/f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb",
      "commit_sha": "f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb",
      "patch": "SINGLE",
      "chain_ord": "['f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb']",
      "before_first_fix_commit": "{'60a45c8b6192a4699f2e2709a2645a751d435cc3'}",
      "last_fix_commit": "f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/05/2021, 18:40:50",
      "message": "Add several missing validations in SDCA\n\nPiperOrigin-RevId: 372172877\nChange-Id: Id366da962432e18dcbfac847d11e98488bebb70a",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 36, 'deletions': 0, 'total': 36}",
      "files": "{'tensorflow/core/kernels/sdca_internal.cc': {'additions': 36, 'deletions': 0, 'changes': 36, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/f7cc8755ac6683131fdfa7a8a121f9d7a9dec6fb/tensorflow%2Fcore%2Fkernels%2Fsdca_internal.cc', 'patch': '@@ -99,17 +99,31 @@ Status ModelWeights::Initialize(OpKernelContext* const context) {\\n   OpInputList sparse_weights_inputs;\\n   TF_RETURN_IF_ERROR(\\n       context->input_list(\"sparse_weights\", &sparse_weights_inputs));\\n+  if (sparse_indices_inputs.size() != sparse_weights_inputs.size())\\n+    return errors::InvalidArgument(\\n+        \"sparse_indices and sparse_weights must have the same length, got \",\\n+        sparse_indices_inputs.size(), \" and \", sparse_weights_inputs.size());\\n   OpInputList dense_weights_inputs;\\n   TF_RETURN_IF_ERROR(\\n       context->input_list(\"dense_weights\", &dense_weights_inputs));\\n \\n   OpOutputList sparse_weights_outputs;\\n   TF_RETURN_IF_ERROR(context->output_list(\"out_delta_sparse_weights\",\\n                                           &sparse_weights_outputs));\\n+  if (sparse_weights_outputs.size() != sparse_weights_inputs.size())\\n+    return errors::InvalidArgument(\\n+        \"out_delta_sparse_weights and sparse_weights must have the same \"\\n+        \"length, got \",\\n+        sparse_weights_outputs.size(), \" and \", sparse_weights_inputs.size());\\n \\n   OpOutputList dense_weights_outputs;\\n   TF_RETURN_IF_ERROR(\\n       context->output_list(\"out_delta_dense_weights\", &dense_weights_outputs));\\n+  if (dense_weights_outputs.size() != dense_weights_inputs.size())\\n+    return errors::InvalidArgument(\\n+        \"out_delta_dense_weights and dense_weights must have the same length, \"\\n+        \"got \",\\n+        dense_weights_outputs.size(), \" and \", dense_weights_inputs.size());\\n \\n   for (int i = 0; i < sparse_weights_inputs.size(); ++i) {\\n     Tensor* delta_t;\\n@@ -327,13 +341,28 @@ Status Examples::Initialize(OpKernelContext* const context,\\n   OpInputList sparse_example_indices_inputs;\\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\\n                                          &sparse_example_indices_inputs));\\n+  if (sparse_example_indices_inputs.size() != num_sparse_features)\\n+    return errors::InvalidArgument(\\n+        \"Expected \", num_sparse_features,\\n+        \" tensors in sparse_example_indices but got \",\\n+        sparse_example_indices_inputs.size());\\n   OpInputList sparse_feature_indices_inputs;\\n   TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\\n                                          &sparse_feature_indices_inputs));\\n+  if (sparse_feature_indices_inputs.size() != num_sparse_features)\\n+    return errors::InvalidArgument(\\n+        \"Expected \", num_sparse_features,\\n+        \" tensors in sparse_feature_indices but got \",\\n+        sparse_feature_indices_inputs.size());\\n   OpInputList sparse_feature_values_inputs;\\n   if (num_sparse_features_with_values > 0) {\\n     TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\\n                                            &sparse_feature_values_inputs));\\n+    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\\n+      return errors::InvalidArgument(\\n+          \"Expected \", num_sparse_features_with_values,\\n+          \" tensors in sparse_feature_values but got \",\\n+          sparse_feature_values_inputs.size());\\n   }\\n \\n   const Tensor* example_weights_t;\\n@@ -400,6 +429,13 @@ Status Examples::CreateSparseFeatureRepresentation(\\n           sparse_example_indices_inputs[i].template flat<int64>();\\n       auto feature_indices =\\n           sparse_feature_indices_inputs[i].template flat<int64>();\\n+      if (example_indices.size() != feature_indices.size()) {\\n+        mutex_lock l(mu);\\n+        result = errors::InvalidArgument(\\n+            \"Found mismatched example_indices and feature_indices [\",\\n+            example_indices, \"] vs [\", feature_indices, \"]\");\\n+        return;\\n+      }\\n \\n       // Parse features for each example. Features for a particular example\\n       // are at the offsets (start_id, end_id]'}}",
      "message_norm": "add several missing validations in sdca\n\npiperorigin-revid: 372172877\nchange-id: id366da962432e18dcbfac847d11e98488bebb70a",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('missing validations', 'SECWORD', ''), ('372172877', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sdca_internal.cc'])",
      "num_files": 1.0
    },
    {
      "index": 97,
      "vuln_id": "GHSA-2hjr-fg6c-v2h6",
      "cwe_id": "{'CWE-200'}",
      "score": 6.5,
      "chain": "{'https://github.com/HubSpot/jinjava/pull/435/commits/1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165', 'https://github.com/HubSpot/jinjava/pull/426/commits/5dfa5b87318744a4d020b66d5f7747acc36b213b'}",
      "dataset": "osv",
      "summary": "Unauthorized access to Class instance in Jinjava Jinjava before 2.5.4 allow access to arbitrary classes by calling Java methods on objects passed into a Jinjava context. This could allow for abuse of the application class loader, including Arbitrary File Disclosure.",
      "published_date": "2022-02-09",
      "chain_len": 2,
      "project": "https://github.com/HubSpot/jinjava",
      "commit_href": "https://github.com/HubSpot/jinjava/pull/435/commits/1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165",
      "commit_sha": "1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165",
      "patch": "MULTI",
      "chain_ord": "['5dfa5b87318744a4d020b66d5f7747acc36b213b', '1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165']",
      "before_first_fix_commit": "{'bfc6ecde3a98db02a00c87a3b905a0af907188f0'}",
      "last_fix_commit": "1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165",
      "chain_ord_pos": 2.0,
      "commit_datetime": "04/28/2020, 18:20:50",
      "message": "Add interpreter to blacklist",
      "author": "Matt Coley",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 1, 'total': 4}",
      "files": "{'src/main/java/com/hubspot/jinjava/el/ext/JinjavaBeanELResolver.java': {'additions': 3, 'deletions': 1, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/HubSpot/jinjava/raw/1b9aaa4b420c58b4a301cf4b7d26207f1c8d1165/src%2Fmain%2Fjava%2Fcom%2Fhubspot%2Fjinjava%2Fel%2Fext%2FJinjavaBeanELResolver.java', 'patch': '@@ -2,6 +2,7 @@\\n \\n import com.google.common.base.CaseFormat;\\n import com.google.common.collect.ImmutableSet;\\n+import com.hubspot.jinjava.interpret.JinjavaInterpreter;\\n import java.lang.reflect.Constructor;\\n import java.lang.reflect.Field;\\n import java.lang.reflect.Method;\\n@@ -136,7 +137,8 @@ protected boolean isRestrictedClass(Object o) {\\n       o instanceof Thread ||\\n       o instanceof Method ||\\n       o instanceof Field ||\\n-      o instanceof Constructor\\n+      o instanceof Constructor ||\\n+      o instanceof JinjavaInterpreter\\n     );\\n   }\\n }'}}",
      "message_norm": "add interpreter to blacklist",
      "language": "sv",
      "entities": "[('add', 'ACTION', ''), ('blacklist', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/main/java/com/hubspot/jinjava/el/ext/JinjavaBeanELResolver.java'])",
      "num_files": 1.0
    },
    {
      "index": 301,
      "vuln_id": "GHSA-3q6g-vf58-7m4g",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/python-restx/flask-restx/commit/bab31e085f355dd73858fd3715f7ed71849656da'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service in flask-restx Flask RESTX contains a regular expression that is vulnerable to [ReDoS](https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS) (Regular Expression Denial of Service) in `email_regex`.",
      "published_date": "2021-09-08",
      "chain_len": 1,
      "project": "https://github.com/python-restx/flask-restx",
      "commit_href": "https://github.com/python-restx/flask-restx/commit/bab31e085f355dd73858fd3715f7ed71849656da",
      "commit_sha": "bab31e085f355dd73858fd3715f7ed71849656da",
      "patch": "SINGLE",
      "chain_ord": "['bab31e085f355dd73858fd3715f7ed71849656da']",
      "before_first_fix_commit": "{'e1ab7e34a47fa8c2fd025402b9c65afbe24d5e98'}",
      "last_fix_commit": "bab31e085f355dd73858fd3715f7ed71849656da",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/01/2021, 19:53:02",
      "message": "optimize email regex (credits: @kevinbackhouse, fix: #372)",
      "author": "ziirish",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'flask_restx/inputs.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/python-restx/flask-restx/raw/bab31e085f355dd73858fd3715f7ed71849656da/flask_restx%2Finputs.py', 'patch': '@@ -48,7 +48,7 @@ def my_type(value):\\n \\n \\n email_regex = re.compile(\\n-    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@]+(?:\\\\.[^@]+)*)\" r\"$\",\\n+    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@\\\\.]+(?:\\\\.[^@\\\\.]+)*)\" r\"$\",\\n     re.IGNORECASE,\\n )'}}",
      "message_norm": "optimize email regex (credits: @kevinbackhouse, fix: #372)",
      "language": "en",
      "entities": "[('optimize', 'ACTION', ''), ('#372', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['flask_restx/inputs.py'])",
      "num_files": 1.0
    },
    {
      "index": 1121,
      "vuln_id": "GHSA-83rx-c8cr-6j8q",
      "cwe_id": "{'CWE-829'}",
      "score": 5.9,
      "chain": "{'https://github.com/naptha/tesseract.js/commit/679eba055f2a4271558e86beec3d1b70cae3fb28'}",
      "dataset": "osv",
      "summary": "Insecure Default Configuration in tesseract.js Versions of `tesseract.js` prior to 1.0.19 default to using a third-party proxy.  Requests may be proxied through `crossorigin.me` which clearly states is not suitable for production use. This may lead to instability and privacy violations.\n\n\n## Recommendation\n\nUpgrade to version 1.0.19 or later.",
      "published_date": "2019-06-05",
      "chain_len": 1,
      "project": "https://github.com/naptha/tesseract.js",
      "commit_href": "https://github.com/naptha/tesseract.js/commit/679eba055f2a4271558e86beec3d1b70cae3fb28",
      "commit_sha": "679eba055f2a4271558e86beec3d1b70cae3fb28",
      "patch": "SINGLE",
      "chain_ord": "['679eba055f2a4271558e86beec3d1b70cae3fb28']",
      "before_first_fix_commit": "{'06d32c6804acbf1f5af1c13966cb72a4ff864ecb'}",
      "last_fix_commit": "679eba055f2a4271558e86beec3d1b70cae3fb28",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/16/2019, 12:34:36",
      "message": "Add stubs for error handling",
      "author": "HoldYourWaffle",
      "comments": null,
      "stats": "{'additions': 11, 'deletions': 6, 'total': 17}",
      "files": "{'src/browser/index.js': {'additions': 11, 'deletions': 6, 'changes': 17, 'status': 'modified', 'raw_url': 'https://github.com/naptha/tesseract.js/raw/679eba055f2a4271558e86beec3d1b70cae3fb28/src%2Fbrowser%2Findex.js', 'patch': '@@ -52,25 +52,30 @@ function loadImage(image, cb){\\n             var im = new Image\\n             im.src = image;\\n             im.onload = e => loadImage(im, cb);\\n+            //im.onerror = e => ?; TODO handle error\\n             return\\n         }else{\\n             var xhr = new XMLHttpRequest();\\n             xhr.open(\\'GET\\', image, true)\\n             xhr.responseType = \"blob\";\\n-            xhr.onload = e => loadImage(xhr.response, cb);\\n-            xhr.onerror = function(e){\\n-                if(/^https?:\\\\/\\\\//.test(image) && !/^https:\\\\/\\\\/crossorigin.me/.test(image)){\\n-                    console.debug(\\'Attempting to load image with CORS proxy\\')\\n-                    loadImage(\\'https://crossorigin.me/\\' + image, cb)\\n+            \\n+            xhr.onload = e => {\\n+                if (xhr.status >= 400){\\n+                    //TODO handle error\\n+                }else{\\n+                    loadImage(xhr.response, cb);\\n                 }\\n-            }\\n+            };\\n+            //xhr.onerror = e => ?; TODO handle error\\n+            \\n             xhr.send(null)\\n             return\\n         }\\n     }else if(image instanceof File){\\n         // files\\n         var fr = new FileReader()\\n         fr.onload = e => loadImage(fr.result, cb);\\n+        //fr.onerror = e => ?; TODO handle error\\n         fr.readAsDataURL(image)\\n         return\\n     }else if(image instanceof Blob){'}}",
      "message_norm": "add stubs for error handling",
      "language": "da",
      "entities": "[('add', 'ACTION', ''), ('error handling', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/browser/index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1314,
      "vuln_id": "GHSA-94qw-r73x-j7hg",
      "cwe_id": "{'CWE-285'}",
      "score": 4.8,
      "chain": "{'https://github.com/opencast/opencast/commit/72fad0031d8a82c860e2bde0b27570c5042320ee'}",
      "dataset": "osv",
      "summary": "Users with ROLE_COURSE_ADMIN can create new users in Opencast ### Impact\n\nUsers with the role `ROLE_COURSE_ADMIN` can use the user-utils endpoint to create new users not including the role `ROLE_ADMIN`. For example:\n\n```bash\n# Use the admin to create a new user with ROLE_COURSE_ADMIN using the admin user.\n# We expect this to work.\n% curl -i -u admin:opencast 'https://example.opencast.org/user-utils/xy.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP/2 201\n\n# Use the new user to create more new users.\n# We don't exp\u00fcect a user with just role ROLE_COURSE_ADMIN to succeed.\n# But it does work\n% curl -i -u xy:f 'https://example.opencast.org/user-utils/ab.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP/2 201\n```\n`ROLE_COURSE_ADMIN` is a non-standard role in Opencast which is referenced neither in the documentation nor in any code (except for tests) but only in the security configuration. From the name \u2013 implying an admin for a specific course \u2013 users would never expect that this role allows user creation.\n\n### Patches\n\nThis issue is fixed in 7.6 and 8.1 which both ship a new default security configuration.\n\n### Workarounds\n\nYou can fix this issue by removing all instances of `ROLE_COURSE_ADMIN` in your organization's security configuration (`etc/security/mh_default_org.xml` by default).\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n- Open an issue in [opencast/opencast](https://github.com/opencast/opencast/issues)\n- For security-relevant information, email us at security@opencast.org",
      "published_date": "2020-01-30",
      "chain_len": 1,
      "project": "https://github.com/opencast/opencast",
      "commit_href": "https://github.com/opencast/opencast/commit/72fad0031d8a82c860e2bde0b27570c5042320ee",
      "commit_sha": "72fad0031d8a82c860e2bde0b27570c5042320ee",
      "patch": "SINGLE",
      "chain_ord": "['72fad0031d8a82c860e2bde0b27570c5042320ee']",
      "before_first_fix_commit": "{'b157e1fb3b35991ca7bf59f0730329fbe7ce82e8'}",
      "last_fix_commit": "72fad0031d8a82c860e2bde0b27570c5042320ee",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/16/2020, 15:40:23",
      "message": "Remove ROLE_COURSE_ADMIN\n\nUsers with the role `ROLE_COURSE_ADMIN` can use the user-utils endpoint\nto create new users not including the role ROLE_ADMIN. For example:\n\n```sh\n% curl -i -u admin:opencast 'https://example.opencast.org/user-utils/xy.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP/2 201\n\n% curl -i -u xy:f 'https://example.opencast.org/user-utils/ab.json' -X PUT \\\n  --data 'password=f&roles=%5B%22ROLE_COURSE_ADMIN%22%5D'\nHTTP/2 201\n```\n\n`ROLE_COURSE_ADMIN` is a non-standard role in Opencast which is\nreferenced neither in the documentation nor in any code (except for\ntests) but only in the security configuration. From the name \u2013 implying\nan admin for a specific course \u2013 users would never expect that this role\nallows user creation.\n\nThis patch fixes the problem by dropping the default access rules for\n`ROLE_COURSE_ADMIN`. Users which use and need this custom role can\neasily configure this specific to their needs. There is no reason to\nship this by default.",
      "author": "Lars Kiesow",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 5, 'total': 10}",
      "files": "{'etc/security/mh_default_org.xml': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/opencast/opencast/raw/72fad0031d8a82c860e2bde0b27570c5042320ee/etc%2Fsecurity%2Fmh_default_org.xml', 'patch': '@@ -297,11 +297,11 @@\\n     <sec:intercept-url pattern=\"/transcripts/watson/results*\" method=\"POST\" access=\"ROLE_ANONYMOUS\" />\\n \\n     <!-- Everything else is for the admin users -->\\n-    <sec:intercept-url pattern=\"/admin-ng\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" />\\n-    <sec:intercept-url pattern=\"/admin-ng/\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" />\\n-    <sec:intercept-url pattern=\"/admin-ng/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" />\\n-    <sec:intercept-url pattern=\"/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI, ROLE_COURSE_ADMIN\" />\\n-    <sec:intercept-url pattern=\"/**\" access=\"ROLE_ADMIN, ROLE_COURSE_ADMIN\" />\\n+    <sec:intercept-url pattern=\"/admin-ng\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" />\\n+    <sec:intercept-url pattern=\"/admin-ng/\" method=\"GET\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" />\\n+    <sec:intercept-url pattern=\"/admin-ng/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" />\\n+    <sec:intercept-url pattern=\"/index.html\" access=\"ROLE_ADMIN, ROLE_ADMIN_UI\" />\\n+    <sec:intercept-url pattern=\"/**\" access=\"ROLE_ADMIN\" />\\n \\n     <!-- ############################# -->\\n     <!-- # LOGIN / LOGOUT MECHANISMS # -->'}}",
      "message_norm": "remove role_course_admin\n\nusers with the role `role_course_admin` can use the user-utils endpoint\nto create new users not including the role role_admin. for example:\n\n```sh\n% curl -i -u admin:opencast 'https://example.opencast.org/user-utils/xy.json' -x put \\\n  --data 'password=f&roles=%5b%22role_course_admin%22%5d'\nhttp/2 201\n\n% curl -i -u xy:f 'https://example.opencast.org/user-utils/ab.json' -x put \\\n  --data 'password=f&roles=%5b%22role_course_admin%22%5d'\nhttp/2 201\n```\n\n`role_course_admin` is a non-standard role in opencast which is\nreferenced neither in the documentation nor in any code (except for\ntests) but only in the security configuration. from the name \u2013 implying\nan admin for a specific course \u2013 users would never expect that this role\nallows user creation.\n\nthis patch fixes the problem by dropping the default access rules for\n`role_course_admin`. users which use and need this custom role can\neasily configure this specific to their needs. there is no reason to\nship this by default.",
      "language": "en",
      "entities": "[('remove', 'ACTION', ''), ('role_course_admin', 'SECWORD', ''), ('role_course_admin', 'SECWORD', ''), ('role_admin', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('https://example.opencast.org/user-utils/xy.json', 'URL', ''), ('password', 'SECWORD', ''), ('f&roles=%5b%22role_course_admin%22%5d', 'SECWORD', ''), ('https://example.opencast.org/user-utils/ab.json', 'URL', ''), ('password', 'SECWORD', ''), ('f&roles=%5b%22role_course_admin%22%5d', 'SECWORD', ''), ('role_course_admin', 'SECWORD', ''), ('security', 'SECWORD', ''), ('admin', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('problem', 'FLAW', ''), ('role_course_admin', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['etc/security/mh_default_org.xml'])",
      "num_files": 1.0
    },
    {
      "index": 3419,
      "vuln_id": "GHSA-xfhp-gmh8-r8v2",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/adaltas/node-printf/commit/a8502e7c9b0b22555696a2d8ef67722086413a68'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service (ReDoS) The package printf before 0.6.1 are vulnerable to Regular Expression Denial of Service (ReDoS) via the regex string /\\%(?:\\(([\\w_.]+)\\)|([1-9]\\d*)\\$)?([0 +\\-\\]*)(\\*|\\d+)?(\\.)?(\\*|\\d+)?[hlL]?([\\%bscdeEfFgGioOuxX])/g in lib/printf.js. The vulnerable regular expression has cubic worst-case time complexity.",
      "published_date": "2021-03-19",
      "chain_len": 1,
      "project": "https://github.com/adaltas/node-printf",
      "commit_href": "https://github.com/adaltas/node-printf/commit/a8502e7c9b0b22555696a2d8ef67722086413a68",
      "commit_sha": "a8502e7c9b0b22555696a2d8ef67722086413a68",
      "patch": "SINGLE",
      "chain_ord": "['a8502e7c9b0b22555696a2d8ef67722086413a68']",
      "before_first_fix_commit": "{'1456b115685791329c6fa6ca4237b7965f10cf82'}",
      "last_fix_commit": "a8502e7c9b0b22555696a2d8ef67722086413a68",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/10/2021, 13:28:56",
      "message": "Fix ReDoS",
      "author": "Yeting Li",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'lib/printf.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/adaltas/node-printf/raw/a8502e7c9b0b22555696a2d8ef67722086413a68/lib%2Fprintf.js', 'patch': '@@ -41,7 +41,7 @@ var Formatter = function(/*String*/ format){\\n   this._tokens = tokenize(format, this._re, this._parseDelim, this);\\n };\\n \\n-Formatter.prototype._re = /\\\\%(?:\\\\(([\\\\w_.]+)\\\\)|([1-9]\\\\d*)\\\\$)?([0 +\\\\-\\\\#]*)([\\\\*1-9]0*)*(?:(\\\\.)(\\\\*|\\\\d+)?)?[hlL]?([\\\\%bscdeEfFgGioOuxX])/g;\\n+Formatter.prototype._re = /\\\\%(?:\\\\(([\\\\w_.]+)\\\\)|([1-9]\\\\d*)\\\\$)?([0 +\\\\-\\\\#]*)(\\\\*|\\\\d+)?(?:(\\\\.)(\\\\*|\\\\d+)?)?[hlL]?([\\\\%bscdeEfFgGioOuxX])/g;\\n Formatter.prototype._parseDelim = function(mapping, intmapping, flags, minWidth, period, precision, specifier){\\n   if(mapping){\\n     this._mapped = true;'}}",
      "message_norm": "fix redos",
      "language": "pt",
      "entities": "[('fix', 'ACTION', ''), ('redos', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/printf.js'])",
      "num_files": 1.0
    },
    {
      "index": 2462,
      "vuln_id": "GHSA-mrq4-7ch7-2465",
      "cwe_id": "{'CWE-94'}",
      "score": 9.0,
      "chain": "{'https://github.com/PrestaShop/PrestaShop/commit/d02b469ec365822e6a9f017e57f588966248bf21'}",
      "dataset": "osv",
      "summary": "Server Side Twig Template Injection PrestaShop is an Open Source e-commerce platform. Starting with version 1.7.0.0 and ending with version 1.7.8.3, an attacker is able to inject twig code inside the back office when using the legacy layout. The problem is fixed in version 1.7.8.3. There are no known workarounds.",
      "published_date": "2022-01-27",
      "chain_len": 1,
      "project": "https://github.com/PrestaShop/PrestaShop",
      "commit_href": "https://github.com/PrestaShop/PrestaShop/commit/d02b469ec365822e6a9f017e57f588966248bf21",
      "commit_sha": "d02b469ec365822e6a9f017e57f588966248bf21",
      "patch": "SINGLE",
      "chain_ord": "['d02b469ec365822e6a9f017e57f588966248bf21']",
      "before_first_fix_commit": "{'ed8eb7ce8242e91d7acf85d7157277aad6bcac21', 'd2807b0560d5ca2835c6a4774e183c182d903f1a'}",
      "last_fix_commit": "d02b469ec365822e6a9f017e57f588966248bf21",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/26/2022, 09:20:05",
      "message": "Merge pull request from GHSA-mrq4-7ch7-2465\n\nProperly escape smarty output for twig",
      "author": "GoT",
      "comments": null,
      "stats": "{'additions': 18, 'deletions': 19, 'total': 37}",
      "files": "{'src/PrestaShopBundle/Twig/LayoutExtension.php': {'additions': 18, 'deletions': 19, 'changes': 37, 'status': 'modified', 'raw_url': 'https://github.com/PrestaShop/PrestaShop/raw/d02b469ec365822e6a9f017e57f588966248bf21/src%2FPrestaShopBundle%2FTwig%2FLayoutExtension.php', 'patch': \"@@ -218,26 +218,25 @@ public function getLegacyLayout(\\n             throw new Exception('PrestaShopBundle\\\\Twig\\\\LayoutExtension cannot find the {$content} string in legacy layout template', 1);\\n         }\\n \\n-        $content = str_replace(\\n-            [\\n-                '{$content}',\\n-                'var currentIndex = \\\\'index.php\\\\';',\\n-                '</head>',\\n-                '</body>',\\n-            ],\\n-            [\\n-                '{% block content_header %}{% endblock %}\\n-                 {% block content %}{% endblock %}\\n-                 {% block content_footer %}{% endblock %}\\n-                 {% block sidebar_right %}{% endblock %}',\\n-                'var currentIndex = \\\\'' . $this->context->getAdminLink($controllerName) . '\\\\';',\\n-                '{% block stylesheets %}{% endblock %}{% block extra_stylesheets %}{% endblock %}</head>',\\n-                '{% block javascripts %}{% endblock %}{% block extra_javascripts %}{% endblock %}{% block translate_javascripts %}{% endblock %}</body>',\\n-            ],\\n-            $layout\\n-        );\\n+        $explodedLayout = explode('{$content}', $layout);\\n+        $header = explode('</head>', $explodedLayout[0]);\\n+        $footer = explode('</body>', $explodedLayout[1]);\\n+\\n+        return $this->escapeSmarty(str_replace('var currentIndex = \\\\'index.php\\\\';', 'var currentIndex = \\\\'' . $this->context->getAdminLink($controllerName) . '\\\\';', $header[0]))\\n+            . '{% block stylesheets %}{% endblock %}{% block extra_stylesheets %}{% endblock %}</head>'\\n+            . $this->escapeSmarty($header[1])\\n+            . '{% block content_header %}{% endblock %}'\\n+            . '{% block content %}{% endblock %}'\\n+            . '{% block content_footer %}{% endblock %}'\\n+            . '{% block sidebar_right %}{% endblock %}'\\n+            . $this->escapeSmarty($footer[0])\\n+            . '{% block javascripts %}{% endblock %}{% block extra_javascripts %}{% endblock %}{% block translate_javascripts %}{% endblock %}</body>'\\n+            . $this->escapeSmarty($footer[1]);\\n+    }\\n \\n-        return $content;\\n+    private function escapeSmarty(string $template): string\\n+    {\\n+        return '{{ \\\\'' . addslashes($template) . '\\\\' | raw }}';\\n     }\\n \\n     /**\"}}",
      "message_norm": "merge pull request from ghsa-mrq4-7ch7-2465\n\nproperly escape smarty output for twig",
      "language": "en",
      "entities": "[('ghsa-mrq4-7ch7-2465', 'VULNID', 'GHSA'), ('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/PrestaShopBundle/Twig/LayoutExtension.php'])",
      "num_files": 1.0
    },
    {
      "index": 1607,
      "vuln_id": "GHSA-cv3f-px9r-54hm",
      "cwe_id": "{'CWE-200'}",
      "score": 4.7,
      "chain": "{'https://github.com/phusion/passenger/commit/4043718264095cde6623c2cbe8c644541036d7bf'}",
      "dataset": "osv",
      "summary": "Phusion Passenger information disclosure In agent/Core/SpawningKit/Spawner.h in Phusion Passenger 5.1.10 (fixed in Passenger Open Source 5.1.11 and Passenger Enterprise 5.1.10), if Passenger is running as root, it is possible to list the contents of arbitrary files on a system by symlinking a file named REVISION from the application root folder to a file of choice and querying passenger-status --show=xml.",
      "published_date": "2022-05-13",
      "chain_len": 1,
      "project": "https://github.com/phusion/passenger",
      "commit_href": "https://github.com/phusion/passenger/commit/4043718264095cde6623c2cbe8c644541036d7bf",
      "commit_sha": "4043718264095cde6623c2cbe8c644541036d7bf",
      "patch": "SINGLE",
      "chain_ord": "['4043718264095cde6623c2cbe8c644541036d7bf']",
      "before_first_fix_commit": "{'a63f1e9cd8148dfaac08b00d74ef2b59bc2c9dd4'}",
      "last_fix_commit": "4043718264095cde6623c2cbe8c644541036d7bf",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/11/2017, 13:55:07",
      "message": "Disable unused feature.",
      "author": "Daniel Knoppel (Phusion)",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 1, 'total': 3}",
      "files": "{'src/agent/Core/SpawningKit/Spawner.h': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/phusion/passenger/raw/4043718264095cde6623c2cbe8c644541036d7bf/src%2Fagent%2FCore%2FSpawningKit%2FSpawner.h', 'patch': '@@ -721,7 +721,6 @@ class Spawner {\\n \\t\\tprepareChroot(info, options);\\n \\t\\tinfo.userSwitching = prepareUserSwitching(options);\\n \\t\\tprepareSwitchingWorkingDirectory(info, options);\\n-\\t\\tinferApplicationInfo(info);\\n \\t\\treturn info;\\n \\t}\\n \\n@@ -775,6 +774,7 @@ class Spawner {\\n \\t\\tassert(info.appRootPathsInsideChroot.back() == info.appRootInsideChroot);\\n \\t}\\n \\n+#ifdef false\\n \\tvoid inferApplicationInfo(SpawnPreparationInfo &info) const {\\n \\t\\tinfo.codeRevision = readFromRevisionFile(info);\\n \\t\\tif (info.codeRevision.empty()) {\\n@@ -817,6 +817,7 @@ class Spawner {\\n \\t\\t\\treturn string();\\n \\t\\t}\\n \\t}\\n+#endif\\n \\n \\tbool shouldLoadShellEnvvars(const Options &options, const SpawnPreparationInfo &preparation) const {\\n \\t\\tif (options.loadShellEnvvars) {'}}",
      "message_norm": "disable unused feature.",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/agent/Core/SpawningKit/Spawner.h'])",
      "num_files": 1.0
    },
    {
      "index": 1931,
      "vuln_id": "GHSA-grvw-q343-58wh",
      "cwe_id": "{'CWE-787'}",
      "score": 7.5,
      "chain": "{'https://github.com/chakra-core/ChakraCore/commit/7e9a2ee60baa95ceb4f48f522f823c812ca90c80', 'https://github.com/chakra-core/ChakraCore/commit/95b3e3400afb8fa20743657f3a8057fb451e6f69'}",
      "dataset": "osv",
      "summary": "Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-1138, CVE-2019-1217, CVE-2019-1237, CVE-2019-1298.",
      "published_date": "2021-03-29",
      "chain_len": 2,
      "project": "https://github.com/chakra-core/ChakraCore",
      "commit_href": "https://github.com/chakra-core/ChakraCore/commit/95b3e3400afb8fa20743657f3a8057fb451e6f69",
      "commit_sha": "95b3e3400afb8fa20743657f3a8057fb451e6f69",
      "patch": "MULTI",
      "chain_ord": "['95b3e3400afb8fa20743657f3a8057fb451e6f69', '7e9a2ee60baa95ceb4f48f522f823c812ca90c80']",
      "before_first_fix_commit": "{'edf5eeef49168bbcc30dac82f57048ad46988295', 'c5297b86536fbf1a02d27cec28fea3c516e6ab84'}",
      "last_fix_commit": "7e9a2ee60baa95ceb4f48f522f823c812ca90c80",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/08/2019, 15:54:11",
      "message": "[CVE-2019-1300]",
      "author": "Paul Leathers",
      "comments": null,
      "stats": "{'additions': 43, 'deletions': 31, 'total': 74}",
      "files": "{'lib/Backend/GlobOpt.cpp': {'additions': 43, 'deletions': 31, 'changes': 74, 'status': 'modified', 'raw_url': 'https://github.com/chakra-core/ChakraCore/raw/95b3e3400afb8fa20743657f3a8057fb451e6f69/lib%2FBackend%2FGlobOpt.cpp', 'patch': \"@@ -1167,6 +1167,10 @@ void GlobOpt::InsertValueCompensation(\\n     IR::Instr *insertBeforeInstr = predecessor->GetLastInstr();\\n     Func *const func = insertBeforeInstr->m_func;\\n     bool setLastInstrInPredecessor;\\n+    // If this is a loop back edge, and the successor has been completed, don't attempt to update its block data.\\n+    // The update is unnecessary, and the data has likely been freed.\\n+    bool updateSuccessorBlockData = !this->isPerformingLoopBackEdgeCompensation || successor->GetDataUseCount() > 0;\\n+\\n     if(insertBeforeInstr->IsBranchInstr() || insertBeforeInstr->m_opcode == Js::OpCode::BailTarget)\\n     {\\n         // Don't insert code between the branch and the corresponding ByteCodeUses instructions\\n@@ -1257,29 +1261,33 @@ void GlobOpt::InsertValueCompensation(\\n             // Merge the head segment length value\\n             Assert(predecessorBlockData.liveVarSyms->Test(predecessorHeadSegmentLengthSym->m_id));\\n             predecessorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\\n-            successorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\\n             Value *const predecessorHeadSegmentLengthValue =\\n                 predecessorBlockData.FindValue(predecessorHeadSegmentLengthSym);\\n             Assert(predecessorHeadSegmentLengthValue);\\n             predecessorBlockData.SetValue(predecessorHeadSegmentLengthValue, mergedHeadSegmentLengthSym);\\n-            Value *const mergedHeadSegmentLengthValue = successorBlockData.FindValue(mergedHeadSegmentLengthSym);\\n-            if(mergedHeadSegmentLengthValue)\\n+\\n+            if (updateSuccessorBlockData)\\n             {\\n-                Assert(mergedHeadSegmentLengthValue->GetValueNumber() != predecessorHeadSegmentLengthValue->GetValueNumber());\\n-                if(predecessorHeadSegmentLengthValue->GetValueInfo() != mergedHeadSegmentLengthValue->GetValueInfo())\\n+                successorBlockData.liveVarSyms->Set(mergedHeadSegmentLengthSym->m_id);\\n+                Value *const mergedHeadSegmentLengthValue = successorBlockData.FindValue(mergedHeadSegmentLengthSym);\\n+                if(mergedHeadSegmentLengthValue)\\n                 {\\n-                    mergedHeadSegmentLengthValue->SetValueInfo(\\n-                        ValueInfo::MergeLikelyIntValueInfo(\\n-                            this->alloc,\\n-                            mergedHeadSegmentLengthValue,\\n-                            predecessorHeadSegmentLengthValue,\\n-                            mergedHeadSegmentLengthValue->GetValueInfo()->Type()\\n-                                .Merge(predecessorHeadSegmentLengthValue->GetValueInfo()->Type())));\\n+                    Assert(mergedHeadSegmentLengthValue->GetValueNumber() != predecessorHeadSegmentLengthValue->GetValueNumber());\\n+                    if(predecessorHeadSegmentLengthValue->GetValueInfo() != mergedHeadSegmentLengthValue->GetValueInfo())\\n+                    {\\n+                        mergedHeadSegmentLengthValue->SetValueInfo(\\n+                            ValueInfo::MergeLikelyIntValueInfo(\\n+                                this->alloc,\\n+                                mergedHeadSegmentLengthValue,\\n+                                predecessorHeadSegmentLengthValue,\\n+                                mergedHeadSegmentLengthValue->GetValueInfo()->Type()\\n+                                    .Merge(predecessorHeadSegmentLengthValue->GetValueInfo()->Type())));\\n+                    }\\n+                }\\n+                else\\n+                {\\n+                    successorBlockData.SetValue(CopyValue(predecessorHeadSegmentLengthValue), mergedHeadSegmentLengthSym);\\n                 }\\n-            }\\n-            else\\n-            {\\n-                successorBlockData.SetValue(CopyValue(predecessorHeadSegmentLengthValue), mergedHeadSegmentLengthSym);\\n             }\\n         }\\n \\n@@ -1300,27 +1308,31 @@ void GlobOpt::InsertValueCompensation(\\n             // Merge the length value\\n             Assert(predecessorBlockData.liveVarSyms->Test(predecessorLengthSym->m_id));\\n             predecessorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\\n-            successorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\\n             Value *const predecessorLengthValue = predecessorBlockData.FindValue(predecessorLengthSym);\\n             Assert(predecessorLengthValue);\\n             predecessorBlockData.SetValue(predecessorLengthValue, mergedLengthSym);\\n-            Value *const mergedLengthValue = successorBlockData.FindValue(mergedLengthSym);\\n-            if(mergedLengthValue)\\n+\\n+            if (updateSuccessorBlockData)\\n             {\\n-                Assert(mergedLengthValue->GetValueNumber() != predecessorLengthValue->GetValueNumber());\\n-                if(predecessorLengthValue->GetValueInfo() != mergedLengthValue->GetValueInfo())\\n+                successorBlockData.liveVarSyms->Set(mergedLengthSym->m_id);\\n+                Value *const mergedLengthValue = successorBlockData.FindValue(mergedLengthSym);\\n+                if(mergedLengthValue)\\n                 {\\n-                    mergedLengthValue->SetValueInfo(\\n-                        ValueInfo::MergeLikelyIntValueInfo(\\n-                            this->alloc,\\n-                            mergedLengthValue,\\n-                            predecessorLengthValue,\\n-                            mergedLengthValue->GetValueInfo()->Type().Merge(predecessorLengthValue->GetValueInfo()->Type())));\\n+                    Assert(mergedLengthValue->GetValueNumber() != predecessorLengthValue->GetValueNumber());\\n+                    if(predecessorLengthValue->GetValueInfo() != mergedLengthValue->GetValueInfo())\\n+                    {\\n+                        mergedLengthValue->SetValueInfo(\\n+                            ValueInfo::MergeLikelyIntValueInfo(\\n+                                this->alloc,\\n+                                mergedLengthValue,\\n+                                predecessorLengthValue,\\n+                                mergedLengthValue->GetValueInfo()->Type().Merge(predecessorLengthValue->GetValueInfo()->Type())));\\n+                    }\\n+                }\\n+                else\\n+                {\\n+                    successorBlockData.SetValue(CopyValue(predecessorLengthValue), mergedLengthSym);\\n                 }\\n-            }\\n-            else\\n-            {\\n-                successorBlockData.SetValue(CopyValue(predecessorLengthValue), mergedLengthSym);\\n             }\\n         }\"}}",
      "message_norm": "[cve-2019-1300]",
      "language": "ro",
      "entities": "[('cve-2019-1300', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/Backend/GlobOpt.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 326,
      "vuln_id": "GHSA-3x96-m42v-hvh5",
      "cwe_id": "{'CWE-79'}",
      "score": 6.1,
      "chain": "{'https://github.com/microweber/microweber/commit/c51285f791e48e536111cd57a9544ccbf7f33961'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in Microweber Cross-site Scripting (XSS) - Reflected in GitHub repository microweber/microweber prior to 1.2.18.",
      "published_date": "2022-06-23",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/c51285f791e48e536111cd57a9544ccbf7f33961",
      "commit_sha": "c51285f791e48e536111cd57a9544ccbf7f33961",
      "patch": "SINGLE",
      "chain_ord": "['c51285f791e48e536111cd57a9544ccbf7f33961']",
      "before_first_fix_commit": "{'10550ec85018bb0f581edd0ac2aed0d7bc9fe6b1'}",
      "last_fix_commit": "c51285f791e48e536111cd57a9544ccbf7f33961",
      "chain_ord_pos": 1.0,
      "commit_datetime": "06/22/2022, 11:56:16",
      "message": "update",
      "author": "Peter Ivanov",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 3, 'total': 12}",
      "files": "{'userfiles/modules/microweber/toolbar/editor_tools/module_settings/index.php': {'additions': 9, 'deletions': 3, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/c51285f791e48e536111cd57a9544ccbf7f33961/userfiles%2Fmodules%2Fmicroweber%2Ftoolbar%2Feditor_tools%2Fmodule_settings%2Findex.php', 'patch': '@@ -87,11 +87,13 @@\\n     if (isset($_GET[\\'autosize\\'])) {\\n         $autoSize = $_GET[\\'autosize\\'];\\n     }\\n+    $autoSize = xss_clean($autoSize);\\n \\n     $type = \\'\\';\\n     if (isset($_GET[\\'type\\'])) {\\n         $type = $_GET[\\'type\\'];\\n     }\\n+    $type = xss_clean($type);\\n \\n     $mod_id = $mod_orig_id = false;\\n     $is_linked_mod = false;\\n@@ -403,7 +405,9 @@\\n                 if (mw.notification) {\\n                     mw.notification.success(\\'<?php _ejs(\\'Settings are saved\\') ?>\\');\\n                 }\\n+                <?php if (isset($params[\\'id\\'])) : ?>\\n                 mw.reload_module_parent(\\'#<?php print $params[\\'id\\']  ?>\\')\\n+                <?php endif; ?>\\n \\n             });\\n \\n@@ -440,9 +444,11 @@\\n <body class=\"mw-external-loading loading\">\\n <div id=\"settings-main\">\\n     <div id=\"settings-container\">\\n-        <div class=\"mw-module-live-edit-settings <?php print $params[\\'id\\'] ?>\"\\n-             id=\"module-id-<?php print $params[\\'id\\'] ?>\">{content}\\n-        </div>\\n+        <?php if (isset($params[\\'id\\'])) : ?>\\n+            <div class=\"mw-module-live-edit-settings <?php print $params[\\'id\\'] ?>\"\\n+                 id=\"module-id-<?php print $params[\\'id\\'] ?>\">{content}\\n+            </div>\\n+        <?php endif; ?>\\n     </div>\\n </div>'}}",
      "message_norm": "update",
      "language": "ro",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['userfiles/modules/microweber/toolbar/editor_tools/module_settings/index.php'])",
      "num_files": 1.0
    },
    {
      "index": 206,
      "vuln_id": "GHSA-36vm-xw34-x4pj",
      "cwe_id": "{'CWE-617'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/1c56f53be0b722ca657cbc7df461ed676c8642a2'}",
      "dataset": "osv",
      "summary": "CHECK-fail in `tf.raw_ops.IRFFT` ### Impact\nAn attacker can cause a denial of service by exploiting a `CHECK`-failure coming from the implementation of `tf.raw_ops.IRFFT`:\n    \n```python\nimport tensorflow as tf\n\nvalues = [-10.0] * 130\nvalues[0] = -9.999999999999995\ninputs = tf.constant(values, shape=[10, 13], dtype=tf.float32)\ninputs = tf.cast(inputs, dtype=tf.complex64)\nfft_length = tf.constant([0], shape=[1], dtype=tf.int32)\n\ntf.raw_ops.IRFFT(input=inputs, fft_length=fft_length)\n``` \n    \nThe above example causes Eigen code to operate on an empty matrix. This triggers on an assertion and causes program termination.\n\n### Patches\nWe have patched the issue in GitHub commit [1c56f53be0b722ca657cbc7df461ed676c8642a2](https://github.com/tensorflow/tensorflow/commit/1c56f53be0b722ca657cbc7df461ed676c8642a2).\n  \nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/1c56f53be0b722ca657cbc7df461ed676c8642a2",
      "commit_sha": "1c56f53be0b722ca657cbc7df461ed676c8642a2",
      "patch": "SINGLE",
      "chain_ord": "['1c56f53be0b722ca657cbc7df461ed676c8642a2']",
      "before_first_fix_commit": "{'8926cbdbbff8b9975d63a41569d51c50a9806d9d'}",
      "last_fix_commit": "1c56f53be0b722ca657cbc7df461ed676c8642a2",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/05/2021, 00:11:46",
      "message": "Fix a check fail in Fast Fourier implementation\n\nPiperOrigin-RevId: 372026629\nChange-Id: Id05c3362aa575271bc3e06b16316c9037085fc11",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'tensorflow/core/kernels/fft_ops.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/1c56f53be0b722ca657cbc7df461ed676c8642a2/tensorflow%2Fcore%2Fkernels%2Ffft_ops.cc', 'patch': '@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\\n limitations under the License.\\n ==============================================================================*/\\n \\n+#include \"tensorflow/core/platform/errors.h\"\\n #define EIGEN_USE_THREADS\\n \\n // See docs in ../ops/fft_ops.cc.\\n@@ -261,6 +262,9 @@ class FFTCPU : public FFTBase {\\n           i == FFTRank ? fft_shape[i - 1] / 2 + 1 : fft_shape[i - 1];\\n       full_fft_shape.AddDim(fft_shape[i - 1]);\\n     }\\n+    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,\\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\\n+                                        full_fft_shape.DebugString()));\\n \\n     Tensor temp;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),'}}",
      "message_norm": "fix a check fail in fast fourier implementation\n\npiperorigin-revid: 372026629\nchange-id: id05c3362aa575271bc3e06b16316c9037085fc11",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('372026629', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/fft_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 72,
      "vuln_id": "GHSA-29mw-wpgm-hmr9",
      "cwe_id": "{'CWE-400'}",
      "score": 5.3,
      "chain": "{'https://github.com/lodash/lodash/pull/5065/commits/02906b8191d3c100c193fe6f7b27d1c40f200bb7'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service (ReDoS) in lodash All versions of package lodash prior to 4.17.21 are vulnerable to Regular Expression Denial of Service (ReDoS) via the toNumber, trim and trimEnd functions. Steps to reproduce (provided by reporter Liyuan Chen): var lo = require('lodash'); function build_blank (n) { var ret = \"1\" for (var i = 0; i < n; i++) { ret += \" \" } return ret + \"1\"; } var s = build_blank(50000) var time0 = Date.now(); lo.trim(s) var time_cost0 = Date.now() - time0; console.log(\"time_cost0: \" + time_cost0) var time1 = Date.now(); lo.toNumber(s) var time_cost1 = Date.now() - time1; console.log(\"time_cost1: \" + time_cost1) var time2 = Date.now(); lo.trimEnd(s) var time_cost2 = Date.now() - time2; console.log(\"time_cost2: \" + time_cost2)",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/lodash/lodash",
      "commit_href": "https://github.com/lodash/lodash/pull/5065/commits/02906b8191d3c100c193fe6f7b27d1c40f200bb7",
      "commit_sha": "02906b8191d3c100c193fe6f7b27d1c40f200bb7",
      "patch": "SINGLE",
      "chain_ord": "['02906b8191d3c100c193fe6f7b27d1c40f200bb7']",
      "before_first_fix_commit": "{'ded9bc66583ed0b4e3b7dc906206d40757b4a90a'}",
      "last_fix_commit": "02906b8191d3c100c193fe6f7b27d1c40f200bb7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/26/2021, 22:17:05",
      "message": "perf: improve performance of `toNumber`, `trim` and `trimEnd` on large input strings",
      "author": "Micha\u0142 Lipi\u0144ski",
      "comments": null,
      "stats": "{'additions': 36, 'deletions': 7, 'total': 43}",
      "files": "{'lodash.js': {'additions': 36, 'deletions': 7, 'changes': 43, 'status': 'modified', 'raw_url': 'https://github.com/lodash/lodash/raw/02906b8191d3c100c193fe6f7b27d1c40f200bb7/lodash.js', 'patch': \"@@ -152,10 +152,11 @@\\n   var reRegExpChar = /[\\\\\\\\^$.*+?()[\\\\]{}|]/g,\\n       reHasRegExpChar = RegExp(reRegExpChar.source);\\n \\n-  /** Used to match leading and trailing whitespace. */\\n-  var reTrim = /^\\\\s+|\\\\s+$/g,\\n-      reTrimStart = /^\\\\s+/,\\n-      reTrimEnd = /\\\\s+$/;\\n+  /** Used to match leading whitespace. */\\n+  var reTrimStart = /^\\\\s+/;\\n+\\n+  /** Used to match a single whitespace character. */\\n+  var reWhitespace = /\\\\s/;\\n \\n   /** Used to match wrap detail comments. */\\n   var reWrapComment = /\\\\{(?:\\\\n\\\\/\\\\* \\\\[wrapped with .+\\\\] \\\\*\\\\/)?\\\\n?/,\\n@@ -993,6 +994,19 @@\\n     });\\n   }\\n \\n+  /**\\n+   * The base implementation of `_.trim`.\\n+   *\\n+   * @private\\n+   * @param {string} string The string to trim.\\n+   * @returns {string} Returns the trimmed string.\\n+   */\\n+  function baseTrim(string) {\\n+    return string\\n+      ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\\n+      : string;\\n+  }\\n+\\n   /**\\n    * The base implementation of `_.unary` without support for storing metadata.\\n    *\\n@@ -1326,6 +1340,21 @@\\n       : asciiToArray(string);\\n   }\\n \\n+  /**\\n+   * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\\n+   * character of `string`.\\n+   *\\n+   * @private\\n+   * @param {string} string The string to inspect.\\n+   * @returns {number} Returns the index of the last non-whitespace character.\\n+   */\\n+  function trimmedEndIndex(string) {\\n+    var index = string.length;\\n+\\n+    while (index-- && reWhitespace.test(string.charAt(index))) {}\\n+    return index;\\n+  }\\n+\\n   /**\\n    * Used by `_.unescape` to convert HTML entities to characters.\\n    *\\n@@ -12494,7 +12523,7 @@\\n       if (typeof value != 'string') {\\n         return value === 0 ? value : +value;\\n       }\\n-      value = value.replace(reTrim, '');\\n+      value = baseTrim(value);\\n       var isBinary = reIsBinary.test(value);\\n       return (isBinary || reIsOctal.test(value))\\n         ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\\n@@ -14979,7 +15008,7 @@\\n     function trim(string, chars, guard) {\\n       string = toString(string);\\n       if (string && (guard || chars === undefined)) {\\n-        return string.replace(reTrim, '');\\n+        return baseTrim(string);\\n       }\\n       if (!string || !(chars = baseToString(chars))) {\\n         return string;\\n@@ -15014,7 +15043,7 @@\\n     function trimEnd(string, chars, guard) {\\n       string = toString(string);\\n       if (string && (guard || chars === undefined)) {\\n-        return string.replace(reTrimEnd, '');\\n+        return string.slice(0, trimmedEndIndex(string) + 1);\\n       }\\n       if (!string || !(chars = baseToString(chars))) {\\n         return string;\"}}",
      "message_norm": "perf: improve performance of `tonumber`, `trim` and `trimend` on large input strings",
      "language": "en",
      "entities": "[('improve', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lodash.js'])",
      "num_files": 1.0
    },
    {
      "index": 769,
      "vuln_id": "GHSA-66rh-8fw6-59q6",
      "cwe_id": "{'CWE-915', 'CWE-20'}",
      "score": 7.5,
      "chain": "{'https://github.com/jonschlinkert/assign-deep/commit/8e3cc4a34246733672c71e96532105384937e56c', 'https://github.com/jonschlinkert/assign-deep/commit/90bf1c551d05940898168d04066bbf15060f50cc'}",
      "dataset": "osv",
      "summary": "assign-deep Vulnerable to Prototype Pollution Versions of `assign-deep` prior to 1.0.1 and 0.4.8 are vulnerable to Prototype Pollution. The `assign` function fails to validate which Object properties it updates. This allows attackers to modify the prototype of Object, causing the addition or modification of an existing property on all objects.\n\n## Recommendation\n\nUpgrade to versions 1.0.1, 0.4.8, or later.",
      "published_date": "2019-08-21",
      "chain_len": 2,
      "project": "https://github.com/jonschlinkert/assign-deep",
      "commit_href": "https://github.com/jonschlinkert/assign-deep/commit/8e3cc4a34246733672c71e96532105384937e56c",
      "commit_sha": "8e3cc4a34246733672c71e96532105384937e56c",
      "patch": "MULTI",
      "chain_ord": "['90bf1c551d05940898168d04066bbf15060f50cc', '8e3cc4a34246733672c71e96532105384937e56c']",
      "before_first_fix_commit": "{'24412bd2b59bc128437819c4a4518a7b7148d81a'}",
      "last_fix_commit": "8e3cc4a34246733672c71e96532105384937e56c",
      "chain_ord_pos": 2.0,
      "commit_datetime": "06/25/2019, 17:46:37",
      "message": "ensure keys are valid",
      "author": "doowb",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 1, 'total': 10}",
      "files": "{'index.js': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/jonschlinkert/assign-deep/raw/8e3cc4a34246733672c71e96532105384937e56c/index.js', 'patch': \"@@ -37,7 +37,7 @@ function extend(target, obj) {\\n   assignSymbols(target, obj);\\n \\n   for (var key in obj) {\\n-    if (key !== '__proto__' && hasOwn(obj, key)) {\\n+    if (isValidKey(key) && hasOwn(obj, key)) {\\n       var val = obj[key];\\n       if (isObject(val)) {\\n         if (typeOf(target[key]) === 'undefined' && typeOf(val) === 'function') {\\n@@ -68,6 +68,14 @@ function hasOwn(obj, key) {\\n   return Object.prototype.hasOwnProperty.call(obj, key);\\n }\\n \\n+/**\\n+ * Returns true if the given `key` is a valid key that can be used for assigning properties.\\n+ */\\n+\\n+function isValidKey(key) {\\n+  return key !== '__proto__' && key !== 'constructor' && key !== 'prototype';\\n+}\\n+\\n /**\\n  * Expose `assign`\\n  */\"}}",
      "message_norm": "ensure keys are valid",
      "language": "af",
      "entities": "[('ensure', 'ACTION', ''), ('keys', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 3274,
      "vuln_id": "GHSA-wg8p-w946-c482",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/star7th/showdoc/commit/56e450c3adf75c707500d7231a78c9fc894c7f13'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in ShowDoc ShowDoc prior to 2.10.4 is vulnerable to stored cross-site scripting via file upload.",
      "published_date": "2022-03-16",
      "chain_len": 1,
      "project": "https://github.com/star7th/showdoc",
      "commit_href": "https://github.com/star7th/showdoc/commit/56e450c3adf75c707500d7231a78c9fc894c7f13",
      "commit_sha": "56e450c3adf75c707500d7231a78c9fc894c7f13",
      "patch": "SINGLE",
      "chain_ord": "['56e450c3adf75c707500d7231a78c9fc894c7f13']",
      "before_first_fix_commit": "{'237ac6d43bf3728bf3587c486a23b4a48ea7acb3'}",
      "last_fix_commit": "56e450c3adf75c707500d7231a78c9fc894c7f13",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2022, 12:15:13",
      "message": "file upload bug",
      "author": "star7th",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'server/Application/Api/Model/AttachmentModel.class.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/star7th/showdoc/raw/56e450c3adf75c707500d7231a78c9fc894c7f13/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -329,7 +329,7 @@ public function isAllowedFilename($filename){\\n \\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso','.bz2','.epub',\\n \\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n \\t\\t\\t'.doc','.docx','.odt','.rtf','.docm','.dotm','.dot','.dotx','.wps','.wpt',\\n-\\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.md','.psd','.csv',\\n+\\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\\n \\t\\t\\t'.cer','.ppt','.pub','.properties','.json','.css',\\n \\t\\t\\t) ;\"}}",
      "message_norm": "file upload bug",
      "language": "ro",
      "entities": "[('bug', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/Application/Api/Model/AttachmentModel.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 1988,
      "vuln_id": "GHSA-h4mx-xv96-2jgm",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/TYPO3/typo3/commit/da611775f92102d7602713003f4c79606c8a445d'}",
      "dataset": "osv",
      "summary": "Cross-Site Scripting in TYPO3's Frontend Login Mailer > ### Meta\n> * CVSS: `CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:N/E:F/RL:O/RC:C` (4.9)\n\n### Problem\nUser submitted content was used without being properly encoded in HTML emails sent to users. The actually affected components were mail clients used to view those messages.\n\n### Solution\nUpdate to TYPO3 versions 9.5.35 ELTS, 10.4.29, 11.5.11 that fix the problem described above.\n\n### Credits\nThanks to Christian Seifert who reported this issue and to TYPO3 framework merger Andreas Fernandez who fixed the issue.\n\n### References\n* [TYPO3-CORE-SA-2022-004](https://typo3.org/security/advisory/typo3-core-sa-2022-004)",
      "published_date": "2022-06-17",
      "chain_len": 1,
      "project": "https://github.com/TYPO3/typo3",
      "commit_href": "https://github.com/TYPO3/typo3/commit/da611775f92102d7602713003f4c79606c8a445d",
      "commit_sha": "da611775f92102d7602713003f4c79606c8a445d",
      "patch": "SINGLE",
      "chain_ord": "['da611775f92102d7602713003f4c79606c8a445d']",
      "before_first_fix_commit": "{'6f2554dc4ea0b670fd5599c54fd788d4db96c4a0'}",
      "last_fix_commit": "da611775f92102d7602713003f4c79606c8a445d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "06/14/2022, 07:18:04",
      "message": "[SECURITY] Avoid HTML injection in password recovery mail\n\nThe `receiverName` variable used in the password recovery mail of the\nExtbase felogin plugin was susceptible to HTML injection due to\nmissing sanitization. The variable is now passed thru the\n`f:format.htmlspecialchars` ViewHelper.\n\nResolves: #96559\nReleases: main, 11.5, 10.4\nChange-Id: I60e23c161f7f2fcc87b8870345b10a4c31d7b8db\nSecurity-Bulletin: TYPO3-CORE-SA-2022-004\nSecurity-References: CVE-2022-31049\nReviewed-on: https://review.typo3.org/c/Packages/TYPO3.CMS/+/74904\nTested-by: Oliver Hader <oliver.hader@typo3.org>\nReviewed-by: Oliver Hader <oliver.hader@typo3.org>",
      "author": "Andreas Fernandez",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'typo3/sysext/felogin/Resources/Private/Email/Templates/PasswordRecovery.html': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/TYPO3/typo3/raw/da611775f92102d7602713003f4c79606c8a445d/typo3%2Fsysext%2Ffelogin%2FResources%2FPrivate%2FEmail%2FTemplates%2FPasswordRecovery.html', 'patch': '@@ -9,7 +9,7 @@\\n         {f:translate(\\n         key: \\'forgot_validate_reset_password_html\\',\\n         extensionName: \\'felogin\\',\\n-        arguments: \\'{ 0: receiverName, 1: recoveryLink, 2: validUntil }\\'\\n+        arguments: \\'{ 0: \"{receiverName -> f:format.htmlspecialchars()}\", 1: recoveryLink, 2: validUntil }\\'\\n         ) -> f:format.html()}\\n     </f:spaceless>\\n </f:section>'}}",
      "message_norm": "[security] avoid html injection in password recovery mail\n\nthe `receivername` variable used in the password recovery mail of the\nextbase felogin plugin was susceptible to html injection due to\nmissing sanitization. the variable is now passed thru the\n`f:format.htmlspecialchars` viewhelper.\n\nresolves: #96559\nreleases: main, 11.5, 10.4\nchange-id: i60e23c161f7f2fcc87b8870345b10a4c31d7b8db\nsecurity-bulletin: typo3-core-sa-2022-004\nsecurity-references: cve-2022-31049\nreviewed-on: https://review.typo3.org/c/packages/typo3.cms/+/74904\ntested-by: oliver hader <oliver.hader@typo3.org>\nreviewed-by: oliver hader <oliver.hader@typo3.org>",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('injection', 'SECWORD', ''), ('password', 'SECWORD', ''), ('password', 'SECWORD', ''), ('injection', 'SECWORD', ''), ('sanitization', 'SECWORD', ''), ('format.htmlspecialchars', 'SECWORD', ''), ('#96559', 'ISSUE', ''), ('security', 'SECWORD', ''), ('security', 'SECWORD', ''), ('cve-2022-31049', 'VULNID', 'CVE'), ('https://review.typo3.org/c/packages/typo3.cms/+/74904', 'URL', ''), ('oliver.hader@typo3.org', 'EMAIL', ''), ('oliver.hader@typo3.org', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['typo3/sysext/felogin/Resources/Private/Email/Templates/PasswordRecovery.html'])",
      "num_files": 1.0
    },
    {
      "index": 2643,
      "vuln_id": "GHSA-pv4c-p2j5-38j4",
      "cwe_id": "{'CWE-425'}",
      "score": 0.0,
      "chain": "{'https://github.com/unshiftio/url-parse/commit/d7b582ec1243e8024e60ac0b62d2569c939ef5de', 'https://github.com/unshiftio/url-parse/commit/53b1794e54d0711ceb52505e0f74145270570d5a'}",
      "dataset": "osv",
      "summary": "Open Redirect in url-parse Versions of `url-parse` before 1.4.3 returns the wrong hostname which could lead to Open Redirect, Server Side Request Forgery (SSRF), or Bypass Authentication Protocol vulnerabilities.\n\n\n## Recommendation\n\nUpdate to version 1.4.3 or later.",
      "published_date": "2018-08-13",
      "chain_len": 2,
      "project": "https://github.com/unshiftio/url-parse",
      "commit_href": "https://github.com/unshiftio/url-parse/commit/d7b582ec1243e8024e60ac0b62d2569c939ef5de",
      "commit_sha": "d7b582ec1243e8024e60ac0b62d2569c939ef5de",
      "patch": "MULTI",
      "chain_ord": "['53b1794e54d0711ceb52505e0f74145270570d5a', 'd7b582ec1243e8024e60ac0b62d2569c939ef5de']",
      "before_first_fix_commit": "{'53b1794e54d0711ceb52505e0f74145270570d5a'}",
      "last_fix_commit": "d7b582ec1243e8024e60ac0b62d2569c939ef5de",
      "chain_ord_pos": 2.0,
      "commit_datetime": "07/29/2018, 12:42:38",
      "message": "[security] Added missing SECURITY.md",
      "author": "Arnout Kazemier",
      "comments": "{'com_1': {'author': 'lpinca', 'datetime': '07/29/2018, 13:18:42', 'body': 'The open redirect vulnerability is not fixed.'}, 'com_2': {'author': '3rd-Eden', 'datetime': '07/29/2018, 18:01:14', 'body': \"Right, I just copy and pasted this from the reported issue. I can change it, and add a security section to the README and warn people to not bluntly accept user-input as valid URL's.\"}, 'com_3': {'author': 'lirantal', 'datetime': '07/30/2018, 08:19:29', 'body': \"@3rd-Eden that's really awesome that you're adding this!\\r\\nWe have a template over at the security-wg repo (https://github.com/nodejs/security-wg/blob/master/processes/responsible_disclosure_template.md) that I'd be happy to work with you on to improve with references to what you've also added here. \\r\\n\\r\\nYou may also add a security badge to raise awareness:\\r\\n[![Security Responsible Disclosure](https://img.shields.io/badge/Security-Responsible%20Disclosure-yellow.svg)](https://github.com/nodejs/security-wg/blob/master/processes/responsible_disclosure_template.md\\r\\n)\"}, 'com_4': {'author': 'SegfaultMasters', 'datetime': '09/03/2018, 06:26:18', 'body': 'Though it replaced double slash, one can still perform open-redirect using encoded format \"%5c%5c\"\\r\\nHere\\'s the testcase \\r\\n```\\r\\n\\'use strict\\';\\r\\nvar URL = require(\\'url-parse\\');\\r\\nvar url = new URL(\\'http://google.com:80%5c%5cyahoo.com//#what\\\\\\\\is going on\\');\\r\\nconsole.log(url.hostname);\\r\\n```'}, 'com_5': {'author': 'lirantal', 'datetime': '09/05/2018, 19:49:45', 'body': '@SegfaultMasters would you be able to submit a vuln repot on the HackerOne platform with the details?'}}",
      "stats": "{'additions': 47, 'deletions': 0, 'total': 47}",
      "files": "{'SECURITY.md': {'additions': 47, 'deletions': 0, 'changes': 47, 'status': 'added', 'raw_url': 'https://github.com/unshiftio/url-parse/raw/d7b582ec1243e8024e60ac0b62d2569c939ef5de/SECURITY.md', 'patch': \"@@ -0,0 +1,47 @@\\n+# Security Guidelines\\n+\\n+Please contact us directly at **security@3rd-Eden.com** for any bug that might\\n+impact the security of this project. Please prefix the subject of your email\\n+with `[security]` in lowercase and square brackets. Our email filters will\\n+automatically prevent these messages from being moved to our spam box. All\\n+emails that do not include security vulnerabilities will be removed and blocked\\n+instantly.\\n+\\n+In addition to a dedicated email address to receive security related reports,\\n+we also have a [Hacker1 account][hacker1] that can be used be used for\\n+communicating security related issues.\\n+\\n+You will receive an acknowledgement of your report within **24 hours** of\\n+notification.\\n+\\n+## Exceptions\\n+\\n+If you do not receive an acknowledgement within the said time frame please give\\n+us the benefit of the doubt as it's possible that we haven't seen it yet. In\\n+this case please send us a message **without details** using one of the\\n+following methods:\\n+\\n+- Give a poke on Twitter [@3rdEden](https://twitter.com/3rdEden)\\n+- Contact the lead developers of this project on their personal e-mails. You\\n+  can find the e-mails in the git logs, for example using the following command:\\n+  `git --no-pager show -s --format='%an <%ae>' <gitsha>` where `<gitsha>` is the\\n+  SHA1 of their latest commit in the project.\\n+\\n+Once we have acknowledged receipt of your report and confirmed the bug\\n+ourselves we will work with you to fix the vulnerability and publicly\\n+acknowledge your responsible disclosure, if you wish.\\n+\\n+## History\\n+\\n+> url-parse returns wrong hostname which leads to multiple vulnerabilities such\\n+> as SSRF, Open Redirect, Bypass Authentication Protocol.\\n+\\n+- Hacker1 report: https://hackerone.com/reports/384029\\n+- Reported by [lolwaleet](https://hackerone.com/lolwalee)\\n+- Triaged by [Liran Tal](https://hackerone.com/lirantal)\\n+- Fixed in: 1.4.3\\n+\\n+---\\n+\\n+[twitter]: https://twitter.com/3rdEden\\n+[hacker1]: https://hackerone.com/3rdeden\"}}",
      "message_norm": "[security] added missing security.md",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('added', 'ACTION', ''), ('security.md', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['SECURITY.md'])",
      "num_files": 1.0
    },
    {
      "index": 2855,
      "vuln_id": "GHSA-r4pj-74mg-8868",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/fca9874a9b42a2134f907d2fb46ab774a831404a'}",
      "dataset": "osv",
      "summary": "Division by 0 in `Conv2DBackpropFilter` ### Impact\nAn attacker can trigger a division by 0 in `tf.raw_ops.Conv2DBackpropFilter`:\n\n```python\nimport tensorflow as tf\n\ninput_tensor = tf.constant([], shape=[0, 0, 1, 0], dtype=tf.float32)\nfilter_sizes = tf.constant([1, 1, 1, 1], shape=[4], dtype=tf.int32)\nout_backprop = tf.constant([], shape=[0, 0, 1, 1], dtype=tf.float32)\n\ntf.raw_ops.Conv2DBackpropFilter(input=input_tensor, filter_sizes=filter_sizes,\n                                out_backprop=out_backprop,\n                                strides=[1, 66, 18, 1], use_cudnn_on_gpu=True,\n                                padding='SAME', explicit_paddings=[],\n                                data_format='NHWC', dilations=[1, 1, 1, 1])\n```                 \n                    \nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/496c2630e51c1a478f095b084329acedb253db6b/tensorflow/core/kernels/conv_grad_shape_utils.cc#L130) does a modulus operation where the divisor is controlled by the caller:\n\n```cc \n  if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) { ... }\n```\n    \n### Patches\nWe have patched the issue in GitHub commit [fca9874a9b42a2134f907d2fb46ab774a831404a](https://github.com/tensorflow/tensorflow/commit/fca9874a9b42a2134f907d2fb46ab774a831404a).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n  \n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/fca9874a9b42a2134f907d2fb46ab774a831404a",
      "commit_sha": "fca9874a9b42a2134f907d2fb46ab774a831404a",
      "patch": "SINGLE",
      "chain_ord": "['fca9874a9b42a2134f907d2fb46ab774a831404a']",
      "before_first_fix_commit": "{'496c2630e51c1a478f095b084329acedb253db6b'}",
      "last_fix_commit": "fca9874a9b42a2134f907d2fb46ab774a831404a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/20/2021, 00:33:11",
      "message": "Prevent another division by zero.\n\nPiperOrigin-RevId: 369338598\nChange-Id: I55471d363e401fdcf8d259670ad4eef672b731e2",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'tensorflow/core/kernels/conv_grad_shape_utils.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/fca9874a9b42a2134f907d2fb46ab774a831404a/tensorflow%2Fcore%2Fkernels%2Fconv_grad_shape_utils.cc', 'patch': '@@ -127,6 +127,10 @@ Status ConvBackpropComputeDimensionsV2(\\n   // dimensions of the filter Tensor.\\n   VLOG(2) << \"input vs filter_in depth \" << dims->in_depth << \" \"\\n           << filter_shape.dim_size(num_dims - 2);\\n+  if (filter_shape.dim_size(num_dims - 2) <= 0) {\\n+    return errors ::InvalidArgument(\\n+        label, \": filter depth must be strictly greated than zero\");\\n+  }\\n   if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {\\n     return errors::InvalidArgument(\\n         label, \": input depth must be evenly divisible by filter depth\");'}}",
      "message_norm": "prevent another division by zero.\n\npiperorigin-revid: 369338598\nchange-id: i55471d363e401fdcf8d259670ad4eef672b731e2",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('division by zero', 'SECWORD', ''), ('369338598', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/conv_grad_shape_utils.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1491,
      "vuln_id": "GHSA-c5hf-mc85-2hx4",
      "cwe_id": "{'CWE-863'}",
      "score": 4.3,
      "chain": "{'https://github.com/moodle/moodle/commit/cdc78a16a5da95a17fb10bf1c66689237f5a3f7d'}",
      "dataset": "osv",
      "summary": "Missing authorization in Moodle Users with the capability to configure badge criteria (teachers and managers by default) were able to configure course badges with profile field criteria, which should only be available for site badges.",
      "published_date": "2022-04-30",
      "chain_len": 1,
      "project": "https://github.com/moodle/moodle",
      "commit_href": "https://github.com/moodle/moodle/commit/cdc78a16a5da95a17fb10bf1c66689237f5a3f7d",
      "commit_sha": "cdc78a16a5da95a17fb10bf1c66689237f5a3f7d",
      "patch": "SINGLE",
      "chain_ord": "['cdc78a16a5da95a17fb10bf1c66689237f5a3f7d']",
      "before_first_fix_commit": "{'4c00836de97bea26a0c5ba6068a55a8c1b16f260'}",
      "last_fix_commit": "cdc78a16a5da95a17fb10bf1c66689237f5a3f7d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/07/2022, 12:39:16",
      "message": "MDL-74075 core_badges: Check accepted criterias",
      "author": "Amaia Anabitarte",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'badges/criteria_settings.php': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/moodle/moodle/raw/cdc78a16a5da95a17fb10bf1c66689237f5a3f7d/badges%2Fcriteria_settings.php', 'patch': \"@@ -55,6 +55,12 @@\\n     redirect($return);\\n }\\n \\n+// Make sure the criteria type is accepted.\\n+$accepted = $badge->get_accepted_criteria();\\n+if (!in_array($type, $accepted)) {\\n+    redirect($return);\\n+}\\n+\\n if ($badge->type == BADGE_TYPE_COURSE) {\\n     require_login($badge->courseid);\\n     $navurl = new moodle_url('/badges/index.php', array('type' => $badge->type, 'id' => $badge->courseid));\"}}",
      "message_norm": "mdl-74075 core_badges: check accepted criterias",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['badges/criteria_settings.php'])",
      "num_files": 1.0
    },
    {
      "index": 3062,
      "vuln_id": "GHSA-v6r6-84gr-92rm",
      "cwe_id": "{'CWE-787', 'CWE-119'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/6fc9141f42f6a72180ecd24021c3e6b36165fe0d'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `AvgPool3DGrad` ### Impact\nThe implementation of `tf.raw_ops.AvgPool3DGrad` is vulnerable to a heap buffer overflow:\n\n```python\nimport tensorflow as tf\n\norig_input_shape = tf.constant([10, 6, 3, 7, 7], shape=[5], dtype=tf.int32)\ngrad = tf.constant([0.01, 0, 0], shape=[3, 1, 1, 1, 1], dtype=tf.float32)\nksize = [1, 1, 1, 1, 1]\nstrides = [1, 1, 1, 1, 1]\npadding = \"SAME\"\n\ntf.raw_ops.AvgPool3DGrad(\n  orig_input_shape=orig_input_shape, grad=grad, ksize=ksize, strides=strides,\n  padding=padding)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/d80ffba9702dc19d1fac74fc4b766b3fa1ee976b/tensorflow/core/kernels/pooling_ops_3d.cc#L376-L450) assumes that the `orig_input_shape` and `grad` tensors have similar first and last dimensions but does not check that this assumption is validated.\n\n### Patches\nWe have patched the issue in GitHub commit [6fc9141f42f6a72180ecd24021c3e6b36165fe0d](https://github.com/tensorflow/tensorflow/commit/6fc9141f42f6a72180ecd24021c3e6b36165fe0d).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/6fc9141f42f6a72180ecd24021c3e6b36165fe0d",
      "commit_sha": "6fc9141f42f6a72180ecd24021c3e6b36165fe0d",
      "patch": "SINGLE",
      "chain_ord": "['6fc9141f42f6a72180ecd24021c3e6b36165fe0d']",
      "before_first_fix_commit": "{'d80ffba9702dc19d1fac74fc4b766b3fa1ee976b'}",
      "last_fix_commit": "6fc9141f42f6a72180ecd24021c3e6b36165fe0d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/06/2021, 16:51:26",
      "message": "Fix assertion failure in pooling_ops_3d\n\nPiperOrigin-RevId: 372364504\nChange-Id: Iecde4fe26b47a8fa935d6e2611b5585ed5777781",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 13, 'deletions': 0, 'total': 13}",
      "files": "{'tensorflow/core/kernels/pooling_ops_3d.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/6fc9141f42f6a72180ecd24021c3e6b36165fe0d/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc', 'patch': '@@ -383,6 +383,19 @@ struct LaunchAvgPooling3dGradOp<CPUDevice, T> {\\n                      const std::array<int64, 3>& output_shape,\\n                      const std::array<int64, 3>& padding,\\n                      TensorFormat data_format, Tensor* output) {\\n+    OP_REQUIRES(\\n+        context, tensor_in_shape.dim_size(0) == out_backprop.dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Expected first dimension of tensor_in_shape and \"\\n+            \"out_backprop to match, got \",\\n+            tensor_in_shape.dim_size(0), \" and \", out_backprop.dim_size(0)));\\n+    OP_REQUIRES(\\n+        context, tensor_in_shape.dim_size(4) == out_backprop.dim_size(4),\\n+        errors::InvalidArgument(\\n+            \"Expected last dimension of tensor_in_shape and \"\\n+            \"out_backprop to match, got \",\\n+            tensor_in_shape.dim_size(4), \" and \", out_backprop.dim_size(4)));\\n+\\n     output->flat<T>().setZero();\\n     std::array<int64, 3> input_size = {{tensor_in_shape.dim_size(3),\\n                                         tensor_in_shape.dim_size(2),'}}",
      "message_norm": "fix assertion failure in pooling_ops_3d\n\npiperorigin-revid: 372364504\nchange-id: iecde4fe26b47a8fa935d6e2611b5585ed5777781",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('372364504', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/pooling_ops_3d.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1400,
      "vuln_id": "GHSA-9jjr-qqfp-ppwx",
      "cwe_id": "{'CWE-94'}",
      "score": 9.6,
      "chain": "{'https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182'}",
      "dataset": "osv",
      "summary": "remote code execution via git repo provider ### Impact\n\nA remote code execution vulnerability has been identified in BinderHub, where providing BinderHub with maliciously crafted input could execute code in the BinderHub context, with the potential to egress credentials of the BinderHub deployment, including JupyterHub API tokens, kubernetes service accounts, and docker registry credentials. This may provide the ability to manipulate images and other user created pods in the deployment, with the potential to escalate to the host depending on the underlying kubernetes configuration.\n\n### Patches\n\nPatch below, or [on GitHub](https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182.patch)\n\n```diff\nFrom 9f4043d9dddc1174920e687773f27b7933f48ab6 Mon Sep 17 00:00:00 2001\nFrom: Riccardo Castellotti <rcastell@cern.ch>\nDate: Thu, 19 Aug 2021 15:49:43 +0200\nSubject: [PATCH] Explicitly separate git-ls-remote options from positional\n arguments\n\n---\n binderhub/repoproviders.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/binderhub/repoproviders.py b/binderhub/repoproviders.py\nindex f33347b..5d4b87c 100755\n--- a/binderhub/repoproviders.py\n+++ b/binderhub/repoproviders.py\n@@ -484,7 +484,7 @@ class GitRepoProvider(RepoProvider):\n             self.sha1_validate(self.unresolved_ref)\n         except ValueError:\n             # The ref is a head/tag and we resolve it using `git ls-remote`\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n             if result.returncode:\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))\n-- \n2.25.1\n\n```\n\n### Workarounds\n\nDisable the git repo provider by specifying the `BinderHub.repo_providers` config, e.g.:\n\n```python\nfrom binderhub.repoproviders import (GitHubRepoProvider,\n                            GitLabRepoProvider, GistRepoProvider,\n                            ZenodoProvider, FigshareProvider, HydroshareProvider,\n                            DataverseProvider)\n\nc.BinderHub.repo_providers =  {\n            'gh': GitHubRepoProvider,\n            'gist': GistRepoProvider,\n            'gl': GitLabRepoProvider,\n            'zenodo': ZenodoProvider,\n            'figshare': FigshareProvider,\n            'hydroshare': HydroshareProvider,\n            'dataverse': DataverseProvider,\n        }\n```\n\n### References\n\nCredit: Jose Carlos Luna Duran (CERN) and Riccardo Castellotti (CERN).\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Email us at [security@ipython.org](mailto:security@ipython.org)",
      "published_date": "2021-08-30",
      "chain_len": 1,
      "project": "https://github.com/jupyterhub/binderhub",
      "commit_href": "https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182",
      "commit_sha": "195caac172690456dcdc8cc7a6ca50e05abf8182",
      "patch": "SINGLE",
      "chain_ord": "['195caac172690456dcdc8cc7a6ca50e05abf8182']",
      "before_first_fix_commit": "{'034430adc8ed379135f3ef46ee6ca650781ef67c'}",
      "last_fix_commit": "195caac172690456dcdc8cc7a6ca50e05abf8182",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/19/2021, 13:49:43",
      "message": "Explicitly separate git-ls-remote options from positional arguments",
      "author": "Riccardo Castellotti",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'binderhub/repoproviders.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/jupyterhub/binderhub/raw/195caac172690456dcdc8cc7a6ca50e05abf8182/binderhub%2Frepoproviders.py', 'patch': '@@ -484,7 +484,7 @@ async def get_resolved_ref(self):\\n             self.sha1_validate(self.unresolved_ref)\\n         except ValueError:\\n             # The ref is a head/tag and we resolve it using `git ls-remote`\\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n             if result.returncode:\\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))'}}",
      "message_norm": "explicitly separate git-ls-remote options from positional arguments",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['binderhub/repoproviders.py'])",
      "num_files": 1.0
    },
    {
      "index": 320,
      "vuln_id": "GHSA-3wfj-vh84-732p",
      "cwe_id": "{'CWE-78'}",
      "score": 7.5,
      "chain": "{'https://github.com/apache/activemq/commit/00921f22ff9a8792d7663ef8fadd4823402a6324'}",
      "dataset": "osv",
      "summary": "Improper Neutralization of Special Elements used in an OS Command in Apache ActiveMQ The processControlCommand function in broker/TransportConnection.java in Apache ActiveMQ before 5.11.0 allows remote attackers to cause a denial of service (shutdown) via a shutdown command.",
      "published_date": "2022-05-14",
      "chain_len": 1,
      "project": "https://github.com/apache/activemq",
      "commit_href": "https://github.com/apache/activemq/commit/00921f22ff9a8792d7663ef8fadd4823402a6324",
      "commit_sha": "00921f22ff9a8792d7663ef8fadd4823402a6324",
      "patch": "SINGLE",
      "chain_ord": "['00921f22ff9a8792d7663ef8fadd4823402a6324']",
      "before_first_fix_commit": "{'9a6d444e0a492231ad1f4833448b3bbacd839bce'}",
      "last_fix_commit": "00921f22ff9a8792d7663ef8fadd4823402a6324",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/13/2014, 15:15:29",
      "message": "Remove unused ConnectionControl handling.",
      "author": "Timothy Bish",
      "comments": "{'com_1': {'author': 'tritschler', 'datetime': '11/10/2015, 09:33:23', 'body': 'No more shutdown ?'}, 'com_2': {'author': 'Hvnt3r', 'datetime': '07/18/2019, 08:46:59', 'body': '> No more shutdown ?\\r\\n\\r\\nyes'}}",
      "stats": "{'additions': 0, 'deletions': 4, 'total': 4}",
      "files": "{'activemq-broker/src/main/java/org/apache/activemq/broker/TransportConnection.java': {'additions': 0, 'deletions': 4, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/apache/activemq/raw/00921f22ff9a8792d7663ef8fadd4823402a6324/activemq-broker%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Factivemq%2Fbroker%2FTransportConnection.java', 'patch': '@@ -1534,10 +1534,6 @@ public int getProtocolVersion() {\\n \\n     @Override\\n     public Response processControlCommand(ControlCommand command) throws Exception {\\n-        String control = command.getCommand();\\n-        if (control != null && control.equals(\"shutdown\")) {\\n-            System.exit(0);\\n-        }\\n         return null;\\n     }'}}",
      "message_norm": "remove unused connectioncontrol handling.",
      "language": "en",
      "entities": "[('remove', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['activemq-broker/src/main/java/org/apache/activemq/broker/TransportConnection.java'])",
      "num_files": 1.0
    },
    {
      "index": 1086,
      "vuln_id": "GHSA-7vvq-7r29-5vg3",
      "cwe_id": "{'CWE-79'}",
      "score": 7.1,
      "chain": "{'https://github.com/mrdoob/three.js/commit/0c31bc605e21965aad8a6479bb1969351773f76d'}",
      "dataset": "osv",
      "summary": "Cross site scripting in three.js # CVE has been withdrawn\n\nVersions of three.js prior to 0.137.0 load untrusted iframes and allow for attackers to inject arbitrary javascript into a users browser.",
      "published_date": "2022-01-27",
      "chain_len": 1,
      "project": "https://github.com/mrdoob/three.js",
      "commit_href": "https://github.com/mrdoob/three.js/commit/0c31bc605e21965aad8a6479bb1969351773f76d",
      "commit_sha": "0c31bc605e21965aad8a6479bb1969351773f76d",
      "patch": "SINGLE",
      "chain_ord": "['0c31bc605e21965aad8a6479bb1969351773f76d']",
      "before_first_fix_commit": "{'55d4f24cb50e995b0dfee73979305e8237384a53'}",
      "last_fix_commit": "0c31bc605e21965aad8a6479bb1969351773f76d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/24/2022, 17:39:24",
      "message": "Only load trusted iframe (#23245)",
      "author": "Rohan Sharma",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'docs/index.html': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/mrdoob/three.js/raw/0c31bc605e21965aad8a6479bb1969351773f76d/docs%2Findex.html', 'patch': '@@ -498,7 +498,7 @@ <h1><a href=\"https://threejs.org\">three.js</a></h1>\\n \\t\\t\\tconst oldIframe = iframe;\\n \\t\\t\\tiframe = oldIframe.cloneNode();\\n \\n-\\t\\t\\tif ( hash ) {\\n+\\t\\t\\tif ( hash && titles[ splitHash[ 0 ] ] ) {\\n \\n \\t\\t\\t\\tiframe.src = splitHash[ 0 ] + \\'.html\\' + splitHash[ 1 ];\\n \\t\\t\\t\\tsubtitle = titles[ splitHash[ 0 ] ] + splitHash[ 1 ] + \\' \u2013 \\';'}}",
      "message_norm": "only load trusted iframe (#23245)",
      "language": "en",
      "entities": "[('#23245', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['docs/index.html'])",
      "num_files": 1.0
    },
    {
      "index": 1945,
      "vuln_id": "GHSA-gwp4-hfv6-p7hw",
      "cwe_id": "{'CWE-502'}",
      "score": 7.5,
      "chain": "{'https://github.com/FasterXML/jackson-databind/commit/ad418eeb974e357f2797aef64aa0e3ffaaa6125b'}",
      "dataset": "osv",
      "summary": "Deserialization of untrusted data in FasterXML jackson-databind A Polymorphic Typing issue was discovered in FasterXML jackson-databind 2.x before 2.9.9.2. This occurs when Default Typing is enabled (either globally or for a specific property) for an externally exposed JSON endpoint and the service has the logback jar in the classpath.",
      "published_date": "2019-08-01",
      "chain_len": 1,
      "project": "https://github.com/FasterXML/jackson-databind",
      "commit_href": "https://github.com/FasterXML/jackson-databind/commit/ad418eeb974e357f2797aef64aa0e3ffaaa6125b",
      "commit_sha": "ad418eeb974e357f2797aef64aa0e3ffaaa6125b",
      "patch": "SINGLE",
      "chain_ord": "['ad418eeb974e357f2797aef64aa0e3ffaaa6125b']",
      "before_first_fix_commit": "{'322ae225cbcd07178a634e548d991b0aec6b47bf'}",
      "last_fix_commit": "ad418eeb974e357f2797aef64aa0e3ffaaa6125b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/26/2019, 04:58:11",
      "message": "Backport #2387, #2389 fixes",
      "author": "Tatu Saloranta",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'src/main/java/com/fasterxml/jackson/databind/jsontype/impl/SubTypeValidator.java': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/FasterXML/jackson-databind/raw/ad418eeb974e357f2797aef64aa0e3ffaaa6125b/src%2Fmain%2Fjava%2Fcom%2Ffasterxml%2Fjackson%2Fdatabind%2Fjsontype%2Fimpl%2FSubTypeValidator.java', 'patch': '@@ -89,6 +89,12 @@\\n         s.add(\"org.jdom.transform.XSLTransformer\");\\n         s.add(\"org.jdom2.transform.XSLTransformer\");\\n \\n+        // [databind#2387]: EHCache\\n+        s.add(\"net.sf.ehcache.transaction.manager.DefaultTransactionManagerLookup\");\\n+\\n+        // [databind#2389]: logback/jndi\\n+        s.add(\"ch.qos.logback.core.db.JNDIConnectionSource\");\\n+\\n         DEFAULT_NO_DESER_CLASS_NAMES = Collections.unmodifiableSet(s);\\n     }'}}",
      "message_norm": "backport #2387, #2389 fixes",
      "language": "en",
      "entities": "[('#2387', 'ISSUE', ''), ('#2389', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/main/java/com/fasterxml/jackson/databind/jsontype/impl/SubTypeValidator.java'])",
      "num_files": 1.0
    },
    {
      "index": 927,
      "vuln_id": "GHSA-72p8-v4hg-v45p",
      "cwe_id": "{'CWE-330', 'CWE-338'}",
      "score": 6.5,
      "chain": "{'https://github.com/sshnet/SSH.NET/commit/03c6d60736b8f7b42e44d6989a53f9b644a091fb', 'https://github.com/sshnet/SSH.NET/commit/f1f273cf349532b9d41c1de51d3b83a9accedc88'}",
      "dataset": "osv",
      "summary": "Weak private key generation in SSH.NET During an **X25519** key exchange, the client\u2019s private is generated with [**System.Random**](https://docs.microsoft.com/en-us/dotnet/api/system.random):\n\n```cs\nvar rnd = new Random();\n_privateKey = new byte[MontgomeryCurve25519.PrivateKeySizeInBytes];\nrnd.NextBytes(_privateKey);\n```\n\nSource: [KeyExchangeECCurve25519.cs](https://github.com/sshnet/SSH.NET/blob/bc99ada7da3f05f50d9379f2644941d91d5bf05a/src/Renci.SshNet/Security/KeyExchangeECCurve25519.cs#L51)  \nSource commit: https://github.com/sshnet/SSH.NET/commit/b58a11c0da55da1f5bad46faad2e9b71b7cb35b3\n\n[**System.Random**](https://docs.microsoft.com/en-us/dotnet/api/system.random) is not a cryptographically secure random number generator, it must therefore not be used for cryptographic purposes.\n\n### Impact\nWhen establishing an SSH connection to a remote host, during the X25519 key exchange, the private key is generated with\na weak random number generator whose seed can be bruteforced. This allows an attacker able to eavesdrop the\ncommunications to decrypt them.\n\n### Workarounds\nTo ensure you're not affected by this vulnerability, you can disable support for `curve25519-sha256` and `curve25519-sha256@libssh.org` key exchange algorithms by invoking the following method before a connection is established:\n```cs\nprivate static void RemoveUnsecureKEX(BaseClient client)\n{\n    client.ConnectionInfo.KeyExchangeAlgorithms.Remove(\"curve25519-sha256\");\n    client.ConnectionInfo.KeyExchangeAlgorithms.Remove(\"curve25519-sha256@libssh.org\");\n}\n```\n\n### Thanks\n\nThis issue was initially reported by **Siemens AG, Digital Industries**, shortly followed by @yaumn-synacktiv.",
      "published_date": "2022-06-01",
      "chain_len": 2,
      "project": "https://github.com/sshnet/SSH.NET",
      "commit_href": "https://github.com/sshnet/SSH.NET/commit/03c6d60736b8f7b42e44d6989a53f9b644a091fb",
      "commit_sha": "03c6d60736b8f7b42e44d6989a53f9b644a091fb",
      "patch": "MULTI",
      "chain_ord": "['f1f273cf349532b9d41c1de51d3b83a9accedc88', '03c6d60736b8f7b42e44d6989a53f9b644a091fb']",
      "before_first_fix_commit": "{'cad943343b4c7ea55975a3033ef1cd0646b6b9d7'}",
      "last_fix_commit": "03c6d60736b8f7b42e44d6989a53f9b644a091fb",
      "chain_ord_pos": 2.0,
      "commit_datetime": "05/29/2022, 14:58:07",
      "message": "Use cryptographically secure random number generator.\nFixes CVE-2022-29245.",
      "author": "drieseng",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 3, 'total': 4}",
      "files": "{'src/Renci.SshNet/Security/KeyExchangeECCurve25519.cs': {'additions': 1, 'deletions': 3, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/sshnet/SSH.NET/raw/03c6d60736b8f7b42e44d6989a53f9b644a091fb/src%2FRenci.SshNet%2FSecurity%2FKeyExchangeECCurve25519.cs', 'patch': '@@ -46,9 +46,7 @@ public override void Start(Session session, KeyExchangeInitMessage message)\\n             var basepoint = new byte[MontgomeryCurve25519.PublicKeySizeInBytes];\\n             basepoint[0] = 9;\\n \\n-            var rnd = new Random();\\n-            _privateKey = new byte[MontgomeryCurve25519.PrivateKeySizeInBytes];\\n-            rnd.NextBytes(_privateKey);\\n+            _privateKey = CryptoAbstraction.GenerateRandom(MontgomeryCurve25519.PrivateKeySizeInBytes);\\n \\n             _clientExchangeValue = new byte[MontgomeryCurve25519.PublicKeySizeInBytes];\\n             MontgomeryOperations.scalarmult(_clientExchangeValue, 0, _privateKey, 0, basepoint, 0);'}}",
      "message_norm": "use cryptographically secure random number generator.\nfixes cve-2022-29245.",
      "language": "en",
      "entities": "[('cryptographically', 'SECWORD', ''), ('secure', 'SECWORD', ''), ('cve-2022-29245', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Renci.SshNet/Security/KeyExchangeECCurve25519.cs'])",
      "num_files": 1.0
    },
    {
      "index": 2709,
      "vuln_id": "GHSA-q6mp-562x-ggvv",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/microweber/microweber/commit/70b46e231e7b2c113666745a0ab6de9a8b7ef08e'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in microweber Cross-site Scripting (XSS) - Stored in GitHub repository microweber/microweber prior to 1.2.19.",
      "published_date": "2022-07-05",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/70b46e231e7b2c113666745a0ab6de9a8b7ef08e",
      "commit_sha": "70b46e231e7b2c113666745a0ab6de9a8b7ef08e",
      "patch": "SINGLE",
      "chain_ord": "['70b46e231e7b2c113666745a0ab6de9a8b7ef08e']",
      "before_first_fix_commit": "{'b7663f9af0f4ab777275ffe7a3b77958f98c81fb'}",
      "last_fix_commit": "70b46e231e7b2c113666745a0ab6de9a8b7ef08e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/04/2022, 08:02:08",
      "message": "update",
      "author": "Peter Ivanov",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'src/MicroweberPackages/Utils/System/Files.php': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/70b46e231e7b2c113666745a0ab6de9a8b7ef08e/src%2FMicroweberPackages%2FUtils%2FSystem%2FFiles.php', 'patch': \"@@ -1154,11 +1154,11 @@ function get_allowed_files_extensions_for_upload($fileTypes = 'images', $returnA\\n                 break;\\n             case 'file':\\n             case 'files':\\n-                $are_allowed .= ',css,json,zip,gzip,csv,7z';\\n+                $are_allowed .= ',css,json,zip,gzip,psd,csv,7z';\\n                 break;\\n             case 'documents':\\n             case 'doc':\\n-                $are_allowed .= ',doc,docx,pdf,odt,pages,rtf,txt,pps,ppt,pptx,xls,xlsx';\\n+                $are_allowed .= ',doc,docx,pdf,odt,rtf,txt,pps,ppt,pptx,xls,xlsx';\\n                 break;\\n             case 'archives':\\n             case 'arc':\"}}",
      "message_norm": "update",
      "language": "ro",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/Utils/System/Files.php'])",
      "num_files": 1.0
    },
    {
      "index": 3344,
      "vuln_id": "GHSA-x28w-hvwc-mp75",
      "cwe_id": "{'CWE-94', 'CWE-96'}",
      "score": 7.7,
      "chain": "{'https://github.com/microweber/microweber/commit/b2baab6e582b2efe63788d367a2bb61a2fa26470'}",
      "dataset": "osv",
      "summary": "Static Code Injection in Microweber Microweber is a new generation CMS with drag and drop. Prior to version 1.3, Microweber is vulnerable to static code injection.",
      "published_date": "2022-03-11",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/b2baab6e582b2efe63788d367a2bb61a2fa26470",
      "commit_sha": "b2baab6e582b2efe63788d367a2bb61a2fa26470",
      "patch": "SINGLE",
      "chain_ord": "['b2baab6e582b2efe63788d367a2bb61a2fa26470']",
      "before_first_fix_commit": "{'a15da374af81c3cd312ee1639e4c6f56c4839f7e'}",
      "last_fix_commit": "b2baab6e582b2efe63788d367a2bb61a2fa26470",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/09/2022, 11:13:43",
      "message": "Update ContactInformationTrait.php",
      "author": "Bozhidar Slaveykov",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 4, 'total': 13}",
      "files": "{'src/MicroweberPackages/Checkout/Http/Controllers/Traits/ContactInformationTrait.php': {'additions': 9, 'deletions': 4, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/b2baab6e582b2efe63788d367a2bb61a2fa26470/src%2FMicroweberPackages%2FCheckout%2FHttp%2FControllers%2FTraits%2FContactInformationTrait.php', 'patch': \"@@ -36,11 +36,16 @@ public function contactInformation() {\\n \\n     public function contactInformationSave(Request $request) {\\n \\n+        $firstName = strip_tags($request->get('first_name'));\\n+        $lastName = strip_tags($request->get('last_name'));\\n+        $email = strip_tags($request->get('email'));\\n+        $phone = strip_tags($request->get('phone'));\\n+\\n         session_append_array('checkout_v2', [\\n-            'first_name'=> $request->get('first_name'),\\n-            'last_name'=> $request->get('last_name'),\\n-            'email'=> $request->get('email'),\\n-            'phone'=> $request->get('phone')\\n+            'first_name'=> $firstName,\\n+            'last_name'=> $lastName,\\n+            'email'=> $email,\\n+            'phone'=> $phone\\n         ]);\\n \\n         $validate = $this->_validateContactInformation($request->all());\"}}",
      "message_norm": "update contactinformationtrait.php",
      "language": "fr",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/Checkout/Http/Controllers/Traits/ContactInformationTrait.php'])",
      "num_files": 1.0
    },
    {
      "index": 1020,
      "vuln_id": "GHSA-7f63-h6g3-7cwm",
      "cwe_id": "{'CWE-79'}",
      "score": 6.1,
      "chain": "{'https://github.com/Finastra/ssr-pages/pull/2/commits/133606ffaec2edd9918d9fba5771ed21da7876a5', 'https://github.com/Finastra/ssr-pages/commit/98abc59e28fec48246be0d59ac144675d6361073'}",
      "dataset": "osv",
      "summary": "Cross Site Scripting (XSS) in @finastra/ssr-pages A cross site scripting (XSS) issue can occur when providing untrusted input to the `redirect.link` property as an argument to the `build(MessagePageOptions)` function.\n\n### References\n- https://github.com/Finastra/ssr-pages/pull/2\n- https://github.com/Finastra/ssr-pages/pull/2/commits/133606ffaec2edd9918d9fba5771ed21da7876a5\n- https://github.com/Finastra/ssr-pages/commit/98abc59e28fec48246be0d59ac144675d6361073",
      "published_date": "2022-03-01",
      "chain_len": 2,
      "project": "https://github.com/Finastra/ssr-pages",
      "commit_href": "https://github.com/Finastra/ssr-pages/commit/98abc59e28fec48246be0d59ac144675d6361073",
      "commit_sha": "98abc59e28fec48246be0d59ac144675d6361073",
      "patch": "MULTI",
      "chain_ord": "['133606ffaec2edd9918d9fba5771ed21da7876a5', '98abc59e28fec48246be0d59ac144675d6361073']",
      "before_first_fix_commit": "{'ea07d3fca4b5b84aab889391c100f9bf71333ded'}",
      "last_fix_commit": "98abc59e28fec48246be0d59ac144675d6361073",
      "chain_ord_pos": 2.0,
      "commit_datetime": "02/27/2022, 18:45:49",
      "message": "fix string encoder",
      "author": "David Bocl\u00e9",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/helpers/string-encoder.helper.ts': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/Finastra/ssr-pages/raw/98abc59e28fec48246be0d59ac144675d6361073/src%2Fhelpers%2Fstring-encoder.helper.ts', 'patch': \"@@ -2,7 +2,7 @@ export function stringEncode(string: string) {\\n     let encodedString = '';\\r\\n     for (let i = 0; i < string.length; i++) {\\r\\n         let charCodePointHex = string.charCodeAt(i).toString(16);\\r\\n-        encodedString += `\\\\\\\\u${charCodePointHex}`;\\r\\n+        encodedString += `\\\\\\\\u{${charCodePointHex}}`;\\r\\n     }\\r\\n     return encodedString;\\r\\n }\\n\\\\ No newline at end of file\"}}",
      "message_norm": "fix string encoder",
      "language": "da",
      "entities": "[('fix', 'ACTION', ''), ('encoder', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/helpers/string-encoder.helper.ts'])",
      "num_files": 1.0
    },
    {
      "index": 2084,
      "vuln_id": "GHSA-hjgp-8ffr-hwwr",
      "cwe_id": "{'CWE-311'}",
      "score": 0.0,
      "chain": "{'https://github.com/dcodeIO/ClosureCompiler.js/commit/e59848f5975e5b15279c044daf9cff8ff192bae6'}",
      "dataset": "osv",
      "summary": "Downloads Resources over HTTP in closurecompiler Affected versions of `closurecompiler` insecurely download an executable over an unencrypted HTTP connection. \n\nIn scenarios where an attacker has a privileged network position, it is possible to intercept the response and replace the executable with a malicious one, resulting in code execution on the system running `closurecompiler`.\n\n\n## Recommendation\n\nUpdate to version 1.6.1 or later.",
      "published_date": "2019-02-18",
      "chain_len": 1,
      "project": "https://github.com/dcodeIO/ClosureCompiler.js",
      "commit_href": "https://github.com/dcodeIO/ClosureCompiler.js/commit/e59848f5975e5b15279c044daf9cff8ff192bae6",
      "commit_sha": "e59848f5975e5b15279c044daf9cff8ff192bae6",
      "patch": "SINGLE",
      "chain_ord": "['e59848f5975e5b15279c044daf9cff8ff192bae6']",
      "before_first_fix_commit": "{'a896952c01f25a5317b6619723fe1ebeabaeb468', '923250af8c94154bdbc48f61230af1adf2543173'}",
      "last_fix_commit": "e59848f5975e5b15279c044daf9cff8ff192bae6",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/01/2016, 14:20:53",
      "message": "Merge pull request #51 from Greenek/master\n\nUpdate link to bundled-openjdk-jre",
      "author": "Daniel Wirtz",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 4, 'total': 8}",
      "files": "{'scripts/configure.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/dcodeIO/ClosureCompiler.js/raw/e59848f5975e5b15279c044daf9cff8ff192bae6/scripts%2Fconfigure.js', 'patch': '@@ -48,7 +48,7 @@ function platformPostfix() {\\n }\\n \\n // Bundled JRE download url\\n-var jrePrefix = \"http://bundled-openjdk-jre.googlecode.com/files/OpenJDK-JRE-7u6_24-\";\\n+var jrePrefix = \"https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/bundled-openjdk-jre/OpenJDK-JRE-7u6_24-\";\\n var jrePostfix = \".tar.gz\";\\n var jreUrl = jrePrefix+platformPostfix()+jrePostfix;\\n \\n@@ -205,13 +205,13 @@ function download(downloadUrl, filename, callback, ondata) {\\n  * @param {function(?Error)} callback\\n  * @param {function(Object)=} entryCallback\\n  */\\n-function unpack(filename, callback, entryCallback) {   \\n+function unpack(filename, callback, entryCallback) {\\n     var input = fs.createReadStream(filename, { flags: \\'r\\', encoding: null }),\\n         files = {},\\n         dir = path.dirname(filename),\\n         returned = false,\\n         to = null;\\n-    \\n+\\n     // Finishs the unpack if all files are done\\n     function maybeFinish() {\\n         if (to !== null) clearTimeout(to);\\n@@ -230,7 +230,7 @@ function unpack(filename, callback, entryCallback) {\\n             }\\n         }, 1000);\\n     }\\n-    \\n+\\n     input.pipe(zlib.createGunzip()).pipe(tar.Parse()).on(\"entry\", function(entry) {\\n         if (entryCallback) entryCallback(entry);\\n         if (entry[\"type\"] == \\'File\\') {'}}",
      "message_norm": "merge pull request #51 from greenek/master\n\nupdate link to bundled-openjdk-jre",
      "language": "no",
      "entities": "[('#51', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['scripts/configure.js'])",
      "num_files": 1.0
    },
    {
      "index": 2853,
      "vuln_id": "GHSA-r4c4-5fpq-56wg",
      "cwe_id": "{'CWE-125'}",
      "score": 7.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/e84c975313e8e8e38bb2ea118196369c45c51378'}",
      "dataset": "osv",
      "summary": "Heap OOB in boosted trees ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `BoostedTreesSparseCalculateBestFeatureSplit`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(\n  node_id_range=[0,10],\n  stats_summary_indices=[[1, 2, 3, 0x1000000]],\n  stats_summary_values=[1.0],\n  stats_summary_shape=[1,1,1,1],\n  l1=l2=[1.0],\n  tree_complexity=[0.5],\n  min_node_weight=[1.0],\n  logits_dimension=3,\n  split_type='inequality')                                                                                                                                                                                                                                                                \n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/stats_ops.cc) needs to validate that each value in `stats_summary_indices` is in range.\n  \n### Patches\nWe have patched the issue in GitHub commit [e84c975313e8e8e38bb2ea118196369c45c51378](https://github.com/tensorflow/tensorflow/commit/e84c975313e8e8e38bb2ea118196369c45c51378).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/e84c975313e8e8e38bb2ea118196369c45c51378",
      "commit_sha": "e84c975313e8e8e38bb2ea118196369c45c51378",
      "patch": "SINGLE",
      "chain_ord": "['e84c975313e8e8e38bb2ea118196369c45c51378']",
      "before_first_fix_commit": "{'2e0ee46f1a47675152d3d865797a18358881d7a6'}",
      "last_fix_commit": "e84c975313e8e8e38bb2ea118196369c45c51378",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/27/2021, 19:35:03",
      "message": "In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaa",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 0, 'total': 7}",
      "files": "{'tensorflow/core/kernels/boosted_trees/stats_ops.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/e84c975313e8e8e38bb2ea118196369c45c51378/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\\n+      OP_REQUIRES(context, stat_dim < stats_dims,\\n+                  errors::InvalidArgument(\\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\\n+                      \"stats_summary_indices, cannot be greater than stats \"\\n+                      \"dims, the last value in stats_summary_shape, which was \",\\n+                      stats_dims, \". At index (\", idx,\\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\\n       auto& b_map = f_insert_result.first->second;'}}",
      "message_norm": "in tf.raw_ops.boostedtreessparsecalculatebestfeaturesplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\npiperorigin-revid: 387171191\nchange-id: i83ca8a75b22aa78c037e8b98779da6cced16bfaa",
      "language": "en",
      "entities": "[('387171191', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/boosted_trees/stats_ops.cc'])",
      "num_files": 1.0
    }
  ]
}