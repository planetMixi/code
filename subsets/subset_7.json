{
  "schema": {
    "fields": [
      {
        "name": "index",
        "type": "integer"
      },
      {
        "name": "vuln_id",
        "type": "string"
      },
      {
        "name": "cwe_id",
        "type": "string"
      },
      {
        "name": "score",
        "type": "number"
      },
      {
        "name": "chain",
        "type": "string"
      },
      {
        "name": "dataset",
        "type": "string"
      },
      {
        "name": "summary",
        "type": "string"
      },
      {
        "name": "published_date",
        "type": "string"
      },
      {
        "name": "chain_len",
        "type": "integer"
      },
      {
        "name": "project",
        "type": "string"
      },
      {
        "name": "commit_href",
        "type": "string"
      },
      {
        "name": "commit_sha",
        "type": "string"
      },
      {
        "name": "patch",
        "type": "string"
      },
      {
        "name": "chain_ord",
        "type": "string"
      },
      {
        "name": "before_first_fix_commit",
        "type": "string"
      },
      {
        "name": "last_fix_commit",
        "type": "string"
      },
      {
        "name": "chain_ord_pos",
        "type": "number"
      },
      {
        "name": "commit_datetime",
        "type": "string"
      },
      {
        "name": "message",
        "type": "string"
      },
      {
        "name": "author",
        "type": "string"
      },
      {
        "name": "comments",
        "type": "string"
      },
      {
        "name": "stats",
        "type": "string"
      },
      {
        "name": "files",
        "type": "string"
      },
      {
        "name": "message_norm",
        "type": "string"
      },
      {
        "name": "language",
        "type": "string"
      },
      {
        "name": "entities",
        "type": "string"
      },
      {
        "name": "classification_level_1",
        "type": "string"
      },
      {
        "name": "classification_level_2",
        "type": "string"
      },
      {
        "name": "list_files",
        "type": "string"
      },
      {
        "name": "num_files",
        "type": "number"
      }
    ],
    "primaryKey": [
      "index"
    ],
    "pandas_version": "1.4.0"
  },
  "data": [
    {
      "index": 399,
      "vuln_id": "GHSA-49x3-8228-3w3m",
      "cwe_id": "{'CWE-1333'}",
      "score": 7.5,
      "chain": "{'https://github.com/cdr/code-server/commit/ca617df135e78833f93c8320cb2d2cf8bba809f5'}",
      "dataset": "osv",
      "summary": "Inefficient Regular Expression Complexity in code-server code-server is vulnerable to Inefficient Regular Expression Complexity",
      "published_date": "2021-09-20",
      "chain_len": 1,
      "project": "https://github.com/cdr/code-server",
      "commit_href": "https://github.com/cdr/code-server/commit/ca617df135e78833f93c8320cb2d2cf8bba809f5",
      "commit_sha": "ca617df135e78833f93c8320cb2d2cf8bba809f5",
      "patch": "SINGLE",
      "chain_ord": "['ca617df135e78833f93c8320cb2d2cf8bba809f5']",
      "before_first_fix_commit": "{'bc3acb071e5393944627e16b2b54dc296a17d2d6'}",
      "last_fix_commit": "ca617df135e78833f93c8320cb2d2cf8bba809f5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/11/2021, 13:10:47",
      "message": "[Security] Fix ReDoS\n\nFix potential ReDoS",
      "author": "ready-research",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/node/util.ts': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/coder/code-server/raw/ca617df135e78833f93c8320cb2d2cf8bba809f5/src%2Fnode%2Futil.ts', 'patch': '@@ -20,7 +20,7 @@ export interface Paths {\\n \\n // From https://github.com/chalk/ansi-regex\\n const pattern = [\\n-  \"[\\\\\\\\u001B\\\\\\\\u009B][[\\\\\\\\]()#;?]*(?:(?:(?:[a-zA-Z\\\\\\\\d]*(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\/#&.:=?%@~_]*)*)?\\\\\\\\u0007)\",\\n+  \"[\\\\\\\\u001B\\\\\\\\u009B][[\\\\\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\\\\\d]+(?:;[-a-zA-Z\\\\\\\\d\\\\\\\\/#&.:=?%@~_]*)*)?\\\\\\\\u0007)\",\\n   \"(?:(?:\\\\\\\\d{1,4}(?:;\\\\\\\\d{0,4})*)?[\\\\\\\\dA-PR-TZcf-ntqry=><~]))\",\\n ].join(\"|\")\\n const re = new RegExp(pattern, \"g\")'}}",
      "message_norm": "[security] fix redos\n\nfix potential redos",
      "language": "es",
      "entities": "[('security', 'SECWORD', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/node/util.ts'])",
      "num_files": 1.0
    },
    {
      "index": 1632,
      "vuln_id": "GHSA-cx2r-mf6x-55rx",
      "cwe_id": "{'CWE-79'}",
      "score": 4.1,
      "chain": "{'https://github.com/PrestaShop/ps_linklist/commit/83e6e0bdda2287f4d6e64127cb90c41d26b5ad82'}",
      "dataset": "osv",
      "summary": "Stored XSS with custom URLs in PrestaShop module ps_linklist ### Impact\nStored XSS when using custom URLs.\n\n### Patches\nThe problem is fixed in 3.1.0\n\n### References\n[Cross-site Scripting (XSS) - Stored (CWE-79)](https://cwe.mitre.org/data/definitions/79.html)",
      "published_date": "2021-10-12",
      "chain_len": 1,
      "project": "https://github.com/PrestaShop/ps_linklist",
      "commit_href": "https://github.com/PrestaShop/ps_linklist/commit/83e6e0bdda2287f4d6e64127cb90c41d26b5ad82",
      "commit_sha": "83e6e0bdda2287f4d6e64127cb90c41d26b5ad82",
      "patch": "SINGLE",
      "chain_ord": "['83e6e0bdda2287f4d6e64127cb90c41d26b5ad82']",
      "before_first_fix_commit": "{'b90005c2cfed949ab564228b277a728e0a62a876', '632e61961553a5cdd4c12ad7218e914455dbaa6b'}",
      "last_fix_commit": "83e6e0bdda2287f4d6e64127cb90c41d26b5ad82",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/15/2020, 14:16:34",
      "message": "Merge pull request from GHSA-cx2r-mf6x-55rx\n\nThe custom url field must be a valid url",
      "author": "GoT",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'src/Form/Type/CustomUrlType.php': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/PrestaShop/ps_linklist/raw/83e6e0bdda2287f4d6e64127cb90c41d26b5ad82/src%2FForm%2FType%2FCustomUrlType.php', 'patch': \"@@ -29,6 +29,7 @@\\n use PrestaShopBundle\\\\Form\\\\Admin\\\\Type\\\\TranslatorAwareType;\\n use Symfony\\\\Component\\\\Form\\\\Extension\\\\Core\\\\Type\\\\TextType;\\n use Symfony\\\\Component\\\\Form\\\\FormBuilderInterface;\\n+use Symfony\\\\Component\\\\Validator\\\\Constraints as Assert;\\n \\n class CustomUrlType extends TranslatorAwareType\\n {\\n@@ -45,6 +46,7 @@ public function buildForm(FormBuilderInterface $builder, array $options)\\n             ->add('url', TextType::class, [\\n                 'label' => $this->trans('URL', 'Modules.Linklist.Admin'),\\n                 'required' => true,\\n+                'constraints' => [new Assert\\\\Url()],\\n             ])\\n         ;\\n     }\"}}",
      "message_norm": "merge pull request from ghsa-cx2r-mf6x-55rx\n\nthe custom url field must be a valid url",
      "language": "en",
      "entities": "[('ghsa-cx2r-mf6x-55rx', 'VULNID', 'GHSA')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Form/Type/CustomUrlType.php'])",
      "num_files": 1.0
    },
    {
      "index": 1546,
      "vuln_id": "GHSA-cfpj-3q4c-jhvr",
      "cwe_id": "{'CWE-369'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/718721986aa137691ee23f03638867151f74935f'}",
      "dataset": "osv",
      "summary": "Division by zero in TFLite ### Impact\nThe implementation of fully connected layers in TFLite is [vulnerable to a division by zero error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/fully_connected.cc#L226):\n\n```cc\nconst int batch_size = input_size / filter->dims->data[1];\n```\n\nAn attacker can craft a model such that `filter->dims->data[1]` is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [718721986aa137691ee23f03638867151f74935f](https://github.com/tensorflow/tensorflow/commit/718721986aa137691ee23f03638867151f74935f).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360. Concurrently, it has also been reported by Yakun Zhang of Baidu Security.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/718721986aa137691ee23f03638867151f74935f",
      "commit_sha": "718721986aa137691ee23f03638867151f74935f",
      "patch": "SINGLE",
      "chain_ord": "['718721986aa137691ee23f03638867151f74935f']",
      "before_first_fix_commit": "{'985f07145a0cab0fd6018fdfc0b221b17e0c5a88'}",
      "last_fix_commit": "718721986aa137691ee23f03638867151f74935f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/16/2021, 13:49:45",
      "message": "Prevent division by 0 in `fully_connected.cc`\n\nPiperOrigin-RevId: 385137282\nChange-Id: If201e69b6e0048f0be001330b4b977e2b46db2cb",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'tensorflow/lite/kernels/fully_connected.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/718721986aa137691ee23f03638867151f74935f/tensorflow%2Flite%2Fkernels%2Ffully_connected.cc', 'patch': '@@ -223,6 +223,7 @@ TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\\n   }\\n \\n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);\\n+  TF_LITE_ENSURE(context, filter->dims->data[1] != 0);\\n   const int batch_size = input_size / filter->dims->data[1];\\n   const int num_units = filter->dims->data[0];'}}",
      "message_norm": "prevent division by 0 in `fully_connected.cc`\n\npiperorigin-revid: 385137282\nchange-id: if201e69b6e0048f0be001330b4b977e2b46db2cb",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('385137282', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/fully_connected.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3405,
      "vuln_id": "GHSA-x9rg-q5fx-fx66",
      "cwe_id": "{'CWE-20'}",
      "score": 6.5,
      "chain": "{'https://github.com/kohsuke/libpam4j/commit/02ffdff218283629ba4a902e7fe2fd44646abc21'}",
      "dataset": "osv",
      "summary": "Improper Input Validation in libpam4j It was found that libpam4j prior to 1.10 did not properly validate user accounts when authenticating. A user with a valid password for a disabled account would be able to bypass security restrictions and possibly access sensitive information.",
      "published_date": "2022-05-13",
      "chain_len": 1,
      "project": "https://github.com/kohsuke/libpam4j",
      "commit_href": "https://github.com/kohsuke/libpam4j/commit/02ffdff218283629ba4a902e7fe2fd44646abc21",
      "commit_sha": "02ffdff218283629ba4a902e7fe2fd44646abc21",
      "patch": "SINGLE",
      "chain_ord": "['02ffdff218283629ba4a902e7fe2fd44646abc21']",
      "before_first_fix_commit": "{'f49e2838cb195b2dce1448393d8c88174ad80652'}",
      "last_fix_commit": "02ffdff218283629ba4a902e7fe2fd44646abc21",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/29/2018, 18:11:55",
      "message": "call pam_acct_mgmt to verify whether the user account is valid.\n\nThis fixes issue #18 and thus CVE-2017-12197",
      "author": "Kohsuke Kawaguchi",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/main/java/org/jvnet/libpam/PAM.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/kohsuke/libpam4j/raw/02ffdff218283629ba4a902e7fe2fd44646abc21/src%2Fmain%2Fjava%2Forg%2Fjvnet%2Flibpam%2FPAM.java', 'patch': '@@ -124,7 +124,7 @@ public UnixUser authenticate(String username, String password) throws PAMExcepti\\n             check(libpam.pam_authenticate(pht,0),\"pam_authenticate failed\");\\n             check(libpam.pam_setcred(pht,0),\"pam_setcred failed\");\\n             // several different error code seem to be used to represent authentication failures\\n-//            check(libpam.pam_acct_mgmt(pht,0),\"pam_acct_mgmt failed\");\\n+            check(libpam.pam_acct_mgmt(pht,0),\"pam_acct_mgmt failed\");\\n \\n             PointerByReference r = new PointerByReference();\\n             check(libpam.pam_get_item(pht,PAM_USER,r),\"pam_get_item failed\");'}}",
      "message_norm": "call pam_acct_mgmt to verify whether the user account is valid.\n\nthis fixes issue #18 and thus cve-2017-12197",
      "language": "en",
      "entities": "[('verify', 'ACTION', ''), ('user account', 'SECWORD', ''), ('#18', 'ISSUE', ''), ('cve-2017-12197', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/main/java/org/jvnet/libpam/PAM.java'])",
      "num_files": 1.0
    },
    {
      "index": 1608,
      "vuln_id": "GHSA-cv3v-7846-6pxm",
      "cwe_id": "{'CWE-552'}",
      "score": 7.5,
      "chain": "{'https://github.com/gabrielcsapo/node-git-server/commit/ac26650f69bc445d71e4f2c55328676d10a4be43'}",
      "dataset": "osv",
      "summary": "Unauthorized File Access in node-git-server Versions of `node-git-server` prior to 0.6.1 are vulnerable to Unauthorized File Access. It is possible to access any git repository by using absolute paths, which may allow attackers to access private repositories.\n\n\n## Recommendation\n\nUpgrade to version 0.6.1 or later.",
      "published_date": "2020-09-03",
      "chain_len": 1,
      "project": "https://github.com/gabrielcsapo/node-git-server",
      "commit_href": "https://github.com/gabrielcsapo/node-git-server/commit/ac26650f69bc445d71e4f2c55328676d10a4be43",
      "commit_sha": "ac26650f69bc445d71e4f2c55328676d10a4be43",
      "patch": "SINGLE",
      "chain_ord": "['ac26650f69bc445d71e4f2c55328676d10a4be43']",
      "before_first_fix_commit": "{'e3ae3737fc9de848856e56a3cf624fe014803f25'}",
      "last_fix_commit": "ac26650f69bc445d71e4f2c55328676d10a4be43",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/29/2020, 17:45:58",
      "message": "Security Issue (#62)\n\nIt is currently possible to overwrite the `repoDir` by sending a repository name that starts with a \"/\", the `path.resolve` method prioritizes the second argument see the example below.\r\n\r\npath.resolve(\"/my/repo/folder\",\"/etc\"); // /etc\r\n\r\nThis behavior gives an attacker the ability to create/write/pull repositories from an arbitrary absolute path, this issue could also impact authentication in some cases as it corrupts the repository name.",
      "author": "Ron Masas",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'lib/git.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/gabrielcsapo/node-git-server/raw/ac26650f69bc445d71e4f2c55328676d10a4be43/lib%2Fgit.js', 'patch': '@@ -143,7 +143,7 @@ class Git extends EventEmitter {\\n         this.dirMap = repoDir;\\n     } else {\\n         this.dirMap = (dir) => {\\n-            return (path.normalize(dir ? path.resolve(repoDir, dir) : repoDir));\\n+            return (path.normalize(dir ? path.join(repoDir, dir) : repoDir));\\n         };\\n     }'}}",
      "message_norm": "security issue (#62)\n\nit is currently possible to overwrite the `repodir` by sending a repository name that starts with a \"/\", the `path.resolve` method prioritizes the second argument see the example below.\r\n\r\npath.resolve(\"/my/repo/folder\",\"/etc\"); // /etc\r\n\r\nthis behavior gives an attacker the ability to create/write/pull repositories from an arbitrary absolute path, this issue could also impact authentication in some cases as it corrupts the repository name.",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('#62', 'ISSUE', ''), ('attacker', 'FLAW', ''), ('issue', 'FLAW', ''), ('authentication', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/git.js'])",
      "num_files": 1.0
    },
    {
      "index": 2734,
      "vuln_id": "GHSA-qc36-q22q-cjw3",
      "cwe_id": "{'CWE-147'}",
      "score": 9.8,
      "chain": "{'https://github.com/lettre/lettre/pull/627/commits/93458d01fed0ec81c0e7b4e98e6f35961356fae2', 'https://github.com/lettre/lettre/commit/8bfc20506cc5e098fe6eb3d1cafe3bea791215ce'}",
      "dataset": "osv",
      "summary": "SMTP command injection in lettre ### Impact\n\nAffected versions of lettre allowed SMTP command injection through an attacker's controlled message body. The module for escaping lines starting with a period wouldn't catch a period that was placed after a double CRLF sequence, allowing the attacker to end the current message and write arbitrary SMTP commands after it.\n\n### Fix\n\nThe flaw is fixed by correctly handling consecutive CRLF sequences.\n\n### References\n\n* [RUSTSEC-2021-0069](https://rustsec.org/advisories/RUSTSEC-2021-0069.html)",
      "published_date": "2021-07-12",
      "chain_len": 2,
      "project": "https://github.com/lettre/lettre",
      "commit_href": "https://github.com/lettre/lettre/commit/8bfc20506cc5e098fe6eb3d1cafe3bea791215ce",
      "commit_sha": "8bfc20506cc5e098fe6eb3d1cafe3bea791215ce",
      "patch": "MULTI",
      "chain_ord": "['93458d01fed0ec81c0e7b4e98e6f35961356fae2', '8bfc20506cc5e098fe6eb3d1cafe3bea791215ce']",
      "before_first_fix_commit": "{'d930c42d5069e344a9dfa84ebe4b60bf3b11ac64'}",
      "last_fix_commit": "8bfc20506cc5e098fe6eb3d1cafe3bea791215ce",
      "chain_ord_pos": 2.0,
      "commit_datetime": "05/22/2021, 17:58:27",
      "message": "fix(transport-smtp): Fix transparency codec - 0.9.x (#628)\n\nCo-authored-by: Paolo Barbolini <paolo@paolo565.org>",
      "author": "Alexis Mousset",
      "comments": null,
      "stats": "{'additions': 11, 'deletions': 2, 'total': 13}",
      "files": "{'lettre/src/smtp/client/mod.rs': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/lettre/lettre/raw/8bfc20506cc5e098fe6eb3d1cafe3bea791215ce/lettre%2Fsrc%2Fsmtp%2Fclient%2Fmod.rs', 'patch': '@@ -51,7 +51,15 @@ impl ClientCodec {\\n                     match self.escape_count {\\n                         0 => self.escape_count = if *byte == b\\'\\\\r\\' { 1 } else { 0 },\\n                         1 => self.escape_count = if *byte == b\\'\\\\n\\' { 2 } else { 0 },\\n-                        2 => self.escape_count = if *byte == b\\'.\\' { 3 } else { 0 },\\n+                        2 => {\\n+                            self.escape_count = if *byte == b\\'.\\' {\\n+                                3\\n+                            } else if *byte == b\\'\\\\r\\' {\\n+                                1\\n+                            } else {\\n+                                0\\n+                            }\\n+                        }\\n                         _ => unreachable!(),\\n                     }\\n                     if self.escape_count == 3 {\\n@@ -286,6 +294,7 @@ mod test {\\n         let mut buf: Vec<u8> = vec![];\\n \\n         assert!(codec.encode(b\"test\\\\r\\\\n\", &mut buf).is_ok());\\n+        assert!(codec.encode(b\"test\\\\r\\\\n\\\\r\\\\n\", &mut buf).is_ok());\\n         assert!(codec.encode(b\".\\\\r\\\\n\", &mut buf).is_ok());\\n         assert!(codec.encode(b\"\\\\r\\\\ntest\", &mut buf).is_ok());\\n         assert!(codec.encode(b\"te\\\\r\\\\n.\\\\r\\\\nst\", &mut buf).is_ok());\\n@@ -296,7 +305,7 @@ mod test {\\n         assert!(codec.encode(b\"test\", &mut buf).is_ok());\\n         assert_eq!(\\n             String::from_utf8(buf).unwrap(),\\n-            \"test\\\\r\\\\n..\\\\r\\\\n\\\\r\\\\ntestte\\\\r\\\\n..\\\\r\\\\nsttesttest.test\\\\n.test\\\\ntest\"\\n+            \"test\\\\r\\\\ntest\\\\r\\\\n\\\\r\\\\n..\\\\r\\\\n\\\\r\\\\ntestte\\\\r\\\\n..\\\\r\\\\nsttesttest.test\\\\n.test\\\\ntest\"\\n         );\\n     }'}}",
      "message_norm": "fix(transport-smtp): fix transparency codec - 0.9.x (#628)\n\nco-authored-by: paolo barbolini <paolo@paolo565.org>",
      "language": "en",
      "entities": "[('fix(transport', 'ACTION', ''), ('fix', 'ACTION', ''), ('#628', 'ISSUE', ''), ('paolo@paolo565.org', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lettre/src/smtp/client/mod.rs'])",
      "num_files": 1.0
    },
    {
      "index": 2277,
      "vuln_id": "GHSA-jmgf-p46x-982h",
      "cwe_id": "{'CWE-352'}",
      "score": 0.0,
      "chain": "{'http://github.com/rails/rails/commit/7282ed863ca7e6f928bae9162c9a63a98775a19d'}",
      "dataset": "osv",
      "summary": "Moderate severity vulnerability that affects rails CRLF injection vulnerability in Ruby on Rails before 2.0.5 allows remote attackers to inject arbitrary HTTP headers and conduct HTTP response splitting attacks via a crafted URL to the redirect_to function.",
      "published_date": "2017-10-24",
      "chain_len": 1,
      "project": "http://github.com/rails/rails",
      "commit_href": "http://github.com/rails/rails/commit/7282ed863ca7e6f928bae9162c9a63a98775a19d",
      "commit_sha": "7282ed863ca7e6f928bae9162c9a63a98775a19d",
      "patch": "SINGLE",
      "chain_ord": "['7282ed863ca7e6f928bae9162c9a63a98775a19d']",
      "before_first_fix_commit": "{'e8577991dcc47bcb11f99fd6582ee2a3f8270498'}",
      "last_fix_commit": "7282ed863ca7e6f928bae9162c9a63a98775a19d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/14/2008, 09:47:27",
      "message": "Sanitize the URLs passed to redirect_to to prevent a potential response spli\n\nCGI.rb and mongrel don't do any sanitization of the contents of HTTP headers",
      "author": "Michael Koziarski",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'actionpack/lib/action_controller/response.rb': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/rails/rails/raw/7282ed863ca7e6f928bae9162c9a63a98775a19d/actionpack%2Flib%2Faction_controller%2Fresponse.rb', 'patch': '@@ -30,9 +30,9 @@ def charset\\n \\n     def redirect(to_url, response_status)\\n       self.headers[\"Status\"] = response_status\\n-      self.headers[\"Location\"] = to_url\\n+      self.headers[\"Location\"] = to_url.gsub(/[\\\\r\\\\n]/, \\'\\')\\n \\n-      self.body = \"<html><body>You are being <a href=\\\\\"#{to_url}\\\\\">redirected</a>.</body></html>\"\\n+      self.body = \"<html><body>You are being <a href=\\\\\"#{CGI.escapeHTML(to_url)}\\\\\">redirected</a>.</body></html>\"\\n     end\\n \\n     def prepare!'}}",
      "message_norm": "sanitize the urls passed to redirect_to to prevent a potential response spli\n\ncgi.rb and mongrel don't do any sanitization of the contents of http headers",
      "language": "en",
      "entities": "[('sanitize', 'SECWORD', ''), ('prevent', 'ACTION', ''), ('sanitization', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['actionpack/lib/action_controller/response.rb'])",
      "num_files": 1.0
    },
    {
      "index": 2171,
      "vuln_id": "GHSA-j259-6c58-9m58",
      "cwe_id": "{'CWE-20'}",
      "score": 9.3,
      "chain": "{'https://github.com/loopbackio/loopback-connector-postgresql/commit/d57406c6737692a3a106b58a35406290cddb23e5'}",
      "dataset": "osv",
      "summary": "loopback-connector-postgresql Vulnerable to Improper Sanitization of `contains` Filter Improper input validation on the `contains` LoopBack filter may allow for arbitrary SQL injection.\n\n### Impact\n\nWhen the extended filter property `contains` is permitted to be interpreted by the Postgres connector, it is possible to inject arbitrary SQL which may affect the confidentiality and integrity of data stored on the connected database.\n\nThis affects users who does any of the following:\n\n- Connect to the database via the DataSource with `allowExtendedProperties: true` setting OR\n- Uses the connector's CRUD methods directly OR\n- Uses the connector's other methods to interpret the LoopBack filter.\n\n### Patches\n\nPatch release `loopback-connector-postgresql@5.5.1` has been published of which resolves this issue.\n\n### Workarounds\n\nUsers who are unable to upgrade should do the following if applicable:\n\n- Remove `allowExtendedProperties: true` DataSource setting\n- Add `allowExtendedProperties: false` DataSource setting\n- When passing directly to the connector functions, manually sanitize the user input for the `contains` LoopBack filter beforehand.",
      "published_date": "2022-08-11",
      "chain_len": 1,
      "project": "https://github.com/loopbackio/loopback-connector-postgresql",
      "commit_href": "https://github.com/loopbackio/loopback-connector-postgresql/commit/d57406c6737692a3a106b58a35406290cddb23e5",
      "commit_sha": "d57406c6737692a3a106b58a35406290cddb23e5",
      "patch": "SINGLE",
      "chain_ord": "['d57406c6737692a3a106b58a35406290cddb23e5']",
      "before_first_fix_commit": "{'1a863f3df332f1732e8fec519f1d686561313a3e'}",
      "last_fix_commit": "d57406c6737692a3a106b58a35406290cddb23e5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/04/2022, 11:27:20",
      "message": "fix: improve filter sanitisation\n\nAdd sanitisation of user-input for `contains` LoopBack filter which may allow for arbitrary SQL injection.\n\nSigned-off-by: Rifa Achrinza <25147899+achrinza@users.noreply.github.com>",
      "author": "Rifa Achrinza",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 3, 'total': 7}",
      "files": "{'lib/postgresql.js': {'additions': 4, 'deletions': 3, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/loopbackio/loopback-connector-postgresql/raw/d57406c6737692a3a106b58a35406290cddb23e5/lib%2Fpostgresql.js', 'patch': \"@@ -545,10 +545,11 @@ PostgreSQL.prototype.buildExpression = function(columnName, operator,\\n       return new ParameterizedSQL(columnName + regexOperator,\\n         [operatorValue.source]);\\n     case 'contains':\\n-      return new ParameterizedSQL(columnName + ' @> array[' + operatorValue.map((v) => `'${v}'`) + ']::'\\n-        + propertyDefinition.postgresql.dataType);\\n+      return new ParameterizedSQL(columnName + ' @> array[' + operatorValue.map(() => '?') + ']::'\\n+        + propertyDefinition.postgresql.dataType,\\n+        operatorValue);\\n     case 'match':\\n-      return new ParameterizedSQL(`to_tsvector(${columnName}) @@ to_tsquery('${operatorValue}')`);\\n+      return new ParameterizedSQL(`to_tsvector(${columnName}) @@ to_tsquery(?)`, [operatorValue]);\\n     default:\\n       // invoke the base implementation of `buildExpression`\\n       return this.invokeSuper('buildExpression', columnName, operator,\"}}",
      "message_norm": "fix: improve filter sanitisation\n\nadd sanitisation of user-input for `contains` loopback filter which may allow for arbitrary sql injection.\n\nsigned-off-by: rifa achrinza <25147899+achrinza@users.noreply.github.com>",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('improve', 'ACTION', ''), ('sanitisation', 'SECWORD', ''), ('add', 'ACTION', ''), ('sanitisation', 'SECWORD', ''), ('sql injection', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/postgresql.js'])",
      "num_files": 1.0
    },
    {
      "index": 3425,
      "vuln_id": "GHSA-xg6r-5gx4-qxjm",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/invoiceninja/invoiceninja/commit/1186eaa82375692d01d5ef3369c5b7bc7315b55f'}",
      "dataset": "osv",
      "summary": "invoiceninja is vulnerable to Cross-site Scripting invoiceninja is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/invoiceninja/invoiceninja",
      "commit_href": "https://github.com/invoiceninja/invoiceninja/commit/1186eaa82375692d01d5ef3369c5b7bc7315b55f",
      "commit_sha": "1186eaa82375692d01d5ef3369c5b7bc7315b55f",
      "patch": "SINGLE",
      "chain_ord": "['1186eaa82375692d01d5ef3369c5b7bc7315b55f']",
      "before_first_fix_commit": "{'ac194665de6728e4091f273ef2e01b4c48369fcd'}",
      "last_fix_commit": "1186eaa82375692d01d5ef3369c5b7bc7315b55f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/10/2021, 03:00:22",
      "message": "Fixes for client password reset",
      "author": "David Bomba",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 6, 'total': 13}",
      "files": "{'app/Http/Controllers/Auth/ContactForgotPasswordController.php': {'additions': 7, 'deletions': 6, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/invoiceninja/invoiceninja/raw/1186eaa82375692d01d5ef3369c5b7bc7315b55f/app%2FHttp%2FControllers%2FAuth%2FContactForgotPasswordController.php', 'patch': \"@@ -93,14 +93,15 @@ public function broker()\\n \\n     public function sendResetLinkEmail(ContactPasswordResetRequest $request)\\n     {\\n-\\n-        if(Ninja::isHosted() && $request->session()->has('company_key'))\\n-            MultiDB::findAndSetDbByCompanyKey($request->session()->get('company_key'));\\n+        if(Ninja::isHosted() && $request->has('company_key'))\\n+            MultiDB::findAndSetDbByCompanyKey($request->input('company_key'));\\n         \\n         $this->validateEmail($request);\\n \\n-        $company = Company::where('company_key', $request->session()->get('company_key'))->first();\\n-        $contact = ClientContact::where(['company_id' => $company->id, 'email' => $request->input('email')])->first();\\n+        // $company = Company::where('company_key', $request->input('company_key'))->first();\\n+        // $contact = ClientContact::where(['company_id' => $company->id, 'email' => $request->input('email')])->first();\\n+\\n+        $contact = ClientContact::where(['email' => $request->input('email')])->first();\\n \\n         $response = false;\\n \\n@@ -117,7 +118,7 @@ public function sendResetLinkEmail(ContactPasswordResetRequest $request)\\n             return $this->sendResetLinkFailedResponse($request, Password::INVALID_USER);\\n \\n         // We will send the password reset link to this user. Once we have attempted\\n-        // to send the link, we will examine the response then see the message we\\n+        // to send the link, we will examine thuser@example.ce response then see the message we\\n         // need to show to the user. Finally, we'll send out a proper response.\\n         // $response = $this->broker()->sendResetLink(\\n         //     $this->credentials($request)\"}}",
      "message_norm": "fixes for client password reset",
      "language": "en",
      "entities": "[('password', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['app/Http/Controllers/Auth/ContactForgotPasswordController.php'])",
      "num_files": 1.0
    },
    {
      "index": 1616,
      "vuln_id": "GHSA-cvpc-8phh-8f45",
      "cwe_id": "{'CWE-787', 'CWE-125'}",
      "score": 4.8,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/00302787b788c5ff04cb6f62aed5a74d936e86c0', 'https://github.com/tensorflow/tensorflow/commit/e11f55585f614645b360563072ffeb5c3eeff162', 'https://github.com/tensorflow/tensorflow/commit/46d5b0852528ddfd614ded79bccc75589f801bd9', 'https://github.com/tensorflow/tensorflow/commit/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'https://github.com/tensorflow/tensorflow/commit/1970c2158b1ffa416d159d03c3370b9a462aee35', 'https://github.com/tensorflow/tensorflow/commit/fff2c8326280c07733828f990548979bdc893859'}",
      "dataset": "osv",
      "summary": "Out of bounds access in tensorflow-lite ### Impact\nIn TensorFlow Lite, saved models in the flatbuffer format use a double indexing scheme: a model has a set of subgraphs, each subgraph has a set of operators and each operator has a set of input/output tensors. The flatbuffer format uses indices for the tensors, indexing into an array of tensors that is owned by the subgraph. This results in a pattern of double array indexing when trying to get the data of each tensor:https://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/lite/kernels/kernel_util.cc#L36\n\nHowever, some operators can have some tensors be optional. To handle this scenario, the flatbuffer model uses a negative `-1` value as index for these tensors:\nhttps://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/lite/c/common.h#L82\n\nThis results in special casing during validation at model loading time: https://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/lite/core/subgraph.cc#L566-L580\n\nUnfortunately, this means that the `-1` index is a valid tensor index for any operator, including those that don't expect optional inputs and including for output tensors. Thus, this allows writing and reading from outside the bounds of heap allocated arrays, although only at a specific offset from the start of these arrays.\n\nThis results in both read and write gadgets, albeit very limited in scope.\n\n### Patches\nWe have patched the issue in several commits (46d5b0852, 00302787b7, e11f5558, cd31fd0ce, 1970c21, and fff2c83). We will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### Workarounds\nA potential workaround would be to add a custom `Verifier` to the model loading code to ensure that only operators which accept optional inputs use the `-1` special value and only for the tensors that they expect to be optional. Since this allow-list type approach is erro-prone, we advise upgrading to the patched code.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2020-09-25",
      "chain_len": 6,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f",
      "commit_sha": "cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f",
      "patch": "MULTI",
      "chain_ord": "['46d5b0852528ddfd614ded79bccc75589f801bd9', '00302787b788c5ff04cb6f62aed5a74d936e86c0', 'e11f55585f614645b360563072ffeb5c3eeff162', 'cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'fff2c8326280c07733828f990548979bdc893859', '1970c2158b1ffa416d159d03c3370b9a462aee35']",
      "before_first_fix_commit": "{'fff2c8326280c07733828f990548979bdc893859'}",
      "last_fix_commit": "1970c2158b1ffa416d159d03c3370b9a462aee35",
      "chain_ord_pos": 4.0,
      "commit_datetime": "09/18/2020, 20:44:32",
      "message": "[tflite]: Insert `nullptr` checks when obtaining tensors.\n\nAs part of ongoing refactoring, `tflite::GetInput`, `tflite::GetOutput`, `tflite::GetTemporary` and `tflite::GetIntermediates` will return `nullptr` in some cases. Hence, we insert the `nullptr` checks on all usages.\n\nWe also insert `nullptr` checks on usages of `tflite::GetVariableInput` and `tflite::GetOptionalInputTensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\nPiperOrigin-RevId: 332518902\nChange-Id: I92eb164a6101ac3cca66090061a9b56a97288236",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 16, 'deletions': 7, 'total': 23}",
      "files": "{'tensorflow/lite/micro/test_helpers.cc': {'additions': 16, 'deletions': 7, 'changes': 23, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f/tensorflow%2Flite%2Fmicro%2Ftest_helpers.cc', 'patch': '@@ -601,7 +601,8 @@ TfLiteStatus SimpleStatefulOp::Prepare(TfLiteContext* context,\\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\\n \\n   // Make sure that the input is in uint8_t with at least 1 data entry.\\n-  const TfLiteTensor* input = tflite::GetInput(context, node, kInputTensor);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\\n   if (input->type != kTfLiteUInt8) return kTfLiteError;\\n   if (NumElements(input->dims) == 0) return kTfLiteError;\\n \\n@@ -622,7 +623,8 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\\n   *data->invoke_count += 1;\\n \\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\\n   const uint8_t* input_data = GetTensorData<uint8_t>(input);\\n   int size = NumElements(input->dims);\\n \\n@@ -641,9 +643,13 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\\n     }\\n   }\\n \\n-  TfLiteTensor* median = GetOutput(context, node, kMedianTensor);\\n+  TfLiteTensor* median;\\n+  TF_LITE_ENSURE_OK(context,\\n+                    GetOutputSafe(context, node, kMedianTensor, &median));\\n   uint8_t* median_data = GetTensorData<uint8_t>(median);\\n-  TfLiteTensor* invoke_count = GetOutput(context, node, kInvokeCount);\\n+  TfLiteTensor* invoke_count;\\n+  TF_LITE_ENSURE_OK(context,\\n+                    GetOutputSafe(context, node, kInvokeCount, &invoke_count));\\n   int32_t* invoke_count_data = GetTensorData<int32_t>(invoke_count);\\n \\n   median_data[0] = sorting_buffer[size / 2];\\n@@ -681,11 +687,14 @@ TfLiteStatus MockCustom::Prepare(TfLiteContext* context, TfLiteNode* node) {\\n }\\n \\n TfLiteStatus MockCustom::Invoke(TfLiteContext* context, TfLiteNode* node) {\\n-  const TfLiteTensor* input = tflite::GetInput(context, node, 0);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\\n   const int32_t* input_data = input->data.i32;\\n-  const TfLiteTensor* weight = tflite::GetInput(context, node, 1);\\n+  const TfLiteTensor* weight;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &weight));\\n   const uint8_t* weight_data = weight->data.uint8;\\n-  TfLiteTensor* output = GetOutput(context, node, 0);\\n+  TfLiteTensor* output;\\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\\n   int32_t* output_data = output->data.i32;\\n   output_data[0] =\\n       0;  // Catch output tensor sharing memory with an input tensor'}}",
      "message_norm": "[tflite]: insert `nullptr` checks when obtaining tensors.\n\nas part of ongoing refactoring, `tflite::getinput`, `tflite::getoutput`, `tflite::gettemporary` and `tflite::getintermediates` will return `nullptr` in some cases. hence, we insert the `nullptr` checks on all usages.\n\nwe also insert `nullptr` checks on usages of `tflite::getvariableinput` and `tflite::getoptionalinputtensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\npiperorigin-revid: 332518902\nchange-id: i92eb164a6101ac3cca66090061a9b56a97288236",
      "language": "en",
      "entities": "[('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('332518902', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/micro/test_helpers.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1677,
      "vuln_id": "GHSA-f6px-w8rh-7r89",
      "cwe_id": "{'CWE-362', 'CWE-732'}",
      "score": 4.7,
      "chain": "{'https://github.com/beego/beego/pull/3975/commits/f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd'}",
      "dataset": "osv",
      "summary": "Data race in Beego The File Session Manager in Beego 1.10.0 allows local users to read session files because there is a race condition involving file creation within a directory with weak permissions.",
      "published_date": "2021-08-02",
      "chain_len": 1,
      "project": "https://github.com/beego/beego",
      "commit_href": "https://github.com/beego/beego/pull/3975/commits/f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd",
      "commit_sha": "f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd",
      "patch": "SINGLE",
      "chain_ord": "['f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd']",
      "before_first_fix_commit": "{'8f3d1c5f42fce57e83e1c3f7d180477595db7cca'}",
      "last_fix_commit": "f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/22/2020, 15:42:54",
      "message": "Change permission mask",
      "author": "Nico Waisman",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'session/sess_file.go': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/beego/beego/raw/f99cbe0fa40936f2f8dd28e70620c559b6e5e2fd/session%2Fsess_file.go', 'patch': '@@ -138,7 +138,7 @@ func (fp *FileProvider) SessionRead(sid string) (Store, error) {\\n \\tfilepder.lock.Lock()\\n \\tdefer filepder.lock.Unlock()\\n \\n-\\terr := os.MkdirAll(path.Join(fp.savePath, string(sid[0]), string(sid[1])), 0777)\\n+\\terr := os.MkdirAll(path.Join(fp.savePath, string(sid[0]), string(sid[1])), 0755)\\n \\tif err != nil {\\n \\t\\tSLogger.Println(err.Error())\\n \\t}\\n@@ -231,7 +231,7 @@ func (fp *FileProvider) SessionRegenerate(oldsid, sid string) (Store, error) {\\n \\t\\treturn nil, fmt.Errorf(\"newsid %s exist\", newSidFile)\\n \\t}\\n \\n-\\terr = os.MkdirAll(newPath, 0777)\\n+\\terr = os.MkdirAll(newPath, 0755)\\n \\tif err != nil {\\n \\t\\tSLogger.Println(err.Error())\\n \\t}'}}",
      "message_norm": "change permission mask",
      "language": "en",
      "entities": "[('change', 'ACTION', ''), ('permission', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['session/sess_file.go'])",
      "num_files": 1.0
    },
    {
      "index": 1405,
      "vuln_id": "GHSA-9m95-8hx6-7p9v",
      "cwe_id": "{'CWE-20'}",
      "score": 5.5,
      "chain": "{'https://github.com/opencontainers/umoci/commit/d9efc31daf2206f7d3fdb839863cf7a576a2eb57'}",
      "dataset": "osv",
      "summary": "Improper input validation in umoci ### Impact\n\numoci 0.4.6 and earlier can be tricked into modifying host files by\ncreating a malicious layer that has a symlink with the name \".\" (or\n\"/\"). Because umoci deletes inodes if they change types, this results in\nthe rootfs directory being replaced with an attacker-controlled symlink.\nSubsequent image layers will then be applied on top of the target of the\nsymlink (which could be any directory on the host filesystem the user\nrunning umoci has access to).\n\nWhile umoci does have defences against symlink-based attacks, they are\nall implemented by resolving things relative to the rootfs directory --\nif the rootfs itself is a symlink, umoci resolves it first.\n\nThis vulnerability affects both \"umoci unpack\" and \"umoci raw unpack\".\n\n### Patches\nThis issue has been patched in umoci 0.4.7, see the references section\nfor the specific commit which fixed this vulnerability.\n\n### Workarounds\nNote that if you use umoci as an unprivileged user (using the --rootless\nflag) then umoci will not be able to overwrite any files that your user\ndoesn't have access to. Other possible mitigations are to run umoci\nunder an LSM profile such as AppArmor or SELinux to restrict the level\nof access it has outside of container image directories.\n\n### References\n* [oss-security public disclosure](https://www.openwall.com/lists/oss-security/2021/04/06/2)\n* [patch](https://github.com/opencontainers/umoci/commit/d9efc31daf2206f7d3fdb839863cf7a576a2eb57)\n\n### Credits\nThanks to Robin Peraglie from Cure53 for discovering and reporting this\nvulnerability.\n\n### For more information\n\nIf you have any questions or comments about this advisory\n* Open an issue in <https://github.com/opencontainers/umoci>.\n* Email us at <security@opencontainers.org>.",
      "published_date": "2022-02-15",
      "chain_len": 1,
      "project": "https://github.com/opencontainers/umoci",
      "commit_href": "https://github.com/opencontainers/umoci/commit/d9efc31daf2206f7d3fdb839863cf7a576a2eb57",
      "commit_sha": "d9efc31daf2206f7d3fdb839863cf7a576a2eb57",
      "patch": "SINGLE",
      "chain_ord": "['d9efc31daf2206f7d3fdb839863cf7a576a2eb57']",
      "before_first_fix_commit": "{'07fa845e5b068dee64dcbf391b456a564a6fcfa6'}",
      "last_fix_commit": "d9efc31daf2206f7d3fdb839863cf7a576a2eb57",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/23/2021, 13:17:06",
      "message": "layer: don't permit / type to be changed on extraction\n\nIf users can change the type of / to a symlink, they can cause umoci to\noverwrite host files. This is obviously bad, and is not caught by the\nrest of our directory escape detection code because the root itself has\nbeen changed to a different directory.\n\nFixes: CVE-2021-29136\nReported-by: Robin Peraglie <robin@cure53.de>\nTested-by: Daniel Dao <dqminh89@gmail.com>\nReviewed-by: Tycho Andersen <tycho@tycho.pizza>\nSigned-off-by: Aleksa Sarai <cyphar@cyphar.com>",
      "author": "Aleksa Sarai",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'oci/layer/tar_extract.go': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/opencontainers/umoci/raw/d9efc31daf2206f7d3fdb839863cf7a576a2eb57/oci%2Flayer%2Ftar_extract.go', 'patch': '@@ -404,6 +404,11 @@ func (te *TarExtractor) UnpackEntry(root string, hdr *tar.Header, r io.Reader) (\\n \\tif filepath.Join(\"/\", hdr.Name) == \"/\" {\\n \\t\\t// If we got an entry for the root, then unsafeDir is the full path.\\n \\t\\tunsafeDir, file = hdr.Name, \".\"\\n+\\t\\t// If we\\'re being asked to change the root type, bail because they may\\n+\\t\\t// change it to a symlink which we could inadvertently follow.\\n+\\t\\tif hdr.Typeflag != tar.TypeDir {\\n+\\t\\t\\treturn errors.New(\"malicious tar entry -- refusing to change type of root directory\")\\n+\\t\\t}\\n \\t}\\n \\tdir, err := securejoin.SecureJoinVFS(root, unsafeDir, te.fsEval)\\n \\tif err != nil {'}}",
      "message_norm": "layer: don't permit / type to be changed on extraction\n\nif users can change the type of / to a symlink, they can cause umoci to\noverwrite host files. this is obviously bad, and is not caught by the\nrest of our directory escape detection code because the root itself has\nbeen changed to a different directory.\n\nfixes: cve-2021-29136\nreported-by: robin peraglie <robin@cure53.de>\ntested-by: daniel dao <dqminh89@gmail.com>\nreviewed-by: tycho andersen <tycho@tycho.pizza>\nsigned-off-by: aleksa sarai <cyphar@cyphar.com>",
      "language": "en",
      "entities": "[('changed', 'ACTION', ''), ('change', 'ACTION', ''), ('symlink', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('changed', 'ACTION', ''), ('fixes', 'ACTION', ''), ('cve-2021-29136', 'VULNID', 'CVE'), ('robin@cure53.de', 'EMAIL', ''), ('dqminh89@gmail.com', 'EMAIL', ''), ('cyphar@cyphar.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['oci/layer/tar_extract.go'])",
      "num_files": 1.0
    },
    {
      "index": 1613,
      "vuln_id": "GHSA-cvpc-8phh-8f45",
      "cwe_id": "{'CWE-787', 'CWE-125'}",
      "score": 4.8,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/00302787b788c5ff04cb6f62aed5a74d936e86c0', 'https://github.com/tensorflow/tensorflow/commit/e11f55585f614645b360563072ffeb5c3eeff162', 'https://github.com/tensorflow/tensorflow/commit/46d5b0852528ddfd614ded79bccc75589f801bd9', 'https://github.com/tensorflow/tensorflow/commit/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'https://github.com/tensorflow/tensorflow/commit/1970c2158b1ffa416d159d03c3370b9a462aee35', 'https://github.com/tensorflow/tensorflow/commit/fff2c8326280c07733828f990548979bdc893859'}",
      "dataset": "osv",
      "summary": "Out of bounds access in tensorflow-lite ### Impact\nIn TensorFlow Lite, saved models in the flatbuffer format use a double indexing scheme: a model has a set of subgraphs, each subgraph has a set of operators and each operator has a set of input/output tensors. The flatbuffer format uses indices for the tensors, indexing into an array of tensors that is owned by the subgraph. This results in a pattern of double array indexing when trying to get the data of each tensor:https://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/lite/kernels/kernel_util.cc#L36\n\nHowever, some operators can have some tensors be optional. To handle this scenario, the flatbuffer model uses a negative `-1` value as index for these tensors:\nhttps://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/lite/c/common.h#L82\n\nThis results in special casing during validation at model loading time: https://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/lite/core/subgraph.cc#L566-L580\n\nUnfortunately, this means that the `-1` index is a valid tensor index for any operator, including those that don't expect optional inputs and including for output tensors. Thus, this allows writing and reading from outside the bounds of heap allocated arrays, although only at a specific offset from the start of these arrays.\n\nThis results in both read and write gadgets, albeit very limited in scope.\n\n### Patches\nWe have patched the issue in several commits (46d5b0852, 00302787b7, e11f5558, cd31fd0ce, 1970c21, and fff2c83). We will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### Workarounds\nA potential workaround would be to add a custom `Verifier` to the model loading code to ensure that only operators which accept optional inputs use the `-1` special value and only for the tensors that they expect to be optional. Since this allow-list type approach is erro-prone, we advise upgrading to the patched code.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2020-09-25",
      "chain_len": 6,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/00302787b788c5ff04cb6f62aed5a74d936e86c0",
      "commit_sha": "00302787b788c5ff04cb6f62aed5a74d936e86c0",
      "patch": "MULTI",
      "chain_ord": "['46d5b0852528ddfd614ded79bccc75589f801bd9', '00302787b788c5ff04cb6f62aed5a74d936e86c0', 'e11f55585f614645b360563072ffeb5c3eeff162', 'cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'fff2c8326280c07733828f990548979bdc893859', '1970c2158b1ffa416d159d03c3370b9a462aee35']",
      "before_first_fix_commit": "{'fff2c8326280c07733828f990548979bdc893859'}",
      "last_fix_commit": "1970c2158b1ffa416d159d03c3370b9a462aee35",
      "chain_ord_pos": 2.0,
      "commit_datetime": "09/18/2020, 20:16:53",
      "message": "[tflite] Make `GetOptionalInputTensor` the same as `GetInput`.\n\nWith the previous change, there is no more need for two separate APIs. We would deprecate `GetOptionalInputTensor` in the future.\n\nPiperOrigin-RevId: 332513386\nChange-Id: Id7110271c25ebd6126ad8c82a493e37e0e0756b3",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 6, 'total': 7}",
      "files": "{'tensorflow/lite/kernels/kernel_util.cc': {'additions': 1, 'deletions': 6, 'changes': 7, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/00302787b788c5ff04cb6f62aed5a74d936e86c0/tensorflow%2Flite%2Fkernels%2Fkernel_util.cc', 'patch': '@@ -75,12 +75,7 @@ TfLiteTensor* GetOutput(TfLiteContext* context, const TfLiteNode* node,\\n \\n const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\\n                                            const TfLiteNode* node, int index) {\\n-  const bool use_tensor = index < node->inputs->size &&\\n-                          node->inputs->data[index] != kTfLiteOptionalTensor;\\n-  if (use_tensor) {\\n-    return GetMutableInput(context, node, index);\\n-  }\\n-  return nullptr;\\n+  return GetInput(context, node, index);\\n }\\n \\n // Per-axis'}}",
      "message_norm": "[tflite] make `getoptionalinputtensor` the same as `getinput`.\n\nwith the previous change, there is no more need for two separate apis. we would deprecate `getoptionalinputtensor` in the future.\n\npiperorigin-revid: 332513386\nchange-id: id7110271c25ebd6126ad8c82a493e37e0e0756b3",
      "language": "en",
      "entities": "[('332513386', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/kernel_util.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2695,
      "vuln_id": "GHSA-q485-j897-qc27",
      "cwe_id": "{'CWE-611'}",
      "score": 9.8,
      "chain": "{'https://github.com/zhutougg/c3p0/commit/2eb0ea97f745740b18dd45e4a909112d4685f87b'}",
      "dataset": "osv",
      "summary": "Moderate severity vulnerability that affects com.mchange:c3p0 c3p0 0.9.5.2 allows XXE in extractXmlConfigFromInputStream in com/mchange/v2/c3p0/cfg/C3P0ConfigXmlUtils.java during initialization.",
      "published_date": "2019-01-07",
      "chain_len": 1,
      "project": "https://github.com/zhutougg/c3p0",
      "commit_href": "https://github.com/zhutougg/c3p0/commit/2eb0ea97f745740b18dd45e4a909112d4685f87b",
      "commit_sha": "2eb0ea97f745740b18dd45e4a909112d4685f87b",
      "patch": "SINGLE",
      "chain_ord": "['2eb0ea97f745740b18dd45e4a909112d4685f87b']",
      "before_first_fix_commit": "{'6796e1d0951b52897531e4ea62252191dacb17b5'}",
      "last_fix_commit": "2eb0ea97f745740b18dd45e4a909112d4685f87b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/20/2018, 13:11:13",
      "message": "Repair XXE vulnerability at initialization",
      "author": "zhutougg",
      "comments": "{'com_1': {'author': 'crazyguyonabike', 'datetime': '01/09/2019, 23:26:09', 'body': 'If this actually fixes the CVE, can you do a PR to the original source and/or make a release?'}, 'com_2': {'author': 'mprins', 'datetime': '02/21/2019, 11:17:44', 'body': 'this is resolved in v.0.9.5.3 in a more elegant way, see: https://github.com/swaldman/c3p0/commit/7dfdda63f42759a5ec9b63d725b7412f74adb3e1'}}",
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'src/java/com/mchange/v2/c3p0/cfg/C3P0ConfigXmlUtils.java': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/zhutougg/c3p0/raw/2eb0ea97f745740b18dd45e4a909112d4685f87b/src%2Fjava%2Fcom%2Fmchange%2Fv2%2Fc3p0%2Fcfg%2FC3P0ConfigXmlUtils.java', 'patch': '@@ -144,6 +144,7 @@ public static C3P0Config extractXmlConfigFromDefaultResource() throws Exception\\n     public static C3P0Config extractXmlConfigFromInputStream(InputStream is) throws Exception\\n     {\\n         DocumentBuilderFactory fact = DocumentBuilderFactory.newInstance();\\n+\\tfact.setExpandEntityReferences(false);\\n         DocumentBuilder db = fact.newDocumentBuilder();\\n         Document doc = db.parse( is );'}}",
      "message_norm": "repair xxe vulnerability at initialization",
      "language": "en",
      "entities": "[('xxe', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('initialization', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/java/com/mchange/v2/c3p0/cfg/C3P0ConfigXmlUtils.java'])",
      "num_files": 1.0
    },
    {
      "index": 369,
      "vuln_id": "GHSA-46c5-pfj8-fv65",
      "cwe_id": "{'CWE-704'}",
      "score": 7.5,
      "chain": "{'https://github.com/pmmp/PocketMine-MP/commit/c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1'}",
      "dataset": "osv",
      "summary": "Improperly checked metadata on tools/armour itemstacks received from the client ### Impact\nDue to a workaround applied in 1.13, an attacker may send a negative damage/meta value in a tool or armour item's NBT, which `TypeConverter` then blindly uses as if it was valid without being checked.\n\nWhen this invalid metadata value reaches `Durable->setDamage()`, an exception is thrown because the metadata is not within the expected range for damage values.\n\nThis can be reproduced with either a too-large damage value, or a negative one.\n\n### Patches\nc8e1cfcbee4945fd4b63d2a7e96025c59744d4f1\n\n### Workarounds\nIn theory this can be checked by plugins using a custom `TypeConverter`, but this is likely to be very cumbersome.\n\n### For more information\n* Email us at [team@pmmp.io](mailto:team@pmmp.io)",
      "published_date": "2022-03-18",
      "chain_len": 1,
      "project": "https://github.com/pmmp/PocketMine-MP",
      "commit_href": "https://github.com/pmmp/PocketMine-MP/commit/c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1",
      "commit_sha": "c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1",
      "patch": "SINGLE",
      "chain_ord": "['c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1']",
      "before_first_fix_commit": "{'869dda9a45a12028243cae590552458ce970ec18'}",
      "last_fix_commit": "c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/15/2022, 23:44:41",
      "message": "TypeConverter: account for possible out-of-range meta in items",
      "author": "Dylan K. Taylor",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'src/network/mcpe/convert/TypeConverter.php': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/pmmp/PocketMine-MP/raw/c8e1cfcbee4945fd4b63d2a7e96025c59744d4f1/src%2Fnetwork%2Fmcpe%2Fconvert%2FTypeConverter.php', 'patch': '@@ -232,6 +232,9 @@ public function netItemStackToCore(ItemStack $itemStack) : Item{\\n \\t\\t\\t\\t$compound = null;\\n \\t\\t\\t}\\n \\t\\t}\\n+\\t\\tif($meta < 0 || $meta >= 0x7fff){ //this meta value may have been restored from the NBT\\n+\\t\\t\\tthrow new TypeConversionException(\"Item meta must be in range 0 ... \" . 0x7fff . \" (received $meta)\");\\n+\\t\\t}\\n \\n \\t\\ttry{\\n \\t\\t\\treturn ItemFactory::getInstance()->get('}}",
      "message_norm": "typeconverter: account for possible out-of-range meta in items",
      "language": "en",
      "entities": "[('out-of-range', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/network/mcpe/convert/TypeConverter.php'])",
      "num_files": 1.0
    },
    {
      "index": 1754,
      "vuln_id": "GHSA-fpcp-9h7m-ffpx",
      "cwe_id": "{'CWE-476'}",
      "score": 5.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/e21af685e1828f7ca65038307df5cc06de4479e8'}",
      "dataset": "osv",
      "summary": "Null pointer dereference in TensorFlow  ### Impact\nWhen [building an XLA compilation cache](https://github.com/tensorflow/tensorflow/blob/274df9b02330b790aa8de1cee164b70f72b9b244/tensorflow/compiler/jit/xla_platform_info.cc#L43-L104), if default settings are used, TensorFlow triggers a null pointer dereference:\n\n```cc \n  string allowed_gpus =\n      flr->config_proto()->gpu_options().visible_device_list();\n``` \n    \nIn the default scenario, all devices are allowed, so `flr->config_proto` is `nullptr`.\n    \n### Patches\nWe have patched the issue in GitHub commit [e21af685e1828f7ca65038307df5cc06de4479e8](https://github.com/tensorflow/tensorflow/commit/e21af685e1828f7ca65038307df5cc06de4479e8).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/e21af685e1828f7ca65038307df5cc06de4479e8",
      "commit_sha": "e21af685e1828f7ca65038307df5cc06de4479e8",
      "patch": "SINGLE",
      "chain_ord": "['e21af685e1828f7ca65038307df5cc06de4479e8']",
      "before_first_fix_commit": "{'30f8e5c460629a9f8dbb04dc562c7b579c07f11b'}",
      "last_fix_commit": "e21af685e1828f7ca65038307df5cc06de4479e8",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/08/2022, 00:20:27",
      "message": "Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be",
      "author": "Smit Hinsu",
      "comments": null,
      "stats": "{'additions': 7, 'deletions': 5, 'total': 12}",
      "files": "{'tensorflow/compiler/jit/xla_platform_info.cc': {'additions': 7, 'deletions': 5, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/e21af685e1828f7ca65038307df5cc06de4479e8/tensorflow%2Fcompiler%2Fjit%2Fxla_platform_info.cc', 'patch': '@@ -82,11 +82,13 @@ Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\\n   client_options.set_intra_op_parallelism_threads(\\n       device->tensorflow_cpu_worker_threads()->num_threads);\\n \\n-  string allowed_gpus =\\n-      flr->config_proto()->gpu_options().visible_device_list();\\n-  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\\n-                      ParseVisibleDeviceList(allowed_gpus));\\n-  client_options.set_allowed_devices(gpu_ids);\\n+  if (flr->config_proto()) {\\n+    string allowed_gpus =\\n+        flr->config_proto()->gpu_options().visible_device_list();\\n+    TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\\n+                        ParseVisibleDeviceList(allowed_gpus));\\n+    client_options.set_allowed_devices(gpu_ids);\\n+  }\\n \\n   auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\\n   if (!client.ok()) {'}}",
      "message_norm": "fix null-pointer dereference in buildxlacompilationcache\n\nif configproto is not used, then use the default settings which is to allow all devices.\n\npiperorigin-revid: 420391800\nchange-id: i88161ad7042990aef678e77b597a2fb2c8f815be",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('null-pointer dereference', 'SECWORD', ''), ('420391800', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/compiler/jit/xla_platform_info.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1212,
      "vuln_id": "GHSA-8gvg-8vhf-h26g",
      "cwe_id": "{'CWE-787'}",
      "score": 7.5,
      "chain": "{'https://github.com/chakra-core/ChakraCore/commit/d797e3f00e34c12c8c0ae52f56344325439dccd7', 'https://github.com/chakra-core/ChakraCore/commit/7827e117753052d479fabe19a25cfece88059bca'}",
      "dataset": "osv",
      "summary": "Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-0912, CVE-2019-0913, CVE-2019-0914, CVE-2019-0915, CVE-2019-0916, CVE-2019-0917, CVE-2019-0922, CVE-2019-0923, CVE-2019-0924, CVE-2019-0925, CVE-2019-0927, CVE-2019-0933.",
      "published_date": "2021-03-29",
      "chain_len": 2,
      "project": "https://github.com/chakra-core/ChakraCore",
      "commit_href": "https://github.com/chakra-core/ChakraCore/commit/7827e117753052d479fabe19a25cfece88059bca",
      "commit_sha": "7827e117753052d479fabe19a25cfece88059bca",
      "patch": "MULTI",
      "chain_ord": "['7827e117753052d479fabe19a25cfece88059bca', 'd797e3f00e34c12c8c0ae52f56344325439dccd7']",
      "before_first_fix_commit": "{'ea0491305137183603bf43844b5584d4cc972e28', '4594e340bc9ca9f857010a68e8b562d65b46eed6'}",
      "last_fix_commit": "d797e3f00e34c12c8c0ae52f56344325439dccd7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/17/2019, 22:42:35",
      "message": "[CVE-2019-0937]",
      "author": "Paul Leathers",
      "comments": null,
      "stats": "{'additions': 10, 'deletions': 0, 'total': 10}",
      "files": "{'lib/Runtime/ByteCode/ByteCodeEmitter.cpp': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/chakra-core/ChakraCore/raw/7827e117753052d479fabe19a25cfece88059bca/lib%2FRuntime%2FByteCode%2FByteCodeEmitter.cpp', 'patch': '@@ -4006,6 +4006,11 @@ void ByteCodeGenerator::StartEmitCatch(ParseNodeCatch *pnodeCatch)\\n                 sym->SetIsGlobalCatch(true);\\n             }\\n \\n+            if (sym->NeedsScopeObject())\\n+            {\\n+                scope->SetIsObject();\\n+            }\\n+\\n             Assert(sym->GetScopeSlot() == Js::Constants::NoProperty);\\n             if (sym->NeedsSlotAlloc(this, funcInfo))\\n             {\\n@@ -4029,6 +4034,11 @@ void ByteCodeGenerator::StartEmitCatch(ParseNodeCatch *pnodeCatch)\\n             sym->SetIsGlobalCatch(true);\\n         }\\n \\n+        if (sym->NeedsScopeObject())\\n+        {\\n+            scope->SetIsObject();\\n+        }\\n+\\n         if (scope->GetMustInstantiate())\\n         {\\n             if (sym->IsInSlot(this, funcInfo))'}}",
      "message_norm": "[cve-2019-0937]",
      "language": "ro",
      "entities": "[('cve-2019-0937', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/Runtime/ByteCode/ByteCodeEmitter.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 288,
      "vuln_id": "GHSA-3pg8-c473-w6rr",
      "cwe_id": "{'CWE-79'}",
      "score": 6.9,
      "chain": "{'https://github.com/star7th/showdoc/commit/3caa32334db0c277b84e993eaca2036f5d1dbef8'}",
      "dataset": "osv",
      "summary": "Stored Cross-site Scripting in showdoc ShowDoc is a tool for an IT team to share documents online. showdoc contains a stored cross-site scripting vulnerability in the File Library page when uploading a file in .ofd format in versions prior to 2.10.4. At this time, there is no known workaround. Users should update to version 2.10.4.",
      "published_date": "2022-03-16",
      "chain_len": 1,
      "project": "https://github.com/star7th/showdoc",
      "commit_href": "https://github.com/star7th/showdoc/commit/3caa32334db0c277b84e993eaca2036f5d1dbef8",
      "commit_sha": "3caa32334db0c277b84e993eaca2036f5d1dbef8",
      "patch": "SINGLE",
      "chain_ord": "['3caa32334db0c277b84e993eaca2036f5d1dbef8']",
      "before_first_fix_commit": "{'92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f'}",
      "last_fix_commit": "3caa32334db0c277b84e993eaca2036f5d1dbef8",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2022, 15:26:49",
      "message": "Upload file vulnerability",
      "author": "star7th",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 7, 'total': 12}",
      "files": "{'server/Application/Api/Model/AttachmentModel.class.php': {'additions': 5, 'deletions': 7, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/star7th/showdoc/raw/3caa32334db0c277b84e993eaca2036f5d1dbef8/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -54,10 +54,10 @@ public function deleteFile($file_id){\\n \\t}\\n \\n \\t//\u4e0a\u4f20\u6587\u4ef6\uff0c\u8fd4\u56deurl\\n-\\tpublic function upload($_files , $file_key , $uid , $item_id = 0  , $page_id = 0  ){\\n+\\tpublic function upload($_files , $file_key , $uid , $item_id = 0  , $page_id = 0 , $check_filename = true  ){\\n \\t\\t$uploadFile = $_files[$file_key] ;\\n \\n-\\t\\tif( !$this->isAllowedFilename($_files[$file_key]['name']) ){\\n+\\t\\tif( $check_filename && !$this->isAllowedFilename($_files[$file_key]['name']) ){\\n \\t\\t\\treturn false;\\n \\t\\t}\\n \\n@@ -324,14 +324,12 @@ public function isDangerFilename($filename){\\n \\tpublic function isAllowedFilename($filename){\\n \\t\\t$allow_array = array(\\n \\t\\t\\t'.jpg','.jpeg','.png','.bmp','.gif','.ico','.webp',\\n-\\t\\t\\t'.mp3','.wav','.mp4',\\n-\\t\\t\\t'.mov','.webmv','.flac','.mkv',\\n+\\t\\t\\t'.mp3','.wav','.mp4','.mov','.flac','.mkv',\\n \\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso',\\n-\\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n-\\t\\t\\t'.doc','.docx','.wps',\\n+\\t\\t\\t'.pdf','.epub','.xps','.doc','.docx','.wps',\\n \\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\\n \\t\\t\\t'.cer','.ppt','.pub','.json','.css',\\n-\\t\\t\\t) ;\\n+\\t\\t) ;\\n \\n \\t\\t$ext = strtolower(substr($filename,strripos($filename,'.')) ); //\u83b7\u53d6\u6587\u4ef6\u6269\u5c55\u540d\uff08\u8f6c\u4e3a\u5c0f\u5199\u540e\uff09\\n \\t\\tif(in_array( $ext , $allow_array ) ){\"}}",
      "message_norm": "upload file vulnerability",
      "language": "ro",
      "entities": "[('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/Application/Api/Model/AttachmentModel.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 1031,
      "vuln_id": "GHSA-7gfg-6934-mqq2",
      "cwe_id": "{'CWE-287'}",
      "score": 5.6,
      "chain": "{'https://github.com/pion/dtls/commit/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0'}",
      "dataset": "osv",
      "summary": "Improper Authenication in Pion DTLS handleIncomingPacket in conn.go in Pion DTLS before 1.5.2 lacks a check for application data with epoch 0, which allows remote attackers to inject arbitrary unencrypted data after handshake completion.",
      "published_date": "2021-06-29",
      "chain_len": 1,
      "project": "https://github.com/pion/dtls",
      "commit_href": "https://github.com/pion/dtls/commit/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
      "commit_sha": "fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
      "patch": "SINGLE",
      "chain_ord": "['fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0']",
      "before_first_fix_commit": "{'82948855ecb86a9e0b86c8dd43d010cbc545dc94'}",
      "last_fix_commit": "fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/11/2019, 09:12:16",
      "message": "Assert that ApplicationData has epoch != 0\n\nOtherwise we may accept unencrypted/unauthenticated ApplicationData\nfrom a remote",
      "author": "Sean DuBois",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'conn.go': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/pion/dtls/raw/fd73a5df2ff0e1fb6ae6a51e2777d7a16cc4f4e0/conn.go', 'patch': '@@ -559,6 +559,10 @@ func (c *Conn) handleIncomingPacket(buf []byte) (*alert, error) {\\n \\t\\tc.log.Trace(\"<- ChangeCipherSpec\")\\n \\t\\tc.setRemoteEpoch(c.getRemoteEpoch() + 1)\\n \\tcase *applicationData:\\n+\\t\\tif h.epoch == 0 {\\n+\\t\\t\\treturn &alert{alertLevelFatal, alertUnexpectedMessage}, fmt.Errorf(\"ApplicationData with epoch of 0\")\\n+\\t\\t}\\n+\\n \\t\\tc.decrypted <- content.data\\n \\tdefault:\\n \\t\\treturn &alert{alertLevelFatal, alertUnexpectedMessage}, fmt.Errorf(\"unhandled contentType %d\", content.contentType())'}}",
      "message_norm": "assert that applicationdata has epoch != 0\n\notherwise we may accept unencrypted/unauthenticated applicationdata\nfrom a remote",
      "language": "en",
      "entities": "[('unencrypted', 'SECWORD', ''), ('unauthenticated', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['conn.go'])",
      "num_files": 1.0
    },
    {
      "index": 227,
      "vuln_id": "GHSA-393f-2jr3-cp69",
      "cwe_id": "{'CWE-754'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/b432a38fe0e1b4b904a6c222cbce794c39703e87'}",
      "dataset": "osv",
      "summary": "CHECK-fail in DrawBoundingBoxes ### Impact\nAn attacker can trigger a denial of service via a `CHECK` failure by passing an empty image to `tf.raw_ops.DrawBoundingBoxes`:\n\n```python\nimport tensorflow as tf\n\nimages = tf.fill([53, 0, 48, 1], 0.)\nboxes = tf.fill([53, 31, 4], 0.)\nboxes = tf.Variable(boxes)\nboxes[0, 0, 0].assign(3.90621)\ntf.raw_ops.DrawBoundingBoxes(images=images, boxes=boxes)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/ea34a18dc3f5c8d80a40ccca1404f343b5d55f91/tensorflow/core/kernels/image/draw_bounding_box_op.cc#L148-L165) uses `CHECK_*` assertions instead of `OP_REQUIRES` to validate user controlled inputs. Whereas `OP_REQUIRES` allows returning an error condition back to the user, the `CHECK_*` macros result in a crash if the condition is false, similar to `assert`.\n\n```cc\nconst int64 max_box_row_clamp = std::min<int64>(max_box_row, height - 1);\n... \nCHECK_GE(max_box_row_clamp, 0);\n``` \n    \nIn this case, `height` is 0 from the `images` input. This results in `max_box_row_clamp` being negative and the assertion being falsified, followed by aborting program execution.\n    \n### Patches\nWe have patched the issue in GitHub commit [b432a38fe0e1b4b904a6c222cbce794c39703e87](https://github.com/tensorflow/tensorflow/commit/b432a38fe0e1b4b904a6c222cbce794c39703e87).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/b432a38fe0e1b4b904a6c222cbce794c39703e87",
      "commit_sha": "b432a38fe0e1b4b904a6c222cbce794c39703e87",
      "patch": "SINGLE",
      "chain_ord": "['b432a38fe0e1b4b904a6c222cbce794c39703e87']",
      "before_first_fix_commit": "{'ea34a18dc3f5c8d80a40ccca1404f343b5d55f91'}",
      "last_fix_commit": "b432a38fe0e1b4b904a6c222cbce794c39703e87",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/21/2021, 22:57:36",
      "message": "Fix overflow CHECK issue with `tf.raw_ops.DrawBoundingBoxes`.\n\nPiperOrigin-RevId: 369753591\nChange-Id: I3b45fc98ee0d28a3c20b7e9c995aa647c976ec40",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 36, 'deletions': 12, 'total': 48}",
      "files": "{'tensorflow/core/kernels/image/draw_bounding_box_op.cc': {'additions': 36, 'deletions': 12, 'changes': 48, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/b432a38fe0e1b4b904a6c222cbce794c39703e87/tensorflow%2Fcore%2Fkernels%2Fimage%2Fdraw_bounding_box_op.cc', 'patch': '@@ -147,22 +147,46 @@ class DrawBoundingBoxesOp : public OpKernel {\\n \\n         // At this point, {min,max}_box_{row,col}_clamp are inside the\\n         // image.\\n-        CHECK_GE(min_box_row_clamp, 0);\\n-        CHECK_GE(max_box_row_clamp, 0);\\n-        CHECK_LT(min_box_row_clamp, height);\\n-        CHECK_LT(max_box_row_clamp, height);\\n-        CHECK_GE(min_box_col_clamp, 0);\\n-        CHECK_GE(max_box_col_clamp, 0);\\n-        CHECK_LT(min_box_col_clamp, width);\\n-        CHECK_LT(max_box_col_clamp, width);\\n+        OP_REQUIRES(\\n+            context, min_box_row_clamp >= 0,\\n+            errors::InvalidArgument(\"Min box row clamp is less than 0.\"));\\n+        OP_REQUIRES(\\n+            context, max_box_row_clamp >= 0,\\n+            errors::InvalidArgument(\"Max box row clamp is less than 0.\"));\\n+        OP_REQUIRES(context, min_box_row_clamp <= height,\\n+                    errors::InvalidArgument(\\n+                        \"Min box row clamp is greater than height.\"));\\n+        OP_REQUIRES(context, max_box_row_clamp <= height,\\n+                    errors::InvalidArgument(\\n+                        \"Max box row clamp is greater than height.\"));\\n+\\n+        OP_REQUIRES(\\n+            context, min_box_col_clamp >= 0,\\n+            errors::InvalidArgument(\"Min box col clamp is less than 0.\"));\\n+        OP_REQUIRES(\\n+            context, max_box_col_clamp >= 0,\\n+            errors::InvalidArgument(\"Max box col clamp is less than 0.\"));\\n+        OP_REQUIRES(context, min_box_col_clamp <= width,\\n+                    errors::InvalidArgument(\\n+                        \"Min box col clamp is greater than width.\"));\\n+        OP_REQUIRES(context, max_box_col_clamp <= width,\\n+                    errors::InvalidArgument(\\n+                        \"Max box col clamp is greater than width.\"));\\n \\n         // At this point, the min_box_row and min_box_col are either\\n         // in the image or above/left of it, and max_box_row and\\n         // max_box_col are either in the image or below/right or it.\\n-        CHECK_LT(min_box_row, height);\\n-        CHECK_GE(max_box_row, 0);\\n-        CHECK_LT(min_box_col, width);\\n-        CHECK_GE(max_box_col, 0);\\n+\\n+        OP_REQUIRES(\\n+            context, min_box_row <= height,\\n+            errors::InvalidArgument(\"Min box row is greater than height.\"));\\n+        OP_REQUIRES(context, max_box_row >= 0,\\n+                    errors::InvalidArgument(\"Max box row is less than 0.\"));\\n+        OP_REQUIRES(\\n+            context, min_box_col <= width,\\n+            errors::InvalidArgument(\"Min box col is greater than width.\"));\\n+        OP_REQUIRES(context, max_box_col >= 0,\\n+                    errors::InvalidArgument(\"Max box col is less than 0.\"));\\n \\n         // Draw top line.\\n         if (min_box_row >= 0) {'}}",
      "message_norm": "fix overflow check issue with `tf.raw_ops.drawboundingboxes`.\n\npiperorigin-revid: 369753591\nchange-id: i3b45fc98ee0d28a3c20b7e9c995aa647c976ec40",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('369753591', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/image/draw_bounding_box_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 279,
      "vuln_id": "GHSA-3mw4-6rj6-74g5",
      "cwe_id": "{'CWE-476'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/53b0dd6dc5957652f35964af16b892ec9af4a559'}",
      "dataset": "osv",
      "summary": "Null pointer dereference in TensorFlow ### Impact \nThe [implementation of `QuantizedMaxPool`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/kernels/quantized_pooling_ops.cc#L114-L130) has an undefined behavior where user controlled inputs can trigger a reference binding to null pointer.\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizedMaxPool(\n    input = tf.constant([[[[4]]]], dtype=tf.quint8),\n    min_input = [],\n    max_input = [1],\n    ksize = [1, 1, 1, 1],\n    strides = [1, 1, 1, 1],\n    padding = \"SAME\", name=None\n)\n```\n\n### Patches\nWe have patched the issue in GitHub commit [53b0dd6dc5957652f35964af16b892ec9af4a559](https://github.com/tensorflow/tensorflow/commit/53b0dd6dc5957652f35964af16b892ec9af4a559).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Faysal Hossain Shezan from University of Virginia.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/53b0dd6dc5957652f35964af16b892ec9af4a559",
      "commit_sha": "53b0dd6dc5957652f35964af16b892ec9af4a559",
      "patch": "SINGLE",
      "chain_ord": "['53b0dd6dc5957652f35964af16b892ec9af4a559']",
      "before_first_fix_commit": "{'19cff800e5805097da69bb1ad0b0a2dd9f83741a'}",
      "last_fix_commit": "53b0dd6dc5957652f35964af16b892ec9af4a559",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/03/2021, 18:02:20",
      "message": "Fix nullptr exception in QuantizedMaxPool op when empty list is sent to min_input or max_input parameters.\n\nPiperOrigin-RevId: 413960973\nChange-Id: I9e3ded593f3c4eabf0d6d5dc356e6a19a3ad2682",
      "author": "Isha Arkatkar",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 0, 'total': 14}",
      "files": "{'tensorflow/core/kernels/quantized_pooling_ops.cc': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/53b0dd6dc5957652f35964af16b892ec9af4a559/tensorflow%2Fcore%2Fkernels%2Fquantized_pooling_ops.cc', 'patch': '@@ -15,6 +15,8 @@ limitations under the License.\\n \\n // See docs in ../ops/nn_ops.cc.\\n \\n+#include \"tensorflow/core/framework/op_requires.h\"\\n+#include \"tensorflow/core/platform/errors.h\"\\n #define EIGEN_USE_THREADS\\n \\n #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\\n@@ -117,6 +119,18 @@ class QuantizedMaxPoolingOp : public MaxPoolingOp<Device, T> {\\n       : MaxPoolingOp<Device, T>(context) {}\\n \\n   void Compute(OpKernelContext* context) override {\\n+    auto min_input_tensor = context->input(1);\\n+    auto max_input_tensor = context->input(2);\\n+    OP_REQUIRES(\\n+        context, min_input_tensor.NumElements() == 1,\\n+        errors::InvalidArgument(\\n+            \"min_input must be a scalar float value, got tensor with shape \",\\n+            min_input_tensor.shape()));\\n+    OP_REQUIRES(\\n+        context, max_input_tensor.NumElements() == 1,\\n+        errors::InvalidArgument(\\n+            \"max_input must be a scalar float value, got tensor with shape \",\\n+            max_input_tensor.shape()));\\n     const float min_input = context->input(1).flat<float>()(0);\\n     const float max_input = context->input(2).flat<float>()(0);\\n     MaxPoolingOp<Device, T>::Compute(context);'}}",
      "message_norm": "fix nullptr exception in quantizedmaxpool op when empty list is sent to min_input or max_input parameters.\n\npiperorigin-revid: 413960973\nchange-id: i9e3ded593f3c4eabf0d6d5dc356e6a19a3ad2682",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('nullptr exception', 'SECWORD', ''), ('413960973', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/quantized_pooling_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 429,
      "vuln_id": "GHSA-4h66-vghf-xg5x",
      "cwe_id": "{'CWE-77'}",
      "score": 9.8,
      "chain": "{'https://github.com/hoperyy/get-npm-package-version/commit/49459d4a3ce68587d48ffa8dead86fc9ed58e965', 'https://github.com/hoperyy/get-npm-package-version/commit/40b1cf31a0607ea66f9e30a0c3af1383b52b2dec'}",
      "dataset": "osv",
      "summary": "get-npm-package-version Command Injection vulnerability The package get-npm-package-version before 1.0.7 is vulnerable to Command Injection via the `main` function in index.js.",
      "published_date": "2022-08-03",
      "chain_len": 2,
      "project": "https://github.com/hoperyy/get-npm-package-version",
      "commit_href": "https://github.com/hoperyy/get-npm-package-version/commit/49459d4a3ce68587d48ffa8dead86fc9ed58e965",
      "commit_sha": "49459d4a3ce68587d48ffa8dead86fc9ed58e965",
      "patch": "MULTI",
      "chain_ord": "['40b1cf31a0607ea66f9e30a0c3af1383b52b2dec', '49459d4a3ce68587d48ffa8dead86fc9ed58e965']",
      "before_first_fix_commit": "{'52797864df09049ea28d65d14620774257a965b0'}",
      "last_fix_commit": "49459d4a3ce68587d48ffa8dead86fc9ed58e965",
      "chain_ord_pos": 2.0,
      "commit_datetime": "01/26/2021, 03:55:57",
      "message": "feat: add test case for Command Injection Attack\n\nadd test case for  Command Injection Attack",
      "author": "DuLinRain",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 1, 'total': 10}",
      "files": "{'test/index.test.js': {'additions': 9, 'deletions': 1, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/hoperyy/get-npm-package-version/raw/49459d4a3ce68587d48ffa8dead86fc9ed58e965/test%2Findex.test.js', 'patch': \"@@ -16,4 +16,12 @@ describe('test webpack and webpackxxx', () => {\\n         });\\n         expect(version).to.be.equal(null);\\n     }).timeout(10 * 1000);\\n-});\\n\\\\ No newline at end of file\\n+\\n+    // test defence attack\\n+    it('test defence Command Injection Attack', () => {\\n+        const version = getVersion('get-npm-package-version; echo hehe; npm view get-npm-package-version', {\\n+            timeout: 100\\n+        });\\n+        expect(version).to.be.equal(null);\\n+    }).timeout(10 * 1000);\\n+});\"}}",
      "message_norm": "feat: add test case for command injection attack\n\nadd test case for  command injection attack",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('command injection', 'SECWORD', ''), ('attack', 'FLAW', ''), ('add', 'ACTION', ''), ('command injection', 'SECWORD', ''), ('attack', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['test/index.test.js'])",
      "num_files": 1.0
    },
    {
      "index": 3313,
      "vuln_id": "GHSA-wqwf-x5cj-rg56",
      "cwe_id": "{'CWE-78'}",
      "score": 7.1,
      "chain": "{'https://github.com/kubernetes/kubernetes/commit/d65039c56ce4de5f2efdc38aa1284eeb95f89169'}",
      "dataset": "osv",
      "summary": "Arbitrary Command Injection In Kubernetes versions 1.9.0-1.9.9, 1.10.0-1.10.5, and 1.11.0-1.11.1, user input was handled insecurely while setting up volume mounts on Windows nodes, which could lead to command line argument injection.",
      "published_date": "2022-02-15",
      "chain_len": 1,
      "project": "https://github.com/kubernetes/kubernetes",
      "commit_href": "https://github.com/kubernetes/kubernetes/commit/d65039c56ce4de5f2efdc38aa1284eeb95f89169",
      "commit_sha": "d65039c56ce4de5f2efdc38aa1284eeb95f89169",
      "patch": "SINGLE",
      "chain_ord": "['d65039c56ce4de5f2efdc38aa1284eeb95f89169']",
      "before_first_fix_commit": "{'dc0afb24d138220cb53d9be3298f1539b0be4f7a', '27bc865cc1bffb97d4dff38492aa9f830f859e45'}",
      "last_fix_commit": "d65039c56ce4de5f2efdc38aa1284eeb95f89169",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/03/2018, 13:16:06",
      "message": "Merge pull request #65751 from andyzhangx/mount-windows-fix\n\nAutomatic merge from submit-queue (batch tested with PRs 65381, 65751). If you want to cherry-pick this change to another branch, please follow the instructions <a href=\"https://github.com/kubernetes/community/blob/master/contributors/devel/cherry-picks.md\">here</a>.\n\nfix smb mount security issue\n\n**What this PR does / why we need it**:\r\nfix smb mount security issue:\r\nuser PowerShell Environment Variables to store user input string to prevent command line injection, the env var in PowerShell would be taken as literal values and not as executable vulnerable code, this kind of fix is common for command line injection issue (called: parameterized way)\r\n\r\nOriginally use go sdk for `New-SmbGlobalMapping` is best solution, while after discussion with Windows team, go API for `New-SmbGlobalMapping` is not ready yet and the new functionality of basic win32 API [NetUseAdd](https://msdn.microsoft.com/en-us/library/windows/desktop/aa370645(v=vs.85).aspx) is not public yet, use [PowerShell with Environment Variables](https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_environment_variables?view=powershell-5.1) is also their recommended way.\r\n\r\n**Which issue(s) this PR fixes** *(optional, in `fixes #<issue number>(, fixes #<issue_number>, ...)` format, will close the issue(s) when PR gets merged)*:\r\nFixes #65750 \r\n\r\n**Special notes for your reviewer**:\r\n - This is a security issue fix, no behavior change, E2E test of smb mount passes.\r\n - Original logging as `azureMount` is incorrect since this mount_windows is for mount disk & smb, it's a common feature on Windows, not specific to Azure, I will send another PR to fixing all the logging naming issue, anyway it's not related to this security issue. Let's keep this PR simple.\r\n\r\n**Release note**:\r\n\r\n```\r\nfix smb mount security issue\r\n```\r\n\r\n/sig windows\r\n/sig storage\r\n/kind bug\r\n\r\n@jessfraz \r\n/assign @jsafrane @msau42",
      "author": "Kubernetes Submit Queue",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 6, 'total': 18}",
      "files": "{'pkg/util/mount/mount_windows.go': {'additions': 12, 'deletions': 6, 'changes': 18, 'status': 'modified', 'raw_url': 'https://github.com/kubernetes/kubernetes/raw/d65039c56ce4de5f2efdc38aa1284eeb95f89169/pkg%2Futil%2Fmount%2Fmount_windows.go', 'patch': '@@ -83,14 +83,20 @@ func (mounter *Mounter) Mount(source string, target string, fstype string, optio\\n \\t\\t\\treturn fmt.Errorf(\"azureMount: only cifs mount is supported now, fstype: %q, mounting source (%q), target (%q), with options (%q)\", fstype, source, target, options)\\n \\t\\t}\\n \\n-\\t\\tcmdLine := fmt.Sprintf(`$User = \"%s\";$PWord = ConvertTo-SecureString -String \"%s\" -AsPlainText -Force;`+\\n-\\t\\t\\t`$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $User, $PWord`,\\n-\\t\\t\\toptions[0], options[1])\\n-\\n \\t\\tbindSource = source\\n-\\t\\tcmdLine += fmt.Sprintf(\";New-SmbGlobalMapping -RemotePath %s -Credential $Credential\", source)\\n \\n-\\t\\tif output, err := exec.Command(\"powershell\", \"/c\", cmdLine).CombinedOutput(); err != nil {\\n+\\t\\t// use PowerShell Environment Variables to store user input string to prevent command line injection\\n+\\t\\t// https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_environment_variables?view=powershell-5.1\\n+\\t\\tcmdLine := fmt.Sprintf(`$PWord = ConvertTo-SecureString -String $Env:smbpassword -AsPlainText -Force` +\\n+\\t\\t\\t`;$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $Env:smbuser, $PWord` +\\n+\\t\\t\\t`;New-SmbGlobalMapping -RemotePath $Env:smbremotepath -Credential $Credential`)\\n+\\n+\\t\\tcmd := exec.Command(\"powershell\", \"/c\", cmdLine)\\n+\\t\\tcmd.Env = append(os.Environ(),\\n+\\t\\t\\tfmt.Sprintf(\"smbuser=%s\", options[0]),\\n+\\t\\t\\tfmt.Sprintf(\"smbpassword=%s\", options[1]),\\n+\\t\\t\\tfmt.Sprintf(\"smbremotepath=%s\", source))\\n+\\t\\tif output, err := cmd.CombinedOutput(); err != nil {\\n \\t\\t\\treturn fmt.Errorf(\"azureMount: SmbGlobalMapping failed: %v, only SMB mount is supported now, output: %q\", err, string(output))\\n \\t\\t}\\n \\t}'}}",
      "message_norm": "merge pull request #65751 from andyzhangx/mount-windows-fix\n\nautomatic merge from submit-queue (batch tested with prs 65381, 65751). if you want to cherry-pick this change to another branch, please follow the instructions <a href=\"https://github.com/kubernetes/community/blob/master/contributors/devel/cherry-picks.md\">here</a>.\n\nfix smb mount security issue\n\n**what this pr does / why we need it**:\r\nfix smb mount security issue:\r\nuser powershell environment variables to store user input string to prevent command line injection, the env var in powershell would be taken as literal values and not as executable vulnerable code, this kind of fix is common for command line injection issue (called: parameterized way)\r\n\r\noriginally use go sdk for `new-smbglobalmapping` is best solution, while after discussion with windows team, go api for `new-smbglobalmapping` is not ready yet and the new functionality of basic win32 api [netuseadd](https://msdn.microsoft.com/en-us/library/windows/desktop/aa370645(v=vs.85).aspx) is not public yet, use [powershell with environment variables](https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_environment_variables?view=powershell-5.1) is also their recommended way.\r\n\r\n**which issue(s) this pr fixes** *(optional, in `fixes #<issue number>(, fixes #<issue_number>, ...)` format, will close the issue(s) when pr gets merged)*:\r\nfixes #65750 \r\n\r\n**special notes for your reviewer**:\r\n - this is a security issue fix, no behavior change, e2e test of smb mount passes.\r\n - original logging as `azuremount` is incorrect since this mount_windows is for mount disk & smb, it's a common feature on windows, not specific to azure, i will send another pr to fixing all the logging naming issue, anyway it's not related to this security issue. let's keep this pr simple.\r\n\r\n**release note**:\r\n\r\n```\r\nfix smb mount security issue\r\n```\r\n\r\n/sig windows\r\n/sig storage\r\n/kind bug\r\n\r\n@jessfraz \r\n/assign @jsafrane @msau42",
      "language": "en",
      "entities": "[('#65751', 'ISSUE', ''), ('href=\"https://github.com', 'URL', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('prevent', 'ACTION', ''), ('injection', 'SECWORD', ''), ('vulnerable', 'SECWORD', ''), ('injection', 'SECWORD', ''), ('issue', 'FLAW', ''), ('netuseadd](https://msdn.microsoft.com', 'URL', ''), ('variables](https://docs.microsoft.com', 'URL', ''), ('issue(s', 'FLAW', ''), ('fixes', 'ACTION', ''), ('fixes', 'ACTION', ''), ('issue', 'FLAW', ''), ('fixes', 'ACTION', ''), ('issue(s', 'FLAW', ''), ('fixes', 'ACTION', ''), ('#65750', 'ISSUE', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('fixing', 'ACTION', ''), ('issue', 'FLAW', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('fix', 'ACTION', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('bug', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['pkg/util/mount/mount_windows.go'])",
      "num_files": 1.0
    },
    {
      "index": 196,
      "vuln_id": "GHSA-34hv-f45p-4qfq",
      "cwe_id": "{'CWE-601'}",
      "score": 6.1,
      "chain": "{'https://github.com/WWBN/AVideo/commit/77e9aa6411ff4b97571eb82e587139ec05ff894c'}",
      "dataset": "osv",
      "summary": "Open redirect in wwbn/avideo Open redirect vulnerability in objects/login.json.php in WWBN AVideo through 11.6, allows attackers to arbitrarily redirect users from a crafted url to the login page. A patch is available on the `master` branch of the repository.",
      "published_date": "2022-04-06",
      "chain_len": 1,
      "project": "https://github.com/WWBN/AVideo",
      "commit_href": "https://github.com/WWBN/AVideo/commit/77e9aa6411ff4b97571eb82e587139ec05ff894c",
      "commit_sha": "77e9aa6411ff4b97571eb82e587139ec05ff894c",
      "patch": "SINGLE",
      "chain_ord": "['77e9aa6411ff4b97571eb82e587139ec05ff894c']",
      "before_first_fix_commit": "{'24a25e4f415be8146c89f04df32ba4acce1b0e80'}",
      "last_fix_commit": "77e9aa6411ff4b97571eb82e587139ec05ff894c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2022, 17:54:12",
      "message": "Open Redirect fix, thanks Max Boll",
      "author": "Daniel",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'objects/login.json.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/WWBN/AVideo/raw/77e9aa6411ff4b97571eb82e587139ec05ff894c/objects%2Flogin.json.php', 'patch': '@@ -30,7 +30,7 @@\\n Category::clearCacheCount();\\n TimeLogEnd($timeLog, __LINE__);\\n \\n-if (!preg_match(\"|^\" . $global[\\'webSiteRootURL\\'] . \"|\", $_POST[\\'redirectUri\\'])) {\\n+if(!isSameDomain($global[\\'webSiteRootURL\\'], $_POST[\\'redirectUri\\'])){\\n     $_POST[\\'redirectUri\\'] = $global[\\'webSiteRootURL\\'];\\n }\\n _error_log(\"Start Login Request redirectUri=\" . $_POST[\\'redirectUri\\']);'}}",
      "message_norm": "open redirect fix, thanks max boll",
      "language": "en",
      "entities": "[('open redirect', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['objects/login.json.php'])",
      "num_files": 1.0
    },
    {
      "index": 1904,
      "vuln_id": "GHSA-gp2m-7cfp-h6gf",
      "cwe_id": "{'CWE-384'}",
      "score": 9.8,
      "chain": "{'https://github.com/simplesamlphp/simplesamlphp/commit/90dca835158495b173808273e7df127303b8b953'}",
      "dataset": "osv",
      "summary": "Incorrect persistent NameID generation in SimpleSAMLphp ### Background\nWhen a SimpleSAMLphp Identity Provider is misconfigured, a bug in the software when trying to build a persistent `NameID` to univocally identify the authenticating subject could cause different users to get the same identifier generated, depending on the attributes available for them right after authentication.\n\nPlease note that even though this is possible thanks to a bug, **an IdP must be misconfigured** to release persistent `NameID`s even if it is not properly configured to generate them based on the specifics of the deployment.\n\n### Description\nPersistent `NameID`s will typically be sent as part of the `Subject` element of a SAML assertion, or as the contents of the `eduPersonTargetedID` attribute. Here is an example of such a `NameID`:\n\n    <NameID Format=\u201curn:oasis:names:tc:SAML:2.0:nameid-format:persistent\u201c>\n        zbonsm0Yn9Gnw14uQEEPr6AO7d+IvxwCQN3t+o24jYs=\n    </NameID>\n\nSome service providers will use this information to identify a user across sessions because a persistent `NameID` will never change for a given user. This could lead to different users accessing the same account in those service providers.\n\nIn order to be affected by this issue, the following circumstances must concur:\n\n- SimpleSAMLphp acts as an identity provider.\n- The service provider asking for authentication requests a persistent `NameID`.\n- No `saml:PersistentNameID` authentication processing filter is configured (neither for the whole IdP, nor for a given SP).\n- No `simplesaml.nameidattribute` configuration option is set (neither for the whole IdP, nor for a given SP).\n- One of the following alternatives:\n  - No `userid.attribute` configuration option is set **and** the users don't have an `eduPersonPrincipalName` attribute in the users backend, **or**\n  - the `userid.attribute` configuration option is set to an empty or missing attribute.\n\nIf all these requirements are met, the `SimpleSAML_Auth_ProcessingChain` class will try to keep a unique user identifier in the state array (`addUserID()` method). Bear in mind that this code is executed **before** all the authentication processing filters configured, meaning that only those attributes retrieved for the user during **initial authentication** will be available. If no `userid.attribute` configuration option is set, the default `eduPersonPrincipalName` will then be used. However, since it is missing, no identifier will be kept. Alternatively, if `userid.attribute` is set to a missing or empty attribute, the `addUserID()` method will abort trying to register an identifier.\n\nAfter executing all authentication processing filters, SimpleSAMLphp will build a SAML assertion. If the service provider requests persistent `NameID`s, SimpleSAMLphp will attempt to generate one given that none is already available (because the `saml:PersistentNameID` filter was not used). At this point, the code will look for the `simplesaml.nameidattribute` configuration option in either the local IdP metadata or in the remote SP metadata. If none of them are configured, it will default to the unique user identifier previously registered by `SimpleSAML_Auth_ProcessingChain`. If no identifier was kept there, the code will log an error message:\n\n    Unable to generate NameID. Check the userid.attribute option.\n\nHowever, instead of aborting the `NameID` generation at that point, it will go on and use a value missing from the state array as the source for the computation, meaning the `null` type will be used. Hence, all users connecting to a given service provider will get the same `NameID` generated, because all the input parameters will be the same:\n\n- The SP's entity identifier.\n- The IdP's entity identifier.\n- The `null` value.\n- The common secret salt from the main configuration.\n\n### Affected versions\nAll SimpleSAMLphp versions between 1.7.0 and 1.14.10, inclusive.\n\n### Impact\nThose identity providers affected by this bug and misconfigured as previously described could be issuing SAML assertions with common `NameID`s for all or a subset of their users. If a service provider uses those `NameID`s to identify the users of the affected IdP, all the users will be associated with the same user account at the service provider, causing all sorts of potential security issues like information disclosure or unauthorized access.\n\nWhile we can consider this unlikely to happen, some cases have been already observed. In particular, some identity providers using default configurations and consuming metadata automatically (i.e. using the _metarefresh_ module) while using a user backend like _Active Directory_ that does not populate `eduPersonPrincipalName` are particularly sensitive to this issue.\n\n### Resolution\nUpgrade to the latest version.\n\nConfigure a `saml:PersistentNameID` authentication processing filter according to your needs. Remember to check that **the attribute used as the source** for the `NameID` **is present at the moment the `saml:PersistentNameID` filter is executed**. The attribute used must be **unique** per user, and **must not change** over time.",
      "published_date": "2020-01-24",
      "chain_len": 1,
      "project": "https://github.com/simplesamlphp/simplesamlphp",
      "commit_href": "https://github.com/simplesamlphp/simplesamlphp/commit/90dca835158495b173808273e7df127303b8b953",
      "commit_sha": "90dca835158495b173808273e7df127303b8b953",
      "patch": "SINGLE",
      "chain_ord": "['90dca835158495b173808273e7df127303b8b953']",
      "before_first_fix_commit": "{'300d8aa48fe93706ade95be481c68e9cf2f32d1f'}",
      "last_fix_commit": "90dca835158495b173808273e7df127303b8b953",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/12/2016, 11:21:31",
      "message": "bugfix: Make sure a persistent NameID is not generated by default when the UserID is missing in the state array.\n\nThis allowed misconfigured IdPs (i.e. those without both a PersistenNameID authproc filter, a \u201cuserid.attribute\u201d configuration option and no \u201ceduPersonPrincipalName\u201d attribute available after running all the authentication processing filters) to generate a persistent NameID based on \u201cnull\u201d, effectively giving all users the same identifier.",
      "author": "Jaime Pe\u0301rez",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'modules/saml/lib/IdP/SAML2.php': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/simplesamlphp/simplesamlphp/raw/90dca835158495b173808273e7df127303b8b953/modules%2Fsaml%2Flib%2FIdP%2FSAML2.php', 'patch': \"@@ -623,6 +623,7 @@ private static function generateNameIdValue(SimpleSAML_Configuration $idpMetadat\\n \\t\\t\\tif ($attribute === NULL) {\\n \\t\\t\\t\\tif (!isset($state['UserID'])) {\\n \\t\\t\\t\\t\\tSimpleSAML_Logger::error('Unable to generate NameID. Check the userid.attribute option.');\\n+\\t\\t\\t\\t\\treturn NULL;\\n \\t\\t\\t\\t}\\n \\t\\t\\t\\t$attributeValue = $state['UserID'];\\n \\t\\t\\t\\t$idpEntityId = $idpMetadata->getString('entityid');\"}}",
      "message_norm": "bugfix: make sure a persistent nameid is not generated by default when the userid is missing in the state array.\n\nthis allowed misconfigured idps (i.e. those without both a persistennameid authproc filter, a \u201cuserid.attribute\u201d configuration option and no \u201cedupersonprincipalname\u201d attribute available after running all the authentication processing filters) to generate a persistent nameid based on \u201cnull\u201d, effectively giving all users the same identifier.",
      "language": "en",
      "entities": "[('bugfix', 'FLAW', ''), ('authentication', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['modules/saml/lib/IdP/SAML2.php'])",
      "num_files": 1.0
    },
    {
      "index": 1468,
      "vuln_id": "GHSA-c3g4-w6cv-6v7h",
      "cwe_id": "{'CWE-276'}",
      "score": 6.8,
      "chain": "{'https://github.com/containers/buildah/commit/e7e55c988c05dd74005184ceb64f097a0cfe645b', 'https://github.com/containers/buildah/commit/90b3254c7404039c1c786999ac189654228f6e0e'}",
      "dataset": "osv",
      "summary": "Non-empty default inheritable capabilities for linux container in Buildah A bug was found in Buildah where containers were created with non-empty inheritable Linux process capabilities, creating an atypical Linux environment and enabling programs with inheritable file capabilities to elevate those capabilities to the permitted set during execve(2).\n\nThis bug did not affect the container security sandbox as the inheritable set never contained more capabilities than were included in the container's bounding set.",
      "published_date": "2022-04-01",
      "chain_len": 2,
      "project": "https://github.com/containers/buildah",
      "commit_href": "https://github.com/containers/buildah/commit/90b3254c7404039c1c786999ac189654228f6e0e",
      "commit_sha": "90b3254c7404039c1c786999ac189654228f6e0e",
      "patch": "MULTI",
      "chain_ord": "['e7e55c988c05dd74005184ceb64f097a0cfe645b', '90b3254c7404039c1c786999ac189654228f6e0e']",
      "before_first_fix_commit": "{'5d252d404df19f77d26d6af956f4809103ce079f'}",
      "last_fix_commit": "90b3254c7404039c1c786999ac189654228f6e0e",
      "chain_ord_pos": 2.0,
      "commit_datetime": "03/24/2022, 20:32:47",
      "message": "Add a test for CVE-2022-27651\n\nCheck that the inheritable capabilities are set to 0, even when we\nexplicitly try to add capabilities.\n\nSigned-off-by: Nalin Dahyabhai <nalin@redhat.com>",
      "author": "Nalin Dahyabhai",
      "comments": null,
      "stats": "{'additions': 14, 'deletions': 0, 'total': 14}",
      "files": "{'tests/run.bats': {'additions': 14, 'deletions': 0, 'changes': 14, 'status': 'modified', 'raw_url': 'https://github.com/containers/buildah/raw/90b3254c7404039c1c786999ac189654228f6e0e/tests%2Frun.bats', 'patch': '@@ -786,9 +786,23 @@ _EOF\\n \\tif test \"$DBUS_SESSION_BUS_ADDRESS\" = \"\"; then\\n \\t\\tskip \"${1:-test does not work when \\\\$BUILDAH_ISOLATION = chroot}\"\\n \\tfi\\n+\\t_prefetch alpine\\n \\n \\trun_buildah from --quiet --pull=false --signature-policy ${TESTSDIR}/policy.json alpine\\n \\tcid=$output\\n \\trun_buildah run --cgroupns=host $cid cat /proc/self/cgroup\\n \\texpect_output --substring \"/user.slice/\"\\n }\\n+\\n+@test \"run-inheritable-capabilities\" {\\n+\\tskip_if_no_runtime\\n+\\n+\\t_prefetch alpine\\n+\\n+\\trun_buildah from --quiet --pull=false --signature-policy ${TESTSDIR}/policy.json alpine\\n+\\tcid=$output\\n+\\trun_buildah run $cid grep ^CapInh: /proc/self/status\\n+\\texpect_output \"CapInh:\\t0000000000000000\"\\n+\\trun_buildah run --cap-add=ALL $cid grep ^CapInh: /proc/self/status\\n+\\texpect_output \"CapInh:\\t0000000000000000\"\\n+}'}}",
      "message_norm": "add a test for cve-2022-27651\n\ncheck that the inheritable capabilities are set to 0, even when we\nexplicitly try to add capabilities.\n\nsigned-off-by: nalin dahyabhai <nalin@redhat.com>",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('cve-2022-27651', 'VULNID', 'CVE'), ('add', 'ACTION', ''), ('nalin@redhat.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tests/run.bats'])",
      "num_files": 1.0
    },
    {
      "index": 152,
      "vuln_id": "GHSA-2wc6-2rcj-8v76",
      "cwe_id": "{'CWE-1240'}",
      "score": 6.5,
      "chain": "{'https://github.com/sodiumoxide/sodiumoxide/commit/24c7a5550807ac8a09648b5878f19d14c3a69135'}",
      "dataset": "osv",
      "summary": "scalarmult() vulnerable to degenerate public keys The `scalarmult()` function included in previous versions of this crate\naccepted all-zero public keys, for which the resulting Diffie-Hellman shared\nsecret will always be zero regardless of the private key used.\n\nThis issue was fixed by checking for this class of keys and rejecting them\nif they are used.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/sodiumoxide/sodiumoxide",
      "commit_href": "https://github.com/sodiumoxide/sodiumoxide/commit/24c7a5550807ac8a09648b5878f19d14c3a69135",
      "commit_sha": "24c7a5550807ac8a09648b5878f19d14c3a69135",
      "patch": "SINGLE",
      "chain_ord": "['24c7a5550807ac8a09648b5878f19d14c3a69135']",
      "before_first_fix_commit": "{'12d49e8ed1b53821465f24312695376eb86c89d2'}",
      "last_fix_commit": "24c7a5550807ac8a09648b5878f19d14c3a69135",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/26/2017, 19:24:31",
      "message": "Check the return value of `scalarmult()`. Closes #154",
      "author": "Daniel Ashhami",
      "comments": null,
      "stats": "{'additions': 55, 'deletions': 46, 'total': 101}",
      "files": "{'src/crypto/scalarmult/curve25519.rs': {'additions': 55, 'deletions': 46, 'changes': 101, 'status': 'modified', 'raw_url': 'https://github.com/sodiumoxide/sodiumoxide/raw/24c7a5550807ac8a09648b5878f19d14c3a69135/src%2Fcrypto%2Fscalarmult%2Fcurve25519.rs', 'patch': '@@ -23,14 +23,20 @@ new_type! {\\n \\n /// `scalarmult()` multiplies a group element `p`\\n /// by an integer `n`. It returns the resulting group element\\n-/// `q`.\\n+/// `Ok(q)`.\\n+/// If the the `GroupElement` is all zero, `scalarmult()` returns `Err(())` since\\n+/// the resulting `GroupElement` would be all zero, no matter the `Scalar`.\\n pub fn scalarmult(&Scalar(ref n): &Scalar,\\n-                  &GroupElement(ref p): &GroupElement) -> GroupElement {\\n+                  &GroupElement(ref p): &GroupElement)\\n+                  -> Result<GroupElement, ()> {\\n     let mut q = [0; GROUPELEMENTBYTES];\\n     unsafe {\\n-        ffi::crypto_scalarmult_curve25519(&mut q, n, p);\\n+        if ffi::crypto_scalarmult_curve25519(&mut q, n, p) != 0 {\\n+            Err(())\\n+        } else {\\n+            Ok(GroupElement(q))\\n+        }\\n     }\\n-    GroupElement(q)\\n }\\n \\n /// `scalarmult_base()` computes the scalar product of a standard\\n@@ -47,74 +53,77 @@ pub fn scalarmult_base(&Scalar(ref n): &Scalar) -> GroupElement {\\n #[cfg(test)]\\n mod test {\\n     use super::*;\\n+    use randombytes::randombytes_into;\\n \\n     #[test]\\n     fn test_vector_1() {\\n         // corresponding to tests/scalarmult.c and tests/scalarmult3.cpp from NaCl\\n-        let alicesk = Scalar([0x77,0x07,0x6d,0x0a,0x73,0x18,0xa5,0x7d\\n-                             ,0x3c,0x16,0xc1,0x72,0x51,0xb2,0x66,0x45\\n-                             ,0xdf,0x4c,0x2f,0x87,0xeb,0xc0,0x99,0x2a\\n-                             ,0xb1,0x77,0xfb,0xa5,0x1d,0xb9,0x2c,0x2a]);\\n-        let alicepk_expected = [0x85,0x20,0xf0,0x09,0x89,0x30,0xa7,0x54\\n-                               ,0x74,0x8b,0x7d,0xdc,0xb4,0x3e,0xf7,0x5a\\n-                               ,0x0d,0xbf,0x3a,0x0d,0x26,0x38,0x1a,0xf4\\n-                               ,0xeb,0xa4,0xa9,0x8e,0xaa,0x9b,0x4e,0x6a];\\n+        let alicesk = Scalar([0x77, 0x07, 0x6d, 0x0a, 0x73, 0x18, 0xa5, 0x7d, 0x3c, 0x16, 0xc1,\\n+                              0x72, 0x51, 0xb2, 0x66, 0x45, 0xdf, 0x4c, 0x2f, 0x87, 0xeb, 0xc0,\\n+                              0x99, 0x2a, 0xb1, 0x77, 0xfb, 0xa5, 0x1d, 0xb9, 0x2c, 0x2a]);\\n+        let alicepk_expected = [0x85, 0x20, 0xf0, 0x09, 0x89, 0x30, 0xa7, 0x54, 0x74, 0x8b, 0x7d,\\n+                                0xdc, 0xb4, 0x3e, 0xf7, 0x5a, 0x0d, 0xbf, 0x3a, 0x0d, 0x26, 0x38,\\n+                                0x1a, 0xf4, 0xeb, 0xa4, 0xa9, 0x8e, 0xaa, 0x9b, 0x4e, 0x6a];\\n         let GroupElement(alicepk) = scalarmult_base(&alicesk);\\n         assert!(alicepk == alicepk_expected);\\n     }\\n \\n     #[test]\\n     fn test_vector_2() {\\n         // corresponding to tests/scalarmult2.c and tests/scalarmult4.cpp from NaCl\\n-        let bobsk = Scalar([0x5d,0xab,0x08,0x7e,0x62,0x4a,0x8a,0x4b\\n-                           ,0x79,0xe1,0x7f,0x8b,0x83,0x80,0x0e,0xe6\\n-                           ,0x6f,0x3b,0xb1,0x29,0x26,0x18,0xb6,0xfd\\n-                           ,0x1c,0x2f,0x8b,0x27,0xff,0x88,0xe0,0xeb]);\\n-        let bobpk_expected = [0xde,0x9e,0xdb,0x7d,0x7b,0x7d,0xc1,0xb4\\n-                             ,0xd3,0x5b,0x61,0xc2,0xec,0xe4,0x35,0x37\\n-                             ,0x3f,0x83,0x43,0xc8,0x5b,0x78,0x67,0x4d\\n-                             ,0xad,0xfc,0x7e,0x14,0x6f,0x88,0x2b,0x4f];\\n+        let bobsk = Scalar([0x5d, 0xab, 0x08, 0x7e, 0x62, 0x4a, 0x8a, 0x4b, 0x79, 0xe1, 0x7f,\\n+                            0x8b, 0x83, 0x80, 0x0e, 0xe6, 0x6f, 0x3b, 0xb1, 0x29, 0x26, 0x18,\\n+                            0xb6, 0xfd, 0x1c, 0x2f, 0x8b, 0x27, 0xff, 0x88, 0xe0, 0xeb]);\\n+        let bobpk_expected = [0xde, 0x9e, 0xdb, 0x7d, 0x7b, 0x7d, 0xc1, 0xb4, 0xd3, 0x5b, 0x61,\\n+                              0xc2, 0xec, 0xe4, 0x35, 0x37, 0x3f, 0x83, 0x43, 0xc8, 0x5b, 0x78,\\n+                              0x67, 0x4d, 0xad, 0xfc, 0x7e, 0x14, 0x6f, 0x88, 0x2b, 0x4f];\\n         let GroupElement(bobpk) = scalarmult_base(&bobsk);\\n         assert!(bobpk == bobpk_expected);\\n     }\\n \\n     #[test]\\n     fn test_vector_3() {\\n         // corresponding to tests/scalarmult5.c and tests/scalarmult7.cpp from NaCl\\n-        let alicesk = Scalar([0x77,0x07,0x6d,0x0a,0x73,0x18,0xa5,0x7d\\n-                             ,0x3c,0x16,0xc1,0x72,0x51,0xb2,0x66,0x45\\n-                             ,0xdf,0x4c,0x2f,0x87,0xeb,0xc0,0x99,0x2a\\n-                             ,0xb1,0x77,0xfb,0xa5,0x1d,0xb9,0x2c,0x2a]);\\n-        let bobpk = GroupElement([0xde,0x9e,0xdb,0x7d,0x7b,0x7d,0xc1,0xb4\\n-                                 ,0xd3,0x5b,0x61,0xc2,0xec,0xe4,0x35,0x37\\n-                                 ,0x3f,0x83,0x43,0xc8,0x5b,0x78,0x67,0x4d\\n-                                 ,0xad,0xfc,0x7e,0x14,0x6f,0x88,0x2b,0x4f]);\\n-        let k_expected = [0x4a,0x5d,0x9d,0x5b,0xa4,0xce,0x2d,0xe1\\n-                         ,0x72,0x8e,0x3b,0xf4,0x80,0x35,0x0f,0x25\\n-                         ,0xe0,0x7e,0x21,0xc9,0x47,0xd1,0x9e,0x33\\n-                         ,0x76,0xf0,0x9b,0x3c,0x1e,0x16,0x17,0x42];\\n-        let GroupElement(k) = scalarmult(&alicesk, &bobpk);\\n+        let alicesk = Scalar([0x77, 0x07, 0x6d, 0x0a, 0x73, 0x18, 0xa5, 0x7d, 0x3c, 0x16, 0xc1,\\n+                              0x72, 0x51, 0xb2, 0x66, 0x45, 0xdf, 0x4c, 0x2f, 0x87, 0xeb, 0xc0,\\n+                              0x99, 0x2a, 0xb1, 0x77, 0xfb, 0xa5, 0x1d, 0xb9, 0x2c, 0x2a]);\\n+        let bobpk = GroupElement([0xde, 0x9e, 0xdb, 0x7d, 0x7b, 0x7d, 0xc1, 0xb4, 0xd3, 0x5b,\\n+                                  0x61, 0xc2, 0xec, 0xe4, 0x35, 0x37, 0x3f, 0x83, 0x43, 0xc8,\\n+                                  0x5b, 0x78, 0x67, 0x4d, 0xad, 0xfc, 0x7e, 0x14, 0x6f, 0x88,\\n+                                  0x2b, 0x4f]);\\n+        let k_expected = [0x4a, 0x5d, 0x9d, 0x5b, 0xa4, 0xce, 0x2d, 0xe1, 0x72, 0x8e, 0x3b, 0xf4,\\n+                          0x80, 0x35, 0x0f, 0x25, 0xe0, 0x7e, 0x21, 0xc9, 0x47, 0xd1, 0x9e, 0x33,\\n+                          0x76, 0xf0, 0x9b, 0x3c, 0x1e, 0x16, 0x17, 0x42];\\n+        let GroupElement(k) = scalarmult(&alicesk, &bobpk).unwrap();\\n         assert!(k == k_expected);\\n     }\\n \\n     #[test]\\n     fn test_vector_4() {\\n         // corresponding to tests/scalarmult6.c from NaCl\\n-        let bobsk = Scalar([0x5d,0xab,0x08,0x7e,0x62,0x4a,0x8a,0x4b\\n-                           ,0x79,0xe1,0x7f,0x8b,0x83,0x80,0x0e,0xe6\\n-                           ,0x6f,0x3b,0xb1,0x29,0x26,0x18,0xb6,0xfd\\n-                           ,0x1c,0x2f,0x8b,0x27,0xff,0x88,0xe0,0xeb]);\\n-        let alicepk = GroupElement([0x85,0x20,0xf0,0x09,0x89,0x30,0xa7,0x54\\n-                                   ,0x74,0x8b,0x7d,0xdc,0xb4,0x3e,0xf7,0x5a\\n-                                   ,0x0d,0xbf,0x3a,0x0d,0x26,0x38,0x1a,0xf4\\n-                                   ,0xeb,0xa4,0xa9,0x8e,0xaa,0x9b,0x4e,0x6a]);\\n-        let k_expected = [0x4a,0x5d,0x9d,0x5b,0xa4,0xce,0x2d,0xe1\\n-                         ,0x72,0x8e,0x3b,0xf4,0x80,0x35,0x0f,0x25\\n-                         ,0xe0,0x7e,0x21,0xc9,0x47,0xd1,0x9e,0x33\\n-                         ,0x76,0xf0,0x9b,0x3c,0x1e,0x16,0x17,0x42];\\n-        let GroupElement(k) = scalarmult(&bobsk, &alicepk);\\n+        let bobsk = Scalar([0x5d, 0xab, 0x08, 0x7e, 0x62, 0x4a, 0x8a, 0x4b, 0x79, 0xe1, 0x7f,\\n+                            0x8b, 0x83, 0x80, 0x0e, 0xe6, 0x6f, 0x3b, 0xb1, 0x29, 0x26, 0x18,\\n+                            0xb6, 0xfd, 0x1c, 0x2f, 0x8b, 0x27, 0xff, 0x88, 0xe0, 0xeb]);\\n+        let alicepk = GroupElement([0x85, 0x20, 0xf0, 0x09, 0x89, 0x30, 0xa7, 0x54, 0x74, 0x8b,\\n+                                    0x7d, 0xdc, 0xb4, 0x3e, 0xf7, 0x5a, 0x0d, 0xbf, 0x3a, 0x0d,\\n+                                    0x26, 0x38, 0x1a, 0xf4, 0xeb, 0xa4, 0xa9, 0x8e, 0xaa, 0x9b,\\n+                                    0x4e, 0x6a]);\\n+        let k_expected = [0x4a, 0x5d, 0x9d, 0x5b, 0xa4, 0xce, 0x2d, 0xe1, 0x72, 0x8e, 0x3b, 0xf4,\\n+                          0x80, 0x35, 0x0f, 0x25, 0xe0, 0x7e, 0x21, 0xc9, 0x47, 0xd1, 0x9e, 0x33,\\n+                          0x76, 0xf0, 0x9b, 0x3c, 0x1e, 0x16, 0x17, 0x42];\\n+        let GroupElement(k) = scalarmult(&bobsk, &alicepk).unwrap();\\n         assert!(k == k_expected);\\n     }\\n+\\n+    #[test]\\n+    #[should_panic]\\n+    fn test_all_zero() {\\n+        let mut sk = [0; SCALARBYTES];\\n+        randombytes_into(&mut sk);\\n+        let sk = Scalar(sk);\\n+        let pk = GroupElement([0; GROUPELEMENTBYTES]);\\n+        let _ = scalarmult(&sk, &pk).unwrap();\\n+    }\\n }\\n \\n #[cfg(feature = \"benchmarks\")]'}}",
      "message_norm": "check the return value of `scalarmult()`. closes #154",
      "language": "en",
      "entities": "[('#154', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/crypto/scalarmult/curve25519.rs'])",
      "num_files": 1.0
    },
    {
      "index": 2094,
      "vuln_id": "GHSA-hm45-mgqm-gjm4",
      "cwe_id": "{'CWE-79'}",
      "score": 7.7,
      "chain": "{'https://github.com/Cog-Creators/Red-Dashboard/commit/a6b9785338003ec87fb75305e7d1cc2d40c7ab91', 'https://github.com/Cog-Creators/Red-Dashboard/commit/99d88b840674674166ce005b784ae8e31e955ab1'}",
      "dataset": "osv",
      "summary": "Remote Code Execution (RCE) Exploit on Cross Site Scripting (XSS) Vulnerability ### Impact\nA RCE exploit has been discovered in the Red Discord Bot - Dashboard Webserver: this exploit allows Discord users with specially crafted Server names and Usernames/Nicknames to inject code into the webserver front-end code.  By abusing this exploit, it's possible to perform destructive actions and/or access sensitive information.\n\n### Patches\nThis high severity exploit has been fixed on version `0.1.7a`.\n\n### Workarounds\nThere are no workarounds, bot owners must upgrade their relevant packages (Dashboard module and Dashboard webserver) in order to patch this issue\n\n### References\n- 99d88b8\n- a6b9785\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Cog-Creators/Red-Dashboard](https://github.com/Cog-Creators/Red-Dashboard/issues/new/choose)\n* Over on the official [Red Server](https://discord.gg/red) or at the Third Party Server [Toxic Layer](https://discord.gg/vQZTdB9)",
      "published_date": "2020-12-08",
      "chain_len": 2,
      "project": "https://github.com/Cog-Creators/Red-Dashboard",
      "commit_href": "https://github.com/Cog-Creators/Red-Dashboard/commit/a6b9785338003ec87fb75305e7d1cc2d40c7ab91",
      "commit_sha": "a6b9785338003ec87fb75305e7d1cc2d40c7ab91",
      "patch": "MULTI",
      "chain_ord": "['99d88b840674674166ce005b784ae8e31e955ab1', 'a6b9785338003ec87fb75305e7d1cc2d40c7ab91']",
      "before_first_fix_commit": "{'261f00f52bbfee4db67f624fd7409bf08124a6c4'}",
      "last_fix_commit": "a6b9785338003ec87fb75305e7d1cc2d40c7ab91",
      "chain_ord_pos": 2.0,
      "commit_datetime": "12/01/2020, 14:15:49",
      "message": "[UI] Fix SelectPicker not rendering properly",
      "author": "NeuroAssassin",
      "comments": null,
      "stats": "{'additions': 41, 'deletions': 16, 'total': 57}",
      "files": "{'reddash/app/home/templates/guild.html': {'additions': 41, 'deletions': 16, 'changes': 57, 'status': 'modified', 'raw_url': 'https://github.com/Cog-Creators/Red-Dashboard/raw/a6b9785338003ec87fb75305e7d1cc2d40c7ab91/reddash%2Fapp%2Fhome%2Ftemplates%2Fguild.html', 'patch': '@@ -930,20 +930,20 @@ <h5>{{ data[\\'message\\'] }}</h5>\\n             img.attr(\"src\", `${img.attr(\"data-src-url\")}png`)\\r\\n         }\\r\\n     }\\r\\n+\\r\\n+    function safe(str) {\\r\\n+        return String(str).replace(/&/g, \\'&amp;\\').replace(/</g, \\'&lt;\\').replace(/>/g, \\'&gt;\\').replace(/\"/g, \\'&quot;\\');\\r\\n+    }\\r\\n </script>\\r\\n \\r\\n {% if data[\\'status\\'] == 1 and data[\\'data\\'][\\'status\\'] == 1 %}\\r\\n \\r\\n-{% if \\'aliascc\\' in data[\\'data\\'][\\'permslist\\'] %}\\r\\n+{% if \\'aliascc\\' in data[\\'data\\'][\\'permslist\\'] and false%}\\r\\n <script>\\r\\n     /* ---------------------------------------------------------------------------------------------------------------------\\r\\n                                                         Aliases group\\r\\n        --------------------------------------------------------------------------------------------------------------------- */\\r\\n \\r\\n-    function safe(str) {\\r\\n-        return String(str).replace(/&/g, \\'&amp;\\').replace(/</g, \\'&lt;\\').replace(/>/g, \\'&gt;\\').replace(/\"/g, \\'&quot;\\');\\r\\n-    }\\r\\n-\\r\\n     // Alias modal\\r\\n     $(document).on(\\'click\\', \\'.editaliasbutton\\', function () {\\r\\n         var command = $(this).parent().parent().data(\"command\")\\r\\n@@ -1186,28 +1186,35 @@ <h5>{{ data[\\'message\\'] }}</h5>\\n             } else if (json.status === 1 && json.data.status === 0) {\\r\\n                 $(\"#targetstatus\").html(`{{ _(\\'Failed to fetch targets\\') }}: ${json.data.message}`)\\r\\n             } else {\\r\\n+                let big_ol_dict = {}\\r\\n                 select.html(\"\")\\r\\n \\r\\n                 var chopt = [`<optgroup label=\"{{ _(\\'Channels\\') }}\">`]\\r\\n                 for (let [id, name] of json.data.CHANNELS) {\\r\\n-                    chopt.push(`<option value=${id}>${name}</option>`)\\r\\n+                    chopt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...</option>`)\\r\\n+                    big_ol_dict[id] = name\\r\\n                 }\\r\\n                 chopt.push(\"</optgroup>\")\\r\\n                 select.append(chopt.join(\"\"))\\r\\n \\r\\n                 var ropt = [`<optgroup label=\"{{ _(\\'Roles\\') }}\">`]\\r\\n                 for (let [id, name] of json.data.ROLES) {\\r\\n-                    ropt.push(`<option value=${id}>${name}</option>`)\\r\\n+                    ropt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...</option>`)\\r\\n+                    big_ol_dict[id] = name\\r\\n                 }\\r\\n                 ropt.push(\"</optgroup>\")\\r\\n                 select.append(ropt.join(\"\"))\\r\\n \\r\\n                 var uopt = [`<optgroup label=\"{{ _(\\'Users\\') }}\">`]\\r\\n                 for (let [id, name] of json.data.USERS) {\\r\\n-                    uopt.push(`<option value=${id}>${name}</option>`)\\r\\n+                    uopt.push(`<option value=${id} class=\"selectpicker-element-${id}\">Loading...</option>`)\\r\\n+                    big_ol_dict[id] = name\\r\\n                 }\\r\\n                 uopt.push(\"</optgroup>\")\\r\\n                 select.append(uopt.join(\"\"))\\r\\n+                for (let [id, name] of Object.entries(big_ol_dict)) {\\r\\n+                    $(`.selectpicker-element-${id}`).text(name)\\r\\n+                }\\r\\n             }\\r\\n             select.selectpicker({ title: \"{{ _(\\'Choose target\\') }}\" })\\r\\n             select.removeAttr(\"disabled\")\\r\\n@@ -1299,18 +1306,24 @@ <h5>{{ data[\\'message\\'] }}</h5>\\n                 $(\"#rulesdiv\").html(\"\")\\r\\n                 var overall = [\\'<h3 style=\"margin-bottom: 10px\">{{ _(\"Cog rules\") }}</h3>\\']\\r\\n                 var allcoglines = [\"<ul>\"]\\r\\n+\\r\\n+                let big_ol_dict_two = {}\\r\\n+                let cog_counter = 0\\r\\n+\\r\\n                 for (let [cog, rules] of Object.entries(json.data.COG)) {\\r\\n                     var coglines = []\\r\\n                     for (let rule of rules) {\\r\\n                         if (rule.type === \"Default\") {\\r\\n                             coglines.unshift(`<li>{{ _(\\'By default, users are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}</code> {{ _(\\'cog\\') }}.</li>`)\\r\\n                         } else if (rule.type === \"Role\") {\\r\\n-                            coglines.push(`<li>{{ _(\\'Users with the\\') }} <code>${rule.name}</code> {{ _(\\'role\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}</code> {{ _(\\'cog\\') }}.</li>`)\\r\\n+                            coglines.push(`<li>{{ _(\\'Users with the\\') }} <code id=\"cog-rules-${cog_counter}\">Loading...</code> {{ _(\\'role\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}</code> {{ _(\\'cog\\') }}.</li>`)\\r\\n                         } else if (rule.type === \"Channel\") {\\r\\n-                            coglines.push(`<li>{{ _(\\'Users in the\\') }} <code>${rule.name}</code> {{ _(\\'channel\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}</code> {{ _(\\'cog\\') }}.</li>`)\\r\\n+                            coglines.push(`<li>{{ _(\\'Users in the\\') }} <code id=\"cog-rules-${cog_counter}\">Loading...</code> {{ _(\\'channel\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}</code> {{ _(\\'cog\\') }}.</li>`)\\r\\n                         } else {\\r\\n-                            coglines.push(`<li>{{ _(\\'User\\') }} <code>${rule.name}</code> (${rule.id}) {{ _(\\'is\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}</code> {{ _(\\'cog\\') }}.</li>`)\\r\\n+                            coglines.push(`<li>{{ _(\\'User\\') }} <code id=\"cog-rules-${cog_counter}\">Loading...</code> (${rule.id}) {{ _(\\'is\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cog}</code> {{ _(\\'cog\\') }}.</li>`)\\r\\n                         }\\r\\n+                        big_ol_dict_two[`cog-rules-${cog_counter}`] = rule.name\\r\\n+                        cog_counter += 1\\r\\n                     }\\r\\n                     if (coglines) {\\r\\n                         allcoglines = allcoglines.concat(coglines)\\r\\n@@ -1324,18 +1337,23 @@ <h5>{{ data[\\'message\\'] }}</h5>\\n \\r\\n                 overall.push(\\'<h3 style=\"margin-bottom: 10px\">{{ _(\"Command rules\") }}</h3>\\')\\r\\n                 var allcmdlines = [\"<ul>\"]\\r\\n+\\r\\n+                let cmd_counter = 0\\r\\n+\\r\\n                 for (let [cmd, rules] of Object.entries(json.data.COMMAND)) {\\r\\n                     var cmdlines = []\\r\\n                     for (let rule of rules) {\\r\\n                         if (rule.type === \"Default\") {\\r\\n                             cmdlines.unshift(`<li>{{ _(\\'By default, users are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}</code> {{ _(\\'command\\') }}.</li>`)\\r\\n                         } else if (rule.type === \"Role\") {\\r\\n-                            cmdlines.push(`<li>{{ _(\\'Users with the\\') }} <code>${rule.name}</code> {{ _(\\'role\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}</code> {{ _(\\'command\\') }}.</li>`)\\r\\n+                            cmdlines.push(`<li>{{ _(\\'Users with the\\') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...</code> {{ _(\\'role\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}</code> {{ _(\\'command\\') }}.</li>`)\\r\\n                         } else if (rule.type === \"Channel\") {\\r\\n-                            cmdlines.push(`<li>{{ _(\\'Users in the\\') }} <code>${rule.name}</code> {{ _(\\'channel\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}</code> {{ _(\\'command\\') }}.</li>`)\\r\\n+                            cmdlines.push(`<li>{{ _(\\'Users in the\\') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...</code> {{ _(\\'channel\\') }} (${rule.id}) {{ _(\\'are\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}</code> {{ _(\\'command\\') }}.</li>`)\\r\\n                         } else {\\r\\n-                            cmdlines.push(`<li>{{ _(\\'User\\') }} <code>${rule.name}</code> (${rule.id}) {{ _(\\'is\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}</code> {{ _(\\'command\\') }}.</li>`)\\r\\n+                            cmdlines.push(`<li>{{ _(\\'User\\') }} <code id=\"cmd-rules-${cmd_counter}\">Loading...</code> (${rule.id}) {{ _(\\'is\\') }} ${rule.permission} {{ _(\\'permission to use the\\') }} <code>${cmd}</code> {{ _(\\'command\\') }}.</li>`)\\r\\n                         }\\r\\n+                        big_ol_dict_two[`cmd-rules-${cmd_counter}`] = rule.name\\r\\n+                        cmd_counter += 1\\r\\n                     }\\r\\n                     if (cmdlines) {\\r\\n                         allcmdlines = allcmdlines.concat(cmdlines)\\r\\n@@ -1347,6 +1365,9 @@ <h5>{{ data[\\'message\\'] }}</h5>\\n                 }\\r\\n                 overall = overall.concat(allcmdlines)\\r\\n                 $(\"#rulesdiv\").html(overall.join(\"\"))\\r\\n+                for (let [id, name] of Object.entries(big_ol_dict_two)) {\\r\\n+                    $(`#${id}`).text(name)\\r\\n+                }\\r\\n                 $(\"#fetchrulesstatus\").html(\"{{ _(\\'Refreshed rules\\') }}.\")\\r\\n             }\\r\\n         }\\r\\n@@ -1378,18 +1399,20 @@ <h5>{{ data[\\'message\\'] }}</h5>\\n \\r\\n     $(document).on(\\'click\\', \\'.adminroleoption\\', function () {\\r\\n         var elm = $(this)\\r\\n+        let random_number = Math.floor(Math.random() * Math.floor(100000))\\r\\n         $(\"#adminrolelist\").append(`\\r\\n                 <li>\\r\\n                     <div class=\"row\">\\r\\n                         <div class=\"col-md-10 col-8\">\\r\\n-                            <input class=\"form-control adminroleinput\" value=\"${elm.text()}\" disabled=True data-id=\"${elm.attr(\"data-id\")}\">\\r\\n+                            <input class=\"form-control adminroleinput\" value=\"Loading...\" disabled=True data-id=\"${elm.attr(\"data-id\")}\" id=\"admin-role-${random_number}\">\\r\\n                         </div>\\r\\n                         <div class=\"col-md-1 col-1\">\\r\\n                             <span class=\"admin-role-x clickable\"><i class=\"tim-icons icon-simple-remove\" style=\"float: right; margin-top: 10px;\"></i></span>\\r\\n                         </div>\\r\\n                     </div>\\r\\n                 </li>\\r\\n             `)\\r\\n+        $(`#admin-role-${random_number}`).val(elm.text())\\r\\n         elm.remove()\\r\\n     })\\r\\n \\r\\n@@ -1442,18 +1465,20 @@ <h5>{{ data[\\'message\\'] }}</h5>\\n \\r\\n     $(document).on(\\'click\\', \\'.modroleoption\\', function () {\\r\\n         var elm = $(this)\\r\\n+        let random_number = Math.floor(Math.random() * Math.floor(100000))\\r\\n         $(\"#modrolelist\").append(`\\r\\n                 <li>\\r\\n                     <div class=\"row\">\\r\\n                         <div class=\"col-md-10 col-8\">\\r\\n-                            <input class=\"form-control modroleinput\" value=\"${elm.text()}\" disabled=True data-id=\"${elm.attr(\"data-id\")}\">\\r\\n+                            <input class=\"form-control modroleinput\" value=\"Loading...\" disabled=True data-id=\"${elm.attr(\"data-id\")}\" id=\"mod-role-${random_number}\">\\r\\n                         </div>\\r\\n                         <div class=\"col-md-1 col-1\">\\r\\n                             <span class=\"mod-role-x clickable\"><i class=\"tim-icons icon-simple-remove\" style=\"float: right; margin-top: 10px;\"></i></span>\\r\\n                         </div>\\r\\n                     </div>\\r\\n                 </li>\\r\\n             `)\\r\\n+        $(`#mod-role-${random_number}`).val(elm.text())\\r\\n         elm.remove()\\r\\n     })'}}",
      "message_norm": "[ui] fix selectpicker not rendering properly",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['reddash/app/home/templates/guild.html'])",
      "num_files": 1.0
    },
    {
      "index": 277,
      "vuln_id": "GHSA-3mpr-hq3p-49h9",
      "cwe_id": "{'CWE-471'}",
      "score": 0.0,
      "chain": "{'https://github.com/jonschlinkert/mixin-deep/commit/578b0bc5e74e14de9ef4975f504dc698796bdf9c'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in mixin-deep Versions of `mixin-deep` before 1.3.1 are vulnerable to prototype pollution via merging functions.\n\n\n## Recommendation\n\nUpdate to version 1.3.1 or later.",
      "published_date": "2018-07-26",
      "chain_len": 1,
      "project": "https://github.com/jonschlinkert/mixin-deep",
      "commit_href": "https://github.com/jonschlinkert/mixin-deep/commit/578b0bc5e74e14de9ef4975f504dc698796bdf9c",
      "commit_sha": "578b0bc5e74e14de9ef4975f504dc698796bdf9c",
      "patch": "SINGLE",
      "chain_ord": "['578b0bc5e74e14de9ef4975f504dc698796bdf9c']",
      "before_first_fix_commit": "{'7705bdf88ff0263242c07c824d20526203876668'}",
      "last_fix_commit": "578b0bc5e74e14de9ef4975f504dc698796bdf9c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/07/2018, 16:04:06",
      "message": "exclude __proto__",
      "author": "doowb",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'index.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/jonschlinkert/mixin-deep/raw/578b0bc5e74e14de9ef4975f504dc698796bdf9c/index.js', 'patch': \"@@ -23,6 +23,10 @@ function mixinDeep(target, objects) {\\n  */\\n \\n function copy(val, key) {\\n+  if (key === '__proto__') {\\n+    return;\\n+  }\\n+\\n   var obj = this[key];\\n   if (isObject(val) && isObject(obj)) {\\n     mixinDeep(obj, val);\"}}",
      "message_norm": "exclude __proto__",
      "language": "pt",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 725,
      "vuln_id": "GHSA-5xwc-mrhx-5g3m",
      "cwe_id": "{'CWE-824'}",
      "score": 7.1,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/f2a673bd34f0d64b8e40a551ac78989d16daad09'}",
      "dataset": "osv",
      "summary": "Reference binding to nullptr in `MatrixDiagV*` ops ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in all operations of type `tf.raw_ops.MatrixDiagV*`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.MatrixDiagV3(\n  diagonal=[1,0],\n  k=[],\n  num_rows=[1,2,3],\n  num_cols=[4,5],\n  padding_value=[],\n  align='RIGHT_RIGHT')\n``` \n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/linalg/matrix_diag_op.cc) has incomplete validation that the value of `k` is a valid tensor. We have check that this value is either a scalar or a vector, but there is no check for the number of elements. If this is an empty tensor, then code that accesses the first element of the tensor is wrong:\n\n```cc\n  auto& diag_index = context->input(1);\n  ...\n  lower_diag_index = diag_index.flat<int32>()(0);\n```\n\n### Patches\nWe have patched the issue in GitHub commit [f2a673bd34f0d64b8e40a551ac78989d16daad09](https://github.com/tensorflow/tensorflow/commit/f2a673bd34f0d64b8e40a551ac78989d16daad09).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/f2a673bd34f0d64b8e40a551ac78989d16daad09",
      "commit_sha": "f2a673bd34f0d64b8e40a551ac78989d16daad09",
      "patch": "SINGLE",
      "chain_ord": "['f2a673bd34f0d64b8e40a551ac78989d16daad09']",
      "before_first_fix_commit": "{'ff8894044dfae5568ecbf2ed514c1a37dc394f1b'}",
      "last_fix_commit": "f2a673bd34f0d64b8e40a551ac78989d16daad09",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/31/2021, 02:00:00",
      "message": "Add missing validation to `matrix_diag_op.cc`\n\nPiperOrigin-RevId: 387923533\nChange-Id: Idfffeb328d5f9c6748d992d28a56d6e9e45103a0",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'tensorflow/core/kernels/linalg/matrix_diag_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/f2a673bd34f0d64b8e40a551ac78989d16daad09/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_diag_op.cc', 'patch': '@@ -73,6 +73,9 @@ class MatrixDiagPartOp : public OpKernel {\\n                   errors::InvalidArgument(\\n                       \"diag_index must be a scalar or vector, received shape: \",\\n                       diag_index.shape().DebugString()));\\n+      OP_REQUIRES(context, diag_index.NumElements() > 0,\\n+                  errors::InvalidArgument(\\n+                      \"Expected diag_index to have at least 1 element\"));\\n       lower_diag_index = diag_index.flat<int32>()(0);\\n       upper_diag_index = lower_diag_index;\\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {\\n@@ -179,6 +182,9 @@ class MatrixDiagOp : public OpKernel {\\n                   errors::InvalidArgument(\\n                       \"diag_index must be a scalar or vector, received shape: \",\\n                       diag_index.shape().DebugString()));\\n+      OP_REQUIRES(context, diag_index.NumElements() > 0,\\n+                  errors::InvalidArgument(\\n+                      \"Expected diag_index to have at least 1 element\"));\\n       lower_diag_index = diag_index.flat<int32>()(0);\\n       upper_diag_index = lower_diag_index;\\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {'}}",
      "message_norm": "add missing validation to `matrix_diag_op.cc`\n\npiperorigin-revid: 387923533\nchange-id: idfffeb328d5f9c6748d992d28a56d6e9e45103a0",
      "language": "en",
      "entities": "[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('387923533', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/linalg/matrix_diag_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3252,
      "vuln_id": "GHSA-w8rc-pgxq-x2cj",
      "cwe_id": "{'CWE-20'}",
      "score": 6.5,
      "chain": "{'https://github.com/shopizer-ecommerce/shopizer/commit/929ca0839a80c6f4dad087e0259089908787ad2a'}",
      "dataset": "osv",
      "summary": "Negative charge in shopping cart in Shopizer ### Impact\nUsing API or Controller based versions negative quantity is not adequately validated hence creating incorrect shopping cart and order total. \n\n### Patches\nAdding a back-end verification to check that quantity parameter isn't negative. If so, it is set to 1. Patched in 2.11.0\n\n### Workarounds\nWithout uprading, it's possible to just apply the fixes in the same files it's done for the patch. Or you use javax constraint validation on the quantity parameter.\n\n### References\n[Input Validation](https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html)\n[Using bean validation constraint](https://javaee.github.io/tutorial/bean-validation002.html)\n[Commits with fixes](https://github.com/shopizer-ecommerce/shopizer/commit/929ca0839a80c6f4dad087e0259089908787ad2a)\nCVE Details below : \n[Mitre](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11007)\n[NVD](https://nvd.nist.gov/vuln/detail/CVE-2020-11007)\n\n### Credits\nFound and solved by Yannick Gosset from Aix-Marseille University cybersecurity\nmaster program supervised by Yassine Ilmi",
      "published_date": "2020-04-22",
      "chain_len": 1,
      "project": "https://github.com/shopizer-ecommerce/shopizer",
      "commit_href": "https://github.com/shopizer-ecommerce/shopizer/commit/929ca0839a80c6f4dad087e0259089908787ad2a",
      "commit_sha": "929ca0839a80c6f4dad087e0259089908787ad2a",
      "patch": "SINGLE",
      "chain_ord": "['929ca0839a80c6f4dad087e0259089908787ad2a']",
      "before_first_fix_commit": "{'de8a8e3183f8c5fed4695f889e309a6fff70adae', '6858049b39bdc51b71e6419b7c4bba1347737cb7'}",
      "last_fix_commit": "929ca0839a80c6f4dad087e0259089908787ad2a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/10/2020, 13:35:12",
      "message": "Merge pull request from GHSA-w8rc-pgxq-x2cj\n\nFixing negative charge vulnerability",
      "author": "Shopizer",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 7, 'total': 12}",
      "files": "{'sm-shop/src/main/java/com/salesmanager/shop/store/controller/shoppingCart/facade/ShoppingCartFacadeImpl.java': {'additions': 5, 'deletions': 7, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/shopizer-ecommerce/shopizer/raw/929ca0839a80c6f4dad087e0259089908787ad2a/sm-shop%2Fsrc%2Fmain%2Fjava%2Fcom%2Fsalesmanager%2Fshop%2Fstore%2Fcontroller%2FshoppingCart%2Ffacade%2FShoppingCartFacadeImpl.java', 'patch': '@@ -108,7 +108,7 @@ public ShoppingCartData addItemsToShoppingCart( final ShoppingCartData shoppingC\\n     {\\n \\n         ShoppingCart cartModel = null;\\n-        \\n+        if(item.getQuantity() < 1) item.setQuantity(1);\\n         /**\\n          * Sometimes a user logs in and a shopping cart is present in db (shoppingCartData\\n          * but ui has no cookie with shopping cart code so the cart code will have\\n@@ -216,7 +216,7 @@ private com.salesmanager.core.model.shoppingcart.ShoppingCartItem createCartItem\\n         }\\n         \\t\\n         for(ProductAvailability availability : availabilities) {\\n-        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() ==0) {\\n+        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() <= 0) {\\n                 throw new Exception( \"Item with id \" + product.getId() + \" is not available\");\\n         \\t}\\n         }\\n@@ -288,7 +288,7 @@ private com.salesmanager.core.model.shoppingcart.ShoppingCartItem createCartItem\\n         }\\n         \\t\\n         for(ProductAvailability availability : availabilities) {\\n-        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() ==0) {\\n+        \\tif(availability.getProductQuantity() == null || availability.getProductQuantity().intValue() <= 0) {\\n                 throw new Exception( \"Item with id \" + product.getId() + \" is not available\");\\n         \\t}\\n         }\\n@@ -554,8 +554,7 @@ public ShoppingCartData updateCartItem( final Long itemID, final String cartId,\\n         return null;\\n     }\\n     \\n-    @SuppressWarnings(\"unchecked\")\\n-\\t@Override\\n+    @Override\\n     public ShoppingCartData updateCartItems( final List<ShoppingCartItem> shoppingCartItems, final MerchantStore store, final Language language )\\n             throws Exception\\n         {\\n@@ -720,7 +719,6 @@ public ReadableShoppingCart addToCart(PersistableShoppingCartItem item, Merchant\\n \\t}\\n \\t\\n \\n-\\t@SuppressWarnings(\"unchecked\")\\n \\t@Override\\n \\tpublic void removeShoppingCartItem(String cartCode, Long productId,\\n \\t      MerchantStore merchant, Language language) throws Exception {\\n@@ -914,7 +912,7 @@ public ReadableShoppingCart addToCart(Customer customer, PersistableShoppingCart\\n \\t\\t\\n \\t\\tValidate.notNull(customer,\"Customer cannot be null\");\\n \\t\\tValidate.notNull(customer.getId(),\"Customer.id cannot be null or empty\");\\n-\\t\\t\\n+\\t\\tif(item.getQuantity() < 1) item.setQuantity(1);\\n \\t\\t//Check if customer has an existing shopping cart\\n \\t\\tShoppingCart cartModel = shoppingCartService.getByCustomer(customer);'}}",
      "message_norm": "merge pull request from ghsa-w8rc-pgxq-x2cj\n\nfixing negative charge vulnerability",
      "language": "en",
      "entities": "[('ghsa-w8rc-pgxq-x2cj', 'VULNID', 'GHSA'), ('fixing', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['sm-shop/src/main/java/com/salesmanager/shop/store/controller/shoppingCart/facade/ShoppingCartFacadeImpl.java'])",
      "num_files": 1.0
    },
    {
      "index": 1355,
      "vuln_id": "GHSA-9c84-4hx6-xmm4",
      "cwe_id": "{'CWE-190'}",
      "score": 6.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/4253f96a58486ffe84b61c0415bb234a4632ee73'}",
      "dataset": "osv",
      "summary": "Integer overflow in TFLite concatentation ### Impact\nThe TFLite implementation of concatenation is [vulnerable to an integer overflow issue](https://github.com/tensorflow/tensorflow/blob/7b7352a724b690b11bfaae2cd54bc3907daf6285/tensorflow/lite/kernels/concatenation.cc#L70-L76):\n\n```cc\nfor (int d = 0; d < t0->dims->size; ++d) {\n  if (d == axis) { \n    sum_axis += t->dims->data[axis]; \n  } else {\n    TF_LITE_ENSURE_EQ(context, t->dims->data[d], t0->dims->data[d]);\n  }\n}\n```\n\nAn attacker can craft a model such that the dimensions of one of the concatenation input overflow the values of `int`. TFLite uses `int` to represent tensor dimensions, whereas TF uses `int64`. Hence, valid TF models can trigger an integer overflow when converted to TFLite format.\n\n### Patches\nWe have patched the issue in GitHub commit [4253f96a58486ffe84b61c0415bb234a4632ee73](https://github.com/tensorflow/tensorflow/commit/4253f96a58486ffe84b61c0415bb234a4632ee73).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/4253f96a58486ffe84b61c0415bb234a4632ee73",
      "commit_sha": "4253f96a58486ffe84b61c0415bb234a4632ee73",
      "patch": "SINGLE",
      "chain_ord": "['4253f96a58486ffe84b61c0415bb234a4632ee73']",
      "before_first_fix_commit": "{'7b7352a724b690b11bfaae2cd54bc3907daf6285'}",
      "last_fix_commit": "4253f96a58486ffe84b61c0415bb234a4632ee73",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 23:50:55",
      "message": "Fix integer overflow in TFLite concat\n\nPiperOrigin-RevId: 371013841\nChange-Id: I6a4782ce7ca753e23ff31e7fb6aeb7f9d412cd29",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'tensorflow/lite/kernels/concatenation.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/4253f96a58486ffe84b61c0415bb234a4632ee73/tensorflow%2Flite%2Fkernels%2Fconcatenation.cc', 'patch': '@@ -16,6 +16,8 @@ limitations under the License.\\n \\n #include <stdint.h>\\n \\n+#include <limits>\\n+\\n #include \"tensorflow/lite/c/builtin_op_data.h\"\\n #include \"tensorflow/lite/c/common.h\"\\n #include \"tensorflow/lite/kernels/internal/compatibility.h\"\\n@@ -69,6 +71,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n     TF_LITE_ENSURE_EQ(context, t->type, input_type);\\n     for (int d = 0; d < t0->dims->size; ++d) {\\n       if (d == axis) {\\n+        // Avoid integer overflow in sum_axis below\\n+        TF_LITE_ENSURE(context, t->dims->data[axis] >= 0);\\n+        TF_LITE_ENSURE(context, t->dims->data[axis] <=\\n+                                    std::numeric_limits<int>::max() - sum_axis);\\n         sum_axis += t->dims->data[axis];\\n       } else {\\n         TF_LITE_ENSURE_EQ(context, t->dims->data[d], t0->dims->data[d]);'}}",
      "message_norm": "fix integer overflow in tflite concat\n\npiperorigin-revid: 371013841\nchange-id: i6a4782ce7ca753e23ff31e7fb6aeb7f9d412cd29",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('integer overflow', 'SECWORD', ''), ('371013841', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/concatenation.cc'])",
      "num_files": 1.0
    },
    {
      "index": 215,
      "vuln_id": "GHSA-37pf-w9ff-gqvm",
      "cwe_id": "{'CWE-787'}",
      "score": 7.5,
      "chain": "{'https://github.com/chakra-core/ChakraCore/commit/d797e3f00e34c12c8c0ae52f56344325439dccd7', 'https://github.com/chakra-core/ChakraCore/commit/87ac2b5a751710ee288fdda3fd4d9818e22387a1'}",
      "dataset": "osv",
      "summary": "Out-of-bounds write A remote code execution vulnerability exists in the way that the Chakra scripting engine handles objects in memory in Microsoft Edge, aka 'Chakra Scripting Engine Memory Corruption Vulnerability'. This CVE ID is unique from CVE-2019-0912, CVE-2019-0913, CVE-2019-0914, CVE-2019-0915, CVE-2019-0916, CVE-2019-0917, CVE-2019-0922, CVE-2019-0923, CVE-2019-0924, CVE-2019-0925, CVE-2019-0933, CVE-2019-0937.",
      "published_date": "2021-03-29",
      "chain_len": 2,
      "project": "https://github.com/chakra-core/ChakraCore",
      "commit_href": "https://github.com/chakra-core/ChakraCore/commit/87ac2b5a751710ee288fdda3fd4d9818e22387a1",
      "commit_sha": "87ac2b5a751710ee288fdda3fd4d9818e22387a1",
      "patch": "MULTI",
      "chain_ord": "['87ac2b5a751710ee288fdda3fd4d9818e22387a1', 'd797e3f00e34c12c8c0ae52f56344325439dccd7']",
      "before_first_fix_commit": "{'ea0491305137183603bf43844b5584d4cc972e28', '4594e340bc9ca9f857010a68e8b562d65b46eed6'}",
      "last_fix_commit": "d797e3f00e34c12c8c0ae52f56344325439dccd7",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/17/2019, 17:22:17",
      "message": "[CVE-2019-0927]",
      "author": "Michael Holman",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'lib/Backend/GlobOptFields.cpp': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/chakra-core/ChakraCore/raw/87ac2b5a751710ee288fdda3fd4d9818e22387a1/lib%2FBackend%2FGlobOptFields.cpp', 'patch': '@@ -394,6 +394,7 @@ GlobOpt::ProcessFieldKills(IR::Instr *instr, BVSparse<JitArenaAllocator> *bv, bo\\n     case Js::OpCode::StRootFldStrict:\\n     case Js::OpCode::StSlot:\\n     case Js::OpCode::StSlotChkUndecl:\\n+    case Js::OpCode::StSuperFld:\\n         Assert(dstOpnd != nullptr);\\n         sym = dstOpnd->AsSymOpnd()->m_sym;\\n         if (inGlobOpt)'}}",
      "message_norm": "[cve-2019-0927]",
      "language": "ro",
      "entities": "[('cve-2019-0927', 'VULNID', 'CVE')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/Backend/GlobOptFields.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 1369,
      "vuln_id": "GHSA-9g8h-pjm4-q92p",
      "cwe_id": "{'CWE-787'}",
      "score": 5.5,
      "chain": "{'https://github.com/opencv/opencv/pull/10566/commits/435a3e337bd9d4e11af61cf8b8afca067bf1a8aa'}",
      "dataset": "osv",
      "summary": "Out-of-bounds Write in OpenCV. In OpenCV 3.3.1 (corresponding with OpenCV-Python 3.3.1.11), a heap-based buffer overflow happens in cv::Jpeg2KDecoder::readComponent8u in modules/imgcodecs/src/grfmt_jpeg2000.cpp when parsing a crafted image file.",
      "published_date": "2021-10-12",
      "chain_len": 1,
      "project": "https://github.com/opencv/opencv",
      "commit_href": "https://github.com/opencv/opencv/pull/10566/commits/435a3e337bd9d4e11af61cf8b8afca067bf1a8aa",
      "commit_sha": "435a3e337bd9d4e11af61cf8b8afca067bf1a8aa",
      "patch": "SINGLE",
      "chain_ord": "['435a3e337bd9d4e11af61cf8b8afca067bf1a8aa']",
      "before_first_fix_commit": "{'f34a0a874a029a6201df0acbf46eeeaab8686e4d'}",
      "last_fix_commit": "435a3e337bd9d4e11af61cf8b8afca067bf1a8aa",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/09/2018, 14:36:57",
      "message": "imgcodecs: add more Jasper checks for supported and tested cases",
      "author": "Alexander Alekhin",
      "comments": null,
      "stats": "{'additions': 39, 'deletions': 7, 'total': 46}",
      "files": "{'modules/imgcodecs/src/grfmt_jpeg2000.cpp': {'additions': 39, 'deletions': 7, 'changes': 46, 'status': 'modified', 'raw_url': 'https://github.com/opencv/opencv/raw/435a3e337bd9d4e11af61cf8b8afca067bf1a8aa/modules%2Fimgcodecs%2Fsrc%2Fgrfmt_jpeg2000.cpp', 'patch': '@@ -77,7 +77,8 @@ static JasperInitializer initialize_jasper;\\n \\n Jpeg2KDecoder::Jpeg2KDecoder()\\n {\\n-    m_signature = \\'\\\\0\\' + String() + \\'\\\\0\\' + String() + \\'\\\\0\\' + String(\"\\\\x0cjP  \\\\r\\\\n\\\\x87\\\\n\");\\n+    static const unsigned char signature_[12] = { 0, 0, 0, 0x0c, \\'j\\', \\'P\\', \\' \\', \\' \\', 13, 10, 0x87, 10};\\n+    m_signature = String((const char*)signature_, (const char*)signature_ + sizeof(signature_));\\n     m_stream = 0;\\n     m_image = 0;\\n }\\n@@ -121,6 +122,8 @@ bool  Jpeg2KDecoder::readHeader()\\n         jas_image_t* image = jas_image_decode( stream, -1, 0 );\\n         m_image = image;\\n         if( image ) {\\n+            CV_Assert(0 == (jas_image_tlx(image)) && \"not supported\");\\n+            CV_Assert(0 == (jas_image_tly(image)) && \"not supported\");\\n             m_width = jas_image_width( image );\\n             m_height = jas_image_height( image );\\n \\n@@ -130,14 +133,31 @@ bool  Jpeg2KDecoder::readHeader()\\n             for( int i = 0; i < numcmpts; i++ )\\n             {\\n                 int depth_i = jas_image_cmptprec( image, i );\\n+                CV_Assert(depth == 0 || depth == depth_i); // component data type mismatch\\n                 depth = MAX(depth, depth_i);\\n                 if( jas_image_cmpttype( image, i ) > 2 )\\n                     continue;\\n+                int sgnd = jas_image_cmptsgnd(image, i);\\n+                int xstart = jas_image_cmpttlx(image, i);\\n+                int xend = jas_image_cmptbrx(image, i);\\n+                int xstep = jas_image_cmpthstep(image, i);\\n+                int ystart = jas_image_cmpttly(image, i);\\n+                int yend = jas_image_cmptbry(image, i);\\n+                int ystep = jas_image_cmptvstep(image, i);\\n+                CV_Assert(sgnd == 0 && \"not supported\");\\n+                CV_Assert(xstart == 0 && \"not supported\");\\n+                CV_Assert(ystart == 0 && \"not supported\");\\n+                CV_Assert(xstep == 1 && \"not supported\");\\n+                CV_Assert(ystep == 1 && \"not supported\");\\n+                CV_Assert(xend == m_width);\\n+                CV_Assert(yend == m_height);\\n                 cntcmpts++;\\n             }\\n \\n             if( cntcmpts )\\n             {\\n+                CV_Assert(depth == 8 || depth == 16);\\n+                CV_Assert(cntcmpts == 1 || cntcmpts == 3);\\n                 m_type = CV_MAKETYPE(depth <= 8 ? CV_8U : CV_16U, cntcmpts > 1 ? 3 : 1);\\n                 result = true;\\n             }\\n@@ -150,9 +170,14 @@ bool  Jpeg2KDecoder::readHeader()\\n     return result;\\n }\\n \\n+static void Jpeg2KDecoder_close(Jpeg2KDecoder* ptr)\\n+{\\n+    ptr->close();\\n+}\\n \\n bool  Jpeg2KDecoder::readData( Mat& img )\\n {\\n+    Ptr<Jpeg2KDecoder> close_this(this, Jpeg2KDecoder_close);\\n     bool result = false;\\n     int color = img.channels() > 1;\\n     uchar* data = img.ptr();\\n@@ -204,11 +229,16 @@ bool  Jpeg2KDecoder::readData( Mat& img )\\n                     result = true;\\n                 }\\n                 else\\n-                    fprintf(stderr, \"JPEG 2000 LOADER ERROR: cannot convert colorspace\\\\n\");\\n+                {\\n+                    jas_cmprof_destroy(clrprof);\\n+                    CV_Error(Error::StsError, \"JPEG 2000 LOADER ERROR: cannot convert colorspace\");\\n+                }\\n                 jas_cmprof_destroy( clrprof );\\n             }\\n             else\\n-                fprintf(stderr, \"JPEG 2000 LOADER ERROR: unable to create colorspace\\\\n\");\\n+            {\\n+                CV_Error(Error::StsError, \"JPEG 2000 LOADER ERROR: unable to create colorspace\");\\n+            }\\n         }\\n         else\\n             result = true;\\n@@ -257,8 +287,8 @@ bool  Jpeg2KDecoder::readData( Mat& img )\\n                                 result = readComponent16u( ((unsigned short *)data) + i, buffer, validateToInt(step / 2), cmptlut[i], maxval, offset, ncmpts );\\n                             if( !result )\\n                             {\\n-                                i = ncmpts;\\n-                                result = false;\\n+                                jas_matrix_destroy( buffer );\\n+                                CV_Error(Error::StsError, \"JPEG2000 LOADER ERROR: failed to read component\");\\n                             }\\n                         }\\n                         jas_matrix_destroy( buffer );\\n@@ -267,10 +297,12 @@ bool  Jpeg2KDecoder::readData( Mat& img )\\n             }\\n         }\\n         else\\n-            fprintf(stderr, \"JPEG2000 LOADER ERROR: colorspace conversion failed\\\\n\" );\\n+        {\\n+            CV_Error(Error::StsError, \"JPEG2000 LOADER ERROR: colorspace conversion failed\");\\n+        }\\n     }\\n \\n-    close();\\n+    CV_Assert(result == true);\\n \\n #ifndef _WIN32\\n     if (!clr.empty())'}}",
      "message_norm": "imgcodecs: add more jasper checks for supported and tested cases",
      "language": "en",
      "entities": "[('add', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['modules/imgcodecs/src/grfmt_jpeg2000.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 309,
      "vuln_id": "GHSA-3r95-23jp-mhvg",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/TYPO3/typo3/commit/6f2554dc4ea0b670fd5599c54fd788d4db96c4a0'}",
      "dataset": "osv",
      "summary": "Cross-Site Scripting in TYPO3's Form Framework > ### Meta\n> * CVSS: `CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:N/E:F/RL:O/RC:C` (4.9)\n\n### Problem\nIt has been discovered that the Form Designer backend module of the Form Framework is vulnerable to cross-site scripting. A valid backend user account with access to the form module is needed to exploit this vulnerability.\n\n### Solution\nUpdate to TYPO3 versions 8.7.47 ELTS, 9.5.35 ELTS, 10.4.29, 11.5.11 that fix the problem described above.\n\n### Credits\nThanks to Gabe Troyan who reported and fixed the issue.\n\n### References\n* [TYPO3-CORE-SA-2022-003](https://typo3.org/security/advisory/typo3-core-sa-2022-003)",
      "published_date": "2022-06-17",
      "chain_len": 1,
      "project": "https://github.com/TYPO3/typo3",
      "commit_href": "https://github.com/TYPO3/typo3/commit/6f2554dc4ea0b670fd5599c54fd788d4db96c4a0",
      "commit_sha": "6f2554dc4ea0b670fd5599c54fd788d4db96c4a0",
      "patch": "SINGLE",
      "chain_ord": "['6f2554dc4ea0b670fd5599c54fd788d4db96c4a0']",
      "before_first_fix_commit": "{'c93ea692e7dfef03b7c50fe5437487545bee4d6a'}",
      "last_fix_commit": "6f2554dc4ea0b670fd5599c54fd788d4db96c4a0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "06/14/2022, 07:17:30",
      "message": "[SECURITY] Ensure text preview of multivalue items in form editor\n\nMultivalue items in the form editor user interface were previewed\nas HTML, but should be treated as scalar text only.\n\nResolves: #96743\nReleases: main, 11.5, 10.4\nChange-Id: I5e8dab26119490ecf19ac5d48c2bc7a5a00daaad\nSecurity-Bulletin: TYPO3-CORE-SA-2022-003\nSecurity-References: CVE-2022-31048\nReviewed-on: https://review.typo3.org/c/Packages/TYPO3.CMS/+/73297\nTested-by: Oliver Hader <oliver.hader@typo3.org>\nReviewed-by: Oliver Hader <oliver.hader@typo3.org>",
      "author": "Gabe Troyan",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 6, 'total': 12}",
      "files": "{'typo3/sysext/form/Resources/Public/JavaScript/backend/form-editor/stage-component.js': {'additions': 6, 'deletions': 6, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/TYPO3/typo3/raw/6f2554dc4ea0b670fd5599c54fd788d4db96c4a0/typo3%2Fsysext%2Fform%2FResources%2FPublic%2FJavaScript%2Fbackend%2Fform-editor%2Fstage-component.js', 'patch': \"@@ -513,10 +513,10 @@ function factory($, Helper, Icons) {\\n      */\\n     function setStageHeadline(title) {\\n       if (getUtility().isUndefinedOrNull(title)) {\\n-        title = buildTitleByFormElement();\\n+        title = buildTitleByFormElement().text();\\n       }\\n \\n-      $(getHelper().getDomElementDataIdentifierSelector('stageHeadline')).html(title);\\n+      $(getHelper().getDomElementDataIdentifierSelector('stageHeadline')).text(title);\\n     };\\n \\n     /**\\n@@ -981,10 +981,10 @@ function factory($, Helper, Icons) {\\n \\n       getHelper()\\n         .getTemplatePropertyDomElement('_type', template)\\n-        .append(getFormElementDefinition(formElement, 'label'));\\n+        .append(document.createTextNode(getFormElementDefinition(formElement, 'label')));\\n       getHelper()\\n         .getTemplatePropertyDomElement('_identifier', template)\\n-        .append(formElement.get('identifier'));\\n+        .append(document.createTextNode(formElement.get('identifier')));\\n     };\\n \\n     /**\\n@@ -1029,7 +1029,7 @@ function factory($, Helper, Icons) {\\n \\n             getHelper()\\n               .getTemplatePropertyDomElement('_label', rowTemplate)\\n-              .append(collectionElementConfiguration['label']);\\n+              .append(document.createTextNode(collectionElementConfiguration['label']));\\n             $(getHelper().getDomElementDataIdentifierSelector('validatorsContainer'), $(template))\\n               .append(rowTemplate.html());\\n           }\\n@@ -1089,7 +1089,7 @@ function factory($, Helper, Icons) {\\n           }\\n         }\\n \\n-        getHelper().getTemplatePropertyDomElement('_label', rowTemplate).append(label);\\n+        getHelper().getTemplatePropertyDomElement('_label', rowTemplate).append(document.createTextNode(label));\\n \\n         if (isPreselected) {\\n           getHelper().getTemplatePropertyDomElement('_label', rowTemplate).addClass(\"}}",
      "message_norm": "[security] ensure text preview of multivalue items in form editor\n\nmultivalue items in the form editor user interface were previewed\nas html, but should be treated as scalar text only.\n\nresolves: #96743\nreleases: main, 11.5, 10.4\nchange-id: i5e8dab26119490ecf19ac5d48c2bc7a5a00daaad\nsecurity-bulletin: typo3-core-sa-2022-003\nsecurity-references: cve-2022-31048\nreviewed-on: https://review.typo3.org/c/packages/typo3.cms/+/73297\ntested-by: oliver hader <oliver.hader@typo3.org>\nreviewed-by: oliver hader <oliver.hader@typo3.org>",
      "language": "en",
      "entities": "[('security', 'SECWORD', ''), ('ensure', 'ACTION', ''), ('#96743', 'ISSUE', ''), ('security', 'SECWORD', ''), ('security', 'SECWORD', ''), ('cve-2022-31048', 'VULNID', 'CVE'), ('https://review.typo3.org/c/packages/typo3.cms/+/73297', 'URL', ''), ('oliver.hader@typo3.org', 'EMAIL', ''), ('oliver.hader@typo3.org', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['typo3/sysext/form/Resources/Public/JavaScript/backend/form-editor/stage-component.js'])",
      "num_files": 1.0
    },
    {
      "index": 2574,
      "vuln_id": "GHSA-pgcq-h79j-2f69",
      "cwe_id": "{'CWE-354'}",
      "score": 7.0,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/4d74d8a00b07441cba090a02e0dd9ed385145bf4', 'https://github.com/tensorflow/tensorflow/commit/da4aad5946be30e5f049920fa076e1f7ef021261', 'https://github.com/tensorflow/tensorflow/commit/e7f497570abb6b4ae5af4970620cd880e4c0c904', 'https://github.com/tensorflow/tensorflow/commit/4dddb2fd0b01cdd196101afbba6518658a2c9e07', 'https://github.com/tensorflow/tensorflow/commit/579261dcd446385831fe4f7457d802a59685121d', 'https://github.com/tensorflow/tensorflow/commit/68422b215e618df5ad375bcdc6d2052e9fd3080a'}",
      "dataset": "osv",
      "summary": "Incomplete validation of shapes in multiple TF ops ### Impact\nSeveral TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible.\n\nWe have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues.\n\n### Patches\nWe have patched the issue in GitHub commits [68422b215e618df5ad375bcdc6d2052e9fd3080a](https://github.com/tensorflow/tensorflow/commit/68422b215e618df5ad375bcdc6d2052e9fd3080a), [4d74d8a00b07441cba090a02e0dd9ed385145bf4](https://github.com/tensorflow/tensorflow/commit/4d74d8a00b07441cba090a02e0dd9ed385145bf4), [579261dcd446385831fe4f7457d802a59685121d](https://github.com/tensorflow/tensorflow/commit/579261dcd446385831fe4f7457d802a59685121d), [da4aad5946be30e5f049920fa076e1f7ef021261](https://github.com/tensorflow/tensorflow/commit/da4aad5946be30e5f049920fa076e1f7ef021261), [4dddb2fd0b01cdd196101afbba6518658a2c9e07](https://github.com/tensorflow/tensorflow/commit/4dddb2fd0b01cdd196101afbba6518658a2c9e07), and [e7f497570abb6b4ae5af4970620cd880e4c0c904](https://github.com/tensorflow/tensorflow/commit/e7f497570abb6b4ae5af4970620cd880e4c0c904).\n\nThese fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2021-11-10",
      "chain_len": 6,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/e7f497570abb6b4ae5af4970620cd880e4c0c904",
      "commit_sha": "e7f497570abb6b4ae5af4970620cd880e4c0c904",
      "patch": "MULTI",
      "chain_ord": "['579261dcd446385831fe4f7457d802a59685121d', '4d74d8a00b07441cba090a02e0dd9ed385145bf4', '68422b215e618df5ad375bcdc6d2052e9fd3080a', 'da4aad5946be30e5f049920fa076e1f7ef021261', '4dddb2fd0b01cdd196101afbba6518658a2c9e07', 'e7f497570abb6b4ae5af4970620cd880e4c0c904']",
      "before_first_fix_commit": "{'e0214528739cad3bd02fbf2696a793dc342ffb94'}",
      "last_fix_commit": "e7f497570abb6b4ae5af4970620cd880e4c0c904",
      "chain_ord_pos": 6.0,
      "commit_datetime": "10/20/2021, 22:41:05",
      "message": "Fix segfault on OOM in Conv2D.\n\nPiperOrigin-RevId: 404655317\nChange-Id: I33588dbd3f5d0fef980e3c908bf5515a9ee09ce7",
      "author": "Reed Wanderman-Milne",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 3, 'total': 15}",
      "files": "{'tensorflow/core/kernels/conv_ops.cc': {'additions': 12, 'deletions': 3, 'changes': 15, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/e7f497570abb6b4ae5af4970620cd880e4c0c904/tensorflow%2Fcore%2Fkernels%2Fconv_ops.cc', 'patch': '@@ -183,20 +183,29 @@ struct LaunchGrouped {\\n     auto on_shuffled = [&]() { shuffles_completed.DecrementCount(); };\\n \\n     // Shuffle input into temporary tensor.\\n-    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\\n+    Tensor input_shuffled;\\n+    OP_REQUIRES_OK(\\n+        ctx, ctx->allocate_temp(input.dtype(), TensorShape(post_shuffle(input)),\\n+                                &input_shuffled));\\n     input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\\n         input.shaped<T, 5>(pre_shuffle(input)).shuffle(shuffle);\\n \\n     // Shuffle filter into temporary tensor.\\n-    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\\n+    Tensor filter_shuffled;\\n+    OP_REQUIRES_OK(ctx, ctx->allocate_temp(filter.dtype(),\\n+                                           TensorShape(post_shuffle(filter)),\\n+                                           &filter_shuffled));\\n     filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\\n         filter.shaped<T, 5>(pre_shuffle(filter)).shuffle(shuffle);\\n \\n     // Wait for the completion of input/filter shuffles.\\n     shuffles_completed.Wait();\\n \\n     // Write group convolution results into temporary output tensor.\\n-    Tensor output_shuffled(output->dtype(), TensorShape(post_shuffle(*output)));\\n+    Tensor output_shuffled;\\n+    OP_REQUIRES_OK(ctx, ctx->allocate_temp(output->dtype(),\\n+                                           TensorShape(post_shuffle(*output)),\\n+                                           &output_shuffled));\\n \\n     for (int64_t i = 0; i < num_groups; ++i) {\\n       // TODO(ezhulenev): Run this loop using `parallelFor` (regular parallelFor'}}",
      "message_norm": "fix segfault on oom in conv2d.\n\npiperorigin-revid: 404655317\nchange-id: i33588dbd3f5d0fef980e3c908bf5515a9ee09ce7",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('segfault', 'SECWORD', ''), ('404655317', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/conv_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1281,
      "vuln_id": "GHSA-8x44-pwr2-rgc6",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/pimcore/pimcore/commit/832c34aeb9f21f213295a0c28377132df996352a'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in pimcore Pimcore settings module is vulnerable to stored cross site scripting",
      "published_date": "2022-01-28",
      "chain_len": 1,
      "project": "https://github.com/pimcore/pimcore",
      "commit_href": "https://github.com/pimcore/pimcore/commit/832c34aeb9f21f213295a0c28377132df996352a",
      "commit_sha": "832c34aeb9f21f213295a0c28377132df996352a",
      "patch": "SINGLE",
      "chain_ord": "['832c34aeb9f21f213295a0c28377132df996352a']",
      "before_first_fix_commit": "{'e94591dd8f5006452667a04c93e4422b05234eea'}",
      "last_fix_commit": "832c34aeb9f21f213295a0c28377132df996352a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/26/2022, 13:08:27",
      "message": "added escape function to the icon field",
      "author": "Jia Jia Ji",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'bundles/AdminBundle/Controller/Admin/DataObject/ClassController.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/pimcore/pimcore/raw/832c34aeb9f21f213295a0c28377132df996352a/bundles%2FAdminBundle%2FController%2FAdmin%2FDataObject%2FClassController.php', 'patch': \"@@ -119,7 +119,7 @@ public function getTreeAction(Request $request)\\n                 'id' => $class->getId(),\\n                 'text' => $text,\\n                 'leaf' => true,\\n-                'icon' => $class->getIcon() ? $class->getIcon() : $defaultIcon,\\n+                'icon' => $class->getIcon() ? htmlspecialchars($class->getIcon()) : $defaultIcon,\\n                 'cls' => 'pimcore_class_icon',\\n                 'propertyVisibility' => $class->getPropertyVisibility(),\\n                 'enableGridLocking' => $class->isEnableGridLocking(),\"}}",
      "message_norm": "added escape function to the icon field",
      "language": "en",
      "entities": "[('added', 'ACTION', ''), ('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['bundles/AdminBundle/Controller/Admin/DataObject/ClassController.php'])",
      "num_files": 1.0
    },
    {
      "index": 2085,
      "vuln_id": "GHSA-hjhp-hwfj-hwf3",
      "cwe_id": "{'CWE-352'}",
      "score": 4.3,
      "chain": "{'https://github.com/firefly-iii/firefly-iii/commit/03a1601bf343181df9f405dd2109aec483cb7053'}",
      "dataset": "osv",
      "summary": "Cross Site Request Forgery in firefly-iii  firefly-iii is vulnerable to a Cross-Site Request Forgery (CSRF) attack which can disable two factor authentication for the target user.",
      "published_date": "2021-12-10",
      "chain_len": 1,
      "project": "https://github.com/firefly-iii/firefly-iii",
      "commit_href": "https://github.com/firefly-iii/firefly-iii/commit/03a1601bf343181df9f405dd2109aec483cb7053",
      "commit_sha": "03a1601bf343181df9f405dd2109aec483cb7053",
      "patch": "SINGLE",
      "chain_ord": "['03a1601bf343181df9f405dd2109aec483cb7053']",
      "before_first_fix_commit": "{'edfff4ec57133bc78bbe6bdc4e1939b75bf9d845'}",
      "last_fix_commit": "03a1601bf343181df9f405dd2109aec483cb7053",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/24/2021, 19:04:39",
      "message": "Fix.",
      "author": "James Cole",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 4, 'total': 9}",
      "files": "{'resources/views/v1/profile/index.twig': {'additions': 5, 'deletions': 4, 'changes': 9, 'status': 'modified', 'raw_url': 'https://github.com/firefly-iii/firefly-iii/raw/03a1601bf343181df9f405dd2109aec483cb7053/resources%2Fviews%2Fv1%2Fprofile%2Findex.twig', 'patch': '@@ -107,7 +107,7 @@\\n                     <div class=\"box box-default\">\\n                         <div class=\"box-body\">\\n                             <p class=\"text-info\">{{ \\'pref_two_factor_auth_help\\'|_ }}</p>\\n-                            {% if enabled2FA == false %}\\n+                            {% if enabled2FA == true %}\\n                                 <p class=\"text-info\">\\n                                     {{ trans_choice(\\'firefly.pref_two_factor_backup_code_count\\', mfaBackupCount) }}\\n                                 </p>\\n@@ -116,10 +116,11 @@\\n                                     <a class=\"btn btn-info\" href=\"{{ route(\\'profile.code\\') }}\">\\n                                         <span class=\"fa fa-recycle\"></span>\\n                                         {{ \\'pref_two_factor_auth_reset_code\\'|_ }}</a>\\n-                                    <a class=\"btn btn-danger\" href=\"{{ route(\\'profile.delete-code\\') }}\">\\n-                                        <span class=\"fa fa-trash\"></span>\\n-                                        {{ \\'pref_two_factor_auth_disable_2fa\\'|_ }}</a>\\n                                 </div>\\n+                                <form method=\"post\" action=\"{{ route(\\'profile.delete-code\\') }}\">\\n+                                    <input type=\"hidden\" name=\"_token\" value=\"{{ csrf_token() }}\" />\\n+                                    <input class=\"btn btn-danger\" style=\"margin-top:20px;\" type=\"submit\" name=\"submit\" value=\"{{ \\'pref_two_factor_auth_disable_2fa\\'|_ }}\" />\\n+                                </form>\\n                                 <form method=\"post\" action=\"{{ route(\\'profile.new-backup-codes\\') }}\">\\n                                     <input type=\"hidden\" name=\"_token\" value=\"{{ csrf_token() }}\" />\\n                                     <input class=\"btn btn-default\" style=\"margin-top:20px;\" type=\"submit\" name=\"submit\" value=\"{{ \\'pref_two_factor_new_backup_codes\\'|_ }}\" />'}}",
      "message_norm": "fix.",
      "language": "ca",
      "entities": null,
      "classification_level_1": "POORLY_DOCUMENTED",
      "classification_level_2": "SINGLE_WORD",
      "list_files": "dict_keys(['resources/views/v1/profile/index.twig'])",
      "num_files": 1.0
    },
    {
      "index": 1123,
      "vuln_id": "GHSA-8434-v7xw-8m9x",
      "cwe_id": "{'CWE-88', 'CWE-78'}",
      "score": 9.3,
      "chain": "{'https://github.com/dwisiswant0/apkleaks/commit/a966e781499ff6fd4eea66876d7532301b13a382'}",
      "dataset": "osv",
      "summary": "Improper Neutralization of Argument Delimiters in a Decompiling Package Process in APKLeaks APKLeaks prior to v2.0.4 allows remote authenticated attackers to execute arbitrary OS commands via package name inside the application manifest.\n\n### Impact\n\nAn authenticated attacker could include arguments that allow unintended commands or code to be executed, allow sensitive data to be read or modified, or could cause other unintended behavior through malicious package names.\n\n\n### References\n\n- a966e781499ff6fd4eea66876d7532301b13a382\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Email me at [me@dw1.io](mailto:me@dw1.io)",
      "published_date": "2022-01-21",
      "chain_len": 1,
      "project": "https://github.com/dwisiswant0/apkleaks",
      "commit_href": "https://github.com/dwisiswant0/apkleaks/commit/a966e781499ff6fd4eea66876d7532301b13a382",
      "commit_sha": "a966e781499ff6fd4eea66876d7532301b13a382",
      "patch": "SINGLE",
      "chain_ord": "['a966e781499ff6fd4eea66876d7532301b13a382']",
      "before_first_fix_commit": "{'8577b7af6224bf0a5455b552963c46721308d2ff'}",
      "last_fix_commit": "a966e781499ff6fd4eea66876d7532301b13a382",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2021, 15:25:42",
      "message": "Escapes decompiling arguments",
      "author": "Dwi Siswanto",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 2, 'total': 6}",
      "files": "{'apkleaks/apkleaks.py': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/dwisiswant0/apkleaks/raw/a966e781499ff6fd4eea66876d7532301b13a382/apkleaks%2Fapkleaks.py', 'patch': '@@ -2,6 +2,7 @@\\n from apkleaks.colors import clr\\n from contextlib import closing\\n from distutils.spawn import find_executable\\n+from pipes import quote\\n from pyaxmlparser import APK\\n from urllib.request import urlopen\\n from zipfile import ZipFile\\n@@ -84,8 +85,9 @@ def decompile(self):\\n \\t\\t\\t\\t\\tclasses.write(zipped.read(\"classes.dex\"))\\n \\t\\t\\texcept Exception as e:\\n \\t\\t\\t\\tsys.exit(self.writeln(str(e), clr.WARNING))\\n-\\t\\tdec = \"%s %s -d %s --deobf\" % (self.jadx, dex, self.tempdir)\\n-\\t\\tos.system(dec)\\n+\\t\\targs = [self.jadx, dex, \"-d\", self.tempdir, \"--deobf\"]\\n+\\t\\tcomm = \"%s\" % (\" \".join(quote(arg) for arg in args))\\n+\\t\\tos.system(comm)\\n \\t\\treturn self.tempdir\\n \\n \\tdef unique(self, list):'}}",
      "message_norm": "escapes decompiling arguments",
      "language": "ca",
      "entities": "[('escapes', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['apkleaks/apkleaks.py'])",
      "num_files": 1.0
    },
    {
      "index": 1986,
      "vuln_id": "GHSA-h4mc-r4f4-hcf4",
      "cwe_id": "{'CWE-311'}",
      "score": 8.1,
      "chain": "{'https://github.com/spunjs/selenium-binaries/commit/be37e82a3c43a4f1679d66cf9467085ec9994c47'}",
      "dataset": "osv",
      "summary": "selenium-binaries downloads resources over HTTP Versions of `selenium-binaries` prior to 0.15.0 insecurely download an executable over an unencrypted HTTP connection. \n\nIn scenarios where an attacker has a privileged network position, it is possible to intercept the response and replace the executable with a malicious one, resulting in code execution on the system running `selenium-binaries`.\n\n\n## Recommendation\n\nA fix for this vulnerability is available on the `master` branch of the repository as part of version 0.15.0.\n\nAnother mitigation currently available is to use an alternate package, such as [selenium-webdriver](https://www.npmjs.com/package/selenium-webdriver), the official selenium bindings for node.js.",
      "published_date": "2019-02-18",
      "chain_len": 1,
      "project": "https://github.com/spunjs/selenium-binaries",
      "commit_href": "https://github.com/spunjs/selenium-binaries/commit/be37e82a3c43a4f1679d66cf9467085ec9994c47",
      "commit_sha": "be37e82a3c43a4f1679d66cf9467085ec9994c47",
      "patch": "SINGLE",
      "chain_ord": "['be37e82a3c43a4f1679d66cf9467085ec9994c47']",
      "before_first_fix_commit": "{'75b0fd18ffd6373fd09d39c48b1df632f9649c08'}",
      "last_fix_commit": "be37e82a3c43a4f1679d66cf9467085ec9994c47",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/22/2020, 17:20:26",
      "message": "Avoid MiTM by downloading through https (#33)\n\nCo-authored-by: Alejandro Romero Herrera <alromh87@gmail.com>\r\nCo-authored-by: Raj <70631238+418raj@users.noreply.github.com>",
      "author": "huntr-helper",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 3, 'total': 6}",
      "files": "{'lib/config.js': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/spunjs/selenium-binaries/raw/be37e82a3c43a4f1679d66cf9467085ec9994c47/lib%2Fconfig.js', 'patch': \"@@ -35,7 +35,7 @@ module.exports = {\\n     seleniumserver: {\\n       version: SELENIUM_BINARIES_SERVER_STANDALONE_VERSION,\\n       url: util.format(\\n-        'http://selenium-release.storage.googleapis.com/%s/',\\n+        'https://selenium-release.storage.googleapis.com/%s/',\\n         getMajorMinorVersion(SELENIUM_BINARIES_SERVER_STANDALONE_VERSION)\\n       ),\\n       path: path.resolve(\\n@@ -55,7 +55,7 @@ module.exports = {\\n     chromedriver: {\\n       version: SELENIUM_BINARIES_CHROMEDRIVER_VERSION,\\n       url: util.format(\\n-        'http://chromedriver.storage.googleapis.com/%s/',\\n+        'https://chromedriver.storage.googleapis.com/%s/',\\n         SELENIUM_BINARIES_CHROMEDRIVER_VERSION\\n       ),\\n       path: path.resolve(\\n@@ -89,7 +89,7 @@ module.exports = {\\n     iedriver: {\\n       version: SELENIUM_BINARIES_IEDRIVER_VERSION,\\n       url: util.format(\\n-        'http://selenium-release.storage.googleapis.com/%s/',\\n+        'https://selenium-release.storage.googleapis.com/%s/',\\n         getMajorMinorVersion(SELENIUM_BINARIES_IEDRIVER_VERSION)\\n       ),\\n       path: path.resolve(\"}}",
      "message_norm": "avoid mitm by downloading through https (#33)\n\nco-authored-by: alejandro romero herrera <alromh87@gmail.com>\r\nco-authored-by: raj <70631238+418raj@users.noreply.github.com>",
      "language": "en",
      "entities": "[('mitm', 'SECWORD', ''), ('#33', 'ISSUE', ''), ('alromh87@gmail.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/config.js'])",
      "num_files": 1.0
    },
    {
      "index": 1197,
      "vuln_id": "GHSA-8cxv-76p7-jxwr",
      "cwe_id": "{'CWE-476'}",
      "score": 6.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/4f38b1ac8e42727e18a2f0bde06d3bee8e77b250'}",
      "dataset": "osv",
      "summary": "Null-dereference in Tensorflow ### Impact\nThe [implementation of `GetInitOp`](https://github.com/tensorflow/tensorflow/blob/a1320ec1eac186da1d03f033109191f715b2b130/tensorflow/cc/saved_model/loader_util.cc#L31-L61) is vulnerable to a crash caused by dereferencing a null pointer:\n\n```cc\nconst auto& init_op_sig_it =\n    meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\nif (init_op_sig_it != sig_def_map.end()) {\n  *init_op_name = init_op_sig_it->second.outputs()\n                      .find(kSavedModelInitOpSignatureKey)\n                      ->second.name();\n  return Status::OK();\n}\n```\n\nHere, we have a nested map and we assume that if the first `.find` succeeds then so would be the search in the internal map. However, the maps are built based on the `SavedModel` protobuf format and a malicious user can alter that on disk before loading to cause the second `.find` to return `nullptr`.\n### Patches\nWe have patched the issue in GitHub commit [4f38b1ac8e42727e18a2f0bde06d3bee8e77b250](https://github.com/tensorflow/tensorflow/commit/4f38b1ac8e42727e18a2f0bde06d3bee8e77b250).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date": "2022-02-10",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
      "commit_sha": "4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
      "patch": "SINGLE",
      "chain_ord": "['4f38b1ac8e42727e18a2f0bde06d3bee8e77b250']",
      "before_first_fix_commit": "{'7b84b7c651dc2ecc1e28f2acc65bfe371a04ecfc'}",
      "last_fix_commit": "4f38b1ac8e42727e18a2f0bde06d3bee8e77b250",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/10/2021, 00:56:28",
      "message": "Prevent null dereference read in `GetInitOp`.\n\nWe have a map of maps. We test that the key exists in the first map but then we don't have any validation that this also means the second map has the needed key. In the scenarios where this is not the case, we'll dereference a nullptr, if we don't have this check\n\nPiperOrigin-RevId: 408739325\nChange-Id: If9bb7ed759aba1f3b56a34913f209508dbaf65ce",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 3, 'total': 11}",
      "files": "{'tensorflow/cc/saved_model/loader_util.cc': {'additions': 8, 'deletions': 3, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/4f38b1ac8e42727e18a2f0bde06d3bee8e77b250/tensorflow%2Fcc%2Fsaved_model%2Floader_util.cc', 'patch': '@@ -34,9 +34,14 @@ Status GetInitOp(const string& export_dir, const MetaGraphDef& meta_graph_def,\\n   const auto& init_op_sig_it =\\n       meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\\n   if (init_op_sig_it != sig_def_map.end()) {\\n-    *init_op_name = init_op_sig_it->second.outputs()\\n-                        .find(kSavedModelInitOpSignatureKey)\\n-                        ->second.name();\\n+    const auto& sig_def_outputs = init_op_sig_it->second.outputs();\\n+    const auto& sig_def_outputs_it =\\n+        sig_def_outputs.find(kSavedModelInitOpSignatureKey);\\n+    if (sig_def_outputs_it == sig_def_outputs.end()) {\\n+      return errors::FailedPrecondition(\"Could not find output \",\\n+                                        kSavedModelInitOpSignatureKey);\\n+    }\\n+    *init_op_name = sig_def_outputs_it->second.name();\\n     return Status::OK();\\n   }'}}",
      "message_norm": "prevent null dereference read in `getinitop`.\n\nwe have a map of maps. we test that the key exists in the first map but then we don't have any validation that this also means the second map has the needed key. in the scenarios where this is not the case, we'll dereference a nullptr, if we don't have this check\n\npiperorigin-revid: 408739325\nchange-id: if9bb7ed759aba1f3b56a34913f209508dbaf65ce",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('null dereference', 'SECWORD', ''), ('key', 'SECWORD', ''), ('key', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('408739325', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/cc/saved_model/loader_util.cc'])",
      "num_files": 1.0
    },
    {
      "index": 942,
      "vuln_id": "GHSA-73q9-7pwj-gm46",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/icecoder/icecoder/commit/51cf24b2a39138e6a7b5739ef59eb38cd7c39763'}",
      "dataset": "osv",
      "summary": "icecoder is vulnerable to Cross-site Scripting icecoder is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
      "published_date": "2022-01-21",
      "chain_len": 1,
      "project": "https://github.com/icecoder/icecoder",
      "commit_href": "https://github.com/icecoder/icecoder/commit/51cf24b2a39138e6a7b5739ef59eb38cd7c39763",
      "commit_sha": "51cf24b2a39138e6a7b5739ef59eb38cd7c39763",
      "patch": "SINGLE",
      "chain_ord": "['51cf24b2a39138e6a7b5739ef59eb38cd7c39763']",
      "before_first_fix_commit": "{'cd964f816f31828011593405e024ee3b4c0f6ed3'}",
      "last_fix_commit": "51cf24b2a39138e6a7b5739ef59eb38cd7c39763",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/17/2022, 12:38:29",
      "message": "rXSS cleaned username in editor info display",
      "author": "Matt Pass",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'editor.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/icecoder/ICEcoder/raw/51cf24b2a39138e6a7b5739ef59eb38cd7c39763/editor.php', 'patch': '@@ -150,7 +150,7 @@\\n             ?>\\n             <h2><?php echo $t[\\'multi-user\\']; ?></h2>\\n             <span class=\"heading\"><?php echo $t[\\'Username\\']; ?></span><br>\\n-            <?php echo $_SESSION[\\'username\\'];?><br><br>\\n+            <?php echo xssClean($_SESSION[\\'username\\'], \"html\");?><br><br>\\n             <?php\\n         }\\n         ?>'}}",
      "message_norm": "rxss cleaned username in editor info display",
      "language": "en",
      "entities": "[('rxss', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['editor.php'])",
      "num_files": 1.0
    },
    {
      "index": 1294,
      "vuln_id": "GHSA-92v9-xh2q-fq9f",
      "cwe_id": "{'CWE-1321', 'CWE-915'}",
      "score": 8.6,
      "chain": "{'https://github.com/tony-tsx/cookiex-deep/commit/b5bea2b7f34a5fa9abb4446cbd038ecdbcd09c88'}",
      "dataset": "osv",
      "summary": "Prototype Pollution in @cookiex/deep The npm @cookiex/deep package before version 0.0.7 has a prototype pollution vulnerability. The global proto object can be polluted using the __proto__ object.",
      "published_date": "2021-09-20",
      "chain_len": 1,
      "project": "https://github.com/tony-tsx/cookiex-deep",
      "commit_href": "https://github.com/tony-tsx/cookiex-deep/commit/b5bea2b7f34a5fa9abb4446cbd038ecdbcd09c88",
      "commit_sha": "b5bea2b7f34a5fa9abb4446cbd038ecdbcd09c88",
      "patch": "SINGLE",
      "chain_ord": "['b5bea2b7f34a5fa9abb4446cbd038ecdbcd09c88']",
      "before_first_fix_commit": "{'ed91f5d004e8a1e3f269bb48c3b2ac294f8580ef'}",
      "last_fix_commit": "b5bea2b7f34a5fa9abb4446cbd038ecdbcd09c88",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/13/2021, 18:04:49",
      "message": "fix: prototype pollution fix #1",
      "author": "Tony",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'src/assigner.ts': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tony-tsx/cookiex-deep/raw/b5bea2b7f34a5fa9abb4446cbd038ecdbcd09c88/src%2Fassigner.ts', 'patch': \"@@ -1,12 +1,12 @@\\n const untracker = [ undefined, null ]\\n-\\n+const invalids = [ '__proto__', 'constructor', 'prototype' ]\\n const Assigner = function( delegate: ( a: any, b: any ) => any, useuntrack: boolean = true ): ( ...args: any[] ) => any {\\n   const assigner = ( ...args: any[] ) => {\\n-    console.log( { args } )\\n     return args.reduce( ( a, b ) => {\\n       if ( untracker.includes( a ) ) throw new TypeError( `can't convert ${a} to object` )\\n       if ( useuntrack && untracker.includes( b ) ) return a\\n       Object.keys( b ).forEach( key => {\\n+        if ( invalids.includes( key ) ) return void 0\\n         if ( untracker.includes( a[key] ) ) a[key] = b[key]\\n         else a[key] = delegate.call( this, a[key], b[key] )\\n       } )\"}}",
      "message_norm": "fix: prototype pollution fix #1",
      "language": "fr",
      "entities": "[('prototype pollution', 'SECWORD', ''), ('#1', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/assigner.ts'])",
      "num_files": 1.0
    },
    {
      "index": 3350,
      "vuln_id": "GHSA-x2p8-rgfm-qw3v",
      "cwe_id": "{'CWE-863'}",
      "score": 9.8,
      "chain": "{'https://github.com/stanfordnlp/CoreNLP/commit/5ee097dbede547023e88f60ed3f430ff09398b87'}",
      "dataset": "osv",
      "summary": "Access Control vulnerability within CoreNLP An Incorrect Access Control vulnerability exists in CoreNLP 4.3.2 via the classifier in NERServlet.java (lines 158 and 159).",
      "published_date": "2022-02-25",
      "chain_len": 1,
      "project": "https://github.com/stanfordnlp/CoreNLP",
      "commit_href": "https://github.com/stanfordnlp/CoreNLP/commit/5ee097dbede547023e88f60ed3f430ff09398b87",
      "commit_sha": "5ee097dbede547023e88f60ed3f430ff09398b87",
      "patch": "SINGLE",
      "chain_ord": "['5ee097dbede547023e88f60ed3f430ff09398b87']",
      "before_first_fix_commit": "{'85e305bf63b3954e6266801175579a8b81769709'}",
      "last_fix_commit": "5ee097dbede547023e88f60ed3f430ff09398b87",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/26/2021, 22:07:33",
      "message": "Address issue #1222: verify that classifier and outputFormat are valid values before returning them in headers.  Should sanitize malicious output",
      "author": "John Bauer",
      "comments": null,
      "stats": "{'additions': 15, 'deletions': 7, 'total': 22}",
      "files": "{'src/edu/stanford/nlp/ie/ner/webapp/NERServlet.java': {'additions': 15, 'deletions': 7, 'changes': 22, 'status': 'modified', 'raw_url': 'https://github.com/stanfordnlp/CoreNLP/raw/5ee097dbede547023e88f60ed3f430ff09398b87/src%2Fedu%2Fstanford%2Fnlp%2Fie%2Fner%2Fwebapp%2FNERServlet.java', 'patch': '@@ -63,9 +63,9 @@ public void init() throws ServletException {\\n       log(classifier);\\n     }\\n \\n-    ners = Generics.newHashMap();\\n+    ners = new HashMap<>();\\n     for (String classifier : classifiers) {\\n-      CRFClassifier model = null;\\n+      CRFClassifier<CoreMap> model = null;\\n       String filename = \"/WEB-INF/data/models/\" + classifier;\\n       InputStream is = getServletConfig().getServletContext().getResourceAsStream(filename);\\n \\n@@ -154,15 +154,23 @@ private void addResults(HttpServletRequest request,\\n       classifier = this.defaultClassifier;\\n     }\\n \\n-    response.addHeader(\"classifier\", classifier);\\n-    response.addHeader(\"outputFormat\", outputFormat);\\n-    response.addHeader(\"preserveSpacing\", String.valueOf(preserveSpacing));\\n+    CRFClassifier<CoreMap> nerModel = ners.get(classifier);\\n+    // check that we weren\\'t asked for a classifier that doesn\\'t exist\\n+    if (nerModel == null) {\\n+      out.print(StringEscapeUtils.escapeHtml4(\"Unknown model \" + classifier));\\n+      return;\\n+    }\\n \\n     if (outputFormat.equals(\"highlighted\")) {\\n-      outputHighlighting(out, ners.get(classifier), input);\\n+      outputHighlighting(out, nerModel, input);\\n     } else {\\n-      out.print(StringEscapeUtils.escapeHtml4(ners.get(classifier).classifyToString(input, outputFormat, preserveSpacing)));\\n+      out.print(StringEscapeUtils.escapeHtml4(nerModel.classifyToString(input, outputFormat, preserveSpacing)));\\n     }\\n+\\n+    response.addHeader(\"classifier\", classifier);\\n+    // a non-existent outputFormat would have just thrown an exception\\n+    response.addHeader(\"outputFormat\", outputFormat);\\n+    response.addHeader(\"preserveSpacing\", String.valueOf(preserveSpacing));\\n   }\\n \\n   private static void outputHighlighting(PrintWriter out,'}}",
      "message_norm": "address issue #1222: verify that classifier and outputformat are valid values before returning them in headers.  should sanitize malicious output",
      "language": "en",
      "entities": "[('issue', 'FLAW', ''), ('#1222', 'ISSUE', ''), ('verify', 'ACTION', ''), ('sanitize', 'SECWORD', ''), ('malicious', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/edu/stanford/nlp/ie/ner/webapp/NERServlet.java'])",
      "num_files": 1.0
    },
    {
      "index": 2730,
      "vuln_id": "GHSA-q9qc-pp5x-mc8c",
      "cwe_id": "{'CWE-94', 'CWE-1336'}",
      "score": 8.8,
      "chain": "{'https://github.com/microweber/microweber/commit/e0224462b3dd6b1f7c6ec1197413afc6019bc3b5'}",
      "dataset": "osv",
      "summary": "Improper Neutralization of Special Elements Used in a Template Engine in microweber Improper Neutralization of Special Elements Used in a Template Engine in GitHub repository microweber/microweber prior to 1.3.",
      "published_date": "2022-03-10",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/e0224462b3dd6b1f7c6ec1197413afc6019bc3b5",
      "commit_sha": "e0224462b3dd6b1f7c6ec1197413afc6019bc3b5",
      "patch": "SINGLE",
      "chain_ord": "['e0224462b3dd6b1f7c6ec1197413afc6019bc3b5']",
      "before_first_fix_commit": "{'b2baab6e582b2efe63788d367a2bb61a2fa26470'}",
      "last_fix_commit": "e0224462b3dd6b1f7c6ec1197413afc6019bc3b5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/09/2022, 11:17:21",
      "message": "Update AdminCommentController.php",
      "author": "Bozhidar Slaveykov",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 10, 'total': 13}",
      "files": "{'src/MicroweberPackages/Comment/Http/Controllers/Admin/AdminCommentController.php': {'additions': 3, 'deletions': 10, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/e0224462b3dd6b1f7c6ec1197413afc6019bc3b5/src%2FMicroweberPackages%2FComment%2FHttp%2FControllers%2FAdmin%2FAdminCommentController.php', 'patch': \"@@ -18,18 +18,16 @@\\n use MicroweberPackages\\\\Comment\\\\Models\\\\Comment;\\n use MicroweberPackages\\\\Comment\\\\Events\\\\NewComment;\\n use MicroweberPackages\\\\Comment\\\\Notifications\\\\NewCommentNotification;\\n+use MicroweberPackages\\\\Helper\\\\HTMLClean;\\n use MicroweberPackages\\\\User\\\\Models\\\\User;\\n use MicroweberPackages\\\\Utils\\\\Mail\\\\MailSender;\\n \\n-\\n class AdminCommentController extends AdminController\\n {\\n     public function index(Request $request)\\n     {\\n-\\n         $contents = $this->getComments($request);\\n \\n-\\n         return $this->view('comment::admin.comments.index', ['contents' => $contents]);\\n     }\\n \\n@@ -42,7 +40,6 @@ public function getComments(Request $request)\\n             $contents = $contents->filter($filter);\\n         }\\n \\n-\\n         $contents = $contents->paginate($request->get('limit', 30))\\n             ->appends($request->except('page'));\\n \\n@@ -148,12 +145,8 @@ public function saveCommentEdit(Request $request)\\n \\n         $comment_body = $data['comment_body'];\\n \\n-        // Claer HTML\\n-        $comment_body = $this->app->format->clean_html($comment_body);\\n-\\n-        // Clear XSS\\n-        $evil = ['(?<!\\\\w)on\\\\w*', 'xmlns', 'formaction', 'xlink:href', 'FSCommand', 'seekSegmentTime'];\\n-        $comment_body = $this->app->format->clean_xss($comment_body, true, $evil, 'removeEvilAttributes');\\n+        $cleanHtml = new HTMLClean();\\n+        $comment_body = $cleanHtml->onlyTags($comment_body);\\n \\n         if (!empty($comment_body) and !empty($data['format']) and $data['format'] == 'markdown') {\\n             $comment_body = Markdown::convertToHtml($comment_body);\"}}",
      "message_norm": "update admincommentcontroller.php",
      "language": "fr",
      "entities": "[('update', 'ACTION', ''), ('admincommentcontroller.php', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/Comment/Http/Controllers/Admin/AdminCommentController.php'])",
      "num_files": 1.0
    },
    {
      "index": 2502,
      "vuln_id": "GHSA-p493-635q-r6gr",
      "cwe_id": "{'CWE-74'}",
      "score": 6.8,
      "chain": "{'https://github.com/pugjs/pug/commit/991e78f7c4220b2f8da042877c6f0ef5a4683be0'}",
      "dataset": "osv",
      "summary": "Remote code execution via the `pretty` option. ### Impact\n\nIf a remote attacker was able to control the `pretty` option of the pug compiler, e.g. if you spread a user provided object such as the query parameters of a request into the pug template inputs, it was possible for them to achieve remote code execution on the node.js backend.\n\n### Patches\n\nUpgrade to `pug@3.0.1` or `pug-code-gen@3.0.2` or `pug-code-gen@2.0.3`, which correctly sanitise the parameter.\n\n### Workarounds\n\nIf there is no way for un-trusted input to be passed to pug as the `pretty` option, e.g. if you compile templates in advance before applying user input to them, you do not need to upgrade.\n\n### References\n\n\nOriginal report: https://github.com/pugjs/pug/issues/3312\n\n### For more information\n\nIf you believe you have found other vulnerabilities, please **DO NOT** open an issue. Instead, you can follow the instructions in our [Security Policy](https://github.com/pugjs/pug/blob/master/SECURITY.md)",
      "published_date": "2021-03-03",
      "chain_len": 1,
      "project": "https://github.com/pugjs/pug",
      "commit_href": "https://github.com/pugjs/pug/commit/991e78f7c4220b2f8da042877c6f0ef5a4683be0",
      "commit_sha": "991e78f7c4220b2f8da042877c6f0ef5a4683be0",
      "patch": "SINGLE",
      "chain_ord": "['991e78f7c4220b2f8da042877c6f0ef5a4683be0']",
      "before_first_fix_commit": "{'06baa525a23049756de9587461d389a12bc12537'}",
      "last_fix_commit": "991e78f7c4220b2f8da042877c6f0ef5a4683be0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/28/2021, 18:21:18",
      "message": "fix: sanitise and escape the `pretty` option (#3314)",
      "author": "Forbes Lindesay",
      "comments": null,
      "stats": "{'additions': 11, 'deletions': 2, 'total': 13}",
      "files": "{'packages/pug-code-gen/index.js': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/pugjs/pug/raw/991e78f7c4220b2f8da042877c6f0ef5a4683be0/packages%2Fpug-code-gen%2Findex.js', 'patch': '@@ -57,6 +57,11 @@ function Compiler(node, options) {\\n   if (this.pp && typeof this.pp !== \\'string\\') {\\n     this.pp = \\'  \\';\\n   }\\n+  if (this.pp && !/^\\\\s+$/.test(this.pp)) {\\n+    throw new Error(\\n+      \\'The pretty parameter should either be a boolean or whitespace only string\\'\\n+    );\\n+  }\\n   this.debug = false !== options.compileDebug;\\n   this.indents = 0;\\n   this.parentIndents = 0;\\n@@ -452,7 +457,9 @@ Compiler.prototype = {\\n   visitMixinBlock: function(block) {\\n     if (this.pp)\\n       this.buf.push(\\n-        \"pug_indent.push(\\'\" + Array(this.indents + 1).join(this.pp) + \"\\');\"\\n+        \\'pug_indent.push(\\' +\\n+          stringify(Array(this.indents + 1).join(this.pp)) +\\n+          \\');\\'\\n       );\\n     this.buf.push(\\'block && block();\\');\\n     if (this.pp) this.buf.push(\\'pug_indent.pop();\\');\\n@@ -504,7 +511,9 @@ Compiler.prototype = {\\n       this.mixins[key].used = true;\\n       if (pp)\\n         this.buf.push(\\n-          \"pug_indent.push(\\'\" + Array(this.indents + 1).join(pp) + \"\\');\"\\n+          \\'pug_indent.push(\\' +\\n+            stringify(Array(this.indents + 1).join(pp)) +\\n+            \\');\\'\\n         );\\n       if (block || attrs.length || attrsBlocks.length) {\\n         this.buf.push(name + \\'.call({\\');'}}",
      "message_norm": "fix: sanitise and escape the `pretty` option (#3314)",
      "language": "en",
      "entities": "[('sanitise', 'SECWORD', ''), ('escape', 'SECWORD', ''), ('#3314', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['packages/pug-code-gen/index.js'])",
      "num_files": 1.0
    },
    {
      "index": 3286,
      "vuln_id": "GHSA-wjh9-344g-vc49",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/francoisjacquet/rosariosis/commit/6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in RosarioSIS Cross-site Scripting (XSS) - Stored in GitHub repository francoisjacquet/rosariosis prior to 9.0.",
      "published_date": "2022-06-09",
      "chain_len": 1,
      "project": "https://github.com/francoisjacquet/rosariosis",
      "commit_href": "https://github.com/francoisjacquet/rosariosis/commit/6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8",
      "commit_sha": "6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8",
      "patch": "SINGLE",
      "chain_ord": "['6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8']",
      "before_first_fix_commit": "{'25eb3196e26df31917dfef87aa9f66f78c1646ea'}",
      "last_fix_commit": "6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8",
      "chain_ord_pos": 1.0,
      "commit_datetime": "06/04/2022, 11:44:21",
      "message": "Fix stored XSS security issue: remove inline JS from URL in PreparePHP_SELF.fnc.php",
      "author": "Fran\u00e7ois Jacquet",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'functions/PreparePHP_SELF.fnc.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/francoisjacquet/rosariosis/raw/6b22c0b5b40fad891c8cf9e7eeff3e42a35c0bf8/functions%2FPreparePHP_SELF.fnc.php', 'patch': \"@@ -200,7 +200,7 @@ function( $match ) {\\n \\n \\tforeach ( $remove as $remove_string )\\n \\t{\\n-\\t\\twhile ( strpos( $string, $remove_string ) !== false )\\n+\\t\\twhile ( stripos( $string, $remove_string ) !== false )\\n \\t\\t{\\n \\t\\t\\t$string = str_ireplace( $remove, '', $string );\\n \\t\\t}\"}}",
      "message_norm": "fix stored xss security issue: remove inline js from url in preparephp_self.fnc.php",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('xss', 'SECWORD', ''), ('security', 'SECWORD', ''), ('issue', 'FLAW', ''), ('remove', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['functions/PreparePHP_SELF.fnc.php'])",
      "num_files": 1.0
    },
    {
      "index": 1753,
      "vuln_id": "GHSA-fp76-f299-v3hj",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/neorazorx/facturascripts/commit/1d1edb40b40016d7fd2893b410b98569d7facca1'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in FacturaScripts Cross-site Scripting (XSS) - Stored in GitHub repository neorazorx/facturascripts prior to 2022.06.",
      "published_date": "2022-06-14",
      "chain_len": 1,
      "project": "https://github.com/neorazorx/facturascripts",
      "commit_href": "https://github.com/neorazorx/facturascripts/commit/1d1edb40b40016d7fd2893b410b98569d7facca1",
      "commit_sha": "1d1edb40b40016d7fd2893b410b98569d7facca1",
      "patch": "SINGLE",
      "chain_ord": "['1d1edb40b40016d7fd2893b410b98569d7facca1']",
      "before_first_fix_commit": "{'73a6595ca85984d65f656c6356fabb23d1936c54'}",
      "last_fix_commit": "1d1edb40b40016d7fd2893b410b98569d7facca1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2022, 09:55:32",
      "message": "Force to download SVG files to prevent security problems.\n------\nForzamos a descargar los archivos SVG para evitar problemas de seguridad.",
      "author": "Carlos Garcia Gomez",
      "comments": null,
      "stats": "{'additions': 19, 'deletions': 10, 'total': 29}",
      "files": "{'Core/App/AppRouter.php': {'additions': 19, 'deletions': 10, 'changes': 29, 'status': 'modified', 'raw_url': 'https://github.com/NeoRazorX/facturascripts/raw/1d1edb40b40016d7fd2893b410b98569d7facca1/Core%2FApp%2FAppRouter.php', 'patch': '@@ -127,8 +127,7 @@ public function getFile(): bool\\n         $allowedFolders = [\\'node_modules\\', \\'vendor\\', \\'Dinamic\\', \\'Core\\', \\'Plugins\\', \\'MyFiles/Public\\'];\\n         foreach ($allowedFolders as $folder) {\\n             if (\\'/\\' . $folder === substr($uri, 0, 1 + strlen($folder))) {\\n-                header(\\'Content-Type: \\' . $this->getMime($filePath));\\n-                readfile($filePath);\\n+                $this->download($filePath);\\n                 return true;\\n             }\\n         }\\n@@ -137,14 +136,7 @@ public function getFile(): bool\\n         $token = filter_input(INPUT_GET, \\'myft\\');\\n         $fixedFilePath = substr(urldecode($uri), 1);\\n         if (\\'/MyFiles/\\' === substr($uri, 0, 9) && $token && MyFilesToken::validate($fixedFilePath, $token)) {\\n-            header(\\'Content-Type: \\' . $this->getMime($filePath));\\n-\\n-            // disable the buffer if enabled\\n-            if (ob_get_contents()) {\\n-                ob_end_flush();\\n-            }\\n-\\n-            readfile($filePath);\\n+            $this->download($filePath);\\n             return true;\\n         }\\n \\n@@ -205,6 +197,23 @@ private function deploy()\\n         }\\n     }\\n \\n+    private function download(string $filePath)\\n+    {\\n+        header(\\'Content-Type: \\' . $this->getMime($filePath));\\n+\\n+        // disable the buffer if enabled\\n+        if (ob_get_contents()) {\\n+            ob_end_flush();\\n+        }\\n+\\n+        // force to download svg files to prevent XSS attacks\\n+        if (strpos($filePath, \\'.svg\\') !== false) {\\n+            header(\\'Content-Disposition: attachment; filename=\"\\' . basename($filePath) . \\'\"\\');\\n+        }\\n+\\n+        readfile($filePath);\\n+    }\\n+\\n     /**\\n      * Return the mime type from given file.\\n      *'}}",
      "message_norm": "force to download svg files to prevent security problems.\n------\nforzamos a descargar los archivos svg para evitar problemas de seguridad.",
      "language": "es",
      "entities": "[('prevent', 'ACTION', ''), ('security', 'SECWORD', ''), ('problems', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['Core/App/AppRouter.php'])",
      "num_files": 1.0
    },
    {
      "index": 29,
      "vuln_id": "GHSA-257v-vj4p-3w2h",
      "cwe_id": "{'CWE-770'}",
      "score": 5.3,
      "chain": "{'https://github.com/Qix-/color-string/commit/0789e21284c33d89ebc4ab4ca6f759b9375ac9d3'}",
      "dataset": "osv",
      "summary": "Regular Expression Denial of Service (ReDOS) In the npm package `color-string`, there is a  ReDos (Regular Expression Denial of Service) vulnerability regarding an exponential time complexity for\nlinearly increasing input lengths for `hwb()` color strings.\n\nStrings reaching more than 5000 characters would see several\nmilliseconds of processing time; strings reaching more than\n50,000 characters began seeing 1500ms (1.5s) of processing time.\n\nThe cause was due to a the regular expression that parses\nhwb() strings - specifically, the hue value - where\nthe integer portion of the hue value used a 0-or-more quantifier\nshortly thereafter followed by a 1-or-more quantifier.\n\nThis caused excessive backtracking and a cartesian scan,\nresulting in exponential time complexity given a linear\nincrease in input length.",
      "published_date": "2021-06-22",
      "chain_len": 1,
      "project": "https://github.com/Qix-/color-string",
      "commit_href": "https://github.com/Qix-/color-string/commit/0789e21284c33d89ebc4ab4ca6f759b9375ac9d3",
      "commit_sha": "0789e21284c33d89ebc4ab4ca6f759b9375ac9d3",
      "patch": "SINGLE",
      "chain_ord": "['0789e21284c33d89ebc4ab4ca6f759b9375ac9d3']",
      "before_first_fix_commit": "{'60f3f66477a298589288e3df6e895f88e6cd8e8e'}",
      "last_fix_commit": "0789e21284c33d89ebc4ab4ca6f759b9375ac9d3",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/05/2021, 17:48:41",
      "message": "fix ReDos in hwb() parser (low-severity)\n\nDiscovered by Yeting Li, c/o Colin Ife via Snyk.io.\n\nA ReDos (Regular Expression Denial of Service) vulnerability\nwas responsibly disclosed to me via email by Colin on\nMar 5 2021 regarding an exponential time complexity for\nlinearly increasing input lengths for `hwb()` color strings.\n\nStrings reaching more than 5000 characters would see several\nmilliseconds of processing time; strings reaching more than\n50,000 characters began seeing 1500ms (1.5s) of processing time.\n\nThe cause was due to a the regular expression that parses\nhwb() strings - specifically, the hue value - where\nthe integer portion of the hue value used a 0-or-more quantifier\nshortly thereafter followed by a 1-or-more quantifier.\n\nThis caused excessive backtracking and a cartesian scan,\nresulting in exponential time complexity given a linear\nincrease in input length.\n\nThank you Yeting Li and Colin Ife for bringing this to my\nattention in a secure, responsible and professional manner.\n\nA CVE will not be assigned for this vulnerability.",
      "author": "Josh Junon",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/Qix-/color-string/raw/0789e21284c33d89ebc4ab4ca6f759b9375ac9d3/index.js', 'patch': '@@ -129,7 +129,7 @@ cs.get.hsl = function (string) {\\n \\t\\treturn null;\\n \\t}\\n \\n-\\tvar hsl = /^hsla?\\\\(\\\\s*([+-]?(?:\\\\d*\\\\.)?\\\\d+)(?:deg)?\\\\s*,\\\\s*([+-]?[\\\\d\\\\.]+)%\\\\s*,\\\\s*([+-]?[\\\\d\\\\.]+)%\\\\s*(?:,\\\\s*([+-]?[\\\\d\\\\.]+)\\\\s*)?\\\\)$/;\\n+\\tvar hsl = /^hsla?\\\\(\\\\s*([+-]?(?:\\\\d{0,3}\\\\.)?\\\\d+)(?:deg)?\\\\s*,\\\\s*([+-]?[\\\\d\\\\.]+)%\\\\s*,\\\\s*([+-]?[\\\\d\\\\.]+)%\\\\s*(?:,\\\\s*([+-]?[\\\\d\\\\.]+)\\\\s*)?\\\\)$/;\\n \\tvar match = string.match(hsl);\\n \\n \\tif (match) {\\n@@ -150,7 +150,7 @@ cs.get.hwb = function (string) {\\n \\t\\treturn null;\\n \\t}\\n \\n-\\tvar hwb = /^hwb\\\\(\\\\s*([+-]?\\\\d*[\\\\.]?\\\\d+)(?:deg)?\\\\s*,\\\\s*([+-]?[\\\\d\\\\.]+)%\\\\s*,\\\\s*([+-]?[\\\\d\\\\.]+)%\\\\s*(?:,\\\\s*([+-]?[\\\\d\\\\.]+)\\\\s*)?\\\\)$/;\\n+\\tvar hwb = /^hwb\\\\(\\\\s*([+-]?\\\\d{0,3}(?:\\\\.\\\\d+)?)(?:deg)?\\\\s*,\\\\s*([+-]?[\\\\d\\\\.]+)%\\\\s*,\\\\s*([+-]?[\\\\d\\\\.]+)%\\\\s*(?:,\\\\s*([+-]?[\\\\d\\\\.]+)\\\\s*)?\\\\)$/;\\n \\tvar match = string.match(hwb);\\n \\n \\tif (match) {'}}",
      "message_norm": "fix redos in hwb() parser (low-severity)\n\ndiscovered by yeting li, c/o colin ife via snyk.io.\n\na redos (regular expression denial of service) vulnerability\nwas responsibly disclosed to me via email by colin on\nmar 5 2021 regarding an exponential time complexity for\nlinearly increasing input lengths for `hwb()` color strings.\n\nstrings reaching more than 5000 characters would see several\nmilliseconds of processing time; strings reaching more than\n50,000 characters began seeing 1500ms (1.5s) of processing time.\n\nthe cause was due to a the regular expression that parses\nhwb() strings - specifically, the hue value - where\nthe integer portion of the hue value used a 0-or-more quantifier\nshortly thereafter followed by a 1-or-more quantifier.\n\nthis caused excessive backtracking and a cartesian scan,\nresulting in exponential time complexity given a linear\nincrease in input length.\n\nthank you yeting li and colin ife for bringing this to my\nattention in a secure, responsible and professional manner.\n\na cve will not be assigned for this vulnerability.",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('low', 'SEVERITY', ''), ('redos', 'SECWORD', ''), ('denial of service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('secure', 'SECWORD', ''), ('cve', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 2981,
      "vuln_id": "GHSA-rphc-h572-2x9f",
      "cwe_id": "{'CWE-434', 'CWE-79'}",
      "score": 9.0,
      "chain": "{'https://github.com/star7th/showdoc/commit/92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in showdoc/showdoc ShowDoc is a tool greatly applicable for an IT team to share documents online. showdoc/showdoc allows .properties files to upload which lead to stored XSS in versions prior to 2.10.4. This allows attackers to execute malicious scripts in the user's browser. This issue was patched in version 2.10.4. There is currently no known workaround.",
      "published_date": "2022-03-15",
      "chain_len": 1,
      "project": "https://github.com/star7th/showdoc",
      "commit_href": "https://github.com/star7th/showdoc/commit/92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f",
      "commit_sha": "92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f",
      "patch": "SINGLE",
      "chain_ord": "['92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f']",
      "before_first_fix_commit": "{'cd258a0de6fad53a5f41beaf2645f3f6f092f216'}",
      "last_fix_commit": "92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/14/2022, 14:36:28",
      "message": "file upload bug",
      "author": "star7th",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 4, 'total': 8}",
      "files": "{'server/Application/Api/Model/AttachmentModel.class.php': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/star7th/showdoc/raw/92bc6a83a3a60e01a0d2effb98ab47d8d7eab28f/server%2FApplication%2FApi%2FModel%2FAttachmentModel.class.php', 'patch': \"@@ -324,13 +324,13 @@ public function isDangerFilename($filename){\\n \\tpublic function isAllowedFilename($filename){\\n \\t\\t$allow_array = array(\\n \\t\\t\\t'.jpg','.jpeg','.png','.bmp','.gif','.ico','.webp',\\n-\\t\\t\\t'.mp3','.wav','.m4a','.ogg','.webma','.mp4','.flv',\\n+\\t\\t\\t'.mp3','.wav','.mp4',\\n \\t\\t\\t'.mov','.webmv','.flac','.mkv',\\n-\\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso','.bz2','.epub',\\n+\\t\\t\\t'.zip','.tar','.gz','.tgz','.ipa','.apk','.rar','.iso',\\n \\t\\t\\t'.pdf','.ofd','.swf','.epub','.xps',\\n-\\t\\t\\t'.doc','.docx','.odt','.rtf','.docm','.dotm','.dot','.dotx','.wps',\\n+\\t\\t\\t'.doc','.docx','.wps',\\n \\t\\t\\t'.ppt','.pptx','.xls','.xlsx','.txt','.psd','.csv',\\n-\\t\\t\\t'.cer','.ppt','.pub','.properties','.json','.css',\\n+\\t\\t\\t'.cer','.ppt','.pub','.json','.css',\\n \\t\\t\\t) ;\\n \\n \\t\\t$ext = strtolower(substr($filename,strripos($filename,'.')) ); //\u83b7\u53d6\u6587\u4ef6\u6269\u5c55\u540d\uff08\u8f6c\u4e3a\u5c0f\u5199\u540e\uff09\"}}",
      "message_norm": "file upload bug",
      "language": "ro",
      "entities": "[('bug', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server/Application/Api/Model/AttachmentModel.class.php'])",
      "num_files": 1.0
    },
    {
      "index": 3053,
      "vuln_id": "GHSA-v592-xf75-856p",
      "cwe_id": "{'CWE-682'}",
      "score": 5.3,
      "chain": "{'https://github.com/ethereum/go-ethereum/commit/d990df909d7839640143344e79356754384dcdd0'}",
      "dataset": "osv",
      "summary": "Erroneous Proof of Work calculation in geth ### Impact\nAn ethash mining DAG generation flaw in Geth could cause miners to erroneously calculate PoW in an upcoming epoch (estimated early January, 2021). This happened on the ETC chain on 2020-11-06. This issue is relevant only for miners, non-mining nodes are unaffected.\n\n### Patches\nThis issue is also fixed as of 1.9.24. Thanks to @slavikus for bringing the issue to our attention and writing the fix. \n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [go-ethereum](https://github.com/ethereum/go-ethereum)\n* Email us at [security@ethereum.org](mailto:security@ethereum.org)",
      "published_date": "2021-06-29",
      "chain_len": 1,
      "project": "https://github.com/ethereum/go-ethereum",
      "commit_href": "https://github.com/ethereum/go-ethereum/commit/d990df909d7839640143344e79356754384dcdd0",
      "commit_sha": "d990df909d7839640143344e79356754384dcdd0",
      "patch": "SINGLE",
      "chain_ord": "['d990df909d7839640143344e79356754384dcdd0']",
      "before_first_fix_commit": "{'27d93c1848846b75d0e67fcac284a0d417acd47c'}",
      "last_fix_commit": "d990df909d7839640143344e79356754384dcdd0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/11/2020, 20:13:12",
      "message": "consensus/ethash: use 64bit indexes for the DAG generation (#21793)\n\n* Bit boundary fix for the DAG generation routine\r\n\r\n* Fix unnecessary conversion warnings\r\n\r\nCo-authored-by: Sergey Pavlov <spavlov@gmail.com>",
      "author": "Slava Karpenko",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 5, 'total': 10}",
      "files": "{'consensus/ethash/algorithm.go': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/ethereum/go-ethereum/raw/d990df909d7839640143344e79356754384dcdd0/consensus%2Fethash%2Falgorithm.go', 'patch': '@@ -304,16 +304,16 @@ func generateDataset(dest []uint32, epoch uint64, cache []uint32) {\\n \\t\\t\\tkeccak512 := makeHasher(sha3.NewLegacyKeccak512())\\n \\n \\t\\t\\t// Calculate the data segment this thread should generate\\n-\\t\\t\\tbatch := uint32((size + hashBytes*uint64(threads) - 1) / (hashBytes * uint64(threads)))\\n-\\t\\t\\tfirst := uint32(id) * batch\\n+\\t\\t\\tbatch := (size + hashBytes*uint64(threads) - 1) / (hashBytes * uint64(threads))\\n+\\t\\t\\tfirst := uint64(id) * batch\\n \\t\\t\\tlimit := first + batch\\n-\\t\\t\\tif limit > uint32(size/hashBytes) {\\n-\\t\\t\\t\\tlimit = uint32(size / hashBytes)\\n+\\t\\t\\tif limit > size/hashBytes {\\n+\\t\\t\\t\\tlimit = size / hashBytes\\n \\t\\t\\t}\\n \\t\\t\\t// Calculate the dataset segment\\n \\t\\t\\tpercent := size / hashBytes / 100\\n \\t\\t\\tfor index := first; index < limit; index++ {\\n-\\t\\t\\t\\titem := generateDatasetItem(cache, index, keccak512)\\n+\\t\\t\\t\\titem := generateDatasetItem(cache, uint32(index), keccak512)\\n \\t\\t\\t\\tif swapped {\\n \\t\\t\\t\\t\\tswap(item)\\n \\t\\t\\t\\t}'}}",
      "message_norm": "consensus/ethash: use 64bit indexes for the dag generation (#21793)\n\n* bit boundary fix for the dag generation routine\r\n\r\n* fix unnecessary conversion warnings\r\n\r\nco-authored-by: sergey pavlov <spavlov@gmail.com>",
      "language": "en",
      "entities": "[('#21793', 'ISSUE', ''), ('fix', 'ACTION', ''), ('warnings', 'FLAW', ''), ('spavlov@gmail.com', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['consensus/ethash/algorithm.go'])",
      "num_files": 1.0
    },
    {
      "index": 665,
      "vuln_id": "GHSA-5pg2-qg87-vmj7",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/microweber/microweber/commit/9ebbb4dd35da74025ab6965f722829a7f8f86566'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in microweber Cross-site Scripting (XSS) - Stored in GitHub repository microweber/microweber prior to 1.2.19.",
      "published_date": "2022-07-02",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/9ebbb4dd35da74025ab6965f722829a7f8f86566",
      "commit_sha": "9ebbb4dd35da74025ab6965f722829a7f8f86566",
      "patch": "SINGLE",
      "chain_ord": "['9ebbb4dd35da74025ab6965f722829a7f8f86566']",
      "before_first_fix_commit": "{'c2991b3a44896320a834a4b611257db587129645'}",
      "last_fix_commit": "9ebbb4dd35da74025ab6965f722829a7f8f86566",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/01/2022, 08:07:47",
      "message": "update",
      "author": "Peter Ivanov",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 1, 'total': 5}",
      "files": "{'src/MicroweberPackages/App/functions/plupload.php': {'additions': 4, 'deletions': 1, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/microweber/microweber/raw/9ebbb4dd35da74025ab6965f722829a7f8f86566/src%2FMicroweberPackages%2FApp%2Ffunctions%2Fplupload.php', 'patch': \"@@ -336,9 +336,12 @@\\n // Make sure the fileName is unique but only if chunking is disabled\\n if ($chunks < 2 && file_exists($targetDir . DIRECTORY_SEPARATOR . $fileName)) {\\n     $ext = strrpos($fileName, '.');\\n+\\n     $fileName_a = substr($fileName, 0, $ext);\\n     $fileName_b = substr($fileName, $ext);\\n \\n+    $fileName_b = strtolower($fileName_b);\\n+\\n     $count = 1;\\n     while (file_exists($targetDir . DIRECTORY_SEPARATOR . $fileName_a . '_' . $count . $fileName_b)) {\\n         ++$count;\\n@@ -500,7 +503,7 @@\\n \\n     if (is_file($filePath) and !$chunks || $chunk == $chunks - 1) {\\n         $ext = get_file_extension($filePath);\\n-\\n+        $ext = strtolower($ext);\\n         if (function_exists('finfo_open') and function_exists('finfo_file')) {\\n             $finfo = finfo_open(FILEINFO_MIME_TYPE); // return mime type ala mimetype extension\\n             $mime = @finfo_file($finfo, $filePath);\"}}",
      "message_norm": "update",
      "language": "ro",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/MicroweberPackages/App/functions/plupload.php'])",
      "num_files": 1.0
    },
    {
      "index": 3349,
      "vuln_id": "GHSA-x2mc-8fgj-3wmr",
      "cwe_id": "{'CWE-20'}",
      "score": 7.5,
      "chain": "{'https://github.com/mafintosh/tar-fs/commit/06672828e6fa29ac8551b1b6f36c852a9a3c58a2'}",
      "dataset": "osv",
      "summary": "Improper Input Validation in tar-fs A vulnerability was found in tar-fs before 1.16.2. An Arbitrary File Overwrite issue exists when extracting a tarball containing a hardlink to a file that already exists on the system, in conjunction with a later plain file with the same name as the hardlink. This plain file content replaces the existing file content.",
      "published_date": "2019-05-01",
      "chain_len": 1,
      "project": "https://github.com/mafintosh/tar-fs",
      "commit_href": "https://github.com/mafintosh/tar-fs/commit/06672828e6fa29ac8551b1b6f36c852a9a3c58a2",
      "commit_sha": "06672828e6fa29ac8551b1b6f36c852a9a3c58a2",
      "patch": "SINGLE",
      "chain_ord": "['06672828e6fa29ac8551b1b6f36c852a9a3c58a2']",
      "before_first_fix_commit": "{'7b4ab17e950832cfd3e67421e48898fdb50318fc'}",
      "last_fix_commit": "06672828e6fa29ac8551b1b6f36c852a9a3c58a2",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/30/2018, 11:20:56",
      "message": "force hardlink targets to be in the tar",
      "author": "Mathias Buus",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/mafintosh/tar-fs/raw/06672828e6fa29ac8551b1b6f36c852a9a3c58a2/index.js', 'patch': \"@@ -261,7 +261,7 @@ exports.extract = function (cwd, opts) {\\n     var onlink = function () {\\n       if (win32) return next() // skip links on win for now before it can be tested\\n       xfs.unlink(name, function () {\\n-        var srcpath = path.resolve(cwd, header.linkname)\\n+        var srcpath = path.join(cwd, path.join('/', header.linkname))\\n \\n         xfs.link(srcpath, name, function (err) {\\n           if (err && err.code === 'EPERM' && opts.hardlinkAsFilesFallback) {\"}}",
      "message_norm": "force hardlink targets to be in the tar",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 2233,
      "vuln_id": "GHSA-jcxv-2j3h-mg59",
      "cwe_id": "{'CWE-119'}",
      "score": 6.5,
      "chain": "{'https://github.com/opencv/opencv/pull/10369/commits/7bbe1a53cfc097b82b1589f7915a2120de39274c'}",
      "dataset": "osv",
      "summary": "Improper Restriction of Operations within the Bounds of a Memory Buffer in OpenCV OpenCV 3.3.1 (corresponding with opencv-python and opencv-contrib-python 3.3.1.11) has a Buffer Overflow in the cv::PxMDecoder::readData function in grfmt_pxm.cpp, because an incorrect size value is used.",
      "published_date": "2021-10-12",
      "chain_len": 1,
      "project": "https://github.com/opencv/opencv",
      "commit_href": "https://github.com/opencv/opencv/pull/10369/commits/7bbe1a53cfc097b82b1589f7915a2120de39274c",
      "commit_sha": "7bbe1a53cfc097b82b1589f7915a2120de39274c",
      "patch": "SINGLE",
      "chain_ord": "['7bbe1a53cfc097b82b1589f7915a2120de39274c']",
      "before_first_fix_commit": "{'eecb64a97313bcc0221db20c9cd0636f1c27a6d8'}",
      "last_fix_commit": "7bbe1a53cfc097b82b1589f7915a2120de39274c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/21/2017, 01:10:24",
      "message": "imgcodecs(pxm): fix memcpy size",
      "author": "Alexander Alekhin",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'modules/imgcodecs/src/grfmt_pxm.cpp': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/opencv/opencv/raw/7bbe1a53cfc097b82b1589f7915a2120de39274c/modules%2Fimgcodecs%2Fsrc%2Fgrfmt_pxm.cpp', 'patch': '@@ -333,7 +333,7 @@ bool PxMDecoder::readData( Mat& img )\\n                         }\\n                     }\\n                     else\\n-                        memcpy( data, src, CV_ELEM_SIZE1(m_type)*m_width);\\n+                        memcpy(data, src, img.elemSize1()*m_width);\\n                 }\\n                 else\\n                 {'}}",
      "message_norm": "imgcodecs(pxm): fix memcpy size",
      "language": "ca",
      "entities": "[('fix', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['modules/imgcodecs/src/grfmt_pxm.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 557,
      "vuln_id": "GHSA-55j9-849x-26h4",
      "cwe_id": "{'CWE-74'}",
      "score": 8.2,
      "chain": "{'https://github.com/Cog-Creators/Red-DiscordBot/pull/4175/commits/9ab536235bafc2b42c3c17d7ce26f1cc64482a81'}",
      "dataset": "osv",
      "summary": "Remote Code Execution in Red Discord Bot ### Impact\nA RCE exploit has been discovered in the Trivia module: this exploit allows Discord users with specifically crafted usernames to inject code into the Trivia module's leaderboard command. By abusing this exploit, it's possible to perform destructive actions and/or access sensitive information.\n\n### Patches\nThis critical exploit has been fixed on version 3.3.11.\n\n### Workarounds\nUnloading the Trivia module with ``unload trivia`` can render this exploit not accessible. We still highly recommend updating to 3.3.11 to completely patch this issue.\n\n### References\nhttps://github.com/Cog-Creators/Red-DiscordBot/pull/4175\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Cog-Creators/Red-DiscordBot](https://github.com/Cog-Creators/Red-DiscordBot)\n* Over on our [Discord server](https://discord.gg/red)",
      "published_date": "2020-08-21",
      "chain_len": 1,
      "project": "https://github.com/Cog-Creators/Red-DiscordBot",
      "commit_href": "https://github.com/Cog-Creators/Red-DiscordBot/pull/4175/commits/9ab536235bafc2b42c3c17d7ce26f1cc64482a81",
      "commit_sha": "9ab536235bafc2b42c3c17d7ce26f1cc64482a81",
      "patch": "SINGLE",
      "chain_ord": "['9ab536235bafc2b42c3c17d7ce26f1cc64482a81']",
      "before_first_fix_commit": "{'c8526d42b4299d50b0c69f86204723cc82754453'}",
      "last_fix_commit": "9ab536235bafc2b42c3c17d7ce26f1cc64482a81",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/09/2020, 23:11:15",
      "message": "Remove an unnecessary `.format`",
      "author": "Flame442",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'redbot/cogs/trivia/trivia.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/Cog-Creators/Red-DiscordBot/raw/9ab536235bafc2b42c3c17d7ce26f1cc64482a81/redbot%2Fcogs%2Ftrivia%2Ftrivia.py', 'patch': '@@ -539,7 +539,7 @@ def _get_leaderboard(data: dict, key: str, top: int):\\n             )\\n             padding = [\" \" * (len(h) - len(f)) for h, f in zip(headers, fields)]\\n             fields = tuple(f + padding[i] for i, f in enumerate(fields))\\n-            lines.append(\" | \".join(fields).format(member=member, **m_data))\\n+            lines.append(\" | \".join(fields))\\n             if rank == top:\\n                 break\\n         return \"\\\\n\".join(lines)'}}",
      "message_norm": "remove an unnecessary `.format`",
      "language": "en",
      "entities": "[('remove', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['redbot/cogs/trivia/trivia.py'])",
      "num_files": 1.0
    },
    {
      "index": 1495,
      "vuln_id": "GHSA-c65v-p733-9796",
      "cwe_id": "{'CWE-79'}",
      "score": 8.0,
      "chain": "{'https://github.com/snipe/snipe-it/commit/7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in snipe/snipe-it snipe-it is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')",
      "published_date": "2021-11-23",
      "chain_len": 1,
      "project": "https://github.com/snipe/snipe-it",
      "commit_href": "https://github.com/snipe/snipe-it/commit/7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e",
      "commit_sha": "7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e",
      "patch": "SINGLE",
      "chain_ord": "['7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e']",
      "before_first_fix_commit": "{'e75a5f13ecb77a53d93d67c23e9f1b3580fe8092', 'f7b483358ff114b56c753ee9c2964059a55a3bd2'}",
      "last_fix_commit": "7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/16/2021, 04:33:51",
      "message": "Merge pull request #10315 from snipe/fixes/escape_custom_fields_in_api_response\n\nEscape custom field values in API response",
      "author": "snipe",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 5, 'total': 10}",
      "files": "{'app/Http/Transformers/AssetsTransformer.php': {'additions': 5, 'deletions': 5, 'changes': 10, 'status': 'modified', 'raw_url': 'https://github.com/snipe/snipe-it/raw/7ce5993f5ae9d713a0955c2fd8e2dff7a7ce886e/app%2FHttp%2FTransformers%2FAssetsTransformer.php', 'patch': \"@@ -93,15 +93,15 @@ public function transformAsset(Asset $asset)\\n                     $value = (Gate::allows('superadmin')) ? $decrypted : strtoupper(trans('admin/custom_fields/general.encrypted'));\\n \\n                     $fields_array[$field->name] = [\\n-                            'field' => $field->convertUnicodeDbSlug(),\\n-                            'value' => $value,\\n+                            'field' => e($field->convertUnicodeDbSlug()),\\n+                            'value' => e($value),\\n                             'field_format' => $field->format,\\n                         ];\\n \\n                 } else {\\n                     $fields_array[$field->name] = [\\n-                        'field' => $field->convertUnicodeDbSlug(),\\n-                        'value' => $asset->{$field->convertUnicodeDbSlug()},\\n+                        'field' => e($field->convertUnicodeDbSlug()),\\n+                        'value' => e($asset->{$field->convertUnicodeDbSlug()}),\\n                         'field_format' => $field->format,\\n                     ];\\n \\n@@ -134,7 +134,7 @@ public function transformAsset(Asset $asset)\\n                         \\n                             'id' => $component->id,\\n                             'pivot_id' => $component->pivot->id,\\n-                            'name' => $component->name,\\n+                            'name' => e($component->name),\\n                             'qty' => $component->pivot->assigned_qty,\\n                             'price_cost' => $component->purchase_cost,\\n                             'purchase_total' => $component->purchase_cost * $component->pivot->assigned_qty,\"}}",
      "message_norm": "merge pull request #10315 from snipe/fixes/escape_custom_fields_in_api_response\n\nescape custom field values in api response",
      "language": "ca",
      "entities": "[('#10315', 'ISSUE', ''), ('escape_custom_fields_in_api_response', 'SECWORD', ''), ('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['app/Http/Transformers/AssetsTransformer.php'])",
      "num_files": 1.0
    },
    {
      "index": 3457,
      "vuln_id": "GHSA-xm9f-vxmx-4m58",
      "cwe_id": "{'CWE-20'}",
      "score": 0.0,
      "chain": "{'https://github.com/OpenMage/magento-lts/commit/34709ac642d554aa1824892059186dd329db744b'}",
      "dataset": "osv",
      "summary": "Data Flow Sanitation Issue Fix  ### Impact\nDue to missing sanitation in data flow it was possible for admin users to upload arbitrary executable files to the server.",
      "published_date": "2021-08-30",
      "chain_len": 1,
      "project": "https://github.com/OpenMage/magento-lts",
      "commit_href": "https://github.com/OpenMage/magento-lts/commit/34709ac642d554aa1824892059186dd329db744b",
      "commit_sha": "34709ac642d554aa1824892059186dd329db744b",
      "patch": "SINGLE",
      "chain_ord": "['34709ac642d554aa1824892059186dd329db744b']",
      "before_first_fix_commit": "{'b99307d00b59c4a226a1e3e4083f02cf2fc8fce7'}",
      "last_fix_commit": "34709ac642d554aa1824892059186dd329db744b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/26/2021, 01:13:20",
      "message": "Merge pull request from GHSA-xm9f-vxmx-4m58\n\nCo-authored-by: Mark Lewis <markwlewis@Marks-MacBook-Pro.local>",
      "author": "Mark Lewis",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'app/code/core/Mage/Dataflow/Model/Convert/Adapter/Io.php': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/OpenMage/magento-lts/raw/34709ac642d554aa1824892059186dd329db744b/app%2Fcode%2Fcore%2FMage%2FDataflow%2FModel%2FConvert%2FAdapter%2FIo.php', 'patch': \"@@ -49,7 +49,7 @@ public function getResource($forWrite = false)\\n             $isError = false;\\n \\n             $ioConfig = $this->getVars();\\n-            switch ($this->getVar('type', 'file')) {\\n+            switch (strtolower($this->getVar('type', 'file'))) {\\n                 case 'file':\\n                     //validate export/import path\\n                     $path = rtrim($ioConfig['path'], '\\\\\\\\/')\"}}",
      "message_norm": "merge pull request from ghsa-xm9f-vxmx-4m58\n\nco-authored-by: mark lewis <markwlewis@marks-macbook-pro.local>",
      "language": "en",
      "entities": "[('ghsa-xm9f-vxmx-4m58', 'VULNID', 'GHSA')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['app/code/core/Mage/Dataflow/Model/Convert/Adapter/Io.php'])",
      "num_files": 1.0
    },
    {
      "index": 2381,
      "vuln_id": "GHSA-m884-279h-32v2",
      "cwe_id": "{'CWE-209'}",
      "score": 4.6,
      "chain": "{'https://github.com/symfony/symfony/commit/629d21b800a15dc649fb0ae9ed7cd9211e7e45db', 'https://github.com/symfony/symfony/commit/cf80224589ac05402d4f72f5ddf80900ec94d5ad'}",
      "dataset": "osv",
      "summary": "Exceptions displayed in non-debug configurations in Symfony Description\n-----------\n\nWhen `ErrorHandler` renders an exception HTML page, it uses un-escaped properties from the related Exception class to render the stacktrace. The security issue comes from the fact that the stacktraces were also displayed in non-`debug` environments.\n\nResolution\n----------\n\nThe `ErrorHandler` class now escapes all properties coming from the related Exception, and the stacktrace is not displayed anymore in non-`debug` environments.\n\nThe patches for this issue are available [here](https://github.com/symfony/symfony/commit/cf80224589ac05402d4f72f5ddf80900ec94d5ad) and [here](https://github.com/symfony/symfony/commit/629d21b800a15dc649fb0ae9ed7cd9211e7e45db) for branch 4.4.\n\nCredits\n-------\n\nI would like to thank Luka Sikic for reporting & Yonel Ceruto and J\u00e9r\u00e9my Deruss\u00e9 for fixing the issue.",
      "published_date": "2020-03-30",
      "chain_len": 2,
      "project": "https://github.com/symfony/symfony",
      "commit_href": "https://github.com/symfony/symfony/commit/629d21b800a15dc649fb0ae9ed7cd9211e7e45db",
      "commit_sha": "629d21b800a15dc649fb0ae9ed7cd9211e7e45db",
      "patch": "MULTI",
      "chain_ord": "['cf80224589ac05402d4f72f5ddf80900ec94d5ad', '629d21b800a15dc649fb0ae9ed7cd9211e7e45db']",
      "before_first_fix_commit": "{'3ee39e7468f1cd0b5a88b89aad72d61214e950f4'}",
      "last_fix_commit": "629d21b800a15dc649fb0ae9ed7cd9211e7e45db",
      "chain_ord_pos": 2.0,
      "commit_datetime": "02/04/2020, 09:49:52",
      "message": "Escape variable in Exception Template",
      "author": "J\u00e9r\u00e9my Deruss\u00e9",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 3, 'total': 6}",
      "files": "{'src/Symfony/Component/ErrorHandler/Resources/views/traces_text.html.php': {'additions': 3, 'deletions': 3, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/symfony/symfony/raw/629d21b800a15dc649fb0ae9ed7cd9211e7e45db/src%2FSymfony%2FComponent%2FErrorHandler%2FResources%2Fviews%2Ftraces_text.html.php', 'patch': '@@ -20,15 +20,15 @@\\n                 <?php if ($exception[\\'trace\\']) { ?>\\n                 <pre class=\"stacktrace\">\\n <?php\\n-                    echo $exception[\\'class\\'].\":\\\\n\";\\n+                    echo $this->escape($exception[\\'class\\']).\":\\\\n\";\\n                     if ($exception[\\'message\\']) {\\n-                        echo $exception[\\'message\\'].\"\\\\n\";\\n+                        echo $this->escape($exception[\\'message\\']).\"\\\\n\";\\n                     }\\n \\n                     foreach ($exception[\\'trace\\'] as $trace) {\\n                         echo \"\\\\n  \";\\n                         if ($trace[\\'function\\']) {\\n-                            echo \\'at \\'.$trace[\\'class\\'].$trace[\\'type\\'].$trace[\\'function\\'].\\'(\\'.(isset($trace[\\'args\\']) ? $this->formatArgsAsText($trace[\\'args\\']) : \\'\\').\\')\\';\\n+                            echo $this->escape(\\'at \\'.$trace[\\'class\\'].$trace[\\'type\\'].$trace[\\'function\\']).\\'(\\'.(isset($trace[\\'args\\']) ? $this->formatArgsAsText($trace[\\'args\\']) : \\'\\').\\')\\';\\n                         }\\n                         if ($trace[\\'file\\'] && $trace[\\'line\\']) {\\n                             echo($trace[\\'function\\'] ? \"\\\\n     (\" : \\'at \\').strtr(strip_tags($this->formatFile($trace[\\'file\\'], $trace[\\'line\\'])), [\\' at line \\'.$trace[\\'line\\'] => \\'\\']).\\':\\'.$trace[\\'line\\'].($trace[\\'function\\'] ? \\')\\' : \\'\\');'}}",
      "message_norm": "escape variable in exception template",
      "language": "ro",
      "entities": "[('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/Symfony/Component/ErrorHandler/Resources/views/traces_text.html.php'])",
      "num_files": 1.0
    },
    {
      "index": 971,
      "vuln_id": "GHSA-75vw-3m5v-fprh",
      "cwe_id": "{'CWE-611'}",
      "score": 9.8,
      "chain": "{'https://github.com/stanfordnlp/corenlp/commit/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd'}",
      "dataset": "osv",
      "summary": "corenlp is vulnerable to Improper Restriction of XML External Entity Reference corenlp is vulnerable to Improper Restriction of XML External Entity Reference",
      "published_date": "2022-01-21",
      "chain_len": 1,
      "project": "https://github.com/stanfordnlp/corenlp",
      "commit_href": "https://github.com/stanfordnlp/corenlp/commit/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
      "commit_sha": "1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
      "patch": "SINGLE",
      "chain_ord": "['1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd']",
      "before_first_fix_commit": "{'820192ce1ad1062057cf6abcb359cd635988bf63'}",
      "last_fix_commit": "1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/16/2022, 06:10:35",
      "message": "Fix XML schema vulnerability",
      "author": "Haxatron",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'src/edu/stanford/nlp/util/XMLUtils.java': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/stanfordnlp/CoreNLP/raw/1940ffb938dc4f3f5bc5f2a2fd8b35aabbbae3dd/src%2Fedu%2Fstanford%2Fnlp%2Futil%2FXMLUtils.java', 'patch': '@@ -302,6 +302,7 @@ public static DocumentBuilder getValidatingXmlParser(File schemaFile) {\\n       DocumentBuilderFactory dbf = safeDocumentBuilderFactory();\\n \\n       SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);\\n+      factory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\\n       Schema schema = factory.newSchema(schemaFile);\\n       dbf.setSchema(schema);'}}",
      "message_norm": "fix xml schema vulnerability",
      "language": "ro",
      "entities": "[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/edu/stanford/nlp/util/XMLUtils.java'])",
      "num_files": 1.0
    },
    {
      "index": 2187,
      "vuln_id": "GHSA-j4f2-536g-r55m",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/socketio/engine.io/commit/734f9d1268840722c41219e69eb58318e0b2ac6b'}",
      "dataset": "osv",
      "summary": "Resource exhaustion in engine.io  Engine.IO before 4.0.0 and 3.6.0 allows attackers to cause a denial of service (resource consumption) via a POST request to the long polling transport.",
      "published_date": "2022-02-09",
      "chain_len": 1,
      "project": "https://github.com/socketio/engine.io",
      "commit_href": "https://github.com/socketio/engine.io/commit/734f9d1268840722c41219e69eb58318e0b2ac6b",
      "commit_sha": "734f9d1268840722c41219e69eb58318e0b2ac6b",
      "patch": "SINGLE",
      "chain_ord": "['734f9d1268840722c41219e69eb58318e0b2ac6b']",
      "before_first_fix_commit": "{'61b949259ed966ef6fc8bfd61f14d1a2ef06d319'}",
      "last_fix_commit": "734f9d1268840722c41219e69eb58318e0b2ac6b",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/11/2020, 06:57:29",
      "message": "feat: decrease the default value of maxHttpBufferSize\n\nThis change reduces the default value from 100 mb to a more sane 1 mb.\n\nThis helps protect the server against denial of service attacks by\nmalicious clients sending huge amounts of data.",
      "author": "Damien Arrachequesne",
      "comments": "{'com_1': {'author': 'abergmann', 'datetime': '01/08/2021, 09:14:06', 'body': '[CVE-2020-36048](https://nvd.nist.gov/vuln/detail/CVE-2020-36048) was assigned to this commit.'}, 'com_2': {'author': 'ixevix', 'datetime': '05/11/2022, 18:37:43', 'body': 'Any luck getting this into an official release on some version of engine.io that socket.io v2.4.x depends on?'}, 'com_3': {'author': 'darrachequesne', 'datetime': '06/27/2022, 05:35:10', 'body': '@ixevix here we go:\\r\\n\\r\\n- https://github.com/socketio/engine.io/releases/tag/3.6.0\\r\\n- https://github.com/socketio/socket.io/releases/tag/2.5.0'}}",
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'lib/server.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/socketio/engine.io/raw/734f9d1268840722c41219e69eb58318e0b2ac6b/lib%2Fserver.js', 'patch': '@@ -26,7 +26,7 @@ class Server extends EventEmitter {\\n         pingTimeout: 5000,\\n         pingInterval: 25000,\\n         upgradeTimeout: 10000,\\n-        maxHttpBufferSize: 10e7,\\n+        maxHttpBufferSize: 1e6,\\n         transports: Object.keys(transports),\\n         allowUpgrades: true,\\n         perMessageDeflate: {'}}",
      "message_norm": "feat: decrease the default value of maxhttpbuffersize\n\nthis change reduces the default value from 100 mb to a more sane 1 mb.\n\nthis helps protect the server against denial of service attacks by\nmalicious clients sending huge amounts of data.",
      "language": "en",
      "entities": "[('protect', 'SECWORD', ''), ('server', 'SECWORD', ''), ('denial of service', 'SECWORD', ''), ('attacks', 'SECWORD', ''), ('malicious', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/server.js'])",
      "num_files": 1.0
    },
    {
      "index": 2457,
      "vuln_id": "GHSA-mqh2-9wrp-vx84",
      "cwe_id": "{'CWE-787'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/8ba6fa29cd8bf9cef9b718dc31c78c73081f5b31'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `SparseSplit` ### Impact\nAn attacker can cause a heap buffer overflow in `tf.raw_ops.SparseSplit`:\n\n```python\nimport tensorflow as tf\n\nshape_dims = tf.constant(0, dtype=tf.int64)\nindices = tf.ones([1, 1], dtype=tf.int64)\nvalues = tf.ones([1], dtype=tf.int64)\nshape = tf.ones([1], dtype=tf.int64)\n\ntf.raw_ops.SparseSplit(\n    split_dim=shape_dims, indices=indices, values=values,\n    shape=shape, num_split=1)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/699bff5d961f0abfde8fa3f876e6d241681fbef8/tensorflow/core/util/sparse/sparse_tensor.h#L528-L530) accesses an array element based on a user controlled offset:\n\n```cc\nconst int dim = input_tensor.indices().matrix<int64>()(i, split_dim);\nint slice_index = GetSliceIndex(dim, split_size, residual);\nnum_values[slice_index]++;\n```\n\nThis results in overriding values on the heap.\n\n### Patches\nWe have patched the issue in GitHub commit [8ba6fa29cd8bf9cef9b718dc31c78c73081f5b31](https://github.com/tensorflow/tensorflow/commit/8ba6fa29cd8bf9cef9b718dc31c78c73081f5b31).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/8ba6fa29cd8bf9cef9b718dc31c78c73081f5b31",
      "commit_sha": "8ba6fa29cd8bf9cef9b718dc31c78c73081f5b31",
      "patch": "SINGLE",
      "chain_ord": "['8ba6fa29cd8bf9cef9b718dc31c78c73081f5b31']",
      "before_first_fix_commit": "{'699bff5d961f0abfde8fa3f876e6d241681fbef8'}",
      "last_fix_commit": "8ba6fa29cd8bf9cef9b718dc31c78c73081f5b31",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/30/2021, 00:58:08",
      "message": "Fix heap-buffer-overflow issue with `tf.raw_ops.SparseSplit`.\n\nPiperOrigin-RevId: 371242872\nChange-Id: I482bb3d12602c7c3cc9446f97fb9f584bb98e9a4",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'tensorflow/core/util/sparse/sparse_tensor.h': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/8ba6fa29cd8bf9cef9b718dc31c78c73081f5b31/tensorflow%2Fcore%2Futil%2Fsparse%2Fsparse_tensor.h', 'patch': '@@ -527,6 +527,10 @@ inline Status SparseTensor::Split(const SparseTensor& input_tensor,\\n   for (int i = 0; i < input_tensor.indices().dim_size(0); ++i) {\\n     const int dim = input_tensor.indices().matrix<int64>()(i, split_dim);\\n     int slice_index = GetSliceIndex(dim, split_size, residual);\\n+    if (slice_index >= num_values.size()) {\\n+      return errors::InvalidArgument(\"Slice index \", slice_index,\\n+                                     \" is larger than num_split.\");\\n+    }\\n     num_values[slice_index]++;\\n   }'}}",
      "message_norm": "fix heap-buffer-overflow issue with `tf.raw_ops.sparsesplit`.\n\npiperorigin-revid: 371242872\nchange-id: i482bb3d12602c7c3cc9446f97fb9f584bb98e9a4",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371242872', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/util/sparse/sparse_tensor.h'])",
      "num_files": 1.0
    },
    {
      "index": 1714,
      "vuln_id": "GHSA-fc42-h7q4-qp8h",
      "cwe_id": "{'CWE-77'}",
      "score": 7.5,
      "chain": "{'https://github.com/ssnau/killport/commit/bec8e371f170a12e11cd222ffc7a6e1ae9942638'}",
      "dataset": "osv",
      "summary": "Command Injection in killport This affects the package killport before 1.0.2. If (attacker-controlled) user input is given, it is possible for an attacker to execute arbitrary commands. This is due to use of the child_process exec function without input sanitization. Running this PoC will cause the command touch success to be executed, leading to the creation of a file called success.",
      "published_date": "2021-04-13",
      "chain_len": 1,
      "project": "https://github.com/ssnau/killport",
      "commit_href": "https://github.com/ssnau/killport/commit/bec8e371f170a12e11cd222ffc7a6e1ae9942638",
      "commit_sha": "bec8e371f170a12e11cd222ffc7a6e1ae9942638",
      "patch": "SINGLE",
      "chain_ord": "['bec8e371f170a12e11cd222ffc7a6e1ae9942638']",
      "before_first_fix_commit": "{'5268f23ea8f152e47182b263d8f7ef20c12a9f28'}",
      "last_fix_commit": "bec8e371f170a12e11cd222ffc7a6e1ae9942638",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/17/2021, 17:26:35",
      "message": "fix a vulnerability issue if a provided port is not a number",
      "author": "ssnau",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'index.js': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/ssnau/killport/raw/bec8e371f170a12e11cd222ffc7a6e1ae9942638/index.js', 'patch': \"@@ -5,6 +5,7 @@ var notEmpty = function(x) {return x};\\n \\n module.exports = function killport(port) {\\n   return (new Promise(function(resolve, reject) {\\n+    if (!/^\\\\d+$/.test(port)) throw new Error('port must be a number.');\\n     var cmd = 'lsof -i:' + port; \\n     cp.exec(cmd, function(err, stdout, stderr){\\n       // do not check `err`, if no process found\"}}",
      "message_norm": "fix a vulnerability issue if a provided port is not a number",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('vulnerability', 'SECWORD', ''), ('issue', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 287,
      "vuln_id": "GHSA-3pcq-34w5-p4g2",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/nicolas-van/modern-async/commit/0010d28de1b15d51db3976080e26357fa7144436'}",
      "dataset": "osv",
      "summary": "forEachSeries and forEachLimit do not limit the number of requests ### Impact\n\nThis is a bug affecting two of the functions in this library: forEachSeries and forEachLimit. They should limit the concurrency of some actions but, in practice, they don't. Any code calling these functions will be written thinking they would limit the concurrency but they won't. This could lead to potential security issues in other projects.\n\n### Patches\n\nThe problem has been patched in 1.0.4.\n\n### Workarounds\n\nThere is no workaround aside from upgrading to 1.0.4.",
      "published_date": "2021-10-21",
      "chain_len": 1,
      "project": "https://github.com/nicolas-van/modern-async",
      "commit_href": "https://github.com/nicolas-van/modern-async/commit/0010d28de1b15d51db3976080e26357fa7144436",
      "commit_sha": "0010d28de1b15d51db3976080e26357fa7144436",
      "patch": "SINGLE",
      "chain_ord": "['0010d28de1b15d51db3976080e26357fa7144436']",
      "before_first_fix_commit": "{'7aa934294e59bc7359651a852e73bd5785b9b99b'}",
      "last_fix_commit": "0010d28de1b15d51db3976080e26357fa7144436",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/19/2021, 21:22:02",
      "message": "Fix #5",
      "author": "Nicolas Vanhoren",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/forEachLimit.mjs': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/nicolas-van/modern-async/raw/0010d28de1b15d51db3976080e26357fa7144436/src%2FforEachLimit.mjs', 'patch': \"@@ -35,7 +35,7 @@ import mapLimit from './mapLimit.mjs'\\n  */\\n async function forEachLimit (iterable, iteratee, concurrency) {\\n   await mapLimit(iterable, async (v, i, t) => {\\n-    iteratee(v, i, t)\\n+    await iteratee(v, i, t)\\n   }, concurrency)\\n }\"}}",
      "message_norm": "fix #5",
      "language": "ca",
      "entities": "[('fix', 'ACTION', ''), ('#5', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/forEachLimit.mjs'])",
      "num_files": 1.0
    },
    {
      "index": 2343,
      "vuln_id": "GHSA-m43c-649m-pm48",
      "cwe_id": "{'CWE-190'}",
      "score": 8.8,
      "chain": "{'https://github.com/opencv/opencv/pull/9726/commits/c58152d94ba878b2d7d76bcac59146312199b9eb'}",
      "dataset": "osv",
      "summary": "Integer Overflow or Wraparound in OpenCV. In opencv/modules/imgcodecs/src/utils.cpp, functions FillUniColor and FillUniGray do not check the input length, which can lead to integer overflow. If the image is from remote, may lead to remote code execution or denial of service. This affects Opencv 3.3 (corresponding with OpenCV-Python 3.3.0.9) and earlier.",
      "published_date": "2021-10-12",
      "chain_len": 1,
      "project": "https://github.com/opencv/opencv",
      "commit_href": "https://github.com/opencv/opencv/pull/9726/commits/c58152d94ba878b2d7d76bcac59146312199b9eb",
      "commit_sha": "c58152d94ba878b2d7d76bcac59146312199b9eb",
      "patch": "SINGLE",
      "chain_ord": "['c58152d94ba878b2d7d76bcac59146312199b9eb']",
      "before_first_fix_commit": "{'7475d23fec4bb7c7e2b662a0fa022d706dd2b520'}",
      "last_fix_commit": "c58152d94ba878b2d7d76bcac59146312199b9eb",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/27/2017, 06:04:01",
      "message": "Fix out of bounds write",
      "author": "blendin",
      "comments": "{'com_1': {'author': 'tyomitch', 'datetime': '04/29/2019, 11:17:11', 'body': 'CVE-2017-1000450'}}",
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'modules/imgcodecs/src/grfmt_bmp.cpp': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/opencv/opencv/raw/c58152d94ba878b2d7d76bcac59146312199b9eb/modules%2Fimgcodecs%2Fsrc%2Fgrfmt_bmp.cpp', 'patch': '@@ -375,6 +375,9 @@ decode_rle4_bad: ;\\n                                                 gray_palette[code] );\\n \\n                         line_end_flag = y - prev_y;\\n+\\n+                        if( y >= m_height )\\n+                            break;\\n                     }\\n                     else if( code > 2 ) // absolute mode\\n                     {'}}",
      "message_norm": "fix out of bounds write",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('out of bounds write', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['modules/imgcodecs/src/grfmt_bmp.cpp'])",
      "num_files": 1.0
    },
    {
      "index": 1741,
      "vuln_id": "GHSA-fj7f-vq84-fh43",
      "cwe_id": "{'CWE-88'}",
      "score": 6.7,
      "chain": "{'https://github.com/rubygems/rubygems/commit/a4f2f8ac17e6ce81c689527a8b6f14381060d95f', 'https://github.com/rubygems/rubygems/commit/0fad1ccfe9dd7a3c5b82c1496df3c2b4842870d3'}",
      "dataset": "osv",
      "summary": "Local Code Execution through Argument Injection via dash leading git url parameter in Gemfile. In `bundler` versions before 2.2.33, when working with untrusted and apparently harmless `Gemfile`'s, it is not expected that they lead to execution of external code, unless that's explicit in the ruby code inside the `Gemfile` itself. However, if the `Gemfile` includes `gem` entries that use the `git` option with invalid, but seemingly harmless, values with a leading dash, this can be false.\n\nTo handle dependencies that come from a Git repository instead of a registry, Bundler uses various commands, such as `git clone`. These commands are being constructed using user input (e.g. the repository URL). When building the\ncommands, Bundler versions before 2.2.33 correctly avoid Command Injection vulnerabilities by passing an array of arguments instead of a command string. However, there is the possibility that a user input starts with a dash (`-`) and is therefore treated as an optional argument instead of a positional one. This can lead to Code Execution because some of the commands have options that can be leveraged to run arbitrary executables.\n\nSince this value comes from the `Gemfile` file, it can contain any character, including a leading dash.\n\n### Exploitation\n\nTo exploit this vulnerability, an attacker has to craft a directory containing a `Gemfile` file that declares a dependency that is located in a Git repository. This dependency has to have a Git URL in the form of `-u./payload`. This URL\nwill be used to construct a Git clone command but will be interpreted as the [upload-pack](https://git-scm.com/docs/git-clone#Documentation/git-clone.txt--ultupload-packgt) argument. Then this directory needs to be shared with the victim, who then needs to run a command that evaluates the Gemfile, such as `bundle lock`, inside.\n\n### Impact\n\nThis vulnerability can lead to Arbitrary Code Execution, which could potentially lead to the takeover of the system. However, as explained above, the exploitability is very low, because it requires a lot of user interaction. It still could put developers at risk when dealing with untrusted files in a way they think is safe, because the exploit still works when the victim tries to make sure nothing can happen, e.g. by manually reviewing the `Gemfile` (although they would need the weird URL with a leading dash to not raise any flags).\n\nThis kind of attack vector [has been used in the past](https://www.cnbc.com/2021/01/26/north-korean-hackers-targeting-security-researchers-on-twitter.html) to target security researchers by sending them projects to collaborate on.\n\n### Patches\n\nBundler 2.2.33 has patched this problem by inserting `--` as an argument before any positional arguments to those Git commands that were affected by this issue.\n\n### Workarounds\n\nRegardless of whether users can upgrade or not, they should review any untrustred `Gemfile`'s before running any `bundler` commands that may read them, since they can contain arbitrary ruby code.\n\n### References\n\nhttps://cwe.mitre.org/data/definitions/88.html",
      "published_date": "2021-12-08",
      "chain_len": 2,
      "project": "https://github.com/rubygems/rubygems",
      "commit_href": "https://github.com/rubygems/rubygems/commit/0fad1ccfe9dd7a3c5b82c1496df3c2b4842870d3",
      "commit_sha": "0fad1ccfe9dd7a3c5b82c1496df3c2b4842870d3",
      "patch": "MULTI",
      "chain_ord": "['a4f2f8ac17e6ce81c689527a8b6f14381060d95f', '0fad1ccfe9dd7a3c5b82c1496df3c2b4842870d3']",
      "before_first_fix_commit": "{'6a655a698e952f897d0d014fc11bae4b608528ce'}",
      "last_fix_commit": "0fad1ccfe9dd7a3c5b82c1496df3c2b4842870d3",
      "chain_ord_pos": 2.0,
      "commit_datetime": "12/07/2021, 14:34:48",
      "message": "Changelog for Bundler version 2.2.33",
      "author": "David Rodr\u00edguez",
      "comments": null,
      "stats": "{'additions': 29, 'deletions': 0, 'total': 29}",
      "files": "{'bundler/CHANGELOG.md': {'additions': 29, 'deletions': 0, 'changes': 29, 'status': 'modified', 'raw_url': 'https://github.com/rubygems/rubygems/raw/0fad1ccfe9dd7a3c5b82c1496df3c2b4842870d3/bundler%2FCHANGELOG.md', 'patch': '@@ -1,3 +1,32 @@\\n+# 2.2.33 (December 7, 2021)\\n+\\n+## Security fixes:\\n+\\n+  - Pass \"--\" to git commands to separate positional and optional args [#5142](https://github.com/rubygems/rubygems/pull/5142)\\n+\\n+## Enhancements:\\n+\\n+  - Accept pull request URLs as github source [#5126](https://github.com/rubygems/rubygems/pull/5126)\\n+  - Add `--version` parameter to `bundle info` command [#5137](https://github.com/rubygems/rubygems/pull/5137)\\n+  - Let original `Errno::EACCES` error be raised in compact index updater [#5110](https://github.com/rubygems/rubygems/pull/5110)\\n+  - Improve gemfile-lockfile source equivalence errors [#5120](https://github.com/rubygems/rubygems/pull/5120)\\n+  - Avoid float-to-string loss of characters in GitHub Actions configuration labels in new gem template [#5089](https://github.com/rubygems/rubygems/pull/5089)\\n+  - Add an initial rbs template to `bundle gem` skeleton [#5041](https://github.com/rubygems/rubygems/pull/5041)\\n+  - Avoid shared libraries not getting environment passed right after argv in memory when `bundle exec` is used [#4815](https://github.com/rubygems/rubygems/pull/4815)\\n+\\n+## Bug fixes:\\n+\\n+  - Don\\'t cleanup paths from gems already activated from `$LOAD_PATH` [#5111](https://github.com/rubygems/rubygems/pull/5111)\\n+  - Fix handling prereleases of 0 versions, like 0.0.0.dev or 0.0.0.SNAPSHOT [#5116](https://github.com/rubygems/rubygems/pull/5116)\\n+  - Fix escape of filenames in `bundle doctor` [#5102](https://github.com/rubygems/rubygems/pull/5102)\\n+  - Don\\'t unlock dependencies when running `bundle install` after changing global source [#5090](https://github.com/rubygems/rubygems/pull/5090)\\n+  - Fix missing locked specs when depended on another platform [#5092](https://github.com/rubygems/rubygems/pull/5092)\\n+  - Fix `bundle info` sometimes claiming that bundler has been deleted [#5097](https://github.com/rubygems/rubygems/pull/5097)\\n+\\n+## Documentation:\\n+\\n+  - Ignore to generate the documentation from vendored libraries [#5118](https://github.com/rubygems/rubygems/pull/5118)\\n+\\n # 2.2.32 (November 23, 2021)\\n \\n ## Enhancements:'}}",
      "message_norm": "changelog for bundler version 2.2.33",
      "language": "da",
      "entities": "[('changelog', 'ACTION', ''), ('2.2.33', 'VERSION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['bundler/CHANGELOG.md'])",
      "num_files": 1.0
    },
    {
      "index": 1041,
      "vuln_id": "GHSA-7jh9-6cpf-h4m7",
      "cwe_id": "{'CWE-79'}",
      "score": 0.0,
      "chain": "{'https://github.com/MrSwitch/hello.js/commit/d6f5137f30de6e0ef7048191ee6ae575fdc2f669'}",
      "dataset": "osv",
      "summary": "XSS in hello.js This affects the package hello.js before 1.18.6. The code get the param oauth_redirect from url and pass it to location.assign without any check and sanitisation. So we can simply pass some XSS payloads into the url param oauth_redirect, such as javascript:alert(1).",
      "published_date": "2021-01-13",
      "chain_len": 1,
      "project": "https://github.com/MrSwitch/hello.js",
      "commit_href": "https://github.com/MrSwitch/hello.js/commit/d6f5137f30de6e0ef7048191ee6ae575fdc2f669",
      "commit_sha": "d6f5137f30de6e0ef7048191ee6ae575fdc2f669",
      "patch": "SINGLE",
      "chain_ord": "['d6f5137f30de6e0ef7048191ee6ae575fdc2f669']",
      "before_first_fix_commit": "{'3b79ec93781b3d7b9c0b56f598e060301d1f3e73'}",
      "last_fix_commit": "d6f5137f30de6e0ef7048191ee6ae575fdc2f669",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/06/2020, 11:20:56",
      "message": "fix(xss): oauth_redirect should be a valid url",
      "author": "Andrew Dodson",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 1, 'total': 6}",
      "files": "{'src/hello.js': {'additions': 5, 'deletions': 1, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/MrSwitch/hello.js/raw/d6f5137f30de6e0ef7048191ee6ae575fdc2f669/src%2Fhello.js', 'patch': \"@@ -1388,8 +1388,12 @@ hello.utils.extend(hello.utils, {\\n \\t\\t// (URI Fragments within 302 Location URI are lost over HTTPS)\\n \\t\\t// Loading the redirect.html before triggering the OAuth Flow seems to fix it.\\n \\t\\telse if ('oauth_redirect' in p) {\\n+\\t\\t\\tvar url = decodeURIComponent(p.oauth_redirect);\\n+\\n+\\t\\t\\tif (isValidUrl(url)) {\\n+\\t\\t\\t\\tlocation.assign(url);\\n+\\t\\t\\t}\\n \\n-\\t\\t\\tlocation.assign(decodeURIComponent(p.oauth_redirect));\\n \\t\\t\\treturn;\\n \\t\\t}\"}}",
      "message_norm": "fix(xss): oauth_redirect should be a valid url",
      "language": "en",
      "entities": "[('fix(xss', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/hello.js'])",
      "num_files": 1.0
    },
    {
      "index": 2130,
      "vuln_id": "GHSA-hv9c-qwqg-qj3v",
      "cwe_id": "{'CWE-1188'}",
      "score": 8.1,
      "chain": "{'https://github.com/electron/electron/commit/bab968ca776be28791e4dddfd50c86bd5fae62fa', 'https://github.com/electron/electron/commit/80221e52d93a96ea704cb6748ead669c55cff504', 'https://github.com/electron/electron/commit/519a02d8d4d28e8a467acb40fb26172a80c9454f', 'https://github.com/electron/electron/commit/ef0a6d9a1c96efc4657c6dd3a6624eba969f095b'}",
      "dataset": "osv",
      "summary": "Electron webPreferences vulnerability can be used to perform remote code execution GitHub Electron 1.7.15, 1.8.7, 2.0.7, and 3.0.0-beta.6, in certain scenarios involving IFRAME elements and \"nativeWindowOpen: true\" or \"sandbox: true\" options, is affected by a webPreferences vulnerability that can be leveraged to perform remote code execution.\n\nMore information to determine if you are impacted can be found on the [electron blog](https://electronjs.org/blog/web-preferences-fix).\n\n\n## Recommendation\n\nUpgrade Electron to >=3.0.0-beta.7, >=2.0.8, >=1.8.8, or >=1.7.16.",
      "published_date": "2018-08-23",
      "chain_len": 4,
      "project": "https://github.com/electron/electron",
      "commit_href": "https://github.com/electron/electron/commit/bab968ca776be28791e4dddfd50c86bd5fae62fa",
      "commit_sha": "bab968ca776be28791e4dddfd50c86bd5fae62fa",
      "patch": "MULTI",
      "chain_ord": "['ef0a6d9a1c96efc4657c6dd3a6624eba969f095b', '80221e52d93a96ea704cb6748ead669c55cff504', '519a02d8d4d28e8a467acb40fb26172a80c9454f', 'bab968ca776be28791e4dddfd50c86bd5fae62fa']",
      "before_first_fix_commit": "{'7fa3eba9512da5bb3a8a61433bb3921c2be67459'}",
      "last_fix_commit": "bab968ca776be28791e4dddfd50c86bd5fae62fa",
      "chain_ord_pos": 4.0,
      "commit_datetime": "08/22/2018, 17:36:02",
      "message": "fix: inheritance of webPreferences sub properties",
      "author": "Samuel Attard",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 2, 'total': 4}",
      "files": "{'lib/browser/guest-window-manager.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/electron/electron/raw/bab968ca776be28791e4dddfd50c86bd5fae62fa/lib%2Fbrowser%2Fguest-window-manager.js', 'patch': \"@@ -26,11 +26,11 @@ const mergeOptions = function (child, parent, visited) {\\n   visited.add(parent)\\n   for (const key in parent) {\\n     if (!hasProp.call(parent, key)) continue\\n-    if (key in child) continue\\n+    if (key in child && key !== 'webPreferences') continue\\n \\n     const value = parent[key]\\n     if (typeof value === 'object') {\\n-      child[key] = mergeOptions({}, value, visited)\\n+      child[key] = mergeOptions(child[key] || {}, value, visited)\\n     } else {\\n       child[key] = value\\n     }\"}}",
      "message_norm": "fix: inheritance of webpreferences sub properties",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/browser/guest-window-manager.js'])",
      "num_files": 1.0
    },
    {
      "index": 3392,
      "vuln_id": "GHSA-x7jg-6pwg-fx5h",
      "cwe_id": "{'CWE-444'}",
      "score": 7.5,
      "chain": "{'https://github.com/puma/puma/commit/f24d5521295a2152c286abb0a45a1e1e2bd275bd'}",
      "dataset": "osv",
      "summary": "HTTP Smuggling via Transfer-Encoding Header in Puma ### Impact\n\nBy using an invalid transfer-encoding header, an attacker could [smuggle an HTTP response.](https://portswigger.net/web-security/request-smuggling)\n\nOriginally reported by @ZeddYu, who has our thanks for the detailed report.\n\n### Patches\n\nThe problem has been fixed in Puma 3.12.5 and Puma 4.3.4.\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [Puma](https://github.com/puma/puma)\n* See our [security policy](https://github.com/puma/puma/security/policy)",
      "published_date": "2020-05-22",
      "chain_len": 1,
      "project": "https://github.com/puma/puma",
      "commit_href": "https://github.com/puma/puma/commit/f24d5521295a2152c286abb0a45a1e1e2bd275bd",
      "commit_sha": "f24d5521295a2152c286abb0a45a1e1e2bd275bd",
      "patch": "SINGLE",
      "chain_ord": "['f24d5521295a2152c286abb0a45a1e1e2bd275bd']",
      "before_first_fix_commit": "{'7a6593760d667dff95953e15c2327892e2da673c'}",
      "last_fix_commit": "f24d5521295a2152c286abb0a45a1e1e2bd275bd",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/18/2020, 23:01:53",
      "message": "Better handle client input",
      "author": "Evan Phoenix",
      "comments": null,
      "stats": "{'additions': 10, 'deletions': 2, 'total': 12}",
      "files": "{'lib/puma/client.rb': {'additions': 10, 'deletions': 2, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/puma/puma/raw/f24d5521295a2152c286abb0a45a1e1e2bd275bd/lib%2Fpuma%2Fclient.rb', 'patch': '@@ -285,8 +285,16 @@ def setup_body\\n \\n       te = @env[TRANSFER_ENCODING2]\\n \\n-      if te && CHUNKED.casecmp(te) == 0\\n-        return setup_chunked_body(body)\\n+      if te\\n+        if te.include?(\",\")\\n+          te.split(\",\").each do |part|\\n+            if CHUNKED.casecmp(part.strip) == 0\\n+              return setup_chunked_body(body)\\n+            end\\n+          end\\n+        elsif CHUNKED.casecmp(te) == 0\\n+          return setup_chunked_body(body)\\n+        end\\n       end\\n \\n       @chunked_body = false'}}",
      "message_norm": "better handle client input",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/puma/client.rb'])",
      "num_files": 1.0
    },
    {
      "index": 1798,
      "vuln_id": "GHSA-fxqh-cfjm-fp93",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/4071d8e2f6c45c1955a811fee757ca2adbe462c1'}",
      "dataset": "osv",
      "summary": "Division by 0 in `Reverse` ### Impact\nAn attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.Reverse`:\n\n```python\nimport tensorflow as tf\n\ntensor_input = tf.constant([], shape=[0, 1, 1], dtype=tf.int32)\ndims = tf.constant([False, True, False], shape=[3], dtype=tf.bool)\n\ntf.raw_ops.Reverse(tensor=tensor_input, dims=dims)\n``` \n    \nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/36229ea9e9451dac14a8b1f4711c435a1d84a594/tensorflow/core/kernels/reverse_op.cc#L75-L76) performs a division based on the first dimension of the tensor argument:\n    \n```cc\nconst int64 N = input.dim_size(0);\nconst int64 cost_per_unit = input.NumElements() / N;\n```\n\nSince this is controlled by the user, an attacker can trigger a denial of service.\n\n### Patches\nWe have patched the issue in GitHub commit [4071d8e2f6c45c1955a811fee757ca2adbe462c1](https://github.com/tensorflow/tensorflow/commit/4071d8e2f6c45c1955a811fee757ca2adbe462c1).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/4071d8e2f6c45c1955a811fee757ca2adbe462c1",
      "commit_sha": "4071d8e2f6c45c1955a811fee757ca2adbe462c1",
      "patch": "SINGLE",
      "chain_ord": "['4071d8e2f6c45c1955a811fee757ca2adbe462c1']",
      "before_first_fix_commit": "{'36229ea9e9451dac14a8b1f4711c435a1d84a594'}",
      "last_fix_commit": "4071d8e2f6c45c1955a811fee757ca2adbe462c1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/29/2021, 19:24:18",
      "message": "Fix FPE issue with `tf.raw_ops.Reverse`.\n\nPiperOrigin-RevId: 371176973\nChange-Id: Ic6d483bfc95313ec2299c2d1c956cfe96c96626c",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 6, 'deletions': 0, 'total': 6}",
      "files": "{'tensorflow/core/kernels/reverse_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/4071d8e2f6c45c1955a811fee757ca2adbe462c1/tensorflow%2Fcore%2Fkernels%2Freverse_op.cc', 'patch': '@@ -155,6 +155,12 @@ class ReverseOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* context) override {\\n     const Tensor& input = context->input(0);\\n+    // If input is provided, check to make sure the first dimension is valid.\\n+    if (input.dims() > 0) {\\n+      OP_REQUIRES(\\n+          context, input.dim_size(0) != 0,\\n+          errors::InvalidArgument(\"Invalid input first dimension. Found 0.\"));\\n+    }\\n     const Tensor& dims = context->input(1);\\n \\n     if (TensorShapeUtils::IsScalar(input.shape())) {'}}",
      "message_norm": "fix fpe issue with `tf.raw_ops.reverse`.\n\npiperorigin-revid: 371176973\nchange-id: ic6d483bfc95313ec2299c2d1c956cfe96c96626c",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('fpe', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371176973', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/reverse_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2027,
      "vuln_id": "GHSA-h8pj-cxx2-jfg2",
      "cwe_id": "{'CWE-20'}",
      "score": 9.1,
      "chain": "{'https://github.com/encode/httpx/pull/2185/commits/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1'}",
      "dataset": "osv",
      "summary": "Improper Input Validation in httpx Encode OSS httpx <=1.0.0.beta0 is affected by improper input validation in `httpx.URL`, `httpx.Client` and some functions using `httpx.URL.copy_with`.",
      "published_date": "2022-04-29",
      "chain_len": 1,
      "project": "https://github.com/encode/httpx",
      "commit_href": "https://github.com/encode/httpx/pull/2185/commits/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1",
      "commit_sha": "e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1",
      "patch": "SINGLE",
      "chain_ord": "['e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1']",
      "before_first_fix_commit": "{'b07fe7b0745e62be5ef9bce1bee9e7d7a8878552'}",
      "last_fix_commit": "e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/21/2022, 06:22:38",
      "message": "Patch `copy_with`",
      "author": "lebr0nli",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 1, 'total': 6}",
      "files": "{'httpx/_urls.py': {'additions': 5, 'deletions': 1, 'changes': 6, 'status': 'modified', 'raw_url': 'https://github.com/encode/httpx/raw/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1/httpx%2F_urls.py', 'patch': '@@ -484,7 +484,11 @@ def copy_with(self, **kwargs: typing.Any) -> \"URL\":\\n         #  \\\\_/   \\\\______________/\\\\_________/ \\\\_________/ \\\\__/\\n         #   |           |            |            |        |\\n         # scheme     authority       path        query   fragment\\n-        return URL(self._uri_reference.copy_with(**kwargs).unsplit())\\n+        new_url = URL(self)\\n+        new_url._uri_reference = self._uri_reference.copy_with(**kwargs)\\n+        if new_url.is_absolute_url:\\n+            new_url._uri_reference = new_url._uri_reference.normalize()\\n+        return URL(new_url)\\n \\n     def copy_set_param(self, key: str, value: typing.Any = None) -> \"URL\":\\n         return self.copy_with(params=self.params.set(key, value))'}}",
      "message_norm": "patch `copy_with`",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['httpx/_urls.py'])",
      "num_files": 1.0
    },
    {
      "index": 2796,
      "vuln_id": "GHSA-qpw2-xchm-655q",
      "cwe_id": "{'CWE-125'}",
      "score": 6.5,
      "chain": "{'https://github.com/mhart/StringStream/commit/2f4a9d496f94b0880e01a26857aa266a5a3ef274'}",
      "dataset": "osv",
      "summary": "Out-of-Bounds read in stringstream Versions less than 0.0.6 of the Node.js stringstream module are vulnerable to an out-of-bounds read because of allocation of uninitialized buffers when a number is passed in the input stream (when using Node.js 4.x).\n\n# WITHDRAWN\n\nThis is a duplicate of GHSA-mf6x-7mm4-x2g7",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/mhart/StringStream",
      "commit_href": "https://github.com/mhart/StringStream/commit/2f4a9d496f94b0880e01a26857aa266a5a3ef274",
      "commit_sha": "2f4a9d496f94b0880e01a26857aa266a5a3ef274",
      "patch": "SINGLE",
      "chain_ord": "['2f4a9d496f94b0880e01a26857aa266a5a3ef274']",
      "before_first_fix_commit": "{'1efe3bf507bf3a1161f8473908b60e881d41422b', 'afbc7442220358419e330618e47f3a65fc265b1b'}",
      "last_fix_commit": "2f4a9d496f94b0880e01a26857aa266a5a3ef274",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/17/2018, 10:22:09",
      "message": "Merge pull request #9 from mhart/fix-buffer-constructor-vuln\n\nEnsure data is not a number in Buffer constructor",
      "author": "Michael Hart",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'stringstream.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/mhart/StringStream/raw/2f4a9d496f94b0880e01a26857aa266a5a3ef274/stringstream.js', 'patch': \"@@ -28,7 +28,7 @@ StringStream.prototype.write = function(data) {\\n     return false\\n   }\\n   if (this.fromEncoding) {\\n-    if (Buffer.isBuffer(data)) data = data.toString()\\n+    if (Buffer.isBuffer(data) || typeof data === 'number') data = data.toString()\\n     data = new Buffer(data, this.fromEncoding)\\n   }\\n   var string = this.decoder.write(data)\"}}",
      "message_norm": "merge pull request #9 from mhart/fix-buffer-constructor-vuln\n\nensure data is not a number in buffer constructor",
      "language": "en",
      "entities": "[('#9', 'ISSUE', ''), ('ensure', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['stringstream.js'])",
      "num_files": 1.0
    },
    {
      "index": 2771,
      "vuln_id": "GHSA-qjj8-32p7-h289",
      "cwe_id": "{'CWE-369'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11'}",
      "dataset": "osv",
      "summary": "Division by 0 in `ResourceGather` ### Impact\nAn attacker can trigger a crash via a floating point exception in `tf.raw_ops.ResourceGather`:\n\n```python\nimport tensorflow as tf\n\ntensor = tf.constant(value=[[]],shape=(0,1),dtype=tf.uint32)\nv = tf.Variable(tensor)\ntf.raw_ops.ResourceGather(\n  resource=v.handle,\n  indices=[0],\n  dtype=tf.uint32,\n  batch_dims=1,\n  validate_indices=False)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L725-L731) computes the value of a value, `batch_size`, and then divides by it without checking that this value is not 0. \n\n### Patches\nWe have patched the issue in GitHub commit  [ac117ee8a8ea57b73d34665cdf00ef3303bc0b11](https://github.com/tensorflow/tensorflow/commit/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11",
      "commit_sha": "ac117ee8a8ea57b73d34665cdf00ef3303bc0b11",
      "patch": "SINGLE",
      "chain_ord": "['ac117ee8a8ea57b73d34665cdf00ef3303bc0b11']",
      "before_first_fix_commit": "{'3a7362750d5c372420aa8f0caf7bf5b5c3d0f52d'}",
      "last_fix_commit": "ac117ee8a8ea57b73d34665cdf00ef3303bc0b11",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/31/2021, 05:23:28",
      "message": "Prevent division by 0 in `resource_variable_ops.cc`\n\nPiperOrigin-RevId: 387939939\nChange-Id: Ib04902d63756633999959a70613f2eaa30c2c151",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 2, 'total': 11}",
      "files": "{'tensorflow/core/kernels/resource_variable_ops.cc': {'additions': 9, 'deletions': 2, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.cc', 'patch': '@@ -710,7 +710,8 @@ class ResourceGatherOp : public OpKernel {\\n         copy_functor(c->eigen_device<Device>(), tmp_indices.flat<Index>(),\\n                      indices.flat<Index>());\\n \\n-        AddBatchOffsets(&tmp_indices, params);\\n+        AddBatchOffsets(c, &tmp_indices, params);\\n+        if (!c->status().ok()) return;\\n         op_indices = &tmp_indices;\\n       }\\n \\n@@ -742,11 +743,17 @@ class ResourceGatherOp : public OpKernel {\\n   // Example: batch_dims = 1, indices = [[0, 1, 2], [0, 1, 2]]\\n   // If indexing into a params dimension of size 4, then the indices will become\\n   // [0, 1, 2, 4, 5, 6]\\n-  void AddBatchOffsets(Tensor* indices, const Tensor& params) {\\n+  void AddBatchOffsets(OpKernelContext* ctx, Tensor* indices,\\n+                       const Tensor& params) {\\n     int64_t batch_size = 1;  // The size of all batch dimensions.\\n     for (int idx = 0; idx < batch_dims_; ++idx) {\\n       batch_size *= params.dim_size(idx);\\n     }\\n+    OP_REQUIRES(\\n+        ctx, batch_size != 0,\\n+        errors::InvalidArgument(\\n+            \"Inner size of indices would result in batch_size of 0 and a \",\\n+            \"division by 0 in the implementation. This is illegal\"));\\n \\n     auto indices_flat = indices->flat<Index>();\\n     int64_t const index_inner_size = indices->NumElements() / batch_size;'}}",
      "message_norm": "prevent division by 0 in `resource_variable_ops.cc`\n\npiperorigin-revid: 387939939\nchange-id: ib04902d63756633999959a70613f2eaa30c2c151",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('387939939', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/resource_variable_ops.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1547,
      "vuln_id": "GHSA-cfx7-2xpc-8w4h",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/2c74674348a4708ced58ad6eb1b23354df8ee044'}",
      "dataset": "osv",
      "summary": "Division by zero in TFLite's implementation of `BatchToSpaceNd` ### Impact\nThe implementation of the `BatchToSpaceNd` TFLite operator is [vulnerable to a division by zero error](https://github.com/tensorflow/tensorflow/blob/b5ed552fe55895aee8bd8b191f744a069957d18d/tensorflow/lite/kernels/batch_to_space_nd.cc#L81-L82):\n\n```cc\nTF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\noutput_batch_size = output_batch_size / block_shape[dim];\n```\n\nAn attacker can craft a model such that one dimension of the `block` input is 0. Hence, the corresponding value in `block_shape` is 0.\n\n### Patches\nWe have patched the issue in GitHub commit [2c74674348a4708ced58ad6eb1b23354df8ee044](https://github.com/tensorflow/tensorflow/commit/2c74674348a4708ced58ad6eb1b23354df8ee044).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/2c74674348a4708ced58ad6eb1b23354df8ee044",
      "commit_sha": "2c74674348a4708ced58ad6eb1b23354df8ee044",
      "patch": "SINGLE",
      "chain_ord": "['2c74674348a4708ced58ad6eb1b23354df8ee044']",
      "before_first_fix_commit": "{'b5ed552fe55895aee8bd8b191f744a069957d18d'}",
      "last_fix_commit": "2c74674348a4708ced58ad6eb1b23354df8ee044",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 20:57:37",
      "message": "Prevent division by 0\n\nPiperOrigin-RevId: 370979352\nChange-Id: Ic79191c316d986fc6072ecaebfec9d5f2b924d00",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'tensorflow/lite/kernels/batch_to_space_nd.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/2c74674348a4708ced58ad6eb1b23354df8ee044/tensorflow%2Flite%2Fkernels%2Fbatch_to_space_nd.cc', 'patch': '@@ -78,6 +78,7 @@ TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\\n   int output_batch_size = input_size->data[0];\\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\\n     // Number of batch must be multiple of (block_shape[dim]).\\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\\n     TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\\n     output_batch_size = output_batch_size / block_shape[dim];\\n     output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -'}}",
      "message_norm": "prevent division by 0\n\npiperorigin-revid: 370979352\nchange-id: ic79191c316d986fc6072ecaebfec9d5f2b924d00",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('division by 0', 'SECWORD', ''), ('370979352', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/batch_to_space_nd.cc'])",
      "num_files": 1.0
    },
    {
      "index": 89,
      "vuln_id": "GHSA-2gfx-95x2-5v3x",
      "cwe_id": "{'CWE-787'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/a324ac84e573fba362a5e53d4e74d5de6729933e'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `QuantizedReshape` ### Impact\nAn attacker can cause a heap buffer overflow in `QuantizedReshape` by passing in invalid thresholds for the quantization:\n\n```python\nimport tensorflow as tf\n\ntensor = tf.constant([], dtype=tf.qint32)\nshape = tf.constant([], dtype=tf.int32)\ninput_min = tf.constant([], dtype=tf.float32)\ninput_max = tf.constant([], dtype=tf.float32)\n\ntf.raw_ops.QuantizedReshape(tensor=tensor, shape=shape, input_min=input_min, input_max=input_max)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/a324ac84e573fba362a5e53d4e74d5de6729933e/tensorflow/core/kernels/quantized_reshape_op.cc#L38-L55) assumes that the 2 arguments are always valid scalars and tries to access the numeric value directly:\n\n```cc\nconst auto& input_min_float_tensor = ctx->input(2);\n...\nconst float input_min_float = input_min_float_tensor.flat<float>()(0);\nconst auto& input_max_float_tensor = ctx->input(3);\n...\nconst float input_max_float = input_max_float_tensor.flat<float>()(0);\n```\n\nHowever, if any of these tensors is empty, then `.flat<T>()` is an empty buffer and accessing the element at position 0 results in overflow.\n\n### Patches\nWe have patched the issue in GitHub commit [a324ac84e573fba362a5e53d4e74d5de6729933e](https://github.com/tensorflow/tensorflow/commit/a324ac84e573fba362a5e53d4e74d5de6729933e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/a324ac84e573fba362a5e53d4e74d5de6729933e",
      "commit_sha": "a324ac84e573fba362a5e53d4e74d5de6729933e",
      "patch": "SINGLE",
      "chain_ord": "['a324ac84e573fba362a5e53d4e74d5de6729933e']",
      "before_first_fix_commit": "{'2ec2ce48365486311e56b3503bb75ab9e72a813d'}",
      "last_fix_commit": "a324ac84e573fba362a5e53d4e74d5de6729933e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/22/2021, 01:11:15",
      "message": "Validate arguments to `QuantizedReshape`.\n\nEnsure that validations from `Reshape` also terminate `QuantizedReshape` on failure.\n\nPiperOrigin-RevId: 369775421\nChange-Id: If8c5342267aceea65b7cb83a4b183304886f1ce8",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 23, 'deletions': 2, 'total': 25}",
      "files": "{'tensorflow/core/kernels/quantized_reshape_op.cc': {'additions': 23, 'deletions': 2, 'changes': 25, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/a324ac84e573fba362a5e53d4e74d5de6729933e/tensorflow%2Fcore%2Fkernels%2Fquantized_reshape_op.cc', 'patch': '@@ -17,6 +17,7 @@ limitations under the License.\\n \\n #include \"tensorflow/core/framework/op_kernel.h\"\\n #include \"tensorflow/core/framework/register_types.h\"\\n+#include \"tensorflow/core/framework/tensor_shape.h\"\\n #include \"tensorflow/core/framework/tensor_types.h\"\\n #include \"tensorflow/core/framework/types.h\"\\n #include \"tensorflow/core/kernels/reshape_op.h\"\\n@@ -30,9 +31,29 @@ class QuantizedReshapeOp : public ReshapeOp {\\n   void Compute(OpKernelContext* ctx) override {\\n     // This call processes inputs 1 and 2 to write output 0.\\n     ReshapeOp::Compute(ctx);\\n+    if (!ctx->status().ok()) {\\n+      return;\\n+    }\\n+\\n+    const auto& input_min_float_tensor = ctx->input(2);\\n+    const auto& input_min_float_shape = input_min_float_tensor.shape();\\n+    OP_REQUIRES(ctx,\\n+                TensorShapeUtils::IsScalar(input_min_float_shape) ||\\n+                    (TensorShapeUtils::IsVector(input_min_float_shape) &&\\n+                     (input_min_float_shape.dim_size(0) == 1)),\\n+                errors::InvalidArgument(\\n+                    \"input_min must be a scalar or a vector of 1 element\"));\\n+    const float input_min_float = input_min_float_tensor.flat<float>()(0);\\n+    const auto& input_max_float_tensor = ctx->input(3);\\n+    const auto& input_max_float_shape = input_max_float_tensor.shape();\\n+    OP_REQUIRES(ctx,\\n+                TensorShapeUtils::IsScalar(input_max_float_shape) ||\\n+                    (TensorShapeUtils::IsVector(input_max_float_shape) &&\\n+                     (input_max_float_shape.dim_size(0) == 1)),\\n+                errors::InvalidArgument(\\n+                    \"input_max must be a scalar or a vector of 1 element\"));\\n+    const float input_max_float = input_max_float_tensor.flat<float>()(0);\\n \\n-    const float input_min_float = ctx->input(2).flat<float>()(0);\\n-    const float input_max_float = ctx->input(3).flat<float>()(0);\\n     Tensor* output_min = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\\n     output_min->flat<float>()(0) = input_min_float;'}}",
      "message_norm": "validate arguments to `quantizedreshape`.\n\nensure that validations from `reshape` also terminate `quantizedreshape` on failure.\n\npiperorigin-revid: 369775421\nchange-id: if8c5342267aceea65b7cb83a4b183304886f1ce8",
      "language": "en",
      "entities": "[('validate', 'ACTION', ''), ('ensure', 'ACTION', ''), ('369775421', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/quantized_reshape_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 163,
      "vuln_id": "GHSA-2xgj-xhgf-ggjv",
      "cwe_id": "{'CWE-120'}",
      "score": 3.6,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/ba6822bd7b7324ba201a28b2f278c29a98edbef2', 'https://github.com/tensorflow/tensorflow/commit/0ab290774f91a23bebe30a358fde4e53ab4876a0'}",
      "dataset": "osv",
      "summary": "Heap buffer overflow in `BandedTriangularSolve` ### Impact\nAn attacker can trigger a heap buffer overflow in Eigen implementation of `tf.raw_ops.BandedTriangularSolve`:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n  \nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(0,1)),dtype=tf.float32)\nrhs_array = np.array([1,1])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(1,2)),dtype=tf.float32)\ntf.raw_ops.BandedTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/eccb7ec454e6617738554a255d77f08e60ee0808/tensorflow/core/kernels/linalg/banded_triangular_solve_op.cc#L269-L278) calls `ValidateInputTensors` for input validation but fails to validate that the two tensors are not empty:\n  \n```cc\nvoid ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0, const Tensor& in1) {\n  OP_REQUIRES(\n      ctx, in0.dims() >= 2, \n      errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n\n  OP_REQUIRES(\n      ctx, in1.dims() >= 2,\n      errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1.dims()));\n}\n``` \n\nFurthermore, since `OP_REQUIRES` macro only stops execution of current function after setting `ctx->status()` to a non-OK value, callers of helper functions that use `OP_REQUIRES` must check value of `ctx->status()` before continuing. This doesn't happen [in this op's implementation](https://github.com/tensorflow/tensorflow/blob/eccb7ec454e6617738554a255d77f08e60ee0808/tensorflow/core/kernels/linalg/banded_triangular_solve_op.cc#L219), hence the validation that is present is also not effective.\n\n### Patches\nWe have patched the issue in GitHub commit [ba6822bd7b7324ba201a28b2f278c29a98edbef2](https://github.com/tensorflow/tensorflow/commit/ba6822bd7b7324ba201a28b2f278c29a98edbef2) followed by GitHub commit [0ab290774f91a23bebe30a358fde4e53ab4876a0](https://github.com/tensorflow/tensorflow/commit/0ab290774f91a23bebe30a358fde4e53ab4876a0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ye Zhang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 2,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/ba6822bd7b7324ba201a28b2f278c29a98edbef2",
      "commit_sha": "ba6822bd7b7324ba201a28b2f278c29a98edbef2",
      "patch": "MULTI",
      "chain_ord": "['ba6822bd7b7324ba201a28b2f278c29a98edbef2', '0ab290774f91a23bebe30a358fde4e53ab4876a0']",
      "before_first_fix_commit": "{'327ef310be67923824814e85e13007e9699f4e0d'}",
      "last_fix_commit": "0ab290774f91a23bebe30a358fde4e53ab4876a0",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2021, 23:06:54",
      "message": "Fix OOB issue with `tf.raw_ops.SparseSparseMinimum`.\n\nPiperOrigin-RevId: 371005787\nChange-Id: Ib686ccc077836e8b980b8b5a03936d36a8ecaf71",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/sparse_sparse_binary_op_shared.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/ba6822bd7b7324ba201a28b2f278c29a98edbef2/tensorflow%2Fcore%2Fkernels%2Fsparse_sparse_binary_op_shared.cc', 'patch': '@@ -180,6 +180,11 @@ class SparseSparseBinaryOpShared : public OpKernel {\\n                                           \" for dimension \", i));\\n     }\\n \\n+    OP_REQUIRES(\\n+        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\\n+        errors::InvalidArgument(\\n+            \"Indices\\' dimensions do not match: got \", a_indices_t->dim_size(1),\\n+            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\\n     const int num_dims = a_indices_t->dim_size(1);\\n     const auto a_indices_mat = a_indices_t->matrix<int64>();\\n     const auto b_indices_mat = b_indices_t->matrix<int64>();'}}",
      "message_norm": "fix oob issue with `tf.raw_ops.sparsesparseminimum`.\n\npiperorigin-revid: 371005787\nchange-id: ib686ccc077836e8b980b8b5a03936d36a8ecaf71",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('oob', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371005787', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_sparse_binary_op_shared.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2539,
      "vuln_id": "GHSA-p92x-r36w-9395",
      "cwe_id": "{'CWE-843'}",
      "score": 5.6,
      "chain": "{'https://github.com/aheckmann/mpath/commit/89402d2880d4ea3518480a8c9847c541f2d824fc'}",
      "dataset": "osv",
      "summary": "Type confusion in mpath This affects the package mpath before 0.8.4. A type confusion vulnerability can lead to a bypass of CVE-2018-16490. In particular, the condition ignoreProperties.indexOf(parts[i]) !== -1 returns -1 if parts[i] is ['__proto__']. This is because the method that has been called if the input is an array is Array.prototype.indexOf() and not String.prototype.indexOf(). They behave differently depending on the type of the input.",
      "published_date": "2021-09-02",
      "chain_len": 1,
      "project": "https://github.com/aheckmann/mpath",
      "commit_href": "https://github.com/aheckmann/mpath/commit/89402d2880d4ea3518480a8c9847c541f2d824fc",
      "commit_sha": "89402d2880d4ea3518480a8c9847c541f2d824fc",
      "patch": "SINGLE",
      "chain_ord": "['89402d2880d4ea3518480a8c9847c541f2d824fc']",
      "before_first_fix_commit": "{'03c4efef8b25425476c1e0d7b6a0fb5adc18c0f9'}",
      "last_fix_commit": "89402d2880d4ea3518480a8c9847c541f2d824fc",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/01/2021, 15:12:24",
      "message": "fix: throw error if `parts` contains an element that isn't a string or number\n\nFix #13",
      "author": "Valeri Karpov",
      "comments": null,
      "stats": "{'additions': 12, 'deletions': 0, 'total': 12}",
      "files": "{'lib/index.js': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https://github.com/mongoosejs/mpath/raw/89402d2880d4ea3518480a8c9847c541f2d824fc/lib%2Findex.js', 'patch': \"@@ -64,6 +64,9 @@ exports.get = function(path, o, special, map) {\\n \\n   for (var i = 0; i < parts.length; ++i) {\\n     part = parts[i];\\n+    if (typeof parts[i] !== 'string' && typeof parts[i] !== 'number') {\\n+      throw new TypeError('Each segment of path to `get()` must be a string or number, got ' + typeof parts[i]);\\n+    }\\n \\n     if (Array.isArray(obj) && !/^\\\\d+$/.test(part)) {\\n       // reading a property from the array items\\n@@ -112,6 +115,9 @@ exports.has = function(path, o) {\\n   var len = parts.length;\\n   var cur = o;\\n   for (var i = 0; i < len; ++i) {\\n+    if (typeof parts[i] !== 'string' && typeof parts[i] !== 'number') {\\n+      throw new TypeError('Each segment of path to `has()` must be a string or number, got ' + typeof parts[i]);\\n+    }\\n     if (cur == null || typeof cur !== 'object' || !(parts[i] in cur)) {\\n       return false;\\n     }\\n@@ -143,6 +149,9 @@ exports.unset = function(path, o) {\\n     if (cur == null || typeof cur !== 'object' || !(parts[i] in cur)) {\\n       return false;\\n     }\\n+    if (typeof parts[i] !== 'string' && typeof parts[i] !== 'number') {\\n+      throw new TypeError('Each segment of path to `unset()` must be a string or number, got ' + typeof parts[i]);\\n+    }\\n     // Disallow any updates to __proto__ or special properties.\\n     if (ignoreProperties.indexOf(parts[i]) !== -1) {\\n       return false;\\n@@ -193,6 +202,9 @@ exports.set = function(path, val, o, special, map, _copying) {\\n   if (null == o) return;\\n \\n   for (var i = 0; i < parts.length; ++i) {\\n+    if (typeof parts[i] !== 'string' && typeof parts[i] !== 'number') {\\n+      throw new TypeError('Each segment of path to `set()` must be a string or number, got ' + typeof parts[i]);\\n+    }\\n     // Silently ignore any updates to `__proto__`, these are potentially\\n     // dangerous if using mpath with unsanitized data.\\n     if (ignoreProperties.indexOf(parts[i]) !== -1) {\"}}",
      "message_norm": "fix: throw error if `parts` contains an element that isn't a string or number\n\nfix #13",
      "language": "en",
      "entities": "[('error', 'FLAW', ''), ('fix', 'ACTION', ''), ('#13', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1158,
      "vuln_id": "GHSA-86wf-436m-h424",
      "cwe_id": "{'CWE-665'}",
      "score": 9.8,
      "chain": "{'https://github.com/TooTallNate/node-http-proxy-agent/commit/b7b7cc793c3226aa83f820ce5c277e81862d32eb'}",
      "dataset": "osv",
      "summary": "Resource Exhaustion Denial of Service in http-proxy-agent  A flaw was found in http-proxy-agent, prior to version 2.1.0. It was discovered http-proxy-agent passes an auth option to the Buffer constructor without proper sanitization. This could result in a Denial of Service through the usage of all available CPU resources and data exposure through an uninitialized memory leak in setups where an attacker could submit typed input to the auth parameter.",
      "published_date": "2022-01-06",
      "chain_len": 1,
      "project": "https://github.com/TooTallNate/node-http-proxy-agent",
      "commit_href": "https://github.com/TooTallNate/node-http-proxy-agent/commit/b7b7cc793c3226aa83f820ce5c277e81862d32eb",
      "commit_sha": "b7b7cc793c3226aa83f820ce5c277e81862d32eb",
      "patch": "SINGLE",
      "chain_ord": "['b7b7cc793c3226aa83f820ce5c277e81862d32eb']",
      "before_first_fix_commit": "{'687da671c075cde76be2d3e907d5384c970efadc'}",
      "last_fix_commit": "b7b7cc793c3226aa83f820ce5c277e81862d32eb",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/03/2018, 23:47:26",
      "message": "Use `Buffer.from()`\n\n`new Buffer()` is deprecated and unsafe.",
      "author": "Nathan Rajlich",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 3, 'total': 8}",
      "files": "{'index.js': {'additions': 5, 'deletions': 3, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/TooTallNate/node-http-proxy-agent/raw/b7b7cc793c3226aa83f820ce5c277e81862d32eb/index.js', 'patch': \"@@ -75,9 +75,11 @@ HttpProxyAgent.prototype.callback = function connect (req, opts, fn) {\\n   req.path = absolute;\\n \\n   // inject the `Proxy-Authorization` header if necessary\\n-  var auth = proxy.auth;\\n-  if (auth) {\\n-    req.setHeader('Proxy-Authorization', 'Basic ' + new Buffer(auth).toString('base64'));\\n+  if (proxy.auth) {\\n+    req.setHeader(\\n+      'Proxy-Authorization',\\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64')\\n+    );\\n   }\\n \\n   // create a socket connection to the proxy server\"}}",
      "message_norm": "use `buffer.from()`\n\n`new buffer()` is deprecated and unsafe.",
      "language": "en",
      "entities": "[('unsafe', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 1487,
      "vuln_id": "GHSA-c558-5gfm-p2r8",
      "cwe_id": "{'CWE-79'}",
      "score": 7.1,
      "chain": "{'https://github.com/DSpace/DSpace/commit/6f75bb084ab1937d094208c55cd84340040bcbb5', 'https://github.com/DSpace/DSpace/commit/ebb83a75234d3de9be129464013e998dc929b68d', 'https://github.com/DSpace/DSpace/commit/35030a23e48b5946f5853332c797e1c4adea7bb7', 'https://github.com/DSpace/DSpace/commit/c89e493e517b424dea6175caba54e91d3847fc3a'}",
      "dataset": "osv",
      "summary": "JSPUI spellcheck and autocomplete tools vulnerable to Cross Site Scripting ### Impact\nThe JSPUI spellcheck \"Did you mean\" HTML escapes the data-spell attribute in the link, but not the actual displayed text.  Similarly, the JSPUI autocomplete HTML does not properly escape text passed to it. Both are vulnerable to XSS.  This vulnerability only impacts the JSPUI.\n\n_This vulnerability does NOT impact the XMLUI or 7.x._\n\n### Patches\n_DSpace 6.x:_\n* Fixed in 6.4 via two commits: \n    * Fix for spellcheck: https://github.com/DSpace/DSpace/commit/ebb83a75234d3de9be129464013e998dc929b68d\n    * Fix for autocomplete: https://github.com/DSpace/DSpace/commit/35030a23e48b5946f5853332c797e1c4adea7bb7\n* 6.x patch files available (may be applied manually if an immediate upgrade to 6.4 or above is not possible)\n    * Fix for spellcheck: https://github.com/DSpace/DSpace/commit/ebb83a75234d3de9be129464013e998dc929b68d.patch\n    * Fix for autocomplete: https://github.com/DSpace/DSpace/commit/35030a23e48b5946f5853332c797e1c4adea7bb7.patch\n\n_DSpace 5.x:_\n* Fixed in 5.11 via two commits: \n    * Fix for spellcheck: https://github.com/DSpace/DSpace/commit/c89e493e517b424dea6175caba54e91d3847fc3a\n    * Fix for autocomplete: https://github.com/DSpace/DSpace/commit/6f75bb084ab1937d094208c55cd84340040bcbb5\n* 5.x patch files available (may be applied manually if an immediate upgrade to 5.11 or 6.4 is not possible)\n    * Fix for spellcheck: https://github.com/DSpace/DSpace/commit/c89e493e517b424dea6175caba54e91d3847fc3a.patch\n    * Fix for autocomplete: https://github.com/DSpace/DSpace/commit/6f75bb084ab1937d094208c55cd84340040bcbb5.patch\n\n#### Apply the patch to your DSpace\nIf at all possible, we recommend upgrading your DSpace site based on the upgrade instructions. However, if you are unable to do so, you can manually apply the above patches as follows:\n1. Download the appropriate patch file to the machine where DSpace is running\n2. From the `[dspace-src]` folder, apply the patch, e.g. `git apply [name-of-file].patch`\n3. Now, update your DSpace site (based loosely on the Upgrade instructions). This generally involves three steps:\n    1. Rebuild DSpace, e.g. `mvn -U clean package`  (This will recompile all DSpace code)\n    2. Redeploy DSpace, e.g. `ant update`  (This will copy all updated WARs / configs to your installation directory). Depending on your setup you also may need to copy the updated WARs over to your Tomcat webapps folder.\n    3. Restart Tomcat\n\n### References\nDiscovered & reported by Hassan Bhuiyan (Brunel University London)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Email us at security@dspace.org",
      "published_date": "2022-08-06",
      "chain_len": 4,
      "project": "https://github.com/DSpace/DSpace",
      "commit_href": "https://github.com/DSpace/DSpace/commit/c89e493e517b424dea6175caba54e91d3847fc3a",
      "commit_sha": "c89e493e517b424dea6175caba54e91d3847fc3a",
      "patch": "MULTI",
      "chain_ord": "['ebb83a75234d3de9be129464013e998dc929b68d', '35030a23e48b5946f5853332c797e1c4adea7bb7', 'c89e493e517b424dea6175caba54e91d3847fc3a', '6f75bb084ab1937d094208c55cd84340040bcbb5']",
      "before_first_fix_commit": "{'d1dd7d23329ef055069759df15cfa200c8e32e54'}",
      "last_fix_commit": "6f75bb084ab1937d094208c55cd84340040bcbb5",
      "chain_ord_pos": 3.0,
      "commit_datetime": "07/26/2022, 04:25:18",
      "message": "[DS-4453] Escape spellcheck, autocomplete HTML (JSPUI)",
      "author": "Kim Shepherd",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'dspace-jspui/src/main/webapp/search/discovery.jsp': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/DSpace/DSpace/raw/c89e493e517b424dea6175caba54e91d3847fc3a/dspace-jspui%2Fsrc%2Fmain%2Fwebapp%2Fsearch%2Fdiscovery.jsp', 'patch': '@@ -196,7 +196,7 @@\\n                                 <input type=\"text\" size=\"50\" id=\"query\" name=\"query\" value=\"<%= (query==null ? \"\" : Utils.addEntities(query)) %>\"/>\\n                                 <input type=\"submit\" id=\"main-query-submit\" class=\"btn btn-primary\" value=\"<fmt:message key=\"jsp.general.go\"/>\" />\\n <% if (StringUtils.isNotBlank(spellCheckQuery)) {%>\\n-\\t<p class=\"lead\"><fmt:message key=\"jsp.search.didyoumean\"><fmt:param><a id=\"spellCheckQuery\" data-spell=\"<%= Utils.addEntities(spellCheckQuery) %>\" href=\"#\"><%= spellCheckQuery %></a></fmt:param></fmt:message></p>\\n+\\t<p class=\"lead\"><fmt:message key=\"jsp.search.didyoumean\"><fmt:param><a id=\"spellCheckQuery\" data-spell=\"<%= Utils.addEntities(spellCheckQuery) %>\" href=\"#\"><%=Utils.addEntities(spellCheckQuery) %></a></fmt:param></fmt:message></p>\\n <% } %>                  \\n                                 <input type=\"hidden\" value=\"<%= rpp %>\" name=\"rpp\" />\\n                                 <input type=\"hidden\" value=\"<%= Utils.addEntities(sortedBy) %>\" name=\"sort_by\" />'}}",
      "message_norm": "[ds-4453] escape spellcheck, autocomplete html (jspui)",
      "language": "fr",
      "entities": "[('escape', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['dspace-jspui/src/main/webapp/search/discovery.jsp'])",
      "num_files": 1.0
    },
    {
      "index": 1661,
      "vuln_id": "GHSA-f4rr-5m7v-wxcw",
      "cwe_id": "{'CWE-843'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/b917181c29b50cb83399ba41f4d938dc369109a1'}",
      "dataset": "osv",
      "summary": "Type confusion leading to `CHECK`-failure based denial of service in TensorFlow ### Impact\nThe [macros that TensorFlow uses for writing assertions (e.g., `CHECK_LT`, `CHECK_GT`, etc.)](https://github.com/tensorflow/tensorflow/blob/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/core/platform/default/logging.h) have an incorrect logic when comparing `size_t` and `int` values. Due to type conversion rules, several of the macros would trigger incorrectly.\n\n### Patches\nWe have patched the issue in GitHub commit [b917181c29b50cb83399ba41f4d938dc369109a1](https://github.com/tensorflow/tensorflow/commit/b917181c29b50cb83399ba41f4d938dc369109a1) (merging GitHub PR [#55730](https://github.com/tensorflow/tensorflow/pull/55730)).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [GitHub issue](https://github.com/tensorflow/tensorflow/issues/55530).",
      "published_date": "2022-05-24",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/b917181c29b50cb83399ba41f4d938dc369109a1",
      "commit_sha": "b917181c29b50cb83399ba41f4d938dc369109a1",
      "patch": "SINGLE",
      "chain_ord": "['b917181c29b50cb83399ba41f4d938dc369109a1']",
      "before_first_fix_commit": "{'cce6f6484e967a0be4df8702c8ac36d021542455', 'd73521b7603f10e3029a2f1cd5067ca985738fc8'}",
      "last_fix_commit": "b917181c29b50cb83399ba41f4d938dc369109a1",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/28/2022, 21:41:18",
      "message": "Merge pull request #55730 from graphcore:awf/issue-55530\n\nPiperOrigin-RevId: 445252025",
      "author": "TensorFlower Gardener",
      "comments": null,
      "stats": "{'additions': 73, 'deletions': 28, 'total': 101}",
      "files": "{'tensorflow/core/platform/default/logging.h': {'additions': 73, 'deletions': 28, 'changes': 101, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/b917181c29b50cb83399ba41f4d938dc369109a1/tensorflow%2Fcore%2Fplatform%2Fdefault%2Flogging.h', 'patch': '@@ -85,7 +85,7 @@ class LogMessage : public std::basic_ostringstream<char> {\\n // that the ternary VLOG() implementation is balanced, type wise.\\n struct Voidifier {\\n   template <typename T>\\n-  void operator&(const T&)const {}\\n+  void operator&(const T&) const {}\\n };\\n \\n // LogMessageFatal ensures the process will exit in failure after\\n@@ -348,11 +348,13 @@ string* MakeCheckOpString(const T1& v1, const T2& v2, const char* exprtext) {\\n }\\n \\n // Helper functions for CHECK_OP macro.\\n-// The (int, int) specialization works around the issue that the compiler\\n+// We use the full name Check_EQ, Check_NE, etc. in case the file including\\n+// base/logging.h provides its own #defines for the simpler names EQ, NE, etc.\\n+// This happens if, for example, those are used as token names in a\\n+// yacc grammar.\\n+// The (int, int) overload works around the issue that the compiler\\n // will not instantiate the template version of the function on values of\\n // unnamed enum type - see comment below.\\n-// The (size_t, int) and (int, size_t) specialization are to handle unsigned\\n-// comparison errors while still being thorough with the comparison.\\n #define TF_DEFINE_CHECK_OP_IMPL(name, op)                                 \\\\\\n   template <typename T1, typename T2>                                     \\\\\\n   inline string* name##Impl(const T1& v1, const T2& v2,                   \\\\\\n@@ -364,34 +366,77 @@ string* MakeCheckOpString(const T1& v1, const T2& v2, const char* exprtext) {\\n   }                                                                       \\\\\\n   inline string* name##Impl(int v1, int v2, const char* exprtext) {       \\\\\\n     return name##Impl<int, int>(v1, v2, exprtext);                        \\\\\\n-  }                                                                       \\\\\\n-  inline string* name##Impl(const size_t v1, const int v2,                \\\\\\n-                            const char* exprtext) {                       \\\\\\n-    if (TF_PREDICT_FALSE(v2 < 0)) {                                       \\\\\\n-      return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext); \\\\\\n-    }                                                                     \\\\\\n-    return name##Impl<size_t, size_t>(v1, v2, exprtext);                  \\\\\\n-  }                                                                       \\\\\\n-  inline string* name##Impl(const int v1, const size_t v2,                \\\\\\n-                            const char* exprtext) {                       \\\\\\n-    if (TF_PREDICT_FALSE(v2 >= std::numeric_limits<int>::max())) {        \\\\\\n-      return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext); \\\\\\n-    }                                                                     \\\\\\n-    const size_t uval = (size_t)((unsigned)v2);                           \\\\\\n-    return name##Impl<size_t, size_t>(v1, uval, exprtext);                \\\\\\n   }\\n \\n-// We use the full name Check_EQ, Check_NE, etc. in case the file including\\n-// base/logging.h provides its own #defines for the simpler names EQ, NE, etc.\\n-// This happens if, for example, those are used as token names in a\\n-// yacc grammar.\\n-TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\\n-                        ==)  // Compilation error with CHECK_EQ(NULL, x)?\\n-TF_DEFINE_CHECK_OP_IMPL(Check_NE, !=)  // Use CHECK(x == NULL) instead.\\n+// The (size_t, int) and (int, size_t) specialization are to handle unsigned\\n+// comparison errors while still being thorough with the comparison.\\n+\\n+TF_DEFINE_CHECK_OP_IMPL(Check_EQ, ==)\\n+// Compilation error with CHECK_EQ(NULL, x)?\\n+// Use CHECK(x == NULL) instead.\\n+\\n+inline string* Check_EQImpl(int v1, size_t v2, const char* exprtext) {\\n+  if (TF_PREDICT_FALSE(v1 < 0))\\n+    ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);\\n+\\n+  return Check_EQImpl(size_t(v1), v2, exprtext);\\n+}\\n+\\n+inline string* Check_EQImpl(size_t v1, int v2, const char* exprtext) {\\n+  return Check_EQImpl(v2, v1, exprtext);\\n+}\\n+\\n+TF_DEFINE_CHECK_OP_IMPL(Check_NE, !=)\\n+\\n+inline string* Check_NEImpl(int v1, size_t v2, const char* exprtext) {\\n+  if (v1 < 0) return NULL;\\n+\\n+  return Check_NEImpl(size_t(v1), v2, exprtext);\\n+}\\n+\\n+inline string* Check_NEImpl(size_t v1, int v2, const char* exprtext) {\\n+  return Check_NEImpl(v2, v1, exprtext);\\n+}\\n+\\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)\\n+\\n+inline string* Check_LEImpl(int v1, size_t v2, const char* exprtext) {\\n+  if (v1 <= 0) return NULL;\\n+\\n+  return Check_LEImpl(size_t(v1), v2, exprtext);\\n+}\\n+\\n+inline string* Check_LEImpl(size_t v1, int v2, const char* exprtext) {\\n+  if (TF_PREDICT_FALSE(v2 < 0))\\n+    return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);\\n+  return Check_LEImpl(v1, size_t(v2), exprtext);\\n+}\\n+\\n TF_DEFINE_CHECK_OP_IMPL(Check_LT, <)\\n-TF_DEFINE_CHECK_OP_IMPL(Check_GE, >=)\\n-TF_DEFINE_CHECK_OP_IMPL(Check_GT, >)\\n+\\n+inline string* Check_LTImpl(int v1, size_t v2, const char* exprtext) {\\n+  if (v1 < 0) return NULL;\\n+\\n+  return Check_LTImpl(size_t(v1), v2, exprtext);\\n+}\\n+\\n+inline string* Check_LTImpl(size_t v1, int v2, const char* exprtext) {\\n+  if (v2 < 0)\\n+    return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);\\n+  return Check_LTImpl(v1, size_t(v2), exprtext);\\n+}\\n+\\n+// Implement GE,GT in terms of LE,LT\\n+template <typename T1, typename T2>\\n+inline string* Check_GEImpl(const T1& v1, const T2& v2, const char* exprtext) {\\n+  return Check_LEImpl(v2, v1, exprtext);\\n+}\\n+\\n+template <typename T1, typename T2>\\n+inline string* Check_GTImpl(const T1& v1, const T2& v2, const char* exprtext) {\\n+  return Check_LTImpl(v2, v1, exprtext);\\n+}\\n+\\n #undef TF_DEFINE_CHECK_OP_IMPL\\n \\n // In optimized mode, use CheckOpString to hint to compiler that'}}",
      "message_norm": "merge pull request #55730 from graphcore:awf/issue-55530\n\npiperorigin-revid: 445252025",
      "language": "en",
      "entities": "[('#55730', 'ISSUE', ''), ('445252025', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/platform/default/logging.h'])",
      "num_files": 1.0
    },
    {
      "index": 1720,
      "vuln_id": "GHSA-ff28-f46g-r9g8",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/gogs/gogs/commit/bc77440b301ac8780698be91dff1ac33b7cee850'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in Gogs ### Impact\n\nThe malicious user is able to upload a crafted SVG file as the issue attachment to archive XSS. All installations [allow uploading SVG (`text/xml`) files as issue attachments (non-default)](https://github.com/gogs/gogs/blob/e51e01683408e10b3dcd2ace65e259ca7f0fd61b/conf/app.ini#L283-L284) are affected.\n\n### Patches\n\nCorrectly setting the Content Security Policy for the serving endpoint. Users should upgrade to 0.12.7 or the latest 0.13.0+dev.\n\n### Workarounds\n\n[Disable uploading SVG files (`text/xml`) as issue attachments](https://github.com/gogs/gogs/blob/e51e01683408e10b3dcd2ace65e259ca7f0fd61b/conf/app.ini#L283-L284).\n\n### References\n\nhttps://huntr.dev/bounties/34a12146-3a5d-4efc-a0f8-7a3ae04b198d/\n\n### For more information\n\nIf you have any questions or comments about this advisory, please post on https://github.com/gogs/gogs/issues/6919.",
      "published_date": "2022-05-24",
      "chain_len": 1,
      "project": "https://github.com/gogs/gogs",
      "commit_href": "https://github.com/gogs/gogs/commit/bc77440b301ac8780698be91dff1ac33b7cee850",
      "commit_sha": "bc77440b301ac8780698be91dff1ac33b7cee850",
      "patch": "SINGLE",
      "chain_ord": "['bc77440b301ac8780698be91dff1ac33b7cee850']",
      "before_first_fix_commit": "{'2a8f561c6413ed7683a3844a8ae6b68d30c0dd08'}",
      "last_fix_commit": "bc77440b301ac8780698be91dff1ac33b7cee850",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/03/2022, 09:51:28",
      "message": "attachment: set CSP header in the serving endpoint (#6926)",
      "author": "Joe Chen",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 0, 'total': 1}",
      "files": "{'internal/cmd/web.go': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https://github.com/gogs/gogs/raw/bc77440b301ac8780698be91dff1ac33b7cee850/internal%2Fcmd%2Fweb.go', 'patch': '@@ -314,6 +314,7 @@ func runWeb(c *cli.Context) error {\\n \\t\\t\\t\\t}\\n \\t\\t\\t\\tdefer fr.Close()\\n \\n+\\t\\t\\t\\tc.Header().Set(\"Content-Security-Policy\", \"default-src \\'none\\'; style-src \\'unsafe-inline\\'; sandbox\")\\n \\t\\t\\t\\tc.Header().Set(\"Cache-Control\", \"public,max-age=86400\")\\n \\t\\t\\t\\tc.Header().Set(\"Content-Disposition\", fmt.Sprintf(`inline; filename=\"%s\"`, attach.Name))'}}",
      "message_norm": "attachment: set csp header in the serving endpoint (#6926)",
      "language": "en",
      "entities": "[('csp header', 'SECWORD', ''), ('#6926', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['internal/cmd/web.go'])",
      "num_files": 1.0
    },
    {
      "index": 2682,
      "vuln_id": "GHSA-q3g3-h9r4-prrc",
      "cwe_id": "{'CWE-125'}",
      "score": 7.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/93f428fd1768df147171ed674fee1fc5ab8309ec'}",
      "dataset": "osv",
      "summary": "Reference binding to nullptr and heap OOB in binary cwise ops ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations):\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.SqrtGrad(y=[4, 16],dy=[])\n```\n  \nThe [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/cwise_ops_common.h#L264) assumes that the two inputs have exactly the same number of elements but does not check that. Hence, when the eigen functor executes it triggers heap OOB reads and undefined behavior due to binding to nullptr.\n\n### Patches\nWe have patched the issue in GitHub commit [93f428fd1768df147171ed674fee1fc5ab8309ec](https://github.com/tensorflow/tensorflow/commit/93f428fd1768df147171ed674fee1fc5ab8309ec).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo  360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/93f428fd1768df147171ed674fee1fc5ab8309ec",
      "commit_sha": "93f428fd1768df147171ed674fee1fc5ab8309ec",
      "patch": "SINGLE",
      "chain_ord": "['93f428fd1768df147171ed674fee1fc5ab8309ec']",
      "before_first_fix_commit": "{'bc9c546ce7015c57c2f15c168b3d9201de679a1d'}",
      "last_fix_commit": "93f428fd1768df147171ed674fee1fc5ab8309ec",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/31/2021, 04:42:36",
      "message": "Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 5, 'deletions': 0, 'total': 5}",
      "files": "{'tensorflow/core/kernels/cwise_ops_common.h': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/93f428fd1768df147171ed674fee1fc5ab8309ec/tensorflow%2Fcore%2Fkernels%2Fcwise_ops_common.h', 'patch': '@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& in0 = ctx->input(0);\\n     const Tensor& in1 = ctx->input(1);\\n+    OP_REQUIRES(\\n+        ctx, in0.NumElements() == in1.NumElements(),\\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\\n+                                \"same number of elements, got \",\\n+                                in0.NumElements(), \" and \", in1.NumElements()));\\n     auto in0_flat = in0.flat<Tin>();\\n     auto in1_flat = in1.flat<Tin>();\\n     const Device& eigen_device = ctx->eigen_device<Device>();'}}",
      "message_norm": "fix nullptr deref and heap oob access in binary cwise ops.\n\npiperorigin-revid: 387936777\nchange-id: i608b8074cec36a982cca622b7144cb2c43e6e19f",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('heap oob', 'SECWORD', ''), ('387936777', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/cwise_ops_common.h'])",
      "num_files": 1.0
    },
    {
      "index": 2099,
      "vuln_id": "GHSA-hp4c-x6r7-6555",
      "cwe_id": "{'CWE-369'}",
      "score": 5.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/d9204be9f49520cdaaeb2541d1dc5187b23f31d9'}",
      "dataset": "osv",
      "summary": "Floating point exception in `SparseDenseCwiseDiv` ### Impact\nThe implementation of `tf.raw_ops.SparseDenseCwiseDiv` is vulnerable to a division by 0 error:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\ntf.raw_ops.SparseDenseCwiseDiv( \n  sp_indices=np.array([[4]]),\n  sp_values=np.array([-400]),\n  sp_shape=np.array([647.]),\n  dense=np.array([0]))\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc#L56) uses a common class for all binary operations but fails to treat the division by 0 case separately.\n\n### Patches\nWe have patched the issue in GitHub commit [d9204be9f49520cdaaeb2541d1dc5187b23f31d9](https://github.com/tensorflow/tensorflow/commit/d9204be9f49520cdaaeb2541d1dc5187b23f31d9).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-08-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/d9204be9f49520cdaaeb2541d1dc5187b23f31d9",
      "commit_sha": "d9204be9f49520cdaaeb2541d1dc5187b23f31d9",
      "patch": "SINGLE",
      "chain_ord": "['d9204be9f49520cdaaeb2541d1dc5187b23f31d9']",
      "before_first_fix_commit": "{'a95743ddba81449601bc32f249d979a944502de6'}",
      "last_fix_commit": "d9204be9f49520cdaaeb2541d1dc5187b23f31d9",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/10/2021, 01:27:22",
      "message": "Disallow division by zero FPE in tf.raw_ops.SparseDenseCwiseDiv\n\nPiperOrigin-RevId: 383959809\nChange-Id: Ibe88458bdf66a686c93e354b8255dec94285c560",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 10, 'deletions': 1, 'total': 11}",
      "files": "{'tensorflow/core/kernels/sparse_dense_binary_op_shared.cc': {'additions': 10, 'deletions': 1, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/d9204be9f49520cdaaeb2541d1dc5187b23f31d9/tensorflow%2Fcore%2Fkernels%2Fsparse_dense_binary_op_shared.cc', 'patch': '@@ -114,7 +114,10 @@ class SparseDenseBinaryOpShared : public OpKernel {\\n     OP_REQUIRES_OK(\\n         ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\\n                                 &dense_gathered));\\n-\\n+    bool op_is_div = false;\\n+    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\\n+      op_is_div = true;\\n+    }\\n     // Pulls relevant entries from the dense side, with reshape and broadcasting\\n     // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\\n     // up memory.\\n@@ -143,6 +146,12 @@ class SparseDenseBinaryOpShared : public OpKernel {\\n           errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\\\\n                                   \"dense side with broadcasted shape\"));       \\\\\\n       dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\\\\n+      if (op_is_div) {                                                         \\\\\\n+        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\\\\n+                    errors::InvalidArgument(                                   \\\\\\n+                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\\\\n+                        \"but input dense tensor contains zero \"));             \\\\\\n+      }                                                                        \\\\\\n     }                                                                          \\\\\\n     break;                                                                     \\\\\\n   }'}}",
      "message_norm": "disallow division by zero fpe in tf.raw_ops.sparsedensecwisediv\n\npiperorigin-revid: 383959809\nchange-id: ibe88458bdf66a686c93e354b8255dec94285c560",
      "language": "en",
      "entities": "[('division by zero', 'SECWORD', ''), ('fpe', 'SECWORD', ''), ('383959809', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/sparse_dense_binary_op_shared.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1834,
      "vuln_id": "GHSA-g6ww-v8xp-vmwg",
      "cwe_id": "{'CWE-1321', 'CWE-20'}",
      "score": 7.2,
      "chain": "{'https://github.com/chaijs/pathval/pull/58/commits/21a9046cfa0c2697cb41990f3b4316db410e6c8a'}",
      "dataset": "osv",
      "summary": "Prototype pollution in pathval A prototype pollution vulnerability affects all versions of package pathval under 1.1.1.",
      "published_date": "2022-02-10",
      "chain_len": 1,
      "project": "https://github.com/chaijs/pathval",
      "commit_href": "https://github.com/chaijs/pathval/pull/58/commits/21a9046cfa0c2697cb41990f3b4316db410e6c8a",
      "commit_sha": "21a9046cfa0c2697cb41990f3b4316db410e6c8a",
      "patch": "SINGLE",
      "chain_ord": "['21a9046cfa0c2697cb41990f3b4316db410e6c8a']",
      "before_first_fix_commit": "{'a1230184a33a18f4eb3a92817e9b7492e8082903'}",
      "last_fix_commit": "21a9046cfa0c2697cb41990f3b4316db410e6c8a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/25/2020, 12:37:44",
      "message": "fix: \ud83d\udc1b fix prototype pollution",
      "author": "Adam Gold",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'index.js': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/chaijs/pathval/raw/21a9046cfa0c2697cb41990f3b4316db410e6c8a/index.js', 'patch': '@@ -76,6 +76,9 @@ function parsePath(path) {\\n   var str = path.replace(/([^\\\\\\\\])\\\\[/g, \\'$1.[\\');\\n   var parts = str.match(/(\\\\\\\\\\\\.|[^.]+?)+/g);\\n   return parts.map(function mapMatches(value) {\\n+    if (value === \"constructor\" || value === \"__proto__\" || value === \"prototype\") {\\n+      return {}\\n+    }\\n     var regexp = /^\\\\[(\\\\d+)\\\\]$/;\\n     var mArr = regexp.exec(value);\\n     var parsed = null;'}}",
      "message_norm": "fix: \ud83d\udc1b fix prototype pollution",
      "language": "fr",
      "entities": "[('fix', 'ACTION', ''), ('prototype pollution', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['index.js'])",
      "num_files": 1.0
    },
    {
      "index": 219,
      "vuln_id": "GHSA-3872-f48p-pxqj",
      "cwe_id": "{'CWE-88', 'CWE-77'}",
      "score": 8.8,
      "chain": "{'https://github.com/WeblateOrg/weblate/commit/d83672a3e7415da1490334e2c9431e5da1966842', 'https://github.com/WeblateOrg/weblate/commit/35d59f1f040541c358cece0a8d4a63183ca919b8'}",
      "dataset": "osv",
      "summary": "Improper Neutralization of Special Elements used in a Command ('Command Injection') in Weblate ### Impact\nWeblate didn't correctly sanitize some arguments passed to Git and Mercurial, which allowed changing their behavior in an unintended way.\n\n### Patches\n\nThe issues were fixed in the 4.11.1 release. The following commits are addressing it:\n\n* 35d59f1f040541c358cece0a8d4a63183ca919b8\n* d83672a3e7415da1490334e2c9431e5da1966842\n\n### Workarounds\n\nInstances in which untrusted users cannot create new components are not affected.\n\n### References\n* [SNYK-PYTHON-WEBLATE-2414088](https://security.snyk.io/vuln/SNYK-PYTHON-WEBLATE-2414088)\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open a topic in [discussions](https://github.com/WeblateOrg/weblate/discussions)\n* Email us at [care@weblate.org](mailto:care@weblate.org)",
      "published_date": "2022-03-04",
      "chain_len": 2,
      "project": "https://github.com/WeblateOrg/weblate",
      "commit_href": "https://github.com/WeblateOrg/weblate/commit/35d59f1f040541c358cece0a8d4a63183ca919b8",
      "commit_sha": "35d59f1f040541c358cece0a8d4a63183ca919b8",
      "patch": "MULTI",
      "chain_ord": "['35d59f1f040541c358cece0a8d4a63183ca919b8', 'd83672a3e7415da1490334e2c9431e5da1966842']",
      "before_first_fix_commit": "{'9a5a09781e5a19ab9a24878afb08c9fcafb21ca7'}",
      "last_fix_commit": "d83672a3e7415da1490334e2c9431e5da1966842",
      "chain_ord_pos": 1.0,
      "commit_datetime": "03/03/2022, 07:25:01",
      "message": "vcs: Improve mercurial parameters handling\n\nMake sure that all user provided input is handled as expected.",
      "author": "Michal \u010ciha\u0159",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 4, 'total': 8}",
      "files": "{'weblate/vcs/mercurial.py': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https://github.com/WeblateOrg/weblate/raw/35d59f1f040541c358cece0a8d4a63183ca919b8/weblate%2Fvcs%2Fmercurial.py', 'patch': '@@ -70,7 +70,7 @@ def check_config(self):\\n     @classmethod\\n     def _clone(cls, source: str, target: str, branch: str):\\n         \"\"\"Clone repository.\"\"\"\\n-        cls._popen([\"clone\", \"--branch\", branch, source, target])\\n+        cls._popen([\"clone\", f\"--branch={branch}\", \"--\", source, target])\\n \\n     def get_config(self, path):\\n         \"\"\"Read entry from configuration.\"\"\"\\n@@ -323,7 +323,7 @@ def on_branch(self, branch):\\n     def configure_branch(self, branch):\\n         \"\"\"Configure repository branch.\"\"\"\\n         if not self.on_branch(branch):\\n-            self.execute([\"update\", branch])\\n+            self.execute([\"update\", \"--\", branch])\\n         self.branch = branch\\n \\n     def describe(self):\\n@@ -343,7 +343,7 @@ def describe(self):\\n     def push(self, branch):\\n         \"\"\"Push given branch to remote repository.\"\"\"\\n         try:\\n-            self.execute([\"push\", \"-b\", self.branch])\\n+            self.execute([\"push\", f\"--branch={self.branch}\"])\\n         except RepositoryException as error:\\n             if error.retcode == 1:\\n                 # No changes found\\n@@ -363,7 +363,7 @@ def cleanup(self):\\n \\n     def update_remote(self):\\n         \"\"\"Update remote repository.\"\"\"\\n-        self.execute([\"pull\", \"--branch\", self.branch])\\n+        self.execute([\"pull\", f\"--branch={self.branch}\"])\\n         self.clean_revision_cache()\\n \\n     def parse_changed_files(self, lines: List[str]) -> Iterator[str]:'}}",
      "message_norm": "vcs: improve mercurial parameters handling\n\nmake sure that all user provided input is handled as expected.",
      "language": "en",
      "entities": "[('improve', 'ACTION', ''), ('user provided input', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['weblate/vcs/mercurial.py'])",
      "num_files": 1.0
    },
    {
      "index": 63,
      "vuln_id": "GHSA-2877-693q-pj33",
      "cwe_id": "{'CWE-78'}",
      "score": 9.8,
      "chain": "{'https://github.com/genieacs/genieacs/commit/7f295beeecc1c1f14308a93c82413bb334045af6'}",
      "dataset": "osv",
      "summary": "OS Command Injection in GenieACS In GenieACS 1.2.x before 1.2.8, the UI interface API is vulnerable to unauthenticated OS command injection via the ping host argument (lib/ui/api.ts and lib/ping.ts). The vulnerability arises from insufficient input validation combined with a missing authorization check.",
      "published_date": "2022-03-07",
      "chain_len": 1,
      "project": "https://github.com/genieacs/genieacs",
      "commit_href": "https://github.com/genieacs/genieacs/commit/7f295beeecc1c1f14308a93c82413bb334045af6",
      "commit_sha": "7f295beeecc1c1f14308a93c82413bb334045af6",
      "patch": "SINGLE",
      "chain_ord": "['7f295beeecc1c1f14308a93c82413bb334045af6']",
      "before_first_fix_commit": "{'2ac536bf8f2dd03c24b2eff35b69578b4efae94e'}",
      "last_fix_commit": "7f295beeecc1c1f14308a93c82413bb334045af6",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/14/2021, 07:33:35",
      "message": "Validate host arg passed to ping\n\nFixes remote code execution vulnerability reported by Alex Hordijk.",
      "author": "Zaid Abdulla",
      "comments": null,
      "stats": "{'additions': 13, 'deletions': 0, 'total': 13}",
      "files": "{'lib/ping.ts': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/genieacs/genieacs/raw/7f295beeecc1c1f14308a93c82413bb334045af6/lib%2Fping.ts', 'patch': '@@ -19,6 +19,7 @@\\n \\n import { platform } from \"os\";\\n import { exec } from \"child_process\";\\n+import { domainToASCII } from \"url\";\\n \\n export interface PingResult {\\n   packetsTransmitted: number;\\n@@ -30,11 +31,23 @@ export interface PingResult {\\n   mdev: number;\\n }\\n \\n+function isValidHost(host: string): boolean {\\n+  // Valid chars in IPv4, IPv6, domain names\\n+  if (/^[a-zA-Z0-9\\\\-.:[\\\\]-]+$/.test(host)) return true;\\n+\\n+  // Check if input is an IDN convert to Punycode\\n+  // Can\\'t merge with above because domainToASCII doesn\\'t accept IP addresses\\n+  return /^[a-zA-Z0-9\\\\-.:[\\\\]-]+$/.test(domainToASCII(host));\\n+}\\n+\\n export function ping(\\n   host: string,\\n   callback: (err: Error, res?: PingResult, stdout?: string) => void\\n ): void {\\n   let cmd: string, parseRegExp1: RegExp, parseRegExp2: RegExp;\\n+  // Validate input to prevent possible remote code execution\\n+  // Credit to Alex Hordijk for reporting this vulnerability\\n+  if (!isValidHost(host)) return callback(new Error(\"Invalid host\"));\\n   host = host.replace(\"[\", \"\").replace(\"]\", \"\");\\n   switch (platform()) {\\n     case \"linux\":'}}",
      "message_norm": "validate host arg passed to ping\n\nfixes remote code execution vulnerability reported by alex hordijk.",
      "language": "en",
      "entities": "[('validate', 'ACTION', ''), ('fixes', 'ACTION', ''), ('remote code execution', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['lib/ping.ts'])",
      "num_files": 1.0
    },
    {
      "index": 2946,
      "vuln_id": "GHSA-rgvq-pcvf-hx75",
      "cwe_id": "{'CWE-131'}",
      "score": 5.3,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/f94ef358bb3e91d517446454edff6535bcfe8e4a', 'https://github.com/tensorflow/tensorflow/commit/c4d7afb6a5986b04505aca4466ae1951686c80f6', 'https://github.com/tensorflow/tensorflow/commit/b761c9b652af2107cfbc33efd19be0ce41daa33e'}",
      "dataset": "osv",
      "summary": "Heap OOB and null pointer dereference in `RaggedTensorToTensor` ### Impact\nDue to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty:\n\n```python\nimport tensorflow as tf\n\nshape = tf.constant([-1, -1], shape=[2], dtype=tf.int64)\nvalues = tf.constant([], shape=[0], dtype=tf.int64)\ndefault_value = tf.constant(404, dtype=tf.int64)\nrow = tf.constant([269, 404, 0, 0, 0, 0, 0], shape=[7], dtype=tf.int64)\nrows = [row]\ntypes = ['ROW_SPLITS']\n\ntf.raw_ops.RaggedTensorToTensor(\n  shape=shape, values=values, default_value=default_value, \n  row_partition_tensors=rows, row_partition_types=types)\n```\n\nThe [implementation](https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones.\n\nThere are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything.\n\n### Patches\nWe have patched the issue in GitHub commit [b761c9b652af2107cfbc33efd19be0ce41daa33e](https://github.com/tensorflow/tensorflow/commit/b761c9b652af2107cfbc33efd19be0ce41daa33e) followed by GitHub commit [f94ef358bb3e91d517446454edff6535bcfe8e4a](https://github.com/tensorflow/tensorflow/commit/f94ef358bb3e91d517446454edff6535bcfe8e4a) and GitHub commit [c4d7afb6a5986b04505aca4466ae1951686c80f6](https://github.com/tensorflow/tensorflow/commit/c4d7afb6a5986b04505aca4466ae1951686c80f6).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 3,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/b761c9b652af2107cfbc33efd19be0ce41daa33e",
      "commit_sha": "b761c9b652af2107cfbc33efd19be0ce41daa33e",
      "patch": "MULTI",
      "chain_ord": "['f94ef358bb3e91d517446454edff6535bcfe8e4a', 'b761c9b652af2107cfbc33efd19be0ce41daa33e', 'c4d7afb6a5986b04505aca4466ae1951686c80f6']",
      "before_first_fix_commit": "{'50034ad2d55b10eb9d4593374546710b12f134e1'}",
      "last_fix_commit": "c4d7afb6a5986b04505aca4466ae1951686c80f6",
      "chain_ord_pos": 2.0,
      "commit_datetime": "04/15/2021, 20:28:49",
      "message": "Fix `tf.raw_ops.RaggedTensorToTensor` failing CHECK.\n\nPiperOrigin-RevId: 368706628\nChange-Id: I5c9ea4833f38835ee183ca50d63251dc89c9f3bc",
      "author": "Amit Patankar",
      "comments": null,
      "stats": "{'additions': 11, 'deletions': 9, 'total': 20}",
      "files": "{'tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc': {'additions': 11, 'deletions': 9, 'changes': 20, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/b761c9b652af2107cfbc33efd19be0ce41daa33e/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_tensor_op.cc', 'patch': '@@ -208,7 +208,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n   }\\n \\n   void CalculateOutputIndexRowSplit(\\n-      const RowPartitionTensor& row_split,\\n+      OpKernelContext* context, const RowPartitionTensor& row_split,\\n       const vector<INDEX_TYPE>& parent_output_index,\\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\\n       vector<INDEX_TYPE>* result) {\\n@@ -233,7 +233,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n       }\\n     }\\n     if (row_split_size > 0) {\\n-      DCHECK_EQ(result->size(), row_split(row_split_size - 1));\\n+      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\\n+                  errors::InvalidArgument(\"Invalid row split size.\"));\\n     }\\n   }\\n \\n@@ -259,7 +260,7 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n   // result[7] = -1 because parent_output_index[value_rowids[6]] == -1\\n   // result[8] = parent_output_index[value_rowids[7]]\\n   void CalculateOutputIndexValueRowID(\\n-      const RowPartitionTensor& value_rowids,\\n+      OpKernelContext* context, const RowPartitionTensor& value_rowids,\\n       const vector<INDEX_TYPE>& parent_output_index,\\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\\n       vector<INDEX_TYPE>* result) {\\n@@ -293,7 +294,8 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n       }\\n       result->push_back(current_output_index);\\n     }\\n-    DCHECK_EQ(result->size(), value_rowids.size());\\n+    OP_REQUIRES(context, result->size() == value_rowids.size(),\\n+                errors::InvalidArgument(\"Invalid row ids.\"));\\n   }\\n \\n   Status CalculateOutputIndex(OpKernelContext* context, int dimension,\\n@@ -307,13 +309,13 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n     switch (partition_type) {\\n       case RowPartitionType::VALUE_ROWIDS:\\n         CalculateOutputIndexValueRowID(\\n-            row_partition_tensor, parent_output_index, output_index_multiplier,\\n-            output_size, result);\\n+            context, row_partition_tensor, parent_output_index,\\n+            output_index_multiplier, output_size, result);\\n         return tensorflow::Status::OK();\\n       case RowPartitionType::ROW_SPLITS:\\n-        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,\\n-                                     output_index_multiplier, output_size,\\n-                                     result);\\n+        CalculateOutputIndexRowSplit(\\n+            context, row_partition_tensor, parent_output_index,\\n+            output_index_multiplier, output_size, result);\\n         return tensorflow::Status::OK();\\n       default:\\n         return errors::InvalidArgument('}}",
      "message_norm": "fix `tf.raw_ops.raggedtensortotensor` failing check.\n\npiperorigin-revid: 368706628\nchange-id: i5c9ea4833f38835ee183ca50d63251dc89c9f3bc",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('368706628', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 3151,
      "vuln_id": "GHSA-vp56-6g26-6827",
      "cwe_id": "{'CWE-400'}",
      "score": 5.9,
      "chain": "{'https://github.com/node-fetch/node-fetch/commit/28802387292baee467e042e168d92597b5bbbe3d'}",
      "dataset": "osv",
      "summary": "node-fetch Inefficient Regular Expression Complexity  [node-fetch](https://www.npmjs.com/package/node-fetch) is a light-weight module that brings window.fetch to node.js.\n\nAffected versions of this package are vulnerable to Regular Expression Denial of Service (ReDoS) in the `isOriginPotentiallyTrustworthy()` function in `referrer.js`, when processing a URL string with alternating letters and periods, such as `'http://' + 'a.a.'.repeat(i) + 'a'`.",
      "published_date": "2022-08-02",
      "chain_len": 1,
      "project": "https://github.com/node-fetch/node-fetch",
      "commit_href": "https://github.com/node-fetch/node-fetch/commit/28802387292baee467e042e168d92597b5bbbe3d",
      "commit_sha": "28802387292baee467e042e168d92597b5bbbe3d",
      "patch": "SINGLE",
      "chain_ord": "['28802387292baee467e042e168d92597b5bbbe3d']",
      "before_first_fix_commit": "{'e87b093fd678a9ea39c5b17b2a1bdfc4691eedc7'}",
      "last_fix_commit": "28802387292baee467e042e168d92597b5bbbe3d",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/31/2022, 08:01:29",
      "message": "fix: ReDoS referrer (#1611)\n\n* fix ReDoS referrer\r\n\r\n* Update src/utils/referrer.js\r\n\r\nEliminate regex and use string matcher\r\n\r\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>\r\n\r\nCo-authored-by: Khang. V\u00f5 V\u0129 <khangvv@vng.com.vn>\r\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>",
      "author": "Khang Vo (doublevkay)",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'src/utils/referrer.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/node-fetch/node-fetch/raw/28802387292baee467e042e168d92597b5bbbe3d/src%2Futils%2Freferrer.js', 'patch': '@@ -119,7 +119,7 @@ export function isOriginPotentiallyTrustworthy(url) {\\n \\t// 5. If origin\\'s host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\\n \\t// We are returning FALSE here because we cannot ensure conformance to\\n \\t// let-localhost-be-loalhost (https://tools.ietf.org/html/draft-west-let-localhost-be-localhost)\\n-\\tif (/^(.+\\\\.)*localhost$/.test(url.host)) {\\n+\\tif (url.host === \\'localhost\\' || url.host.endsWith(\\'.localhost\\')) {\\n \\t\\treturn false;\\n \\t}'}}",
      "message_norm": "fix: redos referrer (#1611)\n\n* fix redos referrer\r\n\r\n* update src/utils/referrer.js\r\n\r\neliminate regex and use string matcher\r\n\r\nco-authored-by: linus unneb\u00e4ck <linus@folkdatorn.se>\r\n\r\nco-authored-by: khang. v\u00f5 v\u0129 <khangvv@vng.com.vn>\r\nco-authored-by: linus unneb\u00e4ck <linus@folkdatorn.se>",
      "language": "en",
      "entities": "[('redos', 'SECWORD', ''), ('#1611', 'ISSUE', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('linus@folkdatorn.se', 'EMAIL', ''), ('linus@folkdatorn.se', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['src/utils/referrer.js'])",
      "num_files": 1.0
    },
    {
      "index": 826,
      "vuln_id": "GHSA-6fvx-r7hx-3vh6",
      "cwe_id": "{'CWE-611'}",
      "score": 9.8,
      "chain": "{'https://github.com/javamelody/javamelody/commit/ef111822562d0b9365bd3e671a75b65bd0613353'}",
      "dataset": "osv",
      "summary": "JavaMelody has XXE via parseSoapMethodName in bull/javamelody/PayloadNameRequestWrapper.java. JavaMelody before 1.74.0 has XXE via parseSoapMethodName in bull/javamelody/PayloadNameRequestWrapper.java.",
      "published_date": "2018-10-17",
      "chain_len": 1,
      "project": "https://github.com/javamelody/javamelody",
      "commit_href": "https://github.com/javamelody/javamelody/commit/ef111822562d0b9365bd3e671a75b65bd0613353",
      "commit_sha": "ef111822562d0b9365bd3e671a75b65bd0613353",
      "patch": "SINGLE",
      "chain_ord": "['ef111822562d0b9365bd3e671a75b65bd0613353']",
      "before_first_fix_commit": "{'00dd8d51a6483cb3a5b4c8ae9c24197028401c58'}",
      "last_fix_commit": "ef111822562d0b9365bd3e671a75b65bd0613353",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/04/2018, 06:31:29",
      "message": "fix for security",
      "author": "evernat",
      "comments": "{'com_1': {'author': 'abergmann', 'datetime': '10/12/2018, 08:21:37', 'body': '[CVE-2018-15531](https://nvd.nist.gov/vuln/detail/CVE-2018-15531) was assigned to this issue.'}}",
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'javamelody-core/src/main/java/net/bull/javamelody/PayloadNameRequestWrapper.java': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/javamelody/javamelody/raw/ef111822562d0b9365bd3e671a75b65bd0613353/javamelody-core%2Fsrc%2Fmain%2Fjava%2Fnet%2Fbull%2Fjavamelody%2FPayloadNameRequestWrapper.java', 'patch': '@@ -235,6 +235,8 @@ private static String parseSoapMethodName(InputStream stream, String charEncodin\\n \\t\\ttry {\\r\\n \\t\\t\\t// newInstance() et pas newFactory() pour java 1.5 (issue 367)\\r\\n \\t\\t\\tfinal XMLInputFactory factory = XMLInputFactory.newInstance();\\r\\n+\\t\\t\\tfactory.setProperty(XMLInputFactory.SUPPORT_DTD, false); // disable DTDs entirely for that factory\\r\\n+\\t\\t\\tfactory.setProperty(XMLInputFactory.IS_SUPPORTING_EXTERNAL_ENTITIES, false); // disable external entities\\r\\n \\t\\t\\tfinal XMLStreamReader xmlReader;\\r\\n \\t\\t\\tif (charEncoding != null) {\\r\\n \\t\\t\\t\\txmlReader = factory.createXMLStreamReader(stream, charEncoding);'}}",
      "message_norm": "fix for security",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('security', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['javamelody-core/src/main/java/net/bull/javamelody/PayloadNameRequestWrapper.java'])",
      "num_files": 1.0
    },
    {
      "index": 2630,
      "vuln_id": "GHSA-pr38-qpxm-g88x",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/apache/activemq-artemis/pull/3871/commits/153d2e9a979aead8dff95fbc91d659ecc7d0fb82', 'https://github.com/apache/activemq-artemis/pull/3862/commits/1f92368240229b8f5db92a92a72c703faf83e9b7'}",
      "dataset": "osv",
      "summary": "Uncontrolled Resource Consumption in Apache ActiveMQ Artemis In Apache ActiveMQ Artemis prior to 2.20.0 or 2.19.1, an attacker could partially disrupt availability (DoS) through uncontrolled resource consumption of memory.",
      "published_date": "2022-02-06",
      "chain_len": 2,
      "project": "https://github.com/apache/activemq-artemis",
      "commit_href": "https://github.com/apache/activemq-artemis/pull/3862/commits/1f92368240229b8f5db92a92a72c703faf83e9b7",
      "commit_sha": "1f92368240229b8f5db92a92a72c703faf83e9b7",
      "patch": "MULTI",
      "chain_ord": "['1f92368240229b8f5db92a92a72c703faf83e9b7', '153d2e9a979aead8dff95fbc91d659ecc7d0fb82']",
      "before_first_fix_commit": "{'4196faf7ce56cb3676d46acb3b0684b5cdf804d7'}",
      "last_fix_commit": "153d2e9a979aead8dff95fbc91d659ecc7d0fb82",
      "chain_ord_pos": 1.0,
      "commit_datetime": "11/19/2021, 12:02:45",
      "message": "Be defensive when reading data from `ActiveMQBuffer` and allocating memory.\n\nOr else, an adversary may handcraft the packet causing OOM situation for a running a JVM.",
      "author": "Viktor Kolomeyko",
      "comments": null,
      "stats": "{'additions': 16, 'deletions': 4, 'total': 20}",
      "files": "{'artemis-core-client/src/main/java/org/apache/activemq/artemis/utils/XidCodecSupport.java': {'additions': 16, 'deletions': 4, 'changes': 20, 'status': 'modified', 'raw_url': 'https://github.com/apache/activemq-artemis/raw/1f92368240229b8f5db92a92a72c703faf83e9b7/artemis-core-client%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Factivemq%2Fartemis%2Futils%2FXidCodecSupport.java', 'patch': '@@ -32,12 +32,24 @@ public static void encodeXid(final Xid xid, final ActiveMQBuffer out) {\\n       out.writeBytes(xid.getGlobalTransactionId());\\n    }\\n \\n+   private static byte[] safeReadBytes(final ActiveMQBuffer in) {\\n+      int claimedSize = in.readInt();\\n+      int bufferCapacity = in.capacity();\\n+      // We have to be defensive here and not try to allocate byte buffer straight from information available in the\\n+      // stream. Or else, an adversary may handcraft the packet causing OOM situation for a running JVM.\\n+      if (claimedSize > bufferCapacity) {\\n+         throw new IllegalStateException(\"Buffer size: \" + claimedSize +\\n+                 \" exceeds overall buffer size of: \" + bufferCapacity);\\n+      }\\n+      byte[] byteBuffer = new byte[claimedSize];\\n+      in.readBytes(byteBuffer);\\n+      return byteBuffer;\\n+   }\\n+\\n    public static Xid decodeXid(final ActiveMQBuffer in) {\\n       int formatID = in.readInt();\\n-      byte[] bq = new byte[in.readInt()];\\n-      in.readBytes(bq);\\n-      byte[] gtxid = new byte[in.readInt()];\\n-      in.readBytes(gtxid);\\n+      byte[] bq = safeReadBytes(in);\\n+      byte[] gtxid = safeReadBytes(in);\\n       return new XidImpl(bq, formatID, gtxid);\\n    }'}}",
      "message_norm": "be defensive when reading data from `activemqbuffer` and allocating memory.\n\nor else, an adversary may handcraft the packet causing oom situation for a running a jvm.",
      "language": "en",
      "entities": null,
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['artemis-core-client/src/main/java/org/apache/activemq/artemis/utils/XidCodecSupport.java'])",
      "num_files": 1.0
    },
    {
      "index": 2545,
      "vuln_id": "GHSA-p9pc-299p-vxgp",
      "cwe_id": "{'CWE-915'}",
      "score": 5.3,
      "chain": "{'https://github.com/yargs/yargs-parser/commit/63810ca1ae1a24b08293a4d971e70e058c7a41e2', 'https://github.com/yargs/yargs-parser/commit/1c417bd0b42b09c475ee881e36d292af4fa2cc36'}",
      "dataset": "osv",
      "summary": "yargs-parser Vulnerable to Prototype Pollution Affected versions of `yargs-parser` are vulnerable to prototype pollution. Arguments are not properly sanitized, allowing an attacker to modify the prototype of `Object`, causing the addition or modification of an existing property that will exist on all objects.  \nParsing the argument `--foo.__proto__.bar baz'` adds a `bar` property with value `baz` to all objects. This is only exploitable if attackers have control over the arguments being passed to `yargs-parser`.\n\n\n\n## Recommendation\n\nUpgrade to versions 13.1.2, 15.0.1, 18.1.1 or later.",
      "published_date": "2020-09-04",
      "chain_len": 2,
      "project": "https://github.com/yargs/yargs-parser",
      "commit_href": "https://github.com/yargs/yargs-parser/commit/1c417bd0b42b09c475ee881e36d292af4fa2cc36",
      "commit_sha": "1c417bd0b42b09c475ee881e36d292af4fa2cc36",
      "patch": "MULTI",
      "chain_ord": "['63810ca1ae1a24b08293a4d971e70e058c7a41e2', '1c417bd0b42b09c475ee881e36d292af4fa2cc36']",
      "before_first_fix_commit": "{'e93a345e1e585ba5df97c1da438673e7f2e8909b'}",
      "last_fix_commit": "1c417bd0b42b09c475ee881e36d292af4fa2cc36",
      "chain_ord_pos": 2.0,
      "commit_datetime": "03/10/2021, 19:14:27",
      "message": "fix(security): address GHSA-p9pc-299p-vxgp (#362)\n\nUpdate release automation to allow for back ports.",
      "author": "Benjamin E. Coe",
      "comments": "{'com_1': {'author': 'kennethalegre19', 'datetime': '10/19/2021, 05:07:29', 'body': '`.github/workflows/release-please.yml'}}",
      "stats": "{'additions': 15, 'deletions': 0, 'total': 15}",
      "files": "{'.github/workflows/release-please.yml': {'additions': 15, 'deletions': 0, 'changes': 15, 'status': 'added', 'raw_url': 'https://github.com/yargs/yargs-parser/raw/1c417bd0b42b09c475ee881e36d292af4fa2cc36/.github%2Fworkflows%2Frelease-please.yml', 'patch': '@@ -0,0 +1,15 @@\\n+on:\\n+   push:\\n+     branches:\\n+       - v5.x.x\\n+name: release-please\\n+jobs:\\n+  release-please:\\n+    runs-on: ubuntu-latest\\n+    steps:\\n+      - uses: google-github-actions/release-please-action@v2\\n+        with:\\n+          token: ${{ secrets.GITHUB_TOKEN }}\\n+          release-type: node\\n+          package-name: yargs-parser\\n+          default-branch: v5.x.x'}}",
      "message_norm": "fix(security): address ghsa-p9pc-299p-vxgp (#362)\n\nupdate release automation to allow for back ports.",
      "language": "en",
      "entities": "[('fix(security', 'SECWORD', ''), ('ghsa-p9pc-299p-vxgp', 'VULNID', 'GHSA'), ('#362', 'ISSUE', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['.github/workflows/release-please.yml'])",
      "num_files": 1.0
    },
    {
      "index": 2089,
      "vuln_id": "GHSA-hm37-9xh2-q499",
      "cwe_id": "{'CWE-209'}",
      "score": 7.7,
      "chain": "{'https://github.com/scottcwang/openssh_key_parser/commit/d5b53b4b7e76c5b666fc657019dbf864fb04076c', 'https://github.com/scottcwang/openssh_key_parser/commit/26e0a471e9fdb23e635bc3014cf4cbd2323a08d3', 'https://github.com/scottcwang/openssh_key_parser/commit/274447f91b4037b7050ae634879b657554523b39'}",
      "dataset": "osv",
      "summary": "Possible leak of key's raw field if declared length is incorrect ### Impact\nIf a field of a key is shorter than it is declared to be, the parser raises an error with a message containing the raw field value. An attacker able to modify the declared length of a key's sensitive field can thus expose the raw value of that field.\n\n### Patches\nUpgrade to version 0.0.6, which no longer includes the raw field value in the error message.\n\n### Workarounds\nN/A\n\n### References\nN/A\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [openssh_key_parser](https://github.com/scottcwang/openssh_key_parser)",
      "published_date": "2022-07-06",
      "chain_len": 3,
      "project": "https://github.com/scottcwang/openssh_key_parser",
      "commit_href": "https://github.com/scottcwang/openssh_key_parser/commit/d5b53b4b7e76c5b666fc657019dbf864fb04076c",
      "commit_sha": "d5b53b4b7e76c5b666fc657019dbf864fb04076c",
      "patch": "MULTI",
      "chain_ord": "['26e0a471e9fdb23e635bc3014cf4cbd2323a08d3', 'd5b53b4b7e76c5b666fc657019dbf864fb04076c', '274447f91b4037b7050ae634879b657554523b39']",
      "before_first_fix_commit": "{'ae4d131d1cd8fe06325bfd6b749305aca60873bf', '69fe5b7addc21d3f39626ae93c6961811aea9d4c'}",
      "last_fix_commit": "274447f91b4037b7050ae634879b657554523b39",
      "chain_ord_pos": 2.0,
      "commit_datetime": "06/22/2022, 14:59:49",
      "message": "Improved error handling to prevent unhandled exceptions in calling code.",
      "author": "Michael Doyle",
      "comments": null,
      "stats": "{'additions': 95, 'deletions': 86, 'total': 181}",
      "files": "{'openssh_key/private_key_list.py': {'additions': 95, 'deletions': 86, 'changes': 181, 'status': 'modified', 'raw_url': 'https://github.com/scottcwang/openssh_key_parser/raw/d5b53b4b7e76c5b666fc657019dbf864fb04076c/openssh_key%2Fprivate_key_list.py', 'patch': '@@ -221,118 +221,127 @@ def from_bytes(\\n \\n         Raises:\\n             ValueError: The provided byte string is not an ``openssh-key-v1``\\n-                key list or the declared key count is negative.\\n+                key list, when the declared key count is negative, or when an\\n+                EOF is found while parsing the key.\\n+\\n             UserWarning: The check numbers in the decrypted private byte string\\n                 do not match (likely due to an incorrect passphrase), the key\\n                 type or parameter values of a private key do not match that of\\n                 the corresponding public key in the list, or the padding bytes\\n                 at the end of the decrypted private byte string are not as\\n                 expected.\\n         \"\"\"\\n-        byte_stream = PascalStyleByteStream(byte_string)\\n+        try:\\n+            byte_stream = PascalStyleByteStream(byte_string)\\n \\n-        header = byte_stream.read_from_format_instructions_dict(\\n-            cls.HEADER_FORMAT_INSTRUCTIONS_DICT\\n-        )\\n+            header = byte_stream.read_from_format_instructions_dict(\\n+                cls.HEADER_FORMAT_INSTRUCTIONS_DICT\\n+            )\\n+\\n+            if header[\\'auth_magic\\'] != b\\'openssh-key-v1\\\\x00\\':\\n+                raise ValueError(\\'Not an openssh-key-v1 key\\')\\n \\n-        if header[\\'auth_magic\\'] != b\\'openssh-key-v1\\\\x00\\':\\n-            raise ValueError(\\'Not an openssh-key-v1 key\\')\\n+            num_keys = header[\\'num_keys\\']\\n \\n-        num_keys = header[\\'num_keys\\']\\n+            if num_keys < 0:\\n+                raise ValueError(\\'Cannot parse negative number of keys\\')\\n \\n-        if num_keys < 0:\\n-            raise ValueError(\\'Cannot parse negative number of keys\\')\\n+            public_key_list = []\\n+            for i in range(num_keys):\\n+                public_key_bytes = byte_stream.read_from_format_instruction(\\n+                    PascalStyleFormatInstruction.BYTES\\n+                )\\n+                public_key_list.append(\\n+                    PublicKey.from_bytes(public_key_bytes)\\n+                )\\n \\n-        public_key_list = []\\n-        for i in range(num_keys):\\n-            public_key_bytes = byte_stream.read_from_format_instruction(\\n+            cipher_bytes = byte_stream.read_from_format_instruction(\\n                 PascalStyleFormatInstruction.BYTES\\n             )\\n-            public_key_list.append(\\n-                PublicKey.from_bytes(public_key_bytes)\\n-            )\\n \\n-        cipher_bytes = byte_stream.read_from_format_instruction(\\n-            PascalStyleFormatInstruction.BYTES\\n-        )\\n-\\n-        kdf_class = get_kdf_options_class(header[\\'kdf\\'])\\n-        kdf_options = kdf_class(\\n-            PascalStyleByteStream(\\n-                header[\\'kdf_options\\']\\n-            ).read_from_format_instructions_dict(\\n-                kdf_class.FORMAT_INSTRUCTIONS_DICT\\n+            kdf_class = get_kdf_options_class(header[\\'kdf\\'])\\n+            kdf_options = kdf_class(\\n+                PascalStyleByteStream(\\n+                    header[\\'kdf_options\\']\\n+                ).read_from_format_instructions_dict(\\n+                    kdf_class.FORMAT_INSTRUCTIONS_DICT\\n+                )\\n             )\\n-        )\\n \\n-        cipher_class = get_cipher_class(header[\\'cipher\\'])\\n+            cipher_class = get_cipher_class(header[\\'cipher\\'])\\n \\n-        if kdf_class == NoneKDFOptions:\\n-            passphrase = \\'\\'\\n-        elif passphrase is None:\\n-            passphrase = getpass.getpass(\\'Key passphrase: \\')\\n+            if kdf_class == NoneKDFOptions:\\n+                passphrase = \\'\\'\\n+            elif passphrase is None:\\n+                passphrase = getpass.getpass(\\'Key passphrase: \\')\\n \\n-        if issubclass(cipher_class, ConfidentialityIntegrityCipher):\\n-            cipher_bytes += byte_stream.read_fixed_bytes(\\n-                cipher_class.TAG_LENGTH\\n-            )\\n-\\n-        decipher_bytes = cipher_class.decrypt(\\n-            kdf_class(kdf_options),\\n-            passphrase,\\n-            cipher_bytes\\n-        )\\n-\\n-        decipher_byte_stream = PascalStyleByteStream(decipher_bytes)\\n+            if issubclass(cipher_class, ConfidentialityIntegrityCipher):\\n+                cipher_bytes += byte_stream.read_fixed_bytes(\\n+                    cipher_class.TAG_LENGTH\\n+                )\\n \\n-        decipher_bytes_header = \\\\\\n-            decipher_byte_stream.read_from_format_instructions_dict(\\n-                cls.DECIPHER_BYTES_HEADER_FORMAT_INSTRUCTIONS_DICT\\n+            decipher_bytes = cipher_class.decrypt(\\n+                kdf_class(kdf_options),\\n+                passphrase,\\n+                cipher_bytes\\n             )\\n \\n-        if decipher_bytes_header[\\'check_int_1\\'] \\\\\\n-                != decipher_bytes_header[\\'check_int_2\\']:\\n-            warnings.warn(\\'Cipher header check numbers do not match\\')\\n+            decipher_byte_stream = PascalStyleByteStream(decipher_bytes)\\n \\n-        initlist = []\\n-        for i in range(num_keys):\\n-            initlist.append(\\n-                PublicPrivateKeyPair(\\n-                    public_key_list[i],\\n-                    PrivateKey.from_byte_stream(decipher_byte_stream)\\n-                )\\n-            )\\n-            if initlist[i].public.header[\\'key_type\\'] \\\\\\n-                    != initlist[i].private.header[\\'key_type\\']:\\n-                warnings.warn(\\n-                    f\\'Inconsistency between private and public \\'\\n-                    f\\'key types for key {i}\\'\\n+            decipher_bytes_header = \\\\\\n+                decipher_byte_stream.read_from_format_instructions_dict(\\n+                    cls.DECIPHER_BYTES_HEADER_FORMAT_INSTRUCTIONS_DICT\\n                 )\\n-            if not all(\\n-                (\\n-                    initlist[i].public.params[k] ==\\n-                    initlist[i].private.params[k]\\n-                ) for k in (\\n-                    initlist[i].public.params.keys() &\\n-                    initlist[i].private.params.keys()\\n+\\n+            if decipher_bytes_header[\\'check_int_1\\'] \\\\\\n+                    != decipher_bytes_header[\\'check_int_2\\']:\\n+                warnings.warn(\\'Cipher header check numbers do not match\\')\\n+\\n+            initlist = []\\n+            for i in range(num_keys):\\n+                initlist.append(\\n+                    PublicPrivateKeyPair(\\n+                        public_key_list[i],\\n+                        PrivateKey.from_byte_stream(decipher_byte_stream)\\n+                    )\\n                 )\\n+                if initlist[i].public.header[\\'key_type\\'] \\\\\\n+                        != initlist[i].private.header[\\'key_type\\']:\\n+                    warnings.warn(\\n+                        f\\'Inconsistency between private and public \\'\\n+                        f\\'key types for key {i}\\'\\n+                    )\\n+                if not all(\\n+                    (\\n+                        initlist[i].public.params[k] ==\\n+                        initlist[i].private.params[k]\\n+                    ) for k in (\\n+                        initlist[i].public.params.keys() &\\n+                        initlist[i].private.params.keys()\\n+                    )\\n+                ):\\n+                    warnings.warn(\\n+                        f\\'Inconsistency between private and public \\'\\n+                        f\\'values for key {i}\\'\\n+                    )\\n+\\n+            decipher_padding = decipher_byte_stream.read()\\n+\\n+            if (\\n+                len(decipher_byte_stream.getvalue()) %\\n+                    cipher_class.BLOCK_SIZE != 0\\n+            ) or not (\\n+                bytes(\\n+                    range(1, 1 + cipher_class.BLOCK_SIZE)\\n+                ).startswith(decipher_padding)\\n             ):\\n-                warnings.warn(\\n-                    f\\'Inconsistency between private and public \\'\\n-                    f\\'values for key {i}\\'\\n-                )\\n-\\n-        decipher_padding = decipher_byte_stream.read()\\n-\\n-        if (\\n-            len(decipher_byte_stream.getvalue()) %\\n-                cipher_class.BLOCK_SIZE != 0\\n-        ) or not (\\n-            bytes(\\n-                range(1, 1 + cipher_class.BLOCK_SIZE)\\n-            ).startswith(decipher_padding)\\n-        ):\\n-            warnings.warn(\\'Incorrect padding at end of ciphertext\\')\\n+                warnings.warn(\\'Incorrect padding at end of ciphertext\\')\\n+        except ValueError as e:\\n+            raise e\\n+        except EOFError as e:\\n+            raise ValueError(\\'Premature EOF detected while parsing key.\\')\\n+        except e:\\n+            raise ValueError(\\'Unexpected error condition reached.\\')\\n \\n         return cls(\\n             initlist,'}}",
      "message_norm": "improved error handling to prevent unhandled exceptions in calling code.",
      "language": "en",
      "entities": "[('improved', 'ACTION', ''), ('error handling', 'SECWORD', ''), ('prevent', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['openssh_key/private_key_list.py'])",
      "num_files": 1.0
    },
    {
      "index": 1739,
      "vuln_id": "GHSA-fj7c-vg2v-ccrm",
      "cwe_id": "{'CWE-400'}",
      "score": 0.0,
      "chain": "{'https://github.com/undertow-io/undertow/commit/c7e84a0b7efced38506d7d1dfea5902366973877'}",
      "dataset": "osv",
      "summary": "Undertow vulnerable to memory exhaustion due to buffer leak Buffer leak on incoming WebSocket PONG message(s) in Undertow before 2.0.40 and 2.2.10 can lead to memory exhaustion and allow a denial of service.",
      "published_date": "2022-07-15",
      "chain_len": 1,
      "project": "https://github.com/undertow-io/undertow",
      "commit_href": "https://github.com/undertow-io/undertow/commit/c7e84a0b7efced38506d7d1dfea5902366973877",
      "commit_sha": "c7e84a0b7efced38506d7d1dfea5902366973877",
      "patch": "SINGLE",
      "chain_ord": "['c7e84a0b7efced38506d7d1dfea5902366973877']",
      "before_first_fix_commit": "{'87f31ddaac835e3b41db339c1841760a1bac004f'}",
      "last_fix_commit": "c7e84a0b7efced38506d7d1dfea5902366973877",
      "chain_ord_pos": 1.0,
      "commit_datetime": "07/30/2021, 21:26:57",
      "message": "[UNDERTOW-1935] - buffer leak on incoming websocket PONG message",
      "author": "Andrey Marinchuk",
      "comments": null,
      "stats": "{'additions': 2, 'deletions': 0, 'total': 2}",
      "files": "{'websockets-jsr/src/main/java/io/undertow/websockets/jsr/FrameHandler.java': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/undertow-io/undertow/raw/c7e84a0b7efced38506d7d1dfea5902366973877/websockets-jsr%2Fsrc%2Fmain%2Fjava%2Fio%2Fundertow%2Fwebsockets%2Fjsr%2FFrameHandler.java', 'patch': '@@ -152,6 +152,8 @@ public void run() {\\n                     }\\n                 }\\n             });\\n+        } else {\\n+            bufferedBinaryMessage.getData().free();\\n         }\\n     }'}}",
      "message_norm": "[undertow-1935] - buffer leak on incoming websocket pong message",
      "language": "en",
      "entities": "[('leak', 'SECWORD', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['websockets-jsr/src/main/java/io/undertow/websockets/jsr/FrameHandler.java'])",
      "num_files": 1.0
    },
    {
      "index": 2511,
      "vuln_id": "GHSA-p55x-7x9v-q8m4",
      "cwe_id": "{'CWE-400'}",
      "score": 7.5,
      "chain": "{'https://github.com/miekg/dns/commit/43913f2f4fbd7dcff930b8a809e709591e4dd79e'}",
      "dataset": "osv",
      "summary": "Denial of Service in miekg-dns A denial of service flaw was found in miekg-dns before 1.0.4. A remote attacker could use carefully timed TCP packets to block the DNS server from accepting new connections.",
      "published_date": "2021-06-29",
      "chain_len": 1,
      "project": "https://github.com/miekg/dns",
      "commit_href": "https://github.com/miekg/dns/commit/43913f2f4fbd7dcff930b8a809e709591e4dd79e",
      "commit_sha": "43913f2f4fbd7dcff930b8a809e709591e4dd79e",
      "patch": "SINGLE",
      "chain_ord": "['43913f2f4fbd7dcff930b8a809e709591e4dd79e']",
      "before_first_fix_commit": "{'862243b3b1e77ca9f73771fc95a7148d11cebb55'}",
      "last_fix_commit": "43913f2f4fbd7dcff930b8a809e709591e4dd79e",
      "chain_ord_pos": 1.0,
      "commit_datetime": "01/25/2018, 10:36:19",
      "message": "Fix for CVE-2017-15133 TCP DOS (#631)\n\nserveTCP calls reader.ReadTCP in the accept loop rather than in\r\nthe per-connection goroutine. If an attacker opens a connection\r\nand leaves it idle, this will block the accept loop until the\r\nconnection times out (2s by default). During this time no other\r\nincoming connections will succeed, preventing legitimate queries\r\nfrom being answered.\r\n\r\nThis commit moves the call to reader.ReadTCP into the per-connection\r\ngoroutine. It also adds a missing call to Close whose absence allowed\r\nfile-descirptors to leak in select cases.\r\n\r\nThis attack and fix have no impact on serving UDP queries.",
      "author": "Miek Gieben",
      "comments": null,
      "stats": "{'additions': 8, 'deletions': 5, 'total': 13}",
      "files": "{'server.go': {'additions': 8, 'deletions': 5, 'changes': 13, 'status': 'modified', 'raw_url': 'https://github.com/miekg/dns/raw/43913f2f4fbd7dcff930b8a809e709591e4dd79e/server.go', 'patch': '@@ -472,11 +472,14 @@ func (srv *Server) serveTCP(l net.Listener) error {\\n \\t\\t\\t}\\n \\t\\t\\treturn err\\n \\t\\t}\\n-\\t\\tm, err := reader.ReadTCP(rw, rtimeout)\\n-\\t\\tif err != nil {\\n-\\t\\t\\tcontinue\\n-\\t\\t}\\n-\\t\\tgo srv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\\n+\\t\\tgo func() {\\n+\\t\\t\\tm, err := reader.ReadTCP(rw, rtimeout)\\n+\\t\\t\\tif err != nil {\\n+\\t\\t\\t\\trw.Close()\\n+\\t\\t\\t\\treturn\\n+\\t\\t\\t}\\n+\\t\\t\\tsrv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\\n+\\t\\t}()\\n \\t}\\n }'}}",
      "message_norm": "fix for cve-2017-15133 tcp dos (#631)\n\nservetcp calls reader.readtcp in the accept loop rather than in\r\nthe per-connection goroutine. if an attacker opens a connection\r\nand leaves it idle, this will block the accept loop until the\r\nconnection times out (2s by default). during this time no other\r\nincoming connections will succeed, preventing legitimate queries\r\nfrom being answered.\r\n\r\nthis commit moves the call to reader.readtcp into the per-connection\r\ngoroutine. it also adds a missing call to close whose absence allowed\r\nfile-descirptors to leak in select cases.\r\n\r\nthis attack and fix have no impact on serving udp queries.",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('cve-2017-15133', 'VULNID', 'CVE'), ('dos', 'SECWORD', ''), ('#631', 'ISSUE', ''), ('attacker', 'SECWORD', ''), ('preventing', 'ACTION', ''), ('adds', 'ACTION', ''), ('leak', 'SECWORD', ''), ('attack', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['server.go'])",
      "num_files": 1.0
    },
    {
      "index": 3137,
      "vuln_id": "GHSA-vjxv-45g9-9296",
      "cwe_id": "{'CWE-347'}",
      "score": 7.1,
      "chain": "{'https://github.com/sigstore/cosign/commit/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94'}",
      "dataset": "osv",
      "summary": "cosign's `cosign verify-attestaton  --type` can report a false positive if any attestation exists `cosign verify-attestation` used with the `--type` flag will report a false positive verification when:\n\n- There is at least one attestation with a valid signature\n- There are NO attestations of the type being verified (--type defaults to \"custom\")\n\nThis can happen when signing with a standard keypair and with \"keyless\" signing with Fulcio. Users should upgrade to cosign version 1.10.1 or greater for a patch. Currently the only workaround is to upgrade.",
      "published_date": "2022-08-10",
      "chain_len": 1,
      "project": "https://github.com/sigstore/cosign",
      "commit_href": "https://github.com/sigstore/cosign/commit/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
      "commit_sha": "c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
      "patch": "SINGLE",
      "chain_ord": "['c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94']",
      "before_first_fix_commit": "{'641f02b146816da54f112e1c1227747da17e5020'}",
      "last_fix_commit": "c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94",
      "chain_ord_pos": 1.0,
      "commit_datetime": "08/04/2022, 16:05:27",
      "message": "Merge pull request from GHSA-vjxv-45g9-9296\n\nToday the verification logic:\n1. Verifies signatures on attestations (at least one must verify, or it errors),\n2. All attestations matching the specified `--type` must pass any specified Cue/Rego policies,\n3. *All* signature-verified attestations are then printed.\n\nHowever, if NONE of the attestations match the specified `--type` then `2.` is considered satisfied and we proceed to `3.`\n\nThis changes the above logic to:\n1. Same.\n2. Same, but these are put into a `checked` list,\n3. `checked` must be non-empty (or an error is printed about no attestations matching `--type`),\n4. *Just* the `checked` attestations are printed.\n\n---\n\nThe bug at HEAD:\n```shell\n$ cosign verify-attestation --type spdx ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nVerification for ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - Any certificates were verified against the Fulcio roots.\nCertificate subject:  https://github.com/distroless/static/.github/workflows/release.yaml@refs/heads/main\nCertificate issuer URL:  https://token.actions.githubusercontent.com\nCertificate extension GitHub Workflow Trigger: schedule\nCertificate extension GitHub Workflow SHA: 7e7572e578de7c51a2f1a1791f025cf315503aa2\nCertificate extension GitHub Workflow Name: Create Release\nCertificate extension GitHub Workflow Trigger distroless/static\nCertificate extension GitHub Workflow Ref: refs/heads/main\n{\"payloadType\":\"application/vnd.in-toto+json\",\"payload\":\"eyJfdHlwZSI6Imh0dHBzOi8vaW4tdG90by5pby9TdGF0ZW1lbnQvdjAuMSIsInByZWRpY2F0ZVR5cGUiOiJjb3NpZ24uc2lnc3RvcmUuZGV2L2F0dGVzdGF0aW9uL3Z1bG4vdjEiLCJzdWJqZWN0IjpbeyJuYW1lIjoiZ2hjci5pby9kaXN0cm9sZXNzL3N0YXRpYyIsImRpZ2VzdCI6eyJzaGEyNTYiOiJkZDc2MTRiNWExMmJjNGQ2MTdiMjIzYzU4OGI0ZTBjODMzNDAyYjhmNDk5MWZiNTcwMmVhODNhZmFkMTk4NmUyIn19XSwicHJlZGljYXRlIjp7Imludm9jYXRpb24iOnsicGFyYW1ldGVycyI6bnVsbCwidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2Rpc3Ryb2xlc3Mvc3RhdGljL2FjdGlvbnMvcnVucy8yNzc5MjEyNzA1IiwiZXZlbnRfaWQiOiIyNzc5MjEyNzA1IiwiYnVpbGRlci5pZCI6IkNyZWF0ZSBSZWxlYXNlIn0sInNjYW5uZXIiOnsidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2FxdWFzZWN1cml0eS90cml2eSIsInZlcnNpb24iOiIwLjI5LjIiLCJkYiI6eyJ1cmkiOiIiLCJ2ZXJzaW9uIjoiIn0sInJlc3VsdCI6eyIkc2NoZW1hIjoiaHR0cHM6Ly9qc29uLnNjaGVtYXN0b3JlLm9yZy9zYXJpZi0yLjEuMC1ydG0uNS5qc29uIiwicnVucyI6W3siY29sdW1uS2luZCI6InV0ZjE2Q29kZVVuaXRzIiwib3JpZ2luYWxVcmlCYXNlSWRzIjp7IlJPT1RQQVRIIjp7InVyaSI6ImZpbGU6Ly8vIn19LCJyZXN1bHRzIjpbXSwidG9vbCI6eyJkcml2ZXIiOnsiZnVsbE5hbWUiOiJUcml2eSBWdWxuZXJhYmlsaXR5IFNjYW5uZXIiLCJpbmZvcm1hdGlvblVyaSI6Imh0dHBzOi8vZ2l0aHViLmNvbS9hcXVhc2VjdXJpdHkvdHJpdnkiLCJuYW1lIjoiVHJpdnkiLCJydWxlcyI6W10sInZlcnNpb24iOiIwLjI5LjIifX19XSwidmVyc2lvbiI6IjIuMS4wIn19LCJtZXRhZGF0YSI6eyJzY2FuU3RhcnRlZE9uIjoiMjAyMi0wOC0wMlQwMjozMzo0N1oiLCJzY2FuRmluaXNoZWRPbiI6IjIwMjItMDgtMDJUMDI6MzM6NTNaIn19fQ==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"MEYCIQCovBtLOBXyB2zpvhp3j6QzqLtsH0/RC7fRINSApySqxAIhAIKlzu1fXuKPPOIheNnsPmBOB6XfZbRs5sDW1yFSch1A\"}]}\n```\n\nThe same with this change:\n```shell\n$ go run ./cmd/cosign verify-attestation --type spdx ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\nError: none of the attestations matched the predicate type: spdx\nmain.go:62: error during command execution: none of the attestations matched the predicate type: spdx\nexit status 1\n```\n\nA valid `--type` with this change:\n```shell\n$ go run ./cmd/cosign verify-attestation --type vuln ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nVerification for ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nThe following checks were performed on each of these signatures:\n  - The cosign claims were validated\n  - Existence of the claims in the transparency log was verified offline\n  - Any certificates were verified against the Fulcio roots.\nCertificate subject:  https://github.com/distroless/static/.github/workflows/release.yaml@refs/heads/main\nCertificate issuer URL:  https://token.actions.githubusercontent.com\nCertificate extension GitHub Workflow Trigger: schedule\nCertificate extension GitHub Workflow SHA: 7e7572e578de7c51a2f1a1791f025cf315503aa2\nCertificate extension GitHub Workflow Name: Create Release\nCertificate extension GitHub Workflow Trigger distroless/static\nCertificate extension GitHub Workflow Ref: refs/heads/main\n{\"payloadType\":\"application/vnd.in-toto+json\",\"payload\":\"eyJfdHlwZSI6Imh0dHBzOi8vaW4tdG90by5pby9TdGF0ZW1lbnQvdjAuMSIsInByZWRpY2F0ZVR5cGUiOiJjb3NpZ24uc2lnc3RvcmUuZGV2L2F0dGVzdGF0aW9uL3Z1bG4vdjEiLCJzdWJqZWN0IjpbeyJuYW1lIjoiZ2hjci5pby9kaXN0cm9sZXNzL3N0YXRpYyIsImRpZ2VzdCI6eyJzaGEyNTYiOiJkZDc2MTRiNWExMmJjNGQ2MTdiMjIzYzU4OGI0ZTBjODMzNDAyYjhmNDk5MWZiNTcwMmVhODNhZmFkMTk4NmUyIn19XSwicHJlZGljYXRlIjp7Imludm9jYXRpb24iOnsicGFyYW1ldGVycyI6bnVsbCwidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2Rpc3Ryb2xlc3Mvc3RhdGljL2FjdGlvbnMvcnVucy8yNzc5MjEyNzA1IiwiZXZlbnRfaWQiOiIyNzc5MjEyNzA1IiwiYnVpbGRlci5pZCI6IkNyZWF0ZSBSZWxlYXNlIn0sInNjYW5uZXIiOnsidXJpIjoiaHR0cHM6Ly9naXRodWIuY29tL2FxdWFzZWN1cml0eS90cml2eSIsInZlcnNpb24iOiIwLjI5LjIiLCJkYiI6eyJ1cmkiOiIiLCJ2ZXJzaW9uIjoiIn0sInJlc3VsdCI6eyIkc2NoZW1hIjoiaHR0cHM6Ly9qc29uLnNjaGVtYXN0b3JlLm9yZy9zYXJpZi0yLjEuMC1ydG0uNS5qc29uIiwicnVucyI6W3siY29sdW1uS2luZCI6InV0ZjE2Q29kZVVuaXRzIiwib3JpZ2luYWxVcmlCYXNlSWRzIjp7IlJPT1RQQVRIIjp7InVyaSI6ImZpbGU6Ly8vIn19LCJyZXN1bHRzIjpbXSwidG9vbCI6eyJkcml2ZXIiOnsiZnVsbE5hbWUiOiJUcml2eSBWdWxuZXJhYmlsaXR5IFNjYW5uZXIiLCJpbmZvcm1hdGlvblVyaSI6Imh0dHBzOi8vZ2l0aHViLmNvbS9hcXVhc2VjdXJpdHkvdHJpdnkiLCJuYW1lIjoiVHJpdnkiLCJydWxlcyI6W10sInZlcnNpb24iOiIwLjI5LjIifX19XSwidmVyc2lvbiI6IjIuMS4wIn19LCJtZXRhZGF0YSI6eyJzY2FuU3RhcnRlZE9uIjoiMjAyMi0wOC0wMlQwMjozMzo0N1oiLCJzY2FuRmluaXNoZWRPbiI6IjIwMjItMDgtMDJUMDI6MzM6NTNaIn19fQ==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"MEYCIQCovBtLOBXyB2zpvhp3j6QzqLtsH0/RC7fRINSApySqxAIhAIKlzu1fXuKPPOIheNnsPmBOB6XfZbRs5sDW1yFSch1A\"}]}\n```\n\nSigned-off-by: Matt Moore <mattmoor@chainguard.dev>",
      "author": "Matt Moore",
      "comments": null,
      "stats": "{'additions': 10, 'deletions': 1, 'total': 11}",
      "files": "{'cmd/cosign/cli/verify/verify_attestation.go': {'additions': 10, 'deletions': 1, 'changes': 11, 'status': 'modified', 'raw_url': 'https://github.com/sigstore/cosign/raw/c5fda01a8ff33ca981f45a9f13e7fb6bd2080b94/cmd%2Fcosign%2Fcli%2Fverify%2Fverify_attestation.go', 'patch': '@@ -201,6 +201,7 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t}\\n \\t\\t}\\n \\n+\\t\\tvar checked []oci.Signature\\n \\t\\tvar validationErrors []error\\n \\t\\tfor _, vp := range verified {\\n \\t\\t\\tpayload, err := policy.AttestationToPayloadJSON(ctx, c.PredicateType, vp)\\n@@ -217,6 +218,7 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t\\tcueValidationErr := cue.ValidateJSON(payload, cuePolicies)\\n \\t\\t\\t\\tif cueValidationErr != nil {\\n \\t\\t\\t\\t\\tvalidationErrors = append(validationErrors, cueValidationErr)\\n+\\t\\t\\t\\t\\tcontinue\\n \\t\\t\\t\\t}\\n \\t\\t\\t}\\n \\n@@ -225,8 +227,11 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\t\\tregoValidationErrs := rego.ValidateJSON(payload, regoPolicies)\\n \\t\\t\\t\\tif len(regoValidationErrs) > 0 {\\n \\t\\t\\t\\t\\tvalidationErrors = append(validationErrors, regoValidationErrs...)\\n+\\t\\t\\t\\t\\tcontinue\\n \\t\\t\\t\\t}\\n \\t\\t\\t}\\n+\\n+\\t\\t\\tchecked = append(checked, vp)\\n \\t\\t}\\n \\n \\t\\tif len(validationErrors) > 0 {\\n@@ -237,10 +242,14 @@ func (c *VerifyAttestationCommand) Exec(ctx context.Context, images []string) (e\\n \\t\\t\\treturn fmt.Errorf(\"%d validation errors occurred\", len(validationErrors))\\n \\t\\t}\\n \\n+\\t\\tif len(checked) == 0 {\\n+\\t\\t\\treturn fmt.Errorf(\"none of the attestations matched the predicate type: %s\", c.PredicateType)\\n+\\t\\t}\\n+\\n \\t\\t// TODO: add CUE validation report to `PrintVerificationHeader`.\\n \\t\\tPrintVerificationHeader(imageRef, co, bundleVerified, fulcioVerified)\\n \\t\\t// The attestations are always JSON, so use the raw \"text\" mode for outputting them instead of conversion\\n-\\t\\tPrintVerification(imageRef, verified, \"text\")\\n+\\t\\tPrintVerification(imageRef, checked, \"text\")\\n \\t}\\n \\n \\treturn nil'}}",
      "message_norm": "merge pull request from ghsa-vjxv-45g9-9296\n\ntoday the verification logic:\n1. verifies signatures on attestations (at least one must verify, or it errors),\n2. all attestations matching the specified `--type` must pass any specified cue/rego policies,\n3. *all* signature-verified attestations are then printed.\n\nhowever, if none of the attestations match the specified `--type` then `2.` is considered satisfied and we proceed to `3.`\n\nthis changes the above logic to:\n1. same.\n2. same, but these are put into a `checked` list,\n3. `checked` must be non-empty (or an error is printed about no attestations matching `--type`),\n4. *just* the `checked` attestations are printed.\n\n---\n\nthe bug at head:\n```shell\n$ cosign verify-attestation --type spdx ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nverification for ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nthe following checks were performed on each of these signatures:\n  - the cosign claims were validated\n  - existence of the claims in the transparency log was verified offline\n  - any certificates were verified against the fulcio roots.\ncertificate subject:  https://github.com/distroless/static/.github/workflows/release.yaml@refs/heads/main\ncertificate issuer url:  https://token.actions.githubusercontent.com\ncertificate extension github workflow trigger: schedule\ncertificate extension github workflow sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2\ncertificate extension github workflow name: create release\ncertificate extension github workflow trigger distroless/static\ncertificate extension github workflow ref: refs/heads/main\n{\"payloadtype\":\"application/vnd.in-toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0/rc7frinsapysqxaihaiklzu1fxukppoihennspmbob6xfzbrs5sdw1yfsch1a\"}]}\n```\n\nthe same with this change:\n```shell\n$ go run ./cmd/cosign verify-attestation --type spdx ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\nerror: none of the attestations matched the predicate type: spdx\nmain.go:62: error during command execution: none of the attestations matched the predicate type: spdx\nexit status 1\n```\n\na valid `--type` with this change:\n```shell\n$ go run ./cmd/cosign verify-attestation --type vuln ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2\n\nverification for ghcr.io/distroless/static@sha256:dd7614b5a12bc4d617b223c588b4e0c833402b8f4991fb5702ea83afad1986e2 --\nthe following checks were performed on each of these signatures:\n  - the cosign claims were validated\n  - existence of the claims in the transparency log was verified offline\n  - any certificates were verified against the fulcio roots.\ncertificate subject:  https://github.com/distroless/static/.github/workflows/release.yaml@refs/heads/main\ncertificate issuer url:  https://token.actions.githubusercontent.com\ncertificate extension github workflow trigger: schedule\ncertificate extension github workflow sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2\ncertificate extension github workflow name: create release\ncertificate extension github workflow trigger distroless/static\ncertificate extension github workflow ref: refs/heads/main\n{\"payloadtype\":\"application/vnd.in-toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0/rc7frinsapysqxaihaiklzu1fxukppoihennspmbob6xfzbrs5sdw1yfsch1a\"}]}\n```\n\nsigned-off-by: matt moore <mattmoor@chainguard.dev>",
      "language": "en",
      "entities": "[('ghsa-vjxv-45g9-9296', 'VULNID', 'GHSA'), ('verifies', 'ACTION', ''), ('verify', 'ACTION', ''), ('signature', 'SECWORD', ''), ('verified', 'ACTION', ''), ('changes', 'ACTION', ''), ('error', 'FLAW', ''), ('bug', 'FLAW', ''), ('validated', 'ACTION', ''), ('verified', 'ACTION', ''), ('verified', 'ACTION', ''), ('certificate', 'SECWORD', ''), ('https://github.com/distroless/static/.github/workflows/release.yaml@refs/heads/main', 'URL', ''), ('certificate', 'SECWORD', ''), ('https://token.actions.githubusercontent.com', 'URL', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2', 'SHA', 'prefix_colon_sha'), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0', 'SECWORD', ''), ('error', 'FLAW', ''), ('error', 'FLAW', ''), ('command execution', 'SECWORD', ''), ('validated', 'ACTION', ''), ('verified', 'ACTION', ''), ('verified', 'ACTION', ''), ('certificate', 'SECWORD', ''), ('https://github.com/distroless/static/.github/workflows/release.yaml@refs/heads/main', 'URL', ''), ('certificate', 'SECWORD', ''), ('https://token.actions.githubusercontent.com', 'URL', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('sha: 7e7572e578de7c51a2f1a1791f025cf315503aa2', 'SHA', 'prefix_colon_sha'), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('certificate', 'SECWORD', ''), ('toto+json\",\"payload\":\"eyjfdhlwzsi6imh0dhbzoi8vaw4tdg90by5pby9tdgf0zw1lbnqvdjaumsisinbyzwrpy2f0zvr5cguioijjb3npz24uc2lnc3rvcmuuzgv2l2f0dgvzdgf0aw9ul3z1bg4vdjeilcjzdwjqzwn0ijpbeyjuyw1lijoiz2hjci5pby9kaxn0cm9szxnzl3n0yxrpyyisimrpz2vzdci6eyjzageyntyioijkzdc2mtrinwexmmjjngq2mtdimjizyzu4ogi0ztbjodmzndayyjhmndk5mwzintcwmmvhodnhzmfkmtk4nmuyin19xswichjlzgljyxrlijp7imludm9jyxrpb24ionsicgfyyw1ldgvycyi6bnvsbcwidxjpijoiahr0chm6ly9naxrodwiuy29tl2rpc3ryb2xlc3mvc3rhdgljl2fjdglvbnmvcnvucy8ynzc5mjeynza1iiwizxzlbnrfawqioiiynzc5mjeynza1iiwiynvpbgrlci5pzci6iknyzwf0zsbszwxlyxnlin0sinnjyw5uzxiionsidxjpijoiahr0chm6ly9naxrodwiuy29tl2fxdwfzzwn1cml0es90cml2esisinzlcnnpb24ioiiwlji5ljiilcjkyii6eyj1cmkioiiilcj2zxjzaw9uijoiin0sinjlc3vsdci6eyikc2nozw1hijoiahr0chm6ly9qc29ulnnjagvtyxn0b3jllm9yzy9zyxjpzi0yljeumc1ydg0uns5qc29uiiwicnvucyi6w3siy29sdw1us2luzci6inv0zje2q29kzvvuaxrziiwib3jpz2luywxvcmlcyxnlswrzijp7iljpt1rqqvriijp7invyasi6imzpbgu6ly8vin19lcjyzxn1bhrzijpbxswidg9vbci6eyjkcml2zxiionsiznvsbe5hbwuioijucml2esbwdwxuzxjhymlsaxr5ifnjyw5uzxiilcjpbmzvcm1hdglvblvyasi6imh0dhbzoi8vz2l0ahvilmnvbs9hcxvhc2vjdxjpdhkvdhjpdnkilcjuyw1lijoivhjpdnkilcjydwxlcyi6w10sinzlcnnpb24ioiiwlji5ljiifx19xswidmvyc2lvbii6ijiums4win19lcjtzxrhzgf0ysi6eyjzy2fuu3rhcnrlze9uijoimjaymi0woc0wmlqwmjozmzo0n1oilcjzy2furmluaxnozwrpbii6ijiwmjitmdgtmdjumdi6mzm6ntnain19fq==\",\"signatures\":[{\"keyid\":\"\",\"sig\":\"meyciqcovbtlobxyb2zpvhp3j6qzqltsh0', 'SECWORD', ''), ('mattmoor@chainguard.dev', 'EMAIL', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['cmd/cosign/cli/verify/verify_attestation.go'])",
      "num_files": 1.0
    },
    {
      "index": 628,
      "vuln_id": "GHSA-5fw9-fq32-wv5p",
      "cwe_id": "{'CWE-78'}",
      "score": 5.6,
      "chain": "{'https://github.com/mikaelbr/node-notifier/commit/5d62799dab88505a709cd032653b2320c5813fce'}",
      "dataset": "osv",
      "summary": "OS Command Injection in node-notifier This affects the package node-notifier before 8.0.1. It allows an attacker to run arbitrary commands on Linux machines due to the options params not being sanitised when being passed an array.",
      "published_date": "2020-12-21",
      "chain_len": 1,
      "project": "https://github.com/mikaelbr/node-notifier",
      "commit_href": "https://github.com/mikaelbr/node-notifier/commit/5d62799dab88505a709cd032653b2320c5813fce",
      "commit_sha": "5d62799dab88505a709cd032653b2320c5813fce",
      "patch": "SINGLE",
      "chain_ord": "['5d62799dab88505a709cd032653b2320c5813fce']",
      "before_first_fix_commit": "{'0c4a80df9a3b5015cd1e1ab858e008be3fece082'}",
      "last_fix_commit": "5d62799dab88505a709cd032653b2320c5813fce",
      "chain_ord_pos": 1.0,
      "commit_datetime": "12/15/2020, 15:30:54",
      "message": "v8.0.1",
      "author": "Mikael Brevik",
      "comments": null,
      "stats": "{'additions': 1, 'deletions': 1, 'total': 2}",
      "files": "{'package.json': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https://github.com/mikaelbr/node-notifier/raw/5d62799dab88505a709cd032653b2320c5813fce/package.json', 'patch': '@@ -1,6 +1,6 @@\\n {\\n   \"name\": \"node-notifier\",\\n-  \"version\": \"8.0.0\",\\n+  \"version\": \"8.0.1\",\\n   \"description\": \"A Node.js module for sending notifications on native Mac, Windows (post and pre 8) and Linux (or Growl as fallback)\",\\n   \"main\": \"index.js\",\\n   \"scripts\": {'}}",
      "message_norm": "v8.0.1",
      "language": "sk",
      "entities": "[('v8.0.1', 'VERSION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['package.json'])",
      "num_files": 1.0
    },
    {
      "index": 1680,
      "vuln_id": "GHSA-f78g-q7r4-9wcv",
      "cwe_id": "{'CWE-369'}",
      "score": 2.5,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/548b5eaf23685d86f722233d8fbc21d0a4aecb96'}",
      "dataset": "osv",
      "summary": "Division by 0 in `FractionalAvgPool` ### Impact\nAn attacker can cause a runtime division by zero error and denial of service in `tf.raw_ops.FractionalAvgPool`:\n\n```python\nimport tensorflow as tf\n\nvalue = tf.constant([60], shape=[1, 1, 1, 1], dtype=tf.int32)\npooling_ratio = [1.0, 1.0000014345305555, 1.0, 1.0]\npseudo_random = False\noverlapping = False\ndeterministic = False\nseed = 0\nseed2 = 0\n\ntf.raw_ops.FractionalAvgPool(\n  value=value, pooling_ratio=pooling_ratio, pseudo_random=pseudo_random,\n  overlapping=overlapping, deterministic=deterministic, seed=seed, seed2=seed2)\n```\n\nThis is because the [implementation](https://github.com/tensorflow/tensorflow/blob/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c/tensorflow/core/kernels/fractional_avg_pool_op.cc#L85-L89) computes a divisor quantity by dividing two user controlled values:\n\n```cc                     \nfor (int i = 0; i < tensor_in_and_out_dims; ++i) {\n  output_size[i] = static_cast<int>(std::floor(input_size[i] / pooling_ratio_[i]));\n  DCHECK_GT(output_size[i], 0); \n} \n``` \n    \nThe user controls the values of `input_size[i]` and `pooling_ratio_[i]` (via the `value.shape()` and `pooling_ratio` arguments). If the value in `input_size[i]` is smaller than the `pooling_ratio_[i]`, then the floor operation results in `output_size[i]` being 0. The `DCHECK_GT` line is a no-op outside of debug mode, so in released versions of TF this does not trigger.\n\nLater, these computed values [are used as arguments](https://github.com/tensorflow/tensorflow/blob/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c/tensorflow/core/kernels/fractional_avg_pool_op.cc#L96-L99) to [`GeneratePoolingSequence`](https://github.com/tensorflow/tensorflow/blob/acc8ee69f5f46f92a3f1f11230f49c6ac266f10c/tensorflow/core/kernels/fractional_pool_common.cc#L100-L108). There, the first computation is a division in a modulo operation:\n\n```cc\nstd::vector<int64> GeneratePoolingSequence(int input_length, int output_length,\n                                           GuardedPhiloxRandom* generator,\n                                           bool pseudo_random) {\n  ...\n  if (input_length % output_length == 0) {\n    diff = std::vector<int64>(output_length, input_length / output_length);\n  }\n  ...\n}\n```\n\nSince `output_length` can be 0, this results in runtime crashing.\n\n### Patches\nWe have patched the issue in GitHub commit [548b5eaf23685d86f722233d8fbc21d0a4aecb96](https://github.com/tensorflow/tensorflow/commit/548b5eaf23685d86f722233d8fbc21d0a4aecb96).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date": "2021-05-21",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/548b5eaf23685d86f722233d8fbc21d0a4aecb96",
      "commit_sha": "548b5eaf23685d86f722233d8fbc21d0a4aecb96",
      "patch": "SINGLE",
      "chain_ord": "['548b5eaf23685d86f722233d8fbc21d0a4aecb96']",
      "before_first_fix_commit": "{'acc8ee69f5f46f92a3f1f11230f49c6ac266f10c'}",
      "last_fix_commit": "548b5eaf23685d86f722233d8fbc21d0a4aecb96",
      "chain_ord_pos": 1.0,
      "commit_datetime": "04/29/2021, 15:38:16",
      "message": "Fix divide by zero error in `fractional_pool_common.cc`.\n\nPiperOrigin-RevId: 371126221\nChange-Id: Iea4b2f363aaeb116ab460e3bc592c687484af344",
      "author": "Laura Pak",
      "comments": null,
      "stats": "{'additions': 4, 'deletions': 0, 'total': 4}",
      "files": "{'tensorflow/core/kernels/fractional_avg_pool_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/548b5eaf23685d86f722233d8fbc21d0a4aecb96/tensorflow%2Fcore%2Fkernels%2Ffractional_avg_pool_op.cc', 'patch': '@@ -80,6 +80,10 @@ class FractionalAvgPoolOp : public OpKernel {\\n     std::vector<int> output_size(tensor_in_and_out_dims);\\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {\\n       input_size[i] = tensor_in.dim_size(i);\\n+      OP_REQUIRES(\\n+          context, pooling_ratio_[i] <= input_size[i],\\n+          errors::InvalidArgument(\\n+              \"Pooling ratio cannot be bigger than input tensor dim size.\"));\\n     }\\n     // Output size.\\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {'}}",
      "message_norm": "fix divide by zero error in `fractional_pool_common.cc`.\n\npiperorigin-revid: 371126221\nchange-id: iea4b2f363aaeb116ab460e3bc592c687484af344",
      "language": "en",
      "entities": "[('fix', 'ACTION', ''), ('divide by zero', 'SECWORD', ''), ('error', 'FLAW', ''), ('371126221', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/kernels/fractional_avg_pool_op.cc'])",
      "num_files": 1.0
    },
    {
      "index": 1610,
      "vuln_id": "GHSA-cvgx-3v3q-m36c",
      "cwe_id": "{'CWE-125'}",
      "score": 7.1,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/a0d64445116c43cf46a5666bd4eee28e7a82f244'}",
      "dataset": "osv",
      "summary": "Heap OOB in shape inference for `QuantizeV2` ### Impact\nThe [shape inference code for `QuantizeV2`](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/framework/common_shape_fns.cc#L2509-L2530) can trigger a read outside of bounds of heap allocated array:\n\n```python\nimport tensorflow as tf\n\n@tf.function\ndef test():\n  data=tf.raw_ops.QuantizeV2(\n    input=[1.0,1.0],\n    min_range=[1.0,10.0],\n    max_range=[1.0,10.0],\n    T=tf.qint32,\n    mode='MIN_COMBINED',\n    round_mode='HALF_TO_EVEN',\n    narrow_range=False,\n    axis=-100,\n    ensure_minimum_range=10)\n  return data\n\ntest()\n```\n\nThis occurs whenever `axis` is a negative value less than `-1`. In this case, we are accessing data before the start of a heap buffer:\n    \n```cc\nint axis = -1;\nStatus s = c->GetAttr(\"axis\", &axis);\nif (!s.ok() && s.code() != error::NOT_FOUND) {\n  return s;\n}   \n... \nif (axis != -1) {\n  ...\n  TF_RETURN_IF_ERROR(\n      c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n}\n```\n\nThe code allows `axis` to be an optional argument (`s` would contain an `error::NOT_FOUND` error code). Otherwise, it assumes that `axis` is a valid index into the dimensions of the `input` tensor. If `axis` is less than `-1` then this results in a heap OOB read.\n    \n### Patches\nWe have patched the issue in GitHub commit [a0d64445116c43cf46a5666bd4eee28e7a82f244](https://github.com/tensorflow/tensorflow/commit/a0d64445116c43cf46a5666bd4eee28e7a82f244).\n    \nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, as this version is the only one that is also affected.\n  \n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2021-11-10",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/a0d64445116c43cf46a5666bd4eee28e7a82f244",
      "commit_sha": "a0d64445116c43cf46a5666bd4eee28e7a82f244",
      "patch": "SINGLE",
      "chain_ord": "['a0d64445116c43cf46a5666bd4eee28e7a82f244']",
      "before_first_fix_commit": "{'4a7c71d60c94ae3bc8149429988eeeb1d5466f00'}",
      "last_fix_commit": "a0d64445116c43cf46a5666bd4eee28e7a82f244",
      "chain_ord_pos": 1.0,
      "commit_datetime": "10/01/2021, 22:52:56",
      "message": "Prevent OOB access in QuantizeV2 shape inference\n\nPiperOrigin-RevId: 400309614\nChange-Id: I31412c71b05b4f21b677f7fa715a61499cbee39d",
      "author": "Yu-Cheng Ling",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'tensorflow/core/framework/common_shape_fns.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/a0d64445116c43cf46a5666bd4eee28e7a82f244/tensorflow%2Fcore%2Fframework%2Fcommon_shape_fns.cc', 'patch': '@@ -2559,6 +2559,9 @@ Status QuantizeV2Shape(InferenceContext* c) {\\n   if (!s.ok() && s.code() != error::NOT_FOUND) {\\n     return s;\\n   }\\n+  if (axis < -1) {\\n+    return errors::InvalidArgument(\"axis should be at least -1, got \", axis);\\n+  }\\n   const int minmax_rank = (axis == -1) ? 0 : 1;\\n   TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\\n   ShapeHandle minmax;'}}",
      "message_norm": "prevent oob access in quantizev2 shape inference\n\npiperorigin-revid: 400309614\nchange-id: i31412c71b05b4f21b677f7fa715a61499cbee39d",
      "language": "en",
      "entities": "[('prevent', 'ACTION', ''), ('oob', 'SECWORD', ''), ('400309614', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/core/framework/common_shape_fns.cc'])",
      "num_files": 1.0
    },
    {
      "index": 2696,
      "vuln_id": "GHSA-q4qf-3fc6-8x34",
      "cwe_id": "{'CWE-787', 'CWE-119'}",
      "score": 8.7,
      "chain": "{'https://github.com/tensorflow/tensorflow/commit/2d88f470dea2671b430884260f3626b1fe99830a'}",
      "dataset": "osv",
      "summary": "Segfault and data corruption in tensorflow-lite ### Impact\nTo mimic Python's indexing with negative values, TFLite uses `ResolveAxis` to convert negative values to positive indices. However, the only check that the converted index is now valid is only present in debug builds:\nhttps://github.com/tensorflow/tensorflow/blob/0e68f4d3295eb0281a517c3662f6698992b7b2cf/tensorflow/lite/kernels/internal/reference/reduce.h#L68-L72\n\nIf the `DCHECK` does not trigger, then code execution moves ahead with a negative index. This, in turn, results in accessing data out of bounds which results in segfaults and/or data corruption.\n### Patches\nWe have patched the issue in 2d88f470dea2671b430884260f3626b1fe99830a and will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date": "2020-09-25",
      "chain_len": 1,
      "project": "https://github.com/tensorflow/tensorflow",
      "commit_href": "https://github.com/tensorflow/tensorflow/commit/2d88f470dea2671b430884260f3626b1fe99830a",
      "commit_sha": "2d88f470dea2671b430884260f3626b1fe99830a",
      "patch": "SINGLE",
      "chain_ord": "['2d88f470dea2671b430884260f3626b1fe99830a']",
      "before_first_fix_commit": "{'d487b8c4ca7d77d650fb8dca94b073aad8ff4b5e'}",
      "last_fix_commit": "2d88f470dea2671b430884260f3626b1fe99830a",
      "chain_ord_pos": 1.0,
      "commit_datetime": "09/18/2020, 21:43:00",
      "message": "[tflite] Ensure `ResolveAxis` properly handles negative inputs.\n\nIn Python, a list `l` of length `n` allows indexing with negative indices, `l[i]`. The only constraint is that `n + i` becomes positive. Code in `ResolveAxis` assumes the constraints and only checks it using a `DCHECK`. But the macro is a no-op in non-debug builds and that can result in reading from negative offsets (buffer underflows).\n\nPiperOrigin-RevId: 332530683\nChange-Id: I464e073fee618054ae3719a3679739007bb3f3bc",
      "author": "Mihai Maruseac",
      "comments": null,
      "stats": "{'additions': 3, 'deletions': 0, 'total': 3}",
      "files": "{'tensorflow/lite/kernels/internal/reference/reduce.h': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https://github.com/tensorflow/tensorflow/raw/2d88f470dea2671b430884260f3626b1fe99830a/tensorflow%2Flite%2Fkernels%2Finternal%2Freference%2Freduce.h', 'patch': '@@ -70,6 +70,9 @@ inline bool ResolveAxis(const int num_dims, const int* axis,\\n     // eg: For num_dims=3, [0, 1, 2] is the same as [-3, -2, -1]  */\\n     int current = axis[idx] < 0 ? (axis[idx] + num_dims) : axis[idx];\\n     TFLITE_DCHECK(current >= 0 && current < num_dims);\\n+    if (current < 0 || current >= num_dims) {\\n+      return false;\\n+    }\\n     bool is_dup = false;\\n     for (int j = 0; j < *out_num_axis; ++j) {\\n       if (out_axis[j] == current) {'}}",
      "message_norm": "[tflite] ensure `resolveaxis` properly handles negative inputs.\n\nin python, a list `l` of length `n` allows indexing with negative indices, `l[i]`. the only constraint is that `n + i` becomes positive. code in `resolveaxis` assumes the constraints and only checks it using a `dcheck`. but the macro is a no-op in non-debug builds and that can result in reading from negative offsets (buffer underflows).\n\npiperorigin-revid: 332530683\nchange-id: i464e073fee618054ae3719a3679739007bb3f3bc",
      "language": "en",
      "entities": "[('ensure', 'ACTION', ''), ('buffer underflows', 'SECWORD', ''), ('332530683', 'SHA', 'generic_sha')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['tensorflow/lite/kernels/internal/reference/reduce.h'])",
      "num_files": 1.0
    },
    {
      "index": 3441,
      "vuln_id": "GHSA-xhp9-4947-rq78",
      "cwe_id": "{'CWE-755'}",
      "score": 9.8,
      "chain": "{'https://github.com/bottlepy/bottle/commit/a2b0ee6bb4ce88895429ec4aca856616244c4c4c', 'https://github.com/bottlepy/bottle/commit/e140e1b54da721a660f2eb9d58a106b7b3ff2f00'}",
      "dataset": "osv",
      "summary": "Denial of service in bottle Bottle before 0.12.20 mishandles errors during early request binding.",
      "published_date": "2022-06-03",
      "chain_len": 2,
      "project": "https://github.com/bottlepy/bottle",
      "commit_href": "https://github.com/bottlepy/bottle/commit/e140e1b54da721a660f2eb9d58a106b7b3ff2f00",
      "commit_sha": "e140e1b54da721a660f2eb9d58a106b7b3ff2f00",
      "patch": "MULTI",
      "chain_ord": "['e140e1b54da721a660f2eb9d58a106b7b3ff2f00', 'a2b0ee6bb4ce88895429ec4aca856616244c4c4c']",
      "before_first_fix_commit": "{'04b27f185412250f9389a6a14d1e1c516c87e13c'}",
      "last_fix_commit": "a2b0ee6bb4ce88895429ec4aca856616244c4c4c",
      "chain_ord_pos": 1.0,
      "commit_datetime": "05/26/2022, 12:49:32",
      "message": "Gracefully handle errors during early request binding.",
      "author": "Marcel Hellkamp",
      "comments": null,
      "stats": "{'additions': 9, 'deletions': 7, 'total': 16}",
      "files": "{'bottle.py': {'additions': 9, 'deletions': 7, 'changes': 16, 'status': 'modified', 'raw_url': 'https://github.com/bottlepy/bottle/raw/e140e1b54da721a660f2eb9d58a106b7b3ff2f00/bottle.py', 'patch': \"@@ -848,17 +848,19 @@ def default_error_handler(self, res):\\n         return tob(template(ERROR_PAGE_TEMPLATE, e=res))\\n \\n     def _handle(self, environ):\\n-        path = environ['bottle.raw_path'] = environ['PATH_INFO']\\n-        if py3k:\\n-            try:\\n-                environ['PATH_INFO'] = path.encode('latin1').decode('utf8')\\n-            except UnicodeError:\\n-                return HTTPError(400, 'Invalid path string. Expected UTF-8')\\n-\\n         try:\\n+\\n             environ['bottle.app'] = self\\n             request.bind(environ)\\n             response.bind()\\n+\\n+            path = environ['bottle.raw_path'] = environ['PATH_INFO']\\n+            if py3k:\\n+                try:\\n+                    environ['PATH_INFO'] = path.encode('latin1').decode('utf8')\\n+                except UnicodeError:\\n+                    return HTTPError(400, 'Invalid path string. Expected UTF-8')\\n+\\n             try:\\n                 self.trigger_hook('before_request')\\n                 route, args = self.router.match(environ)\"}}",
      "message_norm": "gracefully handle errors during early request binding.",
      "language": "en",
      "entities": "[('errors', 'FLAW', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['bottle.py'])",
      "num_files": 1.0
    },
    {
      "index": 455,
      "vuln_id": "GHSA-4p92-fv6v-fhfj",
      "cwe_id": "{'CWE-79'}",
      "score": 5.4,
      "chain": "{'https://github.com/microweber/microweber/commit/15e519a86e4b24526abaf9e6dc81cb1af86843a5'}",
      "dataset": "osv",
      "summary": "Cross-site Scripting in microweber Microweber prior to 1.2.11 is vulnerable to reflected cross-site scripting.",
      "published_date": "2022-02-27",
      "chain_len": 1,
      "project": "https://github.com/microweber/microweber",
      "commit_href": "https://github.com/microweber/microweber/commit/15e519a86e4b24526abaf9e6dc81cb1af86843a5",
      "commit_sha": "15e519a86e4b24526abaf9e6dc81cb1af86843a5",
      "patch": "SINGLE",
      "chain_ord": "['15e519a86e4b24526abaf9e6dc81cb1af86843a5']",
      "before_first_fix_commit": "{'c897d0dc159849763a813184d9b75b966c6360bf'}",
      "last_fix_commit": "15e519a86e4b24526abaf9e6dc81cb1af86843a5",
      "chain_ord_pos": 1.0,
      "commit_datetime": "02/25/2022, 10:57:48",
      "message": "update",
      "author": "Peter Ivanov",
      "comments": null,
      "stats": "{'additions': 0, 'deletions': 0, 'total': 0}",
      "files": "{'.github/workflows/templates.yml': {'additions': 0, 'deletions': 0, 'changes': 0, 'status': 'renamed', 'raw_url': 'https://github.com/microweber/microweber/raw/15e519a86e4b24526abaf9e6dc81cb1af86843a5/.github%2Fworkflows%2Ftemplates.yml', 'patch': None}}",
      "message_norm": "update",
      "language": "ro",
      "entities": "[('update', 'ACTION', '')]",
      "classification_level_1": null,
      "classification_level_2": null,
      "list_files": "dict_keys(['.github/workflows/templates.yml'])",
      "num_files": 1.0
    }
  ]
}