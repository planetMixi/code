vuln_id,code_diff
PYSEC-2020-72,"From f3809fc8a97ee305d721662a75f788f9e9d21938 Mon Sep 17 00:00:00 2001
From: Joshua Sangmeister <joshua.sangmeister@gmail.com>
Date: Fri, 20 Nov 2020 13:38:37 +0100
Subject: [PATCH] Fixed HTML attribute validation

---
 server/openslides/utils/validate.py | 38 +++++++++++++++++++++++++----
 1 file changed, 33 insertions(+), 5 deletions(-)

diff --git a/server/openslides/utils/validate.py b/server/openslides/utils/validate.py
index 14dacee5dc..1aa61edb62 100644
--- a/server/openslides/utils/validate.py
+++ b/server/openslides/utils/validate.py
@@ -43,12 +43,40 @@
     ""video"",
 ]
 
+allowed_attributes = [
+    ""align"",
+    ""alt"",
+    ""autoplay"",
+    ""background"",
+    ""bgcolor"",
+    ""border"",
+    ""class"",
+    ""colspan"",
+    ""controls"",
+    ""dir"",
+    ""height"",
+    ""hidden"",
+    ""href"",
+    ""hreflang"",
+    ""id"",
+    ""lang"",
+    ""loop"",
+    ""muted"",
+    ""poster"",
+    ""preload"",
+    ""rel"",
+    ""rowspan"",
+    ""scope"",
+    ""sizes"",
+    ""src"",
+    ""srcset"",
+    ""start"",
+    ""style"",
+    ""target"",
+    ""title"",
+    ""width"",
+]
 
-def allow_all(tag: str, name: str, value: str) -> bool:
-    return True
-
-
-allowed_attributes = allow_all
 allowed_styles = [
     ""color"",
     ""background-color"","
CVE-2012-2101,"From 8c8735a73afb16d5856f0aa6088e9ae406c52beb Mon Sep 17 00:00:00 2001
From: Dan Prince <dprince@redhat.com>
Date: Wed, 11 Apr 2012 16:21:29 -0400
Subject: [PATCH] Implement quotas for security groups.

Fixes LP Bug #969545 for Diablo.

Change-Id: Ibc02256b6debd29c56307320acc48e9cfae85ba9
---
 nova/api/ec2/cloud.py                         | 12 +++++
 nova/api/openstack/contrib/quotas.py          |  5 ++-
 nova/api/openstack/contrib/security_groups.py | 12 +++++
 nova/db/api.py                                | 10 +++++
 nova/db/sqlalchemy/api.py                     | 19 ++++++++
 nova/quota.py                                 | 32 ++++++++++++++
 .../api/openstack/contrib/test_quotas.py      | 16 +++++--
 .../openstack/contrib/test_security_groups.py | 44 +++++++++++++++++++
 nova/tests/test_cloud.py                      | 25 +++++++++++
 nova/tests/test_quota.py                      | 32 +++++++++++++-
 10 files changed, 201 insertions(+), 6 deletions(-)

diff --git a/nova/api/ec2/cloud.py b/nova/api/ec2/cloud.py
index 64fce0c2b54..cd41921ba24 100644
--- a/nova/api/ec2/cloud.py
+++ b/nova/api/ec2/cloud.py
@@ -42,6 +42,7 @@
 from nova import log as logging
 from nova import network
 from nova import rpc
+from nova import quota
 from nova import utils
 from nova import volume
 from nova.api.ec2 import ec2utils
@@ -856,6 +857,13 @@ def authorize_security_group_ingress(self, context, group_name=None,
                     raise exception.ApiError(_(err) % values_for_rule)
                 postvalues.append(values_for_rule)
 
+        allowed = quota.allowed_security_group_rules(context,
+                                                   security_group['id'],
+                                                   1)
+        if allowed < 1:
+            msg = _(""Quota exceeded, too many security group rules."")
+            raise exception.ApiError(msg)
+
         for values_for_rule in postvalues:
             security_group_rule = db.security_group_rule_create(
                     context,
@@ -908,6 +916,10 @@ def create_security_group(self, context, group_name, group_description):
         if db.security_group_exists(context, context.project_id, group_name):
             raise exception.ApiError(_('group %s already exists') % group_name)
 
+        if quota.allowed_security_groups(context, 1) < 1:
+            msg = _(""Quota exceeded, too many security groups."")
+            raise exception.ApiError(msg)
+
         group = {'user_id': context.user_id,
                  'project_id': context.project_id,
                  'name': group_name,
diff --git a/nova/api/openstack/contrib/quotas.py b/nova/api/openstack/contrib/quotas.py
index 459b71dfdb7..16883269325 100644
--- a/nova/api/openstack/contrib/quotas.py
+++ b/nova/api/openstack/contrib/quotas.py
@@ -40,6 +40,8 @@ def _format_quota_set(self, project_id, quota_set):
             'instances': quota_set['instances'],
             'injected_files': quota_set['injected_files'],
             'cores': quota_set['cores'],
+            'security_groups': quota_set['security_groups'],
+            'security_group_rules': quota_set['security_group_rules'],
         }}
 
     def show(self, req, id):
@@ -56,7 +58,8 @@ def update(self, req, id, body):
         project_id = id
         resources = ['metadata_items', 'injected_file_content_bytes',
                 'volumes', 'gigabytes', 'ram', 'floating_ips', 'instances',
-                'injected_files', 'cores']
+                'injected_files', 'cores', 'security_groups',
+                'security_group_rules']
         for key in body['quota_set'].keys():
             if key in resources:
                 value = int(body['quota_set'][key])
diff --git a/nova/api/openstack/contrib/security_groups.py b/nova/api/openstack/contrib/security_groups.py
index e8f1f2ca680..78d4881251f 100644
--- a/nova/api/openstack/contrib/security_groups.py
+++ b/nova/api/openstack/contrib/security_groups.py
@@ -26,6 +26,7 @@
 from nova import log as logging
 from nova import rpc
 from nova import utils
+from nova import quota
 from nova.api.openstack import common
 from nova.api.openstack import extensions
 from nova.api.openstack import wsgi
@@ -136,6 +137,10 @@ def create(self, req, body):
         group_name = group_name.strip()
         group_description = group_description.strip()
 
+        if quota.allowed_security_groups(context, 1) < 1:
+            msg = _(""Quota exceeded, too many security groups."")
+            raise exc.HTTPBadRequest(explanation=msg)
+
         LOG.audit(_(""Create Security Group %s""), group_name, context=context)
         self.compute_api.ensure_default_security_group(context)
         if db.security_group_exists(context, context.project_id, group_name):
@@ -219,6 +224,13 @@ def create(self, req, body):
             msg = _('This rule already exists in group %s') % parent_group_id
             raise exc.HTTPBadRequest(explanation=msg)
 
+        allowed = quota.allowed_security_group_rules(context,
+                                                   parent_group_id,
+                                                   1)
+        if allowed < 1:
+            msg = _(""Quota exceeded, too many security group rules."")
+            raise exc.HTTPBadRequest(explanation=msg)
+
         security_group_rule = db.security_group_rule_create(context, values)
 
         self.compute_api.trigger_security_group_rules_refresh(context,
diff --git a/nova/db/api.py b/nova/db/api.py
index c0e44d2e7b7..7d241e54ce2 100644
--- a/nova/db/api.py
+++ b/nova/db/api.py
@@ -1098,6 +1098,11 @@ def security_group_destroy_all(context):
     return IMPL.security_group_destroy_all(context)
 
 
+def security_group_count_by_project(context, project_id):
+    """"""Count number of security groups in a project.""""""
+    return IMPL.security_group_count_by_project(context, project_id)
+
+
 ####################
 
 
@@ -1129,6 +1134,11 @@ def security_group_rule_get(context, security_group_rule_id):
     return IMPL.security_group_rule_get(context, security_group_rule_id)
 
 
+def security_group_rule_count_by_group(context, security_group_id):
+    """"""Count rules in a given security group.""""""
+    return IMPL.security_group_rule_count_by_group(context, security_group_id)
+
+
 ###################
 
 
diff --git a/nova/db/sqlalchemy/api.py b/nova/db/sqlalchemy/api.py
index 610858513d6..b06092675f3 100644
--- a/nova/db/sqlalchemy/api.py
+++ b/nova/db/sqlalchemy/api.py
@@ -2803,6 +2803,16 @@ def security_group_destroy_all(context, session=None):
                         'updated_at': literal_column('updated_at')})
 
 
+@require_context
+def security_group_count_by_project(context, project_id):
+    authorize_project_context(context, project_id)
+    session = get_session()
+    return session.query(models.SecurityGroup).\
+                         filter_by(deleted=False).\
+                         filter_by(project_id=project_id).\
+                         count()
+
+
 ###################
 
 
@@ -2884,6 +2894,15 @@ def security_group_rule_destroy(context, security_group_rule_id):
         security_group_rule.delete(session=session)
 
 
+@require_context
+def security_group_rule_count_by_group(context, security_group_id):
+    session = get_session()
+    return session.query(models.SecurityGroupIngressRule).\
+                         filter_by(deleted=False).\
+                         filter_by(parent_group_id=security_group_id).\
+                         count()
+
+
 ###################
 
 
diff --git a/nova/quota.py b/nova/quota.py
index 771477747e0..d491f4a42b1 100644
--- a/nova/quota.py
+++ b/nova/quota.py
@@ -44,6 +44,10 @@
                      'number of bytes allowed per injected file')
 flags.DEFINE_integer('quota_max_injected_file_path_bytes', 255,
                      'number of bytes allowed per injected file path')
+flags.DEFINE_integer('quota_security_groups', 10,
+                     'number of security groups per project')
+flags.DEFINE_integer('quota_security_group_rules', 20,
+                     'number of security rules per security group')
 
 
 def _get_default_quotas():
@@ -58,6 +62,8 @@ def _get_default_quotas():
         'injected_files': FLAGS.quota_max_injected_files,
         'injected_file_content_bytes':
             FLAGS.quota_max_injected_file_content_bytes,
+        'security_groups': FLAGS.quota_security_groups,
+        'security_group_rules': FLAGS.quota_security_group_rules,
     }
     # -1 in the quota flags means unlimited
     for key in defaults.keys():
@@ -134,6 +140,32 @@ def allowed_floating_ips(context, requested_floating_ips):
     return min(requested_floating_ips, allowed_floating_ips)
 
 
+def allowed_security_groups(context, requested_security_groups):
+    """"""Check quota and return min(requested, allowed) security groups.""""""
+    project_id = context.project_id
+    context = context.elevated()
+    used_sec_groups = db.security_group_count_by_project(context, project_id)
+    quota = get_project_quotas(context, project_id)
+    allowed_sec_groups = _get_request_allotment(requested_security_groups,
+                                                  used_sec_groups,
+                                                  quota['security_groups'])
+    return min(requested_security_groups, allowed_sec_groups)
+
+
+def allowed_security_group_rules(context, security_group_id,
+        requested_rules):
+    """"""Check quota and return min(requested, allowed) sec group rules.""""""
+    project_id = context.project_id
+    context = context.elevated()
+    used_rules = db.security_group_rule_count_by_group(context,
+                                                            security_group_id)
+    quota = get_project_quotas(context, project_id)
+    allowed_rules = _get_request_allotment(requested_rules,
+                                              used_rules,
+                                              quota['security_group_rules'])
+    return min(requested_rules, allowed_rules)
+
+
 def _calculate_simple_quota(context, resource, requested):
     """"""Check quota for resource; return min(requested, allowed).""""""
     quota = get_project_quotas(context, context.project_id)
diff --git a/nova/tests/api/openstack/contrib/test_quotas.py b/nova/tests/api/openstack/contrib/test_quotas.py
index e391e5fa091..fe0a165eda2 100644
--- a/nova/tests/api/openstack/contrib/test_quotas.py
+++ b/nova/tests/api/openstack/contrib/test_quotas.py
@@ -29,7 +29,8 @@ def quota_set(id):
     return {'quota_set': {'id': id, 'metadata_items': 128, 'volumes': 10,
             'gigabytes': 1000, 'ram': 51200, 'floating_ips': 10,
             'instances': 10, 'injected_files': 5, 'cores': 20,
-            'injected_file_content_bytes': 10240}}
+            'injected_file_content_bytes': 10240,
+            'security_groups': 10, 'security_group_rules': 20}}
 
 
 def quota_set_list():
@@ -60,7 +61,9 @@ def test_format_quota_set(self):
             'metadata_items': 128,
             'gigabytes': 1000,
             'injected_files': 5,
-            'injected_file_content_bytes': 10240}
+            'injected_file_content_bytes': 10240,
+            'security_groups': 10,
+            'security_group_rules': 20}
 
         quota_set = QuotaSetsController()._format_quota_set('1234',
                                                             raw_quota_set)
@@ -95,7 +98,9 @@ def test_quotas_defaults(self):
                     'floating_ips': 10,
                     'metadata_items': 128,
                     'injected_files': 5,
-                    'injected_file_content_bytes': 10240}}
+                    'injected_file_content_bytes': 10240,
+                    'security_groups': 10,
+                    'security_group_rules': 20}}
 
         self.assertEqual(json.loads(res.body), expected)
 
@@ -123,7 +128,10 @@ def test_quotas_update_as_admin(self):
                              'cores': 50, 'ram': 51200, 'volumes': 10,
                              'gigabytes': 1000, 'floating_ips': 10,
                              'metadata_items': 128, 'injected_files': 5,
-                             'injected_file_content_bytes': 10240}}
+                             'injected_file_content_bytes': 10240,
+                             'security_groups': 40,
+                             'security_group_rules': 80
+                             }}
 
         req = webob.Request.blank('/v1.1/fake/os-quota-sets/update_me')
         req.method = 'PUT'
diff --git a/nova/tests/api/openstack/contrib/test_security_groups.py b/nova/tests/api/openstack/contrib/test_security_groups.py
index d0b25e05655..839f44246e7 100644
--- a/nova/tests/api/openstack/contrib/test_security_groups.py
+++ b/nova/tests/api/openstack/contrib/test_security_groups.py
@@ -22,10 +22,13 @@
 from xml.dom import minidom
 
 from nova import exception
+from nova import flags
 from nova import test
 from nova.api.openstack.contrib import security_groups
 from nova.tests.api.openstack import fakes
 
+FLAGS = flags.FLAGS
+
 
 def _get_create_request_json(body_dict):
     req = webob.Request.blank('/v1.1/fake/os-security-groups')
@@ -257,6 +260,19 @@ def test_create_security_group_non_string_description_json(self):
         response = _create_security_group_json(security_group)
         self.assertEquals(response.status_int, 400)
 
+    def test_create_security_group_quota_limit(self):
+        security_group = {}
+        for num in range(1, FLAGS.quota_security_groups):
+            security_group['name'] = ""test%i"" % num
+            security_group['description'] = ""test%i"" % num
+            response = _create_security_group_json(security_group)
+            self.assertEquals(response.status_int, 200)
+
+        security_group['name'] = ""test_to_many""
+        security_group['description'] = ""test_to_many""
+        response = _create_security_group_json(security_group)
+        self.assertEquals(response.status_int, 400)
+
     def test_get_security_group_list(self):
         security_group = {}
         security_group['name'] = ""test""
@@ -918,6 +934,34 @@ def test_create_rule_with_same_group_parent_id_json(self):
         response = self._create_security_group_rule_json(rules)
         self.assertEquals(response.status_int, 400)
 
+    def test_create_rule_quota_limit(self):
+        #NOTE: subtract 1 because we create 1 rule in setup
+        for num in range(100, (100 + FLAGS.quota_security_group_rules) - 1):
+            rule = {
+                      ""security_group_rule"": {
+                            ""ip_protocol"": ""tcp"",
+                            ""from_port"": num,
+                            ""to_port"": num,
+                            ""parent_group_id"": ""%s""
+                                       % self.parent_security_group['id'],
+                         }
+                      }
+            response = self._create_security_group_rule_json(rule)
+            print response.body
+            self.assertEquals(response.status_int, 200)
+
+        rule = {
+                  ""security_group_rule"": {
+                        ""ip_protocol"": ""tcp"",
+                        ""from_port"": ""121"",
+                        ""to_port"": ""121"",
+                        ""parent_group_id"": ""%s""
+                                   % self.parent_security_group['id'],
+                     }
+                  }
+        response = self._create_security_group_rule_json(rule)
+        self.assertEquals(response.status_int, 400)
+
     def test_delete(self):
         response = self._delete_security_group_rule(
                                   self.security_group_rule['id'])
diff --git a/nova/tests/test_cloud.py b/nova/tests/test_cloud.py
index fa4597422fe..c6fe41b84b4 100644
--- a/nova/tests/test_cloud.py
+++ b/nova/tests/test_cloud.py
@@ -256,6 +256,31 @@ def test_delete_security_group_no_params(self):
         delete = self.cloud.delete_security_group
         self.assertRaises(exception.ApiError, delete, self.context)
 
+    def test_security_group_ingress_quota_limit(self):
+        self.flags(quota_security_group_rules=20)
+        kwargs = {'project_id': self.context.project_id, 'name': 'test'}
+        sec_group = db.security_group_create(self.context, kwargs)
+        authz = self.cloud.authorize_security_group_ingress
+        for i in range(100, 120):
+            kwargs = {'to_port': i, 'from_port': i, 'ip_protocol': 'tcp'}
+            authz(self.context, group_id=sec_group['id'], **kwargs)
+
+        kwargs = {'to_port': 121, 'from_port': 121, 'ip_protocol': 'tcp'}
+        self.assertRaises(exception.ApiError, authz, self.context,
+                              group_id=sec_group['id'], **kwargs)
+
+    def test_security_group_quota_limit(self):
+        self.flags(quota_security_groups=10)
+        for i in range(1, 10):
+            name = 'test name %i' % i
+            descript = 'test description %i' % i
+            create = self.cloud.create_security_group
+            result = create(self.context, name, descript)
+
+        # 11'th group should fail
+        self.assertRaises(exception.ApiError,
+                          create, self.context, 'foo', 'bar')
+
     def test_authorize_security_group_ingress(self):
         kwargs = {'project_id': self.context.project_id, 'name': 'test'}
         sec = db.security_group_create(self.context, kwargs)
diff --git a/nova/tests/test_quota.py b/nova/tests/test_quota.py
index f4b481ebe49..9541a13b26c 100644
--- a/nova/tests/test_quota.py
+++ b/nova/tests/test_quota.py
@@ -43,7 +43,9 @@ def setUp(self):
                    quota_cores=4,
                    quota_volumes=2,
                    quota_gigabytes=20,
-                   quota_floating_ips=1)
+                   quota_floating_ips=1,
+                   quota_security_groups=10,
+                   quota_security_group_rules=20)
 
         self.network = self.network = self.start_service('network')
         self.user_id = 'admin'
@@ -185,6 +187,34 @@ def test_unlimited_floating_ips(self):
         floating_ips = quota.allowed_floating_ips(self.context, 101)
         self.assertEqual(floating_ips, 101)
 
+    def test_unlimited_security_groups(self):
+        self.flags(quota_security_groups=10)
+        security_groups = quota.allowed_security_groups(self.context, 100)
+        self.assertEqual(security_groups, 10)
+        db.quota_create(self.context, self.project_id, 'security_groups', None)
+        security_groups = quota.allowed_security_groups(self.context, 100)
+        self.assertEqual(security_groups, 100)
+        security_groups = quota.allowed_security_groups(self.context, 101)
+        self.assertEqual(security_groups, 101)
+
+    def test_unlimited_security_group_rules(self):
+
+        def fake_security_group_rule_count_by_group(context, sec_group_id):
+            return 0
+
+        self.stubs.Set(db, 'security_group_rule_count_by_group',
+                       fake_security_group_rule_count_by_group)
+
+        self.flags(quota_security_group_rules=20)
+        rules = quota.allowed_security_group_rules(self.context, 1234, 100)
+        self.assertEqual(rules, 20)
+        db.quota_create(self.context, self.project_id, 'security_group_rules',
+                        None)
+        rules = quota.allowed_security_group_rules(self.context, 1234, 100)
+        self.assertEqual(rules, 100)
+        rules = quota.allowed_security_group_rules(self.context, 1234, 101)
+        self.assertEqual(rules, 101)
+
     def test_unlimited_metadata_items(self):
         self.flags(quota_metadata_items=10)
         items = quota.allowed_metadata_items(self.context, 100)"
GHSA-35m5-8cvj-8783,"From e652d56ac60eadfc26489ab83927af13a9b9d8ce Mon Sep 17 00:00:00 2001
From: Morgan-Phoenix <73711602+Morgan-Phoenix@users.noreply.github.com>
Date: Sat, 6 Nov 2021 19:34:45 +0530
Subject: [PATCH] Fixed GHSA-35m5-8cvj-8783

---
 enrocrypt/hashing.py | 5 -----
 1 file changed, 5 deletions(-)

diff --git a/enrocrypt/hashing.py b/enrocrypt/hashing.py
index 275d2e3..14328f0 100644
--- a/enrocrypt/hashing.py
+++ b/enrocrypt/hashing.py
@@ -66,11 +66,6 @@ def SHA244(self,data:str):
         hash = str(sha.digest())
         return self.__Salt(hash,salt=self.salt)
 
-    def MD5(self,data:str):
-        sha = hashlib.md5(bytes(data.encode()))
-        hash = str(sha.digest())
-        return self.__Salt(hash,salt=self.salt)
-
     def SHA384(self,data:str):
         sha = hashlib.sha384(bytes(data.encode()))
         hash = str(sha.digest())"
PYSEC-2017-30,"From b49d0d4b5ca5c6f31f03e2caf97cef1088eeed81 Mon Sep 17 00:00:00 2001
From: Colton Myers <colton.myers@gmail.com>
Date: Wed, 25 Mar 2015 14:29:26 -0600
Subject: [PATCH] Create randomized logfile name in windows for chef.py

---
 salt/modules/chef.py | 15 ++++++++++-----
 1 file changed, 10 insertions(+), 5 deletions(-)

diff --git a/salt/modules/chef.py b/salt/modules/chef.py
index 36eb6ff72de5..9c6d928fc3b9 100644
--- a/salt/modules/chef.py
+++ b/salt/modules/chef.py
@@ -6,6 +6,7 @@
 # Import Python libs
 import logging
 import os
+import tempfile
 
 # Import Salt libs
 import salt.utils
@@ -24,12 +25,16 @@ def __virtual__():
 
 
 def _default_logfile(exe_name):
-
+    '''
+    Retrieve the logfile name
+    '''
     if salt.utils.is_windows():
-        logfile = salt.utils.path_join(
-            os.environ['TMP'],
-            '{0}.log'.format(exe_name)
-        )
+        logfile_tmp = tempfile.NamedTemporaryFile(dir=os.environ['TMP'],
+                                                  prefix=exe_name,
+                                                  suffix='.log',
+                                                  delete=False)
+        logfile = logfile_tmp.name
+        logfile_tmp.close()
     else:
         logfile = salt.utils.path_join(
             '/var/log',"
GHSA-9vg3-cf92-h2h7,"From eeefb784f24c37d5f56a421e1ccc911cace9385e Mon Sep 17 00:00:00 2001
From: ""Bryan D. Payne"" <bdpayne@acm.org>
Date: Fri, 7 Jun 2013 09:34:25 -0700
Subject: [PATCH] Fix memcache encryption middleware

This fixes lp1175367 and lp1175368 by redesigning the memcache crypt
middleware to not do dangerous things. It is forward compatible, but
will invalidate any existing ephemeral encrypted or signed memcache
entries.

Change-Id: Ice8724949a48bfad3b8b7c41b5f50a18a9ad9f42
Signed-off-by: Bryan D. Payne <bdpayne@acm.org>
---
 doc/source/middlewarearchitecture.rst       |  37 ++--
 keystoneclient/middleware/auth_token.py     | 131 ++++++-------
 keystoneclient/middleware/memcache_crypt.py | 197 ++++++++++++--------
 tests/test_auth_token_middleware.py         |  89 ++-------
 tests/test_memcache_crypt.py                |  96 ++++++----
 5 files changed, 277 insertions(+), 273 deletions(-)

diff --git a/doc/source/middlewarearchitecture.rst b/doc/source/middlewarearchitecture.rst
index 803fbd905..894d40dd9 100644
--- a/doc/source/middlewarearchitecture.rst
+++ b/doc/source/middlewarearchitecture.rst
@@ -1,5 +1,5 @@
 ..
-      Copyright 2011-2012 OpenStack, LLC
+      Copyright 2011-2013 OpenStack, LLC
       All Rights Reserved.
 
       Licensed under the Apache License, Version 2.0 (the ""License""); you may
@@ -188,7 +188,8 @@ Configuration Options
   the timeout when validating token by http).
 * ``auth_port``: (optional, default `35357`) the port used to validate tokens
 * ``auth_protocol``: (optional, default `https`)
-* ``auth_uri``: (optional, defaults to `auth_protocol`://`auth_host`:`auth_port`)
+* ``auth_uri``: (optional, defaults to
+  `auth_protocol`://`auth_host`:`auth_port`)
 * ``certfile``: (required, if Keystone server requires client cert)
 * ``keyfile``: (required, if Keystone server requires client cert)  This can be
   the same as the certfile if the certfile includes the private key.
@@ -232,22 +233,24 @@ Memcache Protection
 ===================
 
 When using memcached, we are storing user tokens and token validation
-information into the cache as raw data. Which means anyone who have access
-to the memcache servers can read and modify data stored there. To mitigate
-this risk, ``auth_token`` middleware provides an option to either encrypt
-or authenticate the token data stored in the cache.
-
-* ``memcache_security_strategy``: (optional) if defined, indicate whether token
-  data should be encrypted or authenticated. Acceptable values are ``ENCRYPT``
-  or ``MAC``. If ``ENCRYPT``, token data is encrypted in the cache. If
-  ``MAC``, token data is authenticated (with HMAC) in the cache. If its value
-  is neither ``MAC`` nor ``ENCRYPT``, ``auth_token`` will raise an exception
-  on initialization.
+information into the cache as raw data. Which means that anyone who
+has access to the memcache servers can read and modify data stored
+there. To mitigate this risk, ``auth_token`` middleware provides an
+option to authenticate and optionally encrypt the token data stored in
+the cache.
+
+* ``memcache_security_strategy``: (optional) if defined, indicate
+  whether token data should be authenticated or authenticated and
+  encrypted. Acceptable values are ``MAC`` or ``ENCRYPT``. If ``MAC``,
+  token data is authenticated (with HMAC) in the cache. If
+  ``ENCRYPT``, token data is encrypted and authenticated in the
+  cache. If the value is not one of these options or empty,
+  ``auth_token`` will raise an exception on initialization.
 * ``memcache_secret_key``: (optional, mandatory if
-  ``memcache_security_strategy`` is defined) if defined,
-  a random string to be used for key derivation. If
-  ``memcache_security_strategy`` is defined and ``memcache_secret_key`` is
-  absent, ``auth_token`` will raise an exception on initialization.
+  ``memcache_security_strategy`` is defined) this string is used for
+  key derivation. If ``memcache_security_strategy`` is defined and
+  ``memcache_secret_key`` is absent, ``auth_token`` will raise an
+  exception on initialization.
 
 Exchanging User Information
 ===========================
diff --git a/keystoneclient/middleware/auth_token.py b/keystoneclient/middleware/auth_token.py
index 7e3012cb8..e50f723c8 100644
--- a/keystoneclient/middleware/auth_token.py
+++ b/keystoneclient/middleware/auth_token.py
@@ -222,6 +222,7 @@
 CONF.register_opts(opts, group='keystone_authtoken')
 
 LIST_OF_VERSIONS_TO_ATTEMPT = ['v2.0', 'v3.0']
+CACHE_KEY_TEMPLATE = 'tokens/%s'
 
 
 def will_expire_soon(expiry):
@@ -847,91 +848,81 @@ def _get_header(self, env, key, default=None):
         env_key = self._header_to_env_var(key)
         return env.get(env_key, default)
 
-    def _protect_cache_value(self, token, data):
-        """""" Encrypt or sign data if necessary. """"""
-        try:
-            if self._memcache_security_strategy == 'ENCRYPT':
-                return memcache_crypt.encrypt_data(token,
-                                                   self._memcache_secret_key,
-                                                   data)
-            elif self._memcache_security_strategy == 'MAC':
-                return memcache_crypt.sign_data(token, data)
-            else:
-                return data
-        except:
-            msg = 'Failed to encrypt/sign cache data.'
-            self.LOG.exception(msg)
-            return data
-
-    def _unprotect_cache_value(self, token, data):
-        """""" Decrypt or verify signed data if necessary. """"""
-        if data is None:
-            return data
-
-        try:
-            if self._memcache_security_strategy == 'ENCRYPT':
-                return memcache_crypt.decrypt_data(token,
-                                                   self._memcache_secret_key,
-                                                   data)
-            elif self._memcache_security_strategy == 'MAC':
-                return memcache_crypt.verify_signed_data(token, data)
-            else:
-                return data
-        except:
-            msg = 'Failed to decrypt/verify cache data.'
-            self.LOG.exception(msg)
-            # this should have the same effect as data not found in cache
-            return None
-
-    def _get_cache_key(self, token):
-        """""" Return the cache key.
-
-        Do not use clear token as key if memcache protection is on.
-
-        """"""
-        htoken = token
-        if self._memcache_security_strategy in ('ENCRYPT', 'MAC'):
-            derv_token = token + self._memcache_secret_key
-            htoken = memcache_crypt.hash_data(derv_token)
-        return 'tokens/%s' % htoken
-
-    def _cache_get(self, token):
+    def _cache_get(self, token, ignore_expires=False):
         """"""Return token information from cache.
 
         If token is invalid raise InvalidUserToken
         return token only if fresh (not expired).
         """"""
+
         if self._cache and token:
-            key = self._get_cache_key(token)
-            cached = self._cache.get(key)
-            cached = self._unprotect_cache_value(token, cached)
+            if self._memcache_security_strategy is None:
+                key = CACHE_KEY_TEMPLATE % token
+                serialized = self._cache.get(key)
+            else:
+                keys = memcache_crypt.derive_keys(
+                    token,
+                    self._memcache_secret_key,
+                    self._memcache_security_strategy)
+                cache_key = CACHE_KEY_TEMPLATE % (
+                    memcache_crypt.get_cache_key(keys))
+                raw_cached = self._cache.get(cache_key)
+                try:
+                    # unprotect_data will return None if raw_cached is None
+                    serialized = memcache_crypt.unprotect_data(keys,
+                                                               raw_cached)
+                except Exception:
+                    msg = 'Failed to decrypt/verify cache data'
+                    self.LOG.exception(msg)
+                    # this should have the same effect as data not
+                    # found in cache
+                    serialized = None
+
+            if serialized is None:
+                return None
+
+            # Note that 'invalid' and (data, expires) are the only
+            # valid types of serialized cache entries, so there is not
+            # a collision with json.loads(serialized) == None.
+            cached = json.loads(serialized)
             if cached == 'invalid':
                 self.LOG.debug('Cached Token %s is marked unauthorized', token)
                 raise InvalidUserToken('Token authorization failed')
-            if cached:
-                data, expires = cached
-                if time.time() < float(expires):
-                    self.LOG.debug('Returning cached token %s', token)
-                    return data
-                else:
-                    self.LOG.debug('Cached Token %s seems expired', token)
-
-    def _cache_store(self, token, data, expires=None):
-        """""" Store value into memcache. """"""
-        key = self._get_cache_key(token)
-        data = self._protect_cache_value(token, data)
-        data_to_store = data
-        if expires:
-            data_to_store = (data, expires)
+
+            data, expires = cached
+            if ignore_expires or time.time() < float(expires):
+                self.LOG.debug('Returning cached token %s', token)
+                return data
+            else:
+                self.LOG.debug('Cached Token %s seems expired', token)
+
+    def _cache_store(self, token, data):
+        """""" Store value into memcache.
+
+        data may be the string 'invalid' or a tuple like (data, expires)
+
+        """"""
+        serialized_data = json.dumps(data)
+        if self._memcache_security_strategy is None:
+            cache_key = CACHE_KEY_TEMPLATE % token
+            data_to_store = serialized_data
+        else:
+            keys = memcache_crypt.derive_keys(
+                token,
+                self._memcache_secret_key,
+                self._memcache_security_strategy)
+            cache_key = CACHE_KEY_TEMPLATE % memcache_crypt.get_cache_key(keys)
+            data_to_store = memcache_crypt.protect_data(keys, serialized_data)
+
         # we need to special-case set() because of the incompatibility between
         # Swift MemcacheRing and python-memcached. See
         # https://bugs.launchpad.net/swift/+bug/1095730
         if self._use_keystone_cache:
-            self._cache.set(key,
+            self._cache.set(cache_key,
                             data_to_store,
                             time=self.token_cache_time)
         else:
-            self._cache.set(key,
+            self._cache.set(cache_key,
                             data_to_store,
                             timeout=self.token_cache_time)
 
@@ -959,7 +950,7 @@ def _cache_put(self, token, data, expires):
         """"""
         if self._cache:
                 self.LOG.debug('Storing %s token in memcache', token)
-                self._cache_store(token, data, expires)
+                self._cache_store(token, (data, expires))
 
     def _cache_store_invalid(self, token):
         """"""Store invalid token in cache.""""""
diff --git a/keystoneclient/middleware/memcache_crypt.py b/keystoneclient/middleware/memcache_crypt.py
index 91e261da0..6cadf3ab9 100755
--- a/keystoneclient/middleware/memcache_crypt.py
+++ b/keystoneclient/middleware/memcache_crypt.py
@@ -1,6 +1,6 @@
 # vim: tabstop=4 shiftwidth=4 softtabstop=4
 
-# Copyright 2010-2012 OpenStack LLC
+# Copyright 2010-2013 OpenStack LLC
 #
 # Licensed under the Apache License, Version 2.0 (the ""License"");
 # you may not use this file except in compliance with the License.
@@ -18,33 +18,34 @@
 """"""
 Utilities for memcache encryption and integrity check.
 
-Data is serialized before been encrypted or MACed. Encryption have a
-dependency on the pycrypto. If pycrypto is not available,
-CryptoUnabailableError will be raised.
+Data should be serialized before entering these functions. Encryption
+has a dependency on the pycrypto. If pycrypto is not available,
+CryptoUnavailableError will be raised.
 
-Encrypted data stored in memcache are prefixed with '{ENCRYPT:AES256}'.
-
-MACed data stored in memcache are prefixed with '{MAC:SHA1}'.
+This module will not be called unless signing or encryption is enabled
+in the config. It will always validate signatures, and will decrypt
+data if encryption is enabled. It is not valid to mix protection
+modes.
 
 """"""
 
 import base64
 import functools
 import hashlib
-import json
+import hmac
+import math
 import os
 
-# make sure pycrypt is available
+# make sure pycrypto is available
 try:
     from Crypto.Cipher import AES
 except ImportError:
     AES = None
 
-
-# prefix marker indicating data is HMACed (signed by a secret key)
-MAC_MARKER = '{MAC:SHA1}'
-# prefix marker indicating data is encrypted
-ENCRYPT_MARKER = '{ENCRYPT:AES256}'
+HASH_FUNCTION = hashlib.sha384
+DIGEST_LENGTH = HASH_FUNCTION().digest_size
+DIGEST_SPLIT = DIGEST_LENGTH // 3
+DIGEST_LENGTH_B64 = 4 * int(math.ceil(DIGEST_LENGTH / 3.0))
 
 
 class InvalidMacError(Exception):
@@ -81,77 +82,121 @@ def wrapper(*args, **kwds):
     return wrapper
 
 
-def generate_aes_key(token, secret):
-    """""" Generates and returns a 256 bit AES key, based on sha256 hash. """"""
-    return hashlib.sha256(token + secret).digest()
-
-
-def compute_mac(token, serialized_data):
-    """""" Computes and returns the base64 encoded MAC. """"""
-    return hash_data(serialized_data + token)
+def constant_time_compare(first, second):
+    """""" Returns True if both string inputs are equal, otherwise False
 
+    This function should take a constant amount of time regardless of
+    how many characters in the strings match.
 
-def hash_data(data):
-    """""" Return the base64 encoded SHA1 hash of the data. """"""
-    return base64.b64encode(hashlib.sha1(data).digest())
-
-
-def sign_data(token, data):
-    """""" MAC the data using SHA1. """"""
-    mac_data = {}
-    mac_data['serialized_data'] = json.dumps(data)
-    mac = compute_mac(token, mac_data['serialized_data'])
-    mac_data['mac'] = mac
-    md = MAC_MARKER + base64.b64encode(json.dumps(mac_data))
-    return md
+    """"""
+    if len(first) != len(second):
+        return False
+    result = 0
+    for x, y in zip(first, second):
+        result |= ord(x) ^ ord(y)
+    return result == 0
+
+
+def derive_keys(token, secret, strategy):
+    """""" Derives keys for MAC and ENCRYPTION from the user-provided
+    secret. The resulting keys should be passed to the protect and
+    unprotect functions.
+
+    As suggested by NIST Special Publication 800-108, this uses the
+    first 128 bits from the sha384 KDF for the obscured cache key
+    value, the second 128 bits for the message authentication key and
+    the remaining 128 bits for the encryption key.
+
+    This approach is faster than computing a separate hmac as the KDF
+    for each desired key.
+    """"""
+    digest = hmac.new(secret, token + strategy, HASH_FUNCTION).digest()
+    return {'CACHE_KEY': digest[:DIGEST_SPLIT],
+            'MAC': digest[DIGEST_SPLIT: 2 * DIGEST_SPLIT],
+            'ENCRYPTION': digest[2 * DIGEST_SPLIT:],
+            'strategy': strategy}
 
 
-def verify_signed_data(token, data):
-    """""" Verify data integrity by ensuring MAC is valid. """"""
-    if data.startswith(MAC_MARKER):
-        try:
-            data = data[len(MAC_MARKER):]
-            mac_data = json.loads(base64.b64decode(data))
-            mac = compute_mac(token, mac_data['serialized_data'])
-            if mac != mac_data['mac']:
-                raise InvalidMacError('invalid MAC; expect=%s, actual=%s' %
-                                      (mac_data['mac'], mac))
-            return json.loads(mac_data['serialized_data'])
-        except:
-            raise InvalidMacError('invalid MAC; data appeared to be corrupted')
-    else:
-        # doesn't appear to be MACed data
-        return data
+def sign_data(key, data):
+    """""" Sign the data using the defined function and the derived key""""""
+    mac = hmac.new(key, data, HASH_FUNCTION).digest()
+    return base64.b64encode(mac)
 
 
 @assert_crypto_availability
-def encrypt_data(token, secret, data):
-    """""" Encryptes the data with the given secret key. """"""
+def encrypt_data(key, data):
+    """""" Encrypt the data with the given secret key.
+
+    Padding is n bytes of the value n, where 1 <= n <= blocksize.
+    """"""
     iv = os.urandom(16)
-    aes_key = generate_aes_key(token, secret)
-    cipher = AES.new(aes_key, AES.MODE_CFB, iv)
-    data = json.dumps(data)
-    encoded_data = base64.b64encode(iv + cipher.encrypt(data))
-    encoded_data = ENCRYPT_MARKER + encoded_data
-    return encoded_data
+    cipher = AES.new(key, AES.MODE_CBC, iv)
+    padding = 16 - len(data) % 16
+    return iv + cipher.encrypt(data + chr(padding) * padding)
 
 
 @assert_crypto_availability
-def decrypt_data(token, secret, data):
+def decrypt_data(key, data):
     """""" Decrypt the data with the given secret key. """"""
-    if data.startswith(ENCRYPT_MARKER):
-        try:
-            # encrypted data
-            encoded_data = data[len(ENCRYPT_MARKER):]
-            aes_key = generate_aes_key(token, secret)
-            decoded_data = base64.b64decode(encoded_data)
-            iv = decoded_data[:16]
-            encrypted_data = decoded_data[16:]
-            cipher = AES.new(aes_key, AES.MODE_CFB, iv)
-            decrypted_data = cipher.decrypt(encrypted_data)
-            return json.loads(decrypted_data)
-        except:
-            raise DecryptError('data appeared to be corrupted')
-    else:
-        # doesn't appear to be encrypted data
-        return data
+    iv = data[:16]
+    cipher = AES.new(key, AES.MODE_CBC, iv)
+    try:
+        result = cipher.decrypt(data[16:])
+    except Exception:
+        raise DecryptError('Encrypted data appears to be corrupted.')
+
+    # Strip the last n padding bytes where n is the last value in
+    # the plaintext
+    padding = ord(result[-1])
+    return result[:-1 * padding]
+
+
+def protect_data(keys, data):
+    """""" Given keys and serialized data, returns an appropriately
+    protected string suitable for storage in the cache.
+
+    """"""
+    if keys['strategy'] == 'ENCRYPT':
+        data = encrypt_data(keys['ENCRYPTION'], data)
+
+    encoded_data = base64.b64encode(data)
+
+    signature = sign_data(keys['MAC'], encoded_data)
+    return signature + encoded_data
+
+
+def unprotect_data(keys, signed_data):
+    """""" Given keys and cached string data, verifies the signature,
+    decrypts if necessary, and returns the original serialized data.
+
+    """"""
+    # cache backends return None when no data is found. We don't mind
+    # that this particular special value is unsigned.
+    if signed_data is None:
+        return None
+
+    # First we calculate the signature
+    provided_mac = signed_data[:DIGEST_LENGTH_B64]
+    calculated_mac = sign_data(
+        keys['MAC'],
+        signed_data[DIGEST_LENGTH_B64:])
+
+    # Then verify that it matches the provided value
+    if not constant_time_compare(provided_mac, calculated_mac):
+        raise InvalidMacError('Invalid MAC; data appears to be corrupted.')
+
+    data = base64.b64decode(signed_data[DIGEST_LENGTH_B64:])
+
+    # then if necessary decrypt the data
+    if keys['strategy'] == 'ENCRYPT':
+        data = decrypt_data(keys['ENCRYPTION'], data)
+
+    return data
+
+
+def get_cache_key(keys):
+    """""" Given keys generated by derive_keys(), returns a base64
+    encoded value suitable for use as a cache key in memcached.
+
+    """"""
+    return base64.b64encode(keys['CACHE_KEY'])
diff --git a/tests/test_auth_token_middleware.py b/tests/test_auth_token_middleware.py
index 06054d088..a4285043c 100644
--- a/tests/test_auth_token_middleware.py
+++ b/tests/test_auth_token_middleware.py
@@ -28,7 +28,6 @@
 from keystoneclient.common import cms
 from keystoneclient import utils
 from keystoneclient.middleware import auth_token
-from keystoneclient.middleware import memcache_crypt
 from keystoneclient.openstack.common import memorycache
 from keystoneclient.openstack.common import jsonutils
 from keystoneclient.openstack.common import timeutils
@@ -1013,9 +1012,7 @@ def test_request_blank_token(self):
     def _get_cached_token(self, token):
         token_id = cms.cms_hash_token(token)
         # NOTE(vish): example tokens are expired so skip the expiration check.
-        key = self.middleware._get_cache_key(token_id)
-        cached = self.middleware._cache.get(key)
-        return self.middleware._unprotect_cache_value(token, cached)
+        return self.middleware._cache_get(token_id, ignore_expires=True)
 
     def test_memcache(self):
         req = webob.Request.blank('/')
@@ -1036,7 +1033,8 @@ def test_memcache_set_invalid(self):
         token = 'invalid-token'
         req.headers['X-Auth-Token'] = token
         self.middleware(req.environ, self.start_fake_response)
-        self.assertEqual(self._get_cached_token(token), ""invalid"")
+        self.assertRaises(auth_token.InvalidUserToken,
+                          self._get_cached_token, token)
 
     def test_memcache_set_expired(self):
         token_cache_time = 10
@@ -1096,18 +1094,11 @@ def test_encrypt_cache_data(self):
             'memcache_secret_key': 'mysecret'
         }
         self.set_middleware(conf=conf)
-        encrypted_data = self.middleware._protect_cache_value(
-            'token', TOKEN_RESPONSES[self.token_dict['uuid_token_default']])
-        self.assertEqual('{ENCRYPT:AES256}', encrypted_data[:16])
-        self.assertEqual(
-            TOKEN_RESPONSES[self.token_dict['uuid_token_default']],
-            self.middleware._unprotect_cache_value('token', encrypted_data))
-        # should return None if unable to decrypt
-        self.assertIsNone(
-            self.middleware._unprotect_cache_value(
-                'token', '{ENCRYPT:AES256}corrupted'))
-        self.assertIsNone(
-            self.middleware._unprotect_cache_value('mykey', encrypted_data))
+        token = 'my_token'
+        data = ('this_data', 10e100)
+        self.middleware._init_cache({})
+        self.middleware._cache_store(token, data)
+        self.assertEqual(self.middleware._cache_get(token), data[0])
 
     def test_sign_cache_data(self):
         conf = {
@@ -1119,19 +1110,11 @@ def test_sign_cache_data(self):
             'memcache_secret_key': 'mysecret'
         }
         self.set_middleware(conf=conf)
-        signed_data = self.middleware._protect_cache_value(
-            'mykey', TOKEN_RESPONSES[self.token_dict['uuid_token_default']])
-        expected = '{MAC:SHA1}'
-        self.assertEqual(
-            signed_data[:10],
-            expected)
-        self.assertEqual(
-            TOKEN_RESPONSES[self.token_dict['uuid_token_default']],
-            self.middleware._unprotect_cache_value('mykey', signed_data))
-        # should return None on corrupted data
-        self.assertIsNone(
-            self.middleware._unprotect_cache_value('mykey',
-                                                   '{MAC:SHA1}corrupted'))
+        token = 'my_token'
+        data = ('this_data', 10e100)
+        self.middleware._init_cache({})
+        self.middleware._cache_store(token, data)
+        self.assertEqual(self.middleware._cache_get(token), data[0])
 
     def test_no_memcache_protection(self):
         conf = {
@@ -1142,47 +1125,11 @@ def test_no_memcache_protection(self):
             'memcache_secret_key': 'mysecret'
         }
         self.set_middleware(conf=conf)
-        data = self.middleware._protect_cache_value('mykey',
-                                                    'This is a test!')
-        self.assertEqual(data, 'This is a test!')
-        self.assertEqual(
-            'This is a test!',
-            self.middleware._unprotect_cache_value('mykey', data))
-
-    def test_get_cache_key(self):
-        conf = {
-            'auth_host': 'keystone.example.com',
-            'auth_port': 1234,
-            'auth_admin_prefix': '/testadmin',
-            'memcache_servers': ['localhost:11211'],
-            'memcache_secret_key': 'mysecret'
-        }
-        self.set_middleware(conf=conf)
-        self.assertEqual(
-            'tokens/mytoken',
-            self.middleware._get_cache_key('mytoken'))
-        conf = {
-            'auth_host': 'keystone.example.com',
-            'auth_port': 1234,
-            'auth_admin_prefix': '/testadmin',
-            'memcache_servers': ['localhost:11211'],
-            'memcache_security_strategy': 'mac',
-            'memcache_secret_key': 'mysecret'
-        }
-        self.set_middleware(conf=conf)
-        expected = 'tokens/' + memcache_crypt.hash_data('mytoken' + 'mysecret')
-        self.assertEqual(self.middleware._get_cache_key('mytoken'), expected)
-        conf = {
-            'auth_host': 'keystone.example.com',
-            'auth_port': 1234,
-            'auth_admin_prefix': '/testadmin',
-            'memcache_servers': ['localhost:11211'],
-            'memcache_security_strategy': 'Encrypt',
-            'memcache_secret_key': 'abc!'
-        }
-        self.set_middleware(conf=conf)
-        expected = 'tokens/' + memcache_crypt.hash_data('mytoken' + 'abc!')
-        self.assertEqual(self.middleware._get_cache_key('mytoken'), expected)
+        token = 'my_token'
+        data = ('this_data', 10e100)
+        self.middleware._init_cache({})
+        self.middleware._cache_store(token, data)
+        self.assertEqual(self.middleware._cache_get(token), data[0])
 
     def test_assert_valid_memcache_protection_config(self):
         # test missing memcache_secret_key
diff --git a/tests/test_memcache_crypt.py b/tests/test_memcache_crypt.py
index b2281d935..524cd21da 100644
--- a/tests/test_memcache_crypt.py
+++ b/tests/test_memcache_crypt.py
@@ -4,48 +4,66 @@
 
 
 class MemcacheCryptPositiveTests(testtools.TestCase):
-    def test_generate_aes_key(self):
-        self.assertEqual(
-            len(memcache_crypt.generate_aes_key('Gimme Da Key', 'hush')), 32)
+    def _setup_keys(self, strategy):
+        return memcache_crypt.derive_keys('token', 'secret', strategy)
 
-    def test_compute_mac(self):
-        self.assertEqual(
-            memcache_crypt.compute_mac('mykey', 'This is a test!'),
-            'tREu41yR5tEgeBWIuv9ag4AeKA8=')
+    def test_constant_time_compare(self):
+        # make sure it works as a compare, the ""constant time"" aspect
+        # isn't appropriate to test in unittests
+        ctc = memcache_crypt.constant_time_compare
+        self.assertTrue(ctc('abcd', 'abcd'))
+        self.assertTrue(ctc('', ''))
+        self.assertFalse(ctc('abcd', 'efgh'))
+        self.assertFalse(ctc('abc', 'abcd'))
+        self.assertFalse(ctc('abc', 'abc\x00'))
+        self.assertFalse(ctc('', 'abc'))
+
+    def test_derive_keys(self):
+        keys = memcache_crypt.derive_keys('token', 'secret', 'strategy')
+        self.assertEqual(len(keys['ENCRYPTION']),
+                         len(keys['CACHE_KEY']))
+        self.assertEqual(len(keys['CACHE_KEY']),
+                         len(keys['MAC']))
+        self.assertNotEqual(keys['ENCRYPTION'],
+                            keys['MAC'])
+        self.assertIn('strategy', keys.keys())
+
+    def test_key_strategy_diff(self):
+        k1 = self._setup_keys('MAC')
+        k2 = self._setup_keys('ENCRYPT')
+        self.assertNotEqual(k1, k2)
 
     def test_sign_data(self):
-        expected = '{MAC:SHA1}eyJtYWMiOiAiM0FrQmdPZHRybGo1RFFESHA1eUxqcDVq' +\
-                   'Si9BPSIsICJzZXJpYWxpemVkX2RhdGEiOiAiXCJUaGlzIGlzIGEgdG' +\
-                   'VzdCFcIiJ9'
-        self.assertEqual(
-            memcache_crypt.sign_data('mykey', 'This is a test!'),
-            expected)
-
-    def test_verify_signed_data(self):
-        signed = memcache_crypt.sign_data('mykey', 'Testz')
-        self.assertEqual(
-            memcache_crypt.verify_signed_data('mykey', signed),
-            'Testz')
-        self.assertEqual(
-            memcache_crypt.verify_signed_data('aasSFWE13WER', 'not MACed'),
-            'not MACed')
-
-    def test_encrypt_data(self):
-        expected = '{ENCRYPT:AES256}'
-        self.assertEqual(
-            memcache_crypt.encrypt_data('mykey', 'mysecret',
-                                        'This is a test!')[:16],
-            expected)
-
-    def test_decrypt_data(self):
-        encrypted = memcache_crypt.encrypt_data('mykey', 'mysecret', 'Testz')
-        self.assertEqual(
-            memcache_crypt.decrypt_data('mykey', 'mysecret', encrypted),
-            'Testz')
-        self.assertEqual(
-            memcache_crypt.decrypt_data('mykey', 'mysecret',
-                                        'Not Encrypted!'),
-            'Not Encrypted!')
+        keys = self._setup_keys('MAC')
+        sig = memcache_crypt.sign_data(keys['MAC'], 'data')
+        self.assertEqual(len(sig), memcache_crypt.DIGEST_LENGTH_B64)
+
+    def test_encryption(self):
+        keys = self._setup_keys('ENCRYPT')
+        # what you put in is what you get out
+        for data in ['data', '1234567890123456', '\x00\xFF' * 13
+                     ] + [chr(x % 256) * x for x in range(768)]:
+            crypt = memcache_crypt.encrypt_data(keys['ENCRYPTION'], data)
+            decrypt = memcache_crypt.decrypt_data(keys['ENCRYPTION'], crypt)
+            self.assertEqual(data, decrypt)
+            self.assertRaises(memcache_crypt.DecryptError,
+                              memcache_crypt.decrypt_data,
+                              keys['ENCRYPTION'], crypt[:-1])
+
+    def test_protect_wrappers(self):
+        data = 'My Pretty Little Data'
+        for strategy in ['MAC', 'ENCRYPT']:
+            keys = self._setup_keys(strategy)
+            protected = memcache_crypt.protect_data(keys, data)
+            self.assertNotEqual(protected, data)
+            if strategy == 'ENCRYPT':
+                self.assertNotIn(data, protected)
+            unprotected = memcache_crypt.unprotect_data(keys, protected)
+            self.assertEqual(data, unprotected)
+            self.assertRaises(memcache_crypt.InvalidMacError,
+                              memcache_crypt.unprotect_data,
+                              keys, protected[:-1])
+            self.assertIsNone(memcache_crypt.unprotect_data(keys, None))
 
     def test_no_pycrypt(self):
         aes = memcache_crypt.AES"
CVE-2018-7889,"From aeb5b036a0bf657951756688b3c72bd68b6e4a7d Mon Sep 17 00:00:00 2001
From: Kovid Goyal <kovid@kovidgoyal.net>
Date: Wed, 7 Mar 2018 10:05:56 +0530
Subject: [PATCH] E-book viewer: Change the file format used to import/export
 bookmarks to use JSON. This prevents malicious bookmarks files from causing
 code execution.

Also more work on the EM page for the server.
---
 src/calibre/gui2/viewer/bookmarkmanager.py | 18 ++---
 src/calibre/srv/code.py                    |  4 +-
 src/pyj/book_list/edit_metadata.pyj        | 80 ++++++++++++++++++++--
 3 files changed, 87 insertions(+), 15 deletions(-)

diff --git a/src/calibre/gui2/viewer/bookmarkmanager.py b/src/calibre/gui2/viewer/bookmarkmanager.py
index 1a1c60dc6696..708976d619f7 100644
--- a/src/calibre/gui2/viewer/bookmarkmanager.py
+++ b/src/calibre/gui2/viewer/bookmarkmanager.py
@@ -6,7 +6,7 @@
 __license__ = 'GPL v3'
 __copyright__ = '2013, Kovid Goyal <kovid at kovidgoyal.net>'
 
-import cPickle
+import json
 
 from PyQt5.Qt import (
     Qt, QListWidget, QListWidgetItem, QItemSelectionModel, QAction,
@@ -186,10 +186,10 @@ def pos_key(b):
         self.edited.emit(bm)
 
     def bm_to_item(self, bm):
-        return bytearray(cPickle.dumps(bm, -1))
+        return bm.copy()
 
     def item_to_bm(self, item):
-        return cPickle.loads(bytes(item.data(Qt.UserRole)))
+        return item.data(Qt.UserRole).copy()
 
     def get_bookmarks(self):
         return list(self)
@@ -197,21 +197,21 @@ def get_bookmarks(self):
     def export_bookmarks(self):
         filename = choose_save_file(
             self, 'export-viewer-bookmarks', _('Export bookmarks'),
-            filters=[(_('Saved bookmarks'), ['pickle'])], all_files=False, initial_filename='bookmarks.pickle')
+            filters=[(_('Saved bookmarks'), ['calibre-bookmarks'])], all_files=False, initial_filename='bookmarks.calibre-bookmarks')
         if filename:
-            with open(filename, 'wb') as fileobj:
-                cPickle.dump(self.get_bookmarks(), fileobj, -1)
+            with lopen(filename, 'wb') as fileobj:
+                fileobj.write(json.dumps(self.get_bookmarks(), indent=True))
 
     def import_bookmarks(self):
         files = choose_files(self, 'export-viewer-bookmarks', _('Import bookmarks'),
-            filters=[(_('Saved bookmarks'), ['pickle'])], all_files=False, select_only_single_file=True)
+            filters=[(_('Saved bookmarks'), ['calibre-bookmarks'])], all_files=False, select_only_single_file=True)
         if not files:
             return
         filename = files[0]
 
         imported = None
-        with open(filename, 'rb') as fileobj:
-            imported = cPickle.load(fileobj)
+        with lopen(filename, 'rb') as fileobj:
+            imported = json.load(fileobj)
 
         if imported is not None:
             bad = False
diff --git a/src/calibre/srv/code.py b/src/calibre/srv/code.py
index 4e585e24d1b4..96b29fec05e3 100644
--- a/src/calibre/srv/code.py
+++ b/src/calibre/srv/code.py
@@ -26,7 +26,7 @@
 from calibre.srv.routes import endpoint, json
 from calibre.srv.utils import get_library_data, get_use_roman
 from calibre.utils.config import prefs, tweaks
-from calibre.utils.icu import sort_key
+from calibre.utils.icu import sort_key, numeric_sort_key
 from calibre.utils.localization import get_lang
 from calibre.utils.search_query_parser import ParseException
 
@@ -393,4 +393,4 @@ def field_names(ctx, rd, field):
     Optional: ?library_id=<default library>
     '''
     db, library_id = get_library_data(ctx, rd)[:2]
-    return tuple(db.all_field_names(field))
+    return tuple(sorted(db.all_field_names(field), key=numeric_sort_key))
diff --git a/src/pyj/book_list/edit_metadata.pyj b/src/pyj/book_list/edit_metadata.pyj
index 99498731b7c4..d4987d21a9fe 100644
--- a/src/pyj/book_list/edit_metadata.pyj
+++ b/src/pyj/book_list/edit_metadata.pyj
@@ -15,6 +15,7 @@ from book_list.library_data import (
     loaded_book_ids, set_book_metadata
 )
 from book_list.router import back
+from book_list.theme import get_color
 from book_list.top_bar import create_top_bar, set_title
 from book_list.ui import set_panel_handler, show_panel
 from date import format_date
@@ -39,6 +40,11 @@ add_extra_css(def():
     style += build_rule(sel + 'table.metadata td', padding_bottom='0.5ex', padding_top='0.5ex', cursor='pointer')
     style += build_rule(sel + 'table.metadata tr:hover', color='red')
     style += build_rule(sel + 'table.metadata tr:active', transform='scale(1.5)')
+
+    style += build_rule(sel + '.completions', display='flex', flex_wrap='wrap', align_items='center')
+    style += build_rule(sel + '.completions > div', margin='0.5ex 0.5rem', margin_left='0', padding='0.5ex 0.5rem', border='solid 1px currentColor', border_radius='1ex', cursor='pointer')
+    style += build_rule(sel + '.completions > div:active', transform='scale(1.5)')
+    style += build_rule(sel + '.completions > div:hover', background=get_color('window-foreground'), color=get_color('window-background'))
     return style
 )
 
@@ -114,21 +120,83 @@ def simple_line_edit(container_id, book_id, field, fm, div, mi):
         return x
 
 
+def add_completion(container_id, name):
+    pass
+
+
+def show_completions(container_id, div, field, prefix, names):
+    clear(div)
+    completions = E.div(class_='completions')
+    div.appendChild(completions)
+    for i, name in enumerate(names):
+        completions.appendChild(E.div(name, onclick=add_completion.bind(None, container_id, name)))
+        if i >= 50:
+            break
+
+
+def update_completions(container_id, ok, field, names):
+    c = document.getElementById(container_id)
+    if not c:
+        return
+    d = c.querySelector('div[data-ctype=""edit""]')
+    if not d or d.style.display is not 'block':
+        return
+    div = d.lastChild
+    clear(div)
+    if not ok:
+        err = E.div()
+        safe_set_inner_html(err, names)
+        div.appendChild(E.div(
+            _('Failed to download items for completion, with error:'), err
+        ))
+        return
+    val = d.querySelector('input').value or ''
+    val = value_to_json(val)
+    if jstype(val) is 'string':
+        prefix = val
+    else:
+        prefix = val[-1] if val.length else ''
+    if prefix is update_completions.prefix:
+        return
+    pl = prefix.toLowerCase().strip()
+    if pl:
+        if pl.startswith(update_completions.prefix.toLowerCase()):
+            matching_names = [x for x in update_completions.names if x.toLowerCase().startswith(pl)]
+        else:
+            matching_names = [x for x in names if x.toLowerCase().startswith(pl)]
+    else:
+        matching_names = []
+    update_completions.prefix = prefix
+    update_completions.names = matching_names
+    show_completions(container_id, div, field, prefix, matching_names)
+
+
+update_completions.ui_to_list = None
+update_completions.list_to_ui = None
+update_completions.names = v'[]'
+update_completions.prefix = ''
+
+
+def line_edit_updated(container_id, field):
+    field_names_for(field, update_completions.bind(None, container_id))
+
+
 def multiple_line_edit(list_to_ui, ui_to_list, container_id, book_id, field, fm, div, mi):
     nonlocal value_to_json
+    update_completions.ui_to_list = ui_to_list
+    update_completions.list_to_ui = list_to_ui
     name = fm.name or field
-    le = E.input(type='text', name=name.replace('#', '_c_'), autocomplete=True)
+    le = E.input(type='text', name=name.replace('#', '_c_'), autocomplete=True, oninput=line_edit_updated.bind(None, container_id, field))
     le.value = (resolved_metadata(mi, field) or v'[]').join(list_to_ui)
     form = create_form(le, line_edit_get_value, container_id, book_id, field)
     div.appendChild(E.div(style='margin: 0.5ex 1rem', _(
         'Edit the ""{0}"" below. Multiple items can be separated by {1}.').format(name, list_to_ui.strip())))
     div.appendChild(E.div(style='margin: 0.5ex 1rem', form))
-    div.appendChild(E.div(style='margin: 0.5ex 1rem'))
+    div.appendChild(E.div(E.span(_('Loading all {}...').format(name)), style='margin: 0.5ex 1rem'))
     le.focus(), le.select()
     value_to_json = def(x):
         return [a.strip() for a in x.split(ui_to_list) if a.strip()]
-    div.lastChild.appendChild(E.span(_('Loading all {}...').format(name)))
-    field_names_for(field, print)
+    field_names_for(field, update_completions.bind(None, container_id))
 
 
 def edit_field(container_id, book_id, field):
@@ -142,6 +210,10 @@ def edit_field(container_id, book_id, field):
     d.style.display = 'block'
     d.previousSibling.style.display = 'none'
     clear(d)
+    update_completions.ui_to_list = None
+    update_completions.list_to_ui = None
+    update_completions.names = v'[]'
+    update_completions.prefix = ''
     if field is 'authors':
         multiple_line_edit(' & ', '&', container_id, book_id, field, fm, d, mi)
     else:"
PYSEC-2014-78,"From 77a68c03cd619a0996f3f37337b8c39ca6643d6e Mon Sep 17 00:00:00 2001
From: Christian Hammond <chipx86@chipx86.com>
Date: Fri, 6 Jun 2014 01:28:03 -0700
Subject: [PATCH] Fix a XSS vulnerability with bad input to json_dumps.

Django's JSON serialization does not handle escaping of any characters
to make them safe for injecting into HTML. This allows an attacker who
can provide part of a JSON-serializable object to craft a string that
can break out of a <script> tag and create its own, injecting a custom
script.

To fix this, we escape '<', '>', and '&' characters in the resulting
string, preventing a </script> from executing.
---
 djblets/util/templatetags/djblets_js.py |  9 ++++++++-
 djblets/util/templatetags/tests.py      | 19 +++++++++++++++++++
 2 files changed, 27 insertions(+), 1 deletion(-)
 create mode 100644 djblets/util/templatetags/tests.py

diff --git a/djblets/util/templatetags/djblets_js.py b/djblets/util/templatetags/djblets_js.py
index 5cb5449b..ae9bff85 100644
--- a/djblets/util/templatetags/djblets_js.py
+++ b/djblets/util/templatetags/djblets_js.py
@@ -31,6 +31,7 @@
 from django.core.serializers import serialize
 from django.db.models.query import QuerySet
 from django.utils import six
+from django.utils.encoding import force_text
 from django.utils.safestring import mark_safe
 
 from djblets.util.serializers import DjbletsJSONEncoder
@@ -38,6 +39,12 @@
 
 register = template.Library()
 
+_safe_js_escapes = {
+    ord('&'): '\\u0026',
+    ord('<'): '\\u003C',
+    ord('>'): '\\u003E',
+}
+
 
 @register.simple_tag
 def form_dialog_fields(form):
@@ -75,7 +82,7 @@ def json_dumps(value, indent=None):
     else:
         result = json.dumps(value, indent=indent, cls=DjbletsJSONEncoder)
 
-    return mark_safe(result)
+    return mark_safe(force_text(result).translate(_safe_js_escapes))
 
 
 @register.filter
diff --git a/djblets/util/templatetags/tests.py b/djblets/util/templatetags/tests.py
new file mode 100644
index 00000000..e5281f97
--- /dev/null
+++ b/djblets/util/templatetags/tests.py
@@ -0,0 +1,19 @@
+from __future__ import unicode_literals
+
+from djblets.testing.testcases import TestCase
+from djblets.util.templatetags.djblets_js import json_dumps
+
+
+class JSTagTests(TestCase):
+    """"""Unit tests for djblets_js template tags.""""""
+    def test_json_dumps_xss(self):
+        """"""Testing json_dumps doesn't allow XSS injection""""""
+        # This is bug 3406.
+        obj = {
+            'xss': '</script><script>alert(1);</script>'
+        }
+
+        self.assertEqual(
+            json_dumps(obj),
+            '{""xss"": ""\\u003C/script\\u003E\\u003Cscript\\u003E'
+            'alert(1);\\u003C/script\\u003E""}')"
PYSEC-2020-213,"From 1c36307463b1e8affae100bf9386948e6c1b2308 Mon Sep 17 00:00:00 2001
From: Ben Darnell <ben@bendarnell.com>
Date: Mon, 26 May 2014 15:44:58 -0400
Subject: [PATCH] Change the xsrf cookie format to be masked with a random
 salt.

This protects against the BREACH attack.
---
 tornado/test/web_test.py       |  6 ++--
 tornado/test/websocket_test.py |  3 +-
 tornado/util.py                | 43 +++++++++++++++++++++++++
 tornado/web.py                 | 59 +++++++++++++++++++++++++++++-----
 tornado/websocket.py           | 43 +------------------------
 5 files changed, 101 insertions(+), 53 deletions(-)

diff --git a/tornado/test/web_test.py b/tornado/test/web_test.py
index 7e4fa3133c..2c85bfb01f 100644
--- a/tornado/test/web_test.py
+++ b/tornado/test/web_test.py
@@ -2004,16 +2004,18 @@ def test_cross_user(self):
 
     def test_refresh_token(self):
         token = self.xsrf_token
+        tokens_seen = set([token])
         # A user's token is stable over time.  Refreshing the page in one tab
         # might update the cookie while an older tab still has the old cookie
         # in its DOM.  Simulate this scenario by passing a constant token
         # in the body and re-querying for the token.
         for i in range(5):
             token = self.get_token(token)
-            # Implementation detail: the same token is returned each time
-            self.assertEqual(token, self.xsrf_token)
+            # Tokens are encoded uniquely each time
+            tokens_seen.add(token)
             response = self.fetch(
                 ""/"", method=""POST"",
                 body=urllib_parse.urlencode(dict(_xsrf=self.xsrf_token)),
                 headers=self.cookie_headers(token))
             self.assertEqual(response.code, 200)
+        self.assertEqual(len(tokens_seen), 6)
diff --git a/tornado/test/websocket_test.py b/tornado/test/websocket_test.py
index 01fee72b28..3233e59df8 100644
--- a/tornado/test/websocket_test.py
+++ b/tornado/test/websocket_test.py
@@ -11,6 +11,7 @@
 
 try:
     import tornado.websocket
+    from tornado.util import _websocket_mask_python
 except ImportError:
     # The unittest module presents misleading errors on ImportError
     # (it acts as if websocket_test could not be found, hiding the underlying
@@ -19,7 +20,7 @@
     traceback.print_exc()
     raise
 
-from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError, _websocket_mask_python
+from tornado.websocket import WebSocketHandler, websocket_connect, WebSocketError
 
 try:
     from tornado import speedups
diff --git a/tornado/util.py b/tornado/util.py
index a2fba779ca..05ac4e5fa7 100644
--- a/tornado/util.py
+++ b/tornado/util.py
@@ -12,11 +12,19 @@
 
 from __future__ import absolute_import, division, print_function, with_statement
 
+import array
 import inspect
+import os
 import sys
 import zlib
 
 
+try:
+    xrange  # py2
+except NameError:
+    xrange = range  # py3
+
+
 class ObjectDict(dict):
     """"""Makes a dictionary behave like an object, with attribute-style access.
     """"""
@@ -265,6 +273,41 @@ def replace(self, new_value, args, kwargs):
         return old_value, args, kwargs
 
 
+def _websocket_mask_python(mask, data):
+    """"""Websocket masking function.
+
+    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.
+    Returns a `bytes` object of the same length as `data` with the mask applied
+    as specified in section 5.3 of RFC 6455.
+
+    This pure-python implementation may be replaced by an optimized version when available.
+    """"""
+    mask = array.array(""B"", mask)
+    unmasked = array.array(""B"", data)
+    for i in xrange(len(data)):
+        unmasked[i] = unmasked[i] ^ mask[i % 4]
+    if hasattr(unmasked, 'tobytes'):
+        # tostring was deprecated in py32.  It hasn't been removed,
+        # but since we turn on deprecation warnings in our tests
+        # we need to use the right one.
+        return unmasked.tobytes()
+    else:
+        return unmasked.tostring()
+
+if (os.environ.get('TORNADO_NO_EXTENSION') or
+    os.environ.get('TORNADO_EXTENSION') == '0'):
+    # These environment variables exist to make it easier to do performance
+    # comparisons; they are not guaranteed to remain supported in the future.
+    _websocket_mask = _websocket_mask_python
+else:
+    try:
+        from tornado.speedups import websocket_mask as _websocket_mask
+    except ImportError:
+        if os.environ.get('TORNADO_EXTENSION') == '1':
+            raise
+        _websocket_mask = _websocket_mask_python
+
+
 def doctests():
     import doctest
     return doctest.DocTestSuite()
diff --git a/tornado/web.py b/tornado/web.py
index 1b618a70b7..ed8148e16d 100644
--- a/tornado/web.py
+++ b/tornado/web.py
@@ -72,7 +72,6 @@ def get(self):
 import tornado
 import traceback
 import types
-import uuid
 
 from tornado.concurrent import Future
 from tornado import escape
@@ -82,7 +81,7 @@ def get(self):
 from tornado import stack_context
 from tornado import template
 from tornado.escape import utf8, _unicode
-from tornado.util import bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type
+from tornado.util import bytes_type, import_object, ObjectDict, raise_exc_info, unicode_type, _websocket_mask
 
 try:
     from io import BytesIO  # python 3
@@ -1071,14 +1070,56 @@ def xsrf_token(self):
         See http://en.wikipedia.org/wiki/Cross-site_request_forgery
         """"""
         if not hasattr(self, ""_xsrf_token""):
-            token = self.get_cookie(""_xsrf"")
-            if not token:
-                token = binascii.b2a_hex(os.urandom(16))
+            version, token, timestamp = self._get_raw_xsrf_token()
+            mask = os.urandom(4)
+            self._xsrf_token = b""|"".join([
+                b""2"",
+                binascii.b2a_hex(mask),
+                binascii.b2a_hex(_websocket_mask(mask, token)),
+                utf8(str(int(timestamp)))])
+            if version is None or version != 2:
                 expires_days = 30 if self.current_user else None
-                self.set_cookie(""_xsrf"", token, expires_days=expires_days)
-            self._xsrf_token = token
+                self.set_cookie(""_xsrf"", self._xsrf_token,
+                                expires_days=expires_days)
         return self._xsrf_token
 
+    def _get_raw_xsrf_token(self):
+        if not hasattr(self, '_raw_xsrf_token'):
+            cookie = self.get_cookie(""_xsrf"")
+            if cookie:
+                version, token, timestamp = self._decode_xsrf_token(cookie)
+            else:
+                version, token, timestamp = None, None, None
+            if token is None:
+                version = None
+                token = os.urandom(16)
+                timestamp = time.time()
+            self._raw_xsrf_token = (version, token, timestamp)
+        return self._raw_xsrf_token
+
+    def _decode_xsrf_token(self, cookie):
+        m = _signed_value_version_re.match(utf8(cookie))
+        if m:
+            version = int(m.group(1))
+            if version == 2:
+                _, mask, masked_token, timestamp = cookie.split(""|"")
+                mask = binascii.a2b_hex(utf8(mask))
+                token = _websocket_mask(
+                    mask, binascii.a2b_hex(utf8(masked_token)))
+                timestamp = int(timestamp)
+                return version, token, timestamp
+            else:
+                # Treat unknown versions as not present instead of failing.
+                return None, None, None
+        elif len(cookie) == 32:
+            version = 1
+            token = binascii.a2b_hex(cookie)
+            # We don't have a usable timestamp in older versions.
+            timestamp = int(time.time())
+            return (version, token, timestamp)
+        else:
+            return None, None, None
+
     def check_xsrf_cookie(self):
         """"""Verifies that the ``_xsrf`` cookie matches the ``_xsrf`` argument.
 
@@ -1105,7 +1146,9 @@ def check_xsrf_cookie(self):
                  self.request.headers.get(""X-Csrftoken""))
         if not token:
             raise HTTPError(403, ""'_xsrf' argument missing from POST"")
-        if not _time_independent_equals(utf8(self.xsrf_token), utf8(token)):
+        _, token, _ = self._decode_xsrf_token(token)
+        _, expected_token, _ = self._get_raw_xsrf_token()
+        if not _time_independent_equals(utf8(token), utf8(expected_token)):
             raise HTTPError(403, ""XSRF cookie does not match POST argument"")
 
     def xsrf_form_html(self):
diff --git a/tornado/websocket.py b/tornado/websocket.py
index fda231d0c2..ff78552ce8 100644
--- a/tornado/websocket.py
+++ b/tornado/websocket.py
@@ -20,7 +20,6 @@
 from __future__ import absolute_import, division, print_function, with_statement
 # Author: Jacob Kristhammar, 2010
 
-import array
 import base64
 import collections
 import functools
@@ -39,12 +38,7 @@
 from tornado.log import gen_log, app_log
 from tornado.netutil import Resolver
 from tornado import simple_httpclient
-from tornado.util import bytes_type, unicode_type
-
-try:
-    xrange  # py2
-except NameError:
-    xrange = range  # py3
+from tornado.util import bytes_type, unicode_type, _websocket_mask
 
 
 class WebSocketError(Exception):
@@ -890,38 +884,3 @@ def websocket_connect(url, io_loop=None, callback=None, connect_timeout=None):
     if callback is not None:
         io_loop.add_future(conn.connect_future, callback)
     return conn.connect_future
-
-
-def _websocket_mask_python(mask, data):
-    """"""Websocket masking function.
-
-    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.
-    Returns a `bytes` object of the same length as `data` with the mask applied
-    as specified in section 5.3 of RFC 6455.
-
-    This pure-python implementation may be replaced by an optimized version when available.
-    """"""
-    mask = array.array(""B"", mask)
-    unmasked = array.array(""B"", data)
-    for i in xrange(len(data)):
-        unmasked[i] = unmasked[i] ^ mask[i % 4]
-    if hasattr(unmasked, 'tobytes'):
-        # tostring was deprecated in py32.  It hasn't been removed,
-        # but since we turn on deprecation warnings in our tests
-        # we need to use the right one.
-        return unmasked.tobytes()
-    else:
-        return unmasked.tostring()
-
-if (os.environ.get('TORNADO_NO_EXTENSION') or
-    os.environ.get('TORNADO_EXTENSION') == '0'):
-    # These environment variables exist to make it easier to do performance
-    # comparisons; they are not guaranteed to remain supported in the future.
-    _websocket_mask = _websocket_mask_python
-else:
-    try:
-        from tornado.speedups import websocket_mask as _websocket_mask
-    except ImportError:
-        if os.environ.get('TORNADO_EXTENSION') == '1':
-            raise
-        _websocket_mask = _websocket_mask_python"
CVE-2018-25045,"From 4bb9a3c48427867ef1e46f7dee945a4c25a4f9b8 Mon Sep 17 00:00:00 2001
From: ""Yury V. Zaytsev"" <yury@shurup.com>
Date: Wed, 16 Jan 2019 13:36:25 +0100
Subject: [PATCH] Fix XSS caused by disabled autoescaping in the default DRF
 Browsable API view templates (#6330)

* Add test that verifies that HTML is correctly escaped in Browsable API views

* Fix `urlize_quoted_links` tag to avoid double escaping in autoescape mode

* Fix XSS in default DRF Browsable API template by re-enabling autoescape
---
 .../templates/rest_framework/base.html        |  4 +--
 rest_framework/templatetags/rest_framework.py | 26 +++++++++----------
 tests/test_templatetags.py                    | 13 ++++++++--
 3 files changed, 26 insertions(+), 17 deletions(-)

diff --git a/rest_framework/templates/rest_framework/base.html b/rest_framework/templates/rest_framework/base.html
index 26395e1fdc..688fd23104 100644
--- a/rest_framework/templates/rest_framework/base.html
+++ b/rest_framework/templates/rest_framework/base.html
@@ -171,10 +171,10 @@ <h1>{{ name }}</h1>
               </div>
 
               <div class=""response-info"" aria-label=""{% trans ""response info"" %}"">
-                <pre class=""prettyprint""><span class=""meta nocode""><b>HTTP {{ response.status_code }} {{ response.status_text }}</b>{% autoescape off %}{% for key, val in response_headers|items %}
+                <pre class=""prettyprint""><span class=""meta nocode""><b>HTTP {{ response.status_code }} {{ response.status_text }}</b>{% for key, val in response_headers|items %}
 <b>{{ key }}:</b> <span class=""lit"">{{ val|break_long_headers|urlize_quoted_links }}</span>{% endfor %}
 
-</span>{{ content|urlize_quoted_links }}</pre>{% endautoescape %}
+</span>{{ content|urlize_quoted_links }}</pre>
               </div>
             </div>
 
diff --git a/rest_framework/templatetags/rest_framework.py b/rest_framework/templatetags/rest_framework.py
index 3923389737..f48675d5eb 100644
--- a/rest_framework/templatetags/rest_framework.py
+++ b/rest_framework/templatetags/rest_framework.py
@@ -336,6 +336,12 @@ def trim_url(x, limit=trim_url_limit):
         return limit is not None and (len(x) > limit and ('%s...' % x[:max(0, limit - 3)])) or x
 
     safe_input = isinstance(text, SafeData)
+
+    # Unfortunately, Django built-in cannot be used here, because escaping
+    # is to be performed on words, which have been forcibly coerced to text
+    def conditional_escape(text):
+        return escape(text) if autoescape and not safe_input else text
+
     words = word_split_re.split(force_text(text))
     for i, word in enumerate(words):
         if '.' in word or '@' in word or ':' in word:
@@ -376,21 +382,15 @@ def trim_url(x, limit=trim_url_limit):
             # Make link.
             if url:
                 trimmed = trim_url(middle)
-                if autoescape and not safe_input:
-                    lead, trail = escape(lead), escape(trail)
-                    url, trimmed = escape(url), escape(trimmed)
+                lead, trail = conditional_escape(lead), conditional_escape(trail)
+                url, trimmed = conditional_escape(url), conditional_escape(trimmed)
                 middle = '<a href=""%s""%s>%s</a>' % (url, nofollow_attr, trimmed)
-                words[i] = mark_safe('%s%s%s' % (lead, middle, trail))
+                words[i] = '%s%s%s' % (lead, middle, trail)
             else:
-                if safe_input:
-                    words[i] = mark_safe(word)
-                elif autoescape:
-                    words[i] = escape(word)
-        elif safe_input:
-            words[i] = mark_safe(word)
-        elif autoescape:
-            words[i] = escape(word)
-    return ''.join(words)
+                words[i] = conditional_escape(word)
+        else:
+            words[i] = conditional_escape(word)
+    return mark_safe(''.join(words))
 
 
 @register.filter
diff --git a/tests/test_templatetags.py b/tests/test_templatetags.py
index 5d4f6a4e3d..45bfd4aeb7 100644
--- a/tests/test_templatetags.py
+++ b/tests/test_templatetags.py
@@ -305,6 +305,15 @@ def test_json_with_url(self):
             '&quot;foo_set&quot;: [\n    &quot;<a href=""http://api/foos/1/"">http://api/foos/1/</a>&quot;\n], '
         self._urlize_dict_check(data)
 
+    def test_template_render_with_autoescape(self):
+        """"""
+        Test that HTML is correctly escaped in Browsable API views.
+        """"""
+        template = Template(""{% load rest_framework %}{{ content|urlize_quoted_links }}"")
+        rendered = template.render(Context({'content': '<script>alert()</script> http://example.com'}))
+        assert rendered == '&lt;script&gt;alert()&lt;/script&gt;' \
+                           ' <a href=""http://example.com"" rel=""nofollow"">http://example.com</a>'
+
     def test_template_render_with_noautoescape(self):
         """"""
         Test if the autoescape value is getting passed to urlize_quoted_links filter.
@@ -312,8 +321,8 @@ def test_template_render_with_noautoescape(self):
         template = Template(""{% load rest_framework %}""
                             ""{% autoescape off %}{{ content|urlize_quoted_links }}""
                             ""{% endautoescape %}"")
-        rendered = template.render(Context({'content': '""http://example.com""'}))
-        assert rendered == '""<a href=""http://example.com"" rel=""nofollow"">http://example.com</a>""'
+        rendered = template.render(Context({'content': '<b> ""http://example.com"" </b>'}))
+        assert rendered == '<b> ""<a href=""http://example.com"" rel=""nofollow"">http://example.com</a>"" </b>'
 
 
 @unittest.skipUnless(coreapi, 'coreapi is not installed')"
GHSA-gpvv-69j7-gwj8,"From a4c735b14a62f9cb864533808ac63936704f2ace Mon Sep 17 00:00:00 2001
From: gzpan123 <gzpan123@gmail.com>
Date: Wed, 17 Apr 2019 21:25:45 +0800
Subject: [PATCH] FIX #6413 pip install <url> allow directory traversal

---
 news/6413.bugfix              |  3 ++
 src/pip/_internal/download.py | 31 ++++++++++---
 tests/unit/test_download.py   | 85 +++++++++++++++++++++++++++++++++++
 3 files changed, 114 insertions(+), 5 deletions(-)
 create mode 100644 news/6413.bugfix

diff --git a/news/6413.bugfix b/news/6413.bugfix
new file mode 100644
index 00000000000..68d0a72f64a
--- /dev/null
+++ b/news/6413.bugfix
@@ -0,0 +1,3 @@
+Prevent ``pip install <url>`` from permitting directory traversal if e.g.
+a malicious server sends a ``Content-Disposition`` header with a filename
+containing ``../`` or ``..\\``.
diff --git a/src/pip/_internal/download.py b/src/pip/_internal/download.py
index c98fae5d330..6a54f89400f 100644
--- a/src/pip/_internal/download.py
+++ b/src/pip/_internal/download.py
@@ -66,7 +66,8 @@
            'is_url', 'url_to_path', 'path_to_url',
            'is_archive_file', 'unpack_vcs_link',
            'unpack_file_url', 'is_vcs_url', 'is_file_url',
-           'unpack_http_url', 'unpack_url']
+           'unpack_http_url', 'unpack_url',
+           'parse_content_disposition', 'sanitize_content_filename']
 
 
 logger = logging.getLogger(__name__)
@@ -1050,6 +1051,29 @@ def unpack_url(
         write_delete_marker_file(location)
 
 
+def sanitize_content_filename(filename):
+    # type: (str) -> str
+    """"""
+    Sanitize the ""filename"" value from a Content-Disposition header.
+    """"""
+    return os.path.basename(filename)
+
+
+def parse_content_disposition(content_disposition, default_filename):
+    # type: (str, str) -> str
+    """"""
+    Parse the ""filename"" value from a Content-Disposition header, and
+    return the default filename if the result is empty.
+    """"""
+    _type, params = cgi.parse_header(content_disposition)
+    filename = params.get('filename')
+    if filename:
+        # We need to sanitize the filename to prevent directory traversal
+        # in case the filename contains "".."" path parts.
+        filename = sanitize_content_filename(filename)
+    return filename or default_filename
+
+
 def _download_http_url(
     link,  # type: Link
     session,  # type: PipSession
@@ -1097,10 +1121,7 @@ def _download_http_url(
     # Have a look at the Content-Disposition header for a better guess
     content_disposition = resp.headers.get('content-disposition')
     if content_disposition:
-        type, params = cgi.parse_header(content_disposition)
-        # We use ``or`` here because we don't want to use an ""empty"" value
-        # from the filename param.
-        filename = params.get('filename') or filename
+        filename = parse_content_disposition(content_disposition, filename)
     ext = splitext(filename)[1]
     if not ext:
         ext = mimetypes.guess_extension(content_type)
diff --git a/tests/unit/test_download.py b/tests/unit/test_download.py
index 438ebcb2e10..7baee5e04b4 100644
--- a/tests/unit/test_download.py
+++ b/tests/unit/test_download.py
@@ -12,6 +12,7 @@
 import pip
 from pip._internal.download import (
     CI_ENVIRONMENT_VARIABLES, MultiDomainBasicAuth, PipSession, SafeFileCache,
+    _download_http_url, parse_content_disposition, sanitize_content_filename,
     unpack_file_url, unpack_http_url, url_to_path,
 )
 from pip._internal.exceptions import HashMismatch
@@ -199,6 +200,90 @@ def test_unpack_http_url_bad_downloaded_checksum(mock_unpack_file):
         rmtree(download_dir)
 
 
+@pytest.mark.parametrize(""filename, expected"", [
+    ('dir/file', 'file'),
+    ('../file', 'file'),
+    ('../../file', 'file'),
+    ('../', ''),
+    ('../..', '..'),
+    ('/', ''),
+])
+def test_sanitize_content_filename(filename, expected):
+    """"""
+    Test inputs where the result is the same for Windows and non-Windows.
+    """"""
+    assert sanitize_content_filename(filename) == expected
+
+
+@pytest.mark.parametrize(""filename, win_expected, non_win_expected"", [
+    ('dir\\file', 'file', 'dir\\file'),
+    ('..\\file', 'file', '..\\file'),
+    ('..\\..\\file', 'file', '..\\..\\file'),
+    ('..\\', '', '..\\'),
+    ('..\\..', '..', '..\\..'),
+    ('\\', '', '\\'),
+])
+def test_sanitize_content_filename__platform_dependent(
+    filename,
+    win_expected,
+    non_win_expected
+):
+    """"""
+    Test inputs where the result is different for Windows and non-Windows.
+    """"""
+    if sys.platform == 'win32':
+        expected = win_expected
+    else:
+        expected = non_win_expected
+    assert sanitize_content_filename(filename) == expected
+
+
+@pytest.mark.parametrize(""content_disposition, default_filename, expected"", [
+    ('attachment;filename=""../file""', 'df', 'file'),
+])
+def test_parse_content_disposition(
+    content_disposition,
+    default_filename,
+    expected
+):
+    actual = parse_content_disposition(content_disposition, default_filename)
+    assert actual == expected
+
+
+def test_download_http_url__no_directory_traversal(tmpdir):
+    """"""
+    Test that directory traversal doesn't happen on download when the
+    Content-Disposition header contains a filename with a "".."" path part.
+    """"""
+    mock_url = 'http://www.example.com/whatever.tgz'
+    contents = b'downloaded'
+    link = Link(mock_url)
+
+    session = Mock()
+    resp = MockResponse(contents)
+    resp.url = mock_url
+    resp.headers = {
+        # Set the content-type to a random value to prevent
+        # mimetypes.guess_extension from guessing the extension.
+        'content-type': 'random',
+        'content-disposition': 'attachment;filename=""../out_dir_file""'
+    }
+    session.get.return_value = resp
+
+    download_dir = tmpdir.join('download')
+    os.mkdir(download_dir)
+    file_path, content_type = _download_http_url(
+        link,
+        session,
+        download_dir,
+        hashes=None,
+        progress_bar='on',
+    )
+    # The file should be downloaded to download_dir.
+    actual = os.listdir(download_dir)
+    assert actual == ['out_dir_file']
+
+
 @pytest.mark.parametrize(""url,win_expected,non_win_expected"", [
     ('file:tmp', 'tmp', 'tmp'),
     ('file:c:/path/to/file', r'C:\path\to\file', 'c:/path/to/file'),"
GHSA-3872-f48p-pxqj,"From 35d59f1f040541c358cece0a8d4a63183ca919b8 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Michal=20=C4=8Ciha=C5=99?= <michal@cihar.com>
Date: Thu, 3 Mar 2022 08:25:01 +0100
Subject: [PATCH] vcs: Improve mercurial parameters handling

Make sure that all user provided input is handled as expected.
---
 weblate/vcs/mercurial.py | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/weblate/vcs/mercurial.py b/weblate/vcs/mercurial.py
index 0399c1b0bae2..1131c1abd1e5 100644
--- a/weblate/vcs/mercurial.py
+++ b/weblate/vcs/mercurial.py
@@ -70,7 +70,7 @@ def check_config(self):
     @classmethod
     def _clone(cls, source: str, target: str, branch: str):
         """"""Clone repository.""""""
-        cls._popen([""clone"", ""--branch"", branch, source, target])
+        cls._popen([""clone"", f""--branch={branch}"", ""--"", source, target])
 
     def get_config(self, path):
         """"""Read entry from configuration.""""""
@@ -323,7 +323,7 @@ def on_branch(self, branch):
     def configure_branch(self, branch):
         """"""Configure repository branch.""""""
         if not self.on_branch(branch):
-            self.execute([""update"", branch])
+            self.execute([""update"", ""--"", branch])
         self.branch = branch
 
     def describe(self):
@@ -343,7 +343,7 @@ def describe(self):
     def push(self, branch):
         """"""Push given branch to remote repository.""""""
         try:
-            self.execute([""push"", ""-b"", self.branch])
+            self.execute([""push"", f""--branch={self.branch}""])
         except RepositoryException as error:
             if error.retcode == 1:
                 # No changes found
@@ -363,7 +363,7 @@ def cleanup(self):
 
     def update_remote(self):
         """"""Update remote repository.""""""
-        self.execute([""pull"", ""--branch"", self.branch])
+        self.execute([""pull"", f""--branch={self.branch}""])
         self.clean_revision_cache()
 
     def parse_changed_files(self, lines: List[str]) -> Iterator[str]:"
CVE-2018-1000070,"From 3a8016d31f517775d226aa8b902480f4a3a148a9 Mon Sep 17 00:00:00 2001
From: Peter Surda <surda@economicsofbitcoin.com>
Date: Tue, 13 Feb 2018 16:39:35 +0100
Subject: [PATCH] Fix message encoding bug

- prevent loading invalid message types
---
 src/messagetypes/__init__.py | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/src/messagetypes/__init__.py b/src/messagetypes/__init__.py
index c3911dfdee..d929101326 100644
--- a/src/messagetypes/__init__.py
+++ b/src/messagetypes/__init__.py
@@ -12,9 +12,10 @@ def encode(self):
 
 def constructObject(data):
     try:
-        classBase = eval(data[""""] + ""."" + data[""""].title())
-    except NameError:
-        logger.error(""Don't know how to handle message type: \""%s\"""", data[""""])
+        m = import_module(""messagetypes."" + data[""""])
+        classBase = getattr(m, data[""""].title())
+    except (NameError, ImportError):
+        logger.error(""Don't know how to handle message type: \""%s\"""", data[""""], exc_info=True)
         return None
     try:
         returnObj = classBase()"
GHSA-h88f-r7cw-8fv3,"From bcec1df703cd4a01520a90c3f801cca6f97d9bfd Mon Sep 17 00:00:00 2001
From: Ash Berlin-Taylor <ash_github@firemirror.com>
Date: Fri, 6 Aug 2021 16:22:50 +0100
Subject: [PATCH] Add missing permissions to varimport (#17468)

(cherry picked from commit eb6af07f5bc8958efd06818e84a5273a079304e1)
---
 airflow/www/views.py                   |  2 +-
 tests/www/views/test_views_variable.py | 13 +++++++++++++
 2 files changed, 14 insertions(+), 1 deletion(-)

diff --git a/airflow/www/views.py b/airflow/www/views.py
index e519ebf177a67..09d27e06ad963 100644
--- a/airflow/www/views.py
+++ b/airflow/www/views.py
@@ -3276,7 +3276,6 @@ class VariableModelView(AirflowModelView):
         'delete': 'delete',
         'action_muldelete': 'delete',
         'action_varexport': 'read',
-        'varimport': 'create',
     }
     base_permissions = [
         permissions.ACTION_CAN_CREATE,
@@ -3339,6 +3338,7 @@ def action_varexport(self, items):
         return response
 
     @expose('/varimport', methods=[""POST""])
+    @auth.has_access([(permissions.ACTION_CAN_CREATE, permissions.RESOURCE_VARIABLE)])
     @action_logging
     def varimport(self):
         """"""Import variables""""""
diff --git a/tests/www/views/test_views_variable.py b/tests/www/views/test_views_variable.py
index f9b37440945e3..292e971ae1fbf 100644
--- a/tests/www/views/test_views_variable.py
+++ b/tests/www/views/test_views_variable.py
@@ -96,6 +96,19 @@ def test_import_variables_success(session, admin_client):
     check_content_in_response('4 variable(s) successfully updated.', resp)
 
 
+def test_import_variables_anon(session, app):
+    assert session.query(Variable).count() == 0
+
+    content = '{""str_key"": ""str_value}'
+    bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))
+
+    resp = app.test_client().post(
+        '/variable/varimport', data={'file': (bytes_content, 'test.json')}, follow_redirects=True
+    )
+    check_content_not_in_response('variable(s) successfully updated.', resp)
+    check_content_in_response('Sign In', resp)
+
+
 def test_description_retrieval(session, admin_client):
     # create valid variable
     admin_client.post('/variable/add', data=VARIABLE, follow_redirects=True)"
OSV-2021-211,"From e6f15621c2ab2ecbfabf656942d8ef66f03b2d55 Mon Sep 17 00:00:00 2001
From: Stefan Weil <sw@weilnetz.de>
Date: Thu, 4 Feb 2021 14:45:19 +0100
Subject: [PATCH] Remove Python training scripts which were moved to tesstrain

Signed-off-by: Stefan Weil <sw@weilnetz.de>
---
 src/training/language_specific.py | 1414 -----------------------------
 src/training/tesstrain.py         |  112 ---
 src/training/tesstrain_utils.py   |  734 ---------------
 3 files changed, 2260 deletions(-)
 delete mode 100644 src/training/language_specific.py
 delete mode 100755 src/training/tesstrain.py
 delete mode 100644 src/training/tesstrain_utils.py

diff --git a/src/training/language_specific.py b/src/training/language_specific.py
deleted file mode 100644
index 388ec5c178..0000000000
--- a/src/training/language_specific.py
+++ /dev/null
@@ -1,1414 +0,0 @@
-#!/usr/bin/env python3
-# (C) Copyright 2014, Google Inc.
-# (C) Copyright 2018, James R Barlow
-# Licensed under the Apache License, Version 2.0 (the ""License"");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-# http://www.apache.org/licenses/LICENSE-2.0
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an ""AS IS"" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-# Set some language specific variables. Works in conjunction with
-# tesstrain.sh
-#
-
-# =============================================================================
-# Language specific info
-# =============================================================================
-
-import logging
-import os
-
-log = logging.getLogger(__name__)
-
-# Array of all valid language codes.
-VALID_LANGUAGE_CODES = (
-    ""afr amh ara asm aze aze_cyrl bel ben bih bod bos bul cat ""
-    ""ceb ces chi_sim chi_tra chr cym cyr_lid dan deu div dzo ""
-    ""ell eng enm epo est eus fas fil fin fra frk frm gle glg ""
-    ""grc guj hat heb hin hrv hun hye iast iku ind isl ita ita_old ""
-    ""jav jav_java jpn kan kat kat_old kaz khm kir kmr kor kur_ara lao lat ""
-    ""lat_lid lav lit mal mar mkd mlt msa mya nep nld nor ori ""
-    ""pan pol por pus ron rus san sin slk slv snd spa spa_old ""
-    ""sqi srp srp_latn swa swe syr tam tel tgk tgl tha tir tur ""
-    ""uig ukr urd uzb uzb_cyrl vie yid gle_uncial ""
-)
-
-# Codes for which we have webtext but no fonts:
-UNUSABLE_LANGUAGE_CODES = """"
-
-FRAKTUR_FONTS = [
-    ""CaslonishFraxx Medium"",
-    ""Cloister Black, Light"",
-    ""Proclamate Light"",
-    ""UnifrakturMaguntia"",
-    ""Walbaum-Fraktur"",
-]
-
-# List of fonts to train on
-LATIN_FONTS = [
-    ""Arial Bold"",
-    ""Arial Bold Italic"",
-    ""Arial Italic"",
-    ""Arial"",
-    ""Courier New Bold"",
-    ""Courier New Bold Italic"",
-    ""Courier New Italic"",
-    ""Courier New"",
-    ""Times New Roman, Bold"",
-    ""Times New Roman, Bold Italic"",
-    ""Times New Roman, Italic"",
-    ""Times New Roman,"",
-    ""Georgia Bold"",
-    ""Georgia Italic"",
-    ""Georgia"",
-    ""Georgia Bold Italic"",
-    ""Trebuchet MS Bold"",
-    ""Trebuchet MS Bold Italic"",
-    ""Trebuchet MS Italic"",
-    ""Trebuchet MS"",
-    ""Verdana Bold"",
-    ""Verdana Italic"",
-    ""Verdana"",
-    ""Verdana Bold Italic"",
-    ""URW Bookman L Bold"",
-    ""URW Bookman L Italic"",
-    ""URW Bookman L Bold Italic"",
-    ""Century Schoolbook L Bold"",
-    ""Century Schoolbook L Italic"",
-    ""Century Schoolbook L Bold Italic"",
-    ""Century Schoolbook L Medium"",
-    ""DejaVu Sans Ultra-Light"",
-]
-
-# List of fonts for printed/neo-Latin ('lat' language code, different from Latin script)
-NEOLATIN_FONTS = [
-    ""GFS Bodoni"",
-    ""GFS Bodoni Bold"",
-    ""GFS Bodoni Italic"",
-    ""GFS Bodoni Bold Italic"",
-    ""GFS Didot"",
-    ""GFS Didot Bold"",
-    ""GFS Didot Italic"",
-    ""GFS Didot Bold Italic"",
-    ""Cardo"",
-    ""Cardo Bold"",
-    ""Cardo Italic"",
-    ""Wyld"",
-    ""Wyld Italic"",
-    ""EB Garamond"",
-    ""EB Garamond Italic"",
-    ""Junicode"",
-    ""Junicode Bold"",
-    ""Junicode Italic"",
-    ""Junicode Bold Italic"",
-    ""IM FELL DW Pica PRO"",
-    ""IM FELL English PRO"",
-    ""IM FELL Double Pica PRO"",
-    ""IM FELL French Canon PRO"",
-    ""IM FELL Great Primer PRO"",
-    ""IM FELL DW Pica PRO Italic"",
-    ""IM FELL English PRO Italic"",
-    ""IM FELL Double Pica PRO Italic"",
-    ""IM FELL French Canon PRO Italic"",
-    ""IM FELL Great Primer PRO Italic"",
-]
-
-IRISH_UNCIAL_FONTS = [
-    ""Bunchlo Arsa Dubh GC"",
-    ""Bunchlo Arsa GC"",
-    ""Bunchlo Arsa GC Bold"",
-    ""Bunchlo Dubh GC"",
-    ""Bunchlo GC"",
-    ""Bunchlo GC Bold"",
-    ""Bunchlo Nua GC Bold"",
-    ""Bunchl na Nod GC"",
-    ""Gadelica"",
-    ""Glanchlo Dubh GC"",
-    ""Glanchlo GC"",
-    ""Glanchlo GC Bold"",
-    ""Seanchl Dubh GC"",
-    ""Seanchl GC"",
-    ""Seanchl GC Bold"",
-    ""Seanchl na Nod GC"",
-    ""Seanchl rsa Dubh GC"",
-    ""Seanchl rsa GC"",
-    ""Seanchl rsa GC Bold"",
-    ""Tromchlo Beag GC"",
-    ""Tromchlo Mor GC"",
-    ""Urchlo GC"",
-    ""Urchlo GC Bold"",
-]
-
-EARLY_LATIN_FONTS = [
-    *FRAKTUR_FONTS,
-    *LATIN_FONTS,
-    # The Wyld font family renders early modern ligatures encoded in the private
-    # unicode area.
-    ""Wyld"",
-    ""Wyld Italic"",
-    # Fonts that render the Yogh symbol (U+021C, U+021D) found in Old English.
-    ""GentiumAlt"",
-]
-
-VIETNAMESE_FONTS = [
-    ""Arial Unicode MS Bold"",
-    ""Arial Bold Italic"",
-    ""Arial Italic"",
-    ""Arial Unicode MS"",
-    ""FreeMono Bold"",
-    ""Courier New Bold Italic"",
-    ""FreeMono Italic"",
-    ""FreeMono"",
-    ""GentiumAlt Italic"",
-    ""GentiumAlt"",
-    ""Palatino Linotype Bold"",
-    ""Palatino Linotype Bold Italic"",
-    ""Palatino Linotype Italic"",
-    ""Palatino Linotype"",
-    ""Really No 2 LT W2G Light"",
-    ""Really No 2 LT W2G Light Italic"",
-    ""Really No 2 LT W2G Medium"",
-    ""Really No 2 LT W2G Medium Italic"",
-    ""Really No 2 LT W2G Semi-Bold"",
-    ""Really No 2 LT W2G Semi-Bold Italic"",
-    ""Really No 2 LT W2G Ultra-Bold"",
-    ""Really No 2 LT W2G Ultra-Bold Italic"",
-    ""Times New Roman, Bold"",
-    ""Times New Roman, Bold Italic"",
-    ""Times New Roman, Italic"",
-    ""Times New Roman,"",
-    ""Verdana Bold"",
-    ""Verdana Italic"",
-    ""Verdana"",
-    ""Verdana Bold Italic"",
-    ""VL Gothic"",
-    ""VL PGothic"",
-]
-
-DEVANAGARI_FONTS = [
-    ""FreeSans"",
-    ""Chandas"",
-    ""Kalimati"",
-    ""Uttara"",
-    ""Lucida Sans"",
-    ""gargi Medium"",
-    ""Lohit Devanagari"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""Noto Sans Devanagari Bold"",
-    ""Noto Sans Devanagari"",
-    ""Samyak Devanagari Medium"",
-    ""Sarai"",
-    ""Saral LT Bold"",
-    ""Saral LT Light"",
-    ""Nakula"",
-    ""Sahadeva"",
-    ""Samanata"",
-    ""Santipur OT Medium"",
-]
-
-KANNADA_FONTS = [
-    ""Kedage Bold"",
-    ""Kedage Italic"",
-    ""Kedage"",
-    ""Kedage Bold Italic"",
-    ""Mallige Bold"",
-    ""Mallige Italic"",
-    ""Mallige"",
-    ""Mallige Bold Italic"",
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""cheluvi Medium"",
-    ""Noto Sans Kannada Bold"",
-    ""Noto Sans Kannada"",
-    ""Lohit Kannada"",
-    ""Tunga"",
-    ""Tunga Bold"",
-]
-
-TELUGU_FONTS = [
-    ""Pothana2000"",
-    ""Vemana2000"",
-    ""Lohit Telugu"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""Dhurjati"",
-    ""Gautami Bold"",
-    ""Gidugu"",
-    ""Gurajada"",
-    ""Lakki Reddy"",
-    ""Mallanna"",
-    ""Mandali"",
-    ""NATS"",
-    ""NTR"",
-    ""Noto Sans Telugu Bold"",
-    ""Noto Sans Telugu"",
-    ""Peddana"",
-    ""Ponnala"",
-    ""Ramabhadra"",
-    ""Ravi Prakash"",
-    ""Sree Krushnadevaraya"",
-    ""Suranna"",
-    ""Suravaram"",
-    ""Tenali Ramakrishna"",
-    ""Gautami"",
-]
-
-TAMIL_FONTS = [
-    ""TAMu_Kadambri"",
-    ""TAMu_Kalyani"",
-    ""TAMu_Maduram"",
-    ""TSCu_Paranar"",
-    ""TSCu_Times"",
-    ""TSCu_Paranar Bold"",
-    ""FreeSans"",
-    ""FreeSerif"",
-    ""Lohit Tamil"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""Droid Sans Tamil Bold"",
-    ""Droid Sans Tamil"",
-    ""Karla Tamil Inclined Bold Italic"",
-    ""Karla Tamil Inclined Italic"",
-    ""Karla Tamil Upright Bold"",
-    ""Karla Tamil Upright"",
-    ""Noto Sans Tamil Bold"",
-    ""Noto Sans Tamil"",
-    ""Noto Sans Tamil UI Bold"",
-    ""Noto Sans Tamil UI"",
-    ""TSCu_Comic Normal"",
-    ""Lohit Tamil Classical"",
-]
-
-THAI_FONTS = [
-    ""FreeSerif"",
-    ""FreeSerif Italic"",
-    ""Garuda"",
-    ""Norasi"",
-    ""Lucida Sans Typewriter"",
-    ""Lucida Sans"",
-    ""Garuda Oblique"",
-    ""Norasi Oblique"",
-    ""Norasi Italic"",
-    ""Garuda Bold"",
-    ""Norasi Bold"",
-    ""Lucida Sans Typewriter Bold"",
-    ""Lucida Sans Semi-Bold"",
-    ""Garuda Bold Oblique"",
-    ""Norasi Bold Italic"",
-    ""Norasi Bold Oblique"",
-    ""AnuParp LT Thai"",
-    ""Arial Unicode MS Bold"",
-    ""Arial Unicode MS"",
-    ""Ascender Uni"",
-    ""Loma"",
-    ""Noto Serif Thai Bold"",
-    ""Noto Serif Thai"",
-    ""Purisa Light"",
-    ""Sirichana LT Bold"",
-    ""Sirichana LT"",
-    ""Sukothai LT Bold"",
-    ""Sukothai LT"",
-    ""UtSaHaGumm LT Thai"",
-    ""Tahoma"",
-]
-
-KOREAN_FONTS = [
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Baekmuk Batang Patched"",
-    ""Baekmuk Batang"",
-    ""Baekmuk Dotum"",
-    ""Baekmuk Gulim"",
-    ""Baekmuk Headline"",
-]
-
-CHI_SIM_FONTS = [
-    ""AR PL UKai CN"",
-    ""AR PL UMing Patched Light"",
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""WenQuanYi Zen Hei Medium"",
-]
-
-CHI_TRA_FONTS = [
-    ""AR PL UKai TW"",
-    ""AR PL UMing TW MBE Light"",
-    ""AR PL UKai Patched"",
-    ""AR PL UMing Patched Light"",
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""WenQuanYi Zen Hei Medium"",
-]
-
-JPN_FONTS = [
-    ""TakaoExGothic"",
-    ""TakaoExMincho"",
-    ""TakaoGothic"",
-    ""TakaoMincho"",
-    ""TakaoPGothic"",
-    ""TakaoPMincho"",
-    ""VL Gothic"",
-    ""VL PGothic"",
-    ""Noto Sans Japanese Bold"",
-    ""Noto Sans Japanese Light"",
-]
-
-RUSSIAN_FONTS = [
-    ""Arial Bold"",
-    ""Arial Bold Italic"",
-    ""Arial Italic"",
-    ""Arial"",
-    ""Courier New Bold"",
-    ""Courier New Bold Italic"",
-    ""Courier New Italic"",
-    ""Courier New"",
-    ""Times New Roman, Bold"",
-    ""Times New Roman, Bold Italic"",
-    ""Times New Roman, Italic"",
-    ""Times New Roman,"",
-    ""Georgia Bold"",
-    ""Georgia Italic"",
-    ""Georgia"",
-    ""Georgia Bold Italic"",
-    ""Trebuchet MS Bold"",
-    ""Trebuchet MS Bold Italic"",
-    ""Trebuchet MS Italic"",
-    ""Trebuchet MS"",
-    ""Verdana Bold"",
-    ""Verdana Italic"",
-    ""Verdana"",
-    ""Verdana Bold Italic"",
-    ""DejaVu Serif"",
-    ""DejaVu Serif Oblique"",
-    ""DejaVu Serif Bold"",
-    ""DejaVu Serif Bold Oblique"",
-    ""Lucida Bright"",
-    ""FreeSerif Bold"",
-    ""FreeSerif Bold Italic"",
-    ""DejaVu Sans Ultra-Light"",
-]
-
-GREEK_FONTS = [
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""DejaVu Sans Mono"",
-    ""DejaVu Sans Mono Oblique"",
-    ""DejaVu Sans Mono Bold"",
-    ""DejaVu Sans Mono Bold Oblique"",
-    ""DejaVu Serif"",
-    ""DejaVu Serif Semi-Condensed"",
-    ""DejaVu Serif Oblique"",
-    ""DejaVu Serif Bold"",
-    ""DejaVu Serif Bold Oblique"",
-    ""DejaVu Serif Bold Semi-Condensed"",
-    ""FreeSerif Bold"",
-    ""FreeSerif Bold Italic"",
-    ""FreeSerif Italic"",
-    ""FreeSerif"",
-    ""GentiumAlt"",
-    ""GentiumAlt Italic"",
-    ""Linux Biolinum O Bold"",
-    ""Linux Biolinum O"",
-    ""Linux Libertine O Bold"",
-    ""Linux Libertine O"",
-    ""Linux Libertine O Bold Italic"",
-    ""Linux Libertine O Italic"",
-    ""Palatino Linotype Bold"",
-    ""Palatino Linotype Bold Italic"",
-    ""Palatino Linotype Italic"",
-    ""Palatino Linotype"",
-    ""UmePlus P Gothic"",
-    ""VL PGothic"",
-]
-
-ANCIENT_GREEK_FONTS = [
-    ""GFS Artemisia"",
-    ""GFS Artemisia Bold"",
-    ""GFS Artemisia Bold Italic"",
-    ""GFS Artemisia Italic"",
-    ""GFS Bodoni"",
-    ""GFS Bodoni Bold"",
-    ""GFS Bodoni Bold Italic"",
-    ""GFS Bodoni Italic"",
-    ""GFS Didot"",
-    ""GFS Didot Bold"",
-    ""GFS Didot Bold Italic"",
-    ""GFS Didot Italic"",
-    ""GFS DidotClassic"",
-    ""GFS Neohellenic"",
-    ""GFS Neohellenic Bold"",
-    ""GFS Neohellenic Bold Italic"",
-    ""GFS Neohellenic Italic"",
-    ""GFS Philostratos"",
-    ""GFS Porson"",
-    ""GFS Pyrsos"",
-    ""GFS Solomos"",
-]
-
-ARABIC_FONTS = [
-    ""Arabic Transparent Bold"",
-    ""Arabic Transparent"",
-    ""Arab"",
-    ""Arial Unicode MS Bold"",
-    ""Arial Unicode MS"",
-    ""ASVCodar LT Bold"",
-    ""ASVCodar LT Light"",
-    ""Badiya LT Bold"",
-    ""Badiya LT"",
-    ""Badr LT Bold"",
-    ""Badr LT"",
-    ""Dimnah"",
-    ""Frutiger LT Arabic Bold"",
-    ""Frutiger LT Arabic"",
-    ""Furat"",
-    ""Hassan LT Bold"",
-    ""Hassan LT Light"",
-    ""Jalal LT Bold"",
-    ""Jalal LT Light"",
-    ""Midan Bold"",
-    ""Midan"",
-    ""Mitra LT Bold"",
-    ""Mitra LT Light"",
-    ""Palatino LT Arabic"",
-    ""Palatino Sans Arabic Bold"",
-    ""Palatino Sans Arabic"",
-    ""Simplified Arabic Bold"",
-    ""Simplified Arabic"",
-    ""Times New Roman, Bold"",
-    ""Times New Roman,"",
-    ""Traditional Arabic Bold"",
-    ""Traditional Arabic"",
-]
-
-HEBREW_FONTS = [
-    ""Arial Bold"",
-    ""Arial Bold Italic"",
-    ""Arial Italic"",
-    ""Arial"",
-    ""Courier New Bold"",
-    ""Courier New Bold Italic"",
-    ""Courier New Italic"",
-    ""Courier New"",
-    ""Ergo Hebrew Semi-Bold"",
-    ""Ergo Hebrew Semi-Bold Italic"",
-    ""Ergo Hebrew"",
-    ""Ergo Hebrew Italic"",
-    ""Really No 2 LT W2G Light"",
-    ""Really No 2 LT W2G Light Italic"",
-    ""Really No 2 LT W2G Medium"",
-    ""Really No 2 LT W2G Medium Italic"",
-    ""Really No 2 LT W2G Semi-Bold"",
-    ""Really No 2 LT W2G Semi-Bold Italic"",
-    ""Really No 2 LT W2G Ultra-Bold"",
-    ""Really No 2 LT W2G Ultra-Bold Italic"",
-    ""Times New Roman, Bold"",
-    ""Times New Roman, Bold Italic"",
-    ""Times New Roman, Italic"",
-    ""Times New Roman,"",
-    ""Lucida Sans"",
-    ""Tahoma"",
-]
-
-BENGALI_FONTS = [
-    ""Bangla Medium"",
-    ""Lohit Bengali"",
-    ""Mukti Narrow"",
-    ""Mukti Narrow Bold"",
-    ""Jamrul Medium Semi-Expanded"",
-    ""Likhan Medium"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""FreeSans"",
-    ""FreeSans Oblique"",
-    ""FreeSerif"",
-    ""FreeSerif Italic"",
-    ""Noto Sans Bengali Bold"",
-    ""Noto Sans Bengali"",
-    ""Ani"",
-    ""Lohit Assamese"",
-    ""Lohit Bengali"",
-    ""Mitra Mono"",
-]
-
-KYRGYZ_FONTS = [
-    ""Arial"",
-    ""Arial Bold"",
-    ""Arial Italic"",
-    ""Arial Bold Italic"",
-    ""Courier New"",
-    ""Courier New Bold"",
-    ""Courier New Italic"",
-    ""Courier New Bold Italic"",
-    ""Times New Roman,"",
-    ""Times New Roman, Bold"",
-    ""Times New Roman, Bold Italic"",
-    ""Times New Roman, Italic"",
-    ""DejaVu Serif"",
-    ""DejaVu Serif Oblique"",
-    ""DejaVu Serif Bold"",
-    ""DejaVu Serif Bold Oblique"",
-    ""Lucida Bright"",
-    ""FreeSerif Bold"",
-    ""FreeSerif Bold Italic"",
-]
-
-PERSIAN_FONTS = [
-    ""Amiri Bold Italic"",
-    ""Amiri Bold"",
-    ""Amiri Italic"",
-    ""Amiri"",
-    ""Andale Sans Arabic Farsi"",
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Lateef"",
-    ""Lucida Bright"",
-    ""Lucida Sans Oblique"",
-    ""Lucida Sans Semi-Bold"",
-    ""Lucida Sans"",
-    ""Lucida Sans Typewriter Bold"",
-    ""Lucida Sans Typewriter Oblique"",
-    ""Lucida Sans Typewriter"",
-    ""Scheherazade"",
-    ""Tahoma"",
-    ""Times New Roman,"",
-    ""Times New Roman, Bold"",
-    ""Times New Roman, Bold Italic"",
-    ""Times New Roman, Italic"",
-    ""Yakout Linotype Bold"",
-    ""Yakout Linotype"",
-]
-
-AMHARIC_FONTS = [
-    ""Abyssinica SIL"",
-    ""Droid Sans Ethiopic Bold"",
-    ""Droid Sans Ethiopic"",
-    ""FreeSerif"",
-    ""Noto Sans Ethiopic Bold"",
-    ""Noto Sans Ethiopic"",
-]
-
-ARMENIAN_FONTS = [
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""FreeMono"",
-    ""FreeMono Italic"",
-    ""FreeSans"",
-    ""FreeSans Bold"",
-    ""FreeSans Oblique"",
-]
-
-BURMESE_FONTS = [
-    ""Myanmar Sans Pro"",
-    ""Noto Sans Myanmar Bold"",
-    ""Noto Sans Myanmar"",
-    ""Padauk Bold"",
-    ""Padauk"",
-    ""TharLon"",
-]
-
-JAVANESE_FONTS = [""Prada""]
-
-NORTH_AMERICAN_ABORIGINAL_FONTS = [
-    ""Aboriginal Sans"",
-    ""Aboriginal Sans Bold Italic"",
-    ""Aboriginal Sans Italic"",
-    ""Aboriginal Sans Bold"",
-    ""Aboriginal Serif Bold"",
-    ""Aboriginal Serif Bold Italic"",
-    ""Aboriginal Serif Italic"",
-    ""Aboriginal Serif"",
-]
-
-GEORGIAN_FONTS = [
-    ""Arial Unicode MS Bold"",
-    ""Arial Unicode MS"",
-    ""BPG Algeti GPL\&GNU"",
-    ""BPG Chveulebrivi GPL\&GNU"",
-    ""BPG Courier GPL\&GNU"",
-    ""BPG Courier S GPL\&GNU"",
-    ""BPG DejaVu Sans 2011 GNU-GPL"",
-    ""BPG Elite GPL\&GNU"",
-    ""BPG Excelsior GPL\&GNU"",
-    ""BPG Glaho GPL\&GNU"",
-    ""BPG Gorda GPL\&GNU"",
-    ""BPG Ingiri GPL\&GNU"",
-    ""BPG Mrgvlovani Caps GNU\&GPL"",
-    ""BPG Mrgvlovani GPL\&GNU"",
-    ""BPG Nateli Caps GPL\&GNU Light"",
-    ""BPG Nateli Condenced GPL\&GNU Light"",
-    ""BPG Nateli GPL\&GNU Light"",
-    ""BPG Nino Medium Cond GPL\&GNU"",
-    ""BPG Nino Medium GPL\&GNU Medium"",
-    ""BPG Sans GPL\&GNU"",
-    ""BPG Sans Medium GPL\&GNU"",
-    ""BPG Sans Modern GPL\&GNU"",
-    ""BPG Sans Regular GPL\&GNU"",
-    ""BPG Serif GPL\&GNU"",
-    ""BPG Serif Modern GPL\&GNU"",
-    ""FreeMono"",
-    ""FreeMono Bold Italic"",
-    ""FreeSans"",
-    ""FreeSerif"",
-    ""FreeSerif Bold"",
-    ""FreeSerif Bold Italic"",
-    ""FreeSerif Italic"",
-]
-
-OLD_GEORGIAN_FONTS = [
-    ""Arial Unicode MS Bold"",
-    ""Arial Unicode MS"",
-    ""BPG Algeti GPL\&GNU"",
-    ""BPG Courier S GPL\&GNU"",
-    ""BPG DejaVu Sans 2011 GNU-GPL"",
-    ""BPG Elite GPL\&GNU"",
-    ""BPG Excelsior GPL\&GNU"",
-    ""BPG Glaho GPL\&GNU"",
-    ""BPG Ingiri GPL\&GNU"",
-    ""BPG Mrgvlovani Caps GNU\&GPL"",
-    ""BPG Mrgvlovani GPL\&GNU"",
-    ""BPG Nateli Caps GPL\&GNU Light"",
-    ""BPG Nateli Condenced GPL\&GNU Light"",
-    ""BPG Nateli GPL\&GNU Light"",
-    ""BPG Nino Medium Cond GPL\&GNU"",
-    ""BPG Nino Medium GPL\&GNU Medium"",
-    ""BPG Sans GPL\&GNU"",
-    ""BPG Sans Medium GPL\&GNU"",
-    ""BPG Sans Modern GPL\&GNU"",
-    ""BPG Sans Regular GPL\&GNU"",
-    ""BPG Serif GPL\&GNU"",
-    ""BPG Serif Modern GPL\&GNU"",
-    ""FreeSans"",
-    ""FreeSerif"",
-    ""FreeSerif Bold"",
-    ""FreeSerif Bold Italic"",
-    ""FreeSerif Italic"",
-]
-
-KHMER_FONTS = [
-    ""Khmer OS"",
-    ""Khmer OS System"",
-    ""Khmer OS Battambang"",
-    ""Khmer OS Bokor"",
-    ""Khmer OS Content"",
-    ""Khmer OS Fasthand"",
-    ""Khmer OS Freehand"",
-    ""Khmer OS Metal Chrieng"",
-    ""Khmer OS Muol Light"",
-    ""Khmer OS Muol Pali"",
-    ""Khmer OS Muol"",
-    ""Khmer OS Siemreap"",
-    ""Noto Sans Bold"",
-    ""Noto Sans"",
-    ""Noto Serif Khmer Bold"",
-    ""Noto Serif Khmer Light"",
-]
-
-KURDISH_FONTS = [
-    ""Amiri Bold Italic"",
-    ""Amiri Bold"",
-    ""Amiri Italic"",
-    ""Amiri"",
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Lateef"",
-    ""Lucida Bright"",
-    ""Lucida Sans Oblique"",
-    ""Lucida Sans Semi-Bold"",
-    ""Lucida Sans"",
-    ""Lucida Sans Typewriter Bold"",
-    ""Lucida Sans Typewriter Oblique"",
-    ""Lucida Sans Typewriter"",
-    ""Scheherazade"",
-    ""Tahoma"",
-    ""Times New Roman,"",
-    ""Times New Roman, Bold"",
-    ""Times New Roman, Bold Italic"",
-    ""Times New Roman, Italic"",
-    ""Unikurd Web"",
-    ""Yakout Linotype Bold"",
-    ""Yakout Linotype"",
-]
-
-LAOTHIAN_FONTS = [
-    ""Phetsarath OT"",
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""Dhyana Bold"",
-    ""Dhyana"",
-    ""Lao Muang Don"",
-    ""Lao Muang Khong"",
-    ""Lao Sans Pro"",
-    ""Noto Sans Lao Bold"",
-    ""Noto Sans Lao"",
-    ""Noto Sans Lao UI Bold"",
-    ""Noto Sans Lao UI"",
-    ""Noto Serif Lao Bold"",
-    ""Noto Serif Lao"",
-    ""Phetsarath Bold"",
-    ""Phetsarath"",
-    ""Souliyo Unicode"",
-]
-
-GUJARATI_FONTS = [
-    ""Lohit Gujarati"",
-    ""Rekha Medium"",
-    ""Samyak Gujarati Medium"",
-    ""aakar Medium"",
-    ""padmaa Bold"",
-    ""padmaa Medium"",
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""FreeSans"",
-    ""Noto Sans Gujarati Bold"",
-    ""Noto Sans Gujarati"",
-    ""Shruti"",
-    ""Shruti Bold"",
-]
-
-MALAYALAM_FONTS = [
-    ""AnjaliOldLipi"",
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""Dyuthi"",
-    ""FreeSerif"",
-    ""Kalyani"",
-    ""Kartika"",
-    ""Kartika Bold"",
-    ""Lohit Malayalam"",
-    ""Meera"",
-    ""Noto Sans Malayalam Bold"",
-    ""Noto Sans Malayalam"",
-    ""Rachana"",
-    ""Rachana_w01"",
-    ""RaghuMalayalam"",
-    ""suruma"",
-]
-
-ORIYA_FONTS = [
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""ori1Uni Medium"",
-    ""Samyak Oriya Medium"",
-    ""Lohit Oriya"",
-]
-
-PUNJABI_FONTS = [
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""Saab"",
-    ""Lohit Punjabi"",
-    ""Noto Sans Gurmukhi"",
-    ""Noto Sans Gurmukhi Bold"",
-    ""FreeSans"",
-    ""FreeSans Bold"",
-    ""FreeSerif"",
-]
-
-SINHALA_FONTS = [
-    ""Noto Sans Sinhala Bold"",
-    ""Noto Sans Sinhala"",
-    ""OCRUnicode"",
-    ""Yagpo"",
-    ""LKLUG"",
-    ""FreeSerif"",
-]
-
-SYRIAC_FONTS = [
-    ""East Syriac Adiabene"",
-    ""East Syriac Ctesiphon"",
-    ""Estrangelo Antioch"",
-    ""Estrangelo Edessa"",
-    ""Estrangelo Midyat"",
-    ""Estrangelo Nisibin"",
-    ""Estrangelo Quenneshrin"",
-    ""Estrangelo Talada"",
-    ""Estrangelo TurAbdin"",
-    ""Serto Batnan Bold"",
-    ""Serto Batnan"",
-    ""Serto Jerusalem Bold"",
-    ""Serto Jerusalem Italic"",
-    ""Serto Jerusalem"",
-    ""Serto Kharput"",
-    ""Serto Malankara"",
-    ""Serto Mardin Bold"",
-    ""Serto Mardin"",
-    ""Serto Urhoy Bold"",
-    ""Serto Urhoy"",
-    ""FreeSans"",
-]
-
-THAANA_FONTS = [""FreeSerif""]
-
-TIBETAN_FONTS = [
-    ""Arial Unicode MS"",
-    ""Arial Unicode MS Bold"",
-    ""Ascender Uni"",
-    ""DDC Uchen"",
-    ""Jomolhari"",
-    ""Kailasa"",
-    ""Kokonor"",
-    ""Tibetan Machine Uni"",
-    ""TibetanTsugRing"",
-    ""Yagpo"",
-]
-
-# The following fonts will be rendered vertically in phase I.
-VERTICAL_FONTS = [
-    ""TakaoExGothic"",
-    ""TakaoExMincho"",
-    ""AR PL UKai Patched"",
-    ""AR PL UMing Patched Light"",
-    ""Baekmuk Batang Patched"",
-]
-
-FLAGS_webtext_prefix = os.environ.get(""FLAGS_webtext_prefix"", """")
-
-
-# Set language-specific values for several global variables, including
-#   ${TEXT_CORPUS}
-#      holds the text corpus file for the language, used in phase F
-#   ${FONTS[@]}
-#      holds a sequence of applicable fonts for the language, used in
-#      phase F & I. only set if not already set, i.e. from command line
-#   ${TRAINING_DATA_ARGUMENTS}
-#      non-default arguments to the training_data program used in phase T
-#   ${FILTER_ARGUMENTS}[ -]
-#      character-code-specific filtering to distinguish between scripts
-#      (eg. CJK) used by filter_borbidden_characters in phase F
-#   ${WORDLIST2DAWG_ARGUMENTS}
-#      specify fixed length dawg generation for non-space-delimited lang
-# TODO(dsl): We can refactor these into functions that assign FONTS,
-# TEXT_CORPUS, etc. separately.
-def set_lang_specific_parameters(ctx, lang):
-    # The default text location is now given directly from the language code.
-    TEXT_CORPUS = f""{FLAGS_webtext_prefix}/{lang}.corpus.txt""
-    FILTER_ARGUMENTS = []
-    WORDLIST2DAWG_ARGUMENTS = """"
-    # These dawg factors represent the fraction of the corpus not covered by the
-    # dawg, and seem like reasonable defaults, but the optimal value is likely
-    # to be highly corpus-dependent, as well as somewhat language-dependent.
-    # Number dawg factor is the fraction of all numeric strings that are not
-    # covered, which is why it is higher relative to the others.
-    PUNC_DAWG_FACTOR = None
-    NUMBER_DAWG_FACTOR = 0.125
-    WORD_DAWG_FACTOR = 0.05
-    BIGRAM_DAWG_FACTOR = 0.015
-    TRAINING_DATA_ARGUMENTS = []
-    FRAGMENTS_DISABLED = ""y""
-    RUN_SHAPE_CLUSTERING = False
-    AMBIGS_FILTER_DENOMINATOR = ""100000""
-    LEADING = 32
-    MEAN_COUNT = 40  # Default for latin script.
-    # Language to mix with the language for maximum accuracy. Defaults to eng.
-    # If no language is good, set to the base language.
-    MIX_LANG = ""eng""
-    FONTS = ctx.fonts
-    TEXT2IMAGE_EXTRA_ARGS = []
-    EXPOSURES = []
-
-    GENERATE_WORD_BIGRAMS = None
-    WORD_DAWG_SIZE = None
-
-    # Latin languages.
-    if lang == ""enm"":
-        TEXT2IMAGE_EXTRA_ARGS += [""--ligatures""]  # Add ligatures when supported
-        if not FONTS:
-            FONTS = EARLY_LATIN_FONTS
-    elif lang == ""frm"":
-        TEXT_CORPUS = f""{FLAGS_webtext_prefix}/fra.corpus.txt""
-        # Make long-s substitutions for Middle French text
-        FILTER_ARGUMENTS += [""--make_early_language_variant=fra""]
-        TEXT2IMAGE_EXTRA_ARGS += [""--ligatures""]  # Add ligatures when supported.
-        if not FONTS:
-            FONTS = EARLY_LATIN_FONTS
-    elif lang == ""frk"":
-        TEXT_CORPUS = f""{FLAGS_webtext_prefix}/deu.corpus.txt""
-        if not FONTS:
-            FONTS = FRAKTUR_FONTS
-    elif lang == ""ita_old"":
-        TEXT_CORPUS = f""{FLAGS_webtext_prefix}/ita.corpus.txt""
-        # Make long-s substitutions for Early Italian text
-        FILTER_ARGUMENTS += [""--make_early_language_variant=ita""]
-        TEXT2IMAGE_EXTRA_ARGS += [""--ligatures""]  # Add ligatures when supported.
-        if not FONTS:
-            FONTS = EARLY_LATIN_FONTS
-    elif lang == ""lat"":
-        if not EXPOSURES:
-            EXPOSURES = ""-3 -2 -1 0 1 2 3"".split()
-        if not FONTS:
-            FONTS = NEOLATIN_FONTS
-    elif lang == ""spa_old"":
-        TEXT_CORPUS = f""{FLAGS_webtext_prefix}/spa.corpus.txt""
-        # Make long-s substitutions for Early Spanish text
-        FILTER_ARGUMENTS += [""--make_early_language_variant=spa""]
-        TEXT2IMAGE_EXTRA_ARGS += [""--ligatures""]  # Add ligatures when supported.
-        if not FONTS:
-            FONTS = EARLY_LATIN_FONTS
-    elif lang == ""srp_latn"":
-        TEXT_CORPUS = f""{FLAGS_webtext_prefix}/srp.corpus.txt""
-    elif lang == ""vie"":
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        if not FONTS:
-            FONTS = VIETNAMESE_FONTS
-        # Highly inflective languages get a bigger dawg size.
-        # TODO(rays) Add more here!
-    elif lang == ""hun"":
-        WORD_DAWG_SIZE = 1_000_000
-    elif lang == ""pol"":
-        WORD_DAWG_SIZE = 1_000_000
-
-        # Latin with default treatment.
-    elif lang == ""afr"":
-        pass
-    elif lang == ""aze"":
-        pass
-    elif lang == ""bos"":
-        pass
-    elif lang == ""cat"":
-        pass
-    elif lang == ""ceb"":
-        pass
-    elif lang == ""ces"":
-        PUNC_DAWG_FACTOR = 0.004
-    elif lang == ""cym"":
-        pass
-    elif lang == ""dan"":
-        pass
-    elif lang == ""deu"":
-        WORD_DAWG_FACTOR = 0.125
-    elif lang == ""eng"":
-        WORD_DAWG_FACTOR = 0.03
-    elif lang == ""epo"":
-        pass
-    elif lang == ""est"":
-        pass
-    elif lang == ""eus"":
-        pass
-    elif lang == ""fil"":
-        pass
-    elif lang == ""fin"":
-        pass
-    elif lang == ""fra"":
-        WORD_DAWG_FACTOR = 0.08
-    elif lang == ""gle"":
-        pass
-    elif lang == ""gle_uncial"":
-        if not FONTS:
-            FONTS = IRISH_UNCIAL_FONTS
-    elif lang == ""glg"":
-        pass
-    elif lang == ""hat"":
-        pass
-    elif lang == ""hrv"":
-        pass
-    elif lang == ""iast"":
-        pass
-    elif lang == ""ind"":
-        pass
-    elif lang == ""isl"":
-        pass
-    elif lang == ""ita"":
-        pass
-    elif lang == ""jav"":
-        pass
-    elif lang == ""lav"":
-        pass
-    elif lang == ""lit"":
-        pass
-    elif lang == ""mlt"":
-        pass
-    elif lang == ""msa"":
-        pass
-    elif lang == ""nld"":
-        WORD_DAWG_FACTOR = 0.02
-    elif lang == ""nor"":
-        pass
-    elif lang == ""por"":
-        pass
-    elif lang == ""ron"":
-        pass
-    elif lang == ""slk"":
-        pass
-    elif lang == ""slv"":
-        pass
-    elif lang == ""spa"":
-        pass
-    elif lang == ""sqi"":
-        pass
-    elif lang == ""swa"":
-        pass
-    elif lang == ""swe"":
-        pass
-    elif lang == ""tgl"":
-        pass
-    elif lang == ""tur"":
-        pass
-    elif lang == ""uzb"":
-        pass
-    elif lang == ""zlm"":
-        pass
-
-        # Special code for performing language-id that is trained on
-        # EFIGS+Latin+Vietnamese text with regular + fraktur fonts.
-    elif lang == ""lat_lid"":
-        TEXT_CORPUS = f""{FLAGS_webtext_prefix}/lat_lid.corpus.txt""
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        GENERATE_WORD_BIGRAMS = 0
-        # Strip unrenderable words as not all fonts will render the extended
-        # latin symbols found in Vietnamese text.
-        WORD_DAWG_SIZE = 1_000_000
-        if not FONTS:
-            FONTS = EARLY_LATIN_FONTS
-
-        # Cyrillic script-based languages. It is bad to mix Latin with Cyrillic.
-    elif lang == ""rus"":
-        if not FONTS:
-            FONTS = RUSSIAN_FONTS
-        MIX_LANG = ""rus""
-        NUMBER_DAWG_FACTOR = 0.05
-        WORD_DAWG_SIZE = 1_000_000
-    elif lang in (
-            ""aze_cyrl"",
-            ""bel"",
-            ""bul"",
-            ""kaz"",
-            ""mkd"",
-            ""srp"",
-            ""tgk"",
-            ""ukr"",
-            ""uzb_cyrl"",
-    ):
-        MIX_LANG = f""{lang}""
-        if not FONTS:
-            FONTS = RUSSIAN_FONTS
-
-        # Special code for performing Cyrillic language-id that is trained on
-        # Russian, Serbian, Ukrainian, Belarusian, Macedonian, Tajik and Mongolian
-        # text with the list of Russian fonts.
-    elif lang == ""cyr_lid"":
-        TEXT_CORPUS = f""{FLAGS_webtext_prefix}/cyr_lid.corpus.txt""
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        GENERATE_WORD_BIGRAMS = 0
-        WORD_DAWG_SIZE = 1_000_000
-        if not FONTS:
-            FONTS = RUSSIAN_FONTS
-
-        # South Asian scripts mostly have a lot of different graphemes, so trim
-        # down the MEAN_COUNT so as not to get a huge amount of text.
-    elif lang in (""asm"", ""ben""):
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        if not FONTS:
-            FONTS = BENGALI_FONTS
-    elif lang in (""bih"", ""hin"", ""mar"", ""nep"", ""san""):
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        if not FONTS:
-            FONTS = DEVANAGARI_FONTS
-    elif lang == ""bod"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        if not FONTS:
-            FONTS = TIBETAN_FONTS
-    elif lang == ""dzo"":
-        WORD_DAWG_FACTOR = 0.01
-        if not FONTS:
-            FONTS = TIBETAN_FONTS
-    elif lang == ""guj"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        if not FONTS:
-            FONTS = GUJARATI_FONTS
-    elif lang == ""kan"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        TRAINING_DATA_ARGUMENTS += [""--no_newline_in_output""]
-        TEXT2IMAGE_EXTRA_ARGS += [""--char_spacing=0.5""]
-        if not FONTS:
-            FONTS = KANNADA_FONTS
-    elif lang == ""mal"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        TRAINING_DATA_ARGUMENTS += [""--no_newline_in_output""]
-        TEXT2IMAGE_EXTRA_ARGS += [""--char_spacing=0.5""]
-        if not FONTS:
-            FONTS = MALAYALAM_FONTS
-    elif lang == ""ori"":
-        WORD_DAWG_FACTOR = 0.01
-        if not FONTS:
-            FONTS = ORIYA_FONTS
-    elif lang == ""pan"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.01
-        if not FONTS:
-            FONTS = PUNJABI_FONTS
-    elif lang == ""sin"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.01
-        if not FONTS:
-            FONTS = SINHALA_FONTS
-    elif lang == ""tam"":
-        MEAN_COUNT = 30
-        WORD_DAWG_FACTOR = 0.15
-        TRAINING_DATA_ARGUMENTS += [""--no_newline_in_output""]
-        TEXT2IMAGE_EXTRA_ARGS += [""--char_spacing=0.5""]
-        if not FONTS:
-            FONTS = TAMIL_FONTS
-    elif lang == ""tel"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        TRAINING_DATA_ARGUMENTS += [""--no_newline_in_output""]
-        TEXT2IMAGE_EXTRA_ARGS += [""--char_spacing=0.5""]
-        if not FONTS:
-            FONTS = TELUGU_FONTS
-
-        # SouthEast Asian scripts.
-    elif lang == ""jav_java"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        if not FONTS:
-            FONTS = JAVANESE_FONTS
-    elif lang == ""khm"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        if not FONTS:
-            FONTS = KHMER_FONTS
-    elif lang == ""lao"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.15
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        if not FONTS:
-            FONTS = LAOTHIAN_FONTS
-    elif lang == ""mya"":
-        MEAN_COUNT = 12
-        WORD_DAWG_FACTOR = 0.15
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        if not FONTS:
-            FONTS = BURMESE_FONTS
-    elif lang == ""tha"":
-        MEAN_COUNT = 30
-        WORD_DAWG_FACTOR = 0.01
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        FILTER_ARGUMENTS += [""--segmenter_lang=tha""]
-        TRAINING_DATA_ARGUMENTS += [""--no_space_in_output"", ""--desired_bigrams=""]
-        AMBIGS_FILTER_DENOMINATOR = ""1000""
-        LEADING = 48
-        if not FONTS:
-            FONTS = THAI_FONTS
-
-        # CJK
-    elif lang == ""chi_sim"":
-        MEAN_COUNT = 15
-        PUNC_DAWG_FACTOR = 0.015
-        WORD_DAWG_FACTOR = 0.015
-        GENERATE_WORD_BIGRAMS = 0
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        TRAINING_DATA_ARGUMENTS += [""--no_space_in_output"", ""--desired_bigrams=""]
-        FILTER_ARGUMENTS += [""--charset_filter=chi_sim"", ""--segmenter_lang=chi_sim""]
-        if not FONTS:
-            FONTS = CHI_SIM_FONTS
-    elif lang == ""chi_tra"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.015
-        GENERATE_WORD_BIGRAMS = 0
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        TRAINING_DATA_ARGUMENTS += [""--no_space_in_output"", ""--desired_bigrams=""]
-        FILTER_ARGUMENTS += [""--charset_filter=chi_tr"", ""--segmenter_lang=chi_tra""]
-        if not FONTS:
-            FONTS = CHI_TRA_FONTS
-    elif lang == ""jpn"":
-        MEAN_COUNT = 15
-        WORD_DAWG_FACTOR = 0.015
-        GENERATE_WORD_BIGRAMS = 0
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        TRAINING_DATA_ARGUMENTS += [""--no_space_in_output"", ""--desired_bigrams=""]
-        FILTER_ARGUMENTS += [""--charset_filter=jpn"", ""--segmenter_lang=jpn""]
-        if not FONTS:
-            FONTS = JPN_FONTS
-    elif lang == ""kor"":
-        MEAN_COUNT = 20
-        WORD_DAWG_FACTOR = 0.015
-        NUMBER_DAWG_FACTOR = 0.05
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=10000""]
-        TRAINING_DATA_ARGUMENTS += [""--desired_bigrams=""]
-        GENERATE_WORD_BIGRAMS = 0
-        FILTER_ARGUMENTS += [""--charset_filter=kor"", ""--segmenter_lang=kor""]
-        if not FONTS:
-            FONTS = KOREAN_FONTS
-
-        # Middle-Eastern scripts.
-    elif lang == ""ara"":
-        if not FONTS:
-            FONTS = ARABIC_FONTS
-    elif lang == ""div"":
-        if not FONTS:
-            FONTS = THAANA_FONTS
-    elif lang in (""fas"", ""pus"", ""snd"", ""uig"", ""urd""):
-        if not FONTS:
-            FONTS = PERSIAN_FONTS
-    elif lang in (""heb"", ""yid""):
-        NUMBER_DAWG_FACTOR = 0.05
-        WORD_DAWG_FACTOR = 0.08
-        if not FONTS:
-            FONTS = HEBREW_FONTS
-    elif lang == ""syr"":
-        if not FONTS:
-            FONTS = SYRIAC_FONTS
-
-        # Other scripts.
-    elif lang in (""amh"", ""tir""):
-        if not FONTS:
-            FONTS = AMHARIC_FONTS
-    elif lang == ""chr"":
-        if not FONTS:
-            FONTS = [*NORTH_AMERICAN_ABORIGINAL_FONTS, ""Noto Sans Cherokee""]
-    elif lang == ""ell"":
-        NUMBER_DAWG_FACTOR = 0.05
-        WORD_DAWG_FACTOR = 0.08
-        if not FONTS:
-            FONTS = GREEK_FONTS
-    elif lang == ""grc"":
-        if not EXPOSURES:
-            EXPOSURES = ""-3 -2 -1 0 1 2 3"".split()
-        if not FONTS:
-            FONTS = ANCIENT_GREEK_FONTS
-    elif lang == ""hye"":
-        if not FONTS:
-            FONTS = ARMENIAN_FONTS
-    elif lang == ""iku"":
-        if not FONTS:
-            FONTS = NORTH_AMERICAN_ABORIGINAL_FONTS
-    elif lang == ""kat"":
-        if not FONTS:
-            FONTS = GEORGIAN_FONTS
-    elif lang == ""kat_old"":
-        TEXT_CORPUS = f""{FLAGS_webtext_prefix}/kat.corpus.txt""
-        if not FONTS:
-            FONTS = OLD_GEORGIAN_FONTS
-    elif lang == ""kir"":
-        if not FONTS:
-            FONTS = KYRGYZ_FONTS
-        TRAINING_DATA_ARGUMENTS += [""--infrequent_ratio=100""]
-    elif lang == ""kmr"":
-        if not FONTS:
-            FONTS = LATIN_FONTS
-    elif lang == ""kur_ara"":
-        if not FONTS:
-            FONTS = KURDISH_FONTS
-    else:
-        raise ValueError(f""Error: {lang} is not a valid language code"")
-
-    FLAGS_mean_count = int(os.environ.get(""FLAGS_mean_count"", -1))
-    if FLAGS_mean_count > 0:
-        TRAINING_DATA_ARGUMENTS += [f""--mean_count={FLAGS_mean_count}""]
-    elif not MEAN_COUNT:
-        TRAINING_DATA_ARGUMENTS += [f""--mean_count={MEAN_COUNT}""]
-
-    # Default to Latin fonts if none have been set
-    if not FONTS:
-        FONTS = LATIN_FONTS
-
-    # Default to 0 exposure if it hasn't been set
-    if not EXPOSURES:
-        EXPOSURES = [0]
-    # Set right-to-left and normalization mode.
-    if lang in (
-            ""ara"",
-            ""div"",
-            ""fas"",
-            ""pus"",
-            ""snd"",
-            ""syr"",
-            ""uig"",
-            ""urd"",
-            ""kur_ara"",
-            ""heb"",
-            ""yid"",
-    ):
-        LANG_IS_RTL = True
-        NORM_MODE = 2
-    elif lang in (
-            ""asm"",
-            ""ben"",
-            ""bih"",
-            ""hin"",
-            ""mar"",
-            ""nep"",
-            ""guj"",
-            ""kan"",
-            ""mal"",
-            ""tam"",
-            ""tel"",
-            ""pan"",
-            ""dzo"",
-            ""sin"",
-            ""san"",
-            ""bod"",
-            ""ori"",
-            ""khm"",
-            ""mya"",
-            ""tha"",
-            ""lao"",
-            ""jav "",
-            ""jav_java"",
-    ):
-        LANG_IS_RTL = False
-        NORM_MODE = 2
-    else:
-        LANG_IS_RTL = False
-        NORM_MODE = 1
-
-    vars_to_transfer = {
-        'ambigs_filter_denominator': AMBIGS_FILTER_DENOMINATOR,
-        'bigram_dawg_factor': BIGRAM_DAWG_FACTOR,
-        'exposures': EXPOSURES,
-        'filter_arguments': FILTER_ARGUMENTS,
-        'fonts': FONTS,
-        'fragments_disabled': FRAGMENTS_DISABLED,
-        'generate_word_bigrams': GENERATE_WORD_BIGRAMS,
-        'lang_is_rtl': LANG_IS_RTL,
-        'leading': LEADING,
-        'mean_count': MEAN_COUNT,
-        'mix_lang': MIX_LANG,
-        'norm_mode': NORM_MODE,
-        'number_dawg_factor': NUMBER_DAWG_FACTOR,
-        'punc_dawg_factor': PUNC_DAWG_FACTOR,
-        'run_shape_clustering': RUN_SHAPE_CLUSTERING,
-        'text2image_extra_args': TEXT2IMAGE_EXTRA_ARGS,
-        'text_corpus': TEXT_CORPUS,
-        'training_data_arguments': TRAINING_DATA_ARGUMENTS,
-        'word_dawg_factor': WORD_DAWG_FACTOR,
-        'word_dawg_size': WORD_DAWG_SIZE,
-        'wordlist2dawg_arguments': WORDLIST2DAWG_ARGUMENTS,
-    }
-
-    for attr, value in vars_to_transfer.items():
-        if hasattr(ctx, attr):
-            if getattr(ctx, attr) != value:
-                log.debug(f""{attr} = {value} (was {getattr(ctx, attr)})"")
-                setattr(ctx, attr, value)
-            else:
-                log.debug(f""{attr} = {value} (set on cmdline)"")
-        else:
-            log.debug(f""{attr} = {value}"")
-            setattr(ctx, attr, value)
-
-    return ctx
-
-# =============================================================================
-# END of Language specific info
-# =============================================================================
diff --git a/src/training/tesstrain.py b/src/training/tesstrain.py
deleted file mode 100755
index cbc072a527..0000000000
--- a/src/training/tesstrain.py
+++ /dev/null
@@ -1,112 +0,0 @@
-#!/usr/bin/env python3
-
-# (C) Copyright 2014, Google Inc.
-# (C) Copyright 2018, James R Barlow
-# Licensed under the Apache License, Version 2.0 (the ""License"");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-# http://www.apache.org/licenses/LICENSE-2.0
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an ""AS IS"" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-# This script provides an easy way to execute various phases of training
-# Tesseract.  For a detailed description of the phases, see
-# https://tesseract-ocr.github.io/tessdoc/Training-Tesseract.html.
-
-import logging
-import os
-import sys
-
-if (sys.version_info.major < 3) or (sys.version_info.major == 3 and sys.version_info.minor < 6):
-    raise Exception(""Must be using Python minimum version 3.6!"")
-
-sys.path.insert(0, os.path.dirname(__file__))
-from tesstrain_utils import (
-    parse_flags,
-    initialize_fontconfig,
-    phase_I_generate_image,
-    phase_UP_generate_unicharset,
-    phase_E_extract_features,
-    make_lstmdata,
-    cleanup,
-)
-import language_specific
-
-log = logging.getLogger()
-
-
-def setup_logging_console():
-    log.setLevel(logging.DEBUG)
-    console = logging.StreamHandler()
-    console.setLevel(logging.INFO)
-    console_formatter = logging.Formatter(
-        ""[%(asctime)s] %(levelname)s - %(message)s"", datefmt=""%H:%M:%S""
-    )
-    console.setFormatter(console_formatter)
-    log.addHandler(console)
-
-
-def setup_logging_logfile(logfile):
-    logfile = logging.FileHandler(logfile, encoding='utf-8')
-    logfile.setLevel(logging.DEBUG)
-    logfile_formatter = logging.Formatter(
-        ""[%(asctime)s] - %(levelname)s - %(name)s - %(message)s""
-    )
-    logfile.setFormatter(logfile_formatter)
-    log.addHandler(logfile)
-    return logfile
-
-
-def main():
-    setup_logging_console()
-    ctx = parse_flags()
-    logfile = setup_logging_logfile(ctx.log_file)
-    if not ctx.linedata:
-        log.error(""--linedata_only is required since only LSTM is supported"")
-        sys.exit(1)
-
-    log.info(f""=== Starting training for language {ctx.lang_code}"")
-    ctx = language_specific.set_lang_specific_parameters(ctx, ctx.lang_code)
-
-    initialize_fontconfig(ctx)
-    phase_I_generate_image(ctx, par_factor=8)
-    phase_UP_generate_unicharset(ctx)
-
-    if ctx.linedata:
-        phase_E_extract_features(ctx, [""lstm.train""], ""lstmf"")
-        make_lstmdata(ctx)
-
-    log.removeHandler(logfile)
-    logfile.close()
-    cleanup(ctx)
-    log.info(""All done!"")
-    return 0
-
-
-if __name__ == ""__main__"":
-    main()
-
-# _rc0 = subprocess.call([""tlog"",""\n=== Starting training for language '""+str(LANG_CODE.val)+""'""],shell=True)
-# _rc0 = subprocess.call([""source"",os.popen(""dirname ""+__file__).read().rstrip(""\n"")+""/language-specific.sh""],shell=True)
-# _rc0 = subprocess.call([""set_lang_specific_parameters"",str(LANG_CODE.val)],shell=True)
-# _rc0 = subprocess.call([""initialize_fontconfig""],shell=True)
-# _rc0 = subprocess.call([""phase_I_generate_image"",""8""],shell=True)
-# _rc0 = subprocess.call([""phase_UP_generate_unicharset""],shell=True)
-# if (LINEDATA ):
-# subprocess.call([""phase_E_extract_features"","" --psm 6  lstm.train "",""8"",""lstmf""],shell=True)
-#     subprocess.call([""make__lstmdata""],shell=True)
-#     subprocess.call([""tlog"",""\nCreated starter traineddata for language '""+str(LANG_CODE.val)+""'\n""],shell=True)
-#     subprocess.call([""tlog"",""\nRun lstmtraining to do the LSTM training for language '""+str(LANG_CODE.val)+""'\n""],shell=True)
-# else:
-#     subprocess.call([""phase_D_generate_dawg""],shell=True)
-#     subprocess.call([""phase_E_extract_features"",""box.train"",""8"",""tr""],shell=True)
-#     subprocess.call([""phase_C_cluster_prototypes"",str(TRAINING_DIR.val)+""/""+str(LANG_CODE.val)+"".normproto""],shell=True)
-#     if (str(ENABLE_SHAPE_CLUSTERING.val) == ""y"" ):
-#         subprocess.call([""phase_S_cluster_shapes""],shell=True)
-#     subprocess.call([""phase_M_cluster_microfeatures""],shell=True)
-#     subprocess.call([""phase_B_generate_ambiguities""],shell=True)
-#     subprocess.call([""make__traineddata""],shell=True)
-#     subprocess.call([""tlog"",""\nCompleted training for language '""+str(LANG_CODE.val)+""'\n""],shell=True)
diff --git a/src/training/tesstrain_utils.py b/src/training/tesstrain_utils.py
deleted file mode 100644
index a88c099796..0000000000
--- a/src/training/tesstrain_utils.py
+++ /dev/null
@@ -1,734 +0,0 @@
-# (C) Copyright 2014, Google Inc.
-# (C) Copyright 2018, James R Barlow
-# Licensed under the Apache License, Version 2.0 (the ""License"");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-# http://www.apache.org/licenses/LICENSE-2.0
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an ""AS IS"" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-# For a detailed description of the phases, see
-# https://tesseract-ocr.github.io/tessdoc/Training-Tesseract.html.
-#
-
-import argparse
-import atexit
-import concurrent.futures
-import logging
-import os
-import pathlib
-import platform
-import shutil
-import subprocess
-import sys
-from datetime import date
-from operator import itemgetter
-from tempfile import TemporaryDirectory, mkdtemp
-
-from tqdm import tqdm
-
-from language_specific import VERTICAL_FONTS
-
-log = logging.getLogger(__name__)
-
-
-class TrainingArgs(argparse.Namespace):
-    def __init__(self):
-        super(TrainingArgs, self).__init__()
-        self.uname = platform.uname().system.lower()
-        self.lang_code = ""eng""
-        self.timestamp = str(date.today())
-
-        self._font_config_cache = TemporaryDirectory(prefix=""font_tmp"")
-        self.font_config_cache = self._font_config_cache.name
-        self.fonts_dir = (
-            ""/Library/Fonts/"" if ""darwin"" in self.uname else ""/usr/share/fonts/""
-        )
-
-        self.max_pages = 0
-        self.save_box_tiff = False
-        self.overwrite = False
-        self.linedata = False
-        self.run_shape_clustering = False
-        self.extract_font_properties = True
-        self.distort_image = False
-
-    def __eq__(self, other):
-        return (argparse.Namespace.__eq__(self, other) and
-        self.uname == other.uname and self.lang_code == other.lang_code and
-        self.timestamp == other.timestamp and self.font_config_cache == other.font_config_cache and
-        self.fonts_dir == other.fonts_dir and self.max_pages == other.max_pages and
-        self.save_box_tiff == other.save_box_tiff and self.overwrite == other.overwrite and
-        self.linedata == other.linedata and self.run_shape_clustering == other.run_shape_clustering and
-        self.extract_font_properties == other.extract_font_properties and
-        self.distort_image == other.distort_image)
-
-
-def err_exit(msg):
-    log.critical(msg)
-    sys.exit(1)
-
-
-# Helper function to run a command and append its output to a log. Aborts early
-# if the program file is not found.
-# Usage: run_command CMD ARG1 ARG2...
-def run_command(cmd, *args, env=None):
-    for d in ("""", ""api/"", ""training/""):
-        testcmd = shutil.which(f""{d}{cmd}"")
-        if shutil.which(testcmd):
-            cmd = testcmd
-            break
-    if not shutil.which(cmd):
-        err_exit(f""{cmd} not found"")
-
-    log.debug(f""Running {cmd}"")
-    args = list(args)
-    for idx, arg in enumerate(args):
-        log.debug(arg)
-        # Workaround for https://bugs.python.org/issue33617
-        # TypeError: argument of type 'WindowsPath' is not iterable
-        if isinstance(arg, pathlib.WindowsPath):
-            args[idx] = str(arg)
-
-    proc = subprocess.run(
-        [cmd, *args], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, env=env
-    )
-    proclog = logging.getLogger(cmd)
-    if proc.returncode == 0:
-        proclog.debug(proc.stdout.decode(""utf-8"", errors=""replace""))
-    else:
-        try:
-            proclog.error(proc.stdout.decode(""utf-8"", errors=""replace""))
-        except Exception as e:
-            proclog.error(e)
-        err_exit(f""Program {cmd} failed with return code {proc.returncode}. Abort."")
-
-
-# Check if all the given files exist, or exit otherwise.
-# Used to check required input files and produced output files in each phase.
-# Usage: check_file_readable FILE1 FILE2...
-def check_file_readable(*filenames):
-    if isinstance(filenames, (str, pathlib.Path)):
-        filenames = [filenames]
-    for filename in filenames:
-        try:
-            with pathlib.Path(filename).open():
-                pass
-        except FileNotFoundError:
-            err_exit(f""Required/expected file '{filename}' does not exist"")
-        except PermissionError:
-            err_exit(f""{filename} is not readable"")
-        except IOError as e:
-            err_exit(f""{filename} IO Error: {str(e)}"")
-    return True
-
-
-parser = argparse.ArgumentParser(
-    epilog=""""""
-    The font names specified in --fontlist need to be recognizable by Pango using
-    fontconfig. An easy way to list the canonical names of all fonts available on
-    your system is to run text2image with --list_available_fonts and the
-    appropriate --fonts_dir path.
-    """"""
-)
-parser.add_argument(
-    ""--fontlist"",
-    dest=""fonts"",
-    nargs=""+"",
-    type=str,
-    help=""A list of fontnames to train on."",
-)
-parser.add_argument(""--fonts_dir"", help=""Path to font files."")
-parser.add_argument(""--tmp_dir"", help=""Path to temporary training directory."")
-parser.add_argument(
-    ""--lang"", metavar=""LANG_CODE"", dest=""lang_code"", help=""ISO 639 code.""
-)
-parser.add_argument(
-    ""--langdata_dir"",
-    metavar=""DATADIR"",
-    help=""Path to tesseract/training/langdata directory."",
-)
-parser.add_argument(""--maxpages"", type=int, dest=""max_pages"")
-parser.add_argument(
-    ""--output_dir"", metavar=""OUTPUTDIR"", help=""Location of output traineddata file.""
-)
-parser.add_argument(
-    ""--overwrite"", action=""store_true"", help=""Safe to overwrite files in output_dir.""
-)
-parser.add_argument(
-    ""--save_box_tiff"",
-    action=""store_true"",
-    help=""Save box/tiff pairs along with lstmf files."",
-)
-parser.add_argument(
-    ""--linedata_only"",
-    dest=""linedata"",
-    action=""store_true"",
-    help=""Only generate training data for lstmtraining."",
-)
-
-inputdata_group = parser.add_argument_group(
-    ""inputdata"",
-    ""OPTIONAL flags for input data. If unspecified we will look for them in the langdata_dir directory."",
-)
-inputdata_group.add_argument(
-    ""--training_text"", metavar=""TEXTFILE"", help=""Text to render and use for training.""
-)
-inputdata_group.add_argument(
-    ""--wordlist"",
-    dest=""wordlist_file"",
-    metavar=""WORDFILE"",
-    help=""Word list for the language ordered by decreasing frequency."",
-)
-
-parser.add_argument(""--extract_font_properties"", action=""store_true"")
-parser.add_argument(
-    ""--noextract_font_properties"", dest=""extract_font_properties"", action=""store_false""
-)
-
-parser.add_argument(
-    ""--distort_image"", dest=""distort_image"", action=""store_true""
-)
-
-tessdata_group = parser.add_argument_group(
-    ""tessdata"",
-    ""OPTIONAL flag to specify location of existing traineddata files, required during feature extraction. If unspecified will use TESSDATA_PREFIX defined in the current environment."",
-)
-tessdata_group.add_argument(
-    ""--tessdata_dir"",
-    metavar=""TESSDATADIR"",
-    help=""Path to tesseract/tessdata directory."",
-)
-
-parser.add_argument(
-    ""--exposures"",
-    metavar=""EXPOSURES"",
-    action=""append"",
-    nargs=""+"",
-    help=""A list of exposure levels to use (e.g. -1,0,1)."",
-)
-
-
-# Does simple command-line parsing and initialization.
-def parse_flags(argv=None):
-    ctx = TrainingArgs()
-    log.debug(ctx)
-    parser.parse_args(args=argv, namespace=ctx)
-    log.debug(ctx)
-
-    if not ctx.lang_code:
-        err_exit(""Need to specify a language --lang"")
-    if not ctx.langdata_dir:
-        err_exit(""Need to specify path to language files --langdata_dir"")
-    if not ctx.tessdata_dir:
-        tessdata_prefix = os.environ.get(""TESSDATA_PREFIX"", """")
-        if not tessdata_prefix:
-            err_exit(
-                ""Need to specify a --tessdata_dir or have a ""
-                ""TESSDATA_PREFIX variable defined in your environment""
-            )
-        else:
-            ctx.tessdata_dir = tessdata_prefix
-    if not ctx.output_dir:
-        ctx.output_dir = mkdtemp(prefix=f""trained-{ctx.lang_code}-{ctx.timestamp}"")
-        log.info(f""Output directory set to: {ctx.output_dir}"")
-
-    # Location where intermediate files will be created.
-    if not ctx.tmp_dir:
-        ctx.training_dir = mkdtemp(prefix=f""{ctx.lang_code}-{ctx.timestamp}"")
-    else:
-        ctx.training_dir = mkdtemp(prefix=f""{ctx.lang_code}-{ctx.timestamp}"", dir=ctx.tmp_dir)
-    # Location of log file for the whole run.
-    ctx.log_file = pathlib.Path(ctx.training_dir) / ""tesstrain.log""
-    log.info(f""Log file location: {ctx.log_file}"")
-
-    def show_tmpdir_location(training_dir):
-        # On successful exit we will delete this first; on failure we want to let the user
-        # know where the log is
-        if pathlib.Path(training_dir).exists():
-            print(f""Temporary files retained at: {training_dir}"")
-
-    atexit.register(show_tmpdir_location, ctx.training_dir)
-
-    # Take training text and wordlist from the langdata directory if not
-    # specified in the command-line.
-    if not ctx.training_text:
-        ctx.training_text = (
-                pathlib.Path(ctx.langdata_dir) / ctx.lang_code / f""{ctx.lang_code}.training_text""
-        )
-    if not ctx.wordlist_file:
-        ctx.wordlist_file = (
-                pathlib.Path(ctx.langdata_dir) / ctx.lang_code / f""{ctx.lang_code}.wordlist""
-        )
-
-    ctx.word_bigrams_file = (
-            pathlib.Path(ctx.langdata_dir) / ctx.lang_code / f""{ctx.lang_code}.word.bigrams""
-    )
-    ctx.numbers_file = (
-            pathlib.Path(ctx.langdata_dir) / ctx.lang_code / f""{ctx.lang_code}.numbers""
-    )
-    ctx.punc_file = pathlib.Path(ctx.langdata_dir) / ctx.lang_code / f""{ctx.lang_code}.punc""
-    ctx.bigram_freqs_file = pathlib.Path(ctx.training_text).with_suffix(
-        "".training_text.bigram_freqs""
-    )
-    ctx.unigram_freqs_file = pathlib.Path(ctx.training_text).with_suffix(
-        "".training_text.unigram_freqs""
-    )
-    ctx.train_ngrams_file = pathlib.Path(ctx.training_text).with_suffix(
-        "".training_text.train_ngrams""
-    )
-    ctx.generate_dawgs = 1
-    log.debug(ctx)
-    return ctx
-
-
-def cleanup(ctx):
-    shutil.copy(ctx.log_file, ctx.output_dir)
-    shutil.rmtree(ctx.training_dir)
-    return
-
-
-# Function initializes font config with a unique font cache dir.
-def initialize_fontconfig(ctx):
-    sample_path = pathlib.Path(ctx.font_config_cache) / ""sample_text.txt""
-    pathlib.Path(sample_path).write_text(""Text\n"")
-    log.info(f""Testing font: {ctx.fonts[0]}"")
-    run_command(
-        ""text2image"",
-        f""--fonts_dir={ctx.fonts_dir}"",
-        f""--font={ctx.fonts[0]}"",
-        f""--outputbase={sample_path}"",
-        f""--text={sample_path}"",
-        f""--fontconfig_tmpdir={ctx.font_config_cache}"",
-    )
-
-
-def make_fontname(font):
-    return font.replace("" "", ""_"").replace("","", """")
-
-
-def make_outbase(ctx, fontname, exposure):
-    return pathlib.Path(ctx.training_dir) / f""{ctx.lang_code}.{fontname}.exp{exposure}""
-
-
-# Helper function for phaseI_generate_image. Generates the image for a single
-# language/font combination in a way that can be run in parallel.
-def generate_font_image(ctx, font, exposure, char_spacing):
-    log.info(f""Rendering using {font}"")
-    fontname = make_fontname(font)
-    outbase = make_outbase(ctx, fontname, exposure)
-
-    common_args = [
-        f""--fontconfig_tmpdir={ctx.font_config_cache}"",
-        f""--fonts_dir={ctx.fonts_dir}"",
-        f""--strip_unrenderable_words"",
-        f""--leading={ctx.leading}"",
-        f""--char_spacing={char_spacing}"",
-        f""--exposure={exposure}"",
-        f""--outputbase={outbase}"",
-        f""--max_pages={ctx.max_pages}"",
-    ]
-
-    if ctx.distort_image:
-        common_args.append(""--distort_image"")
-
-    # add --writing_mode=vertical-upright to common_args if the font is
-    # specified to be rendered vertically.
-    if font in VERTICAL_FONTS:
-        common_args.append(""--writing_mode=vertical-upright"")
-
-    run_command(
-        ""text2image"",
-        *common_args,
-        f""--font={font}"",
-        f""--text={ctx.training_text}"",
-        *ctx.text2image_extra_args,
-    )
-
-    check_file_readable(str(outbase) + "".box"", str(outbase) + "".tif"")
-
-    if ctx.extract_font_properties and pathlib.Path(ctx.train_ngrams_file).exists():
-        log.info(f""Extracting font properties of {font}"")
-        run_command(
-            ""text2image"",
-            *common_args,
-            f""--font={font}"",
-            f""--ligatures=false"",
-            f""--text={ctx.train_ngrams_file}"",
-            f""--only_extract_font_properties"",
-            f""--ptsize=32"",
-        )
-        check_file_readable(str(outbase) + "".fontinfo"")
-    return f""{font}-{exposure}""
-
-
-# Phase I : Generate (I)mages from training text for each font.
-def phase_I_generate_image(ctx, par_factor=None):
-    if not par_factor or par_factor <= 0:
-        par_factor = 1
-
-    log.info(""=== Phase I: Generating training images ==="")
-    check_file_readable(ctx.training_text)
-    char_spacing = 0.0
-
-    for exposure in ctx.exposures:
-        if ctx.extract_font_properties and pathlib.Path(ctx.bigram_freqs_file).exists():
-            # Parse .bigram_freqs file and compose a .train_ngrams file with text
-            # for tesseract to recognize during training. Take only the ngrams whose
-            # combined weight accounts for 95% of all the bigrams in the language.
-            lines = pathlib.Path(ctx.bigram_freqs_file).read_text(encoding=""utf-8"").split(""\n"")
-            records = (line.split() for line in lines)
-            p = 0.99
-            ngram_frac = p * sum(int(rec[1]) for rec in records if len(rec) >= 2)
-
-            with pathlib.Path(ctx.train_ngrams_file).open(""w"", encoding=""utf-8"") as f:
-                cumsum = 0
-                for bigram, count in sorted(records, key=itemgetter(1), reverse=True):
-                    if cumsum > ngram_frac:
-                        break
-                    f.write(bigram + "" "")
-                    cumsum += count
-
-            check_file_readable(ctx.train_ngrams_file)
-
-        with tqdm(
-                total=len(ctx.fonts)
-        ) as pbar, concurrent.futures.ThreadPoolExecutor(max_workers=par_factor) as executor:
-            futures = [
-                executor.submit(generate_font_image, ctx, font, exposure, char_spacing)
-                for font in ctx.fonts
-            ]
-            for future in concurrent.futures.as_completed(futures):
-                try:
-                    future.result()
-                except Exception as exc:
-                    err_exit(""Failed while generating images "" + str(exc))
-                else:
-                    pbar.update(1)
-
-        # Check that each process was successful.
-        for font in ctx.fonts:
-            fontname = make_fontname(font)
-            outbase = make_outbase(ctx, fontname, exposure)
-            check_file_readable(str(outbase) + "".box"", str(outbase) + "".tif"")
-    return
-
-
-# Phase UP : Generate (U)nicharset and (P)roperties file.
-def phase_UP_generate_unicharset(ctx):
-    log.info(""=== Phase UP: Generating unicharset and unichar properties files ==="")
-
-    box_files = pathlib.Path(ctx.training_dir).glob(""*.box"")
-
-    ctx.unicharset_file = pathlib.Path(ctx.training_dir) / f""{ctx.lang_code}.unicharset""
-
-    run_command(
-        ""unicharset_extractor"",
-        ""--output_unicharset"",
-        f""{ctx.unicharset_file}"",
-        ""--norm_mode"",
-        f""{ctx.norm_mode}"",
-        *box_files,
-    )
-    check_file_readable(ctx.unicharset_file)
-
-    ctx.xheights_file = pathlib.Path(ctx.training_dir) / f""{ctx.lang_code}.xheights""
-    run_command(
-        ""set_unicharset_properties"",
-        ""-U"",
-        f""{ctx.unicharset_file}"",
-        ""-O"",
-        f""{ctx.unicharset_file}"",
-        ""-X"",
-        f""{ctx.xheights_file}"",
-        f""--script_dir={ctx.langdata_dir}"",
-    )
-    check_file_readable(ctx.xheights_file)
-
-
-# # Phase D : Generate (D)awg files from unicharset file and wordlist files
-# phase_D_generate_dawg() {
-#     tlog ""\n=== Phase D: Generating Dawg files ===""
-
-#     # Skip if requested
-#     if [[ ${GENERATE_DAWGS} -eq 0 ]]; then
-#       tlog ""Skipping ${phase_name}""
-#       return
-#     fi
-
-#     # Output files
-#     WORD_DAWG=${TRAINING_DIR}/${LANG_CODE}.word-dawg
-#     FREQ_DAWG=${TRAINING_DIR}/${LANG_CODE}.freq-dawg
-#     PUNC_DAWG=${TRAINING_DIR}/${LANG_CODE}.punc-dawg
-#     NUMBER_DAWG=${TRAINING_DIR}/${LANG_CODE}.number-dawg
-#     BIGRAM_DAWG=${TRAINING_DIR}/${LANG_CODE}.bigram-dawg
-
-#     # Word DAWG
-#     local freq_wordlist_file=${TRAINING_DIR}/${LANG_CODE}.wordlist.clean.freq
-#     if [[ -s ${WORDLIST_FILE} ]]; then
-#         tlog ""Generating word Dawg""
-#         check_file_readable ${unicharset_file}
-#         run_command wordlist2dawg -r 1 ${WORDLIST_FILE} ${WORD_DAWG} \
-#             ${UNICHARSET_FILE}
-#         check_file_readable ${WORD_DAWG}
-
-#         FREQ_DAWG_SIZE=100
-#         head -n ${FREQ_DAWG_SIZE} ${WORDLIST_FILE} > ${freq_wordlist_file}
-#     fi
-
-#     # Freq-word DAWG
-#     if [[ -s ${freq_wordlist_file} ]]; then
-#         check_file_readable ${UNICHARSET_FILE}
-#         tlog ""Generating frequent-word Dawg""
-#         run_command wordlist2dawg  -r 1 ${freq_wordlist_file} \
-#             ${FREQ_DAWG} ${UNICHARSET_FILE}
-#         check_file_readable ${FREQ_DAWG}
-#     fi
-
-#     # Punctuation DAWG
-#     # -r arguments to wordlist2dawg denote RTL reverse policy
-#     # (see Trie::RTLReversePolicy enum in tesseract/src/dict/trie.h).
-#     # We specify 0/RRP_DO_NO_REVERSE when generating number DAWG,
-#     # 1/RRP_REVERSE_IF_HAS_RTL for freq and word DAWGS,
-#     # 2/RRP_FORCE_REVERSE for the punctuation DAWG.
-#     local punc_reverse_policy=0;
-#     if [[ ""${LANG_IS_RTL}"" == ""1"" ]]; then
-#       punc_reverse_policy=2
-#     fi
-#     if [[ ! -s ${PUNC_FILE} ]]; then
-#         PUNC_FILE=""{ctx.langdata_dir}/common.punc""
-#     fi
-#     check_file_readable ${PUNC_FILE}
-#     run_command wordlist2dawg -r ${punc_reverse_policy} \
-#         ${PUNC_FILE} ${PUNC_DAWG} ${UNICHARSET_FILE}
-#     check_file_readable ${PUNC_DAWG}
-
-#     # Numbers DAWG
-#     if [[ -s ${NUMBERS_FILE} ]]; then
-#         run_command wordlist2dawg -r 0 \
-#             ${NUMBERS_FILE} ${NUMBER_DAWG} ${UNICHARSET_FILE}
-#         check_file_readable ${NUMBER_DAWG}
-#     fi
-
-#     # Bigram dawg
-#     if [[ -s ${WORD_BIGRAMS_FILE} ]]; then
-#         run_command wordlist2dawg -r 1 \
-#             ${WORD_BIGRAMS_FILE} ${BIGRAM_DAWG} ${UNICHARSET_FILE}
-#         check_file_readable ${BIGRAM_DAWG}
-#     fi
-# }
-
-# Phase E : (E)xtract .tr feature files from .tif/.box files
-def phase_E_extract_features(ctx, box_config, ext):
-    log.info(f""=== Phase E: Generating {ext} files ==="")
-
-    img_files = list(pathlib.Path(ctx.training_dir).glob(""*.exp*.tif""))
-    log.debug(img_files)
-
-    # Use any available language-specific configs.
-    config = """"
-    testconfig = pathlib.Path(ctx.langdata_dir) / ctx.lang_code / f""{ctx.lang_code}.config""
-    if testconfig.exists():
-        config = testconfig
-        log.info(f""Using {ctx.lang_code}.config"")
-
-    tessdata_environ = os.environ.copy()
-    tessdata_environ[""TESSDATA_PREFIX""] = str(ctx.tessdata_dir)
-
-    log.info(f""Using TESSDATA_PREFIX={tessdata_environ['TESSDATA_PREFIX']}"")
-
-    with tqdm(total=len(img_files)) as pbar, concurrent.futures.ThreadPoolExecutor(
-            max_workers=2
-    ) as executor:
-        futures = []
-        for img_file in img_files:
-            future = executor.submit(
-                run_command,
-                ""tesseract"",
-                img_file,
-                pathlib.Path(img_file).with_suffix(""""),
-                *box_config,
-                config,
-                env=tessdata_environ,
-            )
-            futures.append(future)
-
-        for future in concurrent.futures.as_completed(futures):
-            try:
-                future.result()
-            except Exception as exc:
-                err_exit(""Failed while extracting features: "" + str(exc))
-            else:
-                pbar.update(1)
-    # Check that all the output files were produced.
-    for img_file in img_files:
-        check_file_readable(pathlib.Path(img_file.with_suffix(""."" + ext)))
-
-    return
-
-
-# # Phase C : (C)luster feature prototypes in .tr into normproto file (cnTraining)
-# # phaseC_cluster_prototypes ${TRAINING_DIR}/${LANG_CODE}.normproto
-# phase_C_cluster_prototypes() {
-#     tlog ""\n=== Phase C: Clustering feature prototypes (cnTraining) ===""
-#     local out_normproto=$1
-
-#     run_command cntraining -D ""${TRAINING_DIR}/"" \
-#         $(ls ${TRAINING_DIR}/*.tr)
-
-#     check_file_readable ${TRAINING_DIR}/normproto
-#     mv ${TRAINING_DIR}/normproto ${out_normproto}
-# }
-
-# # Phase S : (S)hape clustering
-# phase_S_cluster_shapes() {
-#     if ((! RUN_SHAPE_CLUSTERING)); then
-#         tlog ""\n=== Shape Clustering disabled ===""
-#         return
-#     fi
-#     check_file_readable {ctx.langdata_dir}/font_properties
-#     local font_props=""-F {ctx.langdata_dir}/font_properties""
-#     if [[ -r ${TRAINING_DIR}/${LANG_CODE}.xheights ]] &&\
-#        [[ -s ${TRAINING_DIR}/${LANG_CODE}.xheights ]]; then
-#         font_props=${font_props}"" -X ${TRAINING_DIR}/${LANG_CODE}.xheights""
-#     fi
-
-#     run_command shapeclustering \
-#         -D ""${TRAINING_DIR}/"" \
-#         -U ${TRAINING_DIR}/${LANG_CODE}.unicharset \
-#         -O ${TRAINING_DIR}/${LANG_CODE}.mfunicharset \
-#         ${font_props} \
-#         $(ls ${TRAINING_DIR}/*.tr)
-#     check_file_readable ${TRAINING_DIR}/shapetable \
-#         ${TRAINING_DIR}/${LANG_CODE}.mfunicharset
-# }
-
-# # Phase M : Clustering microfeatures (mfTraining)
-# phase_M_cluster_microfeatures() {
-#     tlog ""\n=== Phase M : Clustering microfeatures (mfTraining) ===""
-
-#     check_file_readable {ctx.langdata_dir}/font_properties
-#     font_props=""-F {ctx.langdata_dir}/font_properties""
-#     if [[ -r ${TRAINING_DIR}/${LANG_CODE}.xheights ]] && \
-#        [[ -s ${TRAINING_DIR}/${LANG_CODE}.xheights ]]; then
-#         font_props=${font_props}"" -X ${TRAINING_DIR}/${LANG_CODE}.xheights""
-#     fi
-
-#     run_command mftraining \
-#         -D ""${TRAINING_DIR}/"" \
-#         -U ${TRAINING_DIR}/${LANG_CODE}.unicharset \
-#         -O ${TRAINING_DIR}/${LANG_CODE}.mfunicharset \
-#         ${font_props} \
-#         $(ls ${TRAINING_DIR}/*.tr)
-#     check_file_readable ${TRAINING_DIR}/inttemp ${TRAINING_DIR}/shapetable \
-#         ${TRAINING_DIR}/pffmtable ${TRAINING_DIR}/${LANG_CODE}.mfunicharset
-#     mv ${TRAINING_DIR}/inttemp ${TRAINING_DIR}/${LANG_CODE}.inttemp
-#     mv ${TRAINING_DIR}/shapetable ${TRAINING_DIR}/${LANG_CODE}.shapetable
-#     mv ${TRAINING_DIR}/pffmtable ${TRAINING_DIR}/${LANG_CODE}.pffmtable
-#     mv ${TRAINING_DIR}/${LANG_CODE}.mfunicharset ${TRAINING_DIR}/${LANG_CODE}.unicharset
-# }
-
-# phase_B_generate_ambiguities() {
-#   tlog ""\n=== Phase B : ambiguities training ===""
-
-#   # Check for manually created ambiguities data.
-#   if [[ -r {ctx.langdata_dir}/${LANG_CODE}/${LANG_CODE}.unicharambigs ]]; then
-#       tlog ""Found file {ctx.langdata_dir}/${LANG_CODE}/${LANG_CODE}.unicharambigs""
-#       cp {ctx.langdata_dir}/${LANG_CODE}/${LANG_CODE}.unicharambigs \
-#           ${TRAINING_DIR}/${LANG_CODE}.unicharambigs
-#       # Make it writable, as it may be read-only in the client.
-#       chmod u+w ${TRAINING_DIR}/${LANG_CODE}.unicharambigs
-#       return
-#   else
-#       tlog ""No unicharambigs file found!""
-#   fi
-
-#   # TODO: Add support for generating ambiguities automatically.
-# }
-
-
-def make_lstmdata(ctx):
-    log.info(""=== Constructing LSTM training data ==="")
-    lang_prefix = f""{ctx.langdata_dir}/{ctx.lang_code}/{ctx.lang_code}""
-    path_output = pathlib.Path(ctx.output_dir)
-    if not path_output.is_dir():
-        log.info(f""Creating new directory {ctx.output_dir}"")
-        path_output.mkdir(exist_ok=True, parents=True)
-
-    args = []
-    if ctx.lang_is_rtl:
-        args.append(""--lang_is_rtl"")
-    if ctx.norm_mode >= 2:
-        args.append(""--pass_through_recoder"")
-
-    # Build the starter traineddata from the inputs.
-    run_command(
-        ""combine_lang_model"",
-        ""--input_unicharset"",
-        f""{ctx.training_dir}/{ctx.lang_code}.unicharset"",
-        ""--script_dir"",
-        f""{ctx.langdata_dir}"",
-        ""--words"",
-        f""{lang_prefix}.wordlist"",
-        ""--numbers"",
-        f""{lang_prefix}.numbers"",
-        ""--puncs"",
-        f""{lang_prefix}.punc"",
-        ""--output_dir"",
-        f""{ctx.output_dir}"",
-        ""--lang"",
-        f""{ctx.lang_code}"",
-        *args,
-    )
-
-    def get_file_list():
-        training_path = pathlib.Path(ctx.training_dir)
-        if ctx.save_box_tiff:
-            log.info(""=== Saving box/tiff pairs for training data ==="")
-            yield from training_path.glob(f""{ctx.lang_code}*.box"")
-            yield from training_path.glob(f""{ctx.lang_code}*.tif"")
-        log.info(""=== Moving lstmf files for training data ==="")
-        yield from training_path.glob(f""{ctx.lang_code}.*.lstmf"")
-
-    for f in get_file_list():
-        log.debug(f""Moving {f} to {path_output / f.name}"")
-        shutil.move(str(f), path_output / f.name)
-
-    lstm_list = f""{ctx.output_dir}/{ctx.lang_code}.training_files.txt""
-    dir_listing = (str(p) for p in path_output.glob(f""{ctx.lang_code}.*.lstmf""))
-    pathlib.Path(lstm_list).write_text(""\n"".join(dir_listing))
-
-# make__traineddata() {
-#   tlog ""\n=== Making final traineddata file ===""
-#   local lang_prefix={ctx.langdata_dir}/${LANG_CODE}/${LANG_CODE}
-
-#   # Combine available files for this language from the langdata dir.
-#   if [[ -r ${lang_prefix}.config ]]; then
-#     tlog ""Copying ${lang_prefix}.config to ${TRAINING_DIR}""
-#     cp ${lang_prefix}.config ${TRAINING_DIR}
-#     chmod u+w ${TRAINING_DIR}/${LANG_CODE}.config
-#   fi
-#   if [[ -r ${lang_prefix}.params-model ]]; then
-#     tlog ""Copying ${lang_prefix}.params-model to ${TRAINING_DIR}""
-#     cp ${lang_prefix}.params-model ${TRAINING_DIR}
-#     chmod u+w ${TRAINING_DIR}/${LANG_CODE}.params-model
-#   fi
-
-#   # Compose the traineddata file.
-#   run_command combine_tessdata ${TRAINING_DIR}/${LANG_CODE}.
-
-#   # Copy it to the output dir, overwriting only if allowed by the cmdline flag.
-#   if [[ ! -d ${OUTPUT_DIR} ]]; then
-#       tlog ""Creating new directory ${OUTPUT_DIR}""
-#       mkdir -p ${OUTPUT_DIR}
-#   fi
-#   local destfile=${OUTPUT_DIR}/${LANG_CODE}.traineddata;
-#   if [[ -f ${destfile} ]] && ((! OVERWRITE)); then
-#       err_exit ""File ${destfile} exists and no --overwrite specified"";
-#   fi
-#   tlog ""Moving ${TRAINING_DIR}/${LANG_CODE}.traineddata to ${OUTPUT_DIR}""
-#   cp -f ${TRAINING_DIR}/${LANG_CODE}.traineddata ${destfile}
-# }"
GHSA-rv62-4pmj-xw6h,"From 08c4c898182edbe97aadef1815cce50448f975cb Mon Sep 17 00:00:00 2001
From: Min RK <benjaminrk@gmail.com>
Date: Wed, 27 Mar 2019 21:43:40 +0100
Subject: [PATCH] protect against chrome mishandling backslash as slash in URLs

---
 notebook/auth/login.py | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/notebook/auth/login.py b/notebook/auth/login.py
index d8289d7329..8dbd6112fc 100644
--- a/notebook/auth/login.py
+++ b/notebook/auth/login.py
@@ -39,6 +39,10 @@ def _redirect_safe(self, url, default=None):
         """"""
         if default is None:
             default = self.base_url
+        # protect chrome users from mishandling unescaped backslashes.
+        # \ is not valid in urls, but some browsers treat it as /
+        # instead of %5C, causing `\\` to behave as `//`
+        url = url.replace(""\\"", ""%5C"")
         parsed = urlparse(url)
         if parsed.netloc or not (parsed.path + '/').startswith(self.base_url):
             # require that next_url be absolute path within our path"
GHSA-962m-m8jw-8wrr,"From 1f8456bf1f908ea46012537d52bd7e752a532c91 Mon Sep 17 00:00:00 2001
From: Jens Vagelpohl <jens@netz.ooo>
Date: Fri, 21 May 2021 09:11:02 +0200
Subject: [PATCH] Merge pull request from GHSA-5pr9-v234-jw36

* - Prevent traversal to names starting with ``_`` in TAL expressions

* - include the expressions module

* - simplify test

* - lint fix

* - add DeprecationWarnings for traversal to `_`

* Update src/Products/PageTemplates/tests/testChameleonTalesExpressions.py

Co-authored-by: Michael Howitz <mh@gocept.com>

* - add missing import

* - added tests for the ``traverse`` method fix

* - change control flow

Co-authored-by: Michael Howitz <mh@gocept.com>
---
 CHANGES.rst                                   |  3 +++
 src/Products/PageTemplates/Expressions.py     |  9 +++++++
 src/Products/PageTemplates/expression.py      | 11 +++++++-
 .../tests/input/CheckPathTraverse.html        |  5 ++++
 .../tests/output/CheckPathTraverse.html       |  5 ++++
 .../tests/testChameleonTalesExpressions.py    |  7 ++++++
 .../PageTemplates/tests/testExpressions.py    | 21 +++++++++++++++-
 .../PageTemplates/tests/testHTMLTests.py      | 25 +++++++++++++++++++
 8 files changed, 84 insertions(+), 2 deletions(-)
 create mode 100644 src/Products/PageTemplates/tests/input/CheckPathTraverse.html
 create mode 100644 src/Products/PageTemplates/tests/output/CheckPathTraverse.html

diff --git a/CHANGES.rst b/CHANGES.rst
index 942752d1d6..b78ce36f0c 100644
--- a/CHANGES.rst
+++ b/CHANGES.rst
@@ -11,6 +11,9 @@ https://github.com/zopefoundation/Zope/blob/4.x/CHANGES.rst
 5.2 (unreleased)
 ----------------
 
+- Prevent traversal to names starting with ``_`` in TAL expressions
+  and fix path expressions for the ``chameleon.tales`` expression engine.
+
 - Provide friendlier ZMI error message for the Transaction Undo form
   (`#964 <https://github.com/zopefoundation/Zope/issues/964>`_)
 
diff --git a/src/Products/PageTemplates/Expressions.py b/src/Products/PageTemplates/Expressions.py
index 2a538391e5..66a748e0b1 100644
--- a/src/Products/PageTemplates/Expressions.py
+++ b/src/Products/PageTemplates/Expressions.py
@@ -17,6 +17,7 @@
 """"""
 
 import logging
+import warnings
 
 import OFS.interfaces
 from AccessControl import safe_builtins
@@ -74,6 +75,14 @@ def boboAwareZopeTraverse(object, path_items, econtext):
 
     while path_items:
         name = path_items.pop()
+
+        if name == '_':
+            warnings.warn('Traversing to the name `_` is deprecated '
+                          'and will be removed in Zope 6.',
+                          DeprecationWarning)
+        elif name.startswith('_'):
+            raise NotFound(name)
+
         if OFS.interfaces.ITraversable.providedBy(object):
             object = object.restrictedTraverse(name)
         else:
diff --git a/src/Products/PageTemplates/expression.py b/src/Products/PageTemplates/expression.py
index f651322201..bca086492a 100644
--- a/src/Products/PageTemplates/expression.py
+++ b/src/Products/PageTemplates/expression.py
@@ -1,5 +1,6 @@
 """"""``chameleon.tales`` expressions.""""""
 
+import warnings
 from ast import NodeTransformer
 from ast import parse
 
@@ -61,8 +62,16 @@ def traverse(cls, base, request, path_items):
 
         while path_items:
             name = path_items.pop()
+
+            if name == '_':
+                warnings.warn('Traversing to the name `_` is deprecated '
+                              'and will be removed in Zope 6.',
+                              DeprecationWarning)
+            elif name.startswith('_'):
+                raise NotFound(name)
+
             if ITraversable.providedBy(base):
-                base = getattr(base, cls.traverseMethod)(name)
+                base = getattr(base, cls.traverse_method)(name)
             else:
                 base = traversePathElement(base, name, path_items,
                                            request=request)
diff --git a/src/Products/PageTemplates/tests/input/CheckPathTraverse.html b/src/Products/PageTemplates/tests/input/CheckPathTraverse.html
new file mode 100644
index 0000000000..cd47c46b79
--- /dev/null
+++ b/src/Products/PageTemplates/tests/input/CheckPathTraverse.html
@@ -0,0 +1,5 @@
+<html>
+<body>
+   <div tal:content=""context/laf""></div>
+</body>
+</html>
diff --git a/src/Products/PageTemplates/tests/output/CheckPathTraverse.html b/src/Products/PageTemplates/tests/output/CheckPathTraverse.html
new file mode 100644
index 0000000000..09c1005408
--- /dev/null
+++ b/src/Products/PageTemplates/tests/output/CheckPathTraverse.html
@@ -0,0 +1,5 @@
+<html>
+<body>
+   <div>ok</div>
+</body>
+</html>
diff --git a/src/Products/PageTemplates/tests/testChameleonTalesExpressions.py b/src/Products/PageTemplates/tests/testChameleonTalesExpressions.py
index aa71d65139..fd25a55a38 100644
--- a/src/Products/PageTemplates/tests/testChameleonTalesExpressions.py
+++ b/src/Products/PageTemplates/tests/testChameleonTalesExpressions.py
@@ -1,3 +1,5 @@
+import unittest
+
 from ..expression import getEngine
 from . import testHTMLTests
 
@@ -19,3 +21,8 @@ def setUp(self):
     #   expressions (e.g. the ``zope.tales`` ``not`` expression
     #   returns ``int``, that of ``chameleon.tales`` ``bool``
     PREFIX = ""CH_""
+
+    @unittest.skip('The test in the base class relies on a Zope context with'
+                   ' the ""random"" module available in expressions')
+    def test_underscore_traversal(self):
+        pass
diff --git a/src/Products/PageTemplates/tests/testExpressions.py b/src/Products/PageTemplates/tests/testExpressions.py
index d2cb1672ec..f877cfb877 100644
--- a/src/Products/PageTemplates/tests/testExpressions.py
+++ b/src/Products/PageTemplates/tests/testExpressions.py
@@ -1,6 +1,8 @@
 import unittest
+import warnings
 
 from AccessControl import safe_builtins
+from zExceptions import NotFound
 from zope.component.testing import PlacelessSetup
 
 
@@ -106,8 +108,12 @@ def test_evaluate_alternative_first_missing(self):
         self.assertTrue(ec.evaluate('x | nothing') is None)
 
     def test_evaluate_dict_key_as_underscore(self):
+        # Traversing to the name `_` will raise a DeprecationWarning
+        # because it will go away in Zope 6.
         ec = self._makeContext()
-        self.assertEqual(ec.evaluate('d/_'), 'under')
+        with warnings.catch_warnings():
+            warnings.simplefilter('ignore')
+            self.assertEqual(ec.evaluate('d/_'), 'under')
 
     def test_evaluate_dict_with_key_from_expansion(self):
         ec = self._makeContext()
@@ -220,6 +226,19 @@ def test_list_in_path_expr(self):
         ec = self._makeContext()
         self.assertIs(ec.evaluate('nocall: list'), safe_builtins[""list""])
 
+    def test_underscore_traversal(self):
+        # Prevent traversal to names starting with an underscore (_)
+        ec = self._makeContext()
+
+        with self.assertRaises(NotFound):
+            ec.evaluate(""context/__class__"")
+
+        with self.assertRaises(NotFound):
+            ec.evaluate(""nocall: random/_itertools/repeat"")
+
+        with self.assertRaises(NotFound):
+            ec.evaluate(""random/_itertools/repeat/foobar"")
+
 
 class TrustedEngineTests(EngineTestsBase, unittest.TestCase):
 
diff --git a/src/Products/PageTemplates/tests/testHTMLTests.py b/src/Products/PageTemplates/tests/testHTMLTests.py
index e113095b76..79ee58b3bc 100644
--- a/src/Products/PageTemplates/tests/testHTMLTests.py
+++ b/src/Products/PageTemplates/tests/testHTMLTests.py
@@ -26,6 +26,7 @@
     DefaultUnicodeEncodingConflictResolver
 from Products.PageTemplates.unicodeconflictresolver import \
     PreferredCharsetResolver
+from zExceptions import NotFound
 from zope.component import provideUtility
 from zope.traversing.adapters import DefaultTraversable
 
@@ -155,6 +156,15 @@ def testPathNothing(self):
     def testPathAlt(self):
         self.assert_expected(self.folder.t, 'CheckPathAlt.html')
 
+    def testPathTraverse(self):
+        # need to perform this test with a ""real"" folder
+        from OFS.Folder import Folder
+        f = self.folder
+        self.folder = Folder()
+        self.folder.t, self.folder.laf = f.t, f.laf
+        self.folder.laf.write('ok')
+        self.assert_expected(self.folder.t, 'CheckPathTraverse.html')
+
     def testBatchIteration(self):
         self.assert_expected(self.folder.t, 'CheckBatchIteration.html')
 
@@ -207,3 +217,18 @@ def test_unicode_conflict_resolution(self):
         provideUtility(PreferredCharsetResolver)
         t = PageTemplate()
         self.assert_expected(t, 'UnicodeResolution.html')
+
+    def test_underscore_traversal(self):
+        t = self.folder.t
+
+        t.write('<p tal:define=""p context/__class__"" />')
+        with self.assertRaises(NotFound):
+            t()
+
+        t.write('<p tal:define=""p nocall: random/_itertools/repeat""/>')
+        with self.assertRaises(NotFound):
+            t()
+
+        t.write('<p tal:content=""random/_itertools/repeat/foobar""/>')
+        with self.assertRaises(NotFound):
+            t()"
PYSEC-2017-21,"From 1b76cefb92081efa1e88cd8f330253f857028bd2 Mon Sep 17 00:00:00 2001
From: James Page <james.page@ubuntu.com>
Date: Tue, 31 Jan 2017 11:23:06 +0000
Subject: [PATCH] Ensure LXD veth host device is named correctly

LXD uses a veth pair to plumb the LXD instance into the bridge
providing access to neutron networking.

In later nova-lxd versions, the host_name parameter is set based
on the neutron configured name for the host part of the pair,
ensuring that neutron iptables firewall rules are correctly
applied to instances.

Update the mitaka version of the driver to populate the LXD
network device configuration to ensure that any firewall
rules are correctly applied.

(also dropped version from setup.cfg, as pbr will automatically
generate the version based on git tags, so its really surplus
to requirements).

Change-Id: Ic5b9ad6944a1ac45cd1983d038431252ff738985
Closes-Bug: 1656847
---
 nova_lxd/nova/virt/lxd/config.py | 8 ++++++--
 setup.cfg                        | 1 -
 2 files changed, 6 insertions(+), 3 deletions(-)

diff --git a/nova_lxd/nova/virt/lxd/config.py b/nova_lxd/nova/virt/lxd/config.py
index 0f311c0..5a2b884 100644
--- a/nova_lxd/nova/virt/lxd/config.py
+++ b/nova_lxd/nova/virt/lxd/config.py
@@ -224,11 +224,15 @@ def create_network(self, instance_name, instance, network_info):
 
             for vifaddr in network_info:
                 cfg = self.vif_driver.get_config(instance, vifaddr)
-                network_devices[str(cfg['bridge'])] = \
+                key = str(cfg['bridge'])
+                network_devices[key] = \
                     {'nictype': 'bridged',
                      'hwaddr': str(cfg['mac_address']),
-                     'parent': str(cfg['bridge']),
+                     'parent': key,
                      'type': 'nic'}
+                host_device = self.vif_driver.get_vif_devname(vifaddr)
+                if host_device:
+                    network_devices[key]['host_name'] = host_device
                 return network_devices
         except Exception as ex:
             with excutils.save_and_reraise_exception():
diff --git a/setup.cfg b/setup.cfg
index 45feda3..23ba223 100644
--- a/setup.cfg
+++ b/setup.cfg
@@ -3,7 +3,6 @@ name = nova-lxd
 summary = native lxd driver for openstack
 description-file =
     README.md
-version = 13.2.0
 author = OpenStack
 author-email = openstack-dev@lists.openstack.org
 home-page = http://www.openstack.org/"
GHSA-977j-xj7q-2jr9,"From 5ac1b9e24ff6afc465756edf845d2e9660bd34bf Mon Sep 17 00:00:00 2001
From: Mihai Maruseac <mihaimaruseac@google.com>
Date: Fri, 20 Dec 2019 15:33:46 -0800
Subject: [PATCH] Fix segfault when attempting to convert string to float16.

To make sure this gets fixed, add test for converting string to any numeric type.

PiperOrigin-RevId: 286650886
Change-Id: I81f770ec2bbd33a863e8057ce198c679912fa8e0
---
 tensorflow/python/BUILD                       | 11 ++++
 .../python/framework/constant_op_test.py      | 61 +++++++++++++++++++
 tensorflow/python/lib/core/py_seq_tensor.cc   | 35 +++++++----
 3 files changed, 95 insertions(+), 12 deletions(-)
 create mode 100644 tensorflow/python/framework/constant_op_test.py

diff --git a/tensorflow/python/BUILD b/tensorflow/python/BUILD
index 80cfb7f08600ba..35d76eb5b5d957 100644
--- a/tensorflow/python/BUILD
+++ b/tensorflow/python/BUILD
@@ -1839,6 +1839,17 @@ py_library(
     ],
 )
 
+tf_py_test(
+    name = ""framework_constant_op_test"",
+    size = ""small"",
+    srcs = [""framework/constant_op_test.py""],
+    main = ""framework/constant_op_test.py"",
+    python_version = ""PY3"",
+    deps = [
+        "":constant_op"",
+    ],
+)
+
 tf_py_test(
     name = ""framework_registry_test"",
     size = ""small"",
diff --git a/tensorflow/python/framework/constant_op_test.py b/tensorflow/python/framework/constant_op_test.py
new file mode 100644
index 00000000000000..da0fb64fde6f2b
--- /dev/null
+++ b/tensorflow/python/framework/constant_op_test.py
@@ -0,0 +1,61 @@
+# Copyright 2020 The TensorFlow Authors. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+""""""Tests for tensorflow.python.framework.constant_op.""""""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+from absl.testing import parameterized
+
+from tensorflow.python.framework import constant_op
+from tensorflow.python.framework import dtypes
+from tensorflow.python.framework import ops
+from tensorflow.python.platform import test
+
+
+class ConstantOpTest(test.TestCase, parameterized.TestCase):
+
+  @parameterized.parameters(
+      dtypes.bfloat16,
+      dtypes.complex128,
+      dtypes.complex64,
+      dtypes.double,
+      dtypes.float16,
+      dtypes.float32,
+      dtypes.float64,
+      dtypes.half,
+      dtypes.int16,
+      dtypes.int32,
+      dtypes.int64,
+      dtypes.int8,
+      dtypes.qint16,
+      dtypes.qint32,
+      dtypes.qint8,
+      dtypes.quint16,
+      dtypes.quint8,
+      dtypes.uint16,
+      dtypes.uint32,
+      dtypes.uint64,
+      dtypes.uint8,
+  )
+  def test_convert_string_to_number(self, dtype):
+    with self.assertRaises(TypeError):
+      constant_op.constant(""hello"", dtype)
+
+
+if __name__ == ""__main__"":
+  ops.enable_eager_execution()
+  test.main()
diff --git a/tensorflow/python/lib/core/py_seq_tensor.cc b/tensorflow/python/lib/core/py_seq_tensor.cc
index 8770b362a4ef4a..5d4916f48fc6f5 100644
--- a/tensorflow/python/lib/core/py_seq_tensor.cc
+++ b/tensorflow/python/lib/core/py_seq_tensor.cc
@@ -21,6 +21,7 @@ limitations under the License.
 #include ""tensorflow/core/lib/core/errors.h""
 #include ""tensorflow/core/lib/core/stringpiece.h""
 #include ""tensorflow/core/lib/strings/str_util.h""
+#include ""tensorflow/core/platform/macros.h""
 #include ""tensorflow/core/platform/types.h""
 #include ""tensorflow/python/lib/core/numpy.h""
 #include ""tensorflow/python/lib/core/py_util.h""
@@ -396,6 +397,21 @@ typedef Converter<int32> Int32Converter;
 
 // Floating-point support
 
+// Returns `true` if `out` overflows when converted from `as_double`.
+template <class T>
+static inline bool CheckForOverflow(double as_double, T* out) {
+  return (sizeof(T) < sizeof(double) && std::isinf(*out) &&
+          std::isfinite(as_double));
+}
+
+// There is no `std::isinf` that takes `Eigen::half` as argument but Eigen
+// provides `Eigen::half_impl::isinf` instead.
+template <>
+inline bool CheckForOverflow<Eigen::half>(double as_double, Eigen::half* out) {
+  return (sizeof(Eigen::half) < sizeof(double) &&
+          Eigen::half_impl::isinf(*out) && std::isfinite(as_double));
+}
+
 template <class T>
 static const char* ConvertOneFloat(PyObject* v, T* out) {
   if (PyErr_Occurred()) {
@@ -405,20 +421,19 @@ static const char* ConvertOneFloat(PyObject* v, T* out) {
     const double as_double = PyFloat_AS_DOUBLE(v);
     *out = static_cast<T>(as_double);
     // Check for overflow
-    if (TF_PREDICT_FALSE(sizeof(T) < sizeof(double) && std::isinf(*out) &&
-                         std::isfinite(as_double))) {
+    if (TF_PREDICT_FALSE(CheckForOverflow<T>(as_double, out))) {
       return ErrorOutOfRangeDouble;
     }
     return nullptr;
   }
 #if PY_MAJOR_VERSION < 3
   if (PyInt_Check(v)) {
-    *out = PyInt_AS_LONG(v);
+    *out = static_cast<T>(PyInt_AS_LONG(v));
     return nullptr;
   }
 #endif
   if (PyLong_Check(v)) {
-    *out = PyLong_AsDouble(v);
+    *out = static_cast<T>(PyLong_AsDouble(v));
     if (PyErr_Occurred()) return ErrorOutOfRangeDouble;
     return nullptr;
   }
@@ -467,13 +482,7 @@ struct ConverterTraits<Eigen::half> {
   static const tensorflow::DataType kTypeEnum = DT_HALF;
 
   static const char* ConvertScalar(PyObject* v, Eigen::half* out) {
-    // NOTE(nareshmodi): Is there a way to convert to C double without the
-    // intermediate Python double? This will help with ConvertOneFloat as well.
-    Safe_PyObjectPtr as_float = make_safe(PyNumber_Float(v));
-    double v_double = PyFloat_AS_DOUBLE(as_float.get());
-    *out = Eigen::half(v_double);
-
-    return nullptr;
+    return ConvertOneFloat<Eigen::half>(v, out);
   }
 };
 
@@ -613,7 +622,9 @@ Status PySeqToTensor(PyObject* obj, DataType dtype, Tensor* ret) {
       break;
 
     case DT_HALF:
-      RETURN_STRING_AS_STATUS(NumpyHalfConverter::Convert(obj, &state, ret));
+      if (NumpyHalfConverter::Convert(obj, &state, ret) == nullptr)
+        return Status::OK();
+      break;
 
     case DT_INT64:
       if (Int64Converter::Convert(obj, &state, ret) == nullptr)"
GHSA-47wv-vhj2-g66m,"From b96ecae4dc69fc0a83c7c2d3f1dde600c20a1b41 Mon Sep 17 00:00:00 2001
From: Abin Shahab <ashahab@linkedin.com>
Date: Sun, 16 Jan 2022 02:15:40 -0800
Subject: [PATCH] Replaced use of tempfile.mktemp() with tempfile.mkstemp()
 (#3358)

Signed-off-by: Abin Shahab <ashahab@linkedin.com>
---
 horovod/runner/js_run.py | 7 ++++++-
 test/single/test_run.py  | 2 +-
 test/utils/common.py     | 9 +++------
 3 files changed, 10 insertions(+), 8 deletions(-)

diff --git a/horovod/runner/js_run.py b/horovod/runner/js_run.py
index d25f5dd3f6..5be6801198 100644
--- a/horovod/runner/js_run.py
+++ b/horovod/runner/js_run.py
@@ -126,7 +126,12 @@ def generate_jsrun_rankfile(settings, path=None):
             slots=settings.num_proc))
 
     # Generate rankfile
-    path = tempfile.mktemp() if path is None else path
+    # using mkstemp here instead of insecure mktemp.
+    # note that the caller is responsible for cleaning up this file
+    if path is None:
+        fd, path = tempfile.mkstemp()
+        fd.close()
+
     with open(path, 'w') as tmp:
         tmp.write('overlapping_rs: allow\n')
         tmp.write('cpu_index_using: logical\n')
diff --git a/test/single/test_run.py b/test/single/test_run.py
index f7a82cd06d..5f506f9f0a 100644
--- a/test/single/test_run.py
+++ b/test/single/test_run.py
@@ -640,7 +640,7 @@ def test(output, expected, exit_code=0):
         test((""HYDRA build details:\n""
               ""    Version:           3.3a2\n""
               ""    Configure options: 'MPICHLIB_CFLAGS=-g -O2'\n""), _MPICH_IMPL)
-        
+
         test(""Intel(R) MPI"", _IMPI_IMPL)
 
         test(""Unknown MPI v1.00"", _UNKNOWN_IMPL)
diff --git a/test/utils/common.py b/test/utils/common.py
index 038ed1eab9..77871c456a 100644
--- a/test/utils/common.py
+++ b/test/utils/common.py
@@ -112,15 +112,12 @@ def tempdir():
 
 @contextlib.contextmanager
 def temppath():
-    path = tempfile.mktemp()
+    dir_path = tempfile.TemporaryDirectory()
+    path = os.path.join(dir_path.name,'temp_test_file')
     try:
         yield path
     finally:
-        if os.path.exists(path):
-            if os.path.isfile(path):
-                os.remove(path)
-            else:
-                shutil.rmtree(path)
+        dir_path.cleanup()
 
 
 @contextlib.contextmanager"
CVE-2022-31502,"From 30ab2ba563a19040b07b7b8b06e97ad95c0b5793 Mon Sep 17 00:00:00 2001
From: Porcupiney Hairs <porucpiney.hairs@protonmail.com>
Date: Fri, 29 Apr 2022 02:13:49 +0530
Subject: [PATCH] # Absolute Path Traversal due to incorrect use of `send_file`
 call
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

A path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with dot-dot-slash (../) sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as dot-dot-slash, directory traversal, directory climbing and backtracking.

## Root Cause Analysis

The `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.
```
>>> import os.path
>>> static = ""path/to/mySafeStaticDir""
>>> malicious = ""/../../../../../etc/passwd""
>>> os.path.join(t,malicious)
'/../../../../../etc/passwd'
```
Since the ""malicious"" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.

In this case, the problems occurs due to the following code :
https://github.com/operatorequals/wormnest/blob/dd981626b574a89939babd1246588580ecc323f9/app.py#L127

Here, the `req_path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.

## Proof of Concept

The bug can be verified using a proof of concept similar to the one shown below.

```
curl --path-as-is 'http://<domain>/list//../../../../etc/passwd""'
```
## Remediation

This can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `flask.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.

## References
* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)
* github/securitylab#669

### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*
---
 app.py | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/app.py b/app.py
index 1c5a153..509957c 100755
--- a/app.py
+++ b/app.py
@@ -1,6 +1,6 @@
 #!/bin/env python
 from flask import Flask
-from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort
+from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort, safe_join
 
 from werkzeug.utils import secure_filename
 from ipaddress import ip_address, ip_network
@@ -116,7 +116,7 @@ def dir_listing(req_path):
 https://stackoverflow.com/questions/23718236/python-flask-browsing-through-directory-with-files
   '''
   # Joining the base and the requested path
-  abs_path = os.path.join(CONFIG['SRV_DIR'], req_path)
+  abs_path = safe_join(CONFIG['SRV_DIR'], req_path)
 
   # Return 404 if path doesn't exist
   if not os.path.exists(abs_path):"
GHSA-vhr6-pvjm-9qwf,"From ca412243013a11e234004c5fc71f1958b45bdd63 Mon Sep 17 00:00:00 2001
From: Nick Catalano <nickcatal@gmail.com>
Date: Wed, 1 Jul 2020 23:00:48 -0400
Subject: [PATCH 1/4] Discontinue storing credentials in the session store

Previously the credentials in the ""auth"" form were being stored in plain
text inside the session store. This means that, for example, users who
relied on Django's default database-backed session store and django's
built-in model authentication were briefly storing the user's raw
password in base64 encoded strings within the database.

With this change the user's credentials are first authenticated, then
users are given a set period of time to complete the 2 factor step
before they must again authenticate their credentials.
---
 CHANGELOG.md              |   8 +++
 docs/configuration.rst    |   7 +++
 tests/test_views_login.py | 123 +++++++++++++++++++++++++++++---------
 two_factor/views/core.py  |  74 +++++++++++++++++++++--
 two_factor/views/utils.py |  27 ++++++++-
 5 files changed, 205 insertions(+), 34 deletions(-)

diff --git a/CHANGELOG.md b/CHANGELOG.md
index d4ec3fa8a..20362e5fe 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,4 +1,12 @@
 ## [Unreleased]
+### Added
+- It is possible to set a timeout between a user authenticiating in the LoginView and them needing to re-authenticate. By default this is 10 minutes.
+
+### Removed
+- The final step in the LoginView no longer re-validates a user's credentials
+
+### Changed
+- Security Fix: LoginView no longer stores credentials in plaintext in the session store
 
 ## 1.11.0 - 2020-03-13
 ### Added
diff --git a/docs/configuration.rst b/docs/configuration.rst
index a01081614..5ede64339 100644
--- a/docs/configuration.rst
+++ b/docs/configuration.rst
@@ -73,6 +73,13 @@ General Settings
      `the upstream ticket`_). Don't set this option to 8 unless all of your
      users use a 8 digit compatible token generator app.
 
+``TWO_FACTOR_LOGIN_TIMEOUT`` (default ``600``)
+  The number of seconds between a user successfully passing the ""authentication""
+  step (usually by entering a valid username and password) and them having to
+  restart the login flow and re-authenticate. This ensures that users can't sit
+  indefinately in a state of having entered their password successfully but not
+  having passed two factor authentication. Set to ``0`` to disable.
+
 ``PHONENUMBER_DEFAULT_REGION`` (default: ``None``)
   The default region for parsing phone numbers. If your application's primary
   audience is a certain country, setting the region to that country allows
diff --git a/tests/test_views_login.py b/tests/test_views_login.py
index d4095017b..b9c7ca7a5 100644
--- a/tests/test_views_login.py
+++ b/tests/test_views_login.py
@@ -88,6 +88,100 @@ def test_valid_login_with_disallowed_external_redirect(self):
              'login_view-current_step': 'auth'})
         self.assertRedirects(response, reverse('two_factor:profile'), fetch_redirect_response=False)
 
+    @mock.patch('two_factor.views.core.time')
+    def test_valid_login_primary_key_stored(self, mock_time):
+        mock_time.time.return_value = 12345.12
+        user = self.create_user()
+        user.totpdevice_set.create(name='default',
+                                   key=random_hex_str())
+
+        response = self._post({'auth-username': 'bouke@example.com',
+                               'auth-password': 'secret',
+                               'login_view-current_step': 'auth'})
+        self.assertContains(response, 'Token:')
+
+        self.assertEqual(self.client.session['wizard_login_view']['user_pk'], str(user.pk))
+        self.assertEqual(
+            self.client.session['wizard_login_view']['user_backend'],
+            'django.contrib.auth.backends.ModelBackend')
+        self.assertEqual(self.client.session['wizard_login_view']['authentication_time'], 12345)
+
+    @mock.patch('two_factor.views.core.time')
+    def test_valid_login_post_auth_session_clear_of_form_data(self, mock_time):
+        mock_time.time.return_value = 12345.12
+        user = self.create_user()
+        user.totpdevice_set.create(name='default',
+                                   key=random_hex_str())
+
+        response = self._post({'auth-username': 'bouke@example.com',
+                               'auth-password': 'secret',
+                               'login_view-current_step': 'auth'})
+        self.assertContains(response, 'Token:')
+
+        self.assertEqual(self.client.session['wizard_login_view']['user_pk'], str(user.pk))
+        self.assertEqual(self.client.session['wizard_login_view']['step'], 'token')
+        self.assertEqual(self.client.session['wizard_login_view']['step_data'], {'auth': None})
+        self.assertEqual(self.client.session['wizard_login_view']['step_files'], {'auth': {}})
+        self.assertEqual(self.client.session['wizard_login_view']['validated_step_data'], {})
+
+    @mock.patch('two_factor.views.core.logger')
+    @mock.patch('two_factor.views.core.time')
+    def test_valid_login_expired(self, mock_time, mock_logger):
+        mock_time.time.return_value = 12345.12
+        user = self.create_user()
+        device = user.totpdevice_set.create(name='default',
+                                            key=random_hex_str())
+
+        response = self._post({'auth-username': 'bouke@example.com',
+                               'auth-password': 'secret',
+                               'login_view-current_step': 'auth'})
+        self.assertContains(response, 'Token:')
+
+        self.assertEqual(self.client.session['wizard_login_view']['user_pk'], str(user.pk))
+        self.assertEqual(
+            self.client.session['wizard_login_view']['user_backend'],
+            'django.contrib.auth.backends.ModelBackend')
+        self.assertEqual(self.client.session['wizard_login_view']['authentication_time'], 12345)
+
+        mock_time.time.return_value = 20345.12
+
+        response = self._post({'token-otp_token': totp(device.bin_key),
+                               'login_view-current_step': 'token'})
+        self.assertEqual(response.status_code, 200)
+        self.assertNotContains(response, 'Token:')
+        self.assertContains(response, 'Password:')
+        self.assertContains(response, 'Your session has timed out. Please login again.')
+
+        # Check that a message was logged.
+        mock_logger.info.assert_called_with(
+            ""User's authentication flow has timed out. The user ""
+            ""has been redirected to the initial auth form."")
+
+    @override_settings(TWO_FACTOR_LOGIN_TIMEOUT=0)
+    @mock.patch('two_factor.views.core.time')
+    def test_valid_login_no_timeout(self, mock_time):
+        mock_time.time.return_value = 12345.12
+        user = self.create_user()
+        device = user.totpdevice_set.create(name='default',
+                                            key=random_hex_str())
+
+        response = self._post({'auth-username': 'bouke@example.com',
+                               'auth-password': 'secret',
+                               'login_view-current_step': 'auth'})
+        self.assertContains(response, 'Token:')
+
+        self.assertEqual(self.client.session['wizard_login_view']['user_pk'], str(user.pk))
+        self.assertEqual(
+            self.client.session['wizard_login_view']['user_backend'],
+            'django.contrib.auth.backends.ModelBackend')
+        self.assertEqual(self.client.session['wizard_login_view']['authentication_time'], 12345)
+
+        mock_time.time.return_value = 20345.12
+
+        response = self._post({'token-otp_token': totp(device.bin_key),
+                               'login_view-current_step': 'token'})
+        self.assertRedirects(response, resolve_url(settings.LOGIN_REDIRECT_URL))
+        self.assertEqual(self.client.session['_auth_user_id'], str(user.pk))
 
     def test_valid_login_with_redirect_authenticated_user(self):
         user = self.create_user()
@@ -251,35 +345,6 @@ def test_with_backup_token(self, mock_signal):
         # Check that the signal was fired.
         mock_signal.assert_called_with(sender=mock.ANY, request=mock.ANY, user=user, device=device)
 
-    @mock.patch('two_factor.views.utils.logger')
-    def test_change_password_in_between(self, mock_logger):
-        """"""
-        When the password of the user is changed while trying to login, should
-        not result in errors. Refs #63.
-        """"""
-        user = self.create_user()
-        self.enable_otp()
-
-        response = self._post({'auth-username': 'bouke@example.com',
-                               'auth-password': 'secret',
-                               'login_view-current_step': 'auth'})
-        self.assertContains(response, 'Token:')
-
-        # Now, the password is changed. When the form is submitted, the
-        # credentials should be checked again. If that's the case, the
-        # login form should note that the credentials are invalid.
-        user.set_password('secret2')
-        user.save()
-        response = self._post({'login_view-current_step': 'token'})
-        self.assertContains(response, 'Please enter a correct')
-        self.assertContains(response, 'and password.')
-
-        # Check that a message was logged.
-        mock_logger.warning.assert_called_with(
-            ""Current step '%s' is no longer valid, returning to last valid ""
-            ""step in the wizard."",
-            'token')
-
     @mock.patch('two_factor.views.utils.logger')
     def test_reset_wizard_state(self, mock_logger):
         self.create_user()
diff --git a/two_factor/views/core.py b/two_factor/views/core.py
index cd434a8f7..8e9fe9c7d 100644
--- a/two_factor/views/core.py
+++ b/two_factor/views/core.py
@@ -2,6 +2,7 @@
 import warnings
 from base64 import b32encode
 from binascii import unhexlify
+import time
 
 import django_otp
 import qrcode
@@ -12,13 +13,15 @@
 from django.contrib.auth.forms import AuthenticationForm
 from django.contrib.auth.views import SuccessURLAllowedHostsMixin
 from django.contrib.sites.shortcuts import get_current_site
-from django.forms import Form
+from django.forms import Form, ValidationError
 from django.http import Http404, HttpResponse, HttpResponseRedirect
 from django.shortcuts import redirect, resolve_url
 from django.urls import reverse
 from django.utils.decorators import method_decorator
+from django.utils.functional import cached_property
 from django.utils.http import is_safe_url
 from django.utils.module_loading import import_string
+from django.utils.translation import gettext as _
 from django.views.decorators.cache import never_cache
 from django.views.decorators.csrf import csrf_protect
 from django.views.decorators.debug import sensitive_post_parameters
@@ -80,6 +83,14 @@ def has_backup_step(self):
         return default_device(self.get_user()) and \
             'token' not in self.storage.validated_step_data
 
+    @cached_property
+    def expired(self):
+        login_timeout = getattr(settings, 'TWO_FACTOR_LOGIN_TIMEOUT', 600)
+        if login_timeout == 0:
+            return False
+        expiration_time = self.storage.data.get(""authentication_time"", 0) + login_timeout
+        return int(time.time()) > expiration_time
+
     condition_dict = {
         'token': has_token_step,
         'backup': has_backup_step,
@@ -90,12 +101,21 @@ def __init__(self, **kwargs):
         super().__init__(**kwargs)
         self.user_cache = None
         self.device_cache = None
+        self.show_timeout_error = False
 
     def post(self, *args, **kwargs):
         """"""
         The user can select a particular device to challenge, being the backup
         devices added to the account.
         """"""
+
+        wizard_goto_step = self.request.POST.get('wizard_goto_step', None)
+        if self.expired and self.steps.current != 'auth' and wizard_goto_step != 'auth':
+            logger.info(""User's authentication flow has timed out. The user ""
+                        ""has been redirected to the initial auth form."")
+            self.show_timeout_error = True
+            return self.render_goto_step('auth')
+
         # Generating a challenge doesn't require to validate the form.
         if 'challenge_device' in self.request.POST:
             return self.render_goto_step('token')
@@ -152,6 +172,54 @@ def get_form_kwargs(self, step=None):
             }
         return {}
 
+    def get_done_form_list(self):
+        """"""
+        Return the forms that should be processed during the final step
+        """"""
+        # Intentionally do not process the auth form on the final step. We
+        # haven't stored this data, and it isn't required to login the user
+        form_list = self.get_form_list()
+        form_list.pop('auth')
+        return form_list
+
+    def process_step(self, form):
+        """"""
+        Process an individual step in the flow
+        """"""
+        # To prevent saving any private auth data to the session store, we
+        # validate the authentication form, determine the resulting user, then
+        # only store the minimum needed to login that user (the user's primary
+        # key and the backend used)
+        if self.steps.current == 'auth':
+            user = form.is_valid() and form.user_cache
+            self.storage.reset()
+            self.storage.authenticated_user = user
+            self.storage.data[""authentication_time""] = int(time.time())
+
+            # By returning None when the user clicks the ""back"" button to the
+            # auth step the form will be blank with validation warnings
+            return None
+
+        return super().process_step(form)
+
+    def process_step_files(self, form):
+        """"""
+        Process the files submitted from a specific test
+        """"""
+        if self.steps.current == 'auth':
+            return {}
+        return super().process_step_files(form)
+
+    def get_form(self, *args, **kwargs):
+        """"""
+        Returns the form for the step
+        """"""
+        form = super().get_form(*args, **kwargs)
+        if self.show_timeout_error:
+            form.cleaned_data = getattr(form, 'cleaned_data', {})
+            form.add_error(None, ValidationError(_('Your session has timed out. Please login again.')))
+        return form
+
     def get_device(self, step=None):
         """"""
         Returns the OTP device selected by the user, or his default device.
@@ -187,9 +255,7 @@ def get_user(self):
         if not a valid user; see also issue #65.
         """"""
         if not self.user_cache:
-            form_obj = self.get_form(step='auth',
-                                     data=self.storage.get_step_data('auth'))
-            self.user_cache = form_obj.is_valid() and form_obj.user_cache
+            self.user_cache = self.storage.authenticated_user
         return self.user_cache
 
     def get_context_data(self, form, **kwargs):
diff --git a/two_factor/views/utils.py b/two_factor/views/utils.py
index 19971ef1e..e741040b9 100644
--- a/two_factor/views/utils.py
+++ b/two_factor/views/utils.py
@@ -1,5 +1,6 @@
 import logging
 
+from django.contrib.auth import load_backend
 from django.core.exceptions import SuspiciousOperation
 from django.utils.decorators import method_decorator
 from django.utils.translation import gettext as _
@@ -33,9 +34,30 @@ def _get_validated_step_data(self):
     def _set_validated_step_data(self, validated_step_data):
         self.data[self.validated_step_data_key] = validated_step_data
 
+    def _get_authenticated_user(self):
+        # Ensure that both user_pk and user_backend exist in the session
+        if not all([self.data.get(""user_pk""), self.data.get(""user_backend"")]):
+            return False
+        # Acquire the user the same way django.contrib.auth.get_user does
+        backend = load_backend(self.data[""user_backend""])
+        user = backend.get_user(self.data[""user_pk""])
+        if not user:
+            return False
+        # Set user.backend to the dotted path version of the backend for login()
+        user.backend = self.data[""user_backend""]
+        return user
+
+    def _set_authenticated_user(self, user):
+        # Acquire the PK the same way django's auth middleware does
+        self.data[""user_pk""] = user._meta.pk.value_to_string(user)
+        self.data[""user_backend""] = user.backend
+
     validated_step_data = property(_get_validated_step_data,
                                    _set_validated_step_data)
 
+    authenticated_user = property(_get_authenticated_user,
+                                  _set_authenticated_user)
+
 
 class IdempotentSessionWizardView(SessionWizardView):
     """"""
@@ -153,6 +175,9 @@ def process_step(self, form):
 
         return super().process_step(form)
 
+    def get_done_form_list(self):
+        return self.get_form_list()
+
     def render_done(self, form, **kwargs):
         """"""
         This method gets called when all forms passed. The method should also
@@ -162,7 +187,7 @@ def render_done(self, form, **kwargs):
         """"""
         final_form_list = []
         # walk through the form list and try to validate the data again.
-        for form_key in self.get_form_list():
+        for form_key in self.get_done_form_list():
             form_obj = self.get_form(step=form_key,
                                      data=self.storage.get_step_data(form_key),
                                      files=self.storage.get_step_files(

From 35837cdbb5d66ee52890a572f6a0edfe2290650e Mon Sep 17 00:00:00 2001
From: Bouke Haarsma <bouke@haarsma.eu>
Date: Tue, 7 Jul 2020 20:29:07 +0200
Subject: [PATCH 2/4] Move authenticated user storage to specialised class

---
 two_factor/views/core.py  |  1 +
 two_factor/views/utils.py | 12 +++++++++---
 2 files changed, 10 insertions(+), 3 deletions(-)

diff --git a/two_factor/views/core.py b/two_factor/views/core.py
index 8e9fe9c7d..4854ee109 100644
--- a/two_factor/views/core.py
+++ b/two_factor/views/core.py
@@ -75,6 +75,7 @@ class LoginView(SuccessURLAllowedHostsMixin, IdempotentSessionWizardView):
         'backup': False,
     }
     redirect_authenticated_user = False
+    storage_name = 'two_factor.views.utils.LoginStorage'
 
     def has_token_step(self):
         return default_device(self.get_user())
diff --git a/two_factor/views/utils.py b/two_factor/views/utils.py
index e741040b9..42887da78 100644
--- a/two_factor/views/utils.py
+++ b/two_factor/views/utils.py
@@ -34,6 +34,15 @@ def _get_validated_step_data(self):
     def _set_validated_step_data(self, validated_step_data):
         self.data[self.validated_step_data_key] = validated_step_data
 
+    validated_step_data = property(_get_validated_step_data,
+                                   _set_validated_step_data)
+
+
+class LoginStorage(ExtraSessionStorage):
+    """"""
+    SessionStorage that includes the property 'authenticated_user' for storing
+    backend authenticated users while logging in.
+    """"""
     def _get_authenticated_user(self):
         # Ensure that both user_pk and user_backend exist in the session
         if not all([self.data.get(""user_pk""), self.data.get(""user_backend"")]):
@@ -52,9 +61,6 @@ def _set_authenticated_user(self, user):
         self.data[""user_pk""] = user._meta.pk.value_to_string(user)
         self.data[""user_backend""] = user.backend
 
-    validated_step_data = property(_get_validated_step_data,
-                                   _set_validated_step_data)
-
     authenticated_user = property(_get_authenticated_user,
                                   _set_authenticated_user)
 

From 9988c505a35fa010409620c41137ac058fca1987 Mon Sep 17 00:00:00 2001
From: Bouke Haarsma <bouke@haarsma.eu>
Date: Wed, 8 Jul 2020 08:37:34 +0200
Subject: [PATCH 3/4] Clear storage when going back to login

---
 two_factor/views/core.py | 8 ++++++--
 1 file changed, 6 insertions(+), 2 deletions(-)

diff --git a/two_factor/views/core.py b/two_factor/views/core.py
index 4854ee109..16849b6df 100644
--- a/two_factor/views/core.py
+++ b/two_factor/views/core.py
@@ -109,11 +109,15 @@ def post(self, *args, **kwargs):
         The user can select a particular device to challenge, being the backup
         devices added to the account.
         """"""
-
         wizard_goto_step = self.request.POST.get('wizard_goto_step', None)
-        if self.expired and self.steps.current != 'auth' and wizard_goto_step != 'auth':
+
+        if wizard_goto_step == 'auth':
+            self.storage.reset()
+
+        if self.expired and self.steps.current != 'auth':
             logger.info(""User's authentication flow has timed out. The user ""
                         ""has been redirected to the initial auth form."")
+            self.storage.reset()
             self.show_timeout_error = True
             return self.render_goto_step('auth')
 

From fb9ee1962e07bb07546ee4155e0aee5892638b9d Mon Sep 17 00:00:00 2001
From: Bouke Haarsma <bouke@haarsma.eu>
Date: Wed, 8 Jul 2020 21:00:01 +0200
Subject: [PATCH 4/4] Check that session doesn't contain password

---
 tests/test_views_login.py | 14 ++++++++++++++
 1 file changed, 14 insertions(+)

diff --git a/tests/test_views_login.py b/tests/test_views_login.py
index b9c7ca7a5..c05c2e681 100644
--- a/tests/test_views_login.py
+++ b/tests/test_views_login.py
@@ -1,3 +1,4 @@
+import json
 from unittest import mock
 
 from django.conf import settings
@@ -397,6 +398,19 @@ def test_missing_management_data(self):
         # view should return HTTP 400 Bad Request
         self.assertEqual(response.status_code, 400)
 
+    def test_no_password_in_session(self):
+        self.create_user()
+        self.enable_otp()
+
+        response = self._post({'auth-username': 'bouke@example.com',
+                               'auth-password': 'secret',
+                               'login_view-current_step': 'auth'})
+        self.assertContains(response, 'Token:')
+
+        session_contents = json.dumps(list(self.client.session.items()))
+
+        self.assertNotIn('secret', session_contents)
+
 
 class BackupTokensTest(UserMixin, TestCase):
     def setUp(self):"
CVE-2013-0208,"From 317cc0af385536dee43ef2addad50a91357fc1ad Mon Sep 17 00:00:00 2001
From: Vishvananda Ishaya <vishvananda@gmail.com>
Date: Thu, 24 Jan 2013 10:07:33 +0000
Subject: [PATCH] disallow boot from volume from specifying arbitrary volumes

Fix a vulnerability in volume attachment in nova-volume, affecting the
boot-from-volume feature.  By passing a specific volume ID, an
authenticated user may be able to boot from a volume they don't own,
potentially resulting in full access to that 3rd-party volume.
Folsom setups making use of Cinder are not affected.

Fixes bug: 1069904, CVE-2013-0208
Change-Id: I5f7c8d20d3ebf33ce1ce64bf0a8418bd2b5a6411
---
 nova/compute/api.py | 27 ++++++++++++++++++++++-----
 nova/exception.py   | 14 ++++++++++++++
 2 files changed, 36 insertions(+), 5 deletions(-)

diff --git a/nova/compute/api.py b/nova/compute/api.py
index 3742a0863ac..8df3fdf9a9c 100644
--- a/nova/compute/api.py
+++ b/nova/compute/api.py
@@ -507,6 +507,11 @@ def _create_instance(self, context, instance_type,
                         security_group, block_device_mapping)
                 instances.append(instance)
                 instance_uuids.append(instance['uuid'])
+                self._validate_bdm(context, instance)
+                # send a state update notification for the initial create to
+                # show it going from non-existent to BUILDING
+                notifications.send_update_with_states(context, instance, None,
+                        vm_states.BUILDING, None, None, service=""api"")
 
         # In the case of any exceptions, attempt DB cleanup and rollback the
         # quota reservations.
@@ -623,6 +628,23 @@ def _update_block_device_mapping(self, elevated_context,
             self.db.block_device_mapping_update_or_create(elevated_context,
                                                           values)
 
+    def _validate_bdm(self, context, instance):
+        for bdm in self.db.block_device_mapping_get_all_by_instance(
+                context, instance['uuid']):
+            # NOTE(vish): For now, just make sure the volumes are accessible.
+            snapshot_id = bdm.get('snapshot_id')
+            volume_id = bdm.get('volume_id')
+            if volume_id is not None:
+                try:
+                    self.volume_api.get(context, volume_id)
+                except Exception:
+                    raise exception.InvalidBDMVolume(id=volume_id)
+            elif snapshot_id is not None:
+                try:
+                    self.volume_api.get_snapshot(context, snapshot_id)
+                except Exception:
+                    raise exception.InvalidBDMSnapshot(id=snapshot_id)
+
     def _populate_instance_for_bdm(self, context, instance, instance_type,
             image, block_device_mapping):
         """"""Populate instance block device mapping information.""""""
@@ -735,11 +757,6 @@ def create_db_entry_for_new_instance(self, context, instance_type, image,
         self._populate_instance_for_bdm(context, instance,
                 instance_type, image, block_device_mapping)
 
-        # send a state update notification for the initial create to
-        # show it going from non-existent to BUILDING
-        notifications.send_update_with_states(context, instance, None,
-                vm_states.BUILDING, None, None, service=""api"")
-
         return instance
 
     def _check_create_policies(self, context, availability_zone,
diff --git a/nova/exception.py b/nova/exception.py
index b92e2ab87fd..2eeef046a9a 100644
--- a/nova/exception.py
+++ b/nova/exception.py
@@ -223,6 +223,20 @@ class InvalidSnapshot(Invalid):
     message = _(""Invalid snapshot"") + "": %(reason)s""
 
 
+class InvalidBDM(Invalid):
+    message = _(""Block Device Mapping is Invalid."")
+
+
+class InvalidBDMSnapshot(InvalidBDM):
+    message = _(""Block Device Mapping is Invalid: ""
+                ""failed to get snapshot %(id)s."")
+
+
+class InvalidBDMVolume(InvalidBDM):
+    message = _(""Block Device Mapping is Invalid: ""
+                ""failed to get volume %(id)s."")
+
+
 class VolumeUnattached(Invalid):
     message = _(""Volume %(volume_id)s is not attached to anything"")"
CVE-2021-41250,"From 67390298852513d13e0213870e50fb3cff1424e0 Mon Sep 17 00:00:00 2001
From: Hassan Abouelela <hassan@hassanamr.com>
Date: Fri, 5 Nov 2021 16:31:05 +0400
Subject: [PATCH] Merge pull request from GHSA-j8c3-8x46-8pp6

* Don't Exit Token Filtering Early On URLs

The token filtering function would exit early if it detected a URL
within the message, but it made no extra checks to ensure there weren't
other tokens within that message that would trigger it. This made
sense when the filtering logic was written, but it's been modified since
to introduce this bug.

Regression tests included.

Signed-off-by: Hassan Abouelela <hassan@hassanamr.com>

* Links Advisory In Token Filter Tests

Adds a link to the advisory with reasoning for the existence of the
 test.

Signed-off-by: Hassan Abouelela <hassan@hassanamr.com>
---
 bot/exts/filters/filtering.py            |  4 ---
 tests/bot/exts/filters/test_filtering.py | 40 ++++++++++++++++++++++++
 2 files changed, 40 insertions(+), 4 deletions(-)
 create mode 100644 tests/bot/exts/filters/test_filtering.py

diff --git a/bot/exts/filters/filtering.py b/bot/exts/filters/filtering.py
index 022b4ab025..f05b1d00b5 100644
--- a/bot/exts/filters/filtering.py
+++ b/bot/exts/filters/filtering.py
@@ -496,10 +496,6 @@ async def _has_watch_regex_match(self, text: str) -> Tuple[Union[bool, re.Match]
 
         text = self.clean_input(text)
 
-        # Make sure it's not a URL
-        if URL_RE.search(text):
-            return False, None
-
         watchlist_patterns = self._get_filterlist_items('filter_token', allowed=False)
         for pattern in watchlist_patterns:
             match = re.search(pattern, text, flags=re.IGNORECASE)
diff --git a/tests/bot/exts/filters/test_filtering.py b/tests/bot/exts/filters/test_filtering.py
new file mode 100644
index 0000000000..8ae59c1f15
--- /dev/null
+++ b/tests/bot/exts/filters/test_filtering.py
@@ -0,0 +1,40 @@
+import unittest
+from unittest.mock import patch
+
+from bot.exts.filters import filtering
+from tests.helpers import MockBot, autospec
+
+
+class FilteringCogTests(unittest.IsolatedAsyncioTestCase):
+    """"""Tests the `Filtering` cog.""""""
+
+    def setUp(self):
+        """"""Instantiate the bot and cog.""""""
+        self.bot = MockBot()
+        with patch(""bot.utils.scheduling.create_task"", new=lambda task, **_: task.close()):
+            self.cog = filtering.Filtering(self.bot)
+
+    @autospec(filtering.Filtering, ""_get_filterlist_items"", pass_mocks=False, return_value=[""TOKEN""])
+    async def test_token_filter(self):
+        """"""Ensure that a filter token is correctly detected in a message.""""""
+        messages = {
+            """": False,
+            ""no matches"": False,
+            ""TOKEN"": True,
+
+            # See advisory https://github.com/python-discord/bot/security/advisories/GHSA-j8c3-8x46-8pp6
+            ""https://google.com TOKEN"": True,
+            ""https://google.com something else"": False,
+        }
+
+        for message, match in messages.items():
+            with self.subTest(input=message, match=match):
+                result, _ = await self.cog._has_watch_regex_match(message)
+
+                self.assertEqual(
+                    match,
+                    bool(result),
+                    msg=f""Hit was {'expected' if match else 'not expected'} for this input.""
+                )
+                if result:
+                    self.assertEqual(""TOKEN"", result.group())"
GHSA-hggm-jpg3-v476,"From 58494b41d6ecb0f56b7c5f05d5f5e3ca0320d494 Mon Sep 17 00:00:00 2001
From: Alex Gaynor <alex.gaynor@gmail.com>
Date: Sun, 25 Oct 2020 21:16:42 -0400
Subject: [PATCH] Attempt to mitigate Bleichenbacher attacks on RSA decryption
 (#5507)

---
 CHANGELOG.rst                                 |  6 +++++
 docs/spelling_wordlist.txt                    |  1 +
 .../hazmat/backends/openssl/rsa.py            | 26 ++++++++-----------
 3 files changed, 18 insertions(+), 15 deletions(-)

diff --git a/CHANGELOG.rst b/CHANGELOG.rst
index 32a6c8522547..f105465e2eaa 100644
--- a/CHANGELOG.rst
+++ b/CHANGELOG.rst
@@ -8,6 +8,12 @@ Changelog
 
 .. note:: This version is not yet released and is under active development.
 
+* **SECURITY ISSUE:** Attempted to make RSA PKCS#1v1.5 decryption more constant
+  time, to protect against Bleichenbacher vulnerabilities. Due to limitations
+  imposed by our API, we cannot completely mitigate this vulnerability and a
+  future release will contain a new API which is designed to be resilient to
+  these for contexts where it is required. Credit to **Hubert Kario** for
+  reporting the issue. *CVE-2020-25659*
 * Support for OpenSSL 1.0.2 has been removed. Users on older version of OpenSSL
   will need to upgrade.
 * Added basic support for PKCS7 signing (including SMIME) via
diff --git a/docs/spelling_wordlist.txt b/docs/spelling_wordlist.txt
index 9ec971b36ad2..c8c275142ff7 100644
--- a/docs/spelling_wordlist.txt
+++ b/docs/spelling_wordlist.txt
@@ -7,6 +7,7 @@ backend
 Backends
 backends
 bcrypt
+Bleichenbacher
 Blowfish
 boolean
 Botan
diff --git a/src/cryptography/hazmat/backends/openssl/rsa.py b/src/cryptography/hazmat/backends/openssl/rsa.py
index 69926c8f3723..66b37224e443 100644
--- a/src/cryptography/hazmat/backends/openssl/rsa.py
+++ b/src/cryptography/hazmat/backends/openssl/rsa.py
@@ -119,23 +119,19 @@ def _enc_dec_rsa_pkey_ctx(backend, key, data, padding_enum, padding):
 
     outlen = backend._ffi.new(""size_t *"", buf_size)
     buf = backend._ffi.new(""unsigned char[]"", buf_size)
+    # Everything from this line onwards is written with the goal of being as
+    # constant-time as is practical given the constraints of Python and our
+    # API. See Bleichenbacher's '98 attack on RSA, and its many many variants.
+    # As such, you should not attempt to change this (particularly to ""clean it
+    # up"") without understanding why it was written this way (see
+    # Chesterton's Fence), and without measuring to verify you have not
+    # introduced observable time differences.
     res = crypt(pkey_ctx, buf, outlen, data, len(data))
+    resbuf = backend._ffi.buffer(buf)[: outlen[0]]
+    backend._lib.ERR_clear_error()
     if res <= 0:
-        _handle_rsa_enc_dec_error(backend, key)
-
-    return backend._ffi.buffer(buf)[: outlen[0]]
-
-
-def _handle_rsa_enc_dec_error(backend, key):
-    errors = backend._consume_errors_with_text()
-    if isinstance(key, _RSAPublicKey):
-        raise ValueError(
-            ""Data too long for key size. Encrypt less data or use a ""
-            ""larger key size."",
-            errors,
-        )
-    else:
-        raise ValueError(""Decryption failed."", errors)
+        raise ValueError(""Encryption/decryption failed."")
+    return resbuf
 
 
 def _rsa_sig_determine_padding(backend, key, padding, algorithm):"
GHSA-f248-v4qh-x2r6,"From 273b27d0de1004389dd8cf43c40b1197c787e7cd Mon Sep 17 00:00:00 2001
From: Glenn Snyder <gsnyder@blackducksoftware.com>
Date: Thu, 22 Oct 2020 14:47:14 -0400
Subject: [PATCH] fixed use of hard-coded values for the verify parameter being
 supplied to the requests module calls

---
 blackduck/HubRestApi.py  | 6 +++---
 blackduck/__version__.py | 2 +-
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/blackduck/HubRestApi.py b/blackduck/HubRestApi.py
index df9ad2ac..8ebcd349 100755
--- a/blackduck/HubRestApi.py
+++ b/blackduck/HubRestApi.py
@@ -1307,11 +1307,11 @@ def upload_scan(self, filename):
         if filename.endswith('.json') or filename.endswith('.jsonld'):
             headers['Content-Type'] = 'application/ld+json'
             with open(filename,""r"") as f:
-                response = requests.post(url, headers=headers, data=f, verify=False)
+                response = requests.post(url, headers=headers, data=f, verify=not self.config['insecure'])
         elif filename.endswith('.bdio'):
             headers['Content-Type'] = 'application/vnd.blackducksoftware.bdio+zip'
             with open(filename,""rb"") as f:
-                response = requests.post(url, headers=headers, data=f, verify=False)
+                response = requests.post(url, headers=headers, data=f, verify=not self.config['insecure'])
         else:
             raise Exception(""Unkown file type"")
         return response
@@ -1338,7 +1338,7 @@ def download_project_scans(self, project_name,version_name, output_folder=None):
                     if not os.path.exists(project_name):
                         os.mkdir(project_name)
                     pathname = os.path.join(project_name, filename)
-                responce = requests.get(url, headers=self.get_headers(), stream=True, verify=False)
+                responce = requests.get(url, headers=self.get_headers(), stream=True, verify=not self.config['insecure'])
                 with open(pathname, ""wb"") as f:
                     for data in responce.iter_content():
                         f.write(data)
diff --git a/blackduck/__version__.py b/blackduck/__version__.py
index e456aef6..100276e4 100644
--- a/blackduck/__version__.py
+++ b/blackduck/__version__.py
@@ -1,3 +1,3 @@
-VERSION = (0, 0, 52)
+VERSION = (0, 0, 53)
 
 __version__ = '.'.join(map(str, VERSION))"
PYSEC-2021-62,"From ce1bef6f1ee06ac497ca0c837fbd1c7ef6c2472b Mon Sep 17 00:00:00 2001
From: Alex Gaynor <alex.gaynor@gmail.com>
Date: Sun, 25 Oct 2020 19:01:50 -0400
Subject: [PATCH] Attempt to mitigate Bleichenbacher attacks on RSA decryption

---
 CHANGELOG.rst                                 |  6 +++++
 docs/spelling_wordlist.txt                    |  1 +
 .../hazmat/backends/openssl/rsa.py            | 26 ++++++++-----------
 3 files changed, 18 insertions(+), 15 deletions(-)

diff --git a/CHANGELOG.rst b/CHANGELOG.rst
index 32a6c8522547..f105465e2eaa 100644
--- a/CHANGELOG.rst
+++ b/CHANGELOG.rst
@@ -8,6 +8,12 @@ Changelog
 
 .. note:: This version is not yet released and is under active development.
 
+* **SECURITY ISSUE:** Attempted to make RSA PKCS#1v1.5 decryption more constant
+  time, to protect against Bleichenbacher vulnerabilities. Due to limitations
+  imposed by our API, we cannot completely mitigate this vulnerability and a
+  future release will contain a new API which is designed to be resilient to
+  these for contexts where it is required. Credit to **Hubert Kario** for
+  reporting the issue. *CVE-2020-25659*
 * Support for OpenSSL 1.0.2 has been removed. Users on older version of OpenSSL
   will need to upgrade.
 * Added basic support for PKCS7 signing (including SMIME) via
diff --git a/docs/spelling_wordlist.txt b/docs/spelling_wordlist.txt
index 9ec971b36ad2..c8c275142ff7 100644
--- a/docs/spelling_wordlist.txt
+++ b/docs/spelling_wordlist.txt
@@ -7,6 +7,7 @@ backend
 Backends
 backends
 bcrypt
+Bleichenbacher
 Blowfish
 boolean
 Botan
diff --git a/src/cryptography/hazmat/backends/openssl/rsa.py b/src/cryptography/hazmat/backends/openssl/rsa.py
index 423f6878c124..2c7b0e333e1f 100644
--- a/src/cryptography/hazmat/backends/openssl/rsa.py
+++ b/src/cryptography/hazmat/backends/openssl/rsa.py
@@ -119,23 +119,19 @@ def _enc_dec_rsa_pkey_ctx(backend, key, data, padding_enum, padding):
 
     outlen = backend._ffi.new(""size_t *"", buf_size)
     buf = backend._ffi.new(""unsigned char[]"", buf_size)
+    # Everything from this line onwards is written with the goal of being as
+    # constant-time as is practical given the constraints of Python and our
+    # API. See Bleichenbacher's '98 attack on RSA, and its many many variants.
+    # As such, you should not attempt to change this (particularly to ""clean it
+    # up"") without understanding why it was written this way (see
+    # Chesterton's Fence), and without measuring to verify you have not
+    # introduced observable time differences.
     res = crypt(pkey_ctx, buf, outlen, data, len(data))
+    resbuf = backend._ffi.buffer(buf)[: outlen[0]]
+    backend._lib.ERR_clear_error()
     if res <= 0:
-        _handle_rsa_enc_dec_error(backend, key)
-
-    return backend._ffi.buffer(buf)[: outlen[0]]
-
-
-def _handle_rsa_enc_dec_error(backend, key):
-    errors = backend._consume_errors_with_text()
-    if isinstance(key, _RSAPublicKey):
-        raise ValueError(
-            ""Data too long for key size. Encrypt less data or use a ""
-            ""larger key size."",
-            errors,
-        )
-    else:
-        raise ValueError(""Decryption failed."", errors)
+        raise ValueError(""Encryption/decryption failed."")
+    return resbuf
 
 
 def _rsa_sig_determine_padding(backend, key, padding, algorithm):"
GHSA-qhx9-7hx7-cp4r,"From 57a2f22e0c1d2b328c4f54bf75741d74f47f1a6b Mon Sep 17 00:00:00 2001
From: Marcel Hellkamp <marc@gsites.de>
Date: Wed, 11 Nov 2020 19:24:29 +0100
Subject: [PATCH] Do not split query strings on `;` anymore.

Using `;` as a separator instead of `&` was allowed a long time ago,
but is now obsolete and actually invalid according to the 2014 W3C
recommendations. Even if this change is technically backwards-incompatible,
no real-world application should depend on broken behavior. If you REALLY
need this functionality, monkey-patch the _parse_qsl() function.
---
 bottle.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/bottle.py b/bottle.py
index bcfc5e62b..417b01b98 100644
--- a/bottle.py
+++ b/bottle.py
@@ -2585,7 +2585,7 @@ def parse_range_header(header, maxlen=0):
 
 def _parse_qsl(qs):
     r = []
-    for pair in qs.replace(';','&').split('&'):
+    for pair in qs.split('&'):
         if not pair: continue
         nv = pair.split('=', 1)
         if len(nv) != 2: nv.append('')"
PYSEC-2018-68,"From 1845c0e4b1bff3462c91c3108c85205acd3c75a2 Mon Sep 17 00:00:00 2001
From: Joseph Weston <joseph.weston08@gmail.com>
Date: Fri, 16 Feb 2018 17:08:58 +0100
Subject: [PATCH] Security fix: fix gitlab group whitelist check

check group membership of users

previously, group_whitelist allowed any user who could access the groups in the whitelist,
rather than checking their membership of the groups.

Admin users received the correct behavior already
---
 oauthenticator/gitlab.py | 34 ++++++++--------------------------
 1 file changed, 8 insertions(+), 26 deletions(-)

diff --git a/oauthenticator/gitlab.py b/oauthenticator/gitlab.py
index e5d9029e..e6669c2a 100644
--- a/oauthenticator/gitlab.py
+++ b/oauthenticator/gitlab.py
@@ -21,7 +21,6 @@
 
 from traitlets import Set
 
-from .common import next_page_from_links
 from .oauth2 import OAuthLoginHandler, OAuthenticator
 
 # Support gitlab.com and gitlab community edition installations
@@ -131,31 +130,14 @@ def authenticate(self, handler, data=None):
     def _check_group_whitelist(self, username, user_id, is_admin, access_token):
         http_client = AsyncHTTPClient()
         headers = _api_headers(access_token)
-        if is_admin:
-            # For admins, /groups returns *all* groups. As a workaround
-            # we check if we are a member of each group in the whitelist
-            for group in map(url_escape, self.gitlab_group_whitelist):
-                url = ""%s/groups/%s/members/%d"" % (GITLAB_API, group, user_id)
-                req = HTTPRequest(url, method=""GET"", headers=headers)
-                resp = yield http_client.fetch(req, raise_error=False)
-                if resp.code == 200:
-                    return True  # user _is_ in group
-        else:
-            # For regular users we get all the groups to which they have access
-            # and check if any of these are in the whitelisted groups
-            next_page = url_concat(""%s/groups"" % GITLAB_API,
-                                   dict(all_available=True))
-            while next_page:
-                req = HTTPRequest(next_page, method=""GET"", headers=headers)
-                resp = yield http_client.fetch(req)
-                resp_json = json.loads(resp.body.decode('utf8', 'replace'))
-                next_page = next_page_from_links(resp)
-                user_groups = set(entry[""path""] for entry in resp_json)
-                # check if any of the organizations seen thus far are in whitelist
-                if len(self.gitlab_group_whitelist & user_groups) > 0:
-                    return True
-            return False
-
+        # Check if we are a member of each group in the whitelist
+        for group in map(url_escape, self.gitlab_group_whitelist):
+            url = ""%s/groups/%s/members/%d"" % (GITLAB_API, group, user_id)
+            req = HTTPRequest(url, method=""GET"", headers=headers)
+            resp = yield http_client.fetch(req, raise_error=False)
+            if resp.code == 200:
+                return True  # user _is_ in group
+        return False
 
 
 class LocalGitLabOAuthenticator(LocalAuthenticator, GitLabOAuthenticator):"
GHSA-f865-m6cq-j9vx,"From c811b37c65a4372a7ce613111d2a508c204f9833 Mon Sep 17 00:00:00 2001
From: Vinzent Steinberg <Vinzent.Steinberg@gmail.com>
Date: Wed, 10 Feb 2021 16:45:04 +0100
Subject: [PATCH 1/2] Fix ReDOS vulnerability

Fixes #548, with the workaround suggested by @yetingli.
---
 mpmath/ctx_mp.py             |  4 ++--
 mpmath/tests/test_convert.py | 10 ++++++++++
 2 files changed, 12 insertions(+), 2 deletions(-)

diff --git a/mpmath/ctx_mp.py b/mpmath/ctx_mp.py
index 39fc9411f..93594dd44 100644
--- a/mpmath/ctx_mp.py
+++ b/mpmath/ctx_mp.py
@@ -42,8 +42,8 @@
 
 new = object.__new__
 
-get_complex = re.compile(r'^\(?(?P<re>[\+\-]?\d*\.?\d*(e[\+\-]?\d+)?)??'
-                         r'(?P<im>[\+\-]?\d*\.?\d*(e[\+\-]?\d+)?j)?\)?$')
+get_complex = re.compile(r'^\(?(?P<re>[\+\-]?\d*(\.\d*)?(e[\+\-]?\d+)?)??'
+                         r'(?P<im>[\+\-]?\d*(\.\d*)?(e[\+\-]?\d+)?j)?\)?$')
 
 if BACKEND == 'sage':
     from sage.libs.mpmath.ext_main import Context as BaseMPContext
diff --git a/mpmath/tests/test_convert.py b/mpmath/tests/test_convert.py
index 3e2f55590..cf1a91dac 100644
--- a/mpmath/tests/test_convert.py
+++ b/mpmath/tests/test_convert.py
@@ -194,6 +194,16 @@ def test_mpmathify():
     assert mpmathify('(1.2e-10 - 3.4e5j)') == mpc('1.2e-10', '-3.4e5')
     assert mpmathify('1j') == mpc(1j)
 
+def test_issue548():
+    try:
+        # This expression is invalid, but may trigger the ReDOS vulnerability
+        # in the regular expression.
+        mpmathify('(' + '1' * 5000 + '!j')
+    except:
+        return
+    # The expression is invalid and should raise an exception.
+    assert False
+
 def test_compatibility():
     try:
         import numpy as np

From 2865c7d12b2a077d420427ad187eca831a48bff4 Mon Sep 17 00:00:00 2001
From: Vinzent Steinberg <Vinzent.Steinberg@gmail.com>
Date: Wed, 10 Feb 2021 16:47:57 +0100
Subject: [PATCH 2/2] Improve comment

---
 mpmath/tests/test_convert.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/mpmath/tests/test_convert.py b/mpmath/tests/test_convert.py
index cf1a91dac..cb1db5b55 100644
--- a/mpmath/tests/test_convert.py
+++ b/mpmath/tests/test_convert.py
@@ -197,7 +197,7 @@ def test_mpmathify():
 def test_issue548():
     try:
         # This expression is invalid, but may trigger the ReDOS vulnerability
-        # in the regular expression.
+        # in the regular expression for parsing complex numbers.
         mpmathify('(' + '1' * 5000 + '!j')
     except:
         return"
CVE-2016-10321,"From 944d8bd8f3c5cf8ae296fc03d149056c65358426 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Leonel=20C=C3=A2mara?= <leonelcamara@gmail.com>
Date: Wed, 4 May 2016 19:02:53 +0100
Subject: [PATCH] Check if host is denied before verifying password

---
 applications/admin/controllers/default.py | 3 +++
 applications/admin/models/access.py       | 8 ++++++--
 2 files changed, 9 insertions(+), 2 deletions(-)

diff --git a/applications/admin/controllers/default.py b/applications/admin/controllers/default.py
index 9eaf90d15..bed4e8633 100644
--- a/applications/admin/controllers/default.py
+++ b/applications/admin/controllers/default.py
@@ -121,6 +121,9 @@ def index():
         send = URL('site')
     if session.authorized:
         redirect(send)
+    elif failed_login_count() >= allowed_number_of_attempts:
+        time.sleep(2 ** allowed_number_of_attempts)
+        raise HTTP(403)
     elif request.vars.password:
         if verify_password(request.vars.password[:1024]):
             session.authorized = True
diff --git a/applications/admin/models/access.py b/applications/admin/models/access.py
index fa1ee01cb..b94ce8d08 100644
--- a/applications/admin/models/access.py
+++ b/applications/admin/models/access.py
@@ -104,13 +104,12 @@ def write_hosts_deny(denied_hosts):
     portalocker.unlock(f)
     f.close()
 
-
 def login_record(success=True):
     denied_hosts = read_hosts_deny()
     val = (0, 0)
     if success and request.client in denied_hosts:
         del denied_hosts[request.client]
-    elif not success and not request.is_local:
+    elif not success:
         val = denied_hosts.get(request.client, (0, 0))
         if time.time() - val[1] < expiration_failed_logins \
             and val[0] >= allowed_number_of_attempts:
@@ -121,6 +120,11 @@ def login_record(success=True):
     write_hosts_deny(denied_hosts)
     return val[0]
 
+def failed_login_count():
+    denied_hosts = read_hosts_deny()
+    val = denied_hosts.get(request.client, (0, 0))
+    return val[0]
+
 
 # ###########################################################
 # ## session expiration"
GHSA-p75f-g7gx-2r7p,"From 2dad81128250cb2e5d950cddc9d3c0314a80b4bb Mon Sep 17 00:00:00 2001
From: Jens Vagelpohl <jens@netz.ooo>
Date: Tue, 23 Feb 2021 12:25:04 +0100
Subject: [PATCH] - Fix missing access control on ZODB Role Manager
 enumerateRoles

---
 CHANGES.rst                                                  | 2 ++
 src/Products/PluggableAuthService/plugins/ZODBRoleManager.py | 1 +
 2 files changed, 3 insertions(+)

diff --git a/CHANGES.rst b/CHANGES.rst
index d0683af..a1bfbd8 100644
--- a/CHANGES.rst
+++ b/CHANGES.rst
@@ -4,6 +4,8 @@ Change Log
 2.6.0 (unreleased)
 ------------------
 
+- Fix missing access control on ZODB Role Manager ``enumerateRoles``
+
 - Fix open redirect issue in `Cookie Auth Helper` redirect handling
 
 - Add support for Python 3.9.
diff --git a/src/Products/PluggableAuthService/plugins/ZODBRoleManager.py b/src/Products/PluggableAuthService/plugins/ZODBRoleManager.py
index e0aa1ea..9167b3b 100644
--- a/src/Products/PluggableAuthService/plugins/ZODBRoleManager.py
+++ b/src/Products/PluggableAuthService/plugins/ZODBRoleManager.py
@@ -112,6 +112,7 @@ def getRolesForPrincipal(self, principal, request=None):
     #
     #   IRoleEnumerationPlugin implementation
     #
+    @security.private
     def enumerateRoles(self, id=None, exact_match=False, sort_by=None,
                        max_results=None, **kw):
         """""" See IRoleEnumerationPlugin."
GHSA-5p9j-w2wx-qx4c,"From 8f32f89654d6c30d56e0dd167059d32146fb32ef Mon Sep 17 00:00:00 2001
From: Esteban C Borsani <ecastroborsani@gmail.com>
Date: Wed, 23 Feb 2022 05:16:32 -0300
Subject: [PATCH] fix unsafe redirect (#308)

---
 spirit/admin/views.py              |  5 +++--
 spirit/comment/flag/views.py       |  7 ++++---
 spirit/comment/like/views.py       |  8 +++++---
 spirit/comment/poll/views.py       | 13 +++++++------
 spirit/comment/views.py            | 14 +++++++-------
 spirit/core/utils/decorators.py    |  4 ++--
 spirit/core/utils/http.py          | 29 ++++++++++++++++++++++++++++
 spirit/topic/favorite/views.py     |  8 ++++----
 spirit/topic/moderate/views.py     |  6 +++---
 spirit/topic/notification/views.py | 13 +++++++------
 spirit/topic/private/views.py      | 31 ++++++++++++++++--------------
 spirit/topic/views.py              |  9 +++++----
 spirit/user/admin/views.py         | 11 ++++++-----
 spirit/user/auth/tests/tests.py    |  5 +++++
 spirit/user/auth/views.py          | 12 +++++++-----
 15 files changed, 111 insertions(+), 64 deletions(-)
 create mode 100644 spirit/core/utils/http.py

diff --git a/spirit/admin/views.py b/spirit/admin/views.py
index 31e35a9d5..00e134c5e 100644
--- a/spirit/admin/views.py
+++ b/spirit/admin/views.py
@@ -1,12 +1,13 @@
 # -*- coding: utf-8 -*-
 
-from django.shortcuts import render, redirect
+from django.shortcuts import render
 from django.contrib import messages
 from django.utils.translation import gettext as _
 from django.contrib.auth import get_user_model
 
 import spirit
 import django
+from spirit.core.utils.http import safe_redirect
 from spirit.category.models import Category
 from spirit.comment.flag.models import CommentFlag
 from spirit.comment.like.models import CommentLike
@@ -25,7 +26,7 @@ def config_basic(request):
     if is_post(request) and form.is_valid():
         form.save()
         messages.info(request, _(""Settings updated!""))
-        return redirect(request.GET.get(""next"", request.get_full_path()))
+        return safe_redirect(request, ""next"", request.get_full_path())
     return render(
         request=request,
         template_name='spirit/admin/config_basic.html',
diff --git a/spirit/comment/flag/views.py b/spirit/comment/flag/views.py
index a2f295205..9fa4cf163 100644
--- a/spirit/comment/flag/views.py
+++ b/spirit/comment/flag/views.py
@@ -1,9 +1,10 @@
 # -*- coding: utf-8 -*-
 
 from django.contrib.auth.decorators import login_required
-from django.shortcuts import render, redirect, get_object_or_404
+from django.shortcuts import render, get_object_or_404
 
-from ...core.utils.views import is_post, post_data
+from spirit.core.utils.http import safe_redirect
+from spirit.core.utils.views import is_post, post_data
 from ..models import Comment
 from .forms import FlagForm
 
@@ -18,7 +19,7 @@ def create(request, comment_id):
 
     if is_post(request) and form.is_valid():
         form.save()
-        return redirect(request.POST.get('next', comment.get_absolute_url()))
+        return safe_redirect(request, 'next', comment.get_absolute_url(), method='POST')
 
     return render(
         request=request,
diff --git a/spirit/comment/like/views.py b/spirit/comment/like/views.py
index 6b046b996..541d0e57e 100644
--- a/spirit/comment/like/views.py
+++ b/spirit/comment/like/views.py
@@ -1,9 +1,10 @@
 # -*- coding: utf-8 -*-
 
 from django.contrib.auth.decorators import login_required
-from django.shortcuts import render, redirect, get_object_or_404
+from django.shortcuts import render, get_object_or_404
 from django.urls import reverse
 
+from spirit.core.utils.http import safe_redirect
 from spirit.core.utils.views import is_post, post_data, is_ajax
 from spirit.core.utils import json_response
 from spirit.comment.models import Comment
@@ -28,7 +29,7 @@ def create(request, comment_id):
         if is_ajax(request):
             return json_response({'url_delete': like.get_delete_url()})
 
-        return redirect(request.POST.get('next', comment.get_absolute_url()))
+        return safe_redirect(request, 'next', comment.get_absolute_url(), method='POST')
 
     return render(
         request=request,
@@ -52,7 +53,8 @@ def delete(request, pk):
                 kwargs={'comment_id': like.comment.pk})
             return json_response({'url_create': url, })
 
-        return redirect(request.POST.get('next', like.comment.get_absolute_url()))
+        return safe_redirect(
+            request, 'next', like.comment.get_absolute_url(), method='POST')
 
     return render(
         request=request,
diff --git a/spirit/comment/poll/views.py b/spirit/comment/poll/views.py
index 3a904df3f..18838844a 100644
--- a/spirit/comment/poll/views.py
+++ b/spirit/comment/poll/views.py
@@ -1,7 +1,7 @@
 # -*- coding: utf-8 -*-
 
 from django.contrib.auth.decorators import login_required
-from django.shortcuts import render, redirect, get_object_or_404
+from django.shortcuts import render, get_object_or_404
 from django.views.decorators.http import require_POST
 from django.contrib import messages
 from django.contrib.auth.views import redirect_to_login
@@ -10,8 +10,9 @@
 
 from djconfig import config
 
-from ...core import utils
-from ...core.utils.paginator import yt_paginate
+from spirit.core.utils.http import safe_redirect
+from spirit.core import utils
+from spirit.core.utils.paginator import yt_paginate
 from .models import CommentPoll, CommentPollChoice, CommentPollVote
 from .forms import PollVoteManyForm
 
@@ -35,7 +36,7 @@ def close_or_open(request, pk, close=True):
      .filter(pk=poll.pk)
      .update(close_at=close_at))
 
-    return redirect(request.GET.get('next', poll.get_absolute_url()))
+    return safe_redirect(request, 'next', poll.get_absolute_url())
 
 
 @require_POST
@@ -55,10 +56,10 @@ def vote(request, pk):
         CommentPollChoice.decrease_vote_count(poll=poll, voter=request.user)
         form.save_m2m()
         CommentPollChoice.increase_vote_count(poll=poll, voter=request.user)
-        return redirect(request.POST.get('next', poll.get_absolute_url()))
+        return safe_redirect(request, 'next', poll.get_absolute_url(), method='POST')
 
     messages.error(request, utils.render_form_errors(form))
-    return redirect(request.POST.get('next', poll.get_absolute_url()))
+    return safe_redirect(request, 'next', poll.get_absolute_url(), method='POST')
 
 
 @login_required
diff --git a/spirit/comment/views.py b/spirit/comment/views.py
index e7dff724e..232b0e8c5 100644
--- a/spirit/comment/views.py
+++ b/spirit/comment/views.py
@@ -8,6 +8,7 @@
 
 from djconfig import config
 
+from spirit.core.utils.http import safe_redirect
 from spirit.core.utils.views import is_post, post_data, is_ajax
 from spirit.core.utils.ratelimit.decorators import ratelimit
 from spirit.core.utils.decorators import moderator_required
@@ -41,15 +42,14 @@ def publish(request, topic_id, pk=None):
     if is_post(request) and not request.is_limited() and form.is_valid():
         if not user.st.update_post_hash(form.get_comment_hash()):
             # Hashed comment may have not been saved yet
-            return redirect(
-                request.POST.get('next', None) or
-                Comment
+            default_url = lambda: (Comment
                 .get_last_for_topic(topic_id)
                 .get_absolute_url())
+            return safe_redirect(request, 'next', default_url, method='POST')
 
         comment = form.save()
         comment_posted(comment=comment, mentions=form.mentions)
-        return redirect(request.POST.get('next', comment.get_absolute_url()))
+        return safe_redirect(request, 'next', comment.get_absolute_url(), method='POST')
 
     return render(
         request=request,
@@ -67,7 +67,7 @@ def update(request, pk):
         pre_comment_update(comment=Comment.objects.get(pk=comment.pk))
         comment = form.save()
         post_comment_update(comment=comment)
-        return redirect(request.POST.get('next', comment.get_absolute_url()))
+        return safe_redirect(request, 'next', comment.get_absolute_url(), method='POST')
     return render(
         request=request,
         template_name='spirit/comment/update.html',
@@ -81,7 +81,7 @@ def delete(request, pk, remove=True):
         (Comment.objects
          .filter(pk=pk)
          .update(is_removed=remove))
-        return redirect(request.GET.get('next', comment.get_absolute_url()))
+        return safe_redirect(request, 'next', comment.get_absolute_url())
     return render(
         request=request,
         template_name='spirit/comment/moderate.html',
@@ -104,7 +104,7 @@ def move(request, topic_id):
     else:
         messages.error(request, render_form_errors(form))
 
-    return redirect(request.POST.get('next', topic.get_absolute_url()))
+    return safe_redirect(request, 'next', topic.get_absolute_url(), method='POST')
 
 
 def find(request, pk):
diff --git a/spirit/core/utils/decorators.py b/spirit/core/utils/decorators.py
index 5c68224e3..425bc9d06 100644
--- a/spirit/core/utils/decorators.py
+++ b/spirit/core/utils/decorators.py
@@ -4,9 +4,9 @@
 
 from django.core.exceptions import PermissionDenied
 from django.contrib.auth.views import redirect_to_login
-from django.shortcuts import redirect
 
 from spirit.core.conf import settings
+from spirit.core.utils.http import safe_redirect
 
 
 def moderator_required(view_func):
@@ -48,7 +48,7 @@ def guest_only(view_func):
     @wraps(view_func)
     def wrapper(request, *args, **kwargs):
         if request.user.is_authenticated:
-            return redirect(request.GET.get('next', request.user.st.get_absolute_url()))
+            return safe_redirect(request, 'next', request.user.st.get_absolute_url())
 
         return view_func(request, *args, **kwargs)
 
diff --git a/spirit/core/utils/http.py b/spirit/core/utils/http.py
new file mode 100644
index 000000000..fb3626fa0
--- /dev/null
+++ b/spirit/core/utils/http.py
@@ -0,0 +1,29 @@
+# -*- coding: utf-8 -*-
+
+from django.shortcuts import redirect
+from django.utils.encoding import iri_to_uri
+
+try:
+    from django.utils.http import url_has_allowed_host_and_scheme
+except ImportError:
+    from django.utils.http import is_safe_url as url_has_allowed_host_and_scheme
+
+
+def _resolve_lazy_url(url):
+    if callable(url):
+        return url()
+    return url
+
+
+def safe_redirect(request, key, default_url='', method='GET'):
+    next = (
+        getattr(request, method).get(key, None) or
+        _resolve_lazy_url(default_url)
+    )
+    url_is_safe = url_has_allowed_host_and_scheme(
+        url=next, allowed_hosts=None)
+        #allowed_hosts=settings.ALLOWED_HOSTS,
+        #require_https=request.is_secure())
+    if url_is_safe:
+        return redirect(iri_to_uri(next))
+    return redirect('/')
diff --git a/spirit/topic/favorite/views.py b/spirit/topic/favorite/views.py
index f95e7ecaa..04a6241b9 100644
--- a/spirit/topic/favorite/views.py
+++ b/spirit/topic/favorite/views.py
@@ -2,14 +2,14 @@
 
 from django.contrib.auth.decorators import login_required
 from django.shortcuts import get_object_or_404
-from django.shortcuts import redirect
 from django.views.decorators.http import require_POST
 from django.contrib import messages
 
 from .models import TopicFavorite
 from .forms import FavoriteForm
 from ..models import Topic
-from ...core import utils
+from spirit.core import utils
+from spirit.core.utils.http import safe_redirect
 
 
 @require_POST
@@ -23,7 +23,7 @@ def create(request, topic_id):
     else:
         messages.error(request, utils.render_form_errors(form))
 
-    return redirect(request.POST.get('next', topic.get_absolute_url()))
+    return safe_redirect(request, 'next', topic.get_absolute_url(), method='POST')
 
 
 @require_POST
@@ -31,4 +31,4 @@ def create(request, topic_id):
 def delete(request, pk):
     favorite = get_object_or_404(TopicFavorite, pk=pk, user=request.user)
     favorite.delete()
-    return redirect(request.POST.get('next', favorite.topic.get_absolute_url()))
+    return safe_redirect(request, 'next', favorite.topic.get_absolute_url(), method='POST')
diff --git a/spirit/topic/moderate/views.py b/spirit/topic/moderate/views.py
index 1502f2d31..752ec99f6 100644
--- a/spirit/topic/moderate/views.py
+++ b/spirit/topic/moderate/views.py
@@ -1,10 +1,11 @@
 # -*- coding: utf-8 -*-
 
 from django.utils import timezone
-from django.shortcuts import render, redirect, get_object_or_404
+from django.shortcuts import render, get_object_or_404
 from django.contrib import messages
 from django.utils.translation import gettext as _
 
+from spirit.core.utils.http import safe_redirect
 from spirit.core.utils.views import is_post
 from spirit.core.utils.decorators import moderator_required
 from spirit.comment.models import Comment
@@ -33,8 +34,7 @@ def _moderate(request, pk, field_name, to_value, action=None, message=None):
         if message is not None:
             messages.info(request, message)
 
-        return redirect(request.POST.get(
-            'next', topic.get_absolute_url()))
+        return safe_redirect(request, 'next', topic.get_absolute_url(), method='POST')
 
     return render(
         request=request,
diff --git a/spirit/topic/notification/views.py b/spirit/topic/notification/views.py
index 7ed189d6b..da8673ea0 100644
--- a/spirit/topic/notification/views.py
+++ b/spirit/topic/notification/views.py
@@ -3,7 +3,7 @@
 import json
 
 from django.contrib.auth.decorators import login_required
-from django.shortcuts import render, redirect, get_object_or_404
+from django.shortcuts import render, get_object_or_404
 from django.views.decorators.http import require_POST
 from django.http import Http404, HttpResponse
 from django.contrib import messages
@@ -18,6 +18,7 @@
 from spirit.core.utils.paginator import yt_paginate
 from spirit.core.utils.paginator.infinite_paginator import paginate
 from spirit.core.utils.views import is_ajax
+from spirit.core.utils.http import safe_redirect
 from spirit.topic.models import Topic
 from .models import TopicNotification
 from .forms import NotificationForm, NotificationCreationForm
@@ -39,7 +40,7 @@ def create(request, topic_id):
     else:
         messages.error(request, utils.render_form_errors(form))
 
-    return redirect(request.POST.get('next', topic.get_absolute_url()))
+    return safe_redirect(request, 'next', topic.get_absolute_url(), method='POST')
 
 
 @require_POST
@@ -53,8 +54,8 @@ def update(request, pk):
     else:
         messages.error(request, utils.render_form_errors(form))
 
-    return redirect(request.POST.get(
-        'next', notification.topic.get_absolute_url()))
+    return safe_redirect(
+        request, 'next', notification.topic.get_absolute_url(), method='POST')
 
 
 @login_required
@@ -124,5 +125,5 @@ def mark_all_as_read(request):
         .for_access(request.user)
         .filter(is_read=False)
         .update(is_read=True))
-    return redirect(request.POST.get(
-        'next', reverse('spirit:topic:notification:index')))
+    return safe_redirect(
+        request, 'next', reverse('spirit:topic:notification:index'), method='POST')
diff --git a/spirit/topic/private/views.py b/spirit/topic/private/views.py
index bd0f2a155..4ddd48522 100644
--- a/spirit/topic/private/views.py
+++ b/spirit/topic/private/views.py
@@ -10,14 +10,15 @@
 
 from djconfig import config
 
-from ...core.conf import settings
-from ...core import utils
-from ...core.utils.views import is_post, post_data
-from ...core.utils.paginator import paginate, yt_paginate
-from ...core.utils.ratelimit.decorators import ratelimit
-from ...comment.forms import CommentForm
-from ...comment.utils import comment_posted
-from ...comment.models import Comment
+from spirit.core.conf import settings
+from spirit.core import utils
+from spirit.core.utils.http import safe_redirect
+from spirit.core.utils.views import is_post, post_data
+from spirit.core.utils.paginator import paginate, yt_paginate
+from spirit.core.utils.ratelimit.decorators import ratelimit
+from spirit.comment.forms import CommentForm
+from spirit.comment.utils import comment_posted
+from spirit.comment.models import Comment
 from ..models import Topic
 from ..utils import topic_viewed
 from .utils import notify_access
@@ -50,9 +51,8 @@ def publish(request, user_id=None):
             all([tform.is_valid(), cform.is_valid(), tpform.is_valid()]) and
             not request.is_limited()):
         if not user.st.update_post_hash(tform.get_topic_hash()):
-            return redirect(
-                request.POST.get('next', None) or
-                tform.category.get_absolute_url())
+            return safe_redirect(
+                request, 'next', lambda: tform.category.get_absolute_url(), method='POST')
 
         # wrap in transaction.atomic?
         topic = tform.save()
@@ -123,7 +123,8 @@ def create_access(request, topic_id):
     else:
         messages.error(request, utils.render_form_errors(form))
 
-    return redirect(request.POST.get('next', topic_private.get_absolute_url()))
+    return safe_redirect(
+        request, 'next', topic_private.get_absolute_url(), method='POST')
 
 
 @login_required
@@ -136,7 +137,8 @@ def delete_access(request, pk):
         if request.user.pk == topic_private.user_id:
             return redirect(reverse(""spirit:topic:private:index""))
 
-        return redirect(request.POST.get('next', topic_private.get_absolute_url()))
+        return safe_redirect(
+            request, 'next', topic_private.get_absolute_url(), method='POST')
 
     return render(
         request=request,
@@ -160,7 +162,8 @@ def join_in(request, topic_id):
     if is_post(request) and form.is_valid():
         topic_private = form.save()
         notify_access(user=form.get_user(), topic_private=topic_private)
-        return redirect(request.POST.get('next', topic.get_absolute_url()))
+        return safe_redirect(
+            request, 'next', topic.get_absolute_url(), method='POST')
     return render(
         request=request,
         template_name='spirit/topic/private/join.html',
diff --git a/spirit/topic/views.py b/spirit/topic/views.py
index cfba1d83e..a2a66fccd 100644
--- a/spirit/topic/views.py
+++ b/spirit/topic/views.py
@@ -6,6 +6,7 @@
 
 from djconfig import config
 
+from spirit.core.utils.http import safe_redirect
 from spirit.core.utils.views import is_post, post_data
 from spirit.core.utils.paginator import paginate, yt_paginate
 from spirit.core.utils.ratelimit.decorators import ratelimit
@@ -38,9 +39,9 @@ def publish(request, category_id=None):
             all([form.is_valid(), cform.is_valid()]) and
             not request.is_limited()):
         if not user.st.update_post_hash(form.get_topic_hash()):
-            return redirect(
-                request.POST.get('next', None) or
-                form.get_category().get_absolute_url())
+            default_url = lambda: form.get_category().get_absolute_url()
+            return safe_redirect(
+                request, 'next', default_url, method='POST')
         # wrap in transaction.atomic?
         topic = form.save()
         cform.topic = topic
@@ -66,7 +67,7 @@ def update(request, pk):
         if topic.category_id != category_id:
             Comment.create_moderation_action(
                 user=request.user, topic=topic, action=Comment.MOVED)
-        return redirect(request.POST.get('next', topic.get_absolute_url()))
+        return safe_redirect(request,'next', topic.get_absolute_url(), method='POST')
     return render(
         request=request,
         template_name='spirit/topic/update.html',
diff --git a/spirit/user/admin/views.py b/spirit/user/admin/views.py
index 9e5e4230d..a6cdb0c24 100644
--- a/spirit/user/admin/views.py
+++ b/spirit/user/admin/views.py
@@ -1,15 +1,16 @@
 # -*- coding: utf-8 -*-
 
-from django.shortcuts import render, redirect, get_object_or_404
+from django.shortcuts import render, get_object_or_404
 from django.contrib.auth import get_user_model
 from django.contrib import messages
 from django.utils.translation import gettext as _
 
 from djconfig import config
 
-from ...core.utils.views import is_post, post_data
-from ...core.utils.paginator import yt_paginate
-from ...core.utils.decorators import administrator_required
+from spirit.core.utils.http import safe_redirect
+from spirit.core.utils.views import is_post, post_data
+from spirit.core.utils.paginator import yt_paginate
+from spirit.core.utils.decorators import administrator_required
 from .forms import UserForm, UserProfileForm
 
 User = get_user_model()
@@ -24,7 +25,7 @@ def edit(request, user_id):
         uform.save()
         form.save()
         messages.info(request, _(""This profile has been updated!""))
-        return redirect(request.GET.get(""next"", request.get_full_path()))
+        return safe_redirect(request, ""next"", request.get_full_path())
     return render(
         request=request,
         template_name='spirit/user/admin/edit.html',
diff --git a/spirit/user/auth/tests/tests.py b/spirit/user/auth/tests/tests.py
index ba092b469..2c1103ad0 100644
--- a/spirit/user/auth/tests/tests.py
+++ b/spirit/user/auth/tests/tests.py
@@ -55,6 +55,11 @@ def test_login_redirect(self):
         response = self.client.get(reverse('spirit:user:auth:login') + '?next=/fakepath/')
         self.assertRedirects(response, '/fakepath/', status_code=302, target_status_code=404)
 
+    def test_login_open_redirect(self):
+        utils.login(self)
+        response = self.client.get(reverse('spirit:user:auth:login') + '?next=https%3A%2F%2Fevil.com')
+        self.assertRedirects(response, '/', status_code=302)
+
     @override_settings(ST_CASE_INSENSITIVE_EMAILS=True)
     def test_login_email_case_insensitive(self):
         """"""
diff --git a/spirit/user/auth/views.py b/spirit/user/auth/views.py
index 8a90554f8..514f219ac 100644
--- a/spirit/user/auth/views.py
+++ b/spirit/user/auth/views.py
@@ -9,6 +9,7 @@
 from django.urls import reverse_lazy
 
 from spirit.core.conf import settings
+from spirit.core.utils.http import safe_redirect
 from spirit.core.utils.views import is_post, post_data
 from spirit.core.utils.ratelimit.decorators import ratelimit
 from spirit.user.utils.email import send_activation_email
@@ -62,7 +63,8 @@ class _CustomLoginView(django_views.LoginView):
 def custom_login(request, **kwargs):
     # Currently, Django 1.5 login view does not redirect somewhere if the user is logged in
     if request.user.is_authenticated:
-        return redirect(request.GET.get('next', request.user.st.get_absolute_url()))
+        return safe_redirect(
+            request, 'next', request.user.st.get_absolute_url())
 
     if request.method == ""POST"" and request.is_limited():
         return redirect(request.get_full_path())
@@ -73,7 +75,7 @@ def custom_login(request, **kwargs):
 # TODO: @login_required ?
 def custom_logout(request, **kwargs):
     if not request.user.is_authenticated:
-        return redirect(request.GET.get('next', reverse(settings.LOGIN_URL)))
+        return safe_redirect(request, 'next', reverse(settings.LOGIN_URL))
 
     if request.method == 'POST':
         return _logout_view(request, **kwargs)
@@ -93,7 +95,7 @@ def custom_password_reset(request, **kwargs):
 # TODO: @guest_only
 def register(request, registration_form=RegistrationForm):
     if request.user.is_authenticated:
-        return redirect(request.GET.get('next', reverse('spirit:user:update')))
+        return safe_redirect(request, 'next', reverse('spirit:user:update'))
 
     form = registration_form(data=post_data(request))
     if (is_post(request) and
@@ -109,7 +111,7 @@ def register(request, registration_form=RegistrationForm):
         # TODO: email-less activation
         # if not settings.REGISTER_EMAIL_ACTIVATION_REQUIRED:
         # login(request, user)
-        # return redirect(request.GET.get('next', reverse('spirit:user:update')))
+        # return safe_redirect(request, 'next', reverse('spirit:user:update'))
 
         return redirect(reverse(settings.LOGIN_URL))
     return render(
@@ -135,7 +137,7 @@ def registration_activation(request, pk, token):
 # TODO: @guest_only
 def resend_activation_email(request):
     if request.user.is_authenticated:
-        return redirect(request.GET.get('next', reverse('spirit:user:update')))
+        return safe_redirect(request, 'next', reverse('spirit:user:update'))
 
     form = ResendActivationForm(data=post_data(request))
     if is_post(request):"
GHSA-8phj-f9w2-cjcc,"From f01266a1a479ef11d7d6c539e7dd89e9d5639738 Mon Sep 17 00:00:00 2001
From: mihran113 <vanyanmihran@gmail.com>
Date: Fri, 12 Nov 2021 18:03:22 +0400
Subject: [PATCH] Fix security issue when incorrect path is given to the
 endpoint that serves static files which can lead to a leak of non wanted
 files (e.g. /static-files/../../../../etc/passwd)

---
 aim/web/api/views.py | 10 +++++++++-
 1 file changed, 9 insertions(+), 1 deletion(-)

diff --git a/aim/web/api/views.py b/aim/web/api/views.py
index 30edbc3c03..04cad24fd7 100644
--- a/aim/web/api/views.py
+++ b/aim/web/api/views.py
@@ -1,7 +1,9 @@
 import os
+from pathlib import Path
 
 from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter
 from fastapi.responses import FileResponse
+from fastapi import HTTPException
 
 statics_router = APIRouter()
 
@@ -9,7 +11,13 @@
 @statics_router.get('/static-files/{path:path}/')
 async def serve_static_files(path):
     from aim import web
-    static_file_name = os.path.join(os.path.dirname(web.__file__), 'ui', 'build', path)
+    static_file_root = os.path.join(os.path.dirname(web.__file__), 'ui', 'build')
+    static_file_name = os.path.join(static_file_root, path)
+
+    # check if path is leading inside ui/build directory
+    if not Path(static_file_root) in Path(static_file_name).resolve().parents:
+        raise HTTPException(404)
+
     compressed_file_name = '{}.gz'.format(static_file_name)
     if os.path.exists(compressed_file_name):
         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})"
GHSA-w24h-v9qh-8gxj,"From 6723a26e59b0b5429a0c5873941e01a2e1bdbb81 Mon Sep 17 00:00:00 2001
From: Mariusz Felisiak <felisiak.mariusz@gmail.com>
Date: Fri, 1 Apr 2022 13:48:47 +0200
Subject: [PATCH] Fixed CVE-2022-28347 -- Protected QuerySet.explain(**options)
 against SQL injection on PostgreSQL.

---
 django/db/backends/postgresql/features.py   |  1 -
 django/db/backends/postgresql/operations.py | 31 ++++++++++++++-----
 django/db/models/sql/query.py               | 10 +++++++
 docs/releases/2.2.28.txt                    |  7 +++++
 docs/releases/3.2.13.txt                    |  7 +++++
 docs/releases/4.0.4.txt                     |  7 +++++
 tests/queries/test_explain.py               | 33 +++++++++++++++++++--
 7 files changed, 85 insertions(+), 11 deletions(-)

diff --git a/django/db/backends/postgresql/features.py b/django/db/backends/postgresql/features.py
index 5e6752b97a8d..8aae4caf3401 100644
--- a/django/db/backends/postgresql/features.py
+++ b/django/db/backends/postgresql/features.py
@@ -54,7 +54,6 @@ class DatabaseFeatures(BaseDatabaseFeatures):
     only_supports_unbounded_with_preceding_and_following = True
     supports_aggregate_filter_clause = True
     supported_explain_formats = {""JSON"", ""TEXT"", ""XML"", ""YAML""}
-    validates_explain_options = False  # A query will error on invalid options.
     supports_deferrable_unique_constraints = True
     has_json_operators = True
     json_key_contains_list_matching_requires_list = True
diff --git a/django/db/backends/postgresql/operations.py b/django/db/backends/postgresql/operations.py
index 946baea212d7..ab451ac63f28 100644
--- a/django/db/backends/postgresql/operations.py
+++ b/django/db/backends/postgresql/operations.py
@@ -9,6 +9,18 @@
 class DatabaseOperations(BaseDatabaseOperations):
     cast_char_field_without_max_length = ""varchar""
     explain_prefix = ""EXPLAIN""
+    explain_options = frozenset(
+        [
+            ""ANALYZE"",
+            ""BUFFERS"",
+            ""COSTS"",
+            ""SETTINGS"",
+            ""SUMMARY"",
+            ""TIMING"",
+            ""VERBOSE"",
+            ""WAL"",
+        ]
+    )
     cast_data_types = {
         ""AutoField"": ""integer"",
         ""BigAutoField"": ""bigint"",
@@ -298,17 +310,20 @@ def subtract_temporals(self, internal_type, lhs, rhs):
         return super().subtract_temporals(internal_type, lhs, rhs)
 
     def explain_query_prefix(self, format=None, **options):
-        prefix = super().explain_query_prefix(format)
         extra = {}
+        # Normalize options.
+        if options:
+            options = {
+                name.upper(): ""true"" if value else ""false""
+                for name, value in options.items()
+            }
+            for valid_option in self.explain_options:
+                value = options.pop(valid_option, None)
+                if value is not None:
+                    extra[valid_option.upper()] = value
+        prefix = super().explain_query_prefix(format, **options)
         if format:
             extra[""FORMAT""] = format
-        if options:
-            extra.update(
-                {
-                    name.upper(): ""true"" if value else ""false""
-                    for name, value in options.items()
-                }
-            )
         if extra:
             prefix += "" (%s)"" % "", "".join(""%s %s"" % i for i in extra.items())
         return prefix
diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py
index 894aa7db4a4e..a55eb84a173d 100644
--- a/django/db/models/sql/query.py
+++ b/django/db/models/sql/query.py
@@ -49,6 +49,10 @@
 # SQL comments are forbidden in column aliases.
 FORBIDDEN_ALIAS_PATTERN = _lazy_re_compile(r""['`\""\]\[;\s]|--|/\*|\*/"")
 
+# Inspired from
+# https://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-SYNTAX-IDENTIFIERS
+EXPLAIN_OPTIONS_PATTERN = _lazy_re_compile(r""[\w\-]+"")
+
 
 def get_field_names_from_opts(opts):
     if opts is None:
@@ -589,6 +593,12 @@ def has_results(self, using):
 
     def explain(self, using, format=None, **options):
         q = self.clone()
+        for option_name in options:
+            if (
+                not EXPLAIN_OPTIONS_PATTERN.fullmatch(option_name)
+                or ""--"" in option_name
+            ):
+                raise ValueError(f""Invalid option name: {option_name!r}."")
         q.explain_info = ExplainInfo(format, options)
         compiler = q.get_compiler(using=using)
         return ""\n"".join(compiler.explain_query())
diff --git a/docs/releases/2.2.28.txt b/docs/releases/2.2.28.txt
index a894bddb3c55..43270fc5c080 100644
--- a/docs/releases/2.2.28.txt
+++ b/docs/releases/2.2.28.txt
@@ -13,3 +13,10 @@ CVE-2022-28346: Potential SQL injection in ``QuerySet.annotate()``, ``aggregate(
 :meth:`~.QuerySet.extra` methods were subject to SQL injection in column
 aliases, using a suitably crafted dictionary, with dictionary expansion, as the
 ``**kwargs`` passed to these methods.
+
+CVE-2022-28347: Potential SQL injection via ``QuerySet.explain(**options)`` on PostgreSQL
+=========================================================================================
+
+:meth:`.QuerySet.explain` method was subject to SQL injection in option names,
+using a suitably crafted dictionary, with dictionary expansion, as the
+``**options`` argument.
diff --git a/docs/releases/3.2.13.txt b/docs/releases/3.2.13.txt
index ee20aa2ca1a5..b7afbb8ed77c 100644
--- a/docs/releases/3.2.13.txt
+++ b/docs/releases/3.2.13.txt
@@ -15,6 +15,13 @@ CVE-2022-28346: Potential SQL injection in ``QuerySet.annotate()``, ``aggregate(
 aliases, using a suitably crafted dictionary, with dictionary expansion, as the
 ``**kwargs`` passed to these methods.
 
+CVE-2022-28347: Potential SQL injection via ``QuerySet.explain(**options)`` on PostgreSQL
+=========================================================================================
+
+:meth:`.QuerySet.explain` method was subject to SQL injection in option names,
+using a suitably crafted dictionary, with dictionary expansion, as the
+``**options`` argument.
+
 Bugfixes
 ========
 
diff --git a/docs/releases/4.0.4.txt b/docs/releases/4.0.4.txt
index 6c22788bd1cd..702cebbbe96d 100644
--- a/docs/releases/4.0.4.txt
+++ b/docs/releases/4.0.4.txt
@@ -15,6 +15,13 @@ CVE-2022-28346: Potential SQL injection in ``QuerySet.annotate()``, ``aggregate(
 aliases, using a suitably crafted dictionary, with dictionary expansion, as the
 ``**kwargs`` passed to these methods.
 
+CVE-2022-28347: Potential SQL injection via ``QuerySet.explain(**options)`` on PostgreSQL
+=========================================================================================
+
+:meth:`.QuerySet.explain` method was subject to SQL injection in option names,
+using a suitably crafted dictionary, with dictionary expansion, as the
+``**options`` argument.
+
 Bugfixes
 ========
 
diff --git a/tests/queries/test_explain.py b/tests/queries/test_explain.py
index ab845f992ad8..9eb4347323bb 100644
--- a/tests/queries/test_explain.py
+++ b/tests/queries/test_explain.py
@@ -59,8 +59,8 @@ def test_basic(self):
 
     @skipUnlessDBFeature(""validates_explain_options"")
     def test_unknown_options(self):
-        with self.assertRaisesMessage(ValueError, ""Unknown options: test, test2""):
-            Tag.objects.explain(test=1, test2=1)
+        with self.assertRaisesMessage(ValueError, ""Unknown options: TEST, TEST2""):
+            Tag.objects.explain(**{""TEST"": 1, ""TEST2"": 1})
 
     def test_unknown_format(self):
         msg = ""DOES NOT EXIST is not a recognized format.""
@@ -94,6 +94,35 @@ def test_postgres_options(self):
                     option = ""{} {}"".format(name.upper(), ""true"" if value else ""false"")
                     self.assertIn(option, captured_queries[0][""sql""])
 
+    def test_option_sql_injection(self):
+        qs = Tag.objects.filter(name=""test"")
+        options = {""SUMMARY true) SELECT 1; --"": True}
+        msg = ""Invalid option name: 'SUMMARY true) SELECT 1; --'""
+        with self.assertRaisesMessage(ValueError, msg):
+            qs.explain(**options)
+
+    def test_invalid_option_names(self):
+        qs = Tag.objects.filter(name=""test"")
+        tests = [
+            'opt""ion',
+            ""o'ption"",
+            ""op`tion"",
+            ""opti on"",
+            ""option--"",
+            ""optio\tn"",
+            ""o\nption"",
+            ""option;"",
+            "" "",
+            # [] are used by MSSQL.
+            ""option["",
+            ""option]"",
+        ]
+        for invalid_option in tests:
+            with self.subTest(invalid_option):
+                msg = f""Invalid option name: {invalid_option!r}""
+                with self.assertRaisesMessage(ValueError, msg):
+                    qs.explain(**{invalid_option: True})
+
     @unittest.skipUnless(connection.vendor == ""mysql"", ""MySQL specific"")
     def test_mysql_text_to_traditional(self):
         # Ensure these cached properties are initialized to prevent queries for"
GHSA-f865-m6cq-j9vx,"From c811b37c65a4372a7ce613111d2a508c204f9833 Mon Sep 17 00:00:00 2001
From: Vinzent Steinberg <Vinzent.Steinberg@gmail.com>
Date: Wed, 10 Feb 2021 16:45:04 +0100
Subject: [PATCH] Fix ReDOS vulnerability

Fixes #548, with the workaround suggested by @yetingli.
---
 mpmath/ctx_mp.py             |  4 ++--
 mpmath/tests/test_convert.py | 10 ++++++++++
 2 files changed, 12 insertions(+), 2 deletions(-)

diff --git a/mpmath/ctx_mp.py b/mpmath/ctx_mp.py
index 39fc9411f..93594dd44 100644
--- a/mpmath/ctx_mp.py
+++ b/mpmath/ctx_mp.py
@@ -42,8 +42,8 @@
 
 new = object.__new__
 
-get_complex = re.compile(r'^\(?(?P<re>[\+\-]?\d*\.?\d*(e[\+\-]?\d+)?)??'
-                         r'(?P<im>[\+\-]?\d*\.?\d*(e[\+\-]?\d+)?j)?\)?$')
+get_complex = re.compile(r'^\(?(?P<re>[\+\-]?\d*(\.\d*)?(e[\+\-]?\d+)?)??'
+                         r'(?P<im>[\+\-]?\d*(\.\d*)?(e[\+\-]?\d+)?j)?\)?$')
 
 if BACKEND == 'sage':
     from sage.libs.mpmath.ext_main import Context as BaseMPContext
diff --git a/mpmath/tests/test_convert.py b/mpmath/tests/test_convert.py
index 3e2f55590..cf1a91dac 100644
--- a/mpmath/tests/test_convert.py
+++ b/mpmath/tests/test_convert.py
@@ -194,6 +194,16 @@ def test_mpmathify():
     assert mpmathify('(1.2e-10 - 3.4e5j)') == mpc('1.2e-10', '-3.4e5')
     assert mpmathify('1j') == mpc(1j)
 
+def test_issue548():
+    try:
+        # This expression is invalid, but may trigger the ReDOS vulnerability
+        # in the regular expression.
+        mpmathify('(' + '1' * 5000 + '!j')
+    except:
+        return
+    # The expression is invalid and should raise an exception.
+    assert False
+
 def test_compatibility():
     try:
         import numpy as np"
GHSA-98vv-pw6r-q6q4,"From 9e08eb8f78fdfd2f476e1b20b7cf38683754866b Mon Sep 17 00:00:00 2001
From: Hugo van Kemenade <hugovk@users.noreply.github.com>
Date: Mon, 23 Aug 2021 19:10:49 +0300
Subject: [PATCH] Raise ValueError if color specifier is too long

---
 Tests/test_imagecolor.py | 9 +++++++++
 src/PIL/ImageColor.py    | 2 ++
 2 files changed, 11 insertions(+)

diff --git a/Tests/test_imagecolor.py b/Tests/test_imagecolor.py
index b5d69379655..dbe8b9e957b 100644
--- a/Tests/test_imagecolor.py
+++ b/Tests/test_imagecolor.py
@@ -191,3 +191,12 @@ def test_rounding_errors():
     assert (255, 255) == ImageColor.getcolor(""white"", ""LA"")
     assert (163, 33) == ImageColor.getcolor(""rgba(0, 255, 115, 33)"", ""LA"")
     Image.new(""LA"", (1, 1), ""white"")
+
+
+def test_color_too_long():
+    # Arrange
+    color_too_long = ""hsl("" + ""1"" * 100 + "")""
+
+    # Act / Assert
+    with pytest.raises(ValueError):
+        ImageColor.getrgb(color_too_long)
diff --git a/src/PIL/ImageColor.py b/src/PIL/ImageColor.py
index 51df4404039..25f92f2c732 100644
--- a/src/PIL/ImageColor.py
+++ b/src/PIL/ImageColor.py
@@ -32,6 +32,8 @@ def getrgb(color):
     :param color: A color string
     :return: ``(red, green, blue[, alpha])``
     """"""
+    if len(color) > 100:
+        raise ValueError(""color specifier is too long"")
     color = color.lower()
 
     rgb = colormap.get(color, None)"
CVE-2020-25459,"From 6feccf6d752184a6f9365d56a76fe627983e7139 Mon Sep 17 00:00:00 2001
From: mgqa34 <mgq3374541@163.com>
Date: Fri, 7 Aug 2020 15:56:38 +0800
Subject: [PATCH] remove sensitive info of guest sending to host

Signed-off-by: mgqa34 <mgq3374541@163.com>
---
 .../tree/hetero/hetero_decision_tree_guest.py     | 15 ++++++++++++++-
 1 file changed, 14 insertions(+), 1 deletion(-)

diff --git a/federatedml/tree/hetero/hetero_decision_tree_guest.py b/federatedml/tree/hetero/hetero_decision_tree_guest.py
index 1f23ddc532..028c74c005 100644
--- a/federatedml/tree/hetero/hetero_decision_tree_guest.py
+++ b/federatedml/tree/hetero/hetero_decision_tree_guest.py
@@ -529,10 +529,23 @@ def redispatch_node(self, dep=-1, max_depth_reach=False):
                                                                      unleaf_state_nodeid1) == 2 else unleaf_state_nodeid2)
         self.node_dispatch = self.node_dispatch.union(dispatch_guest_result)
 
+    def remove_sensitive_info(self):
+        """"""
+        host is not allowed to get weights/g/h
+        """"""
+        new_tree_ = copy.deepcopy(self.tree_)
+        for node in new_tree_:
+            node.weight = None
+            node.sum_grad = None
+            node.sum_hess = None
+
+        return new_tree_
+
     def sync_tree(self):
         LOGGER.info(""sync tree to host"")
 
-        self.transfer_inst.tree.remote(self.tree_,
+        tree_nodes = self.remove_sensitive_info()
+        self.transfer_inst.tree.remote(tree_nodes,
                                        role=consts.HOST,
                                        idx=-1)
         """""""
PYSEC-2016-2,"From f68e5a99164867ab0e071a936470958ed867479d Mon Sep 17 00:00:00 2001
From: Tim Graham <timograham@gmail.com>
Date: Wed, 6 Jul 2016 15:41:06 -0400
Subject: [PATCH] [1.8.x] Fixed XSS in admin's add/change related popup.

This is a security fix.
---
 .../admin/js/admin/RelatedObjectLookups.js    |  2 +-
 django/views/debug.py                         |  4 +-
 docs/releases/1.8.14.txt                      | 15 +++++++-
 tests/admin_views/admin.py                    |  3 +-
 tests/admin_views/models.py                   |  4 ++
 tests/admin_views/tests.py                    | 38 +++++++++++++++++++
 6 files changed, 60 insertions(+), 6 deletions(-)

diff --git a/django/contrib/admin/static/admin/js/admin/RelatedObjectLookups.js b/django/contrib/admin/static/admin/js/admin/RelatedObjectLookups.js
index d358b208f462..17ff10ff2644 100644
--- a/django/contrib/admin/static/admin/js/admin/RelatedObjectLookups.js
+++ b/django/contrib/admin/static/admin/js/admin/RelatedObjectLookups.js
@@ -105,7 +105,7 @@ function dismissChangeRelatedObjectPopup(win, objId, newRepr, newId) {
     var selects = django.jQuery(selectsSelector);
     selects.find('option').each(function() {
         if (this.value == objId) {
-            this.innerHTML = newRepr;
+            this.textContent = newRepr;
             this.value = newId;
         }
     });
diff --git a/django/views/debug.py b/django/views/debug.py
index f352196d3d67..9984f3891d45 100644
--- a/django/views/debug.py
+++ b/django/views/debug.py
@@ -704,13 +704,13 @@ def default_urlconf(request):
       var s = link.getElementsByTagName('span')[0];
       var uarr = String.fromCharCode(0x25b6);
       var darr = String.fromCharCode(0x25bc);
-      s.innerHTML = s.innerHTML == uarr ? darr : uarr;
+      s.textContent = s.textContent == uarr ? darr : uarr;
       return false;
     }
     function switchPastebinFriendly(link) {
       s1 = ""Switch to copy-and-paste view"";
       s2 = ""Switch back to interactive view"";
-      link.innerHTML = link.innerHTML.trim() == s1 ? s2: s1;
+      link.textContent = link.textContent.trim() == s1 ? s2: s1;
       toggle('browserTraceback', 'pastebinTraceback');
       return false;
     }
diff --git a/docs/releases/1.8.14.txt b/docs/releases/1.8.14.txt
index 6311172abcf9..31a304f7c060 100644
--- a/docs/releases/1.8.14.txt
+++ b/docs/releases/1.8.14.txt
@@ -2,9 +2,20 @@
 Django 1.8.14 release notes
 ===========================
 
-*Under development*
+*July 18, 2016*
 
-Django 1.8.14 fixes several bugs in 1.8.13.
+Django 1.8.14 fixes a security issue and a bug in 1.8.13.
+
+XSS in admin's add/change related popup
+=======================================
+
+Unsafe usage of JavaScript's ``Element.innerHTML`` could result in XSS in the
+admin's add/change related popup. ``Element.textContent`` is now used to
+prevent execution of the data.
+
+The debug view also used ``innerHTML``. Although a security issue wasn't
+identified there, out of an abundance of caution it's also updated to use
+``textContent``.
 
 Bugfixes
 ========
diff --git a/tests/admin_views/admin.py b/tests/admin_views/admin.py
index 8a980f45d587..a5e33a13bb7c 100644
--- a/tests/admin_views/admin.py
+++ b/tests/admin_views/admin.py
@@ -88,7 +88,8 @@ class ChapterXtra1Admin(admin.ModelAdmin):
 
 class ArticleAdmin(admin.ModelAdmin):
     list_display = ('content', 'date', callable_year, 'model_year',
-                    'modeladmin_year', 'model_year_reversed')
+                    'modeladmin_year', 'model_year_reversed', 'section')
+    list_editable = ('section',)
     list_filter = ('date', 'section')
     view_on_site = False
     fieldsets = (
diff --git a/tests/admin_views/models.py b/tests/admin_views/models.py
index e5f6cc99f233..6fe69662ef87 100644
--- a/tests/admin_views/models.py
+++ b/tests/admin_views/models.py
@@ -16,6 +16,7 @@
 from django.utils.encoding import python_2_unicode_compatible
 
 
+@python_2_unicode_compatible
 class Section(models.Model):
     """"""
     A simple section that links to articles, to test linking to related items
@@ -23,6 +24,9 @@ class Section(models.Model):
     """"""
     name = models.CharField(max_length=100)
 
+    def __str__(self):
+        return self.name
+
     @property
     def name_property(self):
         """"""
diff --git a/tests/admin_views/tests.py b/tests/admin_views/tests.py
index 5b60368042c3..11b23d03ba61 100644
--- a/tests/admin_views/tests.py
+++ b/tests/admin_views/tests.py
@@ -4056,6 +4056,44 @@ def test_cancel_delete_related_confirmation(self):
         self.assertEqual(Pizza.objects.count(), 1)
         self.assertEqual(Topping.objects.count(), 2)
 
+    def test_list_editable_popups(self):
+        """"""
+        list_editable foreign keys have add/change popups.
+        """"""
+        from selenium.webdriver.support.ui import Select
+        s1 = Section.objects.create(name='Test section')
+        Article.objects.create(
+            title='foo',
+            content='<p>Middle content</p>',
+            date=datetime.datetime(2008, 3, 18, 11, 54, 58),
+            section=s1,
+        )
+        self.admin_login(username='super', password='secret', login_url=reverse('admin:index'))
+        self.selenium.get(self.live_server_url + reverse('admin:admin_views_article_changelist'))
+        # Change popup
+        self.selenium.find_element_by_id('change_id_form-0-section').click()
+        self.wait_for_popup()
+        self.selenium.switch_to.window(self.selenium.window_handles[-1])
+        self.wait_for_text('#content h1', 'Change section')
+        name_input = self.selenium.find_element_by_id('id_name')
+        name_input.clear()
+        name_input.send_keys('<i>edited section</i>')
+        self.selenium.find_element_by_xpath('//input[@value=""Save""]').click()
+        self.selenium.switch_to.window(self.selenium.window_handles[0])
+        select = Select(self.selenium.find_element_by_id('id_form-0-section'))
+        self.assertEqual(select.first_selected_option.text, '<i>edited section</i>')
+
+        # Add popup
+        self.selenium.find_element_by_id('add_id_form-0-section').click()
+        self.wait_for_popup()
+        self.selenium.switch_to.window(self.selenium.window_handles[-1])
+        self.wait_for_text('#content h1', 'Add section')
+        self.selenium.find_element_by_id('id_name').send_keys('new section')
+        self.selenium.find_element_by_xpath('//input[@value=""Save""]').click()
+        self.selenium.switch_to.window(self.selenium.window_handles[0])
+        select = Select(self.selenium.find_element_by_id('id_form-0-section'))
+        self.assertEqual(select.first_selected_option.text, 'new section')
+
     def test_list_editable_raw_id_fields(self):
         parent = ParentWithUUIDPK.objects.create(title='test')
         parent2 = ParentWithUUIDPK.objects.create(title='test2')"
CVE-2012-3540,"From 35eada8a27323c0f83c400177797927aba6bc99b Mon Sep 17 00:00:00 2001
From: Paul McMillan <paul.mcmillan@nebula.com>
Date: Wed, 22 Aug 2012 12:15:40 -0700
Subject: [PATCH] Fix open redirect in Horizon.

LP 1039077. Disallow login redirects to anywhere other than the same origin.

Change-Id: I36e8e4f30cf440ecc73534af38fcd8d2a111a603
---
 horizon/views/auth_forms.py | 9 ++++++++-
 1 file changed, 8 insertions(+), 1 deletion(-)

diff --git a/horizon/views/auth_forms.py b/horizon/views/auth_forms.py
index 2ebecfcdadc..abf08803329 100644
--- a/horizon/views/auth_forms.py
+++ b/horizon/views/auth_forms.py
@@ -28,6 +28,7 @@
 from django.conf import settings
 from django.contrib import messages
 from django.contrib.auth import REDIRECT_FIELD_NAME
+from django.utils.http import same_origin
 from django.utils.translation import ugettext as _
 from keystoneclient import exceptions as keystone_exceptions
 
@@ -94,7 +95,13 @@ def handle(self, request, data):
         request.session['region_endpoint'] = endpoint
         request.session['region_name'] = region_name
 
-        redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, """")
+        redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, None)
+        # Make sure the requested redirect matches the protocol,
+        # domain, and port of this request
+        if redirect_to and not same_origin(
+                request.build_absolute_uri(redirect_to),
+                request.build_absolute_uri()):
+            redirect_to = None
 
         if data.get('tenant', None):
             try:"
GHSA-r7rm-8j6h-r933,"From a79b65c47c7dc6fe623aadf09aa6192fc54548f3 Mon Sep 17 00:00:00 2001
From: Andrew Murray <radarhere@users.noreply.github.com>
Date: Wed, 1 Jan 2020 14:16:45 +1100
Subject: [PATCH] Catch SGI buffer overruns

---
 Tests/images/sgi_overrun_expandrow.bin  | Bin 0 -> 545 bytes
 Tests/images/sgi_overrun_expandrow2.bin | Bin 0 -> 545 bytes
 Tests/test_image.py                     |   2 ++
 src/libImaging/SgiRleDecode.c           |  23 +++++++++++++++++------
 4 files changed, 19 insertions(+), 6 deletions(-)
 create mode 100644 Tests/images/sgi_overrun_expandrow.bin
 create mode 100644 Tests/images/sgi_overrun_expandrow2.bin

diff --git a/Tests/images/sgi_overrun_expandrow.bin b/Tests/images/sgi_overrun_expandrow.bin
new file mode 100644
index 0000000000000000000000000000000000000000..316d618818e5071a99cb003c9874ae734213319f
GIT binary patch
literal 545
zcmZR)#mLCO%)khQ%nT6lA4-o>BO(NtBp4W&q=8rt=v`160At2v2F73}#yAE51B3%!

literal 0
HcmV?d00001

diff --git a/Tests/images/sgi_overrun_expandrow2.bin b/Tests/images/sgi_overrun_expandrow2.bin
new file mode 100644
index 0000000000000000000000000000000000000000..f70e03a3960596bf060531ba74a9084a148949cd
GIT binary patch
literal 545
zcmZR)#mL0K%)khQ%nT6lA4-o>BO(NtBp4W&q=8rt=v`160At2v2F73}#yAE51)>9A

literal 0
HcmV?d00001

diff --git a/Tests/test_image.py b/Tests/test_image.py
index 33657d56cf0..2982d16d70c 100644
--- a/Tests/test_image.py
+++ b/Tests/test_image.py
@@ -593,6 +593,8 @@ def test_overrun(self):
         for file in [
             ""fli_overrun.bin"",
             ""sgi_overrun.bin"",
+            ""sgi_overrun_expandrow.bin"",
+            ""sgi_overrun_expandrow2.bin"",
             ""pcx_overrun.bin"",
             ""pcx_overrun2.bin"",
         ]:
diff --git a/src/libImaging/SgiRleDecode.c b/src/libImaging/SgiRleDecode.c
index 8a81ba8e6c0..1ba56b8c7b7 100644
--- a/src/libImaging/SgiRleDecode.c
+++ b/src/libImaging/SgiRleDecode.c
@@ -25,7 +25,7 @@ static void read4B(UINT32* dest, UINT8* buf)
     *dest = (UINT32)((buf[0] << 24) | (buf[1] << 16) | (buf[2] << 8) | buf[3]);
 }
 
-static int expandrow(UINT8* dest, UINT8* src, int n, int z)
+static int expandrow(UINT8* dest, UINT8* src, int n, int z, int xsize)
 {
     UINT8 pixel, count;
 
@@ -37,6 +37,9 @@ static int expandrow(UINT8* dest, UINT8* src, int n, int z)
         count = pixel & RLE_MAX_RUN;
         if (!count)
             return count;
+        if (count > xsize) {
+            return -1;
+        }
         if (pixel & RLE_COPY_FLAG) {
             while(count--) {
                 *dest = *src++;
@@ -56,7 +59,7 @@ static int expandrow(UINT8* dest, UINT8* src, int n, int z)
     return 0;
 }
 
-static int expandrow2(UINT8* dest, const UINT8* src, int n, int z)
+static int expandrow2(UINT8* dest, const UINT8* src, int n, int z, int xsize)
 {
     UINT8 pixel, count;
 
@@ -70,6 +73,9 @@ static int expandrow2(UINT8* dest, const UINT8* src, int n, int z)
         count = pixel & RLE_MAX_RUN;
         if (!count)
             return count;
+        if (count > xsize) {
+            return -1;
+        }
         if (pixel & RLE_COPY_FLAG) {
             while(count--) {
                 memcpy(dest, src, 2);
@@ -96,6 +102,7 @@ ImagingSgiRleDecode(Imaging im, ImagingCodecState state,
     UINT8 *ptr;
     SGISTATE *c;
     int err = 0;
+    int status;
 
     /* Get all data from File descriptor */
     c = (SGISTATE*)state->context;
@@ -164,12 +171,16 @@ ImagingSgiRleDecode(Imaging im, ImagingCodecState state,
 
             /* row decompression */
             if (c->bpc ==1) {
-                if(expandrow(&state->buffer[c->channo], &ptr[c->rleoffset], c->rlelength, im->bands))
-                    goto sgi_finish_decode;
+                status = expandrow(&state->buffer[c->channo], &ptr[c->rleoffset], c->rlelength, im->bands, im->xsize);
             }
             else {
-                if(expandrow2(&state->buffer[c->channo * 2], &ptr[c->rleoffset], c->rlelength, im->bands))
-                    goto sgi_finish_decode;
+                status = expandrow2(&state->buffer[c->channo * 2], &ptr[c->rleoffset], c->rlelength, im->bands, im->xsize);
+            }
+            if (status == -1) {
+                state->errcode = IMAGING_CODEC_OVERRUN;
+                return -1;
+            } else if (status == 1) {
+                goto sgi_finish_decode;
             }
 
             state->count += c->rlelength;"
PYSEC-2014-10,"From 205e056f8f9b06ed7b925cf8aa0874bc4aaf8a7d Mon Sep 17 00:00:00 2001
From: wiredfool <eric-github@soroos.net>
Date: Wed, 6 Aug 2014 16:42:43 -0700
Subject: [PATCH] Icns DOS fix --  CVE-2014-3589

Found and reported by Andrew Drake of dropbox.com
---
 PIL/IcnsImagePlugin.py  |  2 ++
 Tests/check_icns_dos.py | 10 ++++++++++
 2 files changed, 12 insertions(+)
 create mode 100644 Tests/check_icns_dos.py

diff --git a/PIL/IcnsImagePlugin.py b/PIL/IcnsImagePlugin.py
index 6951c932545..ca7a1493125 100644
--- a/PIL/IcnsImagePlugin.py
+++ b/PIL/IcnsImagePlugin.py
@@ -179,6 +179,8 @@ def __init__(self, fobj):
         i = HEADERSIZE
         while i < filesize:
             sig, blocksize = nextheader(fobj)
+            if blocksize <= 0:
+                raise SyntaxError('invalid block header')
             i += HEADERSIZE
             blocksize -= HEADERSIZE
             dct[sig] = (i, blocksize)
diff --git a/Tests/check_icns_dos.py b/Tests/check_icns_dos.py
new file mode 100644
index 00000000000..ce6338a7114
--- /dev/null
+++ b/Tests/check_icns_dos.py
@@ -0,0 +1,10 @@
+# Tests potential DOS of IcnsImagePlugin with 0 length block.
+# Run from anywhere that PIL is importable. 
+
+from PIL import Image
+from io import BytesIO
+
+if bytes is str:
+    Image.open(BytesIO(bytes('icns\x00\x00\x00\x10hang\x00\x00\x00\x00')))
+else:
+    Image.open(BytesIO(bytes('icns\x00\x00\x00\x10hang\x00\x00\x00\x00', 'latin-1')))"
GHSA-mj63-64x7-57xf,"From 99bd29e3995c254e2d6f6c2e3454e4271665955a Mon Sep 17 00:00:00 2001
From: OmriI <omri.inbar@checkmarx.com>
Date: Sun, 25 Apr 2021 14:06:02 +0300
Subject: [PATCH] Fix Path Traversal vulnerabilities by checking path prefix
 against incoming filename

---
 impacket/smbserver.py | 3947 +++++++++++++++++++++--------------------
 1 file changed, 2011 insertions(+), 1936 deletions(-)

diff --git a/impacket/smbserver.py b/impacket/smbserver.py
index d51704d12..a10b79fec 100644
--- a/impacket/smbserver.py
+++ b/impacket/smbserver.py
@@ -46,7 +46,8 @@
 # For signing
 from impacket import smb, nmb, ntlm, uuid
 from impacket import smb3structs as smb2
-from impacket.spnego import SPNEGO_NegTokenInit, TypesMech, MechTypes, SPNEGO_NegTokenResp, ASN1_AID, ASN1_SUPPORTED_MECH
+from impacket.spnego import SPNEGO_NegTokenInit, TypesMech, MechTypes, SPNEGO_NegTokenResp, ASN1_AID, \
+    ASN1_SUPPORTED_MECH
 from impacket.nt_errors import STATUS_NO_MORE_FILES, STATUS_NETWORK_NAME_DELETED, STATUS_INVALID_PARAMETER, \
     STATUS_FILE_CLOSED, STATUS_MORE_PROCESSING_REQUIRED, STATUS_OBJECT_PATH_NOT_FOUND, STATUS_DIRECTORY_NOT_EMPTY, \
     STATUS_FILE_IS_A_DIRECTORY, STATUS_NOT_IMPLEMENTED, STATUS_INVALID_HANDLE, STATUS_OBJECT_NAME_COLLISION, \
@@ -61,16 +62,16 @@
 STATUS_SMB_BAD_UID = 0x005B0002
 STATUS_SMB_BAD_TID = 0x00050002
 
+
 # Utility functions
-# and general functions. 
-# There are some common functions that can be accessed from more than one SMB 
+# and general functions.
+# There are some common functions that can be accessed from more than one SMB
 # command (or either TRANSACTION). That's why I'm putting them here
 # TODO: Return NT ERROR Codes
 
 def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage, ntlmChallenge, type1):
     # Let's calculate the NTLMv2 Response
 
-
     responseKeyNT = ntlm.NTOWFv2(identity, '', authenticateMessage['domain_name'].decode('utf-16le'), nthash)
     responseKeyLM = ntlm.LMOWFv2(identity, '', authenticateMessage['domain_name'].decode('utf-16le'), lmhash)
 
@@ -103,8 +104,8 @@ def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage
         responseFlags &= 0xffffffff ^ ntlm.NTLMSSP_NEGOTIATE_ALWAYS_SIGN
 
     keyExchangeKey = ntlm.KXKEY(ntlmChallenge['flags'], sessionBaseKey, lmChallengeResponse,
-                           ntlmChallenge['challenge'], '',
-                           lmhash, nthash, True)
+                                ntlmChallenge['challenge'], '',
+                                lmhash, nthash, True)
 
     # If we set up key exchange, let's fill the right variables
     if ntlmChallenge['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:
@@ -124,9 +125,9 @@ def computeNTLMv2(identity, lmhash, nthash, serverChallenge, authenticateMessage
 
 
 def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):
-# We don't want to add a possible failure here, since this is an
-# extra bonus. We try, if it fails, returns nothing
-# ToDo: Document the parameter's types (bytes / string) and check all the places where it's called
+    # We don't want to add a possible failure here, since this is an
+    # extra bonus. We try, if it fails, returns nothing
+    # ToDo: Document the parameter's types (bytes / string) and check all the places where it's called
     ret_value = ''
     if type(challenge) is not bytes:
         challenge = challenge.decode('latin-1')
@@ -137,13 +138,13 @@ def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):
             ret_value = {'hash_string': '%s::%s:%s:%s:%s' % (
                 username.decode('utf-16le'), domain.decode('utf-16le'), hexlify(challenge).decode('latin-1'),
                 hexlify(ntresponse).decode('latin-1')[:32],
-            hexlify(ntresponse).decode()[32:]), 'hash_version': 'ntlmv2'}
+                hexlify(ntresponse).decode()[32:]), 'hash_version': 'ntlmv2'}
         else:
             # NTLMv1
             ret_value = {'hash_string': '%s::%s:%s:%s:%s' % (
                 username.decode('utf-16le'), domain.decode('utf-16le'), hexlify(lmresponse).decode('latin-1'),
                 hexlify(ntresponse).decode('latin-1'),
-            hexlify(challenge).decode()), 'hash_version': 'ntlm'}
+                hexlify(challenge).decode()), 'hash_version': 'ntlm'}
     except:
         # Let's try w/o decoding Unicode
         try:
@@ -166,6 +167,7 @@ def outputToJohnFormat(challenge, username, domain, lmresponse, ntresponse):
 
     return ret_value
 
+
 def writeJohnOutputToFile(hash_string, hash_version, file_name):
     fn_data = os.path.splitext(file_name)
     if hash_version == ""ntlmv2"":
@@ -173,33 +175,37 @@ def writeJohnOutputToFile(hash_string, hash_version, file_name):
     else:
         output_filename = fn_data[0] + ""_ntlm"" + fn_data[1]
 
-    with open(output_filename,""a"") as f:
-            f.write(hash_string)
-            f.write('\n')		        
+    with open(output_filename, ""a"") as f:
+        f.write(hash_string)
+        f.write('\n')
 
 
-def decodeSMBString( flags, text ):
+def decodeSMBString(flags, text):
     if flags & smb.SMB.FLAGS2_UNICODE:
         return text.decode('utf-16le')
     else:
         return text
 
-def encodeSMBString( flags, text ):
+
+def encodeSMBString(flags, text):
     if flags & smb.SMB.FLAGS2_UNICODE:
         return (text).encode('utf-16le')
     else:
         return text.encode('ascii')
-    
+
+
 def getFileTime(t):
     t *= 10000000
     t += 116444736000000000
     return t
 
+
 def getUnixTime(t):
     t -= 116444736000000000
     t //= 10000000
     return t
 
+
 def getSMBDate(t):
     # TODO: Fix this :P
     d = datetime.date.fromtimestamp(t)
@@ -207,35 +213,39 @@ def getSMBDate(t):
     ret = (year << 8) + (d.month << 4) + d.day
     return ret
 
+
 def getSMBTime(t):
     # TODO: Fix this :P
     d = datetime.datetime.fromtimestamp(t)
-    return (d.hour << 8) + (d.minute << 4) + d.second 
+    return (d.hour << 8) + (d.minute << 4) + d.second
+
 
 def getShares(connId, smbServer):
     config = smbServer.getServerConfig()
     sections = config.sections()
     # Remove the global one
-    del(sections[sections.index('global')])
+    del (sections[sections.index('global')])
     shares = {}
     for i in sections:
         shares[i] = dict(config.items(i))
     return shares
 
+
 def searchShare(connId, share, smbServer):
     config = smbServer.getServerConfig()
     if config.has_section(share):
-       return dict(config.items(share))
+        return dict(config.items(share))
     else:
-       return None
+        return None
+
 
-def openFile(path,fileName, accessMode, fileAttributes, openMode):
-    fileName = os.path.normpath(fileName.replace('\\','/'))
+def openFile(path, fileName, accessMode, fileAttributes, openMode):
+    fileName = os.path.normpath(fileName.replace('\\', '/'))
     errorCode = 0
     if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
-       # strip leading '/'
-       fileName = fileName[1:]
-    pathName = os.path.join(path,fileName)
+        # strip leading '/'
+        fileName = fileName[1:]
+    pathName = os.path.join(path, fileName)
     mode = 0
     # Check the Open Mode
     if openMode & 0x10:
@@ -245,61 +255,61 @@ def openFile(path,fileName, accessMode, fileAttributes, openMode):
         # If file does not exist, return an error
         if os.path.exists(pathName) is not True:
             errorCode = STATUS_NO_SUCH_FILE
-            return 0,mode, pathName, errorCode
+            return 0, mode, pathName, errorCode
 
     if os.path.isdir(pathName) and (fileAttributes & smb.ATTR_DIRECTORY) == 0:
         # Request to open a normal file and this is actually a directory
-            errorCode = STATUS_FILE_IS_A_DIRECTORY
-            return 0, mode, pathName, errorCode
+        errorCode = STATUS_FILE_IS_A_DIRECTORY
+        return 0, mode, pathName, errorCode
     # Check the Access Mode
     if accessMode & 0x7 == 1:
-       mode |= os.O_WRONLY
+        mode |= os.O_WRONLY
     elif accessMode & 0x7 == 2:
-       mode |= os.O_RDWR
+        mode |= os.O_RDWR
     else:
-       mode = os.O_RDONLY
+        mode = os.O_RDONLY
 
     try:
         if sys.platform == 'win32':
             mode |= os.O_BINARY
         fid = os.open(pathName, mode)
     except Exception as e:
-        LOG.error(""openFile: %s,%s"" % (pathName, mode) ,e)
+        LOG.error(""openFile: %s,%s"" % (pathName, mode), e)
         fid = 0
         errorCode = STATUS_ACCESS_DENIED
 
     return fid, mode, pathName, errorCode
 
-def queryFsInformation(path, filename, level=0, pktFlags = smb.SMB.FLAGS2_UNICODE):
 
+def queryFsInformation(path, filename, level=0, pktFlags=smb.SMB.FLAGS2_UNICODE):
     if pktFlags & smb.SMB.FLAGS2_UNICODE:
-         encoding = 'utf-16le'
+        encoding = 'utf-16le'
     else:
-         encoding = 'ascii'
+        encoding = 'ascii'
 
-    fileName = os.path.normpath(filename.replace('\\','/'))
+    fileName = os.path.normpath(filename.replace('\\', '/'))
     if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
-       # strip leading '/'
-       fileName = fileName[1:]
-    pathName = os.path.join(path,fileName)
+        # strip leading '/'
+        fileName = fileName[1:]
+    pathName = os.path.join(path, fileName)
     fileSize = os.path.getsize(pathName)
     (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)
     if level == smb.SMB_QUERY_FS_ATTRIBUTE_INFO or level == smb2.SMB2_FILESYSTEM_ATTRIBUTE_INFO:
         data = smb.SMBQueryFsAttributeInfo()
-        data['FileSystemAttributes']      = smb.FILE_CASE_SENSITIVE_SEARCH | smb.FILE_CASE_PRESERVED_NAMES
+        data['FileSystemAttributes'] = smb.FILE_CASE_SENSITIVE_SEARCH | smb.FILE_CASE_PRESERVED_NAMES
         data['MaxFilenNameLengthInBytes'] = 255
-        data['LengthOfFileSystemName']    = len('XTFS')*2
-        data['FileSystemName']            = 'XTFS'.encode('utf-16le')
+        data['LengthOfFileSystemName'] = len('XTFS') * 2
+        data['FileSystemName'] = 'XTFS'.encode('utf-16le')
         return data.getData()
     elif level == smb.SMB_INFO_VOLUME:
-        data = smb.SMBQueryFsInfoVolume( flags = pktFlags )
-        data['VolumeLabel']               = 'SHARE'.encode(encoding)
+        data = smb.SMBQueryFsInfoVolume(flags=pktFlags)
+        data['VolumeLabel'] = 'SHARE'.encode(encoding)
         return data.getData()
     elif level == smb.SMB_QUERY_FS_VOLUME_INFO or level == smb2.SMB2_FILESYSTEM_VOLUME_INFO:
         data = smb.SMBQueryFsVolumeInfo()
-        data['VolumeLabel']               = ''
-        data['VolumeCreationTime']        = getFileTime(ctime)
-        return data.getData() 
+        data['VolumeLabel'] = ''
+        data['VolumeCreationTime'] = getFileTime(ctime)
+        return data.getData()
     elif level == smb.SMB_QUERY_FS_SIZE_INFO:
         data = smb.SMBQueryFsSizeInfo()
         return data.getData()
@@ -319,225 +329,241 @@ def queryFsInformation(path, filename, level=0, pktFlags = smb.SMB.FLAGS2_UNICOD
         fileAttributes = attribs
         return fileSize, lastWriteTime, fileAttributes
 
-def findFirst2(path, fileName, level, searchAttributes, pktFlags = smb.SMB.FLAGS2_UNICODE, isSMB2 = False):
-     # TODO: Depending on the level, this could be done much simpler
-     
-     #print ""FindFirs2 path:%s, filename:%s"" % (path, fileName)
-     fileName = os.path.normpath(fileName.replace('\\','/'))
-     # Let's choose the right encoding depending on the request
-     if pktFlags & smb.SMB.FLAGS2_UNICODE:
-         encoding = 'utf-16le'
-     else:
-         encoding = 'ascii'
-
-     if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
+
+def findFirst2(path, fileName, level, searchAttributes, pktFlags=smb.SMB.FLAGS2_UNICODE, isSMB2=False):
+    # TODO: Depending on the level, this could be done much simpler
+
+    # print ""FindFirs2 path:%s, filename:%s"" % (path, fileName)
+    fileName = os.path.normpath(fileName.replace('\\', '/'))
+    # Let's choose the right encoding depending on the request
+    if pktFlags & smb.SMB.FLAGS2_UNICODE:
+        encoding = 'utf-16le'
+    else:
+        encoding = 'ascii'
+
+    if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
         # strip leading '/'
         fileName = fileName[1:]
 
-     pathName = os.path.join(path,fileName)
-     files = []
-
-     if pathName.find('*') == -1 and pathName.find('?') == -1:
-         # No search patterns
-         pattern = ''
-     else:
-         pattern = os.path.basename(pathName)
-         dirName = os.path.dirname(pathName)
-
-     # Always add . and .. Not that important for Windows, but Samba whines if 
-     # not present (for * search only)
-     if pattern == '*':
-         files.append(os.path.join(dirName,'.'))
-         files.append(os.path.join(dirName,'..'))
-
-     if pattern != '':
-         for file in os.listdir(dirName):
-             if fnmatch.fnmatch(file.lower(),pattern.lower()):
+    if not isInFileJail(path, fileName):
+        LOG.error(""Path not in current working directory"")
+        return [], 0, STATUS_NOT_SUPPORTED
+
+    pathName = os.path.join(path, fileName)
+    files = []
+
+    if pathName.find('*') == -1 and pathName.find('?') == -1:
+        # No search patterns
+        pattern = ''
+    else:
+        pattern = os.path.basename(pathName)
+        dirName = os.path.dirname(pathName)
+
+    # Always add . and .. Not that important for Windows, but Samba whines if
+    # not present (for * search only)
+    if pattern == '*':
+        files.append(os.path.join(dirName, '.'))
+        files.append(os.path.join(dirName, '..'))
+
+    if pattern != '':
+        for file in os.listdir(dirName):
+            if fnmatch.fnmatch(file.lower(), pattern.lower()):
                 entry = os.path.join(dirName, file)
                 if os.path.isdir(entry):
                     if searchAttributes & smb.ATTR_DIRECTORY:
                         files.append(entry)
                 else:
                     files.append(entry)
-     else:
-         if os.path.exists(pathName):
-             files.append(pathName)
+    else:
+        if os.path.exists(pathName):
+            files.append(pathName)
 
-     searchResult = []
-     searchCount = len(files)
-     errorCode = STATUS_SUCCESS
+    searchResult = []
+    searchCount = len(files)
+    errorCode = STATUS_SUCCESS
 
-     for i in files:
+    for i in files:
         if level == smb.SMB_FIND_FILE_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_BOTH_DIRECTORY_INFO:
-            item = smb.SMBFindFileBothDirectoryInfo( flags = pktFlags )
+            item = smb.SMBFindFileBothDirectoryInfo(flags=pktFlags)
         elif level == smb.SMB_FIND_FILE_DIRECTORY_INFO or level == smb2.SMB2_FILE_DIRECTORY_INFO:
-            item = smb.SMBFindFileDirectoryInfo( flags = pktFlags )
+            item = smb.SMBFindFileDirectoryInfo(flags=pktFlags)
         elif level == smb.SMB_FIND_FILE_FULL_DIRECTORY_INFO or level == smb2.SMB2_FULL_DIRECTORY_INFO:
-            item = smb.SMBFindFileFullDirectoryInfo( flags = pktFlags )
+            item = smb.SMBFindFileFullDirectoryInfo(flags=pktFlags)
         elif level == smb.SMB_FIND_INFO_STANDARD:
-            item = smb.SMBFindInfoStandard( flags = pktFlags )
+            item = smb.SMBFindInfoStandard(flags=pktFlags)
         elif level == smb.SMB_FIND_FILE_ID_FULL_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_FULL_DIRECTORY_INFO:
-            item = smb.SMBFindFileIdFullDirectoryInfo( flags = pktFlags )
+            item = smb.SMBFindFileIdFullDirectoryInfo(flags=pktFlags)
         elif level == smb.SMB_FIND_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_BOTH_DIRECTORY_INFO:
-            item = smb.SMBFindFileIdBothDirectoryInfo( flags = pktFlags )
+            item = smb.SMBFindFileIdBothDirectoryInfo(flags=pktFlags)
         elif level == smb.SMB_FIND_FILE_NAMES_INFO or level == smb2.SMB2_FILE_NAMES_INFO:
-            item = smb.SMBFindFileNamesInfo( flags = pktFlags )
+            item = smb.SMBFindFileNamesInfo(flags=pktFlags)
         else:
             LOG.error(""Wrong level %d!"" % level)
-            return  searchResult, searchCount, STATUS_NOT_SUPPORTED
-            
+            return searchResult, searchCount, STATUS_NOT_SUPPORTED
+
         (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(i)
         if os.path.isdir(i):
-           item['ExtFileAttributes'] = smb.ATTR_DIRECTORY
+            item['ExtFileAttributes'] = smb.ATTR_DIRECTORY
         else:
-           item['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE
+            item['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE
 
         item['FileName'] = os.path.basename(i).encode(encoding)
 
         if level == smb.SMB_FIND_FILE_BOTH_DIRECTORY_INFO or level == smb.SMB_FIND_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_ID_BOTH_DIRECTORY_INFO or level == smb2.SMB2_FILE_BOTH_DIRECTORY_INFO:
-           item['EaSize']            = 0
-           item['EndOfFile']         = size
-           item['AllocationSize']    = size
-           item['CreationTime']      = getFileTime(ctime)
-           item['LastAccessTime']    = getFileTime(atime)
-           item['LastWriteTime']     = getFileTime(mtime)
-           item['LastChangeTime']    = getFileTime(mtime)
-           item['ShortName']         = '\x00'*24
-           item['FileName']          = os.path.basename(i).encode(encoding)
-           padLen = (8-(len(item) % 8)) % 8
-           item['NextEntryOffset']   = len(item) + padLen
+            item['EaSize'] = 0
+            item['EndOfFile'] = size
+            item['AllocationSize'] = size
+            item['CreationTime'] = getFileTime(ctime)
+            item['LastAccessTime'] = getFileTime(atime)
+            item['LastWriteTime'] = getFileTime(mtime)
+            item['LastChangeTime'] = getFileTime(mtime)
+            item['ShortName'] = '\x00' * 24
+            item['FileName'] = os.path.basename(i).encode(encoding)
+            padLen = (8 - (len(item) % 8)) % 8
+            item['NextEntryOffset'] = len(item) + padLen
         elif level == smb.SMB_FIND_FILE_DIRECTORY_INFO:
-           item['EndOfFile']         = size
-           item['AllocationSize']    = size
-           item['CreationTime']      = getFileTime(ctime)
-           item['LastAccessTime']    = getFileTime(atime)
-           item['LastWriteTime']     = getFileTime(mtime)
-           item['LastChangeTime']    = getFileTime(mtime)
-           item['FileName']          = os.path.basename(i).encode(encoding)
-           padLen = (8-(len(item) % 8)) % 8
-           item['NextEntryOffset']   = len(item) + padLen
+            item['EndOfFile'] = size
+            item['AllocationSize'] = size
+            item['CreationTime'] = getFileTime(ctime)
+            item['LastAccessTime'] = getFileTime(atime)
+            item['LastWriteTime'] = getFileTime(mtime)
+            item['LastChangeTime'] = getFileTime(mtime)
+            item['FileName'] = os.path.basename(i).encode(encoding)
+            padLen = (8 - (len(item) % 8)) % 8
+            item['NextEntryOffset'] = len(item) + padLen
         elif level == smb.SMB_FIND_FILE_FULL_DIRECTORY_INFO or level == smb.SMB_FIND_FILE_ID_FULL_DIRECTORY_INFO or level == smb2.SMB2_FULL_DIRECTORY_INFO:
-           item['EaSize']            = 0
-           item['EndOfFile']         = size
-           item['AllocationSize']    = size
-           item['CreationTime']      = getFileTime(ctime)
-           item['LastAccessTime']    = getFileTime(atime)
-           item['LastWriteTime']     = getFileTime(mtime)
-           item['LastChangeTime']    = getFileTime(mtime)
-           padLen = (8-(len(item) % 8)) % 8
-           item['NextEntryOffset']   = len(item) + padLen
+            item['EaSize'] = 0
+            item['EndOfFile'] = size
+            item['AllocationSize'] = size
+            item['CreationTime'] = getFileTime(ctime)
+            item['LastAccessTime'] = getFileTime(atime)
+            item['LastWriteTime'] = getFileTime(mtime)
+            item['LastChangeTime'] = getFileTime(mtime)
+            padLen = (8 - (len(item) % 8)) % 8
+            item['NextEntryOffset'] = len(item) + padLen
         elif level == smb.SMB_FIND_INFO_STANDARD:
-           item['EaSize']            = size
-           item['CreationDate']      = getSMBDate(ctime)
-           item['CreationTime']      = getSMBTime(ctime)
-           item['LastAccessDate']    = getSMBDate(atime)
-           item['LastAccessTime']    = getSMBTime(atime)
-           item['LastWriteDate']     = getSMBDate(mtime)
-           item['LastWriteTime']     = getSMBTime(mtime)
+            item['EaSize'] = size
+            item['CreationDate'] = getSMBDate(ctime)
+            item['CreationTime'] = getSMBTime(ctime)
+            item['LastAccessDate'] = getSMBDate(atime)
+            item['LastAccessTime'] = getSMBTime(atime)
+            item['LastWriteDate'] = getSMBDate(mtime)
+            item['LastWriteTime'] = getSMBTime(mtime)
         searchResult.append(item)
 
-     # No more files
-     if (level >= smb.SMB_FIND_FILE_DIRECTORY_INFO or isSMB2 is True) and searchCount > 0:
-         searchResult[-1]['NextEntryOffset'] = 0
+    # No more files
+    if (level >= smb.SMB_FIND_FILE_DIRECTORY_INFO or isSMB2 is True) and searchCount > 0:
+        searchResult[-1]['NextEntryOffset'] = 0
+
+    return searchResult, searchCount, errorCode
 
-     return searchResult, searchCount, errorCode
 
 def queryFileInformation(path, filename, level):
-    #print ""queryFileInfo path: %s, filename: %s, level:0x%x"" % (path,filename,level)
-    return queryPathInformation(path,filename, level)
+    # print ""queryFileInfo path: %s, filename: %s, level:0x%x"" % (path,filename,level)
+    return queryPathInformation(path, filename, level)
+
 
 def queryPathInformation(path, filename, level):
     # TODO: Depending on the level, this could be done much simpler
-  #print(""queryPathInfo path: %s, filename: %s, level:0x%x"" % (path,filename,level))
-  try:
-    errorCode = 0
-    fileName = os.path.normpath(filename.replace('\\','/'))
-    if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\') and path != '':
-       # strip leading '/'
-       fileName = fileName[1:]
-    pathName = os.path.join(path,fileName)
-    if os.path.exists(pathName):
-        (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)
-        if level == smb.SMB_QUERY_FILE_BASIC_INFO:
-            infoRecord = smb.SMBQueryFileBasicInfo()
-            infoRecord['CreationTime']         = getFileTime(ctime)
-            infoRecord['LastAccessTime']       = getFileTime(atime)
-            infoRecord['LastWriteTime']        = getFileTime(mtime)
-            infoRecord['LastChangeTime']       = getFileTime(mtime)
-            if os.path.isdir(pathName):
-               infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY
-            else:
-               infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE
-        elif level == smb.SMB_QUERY_FILE_STANDARD_INFO:
-            infoRecord = smb.SMBQueryFileStandardInfo()
-            infoRecord['AllocationSize']       = size
-            infoRecord['EndOfFile']            = size
-            if os.path.isdir(pathName):
-               infoRecord['Directory']         = 1
-            else:
-               infoRecord['Directory']         = 0
-        elif level == smb.SMB_QUERY_FILE_ALL_INFO or level == smb2.SMB2_FILE_ALL_INFO:
-            infoRecord = smb.SMBQueryFileAllInfo()
-            infoRecord['CreationTime']         = getFileTime(ctime)
-            infoRecord['LastAccessTime']       = getFileTime(atime)
-            infoRecord['LastWriteTime']        = getFileTime(mtime)
-            infoRecord['LastChangeTime']       = getFileTime(mtime)
-            if os.path.isdir(pathName):
-               infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY
-            else:
-               infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE
-            infoRecord['AllocationSize']       = size
-            infoRecord['EndOfFile']            = size
-            if os.path.isdir(pathName):
-               infoRecord['Directory']         = 1
-            else:
-               infoRecord['Directory']         = 0
-            infoRecord['FileName']             = filename.encode('utf-16le')
-        elif level == smb2.SMB2_FILE_NETWORK_OPEN_INFO:
-            infoRecord = smb.SMBFileNetworkOpenInfo()
-            infoRecord['CreationTime']         = getFileTime(ctime)
-            infoRecord['LastAccessTime']       = getFileTime(atime)
-            infoRecord['LastWriteTime']        = getFileTime(mtime)
-            infoRecord['ChangeTime']           = getFileTime(mtime)
-            infoRecord['AllocationSize']       = size
-            infoRecord['EndOfFile']            = size
-            if os.path.isdir(pathName):
-               infoRecord['FileAttributes'] = smb.ATTR_DIRECTORY
+    # print(""queryPathInfo path: %s, filename: %s, level:0x%x"" % (path,filename,level))
+    try:
+        errorCode = 0
+        fileName = os.path.normpath(filename.replace('\\', '/'))
+        if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\') and path != '':
+            # strip leading '/'
+            fileName = fileName[1:]
+        pathName = os.path.join(path, fileName)
+        if os.path.exists(pathName):
+            (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)
+            if level == smb.SMB_QUERY_FILE_BASIC_INFO:
+                infoRecord = smb.SMBQueryFileBasicInfo()
+                infoRecord['CreationTime'] = getFileTime(ctime)
+                infoRecord['LastAccessTime'] = getFileTime(atime)
+                infoRecord['LastWriteTime'] = getFileTime(mtime)
+                infoRecord['LastChangeTime'] = getFileTime(mtime)
+                if os.path.isdir(pathName):
+                    infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY
+                else:
+                    infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE
+            elif level == smb.SMB_QUERY_FILE_STANDARD_INFO:
+                infoRecord = smb.SMBQueryFileStandardInfo()
+                infoRecord['AllocationSize'] = size
+                infoRecord['EndOfFile'] = size
+                if os.path.isdir(pathName):
+                    infoRecord['Directory'] = 1
+                else:
+                    infoRecord['Directory'] = 0
+            elif level == smb.SMB_QUERY_FILE_ALL_INFO or level == smb2.SMB2_FILE_ALL_INFO:
+                infoRecord = smb.SMBQueryFileAllInfo()
+                infoRecord['CreationTime'] = getFileTime(ctime)
+                infoRecord['LastAccessTime'] = getFileTime(atime)
+                infoRecord['LastWriteTime'] = getFileTime(mtime)
+                infoRecord['LastChangeTime'] = getFileTime(mtime)
+                if os.path.isdir(pathName):
+                    infoRecord['ExtFileAttributes'] = smb.ATTR_DIRECTORY
+                else:
+                    infoRecord['ExtFileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE
+                infoRecord['AllocationSize'] = size
+                infoRecord['EndOfFile'] = size
+                if os.path.isdir(pathName):
+                    infoRecord['Directory'] = 1
+                else:
+                    infoRecord['Directory'] = 0
+                infoRecord['FileName'] = filename.encode('utf-16le')
+            elif level == smb2.SMB2_FILE_NETWORK_OPEN_INFO:
+                infoRecord = smb.SMBFileNetworkOpenInfo()
+                infoRecord['CreationTime'] = getFileTime(ctime)
+                infoRecord['LastAccessTime'] = getFileTime(atime)
+                infoRecord['LastWriteTime'] = getFileTime(mtime)
+                infoRecord['ChangeTime'] = getFileTime(mtime)
+                infoRecord['AllocationSize'] = size
+                infoRecord['EndOfFile'] = size
+                if os.path.isdir(pathName):
+                    infoRecord['FileAttributes'] = smb.ATTR_DIRECTORY
+                else:
+                    infoRecord['FileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE
+            elif level == smb.SMB_QUERY_FILE_EA_INFO or level == smb2.SMB2_FILE_EA_INFO:
+                infoRecord = smb.SMBQueryFileEaInfo()
+            elif level == smb2.SMB2_FILE_STREAM_INFO:
+                infoRecord = smb.SMBFileStreamInformation()
             else:
-               infoRecord['FileAttributes'] = smb.ATTR_NORMAL | smb.ATTR_ARCHIVE
-        elif level == smb.SMB_QUERY_FILE_EA_INFO or level == smb2.SMB2_FILE_EA_INFO: 
-            infoRecord = smb.SMBQueryFileEaInfo()
-        elif level == smb2.SMB2_FILE_STREAM_INFO:
-            infoRecord = smb.SMBFileStreamInformation()
+                LOG.error('Unknown level for query path info! 0x%x' % level)
+                # UNSUPPORTED
+                return None, STATUS_NOT_SUPPORTED
+
+            return infoRecord, errorCode
         else:
-            LOG.error('Unknown level for query path info! 0x%x' % level)
-            # UNSUPPORTED
-            return None, STATUS_NOT_SUPPORTED
+            # NOT FOUND
+            return None, STATUS_OBJECT_NAME_NOT_FOUND
+    except Exception as e:
+        LOG.error('queryPathInfo: %s' % e)
+        raise
 
-        return infoRecord, errorCode
-    else:
-        # NOT FOUND
-        return None, STATUS_OBJECT_NAME_NOT_FOUND
-  except Exception as e:
-      LOG.error('queryPathInfo: %s' % e)
-      raise
 
 def queryDiskInformation(path):
-# TODO: Do something useful here :)
-# For now we just return fake values
-   totalUnits = 65535
-   freeUnits = 65535
-   return totalUnits, freeUnits
+    # TODO: Do something useful here :)
+    # For now we just return fake values
+    totalUnits = 65535
+    freeUnits = 65535
+    return totalUnits, freeUnits
+
+
+def isInFileJail(path, fileName):
+    pathName = os.path.join(path, fileName)
+    share_real_path = os.path.realpath(path)
+    return os.path.commonprefix((os.path.realpath(pathName), share_real_path)) == share_real_path
+
 
 # Here we implement the NT transaction handlers
 class NTTRANSCommands:
-    def default(self, connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
+    def default(self, connId, smbServer, recvPacket, parameters, data, maxDataCount=0):
         pass
 
+
 # Here we implement the NT transaction handlers
 class TRANSCommands:
     @staticmethod
-    def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
+    def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):
         # Minimal [MS-RAP] implementation, just to return the shares
         connData = smbServer.getConnectionData(connId)
 
@@ -545,20 +571,20 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
         respParameters = b''
         respData = b''
         errorCode = STATUS_SUCCESS
-        if struct.unpack('<H',parameters[:2])[0] == 0:
+        if struct.unpack('<H', parameters[:2])[0] == 0:
             # NetShareEnum Request
             netShareEnum = smb.SMBNetShareEnum(parameters)
             if netShareEnum['InfoLevel'] == 1:
                 shares = getShares(connId, smbServer)
                 respParameters = smb.SMBNetShareEnumResponse()
-                respParameters['EntriesReturned']  = len(shares)
+                respParameters['EntriesReturned'] = len(shares)
                 respParameters['EntriesAvailable'] = len(shares)
                 tailData = ''
                 for i in shares:
                     # NetShareInfo1 len == 20
                     entry = smb.NetShareInfo1()
-                    entry['NetworkName'] = i + '\x00'*(13-len(i))
-                    entry['Type']        = int(shares[i]['share type'])
+                    entry['NetworkName'] = i + '\x00' * (13 - len(i))
+                    entry['Type'] = int(shares[i]['share type'])
                     # (beto) If offset == 0 it crashes explorer.exe on windows 7
                     entry['RemarkOffsetLow'] = 20 * len(shares) + len(tailData)
                     respData += entry.getData()
@@ -570,28 +596,28 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
             else:
                 # We don't support other info levels
                 errorCode = STATUS_NOT_SUPPORTED
-        elif struct.unpack('<H',parameters[:2])[0] == 13:
+        elif struct.unpack('<H', parameters[:2])[0] == 13:
             # NetrServerGetInfo Request
             respParameters = smb.SMBNetServerGetInfoResponse()
             netServerInfo = smb.SMBNetServerInfo1()
             netServerInfo['ServerName'] = smbServer.getServerName()
             respData = netServerInfo.getData()
             respParameters['TotalBytesAvailable'] = len(respData)
-        elif struct.unpack('<H',parameters[:2])[0] == 1:
+        elif struct.unpack('<H', parameters[:2])[0] == 1:
             # NetrShareGetInfo Request
             request = smb.SMBNetShareGetInfo(parameters)
             respParameters = smb.SMBNetShareGetInfoResponse()
             shares = getShares(connId, smbServer)
             share = shares[request['ShareName'].upper()]
-            shareInfo = smb.NetShareInfo1() 
+            shareInfo = smb.NetShareInfo1()
             shareInfo['NetworkName'] = request['ShareName'].upper() + '\x00'
-            shareInfo['Type']        = int(share['share type'])
+            shareInfo['Type'] = int(share['share type'])
             respData = shareInfo.getData()
             if 'comment' in share:
                 shareInfo['RemarkOffsetLow'] = len(respData)
                 respData += share['comment'] + '\x00'
             respParameters['TotalBytesAvailable'] = len(respData)
-     
+
         else:
             # We don't know how to handle anything else
             errorCode = STATUS_NOT_SUPPORTED
@@ -601,15 +627,15 @@ def lanMan(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
         return respSetup, respParameters, respData, errorCode
 
     @staticmethod
-    def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
+    def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):
         connData = smbServer.getConnectionData(connId)
 
         respSetup = b''
         respParameters = b''
         respData = b''
         errorCode = STATUS_SUCCESS
-        SMBCommand  = smb.SMBCommand(recvPacket['Data'][0])
-        transParameters= smb.SMBTransaction_Parameters(SMBCommand['Parameters'])
+        SMBCommand = smb.SMBCommand(recvPacket['Data'][0])
+        transParameters = smb.SMBTransaction_Parameters(SMBCommand['Parameters'])
 
         # Extract the FID
         fid = struct.unpack('<H', transParameters['Setup'][2:])[0]
@@ -617,8 +643,8 @@ def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCo
         if fid in connData['OpenedFiles']:
             fileHandle = connData['OpenedFiles'][fid]['FileHandle']
             if fileHandle != PIPE_FILE_DESCRIPTOR:
-                os.write(fileHandle,data)
-                respData = os.read(fileHandle,data)
+                os.write(fileHandle, data)
+                respData = os.read(fileHandle, data)
             else:
                 sock = connData['OpenedFiles'][fid]['Socket']
                 sock.send(data)
@@ -630,26 +656,27 @@ def transactNamedPipe(connId, smbServer, recvPacket, parameters, data, maxDataCo
 
         return respSetup, respParameters, respData, errorCode
 
+
 # Here we implement the transaction2 handlers
 class TRANS2Commands:
     # All these commands return setup, parameters, data, errorCode
     @staticmethod
-    def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
+    def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):
         connData = smbServer.getConnectionData(connId)
 
         respSetup = b''
         respParameters = b''
         respData = b''
         errorCode = STATUS_SUCCESS
-        setPathInfoParameters = smb.SMBSetPathInformation_Parameters(flags = recvPacket['Flags2'], data = parameters)
+        setPathInfoParameters = smb.SMBSetPathInformation_Parameters(flags=recvPacket['Flags2'], data=parameters)
         if recvPacket['Tid'] in connData['ConnectedShares']:
-            path     = connData['ConnectedShares'][recvPacket['Tid']]['path']
+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']
             fileName = decodeSMBString(recvPacket['Flags2'], setPathInfoParameters['FileName'])
-            fileName = os.path.normpath(fileName.replace('\\','/'))
+            fileName = os.path.normpath(fileName.replace('\\', '/'))
             if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\') and path != '':
-               # strip leading '/'
-               fileName = fileName[1:]
-            pathName = os.path.join(path,fileName)
+                # strip leading '/'
+                fileName = fileName[1:]
+            pathName = os.path.join(path, fileName)
             if os.path.exists(pathName):
                 informationLevel = setPathInfoParameters['InformationLevel']
                 if informationLevel == smb.SMB_SET_FILE_BASIC_INFO:
@@ -666,11 +693,12 @@ def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataC
                     else:
                         mtime = getUnixTime(mtime)
                     if mtime != -1 or atime != -1:
-                        os.utime(pathName,(atime,mtime))
+                        os.utime(pathName, (atime, mtime))
                 else:
-                    smbServer.log('Unknown level for set path info! 0x%x' % setPathInfoParameters['InformationLevel'], logging.ERROR)
+                    smbServer.log('Unknown level for set path info! 0x%x' % setPathInfoParameters['InformationLevel'],
+                                  logging.ERROR)
                     # UNSUPPORTED
-                    errorCode =  STATUS_NOT_SUPPORTED
+                    errorCode = STATUS_NOT_SUPPORTED
             else:
                 errorCode = STATUS_OBJECT_NAME_NOT_FOUND
 
@@ -684,9 +712,8 @@ def setPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataC
 
         return respSetup, respParameters, respData, errorCode
 
-
     @staticmethod
-    def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
+    def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):
         connData = smbServer.getConnectionData(connId)
 
         respSetup = b''
@@ -702,9 +729,9 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC
                 if informationLevel == smb.SMB_SET_FILE_DISPOSITION_INFO:
                     infoRecord = smb.SMBSetFileDispositionInfo(parameters)
                     if infoRecord['DeletePending'] > 0:
-                       # Mark this file for removal after closed
-                       connData['OpenedFiles'][setFileInfoParameters['FID']]['DeleteOnClose'] = True
-                       respParameters = smb.SMBSetFileInformationResponse_Parameters()
+                        # Mark this file for removal after closed
+                        connData['OpenedFiles'][setFileInfoParameters['FID']]['DeleteOnClose'] = True
+                        respParameters = smb.SMBSetFileInformationResponse_Parameters()
                 elif informationLevel == smb.SMB_SET_FILE_BASIC_INFO:
                     infoRecord = smb.SMBSetFileBasicInfo(data)
                     # Creation time won't be set,  the other ones we play with.
@@ -718,17 +745,18 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC
                         mtime = -1
                     else:
                         mtime = getUnixTime(mtime)
-                    os.utime(fileName,(atime,mtime))
+                    os.utime(fileName, (atime, mtime))
                 elif informationLevel == smb.SMB_SET_FILE_END_OF_FILE_INFO:
                     fileHandle = connData['OpenedFiles'][setFileInfoParameters['FID']]['FileHandle']
                     infoRecord = smb.SMBSetFileEndOfFileInfo(data)
                     if infoRecord['EndOfFile'] > 0:
-                        os.lseek(fileHandle, infoRecord['EndOfFile']-1, 0)
+                        os.lseek(fileHandle, infoRecord['EndOfFile'] - 1, 0)
                         os.write(fileHandle, b'\x00')
                 else:
-                    smbServer.log('Unknown level for set file info! 0x%x' % setFileInfoParameters['InformationLevel'], logging.ERROR)
+                    smbServer.log('Unknown level for set file info! 0x%x' % setFileInfoParameters['InformationLevel'],
+                                  logging.ERROR)
                     # UNSUPPORTED
-                    errorCode =  STATUS_NOT_SUPPORTED
+                    errorCode = STATUS_NOT_SUPPORTED
             else:
                 errorCode = STATUS_NO_SUCH_FILE
 
@@ -742,7 +770,7 @@ def setFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataC
         return respSetup, respParameters, respData, errorCode
 
     @staticmethod
-    def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
+    def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):
         connData = smbServer.getConnectionData(connId)
 
         respSetup = b''
@@ -770,7 +798,7 @@ def queryFileInformation(connId, smbServer, recvPacket, parameters, data, maxDat
         return respSetup, respParameters, respData, errorCode
 
     @staticmethod
-    def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
+    def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):
         connData = smbServer.getConnectionData(connId)
 
         respSetup = b''
@@ -778,7 +806,7 @@ def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDat
         respData = b''
         errorCode = 0
 
-        queryPathInfoParameters = smb.SMBQueryPathInformation_Parameters(flags = recvPacket['Flags2'], data = parameters)
+        queryPathInfoParameters = smb.SMBQueryPathInformation_Parameters(flags=recvPacket['Flags2'], data=parameters)
 
         if recvPacket['Tid'] in connData['ConnectedShares']:
             path = connData['ConnectedShares'][recvPacket['Tid']]['path']
@@ -787,30 +815,30 @@ def queryPathInformation(connId, smbServer, recvPacket, parameters, data, maxDat
                                                                                    queryPathInfoParameters['FileName']),
                                                              queryPathInfoParameters['InformationLevel'])
             except Exception as e:
-               smbServer.log(""queryPathInformation: %s"" % e,logging.ERROR)
+                smbServer.log(""queryPathInformation: %s"" % e, logging.ERROR)
 
             if infoRecord is not None:
                 respParameters = smb.SMBQueryPathInformationResponse_Parameters()
                 respData = infoRecord
         else:
             errorCode = STATUS_SMB_BAD_TID
-           
+
         smbServer.setConnectionData(connId, connData)
 
         return respSetup, respParameters, respData, errorCode
 
     @staticmethod
-    def queryFsInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount = 0):
+    def queryFsInformation(connId, smbServer, recvPacket, parameters, data, maxDataCount=0):
         connData = smbServer.getConnectionData(connId)
         errorCode = 0
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
             data = queryFsInformation(connData['ConnectedShares'][recvPacket['Tid']]['path'], '',
-                                      struct.unpack('<H',parameters)[0], pktFlags = recvPacket['Flags2'])
+                                      struct.unpack('<H', parameters)[0], pktFlags=recvPacket['Flags2'])
 
         smbServer.setConnectionData(connId, connData)
 
-        return b'',b'', data, errorCode
+        return b'', b'', data, errorCode
 
     @staticmethod
     def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):
@@ -820,7 +848,7 @@ def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):
         respParameters = b''
         respData = b''
         errorCode = STATUS_SUCCESS
-        findNext2Parameters = smb.SMBFindNext2_Parameters(flags = recvPacket['Flags2'], data = parameters)
+        findNext2Parameters = smb.SMBFindNext2_Parameters(flags=recvPacket['Flags2'], data=parameters)
 
         sid = findNext2Parameters['SID']
         if recvPacket['Tid'] in connData['ConnectedShares']:
@@ -833,28 +861,28 @@ def findNext2(connId, smbServer, recvPacket, parameters, data, maxDataCount):
                 for i in enumerate(searchResult):
                     data = i[1].getData()
                     lenData = len(data)
-                    if (totalData+lenData) >= maxDataCount or (i[0]+1) >= findNext2Parameters['SearchCount']:
+                    if (totalData + lenData) >= maxDataCount or (i[0] + 1) >= findNext2Parameters['SearchCount']:
                         # We gotta stop here and continue on a find_next2
                         endOfSearch = 0
                         connData['SIDs'][sid] = searchResult[i[0]:]
                         respParameters['LastNameOffset'] = totalData
                         break
                     else:
-                        searchCount +=1
+                        searchCount += 1
                         respData += data
                         totalData += lenData
-                    
+
                 # Have we reached the end of the search or still stuff to send?
                 if endOfSearch > 0:
                     # Let's remove the SID from our ConnData
-                    del(connData['SIDs'][sid])
+                    del (connData['SIDs'][sid])
 
                 respParameters['EndOfSearch'] = endOfSearch
                 respParameters['SearchCount'] = searchCount
-            else: 
+            else:
                 errorCode = STATUS_INVALID_HANDLE
         else:
-            errorCode = STATUS_SMB_BAD_TID   
+            errorCode = STATUS_SMB_BAD_TID
 
         smbServer.setConnectionData(connId, connData)
 
@@ -867,55 +895,58 @@ def findFirst2(connId, smbServer, recvPacket, parameters, data, maxDataCount):
         respSetup = b''
         respParameters = b''
         respData = b''
-        findFirst2Parameters = smb.SMBFindFirst2_Parameters( recvPacket['Flags2'], data = parameters)
+        findFirst2Parameters = smb.SMBFindFirst2_Parameters(recvPacket['Flags2'], data=parameters)
 
         if recvPacket['Tid'] in connData['ConnectedShares']:
             path = connData['ConnectedShares'][recvPacket['Tid']]['path']
 
-            searchResult, searchCount, errorCode = findFirst2(path, 
-                          decodeSMBString( recvPacket['Flags2'], findFirst2Parameters['FileName'] ), 
-                          findFirst2Parameters['InformationLevel'], 
-                          findFirst2Parameters['SearchAttributes'] , pktFlags = recvPacket['Flags2'])
+            searchResult, searchCount, errorCode = findFirst2(path,
+                                                              decodeSMBString(recvPacket['Flags2'],
+                                                                              findFirst2Parameters['FileName']),
+                                                              findFirst2Parameters['InformationLevel'],
+                                                              findFirst2Parameters['SearchAttributes'],
+                                                              pktFlags=recvPacket['Flags2'])
 
             respParameters = smb.SMBFindFirst2Response_Parameters()
             endOfSearch = 1
-            sid = 0x80 # default SID
+            sid = 0x80  # default SID
             searchCount = 0
             totalData = 0
             for i in enumerate(searchResult):
-                #i[1].dump()
+                # i[1].dump()
                 data = i[1].getData()
                 lenData = len(data)
-                if (totalData+lenData) >= maxDataCount or (i[0]+1) > findFirst2Parameters['SearchCount']:
+                if (totalData + lenData) >= maxDataCount or (i[0] + 1) > findFirst2Parameters['SearchCount']:
                     # We gotta stop here and continue on a find_next2
                     endOfSearch = 0
                     # Simple way to generate a fid
                     if len(connData['SIDs']) == 0:
-                       sid = 1
+                        sid = 1
                     else:
-                       sid = list(connData['SIDs'].keys())[-1] + 1
+                        sid = list(connData['SIDs'].keys())[-1] + 1
                     # Store the remaining search results in the ConnData SID
                     connData['SIDs'][sid] = searchResult[i[0]:]
                     respParameters['LastNameOffset'] = totalData
                     break
                 else:
-                    searchCount +=1
+                    searchCount += 1
                     respData += data
 
-                    padLen = (8-(lenData % 8)) %8
-                    respData += b'\xaa'*padLen
+                    padLen = (8 - (lenData % 8)) % 8
+                    respData += b'\xaa' * padLen
                     totalData += lenData + padLen
 
             respParameters['SID'] = sid
             respParameters['EndOfSearch'] = endOfSearch
             respParameters['SearchCount'] = searchCount
         else:
-            errorCode = STATUS_SMB_BAD_TID   
+            errorCode = STATUS_SMB_BAD_TID
 
         smbServer.setConnectionData(connId, connData)
 
         return respSetup, respParameters, respData, errorCode
 
+
 # Here we implement the commands handlers
 class SMBCommands:
 
@@ -925,16 +956,16 @@ def smbTransaction(connId, smbServer, SMBCommand, recvPacket, transCommands):
 
         respSMBCommand = smb.SMBCommand(recvPacket['Command'])
 
-        transParameters= smb.SMBTransaction_Parameters(SMBCommand['Parameters'])
+        transParameters = smb.SMBTransaction_Parameters(SMBCommand['Parameters'])
 
         # Do the stuff
         if transParameters['ParameterCount'] != transParameters['TotalParameterCount']:
-            # TODO: Handle partial parameters 
+            # TODO: Handle partial parameters
             raise Exception(""Unsupported partial parameters in TRANSACT2!"")
         else:
-            transData = smb.SMBTransaction_SData(flags = recvPacket['Flags2'])
-            # Standard says servers shouldn't trust Parameters and Data comes 
-            # in order, so we have to parse the offsets, ugly   
+            transData = smb.SMBTransaction_SData(flags=recvPacket['Flags2'])
+            # Standard says servers shouldn't trust Parameters and Data comes
+            # in order, so we have to parse the offsets, ugly
 
             paramCount = transParameters['ParameterCount']
             transData['Trans_ParametersLength'] = paramCount
@@ -943,142 +974,141 @@ def smbTransaction(connId, smbServer, SMBCommand, recvPacket, transCommands):
             transData.fromString(SMBCommand['Data'])
             if transParameters['ParameterOffset'] > 0:
                 paramOffset = transParameters['ParameterOffset'] - 63 - transParameters['SetupLength']
-                transData['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]
+                transData['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]
             else:
                 transData['Trans_Parameters'] = b''
 
             if transParameters['DataOffset'] > 0:
                 dataOffset = transParameters['DataOffset'] - 63 - transParameters['SetupLength']
                 transData['Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]
-            else: 
+            else:
                 transData['Trans_Data'] = b''
-            
+
             # Call the handler for this TRANSACTION
             if transParameters['SetupCount'] == 0:
                 # No subcommand, let's play with the Name
-                command = decodeSMBString(recvPacket['Flags2'],transData['Name'])
+                command = decodeSMBString(recvPacket['Flags2'], transData['Name'])
             else:
                 command = struct.unpack('<H', transParameters['Setup'][:2])[0]
-            
+
             if command in transCommands:
-               # Call the TRANS subcommand
-               setup = b''
-               parameters = b''
-               data = b''
-               try: 
-                   setup, parameters, data, errorCode = transCommands[command](connId,
-                                smbServer, 
-                                recvPacket, 
-                                transData['Trans_Parameters'], 
-                                transData['Trans_Data'],
-                                transParameters['MaxDataCount'])
-               except Exception as e:
-                   #print 'Transaction: %s' % e,e
-                   smbServer.log('Transaction: (%r,%s)' % (command, e), logging.ERROR)
-                   errorCode = STATUS_ACCESS_DENIED
-                   #raise
-
-               if setup == b'' and parameters == b'' and data == b'':
-                   # Something wen't wrong
-                   respParameters = b''
-                   respData = b''
-               else:
-                   # Build the answer
-                   if hasattr(data, 'getData'):
-                       data = data.getData()
-                   remainingData = len(data)
-                   if hasattr(parameters, 'getData'):
-                       parameters = parameters.getData()
-                   remainingParameters = len(parameters)
-                   commands = []
-                   dataDisplacement = 0
-                   while remainingData > 0 or remainingParameters > 0: 
-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])
-                       respParameters = smb.SMBTransactionResponse_Parameters()
-                       respData       = smb.SMBTransaction2Response_Data()
-
-                       respParameters['TotalParameterCount'] = len(parameters)
-                       respParameters['ParameterCount']      = len(parameters)
-                       respData['Trans_ParametersLength']    = len(parameters)
-                       respParameters['TotalDataCount']      = len(data)
-                       respParameters['DataDisplacement']    = dataDisplacement
-
-                       # TODO: Do the same for parameters
-                       if len(data) >  transParameters['MaxDataCount']:
-                           # Answer doesn't fit in this packet
-                           LOG.debug(""Lowering answer from %d to %d"" % (len(data),transParameters['MaxDataCount']) )
-                           respParameters['DataCount'] = transParameters['MaxDataCount']
-                       else:
-                           respParameters['DataCount'] = len(data)
-
-                       respData['Trans_DataLength']          = respParameters['DataCount']
-                       respParameters['SetupCount']          = len(setup)
-                       respParameters['Setup']               = setup
-                       # TODO: Make sure we're calculating the pad right
-                       if len(parameters) > 0:
-                           #padLen = 4 - (55 + len(setup)) % 4 
-                           padLen = (4 - (55 + len(setup)) % 4 ) % 4
-                           padBytes = b'\xFF' * padLen
-                           respData['Pad1'] = padBytes
-                           respParameters['ParameterOffset'] = 55 + len(setup) + padLen 
-                       else:
-                           padLen = 0
-                           respParameters['ParameterOffset'] = 0
-                           respData['Pad1']                  = b''
-
-                       if len(data) > 0:
-                           #pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4
-                           pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4
-                           respData['Pad2'] = b'\xFF' * pad2Len
-                           respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len
-                       else:
-                           respParameters['DataOffset'] = 0
-                           respData['Pad2']             = b''
-
-                       respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]
-                       respData['Trans_Data']       = data[:respParameters['DataCount']] 
-                       respSMBCommand['Parameters'] = respParameters
-                       respSMBCommand['Data']       = respData 
-
-                       data = data[respParameters['DataCount']:]
-                       remainingData -= respParameters['DataCount']
-                       dataDisplacement += respParameters['DataCount'] + 1
-
-                       parameters = parameters[respParameters['ParameterCount']:]
-                       remainingParameters -= respParameters['ParameterCount']
-                       commands.append(respSMBCommand)
-
-                   smbServer.setConnectionData(connId, connData)
-                   return commands, None, errorCode
+                # Call the TRANS subcommand
+                setup = b''
+                parameters = b''
+                data = b''
+                try:
+                    setup, parameters, data, errorCode = transCommands[command](connId,
+                                                                                smbServer,
+                                                                                recvPacket,
+                                                                                transData['Trans_Parameters'],
+                                                                                transData['Trans_Data'],
+                                                                                transParameters['MaxDataCount'])
+                except Exception as e:
+                    # print 'Transaction: %s' % e,e
+                    smbServer.log('Transaction: (%r,%s)' % (command, e), logging.ERROR)
+                    errorCode = STATUS_ACCESS_DENIED
+                    # raise
+
+                if setup == b'' and parameters == b'' and data == b'':
+                    # Something wen't wrong
+                    respParameters = b''
+                    respData = b''
+                else:
+                    # Build the answer
+                    if hasattr(data, 'getData'):
+                        data = data.getData()
+                    remainingData = len(data)
+                    if hasattr(parameters, 'getData'):
+                        parameters = parameters.getData()
+                    remainingParameters = len(parameters)
+                    commands = []
+                    dataDisplacement = 0
+                    while remainingData > 0 or remainingParameters > 0:
+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])
+                        respParameters = smb.SMBTransactionResponse_Parameters()
+                        respData = smb.SMBTransaction2Response_Data()
+
+                        respParameters['TotalParameterCount'] = len(parameters)
+                        respParameters['ParameterCount'] = len(parameters)
+                        respData['Trans_ParametersLength'] = len(parameters)
+                        respParameters['TotalDataCount'] = len(data)
+                        respParameters['DataDisplacement'] = dataDisplacement
+
+                        # TODO: Do the same for parameters
+                        if len(data) > transParameters['MaxDataCount']:
+                            # Answer doesn't fit in this packet
+                            LOG.debug(""Lowering answer from %d to %d"" % (len(data), transParameters['MaxDataCount']))
+                            respParameters['DataCount'] = transParameters['MaxDataCount']
+                        else:
+                            respParameters['DataCount'] = len(data)
+
+                        respData['Trans_DataLength'] = respParameters['DataCount']
+                        respParameters['SetupCount'] = len(setup)
+                        respParameters['Setup'] = setup
+                        # TODO: Make sure we're calculating the pad right
+                        if len(parameters) > 0:
+                            # padLen = 4 - (55 + len(setup)) % 4
+                            padLen = (4 - (55 + len(setup)) % 4) % 4
+                            padBytes = b'\xFF' * padLen
+                            respData['Pad1'] = padBytes
+                            respParameters['ParameterOffset'] = 55 + len(setup) + padLen
+                        else:
+                            padLen = 0
+                            respParameters['ParameterOffset'] = 0
+                            respData['Pad1'] = b''
+
+                        if len(data) > 0:
+                            # pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4
+                            pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4
+                            respData['Pad2'] = b'\xFF' * pad2Len
+                            respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len
+                        else:
+                            respParameters['DataOffset'] = 0
+                            respData['Pad2'] = b''
+
+                        respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]
+                        respData['Trans_Data'] = data[:respParameters['DataCount']]
+                        respSMBCommand['Parameters'] = respParameters
+                        respSMBCommand['Data'] = respData
+
+                        data = data[respParameters['DataCount']:]
+                        remainingData -= respParameters['DataCount']
+                        dataDisplacement += respParameters['DataCount'] + 1
+
+                        parameters = parameters[respParameters['ParameterCount']:]
+                        remainingParameters -= respParameters['ParameterCount']
+                        commands.append(respSMBCommand)
+
+                    smbServer.setConnectionData(connId, connData)
+                    return commands, None, errorCode
 
             else:
-               smbServer.log(""Unsupported Transact command %r"" % command, logging.ERROR)
-               respParameters = b''
-               respData = b''
-               errorCode = STATUS_NOT_IMPLEMENTED
+                smbServer.log(""Unsupported Transact command %r"" % command, logging.ERROR)
+                respParameters = b''
+                respData = b''
+                errorCode = STATUS_NOT_IMPLEMENTED
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
-
     @staticmethod
     def smbNTTransact(connId, smbServer, SMBCommand, recvPacket, transCommands):
         connData = smbServer.getConnectionData(connId)
 
         respSMBCommand = smb.SMBCommand(recvPacket['Command'])
 
-        NTTransParameters= smb.SMBNTTransaction_Parameters(SMBCommand['Parameters'])
+        NTTransParameters = smb.SMBNTTransaction_Parameters(SMBCommand['Parameters'])
         # Do the stuff
         if NTTransParameters['ParameterCount'] != NTTransParameters['TotalParameterCount']:
-            # TODO: Handle partial parameters 
+            # TODO: Handle partial parameters
             raise Exception(""Unsupported partial parameters in NTTrans!"")
         else:
             NTTransData = smb.SMBNTTransaction_Data()
-            # Standard says servers shouldn't trust Parameters and Data comes 
-            # in order, so we have to parse the offsets, ugly   
+            # Standard says servers shouldn't trust Parameters and Data comes
+            # in order, so we have to parse the offsets, ugly
 
             paramCount = NTTransParameters['ParameterCount']
             NTTransData['NT_Trans_ParametersLength'] = paramCount
@@ -1087,139 +1117,138 @@ def smbNTTransact(connId, smbServer, SMBCommand, recvPacket, transCommands):
 
             if NTTransParameters['ParameterOffset'] > 0:
                 paramOffset = NTTransParameters['ParameterOffset'] - 73 - NTTransParameters['SetupLength']
-                NTTransData['NT_Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]
+                NTTransData['NT_Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]
             else:
                 NTTransData['NT_Trans_Parameters'] = b''
 
             if NTTransParameters['DataOffset'] > 0:
                 dataOffset = NTTransParameters['DataOffset'] - 73 - NTTransParameters['SetupLength']
                 NTTransData['NT_Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]
-            else: 
+            else:
                 NTTransData['NT_Trans_Data'] = b''
 
             # Call the handler for this TRANSACTION
             command = NTTransParameters['Function']
             if command in transCommands:
-               # Call the NT TRANS subcommand
-               setup = b''
-               parameters = b''
-               data = b''
-               try: 
-                   setup, parameters, data, errorCode = transCommands[command](connId,
-                                smbServer, 
-                                recvPacket, 
-                                NTTransData['NT_Trans_Parameters'], 
-                                NTTransData['NT_Trans_Data'],
-                                NTTransParameters['MaxDataCount'])
-               except Exception as e:
-                   smbServer.log('NTTransaction: (0x%x,%s)' % (command, e), logging.ERROR)
-                   errorCode = STATUS_ACCESS_DENIED
-                   #raise
-
-               if setup == b'' and parameters == b'' and data == b'':
-                   # Something wen't wrong
-                   respParameters = b''
-                   respData = b''
-                   if errorCode == STATUS_SUCCESS:
-                       errorCode = STATUS_ACCESS_DENIED 
-               else:
-                   # Build the answer
-                   if hasattr(data, 'getData'):
-                       data = data.getData()
-                   remainingData = len(data)
-                   if hasattr(parameters, 'getData'):
-                       parameters = parameters.getData()
-                   remainingParameters = len(parameters)
-                   commands = []
-                   dataDisplacement = 0
-                   while remainingData > 0 or remainingParameters > 0: 
-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])
-                       respParameters = smb.SMBNTTransactionResponse_Parameters()
-                       respData       = smb.SMBNTTransactionResponse_Data()
-
-                       respParameters['TotalParameterCount'] = len(parameters)
-                       respParameters['ParameterCount']      = len(parameters)
-                       respData['Trans_ParametersLength']    = len(parameters)
-                       respParameters['TotalDataCount']      = len(data)
-                       respParameters['DataDisplacement']    = dataDisplacement
-                       # TODO: Do the same for parameters
-                       if len(data) >  NTTransParameters['MaxDataCount']:
-                           # Answer doesn't fit in this packet
-                           LOG.debug(""Lowering answer from %d to %d"" % (len(data),NTTransParameters['MaxDataCount']) )
-                           respParameters['DataCount'] = NTTransParameters['MaxDataCount']
-                       else:
-                           respParameters['DataCount'] = len(data)
-
-                       respData['NT_Trans_DataLength']          = respParameters['DataCount']
-                       respParameters['SetupCount']          = len(setup)
-                       respParameters['Setup']               = setup
-                       # TODO: Make sure we're calculating the pad right
-                       if len(parameters) > 0:
-                           #padLen = 4 - (71 + len(setup)) % 4 
-                           padLen = (4 - (73 + len(setup)) % 4 ) % 4
-                           padBytes = b'\xFF' * padLen
-                           respData['Pad1'] = padBytes
-                           respParameters['ParameterOffset'] = 73 + len(setup) + padLen 
-                       else:
-                           padLen = 0
-                           respParameters['ParameterOffset'] = 0
-                           respData['Pad1']                  = b''
-
-                       if len(data) > 0:
-                           #pad2Len = 4 - (71 + len(setup) + padLen + len(parameters)) % 4
-                           pad2Len = (4 - (73 + len(setup) + padLen + len(parameters)) % 4) % 4
-                           respData['Pad2'] = b'\xFF' * pad2Len
-                           respParameters['DataOffset'] = 73 + len(setup) + padLen + len(parameters) + pad2Len
-                       else:
-                           respParameters['DataOffset'] = 0
-                           respData['Pad2']             = b''
-
-                       respData['NT_Trans_Parameters'] = parameters[:respParameters['ParameterCount']]
-                       respData['NT_Trans_Data']       = data[:respParameters['DataCount']] 
-                       respSMBCommand['Parameters'] = respParameters
-                       respSMBCommand['Data']       = respData 
-
-                       data = data[respParameters['DataCount']:]
-                       remainingData -= respParameters['DataCount']
-                       dataDisplacement += respParameters['DataCount'] + 1
-
-                       parameters = parameters[respParameters['ParameterCount']:]
-                       remainingParameters -= respParameters['ParameterCount']
-                       commands.append(respSMBCommand)
-
-                   smbServer.setConnectionData(connId, connData)
-                   return commands, None, errorCode
+                # Call the NT TRANS subcommand
+                setup = b''
+                parameters = b''
+                data = b''
+                try:
+                    setup, parameters, data, errorCode = transCommands[command](connId,
+                                                                                smbServer,
+                                                                                recvPacket,
+                                                                                NTTransData['NT_Trans_Parameters'],
+                                                                                NTTransData['NT_Trans_Data'],
+                                                                                NTTransParameters['MaxDataCount'])
+                except Exception as e:
+                    smbServer.log('NTTransaction: (0x%x,%s)' % (command, e), logging.ERROR)
+                    errorCode = STATUS_ACCESS_DENIED
+                    # raise
+
+                if setup == b'' and parameters == b'' and data == b'':
+                    # Something wen't wrong
+                    respParameters = b''
+                    respData = b''
+                    if errorCode == STATUS_SUCCESS:
+                        errorCode = STATUS_ACCESS_DENIED
+                else:
+                    # Build the answer
+                    if hasattr(data, 'getData'):
+                        data = data.getData()
+                    remainingData = len(data)
+                    if hasattr(parameters, 'getData'):
+                        parameters = parameters.getData()
+                    remainingParameters = len(parameters)
+                    commands = []
+                    dataDisplacement = 0
+                    while remainingData > 0 or remainingParameters > 0:
+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])
+                        respParameters = smb.SMBNTTransactionResponse_Parameters()
+                        respData = smb.SMBNTTransactionResponse_Data()
+
+                        respParameters['TotalParameterCount'] = len(parameters)
+                        respParameters['ParameterCount'] = len(parameters)
+                        respData['Trans_ParametersLength'] = len(parameters)
+                        respParameters['TotalDataCount'] = len(data)
+                        respParameters['DataDisplacement'] = dataDisplacement
+                        # TODO: Do the same for parameters
+                        if len(data) > NTTransParameters['MaxDataCount']:
+                            # Answer doesn't fit in this packet
+                            LOG.debug(""Lowering answer from %d to %d"" % (len(data), NTTransParameters['MaxDataCount']))
+                            respParameters['DataCount'] = NTTransParameters['MaxDataCount']
+                        else:
+                            respParameters['DataCount'] = len(data)
+
+                        respData['NT_Trans_DataLength'] = respParameters['DataCount']
+                        respParameters['SetupCount'] = len(setup)
+                        respParameters['Setup'] = setup
+                        # TODO: Make sure we're calculating the pad right
+                        if len(parameters) > 0:
+                            # padLen = 4 - (71 + len(setup)) % 4
+                            padLen = (4 - (73 + len(setup)) % 4) % 4
+                            padBytes = b'\xFF' * padLen
+                            respData['Pad1'] = padBytes
+                            respParameters['ParameterOffset'] = 73 + len(setup) + padLen
+                        else:
+                            padLen = 0
+                            respParameters['ParameterOffset'] = 0
+                            respData['Pad1'] = b''
+
+                        if len(data) > 0:
+                            # pad2Len = 4 - (71 + len(setup) + padLen + len(parameters)) % 4
+                            pad2Len = (4 - (73 + len(setup) + padLen + len(parameters)) % 4) % 4
+                            respData['Pad2'] = b'\xFF' * pad2Len
+                            respParameters['DataOffset'] = 73 + len(setup) + padLen + len(parameters) + pad2Len
+                        else:
+                            respParameters['DataOffset'] = 0
+                            respData['Pad2'] = b''
+
+                        respData['NT_Trans_Parameters'] = parameters[:respParameters['ParameterCount']]
+                        respData['NT_Trans_Data'] = data[:respParameters['DataCount']]
+                        respSMBCommand['Parameters'] = respParameters
+                        respSMBCommand['Data'] = respData
+
+                        data = data[respParameters['DataCount']:]
+                        remainingData -= respParameters['DataCount']
+                        dataDisplacement += respParameters['DataCount'] + 1
+
+                        parameters = parameters[respParameters['ParameterCount']:]
+                        remainingParameters -= respParameters['ParameterCount']
+                        commands.append(respSMBCommand)
+
+                    smbServer.setConnectionData(connId, connData)
+                    return commands, None, errorCode
 
             else:
-               #smbServer.log(""Unsupported NTTransact command 0x%x"" % command, logging.ERROR)
-               respParameters = b''
-               respData = b''
-               errorCode = STATUS_NOT_IMPLEMENTED
+                # smbServer.log(""Unsupported NTTransact command 0x%x"" % command, logging.ERROR)
+                respParameters = b''
+                respData = b''
+                errorCode = STATUS_NOT_IMPLEMENTED
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
 
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
 
-
     @staticmethod
     def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):
         connData = smbServer.getConnectionData(connId)
 
         respSMBCommand = smb.SMBCommand(recvPacket['Command'])
 
-        trans2Parameters= smb.SMBTransaction2_Parameters(SMBCommand['Parameters'])
+        trans2Parameters = smb.SMBTransaction2_Parameters(SMBCommand['Parameters'])
 
         # Do the stuff
         if trans2Parameters['ParameterCount'] != trans2Parameters['TotalParameterCount']:
-            # TODO: Handle partial parameters 
-            #print ""Unsupported partial parameters in TRANSACT2!""
+            # TODO: Handle partial parameters
+            # print ""Unsupported partial parameters in TRANSACT2!""
             raise Exception(""Unsupported partial parameters in TRANSACT2!"")
         else:
             trans2Data = smb.SMBTransaction2_Data()
-            # Standard says servers shouldn't trust Parameters and Data comes 
-            # in order, so we have to parse the offsets, ugly   
+            # Standard says servers shouldn't trust Parameters and Data comes
+            # in order, so we have to parse the offsets, ugly
 
             paramCount = trans2Parameters['ParameterCount']
             trans2Data['Trans_ParametersLength'] = paramCount
@@ -1228,113 +1257,113 @@ def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):
 
             if trans2Parameters['ParameterOffset'] > 0:
                 paramOffset = trans2Parameters['ParameterOffset'] - 63 - trans2Parameters['SetupLength']
-                trans2Data['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset+paramCount]
+                trans2Data['Trans_Parameters'] = SMBCommand['Data'][paramOffset:paramOffset + paramCount]
             else:
                 trans2Data['Trans_Parameters'] = b''
 
             if trans2Parameters['DataOffset'] > 0:
                 dataOffset = trans2Parameters['DataOffset'] - 63 - trans2Parameters['SetupLength']
                 trans2Data['Trans_Data'] = SMBCommand['Data'][dataOffset:dataOffset + dataCount]
-            else: 
+            else:
                 trans2Data['Trans_Data'] = b''
 
             # Call the handler for this TRANSACTION
             command = struct.unpack('<H', trans2Parameters['Setup'])[0]
             if command in transCommands:
-               # Call the TRANS2 subcommand
-               try:
-                   setup, parameters, data, errorCode = transCommands[command](connId,
-                                smbServer, 
-                                recvPacket, 
-                                trans2Data['Trans_Parameters'], 
-                                trans2Data['Trans_Data'],
-                                trans2Parameters['MaxDataCount'])
-               except Exception as e:
-                   smbServer.log('Transaction2: (0x%x,%s)' % (command, e), logging.ERROR)
-                   #import traceback
-                   #traceback.print_exc()
-                   raise
-
-               if setup == b'' and parameters == b'' and data == b'':
-                   # Something wen't wrong
-                   respParameters = b''
-                   respData = b''
-               else:
-                   # Build the answer
-                   if hasattr(data, 'getData'):
-                       data = data.getData()
-                   remainingData = len(data)
-                   if hasattr(parameters, 'getData'):
-                       parameters = parameters.getData()
-                   remainingParameters = len(parameters)
-                   commands = []
-                   dataDisplacement = 0
-                   while remainingData > 0 or remainingParameters > 0: 
-                       respSMBCommand = smb.SMBCommand(recvPacket['Command'])
-                       respParameters = smb.SMBTransaction2Response_Parameters()
-                       respData       = smb.SMBTransaction2Response_Data()
-
-                       respParameters['TotalParameterCount'] = len(parameters)
-                       respParameters['ParameterCount']      = len(parameters)
-                       respData['Trans_ParametersLength']    = len(parameters)
-                       respParameters['TotalDataCount']      = len(data)
-                       respParameters['DataDisplacement']    = dataDisplacement
-                       # TODO: Do the same for parameters
-                       if len(data) >  trans2Parameters['MaxDataCount']:
-                           # Answer doesn't fit in this packet
-                           LOG.debug(""Lowering answer from %d to %d"" % (len(data),trans2Parameters['MaxDataCount']) )
-                           respParameters['DataCount'] = trans2Parameters['MaxDataCount']
-                       else:
-                           respParameters['DataCount'] = len(data)
-
-                       respData['Trans_DataLength']          = respParameters['DataCount']
-                       respParameters['SetupCount']          = len(setup)
-                       respParameters['Setup']               = setup
-                       # TODO: Make sure we're calculating the pad right
-                       if len(parameters) > 0:
-                           #padLen = 4 - (55 + len(setup)) % 4 
-                           padLen = (4 - (55 + len(setup)) % 4 ) % 4
-                           padBytes = b'\xFF' * padLen
-                           respData['Pad1'] = padBytes
-                           respParameters['ParameterOffset'] = 55 + len(setup) + padLen 
-                       else:
-                           padLen = 0
-                           respParameters['ParameterOffset'] = 0
-                           respData['Pad1']                  = b''
-
-                       if len(data) > 0:
-                           #pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4
-                           pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4
-                           respData['Pad2'] = b'\xFF' * pad2Len
-                           respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len
-                       else:
-                           respParameters['DataOffset'] = 0
-                           respData['Pad2']             = b''
-
-                       respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]
-                       respData['Trans_Data']       = data[:respParameters['DataCount']] 
-                       respSMBCommand['Parameters'] = respParameters
-                       respSMBCommand['Data']       = respData 
-
-                       data = data[respParameters['DataCount']:]
-                       remainingData -= respParameters['DataCount']
-                       dataDisplacement += respParameters['DataCount'] + 1
-
-                       parameters = parameters[respParameters['ParameterCount']:]
-                       remainingParameters -= respParameters['ParameterCount']
-                       commands.append(respSMBCommand)
-
-                   smbServer.setConnectionData(connId, connData)
-                   return commands, None, errorCode
+                # Call the TRANS2 subcommand
+                try:
+                    setup, parameters, data, errorCode = transCommands[command](connId,
+                                                                                smbServer,
+                                                                                recvPacket,
+                                                                                trans2Data['Trans_Parameters'],
+                                                                                trans2Data['Trans_Data'],
+                                                                                trans2Parameters['MaxDataCount'])
+                except Exception as e:
+                    smbServer.log('Transaction2: (0x%x,%s)' % (command, e), logging.ERROR)
+                    # import traceback
+                    # traceback.print_exc()
+                    raise
+
+                if setup == b'' and parameters == b'' and data == b'':
+                    # Something wen't wrong
+                    respParameters = b''
+                    respData = b''
+                else:
+                    # Build the answer
+                    if hasattr(data, 'getData'):
+                        data = data.getData()
+                    remainingData = len(data)
+                    if hasattr(parameters, 'getData'):
+                        parameters = parameters.getData()
+                    remainingParameters = len(parameters)
+                    commands = []
+                    dataDisplacement = 0
+                    while remainingData > 0 or remainingParameters > 0:
+                        respSMBCommand = smb.SMBCommand(recvPacket['Command'])
+                        respParameters = smb.SMBTransaction2Response_Parameters()
+                        respData = smb.SMBTransaction2Response_Data()
+
+                        respParameters['TotalParameterCount'] = len(parameters)
+                        respParameters['ParameterCount'] = len(parameters)
+                        respData['Trans_ParametersLength'] = len(parameters)
+                        respParameters['TotalDataCount'] = len(data)
+                        respParameters['DataDisplacement'] = dataDisplacement
+                        # TODO: Do the same for parameters
+                        if len(data) > trans2Parameters['MaxDataCount']:
+                            # Answer doesn't fit in this packet
+                            LOG.debug(""Lowering answer from %d to %d"" % (len(data), trans2Parameters['MaxDataCount']))
+                            respParameters['DataCount'] = trans2Parameters['MaxDataCount']
+                        else:
+                            respParameters['DataCount'] = len(data)
+
+                        respData['Trans_DataLength'] = respParameters['DataCount']
+                        respParameters['SetupCount'] = len(setup)
+                        respParameters['Setup'] = setup
+                        # TODO: Make sure we're calculating the pad right
+                        if len(parameters) > 0:
+                            # padLen = 4 - (55 + len(setup)) % 4
+                            padLen = (4 - (55 + len(setup)) % 4) % 4
+                            padBytes = b'\xFF' * padLen
+                            respData['Pad1'] = padBytes
+                            respParameters['ParameterOffset'] = 55 + len(setup) + padLen
+                        else:
+                            padLen = 0
+                            respParameters['ParameterOffset'] = 0
+                            respData['Pad1'] = b''
+
+                        if len(data) > 0:
+                            # pad2Len = 4 - (55 + len(setup) + padLen + len(parameters)) % 4
+                            pad2Len = (4 - (55 + len(setup) + padLen + len(parameters)) % 4) % 4
+                            respData['Pad2'] = b'\xFF' * pad2Len
+                            respParameters['DataOffset'] = 55 + len(setup) + padLen + len(parameters) + pad2Len
+                        else:
+                            respParameters['DataOffset'] = 0
+                            respData['Pad2'] = b''
+
+                        respData['Trans_Parameters'] = parameters[:respParameters['ParameterCount']]
+                        respData['Trans_Data'] = data[:respParameters['DataCount']]
+                        respSMBCommand['Parameters'] = respParameters
+                        respSMBCommand['Data'] = respData
+
+                        data = data[respParameters['DataCount']:]
+                        remainingData -= respParameters['DataCount']
+                        dataDisplacement += respParameters['DataCount'] + 1
+
+                        parameters = parameters[respParameters['ParameterCount']:]
+                        remainingParameters -= respParameters['ParameterCount']
+                        commands.append(respSMBCommand)
+
+                    smbServer.setConnectionData(connId, connData)
+                    return commands, None, errorCode
 
             else:
-               smbServer.log(""Unsupported Transact/2 command 0x%x"" % command, logging.ERROR)
-               respParameters = b''
-               respData = b''
-               errorCode = STATUS_NOT_IMPLEMENTED
+                smbServer.log(""Unsupported Transact/2 command 0x%x"" % command, logging.ERROR)
+                respParameters = b''
+                respData = b''
+                errorCode = STATUS_NOT_IMPLEMENTED
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
 
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
@@ -1343,59 +1372,58 @@ def smbTransaction2(connId, smbServer, SMBCommand, recvPacket, transCommands):
     def smbComLockingAndX(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_LOCKING_ANDX)
-        respParameters        = b''
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_LOCKING_ANDX)
+        respParameters = b''
+        respData = b''
 
         # I'm actually doing nothing.. just make MacOS happy ;)
         errorCode = STATUS_SUCCESS
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
-
     @staticmethod
     def smbComClose(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_CLOSE)
-        respParameters        = b''
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_CLOSE)
+        respParameters = b''
+        respData = b''
 
-        comClose =  smb.SMBClose_Parameters(SMBCommand['Parameters'])
+        comClose = smb.SMBClose_Parameters(SMBCommand['Parameters'])
 
         if comClose['FID'] in connData['OpenedFiles']:
-             errorCode = STATUS_SUCCESS
-             fileHandle = connData['OpenedFiles'][comClose['FID']]['FileHandle']
-             try:
-                 if fileHandle == PIPE_FILE_DESCRIPTOR:
-                     connData['OpenedFiles'][comClose['FID']]['Socket'].close()
-                 elif fileHandle != VOID_FILE_DESCRIPTOR:
-                     os.close(fileHandle)
-             except Exception as e:
-                 smbServer.log(""comClose %s"" % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
-             else:
-                 # Check if the file was marked for removal
-                 if connData['OpenedFiles'][comClose['FID']]['DeleteOnClose'] is True:
-                     try:
-                         os.remove(connData['OpenedFiles'][comClose['FID']]['FileName'])
-                     except Exception as e:
-                         smbServer.log(""comClose %s"" % e, logging.ERROR)
-                         errorCode = STATUS_ACCESS_DENIED
-                 del(connData['OpenedFiles'][comClose['FID']])
+            errorCode = STATUS_SUCCESS
+            fileHandle = connData['OpenedFiles'][comClose['FID']]['FileHandle']
+            try:
+                if fileHandle == PIPE_FILE_DESCRIPTOR:
+                    connData['OpenedFiles'][comClose['FID']]['Socket'].close()
+                elif fileHandle != VOID_FILE_DESCRIPTOR:
+                    os.close(fileHandle)
+            except Exception as e:
+                smbServer.log(""comClose %s"" % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
+            else:
+                # Check if the file was marked for removal
+                if connData['OpenedFiles'][comClose['FID']]['DeleteOnClose'] is True:
+                    try:
+                        os.remove(connData['OpenedFiles'][comClose['FID']]['FileName'])
+                    except Exception as e:
+                        smbServer.log(""comClose %s"" % e, logging.ERROR)
+                        errorCode = STATUS_ACCESS_DENIED
+                del (connData['OpenedFiles'][comClose['FID']])
         else:
             errorCode = STATUS_INVALID_HANDLE
 
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
@@ -1404,310 +1432,308 @@ def smbComClose(connId, smbServer, SMBCommand, recvPacket):
     def smbComWrite(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_WRITE)
-        respParameters        = smb.SMBWriteResponse_Parameters()
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_WRITE)
+        respParameters = smb.SMBWriteResponse_Parameters()
+        respData = b''
 
-        comWriteParameters =  smb.SMBWrite_Parameters(SMBCommand['Parameters'])
+        comWriteParameters = smb.SMBWrite_Parameters(SMBCommand['Parameters'])
         comWriteData = smb.SMBWrite_Data(SMBCommand['Data'])
 
         if comWriteParameters['Fid'] in connData['OpenedFiles']:
-             fileHandle = connData['OpenedFiles'][comWriteParameters['Fid']]['FileHandle']
-             errorCode = STATUS_SUCCESS
-             try:
-                 if fileHandle != PIPE_FILE_DESCRIPTOR:
-                     # TODO: Handle big size files
-                     # If we're trying to write past the file end we just skip the write call (Vista does this)
-                     if os.lseek(fileHandle, 0, 2) >= comWriteParameters['Offset']: 
-                         os.lseek(fileHandle,comWriteParameters['Offset'],0)
-                         os.write(fileHandle,comWriteData['Data'])
-                 else:
-                     sock = connData['OpenedFiles'][comWriteParameters['Fid']]['Socket']
-                     sock.send(comWriteData['Data'])
-                 respParameters['Count']    = comWriteParameters['Count']
-             except Exception as e:
-                 smbServer.log('smbComWrite: %s' % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            fileHandle = connData['OpenedFiles'][comWriteParameters['Fid']]['FileHandle']
+            errorCode = STATUS_SUCCESS
+            try:
+                if fileHandle != PIPE_FILE_DESCRIPTOR:
+                    # TODO: Handle big size files
+                    # If we're trying to write past the file end we just skip the write call (Vista does this)
+                    if os.lseek(fileHandle, 0, 2) >= comWriteParameters['Offset']:
+                        os.lseek(fileHandle, comWriteParameters['Offset'], 0)
+                        os.write(fileHandle, comWriteData['Data'])
+                else:
+                    sock = connData['OpenedFiles'][comWriteParameters['Fid']]['Socket']
+                    sock.send(comWriteData['Data'])
+                respParameters['Count'] = comWriteParameters['Count']
+            except Exception as e:
+                smbServer.log('smbComWrite: %s' % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_HANDLE
 
-
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
     @staticmethod
-    def smbComFlush(connId, smbServer, SMBCommand,recvPacket ):
+    def smbComFlush(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_FLUSH)
-        respParameters        = b''
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_FLUSH)
+        respParameters = b''
+        respData = b''
 
-        comFlush =  smb.SMBFlush_Parameters(SMBCommand['Parameters'])
+        comFlush = smb.SMBFlush_Parameters(SMBCommand['Parameters'])
 
         if comFlush['FID'] in connData['OpenedFiles']:
-             errorCode = STATUS_SUCCESS
-             fileHandle = connData['OpenedFiles'][comFlush['FID']]['FileHandle']
-             try:
-                 os.fsync(fileHandle)
-             except Exception as e:
-                 smbServer.log(""comFlush %s"" % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            errorCode = STATUS_SUCCESS
+            fileHandle = connData['OpenedFiles'][comFlush['FID']]['FileHandle']
+            try:
+                os.fsync(fileHandle)
+            except Exception as e:
+                smbServer.log(""comFlush %s"" % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_HANDLE
 
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
-
     @staticmethod
-    def smbComCreateDirectory(connId, smbServer, SMBCommand,recvPacket ):
+    def smbComCreateDirectory(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_CREATE_DIRECTORY)
-        respParameters        = b''
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_CREATE_DIRECTORY)
+        respParameters = b''
+        respData = b''
 
-        comCreateDirectoryData=  smb.SMBCreateDirectory_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])
+        comCreateDirectoryData = smb.SMBCreateDirectory_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])
 
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
-             errorCode = STATUS_SUCCESS
-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']
-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comCreateDirectoryData['DirectoryName']).replace('\\','/'))
-             if len(fileName) > 0:
+            errorCode = STATUS_SUCCESS
+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']
+            fileName = os.path.normpath(
+                decodeSMBString(recvPacket['Flags2'], comCreateDirectoryData['DirectoryName']).replace('\\', '/'))
+            if len(fileName) > 0:
                 if fileName[0] == '/' or fileName[0] == '\\':
                     # strip leading '/'
                     fileName = fileName[1:]
-             pathName = os.path.join(path,fileName)
-             if os.path.exists(pathName):
+            pathName = os.path.join(path, fileName)
+            if os.path.exists(pathName):
                 errorCode = STATUS_OBJECT_NAME_COLLISION
 
-             # TODO: More checks here in the future.. Specially when we support
-             # user access
-             else:
-                 try:
-                     os.mkdir(pathName)
-                 except Exception as e:
-                     smbServer.log(""smbComCreateDirectory: %s"" % e, logging.ERROR)
-                     errorCode = STATUS_ACCESS_DENIED
+            # TODO: More checks here in the future.. Specially when we support
+            # user access
+            else:
+                try:
+                    os.mkdir(pathName)
+                except Exception as e:
+                    smbServer.log(""smbComCreateDirectory: %s"" % e, logging.ERROR)
+                    errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_SMB_BAD_TID
 
-
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
     @staticmethod
-    def smbComRename(connId, smbServer, SMBCommand, recvPacket ):
+    def smbComRename(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_RENAME)
-        respParameters        = b''
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_RENAME)
+        respParameters = b''
+        respData = b''
 
-        comRenameData      =  smb.SMBRename_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])
+        comRenameData = smb.SMBRename_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
-             errorCode = STATUS_SUCCESS
-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']
-             oldFileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comRenameData['OldFileName']).replace('\\','/'))
-             newFileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comRenameData['NewFileName']).replace('\\','/'))
-             if len(oldFileName) > 0 and (oldFileName[0] == '/' or oldFileName[0] == '\\'):
+            errorCode = STATUS_SUCCESS
+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']
+            oldFileName = os.path.normpath(
+                decodeSMBString(recvPacket['Flags2'], comRenameData['OldFileName']).replace('\\', '/'))
+            newFileName = os.path.normpath(
+                decodeSMBString(recvPacket['Flags2'], comRenameData['NewFileName']).replace('\\', '/'))
+            if len(oldFileName) > 0 and (oldFileName[0] == '/' or oldFileName[0] == '\\'):
                 # strip leading '/'
                 oldFileName = oldFileName[1:]
-             oldPathName = os.path.join(path,oldFileName)
-             if len(newFileName) > 0 and (newFileName[0] == '/' or newFileName[0] == '\\'):
+            oldPathName = os.path.join(path, oldFileName)
+            if len(newFileName) > 0 and (newFileName[0] == '/' or newFileName[0] == '\\'):
                 # strip leading '/'
                 newFileName = newFileName[1:]
-             newPathName = os.path.join(path,newFileName)
+            newPathName = os.path.join(path, newFileName)
 
-             if os.path.exists(oldPathName) is not True:
+            if os.path.exists(oldPathName) is not True:
                 errorCode = STATUS_NO_SUCH_FILE
 
-             # TODO: More checks here in the future.. Specially when we support
-             # user access
-             else:
-                 try:
-                     os.rename(oldPathName,newPathName)
-                 except OSError as e:
-                     smbServer.log(""smbComRename: %s"" % e, logging.ERROR)
-                     errorCode = STATUS_ACCESS_DENIED
+            # TODO: More checks here in the future.. Specially when we support
+            # user access
+            else:
+                try:
+                    os.rename(oldPathName, newPathName)
+                except OSError as e:
+                    smbServer.log(""smbComRename: %s"" % e, logging.ERROR)
+                    errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_SMB_BAD_TID
 
-
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
     @staticmethod
-    def smbComDelete(connId, smbServer, SMBCommand, recvPacket ):
+    def smbComDelete(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_DELETE)
-        respParameters        = b''
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_DELETE)
+        respParameters = b''
+        respData = b''
 
-        comDeleteData         =  smb.SMBDelete_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])
+        comDeleteData = smb.SMBDelete_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])
 
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
-             errorCode = STATUS_SUCCESS
-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']
-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comDeleteData['FileName']).replace('\\','/'))
-             if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
+            errorCode = STATUS_SUCCESS
+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']
+            fileName = os.path.normpath(
+                decodeSMBString(recvPacket['Flags2'], comDeleteData['FileName']).replace('\\', '/'))
+            if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
                 # strip leading '/'
                 fileName = fileName[1:]
-             pathName = os.path.join(path,fileName)
-             if os.path.exists(pathName) is not True:
+            pathName = os.path.join(path, fileName)
+            if os.path.exists(pathName) is not True:
                 errorCode = STATUS_NO_SUCH_FILE
 
-             # TODO: More checks here in the future.. Specially when we support
-             # user access
-             else:
-                 try:
-                     os.remove(pathName)
-                 except OSError as e:
-                     smbServer.log(""smbComDelete: %s"" % e, logging.ERROR)
-                     errorCode = STATUS_ACCESS_DENIED
+            # TODO: More checks here in the future.. Specially when we support
+            # user access
+            else:
+                try:
+                    os.remove(pathName)
+                except OSError as e:
+                    smbServer.log(""smbComDelete: %s"" % e, logging.ERROR)
+                    errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_SMB_BAD_TID
 
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
-
     @staticmethod
-    def smbComDeleteDirectory(connId, smbServer, SMBCommand, recvPacket ):
+    def smbComDeleteDirectory(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_DELETE_DIRECTORY)
-        respParameters        = b''
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_DELETE_DIRECTORY)
+        respParameters = b''
+        respData = b''
 
-        comDeleteDirectoryData=  smb.SMBDeleteDirectory_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])
+        comDeleteDirectoryData = smb.SMBDeleteDirectory_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])
 
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
-             errorCode = STATUS_SUCCESS
-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']
-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],comDeleteDirectoryData['DirectoryName']).replace('\\','/'))
-             if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
+            errorCode = STATUS_SUCCESS
+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']
+            fileName = os.path.normpath(
+                decodeSMBString(recvPacket['Flags2'], comDeleteDirectoryData['DirectoryName']).replace('\\', '/'))
+            if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
                 # strip leading '/'
                 fileName = fileName[1:]
-             pathName = os.path.join(path,fileName)
-             if os.path.exists(pathName) is not True:
+            pathName = os.path.join(path, fileName)
+            if os.path.exists(pathName) is not True:
                 errorCode = STATUS_NO_SUCH_FILE
 
-             # TODO: More checks here in the future.. Specially when we support
-             # user access
-             else:
-                 try:
-                     os.rmdir(pathName)
-                 except OSError as e:
-                     smbServer.log(""smbComDeleteDirectory: %s"" % e,logging.ERROR)
-                     if e.errno == errno.ENOTEMPTY:
-                         errorCode = STATUS_DIRECTORY_NOT_EMPTY
-                     else:
-                         errorCode = STATUS_ACCESS_DENIED
+            # TODO: More checks here in the future.. Specially when we support
+            # user access
+            else:
+                try:
+                    os.rmdir(pathName)
+                except OSError as e:
+                    smbServer.log(""smbComDeleteDirectory: %s"" % e, logging.ERROR)
+                    if e.errno == errno.ENOTEMPTY:
+                        errorCode = STATUS_DIRECTORY_NOT_EMPTY
+                    else:
+                        errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_SMB_BAD_TID
 
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
-
     @staticmethod
     def smbComWriteAndX(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_WRITE_ANDX)
-        respParameters        = smb.SMBWriteAndXResponse_Parameters()
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_WRITE_ANDX)
+        respParameters = smb.SMBWriteAndXResponse_Parameters()
+        respData = b''
 
         if SMBCommand['WordCount'] == 0x0C:
-            writeAndX =  smb.SMBWriteAndX_Parameters_Short(SMBCommand['Parameters'])
+            writeAndX = smb.SMBWriteAndX_Parameters_Short(SMBCommand['Parameters'])
             writeAndXData = smb.SMBWriteAndX_Data_Short()
         else:
-            writeAndX =  smb.SMBWriteAndX_Parameters(SMBCommand['Parameters'])
+            writeAndX = smb.SMBWriteAndX_Parameters(SMBCommand['Parameters'])
             writeAndXData = smb.SMBWriteAndX_Data()
         writeAndXData['DataLength'] = writeAndX['DataLength']
         writeAndXData['DataOffset'] = writeAndX['DataOffset']
         writeAndXData.fromString(SMBCommand['Data'])
-        
 
         if writeAndX['Fid'] in connData['OpenedFiles']:
-             fileHandle = connData['OpenedFiles'][writeAndX['Fid']]['FileHandle']
-             errorCode = STATUS_SUCCESS
-             try:
-                 if fileHandle != PIPE_FILE_DESCRIPTOR:
-                     offset = writeAndX['Offset']
-                     if 'HighOffset' in writeAndX.fields:
-                         offset += (writeAndX['HighOffset'] << 32)
-                     # If we're trying to write past the file end we just skip the write call (Vista does this)
-                     if os.lseek(fileHandle, 0, 2) >= offset:
-                         os.lseek(fileHandle,offset,0)
-                         os.write(fileHandle,writeAndXData['Data'])
-                 else:
-                     sock = connData['OpenedFiles'][writeAndX['Fid']]['Socket']
-                     sock.send(writeAndXData['Data'])
-
-                 respParameters['Count']    = writeAndX['DataLength']
-                 respParameters['Available']= 0xff
-             except Exception as e:
-                 smbServer.log('smbComWriteAndx: %s' % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            fileHandle = connData['OpenedFiles'][writeAndX['Fid']]['FileHandle']
+            errorCode = STATUS_SUCCESS
+            try:
+                if fileHandle != PIPE_FILE_DESCRIPTOR:
+                    offset = writeAndX['Offset']
+                    if 'HighOffset' in writeAndX.fields:
+                        offset += (writeAndX['HighOffset'] << 32)
+                    # If we're trying to write past the file end we just skip the write call (Vista does this)
+                    if os.lseek(fileHandle, 0, 2) >= offset:
+                        os.lseek(fileHandle, offset, 0)
+                        os.write(fileHandle, writeAndXData['Data'])
+                else:
+                    sock = connData['OpenedFiles'][writeAndX['Fid']]['Socket']
+                    sock.send(writeAndXData['Data'])
+
+                respParameters['Count'] = writeAndX['DataLength']
+                respParameters['Available'] = 0xff
+            except Exception as e:
+                smbServer.log('smbComWriteAndx: %s' % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_HANDLE
 
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
@@ -1716,38 +1742,38 @@ def smbComWriteAndX(connId, smbServer, SMBCommand, recvPacket):
     def smbComRead(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_READ)
-        respParameters        = smb.SMBReadResponse_Parameters()
-        respData              = smb.SMBReadResponse_Data()
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_READ)
+        respParameters = smb.SMBReadResponse_Parameters()
+        respData = smb.SMBReadResponse_Data()
 
-        comReadParameters =  smb.SMBRead_Parameters(SMBCommand['Parameters'])
+        comReadParameters = smb.SMBRead_Parameters(SMBCommand['Parameters'])
 
         if comReadParameters['Fid'] in connData['OpenedFiles']:
-             fileHandle = connData['OpenedFiles'][comReadParameters['Fid']]['FileHandle']
-             errorCode = STATUS_SUCCESS
-             try:
-                 if fileHandle != PIPE_FILE_DESCRIPTOR:
-                     # TODO: Handle big size files
-                     os.lseek(fileHandle,comReadParameters['Offset'],0)
-                     content = os.read(fileHandle,comReadParameters['Count'])
-                 else:
-                     sock = connData['OpenedFiles'][comReadParameters['Fid']]['Socket']
-                     content = sock.recv(comReadParameters['Count'])
-                 respParameters['Count']    = len(content)
-                 respData['DataLength']     = len(content)
-                 respData['Data']           = content
-             except Exception as e:
-                 smbServer.log('smbComRead: %s ' % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            fileHandle = connData['OpenedFiles'][comReadParameters['Fid']]['FileHandle']
+            errorCode = STATUS_SUCCESS
+            try:
+                if fileHandle != PIPE_FILE_DESCRIPTOR:
+                    # TODO: Handle big size files
+                    os.lseek(fileHandle, comReadParameters['Offset'], 0)
+                    content = os.read(fileHandle, comReadParameters['Count'])
+                else:
+                    sock = connData['OpenedFiles'][comReadParameters['Fid']]['Socket']
+                    content = sock.recv(comReadParameters['Count'])
+                respParameters['Count'] = len(content)
+                respData['DataLength'] = len(content)
+                respData['Data'] = content
+            except Exception as e:
+                smbServer.log('smbComRead: %s ' % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_HANDLE
 
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
@@ -1756,45 +1782,45 @@ def smbComRead(connId, smbServer, SMBCommand, recvPacket):
     def smbComReadAndX(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_READ_ANDX)
-        respParameters        = smb.SMBReadAndXResponse_Parameters()
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_READ_ANDX)
+        respParameters = smb.SMBReadAndXResponse_Parameters()
+        respData = b''
 
         if SMBCommand['WordCount'] == 0x0A:
-            readAndX =  smb.SMBReadAndX_Parameters2(SMBCommand['Parameters'])
+            readAndX = smb.SMBReadAndX_Parameters2(SMBCommand['Parameters'])
         else:
-            readAndX =  smb.SMBReadAndX_Parameters(SMBCommand['Parameters'])
+            readAndX = smb.SMBReadAndX_Parameters(SMBCommand['Parameters'])
 
         if readAndX['Fid'] in connData['OpenedFiles']:
-             fileHandle = connData['OpenedFiles'][readAndX['Fid']]['FileHandle']
-             errorCode = 0
-             try:
-                 if fileHandle != PIPE_FILE_DESCRIPTOR:
-                     offset = readAndX['Offset']
-                     if 'HighOffset' in readAndX.fields:
-                         offset += (readAndX['HighOffset'] << 32)
-                     os.lseek(fileHandle,offset,0)
-                     content = os.read(fileHandle,readAndX['MaxCount'])
-                 else:
-                     sock = connData['OpenedFiles'][readAndX['Fid']]['Socket']
-                     content = sock.recv(readAndX['MaxCount'])
-                 respParameters['Remaining']    = 0xffff
-                 respParameters['DataCount']    = len(content)
-                 respParameters['DataOffset']   = 59
-                 respParameters['DataCount_Hi'] = 0
-                 respData = content
-             except Exception as e:
-                 smbServer.log('smbComReadAndX: %s ' % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            fileHandle = connData['OpenedFiles'][readAndX['Fid']]['FileHandle']
+            errorCode = 0
+            try:
+                if fileHandle != PIPE_FILE_DESCRIPTOR:
+                    offset = readAndX['Offset']
+                    if 'HighOffset' in readAndX.fields:
+                        offset += (readAndX['HighOffset'] << 32)
+                    os.lseek(fileHandle, offset, 0)
+                    content = os.read(fileHandle, readAndX['MaxCount'])
+                else:
+                    sock = connData['OpenedFiles'][readAndX['Fid']]['Socket']
+                    content = sock.recv(readAndX['MaxCount'])
+                respParameters['Remaining'] = 0xffff
+                respParameters['DataCount'] = len(content)
+                respParameters['DataOffset'] = 59
+                respParameters['DataCount_Hi'] = 0
+                respData = content
+            except Exception as e:
+                smbServer.log('smbComReadAndX: %s ' % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_HANDLE
 
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
@@ -1805,28 +1831,28 @@ def smbQueryInformation(connId, smbServer, SMBCommand, recvPacket):
 
         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION)
         respParameters = smb.SMBQueryInformationResponse_Parameters()
-        respData       = b''
+        respData = b''
 
-        queryInformation= smb.SMBQueryInformation_Data(flags = recvPacket['Flags2'], data = SMBCommand['Data'])
+        queryInformation = smb.SMBQueryInformation_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])
 
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
             fileSize, lastWriteTime, fileAttributes = queryFsInformation(
-                connData['ConnectedShares'][recvPacket['Tid']]['path'], 
-                decodeSMBString(recvPacket['Flags2'],queryInformation['FileName']), pktFlags = recvPacket['Flags2'])
+                connData['ConnectedShares'][recvPacket['Tid']]['path'],
+                decodeSMBString(recvPacket['Flags2'], queryInformation['FileName']), pktFlags=recvPacket['Flags2'])
 
-            respParameters['FileSize']       = fileSize
-            respParameters['LastWriteTime']  = lastWriteTime
+            respParameters['FileSize'] = fileSize
+            respParameters['LastWriteTime'] = lastWriteTime
             respParameters['FileAttributes'] = fileAttributes
             errorCode = STATUS_SUCCESS
         else:
             # STATUS_SMB_BAD_TID
             errorCode = STATUS_SMB_BAD_TID
-            respParameters  = b''
-            respData        = b''
+            respParameters = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
 
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
@@ -1837,27 +1863,26 @@ def smbQueryInformationDisk(connId, smbServer, SMBCommand, recvPacket):
 
         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION_DISK)
         respParameters = smb.SMBQueryInformationDiskResponse_Parameters()
-        respData       = b''
+        respData = b''
 
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
             totalUnits, freeUnits = queryDiskInformation(
-                        connData['ConnectedShares'][recvPacket['Tid']]['path'])
+                connData['ConnectedShares'][recvPacket['Tid']]['path'])
 
-            respParameters['TotalUnits']    = totalUnits
+            respParameters['TotalUnits'] = totalUnits
             respParameters['BlocksPerUnit'] = 1
-            respParameters['BlockSize']     = 1
-            respParameters['FreeUnits']     = freeUnits
+            respParameters['BlockSize'] = 1
+            respParameters['FreeUnits'] = freeUnits
             errorCode = STATUS_SUCCESS
         else:
             # STATUS_SMB_BAD_TID
-            respData  = b''
+            respData = b''
             respParameters = b''
             errorCode = STATUS_SMB_BAD_TID
 
-
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
 
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
@@ -1868,15 +1893,15 @@ def smbComEcho(connId, smbServer, SMBCommand, recvPacket):
 
         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_ECHO)
         respParameters = smb.SMBEchoResponse_Parameters()
-        respData       = smb.SMBEchoResponse_Data()
+        respData = smb.SMBEchoResponse_Data()
 
-        echoData       = smb.SMBEcho_Data(SMBCommand['Data'])
+        echoData = smb.SMBEcho_Data(SMBCommand['Data'])
 
         respParameters['SequenceNumber'] = 1
-        respData['Data']                 = echoData['Data']
+        respData['Data'] = echoData['Data']
 
-        respSMBCommand['Parameters']     = respParameters
-        respSMBCommand['Data']           = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
 
         errorCode = STATUS_SUCCESS
         smbServer.setConnectionData(connId, connData)
@@ -1893,15 +1918,16 @@ def smbComTreeDisconnect(connId, smbServer, SMBCommand, recvPacket):
         respData = b''
 
         if recvPacket['Tid'] in connData['ConnectedShares']:
-            smbServer.log(""Disconnecting Share(%d:%s)"" % (recvPacket['Tid'],connData['ConnectedShares'][recvPacket['Tid']]['shareName']))
-            del(connData['ConnectedShares'][recvPacket['Tid']])
+            smbServer.log(""Disconnecting Share(%d:%s)"" % (
+            recvPacket['Tid'], connData['ConnectedShares'][recvPacket['Tid']]['shareName']))
+            del (connData['ConnectedShares'][recvPacket['Tid']])
             errorCode = STATUS_SUCCESS
         else:
             # STATUS_SMB_BAD_TID
             errorCode = STATUS_SMB_BAD_TID
 
         respSMBCommand['Parameters'] = respParameters
-        respSMBCommand['Data']       = respData 
+        respSMBCommand['Data'] = respData
 
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
@@ -1910,7 +1936,7 @@ def smbComTreeDisconnect(connId, smbServer, SMBCommand, recvPacket):
     def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_LOGOFF_ANDX)
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_LOGOFF_ANDX)
 
         # Check if the Uid matches the user trying to logoff
         respParameters = b''
@@ -1921,8 +1947,8 @@ def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):
         else:
             errorCode = STATUS_SUCCESS
 
-        respSMBCommand['Parameters']   = respParameters
-        respSMBCommand['Data']         = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         connData['Uid'] = 0
         connData['Authenticated'] = False
 
@@ -1934,41 +1960,41 @@ def smbComLogOffAndX(connId, smbServer, SMBCommand, recvPacket):
     def smbComQueryInformation2(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION2)
-        respParameters        = smb.SMBQueryInformation2Response_Parameters()
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_QUERY_INFORMATION2)
+        respParameters = smb.SMBQueryInformation2Response_Parameters()
+        respData = b''
 
         queryInformation2 = smb.SMBQueryInformation2_Parameters(SMBCommand['Parameters'])
         errorCode = 0xFF
         if queryInformation2['Fid'] in connData['OpenedFiles']:
-             errorCode = STATUS_SUCCESS
-             pathName = connData['OpenedFiles'][queryInformation2['Fid']]['FileName']
-             try:
-                 (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)
-                 respParameters['CreateDate']         = getSMBDate(ctime)
-                 respParameters['CreationTime']       = getSMBTime(ctime)
-                 respParameters['LastAccessDate']     = getSMBDate(atime)
-                 respParameters['LastAccessTime']     = getSMBTime(atime)
-                 respParameters['LastWriteDate']      = getSMBDate(mtime)
-                 respParameters['LastWriteTime']      = getSMBTime(mtime)
-                 respParameters['FileDataSize']       = size
-                 respParameters['FileAllocationSize'] = size
-                 attribs = 0
-                 if os.path.isdir(pathName):
-                     attribs = smb.SMB_FILE_ATTRIBUTE_DIRECTORY
-                 if os.path.isfile(pathName):
-                     attribs = smb.SMB_FILE_ATTRIBUTE_NORMAL
-                 respParameters['FileAttributes'] = attribs
-             except Exception as e:
-                 smbServer.log('smbComQueryInformation2 %s' % e,logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            errorCode = STATUS_SUCCESS
+            pathName = connData['OpenedFiles'][queryInformation2['Fid']]['FileName']
+            try:
+                (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(pathName)
+                respParameters['CreateDate'] = getSMBDate(ctime)
+                respParameters['CreationTime'] = getSMBTime(ctime)
+                respParameters['LastAccessDate'] = getSMBDate(atime)
+                respParameters['LastAccessTime'] = getSMBTime(atime)
+                respParameters['LastWriteDate'] = getSMBDate(mtime)
+                respParameters['LastWriteTime'] = getSMBTime(mtime)
+                respParameters['FileDataSize'] = size
+                respParameters['FileAllocationSize'] = size
+                attribs = 0
+                if os.path.isdir(pathName):
+                    attribs = smb.SMB_FILE_ATTRIBUTE_DIRECTORY
+                if os.path.isfile(pathName):
+                    attribs = smb.SMB_FILE_ATTRIBUTE_NORMAL
+                respParameters['FileAttributes'] = attribs
+            except Exception as e:
+                smbServer.log('smbComQueryInformation2 %s' % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
 
         if errorCode > 0:
             respParameters = b''
-            respData       = b''
+            respData = b''
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
@@ -1978,136 +2004,145 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):
         # TODO: Fully implement this
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_NT_CREATE_ANDX)
-        respParameters        = smb.SMBNtCreateAndXResponse_Parameters()
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_NT_CREATE_ANDX)
+        respParameters = smb.SMBNtCreateAndXResponse_Parameters()
+        respData = b''
 
         ntCreateAndXParameters = smb.SMBNtCreateAndX_Parameters(SMBCommand['Parameters'])
-        ntCreateAndXData       = smb.SMBNtCreateAndX_Data( flags = recvPacket['Flags2'], data = SMBCommand['Data'])
+        ntCreateAndXData = smb.SMBNtCreateAndX_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])
 
-        #if ntCreateAndXParameters['CreateFlags'] & 0x10:  # NT_CREATE_REQUEST_EXTENDED_RESPONSE
+        # if ntCreateAndXParameters['CreateFlags'] & 0x10:  # NT_CREATE_REQUEST_EXTENDED_RESPONSE
         #    respParameters        = smb.SMBNtCreateAndXExtendedResponse_Parameters()
         #    respParameters['VolumeGUID'] = '\x00'
 
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
-             # If we have a rootFid, the path is relative to that fid
-             errorCode = STATUS_SUCCESS
-             if ntCreateAndXParameters['RootFid'] > 0:
-                 path = connData['OpenedFiles'][ntCreateAndXParameters['RootFid']]['FileName']
-                 LOG.debug(""RootFid present %s!"" % path)
-             else:
-                 if 'path' in connData['ConnectedShares'][recvPacket['Tid']]:
-                     path = connData['ConnectedShares'][recvPacket['Tid']]['path']
-                 else:
-                     path = 'NONE'
-                     errorCode = STATUS_ACCESS_DENIED
-
-             deleteOnClose = False
-
-             fileName = os.path.normpath(decodeSMBString(recvPacket['Flags2'],ntCreateAndXData['FileName']).replace('\\','/'))
-             if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
+            # If we have a rootFid, the path is relative to that fid
+            errorCode = STATUS_SUCCESS
+            if ntCreateAndXParameters['RootFid'] > 0:
+                path = connData['OpenedFiles'][ntCreateAndXParameters['RootFid']]['FileName']
+                LOG.debug(""RootFid present %s!"" % path)
+            else:
+                if 'path' in connData['ConnectedShares'][recvPacket['Tid']]:
+                    path = connData['ConnectedShares'][recvPacket['Tid']]['path']
+                else:
+                    path = 'NONE'
+                    errorCode = STATUS_ACCESS_DENIED
+
+            deleteOnClose = False
+
+            fileName = os.path.normpath(
+                decodeSMBString(recvPacket['Flags2'], ntCreateAndXData['FileName']).replace('\\', '/'))
+            if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
                 # strip leading '/'
                 fileName = fileName[1:]
-             pathName = os.path.join(path,fileName)
-             createDisposition = ntCreateAndXParameters['Disposition']
-             mode = 0
-
-             if createDisposition == smb.FILE_SUPERSEDE:
-                 mode |= os.O_TRUNC | os.O_CREAT
-             elif createDisposition & smb.FILE_OVERWRITE_IF == smb.FILE_OVERWRITE_IF:
-                 mode |= os.O_TRUNC | os.O_CREAT
-             elif createDisposition & smb.FILE_OVERWRITE == smb.FILE_OVERWRITE:
-                 if os.path.exists(pathName) is True:
-                     mode |= os.O_TRUNC 
-                 else:
-                     errorCode = STATUS_NO_SUCH_FILE
-             elif createDisposition & smb.FILE_OPEN_IF == smb.FILE_OPEN_IF:
-                 if os.path.exists(pathName) is True:
-                     mode |= os.O_TRUNC 
-                 else:
-                     mode |= os.O_TRUNC | os.O_CREAT
-             elif createDisposition & smb.FILE_CREATE == smb.FILE_CREATE:
-                 if os.path.exists(pathName) is True:
-                     errorCode = STATUS_OBJECT_NAME_COLLISION
-                 else:
-                     mode |= os.O_CREAT
-             elif createDisposition & smb.FILE_OPEN == smb.FILE_OPEN:
-                 if os.path.exists(pathName) is not True and (str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:
-                     errorCode = STATUS_NO_SUCH_FILE
-
-             if errorCode == STATUS_SUCCESS:
-                 desiredAccess = ntCreateAndXParameters['AccessMask']
-                 if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):
-                     mode |= os.O_RDONLY
-                 if (desiredAccess & smb.FILE_WRITE_DATA) or (desiredAccess & smb.GENERIC_WRITE):
-                     if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):
-                         mode |= os.O_RDWR #| os.O_APPEND
-                     else: 
-                         mode |= os.O_WRONLY #| os.O_APPEND
-                 if desiredAccess & smb.GENERIC_ALL:
-                     mode |= os.O_RDWR #| os.O_APPEND
-
-                 createOptions =  ntCreateAndXParameters['CreateOptions']
-                 if mode & os.O_CREAT == os.O_CREAT:
-                     if createOptions & smb.FILE_DIRECTORY_FILE == smb.FILE_DIRECTORY_FILE: 
-                         try:
-                             # Let's create the directory
-                             os.mkdir(pathName)
-                             mode = os.O_RDONLY
-                         except Exception as e:
-                             smbServer.log(""NTCreateAndX: %s,%s,%s"" % (pathName,mode,e),logging.ERROR)
-                             errorCode = STATUS_ACCESS_DENIED
-                 if createOptions & smb.FILE_NON_DIRECTORY_FILE == smb.FILE_NON_DIRECTORY_FILE:
-                     # If the file being opened is a directory, the server MUST fail the request with
-                     # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server
-                     # response.
-                     if os.path.isdir(pathName) is True:
+
+            if not isInFileJail(path, fileName):
+                LOG.error(""Path not in current working directory"")
+                respSMBCommand['Parameters'] = b''
+                respSMBCommand['Data'] = b''
+                return [respSMBCommand], None, STATUS_ACCESS_DENIED
+
+            pathName = os.path.join(path, fileName)
+            createDisposition = ntCreateAndXParameters['Disposition']
+            mode = 0
+
+            if createDisposition == smb.FILE_SUPERSEDE:
+                mode |= os.O_TRUNC | os.O_CREAT
+            elif createDisposition & smb.FILE_OVERWRITE_IF == smb.FILE_OVERWRITE_IF:
+                mode |= os.O_TRUNC | os.O_CREAT
+            elif createDisposition & smb.FILE_OVERWRITE == smb.FILE_OVERWRITE:
+                if os.path.exists(pathName) is True:
+                    mode |= os.O_TRUNC
+                else:
+                    errorCode = STATUS_NO_SUCH_FILE
+            elif createDisposition & smb.FILE_OPEN_IF == smb.FILE_OPEN_IF:
+                if os.path.exists(pathName) is True:
+                    mode |= os.O_TRUNC
+                else:
+                    mode |= os.O_TRUNC | os.O_CREAT
+            elif createDisposition & smb.FILE_CREATE == smb.FILE_CREATE:
+                if os.path.exists(pathName) is True:
+                    errorCode = STATUS_OBJECT_NAME_COLLISION
+                else:
+                    mode |= os.O_CREAT
+            elif createDisposition & smb.FILE_OPEN == smb.FILE_OPEN:
+                if os.path.exists(pathName) is not True and (
+                        str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:
+                    errorCode = STATUS_NO_SUCH_FILE
+
+            if errorCode == STATUS_SUCCESS:
+                desiredAccess = ntCreateAndXParameters['AccessMask']
+                if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):
+                    mode |= os.O_RDONLY
+                if (desiredAccess & smb.FILE_WRITE_DATA) or (desiredAccess & smb.GENERIC_WRITE):
+                    if (desiredAccess & smb.FILE_READ_DATA) or (desiredAccess & smb.GENERIC_READ):
+                        mode |= os.O_RDWR  # | os.O_APPEND
+                    else:
+                        mode |= os.O_WRONLY  # | os.O_APPEND
+                if desiredAccess & smb.GENERIC_ALL:
+                    mode |= os.O_RDWR  # | os.O_APPEND
+
+                createOptions = ntCreateAndXParameters['CreateOptions']
+                if mode & os.O_CREAT == os.O_CREAT:
+                    if createOptions & smb.FILE_DIRECTORY_FILE == smb.FILE_DIRECTORY_FILE:
+                        try:
+                            # Let's create the directory
+                            os.mkdir(pathName)
+                            mode = os.O_RDONLY
+                        except Exception as e:
+                            smbServer.log(""NTCreateAndX: %s,%s,%s"" % (pathName, mode, e), logging.ERROR)
+                            errorCode = STATUS_ACCESS_DENIED
+                if createOptions & smb.FILE_NON_DIRECTORY_FILE == smb.FILE_NON_DIRECTORY_FILE:
+                    # If the file being opened is a directory, the server MUST fail the request with
+                    # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server
+                    # response.
+                    if os.path.isdir(pathName) is True:
                         errorCode = STATUS_FILE_IS_A_DIRECTORY
 
-                 if createOptions & smb.FILE_DELETE_ON_CLOSE == smb.FILE_DELETE_ON_CLOSE:
-                     deleteOnClose = True
-                 
-                 if errorCode == STATUS_SUCCESS:
-                     try:
-                         if os.path.isdir(pathName) and sys.platform == 'win32':
+                if createOptions & smb.FILE_DELETE_ON_CLOSE == smb.FILE_DELETE_ON_CLOSE:
+                    deleteOnClose = True
+
+                if errorCode == STATUS_SUCCESS:
+                    try:
+                        if os.path.isdir(pathName) and sys.platform == 'win32':
                             fid = VOID_FILE_DESCRIPTOR
-                         else:
+                        else:
                             if sys.platform == 'win32':
-                               mode |= os.O_BINARY
+                                mode |= os.O_BINARY
                             if str(pathName) in smbServer.getRegisteredNamedPipes():
                                 fid = PIPE_FILE_DESCRIPTOR
                                 sock = socket.socket()
                                 sock.connect(smbServer.getRegisteredNamedPipes()[str(pathName)])
                             else:
                                 fid = os.open(pathName, mode)
-                     except Exception as e:
-                         smbServer.log(""NTCreateAndX: %s,%s,%s"" % (pathName,mode,e),logging.ERROR)
-                         #print e
-                         fid = 0
-                         errorCode = STATUS_ACCESS_DENIED
+                    except Exception as e:
+                        smbServer.log(""NTCreateAndX: %s,%s,%s"" % (pathName, mode, e), logging.ERROR)
+                        # print e
+                        fid = 0
+                        errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_SMB_BAD_TID
 
         if errorCode == STATUS_SUCCESS:
             # Simple way to generate a fid
             if len(connData['OpenedFiles']) == 0:
-               fakefid = 1
+                fakefid = 1
             else:
-               fakefid = list(connData['OpenedFiles'].keys())[-1] + 1
+                fakefid = list(connData['OpenedFiles'].keys())[-1] + 1
             respParameters['Fid'] = fakefid
             respParameters['CreateAction'] = createDisposition
             if fid == PIPE_FILE_DESCRIPTOR:
                 respParameters['FileAttributes'] = 0x80
                 respParameters['IsDirectory'] = 0
-                respParameters['CreateTime']     = 0
+                respParameters['CreateTime'] = 0
                 respParameters['LastAccessTime'] = 0
-                respParameters['LastWriteTime']  = 0
+                respParameters['LastWriteTime'] = 0
                 respParameters['LastChangeTime'] = 0
                 respParameters['AllocationSize'] = 4096
-                respParameters['EndOfFile']      = 0
-                respParameters['FileType']       = 2
-                respParameters['IPCState']       = 0x5ff
+                respParameters['EndOfFile'] = 0
+                respParameters['FileType'] = 2
+                respParameters['IPCState'] = 0x5ff
             else:
                 if os.path.isdir(pathName):
                     respParameters['FileAttributes'] = smb.SMB_FILE_ATTRIBUTE_DIRECTORY
@@ -2116,18 +2151,18 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):
                     respParameters['IsDirectory'] = 0
                     respParameters['FileAttributes'] = ntCreateAndXParameters['FileAttributes']
                 # Let's get this file's information
-                respInfo, errorCode = queryPathInformation('',pathName,level= smb.SMB_QUERY_FILE_ALL_INFO)
+                respInfo, errorCode = queryPathInformation('', pathName, level=smb.SMB_QUERY_FILE_ALL_INFO)
                 if errorCode == STATUS_SUCCESS:
-                    respParameters['CreateTime']     = respInfo['CreationTime']
+                    respParameters['CreateTime'] = respInfo['CreationTime']
                     respParameters['LastAccessTime'] = respInfo['LastAccessTime']
-                    respParameters['LastWriteTime']  = respInfo['LastWriteTime']
+                    respParameters['LastWriteTime'] = respInfo['LastWriteTime']
                     respParameters['LastChangeTime'] = respInfo['LastChangeTime']
                     respParameters['FileAttributes'] = respInfo['ExtFileAttributes']
                     respParameters['AllocationSize'] = respInfo['AllocationSize']
-                    respParameters['EndOfFile']      = respInfo['EndOfFile']
+                    respParameters['EndOfFile'] = respInfo['EndOfFile']
                 else:
                     respParameters = b''
-                    respData       = b''
+                    respData = b''
 
             if errorCode == STATUS_SUCCESS:
                 # Let's store the fid for the connection
@@ -2135,15 +2170,15 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):
                 connData['OpenedFiles'][fakefid] = {}
                 connData['OpenedFiles'][fakefid]['FileHandle'] = fid
                 connData['OpenedFiles'][fakefid]['FileName'] = pathName
-                connData['OpenedFiles'][fakefid]['DeleteOnClose']  = deleteOnClose
+                connData['OpenedFiles'][fakefid]['DeleteOnClose'] = deleteOnClose
                 if fid == PIPE_FILE_DESCRIPTOR:
                     connData['OpenedFiles'][fakefid]['Socket'] = sock
         else:
             respParameters = b''
-            respData       = b''
-        
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+            respData = b''
+
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
@@ -2152,31 +2187,32 @@ def smbComNtCreateAndX(connId, smbServer, SMBCommand, recvPacket):
     def smbComOpenAndX(connId, smbServer, SMBCommand, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_OPEN_ANDX)
-        respParameters        = smb.SMBOpenAndXResponse_Parameters()
-        respData              = b''
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_OPEN_ANDX)
+        respParameters = smb.SMBOpenAndXResponse_Parameters()
+        respData = b''
 
         openAndXParameters = smb.SMBOpenAndX_Parameters(SMBCommand['Parameters'])
-        openAndXData       = smb.SMBOpenAndX_Data( flags = recvPacket['Flags2'], data = SMBCommand['Data'])
+        openAndXData = smb.SMBOpenAndX_Data(flags=recvPacket['Flags2'], data=SMBCommand['Data'])
 
         # Get the Tid associated
         if recvPacket['Tid'] in connData['ConnectedShares']:
-             path = connData['ConnectedShares'][recvPacket['Tid']]['path']
-             openedFile, mode, pathName, errorCode = openFile(path,
-                     decodeSMBString(recvPacket['Flags2'],openAndXData['FileName']), 
-                     openAndXParameters['DesiredAccess'], 
-                     openAndXParameters['FileAttributes'], 
-                     openAndXParameters['OpenMode'])
+            path = connData['ConnectedShares'][recvPacket['Tid']]['path']
+            openedFile, mode, pathName, errorCode = openFile(path,
+                                                             decodeSMBString(recvPacket['Flags2'],
+                                                                             openAndXData['FileName']),
+                                                             openAndXParameters['DesiredAccess'],
+                                                             openAndXParameters['FileAttributes'],
+                                                             openAndXParameters['OpenMode'])
         else:
-           errorCode = STATUS_SMB_BAD_TID
+            errorCode = STATUS_SMB_BAD_TID
 
         if errorCode == STATUS_SUCCESS:
             # Simple way to generate a fid
-            fid = len(connData['OpenedFiles']) + 1 
+            fid = len(connData['OpenedFiles']) + 1
             if len(connData['OpenedFiles']) == 0:
-               fid = 1
+                fid = 1
             else:
-               fid = list(connData['OpenedFiles'].keys())[-1] + 1
+                fid = list(connData['OpenedFiles'].keys())[-1] + 1
             respParameters['Fid'] = fid
             if mode & os.O_CREAT:
                 # File did not exist and was created
@@ -2190,19 +2226,19 @@ def smbComOpenAndX(connId, smbServer, SMBCommand, recvPacket):
             else:
                 # File existed and was truncated
                 respParameters['Action'] = 0x3
-            
+
             # Let's store the fid for the connection
-            #smbServer.log('Opening file %s' % pathName)
+            # smbServer.log('Opening file %s' % pathName)
             connData['OpenedFiles'][fid] = {}
             connData['OpenedFiles'][fid]['FileHandle'] = openedFile
             connData['OpenedFiles'][fid]['FileName'] = pathName
-            connData['OpenedFiles'][fid]['DeleteOnClose']  = False
+            connData['OpenedFiles'][fid]['DeleteOnClose'] = False
         else:
             respParameters = b''
-            respData       = b''
-        
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+            respData = b''
+
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
@@ -2213,22 +2249,23 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):
 
         resp = smb.NewSMBPacket()
         resp['Flags1'] = smb.SMB.FLAGS1_REPLY
-        resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | recvPacket['Flags2'] & smb.SMB.FLAGS2_UNICODE
+        resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | \
+                         recvPacket['Flags2'] & smb.SMB.FLAGS2_UNICODE
 
         resp['Tid'] = recvPacket['Tid']
         resp['Mid'] = recvPacket['Mid']
         resp['Pid'] = connData['Pid']
 
-        respSMBCommand        = smb.SMBCommand(smb.SMB.SMB_COM_TREE_CONNECT_ANDX)
-        respParameters        = smb.SMBTreeConnectAndXResponse_Parameters()
-        respData              = smb.SMBTreeConnectAndXResponse_Data()
+        respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_TREE_CONNECT_ANDX)
+        respParameters = smb.SMBTreeConnectAndXResponse_Parameters()
+        respData = smb.SMBTreeConnectAndXResponse_Data()
 
         treeConnectAndXParameters = smb.SMBTreeConnectAndX_Parameters(SMBCommand['Parameters'])
 
         if treeConnectAndXParameters['Flags'] & 0x8:
-            respParameters        = smb.SMBTreeConnectAndXExtendedResponse_Parameters()
+            respParameters = smb.SMBTreeConnectAndXExtendedResponse_Parameters()
 
-        treeConnectAndXData                    = smb.SMBTreeConnectAndX_Data( flags = recvPacket['Flags2'] )
+        treeConnectAndXData = smb.SMBTreeConnectAndX_Data(flags=recvPacket['Flags2'])
         treeConnectAndXData['_PasswordLength'] = treeConnectAndXParameters['PasswordLength']
         treeConnectAndXData.fromString(SMBCommand['Data'])
 
@@ -2243,34 +2280,34 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):
         else:
             path = ntpath.basename(UNCOrShare)
 
-        share = searchShare(connId, path, smbServer) 
+        share = searchShare(connId, path, smbServer)
         if share is not None:
             # Simple way to generate a Tid
             if len(connData['ConnectedShares']) == 0:
-               tid = 1
+                tid = 1
             else:
-               tid = list(connData['ConnectedShares'].keys())[-1] + 1
+                tid = list(connData['ConnectedShares'].keys())[-1] + 1
             connData['ConnectedShares'][tid] = share
             connData['ConnectedShares'][tid]['shareName'] = path
             resp['Tid'] = tid
-            #smbServer.log(""Connecting Share(%d:%s)"" % (tid,path))
+            # smbServer.log(""Connecting Share(%d:%s)"" % (tid,path))
         else:
             smbServer.log(""TreeConnectAndX not found %s"" % path, logging.ERROR)
             errorCode = STATUS_OBJECT_PATH_NOT_FOUND
-            resp['ErrorCode']   = errorCode >> 16
-            resp['ErrorClass']  = errorCode & 0xff
+            resp['ErrorCode'] = errorCode >> 16
+            resp['ErrorClass'] = errorCode & 0xff
         ##
         respParameters['OptionalSupport'] = smb.SMB.SMB_SUPPORT_SEARCH_BITS
 
         if path == 'IPC$':
-            respData['Service']               = 'IPC'
+            respData['Service'] = 'IPC'
         else:
-            respData['Service']               = path
-        respData['PadLen']                = 0
-        respData['NativeFileSystem']      = encodeSMBString(recvPacket['Flags2'], 'NTFS' ).decode()
+            respData['Service'] = path
+        respData['PadLen'] = 0
+        respData['NativeFileSystem'] = encodeSMBString(recvPacket['Flags2'], 'NTFS').decode()
 
-        respSMBCommand['Parameters']             = respParameters
-        respSMBCommand['Data']                   = respData 
+        respSMBCommand['Parameters'] = respParameters
+        respSMBCommand['Data'] = respData
 
         resp['Uid'] = connData['Uid']
         resp.addCommand(respSMBCommand)
@@ -2284,19 +2321,19 @@ def smbComTreeConnectAndX(connId, smbServer, SMBCommand, recvPacket):
 
     @staticmethod
     def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
-        connData = smbServer.getConnectionData(connId, checkStatus = False)
+        connData = smbServer.getConnectionData(connId, checkStatus=False)
 
         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_SESSION_SETUP_ANDX)
 
         # From [MS-SMB]
-        # When extended security is being used (see section 3.2.4.2.4), the 
+        # When extended security is being used (see section 3.2.4.2.4), the
         # request MUST take the following form
         # [..]
         # WordCount (1 byte): The value of this field MUST be 0x0C.
         if SMBCommand['WordCount'] == 12:
             # Extended security. Here we deal with all SPNEGO stuff
             respParameters = smb.SMBSessionSetupAndX_Extended_Response_Parameters()
-            respData       = smb.SMBSessionSetupAndX_Extended_Response_Data(flags = recvPacket['Flags2'])
+            respData = smb.SMBSessionSetupAndX_Extended_Response_Data(flags=recvPacket['Flags2'])
             sessionSetupParameters = smb.SMBSessionSetupAndX_Extended_Parameters(SMBCommand['Parameters'])
             sessionSetupData = smb.SMBSessionSetupAndX_Extended_Data()
             sessionSetupData['SecurityBlobLength'] = sessionSetupParameters['SecurityBlobLength']
@@ -2304,45 +2341,45 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
             connData['Capabilities'] = sessionSetupParameters['Capabilities']
 
             rawNTLM = False
-            if struct.unpack('B',sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_AID:
-               # NEGOTIATE packet
-               blob =  SPNEGO_NegTokenInit(sessionSetupData['SecurityBlob'])
-               token = blob['MechToken']
-               if len(blob['MechTypes'][0]) > 0:
-                   # Is this GSSAPI NTLM or something else we don't support?
-                   mechType = blob['MechTypes'][0]
-                   if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:
-                       # Nope, do we know it?
-                       if mechType in MechTypes:
-                           mechStr = MechTypes[mechType]
-                       else:
-                           mechStr = hexlify(mechType)
-                       smbServer.log(""Unsupported MechType '%s'"" % mechStr, logging.CRITICAL)
-                       # We don't know the token, we answer back again saying 
-                       # we just support NTLM.
-                       # ToDo: Build this into a SPNEGO_NegTokenResp()
-                       respToken = b'\xa1\x15\x30\x13\xa0\x03\x0a\x01\x03\xa1\x0c\x06\x0a\x2b\x06\x01\x04\x01\x82\x37\x02\x02\x0a'
-                       respParameters['SecurityBlobLength'] = len(respToken)
-                       respData['SecurityBlobLength'] = respParameters['SecurityBlobLength'] 
-                       respData['SecurityBlob']       = respToken
-                       respData['NativeOS']     = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())
-                       respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())
-                       respSMBCommand['Parameters'] = respParameters
-                       respSMBCommand['Data']       = respData 
-                       return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED
-
-            elif struct.unpack('B',sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_SUPPORTED_MECH:
-               # AUTH packet
-               blob = SPNEGO_NegTokenResp(sessionSetupData['SecurityBlob'])
-               token = blob['ResponseToken']
+            if struct.unpack('B', sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_AID:
+                # NEGOTIATE packet
+                blob = SPNEGO_NegTokenInit(sessionSetupData['SecurityBlob'])
+                token = blob['MechToken']
+                if len(blob['MechTypes'][0]) > 0:
+                    # Is this GSSAPI NTLM or something else we don't support?
+                    mechType = blob['MechTypes'][0]
+                    if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:
+                        # Nope, do we know it?
+                        if mechType in MechTypes:
+                            mechStr = MechTypes[mechType]
+                        else:
+                            mechStr = hexlify(mechType)
+                        smbServer.log(""Unsupported MechType '%s'"" % mechStr, logging.CRITICAL)
+                        # We don't know the token, we answer back again saying
+                        # we just support NTLM.
+                        # ToDo: Build this into a SPNEGO_NegTokenResp()
+                        respToken = b'\xa1\x15\x30\x13\xa0\x03\x0a\x01\x03\xa1\x0c\x06\x0a\x2b\x06\x01\x04\x01\x82\x37\x02\x02\x0a'
+                        respParameters['SecurityBlobLength'] = len(respToken)
+                        respData['SecurityBlobLength'] = respParameters['SecurityBlobLength']
+                        respData['SecurityBlob'] = respToken
+                        respData['NativeOS'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())
+                        respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())
+                        respSMBCommand['Parameters'] = respParameters
+                        respSMBCommand['Data'] = respData
+                        return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED
+
+            elif struct.unpack('B', sessionSetupData['SecurityBlob'][0:1])[0] == ASN1_SUPPORTED_MECH:
+                # AUTH packet
+                blob = SPNEGO_NegTokenResp(sessionSetupData['SecurityBlob'])
+                token = blob['ResponseToken']
             else:
-               # No GSSAPI stuff, raw NTLMSSP
-               rawNTLM = True
-               token = sessionSetupData['SecurityBlob']
+                # No GSSAPI stuff, raw NTLMSSP
+                rawNTLM = True
+                token = sessionSetupData['SecurityBlob']
 
-            # Here we only handle NTLMSSP, depending on what stage of the 
+            # Here we only handle NTLMSSP, depending on what stage of the
             # authentication we are, we act on it
-            messageType = struct.unpack('<L',token[len('NTLMSSP\x00'):len('NTLMSSP\x00')+4])[0]
+            messageType = struct.unpack('<L', token[len('NTLMSSP\x00'):len('NTLMSSP\x00') + 4])[0]
 
             if messageType == 0x01:
                 # NEGOTIATE_MESSAGE
@@ -2351,45 +2388,48 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
                 # Let's store it in the connection data
                 connData['NEGOTIATE_MESSAGE'] = negotiateMessage
                 # Let's build the answer flags
-                # TODO: Parse all the flags. With this we're leaving some clients out 
+                # TODO: Parse all the flags. With this we're leaving some clients out
 
                 ansFlags = 0
 
                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_56:
-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56
+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56
                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_128:
-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128
+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128
                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:
-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH
+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH
                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY:
-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY
+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY
                 if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_UNICODE:
-                   ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE
+                    ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE
                 if negotiateMessage['flags'] & ntlm.NTLM_NEGOTIATE_OEM:
-                   ansFlags |= ntlm.NTLM_NEGOTIATE_OEM
+                    ansFlags |= ntlm.NTLM_NEGOTIATE_OEM
 
                 ansFlags |= ntlm.NTLMSSP_NEGOTIATE_VERSION | ntlm.NTLMSSP_NEGOTIATE_TARGET_INFO | ntlm.NTLMSSP_TARGET_TYPE_SERVER | ntlm.NTLMSSP_NEGOTIATE_NTLM | ntlm.NTLMSSP_REQUEST_TARGET
 
                 # Generate the AV_PAIRS
                 av_pairs = ntlm.AV_PAIRS()
                 # TODO: Put the proper data from SMBSERVER config
-                av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')
-                av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')
-                av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (116444736000000000 + calendar.timegm(time.gmtime()) * 10000000) )
+                av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[
+                    ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')
+                av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[
+                    ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')
+                av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (
+                            116444736000000000 + calendar.timegm(time.gmtime()) * 10000000))
 
                 challengeMessage = ntlm.NTLMAuthChallenge()
-                challengeMessage['flags']            = ansFlags
-                challengeMessage['domain_len']       = len(smbServer.getServerDomain().encode('utf-16le'))
-                challengeMessage['domain_max_len']   = challengeMessage['domain_len']
-                challengeMessage['domain_offset']    = 40 + 16
-                challengeMessage['challenge']        = smbServer.getSMBChallenge()
-                challengeMessage['domain_name']      = smbServer.getServerDomain().encode('utf-16le')
-                challengeMessage['TargetInfoFields_len']     = len(av_pairs)
+                challengeMessage['flags'] = ansFlags
+                challengeMessage['domain_len'] = len(smbServer.getServerDomain().encode('utf-16le'))
+                challengeMessage['domain_max_len'] = challengeMessage['domain_len']
+                challengeMessage['domain_offset'] = 40 + 16
+                challengeMessage['challenge'] = smbServer.getSMBChallenge()
+                challengeMessage['domain_name'] = smbServer.getServerDomain().encode('utf-16le')
+                challengeMessage['TargetInfoFields_len'] = len(av_pairs)
                 challengeMessage['TargetInfoFields_max_len'] = len(av_pairs)
                 challengeMessage['TargetInfoFields'] = av_pairs
-                challengeMessage['TargetInfoFields_offset']  = 40 + 16 + len(challengeMessage['domain_name'])
-                challengeMessage['Version']          = b'\xff'*8
-                challengeMessage['VersionLen']       = 8
+                challengeMessage['TargetInfoFields_offset'] = 40 + 16 + len(challengeMessage['domain_name'])
+                challengeMessage['Version'] = b'\xff' * 8
+                challengeMessage['VersionLen'] = 8
 
                 if rawNTLM is False:
                     respToken = SPNEGO_NegTokenResp()
@@ -2403,7 +2443,7 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
 
                 # Setting the packet to STATUS_MORE_PROCESSING
                 errorCode = STATUS_MORE_PROCESSING_REQUIRED
-                # Let's set up an UID for this connection and store it 
+                # Let's set up an UID for this connection and store it
                 # in the connection's data
                 # Picking a fixed value
                 # TODO: Manage more UIDs for the same session
@@ -2419,9 +2459,9 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
                 authenticateMessage = ntlm.NTLMAuthChallengeResponse()
                 authenticateMessage.fromString(token)
                 smbServer.log(""AUTHENTICATE_MESSAGE (%s\\%s,%s)"" % (
-                authenticateMessage['domain_name'].decode('utf-16le'),
-                authenticateMessage['user_name'].decode('utf-16le'),
-                authenticateMessage['host_name'].decode('utf-16le')))
+                    authenticateMessage['domain_name'].decode('utf-16le'),
+                    authenticateMessage['user_name'].decode('utf-16le'),
+                    authenticateMessage['host_name'].decode('utf-16le')))
                 # Do we have credentials to check?
                 if len(smbServer.getCredentials()) > 0:
                     identity = authenticateMessage['user_name'].decode('utf-16le').lower()
@@ -2432,7 +2472,8 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
                         uid, lmhash, nthash = smbServer.getCredentials()[identity]
 
                         errorCode, sessionKey = computeNTLMv2(identity, lmhash, nthash, smbServer.getSMBChallenge(),
-                                             authenticateMessage, connData['CHALLENGE_MESSAGE'], connData['NEGOTIATE_MESSAGE'])
+                                                              authenticateMessage, connData['CHALLENGE_MESSAGE'],
+                                                              connData['NEGOTIATE_MESSAGE'])
 
                         if sessionKey is not None:
                             connData['SignatureEnabled'] = False
@@ -2450,8 +2491,10 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
                     # accept-completed
                     respToken['NegState'] = b'\x00'
 
-                    smbServer.log('User %s\\%s authenticated successfully' % (authenticateMessage['host_name'].decode('utf-16le'),
-                                                                              authenticateMessage['user_name'].decode('utf-16le')))
+                    smbServer.log(
+                        'User %s\\%s authenticated successfully' % (authenticateMessage['host_name'].decode('utf-16le'),
+                                                                    authenticateMessage['user_name'].decode(
+                                                                        'utf-16le')))
                     # Let's store it in the connection data
                     connData['AUTHENTICATE_MESSAGE'] = authenticateMessage
                     try:
@@ -2462,7 +2505,8 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
                                                             authenticateMessage['lanman'], authenticateMessage['ntlm'])
                         smbServer.log(ntlm_hash_data['hash_string'])
                         if jtr_dump_path != '':
-                            writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'], jtr_dump_path)
+                            writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'],
+                                                  jtr_dump_path)
                     except:
                         smbServer.log(""Could not write NTLM Hashes to the specified JTR_Dump_Path %s"" % jtr_dump_path)
                 else:
@@ -2473,13 +2517,13 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
                 raise Exception(""Unknown NTLMSSP MessageType %d"" % messageType)
 
             respParameters['SecurityBlobLength'] = len(respToken)
-            respData['SecurityBlobLength'] = respParameters['SecurityBlobLength'] 
-            respData['SecurityBlob']       = respToken.getData()
+            respData['SecurityBlobLength'] = respParameters['SecurityBlobLength']
+            respData['SecurityBlob'] = respToken.getData()
 
         else:
             # Process Standard Security
             respParameters = smb.SMBSessionSetupAndXResponse_Parameters()
-            respData       = smb.SMBSessionSetupAndXResponse_Data()
+            respData = smb.SMBSessionSetupAndXResponse_Data()
             sessionSetupParameters = smb.SMBSessionSetupAndX_Parameters(SMBCommand['Parameters'])
             sessionSetupData = smb.SMBSessionSetupAndX_Data()
             sessionSetupData['AnsiPwdLength'] = sessionSetupParameters['AnsiPwdLength']
@@ -2492,38 +2536,41 @@ def smbComSessionSetupAndX(connId, smbServer, SMBCommand, recvPacket):
             connData['Uid'] = 10
             connData['Authenticated'] = True
             respParameters['Action'] = 0
-            smbServer.log('User %s\\%s authenticated successfully (basic)' % (sessionSetupData['PrimaryDomain'], sessionSetupData['Account']))
+            smbServer.log('User %s\\%s authenticated successfully (basic)' % (
+            sessionSetupData['PrimaryDomain'], sessionSetupData['Account']))
             try:
                 jtr_dump_path = smbServer.getJTRdumpPath()
-                ntlm_hash_data = outputToJohnFormat( b'', b(sessionSetupData['Account']), b(sessionSetupData['PrimaryDomain']), sessionSetupData['AnsiPwd'], sessionSetupData['UnicodePwd'] )
+                ntlm_hash_data = outputToJohnFormat(b'', b(sessionSetupData['Account']),
+                                                    b(sessionSetupData['PrimaryDomain']), sessionSetupData['AnsiPwd'],
+                                                    sessionSetupData['UnicodePwd'])
                 smbServer.log(ntlm_hash_data['hash_string'])
                 if jtr_dump_path != '':
                     writeJohnOutputToFile(ntlm_hash_data['hash_string'], ntlm_hash_data['hash_version'], jtr_dump_path)
             except:
                 smbServer.log(""Could not write NTLM Hashes to the specified JTR_Dump_Path %s"" % jtr_dump_path)
 
-        respData['NativeOS']     = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())
+        respData['NativeOS'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())
         respData['NativeLanMan'] = encodeSMBString(recvPacket['Flags2'], smbServer.getServerOS())
         respSMBCommand['Parameters'] = respParameters
-        respSMBCommand['Data']       = respData 
+        respSMBCommand['Data'] = respData
 
         # From now on, the client can ask for other commands
         connData['Authenticated'] = True
         # For now, just switching to nobody
-        #os.setregid(65534,65534)
-        #os.setreuid(65534,65534)
+        # os.setregid(65534,65534)
+        # os.setreuid(65534,65534)
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
 
     @staticmethod
-    def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket ):
-        connData = smbServer.getConnectionData(connId, checkStatus = False)
+    def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket):
+        connData = smbServer.getConnectionData(connId, checkStatus=False)
         connData['Pid'] = recvPacket['Pid']
 
         SMBCommand = smb.SMBCommand(recvPacket['Data'][0])
         respSMBCommand = smb.SMBCommand(smb.SMB.SMB_COM_NEGOTIATE)
-        
+
         resp = smb.NewSMBPacket()
         resp['Flags1'] = smb.SMB.FLAGS1_REPLY
         resp['Pid'] = connData['Pid']
@@ -2532,108 +2579,107 @@ def smbComNegotiate(connId, smbServer, SMBCommand, recvPacket ):
 
         # TODO: We support more dialects, and parse them accordingly
         dialects = SMBCommand['Data'].split(b'\x02')
-        try: 
-           index = dialects.index(b'NT LM 0.12\x00') - 1
-           # Let's fill the data for NTLM
-           if recvPacket['Flags2'] & smb.SMB.FLAGS2_EXTENDED_SECURITY:
-                    resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE
-                    #resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS 
-                    _dialects_data = smb.SMBExtended_Security_Data()
-                    _dialects_data['ServerGUID'] = b'A'*16
-                    blob = SPNEGO_NegTokenInit()
-                    blob['MechTypes'] = [TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']]
-                    _dialects_data['SecurityBlob'] = blob.getData()
-        
-                    _dialects_parameters = smb.SMBExtended_Security_Parameters()
-                    _dialects_parameters['Capabilities']    = smb.SMB.CAP_EXTENDED_SECURITY | smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS | smb.SMB.CAP_UNICODE 
-                    _dialects_parameters['ChallengeLength'] = 0
-
-           else:
-                    resp['Flags2'] = smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE
-                    _dialects_parameters = smb.SMBNTLMDialect_Parameters()
-                    _dialects_data= smb.SMBNTLMDialect_Data()
-                    _dialects_data['Payload'] = ''
-                    if 'EncryptionKey' in connData:
-                        _dialects_data['Challenge'] = connData['EncryptionKey']
-                        _dialects_parameters['ChallengeLength'] = len(_dialects_data.getData())
-                    else:
-                        # TODO: Handle random challenges, now one that can be used with rainbow tables
-                        _dialects_data['Challenge'] = b'\x11\x22\x33\x44\x55\x66\x77\x88'
-                        _dialects_parameters['ChallengeLength'] = 8
-                    _dialects_parameters['Capabilities']    = smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS 
-
-           # Let's see if we need to support RPC_REMOTE_APIS
-           config = smbServer.getServerConfig()
-           if config.has_option('global','rpc_apis'):
-               if config.getboolean('global', 'rpc_apis') is True:
-                  _dialects_parameters['Capabilities'] |= smb.SMB.CAP_RPC_REMOTE_APIS
-
-           _dialects_parameters['DialectIndex']    = index
-           #_dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER | smb.SMB.SECURITY_SIGNATURES_REQUIRED
-           _dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER
-           _dialects_parameters['MaxMpxCount']     = 1
-           _dialects_parameters['MaxNumberVcs']    = 1
-           _dialects_parameters['MaxBufferSize']   = 64000
-           _dialects_parameters['MaxRawSize']      = 65536
-           _dialects_parameters['SessionKey']      = 0
-           _dialects_parameters['LowDateTime']     = 0
-           _dialects_parameters['HighDateTime']    = 0
-           _dialects_parameters['ServerTimeZone']  = 0 
-
-
-           respSMBCommand['Data']           = _dialects_data
-           respSMBCommand['Parameters']     = _dialects_parameters
-           connData['_dialects_data']       = _dialects_data
-           connData['_dialects_parameters'] = _dialects_parameters
+        try:
+            index = dialects.index(b'NT LM 0.12\x00') - 1
+            # Let's fill the data for NTLM
+            if recvPacket['Flags2'] & smb.SMB.FLAGS2_EXTENDED_SECURITY:
+                resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE
+                # resp['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS
+                _dialects_data = smb.SMBExtended_Security_Data()
+                _dialects_data['ServerGUID'] = b'A' * 16
+                blob = SPNEGO_NegTokenInit()
+                blob['MechTypes'] = [TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']]
+                _dialects_data['SecurityBlob'] = blob.getData()
+
+                _dialects_parameters = smb.SMBExtended_Security_Parameters()
+                _dialects_parameters[
+                    'Capabilities'] = smb.SMB.CAP_EXTENDED_SECURITY | smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS | smb.SMB.CAP_UNICODE
+                _dialects_parameters['ChallengeLength'] = 0
+
+            else:
+                resp['Flags2'] = smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_UNICODE
+                _dialects_parameters = smb.SMBNTLMDialect_Parameters()
+                _dialects_data = smb.SMBNTLMDialect_Data()
+                _dialects_data['Payload'] = ''
+                if 'EncryptionKey' in connData:
+                    _dialects_data['Challenge'] = connData['EncryptionKey']
+                    _dialects_parameters['ChallengeLength'] = len(_dialects_data.getData())
+                else:
+                    # TODO: Handle random challenges, now one that can be used with rainbow tables
+                    _dialects_data['Challenge'] = b'\x11\x22\x33\x44\x55\x66\x77\x88'
+                    _dialects_parameters['ChallengeLength'] = 8
+                _dialects_parameters['Capabilities'] = smb.SMB.CAP_USE_NT_ERRORS | smb.SMB.CAP_NT_SMBS
+
+                # Let's see if we need to support RPC_REMOTE_APIS
+            config = smbServer.getServerConfig()
+            if config.has_option('global', 'rpc_apis'):
+                if config.getboolean('global', 'rpc_apis') is True:
+                    _dialects_parameters['Capabilities'] |= smb.SMB.CAP_RPC_REMOTE_APIS
+
+            _dialects_parameters['DialectIndex'] = index
+            # _dialects_parameters['SecurityMode']    = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER | smb.SMB.SECURITY_SIGNATURES_REQUIRED
+            _dialects_parameters['SecurityMode'] = smb.SMB.SECURITY_AUTH_ENCRYPTED | smb.SMB.SECURITY_SHARE_USER
+            _dialects_parameters['MaxMpxCount'] = 1
+            _dialects_parameters['MaxNumberVcs'] = 1
+            _dialects_parameters['MaxBufferSize'] = 64000
+            _dialects_parameters['MaxRawSize'] = 65536
+            _dialects_parameters['SessionKey'] = 0
+            _dialects_parameters['LowDateTime'] = 0
+            _dialects_parameters['HighDateTime'] = 0
+            _dialects_parameters['ServerTimeZone'] = 0
+
+            respSMBCommand['Data'] = _dialects_data
+            respSMBCommand['Parameters'] = _dialects_parameters
+            connData['_dialects_data'] = _dialects_data
+            connData['_dialects_parameters'] = _dialects_parameters
 
         except Exception as e:
-           # No NTLM throw an error
-           smbServer.log('smbComNegotiate: %s' % e, logging.ERROR)
-           respSMBCommand['Data'] = struct.pack('<H',0xffff) 
+            # No NTLM throw an error
+            smbServer.log('smbComNegotiate: %s' % e, logging.ERROR)
+            respSMBCommand['Data'] = struct.pack('<H', 0xffff)
 
-       
         smbServer.setConnectionData(connId, connData)
 
         resp.addCommand(respSMBCommand)
-        
+
         return None, [resp], STATUS_SUCCESS
 
     @staticmethod
     def default(connId, smbServer, SMBCommand, recvPacket):
         # By default we return an SMB Packet with error not implemented
-        smbServer.log(""Not implemented command: 0x%x"" % recvPacket['Command'],logging.DEBUG)
+        smbServer.log(""Not implemented command: 0x%x"" % recvPacket['Command'], logging.DEBUG)
         packet = smb.NewSMBPacket()
-        packet['Flags1']  = smb.SMB.FLAGS1_REPLY
-        packet['Flags2']  = smb.SMB.FLAGS2_NT_STATUS 
+        packet['Flags1'] = smb.SMB.FLAGS1_REPLY
+        packet['Flags2'] = smb.SMB.FLAGS2_NT_STATUS
         packet['Command'] = recvPacket['Command']
-        packet['Pid']     = recvPacket['Pid']
-        packet['Tid']     = recvPacket['Tid']
-        packet['Mid']     = recvPacket['Mid']
-        packet['Uid']     = recvPacket['Uid']
-        packet['Data']    = b'\x00\x00\x00'
+        packet['Pid'] = recvPacket['Pid']
+        packet['Tid'] = recvPacket['Tid']
+        packet['Mid'] = recvPacket['Mid']
+        packet['Uid'] = recvPacket['Uid']
+        packet['Data'] = b'\x00\x00\x00'
         errorCode = STATUS_NOT_IMPLEMENTED
-        packet['ErrorCode']   = errorCode >> 16
-        packet['ErrorClass']  = errorCode & 0xff
+        packet['ErrorCode'] = errorCode >> 16
+        packet['ErrorClass'] = errorCode & 0xff
 
         return None, [packet], errorCode
 
+
 class SMB2Commands:
     @staticmethod
-    def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):
-        connData = smbServer.getConnectionData(connId, checkStatus = False)
+    def smb2Negotiate(connId, smbServer, recvPacket, isSMB1=False):
+        connData = smbServer.getConnectionData(connId, checkStatus=False)
 
         respPacket = smb2.SMB2Packet()
-        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR
-        respPacket['Status']    = STATUS_SUCCESS
+        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR
+        respPacket['Status'] = STATUS_SUCCESS
         respPacket['CreditRequestResponse'] = 1
-        respPacket['Command']   = smb2.SMB2_NEGOTIATE
+        respPacket['Command'] = smb2.SMB2_NEGOTIATE
         respPacket['SessionID'] = 0
         if isSMB1 is False:
             respPacket['MessageID'] = recvPacket['MessageID']
         else:
             respPacket['MessageID'] = 0
-        respPacket['TreeID']    = 0
-
+        respPacket['TreeID'] = 0
 
         respSMBCommand = smb2.SMB2Negotiate_Response()
 
@@ -2641,7 +2687,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):
         if isSMB1 is True:
             # Let's first parse the packet to see if the client supports SMB2
             SMBCommand = smb.SMBCommand(recvPacket['Data'][0])
-        
+
             dialects = SMBCommand['Data'].split(b'\x02')
             if b'SMB 2.002\x00' in dialects or b'SMB 2.???\x00' in dialects:
                 respSMBCommand['DialectRevision'] = smb2.SMB2_DIALECT_002
@@ -2650,7 +2696,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):
                 raise Exception('SMB2 not supported, fallbacking')
         else:
             respSMBCommand['DialectRevision'] = smb2.SMB2_DIALECT_002
-        respSMBCommand['ServerGuid'] = b'A'*16
+        respSMBCommand['ServerGuid'] = b'A' * 16
         respSMBCommand['Capabilities'] = 0
         respSMBCommand['MaxTransactSize'] = 65536
         respSMBCommand['MaxReadSize'] = 65536
@@ -2665,7 +2711,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):
         respSMBCommand['Buffer'] = blob.getData()
         respSMBCommand['SecurityBufferLength'] = len(respSMBCommand['Buffer'])
 
-        respPacket['Data']      = respSMBCommand
+        respPacket['Data'] = respSMBCommand
 
         smbServer.setConnectionData(connId, connData)
 
@@ -2673,7 +2719,7 @@ def smb2Negotiate(connId, smbServer, recvPacket, isSMB1 = False):
 
     @staticmethod
     def smb2SessionSetup(connId, smbServer, recvPacket):
-        connData = smbServer.getConnectionData(connId, checkStatus = False)
+        connData = smbServer.getConnectionData(connId, checkStatus=False)
 
         respSMBCommand = smb2.SMB2SessionSetup_Response()
 
@@ -2684,41 +2730,41 @@ def smb2SessionSetup(connId, smbServer, recvPacket):
         securityBlob = sessionSetupData['Buffer']
 
         rawNTLM = False
-        if struct.unpack('B',securityBlob[0:1])[0] == ASN1_AID:
-           # NEGOTIATE packet
-           blob =  SPNEGO_NegTokenInit(securityBlob)
-           token = blob['MechToken']
-           if len(blob['MechTypes'][0]) > 0:
-               # Is this GSSAPI NTLM or something else we don't support?
-               mechType = blob['MechTypes'][0]
-               if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:
-                   # Nope, do we know it?
-                   if mechType in MechTypes:
-                       mechStr = MechTypes[mechType]
-                   else:
-                       mechStr = hexlify(mechType)
-                   smbServer.log(""Unsupported MechType '%s'"" % mechStr, logging.CRITICAL)
-                   # We don't know the token, we answer back again saying 
-                   # we just support NTLM.
-                   # ToDo: Build this into a SPNEGO_NegTokenResp()
-                   respToken = b'\xa1\x15\x30\x13\xa0\x03\x0a\x01\x03\xa1\x0c\x06\x0a\x2b\x06\x01\x04\x01\x82\x37\x02\x02\x0a'
-                   respSMBCommand['SecurityBufferOffset'] = 0x48
-                   respSMBCommand['SecurityBufferLength'] = len(respToken)
-                   respSMBCommand['Buffer'] = respToken
-
-                   return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED
-        elif struct.unpack('B',securityBlob[0:1])[0] == ASN1_SUPPORTED_MECH:
-           # AUTH packet
-           blob = SPNEGO_NegTokenResp(securityBlob)
-           token = blob['ResponseToken']
+        if struct.unpack('B', securityBlob[0:1])[0] == ASN1_AID:
+            # NEGOTIATE packet
+            blob = SPNEGO_NegTokenInit(securityBlob)
+            token = blob['MechToken']
+            if len(blob['MechTypes'][0]) > 0:
+                # Is this GSSAPI NTLM or something else we don't support?
+                mechType = blob['MechTypes'][0]
+                if mechType != TypesMech['NTLMSSP - Microsoft NTLM Security Support Provider']:
+                    # Nope, do we know it?
+                    if mechType in MechTypes:
+                        mechStr = MechTypes[mechType]
+                    else:
+                        mechStr = hexlify(mechType)
+                    smbServer.log(""Unsupported MechType '%s'"" % mechStr, logging.CRITICAL)
+                    # We don't know the token, we answer back again saying
+                    # we just support NTLM.
+                    # ToDo: Build this into a SPNEGO_NegTokenResp()
+                    respToken = b'\xa1\x15\x30\x13\xa0\x03\x0a\x01\x03\xa1\x0c\x06\x0a\x2b\x06\x01\x04\x01\x82\x37\x02\x02\x0a'
+                    respSMBCommand['SecurityBufferOffset'] = 0x48
+                    respSMBCommand['SecurityBufferLength'] = len(respToken)
+                    respSMBCommand['Buffer'] = respToken
+
+                    return [respSMBCommand], None, STATUS_MORE_PROCESSING_REQUIRED
+        elif struct.unpack('B', securityBlob[0:1])[0] == ASN1_SUPPORTED_MECH:
+            # AUTH packet
+            blob = SPNEGO_NegTokenResp(securityBlob)
+            token = blob['ResponseToken']
         else:
-           # No GSSAPI stuff, raw NTLMSSP
-           rawNTLM = True
-           token = securityBlob
+            # No GSSAPI stuff, raw NTLMSSP
+            rawNTLM = True
+            token = securityBlob
 
-        # Here we only handle NTLMSSP, depending on what stage of the 
+        # Here we only handle NTLMSSP, depending on what stage of the
         # authentication we are, we act on it
-        messageType = struct.unpack('<L',token[len('NTLMSSP\x00'):len('NTLMSSP\x00')+4])[0]
+        messageType = struct.unpack('<L', token[len('NTLMSSP\x00'):len('NTLMSSP\x00') + 4])[0]
 
         if messageType == 0x01:
             # NEGOTIATE_MESSAGE
@@ -2727,45 +2773,48 @@ def smb2SessionSetup(connId, smbServer, recvPacket):
             # Let's store it in the connection data
             connData['NEGOTIATE_MESSAGE'] = negotiateMessage
             # Let's build the answer flags
-            # TODO: Parse all the flags. With this we're leaving some clients out 
+            # TODO: Parse all the flags. With this we're leaving some clients out
 
             ansFlags = 0
 
             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_56:
-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56
+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_56
             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_128:
-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128
+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_128
             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH:
-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH
+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_KEY_EXCH
             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY:
-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY
+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY
             if negotiateMessage['flags'] & ntlm.NTLMSSP_NEGOTIATE_UNICODE:
-               ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE
+                ansFlags |= ntlm.NTLMSSP_NEGOTIATE_UNICODE
             if negotiateMessage['flags'] & ntlm.NTLM_NEGOTIATE_OEM:
-               ansFlags |= ntlm.NTLM_NEGOTIATE_OEM
+                ansFlags |= ntlm.NTLM_NEGOTIATE_OEM
 
             ansFlags |= ntlm.NTLMSSP_NEGOTIATE_VERSION | ntlm.NTLMSSP_NEGOTIATE_TARGET_INFO | ntlm.NTLMSSP_TARGET_TYPE_SERVER | ntlm.NTLMSSP_NEGOTIATE_NTLM | ntlm.NTLMSSP_REQUEST_TARGET
 
             # Generate the AV_PAIRS
             av_pairs = ntlm.AV_PAIRS()
             # TODO: Put the proper data from SMBSERVER config
-            av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')
-            av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')
-            av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (116444736000000000 + calendar.timegm(time.gmtime()) * 10000000) )
+            av_pairs[ntlm.NTLMSSP_AV_HOSTNAME] = av_pairs[
+                ntlm.NTLMSSP_AV_DNS_HOSTNAME] = smbServer.getServerName().encode('utf-16le')
+            av_pairs[ntlm.NTLMSSP_AV_DOMAINNAME] = av_pairs[
+                ntlm.NTLMSSP_AV_DNS_DOMAINNAME] = smbServer.getServerDomain().encode('utf-16le')
+            av_pairs[ntlm.NTLMSSP_AV_TIME] = struct.pack('<q', (
+                        116444736000000000 + calendar.timegm(time.gmtime()) * 10000000))
 
             challengeMessage = ntlm.NTLMAuthChallenge()
-            challengeMessage['flags']            = ansFlags
-            challengeMessage['domain_len']       = len(smbServer.getServerDomain().encode('utf-16le'))
-            challengeMessage['domain_max_len']   = challengeMessage['domain_len']
-            challengeMessage['domain_offset']    = 40 + 16
-            challengeMessage['challenge']        = smbServer.getSMBChallenge()
-            challengeMessage['domain_name']      = smbServer.getServerDomain().encode('utf-16le')
-            challengeMessage['TargetInfoFields_len']     = len(av_pairs)
+            challengeMessage['flags'] = ansFlags
+            challengeMessage['domain_len'] = len(smbServer.getServerDomain().encode('utf-16le'))
+            challengeMessage['domain_max_len'] = challengeMessage['domain_len']
+            challengeMessage['domain_offset'] = 40 + 16
+            challengeMessage['challenge'] = smbServer.getSMBChallenge()
+            challengeMessage['domain_name'] = smbServer.getServerDomain().encode('utf-16le')
+            challengeMessage['TargetInfoFields_len'] = len(av_pairs)
             challengeMessage['TargetInfoFields_max_len'] = len(av_pairs)
             challengeMessage['TargetInfoFields'] = av_pairs
-            challengeMessage['TargetInfoFields_offset']  = 40 + 16 + len(challengeMessage['domain_name'])
-            challengeMessage['Version']          = b'\xff'*8
-            challengeMessage['VersionLen']       = 8
+            challengeMessage['TargetInfoFields_offset'] = 40 + 16 + len(challengeMessage['domain_name'])
+            challengeMessage['Version'] = b'\xff' * 8
+            challengeMessage['VersionLen'] = 8
 
             if rawNTLM is False:
                 respToken = SPNEGO_NegTokenResp()
@@ -2779,11 +2828,11 @@ def smb2SessionSetup(connId, smbServer, recvPacket):
 
             # Setting the packet to STATUS_MORE_PROCESSING
             errorCode = STATUS_MORE_PROCESSING_REQUIRED
-            # Let's set up an UID for this connection and store it 
+            # Let's set up an UID for this connection and store it
             # in the connection's data
             # Picking a fixed value
             # TODO: Manage more UIDs for the same session
-            connData['Uid'] = random.randint(1,0xffffffff)
+            connData['Uid'] = random.randint(1, 0xffffffff)
             # Let's store it in the connection data
             connData['CHALLENGE_MESSAGE'] = challengeMessage
 
@@ -2795,8 +2844,9 @@ def smb2SessionSetup(connId, smbServer, recvPacket):
             authenticateMessage = ntlm.NTLMAuthChallengeResponse()
             authenticateMessage.fromString(token)
             smbServer.log(""AUTHENTICATE_MESSAGE (%s\\%s,%s)"" % (
-            authenticateMessage['domain_name'].decode('utf-16le'), authenticateMessage['user_name'].decode('utf-16le'),
-            authenticateMessage['host_name'].decode('utf-16le')))
+                authenticateMessage['domain_name'].decode('utf-16le'),
+                authenticateMessage['user_name'].decode('utf-16le'),
+                authenticateMessage['host_name'].decode('utf-16le')))
             # TODO: Check the credentials! Now granting permissions
             # Do we have credentials to check?
             if len(smbServer.getCredentials()) > 0:
@@ -2829,7 +2879,8 @@ def smb2SessionSetup(connId, smbServer, recvPacket):
                 # accept-completed
                 respToken['NegState'] = b'\x00'
                 smbServer.log('User %s\\%s authenticated successfully' % (
-                authenticateMessage['host_name'].decode('utf-16le'), authenticateMessage['user_name'].decode('utf-16le')))
+                    authenticateMessage['host_name'].decode('utf-16le'),
+                    authenticateMessage['user_name'].decode('utf-16le')))
                 # Let's store it in the connection data
                 connData['AUTHENTICATE_MESSAGE'] = authenticateMessage
                 try:
@@ -2862,8 +2913,8 @@ def smb2SessionSetup(connId, smbServer, recvPacket):
         # From now on, the client can ask for other commands
         connData['Authenticated'] = True
         # For now, just switching to nobody
-        #os.setregid(65534,65534)
-        #os.setreuid(65534,65534)
+        # os.setregid(65534,65534)
+        # os.setreuid(65534,65534)
         smbServer.setConnectionData(connId, connData)
 
         return [respSMBCommand], None, errorCode
@@ -2873,16 +2924,16 @@ def smb2TreeConnect(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
         respPacket = smb2.SMB2Packet()
-        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR
-        respPacket['Status']    = STATUS_SUCCESS
+        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR
+        respPacket['Status'] = STATUS_SUCCESS
         respPacket['CreditRequestResponse'] = 1
-        respPacket['Command']   = recvPacket['Command']
+        respPacket['Command'] = recvPacket['Command']
         respPacket['SessionID'] = connData['Uid']
-        respPacket['Reserved']  = recvPacket['Reserved']
+        respPacket['Reserved'] = recvPacket['Reserved']
         respPacket['MessageID'] = recvPacket['MessageID']
-        respPacket['TreeID']    = recvPacket['TreeID']
+        respPacket['TreeID'] = recvPacket['TreeID']
 
-        respSMBCommand        = smb2.SMB2TreeConnect_Response()
+        respSMBCommand = smb2.SMB2TreeConnect_Response()
 
         treeConnectRequest = smb2.SMB2TreeConnect(recvPacket['Data'])
 
@@ -2902,13 +2953,13 @@ def smb2TreeConnect(connId, smbServer, recvPacket):
         if share is not None:
             # Simple way to generate a Tid
             if len(connData['ConnectedShares']) == 0:
-               tid = 1
+                tid = 1
             else:
-               tid = list(connData['ConnectedShares'].keys())[-1] + 1
+                tid = list(connData['ConnectedShares'].keys())[-1] + 1
             connData['ConnectedShares'][tid] = share
             connData['ConnectedShares'][tid]['shareName'] = path
-            respPacket['TreeID']    = tid
-            smbServer.log(""Connecting Share(%d:%s)"" % (tid,path))
+            respPacket['TreeID'] = tid
+            smbServer.log(""Connecting Share(%d:%s)"" % (tid, path))
         else:
             smbServer.log(""SMB2_TREE_CONNECT not found %s"" % path, logging.ERROR)
             errorCode = STATUS_OBJECT_PATH_NOT_FOUND
@@ -2938,104 +2989,111 @@ def smb2TreeConnect(connId, smbServer, recvPacket):
     def smb2Create(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb2.SMB2Create_Response()
+        respSMBCommand = smb2.SMB2Create_Response()
 
-        ntCreateRequest       = smb2.SMB2Create(recvPacket['Data'])
+        ntCreateRequest = smb2.SMB2Create(recvPacket['Data'])
 
         respSMBCommand['Buffer'] = b'\x00'
         # Get the Tid associated
         if recvPacket['TreeID'] in connData['ConnectedShares']:
-             # If we have a rootFid, the path is relative to that fid
-             errorCode = STATUS_SUCCESS
-             if 'path' in connData['ConnectedShares'][recvPacket['TreeID']]:
-                 path = connData['ConnectedShares'][recvPacket['TreeID']]['path']
-             else:
-                 path = 'NONE'
-                 errorCode = STATUS_ACCESS_DENIED
-
-             deleteOnClose = False
-
-             fileName = os.path.normpath(ntCreateRequest['Buffer'][:ntCreateRequest['NameLength']].decode('utf-16le').replace('\\','/'))
-             if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
+            # If we have a rootFid, the path is relative to that fid
+            errorCode = STATUS_SUCCESS
+            if 'path' in connData['ConnectedShares'][recvPacket['TreeID']]:
+                path = connData['ConnectedShares'][recvPacket['TreeID']]['path']
+            else:
+                path = 'NONE'
+                errorCode = STATUS_ACCESS_DENIED
+
+            deleteOnClose = False
+
+            fileName = os.path.normpath(
+                ntCreateRequest['Buffer'][:ntCreateRequest['NameLength']].decode('utf-16le').replace('\\', '/'))
+            if len(fileName) > 0 and (fileName[0] == '/' or fileName[0] == '\\'):
                 # strip leading '/'
                 fileName = fileName[1:]
-             pathName = os.path.join(path,fileName)
-             createDisposition = ntCreateRequest['CreateDisposition']
-             mode = 0
-
-             if createDisposition == smb2.FILE_SUPERSEDE:
-                 mode |= os.O_TRUNC | os.O_CREAT
-             elif createDisposition & smb2.FILE_OVERWRITE_IF == smb2.FILE_OVERWRITE_IF:
-                 mode |= os.O_TRUNC | os.O_CREAT
-             elif createDisposition & smb2.FILE_OVERWRITE == smb2.FILE_OVERWRITE:
-                 if os.path.exists(pathName) is True:
-                     mode |= os.O_TRUNC 
-                 else:
-                     errorCode = STATUS_NO_SUCH_FILE
-             elif createDisposition & smb2.FILE_OPEN_IF == smb2.FILE_OPEN_IF:
-                 if os.path.exists(pathName) is True:
-                     mode |= os.O_TRUNC 
-                 else:
-                     mode |= os.O_TRUNC | os.O_CREAT
-             elif createDisposition & smb2.FILE_CREATE == smb2.FILE_CREATE:
-                 if os.path.exists(pathName) is True:
-                     errorCode = STATUS_OBJECT_NAME_COLLISION
-                 else:
-                     mode |= os.O_CREAT
-             elif createDisposition & smb2.FILE_OPEN == smb2.FILE_OPEN:
-                 if os.path.exists(pathName) is not True and (str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:
-                     errorCode = STATUS_NO_SUCH_FILE
-
-             if errorCode == STATUS_SUCCESS:
-                 desiredAccess = ntCreateRequest['DesiredAccess']
-                 if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):
-                     mode |= os.O_RDONLY
-                 if (desiredAccess & smb2.FILE_WRITE_DATA) or (desiredAccess & smb2.GENERIC_WRITE):
-                     if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):
-                         mode |= os.O_RDWR #| os.O_APPEND
-                     else: 
-                         mode |= os.O_WRONLY #| os.O_APPEND
-                 if desiredAccess & smb2.GENERIC_ALL:
-                     mode |= os.O_RDWR #| os.O_APPEND
-
-                 createOptions =  ntCreateRequest['CreateOptions']
-                 if mode & os.O_CREAT == os.O_CREAT:
-                     if createOptions & smb2.FILE_DIRECTORY_FILE == smb2.FILE_DIRECTORY_FILE: 
-                         try:
-                             # Let's create the directory
-                             os.mkdir(pathName)
-                             mode = os.O_RDONLY
-                         except Exception as e:
-                             smbServer.log(""SMB2_CREATE: %s,%s,%s"" % (pathName,mode,e),logging.ERROR)
-                             errorCode = STATUS_ACCESS_DENIED
-                 if createOptions & smb2.FILE_NON_DIRECTORY_FILE == smb2.FILE_NON_DIRECTORY_FILE:
-                     # If the file being opened is a directory, the server MUST fail the request with
-                     # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server
-                     # response.
-                     if os.path.isdir(pathName) is True:
+
+            if not isInFileJail(path, fileName):
+                LOG.error(""Path not in current working directory"")
+                return [smb2.SMB2Error()], None, STATUS_ACCESS_DENIED
+
+            pathName = os.path.join(path, fileName)
+            createDisposition = ntCreateRequest['CreateDisposition']
+            mode = 0
+
+            if createDisposition == smb2.FILE_SUPERSEDE:
+                mode |= os.O_TRUNC | os.O_CREAT
+            elif createDisposition & smb2.FILE_OVERWRITE_IF == smb2.FILE_OVERWRITE_IF:
+                mode |= os.O_TRUNC | os.O_CREAT
+            elif createDisposition & smb2.FILE_OVERWRITE == smb2.FILE_OVERWRITE:
+                if os.path.exists(pathName) is True:
+                    mode |= os.O_TRUNC
+                else:
+                    errorCode = STATUS_NO_SUCH_FILE
+            elif createDisposition & smb2.FILE_OPEN_IF == smb2.FILE_OPEN_IF:
+                if os.path.exists(pathName) is True:
+                    mode |= os.O_TRUNC
+                else:
+                    mode |= os.O_TRUNC | os.O_CREAT
+            elif createDisposition & smb2.FILE_CREATE == smb2.FILE_CREATE:
+                if os.path.exists(pathName) is True:
+                    errorCode = STATUS_OBJECT_NAME_COLLISION
+                else:
+                    mode |= os.O_CREAT
+            elif createDisposition & smb2.FILE_OPEN == smb2.FILE_OPEN:
+                if os.path.exists(pathName) is not True and (
+                        str(pathName) in smbServer.getRegisteredNamedPipes()) is not True:
+                    errorCode = STATUS_NO_SUCH_FILE
+
+            if errorCode == STATUS_SUCCESS:
+                desiredAccess = ntCreateRequest['DesiredAccess']
+                if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):
+                    mode |= os.O_RDONLY
+                if (desiredAccess & smb2.FILE_WRITE_DATA) or (desiredAccess & smb2.GENERIC_WRITE):
+                    if (desiredAccess & smb2.FILE_READ_DATA) or (desiredAccess & smb2.GENERIC_READ):
+                        mode |= os.O_RDWR  # | os.O_APPEND
+                    else:
+                        mode |= os.O_WRONLY  # | os.O_APPEND
+                if desiredAccess & smb2.GENERIC_ALL:
+                    mode |= os.O_RDWR  # | os.O_APPEND
+
+                createOptions = ntCreateRequest['CreateOptions']
+                if mode & os.O_CREAT == os.O_CREAT:
+                    if createOptions & smb2.FILE_DIRECTORY_FILE == smb2.FILE_DIRECTORY_FILE:
+                        try:
+                            # Let's create the directory
+                            os.mkdir(pathName)
+                            mode = os.O_RDONLY
+                        except Exception as e:
+                            smbServer.log(""SMB2_CREATE: %s,%s,%s"" % (pathName, mode, e), logging.ERROR)
+                            errorCode = STATUS_ACCESS_DENIED
+                if createOptions & smb2.FILE_NON_DIRECTORY_FILE == smb2.FILE_NON_DIRECTORY_FILE:
+                    # If the file being opened is a directory, the server MUST fail the request with
+                    # STATUS_FILE_IS_A_DIRECTORY in the Status field of the SMB Header in the server
+                    # response.
+                    if os.path.isdir(pathName) is True:
                         errorCode = STATUS_FILE_IS_A_DIRECTORY
 
-                 if createOptions & smb2.FILE_DELETE_ON_CLOSE == smb2.FILE_DELETE_ON_CLOSE:
-                     deleteOnClose = True
-                 
-                 if errorCode == STATUS_SUCCESS:
-                     try:
-                         if os.path.isdir(pathName) and sys.platform == 'win32':
+                if createOptions & smb2.FILE_DELETE_ON_CLOSE == smb2.FILE_DELETE_ON_CLOSE:
+                    deleteOnClose = True
+
+                if errorCode == STATUS_SUCCESS:
+                    try:
+                        if os.path.isdir(pathName) and sys.platform == 'win32':
                             fid = VOID_FILE_DESCRIPTOR
-                         else:
+                        else:
                             if sys.platform == 'win32':
-                               mode |= os.O_BINARY
+                                mode |= os.O_BINARY
                             if str(pathName) in smbServer.getRegisteredNamedPipes():
                                 fid = PIPE_FILE_DESCRIPTOR
                                 sock = socket.socket()
                                 sock.connect(smbServer.getRegisteredNamedPipes()[str(pathName)])
                             else:
                                 fid = os.open(pathName, mode)
-                     except Exception as e:
-                         smbServer.log(""SMB2_CREATE: %s,%s,%s"" % (pathName,mode,e),logging.ERROR)
-                         #print e
-                         fid = 0
-                         errorCode = STATUS_ACCESS_DENIED
+                    except Exception as e:
+                        smbServer.log(""SMB2_CREATE: %s,%s,%s"" % (pathName, mode, e), logging.ERROR)
+                        # print e
+                        fid = 0
+                        errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_SMB_BAD_TID
 
@@ -3047,12 +3105,12 @@ def smb2Create(connId, smbServer, recvPacket):
             respSMBCommand['CreateAction'] = createDisposition
 
             if fid == PIPE_FILE_DESCRIPTOR:
-                respSMBCommand['CreationTime']   = 0
+                respSMBCommand['CreationTime'] = 0
                 respSMBCommand['LastAccessTime'] = 0
-                respSMBCommand['LastWriteTime']  = 0
-                respSMBCommand['ChangeTime']     = 0
+                respSMBCommand['LastWriteTime'] = 0
+                respSMBCommand['ChangeTime'] = 0
                 respSMBCommand['AllocationSize'] = 4096
-                respSMBCommand['EndOfFile']      = 0
+                respSMBCommand['EndOfFile'] = 0
                 respSMBCommand['FileAttributes'] = 0x80
 
             else:
@@ -3061,15 +3119,15 @@ def smb2Create(connId, smbServer, recvPacket):
                 else:
                     respSMBCommand['FileAttributes'] = ntCreateRequest['FileAttributes']
                 # Let's get this file's information
-                respInfo, errorCode = queryPathInformation('',pathName,level= smb.SMB_QUERY_FILE_ALL_INFO)
+                respInfo, errorCode = queryPathInformation('', pathName, level=smb.SMB_QUERY_FILE_ALL_INFO)
                 if errorCode == STATUS_SUCCESS:
-                    respSMBCommand['CreationTime']   = respInfo['CreationTime']
+                    respSMBCommand['CreationTime'] = respInfo['CreationTime']
                     respSMBCommand['LastAccessTime'] = respInfo['LastAccessTime']
-                    respSMBCommand['LastWriteTime']  = respInfo['LastWriteTime']
+                    respSMBCommand['LastWriteTime'] = respInfo['LastWriteTime']
                     respSMBCommand['LastChangeTime'] = respInfo['LastChangeTime']
                     respSMBCommand['FileAttributes'] = respInfo['ExtFileAttributes']
                     respSMBCommand['AllocationSize'] = respInfo['AllocationSize']
-                    respSMBCommand['EndOfFile']      = respInfo['EndOfFile']
+                    respSMBCommand['EndOfFile'] = respInfo['EndOfFile']
 
             if errorCode == STATUS_SUCCESS:
                 # Let's store the fid for the connection
@@ -3077,15 +3135,15 @@ def smb2Create(connId, smbServer, recvPacket):
                 connData['OpenedFiles'][fakefid] = {}
                 connData['OpenedFiles'][fakefid]['FileHandle'] = fid
                 connData['OpenedFiles'][fakefid]['FileName'] = pathName
-                connData['OpenedFiles'][fakefid]['DeleteOnClose']  = deleteOnClose
-                connData['OpenedFiles'][fakefid]['Open']  = {}
+                connData['OpenedFiles'][fakefid]['DeleteOnClose'] = deleteOnClose
+                connData['OpenedFiles'][fakefid]['Open'] = {}
                 connData['OpenedFiles'][fakefid]['Open']['EnumerationLocation'] = 0
                 connData['OpenedFiles'][fakefid]['Open']['EnumerationSearchPattern'] = ''
                 if fid == PIPE_FILE_DESCRIPTOR:
                     connData['OpenedFiles'][fakefid]['Socket'] = sock
         else:
             respSMBCommand = smb2.SMB2Error()
-        
+
         if errorCode == STATUS_SUCCESS:
             connData['LastRequest']['SMB2_CREATE'] = respSMBCommand
         smbServer.setConnectionData(connId, connData)
@@ -3096,13 +3154,13 @@ def smb2Create(connId, smbServer, recvPacket):
     def smb2Close(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb2.SMB2Close_Response()
+        respSMBCommand = smb2.SMB2Close_Response()
 
         closeRequest = smb2.SMB2Close(recvPacket['Data'])
 
-        if closeRequest['FileID'].getData() == b'\xff'*16:
+        if closeRequest['FileID'].getData() == b'\xff' * 16:
             # Let's take the data from the lastRequest
-            if  'SMB2_CREATE' in connData['LastRequest']:
+            if 'SMB2_CREATE' in connData['LastRequest']:
                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']
             else:
                 fileID = closeRequest['FileID'].getData()
@@ -3110,42 +3168,43 @@ def smb2Close(connId, smbServer, recvPacket):
             fileID = closeRequest['FileID'].getData()
 
         if fileID in connData['OpenedFiles']:
-             errorCode = STATUS_SUCCESS
-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']
-             pathName = connData['OpenedFiles'][fileID]['FileName']
-             infoRecord = None
-             try:
-                 if fileHandle == PIPE_FILE_DESCRIPTOR:
-                     connData['OpenedFiles'][fileID]['Socket'].close()
-                 elif fileHandle != VOID_FILE_DESCRIPTOR:
-                     os.close(fileHandle)
-                     infoRecord, errorCode = queryFileInformation(os.path.dirname(pathName), os.path.basename(pathName), smb2.SMB2_FILE_NETWORK_OPEN_INFO)
-             except Exception as e:
-                 smbServer.log(""SMB2_CLOSE %s"" % e, logging.ERROR)
-                 errorCode = STATUS_INVALID_HANDLE
-             else:
-                 # Check if the file was marked for removal
-                 if connData['OpenedFiles'][fileID]['DeleteOnClose'] is True:
-                     try:
-                         if os.path.isdir(pathName):
-                             shutil.rmtree(connData['OpenedFiles'][fileID]['FileName'])
-                         else:
-                             os.remove(connData['OpenedFiles'][fileID]['FileName'])
-                     except Exception as e:
-                         smbServer.log(""SMB2_CLOSE %s"" % e, logging.ERROR)
-                         errorCode = STATUS_ACCESS_DENIED
-    
-                 # Now fill out the response
-                 if infoRecord is not None:
-                     respSMBCommand['CreationTime']   = infoRecord['CreationTime']
-                     respSMBCommand['LastAccessTime'] = infoRecord['LastAccessTime']
-                     respSMBCommand['LastWriteTime']  = infoRecord['LastWriteTime']
-                     respSMBCommand['ChangeTime']     = infoRecord['ChangeTime']
-                     respSMBCommand['AllocationSize'] = infoRecord['AllocationSize']
-                     respSMBCommand['EndofFile']      = infoRecord['EndOfFile']
-                     respSMBCommand['FileAttributes'] = infoRecord['FileAttributes']
-                 if errorCode == STATUS_SUCCESS:
-                     del(connData['OpenedFiles'][fileID])
+            errorCode = STATUS_SUCCESS
+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']
+            pathName = connData['OpenedFiles'][fileID]['FileName']
+            infoRecord = None
+            try:
+                if fileHandle == PIPE_FILE_DESCRIPTOR:
+                    connData['OpenedFiles'][fileID]['Socket'].close()
+                elif fileHandle != VOID_FILE_DESCRIPTOR:
+                    os.close(fileHandle)
+                    infoRecord, errorCode = queryFileInformation(os.path.dirname(pathName), os.path.basename(pathName),
+                                                                 smb2.SMB2_FILE_NETWORK_OPEN_INFO)
+            except Exception as e:
+                smbServer.log(""SMB2_CLOSE %s"" % e, logging.ERROR)
+                errorCode = STATUS_INVALID_HANDLE
+            else:
+                # Check if the file was marked for removal
+                if connData['OpenedFiles'][fileID]['DeleteOnClose'] is True:
+                    try:
+                        if os.path.isdir(pathName):
+                            shutil.rmtree(connData['OpenedFiles'][fileID]['FileName'])
+                        else:
+                            os.remove(connData['OpenedFiles'][fileID]['FileName'])
+                    except Exception as e:
+                        smbServer.log(""SMB2_CLOSE %s"" % e, logging.ERROR)
+                        errorCode = STATUS_ACCESS_DENIED
+
+                # Now fill out the response
+                if infoRecord is not None:
+                    respSMBCommand['CreationTime'] = infoRecord['CreationTime']
+                    respSMBCommand['LastAccessTime'] = infoRecord['LastAccessTime']
+                    respSMBCommand['LastWriteTime'] = infoRecord['LastWriteTime']
+                    respSMBCommand['ChangeTime'] = infoRecord['ChangeTime']
+                    respSMBCommand['AllocationSize'] = infoRecord['AllocationSize']
+                    respSMBCommand['EndofFile'] = infoRecord['EndOfFile']
+                    respSMBCommand['FileAttributes'] = infoRecord['FileAttributes']
+                if errorCode == STATUS_SUCCESS:
+                    del (connData['OpenedFiles'][fileID])
         else:
             errorCode = STATUS_INVALID_HANDLE
 
@@ -3156,18 +3215,18 @@ def smb2Close(connId, smbServer, recvPacket):
     def smb2QueryInfo(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb2.SMB2QueryInfo_Response()
+        respSMBCommand = smb2.SMB2QueryInfo_Response()
 
         queryInfo = smb2.SMB2QueryInfo(recvPacket['Data'])
-       
-        errorCode = STATUS_SUCCESS 
+
+        errorCode = STATUS_SUCCESS
 
         respSMBCommand['OutputBufferOffset'] = 0x48
         respSMBCommand['Buffer'] = b'\x00'
 
-        if queryInfo['FileID'].getData() == b'\xff'*16:
+        if queryInfo['FileID'].getData() == b'\xff' * 16:
             # Let's take the data from the lastRequest
-            if  'SMB2_CREATE' in connData['LastRequest']:
+            if 'SMB2_CREATE' in connData['LastRequest']:
                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']
             else:
                 fileID = queryInfo['FileID'].getData()
@@ -3189,15 +3248,16 @@ def smb2QueryInfo(connId, smbServer, recvPacket):
                                                                      queryInfo['FileInfoClass'])
                 elif queryInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:
                     if queryInfo['FileInfoClass'] == smb2.SMB2_FILE_EA_INFO:
-                        infoRecord = b'\x00'*4
+                        infoRecord = b'\x00' * 4
                     else:
-                        infoRecord = queryFsInformation(os.path.dirname(fileName), os.path.basename(fileName), queryInfo['FileInfoClass'])
+                        infoRecord = queryFsInformation(os.path.dirname(fileName), os.path.basename(fileName),
+                                                        queryInfo['FileInfoClass'])
                 elif queryInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:
                     # Failing for now, until we support it
                     infoRecord = None
                     errorCode = STATUS_ACCESS_DENIED
                 else:
-                    smbServer.log(""queryInfo not supported (%x)"" %  queryInfo['InfoType'], logging.ERROR)
+                    smbServer.log(""queryInfo not supported (%x)"" % queryInfo['InfoType'], logging.ERROR)
 
                 if infoRecord is not None:
                     respSMBCommand['OutputBufferLength'] = len(infoRecord)
@@ -3207,7 +3267,6 @@ def smb2QueryInfo(connId, smbServer, recvPacket):
         else:
             errorCode = STATUS_SMB_BAD_TID
 
-
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
 
@@ -3215,15 +3274,15 @@ def smb2QueryInfo(connId, smbServer, recvPacket):
     def smb2SetInfo(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
-        respSMBCommand        = smb2.SMB2SetInfo_Response()
+        respSMBCommand = smb2.SMB2SetInfo_Response()
 
         setInfo = smb2.SMB2SetInfo(recvPacket['Data'])
-       
-        errorCode = STATUS_SUCCESS 
 
-        if setInfo['FileID'].getData() == b'\xff'*16:
+        errorCode = STATUS_SUCCESS
+
+        if setInfo['FileID'].getData() == b'\xff' * 16:
             # Let's take the data from the lastRequest
-            if  'SMB2_CREATE' in connData['LastRequest']:
+            if 'SMB2_CREATE' in connData['LastRequest']:
                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']
             else:
                 fileID = setInfo['FileID'].getData()
@@ -3231,7 +3290,7 @@ def smb2SetInfo(connId, smbServer, recvPacket):
             fileID = setInfo['FileID'].getData()
 
         if recvPacket['TreeID'] in connData['ConnectedShares']:
-            path     = connData['ConnectedShares'][recvPacket['TreeID']]['path']
+            path = connData['ConnectedShares'][recvPacket['TreeID']]['path']
             if fileID in connData['OpenedFiles']:
                 pathName = connData['OpenedFiles'][fileID]['FileName']
 
@@ -3241,8 +3300,8 @@ def smb2SetInfo(connId, smbServer, recvPacket):
                     if informationLevel == smb2.SMB2_FILE_DISPOSITION_INFO:
                         infoRecord = smb.SMBSetFileDispositionInfo(setInfo['Buffer'])
                         if infoRecord['DeletePending'] > 0:
-                           # Mark this file for removal after closed
-                           connData['OpenedFiles'][fileID]['DeleteOnClose'] = True
+                            # Mark this file for removal after closed
+                            connData['OpenedFiles'][fileID]['DeleteOnClose'] = True
                     elif informationLevel == smb2.SMB2_FILE_BASIC_INFO:
                         infoRecord = smb.SMBSetFileBasicInfo(setInfo['Buffer'])
                         # Creation time won't be set,  the other ones we play with.
@@ -3257,48 +3316,47 @@ def smb2SetInfo(connId, smbServer, recvPacket):
                         else:
                             mtime = getUnixTime(mtime)
                         if atime > 0 and mtime > 0:
-                            os.utime(pathName,(atime,mtime))
+                            os.utime(pathName, (atime, mtime))
                     elif informationLevel == smb2.SMB2_FILE_END_OF_FILE_INFO:
                         fileHandle = connData['OpenedFiles'][fileID]['FileHandle']
                         infoRecord = smb.SMBSetFileEndOfFileInfo(setInfo['Buffer'])
                         if infoRecord['EndOfFile'] > 0:
-                            os.lseek(fileHandle, infoRecord['EndOfFile']-1, 0)
+                            os.lseek(fileHandle, infoRecord['EndOfFile'] - 1, 0)
                             os.write(fileHandle, b'\x00')
                     elif informationLevel == smb2.SMB2_FILE_RENAME_INFO:
                         renameInfo = smb2.FILE_RENAME_INFORMATION_TYPE_2(setInfo['Buffer'])
-                        newPathName = os.path.join(path,renameInfo['FileName'].decode('utf-16le').replace('\\', '/')) 
+                        newPathName = os.path.join(path, renameInfo['FileName'].decode('utf-16le').replace('\\', '/'))
                         if renameInfo['ReplaceIfExists'] == 0 and os.path.exists(newPathName):
                             return [smb2.SMB2Error()], None, STATUS_OBJECT_NAME_COLLISION
                         try:
-                             os.rename(pathName,newPathName)
-                             connData['OpenedFiles'][fileID]['FileName'] = newPathName
+                            os.rename(pathName, newPathName)
+                            connData['OpenedFiles'][fileID]['FileName'] = newPathName
                         except Exception as e:
-                             smbServer.log(""smb2SetInfo: %s"" % e, logging.ERROR)
-                             errorCode = STATUS_ACCESS_DENIED
+                            smbServer.log(""smb2SetInfo: %s"" % e, logging.ERROR)
+                            errorCode = STATUS_ACCESS_DENIED
                     else:
                         smbServer.log('Unknown level for set file info! 0x%x' % informationLevel, logging.ERROR)
                         # UNSUPPORTED
-                        errorCode =  STATUS_NOT_SUPPORTED
-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:
+                        errorCode = STATUS_NOT_SUPPORTED
+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_FILESYSTEM:
                 #    # The underlying object store information is being set.
                 #    setInfo = queryFsInformation('/', fileName, queryInfo['FileInfoClass'])
-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:
+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_SECURITY:
                 #    # The security information is being set.
                 #    # Failing for now, until we support it
                 #    infoRecord = None
                 #    errorCode = STATUS_ACCESS_DENIED
-                #elif setInfo['InfoType'] == smb2.SMB2_0_INFO_QUOTA:
+                # elif setInfo['InfoType'] == smb2.SMB2_0_INFO_QUOTA:
                 #    # The underlying object store quota information is being set.
                 #    setInfo = queryFsInformation('/', fileName, queryInfo['FileInfoClass'])
                 else:
-                    smbServer.log(""setInfo not supported (%x)"" %  setInfo['InfoType'], logging.ERROR)
+                    smbServer.log(""setInfo not supported (%x)"" % setInfo['InfoType'], logging.ERROR)
 
             else:
                 errorCode = STATUS_INVALID_HANDLE
         else:
             errorCode = STATUS_SMB_BAD_TID
 
-
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
 
@@ -3307,13 +3365,13 @@ def smb2Write(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
         respSMBCommand = smb2.SMB2Write_Response()
-        writeRequest   = smb2.SMB2Write(recvPacket['Data'])
+        writeRequest = smb2.SMB2Write(recvPacket['Data'])
 
         respSMBCommand['Buffer'] = b'\x00'
 
-        if writeRequest['FileID'].getData() == b'\xff'*16:
+        if writeRequest['FileID'].getData() == b'\xff' * 16:
             # Let's take the data from the lastRequest
-            if  'SMB2_CREATE' in connData['LastRequest']:
+            if 'SMB2_CREATE' in connData['LastRequest']:
                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']
             else:
                 fileID = writeRequest['FileID'].getData()
@@ -3321,24 +3379,24 @@ def smb2Write(connId, smbServer, recvPacket):
             fileID = writeRequest['FileID'].getData()
 
         if fileID in connData['OpenedFiles']:
-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']
-             errorCode = STATUS_SUCCESS
-             try:
-                 if fileHandle != PIPE_FILE_DESCRIPTOR:
-                     offset = writeRequest['Offset']
-                     # If we're trying to write past the file end we just skip the write call (Vista does this)
-                     if os.lseek(fileHandle, 0, 2) >= offset:
-                         os.lseek(fileHandle,offset,0)
-                         os.write(fileHandle,writeRequest['Buffer'])
-                 else:
-                     sock = connData['OpenedFiles'][fileID]['Socket']
-                     sock.send(writeRequest['Buffer'])
-
-                 respSMBCommand['Count']    = writeRequest['Length']
-                 respSMBCommand['Remaining']= 0xff
-             except Exception as e:
-                 smbServer.log('SMB2_WRITE: %s' % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']
+            errorCode = STATUS_SUCCESS
+            try:
+                if fileHandle != PIPE_FILE_DESCRIPTOR:
+                    offset = writeRequest['Offset']
+                    # If we're trying to write past the file end we just skip the write call (Vista does this)
+                    if os.lseek(fileHandle, 0, 2) >= offset:
+                        os.lseek(fileHandle, offset, 0)
+                        os.write(fileHandle, writeRequest['Buffer'])
+                else:
+                    sock = connData['OpenedFiles'][fileID]['Socket']
+                    sock.send(writeRequest['Buffer'])
+
+                respSMBCommand['Count'] = writeRequest['Length']
+                respSMBCommand['Remaining'] = 0xff
+            except Exception as e:
+                smbServer.log('SMB2_WRITE: %s' % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_HANDLE
 
@@ -3350,13 +3408,13 @@ def smb2Read(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
         respSMBCommand = smb2.SMB2Read_Response()
-        readRequest   = smb2.SMB2Read(recvPacket['Data'])
+        readRequest = smb2.SMB2Read(recvPacket['Data'])
 
         respSMBCommand['Buffer'] = b'\x00'
 
-        if readRequest['FileID'].getData() == b'\xff'*16:
+        if readRequest['FileID'].getData() == b'\xff' * 16:
             # Let's take the data from the lastRequest
-            if  'SMB2_CREATE' in connData['LastRequest']:
+            if 'SMB2_CREATE' in connData['LastRequest']:
                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']
             else:
                 fileID = readRequest['FileID'].getData()
@@ -3364,24 +3422,24 @@ def smb2Read(connId, smbServer, recvPacket):
             fileID = readRequest['FileID'].getData()
 
         if fileID in connData['OpenedFiles']:
-             fileHandle = connData['OpenedFiles'][fileID]['FileHandle']
-             errorCode = 0
-             try:
-                 if fileHandle != PIPE_FILE_DESCRIPTOR:
-                     offset = readRequest['Offset']
-                     os.lseek(fileHandle,offset,0)
-                     content = os.read(fileHandle,readRequest['Length'])
-                 else:
-                     sock = connData['OpenedFiles'][fileID]['Socket']
-                     content = sock.recv(readRequest['Length'])
-
-                 respSMBCommand['DataOffset']   = 0x50
-                 respSMBCommand['DataLength']   = len(content)
-                 respSMBCommand['DataRemaining']= 0
-                 respSMBCommand['Buffer']       = content
-             except Exception as e:
-                 smbServer.log('SMB2_READ: %s ' % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            fileHandle = connData['OpenedFiles'][fileID]['FileHandle']
+            errorCode = 0
+            try:
+                if fileHandle != PIPE_FILE_DESCRIPTOR:
+                    offset = readRequest['Offset']
+                    os.lseek(fileHandle, offset, 0)
+                    content = os.read(fileHandle, readRequest['Length'])
+                else:
+                    sock = connData['OpenedFiles'][fileID]['Socket']
+                    content = sock.recv(readRequest['Length'])
+
+                respSMBCommand['DataOffset'] = 0x50
+                respSMBCommand['DataLength'] = len(content)
+                respSMBCommand['DataRemaining'] = 0
+                respSMBCommand['Buffer'] = content
+            except Exception as e:
+                smbServer.log('SMB2_READ: %s ' % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_HANDLE
 
@@ -3393,40 +3451,39 @@ def smb2Flush(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
         respSMBCommand = smb2.SMB2Flush_Response()
-        flushRequest   = smb2.SMB2Flush(recvPacket['Data'])
+        flushRequest = smb2.SMB2Flush(recvPacket['Data'])
 
         if flushRequest['FileID'].getData() in connData['OpenedFiles']:
-             fileHandle = connData['OpenedFiles'][flushRequest['FileID'].getData()]['FileHandle']
-             errorCode = STATUS_SUCCESS
-             try:
-                 os.fsync(fileHandle)
-             except Exception as e:
-                 smbServer.log(""SMB2_FLUSH %s"" % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            fileHandle = connData['OpenedFiles'][flushRequest['FileID'].getData()]['FileHandle']
+            errorCode = STATUS_SUCCESS
+            try:
+                os.fsync(fileHandle)
+            except Exception as e:
+                smbServer.log(""SMB2_FLUSH %s"" % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_HANDLE
 
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
 
-
     @staticmethod
     def smb2QueryDirectory(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
         respSMBCommand = smb2.SMB2QueryDirectory_Response()
-        queryDirectoryRequest   = smb2.SMB2QueryDirectory(recvPacket['Data'])
+        queryDirectoryRequest = smb2.SMB2QueryDirectory(recvPacket['Data'])
 
         respSMBCommand['Buffer'] = b'\x00'
 
         # The server MUST locate the tree connection, as specified in section 3.3.5.2.11.
         if (recvPacket['TreeID'] in connData['ConnectedShares']) is False:
             return [smb2.SMB2Error()], None, STATUS_NETWORK_NAME_DELETED
-       
-        # Next, the server MUST locate the open for the directory to be queried 
+
+        # Next, the server MUST locate the open for the directory to be queried
         # If no open is found, the server MUST fail the request with STATUS_FILE_CLOSED
-        if queryDirectoryRequest['FileID'].getData() == b'\xff'*16:
+        if queryDirectoryRequest['FileID'].getData() == b'\xff' * 16:
             # Let's take the data from the lastRequest
-            if  'SMB2_CREATE' in connData['LastRequest']:
+            if 'SMB2_CREATE' in connData['LastRequest']:
                 fileID = connData['LastRequest']['SMB2_CREATE']['FileID']
             else:
                 fileID = queryDirectoryRequest['FileID'].getData()
@@ -3436,57 +3493,59 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):
         if (fileID in connData['OpenedFiles']) is False:
             return [smb2.SMB2Error()], None, STATUS_FILE_CLOSED
 
-        # If the open is not an open to a directory, the request MUST be failed 
+        # If the open is not an open to a directory, the request MUST be failed
         # with STATUS_INVALID_PARAMETER.
         if os.path.isdir(connData['OpenedFiles'][fileID]['FileName']) is False:
             return [smb2.SMB2Error()], None, STATUS_INVALID_PARAMETER
 
-        # If any other information class is specified in the FileInformationClass 
-        # field of the SMB2 QUERY_DIRECTORY Request, the server MUST fail the 
-        # operation with STATUS_INVALID_INFO_CLASS. 
+        # If any other information class is specified in the FileInformationClass
+        # field of the SMB2 QUERY_DIRECTORY Request, the server MUST fail the
+        # operation with STATUS_INVALID_INFO_CLASS.
         if queryDirectoryRequest['FileInformationClass'] not in (
-        smb2.FILE_DIRECTORY_INFORMATION, smb2.FILE_FULL_DIRECTORY_INFORMATION, smb2.FILEID_FULL_DIRECTORY_INFORMATION,
-        smb2.FILE_BOTH_DIRECTORY_INFORMATION, smb2.FILEID_BOTH_DIRECTORY_INFORMATION, smb2.FILENAMES_INFORMATION):
+                smb2.FILE_DIRECTORY_INFORMATION, smb2.FILE_FULL_DIRECTORY_INFORMATION,
+                smb2.FILEID_FULL_DIRECTORY_INFORMATION,
+                smb2.FILE_BOTH_DIRECTORY_INFORMATION, smb2.FILEID_BOTH_DIRECTORY_INFORMATION,
+                smb2.FILENAMES_INFORMATION):
             return [smb2.SMB2Error()], None, STATUS_INVALID_INFO_CLASS
 
-        # If SMB2_REOPEN is set in the Flags field of the SMB2 QUERY_DIRECTORY 
-        # Request, the server SHOULD<326> set Open.EnumerationLocation to 0 
+        # If SMB2_REOPEN is set in the Flags field of the SMB2 QUERY_DIRECTORY
+        # Request, the server SHOULD<326> set Open.EnumerationLocation to 0
         # and Open.EnumerationSearchPattern to an empty string.
         if queryDirectoryRequest['Flags'] & smb2.SMB2_REOPEN:
             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = 0
             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = ''
-        
-        # If SMB2_RESTART_SCANS is set in the Flags field of the SMB2 
-        # QUERY_DIRECTORY Request, the server MUST set 
+
+        # If SMB2_RESTART_SCANS is set in the Flags field of the SMB2
+        # QUERY_DIRECTORY Request, the server MUST set
         # Open.EnumerationLocation to 0.
         if queryDirectoryRequest['Flags'] & smb2.SMB2_RESTART_SCANS:
             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = 0
 
-        # If Open.EnumerationLocation is 0 and Open.EnumerationSearchPattern 
-        # is an empty string, then Open.EnumerationSearchPattern MUST be set 
-        # to the search pattern specified in the SMB2 QUERY_DIRECTORY by 
-        # FileNameOffset and FileNameLength. If FileNameLength is 0, the server 
+        # If Open.EnumerationLocation is 0 and Open.EnumerationSearchPattern
+        # is an empty string, then Open.EnumerationSearchPattern MUST be set
+        # to the search pattern specified in the SMB2 QUERY_DIRECTORY by
+        # FileNameOffset and FileNameLength. If FileNameLength is 0, the server
         # SHOULD<327> set Open.EnumerationSearchPattern as ""*"" to search all entries.
 
         pattern = queryDirectoryRequest['Buffer'].decode('utf-16le')
-        if  connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0 and \
-            connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] == '':
+        if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0 and \
+                connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] == '':
             if pattern == '':
                 pattern = '*'
             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = pattern
 
-        # If SMB2_INDEX_SPECIFIED is set and FileNameLength is not zero, 
-        # the server MUST set Open.EnumerationSearchPattern to the search pattern 
+        # If SMB2_INDEX_SPECIFIED is set and FileNameLength is not zero,
+        # the server MUST set Open.EnumerationSearchPattern to the search pattern
         # specified in the request by FileNameOffset and FileNameLength.
         if queryDirectoryRequest['Flags'] & smb2.SMB2_INDEX_SPECIFIED and \
-           queryDirectoryRequest['FileNameLength'] > 0:
+                queryDirectoryRequest['FileNameLength'] > 0:
             connData['OpenedFiles'][fileID]['Open']['EnumerationSearchPattern'] = pattern
 
-        pathName = os.path.join(os.path.normpath(connData['OpenedFiles'][fileID]['FileName']),pattern)
+        pathName = os.path.join(os.path.normpath(connData['OpenedFiles'][fileID]['FileName']), pattern)
         searchResult, searchCount, errorCode = findFirst2(os.path.dirname(pathName),
-                  os.path.basename(pathName),
-                  queryDirectoryRequest['FileInformationClass'], 
-                  smb.ATTR_DIRECTORY, isSMB2 = True )
+                                                          os.path.basename(pathName),
+                                                          queryDirectoryRequest['FileInformationClass'],
+                                                          smb.ATTR_DIRECTORY, isSMB2=True)
 
         if errorCode != STATUS_SUCCESS:
             return [smb2.SMB2Error()], None, errorCode
@@ -3499,7 +3558,7 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):
         if searchCount == 0 and connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] == 0:
             return [smb2.SMB2Error()], None, STATUS_NO_SUCH_FILE
 
-        if  connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] < 0:
+        if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] < 0:
             return [smb2.SMB2Error()], None, STATUS_NO_MORE_FILES
 
         totalData = 0
@@ -3511,20 +3570,20 @@ def smb2QueryDirectory(connId, smbServer, recvPacket):
                 searchResult[nItem]['NextEntryOffset'] = 0
             data = searchResult[nItem].getData()
             lenData = len(data)
-            padLen = (8-(lenData % 8)) %8
- 
-            if (totalData+lenData) >= queryDirectoryRequest['OutputBufferLength']:
+            padLen = (8 - (lenData % 8)) % 8
+
+            if (totalData + lenData) >= queryDirectoryRequest['OutputBufferLength']:
                 connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] -= 1
                 break
             else:
-                respData += data + b'\x00'*padLen
+                respData += data + b'\x00' * padLen
                 totalData += lenData + padLen
 
             if queryDirectoryRequest['Flags'] & smb2.SL_RETURN_SINGLE_ENTRY:
                 break
 
         if connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] >= searchCount:
-             connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = -1
+            connData['OpenedFiles'][fileID]['Open']['EnumerationLocation'] = -1
 
         respSMBCommand['OutputBufferOffset'] = 0x48
         respSMBCommand['OutputBufferLength'] = totalData
@@ -3553,14 +3612,13 @@ def smb2TreeDisconnect(connId, smbServer, recvPacket):
 
         if recvPacket['TreeID'] in connData['ConnectedShares']:
             smbServer.log(""Disconnecting Share(%d:%s)"" % (
-            recvPacket['TreeID'], connData['ConnectedShares'][recvPacket['TreeID']]['shareName']))
-            del(connData['ConnectedShares'][recvPacket['TreeID']])
+                recvPacket['TreeID'], connData['ConnectedShares'][recvPacket['TreeID']]['shareName']))
+            del (connData['ConnectedShares'][recvPacket['TreeID']])
             errorCode = STATUS_SUCCESS
         else:
             # STATUS_SMB_BAD_TID
             errorCode = STATUS_SMB_BAD_TID
 
-
         smbServer.setConnectionData(connId, connData)
         return [respSMBCommand], None, errorCode
 
@@ -3587,24 +3645,24 @@ def smb2Ioctl(connId, smbServer, recvPacket):
         connData = smbServer.getConnectionData(connId)
 
         respSMBCommand = smb2.SMB2Ioctl_Response()
-        ioctlRequest   = smb2.SMB2Ioctl(recvPacket['Data'])
+        ioctlRequest = smb2.SMB2Ioctl(recvPacket['Data'])
 
         ioctls = smbServer.getIoctls()
         if ioctlRequest['CtlCode'] in ioctls:
             outputData, errorCode = ioctls[ioctlRequest['CtlCode']](connId, smbServer, ioctlRequest)
             if errorCode == STATUS_SUCCESS:
-                respSMBCommand['CtlCode']      = ioctlRequest['CtlCode']
-                respSMBCommand['FileID']       = ioctlRequest['FileID']
-                respSMBCommand['InputOffset']  = 0
-                respSMBCommand['InputCount']   = 0
+                respSMBCommand['CtlCode'] = ioctlRequest['CtlCode']
+                respSMBCommand['FileID'] = ioctlRequest['FileID']
+                respSMBCommand['InputOffset'] = 0
+                respSMBCommand['InputCount'] = 0
                 respSMBCommand['OutputOffset'] = 0x70
-                respSMBCommand['OutputCount']  = len(outputData)
-                respSMBCommand['Flags']        = 0
-                respSMBCommand['Buffer']       = outputData
+                respSMBCommand['OutputCount'] = len(outputData)
+                respSMBCommand['Flags'] = 0
+                respSMBCommand['Buffer'] = outputData
             else:
                 respSMBCommand = outputData
         else:
-            smbServer.log(""Ioctl not implemented command: 0x%x"" % ioctlRequest['CtlCode'],logging.DEBUG)
+            smbServer.log(""Ioctl not implemented command: 0x%x"" % ioctlRequest['CtlCode'], logging.DEBUG)
             errorCode = STATUS_INVALID_DEVICE_REQUEST
             respSMBCommand = smb2.SMB2Error()
 
@@ -3631,49 +3689,50 @@ def smb2Cancel(connId, smbServer, recvPacket):
     @staticmethod
     def default(connId, smbServer, recvPacket):
         # By default we return an SMB Packet with error not implemented
-        smbServer.log(""Not implemented command: 0x%x"" % recvPacket['Command'],logging.DEBUG)
+        smbServer.log(""Not implemented command: 0x%x"" % recvPacket['Command'], logging.DEBUG)
         return [smb2.SMB2Error()], None, STATUS_NOT_SUPPORTED
 
+
 class Ioctls:
-   @staticmethod
-   def fsctlDfsGetReferrals(connId, smbServer, ioctlRequest):
+    @staticmethod
+    def fsctlDfsGetReferrals(connId, smbServer, ioctlRequest):
         return smb2.SMB2Error(), STATUS_FS_DRIVER_REQUIRED
 
-   @staticmethod
-   def fsctlPipeTransceive(connId, smbServer, ioctlRequest):
+    @staticmethod
+    def fsctlPipeTransceive(connId, smbServer, ioctlRequest):
         connData = smbServer.getConnectionData(connId)
-        
+
         ioctlResponse = ''
 
         if ioctlRequest['FileID'].getData() in connData['OpenedFiles']:
-             fileHandle = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['FileHandle']
-             errorCode = STATUS_SUCCESS
-             try:
-                 if fileHandle != PIPE_FILE_DESCRIPTOR:
-                     errorCode = STATUS_INVALID_DEVICE_REQUEST
-                 else:
-                     sock = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['Socket']
-                     sock.sendall(ioctlRequest['Buffer'])
-                     ioctlResponse = sock.recv(ioctlRequest['MaxOutputResponse'])
-             except Exception as e:
-                 smbServer.log('fsctlPipeTransceive: %s ' % e, logging.ERROR)
-                 errorCode = STATUS_ACCESS_DENIED
+            fileHandle = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['FileHandle']
+            errorCode = STATUS_SUCCESS
+            try:
+                if fileHandle != PIPE_FILE_DESCRIPTOR:
+                    errorCode = STATUS_INVALID_DEVICE_REQUEST
+                else:
+                    sock = connData['OpenedFiles'][ioctlRequest['FileID'].getData()]['Socket']
+                    sock.sendall(ioctlRequest['Buffer'])
+                    ioctlResponse = sock.recv(ioctlRequest['MaxOutputResponse'])
+            except Exception as e:
+                smbServer.log('fsctlPipeTransceive: %s ' % e, logging.ERROR)
+                errorCode = STATUS_ACCESS_DENIED
         else:
             errorCode = STATUS_INVALID_DEVICE_REQUEST
 
         smbServer.setConnectionData(connId, connData)
         return ioctlResponse, errorCode
 
-   @staticmethod
-   def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):
+    @staticmethod
+    def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):
         connData = smbServer.getConnectionData(connId)
-        
+
         errorCode = STATUS_SUCCESS
 
         validateNegotiateInfo = smb2.VALIDATE_NEGOTIATE_INFO(ioctlRequest['Buffer'])
         validateNegotiateInfoResponse = smb2.VALIDATE_NEGOTIATE_INFO_RESPONSE()
         validateNegotiateInfoResponse['Capabilities'] = 0
-        validateNegotiateInfoResponse['Guid'] = b'A'*16
+        validateNegotiateInfoResponse['Guid'] = b'A' * 16
         validateNegotiateInfoResponse['SecurityMode'] = 1
         validateNegotiateInfoResponse['Dialect'] = smb2.SMB2_DIALECT_002
 
@@ -3682,15 +3741,15 @@ def fsctlValidateNegotiateInfo(connId, smbServer, ioctlRequest):
 
 
 class SMBSERVERHandler(socketserver.BaseRequestHandler):
-    def __init__(self, request, client_address, server, select_poll = False):
+    def __init__(self, request, client_address, server, select_poll=False):
         self.__SMB = server
         # In case of AF_INET6 the client_address contains 4 items, ignore the last 2
         self.__ip, self.__port = client_address[:2]
         self.__request = request
         self.__connId = threading.currentThread().getName()
-        self.__timeOut = 60*5
+        self.__timeOut = 60 * 5
         self.__select_poll = select_poll
-        #self.__connId = os.getpid()
+        # self.__connId = os.getpid()
         socketserver.BaseRequestHandler.__init__(self, request, client_address, server)
 
     def handle(self):
@@ -3706,31 +3765,32 @@ def handle(self):
                 except nmb.NetBIOSTimeout:
                     raise
                 except nmb.NetBIOSError:
-                    break                 
+                    break
 
                 if p.get_type() == nmb.NETBIOS_SESSION_REQUEST:
-                   # Someone is requesting a session, we're gonna accept them all :)
-                   _, rn, my = p.get_trailer().split(b' ')
-                   remote_name = nmb.decode_name(b'\x20'+rn)
-                   myname = nmb.decode_name(b'\x20'+my)
-                   self.__SMB.log(""NetBIOS Session request (%s,%s,%s)"" % (self.__ip, remote_name[1].strip(), myname[1])) 
-                   r = nmb.NetBIOSSessionPacket()
-                   r.set_type(nmb.NETBIOS_SESSION_POSITIVE_RESPONSE)
-                   r.set_trailer(p.get_trailer())
-                   self.__request.send(r.rawData())
+                    # Someone is requesting a session, we're gonna accept them all :)
+                    _, rn, my = p.get_trailer().split(b' ')
+                    remote_name = nmb.decode_name(b'\x20' + rn)
+                    myname = nmb.decode_name(b'\x20' + my)
+                    self.__SMB.log(
+                        ""NetBIOS Session request (%s,%s,%s)"" % (self.__ip, remote_name[1].strip(), myname[1]))
+                    r = nmb.NetBIOSSessionPacket()
+                    r.set_type(nmb.NETBIOS_SESSION_POSITIVE_RESPONSE)
+                    r.set_trailer(p.get_trailer())
+                    self.__request.send(r.rawData())
                 else:
-                   resp = self.__SMB.processRequest(self.__connId, p.get_trailer())
-                   # Send all the packets received. Except for big transactions this should be
-                   # a single packet
-                   for i in resp:
-                       if hasattr(i, 'getData'):
-                           session.send_packet(i.getData())
-                       else:
-                           session.send_packet(i)
+                    resp = self.__SMB.processRequest(self.__connId, p.get_trailer())
+                    # Send all the packets received. Except for big transactions this should be
+                    # a single packet
+                    for i in resp:
+                        if hasattr(i, 'getData'):
+                            session.send_packet(i.getData())
+                        else:
+                            session.send_packet(i)
             except Exception as e:
                 self.__SMB.log(""Handle: %s"" % e)
-                #import traceback
-                #traceback.print_exc()
+                # import traceback
+                # traceback.print_exc()
                 break
 
     def finish(self):
@@ -3739,18 +3799,19 @@ def finish(self):
         self.__SMB.removeConnection(self.__connId)
         return socketserver.BaseRequestHandler.finish(self)
 
+
 class SMBSERVER(socketserver.ThreadingMixIn, socketserver.TCPServer):
-#class SMBSERVER(socketserver.ForkingMixIn, socketserver.TCPServer):
-    def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser = None):
+    # class SMBSERVER(socketserver.ForkingMixIn, socketserver.TCPServer):
+    def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser=None):
         socketserver.TCPServer.allow_reuse_address = True
         socketserver.TCPServer.__init__(self, server_address, handler_class)
 
         # Server name and OS to be presented whenever is necessary
-        self.__serverName   = ''
-        self.__serverOS     = ''
+        self.__serverName = ''
+        self.__serverOS = ''
         self.__serverDomain = ''
-        self.__challenge    = ''
-        self.__log          = None
+        self.__challenge = ''
+        self.__log = None
 
         # Our ConfigParser data
         self.__serverConfig = config_parser
@@ -3769,108 +3830,108 @@ def __init__(self, server_address, handler_class=SMBSERVERHandler, config_parser
 
         # SMB2 Support flag = default not active
         self.__SMB2Support = False
- 
+
         # Our list of commands we will answer, by default the NOT IMPLEMENTED one
         self.__smbCommandsHandler = SMBCommands()
-        self.__smbTrans2Handler   = TRANS2Commands()
-        self.__smbTransHandler    = TRANSCommands()
-        self.__smbNTTransHandler  = NTTRANSCommands()
+        self.__smbTrans2Handler = TRANS2Commands()
+        self.__smbTransHandler = TRANSCommands()
+        self.__smbNTTransHandler = NTTRANSCommands()
         self.__smb2CommandsHandler = SMB2Commands()
-        self.__IoctlHandler       = Ioctls()
+        self.__IoctlHandler = Ioctls()
 
         self.__smbNTTransCommands = {
-        # NT IOCTL, can't find doc for this
-        0xff                               :self.__smbNTTransHandler.default
+            # NT IOCTL, can't find doc for this
+            0xff: self.__smbNTTransHandler.default
         }
 
-        self.__smbTransCommands  = {
-'\\PIPE\\LANMAN'                       :self.__smbTransHandler.lanMan,
-smb.SMB.TRANS_TRANSACT_NMPIPE          :self.__smbTransHandler.transactNamedPipe,
+        self.__smbTransCommands = {
+            '\\PIPE\\LANMAN': self.__smbTransHandler.lanMan,
+            smb.SMB.TRANS_TRANSACT_NMPIPE: self.__smbTransHandler.transactNamedPipe,
         }
         self.__smbTrans2Commands = {
- smb.SMB.TRANS2_FIND_FIRST2            :self.__smbTrans2Handler.findFirst2,
- smb.SMB.TRANS2_FIND_NEXT2             :self.__smbTrans2Handler.findNext2,
- smb.SMB.TRANS2_QUERY_FS_INFORMATION   :self.__smbTrans2Handler.queryFsInformation,
- smb.SMB.TRANS2_QUERY_PATH_INFORMATION :self.__smbTrans2Handler.queryPathInformation,
- smb.SMB.TRANS2_QUERY_FILE_INFORMATION :self.__smbTrans2Handler.queryFileInformation,
- smb.SMB.TRANS2_SET_FILE_INFORMATION   :self.__smbTrans2Handler.setFileInformation,
- smb.SMB.TRANS2_SET_PATH_INFORMATION   :self.__smbTrans2Handler.setPathInformation
+            smb.SMB.TRANS2_FIND_FIRST2: self.__smbTrans2Handler.findFirst2,
+            smb.SMB.TRANS2_FIND_NEXT2: self.__smbTrans2Handler.findNext2,
+            smb.SMB.TRANS2_QUERY_FS_INFORMATION: self.__smbTrans2Handler.queryFsInformation,
+            smb.SMB.TRANS2_QUERY_PATH_INFORMATION: self.__smbTrans2Handler.queryPathInformation,
+            smb.SMB.TRANS2_QUERY_FILE_INFORMATION: self.__smbTrans2Handler.queryFileInformation,
+            smb.SMB.TRANS2_SET_FILE_INFORMATION: self.__smbTrans2Handler.setFileInformation,
+            smb.SMB.TRANS2_SET_PATH_INFORMATION: self.__smbTrans2Handler.setPathInformation
         }
 
-        self.__smbCommands = { 
- #smb.SMB.SMB_COM_FLUSH:              self.__smbCommandsHandler.smbComFlush, 
- smb.SMB.SMB_COM_CREATE_DIRECTORY:   self.__smbCommandsHandler.smbComCreateDirectory, 
- smb.SMB.SMB_COM_DELETE_DIRECTORY:   self.__smbCommandsHandler.smbComDeleteDirectory, 
- smb.SMB.SMB_COM_RENAME:             self.__smbCommandsHandler.smbComRename, 
- smb.SMB.SMB_COM_DELETE:             self.__smbCommandsHandler.smbComDelete, 
- smb.SMB.SMB_COM_NEGOTIATE:          self.__smbCommandsHandler.smbComNegotiate, 
- smb.SMB.SMB_COM_SESSION_SETUP_ANDX: self.__smbCommandsHandler.smbComSessionSetupAndX,
- smb.SMB.SMB_COM_LOGOFF_ANDX:        self.__smbCommandsHandler.smbComLogOffAndX,
- smb.SMB.SMB_COM_TREE_CONNECT_ANDX:  self.__smbCommandsHandler.smbComTreeConnectAndX,
- smb.SMB.SMB_COM_TREE_DISCONNECT:    self.__smbCommandsHandler.smbComTreeDisconnect,
- smb.SMB.SMB_COM_ECHO:               self.__smbCommandsHandler.smbComEcho,
- smb.SMB.SMB_COM_QUERY_INFORMATION:  self.__smbCommandsHandler.smbQueryInformation,
- smb.SMB.SMB_COM_TRANSACTION2:       self.__smbCommandsHandler.smbTransaction2,
- smb.SMB.SMB_COM_TRANSACTION:        self.__smbCommandsHandler.smbTransaction,
- # Not needed for now
- smb.SMB.SMB_COM_NT_TRANSACT:        self.__smbCommandsHandler.smbNTTransact,
- smb.SMB.SMB_COM_QUERY_INFORMATION_DISK: self.__smbCommandsHandler.smbQueryInformationDisk,
- smb.SMB.SMB_COM_OPEN_ANDX:          self.__smbCommandsHandler.smbComOpenAndX,
- smb.SMB.SMB_COM_QUERY_INFORMATION2: self.__smbCommandsHandler.smbComQueryInformation2,
- smb.SMB.SMB_COM_READ_ANDX:          self.__smbCommandsHandler.smbComReadAndX,
- smb.SMB.SMB_COM_READ:               self.__smbCommandsHandler.smbComRead,
- smb.SMB.SMB_COM_WRITE_ANDX:         self.__smbCommandsHandler.smbComWriteAndX,
- smb.SMB.SMB_COM_WRITE:              self.__smbCommandsHandler.smbComWrite,
- smb.SMB.SMB_COM_CLOSE:              self.__smbCommandsHandler.smbComClose,
- smb.SMB.SMB_COM_LOCKING_ANDX:       self.__smbCommandsHandler.smbComLockingAndX,
- smb.SMB.SMB_COM_NT_CREATE_ANDX:     self.__smbCommandsHandler.smbComNtCreateAndX,
- 0xFF:                               self.__smbCommandsHandler.default
-}
-
-        self.__smb2Ioctls = { 
- smb2.FSCTL_DFS_GET_REFERRALS:            self.__IoctlHandler.fsctlDfsGetReferrals, 
-# smb2.FSCTL_PIPE_PEEK:                    self.__IoctlHandler.fsctlPipePeek, 
-# smb2.FSCTL_PIPE_WAIT:                    self.__IoctlHandler.fsctlPipeWait, 
- smb2.FSCTL_PIPE_TRANSCEIVE:              self.__IoctlHandler.fsctlPipeTransceive, 
-# smb2.FSCTL_SRV_COPYCHUNK:                self.__IoctlHandler.fsctlSrvCopyChunk, 
-# smb2.FSCTL_SRV_ENUMERATE_SNAPSHOTS:      self.__IoctlHandler.fsctlSrvEnumerateSnapshots, 
-# smb2.FSCTL_SRV_REQUEST_RESUME_KEY:       self.__IoctlHandler.fsctlSrvRequestResumeKey, 
-# smb2.FSCTL_SRV_READ_HASH:                self.__IoctlHandler.fsctlSrvReadHash, 
-# smb2.FSCTL_SRV_COPYCHUNK_WRITE:          self.__IoctlHandler.fsctlSrvCopyChunkWrite, 
-# smb2.FSCTL_LMR_REQUEST_RESILIENCY:       self.__IoctlHandler.fsctlLmrRequestResiliency, 
-# smb2.FSCTL_QUERY_NETWORK_INTERFACE_INFO: self.__IoctlHandler.fsctlQueryNetworkInterfaceInfo, 
-# smb2.FSCTL_SET_REPARSE_POINT:            self.__IoctlHandler.fsctlSetReparsePoint, 
-# smb2.FSCTL_DFS_GET_REFERRALS_EX:         self.__IoctlHandler.fsctlDfsGetReferralsEx, 
-# smb2.FSCTL_FILE_LEVEL_TRIM:              self.__IoctlHandler.fsctlFileLevelTrim, 
- smb2.FSCTL_VALIDATE_NEGOTIATE_INFO:      self.__IoctlHandler.fsctlValidateNegotiateInfo, 
-}
-
-        self.__smb2Commands = { 
- smb2.SMB2_NEGOTIATE:       self.__smb2CommandsHandler.smb2Negotiate, 
- smb2.SMB2_SESSION_SETUP:   self.__smb2CommandsHandler.smb2SessionSetup, 
- smb2.SMB2_LOGOFF:          self.__smb2CommandsHandler.smb2Logoff, 
- smb2.SMB2_TREE_CONNECT:    self.__smb2CommandsHandler.smb2TreeConnect, 
- smb2.SMB2_TREE_DISCONNECT: self.__smb2CommandsHandler.smb2TreeDisconnect, 
- smb2.SMB2_CREATE:          self.__smb2CommandsHandler.smb2Create, 
- smb2.SMB2_CLOSE:           self.__smb2CommandsHandler.smb2Close, 
- smb2.SMB2_FLUSH:           self.__smb2CommandsHandler.smb2Flush, 
- smb2.SMB2_READ:            self.__smb2CommandsHandler.smb2Read, 
- smb2.SMB2_WRITE:           self.__smb2CommandsHandler.smb2Write, 
- smb2.SMB2_LOCK:            self.__smb2CommandsHandler.smb2Lock, 
- smb2.SMB2_IOCTL:           self.__smb2CommandsHandler.smb2Ioctl, 
- smb2.SMB2_CANCEL:          self.__smb2CommandsHandler.smb2Cancel, 
- smb2.SMB2_ECHO:            self.__smb2CommandsHandler.smb2Echo, 
- smb2.SMB2_QUERY_DIRECTORY: self.__smb2CommandsHandler.smb2QueryDirectory, 
- smb2.SMB2_CHANGE_NOTIFY:   self.__smb2CommandsHandler.smb2ChangeNotify, 
- smb2.SMB2_QUERY_INFO:      self.__smb2CommandsHandler.smb2QueryInfo, 
- smb2.SMB2_SET_INFO:        self.__smb2CommandsHandler.smb2SetInfo, 
-# smb2.SMB2_OPLOCK_BREAK:    self.__smb2CommandsHandler.smb2SessionSetup, 
- 0xFF:                      self.__smb2CommandsHandler.default
-}
+        self.__smbCommands = {
+            # smb.SMB.SMB_COM_FLUSH:              self.__smbCommandsHandler.smbComFlush,
+            smb.SMB.SMB_COM_CREATE_DIRECTORY: self.__smbCommandsHandler.smbComCreateDirectory,
+            smb.SMB.SMB_COM_DELETE_DIRECTORY: self.__smbCommandsHandler.smbComDeleteDirectory,
+            smb.SMB.SMB_COM_RENAME: self.__smbCommandsHandler.smbComRename,
+            smb.SMB.SMB_COM_DELETE: self.__smbCommandsHandler.smbComDelete,
+            smb.SMB.SMB_COM_NEGOTIATE: self.__smbCommandsHandler.smbComNegotiate,
+            smb.SMB.SMB_COM_SESSION_SETUP_ANDX: self.__smbCommandsHandler.smbComSessionSetupAndX,
+            smb.SMB.SMB_COM_LOGOFF_ANDX: self.__smbCommandsHandler.smbComLogOffAndX,
+            smb.SMB.SMB_COM_TREE_CONNECT_ANDX: self.__smbCommandsHandler.smbComTreeConnectAndX,
+            smb.SMB.SMB_COM_TREE_DISCONNECT: self.__smbCommandsHandler.smbComTreeDisconnect,
+            smb.SMB.SMB_COM_ECHO: self.__smbCommandsHandler.smbComEcho,
+            smb.SMB.SMB_COM_QUERY_INFORMATION: self.__smbCommandsHandler.smbQueryInformation,
+            smb.SMB.SMB_COM_TRANSACTION2: self.__smbCommandsHandler.smbTransaction2,
+            smb.SMB.SMB_COM_TRANSACTION: self.__smbCommandsHandler.smbTransaction,
+            # Not needed for now
+            smb.SMB.SMB_COM_NT_TRANSACT: self.__smbCommandsHandler.smbNTTransact,
+            smb.SMB.SMB_COM_QUERY_INFORMATION_DISK: self.__smbCommandsHandler.smbQueryInformationDisk,
+            smb.SMB.SMB_COM_OPEN_ANDX: self.__smbCommandsHandler.smbComOpenAndX,
+            smb.SMB.SMB_COM_QUERY_INFORMATION2: self.__smbCommandsHandler.smbComQueryInformation2,
+            smb.SMB.SMB_COM_READ_ANDX: self.__smbCommandsHandler.smbComReadAndX,
+            smb.SMB.SMB_COM_READ: self.__smbCommandsHandler.smbComRead,
+            smb.SMB.SMB_COM_WRITE_ANDX: self.__smbCommandsHandler.smbComWriteAndX,
+            smb.SMB.SMB_COM_WRITE: self.__smbCommandsHandler.smbComWrite,
+            smb.SMB.SMB_COM_CLOSE: self.__smbCommandsHandler.smbComClose,
+            smb.SMB.SMB_COM_LOCKING_ANDX: self.__smbCommandsHandler.smbComLockingAndX,
+            smb.SMB.SMB_COM_NT_CREATE_ANDX: self.__smbCommandsHandler.smbComNtCreateAndX,
+            0xFF: self.__smbCommandsHandler.default
+        }
+
+        self.__smb2Ioctls = {
+            smb2.FSCTL_DFS_GET_REFERRALS: self.__IoctlHandler.fsctlDfsGetReferrals,
+            # smb2.FSCTL_PIPE_PEEK:                    self.__IoctlHandler.fsctlPipePeek,
+            # smb2.FSCTL_PIPE_WAIT:                    self.__IoctlHandler.fsctlPipeWait,
+            smb2.FSCTL_PIPE_TRANSCEIVE: self.__IoctlHandler.fsctlPipeTransceive,
+            # smb2.FSCTL_SRV_COPYCHUNK:                self.__IoctlHandler.fsctlSrvCopyChunk,
+            # smb2.FSCTL_SRV_ENUMERATE_SNAPSHOTS:      self.__IoctlHandler.fsctlSrvEnumerateSnapshots,
+            # smb2.FSCTL_SRV_REQUEST_RESUME_KEY:       self.__IoctlHandler.fsctlSrvRequestResumeKey,
+            # smb2.FSCTL_SRV_READ_HASH:                self.__IoctlHandler.fsctlSrvReadHash,
+            # smb2.FSCTL_SRV_COPYCHUNK_WRITE:          self.__IoctlHandler.fsctlSrvCopyChunkWrite,
+            # smb2.FSCTL_LMR_REQUEST_RESILIENCY:       self.__IoctlHandler.fsctlLmrRequestResiliency,
+            # smb2.FSCTL_QUERY_NETWORK_INTERFACE_INFO: self.__IoctlHandler.fsctlQueryNetworkInterfaceInfo,
+            # smb2.FSCTL_SET_REPARSE_POINT:            self.__IoctlHandler.fsctlSetReparsePoint,
+            # smb2.FSCTL_DFS_GET_REFERRALS_EX:         self.__IoctlHandler.fsctlDfsGetReferralsEx,
+            # smb2.FSCTL_FILE_LEVEL_TRIM:              self.__IoctlHandler.fsctlFileLevelTrim,
+            smb2.FSCTL_VALIDATE_NEGOTIATE_INFO: self.__IoctlHandler.fsctlValidateNegotiateInfo,
+        }
+
+        self.__smb2Commands = {
+            smb2.SMB2_NEGOTIATE: self.__smb2CommandsHandler.smb2Negotiate,
+            smb2.SMB2_SESSION_SETUP: self.__smb2CommandsHandler.smb2SessionSetup,
+            smb2.SMB2_LOGOFF: self.__smb2CommandsHandler.smb2Logoff,
+            smb2.SMB2_TREE_CONNECT: self.__smb2CommandsHandler.smb2TreeConnect,
+            smb2.SMB2_TREE_DISCONNECT: self.__smb2CommandsHandler.smb2TreeDisconnect,
+            smb2.SMB2_CREATE: self.__smb2CommandsHandler.smb2Create,
+            smb2.SMB2_CLOSE: self.__smb2CommandsHandler.smb2Close,
+            smb2.SMB2_FLUSH: self.__smb2CommandsHandler.smb2Flush,
+            smb2.SMB2_READ: self.__smb2CommandsHandler.smb2Read,
+            smb2.SMB2_WRITE: self.__smb2CommandsHandler.smb2Write,
+            smb2.SMB2_LOCK: self.__smb2CommandsHandler.smb2Lock,
+            smb2.SMB2_IOCTL: self.__smb2CommandsHandler.smb2Ioctl,
+            smb2.SMB2_CANCEL: self.__smb2CommandsHandler.smb2Cancel,
+            smb2.SMB2_ECHO: self.__smb2CommandsHandler.smb2Echo,
+            smb2.SMB2_QUERY_DIRECTORY: self.__smb2CommandsHandler.smb2QueryDirectory,
+            smb2.SMB2_CHANGE_NOTIFY: self.__smb2CommandsHandler.smb2ChangeNotify,
+            smb2.SMB2_QUERY_INFO: self.__smb2CommandsHandler.smb2QueryInfo,
+            smb2.SMB2_SET_INFO: self.__smb2CommandsHandler.smb2SetInfo,
+            # smb2.SMB2_OPLOCK_BREAK:    self.__smb2CommandsHandler.smb2SessionSetup,
+            0xFF: self.__smb2CommandsHandler.default
+        }
 
         # List of active connections
         self.__activeConnections = {}
-  
+
     def getIoctls(self):
         return self.__smb2Ioctls
 
@@ -3879,39 +3940,39 @@ def getCredentials(self):
 
     def removeConnection(self, name):
         try:
-           del(self.__activeConnections[name])
+            del (self.__activeConnections[name])
         except:
-           pass
+            pass
         self.log(""Remaining connections %s"" % list(self.__activeConnections.keys()))
 
     def addConnection(self, name, ip, port):
         self.__activeConnections[name] = {}
         # Let's init with some know stuff we will need to have
         # TODO: Document what's in there
-        #print ""Current Connections"", self.__activeConnections.keys()
-        self.__activeConnections[name]['PacketNum']       = 0
-        self.__activeConnections[name]['ClientIP']        = ip
-        self.__activeConnections[name]['ClientPort']      = port
-        self.__activeConnections[name]['Uid']             = 0
+        # print ""Current Connections"", self.__activeConnections.keys()
+        self.__activeConnections[name]['PacketNum'] = 0
+        self.__activeConnections[name]['ClientIP'] = ip
+        self.__activeConnections[name]['ClientPort'] = port
+        self.__activeConnections[name]['Uid'] = 0
         self.__activeConnections[name]['ConnectedShares'] = {}
-        self.__activeConnections[name]['OpenedFiles']     = {}
+        self.__activeConnections[name]['OpenedFiles'] = {}
         # SID results for findfirst2
-        self.__activeConnections[name]['SIDs']            = {}
-        self.__activeConnections[name]['LastRequest']     = {}
-        self.__activeConnections[name]['SignatureEnabled']= False
-        self.__activeConnections[name]['SigningChallengeResponse']= ''
-        self.__activeConnections[name]['SigningSessionKey']= b''
-        self.__activeConnections[name]['Authenticated']= False
+        self.__activeConnections[name]['SIDs'] = {}
+        self.__activeConnections[name]['LastRequest'] = {}
+        self.__activeConnections[name]['SignatureEnabled'] = False
+        self.__activeConnections[name]['SigningChallengeResponse'] = ''
+        self.__activeConnections[name]['SigningSessionKey'] = b''
+        self.__activeConnections[name]['Authenticated'] = False
 
     def getActiveConnections(self):
         return self.__activeConnections
 
     def setConnectionData(self, connId, data):
         self.__activeConnections[connId] = data
-        #print ""setConnectionData"" 
-        #print self.__activeConnections
+        # print ""setConnectionData""
+        # print self.__activeConnections
 
-    def getConnectionData(self, connId, checkStatus = True):
+    def getConnectionData(self, connId, checkStatus=True):
         conn = self.__activeConnections[connId]
         if checkStatus is True:
             if ('Authenticated' in conn) is not True:
@@ -3928,16 +3989,16 @@ def registerNamedPipe(self, pipeName, address):
 
     def unregisterNamedPipe(self, pipeName):
         if pipeName in self.__registeredNamedPipes:
-            del(self.__registeredNamedPipes[str(pipeName)])
+            del (self.__registeredNamedPipes[str(pipeName)])
             return True
         return False
 
     def unregisterTransaction(self, transCommand):
         if transCommand in self.__smbTransCommands:
-           del(self.__smbTransCommands[transCommand])
+            del (self.__smbTransCommands[transCommand])
 
     def hookTransaction(self, transCommand, callback):
-        # If you call this function, callback will replace 
+        # If you call this function, callback will replace
         # the current Transaction sub command.
         # (don't get confused with the Transaction smbCommand)
         # If the transaction sub command doesn't not exist, it is added
@@ -3948,14 +4009,14 @@ def hookTransaction(self, transCommand, callback):
         #
         # WHERE:
         #
-        # connId      : the connection Id, used to grab/update information about 
+        # connId      : the connection Id, used to grab/update information about
         #               the current connection
-        # smbServer   : the SMBServer instance available for you to ask 
+        # smbServer   : the SMBServer instance available for you to ask
         #               configuration data
         # recvPacket  : the full SMBPacket that triggered this command
         # parameters  : the transaction parameters
         # data        : the transaction data
-        # maxDataCount: the max amount of data that can be transferred agreed 
+        # maxDataCount: the max amount of data that can be transferred agreed
         #               with the client
         #
         # and MUST return:
@@ -3966,53 +4027,53 @@ def hookTransaction(self, transCommand, callback):
         # respSetup: the setup response of the transaction
         # respParameters: the parameters response of the transaction
         # respData: the data response of the transaction
-        # errorCode: the NT error code 
+        # errorCode: the NT error code
 
         if transCommand in self.__smbTransCommands:
-           originalCommand = self.__smbTransCommands[transCommand]
+            originalCommand = self.__smbTransCommands[transCommand]
         else:
-           originalCommand = None 
+            originalCommand = None
 
         self.__smbTransCommands[transCommand] = callback
         return originalCommand
 
     def unregisterTransaction2(self, transCommand):
         if transCommand in self.__smbTrans2Commands:
-           del(self.__smbTrans2Commands[transCommand])
+            del (self.__smbTrans2Commands[transCommand])
 
     def hookTransaction2(self, transCommand, callback):
         # Here we should add to __smbTrans2Commands
         # Same description as Transaction
         if transCommand in self.__smbTrans2Commands:
-           originalCommand = self.__smbTrans2Commands[transCommand]
+            originalCommand = self.__smbTrans2Commands[transCommand]
         else:
-           originalCommand = None 
+            originalCommand = None
 
         self.__smbTrans2Commands[transCommand] = callback
         return originalCommand
 
     def unregisterNTTransaction(self, transCommand):
         if transCommand in self.__smbNTTransCommands:
-           del(self.__smbNTTransCommands[transCommand])
+            del (self.__smbNTTransCommands[transCommand])
 
     def hookNTTransaction(self, transCommand, callback):
         # Here we should add to __smbNTTransCommands
         # Same description as Transaction
         if transCommand in self.__smbNTTransCommands:
-           originalCommand = self.__smbNTTransCommands[transCommand]
+            originalCommand = self.__smbNTTransCommands[transCommand]
         else:
-           originalCommand = None 
+            originalCommand = None
 
         self.__smbNTTransCommands[transCommand] = callback
         return originalCommand
 
     def unregisterSmbCommand(self, smbCommand):
         if smbCommand in self.__smbCommands:
-           del(self.__smbCommands[smbCommand])
+            del (self.__smbCommands[smbCommand])
 
     def hookSmbCommand(self, smbCommand, callback):
         # Here we should add to self.__smbCommands
-        # If you call this function, callback will replace 
+        # If you call this function, callback will replace
         # the current smbCommand.
         # If smbCommand doesn't not exist, it is added
         # If SMB command exists, it returns the original function replaced
@@ -4022,19 +4083,19 @@ def hookSmbCommand(self, smbCommand, callback):
         #
         # WHERE:
         #
-        # connId    : the connection Id, used to grab/update information about 
+        # connId    : the connection Id, used to grab/update information about
         #             the current connection
-        # smbServer : the SMBServer instance available for you to ask 
+        # smbServer : the SMBServer instance available for you to ask
         #             configuration data
-        # SMBCommand: the SMBCommand itself, with its data and parameters. 
+        # SMBCommand: the SMBCommand itself, with its data and parameters.
         #             Check smb.py:SMBCommand() for a reference
         # recvPacket: the full SMBPacket that triggered this command
         #
         # and MUST return:
         # <list of respSMBCommands>, <list of packets>, errorCode
-        # <list of packets> has higher preference over commands, in case you 
-        # want to change the whole packet 
-        # errorCode: the NT error code 
+        # <list of packets> has higher preference over commands, in case you
+        # want to change the whole packet
+        # errorCode: the NT error code
         #
         # For SMB_COM_TRANSACTION2, SMB_COM_TRANSACTION and SMB_COM_NT_TRANSACT
         # the callback function is slightly different:
@@ -4042,46 +4103,46 @@ def hookSmbCommand(self, smbCommand, callback):
         # callback(connId, smbServer, SMBCommand, recvPacket, transCommands)
         #
         # WHERE:
-        # 
+        #
         # transCommands: a list of transaction subcommands already registered
         #
 
         if smbCommand in self.__smbCommands:
-           originalCommand = self.__smbCommands[smbCommand]
+            originalCommand = self.__smbCommands[smbCommand]
         else:
-           originalCommand = None 
+            originalCommand = None
 
         self.__smbCommands[smbCommand] = callback
         return originalCommand
-  
+
     def unregisterSmb2Command(self, smb2Command):
         if smb2Command in self.__smb2Commands:
-           del(self.__smb2Commands[smb2Command])
+            del (self.__smb2Commands[smb2Command])
 
     def hookSmb2Command(self, smb2Command, callback):
         if smb2Command in self.__smb2Commands:
-           originalCommand = self.__smb2Commands[smb2Command]
+            originalCommand = self.__smb2Commands[smb2Command]
         else:
-           originalCommand = None 
+            originalCommand = None
 
         self.__smb2Commands[smb2Command] = callback
         return originalCommand
 
     def log(self, msg, level=logging.INFO):
-        self.__log.log(level,msg)
+        self.__log.log(level, msg)
 
     def getServerName(self):
         return self.__serverName
 
     def getServerOS(self):
         return self.__serverOS
-  
+
     def getServerDomain(self):
         return self.__serverDomain
 
     def getSMBChallenge(self):
         return self.__challenge
-  
+
     def getServerConfig(self):
         return self.__serverConfig
 
@@ -4116,47 +4177,47 @@ def signSMBv1(self, connData, packet, signingSessionKey, signingChallengeRespons
         # The resulting 8-byte signature MUST be copied into the SecuritySignature field of the SMB Header,
         # after which the message can be transmitted.
 
-        #print ""seq(%d) signingSessionKey %r, signingChallengeResponse %r"" % (connData['SignSequenceNumber'], signingSessionKey, signingChallengeResponse)
-        packet['SecurityFeatures'] = struct.pack('<q',connData['SignSequenceNumber'])
+        # print ""seq(%d) signingSessionKey %r, signingChallengeResponse %r"" % (connData['SignSequenceNumber'], signingSessionKey, signingChallengeResponse)
+        packet['SecurityFeatures'] = struct.pack('<q', connData['SignSequenceNumber'])
         # Sign with the sequence
         m = hashlib.md5()
-        m.update( signingSessionKey )
-        m.update( signingChallengeResponse )
+        m.update(signingSessionKey)
+        m.update(signingChallengeResponse)
         if hasattr(packet, 'getData'):
-            m.update( packet.getData() )
+            m.update(packet.getData())
         else:
-            m.update( packet )
+            m.update(packet)
         # Replace sequence with acual hash
         packet['SecurityFeatures'] = m.digest()[:8]
-        connData['SignSequenceNumber'] +=2
+        connData['SignSequenceNumber'] += 2
 
     def signSMBv2(self, packet, signingSessionKey):
-        packet['Signature'] = b'\x00'*16
+        packet['Signature'] = b'\x00' * 16
         packet['Flags'] |= smb2.SMB2_FLAGS_SIGNED
         signature = hmac.new(signingSessionKey, packet.getData(), hashlib.sha256).digest()
         packet['Signature'] = signature[:16]
-        #print ""%s"" % packet['Signature'].encode('hex')
+        # print ""%s"" % packet['Signature'].encode('hex')
 
     def processRequest(self, connId, data):
 
         # TODO: Process batched commands.
-        isSMB2      = False
-        SMBCommand  = None
+        isSMB2 = False
+        SMBCommand = None
         try:
-            packet = smb.NewSMBPacket(data = data)
-            SMBCommand  = smb.SMBCommand(packet['Data'][0])
+            packet = smb.NewSMBPacket(data=data)
+            SMBCommand = smb.SMBCommand(packet['Data'][0])
         except:
             # Maybe a SMB2 packet?
-            packet = smb2.SMB2Packet(data = data)
+            packet = smb2.SMB2Packet(data=data)
             connData = self.getConnectionData(connId, False)
             self.signSMBv2(packet, connData['SigningSessionKey'])
             isSMB2 = True
 
-        connData    = self.getConnectionData(connId, False)
+        connData = self.getConnectionData(connId, False)
 
         # We might have compound requests
         compoundedPacketsResponse = []
-        compoundedPackets         = []
+        compoundedPackets = []
         try:
             # Search out list of implemented commands
             # We provide them with:
@@ -4173,7 +4234,8 @@ def processRequest(self, connId, data):
             # errorCode   : self explanatory
             if isSMB2 is False:
                 # Is the client authenticated already?
-                if connData['Authenticated'] is False and packet['Command'] not in (smb.SMB.SMB_COM_NEGOTIATE, smb.SMB.SMB_COM_SESSION_SETUP_ANDX):
+                if connData['Authenticated'] is False and packet['Command'] not in (
+                smb.SMB.SMB_COM_NEGOTIATE, smb.SMB.SMB_COM_SESSION_SETUP_ANDX):
                     # Nope.. in that case he should only ask for a few commands, if not throw him out.
                     errorCode = STATUS_ACCESS_DENIED
                     respPackets = None
@@ -4181,65 +4243,68 @@ def processRequest(self, connId, data):
                 else:
                     if packet['Command'] == smb.SMB.SMB_COM_TRANSACTION2:
                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
-                                      connId,
-                                      self,
-                                      SMBCommand,
-                                      packet,
-                                      self.__smbTrans2Commands)
+                            connId,
+                            self,
+                            SMBCommand,
+                            packet,
+                            self.__smbTrans2Commands)
                     elif packet['Command'] == smb.SMB.SMB_COM_NT_TRANSACT:
                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
-                                      connId,
-                                      self,
-                                      SMBCommand,
-                                      packet,
-                                      self.__smbNTTransCommands)
+                            connId,
+                            self,
+                            SMBCommand,
+                            packet,
+                            self.__smbNTTransCommands)
                     elif packet['Command'] == smb.SMB.SMB_COM_TRANSACTION:
                         respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
-                                      connId,
-                                      self,
-                                      SMBCommand,
-                                      packet,
-                                      self.__smbTransCommands)
+                            connId,
+                            self,
+                            SMBCommand,
+                            packet,
+                            self.__smbTransCommands)
                     else:
                         if packet['Command'] in self.__smbCommands:
-                           if self.__SMB2Support is True:
-                               if packet['Command'] == smb.SMB.SMB_COM_NEGOTIATE:
-                                   try:
-                                       respCommands, respPackets, errorCode = self.__smb2Commands[smb2.SMB2_NEGOTIATE](connId, self, packet, True)
-                                       isSMB2 = True
-                                   except Exception as e:
-                                       import traceback
-                                       traceback.print_exc()
-                                       self.log('SMB2_NEGOTIATE: %s' % e, logging.ERROR)
-                                       # If something went wrong, let's fallback to SMB1
-                                       respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
-                                           connId,
-                                           self,
-                                           SMBCommand,
-                                           packet)
-                                       #self.__SMB2Support = False
-                                       pass
-                               else:
-                                   respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
-                                           connId,
-                                           self,
-                                           SMBCommand,
-                                           packet)
-                           else:
-                               respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
-                                           connId,
-                                           self,
-                                           SMBCommand,
-                                           packet)
+                            if self.__SMB2Support is True:
+                                if packet['Command'] == smb.SMB.SMB_COM_NEGOTIATE:
+                                    try:
+                                        respCommands, respPackets, errorCode = self.__smb2Commands[smb2.SMB2_NEGOTIATE](
+                                            connId, self, packet, True)
+                                        isSMB2 = True
+                                    except Exception as e:
+                                        import traceback
+                                        traceback.print_exc()
+                                        self.log('SMB2_NEGOTIATE: %s' % e, logging.ERROR)
+                                        # If something went wrong, let's fallback to SMB1
+                                        respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
+                                            connId,
+                                            self,
+                                            SMBCommand,
+                                            packet)
+                                        # self.__SMB2Support = False
+                                        pass
+                                else:
+                                    respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
+                                        connId,
+                                        self,
+                                        SMBCommand,
+                                        packet)
+                            else:
+                                respCommands, respPackets, errorCode = self.__smbCommands[packet['Command']](
+                                    connId,
+                                    self,
+                                    SMBCommand,
+                                    packet)
                         else:
-                           respCommands, respPackets, errorCode = self.__smbCommands[255](connId, self, SMBCommand, packet)
+                            respCommands, respPackets, errorCode = self.__smbCommands[255](connId, self, SMBCommand,
+                                                                                           packet)
 
                 compoundedPacketsResponse.append((respCommands, respPackets, errorCode))
                 compoundedPackets.append(packet)
 
             else:
                 # Is the client authenticated already?
-                if connData['Authenticated'] is False and packet['Command'] not in (smb2.SMB2_NEGOTIATE, smb2.SMB2_SESSION_SETUP):
+                if connData['Authenticated'] is False and packet['Command'] not in (
+                smb2.SMB2_NEGOTIATE, smb2.SMB2_SESSION_SETUP):
                     # Nope.. in that case he should only ask for a few commands, if not throw him out.
                     errorCode = STATUS_ACCESS_DENIED
                     respPackets = None
@@ -4250,37 +4315,37 @@ def processRequest(self, connId, data):
                     done = False
                     while not done:
                         if packet['Command'] in self.__smb2Commands:
-                           if self.__SMB2Support is True:
-                               respCommands, respPackets, errorCode = self.__smb2Commands[packet['Command']](
-                                       connId,
-                                       self,
-                                       packet)
-                           else:
-                               respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)
+                            if self.__SMB2Support is True:
+                                respCommands, respPackets, errorCode = self.__smb2Commands[packet['Command']](
+                                    connId,
+                                    self,
+                                    packet)
+                            else:
+                                respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)
                         else:
-                           respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)
+                            respCommands, respPackets, errorCode = self.__smb2Commands[255](connId, self, packet)
                         # Let's store the result for this compounded packet
                         compoundedPacketsResponse.append((respCommands, respPackets, errorCode))
                         compoundedPackets.append(packet)
                         if packet['NextCommand'] != 0:
                             data = data[packet['NextCommand']:]
-                            packet = smb2.SMB2Packet(data = data)
+                            packet = smb2.SMB2Packet(data=data)
                         else:
                             done = True
 
         except Exception as e:
-            #import traceback
-            #traceback.print_exc()
+            # import traceback
+            # traceback.print_exc()
             # Something wen't wrong, defaulting to Bad user ID
-            self.log('processRequest (0x%x,%s)' % (packet['Command'],e), logging.ERROR)
+            self.log('processRequest (0x%x,%s)' % (packet['Command'], e), logging.ERROR)
             raise
 
         # We prepare the response packet to commands don't need to bother about that.
-        connData    = self.getConnectionData(connId, False)
+        connData = self.getConnectionData(connId, False)
 
         # Force reconnection loop.. This is just a test.. client will send me back credentials :)
-        #connData['PacketNum'] += 1
-        #if connData['PacketNum'] == 15:
+        # connData['PacketNum'] += 1
+        # if connData['PacketNum'] == 15:
         #    connData['PacketNum'] = 0
         #    # Something wen't wrong, defaulting to Bad user ID
         #    self.log('Sending BAD USER ID!', logging.ERROR)
@@ -4292,7 +4357,7 @@ def processRequest(self, connId, data):
         #    packet['ErrorClass']  = errorCode & 0xff
         #    return [packet]
 
-        self.setConnectionData(connId, connData)    
+        self.setConnectionData(connId, connData)
 
         packetsToSend = []
         for packetNum in range(len(compoundedPacketsResponse)):
@@ -4301,49 +4366,51 @@ def processRequest(self, connId, data):
             if respPackets is None:
                 for respCommand in respCommands:
                     if isSMB2 is False:
-                        respPacket           = smb.NewSMBPacket()
+                        respPacket = smb.NewSMBPacket()
                         respPacket['Flags1'] = smb.SMB.FLAGS1_REPLY
 
                         # TODO this should come from a per session configuration
-                        respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | packet['Flags2'] & smb.SMB.FLAGS2_UNICODE
-                        #respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES 
-                        #respPacket['Flags1'] = 0x98
-                        #respPacket['Flags2'] = 0xc807
-                
-
-                        respPacket['Tid']    = packet['Tid']
-                        respPacket['Mid']    = packet['Mid']
-                        respPacket['Pid']    = packet['Pid']
-                        respPacket['Uid']    = connData['Uid']
-        
-                        respPacket['ErrorCode']   = errorCode >> 16
-                        respPacket['_reserved']   = errorCode >> 8 & 0xff
-                        respPacket['ErrorClass']  = errorCode & 0xff
+                        respPacket[
+                            'Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES | \
+                                        packet['Flags2'] & smb.SMB.FLAGS2_UNICODE
+                        # respPacket['Flags2'] = smb.SMB.FLAGS2_EXTENDED_SECURITY | smb.SMB.FLAGS2_NT_STATUS | smb.SMB.FLAGS2_LONG_NAMES
+                        # respPacket['Flags1'] = 0x98
+                        # respPacket['Flags2'] = 0xc807
+
+                        respPacket['Tid'] = packet['Tid']
+                        respPacket['Mid'] = packet['Mid']
+                        respPacket['Pid'] = packet['Pid']
+                        respPacket['Uid'] = connData['Uid']
+
+                        respPacket['ErrorCode'] = errorCode >> 16
+                        respPacket['_reserved'] = errorCode >> 8 & 0xff
+                        respPacket['ErrorClass'] = errorCode & 0xff
                         respPacket.addCommand(respCommand)
 
                         if connData['SignatureEnabled']:
                             respPacket['Flags2'] |= smb.SMB.FLAGS2_SMB_SECURITY_SIGNATURE
-                            self.signSMBv1(connData, respPacket, connData['SigningSessionKey'], connData['SigningChallengeResponse'])
-            
+                            self.signSMBv1(connData, respPacket, connData['SigningSessionKey'],
+                                           connData['SigningChallengeResponse'])
+
                         packetsToSend.append(respPacket)
                     else:
                         respPacket = smb2.SMB2Packet()
-                        respPacket['Flags']     = smb2.SMB2_FLAGS_SERVER_TO_REDIR
+                        respPacket['Flags'] = smb2.SMB2_FLAGS_SERVER_TO_REDIR
                         if packetNum > 0:
                             respPacket['Flags'] |= smb2.SMB2_FLAGS_RELATED_OPERATIONS
-                        respPacket['Status']    = errorCode
+                        respPacket['Status'] = errorCode
                         respPacket['CreditRequestResponse'] = packet['CreditRequestResponse']
-                        respPacket['Command']   = packet['Command']
+                        respPacket['Command'] = packet['Command']
                         respPacket['CreditCharge'] = packet['CreditCharge']
-                        #respPacket['CreditCharge'] = 0
-                        respPacket['Reserved']  = packet['Reserved']
+                        # respPacket['CreditCharge'] = 0
+                        respPacket['Reserved'] = packet['Reserved']
                         respPacket['SessionID'] = connData['Uid']
                         respPacket['MessageID'] = packet['MessageID']
-                        respPacket['TreeID']    = packet['TreeID']
+                        respPacket['TreeID'] = packet['TreeID']
                         if hasattr(respCommand, 'getData'):
-                            respPacket['Data']      = respCommand.getData()
+                            respPacket['Data'] = respCommand.getData()
                         else:
-                            respPacket['Data']      = str(respCommand)
+                            respPacket['Data'] = str(respCommand)
 
                         if connData['SignatureEnabled']:
                             self.signSMBv2(respPacket, connData['SigningSessionKey'])
@@ -4357,21 +4424,21 @@ def processRequest(self, connId, data):
             # Let's build a compound answer
             finalData = b''
             i = 0
-            for i in range(len(packetsToSend)-1):
+            for i in range(len(packetsToSend) - 1):
                 packet = packetsToSend[i]
                 # Align to 8-bytes
-                padLen = (8 - (len(packet) % 8) ) % 8
+                padLen = (8 - (len(packet) % 8)) % 8
                 packet['NextCommand'] = len(packet) + padLen
                 if hasattr(packet, 'getData'):
-                    finalData += packet.getData() + padLen*b'\x00'
+                    finalData += packet.getData() + padLen * b'\x00'
                 else:
-                    finalData += packet + padLen*b'\x00'
+                    finalData += packet + padLen * b'\x00'
 
             # Last one
-            if hasattr(packetsToSend[len(packetsToSend)-1], 'getData'):
-                finalData += packetsToSend[len(packetsToSend)-1].getData()
+            if hasattr(packetsToSend[len(packetsToSend) - 1], 'getData'):
+                finalData += packetsToSend[len(packetsToSend) - 1].getData()
             else:
-                finalData += packetsToSend[len(packetsToSend)-1]
+                finalData += packetsToSend[len(packetsToSend) - 1]
             packetsToSend = [finalData]
 
         # We clear the compound requests
@@ -4379,7 +4446,7 @@ def processRequest(self, connId, data):
 
         return packetsToSend
 
-    def processConfigFile(self, configFile = None):
+    def processConfigFile(self, configFile=None):
         # TODO: Do a real config parser
         if self.__serverConfig is None:
             if configFile is None:
@@ -4387,32 +4454,32 @@ def processConfigFile(self, configFile = None):
             self.__serverConfig = configparser.ConfigParser()
             self.__serverConfig.read(configFile)
 
-        self.__serverName   = self.__serverConfig.get('global','server_name')
-        self.__serverOS     = self.__serverConfig.get('global','server_os')
-        self.__serverDomain = self.__serverConfig.get('global','server_domain')
-        self.__logFile      = self.__serverConfig.get('global','log_file')
+        self.__serverName = self.__serverConfig.get('global', 'server_name')
+        self.__serverOS = self.__serverConfig.get('global', 'server_os')
+        self.__serverDomain = self.__serverConfig.get('global', 'server_domain')
+        self.__logFile = self.__serverConfig.get('global', 'log_file')
         if self.__serverConfig.has_option('global', 'challenge'):
-            self.__challenge    = unhexlify(self.__serverConfig.get('global', 'challenge'))
+            self.__challenge = unhexlify(self.__serverConfig.get('global', 'challenge'))
         else:
-            self.__challenge    = b'A'*16
+            self.__challenge = b'A' * 16
 
         if self.__serverConfig.has_option(""global"", ""jtr_dump_path""):
             self.__jtr_dump_path = self.__serverConfig.get(""global"", ""jtr_dump_path"")
 
         if self.__serverConfig.has_option(""global"", ""SMB2Support""):
-            self.__SMB2Support = self.__serverConfig.getboolean(""global"",""SMB2Support"")
+            self.__SMB2Support = self.__serverConfig.getboolean(""global"", ""SMB2Support"")
         else:
             self.__SMB2Support = False
 
         if self.__logFile != 'None':
-            logging.basicConfig(filename = self.__logFile, 
-                             level = logging.DEBUG, 
-                             format=""%(asctime)s: %(levelname)s: %(message)s"", 
-                             datefmt = '%m/%d/%Y %I:%M:%S %p')
-        self.__log        = LOG
+            logging.basicConfig(filename=self.__logFile,
+                                level=logging.DEBUG,
+                                format=""%(asctime)s: %(levelname)s: %(message)s"",
+                                datefmt='%m/%d/%Y %I:%M:%S %p')
+        self.__log = LOG
 
         # Process the credentials
-        credentials_fname = self.__serverConfig.get('global','credentials_file')
+        credentials_fname = self.__serverConfig.get('global', 'credentials_file')
         if credentials_fname != """":
             cred = open(credentials_fname)
             line = cred.readline()
@@ -4430,13 +4497,14 @@ def addCredential(self, name, uid, lmhash, nthash):
                 lmhash = '0%s' % lmhash
             if len(nthash) % 2:
                 nthash = '0%s' % nthash
-            try: # just in case they were converted already
+            try:  # just in case they were converted already
                 lmhash = a2b_hex(lmhash)
                 nthash = a2b_hex(nthash)
             except:
                 pass
         self.__credentials[name.lower()] = (uid, lmhash, nthash)
 
+
 # For windows platforms, opening a directory is not an option, so we set a void FD
 VOID_FILE_DESCRIPTOR = -1
 PIPE_FILE_DESCRIPTOR = -2
@@ -4447,19 +4515,21 @@ def addCredential(self, name, uid, lmhash, nthash):
 
 from impacket.dcerpc.v5.rpcrt import DCERPCServer
 from impacket.dcerpc.v5.dtypes import NULL
-from impacket.dcerpc.v5.srvs import NetrShareEnum, NetrShareEnumResponse, SHARE_INFO_1, NetrServerGetInfo, NetrServerGetInfoResponse, NetrShareGetInfo, NetrShareGetInfoResponse
+from impacket.dcerpc.v5.srvs import NetrShareEnum, NetrShareEnumResponse, SHARE_INFO_1, NetrServerGetInfo, \
+    NetrServerGetInfoResponse, NetrShareGetInfo, NetrShareGetInfoResponse
 from impacket.dcerpc.v5.wkst import NetrWkstaGetInfo, NetrWkstaGetInfoResponse
 from impacket.system_errors import ERROR_INVALID_LEVEL
 
+
 class WKSTServer(DCERPCServer):
     def __init__(self):
         DCERPCServer.__init__(self)
         self.wkssvcCallBacks = {
             0: self.NetrWkstaGetInfo,
         }
-        self.addCallbacks(('6BFFD098-A112-3610-9833-46C3F87E345A', '1.0'),'\\PIPE\\wkssvc', self.wkssvcCallBacks)
+        self.addCallbacks(('6BFFD098-A112-3610-9833-46C3F87E345A', '1.0'), '\\PIPE\\wkssvc', self.wkssvcCallBacks)
 
-    def NetrWkstaGetInfo(self,data):
+    def NetrWkstaGetInfo(self, data):
         request = NetrWkstaGetInfo(data)
         self.log(""NetrWkstaGetInfo Level: %d"" % request['Level'])
 
@@ -4489,6 +4559,7 @@ def NetrWkstaGetInfo(self,data):
 
         return answer
 
+
 class SRVSServer(DCERPCServer):
     def __init__(self):
         DCERPCServer.__init__(self)
@@ -4503,86 +4574,87 @@ def __init__(self):
             21: self.NetrServerGetInfo,
         }
 
-        self.addCallbacks(('4B324FC8-1670-01D3-1278-5A47BF6EE188', '3.0'),'\\PIPE\\srvsvc', self.srvsvcCallBacks)
+        self.addCallbacks(('4B324FC8-1670-01D3-1278-5A47BF6EE188', '3.0'), '\\PIPE\\srvsvc', self.srvsvcCallBacks)
 
     def setServerConfig(self, config):
         self.__serverConfig = config
 
     def processConfigFile(self, configFile=None):
-       if configFile is not None:
-           self.__serverConfig = configparser.ConfigParser()
-           self.__serverConfig.read(configFile)
-       sections = self.__serverConfig.sections()
-       # Let's check the log file
-       self.__logFile      = self.__serverConfig.get('global','log_file')
-       if self.__logFile != 'None':
-            logging.basicConfig(filename = self.__logFile, 
-                             level = logging.DEBUG, 
-                             format=""%(asctime)s: %(levelname)s: %(message)s"", 
-                             datefmt = '%m/%d/%Y %I:%M:%S %p')
-
-       # Remove the global one
-       del(sections[sections.index('global')])
-       self._shares = {}
-       for i in sections:
-           self._shares[i] = dict(self.__serverConfig.items(i))
-
-    def NetrShareGetInfo(self,data):
-       request = NetrShareGetInfo(data)
-       self.log(""NetrGetShareInfo Level: %d"" % request['Level'])
-
-       s = request['NetName'][:-1].upper()
-       answer = NetrShareGetInfoResponse()
-       if s in self._shares:
-           share  = self._shares[s]
-
-           answer['InfoStruct']['tag'] = 1
-           answer['InfoStruct']['ShareInfo1']['shi1_netname']= s+'\x00'
-           answer['InfoStruct']['ShareInfo1']['shi1_type']   = share['share type']
-           answer['InfoStruct']['ShareInfo1']['shi1_remark'] = share['comment']+'\x00' 
-           answer['ErrorCode'] = 0
-       else:
-           answer['InfoStruct']['tag'] = 1
-           answer['InfoStruct']['ShareInfo1']= NULL
-           answer['ErrorCode'] = 0x0906 #WERR_NET_NAME_NOT_FOUND
-
-       return answer
-
-    def NetrServerGetInfo(self,data):
-       request = NetrServerGetInfo(data)
-       self.log(""NetrServerGetInfo Level: %d"" % request['Level'])
-       answer = NetrServerGetInfoResponse()
-       answer['InfoStruct']['tag'] = 101
-       # PLATFORM_ID_NT = 500
-       answer['InfoStruct']['ServerInfo101']['sv101_platform_id'] = 500
-       answer['InfoStruct']['ServerInfo101']['sv101_name'] = request['ServerName']
-       # Windows 7 = 6.1
-       answer['InfoStruct']['ServerInfo101']['sv101_version_major'] = 6
-       answer['InfoStruct']['ServerInfo101']['sv101_version_minor'] = 1
-       # Workstation = 1
-       answer['InfoStruct']['ServerInfo101']['sv101_type'] = 1
-       answer['InfoStruct']['ServerInfo101']['sv101_comment'] = NULL
-       answer['ErrorCode'] = 0
-       return answer
+        if configFile is not None:
+            self.__serverConfig = configparser.ConfigParser()
+            self.__serverConfig.read(configFile)
+        sections = self.__serverConfig.sections()
+        # Let's check the log file
+        self.__logFile = self.__serverConfig.get('global', 'log_file')
+        if self.__logFile != 'None':
+            logging.basicConfig(filename=self.__logFile,
+                                level=logging.DEBUG,
+                                format=""%(asctime)s: %(levelname)s: %(message)s"",
+                                datefmt='%m/%d/%Y %I:%M:%S %p')
+
+        # Remove the global one
+        del (sections[sections.index('global')])
+        self._shares = {}
+        for i in sections:
+            self._shares[i] = dict(self.__serverConfig.items(i))
+
+    def NetrShareGetInfo(self, data):
+        request = NetrShareGetInfo(data)
+        self.log(""NetrGetShareInfo Level: %d"" % request['Level'])
+
+        s = request['NetName'][:-1].upper()
+        answer = NetrShareGetInfoResponse()
+        if s in self._shares:
+            share = self._shares[s]
+
+            answer['InfoStruct']['tag'] = 1
+            answer['InfoStruct']['ShareInfo1']['shi1_netname'] = s + '\x00'
+            answer['InfoStruct']['ShareInfo1']['shi1_type'] = share['share type']
+            answer['InfoStruct']['ShareInfo1']['shi1_remark'] = share['comment'] + '\x00'
+            answer['ErrorCode'] = 0
+        else:
+            answer['InfoStruct']['tag'] = 1
+            answer['InfoStruct']['ShareInfo1'] = NULL
+            answer['ErrorCode'] = 0x0906  # WERR_NET_NAME_NOT_FOUND
+
+        return answer
+
+    def NetrServerGetInfo(self, data):
+        request = NetrServerGetInfo(data)
+        self.log(""NetrServerGetInfo Level: %d"" % request['Level'])
+        answer = NetrServerGetInfoResponse()
+        answer['InfoStruct']['tag'] = 101
+        # PLATFORM_ID_NT = 500
+        answer['InfoStruct']['ServerInfo101']['sv101_platform_id'] = 500
+        answer['InfoStruct']['ServerInfo101']['sv101_name'] = request['ServerName']
+        # Windows 7 = 6.1
+        answer['InfoStruct']['ServerInfo101']['sv101_version_major'] = 6
+        answer['InfoStruct']['ServerInfo101']['sv101_version_minor'] = 1
+        # Workstation = 1
+        answer['InfoStruct']['ServerInfo101']['sv101_type'] = 1
+        answer['InfoStruct']['ServerInfo101']['sv101_comment'] = NULL
+        answer['ErrorCode'] = 0
+        return answer
 
     def NetrShareEnum(self, data):
-       request = NetrShareEnum(data)
-       self.log(""NetrShareEnum Level: %d"" % request['InfoStruct']['Level'])
-       shareEnum = NetrShareEnumResponse()
-       shareEnum['InfoStruct']['Level'] = 1
-       shareEnum['InfoStruct']['ShareInfo']['tag'] = 1
-       shareEnum['TotalEntries'] = len(self._shares)
-       shareEnum['InfoStruct']['ShareInfo']['Level1']['EntriesRead'] = len(self._shares)
-       shareEnum['ErrorCode'] = 0
-
-       for i in self._shares:
-           shareInfo = SHARE_INFO_1()
-           shareInfo['shi1_netname'] = i+'\x00'
-           shareInfo['shi1_type'] = self._shares[i]['share type']
-           shareInfo['shi1_remark'] = self._shares[i]['comment']+'\x00'
-           shareEnum['InfoStruct']['ShareInfo']['Level1']['Buffer'].append(shareInfo)
-
-       return shareEnum
+        request = NetrShareEnum(data)
+        self.log(""NetrShareEnum Level: %d"" % request['InfoStruct']['Level'])
+        shareEnum = NetrShareEnumResponse()
+        shareEnum['InfoStruct']['Level'] = 1
+        shareEnum['InfoStruct']['ShareInfo']['tag'] = 1
+        shareEnum['TotalEntries'] = len(self._shares)
+        shareEnum['InfoStruct']['ShareInfo']['Level1']['EntriesRead'] = len(self._shares)
+        shareEnum['ErrorCode'] = 0
+
+        for i in self._shares:
+            shareInfo = SHARE_INFO_1()
+            shareInfo['shi1_netname'] = i + '\x00'
+            shareInfo['shi1_type'] = self._shares[i]['share type']
+            shareInfo['shi1_remark'] = self._shares[i]['comment'] + '\x00'
+            shareEnum['InfoStruct']['ShareInfo']['Level1']['Buffer'].append(shareInfo)
+
+        return shareEnum
+
 
 class SimpleSMBServer:
     """"""
@@ -4592,44 +4664,47 @@ class SimpleSMBServer:
     :param integer listenPort: the port number you want the server to listen on
     :param string configFile: a file with all the servers' configuration. If no file specified, this class will create the basic parameters needed to run. You will need to add your shares manually tho. See addShare() method
     """"""
-    def __init__(self, listenAddress = '0.0.0.0', listenPort=445, configFile=''):
+
+    def __init__(self, listenAddress='0.0.0.0', listenPort=445, configFile=''):
         if configFile != '':
-            self.__server = SMBSERVER((listenAddress,listenPort))
+            self.__server = SMBSERVER((listenAddress, listenPort))
             self.__server.processConfigFile(configFile)
             self.__smbConfig = None
         else:
             # Here we write a mini config for the server
             self.__smbConfig = configparser.ConfigParser()
             self.__smbConfig.add_section('global')
-            self.__smbConfig.set('global','server_name',''.join([random.choice(string.ascii_letters) for _ in range(8)]))
-            self.__smbConfig.set('global','server_os',''.join([random.choice(string.ascii_letters) for _ in range(8)])
-)
-            self.__smbConfig.set('global','server_domain',''.join([random.choice(string.ascii_letters) for _ in range(8)])
-)
-            self.__smbConfig.set('global','log_file','None')
-            self.__smbConfig.set('global','rpc_apis','yes')
-            self.__smbConfig.set('global','credentials_file','')
-            self.__smbConfig.set('global', 'challenge', ""A""*16)
+            self.__smbConfig.set('global', 'server_name',
+                                 ''.join([random.choice(string.ascii_letters) for _ in range(8)]))
+            self.__smbConfig.set('global', 'server_os', ''.join([random.choice(string.ascii_letters) for _ in range(8)])
+                                 )
+            self.__smbConfig.set('global', 'server_domain',
+                                 ''.join([random.choice(string.ascii_letters) for _ in range(8)])
+                                 )
+            self.__smbConfig.set('global', 'log_file', 'None')
+            self.__smbConfig.set('global', 'rpc_apis', 'yes')
+            self.__smbConfig.set('global', 'credentials_file', '')
+            self.__smbConfig.set('global', 'challenge', ""A"" * 16)
 
             # IPC always needed
             self.__smbConfig.add_section('IPC$')
-            self.__smbConfig.set('IPC$','comment','')
-            self.__smbConfig.set('IPC$','read only','yes')
-            self.__smbConfig.set('IPC$','share type','3')
-            self.__smbConfig.set('IPC$','path','')
-            self.__server = SMBSERVER((listenAddress,listenPort), config_parser = self.__smbConfig)
+            self.__smbConfig.set('IPC$', 'comment', '')
+            self.__smbConfig.set('IPC$', 'read only', 'yes')
+            self.__smbConfig.set('IPC$', 'share type', '3')
+            self.__smbConfig.set('IPC$', 'path', '')
+            self.__server = SMBSERVER((listenAddress, listenPort), config_parser=self.__smbConfig)
             self.__server.processConfigFile()
 
-        # Now we have to register the MS-SRVS server. This specially important for 
-        # Windows 7+ and Mavericks clients since they WON'T (specially OSX) 
+        # Now we have to register the MS-SRVS server. This specially important for
+        # Windows 7+ and Mavericks clients since they WON'T (specially OSX)
         # ask for shares using MS-RAP.
 
         self.__srvsServer = SRVSServer()
         self.__srvsServer.daemon = True
         self.__wkstServer = WKSTServer()
         self.__wkstServer.daemon = True
-        self.__server.registerNamedPipe('srvsvc',('127.0.0.1',self.__srvsServer.getListenPort()))
-        self.__server.registerNamedPipe('wkssvc',('127.0.0.1',self.__wkstServer.getListenPort()))
+        self.__server.registerNamedPipe('srvsvc', ('127.0.0.1', self.__srvsServer.getListenPort()))
+        self.__server.registerNamedPipe('wkssvc', ('127.0.0.1', self.__wkstServer.getListenPort()))
 
     def start(self):
         self.__srvsServer.start()
@@ -4645,7 +4720,7 @@ def unregisterNamedPipe(self, pipeName):
     def getRegisteredNamedPipes(self):
         return self.__server.getRegisteredNamedPipes()
 
-    def addShare(self, shareName, sharePath, shareComment='', shareType = '0', readOnly = 'no'):
+    def addShare(self, shareName, sharePath, shareComment='', shareType='0', readOnly='no'):
         share = shareName.upper()
         self.__smbConfig.add_section(share)
         self.__smbConfig.set(share, 'comment', shareComment)
@@ -4669,14 +4744,14 @@ def setSMBChallenge(self, challenge):
             self.__smbConfig.set('global', 'challenge', challenge)
             self.__server.setServerConfig(self.__smbConfig)
             self.__server.processConfigFile()
-        
+
     def setLogFile(self, logFile):
-        self.__smbConfig.set('global','log_file',logFile)
+        self.__smbConfig.set('global', 'log_file', logFile)
         self.__server.setServerConfig(self.__smbConfig)
         self.__server.processConfigFile()
 
     def setCredentialsFile(self, logFile):
-        self.__smbConfig.set('global','credentials_file',logFile)
+        self.__smbConfig.set('global', 'credentials_file', logFile)
         self.__server.setServerConfig(self.__smbConfig)
         self.__server.processConfigFile()"
GHSA-9236-8w7q-rmrv,"From 796c3ae318eea183fc88c87ec5a27355b0f6a99d Mon Sep 17 00:00:00 2001
From: Uzay-G <uzgirit@gmail.com>
Date: Fri, 24 Dec 2021 12:16:44 +0100
Subject: [PATCH] better CSRF protection; change delete route to POST

---
 archivy/__init__.py                           | 2 ++
 archivy/click_web/resources/cmd_exec.py       | 6 ++----
 archivy/routes.py                             | 2 +-
 archivy/templates/click_web/command_form.html | 1 +
 archivy/templates/dataobjs/show.html          | 2 +-
 tests/functional/test_routes.py               | 4 ++--
 6 files changed, 9 insertions(+), 8 deletions(-)

diff --git a/archivy/__init__.py b/archivy/__init__.py
index b3aa3e7c..a4eaeee9 100644
--- a/archivy/__init__.py
+++ b/archivy/__init__.py
@@ -6,6 +6,7 @@
 from flask import Flask
 from flask_compress import Compress
 from flask_login import LoginManager
+from flask_wtf.csrf import CSRFProtect
 
 from archivy import helpers
 from archivy.api import api_bp
@@ -77,6 +78,7 @@
 login_manager.login_view = ""login""
 login_manager.init_app(app)
 app.register_blueprint(api_bp, url_prefix=""/api"")
+csrf = CSRFProtect(app)
 
 # compress files
 Compress(app)
diff --git a/archivy/click_web/resources/cmd_exec.py b/archivy/click_web/resources/cmd_exec.py
index 3e31f89c..c92e9d07 100644
--- a/archivy/click_web/resources/cmd_exec.py
+++ b/archivy/click_web/resources/cmd_exec.py
@@ -137,10 +137,8 @@ def _get_download_link(field_info):
 
 class RequestToCommandArgs:
     def __init__(self):
-        field_infos = [
-            FieldInfo.factory(key)
-            for key in list(request.form.keys()) + list(request.files.keys())
-        ]
+        keys = [key for key in list(request.form.keys()) + list(request.files.keys())]
+        field_infos = [FieldInfo.factory(key) for key in keys if key != ""csrf_token""]
         # important to sort them so they will be in expected order on command line
         self.field_infos = list(sorted(field_infos))
 
diff --git a/archivy/routes.py b/archivy/routes.py
index 1c623a5b..dc7a368a 100644
--- a/archivy/routes.py
+++ b/archivy/routes.py
@@ -232,7 +232,7 @@ def move_item(dataobj_id):
         return redirect(f""/dataobj/{dataobj_id}"")
 
 
-@app.route(""/dataobj/delete/<int:dataobj_id>"", methods=[""DELETE"", ""GET""])
+@app.route(""/dataobj/delete/<int:dataobj_id>"", methods=[""POST""])
 def delete_data(dataobj_id):
     try:
         data.delete_item(dataobj_id)
diff --git a/archivy/templates/click_web/command_form.html b/archivy/templates/click_web/command_form.html
index cdffd0cf..3c68052a 100644
--- a/archivy/templates/click_web/command_form.html
+++ b/archivy/templates/click_web/command_form.html
@@ -29,6 +29,7 @@ <h3 class=""command-title"">{{ command.name|title }}</h3>
             </div>
         {% endfor %}
     {% endfor %}
+	<input type=""hidden"" name=""csrf_token"" value=""{{ csrf_token() }}""/>
     <button type=""submit"" id=""submit_btn"" class=""btn btn-primary m-2"">Run</button>
 </form>
 
diff --git a/archivy/templates/dataobjs/show.html b/archivy/templates/dataobjs/show.html
index aad86636..83781921 100644
--- a/archivy/templates/dataobjs/show.html
+++ b/archivy/templates/dataobjs/show.html
@@ -71,7 +71,7 @@ <h2 id=""post-title"">
             <svg class=""octicon"" xmlns=""http://www.w3.org/2000/svg"" viewBox=""0 0 16 16"" width=""16"" height=""16""><path fill-rule=""evenodd"" d=""M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z""></path></svg>
             <span>Edit</span>
           </button>
-          <form action=""/dataobj/delete/{{ dataobj['id'] }}"" method=""delete"" onsubmit=""return confirm('Delete this item permanently?')"" novalidate>
+          <form action=""/dataobj/delete/{{ dataobj['id'] }}"" method=""POST"" onsubmit=""return confirm('Delete this item permanently?')"" novalidate>
             {{ form.hidden_tag() }}
             <button class=""btn btn-delete"">
               <svg class=""octicon"" xmlns=""http://www.w3.org/2000/svg"" viewBox=""0 0 16 16"" width=""16"" height=""16""><path fill-rule=""evenodd"" d=""M6.5 1.75a.25.25 0 01.25-.25h2.5a.25.25 0 01.25.25V3h-3V1.75zm4.5 0V3h2.25a.75.75 0 010 1.5H2.75a.75.75 0 010-1.5H5V1.75C5 .784 5.784 0 6.75 0h2.5C10.216 0 11 .784 11 1.75zM4.496 6.675a.75.75 0 10-1.492.15l.66 6.6A1.75 1.75 0 005.405 15h5.19c.9 0 1.652-.681 1.741-1.576l.66-6.6a.75.75 0 00-1.492-.149l-.66 6.6a.25.25 0 01-.249.225h-5.19a.25.25 0 01-.249-.225l-.66-6.6z""></path></svg>
diff --git a/tests/functional/test_routes.py b/tests/functional/test_routes.py
index 836f38b4..7e59bf42 100644
--- a/tests/functional/test_routes.py
+++ b/tests/functional/test_routes.py
@@ -61,12 +61,12 @@ def test_get_dataobj(test_app, client: FlaskClient, note_fixture):
 
 
 def test_get_delete_dataobj_not_found(test_app, client: FlaskClient):
-    response = client.get(""/dataobj/delete/1"")
+    response = client.post(""/dataobj/delete/1"")
     assert response.status_code == 302
 
 
 def test_get_delete_dataobj(test_app, client: FlaskClient, note_fixture):
-    response = client.get(""/dataobj/delete/1"")
+    response = client.post(""/dataobj/delete/1"")
     assert response.status_code == 302"
CVE-2019-10160,"From f61599b050c621386a3fc6bc480359e2d3bb93de Mon Sep 17 00:00:00 2001
From: Steve Dower <steve.dower@python.org>
Date: Tue, 4 Jun 2019 09:40:16 -0700
Subject: [PATCH] bpo-36742: Corrects fix to handle decomposition in usernames
 (GH-13812)

---
 Lib/test/test_urlparse.py | 13 +++++++------
 Lib/urlparse.py           | 12 ++++++------
 2 files changed, 13 insertions(+), 12 deletions(-)

diff --git a/Lib/test/test_urlparse.py b/Lib/test/test_urlparse.py
index 6fd1071bf7cdec..857ed96d92fe2d 100644
--- a/Lib/test/test_urlparse.py
+++ b/Lib/test/test_urlparse.py
@@ -648,12 +648,13 @@ def test_urlsplit_normalization(self):
             urlparse.urlsplit(u'http://\u30d5\u309a\ufe1380')
 
         for scheme in [u""http"", u""https"", u""ftp""]:
-            for c in denorm_chars:
-                url = u""{}://netloc{}false.netloc/path"".format(scheme, c)
-                if test_support.verbose:
-                    print ""Checking %r"" % url
-                with self.assertRaises(ValueError):
-                    urlparse.urlsplit(url)
+            for netloc in [u""netloc{}false.netloc"", u""n{}user@netloc""]:
+                for c in denorm_chars:
+                    url = u""{}://{}/path"".format(scheme, netloc.format(c))
+                    if test_support.verbose:
+                        print ""Checking %r"" % url
+                    with self.assertRaises(ValueError):
+                        urlparse.urlsplit(url)
 
 def test_main():
     test_support.run_unittest(UrlParseTestCase)
diff --git a/Lib/urlparse.py b/Lib/urlparse.py
index f08e0fe58432ce..6834f3c1798b09 100644
--- a/Lib/urlparse.py
+++ b/Lib/urlparse.py
@@ -171,17 +171,17 @@ def _checknetloc(netloc):
     # looking for characters like \u2100 that expand to 'a/c'
     # IDNA uses NFKC equivalence, so normalize for this check
     import unicodedata
-    n = netloc.rpartition('@')[2] # ignore anything to the left of '@'
-    n = n.replace(':', '')        # ignore characters already included
-    n = n.replace('#', '')        # but not the surrounding text
-    n = n.replace('?', '')
+    n = netloc.replace(u'@', u'') # ignore characters already included
+    n = n.replace(u':', u'')      # but not the surrounding text
+    n = n.replace(u'#', u'')
+    n = n.replace(u'?', u'')
     netloc2 = unicodedata.normalize('NFKC', n)
     if n == netloc2:
         return
     for c in '/?#@:':
         if c in netloc2:
-            raise ValueError(""netloc '"" + netloc + ""' contains invalid "" +
-                             ""characters under NFKC normalization"")
+            raise ValueError(u""netloc '"" + netloc + u""' contains invalid "" +
+                             u""characters under NFKC normalization"")
 
 def urlsplit(url, scheme='', allow_fragments=True):
     """"""Parse a URL into 5 components:"
CVE-2020-28919,"From e7fd8e4c90be490e4293ec91804d00ec01af5ca6 Mon Sep 17 00:00:00 2001
From: Lars Michelsen <lm@tribe29.com>
Date: Tue, 20 Oct 2020 16:31:19 +0200
Subject: [PATCH] Prevent non http/https links from being unescaped

Our permissive HTML escaping is preserving some HTML tags, which includes basic
link tags (a tag with href and optional target attributes). Previous versions
were not inspecting the value of href, which made it possible to add links with
e.g. a ""javascript:"" protocol. This opened some XSS attack vectors.

After this change it is only possible to link to http and https protocols. All
other links will not be unescaped.

Change-Id: I6e029ecc52f3dd3fc1f213c7f809332e3e49b3ee
---
 cmk/gui/escaping.py                        |  6 ++++++
 tests/unit/cmk/gui/test_htmllib_Escaper.py | 10 ++++++++--
 2 files changed, 14 insertions(+), 2 deletions(-)

diff --git a/cmk/gui/escaping.py b/cmk/gui/escaping.py
index 03dcdda9ed3..6f7db543e48 100644
--- a/cmk/gui/escaping.py
+++ b/cmk/gui/escaping.py
@@ -7,6 +7,7 @@
 from html import escape as html_escape
 import re
 from typing import Union
+from urllib.parse import urlparse
 
 from six import ensure_str
 
@@ -113,6 +114,11 @@ def escape_text(text: EscapableEntity) -> str:
     text = _UNESCAPER_TEXT.sub(r'<\1\2>', text)
     for a_href in _A_HREF.finditer(text):
         href = a_href.group(1)
+
+        parsed = urlparse(href)
+        if parsed.scheme != """" and parsed.scheme not in [""http"", ""https""]:
+            continue  # Do not unescape links containing disallowed URLs
+
         target = a_href.group(2)
 
         if target:
diff --git a/tests/unit/cmk/gui/test_htmllib_Escaper.py b/tests/unit/cmk/gui/test_htmllib_Escaper.py
index 3a34499bad4..6a015c82202 100644
--- a/tests/unit/cmk/gui/test_htmllib_Escaper.py
+++ b/tests/unit/cmk/gui/test_htmllib_Escaper.py
@@ -72,8 +72,14 @@ def test_unescape_attribute(inp, out):
             ""<a href=\""xyz\"">abc</a>&lt;script&gt;alert(1)&lt;/script&gt;<a href=\""xyz\"">abc</a>"",
         ),
         (""&nbsp;"", None),
-        # At the moment also javascript URLs are accepted. This will be refused in the next step
-        (""<a href=\""javascript:alert(1)\"">abc</a>"", None),
+        # Only http/https are allowed as schemes
+        (""<a href=\""http://checkmk.com/\"">abc</a>"", None),
+        (""<a href=\""https://checkmk.com/\"">abc</a>"", None),
+        (""<a href=\""HTTP://CHECKMK.COM/\"">abc</a>"", None),
+        (""<a href=\""ftp://checkmk.com/\"">abc</a>"",
+         ""&lt;a href=&quot;ftp://checkmk.com/&quot;&gt;abc</a>""),
+        (""<a href=\""javascript:alert(1)\"">abc</a>"",
+         ""&lt;a href=&quot;javascript:alert(1)&quot;&gt;abc</a>""),
     ])
 def test_escape_text(inp, out):
     if out is None:"
GHSA-c2w9-48qc-qpj4,"From 3f8f659ef443ab870bb19f95d43543470168ae04 Mon Sep 17 00:00:00 2001
From: Tomohiro Nakamura <quickness.net@gmail.com>
Date: Wed, 13 Sep 2017 20:49:38 +0900
Subject: [PATCH] Fix security issue refs #4

* Update version to 1.0.5
* Update to use yaml.safe_load()
* Update to tomoh1r
---
 .travis.yml                       | 20 +++++++++++++-------
 CHANGES.txt                       | 10 ++++++++++
 README.rst                        |  4 ++--
 README_test.rst                   |  1 +
 ansible_vault/api.py              |  2 +-
 ansible_vault/test/file/pwned.txt |  7 +++++++
 ansible_vault/test/test_api.py    | 10 ++++++++--
 setup.cfg                         |  8 ++++++++
 setup.py                          |  8 +++++---
 tox.ini                           | 14 --------------
 10 files changed, 55 insertions(+), 29 deletions(-)
 create mode 100644 ansible_vault/test/file/pwned.txt
 delete mode 100644 tox.ini

diff --git a/.travis.yml b/.travis.yml
index 70055d9..7b6b1ed 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -1,14 +1,20 @@
 ---
 language: python
 sudo: false
+cache:
+  directories:
+    - $HOME/.cache/pip
 python:
-- 2.7
-env:
-  matrix:
-    - TOXENV=py27
-    - TOXENV=py27-ansible2
+  - ""2.7""
+  - ""3.3""
+  - ""3.4""
+  - ""3.5""
+  - ""3.6""
 install:
-  - pip install tox
-script: tox
+  - python -m pip install -U setuptools pip
+  - python setup.py setup_test
+script:
+  - python -m pytest
+  - if [ ""$TRAVIS_PYTHON_VERSION"" == '2.7' ] ; then python -m pip install -U 'ansible<2.0.0' && python -m pytest ; fi
 
 # vim:st=2 sts=2 sw=2:
diff --git a/CHANGES.txt b/CHANGES.txt
index 1e8aa4e..a51a244 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,3 +1,13 @@
+1.0.5 (2017/09/13)
+
+* Update to use yaml.safe_load()$
+* Update to tomoh1r$
+
+1.0.4 (2015/11/29)
+
+* Apply to Ansible 2
+* Add unit tests
+
 1.0.3 (2015/05/18)
 
 * fix README.rst typo
diff --git a/README.rst b/README.rst
index 0663322..63a8dd3 100644
--- a/README.rst
+++ b/README.rst
@@ -2,8 +2,8 @@
 ansible-vault
 =============
 
-.. image:: https://travis-ci.org/jptomo/ansible-vault.svg?branch=master
-   :target: https://travis-ci.org/jptomo/ansible-vault
+.. image:: https://travis-ci.org/tomoh1r/ansible-vault.svg?branch=master
+   :target: https://travis-ci.org/tomoh1r/ansible-vault
 
 This project aim to R/W an ansible-vault yaml file
 
diff --git a/README_test.rst b/README_test.rst
index be5691d..57ce749 100644
--- a/README_test.rst
+++ b/README_test.rst
@@ -12,4 +12,5 @@ how to test
 
    .. code-block:: console
 
+      $ ./venvtest/bin/python setup.py setup_test
       $ ./venvtest/bin/python setup.py test
diff --git a/ansible_vault/api.py b/ansible_vault/api.py
index 3fcc0ad..2f209c1 100644
--- a/ansible_vault/api.py
+++ b/ansible_vault/api.py
@@ -15,7 +15,7 @@ def __init__(self, password):
 
     def load(self, stream):
         '''read vault steam and return python object'''
-        return yaml.load(self.vault.decrypt(stream))
+        return yaml.safe_load(self.vault.decrypt(stream))
 
     def dump(self, data, stream=None):
         '''encrypt data and print stdout or write to stream'''
diff --git a/ansible_vault/test/file/pwned.txt b/ansible_vault/test/file/pwned.txt
new file mode 100644
index 0000000..7e21b6e
--- /dev/null
+++ b/ansible_vault/test/file/pwned.txt
@@ -0,0 +1,7 @@
+$ANSIBLE_VAULT;1.1;AES256
+31616433623434626463363932323936663066353063393731346536636437633463633137643032
+3663656431663830396662646132343735623538346330640a363532326262353732636161633431
+61353936346235396464333333653831356638393264343662363362653433353762396663653465
+6439366430336336660a363931663030323665633136363362353162333864653933653763656462
+31656431653333343834623731393263393865353831333963616165613237376630646665306363
+6238373037663462343565643737303136333032386136356438
diff --git a/ansible_vault/test/test_api.py b/ansible_vault/test/test_api.py
index 2535d5c..5a123d3 100644
--- a/ansible_vault/test/test_api.py
+++ b/ansible_vault/test/test_api.py
@@ -1,9 +1,9 @@
 import os
 from tempfile import mkstemp
 
-from testfixtures import ShouldRaise
-
 from ansible.errors import AnsibleError
+from testfixtures import ShouldRaise
+from yaml.constructor import ConstructorError
 
 
 here = os.path.dirname(os.path.abspath(__file__))
@@ -28,6 +28,12 @@ def test_cannot(self):
         with ShouldRaise(AnsibleError('Decryption failed')):
             vault.load(open(fpath).read())
 
+    def test_not_pwned(self):
+        fpath = os.path.join(here, 'file', 'pwned.txt')
+        vault = self._makeOne('password')
+        with ShouldRaise(ConstructorError):
+            vault.load(open(fpath).read())
+
 
 class TestVaultDump(object):
     def _getTargetClass(self):
diff --git a/setup.cfg b/setup.cfg
index 5aef279..fc590f8 100644
--- a/setup.cfg
+++ b/setup.cfg
@@ -1,2 +1,10 @@
 [metadata]
 description-file = README.rst
+
+[aliases]
+setup_test = develop easy_install ansible-vault[test]
+release = register clean --all sdist
+
+[tools:pytest]
+norecursedirs = venv
+testpaths = ansible_vault/test
diff --git a/setup.py b/setup.py
index c42a8c4..6c4b2f2 100644
--- a/setup.py
+++ b/setup.py
@@ -32,19 +32,21 @@ def run_tests(self):
 
 setup(
     name='ansible-vault',
-    version='1.0.4',
+    version='1.0.5',
     author='Tomohiro NAKAMURA',
     author_email='quickness.net@gmail.com',
-    url='https://github.com/jptomo/ansible-vault',
+    url='https://github.com/tomoh1r/ansible-vault',
     description='R/W an ansible-vault yaml file',
     long_description=_read('README.rst'),
     packages=find_packages(),
     install_requires=['ansible'],
-    tests_require=['pytest', 'testfixtures'],
     cmdclass={'test': PyTest},
     classifiers=[
         'Development Status :: 5 - Production/Stable',
         'License :: OSI Approved :: GNU General Public License v3 (GPLv3)',
     ],
     license='GPLv3',
+    extras_require = {
+        'test': ['pytest', 'testfixtures'],
+    }
 )
diff --git a/tox.ini b/tox.ini
deleted file mode 100644
index cb350f9..0000000
--- a/tox.ini
+++ /dev/null
@@ -1,14 +0,0 @@
-[tox]
-envlist = py27, py27-ansible2
-setupdir = .
-
-[testenv]
-basepython = python2.7
-
-[testenv:py27]
-commands = python2.7 setup.py test
-
-[testenv:py27-ansible2]
-commands =
-    pip install -U git+https://github.com/ansible/ansible.git@stable-2.0#egg=ansible
-    python2.7 setup.py test"
GHSA-rcrv-228c-gprj,"From b307d70bedf745305fa0dd3c5c600d8cb88d09b5 Mon Sep 17 00:00:00 2001
From: Ouroboros Chrysopoeia <impredicative@users.noreply.github.com>
Date: Wed, 19 Jan 2022 15:02:18 -0500
Subject: [PATCH] Stop rewriting bit.ly with j.mp because this suddenly doesn't
 seem to work anymore

---
 README.md                   | 14 +++++++-------
 bitlyshortener/shortener.py |  5 +----
 scripts/try_shortener.py    |  4 +---
 3 files changed, 9 insertions(+), 14 deletions(-)

diff --git a/README.md b/README.md
index 9d5084c..e58a806 100644
--- a/README.md
+++ b/README.md
@@ -33,7 +33,7 @@ The following have historically been the rate limits per token:
 * Per hour: 1000 (presumably for status 200 or 201)
 * Per month: 1000 (presumably for status 201 only)
 
-Bitly sends a monthly email if if 50% of the account's usage limit for new short links is exceeded for the calendar month.
+Bitly sends a monthly email if 50% of the account's usage limit for new short links is exceeded for the calendar month.
 If this email is received, it is suggested to immediately obtain and add additional tokens to the pool used by this package.
 As follows, it is preferable to stay under 50% of the usage limit by having a sufficiently big pool of tokens.
 It is possible to monitor the usage via the **`.usage()`** method as shown in the examples.
@@ -41,7 +41,7 @@ It is possible to monitor the usage via the **`.usage()`** method as shown in th
 It is unknown what the per-IP rate limit is, if any.
 
 ### Python
-Python 3.7+ is required.
+Python 3.7 is required.
 Any older version of Python will not work due to the use of 
 [`ThreadPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor)
 with an *initializer*.
@@ -62,19 +62,19 @@ Usage examples:
 # Shorten to list
 >>> long_urls = ['https://www.amazon.com/gp/product/B07LFJMS2S/', 'https://www.cnn.com/election/2020', 'https://paperswithcode.com/sota']
 >>> shortener.shorten_urls(long_urls)
-['https://amzn.to/2HcWFgV', 'https://cnn.it/3ofdpVp', 'https://j.mp/2IHwQ8P']
+['https://amzn.to/3Inxf9V', 'https://cnn.it/3FKKZd8', 'https://bit.ly/3tLlp5w']
 
 # Shorten to dict
 >>> long_urls = ['https://news.google.com', 'https://yahoo.com/']
 >>> shortener.shorten_urls_to_dict(long_urls)
-{'https://news.google.com': 'https://j.mp/31t9qL2', 'https://yahoo.com/': 'https://yhoo.it/3ondJS2'}
+{'https://news.google.com': 'https://bit.ly/3IjSObD', 'https://yahoo.com/': 'https://yhoo.it/2BiHgp8'}
 
 # Normalize diverse preexisting Bitly links
->>> urls = ['http://j.mp/2Bo2LVf', 'http://bit.ly/2BombJQ', 'https://cnn.it/2Ggb2ih', 'https://j.mp/websniffer']
+>>> urls = ['http://bit.ly/3Ad49Hw', 'http://j.mp/2Bo2LVf', 'https://cnn.it/3FKKZd8', 'https://j.mp/websniffer']
 >>> shortener.shorten_urls(urls)
-['https://j.mp/37qFvH0', 'https://j.mp/3obETLt', 'https://cnn.it/2FMI6jc', 'https://j.mp/37FmjFV']
+['https://bit.ly/3Ad49Hw', 'https://bit.ly/3KjocZw', 'https://cnn.it/3FKKZd8', 'https://bit.ly/3nINKph']
 
-# Show usage for tokens pool (cached for an hour)
+# Show usage for tokens pool (is cached for an hour)
 >>> shortener.usage()
 0.4604  # Means that an average of 46% of the current calendar month's URL shortening quota has been used across all tokens.
 
diff --git a/bitlyshortener/shortener.py b/bitlyshortener/shortener.py
index 1c7cfb6..dceffb4 100644
--- a/bitlyshortener/shortener.py
+++ b/bitlyshortener/shortener.py
@@ -108,7 +108,7 @@ def _shorten_url(self, long_url: str) -> str:  # pylint: disable=too-many-locals
         # Preprocess long URL
         long_url = long_url.strip()
         if self._is_known_short_url(long_url):
-            # Note: A preexisting Bitly link can use one of many domains, not just j.mp. It can also be
+            # Note: A preexisting Bitly link can use one of many domains, not just bit.ly. It can also be
             # a custom link or not. Such a link must be validated and normalized.
             long_url = self._lengthen_url(long_url)
 
@@ -180,9 +180,6 @@ def _shorten_url(self, long_url: str) -> str:  # pylint: disable=too-many-locals
         # Postprocess short URL
         if short_url.startswith(""http://""):  # Example: http://citi.us/2FPqsuZ
             short_url = short_url.replace(""http://"", ""https://"", 1)
-        if short_url.startswith(""https://bit.ly/""):
-            url_id = short_url.rpartition(""/"")[-1]
-            short_url = f""https://j.mp/{url_id}""
 
         log.debug(""Returning short URL %s for long URL %s."", short_url, long_url)
         return short_url
diff --git a/scripts/try_shortener.py b/scripts/try_shortener.py
index 0b7495e..82eab2d 100644
--- a/scripts/try_shortener.py
+++ b/scripts/try_shortener.py
@@ -64,11 +64,9 @@
     ""https://arxiv.org/abs/1902.00541v1"",
 ]
 
-# URLs = [""https://j.mp/websniffer"", ""http://j.mp/2Bo2LVf"", ""http://bit.ly/2BombJQ"", ""https://cnn.it/2Ggb2ih""]
-
 try:
     shortener = Shortener(tokens=TOKENS)
-    urls = random.sample(URLs, k=min(len(URLs), {""none"": 0, ""one"": 1, ""some"": 3, ""all"": len(URLs)}[""one""]))
+    urls = random.sample(URLs, k=min(len(URLs), {""none"": 0, ""one"": 1, ""some"": 3, ""all"": len(URLs)}[""some""]))
     print(shortener.shorten_urls(urls))
     print(shortener.shorten_urls(urls))  # Should use cache."
GHSA-28mg-98xm-q493,"From 2d8cb29853190d42572b36deb61127e68d6be574 Mon Sep 17 00:00:00 2001
From: Uzay-G <uzgirit@gmail.com>
Date: Thu, 24 Feb 2022 21:32:40 +0100
Subject: [PATCH] fix open redirect

---
 archivy/helpers.py | 12 +++++++++++-
 archivy/routes.py  |  7 +++++--
 2 files changed, 16 insertions(+), 3 deletions(-)

diff --git a/archivy/helpers.py b/archivy/helpers.py
index df6d63c8..1eddbdd0 100644
--- a/archivy/helpers.py
+++ b/archivy/helpers.py
@@ -5,8 +5,9 @@
 import elasticsearch
 import yaml
 from elasticsearch import Elasticsearch
-from flask import current_app, g
+from flask import current_app, g, request
 from tinydb import TinyDB, Query, operations
+from urllib.parse import urlparse, urljoin
 
 from archivy.config import BaseHooks, Config
 
@@ -230,3 +231,12 @@ def create_plugin_dir(name):
         return True
     except FileExistsError:
         return False
+
+
+def is_safe_redirect_url(target):
+    host_url = urlparse(request.host_url)
+    redirect_url = urlparse(urljoin(request.host_url, target))
+    return (
+        redirect_url.scheme in (""http"", ""https"")
+        and host_url.netloc == redirect_url.netloc
+    )
diff --git a/archivy/routes.py b/archivy/routes.py
index f96ff519..173e2b12 100644
--- a/archivy/routes.py
+++ b/archivy/routes.py
@@ -19,7 +19,7 @@
 
 from archivy.models import DataObj, User
 from archivy import data, app, forms, csrf
-from archivy.helpers import get_db, write_config
+from archivy.helpers import get_db, write_config, is_safe_redirect_url
 from archivy.tags import get_all_tags
 from archivy.search import search, search_frontmatter_tags
 from archivy.config import Config
@@ -264,7 +264,10 @@ def login():
             flash(""Login successful!"", ""success"")
 
             next_url = request.args.get(""next"")
-            return redirect(next_url or ""/"")
+            if next_url and is_safe_redirect_url(next_url):
+                return redirect(next_url)
+            else:
+                return redirect(""/"")
 
         flash(""Invalid credentials"", ""error"")
         return redirect(""/login"")"
GHSA-h3qr-fjhm-jphw,"From 2a80aa434f74feb31242b6f213b75ce63ae97902 Mon Sep 17 00:00:00 2001
From: Joe Becher <jwbecher@drazisil.com>
Date: Wed, 19 Feb 2020 09:36:10 -0500
Subject: [PATCH] CE-1380_sanitize_args

---
 codecov/__init__.py | 10 +++++++---
 tests/test.py       |  3 +++
 2 files changed, 10 insertions(+), 3 deletions(-)

diff --git a/codecov/__init__.py b/codecov/__init__.py
index 6b3205c3..40ba7a73 100644
--- a/codecov/__init__.py
+++ b/codecov/__init__.py
@@ -34,6 +34,10 @@
 
 remove_token = re.compile(r'token=[^\&]+').sub
 
+def sanitize_arg(replacement, arg):
+    return re.sub(r'[\&]+', replacement, arg, 0, re.MULTILINE)
+
+
 ignored_path = re.compile(r'(/vendor)|'
                           r'(/js/generated/coverage)|'
                           r'(/__pycache__)|'
@@ -624,11 +628,11 @@ def main(*argv, **kwargs):
             )
             write('==> Processing gcov (disable by -X gcov)')
             cmd = ""find %s %s -type f -name '*.gcno' %s -exec %s -pb %s {} +"" % (
-                  (codecov.gcov_root or root),
+                  (sanitize_arg('', codecov.gcov_root or root)),
                   dont_search_here,
                   "" "".join(map(lambda a: ""-not -path '%s'"" % a, codecov.gcov_glob)),
-                  (codecov.gcov_exec or ''),
-                  (codecov.gcov_args or ''))
+                  (sanitize_arg('', codecov.gcov_exec or '')),
+                  (sanitize_arg('', codecov.gcov_args or '')))
             write('    Executing gcov (%s)' % cmd)
             try_to_run(cmd)
 
diff --git a/tests/test.py b/tests/test.py
index ed640c6e..cf001d61 100644
--- a/tests/test.py
+++ b/tests/test.py
@@ -315,6 +315,9 @@ def test_none_found(self):
         else:
             raise Exception(""Did not raise AssertionError"")
 
+    def test_sanitize_arg(self):
+        self.assertEqual(codecov.sanitize_arg('', '& echo test > vuln1.txt'), ' echo test > vuln1.txt')
+
     @unittest.skipUnless(os.getenv('JENKINS_URL'), 'Skip Jenkins CI test')
     def test_ci_jenkins(self):
         self.set_env(BUILD_URL='https://....',"
GHSA-23c7-6444-399m,"From 7c96d400358221e59135f0a0be0744f3fad73856 Mon Sep 17 00:00:00 2001
From: RhinosF1 <rhinosf1@gmail.com>
Date: Thu, 8 Apr 2021 18:21:42 +0100
Subject: [PATCH] [SECURITY] Release 2.0.1 (#65)

Fixes CVE-2021-21431
---
 dev-requirements.txt                      |  2 +-
 setup.py                                  |  4 ++--
 sopel_channelmgnt/channelmgnt/__init__.py | 16 ++++++++++++++++
 3 files changed, 19 insertions(+), 3 deletions(-)

diff --git a/dev-requirements.txt b/dev-requirements.txt
index 586ff0a..2afd463 100644
--- a/dev-requirements.txt
+++ b/dev-requirements.txt
@@ -15,7 +15,7 @@ flake8-fixme==1.1.1
 flake8-multiline-containers==0.0.17
 flake8-print==4.0.0
 flake8-pytest-style==1.3.0
-flake8-return==1.1.2
+#flake8-return==1.1.2
 flake8-quotes==3.2.0
 flake8-simplify==0.13.0
 flake8-pytest==1.3
diff --git a/setup.py b/setup.py
index 9b8eb35..c94a255 100644
--- a/setup.py
+++ b/setup.py
@@ -10,12 +10,12 @@
 
 setup(
     name='sopel_plugins.channelmgnt',
-    version='2.0',
+    version='2.0.1',
     description='Channelmgnt plugin for Sopel',
     long_description=readme,
     long_description_content_type='text/markdown',  # This is important!
     author='MirahezeBot Contributors',
-    author_email='bots@miraheze.org',
+    author_email='staff@mirahezebots.org',
     url='https://github.com/MirahezeBots/sopel-channelmgnt',
     packages=find_packages('.'),
     include_package_data=True,
diff --git a/sopel_channelmgnt/channelmgnt/__init__.py b/sopel_channelmgnt/channelmgnt/__init__.py
index 2ff180f..35d3553 100644
--- a/sopel_channelmgnt/channelmgnt/__init__.py
+++ b/sopel_channelmgnt/channelmgnt/__init__.py
@@ -216,6 +216,10 @@ def kick(bot, trigger):
             return
         nick = Identifier(text[1])
         reason = ' '.join(text[2:])
+        if ',' in str(nick):
+            return bot.reply('Unable to kick. Kicking multiple users is not allowed.')
+        if '#' in str(nick):
+            return bot.reply('Unable to kick. Use of # when kicking is not expected.')
         if nick != bot.config.core.nick and trigger.account in chanops:
             bot.write(['KICK', trigger.sender, nick, ':' + reason])
             if dodeop:
@@ -263,6 +267,10 @@ def parse_host_mask(text):
 @example('.ban Zppix')
 def ban(bot, trigger):
     """"""Ban a user from the channel. The bot must be a channel operator for this command to work.""""""
+    if ',' in str(parse_host_mask(trigger.group().split())):
+        return bot.reply('Unable to ban. Banning multiple users is not allowed.')
+    if '#' in str(parse_host_mask(trigger.group().split())):
+        return bot.reply('Unable to ban. Use of # when banning is not expected.')
     makemodechange(bot, trigger, '+b', isbqmode=True)
 
 
@@ -271,6 +279,10 @@ def ban(bot, trigger):
 @example('.unban Zppix')
 def unban(bot, trigger):
     """"""Unban a user from the channel. The bot must be a channel operator for this command to work.""""""
+    if ',' in str(parse_host_mask(trigger.group().split())):
+        return bot.reply('Unable to ban. Banning multiple users is not allowed.')
+    if '#' in str(parse_host_mask(trigger.group().split())):
+        return bot.reply('Unable to ban. Use of # when banning is not expected.')
     makemodechange(bot, trigger, '-b', isbqmode=True)
 
 
@@ -312,6 +324,10 @@ def kickban(bot, trigger):
                 deopbot(trigger.sender, bot)
             return
         nick = Identifier(text[1])
+        if ',' in str(nick):
+            return bot.reply('Unable to kickban. Kickbanning multiple users is not allowed.')
+        if '#' in str(nick):
+            return bot.reply('Unable to kickban. Use of # when kickbanning is not expected.')
         mask = text[2] if any(s in text[2] for s in '!@*') else ''
         reasonidx = 3 if mask != '' else 2
         reason = ' '.join(text[reasonidx:])"
GHSA-g53g-q539-93cv,"From b0ef15f4737d0c801154c1991b52ff5cab4f5c83 Mon Sep 17 00:00:00 2001
From: Chiara Rasi <rasi.chiara@gmail.com>
Date: Thu, 5 May 2022 09:11:31 +0200
Subject: [PATCH] Protect remote_cors from Server-Side Request Forgery (#3326)

* Protect remote_cors from Server-Side Request Forgery

* Improved code and added test

* Fix a couple of comments in a test
---
 CHANGELOG.md                                  |  1 +
 .../blueprints/alignviewers/controllers.py    | 21 ++++++++++-
 scout/server/blueprints/alignviewers/views.py |  7 ++--
 .../alignviewers/test_alignviewers_views.py   | 36 +++++++++++++++----
 4 files changed, 55 insertions(+), 10 deletions(-)

diff --git a/CHANGELOG.md b/CHANGELOG.md
index b99b08274c..e27501ff2c 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -29,6 +29,7 @@ About changelog [here](https://keepachangelog.com/en/1.0.0/)
 - Removed stream argument deprecation warning in tests
 - Handle `no intervals found` warning in load_region test
 - Beacon remove variants
+- Protect remote_cors function in alignviewers view from Server-Side Request Forgery (SSRF)
 
 ## [4.51]
 ### Added
diff --git a/scout/server/blueprints/alignviewers/controllers.py b/scout/server/blueprints/alignviewers/controllers.py
index e123a47efe..59c124aa3c 100644
--- a/scout/server/blueprints/alignviewers/controllers.py
+++ b/scout/server/blueprints/alignviewers/controllers.py
@@ -14,6 +14,25 @@
 CUSTOM_TRACK_NAMES = [""Genes"", ""ClinVar"", ""ClinVar CNVs""]
 
 
+def check_session_tracks(resource):
+    """"""Make sure that a user requesting a resource is authenticated and resource is in session IGV tracks
+
+    Args:
+        resource(str): a resource on the server or on a remote URL
+
+    Returns
+        True is user has access to resource else False
+    """"""
+    # Check that user is logged in or that file extension is valid
+    if current_user.is_authenticated is False:
+        LOG.warning(""Unauthenticated user requesting resource via remote_static"")
+        return False
+    if resource not in session.get(""igv_tracks"", []):
+        LOG.warning(f""{resource} not in {session.get('igv_tracks', [])}"")
+        return False
+    return True
+
+
 def set_session_tracks(display_obj):
     """"""Save igv tracks as a session object. This way it's easy to verify that a user is requesting one of these files from remote_static view endpoint
 
@@ -22,7 +41,7 @@ def set_session_tracks(display_obj):
     """"""
     session_tracks = list(display_obj.get(""reference_track"", {}).values())
     for key, track_items in display_obj.items():
-        if key not in [""tracks"", ""custom_tracks"", ""sample_tracks""]:
+        if key not in [""tracks"", ""custom_tracks"", ""sample_tracks"", ""cloud_public_tracks""]:
             continue
         for track_item in track_items:
             session_tracks += list(track_item.values())
diff --git a/scout/server/blueprints/alignviewers/views.py b/scout/server/blueprints/alignviewers/views.py
index 30bcd77db8..de2e6d6b81 100644
--- a/scout/server/blueprints/alignviewers/views.py
+++ b/scout/server/blueprints/alignviewers/views.py
@@ -39,6 +39,10 @@ def remote_cors(remote_url):
     Based on code from answers to this thread:
         https://stackoverflow.com/questions/6656363/proxying-to-another-web-service-with-flask/
     """"""
+    # Check that user is logged in or that file extension is valid
+    if controllers.check_session_tracks(remote_url) is False:
+        return abort(403)
+
     resp = requests.request(
         method=request.method,
         url=remote_url,
@@ -70,8 +74,7 @@ def remote_static():
     file_path = request.args.get(""file"") or "".""
 
     # Check that user is logged in or that file extension is valid
-    if current_user.is_authenticated is False or file_path not in session.get(""igv_tracks"", []):
-        LOG.warning(f""{file_path} not in {session.get('igv_tracks', [])}"")
+    if controllers.check_session_tracks(file_path) is False:
         return abort(403)
 
     range_header = request.headers.get(""Range"", None)
diff --git a/tests/server/blueprints/alignviewers/test_alignviewers_views.py b/tests/server/blueprints/alignviewers/test_alignviewers_views.py
index db7e02a77a..6b7b341b55 100644
--- a/tests/server/blueprints/alignviewers/test_alignviewers_views.py
+++ b/tests/server/blueprints/alignviewers/test_alignviewers_views.py
@@ -47,8 +47,9 @@ def test_remote_static(app):
     with app.test_client() as client:
         # GIVEN that user is logged in
         client.get(url_for(""auto_login""))
+
+        # GIVEN that resource file exists in user session
         with client.session_transaction() as session:
-            # GIVEN that resource file exists in user session
             session[""igv_tracks""] = [file]
 
         # THEN the resource should be available to the user
@@ -61,20 +62,41 @@ def test_remote_static(app):
         assert resp.status_code == 200
 
 
-def test_remote_cors(app):
+def test_remote_cors_wrong_resource(app):
     """"""Test endpoint that serves as a proxy to the actual remote track on the cloud""""""
-    cloud_track_url = ""http://google.com""
+    # GIVEN a resource not present in session[""igv_tracks""]
+    an_url = ""http://google.com""
 
-    # GIVEN an initialized app
-    # GIVEN a valid user and institute
+    # GIVEN a running demo app
     with app.test_client() as client:
         # GIVEN that the user could be logged in
         resp = client.get(url_for(""auto_login""))
-        assert resp.status_code == 200
 
         # WHEN the remote cors endpoint is invoked with an url
+        resp = client.get(url_for(""alignviewers.remote_cors"", remote_url=an_url))
+
+        # THEN it should return forbidden (403)
+        assert resp.status_code == 403
+
+
+def test_remote_cors(app):
+    """"""Test endpoint that serves as a proxy to the actual remote track on the cloud""""""
+    # GIVEN an igv track on the cloud
+    cloud_track_url = ""https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/25777460/GRCh37.variant_call.clinical.pathogenic_or_likely_pathogenic.vcf.gz.tbi""
+
+    # GIVEN a running demo app
+    with app.test_client() as client:
+        # GIVEN that the user could be logged in
+        resp = client.get(url_for(""auto_login""))
+
+        # GIVEN that resource url exists in user session
+        with client.session_transaction() as session:
+            session[""igv_tracks""] = [cloud_track_url]
+
+        # WHEN the remote cors endpoint is invoked with cloud_track_url
         resp = client.get(url_for(""alignviewers.remote_cors"", remote_url=cloud_track_url))
-        # THEN it should return success response
+
+        # THEN response should be successful
         assert resp.status_code == 200"
CVE-2015-0284,"From dd418384171473c3e31386a1b4792f8c555dc744 Mon Sep 17 00:00:00 2001
From: Jiri Dostal <jdostal@redhat.com>
Date: Wed, 22 Jul 2015 13:19:34 +0200
Subject: [PATCH] 1181152 - XSS when altering user details and going somewhere
 where you are choosing user         - Escaped tags in real names

---
 backend/server/rhnPackage.py                                    | 2 +-
 java/code/webapp/WEB-INF/pages/admin/multiorg/org_users.jsp     | 2 +-
 java/code/webapp/WEB-INF/pages/admin/multiorg/sat_org_users.jsp | 2 +-
 java/code/webapp/WEB-INF/pages/admin/users/activelist.jsp       | 2 +-
 .../webapp/WEB-INF/pages/common/fragments/manage/managers.jspf  | 2 +-
 .../WEB-INF/pages/common/fragments/manage/subscribers.jspf      | 2 +-
 .../WEB-INF/pages/common/fragments/user/userlist_columns.jspf   | 2 +-
 java/code/webapp/WEB-INF/pages/groups/adminlist.jsp             | 2 +-
 8 files changed, 8 insertions(+), 8 deletions(-)

diff --git a/backend/server/rhnPackage.py b/backend/server/rhnPackage.py
index fd9cd0fa8ee..b8ee26daa6f 100644
--- a/backend/server/rhnPackage.py
+++ b/backend/server/rhnPackage.py
@@ -203,7 +203,7 @@ def get_info_for_package(pkg, channel_id, org_id):
               'channel_id': channel_id,
               'org_id': org_id}
     # yum repo has epoch=""0"" not only when epoch is ""0"" but also if it's NULL
-    if pkg[3] == '0' or pkg[3] == '':
+    if pkg[3] == '0' or pkg[3] == '' or pkg[3]==None:
         epochStatement = ""(epoch is null or epoch = :epoch)""
     else:
         epochStatement = ""epoch = :epoch""
diff --git a/java/code/webapp/WEB-INF/pages/admin/multiorg/org_users.jsp b/java/code/webapp/WEB-INF/pages/admin/multiorg/org_users.jsp
index 2de867c8426..d76fcb087c3 100644
--- a/java/code/webapp/WEB-INF/pages/admin/multiorg/org_users.jsp
+++ b/java/code/webapp/WEB-INF/pages/admin/multiorg/org_users.jsp
@@ -78,7 +78,7 @@
                    sortable=""false""
                    headerkey=""realname.displayname""
                    attr=""userLastName"">
-                <c:out value=""${current.userDisplayName}"" escapeXml=""false"" />
+                <c:out value=""${current.userDisplayName}"" escapeXml=""true"" />
         </rl:column>
         <rl:column bound=""false""
                    sortable=""false""
diff --git a/java/code/webapp/WEB-INF/pages/admin/multiorg/sat_org_users.jsp b/java/code/webapp/WEB-INF/pages/admin/multiorg/sat_org_users.jsp
index e640491a7eb..5880d441153 100644
--- a/java/code/webapp/WEB-INF/pages/admin/multiorg/sat_org_users.jsp
+++ b/java/code/webapp/WEB-INF/pages/admin/multiorg/sat_org_users.jsp
@@ -55,7 +55,7 @@
                    sortable=""false""
                    headerkey=""realname.displayname""
                    attr=""userLastName"">
-                <c:out value=""<a href=\""mailto:${current.address}\"">${current.userLastName}, ${current.userFirstName}</a>"" escapeXml=""false""/>
+                <c:out value=""<a href=\""mailto:${current.address}\"">${current.userLastName}, ${current.userFirstName}</a>"" escapeXml=""true""/>
         </rl:column>
         <rl:column bound=""false""
                    sortable=""false""
diff --git a/java/code/webapp/WEB-INF/pages/admin/users/activelist.jsp b/java/code/webapp/WEB-INF/pages/admin/users/activelist.jsp
index dd91fa5844c..8fade0f9349 100644
--- a/java/code/webapp/WEB-INF/pages/admin/users/activelist.jsp
+++ b/java/code/webapp/WEB-INF/pages/admin/users/activelist.jsp
@@ -44,7 +44,7 @@
                    sortable=""true""
                    headerkey=""realname.displayname""
                    sortattr=""userLastName"">
-                <c:out value=""${current.userLastName}, ${current.userFirstName}"" />
+                <c:out escapeXml=""true"" value=""${current.userLastName}, ${current.userFirstName}"" />
         </rl:column>
 
         <!--  Roles column -->
diff --git a/java/code/webapp/WEB-INF/pages/common/fragments/manage/managers.jspf b/java/code/webapp/WEB-INF/pages/common/fragments/manage/managers.jspf
index 619471bf54b..1bec08c6bfb 100644
--- a/java/code/webapp/WEB-INF/pages/common/fragments/manage/managers.jspf
+++ b/java/code/webapp/WEB-INF/pages/common/fragments/manage/managers.jspf
@@ -39,7 +39,7 @@
          <rl:column sortable=""false""
             bound=""false""
             headerkey=""realname.displayname"" >
-            ${current.userLastName}, ${current.userFirstName}
+            <c:out escapeXml=""true"" value=""${current.userLastName},${current.userFirstName}"" />
          </rl:column>
 
          <rl:column sortable=""false""
diff --git a/java/code/webapp/WEB-INF/pages/common/fragments/manage/subscribers.jspf b/java/code/webapp/WEB-INF/pages/common/fragments/manage/subscribers.jspf
index 0ac6b3e9614..24ed0e1d111 100644
--- a/java/code/webapp/WEB-INF/pages/common/fragments/manage/subscribers.jspf
+++ b/java/code/webapp/WEB-INF/pages/common/fragments/manage/subscribers.jspf
@@ -39,7 +39,7 @@
          <rl:column sortable=""false""
             bound=""false""
             headerkey=""realname.displayname"" >
-            ${current.userLastName}, ${current.userFirstName}
+            <c:out escapeXml=""true"" value=""${current.userLastName},${current.userFirstName}"" />
          </rl:column>
 
          <rl:column sortable=""false""
diff --git a/java/code/webapp/WEB-INF/pages/common/fragments/user/userlist_columns.jspf b/java/code/webapp/WEB-INF/pages/common/fragments/user/userlist_columns.jspf
index 27944d08cc1..f14bf856d5a 100644
--- a/java/code/webapp/WEB-INF/pages/common/fragments/user/userlist_columns.jspf
+++ b/java/code/webapp/WEB-INF/pages/common/fragments/user/userlist_columns.jspf
@@ -4,7 +4,7 @@
         sortable=""true""
         headerkey=""realname.displayname""
         sortattr=""userLastName"">
-        <c:out value=""${current.userLastName}, ${current.userFirstName}"" />
+        <c:out escapeXml=""true"" value=""${current.userLastName}, ${current.userFirstName}"" />
 </rl:column>
 
 <rl:column bound=""true""
diff --git a/java/code/webapp/WEB-INF/pages/groups/adminlist.jsp b/java/code/webapp/WEB-INF/pages/groups/adminlist.jsp
index dc5a606c135..33333f55823 100644
--- a/java/code/webapp/WEB-INF/pages/groups/adminlist.jsp
+++ b/java/code/webapp/WEB-INF/pages/groups/adminlist.jsp
@@ -50,7 +50,7 @@
          <rl:column sortable=""false""
             bound=""false""
             headerkey=""realname.displayname"" >
-            ${current.userLastName}, ${current.userFirstName}
+            <c:out escapeXml=""true"" value=""${current.userLastName},${current.userFirstName}"" />
          </rl:column>
 
          <rl:column sortable=""true"""
GHSA-ffqj-6fqr-9h24,"From 9c528670c455b8d948aff95ed50e22940d1ad3fc Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Jos=C3=A9=20Padilla?= <jpadilla@webapplicate.com>
Date: Thu, 12 May 2022 14:31:00 -0400
Subject: [PATCH] Merge pull request from GHSA-ffqj-6fqr-9h24
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Co-authored-by: Jos Padilla <jpadilla@users.noreply.github.com>
---
 .gitignore               |   1 +
 jwt/__init__.py          |   2 +-
 jwt/algorithms.py        |  39 +++++++-------
 jwt/utils.py             |  61 ++++++++++++++++++++++
 tests/test_advisory.py   | 109 +++++++++++++++++++++++++++++++++++++++
 tests/test_algorithms.py |   2 +-
 6 files changed, 191 insertions(+), 23 deletions(-)
 create mode 100644 tests/test_advisory.py

diff --git a/.gitignore b/.gitignore
index 63406706..8f78dc38 100644
--- a/.gitignore
+++ b/.gitignore
@@ -60,3 +60,4 @@ target/
 
 .pytest_cache
 .mypy_cache
+pip-wheel-metadata/
diff --git a/jwt/__init__.py b/jwt/__init__.py
index e692a842..6b3f8ab1 100644
--- a/jwt/__init__.py
+++ b/jwt/__init__.py
@@ -25,7 +25,7 @@
 )
 from .jwks_client import PyJWKClient
 
-__version__ = ""2.3.0""
+__version__ = ""2.4.0""
 
 __title__ = ""PyJWT""
 __description__ = ""JSON Web Token implementation in Python""
diff --git a/jwt/algorithms.py b/jwt/algorithms.py
index 739df808..46a1a532 100644
--- a/jwt/algorithms.py
+++ b/jwt/algorithms.py
@@ -9,6 +9,8 @@
     der_to_raw_signature,
     force_bytes,
     from_base64url_uint,
+    is_pem_format,
+    is_ssh_key,
     raw_to_der_signature,
     to_base64url_uint,
 )
@@ -183,14 +185,7 @@ def __init__(self, hash_alg):
     def prepare_key(self, key):
         key = force_bytes(key)
 
-        invalid_strings = [
-            b""-----BEGIN PUBLIC KEY-----"",
-            b""-----BEGIN CERTIFICATE-----"",
-            b""-----BEGIN RSA PUBLIC KEY-----"",
-            b""ssh-rsa"",
-        ]
-
-        if any(string_value in key for string_value in invalid_strings):
+        if is_pem_format(key) or is_ssh_key(key):
             raise InvalidKeyError(
                 ""The specified key is an asymmetric key or x509 certificate and""
                 "" should not be used as an HMAC secret.""
@@ -551,26 +546,28 @@ def __init__(self, **kwargs):
             pass
 
         def prepare_key(self, key):
-
-            if isinstance(
-                key,
-                (Ed25519PrivateKey, Ed25519PublicKey, Ed448PrivateKey, Ed448PublicKey),
-            ):
-                return key
-
             if isinstance(key, (bytes, str)):
                 if isinstance(key, str):
                     key = key.encode(""utf-8"")
                 str_key = key.decode(""utf-8"")
 
                 if ""-----BEGIN PUBLIC"" in str_key:
-                    return load_pem_public_key(key)
-                if ""-----BEGIN PRIVATE"" in str_key:
-                    return load_pem_private_key(key, password=None)
-                if str_key[0:4] == ""ssh-"":
-                    return load_ssh_public_key(key)
+                    key = load_pem_public_key(key)
+                elif ""-----BEGIN PRIVATE"" in str_key:
+                    key = load_pem_private_key(key, password=None)
+                elif str_key[0:4] == ""ssh-"":
+                    key = load_ssh_public_key(key)
 
-            raise TypeError(""Expecting a PEM-formatted or OpenSSH key."")
+            # Explicit check the key to prevent confusing errors from cryptography
+            if not isinstance(
+                key,
+                (Ed25519PrivateKey, Ed25519PublicKey, Ed448PrivateKey, Ed448PublicKey),
+            ):
+                raise InvalidKeyError(
+                    ""Expecting a EllipticCurvePrivateKey/EllipticCurvePublicKey. Wrong key provided for EdDSA algorithms""
+                )
+
+            return key
 
         def sign(self, msg, key):
             """"""
diff --git a/jwt/utils.py b/jwt/utils.py
index 9dde10cf..8ab73b42 100644
--- a/jwt/utils.py
+++ b/jwt/utils.py
@@ -1,5 +1,6 @@
 import base64
 import binascii
+import re
 from typing import Any, Union
 
 try:
@@ -97,3 +98,63 @@ def raw_to_der_signature(raw_sig: bytes, curve: EllipticCurve) -> bytes:
     s = bytes_to_number(raw_sig[num_bytes:])
 
     return encode_dss_signature(r, s)
+
+
+# Based on https://github.com/hynek/pem/blob/7ad94db26b0bc21d10953f5dbad3acfdfacf57aa/src/pem/_core.py#L224-L252
+_PEMS = {
+    b""CERTIFICATE"",
+    b""TRUSTED CERTIFICATE"",
+    b""PRIVATE KEY"",
+    b""PUBLIC KEY"",
+    b""ENCRYPTED PRIVATE KEY"",
+    b""OPENSSH PRIVATE KEY"",
+    b""DSA PRIVATE KEY"",
+    b""RSA PRIVATE KEY"",
+    b""RSA PUBLIC KEY"",
+    b""EC PRIVATE KEY"",
+    b""DH PARAMETERS"",
+    b""NEW CERTIFICATE REQUEST"",
+    b""CERTIFICATE REQUEST"",
+    b""SSH2 PUBLIC KEY"",
+    b""SSH2 ENCRYPTED PRIVATE KEY"",
+    b""X509 CRL"",
+}
+
+_PEM_RE = re.compile(
+    b""----[- ]BEGIN (""
+    + b""|"".join(_PEMS)
+    + b"""""")[- ]----\r?
+.+?\r?
+----[- ]END \\1[- ]----\r?\n?"""""",
+    re.DOTALL,
+)
+
+
+def is_pem_format(key: bytes) -> bool:
+    return bool(_PEM_RE.search(key))
+
+
+# Based on https://github.com/pyca/cryptography/blob/bcb70852d577b3f490f015378c75cba74986297b/src/cryptography/hazmat/primitives/serialization/ssh.py#L40-L46
+_CERT_SUFFIX = b""-cert-v01@openssh.com""
+_SSH_PUBKEY_RC = re.compile(br""\A(\S+)[ \t]+(\S+)"")
+_SSH_KEY_FORMATS = [
+    b""ssh-ed25519"",
+    b""ssh-rsa"",
+    b""ssh-dss"",
+    b""ecdsa-sha2-nistp256"",
+    b""ecdsa-sha2-nistp384"",
+    b""ecdsa-sha2-nistp521"",
+]
+
+
+def is_ssh_key(key: bytes) -> bool:
+    if any(string_value in key for string_value in _SSH_KEY_FORMATS):
+        return True
+
+    ssh_pubkey_match = _SSH_PUBKEY_RC.match(key)
+    if ssh_pubkey_match:
+        key_type = ssh_pubkey_match.group(1)
+        if _CERT_SUFFIX == key_type[-len(_CERT_SUFFIX) :]:
+            return True
+
+    return False
diff --git a/tests/test_advisory.py b/tests/test_advisory.py
new file mode 100644
index 00000000..f70f54ba
--- /dev/null
+++ b/tests/test_advisory.py
@@ -0,0 +1,109 @@
+import jwt
+import pytest
+from jwt.exceptions import InvalidKeyError
+
+priv_key_bytes = b'''-----BEGIN PRIVATE KEY-----
+MC4CAQAwBQYDK2VwBCIEIIbBhdo2ah7X32i50GOzrCr4acZTe6BezUdRIixjTAdL
+-----END PRIVATE KEY-----'''
+
+pub_key_bytes = b'ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPL1I9oiq+B8crkmuV4YViiUnhdLjCp3hvy1bNGuGfNL'
+
+ssh_priv_key_bytes = b""""""-----BEGIN EC PRIVATE KEY-----
+MHcCAQEEIOWc7RbaNswMtNtc+n6WZDlUblMr2FBPo79fcGXsJlGQoAoGCCqGSM49
+AwEHoUQDQgAElcy2RSSSgn2RA/xCGko79N+7FwoLZr3Z0ij/ENjow2XpUDwwKEKk
+Ak3TDXC9U8nipMlGcY7sDpXp2XyhHEM+Rw==
+-----END EC PRIVATE KEY-----""""""
+
+ssh_key_bytes = b""""""ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBJXMtkUkkoJ9kQP8QhpKO/TfuxcKC2a92dIo/xDY6MNl6VA8MChCpAJN0w1wvVPJ4qTJRnGO7A6V6dl8oRxDPkc=""""""
+
+
+class TestAdvisory:
+    def test_ghsa_ffqj_6fqr_9h24(self):
+        # Generate ed25519 private key
+        # private_key = ed25519.Ed25519PrivateKey.generate()
+
+        # Get private key bytes as they would be stored in a file
+        # priv_key_bytes = private_key.private_bytes(
+        #     encoding=serialization.Encoding.PEM,
+        #     format=serialization.PrivateFormat.PKCS8,
+        #     encryption_algorithm=serialization.NoEncryption(),
+        # )
+
+        # Get public key bytes as they would be stored in a file
+        # pub_key_bytes = private_key.public_key().public_bytes(
+        #     encoding=serialization.Encoding.OpenSSH,
+        #     format=serialization.PublicFormat.OpenSSH,
+        # )
+
+        # Making a good jwt token that should work by signing it
+        # with the private key
+        # encoded_good = jwt.encode({""test"": 1234}, priv_key_bytes, algorithm=""EdDSA"")
+        encoded_good = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJFZERTQSJ9.eyJ0ZXN0IjoxMjM0fQ.M5y1EEavZkHSlj9i8yi9nXKKyPBSAUhDRTOYZi3zZY11tZItDaR3qwAye8pc74_lZY3Ogt9KPNFbVOSGnUBHDg'
+
+        # Using HMAC with the public key to trick the receiver to think that the
+        # public key is a HMAC secret
+        encoded_bad = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0ZXN0IjoxMjM0fQ.6ulDpqSlbHmQ8bZXhZRLFko9SwcHrghCwh8d-exJEE4'
+
+        # Both of the jwt tokens are validated as valid
+        jwt.decode(
+            encoded_good,
+            pub_key_bytes,
+            algorithms=jwt.algorithms.get_default_algorithms(),
+        )
+
+        with pytest.raises(InvalidKeyError):
+            jwt.decode(
+                encoded_bad,
+                pub_key_bytes,
+                algorithms=jwt.algorithms.get_default_algorithms(),
+            )
+
+        # Of course the receiver should specify ed25519 algorithm to be used if
+        # they specify ed25519 public key. However, if other algorithms are used,
+        # the POC does not work
+        # HMAC specifies illegal strings for the HMAC secret in jwt/algorithms.py
+        #
+        #        invalid_str ings = [
+        #            b""-----BEGIN PUBLIC KEY-----"",
+        #            b""-----BEGIN CERTIFICATE-----"",
+        #            b""-----BEGIN RSA PUBLIC KEY-----"",
+        #            b""ssh-rsa"",
+        #        ]
+        #
+        # However, OKPAlgorithm (ed25519) accepts the following in  jwt/algorithms.py:
+        #
+        #                if ""-----BEGIN PUBLIC"" in str_key:
+        #                    return load_pem_public_key(key)
+        #                if ""-----BEGIN PRIVATE"" in str_key:
+        #                    return load_pem_private_key(key, password=None)
+        #                if str_key[0:4] == ""ssh-"":
+        #                    return load_ssh_public_key(key)
+        #
+        # These should most likely made to match each other to prevent this behavior
+
+        # POC for the ecdsa-sha2-nistp256 format.
+        # openssl ecparam -genkey -name prime256v1 -noout -out ec256-key-priv.pem
+        # openssl ec -in ec256-key-priv.pem -pubout > ec256-key-pub.pem
+        # ssh-keygen -y -f ec256-key-priv.pem > ec256-key-ssh.pub
+
+        # Making a good jwt token that should work by signing it with the private key
+        # encoded_good = jwt.encode({""test"": 1234}, ssh_priv_key_bytes, algorithm=""ES256"")
+        encoded_good = ""eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXN0IjoxMjM0fQ.NX42mS8cNqYoL3FOW9ZcKw8Nfq2mb6GqJVADeMA1-kyHAclilYo_edhdM_5eav9tBRQTlL0XMeu_WFE_mz3OXg""
+
+        # Using HMAC with the ssh public key to trick the receiver to think that the public key is a HMAC secret
+        # encoded_bad = jwt.encode({""test"": 1234}, ssh_key_bytes, algorithm=""HS256"")
+        encoded_bad = ""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXN0IjoxMjM0fQ.5eYfbrbeGYmWfypQ6rMWXNZ8bdHcqKng5GPr9MJZITU""
+
+        # Both of the jwt tokens are validated as valid
+        jwt.decode(
+            encoded_good,
+            ssh_key_bytes,
+            algorithms=jwt.algorithms.get_default_algorithms()
+        )
+
+        with pytest.raises(InvalidKeyError):
+            jwt.decode(
+                encoded_bad,
+                ssh_key_bytes,
+                algorithms=jwt.algorithms.get_default_algorithms()
+            )
diff --git a/tests/test_algorithms.py b/tests/test_algorithms.py
index fca930cf..ac26600d 100644
--- a/tests/test_algorithms.py
+++ b/tests/test_algorithms.py
@@ -679,7 +679,7 @@ class TestOKPAlgorithms:
     def test_okp_ed25519_should_reject_non_string_key(self):
         algo = OKPAlgorithm()
 
-        with pytest.raises(TypeError):
+        with pytest.raises(InvalidKeyError):
             algo.prepare_key(None)
 
         with open(key_path(""testkey_ed25519"")) as keyfile:"
GHSA-pq7m-3gw7-gq5x,"From 1ec91ebf328bdf3450130de4b4604c79dc1e19d9 Mon Sep 17 00:00:00 2001
From: Matthias Bussonnier <bussonniermatthias@gmail.com>
Date: Sat, 15 Jan 2022 19:43:14 +0100
Subject: [PATCH 1/3] FIX CVE-2022-21699

See https://github.com/ipython/ipython/security/advisories/GHSA-pq7m-3gw7-gq5x
---
 IPython/__init__.py               |  4 +++
 IPython/core/application.py       |  2 +-
 IPython/core/profileapp.py        |  7 +++---
 IPython/core/profiledir.py        |  4 +--
 docs/source/whatsnew/version8.rst | 42 +++++++++++++++++++++++++++++++
 5 files changed, 53 insertions(+), 6 deletions(-)

diff --git a/IPython/__init__.py b/IPython/__init__.py
index 5d656e40a25..e12da90d375 100644
--- a/IPython/__init__.py
+++ b/IPython/__init__.py
@@ -60,6 +60,10 @@
 __license__  = release.license
 __version__  = release.version
 version_info = release.version_info
+# list of CVEs that should have been patched in this release.
+# this is informational and should not be relied upon.
+__patched_cves__ = {""CVE-2022-21699""}
+
 
 def embed_kernel(module=None, local_ns=None, **kwargs):
     """"""Embed and start an IPython kernel in a given scope.
diff --git a/IPython/core/application.py b/IPython/core/application.py
index e93a10647a0..2b389a686d4 100644
--- a/IPython/core/application.py
+++ b/IPython/core/application.py
@@ -157,7 +157,7 @@ def _config_file_name_changed(self, change):
     config_file_paths = List(Unicode())
     @default('config_file_paths')
     def _config_file_paths_default(self):
-        return [os.getcwd()]
+        return []
 
     extra_config_file = Unicode(
     help=""""""Path to an extra config file to load.
diff --git a/IPython/core/profileapp.py b/IPython/core/profileapp.py
index 97434e3d0b5..9a1bae55ac5 100644
--- a/IPython/core/profileapp.py
+++ b/IPython/core/profileapp.py
@@ -181,9 +181,10 @@ def list_profile_dirs(self):
         profiles = list_profiles_in(os.getcwd())
         if profiles:
             print()
-            print(""Available profiles in current directory (%s):"" % os.getcwd())
-            self._print_profiles(profiles)
-        
+            print(
+                ""Profiles from CWD have been removed for security reason, see CVE-2022-21699:""
+            )
+
         print()
         print(""To use any of the above profiles, start IPython with:"")
         print(""    ipython --profile=<name>"")
diff --git a/IPython/core/profiledir.py b/IPython/core/profiledir.py
index 756595adbfe..1e33b552fb7 100644
--- a/IPython/core/profiledir.py
+++ b/IPython/core/profiledir.py
@@ -188,7 +188,7 @@ def find_profile_dir_by_name(cls, ipython_dir, name=u'default', config=None):
         is not found, a :class:`ProfileDirError` exception will be raised.
 
         The search path algorithm is:
-        1. ``os.getcwd()``
+        1. ``os.getcwd()`` # removed for security reason.
         2. ``ipython_dir``
 
         Parameters
@@ -200,7 +200,7 @@ def find_profile_dir_by_name(cls, ipython_dir, name=u'default', config=None):
             will be ""profile_<profile>"".
         """"""
         dirname = u'profile_' + name
-        paths = [os.getcwd(), ipython_dir]
+        paths = [ipython_dir]
         for p in paths:
             profile_dir = os.path.join(p, dirname)
             if os.path.isdir(profile_dir):
diff --git a/docs/source/whatsnew/version8.rst b/docs/source/whatsnew/version8.rst
index 2ff732c7f96..72167a5984c 100644
--- a/docs/source/whatsnew/version8.rst
+++ b/docs/source/whatsnew/version8.rst
@@ -2,6 +2,48 @@
  8.x Series
 ============
 
+
+IPython 8.0.1 (CVE-2022-21699)
+------------------------------
+
+IPython 8.0.1, 7.31.1 and 5.11 are security releases that change some default
+values in order to prevent potential Execution with Unnecessary Privileges.
+
+Almost all version of IPython looks for configuration and profiles in current
+working directory. Since IPython was developed before pip and environments
+existed it was used a convenient way to load code/packages in a project
+dependant way.
+
+In 2022, it is not necessary anymore, and can lead to confusing behavior where
+for example cloning a repository and starting IPython or loading a notebook from
+any Jupyter-Compatible interface that has ipython set as a kernel can lead to
+code execution.
+
+
+I did not find any standard way for packaged to advertise CVEs they fix, I'm
+thus trying to add a ``__patched_cves__`` attribute to the IPython module that
+list the CVEs that should have been fixed. This attribute is informational only
+as if a executable has a flaw, this value can always be changed by an attacker.
+
+.. code::
+
+    In [1]: import IPython
+
+    In [2]: IPython.__patched_cves__
+    Out[2]: {'CVE-2022-21699'}
+
+    In [3]: 'CVE-2022-21699' in IPython.__patched_cves__
+    Out[3]: True
+
+Thus starting with this version:
+
+ - The current working directory is not searched anymore for profiles or
+   configurations files.
+ - Added a ``__patched_cves__`` attribute (set of strings) to IPython module that contain
+   the list of fixed CVE. This is informational only.
+
+
+
 IPython 8.0
 -----------
 

From 56665dfcf7df8690da46aab1278df8e47b14fe3b Mon Sep 17 00:00:00 2001
From: Matthias Bussonnier <bussonniermatthias@gmail.com>
Date: Wed, 19 Jan 2022 11:31:02 +0100
Subject: [PATCH 2/3] Add test for CVE-2022-21699

---
 IPython/tests/cve.py | 56 ++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 56 insertions(+)
 create mode 100644 IPython/tests/cve.py

diff --git a/IPython/tests/cve.py b/IPython/tests/cve.py
new file mode 100644
index 00000000000..026415a57a4
--- /dev/null
+++ b/IPython/tests/cve.py
@@ -0,0 +1,56 @@
+""""""
+Test that CVEs stay fixed. 
+""""""
+
+from IPython.utils.tempdir import TemporaryDirectory, TemporaryWorkingDirectory
+from pathlib import Path
+import random
+import sys
+import os
+import string
+import subprocess
+import time
+
+def test_cve_2022_21699():
+    """"""
+    Here we test CVE-2022-21699.
+
+    We create a temporary directory, cd into it. 
+    Make a profile file that should not be executed and start IPython in a subprocess, 
+    checking for the value.
+
+
+
+    """"""
+
+    dangerous_profile_dir = Path('profile_default')
+
+    dangerous_startup_dir = dangerous_profile_dir / 'startup'
+    dangerous_expected = 'CVE-2022-21699-'+''.join([random.choice(string.ascii_letters) for i in range(10)])
+
+    with TemporaryWorkingDirectory() as t:
+        dangerous_startup_dir.mkdir(parents=True)
+        (dangerous_startup_dir/ 'foo.py').write_text(f'print(""{dangerous_expected}"")')
+        # 1 sec to make sure FS is flushed.
+        #time.sleep(1)
+        cmd = [sys.executable,'-m', 'IPython']
+        env = os.environ.copy()
+        env['IPY_TEST_SIMPLE_PROMPT'] = '1'
+
+
+        # First we fake old behavior, making sure the profile is/was actually dangerous
+        p_dangerous = subprocess.Popen(cmd + [f'--profile-dir={dangerous_profile_dir}'], env=env, stdin=subprocess.PIPE,
+                stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+        out_dangerous, err_dangerouns = p_dangerous.communicate(b""exit\r"")
+        assert dangerous_expected in out_dangerous.decode()
+
+        # Now that we know it _would_ have been dangerous, we test it's not loaded
+        p = subprocess.Popen(cmd, env=env, stdin=subprocess.PIPE,
+                stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+        out, err = p.communicate(b""exit\r"")
+        assert b'IPython' in out
+        assert dangerous_expected not in out.decode()
+        assert err == b''
+
+
+

From 5a3dd92fe47af28fa7b6a6995e3f3fe6145952f7 Mon Sep 17 00:00:00 2001
From: Matthias Bussonnier <bussonniermatthias@gmail.com>
Date: Wed, 19 Jan 2022 14:11:27 +0100
Subject: [PATCH 3/3] link to gh advisory

---
 docs/source/whatsnew/version8.rst | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/docs/source/whatsnew/version8.rst b/docs/source/whatsnew/version8.rst
index 72167a5984c..f08ac0cc4db 100644
--- a/docs/source/whatsnew/version8.rst
+++ b/docs/source/whatsnew/version8.rst
@@ -42,6 +42,8 @@ Thus starting with this version:
  - Added a ``__patched_cves__`` attribute (set of strings) to IPython module that contain
    the list of fixed CVE. This is informational only.
 
+Further details can be read on the `GitHub Advisory <https://github.com/ipython/ipython/security/advisories/GHSA-pq7m-3gw7-gq5x>`__
+
 
 
 IPython 8.0"
PYSEC-2019-156,"From bd296e0336420b840fcd2faabb97084fd252a973 Mon Sep 17 00:00:00 2001
From: Tomas Tomecek <ttomecek@redhat.com>
Date: Sun, 1 Sep 2013 16:40:18 +0300
Subject: [PATCH] BUG: weave: fix issues with temporary directory usage

---
 scipy/weave/catalog.py            | 259 +++++++++++++++++++++++++-----
 scipy/weave/tests/test_catalog.py | 226 +++++++++++++++++++++++++-
 2 files changed, 436 insertions(+), 49 deletions(-)

diff --git a/scipy/weave/catalog.py b/scipy/weave/catalog.py
index 9abf4ecd8658..274ed415f5a8 100644
--- a/scipy/weave/catalog.py
+++ b/scipy/weave/catalog.py
@@ -34,6 +34,7 @@
 
 import os
 import sys
+import stat
 import pickle
 import socket
 import tempfile
@@ -133,7 +134,7 @@ def is_writable(dir):
 
     # Do NOT use a hardcoded name here due to the danger from race conditions
     # on NFS when multiple processes are accessing the same base directory in
-    # parallel.  We use both hostname and pocess id for the prefix in an
+    # parallel.  We use both hostname and process id for the prefix in an
     # attempt to ensure that there can really be no name collisions (tempfile
     # appends 6 random chars to this prefix).
     prefix = 'dummy_%s_%s_' % (socket.gethostname(),os.getpid())
@@ -150,6 +151,88 @@ def whoami():
     """"""return a string identifying the user.""""""
     return os.environ.get(""USER"") or os.environ.get(""USERNAME"") or ""unknown""
 
+
+def _create_dirs(path):
+    """""" create provided path, ignore errors """"""
+    try:
+        os.makedirs(path, mode=0o700)
+    except OSError:
+        pass
+
+
+def default_dir_posix(tmp_dir=None):
+    """"""
+    Create or find default catalog store for posix systems
+
+    purpose of 'tmp_dir' is to enable way how to test this function easily
+    """"""
+    path_candidates = []
+    python_name = ""python%d%d_compiled"" % tuple(sys.version_info[:2])
+
+    if tmp_dir:
+        home_dir = tmp_dir
+    else:
+        home_dir = os.path.expanduser('~')
+    tmp_dir = tmp_dir or tempfile.gettempdir()
+
+    home_temp_dir_name = '.' + python_name
+    home_temp_dir = os.path.join(home_dir, home_temp_dir_name)
+    path_candidates.append(home_temp_dir)
+
+    temp_dir_name = repr(os.getuid()) + '_' + python_name
+    temp_dir_path = os.path.join(tmp_dir, temp_dir_name)
+    path_candidates.append(temp_dir_path)
+
+    for path in path_candidates:
+        _create_dirs(path)
+        if check_dir(path):
+            return path
+
+    # since we got here, both dirs are not useful
+    tmp_dir_path = find_valid_temp_dir(temp_dir_name, tmp_dir)
+    if not tmp_dir_path:
+        tmp_dir_path = create_temp_dir(temp_dir_name, tmp_dir=tmp_dir)
+    return tmp_dir_path
+
+
+def default_dir_win(tmp_dir=None):
+    """"""
+    Create or find default catalog store for Windows systems
+
+    purpose of 'tmp_dir' is to enable way how to test this function easily
+    """"""
+    def create_win_temp_dir(prefix, inner_dir=None, tmp_dir=None):
+        """"""
+        create temp dir starting with 'prefix' in 'tmp_dir' or
+        'tempfile.gettempdir'; if 'inner_dir' is specified, it should be
+        created inside
+        """"""
+        tmp_dir_path = find_valid_temp_dir(prefix, tmp_dir)
+        if tmp_dir_path:
+            if inner_dir:
+                tmp_dir_path = os.path.join(tmp_dir_path, inner_dir)
+                if not os.path.isdir(tmp_dir_path):
+                    os.mkdir(tmp_dir_path, 0o700)
+        else:
+            tmp_dir_path = create_temp_dir(prefix, inner_dir, tmp_dir)
+        return tmp_dir_path
+
+    python_name = ""python%d%d_compiled"" % tuple(sys.version_info[:2])
+    tmp_dir = tmp_dir or tempfile.gettempdir()
+
+    temp_dir_name = ""%s"" % whoami()
+    temp_root_dir = os.path.join(tmp_dir, temp_dir_name)
+    temp_dir_path = os.path.join(temp_root_dir, python_name)
+    _create_dirs(temp_dir_path)
+    if check_dir(temp_dir_path) and check_dir(temp_root_dir):
+        return temp_dir_path
+    else:
+        if check_dir(temp_root_dir):
+            return create_win_temp_dir(python_name, tmp_dir=temp_root_dir)
+        else:
+            return create_win_temp_dir(temp_dir_name, python_name, tmp_dir)
+
+
 def default_dir():
     """""" Return a default location to store compiled files and catalogs.
 
@@ -164,45 +247,18 @@ def default_dir():
         in the user's home, /tmp/<uid>_pythonXX_compiled is used.  If it
         doesn't exist, it is created.  The directory is marked rwx------
         to try and keep people from being able to sneak a bad module
-        in on you.
-
+        in on you. If the directory already exists in /tmp/ and is not
+        secure, new one is created.
     """"""
-
     # Use a cached value for fast return if possible
-    if hasattr(default_dir,""cached_path"") and \
-       os.path.exists(default_dir.cached_path) and \
-       os.access(default_dir.cached_path, os.W_OK):
+    if hasattr(default_dir, ""cached_path"") and \
+       check_dir(default_dir.cached_path):
         return default_dir.cached_path
 
-    python_name = ""python%d%d_compiled"" % tuple(sys.version_info[:2])
-    path_candidates = []
-    if sys.platform != 'win32':
-        try:
-            path_candidates.append(os.path.join(os.environ['HOME'],
-                                                '.' + python_name))
-        except KeyError:
-            pass
-
-        temp_dir = repr(os.getuid()) + '_' + python_name
-        path_candidates.append(os.path.join(tempfile.gettempdir(), temp_dir))
+    if sys.platform == 'win32':
+        path = default_dir_win()
     else:
-        path_candidates.append(os.path.join(tempfile.gettempdir(),
-                                           ""%s"" % whoami(), python_name))
-
-    writable = False
-    for path in path_candidates:
-        if not os.path.exists(path):
-            try:
-                os.makedirs(path, mode=0o700)
-            except OSError:
-                continue
-        if is_writable(path):
-            writable = True
-            break
-
-    if not writable:
-        print('warning: default directory is not write accessible.')
-        print('default:', path)
+        path = default_dir_posix()
 
     # Cache the default dir path so that this function returns quickly after
     # being called once (nothing in it should change after the first call)
@@ -210,15 +266,132 @@ def default_dir():
 
     return path
 
-def intermediate_dir():
-    """""" Location in temp dir for storing .cpp and .o  files during
-        builds.
+
+def check_dir(im_dir):
     """"""
-    python_name = ""python%d%d_intermediate"" % tuple(sys.version_info[:2])
-    path = os.path.join(tempfile.gettempdir(),""%s""%whoami(),python_name)
-    if not os.path.exists(path):
-        os.makedirs(path, mode=0o700)
-    return path
+    Check if dir is safe; if it is, return True.
+    These checks make sense only on posix:
+     * directory has correct owner
+     * directory has correct permissions (0700)
+     * directory is not a symlink
+    """"""
+    def check_is_dir():
+        return os.path.isdir(im_dir)
+
+    def check_permissions():
+        """""" If on posix, permissions should be 0700. """"""
+        writable = is_writable(im_dir)
+        if sys.platform != 'win32':
+            try:
+                im_dir_stat = os.stat(im_dir)
+            except OSError:
+                return False
+            writable &= stat.S_IMODE(im_dir_stat.st_mode) == 0o0700
+        return writable
+
+    def check_ownership():
+        """""" Intermediate dir owner should be same as owner of process. """"""
+        if sys.platform != 'win32':
+            try:
+                im_dir_stat = os.stat(im_dir)
+            except OSError:
+                return False
+            proc_uid = os.getuid()
+            return proc_uid == im_dir_stat.st_uid
+        return True
+
+    def check_is_symlink():
+        """""" Check if intermediate dir is symlink. """"""
+        try:
+            return not os.path.islink(im_dir)
+        except OSError:
+            return False
+
+    checks = [check_is_dir, check_permissions,
+              check_ownership, check_is_symlink]
+
+    for check in checks:
+        if not check():
+            return False
+
+    return True
+
+
+def create_temp_dir(prefix, inner_dir=None, tmp_dir=None):
+    """"""
+    Create intermediate dirs <tmp>/<prefix+random suffix>/<inner_dir>/
+
+    argument 'tmp_dir' is used in unit tests
+    """"""
+    if not tmp_dir:
+        tmp_dir_path = tempfile.mkdtemp(prefix=prefix)
+    else:
+        tmp_dir_path = tempfile.mkdtemp(prefix=prefix, dir=tmp_dir)
+    if inner_dir:
+        tmp_dir_path = os.path.join(tmp_dir_path, inner_dir)
+        os.mkdir(tmp_dir_path, 0o700)
+    return tmp_dir_path
+
+
+def intermediate_dir_prefix():
+    """""" Prefix of root intermediate dir (<tmp>/<root_im_dir>). """"""
+    return ""%s-%s-"" % (""scipy"", whoami())
+
+
+def find_temp_dir(prefix, tmp_dir=None):
+    """""" Find temp dirs in 'tmp_dir' starting with 'prefix'""""""
+    matches = []
+    tmp_dir = tmp_dir or tempfile.gettempdir()
+    for tmp_file in os.listdir(tmp_dir):
+        if tmp_file.startswith(prefix):
+            matches.append(os.path.join(tmp_dir, tmp_file))
+    return matches
+
+
+def find_valid_temp_dir(prefix, tmp_dir=None):
+    """"""
+    Try to look for existing temp dirs.
+    If there is one suitable found, return it, otherwise return None.
+    """"""
+    matches = find_temp_dir(prefix, tmp_dir)
+    for match in matches:
+        if check_dir(match):
+            # as soon as we find correct dir, we can stop searching
+            return match
+
+
+def py_intermediate_dir():
+    """"""
+    Name of intermediate dir for current python interpreter:
+    <temp dir>/<name>/pythonXY_intermediate/
+    """"""
+    name = ""python%d%d_intermediate"" % tuple(sys.version_info[:2])
+    return name
+
+
+def create_intermediate_dir(tmp_dir=None):
+    py_im_dir = py_intermediate_dir()
+    return create_temp_dir(intermediate_dir_prefix(), py_im_dir, tmp_dir)
+
+
+def intermediate_dir(tmp_dir=None):
+    """"""
+    Temporary directory for storing .cpp and .o files during builds.
+
+    First, try to find the dir and if it exists, verify it is safe.
+    Otherwise, create it.
+    """"""
+    im_dir = find_valid_temp_dir(intermediate_dir_prefix(), tmp_dir)
+    py_im_dir = py_intermediate_dir()
+    if im_dir is None:
+        py_im_dir = py_intermediate_dir()
+        im_dir = create_intermediate_dir(tmp_dir)
+    else:
+        im_dir = os.path.join(im_dir, py_im_dir)
+        if not os.path.isdir(im_dir):
+            os.mkdir(im_dir, 0o700)
+    return im_dir
+
 
 def default_temp_dir():
     path = os.path.join(default_dir(),'temp')
diff --git a/scipy/weave/tests/test_catalog.py b/scipy/weave/tests/test_catalog.py
index 61c35394b292..c03fb51e952d 100644
--- a/scipy/weave/tests/test_catalog.py
+++ b/scipy/weave/tests/test_catalog.py
@@ -2,16 +2,234 @@
 
 import sys
 import os
+import stat
+import tempfile
+
+from distutils.dir_util import remove_tree
 
 from numpy.testing import TestCase, assert_
+from numpy.testing.noseclasses import KnownFailureTest
 
 from scipy.weave import catalog
 from weave_test_utils import clear_temp_catalog, restore_temp_catalog, \
         empty_temp_dir, cleanup_temp_dir
 
 
+class TestIntermediateDir(TestCase):
+    """"""
+    Tests for intermediate dir (store of .cpp and .o during builds).
+    These tests test whether intermediate dir is safe. If it's not,
+    new one should be created.
+    """"""
+    def dirs_are_valid(self, wrong_dir, tmpdir):
+        """""" test if new dir is created and is consistent """"""
+        new_im_dir = catalog.intermediate_dir(tmpdir)
+        assert_(not os.path.samefile(new_im_dir, wrong_dir))
+        new_im_dir2 = catalog.intermediate_dir(tmpdir)
+        assert_(os.path.samefile(new_im_dir, new_im_dir2))
+
+    def test_ownership(self):
+        """""" test if intermediate dir is owned by correct user """"""
+        if sys.platform != 'win32':
+            im_dir = catalog.intermediate_dir()
+            im_dir_stat = os.stat(im_dir)
+            proc_uid = os.getuid()
+            assert_(proc_uid == im_dir_stat.st_uid)
+            r_im_dir_stat = os.stat(os.path.dirname(im_dir))
+            assert_(proc_uid == r_im_dir_stat.st_uid)
+
+    def test_incorrect_ownership(self):
+        """"""
+        test if new intermediate dir is created when there is only one
+        im dir owned by improper user
+        """"""
+        if sys.platform != 'win32':
+            import pwd
+            tmpdir = tempfile.mkdtemp()
+            try:
+                im_dir = catalog.create_intermediate_dir(tmpdir)
+                root_im_dir = os.path.dirname(im_dir)
+                nobody = pwd.getpwnam('nobody')[2]
+                nobody_g = pwd.getpwnam('nobody')[3]
+                try:
+                    os.chown(root_im_dir, nobody, nobody_g)
+                except OSError:
+                    raise KnownFailureTest(""Can't change owner."")
+                else:
+                    self.dirs_are_valid(im_dir, tmpdir)
+            finally:
+                remove_tree(tmpdir)
+
+    def test_permissions(self):
+        """""" im dir should have permissions 0700 """"""
+        if sys.platform != 'win32':
+            im_dir = catalog.intermediate_dir()
+            im_dir_stat = os.stat(im_dir)
+            assert_(stat.S_IMODE(im_dir_stat.st_mode) == 0o0700)
+            r_im_dir_stat = os.stat(os.path.dirname(im_dir))
+            assert_(stat.S_IMODE(r_im_dir_stat.st_mode) == 0o0700)
+
+    def test_incorrect_permissions(self):
+        """"""
+        if permissions on existing im dir are not correct,
+        new one should be created
+        """"""
+        if sys.platform != 'win32':
+            tmpdir = tempfile.mkdtemp()
+            try:
+                im_dir = catalog.create_intermediate_dir(tmpdir)
+                root_im_dir = os.path.dirname(im_dir)
+                try:
+                    os.chmod(root_im_dir, 0o777)
+                except OSError:
+                    raise KnownFailureTest(""Can't set file permissions."")
+                else:
+                    self.dirs_are_valid(im_dir, tmpdir)
+            finally:
+                remove_tree(tmpdir)
+
+    def test_symlink(self):
+        """""" im dir shouldn't be a symlink """"""
+        if sys.platform != 'win32':
+            r_im_dir = os.path.dirname(catalog.intermediate_dir())
+            assert_(os.path.islink(r_im_dir) is False)
+
+    def test_symlink_raise(self):
+        """""" if existing im dir is a symlink, new one should be created """"""
+        if sys.platform != 'win32':
+            tmpdir = tempfile.mkdtemp()
+            try:
+                im_dir = catalog.create_intermediate_dir(tmpdir)
+                root_im_dir = os.path.dirname(im_dir)
+
+                tempdir = tempfile.mkdtemp(prefix='scipy-test', dir=tmpdir)
+                try:
+                    os.rename(root_im_dir, tempdir)
+                except OSError:
+                    raise KnownFailureTest(""Can't move intermediate dir."")
+
+                try:
+                    os.symlink(tempdir, root_im_dir)
+                except OSError:
+                    raise KnownFailureTest(
+                        ""Can't create symlink to intermediate dir."")
+                else:
+                    self.dirs_are_valid(im_dir, tmpdir)
+            finally:
+                remove_tree(tmpdir)
+
+
 class TestDefaultDir(TestCase):
+    """"""
+    Tests for 'catalog.default_dir()'.
+    These should verified posix and win default_dir function.
+    """"""
+    def test_win(self):
+        """"""
+        test if default_dir for Windows platform is accessible
+
+        since default_dir_win() does not have any Windows specific code,
+        let's test it everywhere
+        """"""
+        d = catalog.default_dir_win()
+        assert_(catalog.is_writable(d))
+
+    def test_win_inaccessible_root(self):
+        """"""
+        there should be a new root dir created if existing one is not accessible
+        """"""
+        tmpdir = tempfile.mkdtemp()
+        try:
+            d_dir = catalog.default_dir_win(tmpdir)
+            root_ddir = os.path.dirname(d_dir)
+
+            try:
+                os.chmod(root_ddir, stat.S_IREAD | stat.S_IEXEC)
+            except OSError:
+                raise KnownFailureTest(""Can't change permissions of root default_dir."")
+
+            new_ddir = catalog.default_dir_win(tmpdir)
+            assert_(not os.path.samefile(new_ddir, d_dir))
+            new_ddir2 = catalog.default_dir_win(tmpdir)
+            assert_(os.path.samefile(new_ddir, new_ddir2))
+        finally:
+            os.chmod(root_ddir, 0o700)
+            remove_tree(tmpdir)
+
+    def test_win_inaccessible_ddir(self):
+        """"""
+        create new defualt_dir if current one is not accessible
+        """"""
+        tmpdir = tempfile.mkdtemp()
+        try:
+            d_dir = catalog.default_dir_win(tmpdir)
+
+            try:
+                os.chmod(d_dir, stat.S_IREAD | stat.S_IEXEC)
+            except OSError:
+                raise KnownFailureTest(""Can't change permissions of default_dir."")
+
+            new_ddir = catalog.default_dir_win(tmpdir)
+            assert_(not os.path.samefile(new_ddir, d_dir))
+            new_ddir2 = catalog.default_dir_win(tmpdir)
+            assert_(os.path.samefile(new_ddir, new_ddir2))
+        finally:
+            os.chmod(d_dir, 0o700)
+            remove_tree(tmpdir)
+
+    def test_posix(self):
+        """""" test if posix default_dir is writable """"""
+        d = catalog.default_dir_posix()
+        assert_(catalog.is_writable(d))
+
+    def test_posix_home_inaccessible(self):
+        """""" what happens when home catalog dir is innaccessible """"""
+        tmpdir = tempfile.mkdtemp()
+        try:
+            d_dir = catalog.default_dir_posix(tmpdir)
+
+            try:
+                os.chmod(d_dir, 0o000)
+            except OSError:
+                raise KnownFailureTest(""Can't change permissions of default_dir."")
+
+            new_ddir = catalog.default_dir_posix(tmpdir)
+            assert_(not os.path.samefile(new_ddir, d_dir))
+            new_ddir2 = catalog.default_dir_posix(tmpdir)
+            assert_(os.path.samefile(new_ddir, new_ddir2))
+        finally:
+            os.chmod(d_dir, 0o700)
+            remove_tree(tmpdir)
+
+    def test_posix_dirs_inaccessible(self):
+        """""" test if new dir is created if both implicit dirs are not valid""""""
+        tmpdir = tempfile.mkdtemp()
+        try:
+            d_dir = catalog.default_dir_posix(tmpdir)
+
+            try:
+                os.chmod(d_dir, 0o000)
+            except OSError:
+                raise KnownFailureTest(""Can't change permissions of default_dir."")
+
+            d_dir2 = catalog.default_dir_posix(tmpdir)
+
+            try:
+                os.chmod(d_dir2, 0o000)
+            except OSError:
+                raise KnownFailureTest(""Can't change permissions of default_dir."")
+
+            new_ddir = catalog.default_dir_posix(tmpdir)
+            assert_(not (os.path.samefile(new_ddir, d_dir) or os.path.samefile(new_ddir, d_dir2)))
+            new_ddir2 = catalog.default_dir_posix(tmpdir)
+            assert_(os.path.samefile(new_ddir, new_ddir2))
+        finally:
+            os.chmod(d_dir, 0o700)
+            os.chmod(d_dir2, 0o700)
+            remove_tree(tmpdir)
+
     def test_is_writable(self):
+        """""" default_dir has to be writable """"""
         path = catalog.default_dir()
         name = os.path.join(path,'dummy_catalog')
         test_file = open(name,'w')
@@ -93,14 +311,10 @@ def get_test_dir(self,erase = 0):
                 os.remove(cat_file)
         return pardir
 
-    def remove_dir(self,d):
-        import distutils.dir_util
-        distutils.dir_util.remove_tree(d)
-
     def test_nonexistent_catalog_is_none(self):
         pardir = self.get_test_dir(erase=1)
         cat = catalog.get_catalog(pardir,'r')
-        self.remove_dir(pardir)
+        remove_tree(pardir)
         assert_(cat is None)
 
     def test_create_catalog(self):
@@ -108,7 +322,7 @@ def test_create_catalog(self):
         cat = catalog.get_catalog(pardir,'c')
         assert_(cat is not None)
         cat.close()
-        self.remove_dir(pardir)
+        remove_tree(pardir)
 
 
 class TestCatalog(TestCase):"
CVE-2019-10160,"From 8d0ef0b5edeae52960c7ed05ae8a12388324f87e Mon Sep 17 00:00:00 2001
From: Steve Dower <steve.dower@python.org>
Date: Tue, 4 Jun 2019 08:55:30 -0700
Subject: [PATCH] bpo-36742: Corrects fix to handle decomposition in usernames
 (#13812)

---
 Lib/test/test_urlparse.py | 11 ++++++-----
 Lib/urllib/parse.py       |  6 +++---
 2 files changed, 9 insertions(+), 8 deletions(-)

diff --git a/Lib/test/test_urlparse.py b/Lib/test/test_urlparse.py
index 43447656376472..4ae6ed33858ce2 100644
--- a/Lib/test/test_urlparse.py
+++ b/Lib/test/test_urlparse.py
@@ -1018,11 +1018,12 @@ def test_urlsplit_normalization(self):
             urllib.parse.urlsplit('http://\u30d5\u309a\ufe1380')
 
         for scheme in [""http"", ""https"", ""ftp""]:
-            for c in denorm_chars:
-                url = ""{}://netloc{}false.netloc/path"".format(scheme, c)
-                with self.subTest(url=url, char='{:04X}'.format(ord(c))):
-                    with self.assertRaises(ValueError):
-                        urllib.parse.urlsplit(url)
+            for netloc in [""netloc{}false.netloc"", ""n{}user@netloc""]:
+                for c in denorm_chars:
+                    url = ""{}://{}/path"".format(scheme, netloc.format(c))
+                    with self.subTest(url=url, char='{:04X}'.format(ord(c))):
+                        with self.assertRaises(ValueError):
+                            urllib.parse.urlsplit(url)
 
 class Utility_Tests(unittest.TestCase):
     """"""Testcase to test the various utility functions in the urllib.""""""
diff --git a/Lib/urllib/parse.py b/Lib/urllib/parse.py
index daefb2025b14ea..b6608783a89471 100644
--- a/Lib/urllib/parse.py
+++ b/Lib/urllib/parse.py
@@ -402,9 +402,9 @@ def _checknetloc(netloc):
     # looking for characters like \u2100 that expand to 'a/c'
     # IDNA uses NFKC equivalence, so normalize for this check
     import unicodedata
-    n = netloc.rpartition('@')[2] # ignore anything to the left of '@'
-    n = n.replace(':', '')        # ignore characters already included
-    n = n.replace('#', '')        # but not the surrounding text
+    n = netloc.replace('@', '')   # ignore characters already included
+    n = n.replace(':', '')        # but not the surrounding text
+    n = n.replace('#', '')
     n = n.replace('?', '')
     netloc2 = unicodedata.normalize('NFKC', n)
     if n == netloc2:"
PYSEC-2017-36,"From 80d90307b07b3703428ecbb7c8bb468e28a9ae6d Mon Sep 17 00:00:00 2001
From: Erik Johnson <palehose@gmail.com>
Date: Wed, 23 Aug 2017 10:20:50 -0500
Subject: [PATCH] Don't allow path separators in minion ID

---
 salt/utils/verify.py            | 15 ++++-----------
 tests/unit/utils/test_verify.py | 10 ++++++++++
 2 files changed, 14 insertions(+), 11 deletions(-)

diff --git a/salt/utils/verify.py b/salt/utils/verify.py
index 6e69283f073c..24b2a1d962e0 100644
--- a/salt/utils/verify.py
+++ b/salt/utils/verify.py
@@ -480,22 +480,15 @@ def clean_path(root, path, subdir=False):
     return ''
 
 
-def clean_id(id_):
-    '''
-    Returns if the passed id is clean.
-    '''
-    if re.search(r'\.\.\{sep}'.format(sep=os.sep), id_):
-        return False
-    return True
-
-
 def valid_id(opts, id_):
     '''
     Returns if the passed id is valid
     '''
     try:
-        return bool(clean_path(opts['pki_dir'], id_)) and clean_id(id_)
-    except (AttributeError, KeyError, TypeError) as e:
+        if any(x in id_ for x in ('/', '\\', '\0')):
+            return False
+        return bool(clean_path(opts['pki_dir'], id_))
+    except (AttributeError, KeyError, TypeError):
         return False
 
 
diff --git a/tests/unit/utils/test_verify.py b/tests/unit/utils/test_verify.py
index 795298877dd0..fa091f6cb393 100644
--- a/tests/unit/utils/test_verify.py
+++ b/tests/unit/utils/test_verify.py
@@ -58,6 +58,16 @@ def test_valid_id_exception_handler(self):
         opts = {'pki_dir': '/tmp/whatever'}
         self.assertFalse(valid_id(opts, None))
 
+    def test_valid_id_pathsep(self):
+        '''
+        Path separators in id should make it invalid
+        '''
+        opts = {'pki_dir': '/tmp/whatever'}
+        # We have to test both path separators because os.path.normpath will
+        # convert forward slashes to backslashes on Windows.
+        for pathsep in ('/', '\\'):
+            self.assertFalse(valid_id(opts, pathsep.join(('..', 'foobar'))))
+
     def test_zmq_verify(self):
         self.assertTrue(zmq_version())"
GHSA-8278-88vv-x98r,"From f8c2095fd529e664e7fa25403a0a4a85bb3907d0 Mon Sep 17 00:00:00 2001
From: Steve McGrath <smcgrath@tenable.com>
Date: Thu, 4 Mar 2021 08:58:38 -0600
Subject: [PATCH] switched yaml.load() to yaml.safe_load() to not load
 serialized python objects.

---
 tenable_jira/cli.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/tenable_jira/cli.py b/tenable_jira/cli.py
index 17bb76b..1f16571 100644
--- a/tenable_jira/cli.py
+++ b/tenable_jira/cli.py
@@ -62,7 +62,7 @@ def cli(configfile, observed_since, setup_only=False, troubleshoot=False):
     '''
     # Load the config, but ensure that any additional fields are additive to the
     # basic field set.
-    config_from_file = yaml.load(configfile, Loader=yaml.Loader)
+    config_from_file = yaml.safe_load(configfile)
     fields = config_from_file.pop('custom_fields', list())
     config = dict_merge(base_config(), config_from_file)
     config['fields'] = config['fields'] + fields"
GHSA-cvp7-c586-cmf4,"From 4b0070a4f30cbf6d5e12e6274b242b62ea11c81b Mon Sep 17 00:00:00 2001
From: Delgan <delgan.py@gmail.com>
Date: Fri, 21 Jan 2022 11:21:58 +0100
Subject: [PATCH] Remove use of ""pickle.loads()"" to comply with security tools
 (#563)

---
 loguru/_recattrs.py              | 18 +++++++-----------
 tests/test_add_option_enqueue.py | 28 +++++++++++++++++++++++++---
 2 files changed, 32 insertions(+), 14 deletions(-)

diff --git a/loguru/_recattrs.py b/loguru/_recattrs.py
index 50150aab..7c48f011 100644
--- a/loguru/_recattrs.py
+++ b/loguru/_recattrs.py
@@ -64,18 +64,14 @@ def __repr__(self):
         return ""(type=%r, value=%r, traceback=%r)"" % (self.type, self.value, self.traceback)
 
     def __reduce__(self):
+        # The traceback is not picklable so we need to remove it. Also, some custom exception
+        # values aren't picklable either. For user convenience, we try first to serialize it and
+        # we remove the value in case or error. As an optimization, we could have re-used the
+        # dumped value during unpickling, but this requires using ""pickle.loads()"" which is
+        # flagged as insecure by some security tools.
         try:
-            pickled_value = pickle.dumps(self.value)
+            pickle.dumps(self.value)
         except pickle.PickleError:
             return (RecordException, (self.type, None, None))
         else:
-            return (RecordException._from_pickled_value, (self.type, pickled_value, None))
-
-    @classmethod
-    def _from_pickled_value(cls, type_, pickled_value, traceback_):
-        try:
-            value = pickle.loads(pickled_value)
-        except pickle.PickleError:
-            return cls(type_, None, traceback_)
-        else:
-            return cls(type_, value, traceback_)
+            return (RecordException, (self.type, self.value, None))
diff --git a/tests/test_add_option_enqueue.py b/tests/test_add_option_enqueue.py
index 0b438009..589cdc26 100644
--- a/tests/test_add_option_enqueue.py
+++ b/tests/test_add_option_enqueue.py
@@ -191,8 +191,7 @@ def slow_sink(message):
     assert err == """".join(""%d\n"" % i for i in range(10))
 
 
-@pytest.mark.parametrize(""arg"", [NotPicklable(), NotUnpicklable()])
-def test_logging_not_picklable_exception(arg):
+def test_logging_not_picklable_exception():
     exception = None
 
     def sink(message):
@@ -202,7 +201,30 @@ def sink(message):
     logger.add(sink, enqueue=True, catch=False)
 
     try:
-        raise ValueError(arg)
+        raise ValueError(NotPicklable())
+    except Exception:
+        logger.exception(""Oups"")
+
+    logger.remove()
+
+    type_, value, traceback_ = exception
+    assert type_ is ValueError
+    assert value is None
+    assert traceback_ is None
+
+
+@pytest.mark.xfail(reason=""No way to safely deserialize exception yet"")
+def test_logging_not_unpicklable_exception():
+    exception = None
+
+    def sink(message):
+        nonlocal exception
+        exception = message.record[""exception""]
+
+    logger.add(sink, enqueue=True, catch=False)
+
+    try:
+        raise ValueError(NotUnpicklable())
     except Exception:
         logger.exception(""Oups"")"
CVE-2022-1531,"From fa2797e656e3dba18f990a2db1f0f029d41f1921 Mon Sep 17 00:00:00 2001
From: Eric Deutsch <edeutsch@systemsbiology.org>
Date: Wed, 20 Apr 2022 18:38:35 +0000
Subject: [PATCH] avoid SQL injection exploits

---
 code/autocomplete/rtxcomplete.py | 12 ++++++++++--
 1 file changed, 10 insertions(+), 2 deletions(-)

diff --git a/code/autocomplete/rtxcomplete.py b/code/autocomplete/rtxcomplete.py
index 714398532..4ad23484d 100644
--- a/code/autocomplete/rtxcomplete.py
+++ b/code/autocomplete/rtxcomplete.py
@@ -23,6 +23,7 @@ def load():
     database_name = f""{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}""
     conn = sqlite3.connect(database_name)
     cursor = conn.cursor()
+    #print(f""INFO: Connected to {database_name}"",file=sys.stderr)
     return True
 
 
@@ -39,6 +40,9 @@ def get_nodes_like(word,requested_limit):
     if len(word) < 2:
         return values
 
+    #### Try to avoid SQL injection exploits by sanitizing input #1823
+    word = word.replace('""','')
+
     floor = word[:-1]
     ceiling = floor + 'zz'
 
@@ -103,8 +107,12 @@ def get_nodes_like(word,requested_limit):
         if found_fragment is None:
 
             #### Cache this fragment in the database
-            cursor.execute(""INSERT INTO cached_fragments(fragment) VALUES(?)"", (word,))
-            fragment_id = cursor.lastrowid
+            try:
+                cursor.execute(""INSERT INTO cached_fragments(fragment) VALUES(?)"", (word,))
+                fragment_id = cursor.lastrowid
+            except:
+                print(f""ERROR: Unable to INSERT into cached_fragments(fragment)"",file=sys.stderr)
+                fragment_id = 0
             if debug:
                 print(f""fragment_id = {fragment_id}"")"
CVE-2021-43777,"From da696ff7f84787cbf85967460fac52886cbe063e Mon Sep 17 00:00:00 2001
From: Jesse <jesse.whitehouse@databricks.com>
Date: Tue, 23 Nov 2021 16:22:02 -0600
Subject: [PATCH] Merge pull request from GHSA-vhc7-w7r8-8m34

* WIP: break the flask_oauthlib behavior

* Refactor google-oauth to use cryptographic state.

* Clean up comments

* Fix: tests didn't pass because of the scope issues.

Moved outside the create_blueprint method because this does not depend
on the Authlib object.

* Apply Arik's fixes. Tests pass.
---
 redash/authentication/__init__.py     |   8 +-
 redash/authentication/google_oauth.py | 181 +++++++++++++-------------
 requirements.txt                      |   4 +-
 3 files changed, 100 insertions(+), 93 deletions(-)

diff --git a/redash/authentication/__init__.py b/redash/authentication/__init__.py
index 94bf53bea1..f06cd3cdb2 100644
--- a/redash/authentication/__init__.py
+++ b/redash/authentication/__init__.py
@@ -243,12 +243,13 @@ def logout_and_redirect_to_index():
 
 def init_app(app):
     from redash.authentication import (
-        google_oauth,
         saml_auth,
         remote_user_auth,
         ldap_auth,
     )
 
+    from redash.authentication.google_oauth import create_google_oauth_blueprint
+
     login_manager.init_app(app)
     login_manager.anonymous_user = models.AnonymousUser
     login_manager.REMEMBER_COOKIE_DURATION = settings.REMEMBER_COOKIE_DURATION
@@ -259,8 +260,9 @@ def extend_session():
         app.permanent_session_lifetime = timedelta(seconds=settings.SESSION_EXPIRY_TIME)
 
     from redash.security import csrf
-    for auth in [google_oauth, saml_auth, remote_user_auth, ldap_auth]:
-        blueprint = auth.blueprint
+
+    # Authlib's flask oauth client requires a Flask app to initialize
+    for blueprint in [create_google_oauth_blueprint(app), saml_auth.blueprint, remote_user_auth.blueprint, ldap_auth.blueprint, ]:
         csrf.exempt(blueprint)
         app.register_blueprint(blueprint)
 
diff --git a/redash/authentication/google_oauth.py b/redash/authentication/google_oauth.py
index 59d49ef90e..a1f58d3fcf 100644
--- a/redash/authentication/google_oauth.py
+++ b/redash/authentication/google_oauth.py
@@ -1,7 +1,7 @@
 import logging
 import requests
 from flask import redirect, url_for, Blueprint, flash, request, session
-from flask_oauthlib.client import OAuth
+
 
 from redash import models, settings
 from redash.authentication import (
@@ -11,42 +11,7 @@
 )
 from redash.authentication.org_resolving import current_org
 
-logger = logging.getLogger(""google_oauth"")
-
-oauth = OAuth()
-blueprint = Blueprint(""google_oauth"", __name__)
-
-
-def google_remote_app():
-    if ""google"" not in oauth.remote_apps:
-        oauth.remote_app(
-            ""google"",
-            base_url=""https://www.google.com/accounts/"",
-            authorize_url=""https://accounts.google.com/o/oauth2/auth?prompt=select_account+consent"",
-            request_token_url=None,
-            request_token_params={
-                ""scope"": ""https://www.googleapis.com/auth/userinfo.email https://www.googleapis.com/auth/userinfo.profile""
-            },
-            access_token_url=""https://accounts.google.com/o/oauth2/token"",
-            access_token_method=""POST"",
-            consumer_key=settings.GOOGLE_CLIENT_ID,
-            consumer_secret=settings.GOOGLE_CLIENT_SECRET,
-        )
-
-    return oauth.google
-
-
-def get_user_profile(access_token):
-    headers = {""Authorization"": ""OAuth {}"".format(access_token)}
-    response = requests.get(
-        ""https://www.googleapis.com/oauth2/v1/userinfo"", headers=headers
-    )
-
-    if response.status_code == 401:
-        logger.warning(""Failed getting user profile (response code 401)."")
-        return None
-
-    return response.json()
+from authlib.integrations.flask_client import OAuth
 
 
 def verify_profile(org, profile):
@@ -65,60 +30,102 @@ def verify_profile(org, profile):
     return False
 
 
-@blueprint.route(""/<org_slug>/oauth/google"", endpoint=""authorize_org"")
-def org_login(org_slug):
-    session[""org_slug""] = current_org.slug
-    return redirect(url_for("".authorize"", next=request.args.get(""next"", None)))
+def create_google_oauth_blueprint(app):
+    oauth = OAuth(app)
 
+    logger = logging.getLogger(""google_oauth"")
+    blueprint = Blueprint(""google_oauth"", __name__)
 
-@blueprint.route(""/oauth/google"", endpoint=""authorize"")
-def login():
-    callback = url_for("".callback"", _external=True)
-    next_path = request.args.get(
-        ""next"", url_for(""redash.index"", org_slug=session.get(""org_slug""))
+    CONF_URL = ""https://accounts.google.com/.well-known/openid-configuration""
+    oauth = OAuth(app)
+    oauth.register(
+        name=""google"",
+        server_metadata_url=CONF_URL,
+        client_kwargs={""scope"": ""openid email profile""},
     )
-    logger.debug(""Callback url: %s"", callback)
-    logger.debug(""Next is: %s"", next_path)
-    return google_remote_app().authorize(callback=callback, state=next_path)
-
-
-@blueprint.route(""/oauth/google_callback"", endpoint=""callback"")
-def authorized():
-    resp = google_remote_app().authorized_response()
-    access_token = resp[""access_token""]
-
-    if access_token is None:
-        logger.warning(""Access token missing in call back request."")
-        flash(""Validation error. Please retry."")
-        return redirect(url_for(""redash.login""))
-
-    profile = get_user_profile(access_token)
-    if profile is None:
-        flash(""Validation error. Please retry."")
-        return redirect(url_for(""redash.login""))
-
-    if ""org_slug"" in session:
-        org = models.Organization.get_by_slug(session.pop(""org_slug""))
-    else:
-        org = current_org
-
-    if not verify_profile(org, profile):
-        logger.warning(
-            ""User tried to login with unauthorized domain name: %s (org: %s)"",
-            profile[""email""],
-            org,
+
+    def get_user_profile(access_token):
+        headers = {""Authorization"": ""OAuth {}"".format(access_token)}
+        response = requests.get(
+            ""https://www.googleapis.com/oauth2/v1/userinfo"", headers=headers
         )
-        flash(""Your Google Apps account ({}) isn't allowed."".format(profile[""email""]))
-        return redirect(url_for(""redash.login"", org_slug=org.slug))
 
-    picture_url = ""%s?sz=40"" % profile[""picture""]
-    user = create_and_login_user(org, profile[""name""], profile[""email""], picture_url)
-    if user is None:
-        return logout_and_redirect_to_index()
+        if response.status_code == 401:
+            logger.warning(""Failed getting user profile (response code 401)."")
+            return None
 
-    unsafe_next_path = request.args.get(""state"") or url_for(
-        ""redash.index"", org_slug=org.slug
-    )
-    next_path = get_next_path(unsafe_next_path)
+        return response.json()
+
+    @blueprint.route(""/<org_slug>/oauth/google"", endpoint=""authorize_org"")
+    def org_login(org_slug):
+        session[""org_slug""] = current_org.slug
+        return redirect(url_for("".authorize"", next=request.args.get(""next"", None)))
+
+    @blueprint.route(""/oauth/google"", endpoint=""authorize"")
+    def login():
+
+        redirect_uri = url_for("".callback"", _external=True)
+
+        next_path = request.args.get(
+            ""next"", url_for(""redash.index"", org_slug=session.get(""org_slug""))
+        )
+        logger.debug(""Callback url: %s"", redirect_uri)
+        logger.debug(""Next is: %s"", next_path)
+
+        session[""next_url""] = next_path
+
+        return oauth.google.authorize_redirect(redirect_uri)
+
+    @blueprint.route(""/oauth/google_callback"", endpoint=""callback"")
+    def authorized():
+
+        logger.debug(""Authorized user inbound"")
+
+        resp = oauth.google.authorize_access_token()
+        user = resp.get(""userinfo"")
+        if user:
+            session[""user""] = user
+
+        access_token = resp[""access_token""]
+
+        if access_token is None:
+            logger.warning(""Access token missing in call back request."")
+            flash(""Validation error. Please retry."")
+            return redirect(url_for(""redash.login""))
+
+        profile = get_user_profile(access_token)
+        if profile is None:
+            flash(""Validation error. Please retry."")
+            return redirect(url_for(""redash.login""))
+
+        if ""org_slug"" in session:
+            org = models.Organization.get_by_slug(session.pop(""org_slug""))
+        else:
+            org = current_org
+
+        if not verify_profile(org, profile):
+            logger.warning(
+                ""User tried to login with unauthorized domain name: %s (org: %s)"",
+                profile[""email""],
+                org,
+            )
+            flash(
+                ""Your Google Apps account ({}) isn't allowed."".format(profile[""email""])
+            )
+            return redirect(url_for(""redash.login"", org_slug=org.slug))
+
+        picture_url = ""%s?sz=40"" % profile[""picture""]
+        user = create_and_login_user(
+            org, profile[""name""], profile[""email""], picture_url
+        )
+        if user is None:
+            return logout_and_redirect_to_index()
+
+        unsafe_next_path = session.get(""next_url"") or url_for(
+            ""redash.index"", org_slug=org.slug
+        )
+        next_path = get_next_path(unsafe_next_path)
+
+        return redirect(next_path)
 
-    return redirect(next_path)
+    return blueprint
diff --git a/requirements.txt b/requirements.txt
index 62e64f3a36..03eb0e9edc 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -8,9 +8,6 @@ httplib2==0.14.0
 wtforms==2.2.1
 Flask-RESTful==0.3.7
 Flask-Login==0.4.1
-Flask-OAuthLib==0.9.5
-# pin this until https://github.com/lepture/flask-oauthlib/pull/388 is released
-requests-oauthlib>=0.6.2,<1.2.0
 Flask-SQLAlchemy==2.4.1
 Flask-Migrate==2.5.2
 flask-mail==0.9.1
@@ -67,3 +64,4 @@ werkzeug==0.16.1
 # Uncomment the requirement for ldap3 if using ldap.
 # It is not included by default because of the GPL license conflict.
 # ldap3==2.2.4
+Authlib==0.15.5
\ No newline at end of file"
CVE-2021-3027,"From 366b03f607729c4538e91b634ecc57c8398522a1 Mon Sep 17 00:00:00 2001
From: Erwan Le Gall <legall.erwan@gmail.com>
Date: Tue, 26 Jan 2021 13:09:03 +0100
Subject: [PATCH] Update user.py

Double check on bind from user input in case of external access of the function
---
 passhportd/app/views_mod/user/user.py | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/passhportd/app/views_mod/user/user.py b/passhportd/app/views_mod/user/user.py
index f082da5f..20d7d1cd 100755
--- a/passhportd/app/views_mod/user/user.py
+++ b/passhportd/app/views_mod/user/user.py
@@ -28,7 +28,7 @@ def useruid(s, login):
 
     # Look for the user entry.
     if not c.search(config.LDAPBASE,
-                    ""("" + config.LDAPFIELD + ""="" + login + "")"") :
+                    ""("" + config.LDAPFIELD + ""="" + escape_rdn(login) + "")"") :
         app.logger.error(""Error: Connection to the LDAP with service account failed"")
     else:
         if len(c.entries) >= 1 :
@@ -49,7 +49,7 @@ def try_ldap_login(login, password):
     s = Server(config.LDAPURI, port=config.LDAPPORT,
                use_ssl=False, get_info=ALL)
     # 1. connection with service account to find the user uid
-    uid = useruid(s, login)
+    uid = useruid(s, escape_rdn(login))
    
     if uid: 
         # 2. Try to bind the user to the LDAP"
PYSEC-2015-2,"From 3cdc6cb555173130d64ea6d90033a6e00cbde330 Mon Sep 17 00:00:00 2001
From: Owen Synge <osynge@suse.com>
Date: Tue, 17 Mar 2015 14:09:42 +0100
Subject: [PATCH] Fix: keyring permissions where world readable

Reported in https://bugzilla.suse.com/show_bug.cgi?id=920926
by  Andreas Stieger <astieger@suse.com>

Before thsi fix to umask for keyring handling, After execution
of ceph-deploy, all keyrings have mode 644.

The documented ceph-deploy procedure by creating a dedicated
admin user, and keys will be readable to all other (non-admin)
users as well, thus leaking authentication credentials.

The fix uses umask to resolve the writing of keyfiles.

Signed-off-by: Owen Synge <osynge@suse.com>
---
 ceph_deploy/gatherkeys.py | 75 ++++++++++++++++++++-------------------
 ceph_deploy/new.py        | 23 ++++++------
 2 files changed, 52 insertions(+), 46 deletions(-)

diff --git a/ceph_deploy/gatherkeys.py b/ceph_deploy/gatherkeys.py
index bd856628..d35a9ae3 100644
--- a/ceph_deploy/gatherkeys.py
+++ b/ceph_deploy/gatherkeys.py
@@ -30,51 +30,54 @@ def fetch_file(args, frompath, topath, _hosts):
 
 
 def gatherkeys(args):
-    # client.admin
-    keyring = '/etc/ceph/{cluster}.client.admin.keyring'.format(
-        cluster=args.cluster)
-    r = fetch_file(
-        args=args,
-        frompath=keyring,
-        topath='{cluster}.client.admin.keyring'.format(
-            cluster=args.cluster),
-        _hosts=args.mon,
-        )
-    if not r:
-        raise exc.KeyNotFoundError(keyring, args.mon)
-
-    # mon.
-    keyring = '/var/lib/ceph/mon/{cluster}-{{hostname}}/keyring'.format(
-        cluster=args.cluster)
-    r = fetch_file(
-        args=args,
-        frompath=keyring,
-        topath='{cluster}.mon.keyring'.format(cluster=args.cluster),
-        _hosts=args.mon,
-        )
-    if not r:
-        raise exc.KeyNotFoundError(keyring, args.mon)
+    oldmask = os.umask(077)
+    try:
+        # client.admin
+        keyring = '/etc/ceph/{cluster}.client.admin.keyring'.format(
+            cluster=args.cluster)
+        r = fetch_file(
+            args=args,
+            frompath=keyring,
+            topath='{cluster}.client.admin.keyring'.format(
+                cluster=args.cluster),
+            _hosts=args.mon,
+            )
+        if not r:
+            raise exc.KeyNotFoundError(keyring, args.mon)
 
-    # bootstrap
-    for what in ['osd', 'mds', 'rgw']:
-        keyring = '/var/lib/ceph/bootstrap-{what}/{cluster}.keyring'.format(
-            what=what,
+        # mon.
+        keyring = '/var/lib/ceph/mon/{cluster}-{{hostname}}/keyring'.format(
             cluster=args.cluster)
         r = fetch_file(
             args=args,
             frompath=keyring,
-            topath='{cluster}.bootstrap-{what}.keyring'.format(
-                cluster=args.cluster,
-                what=what),
+            topath='{cluster}.mon.keyring'.format(cluster=args.cluster),
             _hosts=args.mon,
             )
         if not r:
-            if what in ['osd', 'mds']:
-                raise exc.KeyNotFoundError(keyring, args.mon)
-            else:
-                LOG.warning((""No RGW bootstrap key found. Will not be able to ""
-                             ""deploy RGW daemons""))
+            raise exc.KeyNotFoundError(keyring, args.mon)
 
+        # bootstrap
+        for what in ['osd', 'mds', 'rgw']:
+            keyring = '/var/lib/ceph/bootstrap-{what}/{cluster}.keyring'.format(
+                what=what,
+                cluster=args.cluster)
+            r = fetch_file(
+                args=args,
+                frompath=keyring,
+                topath='{cluster}.bootstrap-{what}.keyring'.format(
+                    cluster=args.cluster,
+                    what=what),
+                _hosts=args.mon,
+                )
+            if not r:
+                if what in ['osd', 'mds']:
+                    raise exc.KeyNotFoundError(keyring, args.mon)
+                else:
+                    LOG.warning((""No RGW bootstrap key found. Will not be able to ""
+                                 ""deploy RGW daemons""))
+    finally:
+        os.umask(oldmask)
 
 @priority(40)
 def make(parser):
diff --git a/ceph_deploy/new.py b/ceph_deploy/new.py
index 902e87d9..ab1dfc03 100644
--- a/ceph_deploy/new.py
+++ b/ceph_deploy/new.py
@@ -211,18 +211,21 @@ def new_mon_keyring(args):
     keypath = '{name}.mon.keyring'.format(
         name=args.cluster,
         )
-
+    oldmask = os.umask(077)
     LOG.debug('Writing monitor keyring to %s...', keypath)
-    tmp = '%s.tmp' % keypath
-    with file(tmp, 'w') as f:
-        f.write(mon_keyring)
     try:
-        os.rename(tmp, keypath)
-    except OSError as e:
-        if e.errno == errno.EEXIST:
-            raise exc.ClusterExistsError(keypath)
-        else:
-            raise
+        tmp = '%s.tmp' % keypath
+        with open(tmp, 'w', 0600) as f:
+            f.write(mon_keyring)
+        try:
+            os.rename(tmp, keypath)
+        except OSError as e:
+            if e.errno == errno.EEXIST:
+                raise exc.ClusterExistsError(keypath)
+            else:
+                raise
+    finally:
+        os.umask(oldmask)
 
 
 @priority(10)"
GHSA-8wwf-2644-f8x4,"From e343c577cd7da4d304b837d4a07ab4df1e023092 Mon Sep 17 00:00:00 2001
From: Vladimir Iakovlev <nvbn.rm@gmail.com>
Date: Tue, 8 Jun 2021 22:04:51 +0200
Subject: [PATCH] NA: Fix possible changes in files outside of working
 directory (#1206)

---
 thefuck/rules/dirty_untar.py | 4 ++++
 thefuck/rules/dirty_unzip.py | 4 ++++
 2 files changed, 8 insertions(+)

diff --git a/thefuck/rules/dirty_untar.py b/thefuck/rules/dirty_untar.py
index d94958b97..638aa8767 100644
--- a/thefuck/rules/dirty_untar.py
+++ b/thefuck/rules/dirty_untar.py
@@ -41,6 +41,10 @@ def get_new_command(command):
 def side_effect(old_cmd, command):
     with tarfile.TarFile(_tar_file(old_cmd.script_parts)[0]) as archive:
         for file in archive.getnames():
+            if not os.path.abspath(file).startswith(os.getcwd()):
+                # it's unsafe to overwrite files outside of the current directory
+                continue
+
             try:
                 os.remove(file)
             except OSError:
diff --git a/thefuck/rules/dirty_unzip.py b/thefuck/rules/dirty_unzip.py
index 5369dea70..6b5079876 100644
--- a/thefuck/rules/dirty_unzip.py
+++ b/thefuck/rules/dirty_unzip.py
@@ -45,6 +45,10 @@ def get_new_command(command):
 def side_effect(old_cmd, command):
     with zipfile.ZipFile(_zip_file(old_cmd), 'r') as archive:
         for file in archive.namelist():
+            if not os.path.abspath(file).startswith(os.getcwd()):
+                # it's unsafe to overwrite files outside of the current directory
+                continue
+
             try:
                 os.remove(file)
             except OSError:"
GHSA-2ww3-fxvq-293j,"From 277711ab1dec729e626b27aab6fa35ea5efbd7e6 Mon Sep 17 00:00:00 2001
From: Tom Aarsen <37621491+tomaarsen@users.noreply.github.com>
Date: Sat, 25 Sep 2021 01:14:32 +0200
Subject: [PATCH] Resolved ReDoS vulnerability in Corpus Reader (#2816)

* Resolved ReDoS vulnerability in the Corpus Reader for the Comparative Sentence Dataset

* Solidified performance tests
---
 nltk/corpus/reader/comparative_sents.py |  2 +-
 nltk/test/corpus.doctest                | 32 +++++++++++++++++++++++++
 2 files changed, 33 insertions(+), 1 deletion(-)

diff --git a/nltk/corpus/reader/comparative_sents.py b/nltk/corpus/reader/comparative_sents.py
index cbfac4c13c..ed295e4e02 100644
--- a/nltk/corpus/reader/comparative_sents.py
+++ b/nltk/corpus/reader/comparative_sents.py
@@ -45,7 +45,7 @@
 GRAD_COMPARISON = re.compile(r""<cs-[123]>"")
 NON_GRAD_COMPARISON = re.compile(r""<cs-4>"")
 ENTITIES_FEATS = re.compile(r""(\d)_((?:[\.\w\s/-](?!\d_))+)"")
-KEYWORD = re.compile(r""\((?!.*\()(.*)\)$"")
+KEYWORD = re.compile(r""\(([^\(]*)\)$"")
 
 
 class Comparison:
diff --git a/nltk/test/corpus.doctest b/nltk/test/corpus.doctest
index 82b17f8a5a..560e641a69 100644
--- a/nltk/test/corpus.doctest
+++ b/nltk/test/corpus.doctest
@@ -2162,3 +2162,35 @@ access to its tuples() method
     >>> from nltk.corpus import qc
     >>> qc.tuples('test.txt')
     [('NUM:dist', 'How far is it from Denver to Aspen ?'), ('LOC:city', 'What county is Modesto , California in ?'), ...]
+
+Ensure that KEYWORD from `comparative_sents.py` no longer contains a ReDoS vulnerability.
+
+    >>> import re
+    >>> import time
+    >>> from nltk.corpus.reader.comparative_sents import KEYWORD
+    >>> sizes = {
+    ...     ""short"": 4000,
+    ...     ""long"": 40000
+    ... }
+    >>> exec_times = {
+    ...     ""short"": [],
+    ...     ""long"": [],
+    ... }
+    >>> for size_name, size in sizes.items():
+    ...     for j in range(9):
+    ...         start_t = time.perf_counter()
+    ...         payload = ""( "" + ""("" * size
+    ...         output = KEYWORD.findall(payload)
+    ...         exec_times[size_name].append(time.perf_counter() - start_t)
+    ...     exec_times[size_name] = sorted(exec_times[size_name])[4] # Get the mean
+
+Ideally, the execution time of such a regular expression is linear
+in the length of the input. As such, we would expect exec_times[""long""]
+to be roughly 10 times as big as exec_times[""short""].
+With the ReDoS in place, it took roughly 80 times as long.
+For now, we accept values below 30 (times as long), due to the potential
+for variance. This ensures that the ReDoS has certainly been reduced,
+if not removed.
+
+    >>> exec_times[""long""] / exec_times[""short""] < 30
+    True"
GHSA-75c9-jrh4-79mc,"From 8b202f08d52e8206af2bdb2112a62fafbc546ec7 Mon Sep 17 00:00:00 2001
From: Katherine Wu <kathywu@google.com>
Date: Thu, 30 Sep 2021 13:35:10 -0700
Subject: [PATCH] Remove use of `eval` when evaluating the input example.

Use `ast.eval_literal` instead which safely evaluates the expression.

PiperOrigin-RevId: 400012249
Change-Id: I5ff98608ea2d736d093aa488af723ff4f6707e02
---
 RELEASE.md                                    |  2 ++
 tensorflow/python/tools/saved_model_cli.py    | 26 ++++++++++++++-----
 .../python/tools/saved_model_cli_test.py      | 11 +++++---
 3 files changed, 29 insertions(+), 10 deletions(-)

diff --git a/RELEASE.md b/RELEASE.md
index 23820977eca765..aba46a1fad9fc2 100644
--- a/RELEASE.md
+++ b/RELEASE.md
@@ -249,6 +249,8 @@
         endpoint.
 *   TF SavedModel:
     *   Custom gradients are now saved by default. See `tf.saved_model.SaveOptions` to disable this.
+    *   The saved_model_cli's `--input_examples` inputs are now restricted to
+        python literals to avoid code injection.
 *   XLA:
     * Added a new API that allows custom call functions to signal errors. The
       old API will be deprecated in a future release. See
diff --git a/tensorflow/python/tools/saved_model_cli.py b/tensorflow/python/tools/saved_model_cli.py
index 9c37cc40c50bfb..f8d7bbb1eece38 100644
--- a/tensorflow/python/tools/saved_model_cli.py
+++ b/tensorflow/python/tools/saved_model_cli.py
@@ -20,6 +20,7 @@
 """"""
 
 import argparse
+import ast
 import os
 import re
 import sys
@@ -521,7 +522,7 @@ def preprocess_inputs_arg_string(inputs_str):
   return input_dict
 
 
-def preprocess_input_exprs_arg_string(input_exprs_str):
+def preprocess_input_exprs_arg_string(input_exprs_str, safe=True):
   """"""Parses input arg into dictionary that maps input key to python expression.
 
   Parses input string in the format of 'input_key=<python expression>' into a
@@ -529,8 +530,10 @@ def preprocess_input_exprs_arg_string(input_exprs_str):
 
   Args:
     input_exprs_str: A string that specifies python expression for input keys.
-    Each input is separated by semicolon. For each input key:
+      Each input is separated by semicolon. For each input key:
         'input_key=<python expression>'
+    safe: Whether to evaluate the python expression as literals or allow
+      arbitrary calls (e.g. numpy usage).
 
   Returns:
     A dictionary that maps input keys to their values.
@@ -545,8 +548,15 @@ def preprocess_input_exprs_arg_string(input_exprs_str):
       raise RuntimeError('--input_exprs ""%s"" format is incorrect. Please follow'
                          '""<input_key>=<python expression>""' % input_exprs_str)
     input_key, expr = input_raw.split('=', 1)
-    # ast.literal_eval does not work with numpy expressions
-    input_dict[input_key] = eval(expr)  # pylint: disable=eval-used
+    if safe:
+      try:
+        input_dict[input_key] = ast.literal_eval(expr)
+      except:
+        raise RuntimeError(
+            f'Expression ""{expr}"" is not a valid python literal.')
+    else:
+      # ast.literal_eval does not work with numpy expressions
+      input_dict[input_key] = eval(expr)  # pylint: disable=eval-used
   return input_dict
 
 
@@ -659,7 +669,7 @@ def load_inputs_from_input_arg_string(inputs_str, input_exprs_str,
   tensor_key_feed_dict = {}
 
   inputs = preprocess_inputs_arg_string(inputs_str)
-  input_exprs = preprocess_input_exprs_arg_string(input_exprs_str)
+  input_exprs = preprocess_input_exprs_arg_string(input_exprs_str, safe=False)
   input_examples = preprocess_input_examples_arg_string(input_examples_str)
 
   for input_tensor_key, (filename, variable_name) in inputs.items():
@@ -923,8 +933,10 @@ def add_run_subparser(subparsers):
   parser_run.add_argument('--inputs', type=str, default='', help=msg)
   msg = ('Specifying inputs by python expressions, in the format of'
          ' ""<input_key>=\'<python expression>\'"", separated by \';\'. '
-         'numpy module is available as \'np\'. '
-         'Will override duplicate input keys from --inputs option.')
+         'numpy module is available as \'np\'. Please note that the expression '
+         'will be evaluated as-is, and is susceptible to code injection. '
+         'When this is set, the value will override duplicate input keys from '
+         '--inputs option.')
   parser_run.add_argument('--input_exprs', type=str, default='', help=msg)
   msg = (
       'Specifying tf.Example inputs as list of dictionaries. For example: '
diff --git a/tensorflow/python/tools/saved_model_cli_test.py b/tensorflow/python/tools/saved_model_cli_test.py
index 9a4cfcd4a02769..424f156b86b883 100644
--- a/tensorflow/python/tools/saved_model_cli_test.py
+++ b/tensorflow/python/tools/saved_model_cli_test.py
@@ -382,7 +382,7 @@ def testInputPreProcessFormats(self):
     input_expr_str = 'input3=np.zeros([2,2]);input4=[4,5]'
     input_dict = saved_model_cli.preprocess_inputs_arg_string(input_str)
     input_expr_dict = saved_model_cli.preprocess_input_exprs_arg_string(
-        input_expr_str)
+        input_expr_str, safe=False)
     self.assertTrue(input_dict['input1'] == ('/path/file.txt', 'ab3'))
     self.assertTrue(input_dict['input2'] == ('file2', None))
     print(input_expr_dict['input3'])
@@ -418,6 +418,11 @@ def testInputPreProcessExamplesWithStrAndBytes(self):
           }
     """""", feature)
 
+  def testInputPreprocessExampleWithCodeInjection(self):
+    input_examples_str = 'inputs=os.system(""echo hacked"")'
+    with self.assertRaisesRegex(RuntimeError, 'not a valid python literal.'):
+      saved_model_cli.preprocess_input_examples_arg_string(input_examples_str)
+
   def testInputPreProcessFileNames(self):
     input_str = (r'inputx=C:\Program Files\data.npz[v:0];'
                  r'input:0=c:\PROGRA~1\data.npy')
@@ -434,8 +439,8 @@ def testInputPreProcessErrorBadFormat(self):
     with self.assertRaises(RuntimeError):
       saved_model_cli.preprocess_inputs_arg_string(input_str)
     input_str = 'inputx:np.zeros((5))'
-    with self.assertRaises(RuntimeError):
-      saved_model_cli.preprocess_input_exprs_arg_string(input_str)
+    with self.assertRaisesRegex(RuntimeError, 'format is incorrect'):
+      saved_model_cli.preprocess_input_exprs_arg_string(input_str, safe=False)
 
   def testInputParserNPY(self):
     x0 = np.array([[1], [2]])"
PYSEC-2017-102,"From 059ba8dec1f22ccbeab837e288b3833a099cee2d Mon Sep 17 00:00:00 2001
From: Guillaume Ayoub <guillaume.ayoub@kozea.fr>
Date: Wed, 19 Apr 2017 13:48:30 +0200
Subject: [PATCH] Random timer to avoid timing oracles and simple bruteforce
 attacks

Important note: this is a security fix.
---
 radicale/auth.py | 8 ++++++--
 1 file changed, 6 insertions(+), 2 deletions(-)

diff --git a/radicale/auth.py b/radicale/auth.py
index 2fa2807ee..8ae493a7c 100644
--- a/radicale/auth.py
+++ b/radicale/auth.py
@@ -57,6 +57,8 @@
 import functools
 import hashlib
 import os
+import random
+import time
 from importlib import import_module
 
 
@@ -192,6 +194,8 @@ def is_authenticated(self, user, password):
                 line = line.strip()
                 if line:
                     login, hash_value = line.split("":"")
-                    if login == user:
-                        return self.verify(hash_value, password)
+                    if login == user and self.verify(hash_value, password):
+                        return True
+        # Random timer to avoid timing oracles and simple bruteforce attacks
+        time.sleep(1 + random.random())
         return False"
GHSA-6pc9-xqrg-wfqw,"From 65ab7d5caaaf2f95e61f9dd65441801c2ddee38b Mon Sep 17 00:00:00 2001
From: Batuhan Taskaya <isidentical@gmail.com>
Date: Tue, 1 Feb 2022 12:14:24 +0300
Subject: [PATCH] Implement new style cookies

---
 docs/README.md                                | 140 ++++++++++
 httpie/client.py                              |   6 +-
 httpie/config.py                              |  60 ++--
 httpie/manager/cli.py                         |  43 ++-
 httpie/manager/core.py                        |  11 +
 httpie/manager/tasks.py                       | 134 +++++++++
 httpie/sessions.py                            | 206 +++++++++++---
 httpie/utils.py                               |   5 +
 setup.py                                      |   1 +
 tests/conftest.py                             |   6 +-
 tests/fixtures/__init__.py                    |  24 ++
 .../session_data/new/cookies_dict.json        |  31 +++
 .../new/cookies_dict_dev_version.json         |  31 +++
 .../new/cookies_dict_with_extras.json         |  33 +++
 .../session_data/new/empty_cookies_dict.json  |  14 +
 .../session_data/new/empty_cookies_list.json  |  14 +
 .../session_data/old/cookies_dict.json        |  27 ++
 .../old/cookies_dict_dev_version.json         |  27 ++
 .../old/cookies_dict_with_extras.json         |  29 ++
 .../session_data/old/empty_cookies_dict.json  |  14 +
 .../session_data/old/empty_cookies_list.json  |  14 +
 tests/test_cookie_on_redirects.py             | 262 ++++++++++++++++++
 tests/test_httpie_cli.py                      | 125 +++++++++
 tests/test_plugins_cli.py                     |  43 ---
 tests/test_sessions.py                        | 186 ++++++++++++-
 tests/utils/__init__.py                       |  24 +-
 tests/utils/http_server.py                    |  13 +
 27 files changed, 1406 insertions(+), 117 deletions(-)
 create mode 100644 httpie/manager/tasks.py
 create mode 100644 tests/fixtures/session_data/new/cookies_dict.json
 create mode 100644 tests/fixtures/session_data/new/cookies_dict_dev_version.json
 create mode 100644 tests/fixtures/session_data/new/cookies_dict_with_extras.json
 create mode 100644 tests/fixtures/session_data/new/empty_cookies_dict.json
 create mode 100644 tests/fixtures/session_data/new/empty_cookies_list.json
 create mode 100644 tests/fixtures/session_data/old/cookies_dict.json
 create mode 100644 tests/fixtures/session_data/old/cookies_dict_dev_version.json
 create mode 100644 tests/fixtures/session_data/old/cookies_dict_with_extras.json
 create mode 100644 tests/fixtures/session_data/old/empty_cookies_dict.json
 create mode 100644 tests/fixtures/session_data/old/empty_cookies_list.json
 create mode 100644 tests/test_cookie_on_redirects.py
 create mode 100644 tests/test_httpie_cli.py

diff --git a/docs/README.md b/docs/README.md
index 00aff4b842..efd579a343 100644
--- a/docs/README.md
+++ b/docs/README.md
@@ -2157,6 +2157,85 @@ $ http --session-read-only=./ro-session.json pie.dev/headers Custom-Header:orig-
 $ http --session-read-only=./ro-session.json pie.dev/headers Custom-Header:new-value
 ```
 
+### Host-based Cookie Policy
+
+Cookies in stored HTTPie sessions have a `domain` field which is binding them to the
+specified hostname. For example, in the following session:
+
+```json
+{
+    ""cookies"": [
+        {
+            ""domain"": ""pie.dev"",
+            ""name"": ""secret_cookie"",
+            ""value"": ""value_1""
+        },
+        {
+            ""domain"": ""httpbin.org"",
+            ""name"": ""secret_cookie"",
+            ""value"": ""value_2""
+        }
+    ]
+}
+```
+
+we will send `Cookie:secret_cookie=value_1` only when you are making a request against `pie.dev` (it
+also includes the domains, like `api.pie.dev`), and `Cookie:secret_cookie=value_2` when you use `httpbin.org`.
+
+```bash
+$ http --session=./session.json pie.dev/cookies
+```
+
+```json
+{
+    ""cookies"": {
+        ""secret_cookie"": ""value_1""
+    }
+}
+```
+
+```bash
+$ http --session=./session.json httpbin.org/cookies
+```
+
+```json
+{
+    ""cookies"": {
+        ""secret_cookie"": ""value_2""
+    }
+}
+```
+
+If you want to make a cookie domain unbound, you can simply set the `domain`
+field to `null` by editing the session file directly:
+
+```json
+{
+    ""cookies"": [
+        {
+            ""domain"": null,
+            ""expires"": null,
+            ""name"": ""generic_cookie"",
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""generic_value""
+        }
+    ]
+}
+```
+
+```bash
+$ http --session=./session.json pie.dev/cookies
+```
+
+```json
+{
+    ""cookies"": {
+        ""generic_cookie"": ""generic_value""
+    }
+}
+```
+
 ### Cookie Storage Behavior
 
 **TL;DR:** Cookie storage priority: Server response > Command line request > Session file
@@ -2208,6 +2287,50 @@ Expired cookies are never stored.
 If a cookie in a session file expires, it will be removed before sending a new request.
 If the server expires an existing cookie, it will also be removed from the session file.
 
+### Upgrading Sessions
+
+In rare circumstances, HTTPie makes changes in it's session layout. For allowing a smoother transition of existing files
+from the old layout to the new layout we offer 2 interfaces:
+
+- `httpie cli sessions upgrade`
+- `httpie cli sessions upgrade-all`
+
+
+With `httpie cli sessions upgrade`, you can upgrade a single session with it's name (or it's path, if it is an
+[anonymous session](#anonymous-sessions)) and the hostname it belongs to. For example:
+
+([named session](#named-sessions))
+
+```bash
+$ httpie cli sessions upgrade pie.dev api_auth
+Refactored 'api_auth' (for 'pie.dev') to the version 3.1.0.
+```
+
+([anonymous session](#anonymous-sessions))
+
+```bash
+$ httpie cli sessions upgrade pie.dev ./session.json
+Refactored 'session' (for 'pie.dev') to the version 3.1.0.
+```
+
+If you want to upgrade every existing [named session](#named-sessions), you can use `httpie cli sessions upgrade-all` (be aware
+that this won't upgrade [anonymous sessions](#anonymous-sessions)):
+
+```bash
+$ httpie cli sessions upgrade-all
+Refactored 'api_auth' (for 'pie.dev') to the version 3.1.0.
+Refactored 'login_cookies' (for 'httpie.io') to the version 3.1.0.
+```
+
+#### Additional Customizations
+
+| Flag             | Description                                                                                                                                                                                                                  |
+|------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| `--bind-cookies` | Bind all the unbound cookies to the hostname that session belongs. By default, if the cookie is unbound (the `domain` attribute does not exist / set to an empty string) then it will still continue to be a generic cookie. |
+
+These flags can be used to customize the defaults during an `upgrade` operation. They can
+be used in both `sessions upgrade` and `sessions upgrade-all`.
+
 ## Config
 
 HTTPie uses a simple `config.json` file.
@@ -2299,6 +2422,23 @@ And since theres neither data nor `EOF`, it will get stuck. So unless your
 
 Also, it might be good to set a connection `--timeout` limit to prevent your program from hanging if the server never responds.
 
+### Security
+
+#### Exposure of Cookies To The 3rd Party Hosts On Redirects
+
+*Vulnerability Type*: [CWE-200](https://cwe.mitre.org/data/definitions/200.html)
+*Severity Level*: LOW
+*Affected Versions*: `<3.1.0`
+
+The handling of [cookies](#cookies) was not compatible with the [RFC 6265](https://datatracker.ietf.org/doc/html/rfc6265)
+on the point of handling the `Domain` attribute when they were saved into [session](#sessions) files. All cookies were shared
+across all hosts during the runtime, including redirects to the 3rd party hosts.
+
+This vulnerability has been fixed in [3.1.0](https://github.com/httpie/httpie/releases/tag/3.1.0) and the
+[`httpie cli sessions upgrade`](#upgrading-sessions)/[`httpie cli sessions upgrade-all`]((#upgrading-sessions) commands
+have been put in place in order to allow a smooth transition to the new session layout from the existing [session](#sessions)
+files.
+
 ## Plugin manager
 
 HTTPie offers extensibility through a [plugin API](https://github.com/httpie/httpie/blob/master/httpie/plugins/base.py),
diff --git a/httpie/client.py b/httpie/client.py
index 1984537c2b..530d589cae 100644
--- a/httpie/client.py
+++ b/httpie/client.py
@@ -44,6 +44,7 @@ def collect_messages(
     httpie_session_headers = None
     if args.session or args.session_read_only:
         httpie_session = get_httpie_session(
+            env=env,
             config_dir=env.config.directory,
             session_name=args.session or args.session_read_only,
             host=args.headers.get('Host'),
@@ -130,10 +131,7 @@ def collect_messages(
     if httpie_session:
         if httpie_session.is_new() or not args.session_read_only:
             httpie_session.cookies = requests_session.cookies
-            httpie_session.remove_cookies(
-                # TODO: take path & domain into account?
-                cookie['name'] for cookie in expired_cookies
-            )
+            httpie_session.remove_cookies(expired_cookies)
             httpie_session.save()
 
 
diff --git a/httpie/config.py b/httpie/config.py
index 28574e4ae7..f7fee5bdab 100644
--- a/httpie/config.py
+++ b/httpie/config.py
@@ -1,7 +1,7 @@
 import json
 import os
 from pathlib import Path
-from typing import Union
+from typing import Any, Dict, Union
 
 from . import __version__
 from .compat import is_windows
@@ -62,6 +62,21 @@ class ConfigFileError(Exception):
     pass
 
 
+def read_raw_config(config_type: str, path: Path) -> Dict[str, Any]:
+    try:
+        with path.open(encoding=UTF8) as f:
+            try:
+                return json.load(f)
+            except ValueError as e:
+                raise ConfigFileError(
+                    f'invalid {config_type} file: {e} [{path}]'
+                )
+    except FileNotFoundError:
+        pass
+    except OSError as e:
+        raise ConfigFileError(f'cannot read {config_type} file: {e}')
+
+
 class BaseConfigDict(dict):
     name = None
     helpurl = None
@@ -77,26 +92,25 @@ def ensure_directory(self):
     def is_new(self) -> bool:
         return not self.path.exists()
 
+    def pre_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
+        """"""Hook for processing the incoming config data.""""""
+        return data
+
+    def post_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
+        """"""Hook for processing the outgoing config data.""""""
+        return data
+
     def load(self):
         config_type = type(self).__name__.lower()
-        try:
-            with self.path.open(encoding=UTF8) as f:
-                try:
-                    data = json.load(f)
-                except ValueError as e:
-                    raise ConfigFileError(
-                        f'invalid {config_type} file: {e} [{self.path}]'
-                    )
-                self.update(data)
-        except FileNotFoundError:
-            pass
-        except OSError as e:
-            raise ConfigFileError(f'cannot read {config_type} file: {e}')
-
-    def save(self):
-        self['__meta__'] = {
-            'httpie': __version__
-        }
+        data = read_raw_config(config_type, self.path)
+        if data is not None:
+            data = self.pre_process_data(data)
+            self.update(data)
+
+    def save(self, *, bump_version: bool = False):
+        self.setdefault('__meta__', {})
+        if bump_version or 'httpie' not in self['__meta__']:
+            self['__meta__']['httpie'] = __version__
         if self.helpurl:
             self['__meta__']['help'] = self.helpurl
 
@@ -106,13 +120,19 @@ def save(self):
         self.ensure_directory()
 
         json_string = json.dumps(
-            obj=self,
+            obj=self.post_process_data(self),
             indent=4,
             sort_keys=True,
             ensure_ascii=True,
         )
         self.path.write_text(json_string + '\n', encoding=UTF8)
 
+    @property
+    def version(self):
+        return self.get(
+            '__meta__', {}
+        ).get('httpie', __version__)
+
 
 class Config(BaseConfigDict):
     FILENAME = 'config.json'
diff --git a/httpie/manager/cli.py b/httpie/manager/cli.py
index 11c63d0a31..9ad4eca6ba 100644
--- a/httpie/manager/cli.py
+++ b/httpie/manager/cli.py
@@ -2,6 +2,15 @@
 from httpie.cli.argparser import HTTPieManagerArgumentParser
 from httpie import __version__
 
+CLI_SESSION_UPGRADE_FLAGS = [
+    {
+        'variadic': ['--bind-cookies'],
+        'action': 'store_true',
+        'default': False,
+        'help': 'Bind domainless cookies to the host that session belongs.'
+    }
+]
+
 COMMANDS = {
     'plugins': {
         'help': 'Manage HTTPie plugins.',
@@ -34,6 +43,34 @@
             'List all installed HTTPie plugins.'
         ],
     },
+    'cli': {
+        'help': 'Manage HTTPie for Terminal',
+        'sessions': {
+            'help': 'Manage HTTPie sessions',
+            'upgrade': [
+                'Upgrade the given HTTPie session with the latest '
+                'layout. A list of changes between different session versions '
+                'can be found in the official documentation.',
+                {
+                    'dest': 'hostname',
+                    'metavar': 'HOSTNAME',
+                    'help': 'The host this session belongs.'
+                },
+                {
+                    'dest': 'session',
+                    'metavar': 'SESSION_NAME_OR_PATH',
+                    'help': 'The name or the path for the session that will be upgraded.'
+                },
+                *CLI_SESSION_UPGRADE_FLAGS
+            ],
+            'upgrade-all': [
+                'Upgrade all named sessions with the latest layout. A list of '
+                'changes between different session versions can be found in the official '
+                'documentation.',
+                *CLI_SESSION_UPGRADE_FLAGS
+            ],
+        }
+    }
 }
 
 
@@ -54,6 +91,8 @@ def generate_subparsers(root, parent_parser, definitions):
     )
     for command, properties in definitions.items():
         is_subparser = isinstance(properties, dict)
+        properties = properties.copy()
+
         descr = properties.pop('help', None) if is_subparser else properties.pop(0)
         command_parser = actions.add_parser(command, description=descr)
         command_parser.root = root
@@ -62,7 +101,9 @@ def generate_subparsers(root, parent_parser, definitions):
             continue
 
         for argument in properties:
-            command_parser.add_argument(**argument)
+            argument = argument.copy()
+            variadic = argument.pop('variadic', [])
+            command_parser.add_argument(*variadic, **argument)
 
 
 parser = HTTPieManagerArgumentParser(
diff --git a/httpie/manager/core.py b/httpie/manager/core.py
index e2134b5527..1289fef1a4 100644
--- a/httpie/manager/core.py
+++ b/httpie/manager/core.py
@@ -1,9 +1,11 @@
 import argparse
+from typing import Optional
 
 from httpie.context import Environment
 from httpie.manager.plugins import PluginInstaller
 from httpie.status import ExitStatus
 from httpie.manager.cli import missing_subcommand, parser
+from httpie.manager.tasks import CLI_TASKS
 
 MSG_COMMAND_CONFUSION = '''\
 This command is only for managing HTTPie plugins.
@@ -22,6 +24,13 @@
 '''.rstrip(""\n"").format(args='POST pie.dev/post hello=world')
 
 
+def dispatch_cli_task(env: Environment, action: Optional[str], args: argparse.Namespace) -> ExitStatus:
+    if action is None:
+        parser.error(missing_subcommand('cli'))
+
+    return CLI_TASKS[action](env, args)
+
+
 def program(args: argparse.Namespace, env: Environment) -> ExitStatus:
     if args.action is None:
         parser.error(MSG_NAKED_INVOCATION)
@@ -29,5 +38,7 @@ def program(args: argparse.Namespace, env: Environment) -> ExitStatus:
     if args.action == 'plugins':
         plugins = PluginInstaller(env, debug=args.debug)
         return plugins.run(args.plugins_action, args)
+    elif args.action == 'cli':
+        return dispatch_cli_task(env, args.cli_action, args)
 
     return ExitStatus.SUCCESS
diff --git a/httpie/manager/tasks.py b/httpie/manager/tasks.py
new file mode 100644
index 0000000000..c04ed9bc3d
--- /dev/null
+++ b/httpie/manager/tasks.py
@@ -0,0 +1,134 @@
+import argparse
+from typing import TypeVar, Callable, Tuple
+
+from httpie.sessions import SESSIONS_DIR_NAME, Session, get_httpie_session
+from httpie.status import ExitStatus
+from httpie.context import Environment
+from httpie.manager.cli import missing_subcommand, parser
+
+T = TypeVar('T')
+
+CLI_TASKS = {}
+
+
+def task(name: str) -> Callable[[T], T]:
+    def wrapper(func: T) -> T:
+        CLI_TASKS[name] = func
+        return func
+    return wrapper
+
+
+@task('sessions')
+def cli_sessions(env: Environment, args: argparse.Namespace) -> ExitStatus:
+    action = args.cli_sessions_action
+    if action is None:
+        parser.error(missing_subcommand('cli', 'sessions'))
+
+    if action == 'upgrade':
+        return cli_upgrade_session(env, args)
+    elif action == 'upgrade-all':
+        return cli_upgrade_all_sessions(env, args)
+    else:
+        raise ValueError(f'Unexpected action: {action}')
+
+
+def is_version_greater(version_1: str, version_2: str) -> bool:
+    # In an ideal scenerio, we would depend on `packaging` in order
+    # to offer PEP 440 compatible parsing. But since it might not be
+    # commonly available for outside packages, and since we are only
+    # going to parse HTTPie's own version it should be fine to compare
+    # this in a SemVer subset fashion.
+
+    def split_version(version: str) -> Tuple[int, ...]:
+        parts = []
+        for part in version.split('.')[:3]:
+            try:
+                parts.append(int(part))
+            except ValueError:
+                break
+        return tuple(parts)
+
+    return split_version(version_1) > split_version(version_2)
+
+
+def fix_cookie_layout(session: Session, hostname: str, args: argparse.Namespace) -> None:
+    if not isinstance(session['cookies'], dict):
+        return None
+
+    session['cookies'] = [
+        {
+            'name': key,
+            **value
+        }
+        for key, value in session['cookies'].items()
+    ]
+    for cookie in session.cookies:
+        if cookie.domain == '':
+            if args.bind_cookies:
+                cookie.domain = hostname
+            else:
+                cookie._rest['is_explicit_none'] = True
+
+
+FIXERS_TO_VERSIONS = {
+    '3.1.0': fix_cookie_layout
+}
+
+
+def upgrade_session(env: Environment, args: argparse.Namespace, hostname: str, session_name: str):
+    session = get_httpie_session(
+        env=env,
+        config_dir=env.config.directory,
+        session_name=session_name,
+        host=hostname,
+        url=hostname,
+        refactor_mode=True
+    )
+
+    session_name = session.path.stem
+    if session.is_new():
+        env.log_error(f'{session_name!r} (for {hostname!r}) does not exist.')
+        return ExitStatus.ERROR
+
+    fixers = [
+        fixer
+        for version, fixer in FIXERS_TO_VERSIONS.items()
+        if is_version_greater(version, session.version)
+    ]
+
+    if len(fixers) == 0:
+        env.stdout.write(f'{session_name!r} (for {hostname!r}) is already up-to-date.\n')
+        return ExitStatus.SUCCESS
+
+    for fixer in fixers:
+        fixer(session, hostname, args)
+
+    session.save(bump_version=True)
+    env.stdout.write(f'Refactored {session_name!r} (for {hostname!r}) to the version {session.version}.\n')
+    return ExitStatus.SUCCESS
+
+
+def cli_upgrade_session(env: Environment, args: argparse.Namespace) -> ExitStatus:
+    return upgrade_session(
+        env,
+        args=args,
+        hostname=args.hostname,
+        session_name=args.session
+    )
+
+
+def cli_upgrade_all_sessions(env: Environment, args: argparse.Namespace) -> ExitStatus:
+    session_dir_path = env.config_dir / SESSIONS_DIR_NAME
+
+    status = ExitStatus.SUCCESS
+    for host_path in session_dir_path.iterdir():
+        hostname = host_path.name
+        for session_path in host_path.glob(""*.json""):
+            session_name = session_path.stem
+            status |= upgrade_session(
+                env,
+                args=args,
+                hostname=hostname,
+                session_name=session_name
+            )
+    return status
diff --git a/httpie/sessions.py b/httpie/sessions.py
index 176c03e76d..c23cb56852 100644
--- a/httpie/sessions.py
+++ b/httpie/sessions.py
@@ -6,15 +6,17 @@
 import re
 
 from http.cookies import SimpleCookie
+from http.cookiejar import Cookie
 from pathlib import Path
-from typing import Iterable, Optional, Union
-from urllib.parse import urlsplit
+from typing import Any, Dict, Optional, Union
 
 from requests.auth import AuthBase
-from requests.cookies import RequestsCookieJar, create_cookie
+from requests.cookies import RequestsCookieJar, remove_cookie_by_name
 
+from .context import Environment
 from .cli.dicts import HTTPHeadersDict
 from .config import BaseConfigDict, DEFAULT_CONFIG_DIR
+from .utils import url_as_host
 from .plugins.registry import plugin_manager
 
 
@@ -26,27 +28,88 @@
 # <https://en.wikipedia.org/wiki/List_of_HTTP_header_fields#Requests>
 SESSION_IGNORED_HEADER_PREFIXES = ['Content-', 'If-']
 
+# Cookie related options
+KEPT_COOKIE_OPTIONS = ['name', 'expires', 'path', 'value', 'domain', 'secure']
+DEFAULT_COOKIE_PATH = '/'
+
+INSECURE_COOKIE_JAR_WARNING = '''\
+Outdated layout detected for the current session. Please consider updating it,
+in order to not get affected by potential security problems.
+
+For fixing the current session:
+
+    With binding all cookies to the current host (secure):
+        $ httpie cli sessions upgrade --bind-cookies {hostname} {session_id}
+
+    Without binding cookies (leaving them as is) (insecure):
+        $ httpie cli sessions upgrade {hostname} {session_id}
+'''
+
+INSECURE_COOKIE_JAR_WARNING_FOR_NAMED_SESSIONS = '''\
+
+For fixing all named sessions:
+
+    With binding all cookies to the current host (secure):
+        $ httpie cli sessions upgrade-all --bind-cookies
+
+    Without binding cookies (leaving them as is) (insecure):
+        $ httpie cli sessions upgrade-all
+
+See https://pie.co/docs/security for more information.
+'''
+
+
+def is_anonymous_session(session_name: str) -> bool:
+    return os.path.sep in session_name
+
+
+def materialize_cookie(cookie: Cookie) -> Dict[str, Any]:
+    materialized_cookie = {
+        option: getattr(cookie, option)
+        for option in KEPT_COOKIE_OPTIONS
+    }
+
+    if (
+        cookie._rest.get('is_explicit_none')
+        and materialized_cookie['domain'] == ''
+    ):
+        materialized_cookie['domain'] = None
+
+    return materialized_cookie
+
 
 def get_httpie_session(
+    env: Environment,
     config_dir: Path,
     session_name: str,
     host: Optional[str],
     url: str,
+    *,
+    refactor_mode: bool = False
 ) -> 'Session':
-    if os.path.sep in session_name:
+    bound_hostname = host or url_as_host(url)
+    if not bound_hostname:
+        # HACK/FIXME: httpie-unixsocket's URLs have no hostname.
+        bound_hostname = 'localhost'
+
+    # host:port => host_port
+    hostname = bound_hostname.replace(':', '_')
+    if is_anonymous_session(session_name):
         path = os.path.expanduser(session_name)
+        session_id = path
     else:
-        hostname = host or urlsplit(url).netloc.split('@')[-1]
-        if not hostname:
-            # HACK/FIXME: httpie-unixsocket's URLs have no hostname.
-            hostname = 'localhost'
-
-        # host:port => host_port
-        hostname = hostname.replace(':', '_')
         path = (
             config_dir / SESSIONS_DIR_NAME / hostname / f'{session_name}.json'
         )
-    session = Session(path)
+        session_id = session_name
+
+    session = Session(
+        path,
+        env=env,
+        session_id=session_id,
+        bound_host=bound_hostname.split(':')[0],
+        refactor_mode=refactor_mode
+    )
     session.load()
     return session
 
@@ -55,15 +118,86 @@ class Session(BaseConfigDict):
     helpurl = 'https://httpie.io/docs#sessions'
     about = 'HTTPie session file'
 
-    def __init__(self, path: Union[str, Path]):
+    def __init__(
+        self,
+        path: Union[str, Path],
+        env: Environment,
+        bound_host: str,
+        session_id: str,
+        refactor_mode: bool = False,
+    ):
         super().__init__(path=Path(path))
         self['headers'] = {}
-        self['cookies'] = {}
+        self['cookies'] = []
         self['auth'] = {
             'type': None,
             'username': None,
             'password': None
         }
+        self.env = env
+        self.cookie_jar = RequestsCookieJar()
+        self.session_id = session_id
+        self.bound_host = bound_host
+        self.refactor_mode = refactor_mode
+
+    def pre_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
+        cookies = data.get('cookies')
+        if isinstance(cookies, dict):
+            normalized_cookies = [
+                {
+                    'name': key,
+                    **value
+                }
+                for key, value in cookies.items()
+            ]
+        elif isinstance(cookies, list):
+            normalized_cookies = cookies
+        else:
+            normalized_cookies = []
+
+        should_issue_warning = False
+        for cookie in normalized_cookies:
+            domain = cookie.get('domain', '')
+            if domain == '' and isinstance(cookies, dict):
+                should_issue_warning = True
+            elif domain is None:
+                # domain = None means explicitly lack of cookie, though
+                # requests requires domain to be string so we'll cast it
+                # manually.
+                cookie['domain'] = ''
+                cookie['rest'] = {'is_explicit_none': True}
+
+            self.cookie_jar.set(**cookie)
+
+        if should_issue_warning and not self.refactor_mode:
+            warning = INSECURE_COOKIE_JAR_WARNING.format(hostname=self.bound_host, session_id=self.session_id)
+            if not is_anonymous_session(self.session_id):
+                warning += INSECURE_COOKIE_JAR_WARNING_FOR_NAMED_SESSIONS
+
+            self.env.log_error(
+                warning,
+                level='warning'
+            )
+
+        return data
+
+    def post_process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
+        cookies = data.get('cookies')
+        # Save in the old-style fashion
+
+        normalized_cookies = [
+            materialize_cookie(cookie)
+            for cookie in self.cookie_jar
+        ]
+        if isinstance(cookies, dict):
+            data['cookies'] = {
+                cookie.pop('name'): cookie
+                for cookie in normalized_cookies
+            }
+        else:
+            data['cookies'] = normalized_cookies
+
+        return data
 
     def update_headers(self, request_headers: HTTPHeadersDict):
         """"""
@@ -73,10 +207,10 @@ def update_headers(self, request_headers: HTTPHeadersDict):
         """"""
         headers = self.headers
         for name, value in request_headers.copy().items():
-
             if value is None:
                 continue  # Ignore explicitly unset headers
 
+            original_value = value
             if type(value) is not str:
                 value = value.decode()
 
@@ -85,8 +219,15 @@ def update_headers(self, request_headers: HTTPHeadersDict):
 
             if name.lower() == 'cookie':
                 for cookie_name, morsel in SimpleCookie(value).items():
-                    self['cookies'][cookie_name] = {'value': morsel.value}
-                del request_headers[name]
+                    if not morsel['path']:
+                        morsel['path'] = DEFAULT_COOKIE_PATH
+                    self.cookie_jar.set(cookie_name, morsel)
+
+                all_cookie_headers = request_headers.getall(name)
+                if len(all_cookie_headers) > 1:
+                    all_cookie_headers.remove(original_value)
+                else:
+                    request_headers.popall(name)
                 continue
 
             for prefix in SESSION_IGNORED_HEADER_PREFIXES:
@@ -103,23 +244,21 @@ def headers(self) -> HTTPHeadersDict:
 
     @property
     def cookies(self) -> RequestsCookieJar:
-        jar = RequestsCookieJar()
-        for name, cookie_dict in self['cookies'].items():
-            jar.set_cookie(create_cookie(
-                name, cookie_dict.pop('value'), **cookie_dict))
-        jar.clear_expired_cookies()
-        return jar
+        self.cookie_jar.clear_expired_cookies()
+        return self.cookie_jar
 
     @cookies.setter
     def cookies(self, jar: RequestsCookieJar):
-        # <https://docs.python.org/3/library/cookielib.html#cookie-objects>
-        stored_attrs = ['value', 'path', 'secure', 'expires']
-        self['cookies'] = {}
-        for cookie in jar:
-            self['cookies'][cookie.name] = {
-                attname: getattr(cookie, attname)
-                for attname in stored_attrs
-            }
+        self.cookie_jar = jar
+
+    def remove_cookies(self, cookies: Dict[str, str]):
+        for cookie in cookies:
+            remove_cookie_by_name(
+                self.cookie_jar,
+                cookie['name'],
+                domain=cookie.get('domain', None),
+                path=cookie.get('path', None)
+            )
 
     @property
     def auth(self) -> Optional[AuthBase]:
@@ -154,8 +293,3 @@ def auth(self) -> Optional[AuthBase]:
     def auth(self, auth: dict):
         assert {'type', 'raw_auth'} == auth.keys()
         self['auth'] = auth
-
-    def remove_cookies(self, names: Iterable[str]):
-        for name in names:
-            if name in self['cookies']:
-                del self['cookies'][name]
diff --git a/httpie/utils.py b/httpie/utils.py
index fa19fa7cde..4fffb2826e 100644
--- a/httpie/utils.py
+++ b/httpie/utils.py
@@ -9,6 +9,7 @@
 from http.cookiejar import parse_ns_headers
 from pathlib import Path
 from pprint import pformat
+from urllib.parse import urlsplit
 from typing import Any, List, Optional, Tuple, Callable, Iterable, TypeVar
 
 import requests.auth
@@ -237,3 +238,7 @@ def unwrap_context(exc: Exception) -> Optional[Exception]:
         return unwrap_context(context)
     else:
         return exc
+
+
+def url_as_host(url: str) -> str:
+    return urlsplit(url).netloc.split('@')[-1]
diff --git a/setup.py b/setup.py
index 5316ff73d3..8f9a93140f 100644
--- a/setup.py
+++ b/setup.py
@@ -11,6 +11,7 @@
 tests_require = [
     'pytest',
     'pytest-httpbin>=0.0.6',
+    'pytest-lazy-fixture>=0.0.6',
     'responses',
 ]
 dev_require = [
diff --git a/tests/conftest.py b/tests/conftest.py
index 5e8c511072..7ca0e60440 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -4,7 +4,11 @@
 import pytest
 from pytest_httpbin import certs
 
-from .utils import HTTPBIN_WITH_CHUNKED_SUPPORT_DOMAIN, HTTPBIN_WITH_CHUNKED_SUPPORT
+from .utils import ( # noqa
+    HTTPBIN_WITH_CHUNKED_SUPPORT_DOMAIN,
+    HTTPBIN_WITH_CHUNKED_SUPPORT,
+    mock_env
+)
 from .utils.plugins_cli import ( # noqa
     broken_plugin,
     dummy_plugin,
diff --git a/tests/fixtures/__init__.py b/tests/fixtures/__init__.py
index 126b13276e..6e6e73676e 100644
--- a/tests/fixtures/__init__.py
+++ b/tests/fixtures/__init__.py
@@ -1,6 +1,9 @@
 """"""Test data""""""
+import json
 from pathlib import Path
+from typing import Optional, Dict, Any
 
+import httpie
 from httpie.encoding import UTF8
 from httpie.output.formatters.xml import pretty_xml, parse_xml
 
@@ -19,10 +22,20 @@ def patharg(path):
 JSON_FILE_PATH = FIXTURES_ROOT / 'test.json'
 JSON_WITH_DUPE_KEYS_FILE_PATH = FIXTURES_ROOT / 'test_with_dupe_keys.json'
 BIN_FILE_PATH = FIXTURES_ROOT / 'test.bin'
+
 XML_FILES_PATH = FIXTURES_ROOT / 'xmldata'
 XML_FILES_VALID = list((XML_FILES_PATH / 'valid').glob('*_raw.xml'))
 XML_FILES_INVALID = list((XML_FILES_PATH / 'invalid').glob('*.xml'))
 
+SESSION_FILES_PATH = FIXTURES_ROOT / 'session_data'
+SESSION_FILES_OLD = sorted((SESSION_FILES_PATH / 'old').glob('*.json'))
+SESSION_FILES_NEW = sorted((SESSION_FILES_PATH / 'new').glob('*.json'))
+
+SESSION_VARIABLES = {
+    '__version__': httpie.__version__,
+    '__host__': 'null',
+}
+
 FILE_PATH_ARG = patharg(FILE_PATH)
 BIN_FILE_PATH_ARG = patharg(BIN_FILE_PATH)
 JSON_FILE_PATH_ARG = patharg(JSON_FILE_PATH)
@@ -40,3 +53,14 @@ def patharg(path):
 UNICODE = FILE_CONTENT
 XML_DATA_RAW = '<?xml version=""1.0"" encoding=""utf-8""?><root><e>text</e></root>'
 XML_DATA_FORMATTED = pretty_xml(parse_xml(XML_DATA_RAW))
+
+
+def read_session_file(session_file: Path, *, extra_variables: Optional[Dict[str, str]] = None) -> Any:
+    with open(session_file) as stream:
+        data = stream.read()
+
+    session_vars = {**SESSION_VARIABLES, **(extra_variables or {})}
+    for variable, value in session_vars.items():
+        data = data.replace(variable, value)
+
+    return json.loads(data)
diff --git a/tests/fixtures/session_data/new/cookies_dict.json b/tests/fixtures/session_data/new/cookies_dict.json
new file mode 100644
index 0000000000..8a4d5f2e13
--- /dev/null
+++ b/tests/fixtures/session_data/new/cookies_dict.json
@@ -0,0 +1,31 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""__version__""
+    },
+    ""auth"": {
+        ""password"": null,
+        ""type"": null,
+        ""username"": null
+    },
+    ""cookies"": [
+        {
+            ""domain"": __host__,
+            ""expires"": null,
+            ""name"": ""baz"",
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""quux""
+        },
+        {
+            ""domain"": __host__,
+            ""expires"": null,
+            ""name"": ""foo"",
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""bar""
+        }
+    ],
+    ""headers"": {}
+}
diff --git a/tests/fixtures/session_data/new/cookies_dict_dev_version.json b/tests/fixtures/session_data/new/cookies_dict_dev_version.json
new file mode 100644
index 0000000000..8a4d5f2e13
--- /dev/null
+++ b/tests/fixtures/session_data/new/cookies_dict_dev_version.json
@@ -0,0 +1,31 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""__version__""
+    },
+    ""auth"": {
+        ""password"": null,
+        ""type"": null,
+        ""username"": null
+    },
+    ""cookies"": [
+        {
+            ""domain"": __host__,
+            ""expires"": null,
+            ""name"": ""baz"",
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""quux""
+        },
+        {
+            ""domain"": __host__,
+            ""expires"": null,
+            ""name"": ""foo"",
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""bar""
+        }
+    ],
+    ""headers"": {}
+}
diff --git a/tests/fixtures/session_data/new/cookies_dict_with_extras.json b/tests/fixtures/session_data/new/cookies_dict_with_extras.json
new file mode 100644
index 0000000000..9a99f15268
--- /dev/null
+++ b/tests/fixtures/session_data/new/cookies_dict_with_extras.json
@@ -0,0 +1,33 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""__version__""
+    },
+    ""auth"": {
+        ""raw_auth"": ""foo:bar"",
+        ""type"": ""basic""
+    },
+    ""cookies"": [
+        {
+            ""domain"": __host__,
+            ""expires"": null,
+            ""name"": ""baz"",
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""quux""
+        },
+        {
+            ""domain"": __host__,
+            ""expires"": null,
+            ""name"": ""foo"",
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""bar""
+        }
+    ],
+    ""headers"": {
+        ""X-Data"": ""value"",
+        ""X-Foo"": ""bar""
+    }
+}
diff --git a/tests/fixtures/session_data/new/empty_cookies_dict.json b/tests/fixtures/session_data/new/empty_cookies_dict.json
new file mode 100644
index 0000000000..1d01661a06
--- /dev/null
+++ b/tests/fixtures/session_data/new/empty_cookies_dict.json
@@ -0,0 +1,14 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""__version__""
+    },
+    ""auth"": {
+        ""password"": null,
+        ""type"": null,
+        ""username"": null
+    },
+    ""cookies"": [],
+    ""headers"": {}
+}
diff --git a/tests/fixtures/session_data/new/empty_cookies_list.json b/tests/fixtures/session_data/new/empty_cookies_list.json
new file mode 100644
index 0000000000..1d01661a06
--- /dev/null
+++ b/tests/fixtures/session_data/new/empty_cookies_list.json
@@ -0,0 +1,14 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""__version__""
+    },
+    ""auth"": {
+        ""password"": null,
+        ""type"": null,
+        ""username"": null
+    },
+    ""cookies"": [],
+    ""headers"": {}
+}
diff --git a/tests/fixtures/session_data/old/cookies_dict.json b/tests/fixtures/session_data/old/cookies_dict.json
new file mode 100644
index 0000000000..9c4fd21476
--- /dev/null
+++ b/tests/fixtures/session_data/old/cookies_dict.json
@@ -0,0 +1,27 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""3.0.2""
+    },
+    ""auth"": {
+        ""password"": null,
+        ""type"": null,
+        ""username"": null
+    },
+    ""cookies"": {
+        ""baz"": {
+            ""expires"": null,
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""quux""
+        },
+        ""foo"": {
+            ""expires"": null,
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""bar""
+        }
+    },
+    ""headers"": {}
+}
diff --git a/tests/fixtures/session_data/old/cookies_dict_dev_version.json b/tests/fixtures/session_data/old/cookies_dict_dev_version.json
new file mode 100644
index 0000000000..935b43f083
--- /dev/null
+++ b/tests/fixtures/session_data/old/cookies_dict_dev_version.json
@@ -0,0 +1,27 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""2.7.0.dev0""
+    },
+    ""auth"": {
+        ""password"": null,
+        ""type"": null,
+        ""username"": null
+    },
+    ""cookies"": {
+        ""baz"": {
+            ""expires"": null,
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""quux""
+        },
+        ""foo"": {
+            ""expires"": null,
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""bar""
+        }
+    },
+    ""headers"": {}
+}
diff --git a/tests/fixtures/session_data/old/cookies_dict_with_extras.json b/tests/fixtures/session_data/old/cookies_dict_with_extras.json
new file mode 100644
index 0000000000..42968e52a9
--- /dev/null
+++ b/tests/fixtures/session_data/old/cookies_dict_with_extras.json
@@ -0,0 +1,29 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""3.0.2""
+    },
+    ""auth"": {
+        ""raw_auth"": ""foo:bar"",
+        ""type"": ""basic""
+    },
+    ""cookies"": {
+        ""baz"": {
+            ""expires"": null,
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""quux""
+        },
+        ""foo"": {
+            ""expires"": null,
+            ""path"": ""/"",
+            ""secure"": false,
+            ""value"": ""bar""
+        }
+    },
+    ""headers"": {
+        ""X-Data"": ""value"",
+        ""X-Foo"": ""bar""
+    }
+}
diff --git a/tests/fixtures/session_data/old/empty_cookies_dict.json b/tests/fixtures/session_data/old/empty_cookies_dict.json
new file mode 100644
index 0000000000..8de1a9217c
--- /dev/null
+++ b/tests/fixtures/session_data/old/empty_cookies_dict.json
@@ -0,0 +1,14 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""3.0.2""
+    },
+    ""auth"": {
+        ""password"": null,
+        ""type"": null,
+        ""username"": null
+    },
+    ""cookies"": {},
+    ""headers"": {}
+}
diff --git a/tests/fixtures/session_data/old/empty_cookies_list.json b/tests/fixtures/session_data/old/empty_cookies_list.json
new file mode 100644
index 0000000000..12194f7ed2
--- /dev/null
+++ b/tests/fixtures/session_data/old/empty_cookies_list.json
@@ -0,0 +1,14 @@
+{
+    ""__meta__"": {
+        ""about"": ""HTTPie session file"",
+        ""help"": ""https://httpie.io/docs#sessions"",
+        ""httpie"": ""3.0.2""
+    },
+    ""auth"": {
+        ""password"": null,
+        ""type"": null,
+        ""username"": null
+    },
+    ""cookies"": [],
+    ""headers"": {}
+}
diff --git a/tests/test_cookie_on_redirects.py b/tests/test_cookie_on_redirects.py
new file mode 100644
index 0000000000..e22f833048
--- /dev/null
+++ b/tests/test_cookie_on_redirects.py
@@ -0,0 +1,262 @@
+import pytest
+from .utils import http
+
+
+@pytest.fixture
+def remote_httpbin(httpbin_with_chunked_support):
+    return httpbin_with_chunked_support
+
+
+def _stringify(fixture):
+    return fixture + ''
+
+
+@pytest.mark.parametrize('instance', [
+    pytest.lazy_fixture('httpbin'),
+    pytest.lazy_fixture('remote_httpbin'),
+])
+def test_explicit_user_set_cookie(httpbin, instance):
+    # User set cookies ARE NOT persisted within redirects
+    # when there is no session, even on the same domain.
+
+    r = http(
+        '--follow',
+        httpbin + '/redirect-to',
+        f'url=={_stringify(instance)}/cookies',
+        'Cookie:a=b'
+    )
+    assert r.json == {'cookies': {}}
+
+
+@pytest.mark.parametrize('instance', [
+    pytest.lazy_fixture('httpbin'),
+    pytest.lazy_fixture('remote_httpbin'),
+])
+def test_explicit_user_set_cookie_in_session(tmp_path, httpbin, instance):
+    # User set cookies ARE persisted within redirects
+    # when there is A session, even on the same domain.
+
+    r = http(
+        '--follow',
+        '--session',
+        str(tmp_path / 'session.json'),
+        httpbin + '/redirect-to',
+        f'url=={_stringify(instance)}/cookies',
+        'Cookie:a=b'
+    )
+    assert r.json == {'cookies': {'a': 'b'}}
+
+
+@pytest.mark.parametrize('instance', [
+    pytest.lazy_fixture('httpbin'),
+    pytest.lazy_fixture('remote_httpbin'),
+])
+def test_saved_user_set_cookie_in_session(tmp_path, httpbin, instance):
+    # User set cookies ARE persisted within redirects
+    # when there is A session, even on the same domain.
+
+    http(
+        '--follow',
+        '--session',
+        str(tmp_path / 'session.json'),
+        httpbin + '/get',
+        'Cookie:a=b'
+    )
+    r = http(
+        '--follow',
+        '--session',
+        str(tmp_path / 'session.json'),
+        httpbin + '/redirect-to',
+        f'url=={_stringify(instance)}/cookies',
+    )
+    assert r.json == {'cookies': {'a': 'b'}}
+
+
+@pytest.mark.parametrize('instance', [
+    pytest.lazy_fixture('httpbin'),
+    pytest.lazy_fixture('remote_httpbin'),
+])
+@pytest.mark.parametrize('session', [True, False])
+def test_explicit_user_set_headers(httpbin, tmp_path, instance, session):
+    # User set headers ARE persisted within redirects
+    # even on different domains domain with or without
+    # an active session.
+    session_args = []
+    if session:
+        session_args.extend([
+            '--session',
+            str(tmp_path / 'session.json')
+        ])
+
+    r = http(
+        '--follow',
+        *session_args,
+        httpbin + '/redirect-to',
+        f'url=={_stringify(instance)}/get',
+        'X-Custom-Header:value'
+    )
+    assert 'X-Custom-Header' in r.json['headers']
+
+
+@pytest.mark.parametrize('session', [True, False])
+def test_server_set_cookie_on_redirect_same_domain(tmp_path, httpbin, session):
+    # Server set cookies ARE persisted on the same domain
+    # when they are forwarded.
+
+    session_args = []
+    if session:
+        session_args.extend([
+            '--session',
+            str(tmp_path / 'session.json')
+        ])
+
+    r = http(
+        '--follow',
+        *session_args,
+        httpbin + '/cookies/set/a/b',
+    )
+    assert r.json['cookies'] == {'a': 'b'}
+
+
+@pytest.mark.parametrize('session', [True, False])
+def test_server_set_cookie_on_redirect_different_domain(tmp_path, http_server, httpbin, session):
+    # Server set cookies ARE persisted on different domains
+    # when they are forwarded.
+
+    session_args = []
+    if session:
+        session_args.extend([
+            '--session',
+            str(tmp_path / 'session.json')
+        ])
+
+    r = http(
+        '--follow',
+        *session_args,
+        http_server + '/cookies/set-and-redirect',
+        f""X-Redirect-To:{httpbin + '/cookies'}"",
+        'X-Cookies:a=b'
+    )
+    assert r.json['cookies'] == {'a': 'b'}
+
+
+def test_saved_session_cookies_on_same_domain(tmp_path, httpbin):
+    # Saved session cookies ARE persisted when making a new
+    # request to the same domain.
+    http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        httpbin + '/cookies/set/a/b'
+    )
+    r = http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        httpbin + '/cookies'
+    )
+    assert r.json == {'cookies': {'a': 'b'}}
+
+
+def test_saved_session_cookies_on_different_domain(tmp_path, httpbin, remote_httpbin):
+    # Saved session cookies ARE persisted when making a new
+    # request to a different domain.
+    http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        httpbin + '/cookies/set/a/b'
+    )
+    r = http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        remote_httpbin + '/cookies'
+    )
+    assert r.json == {'cookies': {}}
+
+
+@pytest.mark.parametrize('initial_domain, first_request_domain, second_request_domain, expect_cookies', [
+    (
+        # Cookies are set by    Domain A
+        # Initial domain is     Domain A
+        # Redirected domain is  Domain A
+        pytest.lazy_fixture('httpbin'),
+        pytest.lazy_fixture('httpbin'),
+        pytest.lazy_fixture('httpbin'),
+        True,
+    ),
+    (
+        # Cookies are set by    Domain A
+        # Initial domain is     Domain B
+        # Redirected domain is  Domain B
+        pytest.lazy_fixture('httpbin'),
+        pytest.lazy_fixture('remote_httpbin'),
+        pytest.lazy_fixture('remote_httpbin'),
+        False,
+    ),
+    (
+        # Cookies are set by    Domain A
+        # Initial domain is     Domain A
+        # Redirected domain is  Domain B
+        pytest.lazy_fixture('httpbin'),
+        pytest.lazy_fixture('httpbin'),
+        pytest.lazy_fixture('remote_httpbin'),
+        False,
+    ),
+    (
+        # Cookies are set by    Domain A
+        # Initial domain is     Domain B
+        # Redirected domain is  Domain A
+        pytest.lazy_fixture('httpbin'),
+        pytest.lazy_fixture('remote_httpbin'),
+        pytest.lazy_fixture('httpbin'),
+        True,
+    ),
+])
+def test_saved_session_cookies_on_redirect(tmp_path, initial_domain, first_request_domain, second_request_domain, expect_cookies):
+    http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        initial_domain + '/cookies/set/a/b'
+    )
+    r = http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        '--follow',
+        first_request_domain + '/redirect-to',
+        f'url=={_stringify(second_request_domain)}/cookies'
+    )
+    if expect_cookies:
+        expected_data = {'cookies': {'a': 'b'}}
+    else:
+        expected_data = {'cookies': {}}
+    assert r.json == expected_data
+
+
+def test_saved_session_cookie_pool(tmp_path, httpbin, remote_httpbin):
+    http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        httpbin + '/cookies/set/a/b'
+    )
+    http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        remote_httpbin + '/cookies/set/a/c'
+    )
+    http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        remote_httpbin + '/cookies/set/b/d'
+    )
+
+    response = http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        httpbin + '/cookies'
+    )
+    assert response.json['cookies'] == {'a': 'b'}
+
+    response = http(
+        '--session',
+        str(tmp_path / 'session.json'),
+        remote_httpbin + '/cookies'
+    )
+    assert response.json['cookies'] == {'a': 'c', 'b': 'd'}
diff --git a/tests/test_httpie_cli.py b/tests/test_httpie_cli.py
new file mode 100644
index 0000000000..31c44d7f1f
--- /dev/null
+++ b/tests/test_httpie_cli.py
@@ -0,0 +1,125 @@
+import pytest
+import shutil
+import json
+from httpie.sessions import SESSIONS_DIR_NAME
+from httpie.status import ExitStatus
+from tests.utils import DUMMY_HOST, httpie
+from tests.fixtures import SESSION_FILES_PATH, SESSION_FILES_NEW, SESSION_FILES_OLD, read_session_file
+
+
+OLD_SESSION_FILES_PATH = SESSION_FILES_PATH / 'old'
+
+
+@pytest.mark.requires_installation
+def test_plugins_cli_error_message_without_args():
+    # No arguments
+    result = httpie(no_debug=True)
+    assert result.exit_status == ExitStatus.ERROR
+    assert 'usage: ' in result.stderr
+    assert 'specify one of these' in result.stderr
+    assert 'please use the http/https commands:' in result.stderr
+
+
+@pytest.mark.parametrize(
+    'example',
+    [
+        'pie.dev/get',
+        'DELETE localhost:8000/delete',
+        'POST pie.dev/post header:value a=b header_2:value x:=1',
+    ],
+)
+@pytest.mark.requires_installation
+def test_plugins_cli_error_messages_with_example(example):
+    result = httpie(*example.split(), no_debug=True)
+    assert result.exit_status == ExitStatus.ERROR
+    assert 'usage: ' in result.stderr
+    assert f'http {example}' in result.stderr
+    assert f'https {example}' in result.stderr
+
+
+@pytest.mark.parametrize(
+    'example',
+    [
+        'cli',
+        'plugins',
+        'cli foo',
+        'plugins unknown',
+        'plugins unknown.com A:B c=d',
+        'unknown.com UNPARSABLE????SYNTAX',
+    ],
+)
+@pytest.mark.requires_installation
+def test_plugins_cli_error_messages_invalid_example(example):
+    result = httpie(*example.split(), no_debug=True)
+    assert result.exit_status == ExitStatus.ERROR
+    assert 'usage: ' in result.stderr
+    assert f'http {example}' not in result.stderr
+    assert f'https {example}' not in result.stderr
+
+
+HTTPIE_CLI_SESSIONS_UPGRADE_OPTIONS = [
+    (
+        # Default settings
+        [],
+        {'__host__': json.dumps(None)},
+    ),
+    (
+        # When --bind-cookies is applied, the __host__ becomes DUMMY_URL.
+        ['--bind-cookies'],
+        {'__host__': json.dumps(DUMMY_HOST)},
+    ),
+]
+
+
+@pytest.mark.parametrize(
+    'old_session_file, new_session_file', zip(SESSION_FILES_OLD, SESSION_FILES_NEW)
+)
+@pytest.mark.parametrize(
+    'extra_args, extra_variables',
+    HTTPIE_CLI_SESSIONS_UPGRADE_OPTIONS,
+)
+def test_httpie_sessions_upgrade(tmp_path, old_session_file, new_session_file, extra_args, extra_variables):
+    session_path = tmp_path / 'session.json'
+    shutil.copyfile(old_session_file, session_path)
+
+    result = httpie(
+        'cli', 'sessions', 'upgrade', *extra_args, DUMMY_HOST, str(session_path)
+    )
+    assert result.exit_status == ExitStatus.SUCCESS
+    assert read_session_file(session_path) == read_session_file(
+        new_session_file, extra_variables=extra_variables
+    )
+
+
+def test_httpie_sessions_upgrade_on_non_existent_file(tmp_path):
+    session_path = tmp_path / 'session.json'
+    result = httpie('cli', 'sessions', 'upgrade', DUMMY_HOST, str(session_path))
+    assert result.exit_status == ExitStatus.ERROR
+    assert 'does not exist' in result.stderr
+
+
+@pytest.mark.parametrize(
+    'extra_args, extra_variables',
+    HTTPIE_CLI_SESSIONS_UPGRADE_OPTIONS,
+)
+def test_httpie_sessions_upgrade_all(tmp_path, mock_env, extra_args, extra_variables):
+    mock_env._create_temp_config_dir = False
+    mock_env.config_dir = tmp_path / ""config""
+
+    session_dir = mock_env.config_dir / SESSIONS_DIR_NAME / DUMMY_HOST
+    session_dir.mkdir(parents=True)
+    for original_session_file in SESSION_FILES_OLD:
+        shutil.copy(original_session_file, session_dir)
+
+    result = httpie(
+        'cli', 'sessions', 'upgrade-all', *extra_args, env=mock_env
+    )
+    assert result.exit_status == ExitStatus.SUCCESS
+
+    for refactored_session_file, expected_session_file in zip(
+        sorted(session_dir.glob(""*.json"")),
+        SESSION_FILES_NEW
+    ):
+        assert read_session_file(refactored_session_file) == read_session_file(
+            expected_session_file, extra_variables=extra_variables
+        )
diff --git a/tests/test_plugins_cli.py b/tests/test_plugins_cli.py
index 9f94821505..70cecb1fb7 100644
--- a/tests/test_plugins_cli.py
+++ b/tests/test_plugins_cli.py
@@ -1,7 +1,6 @@
 import pytest
 
 from httpie.status import ExitStatus
-from tests.utils import httpie
 from tests.utils.plugins_cli import parse_listing
 
 
@@ -149,45 +148,3 @@ def test_broken_plugins(httpie_plugins, httpie_plugins_success, dummy_plugin, br
     # No warning now, since it is uninstalled.
     data = parse_listing(httpie_plugins_success('list'))
     assert len(data) == 1
-
-
-@pytest.mark.requires_installation
-def test_plugins_cli_error_message_without_args():
-    # No arguments
-    result = httpie(no_debug=True)
-    assert result.exit_status == ExitStatus.ERROR
-    assert 'usage: ' in result.stderr
-    assert 'specify one of these' in result.stderr
-    assert 'please use the http/https commands:' in result.stderr
-
-
-@pytest.mark.parametrize(
-    'example', [
-        'pie.dev/get',
-        'DELETE localhost:8000/delete',
-        'POST pie.dev/post header:value a=b header_2:value x:=1'
-    ]
-)
-@pytest.mark.requires_installation
-def test_plugins_cli_error_messages_with_example(example):
-    result = httpie(*example.split(), no_debug=True)
-    assert result.exit_status == ExitStatus.ERROR
-    assert 'usage: ' in result.stderr
-    assert f'http {example}' in result.stderr
-    assert f'https {example}' in result.stderr
-
-
-@pytest.mark.parametrize(
-    'example', [
-        'plugins unknown',
-        'plugins unknown.com A:B c=d',
-        'unknown.com UNPARSABLE????SYNTAX',
-    ]
-)
-@pytest.mark.requires_installation
-def test_plugins_cli_error_messages_invalid_example(example):
-    result = httpie(*example.split(), no_debug=True)
-    assert result.exit_status == ExitStatus.ERROR
-    assert 'usage: ' in result.stderr
-    assert f'http {example}' not in result.stderr
-    assert f'https {example}' not in result.stderr
diff --git a/tests/test_sessions.py b/tests/test_sessions.py
index 5835993605..8bcd906327 100644
--- a/tests/test_sessions.py
+++ b/tests/test_sessions.py
@@ -1,12 +1,16 @@
 import json
 import os
 import shutil
+from contextlib import contextmanager
 from datetime import datetime
 from unittest import mock
+from pathlib import Path
+from typing import Iterator
 
 import pytest
 
 from .fixtures import FILE_PATH_ARG, UNICODE
+from httpie.context import Environment
 from httpie.encoding import UTF8
 from httpie.plugins import AuthPlugin
 from httpie.plugins.builtin import HTTPBasicAuth
@@ -14,7 +18,7 @@
 from httpie.sessions import Session
 from httpie.utils import get_expired_cookies
 from .test_auth_plugins import basic_auth
-from .utils import HTTP_OK, MockEnvironment, http, mk_config_dir
+from .utils import DUMMY_HOST, HTTP_OK, MockEnvironment, http, mk_config_dir
 from base64 import b64encode
 
 
@@ -203,9 +207,9 @@ def test_session_with_cookie_followed_by_another_header(self, httpbin):
         """"""
         self.start_session(httpbin)
         session_data = {
-            ""headers"": {
-                ""cookie"": ""..."",
-                ""zzz"": ""...""
+            'headers': {
+                'cookie': '...',
+                'zzz': '...'
             }
         }
         session_path = self.config_dir / 'session-data.json'
@@ -307,7 +311,7 @@ class Plugin(AuthPlugin):
             auth_type = 'test-prompted'
 
             def get_auth(self, username=None, password=None):
-                basic_auth_header = ""Basic "" + b64encode(self.raw_auth.encode()).strip().decode('latin1')
+                basic_auth_header = 'Basic ' + b64encode(self.raw_auth.encode()).strip().decode('latin1')
                 return basic_auth(basic_auth_header)
 
         plugin_manager.register(Plugin)
@@ -359,7 +363,7 @@ def get_auth(self, username=None, password=None):
              )
         updated_session = json.loads(self.session_path.read_text(encoding=UTF8))
         assert updated_session['auth']['type'] == 'test-saved'
-        assert updated_session['auth']['raw_auth'] == ""user:password""
+        assert updated_session['auth']['raw_auth'] == 'user:password'
         plugin_manager.unregister(Plugin)
 
 
@@ -368,12 +372,12 @@ class TestExpiredCookies(CookieTestBase):
     @pytest.mark.parametrize(
         'initial_cookie, expired_cookie',
         [
-            ({'id': {'value': 123}}, 'id'),
-            ({'id': {'value': 123}}, 'token')
+            ({'id': {'value': 123}}, {'name': 'id'}),
+            ({'id': {'value': 123}}, {'name': 'token'})
         ]
     )
-    def test_removes_expired_cookies_from_session_obj(self, initial_cookie, expired_cookie, httpbin):
-        session = Session(self.config_dir)
+    def test_removes_expired_cookies_from_session_obj(self, initial_cookie, expired_cookie, httpbin, mock_env):
+        session = Session(self.config_dir, env=mock_env, session_id=None, bound_host=None)
         session['cookies'] = initial_cookie
         session.remove_cookies([expired_cookie])
         assert expired_cookie not in session.cookies
@@ -524,3 +528,165 @@ def test_cookie_storage_priority(self, cli_cookie, set_cookie, expected, httpbin
         updated_session = json.loads(self.session_path.read_text(encoding=UTF8))
 
         assert updated_session['cookies']['cookie1']['value'] == expected
+
+
+@pytest.fixture
+def basic_session(httpbin, tmp_path):
+    session_path = tmp_path / 'session.json'
+    http(
+        '--session', str(session_path),
+        httpbin + '/get'
+    )
+    return session_path
+
+
+@contextmanager
+def open_session(path: Path, env: Environment, read_only: bool = False) -> Iterator[Session]:
+    session = Session(path, env, session_id='test', bound_host=DUMMY_HOST)
+    session.load()
+    yield session
+    if not read_only:
+        session.save()
+
+
+@contextmanager
+def open_raw_session(path: Path, read_only: bool = False) -> None:
+    with open(path) as stream:
+        raw_session = json.load(stream)
+
+    yield raw_session
+
+    if not read_only:
+        with open(path, 'w') as stream:
+            json.dump(raw_session, stream)
+
+
+def read_stderr(env: Environment) -> bytes:
+    env.stderr.seek(0)
+    stderr_data = env.stderr.read()
+    if isinstance(stderr_data, str):
+        return stderr_data.encode()
+    else:
+        return stderr_data
+
+
+def test_old_session_version_saved_as_is(basic_session, mock_env):
+    with open_session(basic_session, mock_env) as session:
+        session['__meta__'] = {'httpie': '0.0.1'}
+
+    with open_session(basic_session, mock_env, read_only=True) as session:
+        assert session['__meta__']['httpie'] == '0.0.1'
+
+
+def test_old_session_cookie_layout_warning(basic_session, mock_env):
+    with open_session(basic_session, mock_env) as session:
+        # Use the old layout & set a cookie
+        session['cookies'] = {}
+        session.cookies.set('foo', 'bar')
+
+    assert read_stderr(mock_env) == b''
+
+    with open_session(basic_session, mock_env, read_only=True) as session:
+        assert b'Outdated layout detected' in read_stderr(mock_env)
+
+
+@pytest.mark.parametrize('cookies, expect_warning', [
+    # Old-style cookie format
+    (
+        # Without 'domain' set
+        {'foo': {'value': 'bar'}},
+        True
+    ),
+    (
+        # With 'domain' set to empty string
+        {'foo': {'value': 'bar', 'domain': ''}},
+        True
+    ),
+    (
+        # With 'domain' set to null
+        {'foo': {'value': 'bar', 'domain': None}},
+        False,
+    ),
+    (
+        # With 'domain' set to a URL
+        {'foo': {'value': 'bar', 'domain': DUMMY_HOST}},
+        False,
+    ),
+    # New style cookie format
+    (
+        # Without 'domain' set
+        [{'name': 'foo', 'value': 'bar'}],
+        False
+    ),
+    (
+        # With 'domain' set to empty string
+        [{'name': 'foo', 'value': 'bar', 'domain': ''}],
+        False
+    ),
+    (
+        # With 'domain' set to null
+        [{'name': 'foo', 'value': 'bar', 'domain': None}],
+        False,
+    ),
+    (
+        # With 'domain' set to a URL
+        [{'name': 'foo', 'value': 'bar', 'domain': DUMMY_HOST}],
+        False,
+    ),
+])
+def test_cookie_security_warnings_on_raw_cookies(basic_session, mock_env, cookies, expect_warning):
+    with open_raw_session(basic_session) as raw_session:
+        raw_session['cookies'] = cookies
+
+    with open_session(basic_session, mock_env, read_only=True):
+        warning = b'Outdated layout detected'
+        stderr = read_stderr(mock_env)
+
+        if expect_warning:
+            assert warning in stderr
+        else:
+            assert warning not in stderr
+
+
+def test_old_session_cookie_layout_loading(basic_session, httpbin, mock_env):
+    with open_session(basic_session, mock_env) as session:
+        # Use the old layout & set a cookie
+        session['cookies'] = {}
+        session.cookies.set('foo', 'bar')
+
+    response = http(
+        '--session', str(basic_session),
+        httpbin + '/cookies'
+    )
+    assert response.json['cookies'] == {'foo': 'bar'}
+
+
+@pytest.mark.parametrize('layout_type', [
+    dict, list
+])
+def test_session_cookie_layout_preservance(basic_session, mock_env, layout_type):
+    with open_session(basic_session, mock_env) as session:
+        session['cookies'] = layout_type()
+        session.cookies.set('foo', 'bar')
+        session.save()
+
+    with open_session(basic_session, mock_env, read_only=True) as session:
+        assert isinstance(session['cookies'], layout_type)
+
+
+@pytest.mark.parametrize('layout_type', [
+    dict, list
+])
+def test_session_cookie_layout_preservance_on_new_cookies(basic_session, httpbin, mock_env, layout_type):
+    with open_session(basic_session, mock_env) as session:
+        session['cookies'] = layout_type()
+        session.cookies.set('foo', 'bar')
+        session.save()
+
+    http(
+        '--session', str(basic_session),
+        httpbin + '/cookies/set/baz/quux'
+    )
+
+    with open_session(basic_session, mock_env, read_only=True) as session:
+        assert isinstance(session['cookies'], layout_type)
diff --git a/tests/utils/__init__.py b/tests/utils/__init__.py
index cf90d684b9..d3359820c1 100644
--- a/tests/utils/__init__.py
+++ b/tests/utils/__init__.py
@@ -6,6 +6,8 @@
 import json
 import tempfile
 import warnings
+import pytest
+from contextlib import suppress
 from io import BytesIO
 from pathlib import Path
 from typing import Any, Optional, Union, List, Iterable
@@ -16,6 +18,7 @@
 from httpie.status import ExitStatus
 from httpie.config import Config
 from httpie.context import Environment
+from httpie.utils import url_as_host
 
 
 # pytest-httpbin currently does not support chunked requests:
@@ -39,6 +42,7 @@
 )
 
 DUMMY_URL = 'http://this-should.never-resolve'  # Note: URL never fetched
+DUMMY_HOST = url_as_host(DUMMY_URL)
 
 
 def strip_colors(colorized_msg: str) -> str:
@@ -187,6 +191,13 @@ class ExitStatusError(Exception):
     pass
 
 
+@pytest.fixture
+def mock_env() -> MockEnvironment:
+    env = MockEnvironment(stdout_mode='')
+    yield env
+    env.cleanup()
+
+
 def normalize_args(args: Iterable[Any]) -> List[str]:
     return [str(arg) for arg in args]
 
@@ -201,7 +212,7 @@ def httpie(
     status.
     """"""
 
-    env = kwargs.setdefault('env', MockEnvironment())
+    env = kwargs.setdefault('env', MockEnvironment(stdout_mode=''))
     cli_args = ['httpie']
     if not kwargs.pop('no_debug', False):
         cli_args.append('--debug')
@@ -214,7 +225,16 @@ def httpie(
     env.stdout.seek(0)
     env.stderr.seek(0)
     try:
-        response = StrCLIResponse(env.stdout.read())
+        output = env.stdout.read()
+        if isinstance(output, bytes):
+            with suppress(UnicodeDecodeError):
+                output = output.decode()
+
+        if isinstance(output, bytes):
+            response = BytesCLIResponse(output)
+        else:
+            response = StrCLIResponse(output)
+
         response.stderr = env.stderr.read()
         response.exit_status = exit_status
         response.args = cli_args
diff --git a/tests/utils/http_server.py b/tests/utils/http_server.py
index 0a96dd8b07..ecc14966b9 100644
--- a/tests/utils/http_server.py
+++ b/tests/utils/http_server.py
@@ -85,6 +85,19 @@ def status_custom_msg(handler):
     handler.end_headers()
 
 
+@TestHandler.handler('GET', '/cookies/set-and-redirect')
+def set_cookie_and_redirect(handler):
+    handler.send_response(302)
+
+    redirect_to = handler.headers.get('X-Redirect-To', '/headers')
+    handler.send_header('Location', redirect_to)
+
+    raw_cookies = handler.headers.get('X-Cookies', 'a=b')
+    for cookie in raw_cookies.split(', '):
+        handler.send_header('Set-Cookie', cookie)
+    handler.end_headers()
+
+
 @pytest.fixture(scope=""function"")
 def http_server():
     """"""A custom HTTP server implementation for our tests, that is"
GHSA-vcqg-3p29-xw73,"From 4e2def2539ec13e53a82e06c4b3daf00454100c4 Mon Sep 17 00:00:00 2001
From: Andrew Murray <radarhere@users.noreply.github.com>
Date: Wed, 1 Jan 2020 16:38:37 +1100
Subject: [PATCH] Overflow checks for realloc for tiff decoding

---
 Tests/images/tiff_overflow_rows_per_strip.tif | Bin 0 -> 312438 bytes
 Tests/test_file_libtiff.py                    |  10 ++++++++++
 src/libImaging/TiffDecode.c                   |  17 ++++++++++++++---
 3 files changed, 24 insertions(+), 3 deletions(-)
 create mode 100644 Tests/images/tiff_overflow_rows_per_strip.tif

diff --git a/Tests/images/tiff_overflow_rows_per_strip.tif b/Tests/images/tiff_overflow_rows_per_strip.tif
new file mode 100644
index 0000000000000000000000000000000000000000..979c7f17696d5c9586e1157e547196d3c9919dd4
GIT binary patch
literal 312438
zcmd442XtKLmFEfB-aS2Yw!1CcqQlPY_Uzf-+4gMrXxzbe+af`bAVB~m!AvlMnFNt@
z&KW46kaHpDoO8|@%pjOaQB0C3$+DcS{oPju0;B*DvZMhoP=!~o3V5i0-F)wNzfGHd
ztoK)XdU}7Or}x@7^<Lv>6?d=cj$JtZ2FKsz{2;e)>dwpS{#V`cH#mO%wQuSDSAL%6
zi8plT<#$$bUS7-1@B6yfjPv+Mul+B|`9_ZacinL($Ny=;-~4|U{GA;f%isH!TnzdY
z>hS)n|1kISuXqoCrRVd1>V2WxFaOgQd%gVqzw~$hBma5We*v|%dU`<?py~%CS$cYZ
z=52f3)YJR@pY-(H{_|^kpZxMQJ*NY&>3!t+n%+O9yrx&)^qSs}ue_#L{K;#2|Iey#
z=;i<GH}w9mUEk2lcKU|i|B>(wy^OkV=>6!zH}q0I`i9=B?|f5l`#*hCZ+i1L^|n}l
zQ*S)#n|j9O-_#o(`=;K8C*RcT|Bv6&Gx+hh^tv~FOK<g=Z|Sv%eM|4(i{%rNuazVp
zFL!q@FLw_wPj?RwFQ0(0@Q~23(2(%3(BQzpz=(+O@Th22OiWB%qDmc?5T6j2n39%~
zoSL4NnwpuNm6@KFk&~O3mseO^QeIJ2)!5irUt3dGS6^RKT~b_9Qc_k{URhOMTEc_!
zs*18QP8Amw78Mrc=NA+e7Z>H`=49t&XJzH&<>qmy$w*E~NlHjaPDxH)NmM*6c9|Od
z^t(&a_g<hk7SO6W`o5Na@G{c9Zpj~We^2?jlBl@uGFkV%{~Y!17o+!{qxY9X3xDJJ
zi#^fNV=X<>(!-TR#off<Z`3n&*+N-a8jU71Gc!X+9L^C>XempR1<9*(a`O>`g2F-s
zq6ldafhj31DV?XXGUZsL2C*qDC_rxVa-kfdEZz0wV(CaELX(`Bm=GTq8>^0qj#jNC
zDlTijryh_unVk(H{CnwXLa8s1oZ`mQ>FK<Q4A24_(I|q90!@(u4d^HY5~XF&U;!0H
zm*fFT4)D)?0(=HqOt@fja#9kY!~=>tMx}~cNmM-k`9II-Kmijzu%yJqB=nt*5_QBs
zoHS3#$tkI6=>P-62rvbLj6frd16LFZ>nNy{mz9^7iL%wfq6I~GQa%Iu5ad%xO@UFk
zL}G%liaJI>Sy5D6e-KrxppvCYPfbor;G>F-QS)g%Pdw(Nj$-5D;uDfEMBtJmxM+Ds
z1WNhVqElRg{i&#|tgI-9XSBHF^IA-fV4`J9v1JM-@@eo%=;TKg6&bOTyyE`d>##H&
zt;tAB29s$1p9sFiCPQ)n$w8z%p}mVzMXO`u6O+?2GBw}=GLT@S{no0R;!=!qbxlo8
zb#;{>Q(B60LA5Bbz?UMX@QA1rxDcKcOyc7BK%(K4l|{w#yYFg2(WIv&#>J>2a8{t;
z;2<3ZLvkoTA>}9}G(1uj9hU&RWT0OVq=h61<rfqdl~q>P;<+@`*VR5lrUYQ}@^a)e
z0FtC6VUffHg-Zky!30e!poFg^uXre^V0|*vlj38d!b1ZCg#7$`74q}*_xJbn<%geN
zKu}1SLg5jSsu*=#Vrsf@is%(BDUzcVpOVtDit4)NmbT{B)|Td`#zrkR!ZfADh55PJ
z$SXQb5gTC=2uu{?1E;{1;bAL@in|sSR9|XRTy#WepaO@Fx0jB*y}jhv+uPeGAR@J}
zP-lx#rRA^!oY2^$rRF(mX>Mt0X>Duo=<ews92y=O86F-U8X6oN92n^D@9XR7?(Xbp
zYiVw*udl5|zK}2xGQLI9ij&|IKnV*AT}f255+nv8H6b=CG&sNq1iZXFJ=_)Y(2=``
zr>Bp%_36{6PjNea`pg;2vuCZWZES3X>^@8O_709tF0QVwZV*3&T!fsRog5t<?CorA
zZEUQyWMyroql1>}@<jL~EHpG^B~ft|UO|4a$_X*TD&C#~gu6R$Mc$A?9J&)GdAOYo
z$jlQJk_*cem6TPWO>3dLI_-De90?CKw{`aP^$!dV!6a~rLVdlxJ>6X$?X67>wKXD6
zm?tfjmhn}ZpX^|sq5%{%*h-?}0xF_aGSXAxV<JKVeTf!@Yz`kfX6@)?d-})`OD7i>
z1r{$~KO3KHv}ImC9tq)I4cfGUi10;fYHDt2?da|s92py*oSYaRAA?56Mn^{xr=fxV
z-tG=?sjI23ssfq?R9;?^y3bFeDD@Ra1tWs@kd_=D9T5`XtBB4q3!m(c^Vjd(y?&u9
zFYxp+J7mGljo{kL)>}+W9wr7>fm1LtSQ+`QZ)nhdH$cGB-q|}aJUTuxF)=<mGCHCo
zQ0edM?P_mntgEdSM9LKsXHQ3YM}m@qf&v3q5)~v!!XE?(RKi07d_d*ovAEs`e;`-%
z=Rb4zhsT2{)+g*;kR`;(&C)9m#|>19K}9G#8|Ti?&(02Do>5~{Nm_n!^}vY2E6*?y
zRv8@V8|dq6ZG=@sg682sgd~tE%h{0}7U1u{lBl?WisEUeCda8Fg8f0|pl|m_pZ@-n
zk3asE(8r(r{?m^KB2J!lR$y^;IT3)fhCd>xbgL!L27O>=VNqW%j3f7T^^Gb&XJ?O~
zg#Kr!V2Ol=5TN#knwo~%y6Q^dk5UOJC9otczyX%;=!4041}ljQHb@Cc;FUO47^pZ~
zWZeGKCm(+BEIaV@gAYIX)BPOl(~hoUOk7+KYDK8Hto#`&AAF$yrrDgTt+ObobGF!{
zum7`+!Qq0+m{{i_NG$X~e@BxhHX*gFy1KGDMM5M65N%9Jv?O#mD#*uYB~ig&QDWsZ
z9V+g}N}m4ay?39G<anqM2T$I8?~{)z9Zou8SY2J*Y+PU#c%`&FyW3C8DIeT^)6Yz7
z5mZ}k;TB|Prmw%lOy4Yg3{(^y3m)RK4D|Q47euC~sG~{KRV0>yh7w9@;gHC(u&^ZD
zGSbUyB~d|wFhD5V)TCJ9m7}E}e(>;}`)|K}Z;sx6`|bPhJbe0bmHjb$oDFAZ&;3z3
zf=UUf*eT-k!R_fc?Lb9G78Z89_4U2lYky|sH--rU6*15KVxRl^dK)z1O)dGVu)>m}
z6eX6H{0vDNA;n29)R;$mc&sccPm~l#T8e_o(aa}LZV%y<idQ;1b@j$Ag>K)u_xNd^
z<p~EzM`tHjYa6W*(xLJJpmhJ8#XKrzW)^nl@y+es`k*2vXn41f7L(qd293J4xxP5I
zsw^*2$vYGlDDJU>2zjZz{M>_KZf+}#ijwysix3+XW*>Ot(T)C^_Wt3C3o|z#-JG~^
zbyiE)Za%!LK788V5nMcW=HkX-n$_JFC|Uuf``ZdCiU(g~_NJMgMNv~*m%dTRsDjF4
zKzZB;pY-<h^wj1@wl>w(wU*^2Cu*4^|2<%NFCRp}MCeq2tIJBF;_{s*f(mLS5r_X&
z-=mp}^=-ogaLV}9(+{UcFI}Cva^>=+ix)3neK_pC@2tIpgQMqR4-^ZgS>0W2VP>ZP
z=9_;9DEeARxYyU`)SFFh75ZigI4ol$!-J1^KkgL*l&;F$sD{S6l*B}$<AMS~B0ulF
zruPI5$w)wXXZ>89R}vKmK_xw%1Yv?Y(k}V#mFdZr@xl7m&aSTR*-vivoxeIWbNSMR
zb5m32uH4T$cEpDG#@)su2luwP%nxq`R|Q{1z)?`qhI!Sswe?M{N%|JJapPknSYrVN
zNV>bay4p2~`3<$yL5eAW%wh3fZVq4CjBa+$8DA&I6-GtUgoO18F_EWxZj28Pw@wc=
z4^B=^PtW}7TJQN;nC0@ta}%SZ6W0gacbu`avv=_{BN9?j$yS>Q2`KtX*sC~pguu1+
zjjemkA_SFDaq{~VOaP^`v!gI2w!WsatfYwG0nW(L5@{YK|HTi@F&_u}l|;qvJ5MBc
zN-jAe#y9ZtM1S8v+r{Db$(gIO*RDLB?T=malb`(P^~lNb(V?M<s|kCK5+FPKnu#A*
zTxJKSnCZPaJ#B%|=qrF!RTA4&NrY4yWwvKvNI_*#K<VxlMgf%e*5t&Ta$%LZgumnh
zCBdz|%gT;F?P+VflBn2x=ZTWiCuJLBn|GzZyJw(nW~_4>P;N}$zcTo3yDdA{Z1~a8
z_~>B&;FXfo`>kzloqcvoC?u%(`I)_Gcl);8oBD4GDr9N31hb@@=_d>fjR>y@DuPKT
zm~^zawKgUv7L>y(3Y#dYK#4kZMAFm8#o5MYB~h{c&J!tekQa-OKGSl(r>keM{pMKL
z^tBteZeP4MI_~-R4n2K4e$+iWHrUsHzTIWVX<J(-@4dPC3My*9zx%uD>h5kcw5z@j
zkP3<UNHHXM)%Elbjf^U4rMI_Ri%Ca&yQG{@)g_XWQ#j-qB)aNTyrZ9umDNh30<Q=v
z$;nA^D(ivCp02);j<+X!FWk6w=kBeGlb5btoH%!B-#>PbPY(C@PY(K<oB$QC{p2Mv
z&8g@UNW=%T11jKAQBKTPQCVG6hr`l8I6OLvvPFPIc7Oy>T3ebLP%8+KF5QoFts~4~
zW@e&KpxfEAmMe*h)pwqxD6Engr*a#d80hOC?6~*j+U(WKS8hCfI5Qjmw*gmTkN%=_
zWPD_3cxpV-=$NgogU10aDrFQl6g47jB8bc-2B^eW*EY9x^^r>em45P)U0P7u0HwJJ
zWm{TYK=yVH58x0}D0c~-k%4DO_pKx<wy!_d)*ce#Q~@=OjaAi6t(QLj-EV&N;M(k?
zyVr01Z*Tqe%-?&hYwzo7s&8#;PBuJhYh&+mP;%IkVX4rfGM7A(TnX__8Cklj+NQQ{
zEh?xL$-s&5K%mlCUsF+9l%Jagizskti$f^5v=o(dY}Dyf&`P3W{rY1HGU(cbSXFpw
zd`5nC`#?|E`Kj^o*&8#L?%dA&4<6V2{yuzgY@oS3FSSy${wTRxw}YB&O?GZRah+sD
zv^R-*l^73yl}uepc}+u0M^|q@nK#nch)olzev<u??XNB`fm1SZ2$Z6swknw@<mRSP
zojNJB@~B9GH&zu<lbTc7*gJ9l-1*D1*Ka+1`tZ&>PanVi=)Jo*w_}~P#aVTl^%gcZ
zb`Hk&F0Sq#<h^~g1rlFhABaK#q!b5u!atCzQB<^4y`;P&8EPS=))eUPOT&z-lGt`w
zKrR8A0`KD|RvZ<Z*B{F#l`u3lIUe7hnP1sDeCgIbBH=&0|MYji{qSkyse%u3EbX1T
zCwm*qa$5@AOK^I-Cof;Vas`)WcJ`W<bkWl6)j68Ib{#8r_ukw0@4tQT?%g|gZbP?j
z@hx=o`n6diiAzKh7cVTJtLFzq$`nysVP271)o}2e|McJX_2d`TbdFzp^zokrmIuH2
z{ilzQRogzcY$#5)8SihYEba;U_NpKL2>QSO{=feCAOHJL{^ei)_1_kupZ@gczj#aE
z(0J>PU3>QJGvBjo*Us(Rw<)w8+O}=0sqx1325Wx#@BjYupXunQ^7AJPXoXP`ah`q?
zzcaa~vbery`p(l|gUKHr-Fg2vkM9*YWZcViOikE7*xz1VGY}h4$qWCd&`P3W`TAoi
z^G*pWr7fK$P5l?|zyHanf4DSz^TE@H_a1%t<lf^CAKLov9USVa=^FKnuG2wMmz|7r
zq1aQU<psq#Ur6UKCeYkKCyG)xj;2ZHIf~C~dMUCiiOOkEq0T$?Klm@(vZtzBhOWH*
z?r%Q*{p`aJKK_{8Nv&PQhoAiVjKj{sk)DRhCY!Vt?c1qOxXKIWNXdI^?>?HN59jHF
z7wO?hY{Sc7Sy@ybN$Fcbr8DDFZ}Z5NJ5PT5>7Q;s{oU_A{?nfyxm4Oc`StIQoiOVg
z>FJ-1@hTz30Ci>${_5Ay(;Py|&jm2eAI{;$&tFYsY5&mD*sLTfr(S<VGeDezN>_c&
zwa(#-w;uiG51%TieER7fm!dSQQ^$6g7<3QyUmv$t*K0xPj6VPC-_Fx-7NJj;A_4Q0
zJF42H0a2cLWl-tJzHw#X{PhRF{_WF0e){J>QYO3Qk{#>kaKd<vNmuWccSAf1+O?>(
ztEPUf6^o~H^sH3!zP4R*@kU8qzvO#YRW&bRmX$=s^7ThFbj50UrK>6Lql*)>?|k&p
zZ+|bf!%u&8EBE-p-8;4z7$<d1e9~Z*(4Z5bHc**^gP$)VBDe@Db4{bq_l`b({P_KI
zs;Z99XO@*j<@C27#j0cHQ0c5_|HG9l_n-dyqmMrR)d#<Ndh7m&@7}$2>-v@H!O@Rq
z&W4oh-bqKRYWm}OD0JMRgF?q7f&}mX8Bti8r}sxyRa&-N5}K7n<<z$yVLsJUKhgeo
zZTVw=y!ZCw2X}7Yx_$f3o%`?q_O~B@^x@M-w{QIFww+IYtL{B?v^+yaD=yCgqUDUm
z;n3CIp7yIM+m-}Gd156|ISDGXN6w+r)soZy>4)!s_|b<{m_PpYZ+`#BKmG9!fB4<6
zKKkQ~oo80_oGNGsm0#)bfHmyjcw^Pni&7$tp)Eho-9MP8r`@W`If&=LIY=}7!MO)r
zT`P`C%seWc&AH`&`qS@z_lH0J=}&(a`V+9AWLnPpWHru#LZgN1+^=+!BB;dcAbBP-
z&m%IAh8(>EJ?&Ce>O7xkI2?5A>RKK9?BPnHa_rlWqN5j}($(2glzagL^hZFEUJY>h
z^Pg|2tU~giaSHw(sC)z*Ixy_wL|it#u`2FS+#7Ffdic;5=21VeQ9qEInp5w*GsdZy
z`*ZX@s5CzVKzpE|!r{R;R=L48D~rlQ{BiZ9POr%S*H)2~Huf7aL0bCb<y0GwgmNhn
z&5?o%kmz)WU7U!^sz<i5A}qF5g2nizcWl(}yknyvVO@FOI)-m*)>?WG3Hl5w;0CM2
zu9B-9T+xc^@ox(%F$+=Y>TE2Ei^ys}fAjwRyO(=&eQmtd1r5*HQBXPmp$-!8umzQe
z<C`7|Dq1e#{{DSyK5^j>xqll-6jZcD{Y6pHN|3P3N~3Z@K_&V*R4DH?lx9Q+dAqx~
zxO)Xer<c^XFJKh@=Q&h_MIePos%#&^BCEz>6ycI8BZW6WV$}$E+`A{(%=J0kTM8Ao
zgK){pqawVbQoV=@flh0ERhcv%l~vZYJP!%~bZ49D+=ufP#uf#l17p=Y@4z02OQn&5
z1$eBwcW+h9-65m9R?&BLbm!e}Rn-#O)@}7GfeJBx^uz+aBLCD&sH06a{Q)XOF)k<%
z6o?v)D!Sv1RU#`eM)^JKn7e|6)f=n0UsZa?N_A(Bo-AgA_$A>JwCyV)K~btNhzb%k
z^;9vjSXrH2nNy^5{XmkIoF_?8&eN^OU8;(gq*zwc25GhJUx3QwQ}H_>EhwMGWC1Ai
za7gY}=oLrhq@r#A5>(z7IG%wq$01~{6@p9VvCtx+y}zl@D~<{_=r7PKNYKQ4T10ea
zMF+++1_6?JEVM`{_cyfk=+%~>6R#^a=!@!==D4YM1&=u}=9I`Y{s5BCVgVx8we+Ab
zsq7WjD`#H+OL(OvyW;9Y5Si1a3&BuWL=e%j#XJ-WAlmxTy{YQtmt<~NQrn(}S0H$$
zr6BIPJpAW9NNT)(UqR#<9G{gJ1r!}?Xn*J`YRZpWQ&pdL0iJsmQ2FP^tijug`|+yW
ztt2WoI$rtb+~Io*KJR%=xnf5viHh~>k7DTXoc!l#l5f*=lz+W6t;pT7u4Ax%;|7CY
zuG_d~_1X;vYu9YhU$<sGRoGv=_14eV8mxWmmuuFped`x%H*Pf8@XIv@>o%Gg8E#x}
zw9(XLi;2<t%_gQ>x9-@nefyr>JGSjM-+y4=Uh^X^QJRtpI`$fC>uYI?XzJ`69Gf_I
ze&+I3s^(X(%wE4fJA32$-Rn26U9)|iTwF}d#J{NS+?wov_$=S}H68R%!h6fR&f0Yw
zHX5umpdP(;!v+Jxb@~RsFaVv^t5>gEy;}b*{k3b>t~StLzkdBXz6>^)Y}l~T$k^D#
z#FX3Sty|2t@7%L@_ny6b_n7ZJaNy9vBQ~B<d6hMF(kW6?RoB?m(b+RNI)35&rHfZC
z2`Y3G&`xk2b$IQXJ*ZIjoctHn?VEiM-dkWzzn;Us2RD~_optNiY%ttpD99LXSi63;
z0e}F)nssZ}=&%0enl%P%^w+FiZ@6y#Mq|TuAh^lc(Aao0xR`F)vSsVG9XofM@7uTU
z;K4%&_Z~QW!rIn7EUmPTC9};94Yl=kO)YI5ee^O;O-*08d}Ri@GBbPi+EuOVVE-K@
zn++<ruJ^qAoXPlF9>_J8cbyHOVQ9Qz!@3QIMjO`|>aPclwFawK8?0MnVDQ#jeS@`Y
z*BXGyCM0IPk%_74W@FP$##=U<8k?Hz+P;%+i2Vo5_Z>KNX#bvrXIuipA~Py#0Hw99
zt+~FTrm>}|t#4?Ub$?@17iVT?u3o=-S?N2$rJB9!q(kLjRX4A7KUruyzn){c#`3OX
zXt>U3lgY-78;v&^p)uAOY|z(VZy<e%Ykz5=zk1CYeFKB_1{)1GZQ2A+p-xPV;T5xO
zW?Q#x7QxxS@4$ZZ{f7=)96os3BQz;JyS%QEMa4~Rt!+)Ryt=Wuofc0PEsalKyh0b#
zwV7+zzy)TRopJrnBWWF&{8!bD*{&yZ%{fc{oUU)^=$@Wg^7)rOA=g;Ob@)4Q!A3(v
zlT8~;Hk*Kp$p&KscmqyZ{nnaw25-HkZ=k<+-Fg$_O&g3h85?gxY|Ko}c8WgPxqIKP
zy?YOsA3U^w|KSs-jvsS~(iE51Ha4}lw;(v}Ev@y<OcZKp?HiN@3oPWAxjZv-jZUMh
z+@oEzs8A*QH`Vp4osZ`_m6rV3H2&_p84c&JEcpU?qNnic)!Vny7k!OfV;R@sch_wK
z7NZTq2^+R-*=%BLwBB&7AsTl5+O@0KtkyRaRlISd(MIF-pt8l#Yzyr|d${d3-@9v{
zxw-kFLly@PpK)__^N7$?HlRj2yXgyWW!Z3jO;t^ObyG)gAIp8FS-1g{%wE5G<HpVF
zVu7w+bN{Zk`u<bZwVC$EqIDLdVQG{V%6qpaeI~C%M}t~D_2O@gs>f&Et}cD?wDMT4
zvGjEo{)*v75CItz%<aaF!V#eI%b))oi>$v|e+^o9y^(>@CL<F=USqm_^LDeH+qUi8
zv3<v$J&4bt1N#pjK6d=HOOQG-tE9T2sl9t(u)njll~&H?x@x*bo7=m(dk2R=<qD|4
zDc5dXlQ?a5c4o#)P@z-fr>fa2ZI7-jLG5E`nIW(!dpEs$Hm9tkV~|g?yJPCoqQ9Un
zy?V={bJ3^d8cSbi;jb8NG&C~WykU#6k*P5<vSIxiF+OYH5<oG4UDg_ISdTh320h~~
zTX$^VX0~nT&Rx5(#^&Y+Ee;(%e#+LvFDfagqP79KX>08t9_efo0cv2DL1TMIS5Iem
z&*1oZMS5;r7macgP7y)!|1MoU@$u6?Q(e8>`snf!)PC*U`STiGS?u1W3)4->tW%!o
z7(Kt}FVw2fcbj!A`jlK_>FX@~l}#Hq7#VLtyP#7{Hezv&HW;kaU;T4@wzX^5>mxtw
zH*G+KObrZ8wr=0D9j9&gt{uC~ckel1ap>q#i{n=A!SU(YMa8vEEv*ebo$dXDV||^i
zEp06|WkuD^tsMwdclYSDG(FzDaZ@nC>au>}>g?5^?@6yyf}nD#`QfD{sD1YQ`SUsN
z-f3iQLUTRs*!5aehNc(&g=%$<-JV6CQLZ7^dA7uA$pa%1A7jL0lac9Gw93YfxU|@y
zw+svo@bC=u4X{qeCYww)n{M4^wtf4q9lQ7L+P(MCfxQQhojP;Y*4{llDYvwuzP5pt
z18p50-Mzz;13m4n?JczxrM1oN?VUX=zPNB1zwIVj518dPKanBaxbW{iPNa)%`sb>d
zi%kz{^jwtMXV0BGSCNz`4a-7F$+-%z3{EZj@?KU^SugsGat*mo&4NCU#SgKzn~ZT+
zO-whLpj$A``fK09ebZmJ4&hn9PJgW-o{6!kF~$c)y94ij@18yTEG+gNwXtOllV?Oy
zUPW~iAEQk8Xl<89@!{_F*0z?0=BDQ6?#|vpmMB~mzwHLgD{rE0Z!6gkGz_T75R~bE
zS6#W#_+UZn>vM-4v(pMqO-)Wt3LaW&ADDdZWzQa*G&9S2_Tae#xrW?cjtZ<|YHGY`
z(`FMRBa<z3qHbKf4rfkZoHr~Go*VqLX|t)RDGthx?YnmEG2eq<Z*PCr-rd*JH#9c0
zu(GzXrM;)8qob2GTYW=AV|`scU98CI>Fezq9G*BQvCs7z*Y4gz&5}^Pd-K+H)XUA;
zYmslzv7VT8?%!3H&(}XdP8KB{Dhepip)#@9%i9CZ+|2g)<uCS}TtjXzM`iOSm<8Kx
z%Du4(+SX8PvS4CJJOn^SoA72g8*ee&w!>`qu01>VS{$=-@bdC-_4W@A4~tFDE-SB-
zif4CMPj7#3-@uSG&&#6fA?}z9Gkpou1E*ZOPIL5)o44=Yy?x{6H6G8-s^3snH-O5e
zb9L_^CyP?YRbiE>7g%MYy?=a>m$#kVW3<l5Oy75r=ag&6b(VpO(MBU93^K-7jtmSH
zK3TVJ-TDm%>(?7f;Dc#0HQBm#`>vgQnOmH3^z>!yL_mZpOr=W6$}g;_ZElsSXD17l
z1_%4QJNtSEhliPE!S~qIrK>k?-lT(E*af|Elg{z$H*eg!F*|!T_KhbjnMywQ3)T2g
z)g4*3zZi8~1raSM3ni$PP~x-X#H!UpX3Yt2e)g#$<r;FGm!o2Agbl(+GcqwYG2DRl
z*|7ST!X_IwN<?UAXk<#hz|_<PPT8@0_pV(B&N#bx2ZcteW8-3CBBPSivhqtyYpTl{
z+d4bD`+E8Zy1NE?`iF;y$A-qn#wR8(UA=be7V+^d@!_uDxPJRC33wb3V3|o?C99@V
z6jUmgM5R+fWpYy1^!N8Es|Y(gCngq0#jLvG%?`8b$VE|+Ysl^8sF)hz>u&`U;-K~G
z*1ffM{n~W~$j*k1NDqbyU!Q~ls&>cjoxAoPusCVw?CKp95v7h#P*V*}&dgv<N>z1L
zeOp(rtUT#Oh`Re&h0g-^v8i(xFXOg}zz`YY&ElurxQ(8@PBb$!ld<ZFOej15OL*mT
zP?<r?LW5eDMQK~<s2yAi71-p2{+s`>7_TfJmF*~vO`A6v5e;oHG{k`;G{hj|p=>nd
z+jxr!DutB6Hcaxq1IN$UIJ$cWM#ie56BE@5v2n>+c_kIq4UG9{ZtZ4hkg`U$w}(%)
zM~u&f*%=gyh|YELDp#+wOylMaQVHU&T)CRL>WMU*pMOg=v20WnP#$-5!kmjq5P<y4
zP{PmtA?VAYVq!{m%@{-s42&?t_$P+kHW=g28ey|dj5eEX-nw<$_U*fO?>ua6&m0sN
z@6gcLL|W(56H}8i^NMR5>l#>@-O|+D*^NmiVCn4W>FDn4AD+5=^~UV=nHxxqtk<5o
zLOSj$%jafhudq(}(k0ERCo<3uRK|zOmX;tbuS^WQ`>t-W%j3uGR~oaMdKY=;2?jq~
z6cFX5at*n?T!KtC8*jq?7#XfNBpqk4Mgr#bICX2+85tRy8g1Teym>1QtwhKcR&Jg$
zqKhO-Y+7bUiY8N|DJ-d!iENF{9c@ib5*N0$wY0RhcXagh4vbD;njz>xey&};eChJ#
znM<t4xp)DaNk;AptJ?FwudIC+UKuXGi!NG}I%l*F3aHTb^;qd~YQKA>Ke-*9{)I@c
zA-83qVj_Vu{@eO>Yw_F+us&#6qjiSj?rz$+!F0>kE!%eP*>Ar0sEtQZXmD6SkV+K=
zDw+&dTNhX2)3$fCceKcwSPtNm)~3#`j;_AG5zLQ-J2$V*lAL6X(xpp+$i;IP&Iv-7
zE?+G8{<}=NO24ogRLYh_rE4CQt5;`Wx|zq1+iHu`las~NeG!st$nE8*Y(tZ7#4H<1
zR+|*$dXh{)VzAb5BRRKCM#Mf_%y#3=9<}rcRmDU^$Hc^|)hU@Q{VOdhV}xH@-@pKK
zwOCe;zuzHihdcO&Rp1oi_}ObSq_IKc;<@Q*zF9(d4uE7WR}rWH%Q8{v7nP!PercPW
z9wm3+Mt>3d0;rgpkeW7xFhOe#NJAPL;md7YN8|$!p=q}eAn)2^Vd)X9VuE#2T1skq
zx+W(tC$FNshKU}GAR7jjuI|qEF7zL(`Y}T|wUZZ7tq97@<trC2o}WH9g(HR~nV2{~
zJ$->Q7cN~a{ed!-=E53yrF3atxuTVzz9&y4?aSggLFM72N68E&`9dVuklQkN#bh(0
zf@a-lpubU+%X&Pz4LsavYPQ7$Ot$UVw%>gBAuE@_n8cWvqznyf#xt3Ll9N|Tq5yL<
zG&VUp*wxeB(=#|SJ~lkWl&yYd6ii*3xqf5j0$TOL)cNsA5E&m~c+SKG9CIEiI)CmQ
zsK^Mg3;N4NMOa10C^S2Lji`v3F(UuC5uHnp$#@e=#c%^@1w(SQ#+!+h_fY29cibs3
zT&0dpOv}kDWcmbyKeGx-s~T8h-qkZSG1AK*gOSn6a~BvdH99ni#vd8GNW$X6)H(1N
zpBNt-$JHGj8Xg|Uvzr*7oIZd4!gS>i-jx;T7eQsD<nG*5w-<kQ>3F60$rDKoT?S{g
z)Fn{q7<loupZ{2{A-9+F3XVRRM^n-(8w@uZ;?k~PzsZp3*~HLv3-)P?soA!@2aZ}g
zxCKYVL?@(Y<rL*JuRSL#r?9e)au5CReaH<i+vwQ%xl89KC#EJxMutX4#>UQFxOfhb
zWR%^+*x2aE7_+#TH#0uPqw#ULW~^3F$<DgCRyDZ{RC+|Gi0mjWaWp!8ji_v(oUzH&
zbQ4}1rLql%>o<_G#9D79A8Bf~8I!zc|8Z*v7x$p3`1sVEqQc?=fhD)Fysnwyh8;cK
zeSN(h-TlMk6H^y1O-)WrpPLvNAp)8hn;2)(6le)547ZR(|L7P~g+_sfaWSK#4L^J@
zmmv<93_h1vx^=t)Dhqk#Yej{!hbbvIiH4{j;;R^~0~VtVn<cfqW$Vtp<_C|Tad!0z
z2#!uj%*-z-Wr=wK<4ST0Yg;>78(DbY+0x8<{l3w$bC<4MJ~wrKa%^O9aCBmPXmpfm
zM1;+Vj?Awj2tc%m8prq=W<cb4^AF$4)1fk2a*vlSN^=qfDhoM9P#Jvw7nC6^*-g)%
zT<}P)A-9)Hkm(lk2LwB0vW;=y)=A!Jqw!`F5ZSVYr1g${hfdnN1q20!$0Q_W6_v^`
zqyiLfZc#-I6+-MzXLDmiYkOD!;KYS1m(HEPFf}$z8Ue$^4gEqgK^qk@G-r@{8K{hn
z4Gl3gbG$}S$;r92PBl4Ja!;mcE=Kdbq9nZM^a`kS5`ZqGYUy&%wy0QmZsD<9LvAle
zg*DGx0bnyJ7E}t=FzUw}kR4+ao*{X#=g=t|&j7z*!olR^Y^EV$e)95i@{1X~+ej|I
ztGA<}u0aN;4v$P-ynw=;9+E*Y{R0DoKrl24;|ww?Q|8#=bd8M-k5ftH5M_h}F)>Gr
zO7YUDhzLSGbF6|&QMxA=M}^s7OTi-7klV{qVJSG6m~EvXv}x0Nqb;U*w8TH;4oo&n
z-g@sLTaUo-u%HNaTrxv)^0Kn?^KuGuORK7BIiNb&(%jrwQ`goF41?oSlhYS3PERoL
zgsF9Xf&ysZ<zXv^M-ZO@ERjSc!xPg3gTn*u%R;4-xy3@DvQV$wzrP47-PO}-<cOJ_
z)eD(Kcl->MC9~LbPi(~{*|K#j2})zUH?oz22}X%?+qO$K@`STbuqs-Wkd~O9n=jLk
zn3t7TP)ez%roN%Mp{c39s-m`0(%6IJljqJ|xG>HLnE}A)?MHM*U>WQ&T4e-{G6eSw
zj|$U_4+B!Gf=aF;K}AdQ%1FO5YNu1-l}8Vi{$pt@{VXck2+#+&6*=;IGyk)&$TgO}
z&cfH5?J(PFw#|66M2L7Q8@Cv3HZ>y6L`IV7b9?unvUB$gjEsp*(PZQl<g*im_$oPh
z#g$A4t*x$Ys&A~RF0Za9z27x})x`*n3?Ljt0sZ{~2O1WOG&IZ*Ud9P=ID!rqwi)X0
zQEZSRK~v+!Z=-$}rLj@|45X8w2Lg+L@^*3;-p@kH{*(z=c7n~PcGYj@FMLWlmTN41
zorNzq+rHIo`!<|4s)nXpHg4ErvI#$Bvnl04hA-?tic$9T508mUO3N-NWNJxPMw(1}
zFQ}-kr7}a`0aH;cYN?C2we;enO<-vT;1Nlh4Gc=YAL|1sI53!J0cC8M!FGe-*3;MU
z!*@}(*}^N!_;0&wOS6>H$FsW^QBf<i2D3j^tEVlPuD9@QeqmJ1wt>oKYVX8DCQ>%t
zynVZw*$(PHv>P0@baZtO2n~;pPt4HdXfl{Ml!jW#FO{7Us_N^RLtI@|Q&ZpC+|t3Y
z)Ugpb1Y<lj*xQSKg<HhU1(i{HHAcsW;UgfyCc!Ly{dGTl7f`Y;8Y~Ny;ocXQJ@mf7
zE9wuJsb{BF<fuFQ%b-G*ZSxk!Zx9}%Sj<c|5c_O1+qn}|_Uth~Y;n@o*)u3SQk@u|
zoK8+9AvrO<prDYUyJh7il{GSrnIWpR{AlYMAWj_V0~Ut94+=UAG(&{?hZIDJ1jdJk
z`%$%Gs0W5n$+e)u3@!zgq9rA0?jy%Hev$Bz7n1seX{J*8ed;IU1{Xm^uJQ8g$Y0!s
zUEWUj1wW`9qE6^xGNaXv>iWSw`;VTqa`yD|3kXk0OJjs4!-f)5vT_R<?N?P?np;p=
zM<J|ErYN=bkWA>s-t;qpd8kiel99o_K5P@`@KK0`rp6~=qJc3uWq?=p_0|0FU70y`
z0bZFXcw1|Kzs$Xw8EJ36X@|<4?yk=MyU+Y7xyJIYvwhnZwC&cd##_x0BTTf}X7r5N
z_8q&>wfm0X!TI<FgoZ`M#3aTiCMla>rDx_cVYVP&lV91`)Yyd9WzajBgsxt`d$BM~
zcf%Uvv@q1Krxy)FPtWKm5u%LX1rV(GFv*6V>L1G7>`dX6W&XFHd83P*u=rG&nf9en
z*<xn48C<qfTIZ*hUAAxAzH|2;w93K5ryad~0|LXt!z0)tjNQRhanZ3U>FJr-?7)&!
zSl!gz)QY}sZ<9h{Z&wSeCi~GReaO)uiS16xL_K|yVt~*w;=3U^K&8x~(xGyJ=<q8<
z#q0xIZ^n#&4zDoh@$+fhHc&C$C0w!{g|b;ZI<xIGV(c+Lc=*WS)2=~5{vqtK5gx6M
zq23W08Lf_vO-jjRs%3sjmFSg*hNi|=-sb?V2qYG$d>|gAo)}2h*3zy+g+d}p7qm$~
zLM0;*Wrmxe!X6)j%4ETPrM&SK+{tiPg+BAQ<Qj5IsavdPVet0++0AD3bD84XZrfqX
z*dw#;W{g0hn!IQ4p(DqRp0)RliU<}|g2TeYnW7a=lY3lTVp@iT&6RWmGJuWHxl^`E
z=<V$2<bYfYGD0NXqs&h2;Yg$gzYaCr&&eL<%#yilYr`^UF?aqeM&&bLJUcOmO2YLQ
z)wVqDxIBNB9-VDlOt){M4Pz^=+?K7I;hsIa%n$6}f9&L0mw;G`Vc`+sp#gy*A;F<x
zkzrBMF>%Rhnu0=%bA5di9)Gj+Gx7N|pG)e^o&69V391F2=p<j+Ge|uiRL~{;2o#J$
zzMGDPdQg$P?ON5uSI8^RK={nT94axl7X;GJ4m+<rI~+CHvTeKB=I!X)?c29*GdA0`
zdCR_i+jky1y#KhBy=N?5TXK4IOmswWu%CaRe^79^Dke6L)NOt#3rHKA8<hx=CNJ2d
zt3&!%y1J;rW15GMseUQ2Qci?J=vJWKN^KEdp+M5r-rn5YDmExH{k))(|AGV^V?FY*
z&%CcMcS5cqx5&Hm?|=SiAu7PJb&KhaZCf{EkawDH-Lch-%IUs?$B$Y&`^0GSvojOp
z<J2;WF3``%KL}<Ci;ZJLqr4&#l#R_z4Nds^eEjT9!x%qO{iOGSVQ6Sn=9&);()~q2
zQQNSfz$5(APJatgWtT`$dfIt?)#OzEeQk|>?*4ed)YRI{xkq2kPq~KNLf>8(^UNK0
z&CDH*jp3&d8}5WzHk<6+fkigky>sV5i~Yw=x%kKA7MJIyvR7DSlqw=3(BD5eBs?-S
zJXW2YmZr%sEUzavY-phB&Zpl-Yr4#P?2u9rZXC`l`V~cjyV6H|C)$|#wP>4;PFgIP
zlG)lg@S}ILGcvTO<SvE^U>tvARe&sGZ{mKfJmm3|K(;DCdtQ#0NpcOj1w7#WkK|b8
zkNF)v;y0FWl_NQyc~nMyw{6*siy~@v+t%IN_wL+jwr|g#!-w`BJMA8kQCd<_oD`!{
zt0SVKBEo`0f<i*r>nSpvv|M^lK^Z#(z%Ha%dYSvs+S%Vnw+2QUCXsA5*#pVN5i0h>
zMs&BJa{#WhRr=XcM=eeLpu%=o3a@+y72ZCqlDSIWvF@E8&y=I4wQ_%aEojJj-E+$U
zW)2mf#|l?uTV{2hKH8aOnXNpWM`f&d2POxTOlRb_9lN&fp*`||xw*wrixbwNiMVTd
zS@AK^>Ns^wlu8vD6&xHGN+UvaJg8*mlVho-Q=g`<J~1gBc&ohUwr+TXz=!Fp5-JlP
z_jk2+!AZRssP@jzj%IfEk&Uq$nuJ%_4eJ~dG@bX3^zO{l@xbZnb((4UF|EA^rod_8
z6?v>VF3%`8<^23Fe$J6xLvEgrm0Cb=)Uo^n2l9_a^(qfLt|&j`&H_EMZP!l0X6vq9
zrn~p;WU<2jLq|?nxyGd@C2O*i<6`6aQb)6mSyVW?zedHzCC0@kWn|_RmRDBNIY}WE
z#nHx=J-vP1()EOkCYfuZWk{TtE=uw+OBWT_uGSXzC}}1U-q=(JuViJWr+~`DqNoHO
zUx3Q0W_iH3W*zr()1eYL-3(C6p*d7s-^L6=ZJuY29y{aNrhU{z45cMMi`_f7?<Bv3
zH@kDsR_RgMy~pCv5sMQ}{_!~)cIZrvW$K0O87VRp1}JKETpWAirGg40W~*ummO%n#
zLFyJ44HMJfOV2HWLoZlg4+guFGBo~NFaAt>M{_fQb^|+#HP_dIiiYj$mP7?!;q60$
z0PkFQMT?5|Xbzb#ii-0sY4vVzN;`e@z=5Nu)9A5>>L-*R?d=T~M|bYnxr<m3T()jE
zBla;rc;Jx5(IYlq(W#ouw4ChJ_}GLv+2aiv3X6!KREA}aA%M<eDt;*|fts4BxOa56
zwc@kTwIXp3?h0vrGEZz_)ZN~N)}d3I`BGw#TUzRBYXy~tnyNnGl{76XIWJ0(PB756
zbCR+ONJN5=E3kUTE6SPAu*z^vMbC>T<r;Exen&io?#e)iumcCe90DuFvFvF&C-+d0
zMI=pKySDA%eg_`Q&Tach9vnS-^rS;TbV^!UN_u8OLQ;HEVoE|{96ZAwiP15!F{-HO
zBn|t!7O=jfp|O>I1VuzTd(kYoC`i%(d29ywf)-cr@9S)9Z)?Z&FetUDnH>o0YGk*c
z8c<>QZnE&oxtt}t1sCi4d+E9U>e`Id7hfgUkel-zoQK}d1k32U0|)A&Efa7xdwZMD
z$$f8cxy9Mu9Xrq}1juw2?;|AKd+_ivi<8GK-F+fs<I^+QJu)pNj_sl80gj86ouhH$
zBErI>;;=!bG&!L)`9irMMsx|XbqQjF6$Y9P>`Ys44?-oL3=Uqq%p{gA^<*<oW?NVF
zDySq)gUb1wB|A$O>k<9Db0Y|JUwKVRK=6yNl55D#?G7JbXZcCT+OiV|%W54@mUnWZ
z<ve%LNsHP(tPb_TUHJHWrRSP3`H02w6OLYfp)m<5>@7!tEZZ8;zDB<=6c-yA7O9|8
z#C`yc=*{{D$vU-5a|X#;P?0XMzV2=oeKfS;%l7nQerP-;huPZN*i=K$HlwX8t12sd
ze)uliR0=BNUmYr=U9*$3jkSQ%yc8;4cZfz}ovf02V@@B5=}oe7iseM>MeYU$oGdIX
z2jG%jtQ=(B;ErwhwEGSmIdbfbrK@LHR9s?mN@7BCMyBk7fsRQ|Oo&TJNr;UI$4bYh
zWEC;@9_JRdSzXmgzdo($Fo~odJGw-Pv^23ch>%&@9=p5o-rB?!W;J4E1@qC%*w+Z(
zHUqT3N>rwMIxlwJ9=nns|5;EJ<b_v!Z%Y#BMQXb^e`Y7cf?<=r!Ycds?LEkHpW{|e
z-prh4TU$0^1(x(Ik|}w3{>h2VkyS@UkW`3?Ps_yVmvyMs=m}Pjp+cmwbaZ^63lq!)
zZ>X8Dh{TJ8LD;-bGF0rsQCV40QC`Y+ulX%Me1cj@oT7i_Le7#M>(4cvf9`{G<HJ3-
z9z3|xI9t>nUijIU$~EK`d}}^Bo<CX`Gw<2Gb2n>R_U<90vfteN(2>Iyr)*vQRiJ^}
znL#&S7JED87Z+x;_YpnAaZwSWAz|!g8kdl+-NY4Pz!1@#KsHiZScZCW)^J_vki&&-
zCE<b$2`U{ejcoN=RtYR6MJ0uK*`Sij{_|fMDw7xPKY-pI&8gF*hb)as*sb}PaQ<jv
zbhvjnX=~Oiu!eB|!Tre3!4p<4z7a8r=`y&V@=tDI5nCmc7Z+yI8=IIE6B_967Z4m8
z5fMu*vADd76}mO`O3Q{s&MZhB>J~$dSJy!V*w9Qrzi3?SQF}`hik6KA%gY&vPiKRm
zlAIV1D&rTjz5-sEoVpGscdlIQiOY`*ocIhZat*nuZY`47oammNKg&8fa~Zk4n}o`N
zeFrR#AF*`s4vI}8v82h!%*jsAE~zM>E3l-Px&Cb5tBwo`4Db&Mjf#p*rfybVO@fjw
zDkXB3+)5AGgWhh$r&A*17EqCmDkZN%Cm}|;qO`Q4jIFQoXqd`q{J~>(TaTYwy-ZXn
z+wI={nfJQj#MIFB``4~qoan8J3T#<$UUxW$O8o5?JsEl2cYXdW!n1Gxo&)4)4<0^r
z@ZgbS$4*&!h9%QEnvs>BNT6R-SzeTrS6*3?pG)2>IZhoB8Wt829ZLstW_Dg>J){50
zQ+BYGMmtDgo(YigbNg6l*M=^pZGjwjcVCwz59({mOH0_0r7%B_)MQ4jpb{TD2`U$}
zmRuh+zt%_DOKbk&B1fY==Pv_FbGd)dBG1Y-<d)KLZxK58c>d(Ry?b|??>=~#h3khb
z1e9Zzww{q`#Il;~tkhI`o60K-*+HVZy0nnbH!UG1Iy^Ewk|bqHN=8n81?9s=dicq?
zAvMx)E7_E8vP%P9on5kMsFm4f*lE1l*0x4W54*<|=Vs?+rKhJ={@^ioO+B$(R4%fY
z)*^3q;i=AwNdd*PYT?Pb<2h6=X1t8{9oV;<m8SUl`wnA%j-9Y|4UCOV$;{4y$#YV&
za*9hT3kwPh%F2uLsU2n{#j?LMUVmy@MmqWIO4_np33Kq^aOfqu!X6S`ghH~F1iH4R
zwT03=4`7wX#=2^Dx8?6-Wzr>>l3ekF$M`=n6K|=;mc=U<FTM<vix)dGmIOt)#&US_
z;>F!qWu)gIw&&Q<BgaozI{4GRlOY|(1$j9rmYnQ7*?}lOzc4pFDK#^Rh$uQt6_=8x
z(a@SuQP;u>vX+kaZq{A4)KeEC1J&Ivt)`$t1{1r3eHQ1oMXWfe6q4U#bMo}0#Io-{
zj*pFr29@zknkCmA&S&12b<~!W<ypP>E9Dx?yN;OSgXXL?wXisO^n~SE2hR|7bbJzd
z*}CeIT=tX6Aj^`KihY*7*;)M;r;dz>j8G+J<d+r|R#eruklF7bJB=IH#1e0o3bmqh
zapKz8s;9A@c6Que$<nnnHq^0uX?Y2}LWqT)E&Ki>GB>L6uN0L_9dVh9gQ6g^JXH2e
zHvgc-;loFdp0GG&ZDr>ks>0XLEUjv+ttg@u3ByB58(5MO;$`hiRCrj3Dk3sIEvK}s
zq^i21y=SnyyH7yD##B-a5$~TgN>dZ@pH$}=!V2fKH3LyiRYgf*q3lPm!B0sj{r)3Z
zC2IVas<CB$hD*HNWu9I>uaIIobbyf<7DtaCKXLkurHvb1O^IoR6_vFWSc@DCs3tux
zmqcw+N(#FuN0MU+iNFZq^0OmNRa5uC2ss0oqYY=isIaKKOtyMzX%s(((3plOG7XY}
zYalYHknQLTa!DT~qftt}{|Hbb#z5t=X36!;wC#RHB-dEpb?{R5i<^J&`0+C*PoFt!
z;~IoVpO%MXQCwD5fCOdd=9Lt)z9TI?B>`B%g95`tqQWBM)AK7}me&3;I#Y&*I;zVH
z3k#)Vj#X3y0aZkQz(X#jQFN|UqbqAF%S(%kL4~LjP}GI19;qlEjQ!%3LuH>ivmXwV
zeLHsYsHMHlX_lS_g+wNkJ}JPf#m`Td(ob<oURnkX39+b@u;5_cN=$NAPDOcHRof6X
z8d#+cFOS$DKd%U%uYycLaak!DOd`no`bLJaG*p*Wmsg4dR{;N|P)><g=dOCFiVP1M
z1(hqAOHKrkX1K40<QmJn&VhsGB;O8O9JDxg=8ToK<yjjSFRy^uG}^rKi;4<za?<k(
z83Iw2pOu~z9~psG2_w}X5fz_8$6!TCdD9SW*2qtN89NB(7v!<ec3~NPK9#g{uwOQ7
z??^DQ{dgT)@3BpE0bu87(vxH3G0EAh9!61?9Qk+E*i7b<(<2s6b@+0}a*gF($KnvG
z_SlIdhmRgdeyq+~+d8>>gvO_8vI{WH**Q76l*4Lj%JMQ(*#R~(JUB3fnzJf4EvJ%z
zxxBQ#Z+K#goON?GTcG7(zY9x>$>!Enpkj!4%F3mIjyWuKvPW7mF(KVe8OibLcru=u
zZ#;xmLIjnonUhK)>}$QtWYWm;u5;+v!Tm?bzKL2nb(Y=G>={8E8K2CSXt^1gDd}ki
zWi?f0MFpB<a+Hyg!QmmS*Hy<SWfwIN6IYj1w6d<4M(mba#DiwsTr_Y+Rb6d)QBg@L
z(3F-|*HqP3SJeWF@KGM64no2Nj8Am>8xN`I2ao(*H8!jHpMZ*nsWi*G&Jhb(<@gb{
z<2rlhv?aZP&Ys@Bk?{#>>~xnLmz<iB#}3hKd7YPyQi;GMM?}WN#Kk8UR8!Sysw=N*
zAD)_`Pn6tKSy4WgytJ~iyaL83Dq{1&qJom5vZ{&-_I)ic%`bpcva$)ilM<8E(W<EA
zHy(tA1_y!4=xoNgB$B^g$^ez+UFY!O!$*!BJ&H{}efrF4YbQ4^Z~wrkgy@8nwB-1x
zSlrx9dL}iwIho?EL`Jh5hWb!^T5(-lZ+k;sSylJY<T?5cnoy_3cztaAT2WXco6Q%M
zRAGkm3ed7;)m3GZJU|(1G_*i6b%nfmWYQZCLPLTBhkvFTy_Pxg^&p~bzIIakw=<dR
zw7lyaICS*bQ9PAXCr{g2+PJuR1ccGCAIE!7N?~noOjJyQIyEzwNKvgOZJQWNa~zSO
zrbJnL+1k)DJb8X<l&oh>Rdp#CkoqrW17%v<3-SsI3Ucxb3yMoh36+cTQQfQt!l}g_
zWb9;2WZd^21P28PDr46(CwhDBn8#-KOtaX9K093OplY@GVy9m`ck<6d+OwI=0F&#y
zoX8xUI&tdMY0Fb***4GBGe8<9N#{#KA4sCZB4T3G(zCNNlHwB*B#|3Ojyo+aySSRQ
zK|P&qovfG}rFpi#y1cxo5LY-2-hyRvQPmXLNanFZv8a@N2^H%@E+R3BSV|qMii}i$
z??FglV8GB%Rbw|aV?8}~Aq)BC`9}+%k>k~?Up%w;<CA}$Kd*WBhH{<xGfN#YL*?|z
zGiNNVEv;-ETs{55R1vD^*cf*9qQI<Dt0KZ9z#%i8{3P#(JZ^k)S~_z83d(C)zueZ^
zF)}tl@Yh^hmW$HJOiiYzkkm<PYKA5)H6=baE<S}!4ZB(9W06@-mzIe9u?-<j4iVAc
zdk_>9;Qu@-A$Gjws-6(|W_3FMH4G$p!A07)z+=FZS1C{S^i;`X-K!L2d9AtjwcLY>
z_M7A7qhf1~OMCjXwY9Civxk>|aHKjumUZp%lzu2K$HM38L{zWLGmzv#Dy^j{sfkig
zEiJ2($xWnIT3ef{%kwidsYwaZsz`ML*@hUzjjorl(5UEm%5CJBa`NdSg;fwj0_B*<
zNMQNigFy0~pfY+>w4g{(NY(0|D)XN7)gVy?I_Y*jAt5{iRDw}YI&YZMcDxo~>^K=>
z9y0eTfk)vtJLR?Vdf^pxi^4G(j4xcCwzac5ebUm>(#Dp~bn>ydXYd2>JSmws181mX
z;^UHdoAK1i(lX$fB+-_M8QIwxX_>swVzyDQt}d@A)FjJB<xy}zRA@NHDk>;6Fd)!B
zG%_Zh{8W0TCNCEjV%Om~HMxjr!m03x@4ge@@9#VKZ>rH-nd9gcG|B2J^QzELIn;eC
zx<;OnoA#a~bCimCMlY?{+<2|_Rot(ZzoFb~wZ}<xil8EoGT*zUTu1xN=iNKl*`BpL
zYh~x=?Cuv37#2<Ho-A2LhVZ>cgAq-RPe?+?#>HcmD26Z@1ZRUT%0%3-XzGikrAkWk
zi}KRouUK_tcz8&VZ(vAhcqmD4AHN_!T03Z@OV(s&<x((6rf~`$M5%<bk>_{c@%Qud
z8T?n(=<Uo=?dNQs9ui^>FTfvj-+bc20Xi<w9tkrD5AoU%?F;8$C9I@yjPMF1W=P?c
z%=d3A*U_H-ynEZTwruZf>*(R;=@%FhrA|r9$&`kDQrTIwQKY3K7fA_Xe_#@ZBY+d{
z3jPlZ=JgTu_ot_%OCBaMUKJ4<6dV>2=m+@*`uY38E5QN5A)&#fc`2m8E2wM~xzww}
zNdE>2ulUZP(%o$v++DG{qQcg^yE|<)k9g1>%mbb=muKWCjmL7@w!7Orjn@PRSMY1P
zR|PA7V>PefXr9Ch$s;W)^XHd7vbD0sp>=ffaQ6xhjEKR^q>?*8J5nu7C9RT@l`g4}
zq$I#Ws4&a1YC^h*FcgB1e`pka8>F@ADU7D`G#LKy^KzHXUcJ10JbnHBy!?FwgM-3V
z6y2!hQ^b$w_hV><k*<$mc*WP(d+=XWqjxmIE3iHvvfSpit+^;&Q6svKUw6b0(JLY7
zAYlyct2hwG;VIpVpXUe7`*)P<Jb!kvN7j~>wl;Q7?w($LAt8}?tqJ(ES^3l^GP8(n
zv99SF3h;@k8RREX5Xs5xJQ*Ds9vUL3u(d4$k(5q4Hzpz?G}OnF?QGc(*VB{TZ@t+F
z*N=^H{ewe;G4~0it>WnWptS)33Z{!U_&e|T=}@_=8JYX!bW9<f^NbcAKRfw_4>V8j
zF1XI;{ko;)85?UmCl4S0fRNA#v83@ysp%Rb8Y07dqzLVju7Upn2?L##NgGb0wBSYs
z`*~rsLZV^`4^qXBM}`Oa`+9hJGI+z&!`mB<@#P3?{C#`^6fa24I&pLqJyT&J!9jij
z-+6~^guMs;MKyFca}Jf@IqqMG#KPmxdpDo|TqdYIyUypn^rYokYa5m;vxb5EKrH$*
zF)1aTE+-Au9(;@(fhCJW5+iwe7?K>4i*c$@v_%jbBm1FA!lM)69z`g8`~btx+uhsK
z%Li`p@$vL<^Y%obe8bo<nN7&zk}%p);h{kxf&4nW!gHX~cdt$Jx&P)@@nlll(|gOj
z&KWB!TL(v14{x8q;IODD`M)vA6jRgF1q&Qh$?_MLRLLIl#Z;WLGg8#5D0<h!Ljrug
zynPXpKng?zG{Js8L4N)y6EN}h^kjgIyC+jSz1=)LJ$z;Duawpj6Jyjk%t16B`g_4E
zXrO_Aj_Q5q?KXV8ub0}MN*!!j*8vlI2PZ}~`3K-@gvB8D>Nr*dVSBUkiIocqbMmN#
zHP$y&N+euZh)*9IMqff~Y;;T*oynf=o<2bV3LZW_LB4)I-bj{*x2v10i=(5Xi;J_f
ztE;=0uX{iUIV)Pn64kNM;pi0lR6W0QAGHE1vAt7wA3XT*>!$alHovUvz$$jm&ivc{
z0i+(oA~Blm;)|b_oSKziAo;{xQVCQD>#OS<YAVPmWTq!#QsVgB<HCb{y}doaz{ArA
zeBc~EKhd_H9-gkwkdwWWqqC#Ele4RfuYX8HWR!R=)H-PJ29y9n1wkA5Nm)L{kynYV
z?d@%xTwT4qVR1e|j7vB@lc@<w>6v)-q@MD~8`YCbX=8|DeMJ#Yduk$Etg%;ad|XtJ
zudk<vm%FE@iw9zYPT`}6Q`|i~T%2889bgtGCwm8HU~%^i5dlq1;+Lan@DAcvJzl?$
znF5unLX_33M7DNLPA<-_KE9Y)l8>ZO!wC#i&@QQ|h<Q$CZb_l6U|{xWYi)HY{wWSB
zd_s&zZY~_v;)CMw@p5<d@bpCidwF}gySsa!RGi(MWv_WBFmZEsar5;H2NlNJ5H3sq
zdq9AntAdL6z)z?t7E>X3b;yy=(aqhR57|G+H<(61K_xCRmUur=rt)ND7gja3wh|V%
zHB=Pm=jP^+R8XUn<Ktt)!y*Iy1Cbf@st@TZq)2SBi>sTPtA{Jx;$ROjPDqinGfxNN
z4`Ig1P^cn;{Js6W9beb#m7g$=y>@Qd`780$9X){C<sX1bV9{7O@02+!Now)9Fw$vR
zxn(sB$fFUXp{le1fy&FuNQ@y6Qh0?0GQPg>iJQB(haZO83oYXg%pR_;&TdYkSR9>z
z$JNQv#lyoVD1s#c>Lgn0LPLE0y*-^k1rZwj9|Y~M7NI8n1B1wj;em#P(yXJxyu>BM
zrKYmNP@RyPom*Vd*3#Y8QdLu4ED8FYyv!8xwm9%)r6RG;0azgq)Gh9sCvk(PyR)a8
zi>o_W@a636;$rXOif(bmB@*GJKBkTcBd_A_DZGNO2P&VwVuU^k2qGvU*B-=Lu`pI$
zMkgkbN=ZwQ2q!H&zofjmrL(=UuC78duXuKnflAk8rsBJiH3$s$Lyx$-d3yMG@x#r-
z-QCUA0XD(#2$x`)T^#M~g;|(M7@H7}#}XA3=;w>5y)GXAtB8ufFHLTgja5qZI3grM
z6;BUSer{F@L2_bpMs`toZBuJUdtF(1c|j3fas|1XG|56{rm^NhN`E1N-fphQkeD7<
zl&*)jixWY(Ev5&-adCEZb#-w-wYYf(gwpM<CX*c*7>KLqE~o&@E66K>K>@+x{I`_B
z!z1~YPFf0NG^?aY43tw`T3*-G+1XN4QzBhTh4}s1X>d|H=|^@%BBMZ#5s`6rM!$j$
zEa5JK1CKa3I@sFT+d0`f0+5S~n|DB<G^MJEqJo3`aa2Hs{EFYut0zI!cS30^=3k{U
z7)9zjAvGtbn9@!@(;^C38b#wyQ%6U0EfrA;Jf-x3(U8mx2@-FtaE4W=UHJRBySccb
zM_gSA9$*a@M<+)II|m1QM|*om_{7Np_r=veh&Eml2_%C<#p!c;U2<`+A}VCcRP+=l
zuw)E(A{u`pJyQ}1^bQmimr)`sWqy2Tdjn;zN~V*7OAhg~q-co<BV|=@L|AAbuAGZ2
ziq!>FT%Cy_@D1(l?Cl*KY`EDwxj4GGySVy=gp<8Wj6+EW!6d#8pb|hf`_<!>xHxi3
zu?dOvli;P`Oe9HjQ*n7oF~H=q)}@wi9Gd<_uT;~6Ur9?rs$?l+NL7c12LuF#_z@(F
z2%%bCaPS@N?C|j&t?h`#fyU0>#!lGA)ydU2I4mwHJ)TwcQ4v8QL4nS%zr$ii|KVk#
z;v_pjIeit@>Xx3-=l>b<2C0d035kjHcTv@#cc13Tf)aY|ON$DMO3P?RudB!3Z<Mx+
z%JP!(9P;$IwNYWAK>=hTB|9s&2R4CAoE@DUz`@qe(bn3Inl&XR;TSsyXL}TmZ*WL#
z0xe`QFepkozztOJahHpVQO2jAW_%T>I2mQU1eMgZ)HGHAr6#8&G0uuCBDt09d@|JK
zl~v_5TGY^L!O9MXH&G-N-!?Oq^h#8CcyIs?7%4Xo7{$ZW1z231ozNk+ww89bb~aX4
z_Eb}BX(>aqpm-gf-Q9hI#E+vKL^(ASRP4U}4g<IYN0!MedR<yn1esfUw?6&UNMRje
zp{|S!et??poR%5%^yGyCfE?+b;($N%5>(PsGg-OBteI4jO@NY-F12AY2q=;2YDTNn
zR5!5BwxzMIvP63MQ|M7b1BC|Re!1eCkR$LQiQ?ksE~?hv-qzZdIsMjF*0y$bwj_mZ
ztgJZz6gPHT4h#y5P{k!D#L8lTU_k{?0!Q9Ft^BJmxl@1;MC4`!Do(c)aGZpFGJxb3
zu<6cq$@4GV>7G)q@={ciGsO2ur7t%#lN>GM@mS$O?@DP^ZB-4ON=OikY?~Tr&eo(*
zwur`Dk<9nSqa|bD=1OJ>NRS^Ci-V&*tYSkk#RiiMK-SiF4hRt;qO&WR;eY@ZL`xZt
zOioC!zb(81EfbY4`Mh<gz!|rcw`T+p3Mz8vB+LS0UA&BArwm>+f24a#dCALANg<Cy
zc7VJ=7Lt=E6?2FV3zl-QB?S$Cb@eo!*H@Nk(v#xIL`PE$4fYT8rBveS?(Ir|EFK(D
zG0vI`B4mq-B@=9iO0j`&fC$Cnh%4ji<I6~a@Gw<WBo0exNRXe+7eYk<(V+rByy07-
zeV;?cY3^KxQ<o7hQSg~N(!G3HsGwF@NXKa7EDGjDtWYVY9}a)5yb%vyM&(siFom<O
zy0j=chKM&ZlI$ezI$3;A0P%!Nyggi8U>aw!LbxW5j$(Hl>>QCHTPqtIYioNulnQwU
zKVQE<(2(W7At3?5fj*Ysrp^qn{P$%^kSJRnDnKINT?$`3$18K^GCtJ<MTKGJj&x5g
z6BXKb;1s5vk&u)IB|7>_%4kJreMWgrHA{I|4p&SASR!dU%ERQPf=IR!@3@da!1#Ee
zRh(U%@KTgSle3eZ6Yh$gGeug_GIll&=vo)#&DYx(?<9ccj9`LM{{a6p-+n-qD|mES
zs3-!YMMc!A7L~4NyrSq81t~cvf+bI7EI8t^JhePjr~m^Ap>SRSrO{Fv*%)P2RZ(46
zQ(i{jQgIQvpnOeQf;v$xUN8zFFwoo6&C?YpR`S(89!_rV&W;!$2Rv9uSjGWM48Mp8
zvb939D9JcC$<ldwk&Y23KLEb*4?Od?4?>`2p`th|A~Jef0|F{tdU{4q&m@Q!@RoJw
zlxG#rnm^J#1uDwl`dlkSM@4pSK|am;Ma31B74SzDtG%jfNL`my)KpjIY2c&Gq{IXo
zomkHt79JR&SRYR;F)9U51vzpjpGPXv9=`-|>}^GWz{M6j1jpdP@lvu4#L0L!9$rL*
z{1NYfIaK~>84{$^q%ev0(|+MzQ93W2`w|buY0INEt5E5*rb}2l9hnnOk4}CG3q5j@
zabPGI(%*wK8ze<_(rpNhyEDmI7bJ+Xm^%prG_8}Jqa(uOXs3jQ7$I@soRk!$8)Y+8
zkxZ`l@RFnoRW$!&e@kB+yz=Uy!V*+c)&+pV^5mMbl7jqP`iKkY^2^DlD?2xbsUp<d
zW1_;TwTB0UQU~<H{=g!x9$p?K^4KrOopc*4;sgN;5<_aAj0!h<G1%_TZa!po!Gz+F
zr?)pn00L%jZ|@U=N@(cVtA`2_R6u}Cmuztn!4ECxOeJOhCT$6r>kQf}$fHQNeMA&3
zDc)}QZf?}Ru*T?FZx3e=7ao$6gjLA9iOb@67TIwSJ`r-p^HuaR-i<4-c5x&z<t&L^
zcaM{Q`yd=xM*ndc67(g+;V<}AP@!|Uh$xxN38`uZEzxO0%9^M+0hgC`2(kFGQIrS6
zA_B<Z`$&3;@EEU*FU$@(S}BQf?}T2#;P8zYp>iGZ-W*ZMKtR$3o$TU4vJ!_5PZw-l
zk)T%<6?``s1u0_v9I2$_q?F`z7J3jY#<DtB1_9u<F)&U7WFHY3)GO~#-YMchPQ}Fu
z?ZO+C(hq6{F|xrL5jmq}939ZY&TjZK{F1vw)y_7c=3tM^dAL~o%>%OMp=1BwtCh;;
zzd@}O6et<CYz?gxq?+R>WhJL3u|tEJ8i@2I@vjHdni5E{N2*_V`A*!qd59$Nm}C?8
z?o$21X@Nn|ub3m=Jr>BB5}d0u5doOMBJdOaGGrIX%{d<g6_KF-_R2{RjtcTqP?)R9
zOk<h|RY69dNp>Iao~>|LV@L~I1Sv&aQ)(QD3JBo8VQjs`%}13e#bik#fC${-Bnbrt
z9Z<28=N(D*^AomlKpo@S5g@@*E{Ff-AzT<X1}b08qK>cZuQ2qPmQZrkBpnHIXm+FB
zjlK(#N;G2A2pJtoAQv7?0h!V%yaA)g`ve+3eJ5a%+M^TsYLN_U*ud4vjq;c{{<eI(
zieaLvN@Cm5$pzyi4xWu2Et`(c`#=SH1yLzvK~HW@sb~^%Nin4R(X8Z@7@0>i1`W3{
zst^iAf!@9tW7LDI8@ynLP&iO^1SF9d2Rmo<EPBKmV=P4ukh4e6*gM%-W3t6ai$vK|
z5wW#C>u7V<=8X6?PM|^r5jp<jS5B`Kk+&y(otHt!Cpv`XKeT*O&j@Gj6pc6pxYC$}
zN)a<63Isr$SOX!B2v!ICYh&+Bn#tY~N0uxc%z{Z4CL#=iee8LNbb$(S5`nZW=}IM|
zYv<&0;BOv^c^m)n(tRtx`*NiD3xAy+`ywPLJ2f#OAy!4JPDmiFCBZby28Pjk6C!RF
zLBFpX1$D3xn=F2;SYptD0YC&aBsWWL#m130jwF%NcP5Dd5)Pzqc?Qjk2O~iM;Q(ma
z^4MYT-#jEQp_=%yW{KsL)tXPf9Q~!gPi3Q|K%BOegoHRoLj(pA(E<(A5NKYKk|OPL
z{sG?P@ZBYcPw<B>rLayq5)Ke9paX^slZ~ydlcNpHU=4rpo^7nHU<{kHXX!ArBGY0|
zq$mkXJ1cuiXm(B{clZ4@s6<B#D)jj;Le-j&za0Igzh73SEPKnz)}%6rlX#eRSzrGk
zX{;7t0%@V83{44H+%z#jm>l|a&>aE`n27SUAx%q%D)K|B$x8fMB4#V%Wver1Pg`1A
zos?&7Y^{{^9KgUYj<C(Hzkb9dmzc@VLFJ<_N1DIz*GmZliy1nTMe05#lD;+?xTvE`
z(*?Nr`yoE`htj;{>E(e45h~MQfTB>cOZJX7_Amf!0U~zxR&WJ8BCG*eESNZJd6Kmx
zCs}s{@ls&2u_PHqHBoRe|7+RdJa+0ImgbcYz8q=(!e3`yb|sSwa&oiNGE{Vi(&tA&
z>mv=;KK?#bHvIj31N^0dN$E*JySQRgrR;;nRdSHlA~i?{6)`JIt5a6wByFt_oU=Bk
zEzg`i!wNM^D;AaTWqsC~_Fni2)9i?0+V|IwWair9s0<@f)tdLe9Q~!gUs+RIMWoDn
zrnI<7s=qWr`gnNz)8Xdh=O>vE+EPdzNS7DwO9;^a&)i%1#hqs9qx%o^?(cVh_wJ7L
z%<lHiPC6Y!i=uFMceg4Em*DR1?he5nf(3VXf)fY?LfpOQK5r!%NTw%up!ai=ZzoVi
z)i<B6hx49u-se2$yznZBvaSfoU=Cm*HiTXRGO!OA36_i<dOCrMrL~oXH9FKRnM^A?
zU}Irpjdcc-A(W-P4WS#fzI%T@^Do)T&?^=yIJWK!SMwRSFT9GEJ|1@c%kN4%gRA+M
zUaPHdtVOqWVL^6EY#3DaU<wHL;p6K^^uykeRznYnZ6N-#_Pz)^t|Z91I6C6f;lhHk
zaX@b?Xnm{=m<u4WvL@ZGct}=}C4RzW!f33mELjd1B{X|GI3IhR?{GeIO3LgnpfdRU
zISZA;FJ7*$XTJFQVeS`SPE|cTO#Q`wp|Jr}B;-2T>51VX(5eM^2M{S2j0A!de;?S3
zrw94#Nt8Q;l|<GKS)@J5*O0ps&VU$)r4`Hrsl1JimAQ>2RPb=WuoY{d!T8Xa#k91w
zf?q*N5qBX5IXP&4cbHC2m;GB*2H+)Gs2qIpIy0%#@WnUee(}{5m4k!HGn2pY9t`EG
ztpG2Zo)i;-nr|Rj)c_a@Yb6ocCn3=Mz!8xeAy|EQT%_=q9qpWmyTlrT1`}Sz&Vgke
zcD9JaHfXJ}B0iU_7yQ87!pg=9E6E0!5YLPdPO7d*e6_wKr^{x{{S7L8#G9~Cx%H*1
zUgcJ@%9q}7EBA}9lAC||AHaye>XIA?FA|`hfQ-@)MH?`PJ^_ASXlU|<&dnEf4*wvC
zM!~zmzkpsseu@;u$<5xu6~4sL77Gaf5$hms*2dD26g+H*xd0n$rVaiwv5qX@c1XuG
z_K+ltbF^3g?hcMo&HNiwSSOGjvQRl1D)bAFloM}`o*Dgx7ykOA+`m5hr3Z<`uO$A`
zD`*3&EX3%*Bos;g{ji1te2Ifa@PWhi1Qvl%C4odBtu3$|5ZI`3kWU4n3gHUiZ5;sz
ze5jSJy^|%psRN6hMCw9nLAHR)3bDu%HpE1_2l(&?VqKU$p!VGzRB*HAKeLtY_rG8k
zD%)SUhR+OdZ!5=t;T_w#UwUynUKuZ+`K5oLwzjsaFe@n;B7tCtNf3#lR6}n9Nn8+|
zeUZzB24apl91Q4aq8G)68NLMBJP2C26ch^a*&Q%q0Zs);Kg*5~d`aR$%47)9mgbfu
zR3nLVLXt}&ISE*H1eF|I3!kFWwe$XBp|bUbD~|lC&nSN39b36ydT}d`-0SH03-77L
z2#A8r_(W*yg9CyBfkZ%nua}QMJPaD3h>{QuF358Ik;afM^JO67gins73@I!`2llpB
z#D%~nY%MJzTCumbb|edoxM8d#1Rxt53w$LQv9?M?u)tC)02R!)&CUH3mCld<lPpv=
zzHpt1!;1rFD!%ZR+%LSgu@R?;ms$VH=WnaV__l)l_&89IK}2GM;N#<mdJVcA@E2t<
zOvw%p4?tlVYY5Z|+2Igs0LWZsB`U-whyftzlFZExVHZ)!7W+kl8F|TyI2c52lGI?a
z;Vv6n<iR$!D&O7BhxYChR65o^UMy5TKKX_3<!4www736-*FOFz_v3?K{2oJW?H6w+
z6HyAY5@I0aLYb2kI?>|egPl-ND9$mDiUvCu3(5uE9X^n#AX6b9+7UD@*#na>3oLAq
z;@cn|!!odtNY(;KkifuzY%S~%k&w6GE|Tv75&%Wy90*0KKn1WY9$P`}M|2ts6&z3d
zYp&c=-i)UG9Eh!PvOSar!Dybu<UlmD1c7FW#6S_Ec*GTkrG)}Jp-Het9NfS?+Tz2*
z=Q`RWx>#A+f;d87w51i(0vHjyz>WwxjEx15vc}I5maOfd;s8hpMR*UK5^M!SI0}}I
zp#mt5U3IxfAf4*bY40yC%*I?IQr3tJ0kZ<f8W!Le93BBoFj55FE;#faWH#0h@;7W=
z;4SbU*$yI$!|xpN*BU!Or1WMCCf$n3G>3U$`;1JM;9<!`2(rM)0R$l!k0m0sl@*9g
zFbj_GEBA_VeF>GnL%jT>KmL2f&HvZ^#RaHsM2EwDghd1amf&y*2EsteMS;J?P!Uku
zu~AUqKr@VO56fXfc>!NbI0Jk-)+Z<9IG79ugU+Bck(Us2Ks3gb8!R46OD5eMTSE&g
zJ1Z-5bApSl9nuzrXwC2L5wXnmv$>E}{o<87|Ld;P-d}`y;SleU4t+3ip_msAZB}?B
zls8ck5Id6AV~pVs@b|>Fkj1(I4#KHmA;EJJR>=Y%mCm$en3^zv3>xW~77Q#VD@!Jj
zBCE=h{1o4iwE!M-<TQ?m<Z!(j-`zuju5|hA-)AVl(kmeMA^t<ZVMJ&wP(Vcta70E%
zMFS=f{UEb3dMTJ_y*x?$ffgNtu8*ve1^g>E#+I1BhtVA7mgaOIVQ#^&WHATkbTe~?
znHimKX2xKcG656bVqwi7dnOk7p!(hYGF;1NcmLj%OOzSE;+i?-y-@6<wH=X$l!3@t
z2UNuX3L2s!2$v1OaBxr{l+<3}YaPKk5==;@0?vT&B_K?gmgeRR6EkCDGlrRoIcpg)
z&6yaAWX@!mnBXU{A_lyUIm4V`X+c6VvKK;ZYkYT~j38P022sIykW^^95}^1@#9*$3
z7);8Gh=>UT&mW2C6B&)h$)F%e3c%14NhIOyiGM+EPx28v?EYXZbW;-}O#Ojbn3&T+
zrkK;sjZNsLrgTFLEi^HNwV2^0jCrwu*TFx;%Jj5=3K-JWZx5AnG@)igY>iPGsmTy%
z$A{y{dq|pC4j5Bg!-%jJeRLiqRUs?@f-*>0YY-<)D>9}8MqzA9H#IadH8ZB08WHbe
zjB`Th3?l~J$jHEmfh7cMF~^jD_#JaoCh^7C7a;M~{_a6FuC*_qa>^C(@wU^hAdDI+
zLKjCirif;<28*Bq1Z#=J>WPM}AY4PN1!4uIW02KEJPX0KjlC6C57Kz79i|zBOolQ5
zDn<+(hG7awaA5$dsUe0I8UZL%BO}ZhGsCh1<6;4COOiRnbe-=WU>jDm_S4^UE4#TL
zKi(<7pB5G9^-D^T^XKLj=4C?1k4!cq76Ax@vC-p?`WW_w5H&fGNKCSNvUK1Vun@2v
zM)-lpU;-4nKETj7#6V>eLkyn-7$)QyCUIjLs-dYd-eGQPMu%4+g%GShq{G%)-#tK=
zVcq(-hYIGMV=Ps1UN)pFsYxk`F~sAdh!~0P7$h-B>jHe;z+5B2$HosSsVzz0t*jY@
zas(<^HCR2y`k1hWY0COI5yQ~f(9qPxMAy(jM^|6p2s18?a7u=mDdLa`!_vlrWW!(*
z5Yx5(`C$XDjpL|{ol!n!IVZ4{_tJDCs)a6>eCvjNoxoN;xxW(Q{xAy~l0Y&>l;DBk
z7#Qdjg`f<<WN;v8TTqg4DcBohBM3}v>`3^rHfLBc=<q2x7sLpk-pD`?#$gB;OmHfO
ziLtJ(A^8z3#@N)z*u>Dp1aSzcnA_T6U=scT3oE^Ue%OSmgB$0LaBxyiJRK?@Iu@jf
zI2pQ1qOd#>Dxcn8h$#s9`Iw)M`9n#`u}Mi-J?Qv~M)-N(D25JHY>}}G#0C&MJ49jv
ziM2h`%#;Z`F*YzXqMI1#85!!ri5Tc&)nJ6M30XwOCi*ZK%>Fcj?HC)In3*H5wP4yX
z;aVJ!>sjdk^TTFbo5xVu-905Lkdc1Win8R&0B7q&w(`mSP&z@ol8w?KI$<z<1%s+0
z<I(YjbGLvB7=N-UM6m-qI@B+aY*?ZYXklxCV9bC&HA9*L01PoY*w{cv!`K+cVFV`&
zY_ODcjZI-K`Ua-@7(h+801yldlJz4%TiGxy4FCBNMkQa}`X5H+z0}y5fOLWtbc71-
z&o9i!As%_TIK~5GcQ7^&Q~%;|G$<06m~gcIApE$YYzj&QTRpfE6uby3mKN}xNI~E-
zjEpdcTu0Z)%urVsNsA%Yijjf7KH`vxv5~2Pk%0jnzSa<<V&R+V7*0o^v9Vy%^^N}d
z5jigLe;5^(&3wp-PlF1%AA{3#(f^W$6FicMP(P8JLxzJM$&3dyD?=Da3heN)h#n*b
zBik5cDpm-{3{wPSSci!rStP_jSbo(6UIk#`Xc;pj5`4@MrOnMTY8iP8a500$SlE~|
zjMd~!{^e0edwcth^GAN=*RP;%vT|?{_i`FrVcico561mr5*p?|lhf)zr^F?~QZRc7
zas*%0e^59@qJl6?cxiKU5RsVggX9${n=xWCKrzJ<VvU)`Ix#}RVq$E7B!wg_B=*2`
zU?v#fPWIFcLMkBBG1FEM;4}M|$K=qf?f*$sK7xYA2dMo|ZY%HahajDduu4zH{B#He
zAgxWpWEy;n3iU&E%$-P;pfCW50=57qLcEH(1@<;b;PLqphT%(Djszi?_!6LDLVPO_
zGekJX+kggE8}<NnvJ+zBARdOcvILEfm+>!;F;cs0=feM-t&o-=Tv!CBvy~6`W58Wj
z3W9Pf8RQm=|8R^Syh}u62-1A4A1Ka2!-7E~v<ZtG!EVsf%-k3s6hQ~G*$wf{m;@kw
zBRx|i5{F5!#?k>gCT6BE9{6RtDcL|{Z;ds?G*gq{6XK<E+WfD_I2@#V=i(76PJ~K5
zip~FczVe}C0se%zlx%!~shq%8KD|E~GepzUF(@KFj@1)|aT&3R=!6GPi#nkj>Kv?8
z1xO%gL&gq@glUEkOZGj00C5@CVr+&rW2mQ%LDQJlZUCEsDVdtVSj^2}IAjxml>`55
z%49N)4fJG$Y2v~n9M=Eq2^mXv^U@J2pFR4=Q6U!cx7SHl(DA!*niS^1!BAi&U=cvP
zk;!F|A*Aut!`%fNWaKGi0fCY=hw=ghqZP?h;5Cd%?gk%=oEDZsl6(_=oZkhcFtFX!
z90o(U6_WWP05L!-04Z}LJ!3t6MF9aCg~I9Zzn|d5;{IK>&#*Xp`qfZLNdzpcK6Y{h
zW*qt$kf)&03q>Js4@l3+W)K001ZJceSVQK>RPbSusUh;}8<XHnTncNw;0s{F@_{wM
zMi>ke1|53>W4bZ?ELbRGy0U_bhOUATjg6DW?fk!=;?S$XJ@z9QK6~`lP)ULUI}RC2
z5)i>eC)f%?GKwHRsJOd1q2@!jawu;g8Y45MW8+JH=fqvW<HFD4a73&j#2i=ziOhIx
zXl9IY+{9qaU@*kTVCf(Lnd#`6C<+S-%Sh08*x7lhzW>)#9C<!`i}N!qj-GxkRFVlC
zvC)wj0)l}6SV7SkFNE@kA8T+3sf3Z*Ahx-nBCW9Tv1A|w*<eR#Y66!5lfmak(t_QO
zp&pizfxZEDL^!buJ_pGR_CsKz@D@VGF^~#t$cXat^U|nPu1gm<!vD`xa%$;5*WYJn
zj}AKe|Md~hUWT4D9GqlK6#jx#0iPX0<_mc`VQ>mT1x^L(97}65`_qg`w;<`589DzP
zP8Fvc5Dtz!G&Uea3KkQxI?S^-qBHPASP%ow)&#a<VQ!|aAtOK);OFP%<zi>2Tnhg`
z&&J2c#`Y;k#_`#suVpLPBu9saW2y$IS|Z{HvmcHC6o3`v;$rXW1b!AgG^vE)n-zm$
zVTNP{=zxtRnF%W~0T{YiIR*w=dZ1ab=g~)KGBD63&X^dAk%<}3YXYgOEXGe`=ixnn
ziJk2NH}|F3|NGhG<mAKw&u3U1J^fm!kTFDrVnXedOm&Eg2EmV`2p~c5g1#J_3afZ-
z!z4r#&|or1VulclUq8Gj_J+u3iHVR+A!{LF2Y|(7fY1XH0eI-^njxh#G-2xKsR#-1
zQYl;%_KTM|IVoHhQ~#f5)6>&aw|S3X`0UZwLM1US3e+{wz}W-%ij_o;!hw_psS5IZ
z=pRunwX!wGcPkWktl>4WouSjQbnt26HpmLXCI}1yHiSTiFe*5viG*tteE?+u90880
zo}!!>FNKST%FfPpk)6U#<vd^Xug_;@XJ!s*pJ8$I^lPDlaYCp7#h^kM9T$l@JK8<S
zNgjcywWDCps+VKi&#H03RxGWt5LnwhlFE}<g!l_sutmmK#Az%k9KA!_3r?D0v6Dt-
zR&-=}>Kcj);yj$3RN!&pJP#)aCp&w=zdoPGsh)QPj$rug(N{zz3Z)>F$D*J>0EdkN
za~RGv^zw8?)fDn`I|s;Rk=g<n@&)uOoz66azs2t#Q3$&r))GR_0<wvuaQfINni}ik
z2p*t<-80kNOjkutLRv<KmxDs3QfPcUoLm%6E*{Q`e|xcnitk;)&#*Xp`n6CYZBenv
zY(X4g`9xtb1cWTX{=OtvA)_%!>C_GzLkKZg#bUt0Fa;lgJkAu4@TtuZYCs|w8|fJ!
zg(HjtakF5XSnJ3@-<)ZnA}2-@5#r;#z|KpfQMiE#g-YR}HU8$s_3KMZcZH8&7{fNm
z>FDVxQ0XS4MNYxnzEAi++=yW)#8OZki;ag80f$~9Fe6)G=>n}$?0{SpC3La@f{YeB
zLzG3C*zTFYwU8JDLRKH4805a5J{Wx?eLYZ>@GAQHI(qOiCc0)!Gks|>+9hrtZZ>u<
z8V?m_BFMqbFC;{5{p|~K^vyldBN&v&cE`@t{`L7OQ28f9!kwJA{jdxAa3g89#008D
zl;Fu(KEarzhXxo(SUlaK)^~Cy>H{Jz2Gzs_gNDrzGJaGFiL-^VAX6b1Vh}mrOb?-1
zUq>5XU?}7VNOwUe7$}L+xG9{xoB)Nw1>eGb=1)ITgn7Gu`*Ic6eX+lyz<QvZ_}Awr
zM<v_&1An`9Qr`CC?vUJwAu~9#4m1DYbx}k`8w`|R2tj@x&@++VIBc2WcA=q#y1?3k
z2@0D*XXUGKDxmF2qEB{+*eSw7^mKKB2aX=q(S>8tMMj7EkiMppxF8QF8<ob(L*<5_
z<)U7=be5gM)Bn4dM45G8;;$&M9{d_x+4?X>0p<deIRTUK5tH{f;<N>vbOIg$lVUK?
zD+sAdP!M`OAeRJ_fPNr!JQ3|5)CYv1v^IxR!C|Y|+mOhNf|wBr&B*e}sv(RVyosI;
zu@uB=xEs2Orh*8c06zy=JzU)U6iynA#(s{Ei;asq`umsbxE@G;g357{|HQUJCaw@T
z{^`Az;p9xh`x`NN3WF!%Sum{>jX;5D5Q1Vd2pvI~IzyU*&_;-2J89<t=>!&zmC2!u
z40004;P4?6_*Y~sILV9D3Q+<A(ZWh>S*RH3sfY>i@blBCJbYYmw!C~)D*yQ(FL85H
z*(ZMgl86@{NF7I|_RQGP)03jY8s$S!IRzKTy6eM@;3BaNia>rF92x*vf*?c=B(v@O
zFpn4gbgUjzC$#o}xwVEQADd=ua7biE3?g&^;tujQFe^rSSVOvc+B!)1VJ!$rh)Bk&
zqM}0Ff`UT)6gGBlZazMKDhCIJ?JNf;H`j%!-@n}4+}M109F<Q%IdPqt#i;$$2bS`L
zyzNI+2;qxnZVb{7go_P@1UbY%I0&Z-K#lC}8{p@L$zGQ|JRF@bqdImOAqeS;Dcr2N
z85R+trorMHf<%JRAh~DRi<YiF_CLS}1!hBIK&31!C?X;xO5-@s&db5YN1?EvyLkR0
z+XcAY^Yh=o+S=UQd?<Zn9Ery*W%tCWkWWTd5dNH)w`HO7{>JY3Saj*KgmBm?2SHnk
zHAL1CQL1~pqC^Hcf-6MFU|2wAgJxku0tYgIZeos{g;)#B1x}Tqf`x>dkby4jge3lY
z+Bh&>T}((!Qdo$_eu;yJ%ENu(%%9nLsGOWUY@A#_Edmu>$5A1)?U^%wMd_p~=p!m8
z=WSV-08;oB*ceoT=v@xQbS^X)!p-7OAnYa7FA%*j-mETnG7`cbVtu0dgV>EEE#?e_
zXa?Ps^@nVW!7LDA1`GsYnZ#%0E&4hddU`4{BBC;~LSPO!upzv_j<_r&!bjmecZQSW
z`uDGH+_>=xDu2b}{e#n>^5OHbzMb6LzP~#P!8iymB`}C+)B#N>tOW;~_`tPb5(4HT
zT(*aL5@mM>Ru)Iv<)8vYkVa7lxh+U)Q<B~iCt{$FvlBsUzmL*zz({hH6(wYV3O9{|
zi<jdP7ga=2Ttb+7;oQ0Z_%E)N?_ZJbgGa|!&^Lk#Io6R}kWNDWMsherp%C=h`J<Ns
zbDPl24W1u`=J%y{bEpZR?}8{0djJ$iadsDWh;*=WVEK{QqNr?U3~x)QN&{^zT>}Lv
zF*#YJD>N#oCT=bm3XPZR{GWfi@WX%pnfR5htxx>QH-ZYJfjGz~7+uVmkRMEXx*<l!
z!6yEG7!Xd}tt-YJK-7b#Qc@Q}kr`<V5P_JB0eD!dK+tSVs8m3~kt7$<8N?jok&(Wd
zu9mpCxU9Uiupl=tFXaLU8wZ7#!gl_rvwyyD_TT?|?tA1b$l|^|Tfw<wIQ9lZYRN)^
zm0%`UAWme!_7KfLUhWtp?{XP)MbI^7=U`)V*^20gEpc2V%ByfOwscb~oZyAR7s^9~
z^he;)(+3x2YM_qLq@txQDJdZ*$tNg|T%V6hV?TchmU8LB`5)QO{h6}xJ!{W=NBW!N
zZ9_wYfeXe%fY--=Xlfvttsm*cL|ZBvQ&A~H9CC+N-Ps!49GM!3)F0v=s5Kx+hg=XD
z45$TCJ42#Nb^usD`g*$97O1PM%1g^DiqixUk|}&5RCerw&R*m_clP3s>{OA(@9$Su
zl$Wi1d$vN7d<@ON&<Hd)0HPow`ND}NXp$mrQeGILfnge+t`G~l*kfv~BW4C-Fb32t
z$aP5>9;5<fw19?zQZk4-5ZJ~>3~ZxKElf2P<RwLAWd(V85t@1UL@DRFs9YSJ;=(`u
zNJC0D|2>(%5;6Ymp#s%@a4;rkhXn?OLB)?u1+fU@?!0~de8`l2Xpb?t2{VdZoH1_&
z1H#cmcG&@Kau9AH8j)^g$ZcUNC~QDMY6PVM6g@yjM_b!SU0#TfCLzX0LGkATJD(sY
z(l{<2inJ)(Mb7hFf^**=U{+7)n9OHB_UP%?ip+2%=w`qqxIkZIwrHsf@B@p0>H6gK
z0=N}2P7%|JFq;a)XI$Okbe+*XNTigA%@#Nk9TI&jOX$^^7D(v~Q7AMd>Ms;mmDNlP
zW%)U{g+&D@96aYQa#8uPJ*40<FXbXtl)}xw{0G=dc-Xgy3akU%0b1yQh9B}-474Is
z5j@FxCg@+r@IXi6b=^EM*UHTeeavWvfk2zYBk0^nnH8)qiP2VM2|=5If}x?Ixv7qx
zs<N&e&m|5aK~R$5uDQ9fUFPDUu~T??c!VTGrKQ*ZaDel#!@ogPuuuX(r+8!jo2RF@
zx2LN&#s;Fn5GSg7x?jfH!SMq)*u;y>GIMh$;}OvI4nZY4e297jS}t4UE@1w#jIfZf
zB?5VX?W2jYhM~T+h#)r)LeHg(98@m$a~IBY3knNf;-_#?1;h=k4Q~Jyz%u^rtswYR
zKQcFy%n|YMz`!mXCqQO)p)nWGV4NAo`jW<XfQ1zV8Va6;w9t{(Ah=twa~4SDm~{AD
zB0xa8Yifx4GM#Rur(-B1Dn_BwsN7r^FL6`3e)#DURYDBB6CV#ZpO~?x;_ly~LU`LF
zg7W0ML$Z${l2XFIo^H>~;(akJ!`mB&E?@u;X3b!%3Yo=&GX-2=E0`C7_yYsNGyqp;
z*p55=EmR6lm@I=Jgfy2-L4YU{ib_H<02!t^vRvqQP?6Tw(vlGnAoMjG$GM9X{-6H%
z6E{B}55F+K2oIH4NM2L`sE~%6aoHpH>NK`nd$c(`1uA4TFac$Y_5Bq4AQtZnzd=Ue
z0SSzahlCVk&d?J@Mo9t}z=ffao^HfckpGhrf*49e3L>l?LXf$HxMW%(Bty22<R1b!
zIw^)2z}pz9$&flB2R9E7_a$~g?jQbqiIe>zkC==cJFf_@1Rt;9&fnS!@EJQsCY(41
zeVASPal+}zQF+h%k~3{w+@Vv!5PfvAlLi+woH{tdkGQ$}<BS(f8S%kT7H=#e3>v{S
zFEoFU1q5=AMg9|70m&_Fgw)JP<()84;GmQwK{Qb~Ij~ti&&eku$bO#fEE@-(l(Z^E
zNKHy!P?(>f0&n}7UvWATfStlt-me^Kj9)*QHk)Ny#K>6u4DlCe$c4(7%r8KKMrx>*
zXpM5g#t;)Y-7#AfD+ob}<yBxrj?S#1Jfv0E(w1PtA};BuIAixis?88mnlkidIJmjl
z*(hAx9GsjNIQZoRIWG$G3X3SH%d3m1>uE}h$tZ3ALS#P9uAGi_B6Jh+DbiR>C$^Oj
zyf03mxa@3W4V5HOUt>dz!<u0UXyhhmb-)9YhIbH^PVQvj7aXmVjguYp8${BAtq=->
zW=Lp_%q-zfki0<^rw<{&wywGeCl}j!4jvlEB{nurPMS3Le+dgqN(;%#YpTepiiitJ
z>1y5hp3Jum8T~Z3{gw3~ko3-fAzE9)$(<CHkG!voD?Tb(n4s~(Fc1_?p+2xdcN9uN
znAeKTjZD<UH!`x8wCa)xG#D5{)ci0Ogdg<6U}K0ppD_F^k_FpkB?a(IoR`jXQh2%k
zn}hqmIR$AH9$rpPWd=i3lF2j>p($EA1+9FK6V8JIM~?Hha4f&79)y(u-j!%=PlL)w
z-WQ$Qq}+qQkQ<;f$f}#7hsVi*L}_xg3)mGhFM@0g(cOS%7}yBJ>*yszKxUA-Gs+)?
zoJ6(5P?s?MI$EM!Y@8GxZY&}i7oXt8Kd}jNaSH>AFgJY_BUieVsE(IUROZa@Z-LwL
zA3j$3fKT}~w$cqWh>n;ba>~d|?(KH4b9QjBB*j5cYzQSpPfkYdpyLw0myCWR-j#S9
zqR+OqM`tebSvqU`1EwF!V&t+=@qlhZQA}S;TT@3*LxsZ5#>LLTfuIbv7Y#WJABUih
zv4(AAfTOOFv7V+!rmKU0%INR*NUAh+tV%{kq8ybDPws8uWLZJ^{b3g;UO~j?5=6<C
z2J=F|nb4VZNK>Ey#lFVc679wqtpeJB%t^<nH~1W6_T&%r2>_4KaOP-(LcoCrPEQAh
zf=a5kx`w)@nv^&<8{3aRp1nljpwPs5`Gf>Hd3ofRbVJ{GUrPr~B`2?tFlR^i;J)AO
z!E1R8h#%!EpFKKpWF{Z$*mY9B^6^&u<{^9|joH}of`>Ilhbee`P;Qu;f?YAmUhT-l
zDgqX1Rz}|w(Z``Lm*ld<zv}CueyXFTt){7^qOPK@uE@>yBM0ZjpUw-23JD8yQ+aq*
z)D<l}oYS*%GD4Hx)ac<6@$LaWmzgcU-6ezh`j1uLzY$a{%^|0?LQf^r)C#&jqRvP1
zLAHLNmgw*uCZJHz(*Ox1EQE+=>E;j<quU3qxu|%c2S#6CS4&G%Q%y-lSw&e^RbHG8
zdCDbD3a6C0uY|D;zl=kqqjOGiKz@v^Z*-KEYq*1NildJ&!?^l4H!+dVsZZoHERLRj
zEn9)o4O<x~?1}IX1OU<ClO_bD@9-WVX3a>yzd7BI1YlACB5#58jU}4IvVo0Y(Wt8_
zt17FgC@H8&N(l0bTsqH7VW()j`2+~a8EQaL>X=%bkdm1g8XOtmYVTuXpA=JPc)6hD
zH#d<zI`kaVuN(owdi1qWF~bg*@I^$ALdZp;vc{GM!Ip>t@r^J^gkeKr3@;&rMX*72
z1MU?91S}j)O-&GystSq<imHmT@-qB9JSsFEA>NB3K2ZToUSUN6Ayu2Cl9G)4EMFJ*
z%O2r@vGEw&UMgo@R`_o_WS`kB^v&_MpodJ+jSaCds^~;-LBu+!WT32$pQE7z4+&+$
zuwxkO>l!l<cwrz0+S=NhT6&rqYHAv)DoV-<a;gf-in0=76zFv*+#(`;{4~ojKT{<s
zGYt`!l)}us#896g2Ma@ngR_YiYKwG9ifjl_A@%F-Z%+Y6jDx5vP#A{10$-uTAr%ZL
zsv#bxL;VPAg6_b~+R|7@7p=K^dOF$~n%df0n(7)V%1SD#3Q7ucva)jWvJk$pv2j!Q
z1i6KTc_fSiylwQY>3+ef6(!Y~rMc;mk&Z4to|XpY%JQa|%V-ynkq1;z)9?EB)Pg7q
zle`OL2*HI^xpbkDh1{B`tLb!o9Sd8AA;VCgVNEyH(bmz%nt_2J(x|Gcswm6J$t%do
z$;e1bNJ@xF3UPCBa`TEx%ZZ9gJK~%NYuC8c%%a?af}*UP)T}~hwcwm+Cx(%}O=4<5
zc#vOM?!WB-6svC#6_m*J^|VkB*3l&jE*%IT4Go<^sp&vN$}l%GX4+U7m;f{eD##id
zT39ryDynMAN=nK~%8D|wvWjw2QnC^<vf=_FR1lB?(uQ#^()vD0U{2g()1ou7QZvGH
z6QZ-PTnP@w1SvZ+&uBkax~w$6umNlZnc=sHiVnyj9W`xTJzXSWa2Z%4Ms!0}by+D>
z3w`W<^-N6lWaJbTlr%MUwA3}UHC5FSf8kpd6cy#=<>h1*rNvP)6%!HR7NAmv#T^}W
z+<f6uqeJ2=F&Z`~FsZztz9B6lG$q{C%+}RR+dC#J+}qkrhj!)yY~>qWL2wW1S}IyP
znp)aA5N_!xh)T%Ga8P*I*c4GCR@IPIP?eBYke3iu($r8_Q&(44Q&m+4DzXYniVAWH
z^3rlrB9c;)Vh|VeOBi}#=7x7>dZMR=PgGovr&CmXNMccVbxdk3Gr(EZ&``}YDkC*F
zCd^)i`#=8m_plZ0tZcr)6{Ml2f&@%UM?+gjS6f+8oR8zj^E~JN^vCc2%qzmfD=SLl
z<L8l6l@k_(xLQqFT}4?{QAtrnUQrtERaQzyMoLCO65kd0C9Rx1{PHTYTKck6a)Rv>
zbMr&!ZkZ`@`6Z<VVX=PhuC_`h_U;+ki5^aVi7vu_`u;b6DEiG!LIHmogKCep9iCtx
z^pUW|<`Das)9|*(Z`4pz*3eW{Q^)$yk){gpa{YAf+@%Zu{+sXr^wZgMykcCJxVgCn
zB_;VK)m0T#l~mzQ6yy~Z<dtM)q@-merSL~wO5M~mJTf{p14rLo$xcr%N=;8q$S#Yq
z@XaW$>uAg@&r0)9GP7l9OM6yFg?r(cm|#1hv;Y0m#VaI>b9CqtI-a|oIUN`G*JG7f
zyz6Or+v7I^6;(|&{K39XfStyF@e;=cZnoe2@lR)e`iWbJ=OQ~aIH*_fNkE6M3PT~;
znw+eRoRp-5xU?iLX=TIk$k?p3oVx1T#@<YvXLuzhC?+;1-zPM;qO!5}N@+!IikD4v
zpoX+gWI<}AjiG;Ptg9jyuZ$p2Arr}akLR|DPN&mQenjOx?|KT}_LCdcl~fT`GysgY
zJcPpH6v#_B*?#!_SzfM7G%+qt0dX-dDosF8LP|znRaqWR7J__nX(<Vqikzr~w3?1r
zL}_6{L|Q>naqmDwU2Z}^M6!Qmc2a0oL2+eSMrL+lYP5TDS(=wFGu+EJBGAG<t;|d4
z55NC`!e8;*U2>l0@qN(PnNP+?{Now_2kF)a-u2|X?WZ@YD{E+}YN@HKX=w;tJa?X(
zherG9(xo$hI>#eOp$Q5I$cPK`)A$91B;=G7k)9~ZAVrapkdczZ3KG}1i;s7Y%g!oD
z@Qh3hk4y6PbGCBv!!(Y#bR1+{QIrxLnOG94tQnjZ5bfvNlpB+k7L%A)R~63v!+)MV
z$5;2;UGRObeaH69%C)CNh2=}SStme#V4P0I+kPNyKM=mED(V_)*xhMr%W+@&iJc-K
z$a|ih^Ww#ey!=$KXM$+l7Zer~<dxJ=QBomEtc-$!jFc3-iKLuucy>X0;+2Brlw|L~
z@aS+)rnyUyx4XB0Y+Qatd1h90Ku}gut&M<Pw4E!{EGj$yN=-skd|YvFrO=rR=c)Yl
zzuhJ6!Tm>y^+a?woNfgXW&{Ufg286-aNX~}|HJ&sXEy>5BrNI*>dL}Y4tBJu2+-Il
zsCixx5)u)k2}uhhGeg0TA|@%Tq$DS+EGsRGTvl90L)Y3T)Gxj`E$M1HB&iXx>4EOP
zAz|?m0nzBAkBUjkPfy2*J2{aV;okmE_Ihp=dGUeirJ0%eMWv(NHf-!aanYK<I)Qc?
zI6{Th`hMo9AoP!~AcBfCIbxQ@#+{hA{p>~+H7zZ5H9>w!N$v|jadL9;3eY%dJZyaY
zf;1rkimZ$nA19X(A2)@{Es5k_S{@EXN?KOgAwD+J*VU&gJHMsC*Tpv^I>Oh(Eh;h8
z-y=Awv@|v`F)1}PG(W*7BqrS3-c(CU38ggyGncT~q};OF(#B{`QTg+n&A;12xyfr#
z{CEsHovnN%Y=I526_&l6w4!?KMkS;mN}}wXJbY|_{%>{&?L~RH1-UtduxJDYc%_vT
z#3?*H=yke8QBY8llTnb7mK2wgvyIJ8P0h{Dtq;hHwsr7NjJI|1@{Y;R3=N2mO)e}f
zE-KFPwRdz@Q3*(7nueyux?}%DH_?)}4~R;N@U?C55jM2orq+YE1#$a7feI1sf2g98
z5BKrZ;eU7q5mP&MqqaJgi$+`tg(gIUteg}5O_IEqc=;%NauPgJG6LB0@d$FA`!lZ;
z+^m$Wh?u;%q=E#aw!APqH!3*P*V@|E&6aKvmXaNp;1!#fota#ck`x)|W~{0pDkiCF
z>ytm&6|2Wg4tHak>ID>pS~Cp{ERAL4B&4W~zuUv?fA7I#Z1yKsbGj-S`G6m<6QT0)
zCVUs;=cKY-<lwjj%_qMg+j%}TXbAJN(S&%V)n$bw#e{^o&T>-D|M}m4_^%7x!qU?6
z3R03%3iQ~*P*;W@CZ^e%+1Z)91x9ApmSse{7sRAxM*Djt$6Jfbnu>`COKX@1)FnB(
zUiPsyk``A8Nc3{`kMK4zancr%l;dv)D!#rx$2tCQ1QoUm?9feL;NlS$<>$F@fkR9J
z5>P59uaJnkycoy<K_Q+W*(vAF{^^JRI&+>=P+U-4PLUp#=I7@V=!SwLI9>~D=cIz7
z%;Nm3g)t@h*?z{_j&V`?V!A5q7uiLbwxRi9PIP-4X;lLyW_qfJlTTcLOJGKbC_3)i
zez)fbScZ<(gT4_|czMx;!FG{bKva;z^#dojfSN2XJG#F3Bo&2)1Ox>IM0hVy#00q6
z@UC-zK6{BzTFNdt#o4L2HZwTL$KBDE=^vX`QjqGCeWg0SusPD2uHahcuOu!m#`*96
zeU5_>T$W%cqiLlm<)3KclbM%hEv;b|7?+x2&&Ma#08{|WH;9TLjf#>MA5<kYu5)K8
z+%zK%ZmIwmhkzJ#CcJ_|0s>S%X=!1$a~C-|0nAxmz37r?7ds!HfTUnw*YKp&{G#$C
zA9w$Rg8UFW$i!l-OmZ_lr1;o5&j0a`7o}}I^d<O2v@xsFC(}1P#6?$?Ztj?qfk|Vg
zQfe&(6+fWz&GEM4JjA7lONeu!H3iLYqN*xrY+_><78Az?NCI}wC#E8U?GZ&>QdU+>
zSkSk!C@(K8F1D~HIW8&@hh3M|1Udy3<wf|b%1ZhrC+3&sN9ynj@QZVt5wvwR6hRvq
zMLR6UD+V)kO(pd#jeV2KvokWTWSKJGqvChGqWX=jAij&|X+jcUpSif$E^=Mu)HK(m
zQU$17!W2<VdJq<)aqwxXhzLrE$QWBY+R_dEOE5Alue_wWvobb3DGQ@<(=r1hLsPTd
zjU_I7Uumr^NiX!378gS?RXWg4NtTaYMoE?#mmU)z5@=yYcQR&F)E6d&$3%F!+Fxba
z%D0FL?L3F5h^Qb<-~u}jRQCMJ_VNOJyi_WcTTYrPs360|CZelj?RDAQ*2^n2)HOUK
zt01qSWU!&IyrLj0%|9?UE0$=wLn1CqXeCvZG&kqvr|JUCi`=|cNos<;?0mk7Q3=U7
zL{(QpQd3paAt9rxA~&hXE6Sga+!oIETSSHT0=p2ukg$LN7e$EUf}oHHT}x7opI?kZ
zQ<UcwlNI5kNomu)<D!CM662Cm60%Zq%W^WCDvNVVQZovHN_ug&kJV+*Kxa!iW@2tp
zR(*Ae9o*7+HrdO;m!%{H1tq=Wqy3%rbkzlE+=?~<v61%im<*H^9crLjhb#`Te1j{9
z#>OE)LX9*Jw=^%*e1cj!!W1zHF;O7}B_VMUs+gz(!zVgAJtrk4F{v=8xHcy<D>E&!
zG(9LfF38i`H!{ZE+9f(fTUg8p$BHJyZ(ddrr(U`sVw2&gpe!dXBYWA+%UqF*rlhK3
z>Yo!A?Pq4<>4ae><{I|3B)9!0V-Pomm&z|H2&I}R4e1-Nu)G}QM|mZxjD)JRkfb=b
zsFHzCn6GzyW=4!(QEqHjHpu%JU$^9hq)>8NSx|U<NNiMq3J;&OeO6RdPGU-wu9%iQ
zO;C+tYb7ZzASNj#t0E~VV&-C`p<obR78(~WC9I%r$Dpf9O4g8lkdMzd7@27j(o|j%
z8o#QN1ms#&s)RTi66AGNmDKgbh1G?rDpt&Z#JrrOv^3YSoYa`el*@9a5z)yh+412x
zz%d}cpr|=ohM$9~?N`v*ni=F4VJ$B%Cd^Ca<Kh>lvY$UMEXKjFW_!8(N@AF+V@!^x
zJ5yU1XvylR$Z1slb`L7VPf%eU>2nl_PPS(zDLb}9gkND@-6znme7NHS{Y&8&rASDL
z@QCWF@$ztSibzql<Yn{>O?6dumE;tJgsh`dOL8+ZB2v<l3(6CinwDm+5s9V28k)K~
zcF{hrJ|5;wX$>POk<9Aej!<hoUoR~YC<M7_f)~!Spa1dVPm<E&&IKhU1$ozo`szD|
zgP4YHK}xb(`ljyA;o#!XRpNczRtUjz>^d<jgqkEY0<La|C{MNz!W|!oPRzF8mk|@<
zq3IgS3WyVNu!uOXv<XD`>I#Zt;!-xL1t1nPqGD3xQ~d3%d?FL#oy_Pe@_LTGK|x{3
z=?NL(!5LR#LXz@}J<Y`V6jYQHMT7;#g}Kq7d;a`I5jFFy>inGI%<}$*l<1V=+&C|X
zAP1jN8ymNX)M~I!P-hMv%lLmSDxlQ<@`1D^;G7H<-0=|=9zJminxL3~vaX_-ny93n
zwzwdTS5`w<R)oSYVyxgCe3@bA7zVD*+0n<^BFx>KsVbutm6%mh8lI5i7oC<In_SbB
z?eCTAsV%3jrLUzR&4*nC=f$%Z&Ya;fipp>9t1T#~y;_wR8tLU*HrUsgo^sheF4!fq
zqPdZv;`u2mzfu9#{ZHL2Lg2lroD3CWTp#FP9&RBCJ|0O0Q4vXHB@H<vH6CFZUWynh
z>VgU)LW0VUW(xF>aKE_JJb$N{1XmMF%b2YA;>POInj9QCpzRUkk(ODQABQeHS!GEX
z{!8aY<Y+uRY?s*2af+%q7GCS=xLT24(O4AYALV8e(b|$38E>oaU!0L%+}a9M&?w;f
z8I$m9)Pe+z4>Sw(r6;r%)*Ymj)cqF`P99M<E_qc&QE?4beN|n_OI*t067u3QnqsJ-
zi%6bh)3T4thzd!`N=;18^^mhPbFs1YEh@_{jWaV*(DRRr%gm}ubI|0wbnznl8MJlq
z2=P$JCS1-jCcCDitGl<ltRz3eJ2cXd5rWD8(cX@x4smg%X~orzZ9oOB0-vF>>vZH>
zPVQHn@u`Skd0!Da$qM>dLn3-zeh!-S*-K*b>ZIgj?WD-det}<BRY6kIN?XQEM@CXW
zBRDbVN?A@~Nxn~@hnkFziXFOQVv=I=^OJ)v`^2W?CfJyWahyGWp2B?|Y&bh7>Cokr
zut};cZ>X(ruPH7_ai<$Iy<&YYheo^md1A7%Yfxr%U|wccJ2-ym;y+gl{tCS<>yxpT
z(EDHfNl^J<D#TlFfvFYepbGPe^RsK1T3bp`(cz>gDPw7Ct}U-3En#l$UDQx<wYaXl
zr6$EY!j);CUWyZEJ$!LonWbfDa#3cwohTJzV-aC0H@Ho7NKq+5V%DjZbv3n>X{lLh
zZhoPTCYp4Y%XWUYm`rG&5S;7o?q^V2U0B`0QVY5rL!}m~(&O_ZPHZbglub$=WEtQ(
z0V=FJKGMJ3f&!vS>|7jt{9<y_YV!O7d|bk^a{5MAN<s>nV!RevA)%F5Yjbn6>#H&X
zgF_M%Z4FJGeVhX#{e41`;zI&V<irJp#H1ud!8{1VPxA|jNZX_o7nW3}B&0@rq5mvC
zFUil!{<0MWR0a%YNS&{(y_bDtOH)G|{0eD0>K8wX#c;Mq4F4$@O1KqPotZV0=0vEx
zzk{SLTYvcrpQ5y|st^Yk9IKcZO;}8rk6l<uRbD|ufJfGrPBW{Ix?Isxn%dG<mKf>b
z<K*mN!f<Dp289MjWmc8Cp;eg=#S$?wad~4s)SX47^&I?yld{s%Q@p(js^cz$#Pslw
z$_jA_b7x{qp{qyemCLF+UNNN&ZEZbezqyJ2PM2f#pd)zRKRU6k5Cb`OoxoO(-SwBh
za45)0@rz1|3G!2Z62ki76;lwC(iEg}DB3YhwKd}lO1kTEQWMI{a2%C`jjn<w!!a6+
z6O>Gm;pxt5DiVTRD8h2{coY`Lh57rWR#$}^Tg9ZsTDZ1VMmjsW)2)1hLQ*1vW4#=4
z8hCV=PoR@`NMU_LQ%75WKI+WQ-y|yRQsQ#LQc_BMf|q{a5oe?DNULc=(4{D;Wu>a)
znN$>)a<wuhBFfs#(T8E=>S*ce=^f&w9UARs%5XMP6Bb}c(S#;$;FXl*=NS@PQeKeZ
zWghH>v+y#S8#5CyH!C_WEFcmEGY1P#ceKGqCFIt%G<9`1x3zT_e6y%<$Vkg;NJ=Y7
zQ!oC27E(Dybuk4hw}P~cgo;YywYK(Tm$<}07d=&TV=WBQFtISR4G+C+WbLXeC(Mb6
z!!BrS<rNj=;p*-06H`)Lo)hHi8xrgvdZjqMDmN`7J~}xZ6hvBajIV!mw6nc+KuK*|
zNBdx3eS3RTQ{iuS(X!|I4Xz+|ehGC8RZ($C+Mmt}2}rByYKpL*!At`gP5qd*&ieYo
znyRR*>;yYAD?2kex~-+Dv8APfz8KF1DNO?zKB}^fS6o$fQDS^*adBZ;S$Vp9N{VB+
zueAv?ygVfbI=HmR#Om^-vPAc|#Bg^@=j@)=?!n&nmX?<0+J;gRgWM2<zB%3&jkGe_
zHi`;-f4;ykD5_~=sVH#aPlEi?y86*w&GpUwQ)BhTHGRDf3PE8?;<k3Cs@lp@QbJPd
zcJavxp3e5>rXgiTC?h6^WE5AIWYpD_SC%Km*c&k1Bh&Lsi>e1}ip$1F8*8ev)5C*3
z9SS>Id#<(BmNfS^;xHPr4?=SLc@}rf<$f)1D@);)GjlfAx^#(8SWMBxSW|-I$3Mwy
zYKT}hcQn-Xu1*b9r*?LyXsMeS>8onWsf)6m<KUzjWaL-XLTznI_f4)Z$-7dPQbZ05
zDXhtjF6t;wj7m+-%qc9JURfRNYj3-;y0Eq}-Cp43kUM#;CNsUVrLLp5wz0XXl~mt9
z-5nl7ggpFOs0fLPs$0^vbw#*^XrfwRJ;a1nv~7&VRFkjO*VN4n)l~R-_tf~>IJg*~
zXO16=1%3%_JNx9ctf-LqU`>bo+VZ@tTpW>}8txL3mmL*c-B?qeUs6^#*EhJ{du?v0
zt#5N~_twtJ@@#HVLtS=SWJybNc}-($V{>oc?+I`FE!Klj^O2R4)R2)<kQ0{I(6%ts
zWqAA8%Si>+)m*tUIMI-vo8Xy}<mAQ_r}Byl3DP7bge6r}Y(w0FBjcQ`V(Ob)Q(`as
zq!py+#)Ux2Q`*;2(>gIYb7N<&YxU+x)6Dev!phY2?#{@_!qx1gw5-OK`ufa-yoR>s
z-i`^<OBUci@@e1UadY`<wnF6=mXI)(kyg=Wx_EinTcW2>PeIbdC$Xr$p?A2cwD(#e
zwm{NC-0U<dPF_A9n!JL%ild8XOk%D>^w8>Pd2(7<L}D_A)~A)0T&Zel>zdrySYCg0
z>-PPF)v?W`_5F>7vAONZ)uGwu+~V46eVtvErS(16T3hR<zQ2WWNkOCE-b4TlhrGb6
zW+ADlYL*-r<fdccY$c;D=U9}NR6jX2G1fIU)7g79&s&9d{sN~sKP2gbVj?<$8EGlC
z#pONg`>XAPO-asv1!cvlsfA^UnWZi3w^t4huit(C`pv`nn^SZ18#iujY%VX3OwF$?
zZVbkhjr7$8=5~&Dx3@Hne19t#*Efg?w1MY-qRJ}UI@_aN-N2e*py8YpoL^ay*D*Cd
zJ2t#D)w#H}bS>P7p=zQd!Xt(;dG=A61-W@~NyEFVYpe5RaY5mc8A%zrW%-%u8Ql*a
z?j1h6fA8?c+ZRus-rZQ++q$v7v~^=~w0&T>r@J!3%QLMaud=J71xIg<qDK|i=&^|a
z=*2wVczF61^j<xC+KgY2`yv+`)yUS@-PD?H6dUIm=#^fYm;`=pXn0_DVS4D=^7Yvp
z%d_42Aw?eIVtW3evGGMsO{Li}nVr+q-HmlI8F|rZSBmqm)D@<tm)`pM-oxkjo;^5t
z@$S`|cZYXw+@4=t-rU_@7;bCtt1YW;EyK9-;Iy`ZrkX27Bj4}ih{=$#W2hV-2k@(6
z5KBFKl0EY$`yd_)4=0aqxNV5Psi}5EwvT&yT5JTiy2bsILyZm7V->S={afp^>m!9t
z)2WI^kqJ5FVFhh%HDx`?Rii6)={c3TiK!?X*H^aJl$Q4$K7Mff;p=<PUcP(%=H=bx
zhX?CxGb<ZQivt7WJspj;O^sDGlVdry34<-Ag{k9zi;B~+2Gw7K%7-zxr?nM!4l0MZ
zWk5(yu#Ta3QK(f)RZ@6LN=kTD)zzA=_RjLk8(W*}OLJ{SMXlGO+@ou<vum=83TqoX
zhoUN*JE}4hv(rkFtg+Dv%FM~>x%2q(y(d3Ez5DL%^B0eI*RJ1wvc0*sv^X`~KQlKq
zaILw%rn07cv@I(ns=lMOcKAIi$5)WDGFH%06guq+`k<aYwXJaS^7Ctireqa`Y0LX$
z=OpFiMEc}kDQhjt%)K&H($O|^^VY!h@<4G>TXR-yWKmCMSwm_`R$leomBjS?;?jil
z{JaDgcW=MQz_gT%8xNkoeEI6-{=FAZo;*0%xqa{6;qK1P%KYT$?B@2yLRVc=Lrr<_
zSaWruM|gf!#U$}7@V3WR5NT#s{uK=6hjs9A%<XAyg+oS0!zm{xJ1yBsK`XW{KO)&X
z`f77$RdhmXcVj^H)WX8yQe%GN)$Y=S;_Uj)%G%tLD_Mc@<#qWvS%n!n=~)Sp-agTR
z*d6<Yx4!)O&AWF`R@NUsd-&|;^6K6Dw{I+LY_G3O%-q=C+uj(c=xnNK=o#zl?5NGO
zrMpa#i2$F*ATpBXnBex5w(?Oudum(ZQnd9;sK`n1G*XvVvMuPW_wlIfYOPI8$Y{Tk
zR4_1GJ+RQ45)x6_dZoIiYN9K(y(T&)C9l4+qB1W%Hzgqob1W_65|dIwTzndDzxesh
z^Lsl>x1ZhL+TLDW+uYm3K*iO~rJj}To!yPaftIeu%IdD+@yW5lt^^(RiN8gKaJIi5
zm5=J#Q==ki7@VG&6XQu&(lJt3x2mWy_GxRnS`wMp(e4(K-!{KCezhPaHZ-NY^lEoY
zL*13iwB(%Xo`L2onaR<qxdrKA36Tz&l?_EvS%Z(?K6r6=`_|#+-G^ICTQ|2>mu}qL
zzOlW%Jl?;1b9aAly?eB;tG%|VXZrfgaQBGcdsIHn;s_$gMgpADR>(SHaoVR{K}tSp
z0p0;Nrp8u|mrYI8ZG&9WYOCrhuT&4@hNRSAzu9@UFeNf7<w{j?Wo=n;T~UZ%Zew{-
zd1G5%utQ)}e3*BHk3&LsenRg0yXX7&_IGaHx^rjm{?x+ejosB7yW4A<8#iYcw{G3s
z+u9s$Uznbo>#1w(S)A+X>WI@`Ahz-;D!cHuM{ecU><)hwD$bdiJ`S!pD%jdN(D|~N
zeQXiP!~Wrlg!%~Ekb$wG#>UJ-kL1qQg2LjAn1ae|KlhNdjPRVQ%A{cL%Z@fod-ux@
z&hDWFyKmp@AKcp9+`aSU?#`WsmBYjRgU62#Ha1o_S8v_hKe#?UH!!)hI6F0dt*vKj
zw52vaJnlLRmB4Q>x6R5g2)1>#a&j>?4`7&jCR8?5wp{OO$t`OPaB(Sb8S5LaPmN2e
z%r9&yFO1L1N%KjnEGcg&%Ds{q9~|UoV`||a8W)jxW&7>B2RqwKi(3cx@7!F!cV~b1
z#_gByp5H&%S=~K6e02ZT>eBT3ts9%uqieH${bPeIg&AGl6MtaMU-<@6iAqUw436>g
zwzcw&a&=D4s;|px@6Kr)9IMD`8|hrVw=-8=*in%mU))wxQ(2r5pO~AHT|0EGuCcy2
zD?I_H(PpLQR5VPzdi835YhiQy)~)@U8~5(+KiZkO_v+^-uiouXJ$?D;)!ogtiRr_=
z^-YXazdkp+G#gr9KfFHq2jsTF-{S7j^m0O2T(F0^OJY`Hd{|`K)r!Qrj;_&#g{hhA
z)1$k4JL8q9d1X04!Ql>GQEv8zwhp274IP86&7<A5mF4wq%{7&E18a{TK7V;{b^F%(
z#_hw6t;hFo9vs|x@%qj4SMLtz?makoba;KDb7tqp+WOA&?9}A^LQC{;d+YN0ANFzl
z%(u8ZWQM1Nr-nM%;B-G6=@*@vm(egfH8wUrJhrwtzqqn-qXT}nq1xNgP(|HHT}w5%
z=2~Y<f5+8^$^P29y3Voj$$^ojCoi7Ada}2%wYzoW_TJ9^;k}#NJ5L`yef;R*<Gt&*
zcJDu#>Z=>w-P+#V+nF00m{=UIOTXIJvb6RGOy|U0C)sa~w~Z|HGq=}~xA(Jm&n(T(
z%?ZmHTV0(-2<`9d>X@3DyWTT6KAh*Gr7o|eW##B%<CBn-l$evyJlxw-ota$SHPGLS
zwetM!o2LlF2U~aUKDvAN=EG-)w;w-yuzzD`Z)fZN)2G+#8tQL8*xO%QTf#p*vozh8
zmetZbxAI3!M#FSYxuX>Svq!%oGPAPW(?;glSRY3d4oOXYi>T`Es=}P~?m_HZ#^>h-
z%JSM)raC&?Cr1bBvlE=1tlcv5vi+k|ll`57;!Dc%D|(wU^4dBFH=n+I{qEhHhqrDX
zK03Vj`2PN_`_Eq9eemGUy~CSpyAPhdeQ;x_=IZSJ-P_wMvx_s6qZ12LW03ST^{@Z&
z0B3$hj>~_B#nIERg-Tp>ia$d^Ra?a%rK!3pzoc$pdURxLdUkiZq-}MrrMxn`qpP{A
zqqlyrvSN5@qAK2v>46!h;Sgu%Hny~-7TkXR`2Jhu`S<rX?mc;aZ*TwZo#!u~K6{LH
zbobt^`wySKT$ygJ9NWLMd-vw`>8Yuih4Jyh3ZK%t#_^kfyd4`G6Fu?mp%R)=lp5e;
ztP^4r)zn&?b9D;8&B4)$#lzLb^_AhSmN@6e>CV;)=*^oOYPyTk;@wS|>aJeyaYcn;
z>D859z3(18yNBJ+vs>%ycOJZbw6=2l-Qx%EUOjqr_h5g2@Aj=b56Aik=e9RDckb<O
zULP5qp1(falj>19w=@k@aMoh%q{5MLeD>&T*@~NgRAN$=m1nF=MpJj^$n@;Y*x2;q
z)Y8n%-1PP3@v<!c^5N=Wy19RFN^U_%NyB7Wf>&Uo$K~vtx|IC<()tH)9>0D2`puh%
zdwaL;y?Fa{Z|(5K%jb_D-r3tfxV?*Q^WF9S-U*~HD@z+YTdQ;9vx`gPJ^4A;mTq)x
z{P6%sI>k*Yeul--)31d}LP~gKO^Ug1x=(s((ZJTy^yKLH+~VBA<ih;o!s>j*R6|aY
zuj^&syu#eN?#{;ctE0V1A<>tkbBkx@u4b2Y9=v}0?$wJoKi}TGwRQOR&GWmfd#_(T
ze7Lu^d-L$l#@@qw_orGW*H@ONXNHECR@WA%=a(i%`wBZJRu8IIF|!nBTz!M6<Y$Bx
z#Jf186(&~Kx6aIu3`|VU&Ww*v&F<|i&&*C#E$q}sdItC<Uh5xNzB9M5+}Ks%5LB0&
zo>n(Fvokrg`rzHqFQ2`9b^H44`sV$okMHlS+<Nl-*537@m972#ox^)OH@iC4R!4ff
zJKMV^7Z%5tR_8ie#_IZJm$vg}|F9o{gBB-_tsrntxc)lf_8+&Ek8={XAVA56sOO(p
zvYyk%ptK05fOP-Z@|4VLz2jrUef_;d!+l+?{qx)Vt1FXb#iMtwca+6NmG*Z`E^p7S
zt<5*nLyHQ#N=ur@mX{`19=(41^Uu!?_qW%kMz$Xx?BChjxp{c|#>V{hq3r`Wlij<+
zjT@`eeLWqWoju)y^W!rsi#;t9ZT-C!%}HI~-@<(N@Xuq=u>rRyK!u0{Kg!`we=Zs8
zANk8)+}s0l6Wv>i3L5(+a4hgxZ*NmmXaC65(%R<i_3_HC#g(yvs;sn{x$A@dE8Trp
z+k<WET6-7D%X(%e=e7@CyngrQ<%7K&Yl~weyN?gnZ{OZMxV<%p&G9-M&8_XV2Lpp!
zeLYRhZP%_{>+Twvo>{s+-#a@x)0S8gUG@7t|A0@qIO0-HrHlI@l>Im$;R8OWwUxlY
zvZ|QOlB&sqs>$i${*LaR(hjVliIuta>WHeo{>ky{qs?vgZS4gm*_px4-f>=OwY>|=
zwH?EQ*EiQTAHIF}=J}(w4csxg{qg}=l)c9fH|Oxt50=-qceb~8#zsb3>dGr>8oI6x
zPL7Su&TlLZPpxjYC1yq!p!)9Z<2(Fm?eLhXoPbIAAe8+$AOTur(!hIKR4lWqVj|lc
zuND{eO%HbxGw+(7ot;^p8psdK>Fn*C+B}@9?<_3Li7CplS68tOYv>yq+n8*)+SNTf
zu{pi<_RX6&_in6@j`a;(Ke&CcyMO=1gU!jM)rE!W*`>9`mD$0e&X(#c6%{qDU4!$B
z<CE8?<|k)n2I~rQO0$1^)6E^4gk#!ln94C>=?PF_t)8R7w(u)tF`O0^Mp$re^VOQ_
z4lEzoc+c?I=)}yz!hA=Tdwk2#aBt((je#pUd401ZMOXZd{1{OyTN9I`SL-@kY8wU?
zM(@0P`}W1{<;AhVzTx@RoxT0rPv1N}TwPsWT3DW6o$Q^R8W_6P+EP<faizI?cyVQX
zcy4Z@f3UNvw57H&^EWp!F!nQD+$R;Gf84JS44@4qKK8vho27|7Eh^qYMa|8vHThj*
z9qpanBa>5O)1wpD=Q^Xk$_IOTs%x7EM|=93Cw6boU+ahq^st@W8-aYQG$bUuv|+5R
z{pH&?Z{Hm(&rc5YjLco%y7T1W+c%FM9&9YHtZlB|?CT!C-rL;L+T74wRo>J)c71Jj
zV0@%+rXxGDxVEw>3loemqr3OmOpQ-X<z%)(+8T&>|2-<Kho?oQvOKH2tGBbUroFMf
ze`I2EYHEIVdZxcFqG<lwWLr~R)z;zdoteskh5o6YXqT|kfuZh^u5?GHQ(9~5weG%`
zZ-0LC<ktG!Sa)~d@H8qPPk(-S_wJp|O%#`JZ1j#T&9s$O*41@%H`Wi%PA;r2jgE~D
zcI3nd7uK}breWF@W}|*Gaq+lb{RH}zk3w032qH7S{u*29PK<L+?`R+C9~`c18XTV-
zpO~3nU+ua!Su@^PJ<-(ORk`xy@%~y(LEBJoQ(jT?aQEEJ%^U++?~Kxnko?8*C+}Y0
zIefA+JJ`|P-P^zT;??U{PaZsev~!b$<<8;W^_8BIs*0wr{_48f8;jG63!?)-uqrB`
zroHV-I+-nKYukN%R?qSIMJGVzFK{Hs2HSq{y{GmoKDG|&jU&D7izCf-eG?NiNIn<F
zua0!LcUKKh4t8uDJbLx^?pj?yY~5g5X#KU$uEmFQ@v<gqW&Rd+SH{*}zIu1}*}Gc{
z<DH!_wQ1yWFCIUA{On-!#;vEj-7_P5a|l2U&DU!3x^EudoSdEP8D8!m?TK}&tgbJ^
z3WBNFeS*qSwoe|N%&!pN^67Qj734-wZt0o6Iy5_!nR9J)d}w@jcCdSVVZ5)cZ*{hJ
zaOLIe*AEujOR76Mo3c{|dmFpAu3wFeF7(#YcTeu>-F^uQ;rY)GclU-fa*>WK-Q7KS
z@ci!n?%u7t_g9~;%<j*3HaGN*kM@q;eEe>EcyVT6Vt!zFI6WvQzq&k!HSNmrlNIzC
zDj#CWr=Rs7e|B0_f+MPXdxkm(+q1(;TgIlw=N4L9x_XA&I!C6a`eu=)y}FNduD_wR
zY9O!bpuK8tW_lpd!$!#<v#;aY;Qe=R-o1MJ^XsQ?ujUt3^)>WNOx@mna{u7zgWWq*
z8+WF+H%EGVdp93Ee|Y!)!w2iLD~m%TGh;KOrI}Z%I$EJD#k6vl;}eWN1!Xt)E1?qE
z*4Nu!o08U)l2z5yJGH(!*V0{4+}=OX(%IR+y?*#+fA{gjrP_*y&eF>j8?Al2W6S+<
zMvSoT-KCy^g`3m&-o1JA?*75uqJWy5p4Ph7;kSGHk5FY^8Sh`|T3Q>sHnPxr>kYUT
z@cfh0%i~vvt}omeF3PX(Uf(SF9qF3#9QeYdk*|b`NBzW5du42JaBS_;V$ba6<nY{3
zW82hbZ}!#B>CtN&hlfvIu3oEX>8$edo4+wQvpLn%KVIE5zC1qIJJ(Z_Jp1$8*Ds#m
z>aaJ{v1sh?9-g|tdH?X?>%)QenYqQ~xykkUjok+~v17cyzc4nnGS%EYH!<B&+}t{{
zz1+ys#RUvY{e9jRsC<npDKsj(ytXdcH?eYdZEmr<sQg<0^4*Qjy0qz;ozcp%o6lc7
zn!S3pA~Pl{ccN!#Xr`rkcKycU#%x#j)M0J1-{8-$UO#>QxH>(~+jo9xb-s6Q{KfM-
zdoxqWUT)ug^!VldXAf?6Ouu;XXmzluvb(#XuDheDs(HDmYrJ;^96t_m9sdGv3rPNP
zFY>qVJgr{|2<z(XZE0+tpBi0W9jwcWYn>V2+UaaA>7SjxGgP^QZO-lC%F>9yl!E@j
z^v;>quBF{OhllI^t%HvrO~hy4d3W#C>y7mrYa2~9d*dMVw@2PQy+72kw6JjS_SNf`
zFJAxrc*Z^c&dx-6q?4VKUtxLUZ12cQcjf3zFN=%&CRwN0*5&@5zM<)rmG#~Ep7N&7
z(S^bC+N`9`iIKVarQW?)Z=P?p7UYM;R-)IxXKkQ=WaYt~JGT}F2euzR?#esB>(B1Z
z_4JG_buRBMukS5gpLl+6wPkRAdj9_F=g(ihdHZ&&EI4IsD3ysh)XbEchWeSc&8?B~
z{?+kE|9+T^Yx>x6C!c%Uzy0-}=qIPOm8Q1A;qj@BO_cTKYb%B)dau=Hgu8gu4|LDZ
zuWl{gfA;KPraCu0ySlxyqGxv(F>3GW-P@~^6Kl`kJ?@!7S>xXGd*iJwBQ-+@%Lh9<
zyZ4s&A1`<J_tYg$y?g%V?dwO+d;H5%YD=sPOw8yGr4228Hy*9_jc*OFO+EjQI~lm<
zR6oPw=;_zWSE8=XEG;f<tnXYaxl%peTG3t_?PqG0+dVKiv;O44y~F+e<^JlTlGeK1
zD<jt*?%uw+arepo#?<V@t9P%TuC3mG{QSZ58>>^p*Yf+8W)^PTd-ANOb9b>Z(aX%D
z=iRgCPww1$+h`P%k(_L%XROc6=xiODd--T$cwuB_ck0D|-pPTWXkPsYhR+^-EmWfG
zYA08AmdCnFi@WE`voWdHN}HL}**!EmefQ0~M+f`c(_L+K6;%~^iS?Ve?;LDxK6rVs
zKDBiF&C}=mk8VGF_3qKL?Sn^q&87WgLjyB7LpLe+pvTkHfbP2TV(;L=-3KrF^vsgI
z9nJKam~2~9*D&?)&g%BU;QZXg+aK=c=jG)tXncmn(bKPmN@3Uk%iMeTwY8?_qWKqQ
zlG!E6$vw%rzkBa5=bqn9=46tcJ+t@N-jkV~%#Itq_a>T<Xaa;p@4aKw!C+&$>Aee4
zL=(M;-aE#)?R}qj2?55~#@@4oKU-Q$OM<2K@Yd&hzjxJ+O-<Lv6}5L&B&0n^5!n8_
zX<WXjt*2i0^zdM7V{d7ot>s~Ca!!6+&DQ4n{O}Ztcji}ipMhABEl)gtd~moU+d5nt
z7FRWbzaQysbW5%YK!<u`ThZqH*52yEkl4~X!Qi$Yt8y$oGq1LFY-4hAbf~Slw(H5?
zt*51>rAkku0@n7FnR#zi<Zis4A#UG$?fZ$zY944E6sLwIl#F(dm*ph67=3rc<zdIj
z_*C!W^T*432anffgY}u&prwMlKvRzmjcq^OeEjm|!OQ0_WaF!AJ5QdhZ9iRJT#&Vn
z4fS@kiDTG#?)tihhQ>BcyH8(C&CM-IGji{6H0^Un9yXShw%2y-^pxaOR~1%^pZ?uO
zdU{&gX;i4P^n)16lPjVI35vDJA8Ku7y`sjndy=-Y@<z#nV6NtOS8UVD2j-?`mUo{W
z?C!t#{_)~q48Nh~PC!EM_U_E&=)}g(;lcL)v!`26CVFJs&-OPr4;Q2>>#MU%<HOy}
zX*Leds+wv##wK2Kk2luF)|OUBD)ZArd^5``#Z?K}dCr;LqmR-X?w1Ypy!am*8Gz+9
zD(G1{f2!v8y=8^K0mq`CZ$A{3IazB`cK!Tj*@L>m`dn`dHM_Lhrt!6z`Bji?+fQIp
z=OyksQLPPwW3vZa^JAlvnEslO9X#9F+MQ?_hREza-t3VqOwCQmWCJCUW`DS)qNS>;
zrm5*VxU{}CFYD{5E4=5?JU=C?udXkzjd8tGDyqrNFBJE;J_jlpucA`$e;1r87W|-`
znc5vF=-UrPWp*6Swza>eaxBkF+*46}uez;oWNvO@dHKbQy(fs_9<PoU`?@sB#yZ5?
zt24c0(|tY7lJ#eYj}Ml{I|p7od->w&TKD)uQ-9y^SecWS@*jSGOU1@nThoNwv$Z)p
zA*n8G8yXNz94^h2mWw5IMP*fO6-AYKRrOT`FJDImYrKEddS-|UtzoC80Pok|_LK%<
zcR)5hJJKzx9+xB(N!l8_MGZZpQ*%?Z<AYB@A>on_)@8lfo|(f#Wn<5lhWaKX<xTaA
zPoI7N;>pf}Y-9Tn#O>Dn;!Ia(?}#+p8Mni{VHaOp6~HqRj?T}FP7UOwKWgfhO-aWm
z2isaZhR6E)`$gq-)%gX5?dPBZDqH;HYA6|#qM&a-R95<?hdb)~M#YWoVrf@HO><Xs
z*TnSn%y9qe3rv7PKNiM%3*us;lJb%&S{mC#gI$GPW6yUE>D}%9Clk9bU%WinTA5py
zjSdXncX#u+m%PxO9l_O7@vQFMSYNF~(L+Y}sBC4er=_^4b$qa|seisvDlIE%-T2`(
zSz)N`Q!4ZUc7;Ucn7;i`RHPF_J#BsMu_==2u9l`cT=&4l`lNJX4Fti<XL|#A@t(Mw
ztiL~xb^GcU-zw=kxs}ha9;_d}+&z4GxVJw%k1D72&GnVJ!H!OGet6$bN8ZM4w5pOx
zNMW6H<4{@<{YW&wxVZIvy1r3V-#0YX(I(BUZo7{xeD`%!=4mqZM^&sdbS*<@lNNm_
zDoe{-(^GS~IhDQreVwHZ!y^+Tvhl&`&Ar1HFJ5dv3XKY8>)zD1b>R!u{_yp;|Mmw#
z`|9D+{M`177cXDzZ_IaY?e1@Et}TuY_lR2Co1|N7;;H9P7Yp5Eh7lYNOKa;TCAm}U
zt&OXwK^C`kcaKZNT_ycpF;TgdL+79Zv+|?j75U^CgyqlvjAZ6RQJGzSHa9h1_8_-@
z=3u0vb7olDH#IxCxOMpa$&2-h5HuU&-Tvz98-LV_Gyd+kx1IdEAsUOz%UhW8c)qsK
zG4O10VPk7?uuI(1+BQ1BwmjCmd2sM-ud{J?X`wl%sJ^PVC+lHWMqzPRLsMDj^gv&K
zeRaRAzoVn7tm*sLH0UI%mG6Ck2EAf7KNyv%#hLcn>XORdt-Y4Ek(u%4-q{t|!t<BU
zUT(KN$Ow-K=iU7BS6}_pmv-M>`O+|b{P5+=g|R13pYFamJeV1;S>BwU-CFDywW5ly
zdvSgD>2&An{PgzPAvnsJblZfA2aR2QH3MalWqae|d!mW?mb&KZ{KBdE(V?NC@BeNi
z^NeRc1IuNh($X>BSy@+AjA@Ui&YrIR;aaS-omqYM?D=|kb7A?zJN{Z|B=_}~Uw-jV
zzxu6n^}+YgpH7cH-+!`yurW6`-@U%Lv^wA0C2p;)6)){0C2H^QF6v%ce)@D}s5K$6
zGB&AoY<X|0z9hS~B)?-|biFq3QT6@OE=-~wZol|D#48!;r=z%!1Qpa|NSeCZtEw7B
zU9%I-?LAeaD=VwJFApa~qVCfCg35sF*OjmQ^B4d6ufP1qFRdD0AY&Ze+Fsvzu{0n-
zb=RhBen}z{b+%VFFYfH`Z;pxUnl=u$*PgES^wvCj_~33-{=&1Db7KXWWrd{`_j4O6
zazax?0|SF|m}GfL5&x@E+(&{+Lsds#bxZrB%8s#_^*vG3)YRU=+V+zd8$B%@eHCrJ
z9qxbBvNHMO7wFyj_y3RPBN*AkwbhNSCr`&Z#<pKRo<)h17$q;Fwl48L9CbsPX!rR`
zP?U|Cg<&}*5Aw3xb|(5ng%1nrI?~H)(wf^EvrC7hy@S0?{gNLP+2Nac+uq9=HPz!?
zrPW2H?c-B(TT`vFXD^@b?rg4Y$vQ>#ZN1{*4nLLuyk%&1>*~MYzK;J^^BiH_-X^Lf
z7Z!S^o*rz@&W%b%ttc-XnklH68LEF+G`6%TYf4PIo05`vzqq)$cfK*Ku%WlNxUxID
zuC=f(zggTh*)8d-D<2ts@we+Ksi`R+A(PP6x6)ox^suaNVqs@{ZSCOYv&D&}Z8(*J
zg4&)A-&%2`=6_y8BRJ*jSAO;XUg>_ezq=^g+<UP<)YiXqu)i@oFYRwHt!W-x!P=<g
zpxBC<ocOHbdr1O4*W`rAjM2xND+O^aBg?B3JyTPoLtT%W+Xp&FC&s!Os%EFR{ySKw
z<d2bG8SI?t%u7gqB$=3=U3iL%cp|Nzn(Yubl%$mo)dfGQOVaw?*I)hdx{}iM>wi?0
ze7`(5g!;FI_6MW$o6q*AP@>Y<SU&S~qqpK-WI#e~O;UW~-J;^MWc{0V$)(-Pz0*C}
z)#Jz>m-Zen*EbJ!txriNmSm%y;<5Fqh5x>mc<1iN$i+3)47KECrIdEIh<e60H>c+w
zOC;msT2WPfX2GBYi+S!F{`#xme50*>OHE1DsNu!(xNKo_wza!ew)XVdVn;`BTTWeH
zXLVjeL2FfBZCiPTI435#;I6NUMRF4YLy2^HX>6oDJ1?!FGQCPnRqf-8lOx@As792I
z{U57w@!)Nh&e+(KmzU+4EBl5ADw>Ont4k_|vAk((`^gg4dzG}76y?@+wKvy165jaz
z*I$0EqOGoaL*;hj-rCgM($bK)zxy%D586xHIt$C{#1T<lnR$}(nr2bAxIQ5~0{4jV
zDy;924ollR28Jbh_wV?4JwP$`O!x3YYg1cO_r%EJ_WHEwZ&qVtW8*(URC*VO`rC#?
zs7V*g_O>^77v~l`TJBXeVnt?CZDV!yL)~k?`|3-y8od3jmiF!FjfFX>OxDpqG><y<
z#|;(TwRx2t1-ZFpHEm@j$fH_&$|ADElXFW%1HE1Sn=^fFRb6#e4-;b~)13n&gT3{2
zr4QTM`^Tq7W_sEi{@Y4abWBX&$H(!bq;GCwda$#8pnLUjb8UBNuCL;LVo7~NUw>U?
zX-jjC#?{~a=8G?HT>rhYmWF=r=Ej<Id}0jT+vfJ+v!(RPru>wL#VzHf6SC6MmXhk$
z&YXyx+M?P)>0npS>Of}W++=xmWl?h8fJ8FXCu-{)5*JCP$2ayn`Wp+H{@Y4KL{xO|
ztrL}*M;-){QZe3JgA|3fpeaABT2NlEJ3F(#F(Di4A6}Z<+uh#VnQm$-e~{MJ&^j?v
zU6I<{?)BZZ-+uG^Ynr!IwDnBw5+|SSF9Vgn`HA%>FP_ibFKp_`s>tb>o7!3EZ*8us
z>ge*n+b-$q>z-L1-dfJiUVlC#&W}xK85o|Jmd*6`4$jXO)ekMr)#r6Ty4&^F%c0>B
zQN5?=Yl7sY2>JcFIQwa$Z81KuPr?!5yNyM0QzMhh8w)$T>o2xvnsOT&($m@-x<`kb
z1Jn{a1OMae-`uh^G0?Zu)3dA?NCF8b8|WOK?jMk>t#;nOU)3@^o+(}%n;4Q!b(YpY
zN)IZVSeg=#V!CLjE@|NT>ST9OdFSNB^!%c1cyt!^nRSnP4|W%qhr7Dk|9Tm>r3#na
zP>2Q?C-INwZRNcv?V0Mh_s$NF2;Z&Eg^98GrIoG4Z7k_&EiWsmD9uc3sucANiL^B;
zYJ+e8yG=}Ts&jB*KuAPc#oeiK+2X*!)T$)ZXK3<KY;{-j_TIK^N>tM_F)X=T5apde
zJi9a1zjnAd(A_t%u{5?i)YmmQIX*WtHQB$lE$tDDdKO+D9_(YKUF%;j2L}g-_MEO*
zCpP<J>F#@L5Tt|(Z9lkA!V%%Sw7S(lyR@;qwYDVdEYB<`DakD_uj=e*ZXBuQ=hsFi
z206CRH%?_&$+99n977)QT%xk>iI@7~Vyf4r$rYR9{j*P>t*^GG7R|Jlr=%BF^bgH$
z%uO!M&uq_jElm&fNT-G+XjU>U?p$BoT%GFMK6t$F^yQ1)L9wLaua<*?f`YqGtq)@O
zl^=tOyolk0`y?C@z8%9GOA{0O2lI2yMMe3Qb!An#*?BGf&7v0A%Z_B<itL=`<(7)x
zp5?OWq!j-ULCQu!Mp<3%gRPf+4Q=aBX6C2*&~pQKY-s51D6WxAjEoOYOv+}Lo;_V0
zpOQ2-_l&Nt)Rnh4cZdg8WOJLcgZ<sv!^6k3L%kzFB``1`pzBok2-2k=DJx*(KD<xD
z5#ft<aO<lJ%QJ07MTL1~wRr_C%^ATD>&n}@_pr?8@xl%kt4b;hh6ejaAJ#^h`6N9k
zkBJWoX+{BtXkvD5ZMMI^ceqWQY$r$_9us#BP7L*q4i5~=miM+dHnw`JYg>CqdrEpx
zq}|>+&^`a+<wi?;-<WJ_ZgOs-@~@TxFgnllb^0;ZmJIF5?aAJsi#w{<J=mMx+!*a_
zs46bZ$||fbu9i0B#olf1ube@DjOQ<wy6UUzQWMf73)^$vECbx~JmenR+{`p==gH=?
zwJ|Kl?VA`G7MCX{wMdrwJ38A3Muw(mM~7!t5BA5WCI&>UL#>U&Gl=}AMPoAQ>hq12
z;lbXnzR8^@&*zH&a>>`v&rke^V{6NZ$|;xh-gZS%X#1gk66E!|^=rH9^ZnJ8Wko2*
zNV%6=UENbxlV8~OAXxVF<;$15^$Fz_!T{01lf@b@!?N*5WnmB6gRIRs_ap<O5=qy<
zD9Ww-2HV;PCWeQ)`}+n52PfBN_Qs@3%c9yUSyN7T%aT+C-fnYrQamKtd)_%P+~3<e
zFoBhdyORtmzP=r&>iE$n;S?zE@0k^awjYYh5#c*9H#^W={U9VTK0GcXBdfTizFySR
zJXT>p^78q!7puAV%41R_+fQ2qbiZ-O`rPlwa{ajB0sNer(#q=EIxNZS9q#Lu^p8r%
zcS;Ld`=ru^ooU(7#QO3`N3%4)rmJ&!X=rm53HIueq-<hkQPwxNIxsT6f!gNTvcFvN
zL1U+mw^R#~M*N8J-k$mBTpi8g#+>ZCf{^&6w2YjBl1H_z-GlX_c$emvnE#T-2;&P!
z#x|b!SA^^O>^^_-eaGT#*<i6pSk|5UIW_2<*woZjTHD>z-M#RlC82e&UnUbZ4Nk61
z&u)(Q^mj^n$A-l{Ypb){FJG?ZH4aM;pH9pyO-)TqOki&I5m50)M}XhGqCux$ytf9O
zLGVLSxr_=$#W{lm`~tD?5O@6!2?-AN_xAB}7kGFGJlusI0=|ozD>duK`XN``$$;;U
zTL8M^5W0Cf)6G{M9G#pT9GzWUczD-^?=BExczFAw!+@u!m(U%*!_&jl+s_Y+)qH)u
zygY>h`~nxAGgc&Fi#<nsM<)k+X9q4i4?AMmb8rJ-8(TJ)%jGD(;bm;YY>m~gU;F%I
ze0FMl`hMfoPoCaY{O(i7&i}oiyfQ8W4aGTw3{}7T%fF4-mXEF1#^#@PY$(S1$yhrY
zt4Cvn8Ow@qcp2MJweNlwJ>67NQc{djR9IM8P*9McpPwfm4<F_-;{nEf4EZzdof`BG
z9{7m-!@1}<h4GL^9zD@3yqlAgot=H}UREZiS}?Bwx)>CC(p`)@i3#!XadC06G11YH
zkr5H-s2O@0XeiDZ_T67b_a0$Fpa2rWgRTXGxfntO7o9^x{><#sD|*Qsl4FFAF(1Yg
zp@QE7d<kI&82k<bg+V2Q%Fa-aheAbQawid}0F&6581%)63<oG7A&PH!8QYLw|Lrs*
zCXA#25(bG=f*^+@J3EURxF}|1D}XuKp8gp^<zXHwK?(~IuaoQ@{o))(R!CTYid<0c
z0F(q06<~tOUq(`>b;D(#p*UyYUq>{O?qEPr@*a|yD=wY3axgIIdOR}HGcqzWv+mu4
zIvjy>yraPAKB0nIO$gzmM*tnr0Gqr#=uu7%gayA3`jbL6tt2PF1fawM6G%z~L<OK+
zE-IhT9f?X2zIJZTJ^U3@X{4p5rOA<CgdMVuOQ1=T6dI|xsc)tn7y{>b08>JSP{}JS
zE-f#wsI084C@(7|a2R9=_j_4%7FZS19@Ibs6w)5T1fqgw79r?<qWHUA#y0%(ZMmcr
z7ZNDAAr)i&?%?a*0SHig{3jV_tYKU{<^vKE6YnG?r=la7T$zp`Iocs)9^~fb7nfC5
zW8qtUZB2DmRh1l@5)zr*``Lg6s2ocQ2z6*rR1~QXNeV<I@G{U)oKt}crRxMrasp%Y
zKyb&#!YMF=`OZ<1(J^reiNK1$N+wKj?PQV}Z$&%IU|!`xd$82Lv8AP{rKP#4v9SSb
zwCifC37bbHh4~Nf-^(CjA;d{mNKzmwQH=8mfuIBh1t`AZWo-QzSt%l$h_9NSoDhq@
z82)4!xEVMNNVQzoBV*DSj}6mVP>B0sl$MctFr!MbQ&|bAfMg&)YiMc}i95TxySutN
zJH;3sB9W-Qt+l18v7xS}no+Bxc!2SJj7`2D$7oLwD4)wfLvhaFBUGUC5S7%saZwa4
zkY<C<4I>{(gOTYlKd#l$u(r0brDf1|oHq<ER*vJIBFF@oLCe)>P_E$Y<V5KLVtY2*
zRz7GwD6N#W)-nrw7#l>G`1>oq;bm-t2o-V>h55PJ8L4-GiW~)k1-LNyK+T!q#|g;A
zhl`4eOG-=2E30a1YwOM%_4N&nO)a8Mbm|(w{L4Upe}A8R^hzW>U7a0mEoggE0|~3B
zs3<QlD`TuNtp5GG_NuWdgo(f3WuT!rXCP1^{Q)Wuj!+?k7v{mX=DK_PcsSYFxdj9T
z1EY}8@W@Cf-=Z?|wq@lNz@)wbSAWiEZf<F9@96Fu93CB;m>3@$8yy`TVaD*#kQ7VU
zyF1#N89l0I3^A+?peZdaeN<AEs^y*vOniJ4-|#ZF0iSQnK`G25RFV=9T}DMYa>5Eb
z#=zdqjdzwrJ9B-5Np65jq>B%}dPzxXSved`9SOzjqp7i}xus3ig`PkoW8**tkPOqn
zGnV{d=DUkff%OF@BrdQqz=VEpNpZ;oBae76KHisshT@$5pKr-gDF7;&X~}osg4`W4
zd)8hMP4Yb+FE)DbyE_Ghk^PN`3bXfyun;N`mWqnP!kpCj@Nj>jvore?JV2$Pw7OX|
zI5IXlc?y*gLS>*299er4p~6^c2nqt4(o(_%qa<4?CJ2p)72ohOwhSuJp8`T9D?KIY
zP9is|YyXGmPYxb4<KW5j9}XmU9KFIxh$6#7Z9~dR;D5-h6gGq(QA~&G>go-R$AZ(;
zoF9KDIzA&;dV~suWQY+LsdS)U++2@^ZcT7Ra9u~1g+v9AK$nY(qcsz}y*w`i4aGSF
zKi>i-lqgfUl984Y=a9ef^2r`LH6D$f-MuH@uN1in!lEdj4Gl7W#GnFMDQxhUqjI=?
z^B>e3$jl%zY4opXjP>_6H#g&Fq>huUFq$KkN?}ycKt<e|pPu=ks<y7C?mmNwLVx6_
z;L8{V`FnUMzTstT8B~DD5i044&Xv1|+glqOC;Z0-)s8%_^>hshhaC<Ha}|~zX;4ms
zkU`~ed-<mG&3afF8uh}Yv~VHrYvrmh%qCeG9T}Daj=@1Z4?t8N-F=vomQq<&S(8->
z?KuI3tUi+VqHxm?55Z-ip*SZrhy<k|9~uN%Nq4H++g)E>##oY%Wpw{pSzX^fs1-N{
zFi~fiQ34s3ipuKL24_MApp1OWCRBh6{`rT;2kYx6cDCyAljNu{aG+|FoOEAv{++hA
zN6Cq$6{Yv(Zke&Pa#u*?PC=Ghgy2$9@%wy>0R@>p>`I1n!RF=!_gBCC)fZoWeeIjb
zu~|8<y|A#nxm)b$<QotW7!b^JDk+9<uB?u4U>||fd&OLi3LzsDhNs#*z_MF&#|#FQ
zVLpxi0SHQ8pQJfI4KAoWy|%JAi$WD(LK1@;)lhtZ%sM|;FG%RF_`6-kHsA!6``MX+
zv2z=9j-P)1^S}9@U;a_Yg%vhBjkTRLX6DwH(pgSkK0dzwfm+2yC6CG~s=^!0<&x4X
z`a=I(;86!(U0?6a7RHBHwTXMo`J_QGE4u(?w+{<&07_3|NfPSF(H)~WJBz{OQOO2C
z*^sLbaa8#%Zvp=@&`_L{L4`;mWU}|tc|9A`6aV<h&;Q|{zxw@kHUDTe$@nySCr^xz
zk55dm_xYQ+czAkw2bp^zx`nX#S5)ZhtKYo&?UgU|)xT9lx%F(eIgX;ko4K%XY;uAc
zOzjdV@W>R~))XZ*w=~|*$^ydzIiWD6c%yuSj6U;4fQpreyPM)0UdGn%vn@GI3*IBk
zJ7*a;)cL>u>VH->w6wOixh30*My98x5Qo8wj83i;u&i7KLJwbO^MWFfCzZm&!c>Y?
z7!;0C0Xhion%g=aI{OcgV%7<$4D13C3^Yvb7UyM^G&j`NRF=yjVLUP;DNOR2_b~6F
zxi|l^QK9bw5&%IQuX}E=ukY{w&;MQDh5TiR7iHN#f_scWRz?tJNM|KJ+K%o5ftRl;
zn1V-TmCiY-;RsaJ_082GFLGI_rGeZ0Hnn!R_}?2IMOD@?ei(rp4S>?!iKgg4rK+L~
zfg9tEnK)9;V-m%ici+g@)%7xDL~%~v&$hsb5Hs>1J0@mwsHa=<zy9&pO#@TY(=v{~
zsi^c}YHA?+A>#Dj-XU3rj+L9cyGNjEeo;{gP=TbV|Jjuhne(^bUb%wFUBw_&>avB7
zQlK(E%Aj%#N|(6fURF^xM5XKzFk!My@EGKL@?i798|U9O^SNA9ygu6`NbqGIWC=^A
zdc>WQfB5b1TcoI<n>BSb5L;J9-wlnm=^7Z2bW5hnZH#$*zDIy|0fP!V-e0JG#aXs2
zymIBr7jj5yYHDhUfom-CXXhe4l%vwu+rtd7Eu9^rmh7xYAXrLEASC2?<d{HY8BlU_
zJzPCpd5XW=Wo(6n3MjSQ-1}L)Hq>i(N`7_yKU;@p=H?gDxG|DU&YiaQ`+~MUpwcte
zF3_~+^MwI==z0%XF%K7h`wtZr4WgR>g+T?FFaxL*rndGD4vi2hln_F7@E;VExTC$T
zrL3&F0-|yR35+a;Tx9WGlDL7cyh}yJ<Fieg!@|VR{Y-xEP^Y-7?^oJt?IQqX5iROR
zr$_pvV|o5<{nEbfo*_wy5}WTP^fzQssYru8fd_*6e1QSB1&CBv<3CYx&Fx5<rAV4b
zNc|*0gfIapAmm_Hs!3GjZbuFYsWH9=?(!)N^ycxLFGEHY=k)w+^Jro#C({=_*}8iq
z-<mu4c(^&{%#_^7nyTbCj2GueH%oA3eZ$h&8#Zok0$*dYE2R}6tBH4FROd)YfCvq!
zP*Zy+P#GQ@gQbQ7F^~WhLZ!7Ct#%nyXgY)$axKR5gLFYyI2gN2MMe1OCNmj|dA*GA
z`lhCu+GZDnfXw(1K6g^d|93OoB=>PnYjRVkxVfRVttI_CD>qknUy}mFafAvi2s21Z
zFc?HY+g5>kK?l)Zk`)FOC=ld?A#giHZLQ>j%1euBvW2nq5E4dSb8~YNoMPe$6eq>s
z?J~B4PdASy{jxLSE3+P!)V4P{DA}@1Et02_u6WJV>1R%6b8^JEc~@0&Zq5Dwuyl2G
z^D@arR8fdPuADd{3?^ikhwq5sODRjLX=oK=5z@dQ>Q_5qOE6k7K>0V|ZZznN2~LzI
zCTYHenL=Tv<lJ2{5*cpyQc-bdP{EAx{p|F(`UmJH+$9~64h@e_%9giRW|y|t=2ti8
zM@Gj6MD^tb^*R5+0xIse*iJ64d=$EPDh6(_NrNg_Xy6?mzrc{Nh)9|vrMW;%X3(I5
zO@BXMZ`88zsgwoWHrQ?XaBy()N-GSeBN&$<BZ_kpDmfT^BO}rzQ9f1y^iIr+tE<uS
zbz4^2wcVTAxYL^QAh}1{)l^m7lIxm>zjs^jFmM{5n4FxPk`L_32P&v&;Eie7EG+gC
zlJCWZ`T4oI+1Xio%%TnPj65`yGnZH>dpxFwyP6e4@eMCy3sgvi`$E3{>PzG9lF~ZS
z;LLj7{Kn4X_T@)&xob)D_tsLT`kK@GyIX6@yMq7XZ~hMBfBdii@0Y*&moLA%a^>o^
z^Ts#-_WN)DcvD4FN8ixI#86*XTT4?zT|+~Y85$buYAQ;%ZhZIefB3h5``tI+d~@;}
zetl|O1{#WUx_`PssEmA#1n_=Wby;KQ$l^}^;#_-s$867|*15(9RdY=_&GpgU-R-q?
zlDjeO_~3uZP<+G7*t&hXf#QOD3@VLH9Tm+z6D!*fX4{9xr(sv-R(IEM>yYL94<kBz
za6{LAzx3`SNcx*9D2hGpcxVFg*z{8B#|)&zloh`+%9^F`MD{Y!P@K~RsG#bCL1p;C
zNNr2+)bdvLSi|_r&SPm)|4vVK$Ig?-87U#+-ma$M2KS;t`Q`Mtt{&hvPDkVLoblwf
zad13##!LI(1&iVvUdGntlMR%p$Wa+9oak!lpIY3^kkm|XKYP~vq-mvK_}<#Vv*gGi
zQEyj|EFr8Bi4DeBBib3B3<Wx;x32?r8m5_sv3J078E7cZ>HNt?CI%xb<2_Zg9sT3;
z8%d9f8B})iW(s;+@1-Sqy9nBQdS?4vvwGy9j21tAiq7t@jT4~WvA0*!^>L$u%B9R<
zvbN(RkLIQ%W3y}V+4pnu%PSUFi>3?2H4jswc{aXnol~1(!L`WtFh)m;pFcg;hl8W3
zBl!dp^Spm{?7cc3KQ8W+OC9t3&U;e)-7aGb4FW0|a#Y6q3m#7l&8()TWapQOhZffh
zr|a&<h6no#yegZeht+QPC33kR9g?GR3J2PK1&UW;IDWOujK>GXX#MuqaT#bR&It`d
z&6@(1(YEH7Q&X$cSt#Dg&d4sVT-aHkot~Z?#mzzX$9RdYM^`c;Eq;D@3X)gg*gr;q
zcH}6WeSZ9;So9I2;`GTnRlgm{%J^_KmewzCEYHe7?$69DY#tushHqPI^RxRi{O}ru
zKOGqaDyN`$1&32W?3_1fPV(_#ar^LFMP*#^ce{+Oqa2kX#;)LN4wj35*x$i~>fYY|
z{^KXOGZ7jBJ$=0Ya*Q8R*01mz$Ee8RK!9udnpnIF$kFtyV)OWEak~Oy1vnHY7bsqg
zUn(j`vT}^d*g$3JOY~NL{^I4!?`gcmvJ<Q`spEy0^(jCZXHYp2kgKC78gdMV0)SK7
zlX`eU<tXww#^Gw~c<a^USC@?nYDm+MQ5hc_Y{(k=;fEJ50Ll+PFt~jG{Y<P|V$HFn
zjE@gPgPxoqadi|}j9$Hlt?9LE8Qa_VvtJ$B!hd?up{>nyI<%=6`_GEo2Tl-R_6QX|
z_O4#z8$fI>Lvs}8<bAS^;@VTF;F8;Nvm}Siv^w+jVkFHi_<pPOSW-@*B9{yXm3rUp
ztHUH1SMh&%D<cDlY;MYtxXSD>`y0$S7Zu<JQ22z*_|;a$H@u9k1A|K1iLBrojrKKU
zC+0LtXO@=cN80WOxrb%dN?!38Br6BUy0XKdk&!{D)XAmf+BF{lfxkGAsKK*zL;hcm
z$;QSWWaVtkf22X!TskVSD^!RrRajg4MhNG6n@cj{!UFyM1H)p{iyM1DN}nF5P+_El
zWW=Wy!cl9=C=IaiN#6tz0Hel)o;L`a!F9#hJs*{Eg91nio#}FA#U7}nq?|<s@*?dK
zwNQypOMCa=Yf&i0D~|~e446<dAfzu>hiZH_YiLKh;gbd|*4M8NR{N}11CO+{^{WGl
zr9f+h%6WDLDr6A%QJ_L)`DbM1v|OCGKYWDBky9a5Ow#4H<C+iY3Iu}?VIEg;Xt4U~
z+S<EN!4Hv~z}jB6tiY}Sm6Z2I1$Jd0kSJUVwhD`Ztz1ox<>JgzF=oZs&N&)%2L8*i
zvWjy;gFY0MBS;i*C``s_OpeyfDK_%8bM*X?qr&}UJsFEzq+gx+OTGOiS=;?1I9@^H
zSU`?|IKe@_N2O&nwm)uJ;eJB>_>(^XmAz91g@nv8AlQ*(@+u^9IF6oyO50h_eC7|K
zkmk$Sa(?kasPtDp+dT`#5f%(0M}WM7#Bl*4$`H2>Yg;~IRJb36inMY332rq)Lt!(p
zJtZ3oIF1T2k2Z_PW9{*DspO1soOyW}GNL%A-7nT?71ZEY<3p|Guki41dr>#{WaoT1
zfXophZvsS)%*Nx1x19j*DZb%lY}pD_1{z0Jj>3<RV{;j3D9#BDf~?#f{Hl3$^Njg?
z#ku^~zfgR`%h)oqau=u+!$eGAdDBljCK$cD(0Me~lvOk|a1RPiO${9lZB0!zH4PP2
zRaG5L6;(|w4K-~oEj3kj4K=h}#K%<Cv^BN0^)Y#Cpl4uctgmlqXkuh)Vq#`tX2G(w
zv9`3ba~66B1_uO%golREil^|HxHv4MOia3yayL08H7OPAL(?)-vDP{@g;2SBH)-Ij
z;?0$@zO56^<fqx|8-wAw*m*Qm)znormDJQU)l{_9wKde#)ihOA)HDHvx|#;C!mhfC
zs<MijnyRXbx|WufwzjUWp}xMJp}wJ!p@E^1k%gJ58Oz+l+``hz($?A8#V;t7)(wUP
z`iF#tMPqeoVj`lFq!cW<#oFp*T6mk5N-LMi+F}qY%e|Ys3g7XQZTmKtm-{Ys9#wT^
zbyamGRb^FWfPnwn+G;8q+Gxh9PI##jYD(&wDz}xCZ{Jn|T-q8sI(oW#hDOGEMn=Yl
zdin+?=4LEQmKDp=(uTuvbo1~J3diEo@X%mdP8l8<8=sg!t|m1VfFK!6PEJcnN4MX!
zG`XxWs4Pi#UiBM4#Vb0;#m)l((7dgxs;;7@s-X@!(bUn@&`?uVQ-i{2ldxc`qN1vz
ztaAItjoV7MRW&vBv~{&~_4N((jSY<<GzNx-#%880Yb#rhGtbS{GZ=yr84(>F9ugTE
z254dv5)$GQu{axRh#?|~@v$Hun4~0gK2gZZ#$xx*aXj&p?a(<cb{<tVC3Q75WrziE
zQHHeOhAtXvDD%LRrYZnZ)6`H^QogBl`}WP7w{PEuL}>vzZ9P4GSQQf^V|^po7Bgcr
zYk=a4mO1{kOfWnmB0Lg;5)m328W|TKhc((*q@9$M22?;a0Tp`KouIPNy}j_RG2YbF
z(KRvmu8+O>eLBYl&Vye7qoJ&<qNH@|rm~9iZK#ooin6MPrk19<rn(ji!ZkHvVsGEN
zdHweFTep>ODQRfwX=-ZeXhB*G^>mGaim9=&8Ce!fuDhq7e_&8>B$f!q#6*Ng1cryB
z04oCP*kj_+^cb3x3~8a(4G<eB(~+#e2W?#B+qMkv?>}ssemgAf1q%x+vdnX#c@I>y
zlyBj3Ra8`zZr;A7tf~nafxT7I0W8oSbqLBW<y$vz+)%m!Nm0F}rKzi{t*4_)(gI)r
z3CxPQg_RxKj^`a58Ws`}8Xb<+lTqQJq2bV=kjUtGnA?QA00mkDNH8y!ng$P)oNiCD
zg4p)!;`RBi?bBVZPVWzjL>;0I{4d_G%bhJod1!|iV_<gf^rsa2!|@~Yn}rpMm#=K;
z9B)3)>5szND&4*XJd|!J0iD~hC{Q1DIAsPE4Gm=#)!X#u&09BbD`~=0>k%qCI=Xs#
zdWL2|1$Qwtv$c10@$m8S4GE8kj)@Kr#dBn6aBy&FNLVDg5X2|M-<7)_*b~A8_@pGI
zILdQoLS;_8HTQ-g8p8L*EigJN_jBv!3oAQ1`tivw@x;uzKM-Frzr+@u`xc$!&F4A&
zBZy5@ZYteWxph<N`hVVlwy0>RYiYm%!!JWs)KsBS5TqMQw{PCMrJ|;zsimc(ucxc4
zZ(sm3Yhnsfv9PgocH{f{`ayd_g3+LYP>Bi)Lw_$4ni${`mk9p@VL?9_Ad-RZ4b&}%
zP(c?FLS<IG#Z>d1^VBhq3c$RhDb#h@<akRCE!q|jPo4AO+1cXo5s`lTxo^=q-h7_Z
zKSD+YQgVwNuL?AYTr?ar;Ly<0)*=U_goE%s-`!AxvxWd^>5{1E85kQF8tCgAnXnzO
z=s@6sWnRJPa26U96@!KSWM_l?L!;2@I5s*q_D(W&Qc5RCNLCojLa3}0SPUv1Z%3tY
zf3+DMAX*zy_0^copdvjVmCE=BLiN*Ec(PCDpa)a0{MILcaPuaNEw%&?;xu?>EeHu*
zGmNdOva*uWZFpwL6uBx52n)q4<dF3Y4G^-h>|KSP9$sGFsAWYk8y*pp5DiNk85$bs
zkCIoQ5+5I*3~Q2>k&ad~X(<_LXt=}dI(-T*4zlvw;`JHPCW=1K9gM70-^-%HLaH0S
zmt91tbPP_O`|&OzTi@y2cbId~d8*%;f<i`MWp6_}lyAeZAf(sDg=^>{W>HZ=vw2t@
zL~qLK00a+JbuAroL2%2sqoJ{pk-3?@qrlt8-!C|TMo=)6Cq9Neb67BztB1uz#l|Ki
z-c3t^d=M^Jw4BO70&|<npps0etjXFpnI(qjJax>=$&WE~JRmrZM#lhd4|m>h)Hg3U
z@3@RP2c75Ls3=2JZb5g{Zry|yDQjqI>u3Q0Z5?0$zjXV?ty|Y`Dv`fdQ&&Myqp7B@
zuA>iAYhY|_YGTE)=ec`%qeUP}pF@H};e8O|#{v}SQB-tPbX?q>M7ZPB)by0h^py0}
zOyEO8lbV&0lFDObC7EPpx@}|n4dV!vGoXxg42+-m13l@&IA{0d%Jbf%bI{}6s3;*`
zy^S149ri;>Sq*`Tu8yi2(nM9{J<2z(U%z=1=2o3jNMr-BwJ^d4h9(GWO-)!f*7iJC
z^fiP%fuSX15{4@A=-7zpSloUf4pufk_Rif@Mt_j{WM(4HhxVkyw4|q}q_};$j<_Xx
z@JjL8TTl_tk*tiJMMZQjDm~FYdIpZp=5aqB6(+hRRFn|qYiT1L)YKv~qkQZ74T@(G
z&@##c&4L})H8eFs*k;ONSz22;xVXD}d67YZ`w5K*i-<xygV;zI*o3%*IJ9EALy`g;
zn@Jt4GGJ}f(=yXDGw@Q53Z_1Q%JN9_szNo+ZpCvzgaPHW0*$nH4W9iZUZ?t--*j>A
z%)5Ecd(1iLJnxnj6*U!#&Qx!cL4`L)NUNfuiL!3xTL|&5U%!Qvfbt;90I1qq!@$_c
zlx1dvW;a$G8!HEASAmDn+gsoh01pJ092pW48Hvy~CV{MMd;;ZzKp-tMnUWuL@4A<X
zjtFU~87V2r?vNF17*v|xfy(G8)+1w`DOQ?dp`3W+4XF6HH{Fytx29Y<4;4BGJ>HFq
z8p_(0!KaX$f%74TMN=J~7`5({4&FpEpbjssrmCe&)QhIJzM+8$%iM-z$FZ}q!SV|y
zK1qwGFDR7|%6-szC?X;@CN_pJxpNnn&4l>LcabeqQkb4WqC;^?vd3pM&n%af#y6uf
zi@q{2wEgmsg{kKeH}sz`E5g<XH%9{Wul)UasL(m+@orR9l+}?Rf;B*%tfQ@^4+Vl;
z+=iXKb?erD-iGr5SV*PSwXsY<T}uztfsv_&m5r?(hik*;IP!Q{P3z-@PS3tUL80N)
zc?fMD;E$u?fJqXyW<%-&;kXMYjQ!M106_^+%H1SSpaRIGSBh7dZ+qUAjEr;=DtN1p
zL4^Tjx1+PN`CJVO(7*Y|k-V!{@1FO&E{=+l3d{*e1SH7H<a#vJ!NMU#xphP7rn1s?
zL@DYTSU;f+Ia1d#(A6{0*D<!TvSFjw6xWVx>%bFw`g;3%2L}22_ydw4KZN<nlM&U%
z#N7dPkd%^?o(U;QOHBeU$cB>8?GT8-$|eI93ho$G8r~=?owM>Q1S(k5LSuKgW2U(f
zZD(E|d1hDRUq5<ugw8>acgu>Bs)`acL{&pa3pQ38$svdZDAkSYw{F7bz#rp1<j}Cg
z+6JbEM8BDWinMod;G*xYldC(#1U-NJ0{#8`g2RFWu{0?tAS5&dL2W$RyQL<lX226C
zF>UegqQBvtICN=C0xBsfcfElMWJ!9pc=fHaBEKj`R`zz8DoN4WOmBAA&>OG+{5LKx
zD~R*Ktbm==fkn~P1tZBMK9miT48dcA&ea0Xq^WOU%wm~aniyMITUoNXPWH~OJidpw
zA3|EcKtC+g3P4l7z>v_O03?N>k&!V8L`hOCo0goIfDVC4$<zunG4XC9L<ZWGC}dDc
zWl(vytn}{h&&@H5pLTae4Q096+5PVc%f)3y6+yldtSE9q9bIj09aZ=qB2wU!;d&q?
z>Z&^0`UrOo4ZtkfSOO9oYnCm?(V540<$HSi_y>nTJ_50R%`YG@Fbo6&1}KFn#BZPp
zlE9_Fu#)9Xq~3|l1|1cX01m7zWJQij{W~?NmrM%7b03v|W%o$Wmx(tWrE}2Z0vZG^
zmKbbJHA;TewL!?KAlwDNqzsos=0pQ<AyGCov#_+~aM>KT9T#1zc}^|@cl4?D4?^Q>
z=uJ>?kU#DOLL3~NP<VJGSSIu|1T1%x?m%e}x!g$vHVAg1M${Pd&K<c15h`oUw>|%A
zI%nj^C3}0bvorWVL#S-;>|~#7Z_ocF%+ZUZa{D$CK@}KM4K*!rD(VmrWmsC67KANG
z6d@(*nh4ztj4f>JIUIWqEQ$li(GhDIUA?^h1AGI6!oq_w$$>ZyF&q-ZPymC*ks#la
zl5zDwBo1&8^(2pAphVCi9EkV&e4VI%>9yju(fU<#zvqopsF0`}2@1-;vb&|{eg4hI
z=p6L8fUKw>G*iVC5Nz#D6}V^+2gm_HSgL_FK!^`P(ZduFYzkr&ww=9`D~v49*@?n8
zA0Hoos8D!F02<weheyRG#>OG}0XWeyQHfw`sm*X=Lfjp68zr6+T{qDRGl3)r*u?t)
z6}s>Hwc_;)pwhFqN2#!EhEl)j>7Nu8gl|L`AU{Urs)?Wl!JHB@pxY`MTDrP`L>Eak
zB*n;rh3=1b9D5gM2M0$-M<<@Z6LE@<pKovwLO0|<u&?pd6O|B&K@(8wyc!>ej3`c?
z6vf40Y6z&{C^|C3!o>QMtN@j7-ik`skp^{>O(ET3iUdIh{DiUs-wV<ju`T!|7+s`^
z+B!&!K{u(Y>+0!(wg$mu06xVW)GWur$;FN5WRFhvE_@F!Z*Nb(AnK?e5RB<CB*^g*
z)N>UB%}1l7AvTdQQ4o<>Q2e0zqoQKabr=a_EH$bHSpJ`5)l_==#ZfseD?ceJG_#=$
zaRDMKw~_RyBV<9OtD>$6ol?<-yT;V1iGdM|Ws6$_@Z8*8U7a2692}ipJp2NDgnmK6
zbQ1u7|KP~*7$`+-bPN*2h{%{YBtvK#OY(sSc4G00<OpcQ%Kyg%0u`jtL*Eo{yhVdf
z$;v57L1El$vVzWN4HbngZ!|0yw<{_zDay*~fP!Y6VOZ5wkqqfjD2vQTk7f!nbBeh^
zOSU~1Igg8rvonw5=;Z7s5c>Ig`UM2}<6a&9@IT~><71&S=*J33C`SYclo3&<VIUI;
zmLY}^iN+xaO$=m(cm<%cIo7boB*y1FouIOFT2_Ec&(NzMZ=fRgLSfyjM^9eSIp}c#
zYpZk%#smZcA`^IL9UU#8qNfdJ7Tglh(bUz`mQM{@+u1m{ARBaY#+@LX-P{H4-o8G5
zegVF)F90Ppf>^kigt#b7q>`0^ogqYkMpQU7DUy(Z3;`B`3=$OON3sG`e)o1%j$*a$
z6Qd%ppgbRy91;6Xu)Gf{O7J<D{L+OEX{$m^fDBEr>wwJG!(6+%ww{HBnI)4T!_GQz
z?45v$t5E1E^uql!m>X+&2Ze=FTY{+YC^8?!$l(barc(g{ggt7SNMZt6fj$ur697~|
zK>?NRx5!F&GigRc15kN~tW^9k(kn|9ks1}YpNPou-Z3g~WwPl_Fxg57*Z=`c2nB7Z
z#6WrszeD)wfu=PuHaEAl<=WZWIXKwaJ90UW=rru=;p^@0?d{{~<Ky8j@bZIihCpD%
z#YRF>Ku#i-LxXN=T~1;W6%kEZ1(OVc!K<iPya`n3uGNIfc>NkNZs(0rX&=*<iIJ5Z
zDpF@eWn&{-a%M$X;SbbmP(*r^V_x_A@1k?O`8=mT56%Gm3MPQSvJn%fsiCc_p{uJ)
zRHZfoTX<y@9aypL?O|daIZn<FXs~SW=qm8?6nY8--d;W)9`2q#fkf}efP#y`q#?`-
zt{MIrEiC{5WQ1%mOfBgZU?Nx|F>3@3BD(?~^fpw`=Yi=sdZa<epuCPs&JUuB!c@k(
z#EaCcPG2Uoe{od6@hgE@(bQ2z3W$H&u&)}3@O8Cec_Ba$8AB6GTQ-Law_|T_?`+TJ
za2)Irt$6SSp1vMl_$R;(Y6AUzLuh`Pni+%KXTsZPMqWr)K(`=-fzbsb)V~)W2n!AO
z{haRQoeETTChFHQ7xvcC)liX7vmYm;cjVO{$RSaYRs2v`ID)2WH(z}dujm}_J`eqv
zGB|9ID}(?-Hh@C91R<dm8ksWejh-PWS}Qh%`k++op+yL6`9gs}2xL4xJv}fP<OBEY
zhpwU#k$?n<P#1StUtB#Nq(~IlL1tp`ZYZi-kSxI@`%-L+i2s}7-3xr%(ShDGV*qXP
zPLI^X!qn9G94OG?a&O^}LPZ5(EYt=6iK@o5x&i9GfC@F{(AGs+7zz(8SXQ>S$bmSv
zwp@+_G9bRt(_M%OLr-sCKQC_|I3tj8U~EI_?je{X3&*vGMNrT5m`Kq6)bSnzK^@>g
z28qd{(4f#ziuj3jB2;SMDJxjseP*Cb-YX+@TQ<@wO8p@xK3pg){Pvai=mnkQ-RGfC
zs-RE<Q$Ls&RM*r&`Gp>6O5i~g%}^@vP$*_X83xCmZNp~S*;;ZaR&fR(d?63m02Lqj
zB0nFRP9;YK8X+Qr!~yn%+z>Pc*ih&~I)s!uG#0>whee`=j`!zs-u7as(6@d2NJU4m
zZ@)#0<ZW4R!;eD+B`fM6+%Rhh2(%HY;8~rSV@BAkt!rp#XkcV!&ay_^dOMD_6^F~^
zaGhLT-CSJkc_8<}PI`O!`D5A;J%hmVV^$~<CIi=vF7nVRXbSWx5~yI1r45Y$Clwxr
z=U~sz<sAQ?3KcnK{y#ucgu<L3BP&WOAhH1qHo!nzTNAY@U=OtPkSJ?u>*yI_+Em{Z
z1uC{yme#hmEL#g}I|mqDR|L5{AtlXT9^QfeC=dk25`f$pSU_gTY@qy$O5+geLT=!z
zVTplCFnFmjl!)PWWMG{z@sT`u?Lr##b~!nD*ZB~g;0kkcuACe?+B?=Dra#u(o`4AS
zM_p4%Rg3fmeSh>wT0mC9;DSgnurM*SFf%hVhh>4ywXm?Xw6sCY;_T??0{09f3tQ{s
z3sgW)24aJI3lPsA5(G>F0)tWOL~%=aB-}D4(O`~&6MzBr5KO3mngS|&leO!Uf1<&L
z`$2cTD_36oeRK|bl%HGPGO{Y?%ITSk;6U7}BP&E{6U?m^>fQ7KkQU(4(9<)vvM^?u
znwlD$nzL|EOfw`zU=$GEf_QTG^rn{n;IctJfvgRrC)n8#s7PoqZrOx#C-5!+1qy}o
z4T@f%K2&u|B|kyn;*vr84*->^x{axye9$@QQL^${D1!t2N3;C&9wY==A!?WqqrlFh
zz}Nr<#y|&5la8J#NEJ&<3$!f9w6dv*nJHw&%G%lvoRbSm10f{1a~@`bAQj;CfeI$z
zQ3VE4jtoi|R0%u-IUVGVkQCS(QY;b_ki7xm;s6Svvj1O-O8)9=%7p_13nxc4$*^jm
zcnKRScGE?r4l3WYiD@!4<T`LUY!1uH(!vNc%Yen)9CJa|Y<mY++<y>l*?fJN3XOn3
z$N=3qBoK-L35i170v8+(1tN`!rVW%Qk{maV!TJOS`uV{#V+!$3|J8F)q4mf`e`4uT
z$jXCrwRLduMCA~uA+ARp3$KhoUq{POS4SH(la`*5skyDQlN}c~PqAXLEG$fn4N#eG
zX>QK80dI?&DGI$1r+6c6h6f5Dk{=@&6)eF>gu=r?C;%G9ih%eh*F+pQj4);Zf`bAA
zAY$O+07~NdsEDRSSAQZ@?rom;i=~SvM~QCI0mB5R1Mj1+qhp|>M@2hY2IiJ*@UwPo
z8(S-QW}sqZXvVU(#9<q*6T*KNKC(j}WX)h#z_0kDEDrve?sEwMASp<8;G#(`7*r7F
zVmbsc1(EV#4k^GV0H}cZ2P%)J>(11#Top}=1Sq$-dQD&mu`!&+a{|4*hIjD4=&DG5
z9Qzj?bPjr?ZR7eU9(hzwMLRi0PgQz6n!te*R3@XT(hH>-2<%aYu5XOuE^U1{Wj$kK
za~tHw&Q3Pgh-}R)U|V2T;DBIP%q=-w_+|laf{G~4o0KRJ_60Zn#5`F*5b8;R3CNX5
zN}r)RurFkAV11!Hfxsic4>OHO5`YTk6Z@~6hYBtqS1S<EB_CZm4qz`Kfu0TNnBqa7
zxxi4MlDx}E#Uo)!AK$63MEHn#d4kGR4JxtKwbTHHu8sl1SS<()k=XjisAJ-SezUW(
zMiyiR#lgIxnYo#TE!)<baz#fMA#xy3Uw?m0dcdOi`l7A}zy#2pZQzJeGYB1GQo)eG
zP>4`iAe?sy);wSiiD?Jv<43ZR7~gj;Dv%X93b<Ul`XafMT)QTq*8<4O5h~2_3t%Fb
z6GA3&hp`|-X}n4fr;?X8#JoIZR~%K4F>9*pXzLm1nNY<j6Wr?RVl9UiCfFUgxU-WD
z<_lTo=7{7h01Z|!aILxam?h&2h3+263;lheI=+60;NXvg5zSEv3wS2t4Zy0vyujK3
zI{J_H2gsQMAX&bkH$Pv4sKgN}vbr;MaaYAMnPG{HHZpoHF=RH_6C}#6mI#=4=v_P#
z1@xhJ4>|`u;@1b6Aqf{a^911%`K#_}`F3zH))BSWYHBDc);G{IMAJqsO;uE?BTg}~
zu(h{ibGf#V6dOAT2+Ps}HQ1KcY%mFq4o*B*o~uycF7$#zKwO|gv;YPUhN;y+N{j@W
zqFM^-LPGrmQFjXW9T?>2=jDqZ@Im<J4OyW%G@x=YQ-7w0@@nTy=hc}R!$jiW@S;RG
zQ-Tft3lnFq%J=9MJrafVp?42D2R&j}nB==N-`$zRadyw|WL}CVj#BatM`uiWXlj5&
zL9q@zF)Rw^3hAXO5+2;%%h47%*syKkj#-wF78ZjFJhL;;)s+@Ac>1Ey*55zS2l*id
zZ)9451Y`x6fHnvXpu`6f1os5LjgP`}!J(s{s;4hx1^1BaB~)t9q5{RhHP2kVhD&Cy
z{+bXQvbJ~)te9hj3UlN&NJi?b`_CSvbI>Dpa{!~iG2ZVkhjZ62zOkQPcTLeVMuKAs
z3XM@$3~I>;WyN}GdT`P-JEmi5W6$L}*l{hbY^}jL+1go|gHEurw6fvQt<pdz;C9K#
zgD|TK#tGJw(!&sl2owg=0h<CafCgS*4>2#rZGnLSzW%V$aOg-AynH@ig94q8%GoP=
z&({OB4G-_1{h4D_R;3tyIfC?d4yQd`kb_&0OQk(BdX`G-9X+H7_BAyTzQM2<8|q+*
ziz;#;Jxx6mL@6}WZfj>}X=i6|%VlGs80N_=t?ejH<k&m&af1m^2$TikmiDl@$b6WX
zje=S@9CE)Q2xt+(0h1sQ-u|#bP#{Q&2dFA<5AV;`FuD4tMrF9Ov$Mad?tXOqn^1{g
zLsQ$ndN=>JdKYeeo4;Fq9}Y-lc*1aVY#jo#f-(&X;!wxLuueLtK}MY<N_SA<Wy9v$
zVgA(7mIHiHjR0F?iGotZaV~r>s?+fG^#GNCtHs=hJjh2Pgls4zg#0gN;t3-%!Vn-t
zdj9^NzMf3CVqgPQAS%(4-=3pEXRqkOuSYxQN9UUx0E+1B&nRT&&MJuDEI*I?(saIK
zy7az>UltBXW*B-n(9uyaj0J@#QU|L-u^Su^+>f4?p`j@zP`P%nCn(OK`5y;IF7E%$
z;qV;npi^vXtY>foi9s_$KHeUl{_x0w!QsIOUlF08L;+b5Rj?!YM?eSH1m+D#plaTp
zUY;Z@US1Hj&(>&W8mK&Z&90oiq6@yBmUK>at_;nTWWEjxa}Gi#<=py*zPXc0M^!9B
zB`QTz12d;a1}JDUgaa}`F)hq3?vrR`>)^m~b)p#$@G2<!vPD%K#D>e`2?bCC@RNvd
zv094qAEY?pkqAmqwSmYEA#7MA)oX{NUI7s<{0~AtSX&HG;Bf1ot>G5HQH08D?HgA&
zoUBfG*WUEVVE6LY)=cw!Sw~{o>z}4`&?95@-8nP3T0|+DNPMthf!3WG8iA6u!9)ja
zEabz1$8&Y!@f<Nhh6fjSlC-kMVLJ{_;Euc3dwU2yfJzWtGA^Ie9oUc%q&b8NqB}@S
zC?p6P1XGL2S5Ls`4NTC`Tlm>3L?!Z1hRVp)2CZ9ImlihW=f=Mom7I6x%v7PGjl>YT
zW2kS0p^Ftih)ry`_NZ$Di{i|4adLIzySh5s+hgL;7XBG20Af2k9v}B;K?Nl^Z3OY;
zaR5t1bOcJDfIwgvB3}3>qHe+F0xHBb-uNg41(M>9X?*ujS82+q=j-Cbx!O0bnmXZv
z-nBPAwg^mCXQsN-OVVSeUi&zmgB}mp&I^U5OD9K(s|6%bBW7wD3pq?thz`}^+S?<7
zb!OYsJxJXJC`Ev6L5(d?F*mcaX4|r{A{D$7d^3Dd0LtTFQ9(NqtrSS}&QuqM9TX1&
zmq?UX27;kNj^O2mSrfjSE6;`Z=_)eo@C&2Dr}5ggo;ol&u(+`>Gd0pvn-n8Hb^K^o
zflATZc~)w8<>V;zM-SN#QbQP9Q2d6*s2oKKggP%6R!4h|s}P;*UEKMu&Q6Hk9PALz
zSy{2UjvTfFn&UGC$cXk4(+8t00U1$fSOBR|SVRyp3|Iz_3?K~p72pq4ygh&l2?|hg
zb#?i4m1d5*zq+8TF!$1W{bElY8Sb8x0hHFN=-yLD6}t*lO8Yj>8M57zgN)bF($hyq
zNDB$|uo&0EhKdhprrp-o5tAJ5xP7gQ(8I+A0j;wm7bV&FfHTj*-UYLVSOx<R43!BD
z#xt0wNMwOw(UGCysQ1Bt$PGie1j8c*_`wEwz^1sl^7#-I$4^&~8iaHKmHFB?uEspI
zN)q?dI`!(j-R|m90wuKJyf^6_%y}x`HK-B;!HOY*6^M$liLt4f6>KS0NrH#7#ymUE
z-OY{9bK|?ay6_wvxOfj92zrHkZU`{L?CFISQ$c_O#+5Q5+#?tM7@QlKS7=Z$+*3I4
z2?(Zy5N=C|`+m9MKM?+O1uVmRpfdk1P_PE|;Tu6=5V;Wg^QcC^L>Q(`v4qf2ADEb1
z;<{mDol&V`&vk?%@o)i7E<ATvC$6K5J;#B=wy=X^;=|ftn#>P(+@tj#SltldL+fF{
z?uTN6j6(c?Kwtj=9|Uj6mjePZ#R$vn<qq#dNtBb5!zU{UdxN`vb5U72PXNvy6W=R1
zUsB|9axqjuBA_0FI0PL7kZtCcHf(!%V5)l)xH>u^mbG_rbHv0L%HhB)I62sJ;G5Z4
z=PvLPAiVXaL>QM%!h!%7)*}!_8&M%a{_x5uJcZgY#kfIK((da8jq?!j`7l)&Kn1=j
zu=6*?PcNoHXAwB}byr6IxyRoJ6-00HQUp*ex&~$@rWPnN=D}ikc)9ak;F*ylB2uw;
za^`Y4a6Ev-#u99TqqCdPLx?{=*198r15W^lgGhw#)riE0*h*q%0R?C%h!C7KZal(7
zDts3{Uw}Jn^SGZZ(=1ZwuZy29)V#YRz`5($-{&Bm<6`I003oTv)F6Pwrd2MMC_ZrH
z@o^J9H#ZnWDwqVJfVveB3z&VkV$vWRWQT5GS71~S%_3Amlplg@*b~)YsMq#~@*ovN
z(1wK%jL#<a4M7}2KGZTGRDlEHIRO=lX~Z8PDwF_Wo=^)KWPnLAb1N=jKqTVEcX8!8
zIZ&+c%5%ma7GlHU*ja(^2isz6=SU?i0<Qr08!9mf^zwslcp|~^5TadzFA5b9$WlQr
zQQSmeV!@1$C(Qs0-BF&(gRNr!Vi^MF*YRcX)5V(qf}R?5j*Fc~9g~JIEz~;%T!N9Y
ziHU_JO1+%G;lskh5!-Wlh%Ve*9Gr-60U}oB<~FEf;i2%$)5AA7f=KJgU|)BXw0O9I
zoD=driRJe6!)y^KDWVUcJH9?1NP>WvkAN@W^Bi1wF3vW;SSFDoRF-P~3;M6nIWBe{
z)WU&WL2xTqAWRT~ptZEIcd&QhF*EG;C_Hu(x>Mqek_2lT2n*a4j1AV+K~{oM#uO2X
zSRR3hP{?;@coWKZfDxiLkW7FEq!dFnQGJv*9}%3hJ!Hkv7N`XH`4B2AwLg8Up5+>x
zgC6f5C|98z2m}2O;F--WOie7<Y)~pZJ`Yu-=tu+s@DQLRn~hAs${N)P*4CgGTxsGE
zv~5Hz>fORZP@3T7=}v_{O#TOVBlKVxH%vtnhlzp?#BTu3gO4y7s6Yy>ezAmkYVVGJ
zEq=OOBRf;F^Ao&eP`S`~H1(*P6Y5m-^)+;i%uJBvm{{7e9icr4Z|&^ukn0Equ6$>E
zdkzR(OW*=ca&UCzGo-YKXCNxoV`IVskn?$>{7Hy)@MLd&>9r3MM=w9n);`|;bl)oh
zV^k0ek)+r=uzs-wWW7W{Wu<QFCxGG1udLf$x!`$-aDop)frg$o<;<AdKv4!8t_S5i
zC?v(@3s8{lhQBQvQ_MEDHa1+uc4z|tr|So@1S*7boiGvxkZeK$Srek7ya@}mPw?>a
z1!sqgN5v&H4B@^D5QiP-axMR232w<#^hNQr)w-z@&gZAvtJ_<>;CWD;K_zg=4yk*H
zp}vVVrcG_xU=a}8+b|2HP@;}XI3DJk**10{DM3CtxFG!r#Uzl>D-<>Q;NK9ectdHR
zBcRzZ%ZiB&FTCp|6ngoA%0w9|6inbQa1*$>x}Yowuya^I1-G7W2P$iI(`Wv$f1;OE
zO%oa_|7CT1YZp8Zl}gIX;ZTiWXl8<vW0oDq*1{GBl}+XQwy2zRc0t07GFzhkF~^M8
zu0l+T!N~ghM@7cQV3s2gKtN}}61aPkRCppZ0c{|JO(OOH9vh`}e0P{_id39<cF4NT
z{$dHBc(ngZ@w4^1>CsUZM)|RzutdkZ=j~*%vd%kv_E_lmG~`F?_Sc#7oc+w}uTeWn
zs9-wP01AYn0~QNRn+@@`Y=kDb_aJJrv2x7G4#l>J>739R!G-Ru=ZywvlnTZs#1dnT
zx(hE4A9v^nu3QLP<Rx?m2z+FfScylGKC(jOgl<mwY5Y2H6hLJWVk9I~HtHrvMp&ZL
z0`lss)9+xvoE3TI$QxdUet+^t9hwExdEPy!&RE+(Ul%oj`smPvR$eR{HrQ%RZlF`3
zwKWT(12ia01VhPl#=;MZWca932O|qs1-&AOyZ3{~<qIJPSogpOs|2Ra#T98K=8eD`
zKy`$G1RrrlV8{a|NXR*+e-2bU1cb^~-PG6^s{<wX!iup9AvPp9RDsW8Md9fli&a6d
z=rw%|pJHC%y?gXp{wdn&pdY=*yh~4^-yi+Qe%<3O<~+x5zHtWuE$j)X6(huN&>nPs
zLnQ{6jp!8to1L`{mK)kRqY4hQs7|<Onl<F1I}eIikS+T_V8THp1R!2<1-%9u6FwW1
zCc+!&91J$nZpya_8IUT#$;k!!=!hiKo@4yyi=MF0ZU4-mBG({MR@7)#)@W4JC`*(j
z7#)o&9~Fp3Sy7|qEJo0yvPR2sm=(n+8w&@cplU~-g3ihHPX1Z?flz1<3=5+}a#UW|
zm)DOF-DCg<q=%+eAoeY-5UOB)or46BD)#NHF-L}3AUjkaV<8ztpORfnks)GpMZJ^2
z7ZX3^biCbBQ;F0D*)=X0fv`Pb1&?WmqJJoyEA9)6@Qnwyljp<(1&nv>^#6Pjptu8-
z=iBv@%oUXjL;?l|AR+$`*(hhO_2_z;D;L42h;ZqwsB%#jeNg@>+K7N3Js*wJsMO<@
z4|JY)4`NoZ6iCm+2yLs#C$o_Yl6)g0#10q5*no$)euSe4bAgHjTnHxLkw~M81$Gt2
zROs#H=8QA}vjQX_;H5CDhH@ZVxG^jya(8w{)&PNl@}bZWQUw3TVe9?*q7Ynv+pmhB
zGv5~1f=d-JvT%$FbA5D`@+&>sBViyJDv!z%;n3;#j(+^)(#Z)ivT|`$jHnRKNMGNC
zWW|zYjbs>Bl_8s4TpgWp-H82hosbkq&<O~?kUV4B1FV7ts@S;*f!$zbgnVSx9Lz9s
z9AJ_V{n}aLm$3*KHYge{I+C~vuvi|S!Y^{PhiY2eXp^kCyC0##SlcYYNLFOl$Vg-)
zY%gAn2=D^$WR1`Z47^!Rhs#GqEcyw&hFL!P6s$E%R2~Ui{EFQsFGN2pM}_v@H4IUt
zf%!3g<b_r&8!ArWAQneTE9VZlcCY~u7tDHKz$Wkj7??|28y3737RWe4r(8fPxY)y=
zW2(s3l4W6IZH>8lYt%2Gq5(Axwxo=1ur@^S0Tx;%fl_Z<y`L|_FY#OdsrdPB1Nk5l
z{i90~&<lKd5wl@M(mTvxKEr&roG{2@P&xV(g9?64q~gP`UVX!pUFJNm9zE|B3QF}+
zyn+^_rYKH<`vE8GfLcH>h_D}aWCReL<GP%9_AsG*copalB3v{Fu!NFud01@+GfH_4
zo0%4YYex!cX@%(%Yil+ObM+``fVm-qgr9W+#K0csvN8DiqCnuzZ~Ld>XL}73if?x$
z6eI%2<MjUV!S~*2c(QluJa7APbV8tBfrg0Q%q*=@gg{Ebb%0TX4S>LqeT6Dfi~$$p
z0>TLNKZ+G>9TCo$n_F|8V1tnZ<6@yxHa0+ky8mK^9=Ko&fwHt=S)w`$u+aK&C=eSI
zC*+C+Ss_#)E6?_it)M_|BNTQ-ZXOiJPK?Ee?A7CTX2<7w>n~72Y^x1fF-286{<Nq;
zpy6PTbQ$v<Jj_qvFN`u$Q2dC;T*zXAbm7?2Y6tLgRLudS0i~e)zz$Q;5F=}I6zBpS
z;DRn3BsLaS92jjRmCj(VxFl)NEOVWoFT$+20hOnF()zdk?fxY1l}mxj#m<A39tdrX
z(4rPgE^V-Aj39v<LH#5kapA+f!Vx2JrkWF^y~Ly0b8um7I~$r^MWGy3b2wxE*$y*~
z)|j!kMj0xoDNMYwtXRO>91$|g$f)`sOsAt0*UlOdB1*osNmlr7t^d3D=?-A|sfYCN
z0PTJ*bRMj@ga#QHkT$?=kOxL2!A144J!T9Mp}PScu+}KAfDZ;PWO3LIpzG`*FpwA)
zM8OWFEoeZ33%ABEK`AQB+5)wxDCUM<qAC^en4@5d>QOPv1Yv>Yv9@7p{d_@=O3~i-
z_U`WKTb=$S`;T{-ae?2hrHR60lp~npkBiXOlK$klMsmf@u86%5c)7a^u^1Ke!^ny~
zFjwa4jChqCwu7xTYzNE>!av$ltpbXE&{v#<1XY(*{f~sx1nLPxPKd*00ZtA)wzU;x
zWdUXdveMYN@#N{pGyn=}G|<-Af<=rI3wne~F9%0VygRsHj>5&&lbRG^VuvaWyxiTe
z_T7nA*-<#gg>``000t)JKm%9KI48n|n%<f~SWHb&B1DZ%t${TXW#UyZSB)wdb2Fd<
z$INg0Wm`?j!v`PJ0PBRQcO-`<=EmmKKi&f0pH^N{;EJUkpz>XO(4YtvlKvpuh=fLp
zh&YdOBMuui%J`#O*;rzY4C=zzELd4650!F*zcN7wX;Unp!7B@-4rFl={ZMBcEDf+U
z*ZA3@JH;!%>}+qWtNEA)t#d~?0xBrYF+)bmfPx+b>~KV2SRfKSHxJNjfta}Qg~K3E
z3Jt;<JIE4;ZI2)pwcF@B&oZaEBF4a)LmSa(4|Uv_wMONKsVR&Lq8re?6bfQmiHpJp
zGnT2!&tO*&ul%yRON=(HAJNb^gsdQjgOD4TSs;=ltBJ;e_9!1kPUGn63dR~t0j7*S
z!3TIEw#R%kcv~>9K*yGifQ^M-{45riZ3$Onfii!Him90iSr#(`Kn+0wFfiwqG!02<
z5{OQ`Hdg)FBAl9g+b@GZwt<eU)Ht4cS-}!mkZ&Lw66u>QR$p?RKmmAQjx-2_BkE4j
z;EFGBal#UKxNS_Iqfdafr5WrBLN#mbVq*nS!5luO3QPeFp3M*oL1;{|G=f$vBCA4a
z5G2XaSmhWMTEzb`4PatoYRSTshnW$4D2lsm(WwZ3Q*srss$h>id;)^}eEdC`iBMD&
zfD1rA2wDJ)nj=-SfPlap63d2eR6rHn@X1&>LwaKh(*na{2$~!Q#*%|<9QKN4AkEB7
zOw@jc>`*9Z|7GyUga~~XQ(_QUw8oMkvB2F1>`+ST3T6qu*$&Hq1ZWU}`U0p97+I8K
zgQo{l6lWlQCw;KzAUJ_R#mXxBhg2DIVPu9T{S>d5noxsN@D#`?DDHQFAW{sBHy91V
zT*ya=3f*7;K^AF%IsW9xbM2`*&;?8)LVK{*LJzEQ2?A3sz+@pPdvJ|ln|PQ|B!Uj8
zAo@Ub0tKPf4=nOx5Ch<0h7utIBUFDF8XK7yn;9V|x1gq;;IeFBo&g!`3PR?O5funL
zidGO{SX;qQSRe`J@|^ernzX?K>Vr;Sw5o$9&cW8Bs>R*S*$ETR2wcGCg0zEev1PLW
zhXs5OmR7+b8<IIe+am-jV93##-WWP$Y=Zh_pn@O4iZnBb4?Hv2Y>$snR*02EyFhpz
zL}WHlA182e#3Z4eBI-#IPM}pDDp7nq1)d0TLD&BO%)JMYoauSr$?}oh08CDubN5V7
z_oU7_=iEKrJvnD!W)K&Puvl!sE;lffI-ez4qGZ{WY)K9$@41Th!E#cfv=V8bt#jD3
zNs+q@lI0+&TvxUCdwYPz09>vxvpfSIfSGT4=0jCK^Thx2f1dX_YDK{*0BHd|!uOmz
zw+9G;|0L)j89WBQN?47EY-r0GXX%JTFE-FevRlfaJ$@6|72cN4#|yvl==l}skbB_y
ztb&834~BrFg&|1O0`A&%vAhYw#V1$_$6j9sFKLCrJ^_6ZtU*cxszfrfvsj*pv?9Id
zFd_Ez3puPUtr3`EG{bX%+l=2mbq2VS9;Ap|TTG{6L89;a8xs%aZCeLF-THAj<}ZEZ
zOCS8-?BN$c8U?s0FkA7vr%^}~9ZP{CDAvy0eEBt&<+Y{^c@va}bh(7t040cuP}F%M
z{X0z(D<reFy2i063>&d;9P|^fvbMCoxw45z-akWV2E(C)aGLyOy6ZbMUSIsp2b0QM
zA9?HDcQZc@seI&1nZH0PVzh8?mrXn^ZK0s0!EptzaRcH7T`u}tFF?+rXDr4MXqVE7
z7x5T01&ae!5(ykY3MtB#a4FlT*4LMW7l8|dL};s^Cg={#7`zSu4trdPL1$5~?XAf!
zI;uBsKA==?eT3hykc#;CrOdnUzJ>B|D^%#+jQHZM_g-r$!>x~8<OhXXwC-;I_`Blz
zi==Y?{L^CJCTRp193JJ$rR!J-?JQyqzyX{Bc7@Ys7b7n(+_(xL2b}#hWMq<)O;HB!
zZtR{WE^iRk3D8?a`gPO;IdHhpDx<C_4n-D85hM^2XRMCS0YDs5sds%x>=SrEsR%*b
zk;+>i;S2tX*Mwx=%^;F5A-3DEUCeNE--p}Z;)nUMzd%<mz||Ms8%kh^U&LfCzyeZO
zgaUpbrlJJN8ukICO0nt}G9~u2e~MulG({vT=*#9hQ3ZEP-2;S0a~5CA@mzwy%fJK?
zN%&uZyPQEROu1ro+j!gWK>2z3w;s%bF7lhdBbCfW-Xqsr2;x90xA;mZ%fV}zTijzP
z;(<GNx4$KR<S&*A^)G*(q6`!*WI;BD414|B3pa_x@N!^t;cj1h<t7*csU4^bl`>sd
z5`E+#%0jXfA~K6!x5!a8H(5joJdSXf*dqW50tg|AZ;HJf;5R_v;Bvx%*3p$CNTuac
z4lL;6#arSx-?E*<Qn_{Kwal%HU%G`=38~z<yZz%2Bo)xei%%1H0B6bLv7Rf>fZ0EL
z^*K0ft>J~6FTC;+$jbB23U_i5kXE=$VE|NsJ0!$ZgjC1^PoeH1k0rAgIm*h$D$Uvj
zHc&A8+QQ_}l$}$1G(`l!jnQqc*E(VKy!`TSKaj4pob7?GpeRU1_?i24<-OP5x|O+j
zODNAr?%dt^)&og}j9sA2AoYN>E%5C*y5u*mKaW(PM85RGv(KU|NQjm>tya;tpm5xU
zt3a{SDtYi1=mHtr3R*)}OCkrZva*G55w;{+O|0-oYQh&&R$zCSkC1A$^E(g;UwJU8
zv<&D#D!kd-Qn~n^1@RgNBi=f%wS*<U_14|H+uv#l<v}b6s}P+U2u;@kP=IC$HXPo;
zXU2bUFnqdB_J8^53ye}h)`r}JDPRwnj(C&ng7tzph{^|rG64s9Fqej(B@i8eaeGt*
z;+!t(B?1<dknOFOR9<;7sR(OnT^Cz#Nm$Uuk9<Tp*xP=EZ}N^0UTb|9H<Y<`_wLS*
z^Fyuw=L7w%U~|#uK`7$=3;lShH8=Mhz?<N3iKON7Rg{TR_sm5=S1^1kNs3<an<wUM
ziu!n+zrw$+QQZhHyS6OCkk|>eLS48bj=(@BqKE{v+d4(EM<CzCg2dv92htUEp>^F7
zKKF;Omecv+myi1j<YJ`K^03#hi>@y@2>=-lb;ewtzxl#5PhGn~%Uu-5@V{uPi=HX^
z&s*EYUP$cu<s%xQFjRpX=!vKa#iSm8P!*2o5<FfZ5&^sL0sMs`i2SA0`5jpQuYT=8
z{L24asR;T7OdP_FNZCl|SvDg8GQpdC_R5Xx&r&xtMTX^^VZfVipa8FNB`6AO69_@{
zdQOq%qbP`l3WzLaU8J_+3&xEQ4X~5g$AO7)LI_I2OZ+%7yVMCc`?c2|L8*XCg9*T?
zML`6a1Uflh_xcN>Zzx(H1ZrmO;A;ugav#&#0eV{(u7Te<=<Dt_@mTEeX<5Z870)``
z)K=D(D1ngFst8IzDKz0QG{l4&5t~G|ySh^Dd|S-JKaf<8YYWGFPVgbG2{{OM7Mv~m
z=vSx?L6)eAMP&@z1Wbg{O#1Tspt1su1WW>1+eJ}mgNb|5=O9R<B(3D05QISRxuRG^
zX*NZ+D{@_G0l~jx6c!0B7dnJgUjN$ogH?yedxOV%>H-5%*O++`BqXst{b@GsbM7Z!
z3E)}ug~?<Aw#jD6Qivft+o!PyvJ=3}9c*VCM2UEUUuo%tupBa4&f^tX3x>j3cS11S
zQ5-QGynwG+T!3`8E~EmC{rcC&9yKuglNZQmQ4oPJ0ZNL&R1kdD%M09DkX9&<sHy3l
z(mbQZv9q(zS!5(7piJA_trb`zMH3i4zx`DbI6N!*LF_?22+PQ(r9udbqX0>2SWHf<
z1%l%0DpL6r6IV#(SijK!A0Gml1xukvh^;&Ym;hErv=Mz95;mMHa)QFfu+;4e`4lb_
zUOPdV*dvY#MGXY<h66<sA}}Kq5uK6GfmB55g6<$QN@z4^WeF-PXGt!u2&r)W&gduK
z{r01E2`&aROoD&`)eqnUQUdUkh{J;aDAps8w25)u(_;UZXp_=q6pf5^tOz7r^uf>_
zp&Gaf{xRgbwTAsr4#8F>;0SSvv)yPXFfOnnSm3O*pI=<bcDyY(YmcB*E<+c+di@2q
zvtB_G7xsak&g=`<3KQil12N|)`|&GakYpNU`K0$-TOzWM#A6(rD=pjrUD!fB7N`lu
zriC@4?*^yOu0a<PCw`+Jg1#!KnzV0OQ^6TcT)B>S*thZN-x+!2{EC1M=<YlN9~4p0
zF%-wXfFRPGfaXY>k5}jlpB7NH2q+>c#lH##Aq5fsgQ>h0v71|=An1lLo;7k6`n0Q@
zKudrY1LRcF^UT~ViP<%VwD7uxj&~UG{p|0KyzwKi|M$aPZyfV+(tM)u^((^BVl0A~
zC7P-tU4sk>K?R}#T&2^Z6hsh$XFyiEA;2YU0-qt8kLZF3#Z-d$5<-qhRD{;7VlMdB
zR^UNJkOs$iEiKH7RppFor90kX0^oCRj=b?BhDzUj<9~d(>$uN9`^@urT6kW-1TY)n
zT~O;I4zvStU`Kn9e8}A>c?5cbeyj?O*+2}!!IF!SmWiW7kpSM63%em75vIZy^Xx&z
zi-?`DFhW?}!S;6c+q3tE1)!OZcf|UqH?41c>z}>v_2wIY{^73UJ}<CH!8IqZryNE@
zh`ubE-xqs|_5?=6SPb;Goo#_JVnW0h;>;$2sFk3RtDzRlt?3A%7Kmeke!lRj7>n3$
zIXySGFwNo)E+oRPSQctci(Rp^v+<61zQFZCQu)&lcfE1U$LVieg93<Hu0Bo27-tIf
zNM95Nli=&@5R~`|MWOT|6>C9Dz$w@f;dgbDyuRf!R!Gc*7ZG#7m<*;Ow&b#soZ~U3
zF_t-@Evymdd==)Vg-n>LNVc<S<cnYYy${e8h-@F`dgGW6Qyw$2g2R30si)ZKOMOG9
zn95Hyy9D5dV?lpJ7k!P03wX3c`o0NzPnxzViW%$&T@emM@OGDG=9gAm=CL%t$a*oc
zvYkay2xV@LLuc5=J-r~d3*%oF7gFut<v^kT_4nUbDt~}Yz4?YXb?ZZ1$9-O`O@vEN
zhI{$U*;WxOWWZmr5YgeI`797xbObNk%Gj_N3LH@)3#qIvu924@4mgKP9Q`*7c~=O6
zb3-^IQ5*%q<~1RbnT2@{C=yCD$HjR~3-j^z@BU@3ufLyE{>}erN###I@On9V>jS_4
zCvSY<w>P3(@B0(tkb&oJ&?UXb#wGzH($r~TAONy>6Ii(H<`gBd@U;YEvNCbLAIa?M
z0wx2#B!UdlR=5#vh%We4^nnEoI1yH@9moWmnX5N(Dhr&fGQ(Eg>ABf-`}a6V=zn`Z
zsr>6d`?Ho*#73eYeMMh-=|_K4eCLf1{PxDr{qY}fyzl?OffTHBpcs7mQmaR^vwoUL
z(^3<*(|{%dJ%S#PrmT|FivB1DgyC#~3bbPKx(K*95maPB_|&=SB}`-iA<VLHnseeg
zoM>iddS<FIHN`GE9LhY3!vyH!T&n$hKlPJ8`IGM>m4AiRw4`!(QOx_?{loQt8GWCZ
z554rpq5B`cUH|eAe(>e>AAbD@KY(Mvl$Y3taCT2P6=6hxj=)JRLM2~O^@!#Mnj*|d
zfNezNWpstTJ`{T>i}1JX{1G`C|Co<vWiF?Mu!c?;OB0byPqW6J116CQOUF<X3~6aD
zfmFW4hUg!%pnoZT#Vx6P?}M(JKl8oypZTC4_}&{I_+9bv`~L?_U4!3~uAGNb-RkZ@
zr*0Vx$4lW`sgi}?ZFye-qzF8gvSyjAmPCFNMG@YFGcd^EIX_0MR&FvdF5(PQ5Q@PO
zq*LP9GmdW(3(KcTScEwdoucjE`>S04(sEzE@{R9{t0k51e!%th=-0pd(`z5_1K<7b
z8z1=HHQ`sj{(e8gj6R#J#1sat-_3pE4RPnxCQv+zBl;DfDeHtJGzCNwOA>Gqg|Dc9
z2|8pdODmWSkO>kX?jV&`T93yS@p!ID+?hfooCR0s+$wP=l!@cgn=`TY?{jeIPv0+<
z-+!ldwWRVv!}~wI_V(LvM&JCPA9>@0zWMgrPrv>4KX~8&fCk}n*FX)J!vI=i|1%Ls
zVDPOlgc$HG^ek{W#3X^a;!^}j-O6RjOXe5WTKO5NEHV*ch>b|N8B#WU4ddhDfXV4P
ziXo0X<Cvyd4u-(duv2$x8mWkri2v2Sy7GH}cyP6(@<9MY>sKB9s~_|uZ+y@<zr7}&
zjs73+^D{SS_J|?~xB#i}=3&R-Kg7y7JT2I@=yZtr4PiYZX(5*vu7r;wJporj5Tt21
z6i%k%ATx2w4x1ZUaw8I17Eq%wY@uf3GIk?Ebj$HhbC}>%yqyz6Ioa<Xsl550ZeJ~_
z{D=Zcy!`j0U*qFXML*z2zV)LDtb=D(f9lTva{vGF+zr9@x_FUf4Id(6u^<mHt12id
zTM#SGaUR(|O;Bn>*g2RFZPFE1NK^d@z2LL(EsG>4NCE3%KcVoatrAf94<v)M#0^1-
zZMqztG0lN14bGm7wf~@X-r-@X{LX*4bG4*$M?~-Q`MKv>FGhd$eZF_+rT1C8c;{Pu
zUKM`jeIJLU^UPI<OVork_XLqrbSbvBFdPU3;I+^JSqwlEhzglvxP_4*8=w=x=@$DH
z#KuOB)ZxgtMWn%&H8f&@#FkLRdFkTZo!KTi9a5QU;$p-x>dhv1%|!db8Fq)H^0m7o
z#x1G*#}9YCam>fT^e<l){d6v{>Maq8L^q47ka6bo48(}$^1cW}Xo@HWnX%dyIMOn@
zfwv{3kjZj{u}I`Oq*e?Z9n?SboG-}|VNMO4LI@-;oGy=^U`|ub1_$#rkjh{G`Jey!
ze|<<Qh~m)o<{NjHARg=PxX&}~!<)uV&Yy=?icFaC+G0e3;XyIb!$b^3P&V?D)xs`d
znw1kTgiJ&}%lb-0LhNB}@bpYmSPd?O%$3EKvlPnY`v^hUOruV0ZlED`wwE{O5t2A-
zKGpt%uYBci{EdI}0aCepoWim0-Z<7%|Nh@!y9P1~fs)x2*b`!Aj^eO|=pz)sxE3=E
zpCf=snp-QZt|2lnECCnbP?tH*ZI)~eXG&n1Zs0D+<;7XgQ?vMwSzg7HAekvnt(~5%
zPfj*!!g?Ch^~qW@+x|yi`N}W+0#bSNM_g~b-^$e^yms8@uM?JmAoot4-6#Gqcu3e`
zbc(TcaQ!oErD17;h}O(K1GwR9iNH9NmPg^xW;SdSbCJNz)MTx}vEUrrTc2s52{Yo&
zPx6Xzu$*k%5a+^G>y2t-syT<^@WYw*Kl;UA{F{IC4=g_tpnO>0xPI*_79w_r!(U?B
z>nuaf0+tk5wxDa#4WjEIph$uXyPpU=WV6VIPq-5SosiAer#PK<YKnssr!f*lB#NKL
zWDSj|R;%bpt;~<qYZXortkx#^nQ5eyZ2zNQ`lY}1xBkG|%4Og0!yAw)K1|!^Umx>f
z>O#i;0VRcQK>KXDT?Q=ajA2*IH$x%a6ZG;8=Hr)f7$Q3nSR)Z;Mp%*16#_~P83=Vi
zDz%zWkS5l`so=E=BB@nt6(m%zm8(@wKx@|P{F|IiwEyuhasA(qo>btGUcJ~F2)YQB
zl3q}Yrw!MUY!@&au%D!t7V-vkw^qavN9qudfsNQYPFBBwrA(s-2&0A#O-(i{n9fvl
zrc|y~5K6gHt(L`2rCOQf6N<x$MfFKUm}>vyU;dR}`IUeB=t)J)>5Dx)V(S<DIF_HW
zSe>pI3l7+<$kZ(~V?ekqaV`o8D`o^vze2RZp>Px+rb1Ym;x}KPtW>5EO;y+k$Hvzx
z)l#XFFAM#sA(vtWOR7#*g@eKGOja6`>5f1CJ6!*6<o%4N_1YW9w17L09oK^3!d<-z
zw^VFNxdP`CXF{7@^gGV5<bdEqvMVSCYXYApkr#O^2|eSA9G*#9MvR@pI1XIMOuaHW
zi6aqegV7Z7m2$aKsFaK4TD4Mc)P$zAv<1Igt=BRg|M~B6J%UmZNcQ#X5c3)6zRW&^
zbBN-cn1o_Vkc3u@xX}BdJ{Iz59WVq^O=cpFj08!dnrY5XPEOWKLLusS*2!wKS}tKO
zrD7hD6pH-edzDJ1SS<_3TfqU>Cd&ve)$yNy^;duOfBz4Up03=ufn1)y!6*<yd5U%_
z6SgA!5P#U32RDP3p`ceY#tKc8-i}CQmuBXg0J9(_O_H)E4y3>@zg(L{6jfn4HK8Jf
zT&Ywn7Yn5#rc^CeO4w1YS(|KNOD*vsmA}vRA4U&Z(3hiMKJ?WQEa+fjL6B;1z1yPQ
z3M)E-1>N)f4Y(^}|Hso5&g3TN=m0S*w=WVqZonqNBSD#nJS}*DIuDHjWE035nOUQT
zpRJ=DSP1{n5cC8gl*)x%v0N?`%B4cNS}vA~NT-6bOjW9lN*Ptb&~hDr!l8q2ymd$_
z(J!wbPbvo!3vac^$&e>uQwmz)gG=S!=V^Mt-w{LG%zK<U&!!Bq5aS>|i`fMjDQkjn
zf>c0bnUrq<uOP4@+|+85_}EGv`>5AS!gmyk#bOB|AeLgWT*~DuC`ySBe8~;L2tV9%
zJEd|p-|;8^0I?jF%J;v2OsU*up&!tdTNM8zNafz=FNvkCS7AKSeZL6P3tq+^LouRf
z$hbd+B9#xY0U-y_m7omDNbheJ)JPOH74!sQ)G(StC6B=fnN;y7Xbw`z<O(@%3gsMv
zDo>(3#qwkcovIWktGP<C<4?p|@BinJuKXCJBIw3ktr4IH*Oj|c5zj*!h4RI&5awyA
zc`kBL(5_%7FdzmI5RMLLB#m>LS^^_!{h{yyI-=g=!VaqCe6>Qfsg+TN0`I(5DkF-P
ziey_RR7H34#S)){!r*EMQl)%0k?;JIuX6pzAFouzJjbn%h$)z(SkPUmi05f9Ut-IJ
z*cL(NPcg`*4Ezh3?(S&-eR_oSdpJ4=4IyotnHQZL0DBHzCBdIWD&!+Y0&op&C{=my
z6^y6cQk7b*Sj^*0#K&?0^Fd#*G4Xk_l#jVaOP&AaAN`|$_z(Z%*dhP=p)Kh4G)QYM
z<~SDAdY-j-0x*Ehe~E0L@`uqdsv%;Lpwm((0~(OM(G#UVii;Khre{f0D236F+9dI&
z&YP|Ab_?Zvfj5mt<cpO`p;Rs8MO@Bju`S_yQ4`@~h|rZxU|c1ubpDtBlj}eIIHht&
zC~*1TI*zU!Jb!SG`+0UA0Hm;|>C7G~)8etfyatdIJ!8;m%!llRU<{Dfg3=l!9%Qm2
zXXQ6fqSmsWVji8qO!$j@@*;=BtKfr$-S9_bb=iC_;k6H{6n#kLA9H<k{Kuy&Vp@t(
z5X?tV{Ex0Hx1Sf|=y3VP2C6dvw0jH%GMovqmexBd?J~$c{Vmd1@)O|2`Q|k3z<Mj6
zB@S21yk{&1(?L;+xl$oZdeRaR`I~Sws11S<RwG{KwPH3K8P_W`3TgXP*MI#ru5V7<
zm5M-84`nP5p0ALnFzkRo;bH)SkEqHKq|$ouz30yYwTTs1Y#@Suy)QP{?w)0QLC`Y5
z4=4ihDB=T6FDhNmaTdqXQsvZJd0R~+vz00iwpuD?MS@Z!hvnTD^2iHOP#w0+hag?d
zA+};68S@!c{d%2Af>iz~*S8Ky<*s~McMmQVMDRY>QDV^H$Inq53s{A!5KL~DU<@wD
z3{<NNwkjH>0BSTZ=<0wdP0dV#oHU3b2nJ0c#)@bw^hG$0VveGxT+C-HWc!#9s)Di<
z^64xuqD1*zF%=2B9K$ND(O}Tbbp6+V&h>}3`($zV%ZDWu+$!59**?WOFWQIf!~oo9
zhyy)g+EidnfUg*k@GEG_3|(UYBLSHpjZ!IJtRW7ZEh50TionZFHlG)+m(YXWaGT9$
za#`e*O=g_7(Gi>3FsRm;)U)0H?Kgh?*MI%nj=N&G@9tqqrM2ac=@ybU;c6l0BOpM2
zXtZmqfRS`SX<z_S13KbqImK+IiA4BA{!uPrCkR4>+zS4Kv|hN{G;%2Akpf~W=JWYn
zK9v-ol3rhQRI5`D4eAF~Dvf%j`@e~0G~agKCyTpZJ}jxw?4cDz6lN_KyHjYNwxmKz
z%c2ANU%1&;^I}f4EC|Of$be8Rq(Nna!Bol4xJ45Rg+eZy%NKG5>?KzyWpN~YozD~!
zDbyz&^GEE%CY@HL(;JOyxpu4Pzx~#4{pN3e$MvJ(+19ag|MNeb<1}|D*DTTzvyx&_
z2yIm{&(B1QVE+LawA!L5445nRU~LLix>iLDc|0qw1(6hsxjddj=!uXEkp>S^L{|#A
zOe&kn<P!00F&9sGoff@btJUj`TCGN}+35Z6zs>cw`>t}_clWS#1u-z#BGxX6W-?%;
z7@EX<03<<W1*t-S1>~|#eC?C~Psmiz7~+n|K5(c4B`6hyisVzdT(OkO7f}#gNG6xh
zrPJv|CZ35#vzc_nJ7F=Jv`TfqT%*$K)$*<0|Nc8%Z+q^O#oaF-mQ)yoqGL$QT?nNm
zlNQ~04W7ARUx*Zcram>>Act#EArps*$oSex;1p2<3HORriW#ILyhu?P63(@d$*1#~
zEXheEkxImap{O@(9~#nXG&+M?q0kH&H1gAZ|NVF0eDinT@!b`}eRmH_Dn#MUUAS;G
z$o7!O_Rc}`bY-0#$z=KTh^Oh^%uS*wjT%i2f!Gs*CM!7HR=tCl1z93LA+aYV$!9a!
zbTXSw3&Tkz63JLRl}si>?g`7Nb<m(t>$DoJTx~F!w2G(t{!|=u`(6Kivbg)@!;;EA
z_JS)B4tEy@&kj@R5R4(IEJBAA1V{)cqP0O&3(x=@jUEQd0)kK}iSR5^R^e92@C&&#
zxk)~i$>nmy;zTN$iYJosOez@;`z+(b!&bdoWh5p`Bt~>bqdMRJr(gg2@BjYy0(Zr5
z-`&HK${EO!aE@E_Yls@6O$b$Eon^p_Gcbt7AK_B~@$o09iKvmQfY#t|0(rxs2s{aq
z5P5Ti;Y>D#*#HxyV##DWnaU>O(U8YFs2d!_rD*l0VZDLRI*rz#xZ3}x;-Kj71@Du^
z-7g=OREWcD0NDqD6XwI#12|rAN9nDT&I+QRpd|rXldsV7K^W*t8QI`(5euq9h!!CS
znPhV%97!5A;Yy|x$uzc;i6z5Mvsu%t)M%74rN(F>ThXbtMx#M<b>Pp$(ZAmh-4(-^
zDTBUx_se5Q<)VO_1bizp_#<chw;v>L!+7@33I-g@Bx!SO5`IMElr~tcMK&STr&Zo+
z_tgPv0iuPkt&+8p)YINb3+RB<Bu8SBPsX#TND>DdOXO1cltd;pp_BJKE;Z=o3iY7T
zq*D&)q$;GMLMs0k*Y_juiQyaT-~axXqwjtB{i93eRz{#kN5^e%S3$QQ6w4fl$a}kD
z@Mnt=7qM;#unD0+$eEjMOu=mvePI$fl!d<lwUZP(B(p7eme3>YD2uM-Gf8|&B92g!
zc$Ea7lJQ8u>(;CK`cxW{lp&J=-=dVBe6mMnP&^~~Gm)VE;I34JJiZY<;82SDqe~@o
z>-KJy*1DD>>k7gV58_a^QJ2=X9jIRn*@|g6Na&(Y7NiR@TfxI<(&M6;gQ8Suc8SIp
zMKbj<*(*K;yE%wHiDWX7PG^#dL_Cp5q|*3Xx6@|QsT69J-aIsDHfmK0sl2nRYd|8o
zA^9`0<oJ&cDF>4H>Y*=>ER`=EtWn_29T~U1tu3tw1&2puDlI&P$sgJr>w+T*(nK#A
zSYNP}z$EFU(+@>q=;?q+0}`|nxO|p!xRlRP{iU->Qnd_5lM>=UThggSG8ge!sd-d#
zwa%c|8!S4NUaRgtsqF3Qm%kwSvp?YaqnJ>O_pZYr|52qPR%jd-w{1z~HsDLH51EJa
z2{0fELKZ)Wu{mbfmuZI4I;9E%aB4M@u^y4X;Zdl9L|2efhmcI&oX@0lMB<e2uEKO;
zsbm}jN)v-(KATP^*Qixmok1bf>+!e>RofFi1N}<r^U^;TG`K&Czb6rHZsJ<ryN)WA
z*3ugM3fGabxYkp*AH=I57e=<XSo?rf#B|s)Q*&Zy;h@Jp)m&Hrs1-~d8acp7MIc!k
zJ`~6TX9F<E0ia}a*+fPdO+1Pf#iQ{IIc++XozTh#dZh-fLN+iUQ)*R`j_zJb&&fWS
zLOJlF^v?xv=^m-vBa|cil@_8Vc0P%PHE$gw2Hk#;436>j)h#i$&v+?=KVsCD(KwiZ
zfcj#nWlHD@G#tSus0ic)?I;n21aOV6<Z@L~w{$v-rie^75lKa3C<^KlPe#r10jZ=%
zr|N6#QfkzizP|Rhwi6w_y>gYj@0A~x%KBkVIgYn&S<ta?+m<K~0N;zyNyQ|x7@%ya
z2qTrP8VDLKFdXD_AsJYpv^gpQMSz4tWhgX;>PM8zBq}+Q{B-MIDix0tj#Ck=DHREX
zW06snR4(sRD<xe$GPPo$?XizP+0on6uk7pZZ~uh!&;K3QAK$g0uad4rqc@LjLE@dY
zA~Q<!7WYSvK?i{EEinwmMj0`jjqNaxOb3XY7P>E{!2}jJ+njFBh?Xh23SpVjuvD&-
z*Aj?`%Y}R^#V-_awfGj|GT|qR(nNxRNYJ8_Nt6gh);BPqm9{<k#A9s(DurC${bWx!
zy7KRZRPOb*?}>z)qxuygmBZJOrE>dW2IiRJ5O~VU8YdAGfy6MsV4|-qLARzUMsf?q
zjr^^Z(28`QthU|&hbxu|%K%K70_uWHh&ib=>02t9jz#0ia3~ZB51SM!rA98(OC<9C
zuFkd|@)o^nV4(M7k4s;c{<$Dx|K~?fDy?LeK{*DInXAN>;7T$e21~Lv#6t*z3<xz6
z&K4{cf->cD1q_agIg426^auz+R6eN;P)dsU6N}?<<MBk;?eqD}TB%AYlPe8MDUP;J
zrZ=k9>VdAlt|y*oM=Gewzr8OqKMJ}+E-PjhxCGEdWX98q0JOL;1^r-grb)KK*h+0`
zrb%%qI7;NU&@V*eOO%9^%q;*RB{H`Zp*WsEPe^dX(TLyfwdoLvN})8Ulzm-YQlgMn
zDedp;X*+T9qiruq$>PXuA3<FKcq3714MPDm0qiriEx2#+n#9BxxIP_aT84sOT@wti
z7B2%c5}9qa2<Lz>RLtUSaj+Rmpx8mF?1@I)Lt_&%xfGa5Z%|14`;|(WN~IX+?r(4J
zc;fLBnwO-1`uhT3i9K?-Eqj<4a1l#nM5CSj4fzO$Bo_n(plm>W{!u=|fTM*f5GUA?
zRX9x|-={$;Foa?@Q^=;$1fWzrhPO?|LjF+DJ8ZQYRJtL9%BYsg`z3m%T&<LLcSt(h
zI@)?=#+Rkc2mSQV{HsS#SMahp62dXE5Q`p=%qrVaNZbTPUyMA_TxJ9pVpFp|U8CO)
zcS%?gNp1_Z6=(`M3;~+_mYjtc1a=(__(KV=)i|V68B7|b&ZruYDahfZ3T01^Uengw
zKcF<dB>h8JdDs5=BPbPAq%|+s+WH{$1)e@!Nii)cx?_|;^AIyc>ky0*20CEvB%O~I
zmJKv1!2Kc-h=M33ut|`&cqE>{rvw82VcdzFCWlg~R`d+0RZ^vL0G~Uk?Nh7T+oU(8
z-(uqN%0IiCuN?NY;{IVpW>E{WN{765USumA-X=Jb@X;ZTf+P@@5eZ_M15O|mAru%0
zrIxk`a1soG{zeg=K`t+V1CXY8h8PqHxW?U47Z8HfFlbb(RGmFig~<B*`Z_uXWZe>F
zN87+F(m#aGdifEQ3X%XeXf2GP8idv)W_xfdf)R*cf#@~eU_@?CBrVj4u$u@)fVV|D
z${8v{+)6e}R~d9Am7r24{9r+mWW+T#KJFM)^hpN?jT#YwWKzI`0ZC7nOxfQdRZA4A
zS7m>A4Y53eQb7tND(qT95Mq3i^SHoMkOodg(3%)kKrl13J_N-{V3dM{Ao}fsD~g_!
z%Cratb4LIPEmS`lqf89PCfp9amZVmv)*}uHxo!7}9;KqcThZ6iC70=(*4L5BwX0Vj
zL8(B*hmDWH5QX7dBaRu$9(o>BKS2C6Q3bw&Eise;rY%_5qKztu2(5})6hc|j+f0f-
znG`i5SzI(83Hj_}4ub}0MXQua`uk)m#fi4|e!Z%#y<0LMmuu`JmQTxsx4rt$6L;N-
zz-{k-b#%WX>KMU@6Zq>}$EbtEeov4H5)(10AOJUp1Dm{mCR%VQ0C9rZL_<hScZg9R
zyb8wCL?qZx704DKyG6#xX6OTPArg{)k-;Tmu~2Y)bYe)QkO9KU6g?8PvFD?0{W4j1
zch`VgrjcnzOs3Bwm1pji3MKQ+yT#!#q;jiO$+X}}?v7pu9pJw7Op%EI+>ikBm;$O5
z-BZEK5K<BX0!82za$8E~daWTw6(C{cNZt-0+al0PHV*B8d_{n8@kEG(E<A2k%H;}$
zQX!Z0%ZJrZwh#1nw0A4$s4AobgBqn?Naa3VK~KJnWbRx?jzPC~m$nM#V@c%z_Z0(j
zb4y~#80tB_LBdQc0Jl_z;bW3HnyP@>bPYk`XnN555ZsJ>4ppH5A{=LPwAkZxlqr^D
zG4MAGC=zrIs}YD?E>ox^TBF%0>y?~nJJ}^uYx^WhnOP(4#;>3%_gE0(I79$DhOV?M
zhh^gjhIC|IxsCe@swlc5W(Mge6J}~Oei($S<6fZ$HfS`XNy2<Y3y3TZ-bw{%5*!XE
zTLick^)g*Cfn$eBYoh>i;b=Ty6#%wGuGXs5YN^gNu9M01{jxrVQe%*qOgfW6E*0LE
z7<AaL0I(b~prcC#{Q#Q0g|56M`20te${pNydX5-eYv~B80^5MdD{Mr}z|}=Mi{?=K
zFgb{(2tQjd3M?A}AfRnF&EEu4A=8gW!LJk1WGog<Mgjr1kp_oMDIe0wq<tqk^+s72
z;H^TY8#0=e2BT6U9nybN`YmQE?$1{~Tt5i0eB@S(o-NR)qe|rt?n`%lhHM0hFcL@L
zMJ7x@iAFMdGc7n7;tv%N=p-^J=Bt9w1fW6$qG3p%FhylZ`X-cwtTrBtC1Me`!=#ie
zq%w_iP|+<Pc(PlfQc4uceuHIDp|M&<bv>#HtLszJZ;2y_{^`BB?T70JwE)`|W_ui|
zV1HbhcWJEy6^LL%X9G^Y_(P#XcaWaDkP`PuL@=;hJYt}ORz6GLkopJbnx_8)(uD0G
zkXWQ;Kp~4#M%PCwB`r}wmVB~Dqfn?6UAln7Iy^jXRx9;RcO?0m^jqR^-$PRQ2Ili&
zbmih(gjT?8BqFTn$hv~2iDxg?8vsi+G1DR@T0~17r&_uFk4ZTU3f?H+fFUYM<a8dC
z3GXUOWgKlT1uB`2#be|dp>Q-2#?MAVUbRfB7#NVM6;hQ!snL<N^vQ>f#u4{~*<hZ~
zYJ6dr%@=xE^398EzW*nOs>5~upS!KYBl{J>w-pHgTYSF7=c8H>kF+ET+iiMk60&H8
zNicyY!88zF73m1_wa^>nAut1UL^M0{g1<w19Wq8XnarjlLQi7BXfzy%gkr%^FytPw
zDy7nnE-D`h)IgJ7qf;v+hVdbzJK!-4>olV_uYJri;=UpICj8BFzjiopyAzWSJ|8(U
zi??;?I*wGt<BdA=kxUu`I-(L#QNSQcT_@@K95j7kU)ShvKw+XnrWOQCf%r#fgX&l`
z#sqR5i-yCYa3B=+g#y8#Qz_|?EBa1$sa0}vew|7RC&B8o3yOj}Frv2vg8|FPh;`^$
z$v4k2N%3p<_L&dM<zY!>ss@LNPDZg_nGyiLpe_-7MMsbU1(XABBwU?hl2>rCFx@D2
zQn>`FJwXTHEe39YI|+q@KEFTUw)vbBRDcqRMxr!WCKP6eMsA5uOe90rgm=g_;Tdzg
zMtq@R$LOH`y5yT@8T$OkkDgRS64Jm#pteCV$6O$DVJu)KR5+*(!pLV!g>)<>SO+-Q
z7VAK$2&fz01P2=mhC}E{!0+>T{bM6TCZlvfPI+t|4cfcZM$O2mWh91eg`9Sm&t{z%
zGmoW$1;beS+Q2u@p4s1j1f>FCFI*}91kDgtFj6ViU{;GdM<_`q7pKn2CS#&$nu@~L
z5h*>X2{Hk<jz%MxPcQ_=<PW;tE}KEC9aE`P{p|{m+iN^2lgQMDu|OgcjfY39&arWy
zBNB;5VmXPuAaq4YCH%<Ywv203>vS(lj5whod4|G-<G`WfLo#qgqj3My#T>m-y6I_L
z30<&QGJ-^6@o*#<4C5t&e!t%n^iwA5qzckD4U9mAE$GqpD?ys<IOK$Hd}PEjq|%tj
z^{^8Ry8e^O*mL+5VL{=;uH>Hkhvip@FpSv3mKCB9)lIgNCwZs(jpISc(qgeJO$~}*
zT0CjKg8vtbL`Y4d5!zsZP{@xsyr_xW<r?bilS^cBg;uZBkNd_3)rMiGI|K<C6e{R-
zj9N!523T=2waTC~j)k8WG3e~sM^Gx54xuHT&k}ga%phG9Gqkx<v2Zw1C_o9#33^+Q
zm`m`b_!H=3C=}!aW`o^$>4bT`UXRx`F+K!RJs?r)wAw-Kgv&Lm8}|896h&#gPB4^k
z7=01%h*7K7dz|)ByW97Y<XentoqGgh5W_n-RY4jS)SNW*wqhxrjfZ1_U`$YTBJp%G
z9C40&f`JeOj94ffiG(A-CxKwV<M;VIZco7NcGx}RW8nDR{arFsz$w$YLN344iWWtq
zUXL&891Eng5l^;~v}nd1L&F9+T4g2UfBMqJ3;*QNi$Q<^RJ;UTTnhe`u4t;1_1QgE
zO9*Mi;(>tAJ~(7F4BI^+JZn4_LQ6>10zSXb<qi7X9+%7Gc1?_s#zVePTStu}V>YkT
z?{!rY5%>5+q=@zfeUX@NczAT&AQ`p!9Zri$*ZsuF&&WWtpT6`@9=$9MiXYe_gi!J`
zTx`r?83~NbW!iqpSZI96fpkW6dYH1R34e%a6Tq9aOvmH%V>SW5%k6Nwoz7vMN-dFD
z9AnmTXCdgfTPDJxlzGtUvio8a1%J??a}MK7`iJfO7jEyUw(Vmd{n!^;_{yV*X4Bk)
zO@LJJx9O1AqUrBc)4VzPc#qbkR16uFDz)4=td*&KVc$XiDw6s@z~%9}-A-iUns9g=
z<7SC$++p*P;Z08`yb0GtvXFM`tcid-oXo~t0lulz4v&w8qH))l!#~vV*vCKm*q7wr
zevXa9hw&8v%HyF<cL3W1-1RuPZ40nHc<>g~N00!rGdiMnok1|P2KpskAN_b|S9`BY
zGtf`M0l`mV4g|ds!Z04zkM#sR1Rb~2;j%kjjtN_sA}9`Vuu@G&!})M59E%sdrg7p{
zHW$gqgH|axt-Qxo@OUOh#%(r3+sFQwCp&*u@tqghIs7kDhobRU*N?{*ymPG50q%MX
z-1eRaq57r47&FlP!iE7TS_9H9Nyo=OcCxpvO|I_i>eHwt)V?xH#OJ4;4fFm3UYEz?
z<Z?Uh4!hgqO^4IfOrg;z&Ms$z!BD{;2*k26i!GE$i#A#=9~>J=JJsFlU@Yj->qot=
z5m|e;M)`9JPHTJV=5M4ANoD=3A5JO<xa%=++j}0&WD`vCz*0&lY+#DIZiTF`uk&O7
zOILs2fYQ+0r#9$%rBbEFGUg4%VqqeW)9b^*x||N1%jU7WT%lMwpA5zdjq>8kR6U#U
zM1vlGEMNoChI<=HX9C{Aa3NupT7C4*M&x>DWVqv_AOE;i^$W_kUw!2hpZKlpU8#Ke
z<~_sj51z#xP`BPaz+I1l+ur-2K+>`WQj&bks8L9ya;>7RyX(mlU42?Lh^yLS(kLM1
zXf2LlIEwjry|`JF#D$(XoDrtxkZU0{;fr|UDWA_a>h<`eaK8kzG#>W*!^!ZlB~f$+
z#$8eGC_dUBj%LT({?f<WyVbv};-s9{U;FL+ds6uZ;plj}LirD1dmDE>I&OR4gNXxQ
zo6IELXvu(-@Y>ni+u7A4(Wng|Mq?_uQl(QWEg|yR2=pbd-|u$0?c<~<vBV6+gas<2
z*o4;;@{OA;l*|sl%j3`HlA$>Fkyyqo^98JCvmqP}#M3U9Z7en!?D$K)0~*~gsovq3
zk57HA@SarGnQS<=Q~+#m<E}@?ZSQ+f;AtTAp_pe#)7?EFlS%u#`lUU6of?zbq%sb{
zu8<gY62<U@5267TkJs;WJH0Ny#~TfJl7(z!rYPhT%lpU1{h?Uc8%ai^KAcZ1?ehh~
zzJSl;ni#cM3)z4R*BkMMlao2sNp+u6`^&0#KKI$re&%<I?@0yE#dWtK^xzhRu7K78
z!EtdY=356`$_GZB?t74CPA(G}u}%z2`#bR^GFfkrqQ70uP?KJz9A_j>+OJc|R630Z
zyCAuDle0OzkxVo+VYL;Lg=Qr%;R;23Hn$_3j<_bg;e5siOc}7dl76S(?e&f64HDhB
zbxb#83;CSUP_B|2>(QCICBLA4=kpwC@w=t>q#|yPr7L#;TZAJ}>|^1!haSx2pt6ms
z7^m%OZ|@&~+}Jl@9OyL-YSmio$1-fu)7Q~y29$w_fKUKY>~?#sm<CgcWGe20e{9qj
zkBp2v+@Vy&YsdA(64`tr;vBJ!NfoYu*)Zm^nIuXT`OkpK>Orofg>mj=vR_eu_X}V6
z!sp-oF-YYOV0&9C$HHxeRBk_*O^*zkO<Ijy(%au}kazc~7=lwN^fb6eh82Uu`az{a
zXOIu{54p+py*{^#zcyR69M4CJA&=iPG-7v-nyle)Dvr;k@197817WX4J<!|T+pPkR
zEEl~hV<70z8r0*#@xdX3-mDvd>(u-A)ZhK$7dhvne2=ai{^Cd$ghcMY9@v8Jd(dme
zmqH8fSLk#)4Y`U&Kd4tp$=^*ji*C@Qr;vj)+;!q)uX@-S@Ht6UCcMFNHEJ94IP9ZV
z!|0gN=?`YAg+#!S2_Ta3(SUD|B&Vw%pRKl~U1rm$)2ySTIv$v?jyc9m>QR+MrtSON
z>ee|QkDycpb6PggB~eny>beIcT7$+&FGr=;*ewPV<&93++bikpYJ2=-mqcrs0Cu%U
znpKa@>$Q!IjTr}r&7<RSG1?t3q=JcX!m8^V4tQbn^gel_t>0jBhR1EjiJ|TRP0ygu
zIW|U&9+?P@3Q_+Zr1BGA{NnFDdb+~gjzZGYr!Wi|<f=|)Rz^)4iJBz_mNAVUZ==wu
zdV4i0Szm8|Z&ydJe9Y%blnM?<aVqO0<+qMl-LX`ym~;li1z)t}G7b)mgho_7J-xjj
z{mA3p*71bj)TcDd`t4(i@w6{6rdF6;o`A>HFO&YNkjhVd@%Ji+jpm;Fhh;$~wOlHJ
z(Ko17^+D*9tGrf))~MGQU_TmFGNqDku|}il>FnxdD51a07^u_&cB^CD6Zd)T;Yc`_
zE`{vlE>AY;usTLZf?7j3KG@TB^2v{V^rI*G2CdrOlU+*Mt78G1&26POq#X<(l?mN|
z9KV88e&Y8kj~s4GKUkvDS*>On{#K?@Xl!QPpjN3gupdP>fFUX9V5kN<dn9s&N+pwM
z0@YG3We<j_aKhnOI$10=Y!l?QL0iA1$L5PfGtmiI8*?3xf3$aKNY&MG^2tt>V@z)&
z!P83A8r`rf=I{m5K9%n8-jT{Z`f>P+hovin3aQpGiv9E{6-tR*HEJJ09y*xidi8(|
znxAyQWK>8L1IA$@taZqq&!v)?bbhK{N(SS_SSXrExq`uXWJ29DJX)Jtm<-1)J?))6
zPd+Ib*U0)#o{)C-DaU-{UK=zy-LO<2ic?dD-4>GxZ~MhB3SBuYh<olImQ+kKwPkQ<
z$ZYB-*OzJxBLS0Mr!lG2GK1Lipq2K^bb1Rtt#M}nR3%hOGZj@^n<>_6*;K;i4dlY^
zh|}wI4s~h+Wm>Z#w@cB}#mGySX`-jI^F)`;X>&TvBO^p(ja)hC3&vx9S8&)lruk*{
zJ6{lIO+9*2G0K!fI=yvBuOmh2*BcD3VNe!U$4E8$ewAL<*H8Z9AX5?j^=Jt8Xf~0a
znocJwbUs23XDA!7)A@4P^!=t(qmn456WXq}6Hl~BOcVO<?w-zmi`#A+QOjhVCpx7%
zyT@VlheF<viwgZ0RquTM3txB?r7|d!oAg>ElyW(Fi$<-rniX=j#>f}y0UZ?ce*MTq
z9Hb<g4u<jx_QGZ8r~1mlalhL?YIL(`MnCKdN;*4+BLLT_h~KR2e)5SYdxkwjQdtik
zddNC5*n6^5u9WE~d=!U9<Cw+nA5kj|zd#-I`Okmh5!4lpQq9r=wRY5Clxxi-`6g{|
zui2zfEA+AfB_tG$+39mRW0`c+kxfUTz{P@rVROLlb=qv!F{d-?jKtjXwzfW7+%^&M
zc<rh#>Zop|aY)nC-bFm`QS^3pD+c@f`ZV_7xQpJrLOX)R_V;~R#VL@V`}~`ao(1WL
ztr{A9YO85Tsn8e{tk8kmH*C~sO>((jAy-+4?eTQj7Y&bjk}y<KW4&sdBNR>h9YL?h
z884Qn{oU>DCk(E1B?}hr0IBNj>hA39=<a^<@y8$U?P)_zhC@Nyuu(nXunc3bssX87
zG0>y@8Rgrb{>*1TcR05d{FOt*xFdU8Q4a}5PwP4Yf91{-x8YyipiZV#OGsPIgkENi
zWrktH@Swx0A6FY-hE4>-`9d`3robr|!&aG5Hy(`UJvy~g>-5`($0ke$c==r&`KigW
z!>St}S9Uy!lsY<2v^{a+vBw^h4Rj9$0>NmoR7(5Pd8?t%I-(d*^sC496Mt3t_NPAm
z>CfCFl|!o|h(<@2N{c4=R;#KJ3vQ2A2l2#h_*bVIP-zsseSPK;rBX{Q9+0b4`r#23
zJ{K3MbtbbxhdtvLdmx;ngHC@qYy<M|r9v=`j*U)C*hVexki$dMb;8`!-48dtyREaM
zz3pQkd+cM6J=rbS`y${Eu5dZ-b@=?wVS~Y;9vv|nEDq<-D#7AD_37U|l<^DL>Ckml
zsR&5z-2>3Jg|Qq-D&mO)sl269DRqp|Y856kEe@%2*vNRgR0I2@PbyLCloOtDgLO1G
z0e&#<v5rJ0hOP2mwQnL24Vi7W5xRypJDC22Gd8O1?-#S%y`8<C9Vec6^2sM3Z`V0u
zK(~QlA{}>+jSX5u`CP>2)|uSyVP`7&73JHnzy8Tj{mvmI;X^XO=zFyA6=ZY7UC6he
zxDEfxrCLqDL`Dcw8nh<uxV}TF?Hy1tge})gWD1krBsWhu9C45U>o^p2lfmm9PZXl*
zLd0wxl$k6Rhd&bYnkGj2)iBdL+eqL#PT)`;d!kc16a>>E+e_slu5q7H=_o`2dkxxA
z7(kgu`76rry!P5_pFAuT^yI^^1qBViHTf?1rM%H2=}PN~7X16Jo<P$^q|r)bX48<`
zEbjo2)T*EjC=>(If&R8GjTLyn;}6jm3tHtC<G9)4Vh}YorjbgN*g+tg30u|u9Z$5K
zIPuuWpTN&PftzjX*Nq2KxoWilIXUVWvDrqo4u9Bh14poWeX(#NS^7!EcV2n*)z`ju
z7olt!&!M$6N3|d!i!Ze-=%6EX6sg?lA&LJ()vwb&Hb6j@^eHT3ZcT6ZfWm0h3}}XQ
z@*%yvr{4r<os9)u>ClLCOxmZCjf@RXgoE}(IN-95dxMG4u(7v|;q8tSC)-Y*IC0`+
zd;7^JyA57|Y?hE<K)x}J);xx1wmGb0<JQ3;lSud@-sn%$4|?U5R}Z1tLMk7IZ`*oj
z0#iFsl_TlOZB-HQ@0WTMI(2uqv|ruXIcOQT$UFKaQiDcqwCGKg%LBs}PZ~;Trj*Uc
zy`vKrt=X4!LA0R1?l4;1QKnMOC)!zj(ACv-@??jwp7xV%y--IJ@qE!ANH|9vb|c)U
z(NW`sc}Qy-x7(vut5sJ_1~NaR_|D5Ozx>K?7lbfc*G*WZH}8VkM~*=P+<!~Fz1BvJ
zBUw=EiQDk+tzLyjs|6<L?xRC!(e(}JXnDwnjKivalTtD;8gbc^g+c_vM#ekpbO*d<
zoo>u&vxnTaK$=#dxxc5ow+o@PQxdj!c64@i4-7fOkhJ~Ym}h)^Y|Im4D$`;%nv4wa
zn*15t=%C%=ZxnLXzoPi|&6i$!`H)n^o`gd}IkHr6D<WS(Rm6uQNu~9KNLz$ok`I~W
z8f8~spL9qj>yygm$^n^F52)YQuCW-pEE&6nd^TJvCj6e!v9XCUz1cQ8>Tr94shQ%0
zq^k}0iX>1sIih9IWoUF1ATt)SJ5$-<pv`6<xBJ5`_LQ2;mLc1?Gpbh_?7lSnqbGkt
z{_PiU-hAn|?sm!U=**qZNA@c%S={|_6u)x!sdwM)x0=~nKrgws|1p`or&k7ut5tQj
zcgxH}W`&C1c`lL)c=I{0$7M2^6ebIhqa)$*27SKZkffiHpObCvZQW+Se|*Ghb%v5|
z%@7QiL1#UKkF^gE!FmGfwUh6SjRxJrBj!<8y1??}Y7?ov@ZyU%A3>=|j2gX?tz}Y4
z`(p!&&fWpJR?`Q3pi*0v+A&Yu?avniZr8AR#6D;oHJk0@qjr}$=&|YzV<zTJ2{>&X
z-ST0l(`p`ZMB>5l#9+YXa60p~QZVe87!P>Bo5DW-u*qs2o0xC};?TdR;F{IypFt`w
zym<3Bb9YqZhdw_nU13;q$f(!qbpwyL_4f8k8CH>XNTf2UQlg5$w;eZmVH7A82Cc?q
zF`EYU!w&c8pmj{%-%Z46Z|jm72FEOeCgZTh5oO}TWwqHS+z~d%6;rX8S5OJ@xjC=R
z?zUTpjN^%Hk>N#1@oba+EEXhm<<XOhTxJ*=)u^=cp2wb)cJ;w8@9TQJ6VP9$j8ux5
zbU2=v@HqplG#eU{>c@x8gC?_H+e=n2mElkN48u0~rEvcQWg!#~SmN}Y$H%RvM3M0+
z8t`5Z{o1sD+~c#G^_CEaHi&^EHXoHLSkTRuUwPzkTa7}k9cJ#U`>}Syka1*K()Z*O
ztTNE)!z=~Qlp1CBsWfZD18!TtY{)za@Gt4>>64nqUA7@Yt;!YgI=w+gIH0V=SkYg`
z;7n@WSdeyErZQD7CfDa{rF1ZW2@Zy<lT-CdCe9fbsciD66yG5Py?lt1aK8yXEDJKS
z^TIM_GT<<k{c`i5uDAVTZHx*I3{|SRRBdLm6pCc)KI#FT5$~fJXg|@@aZ>AvgrdQK
zTTcHg83@H9zBIdeBI$C*mzjwL9G*ZTkgsg4pPJ&>!@a%bjg_gIe^8g0DHkH{SS~X;
z$>d0$eB~3L_{8CS<x!D}T&6S(59@U#EZtJAn%-4+pVn;XmB*X;NWNJKWz8eisCmd?
z9h7u*c6YH1qgSER+TDIT=(ch=z+RqYG*wJ`f;M~7=d{)9C8!&@^6KQ&USo1)zQVEJ
zoYAzgIpc~Hb5V~iQOqQuuO?IVpHqJ4Rgv)*?ia>;Uq38eVXdl?2C5YQ+AG({hYU)i
z#bT05U72JwQmscl!EtlYM_BD|@9ODk?-}UnWyP7<Hez?UM~r^x+<xEiSTGR|dfm*t
zCugTiwWWp4z5V6p-kHTR`+rupr&mv(Tby05M1tcUu`=4{i7|LJS@~I{^4jaK-(Ls4
zCzE5~D~FQ~?vI<V4D@%==`lzpGL6|{9UmDoTiKT)v5trR@mQ&nrKt|dV0@szy`x{+
z)!Eg-zJq>=$vWW;`%S*3)%kSL=OWSsz0p{{lxCgJ{02My&s;fm=F<ND;@0x!>7C{I
zmD5Y7XV$Z^D9*N63@13xfMKLxRK88ge1FY+NGM0oZGTKsktif>0|v8nKs6GYm>5x8
z$E`AD-&iQ@&6H+l%Gm<@R<h3F0T7e+zP8SG^1Lp^NGQcd?Bdk^#hsbCoM&Pbsw9IT
z%<+~hr=Qxma&7JM^=B`iS=e1zUS&V5INfZ9^+?-0a{*|Uk>N~{!=@&4EqvwmM^P#Y
zwXCDPSE{yHh9Ng;%m$Te(Cc7FQ;2C^R&q8f+1m0#c1)p_YLo+={YtfFBpi#S(}DQ>
z?kP?|Oa~p_U^*E~<P*_UZ1&pay{E2Ux^VXTGf!W5`uxV$*`3py%PcHksxB^0*0UtJ
z(QF{ysFKBjue^-`y?zhAA{Hgw9Xvd~UpZjU9@m28n%>@y9)o#o++Z;pJdV*(TLh}Q
zH<O*`<U%pq%~{k7Q&T1PSkN-ir<$;NV})87sU+uDR%WIvzBrVXbPB?5A`r?y{o?s6
z&z!$<VfV`QXP&=$Zg=a<?9%GyDRy>LCufSuWGU_Q1YODbDWZM~+!oa79=~#U9RQ|u
zY^fZuXOHby`qYZ9PK$HUHa2KfxWnVa9+wAJiZkDUBwCnh#8#R!i}UrRY9ul3@6ma^
zk(50-JC!Ld1g6*5^U+*6mnlV4%|fBVKD61VuX2X(^G`kd{7cV1^W3?$vztpR)2nOq
zbCt&8Boolpd~SMWHZ+o3s;ASTzYMeVKGf-uo(TVPY^mH{b9-D}k;$dqiV=r9Frm?V
zLKEh2DhM0W70AX5$!w_<$#dN9!pdC2=TDW##-r6ls+dWY*-f+TuQaAhk#Ia-%8vvR
zjEIHf^G{#B`t+6OuU`1XtJj}Bzq7Wmdv<e!GtH)_E3+$$4JKVP@%-$3J?RJ)8|B=W
zL}b1Pb^1mW;P%6GK5l#4J8N!_D;0&LyI=42M-xt+&J~M>=%w33>2x{j@W#vDLT2{t
zsm9!VE#gb&!X963C0oG*r*frJ*+4Q=N(5OC9T~NI13_mf96NXM>XoOizOa4fnadaU
z_m)p>o!jHg5DqnK&Ma?iuXFwqr+?Jv>&1jM%ozt?7A)jf4rg&+MOVJ@VGzm#soZAI
z9zQb6R0D?bP$(G<jB1UsO41Rwd+>x|%ZRNQb0!zJ7Pn_}0aqpyie@5><>n+~%sEe}
zP=sonj<Xrt;d0pg5r746Xy*F!*Pgp^d2xOB+WCu{3(I>PguTL!%jL%O=EmvmjasS+
zxIMMV?tx6yVjKHw2i)vK8GmaJ@*xuCF)iped-nKJ8BmY9g4tNa!AduUm0#wlomDfr
zQM)q}cY3PL#LQyOHsXjg5>hH}&O~d4KscDFLHS~Z6YN{B+c8K+;~yV$)-OH#!n2po
zY|idqJj1fj#pSiFEp|CBZmm|hJGHUW$ThOba+B>q>@4&fjKrW8WBo4b)WU2(yi^Wa
zhk$CwwjiTD5{|jY27&oCijh)5;bg`=Y6;}?rcqCNX0Z(a&+iLnlGW*YnN@-`S4%A4
zC_rBarw`iVo}pN-knqG;Z@zTt`nk=W-K8_<*O%DhxVpr-nrj<dt5dbDb@mFc)@P=f
zCNEDdts|AmA<f?;2E7W8|E^R7*;ZK5o$HvoBJ8MzX&+N6Z)xp*>*&OwPHQxo3|f`d
zHWW(bgRXF}>KPf$POa36o}fJt;XELA0%XexzdKjUa`;#|;T`cuB0hV>Iv9xu+_AHt
zd;aXXvs<mR<4;d5F0!zY(+>EwJG-#Cy|J^gS*frAbakp+YOby{W(rQt-&OsPRK7vF
za;SaykfieNXf!Ye<gU{h&7M(<ZrGE|CYi|exw2NRoue-cX=m6RXil;pPq@~!dxS9|
zKcvY3Bd11<4m4rVJT#KM@cOI!XHIXfZ|z>(-`<*DK6P&U)Wvg~OY6&9%bX*Bc4=<8
z&SBTfi_`V`%+f*yY~1^X>h0I>)0I0)a{Kd#kV?z%9#dD|4MkE8J#7xNQs>Yaot{iJ
zotw*LoZ+ZJYj(wJg>1rU3zcFCmN$j6$&fvs52fjR<pa*q5ewu$rVQ<l$lfcjT-w@R
zp553xyT3_|ytBD{`pUKQySp39duR5~?{6(GG&fIgt<Ej3EY8f$PnAQVYU5WPS*iF#
zVTQX#EW^fOw|O)at&{?VoHL!vIc%&zXsk>(BEe=R<<C{KrED=82&5y?%5)`PEd{*+
z_bBu(mnRaPf91;6)0?v^;&_?Ol~ZSS_LnF3pT2zhsjKS?=PsSUc7APTeszC$^R(D{
zDVBdaipBZ0pBGYj<sQHCi0F#J;u?d(rLj2ujFoz#rMNwn%1<^I>XmA~w6L;VWj#d7
zZ+A=#kNYM@hv1G@OKeChOckLVv*wp6#NyKV{imMVU)tPWSvj@8ynbPCbsPJ+eC6U(
z*G{jVy>RB*{_<R5f#Wi^b~xjCWqG3#m@dt1eFdq!M!s^$+dd*v(L4Pfzir46@rRr&
zHXyR3#0oTyQC^suDNoPMi{)PVyu$)KrIo2Pz6wijIbk_9TVduqHCZoI%QF`)oV~Qa
zE>e?qjvw0F+g@5*Kf8bN5-0eA$DO`(ZMu?da$d&fnVrSisg;$5Oq|t7>wlf8sn=h9
z^|$kn9BylmPMD0~DI<n4Um_Td+v82PE-tXFN1QCi&YEg<p&B+TWc^aLe%New`5i8Q
z!Y$U@M!X&xJB8Bxr5l&YQ&zUuH<otKUOanddzZ6mIe~P4hv2h)_R586hJ!inY=2{Y
zi9N!&mP#-?*;xKr)jOYJmh2J4;+&3QtFA|))eL&$1vVh~t4(q8*4#`Z?$3~+lqWe~
zD&ZT2lWXz#y`wglcYJ8f5n+#QF6Z$T^0k#qS1w<>ad~%hn^U~@FYIltp1$z(?m3R!
zJhQpHbLPTRXO~&RuyFbmhvF?P%`G&imgi@kp<-p~uZdZ*Pkr(c#Ns?|$Apnx@M>ca
zQ;9?ijd@NuoL^dNcuPx*304%bbU#0t%~WGC4pvIo%zE=M<-mk36Ut|5vGnC@7th^z
z;U>~pI(6ph{cVzzGo1E(o@E)Fj(1`I^zQ6rB0jTyW`A#$Ly4y5=9lN1Nl&(1pZ!HO
zvt*z7%zaZ+hh59Vip(~KaUDZ4gJaN}DaL|@1rC&*oSIu-n`ti1m$C()CCA`tGT@4`
z7p@SY-C@!x^rKc=Jm~S2a@N)7_AXy~;l&$I?XIovoqu|7VQKf7vm94@Zino4du@I5
z)JDFNX>6{oZeQT2nI_8$mlul;OLcL5=2yfl+2`+J3mz5;_YX@dfCx<Dn#cX)5l-!+
zwB1-Br<hq~*<y8isuuHF^OeM?-eehN^t~L+)qU<kr_Vgdf*u#`<jS+>FFgO;GuNKp
z-#WE*>cW+Co6CDoT|9r`{Ej#skmb3Xr)LYfh3zd)f7{pr+n%0TnwzVJL$jM3#b1S+
z&GiT}OMO1KFXJ_j1s#cGWa`xV5*QN)6fALA_uRtjTx6O>aHE2U6AmN_CAQ_|(;k~=
zDCmvV$`O00c<H5QZ(KS5)YBWwr{^~=Up~LPwDt7ab9>_CgYE6P)t%GpIFOCyrP;;l
zxpn^E*}0YJ*?P1(wYnC6<2GZxdY^{e{qkYyN-_Y!V8{}P__N8z#yUH)=QwG%IalYr
z0*+>mFR#RGR=e4i&K9TEre^1&(-EUT!{liqU!JLF=dXVDne*o_UEZ9YA&WhK=JeX)
z&iS*amZ!^eYn$sUJ3Ff@k<#)^ojpLMNo=RNvN2z)&E}_;S2sd`8*cXJV65Mj%E37w
zcXw<&xK!@!NjO++d;55?W7o`S@3_P72xLO>#<ZyLS=2dKFJ~tgw@$6Dl!KwAo#}kk
zX-}4GjYZbHPB-!@TR2?~$79u6qqK10)mN@xzqkWTFg>|-aeI4*^LDmRt**{4W;Zt3
zoV&VF%B(EbIdPW5F97gnm)6%NDGeJ_$ztf|RIreLn45iQ!R-;Ga;sJN+$OgHA{?DV
z+4>I-KG?@?QI8`ZPt_NRnlp{+T&XxYJ-gUC_@k0(uFp-C68=E0J~KJFT*+rjBbGw8
z+ziL^)kbA%`TA#Ge(vfX4rIPwKXqYa`4six*4pCC<kIrS+UnNo>~?u+WfHJE!-|*5
z(k#b9Y|c$D&CC=+`M^)WEdAuCKXaIGi}4(f7k8UJe89C8Z>=St<5q`$M=I-0q$<mq
z$@PV1qg<`UYaBpKXx_;BlXcF5X-vmU>FQJ{5so`dW{}-<cBYZxbg~7uOW*w5&1)A<
z&u)lq!As|N*LF76&+pF9EiNygMy?z48>{TK1h!+TTq#dZxUf32u{poAxt8|Fe4l|A
z_sS1(C=aR15n|8*QTDwB3AZ_5$Cb)(Jn8n;E6rqPc4fY`uC&S0=mjJcb%&>>3eBa}
z$x<m8@i@a?vqWxj7b?~2=6o?v=8q-pe(L7sXYj2oXPlhf+T(PL-SelG>WgbDY~5Y}
zIGC+Ai_j<uSrAv|mgea;u1qg1)$)mW>QjR2^g|4=W8*7_7Tdya6Wg<o?N`ihXR_8T
z)*JJjO29b;9OlOw;HBke#1behPEDp4H=#RvDz#i7rh{$kT3M?T!YhqhAz7>y&cE`B
z%a?cQ_LQs5*}09?jm@(ccXt;#M1>%;TxSJ&rJikV$ns_?jfIujne~;q$(dR-UdW|h
zll|edH*P%t8`---=iUX;N6-}^gF}mLZ?h<mt1BbkO0x-ZbasAfa;m{L=&2cg#q*Pn
z;mlOI8jI&(_2o0X){MricKyi0PNP_EW?82Zi&bLzr(byP+Os=LvyF0*gEW`7&z`<?
zY3tlJ=T>cOoLVkbCKq4^CD|<(2*wFKD+|rV#l}+A?}CS$_=N0RSFb(u%)dCif93m!
zRpn?>fhgM|@3*i?L7P3ku9T~};_O0$<;Ugv42#uS%fGg?Fqxc4%~q$`BA?mfOyXv;
z*(}WDMu(j_K>l(m0%#X3#dEpoD=*%-egPPkLzXyi3GTuE<)=2q$#1J$>)Q*Jsm0kG
zKtwWMh$T2%Mi|z7vsv=mN7&JxctxCO!G`F=yLt}u)sK+d-r19YL~bD*%%{blJ*KW)
zOh#S#spiu3^nAH8$1$Nx95uC4sm-OQSs|CpS7LK};A-JewU&+h!yFLWoL!D;6r--V
zZzR%Ky!_&`bWNApN6!NG%Ho9!=bt*eyMJnPoAY~@vW?00**semXt%keoc=bwvec~4
zH%rM;Yl*S&mk*@!&yt5M=<rsjBS_^AQT8q1{aZlUd_q-@>sM~sUAFA>;{43|a+!o>
z8L_Oa%;x8E`C6z_FV<J*w=bO8oC}x(iK^4hTJ<EwKu~H5#zu9z=)%h7>*sgRUf!H<
zuq?UWoZq{+zrVA;e|~3qb9Z;SG~3vlg*2EbXJg*V=IQmhrMYTtp*d5Tu&|*n`J$|)
zEB8p{kbt;-@O%Xkyw7z^U3u3&maNV!)ECz0<Ed#B9;CThn^~+?a+3=)<>LJLv*%CE
zrag&#Jnf83PbSOr3l+OBVN)tcD4fnebN$lZ)0cO**Jq+}*7VPw**?90c6VcCef!Mr
z_Qi#{jajy7Ri|gN_4U&?HtRSn%(Yf?*jY^(eNmif!AUuXE$BX}@H>B>H~YXZ9ak#8
z#N@)#?DYI})LWUPf3>nutk%m74yjw3Yfi6ho;|-cU2o*$SqA=d+nM-meRjcVAC$=b
zg!9=e&s@Cp)Xl3;UAs}tL<mWh$=S2pyQelUo!{JTo<3XOTqW0UZl1Y%YG-Hn((>%e
z>?DVWG^^n-OD?mo%D;Vs>(}q`w)cqTjfW(am^jFSi9v?5OO2^zQmlL<76C~qHmg&d
zXm^3aX1xv=Sqd6TEBOLVjnbG@?VLWnJY8SgU%hno@^jDapT86i)gx8fty9-_wt!Oh
zR_2;ZmBrP$LUW<Iec|-h>AlUh$%WO~()z-}W<3x}l~%Vu)#CBL^g%4-ha?qOV|Aul
z2>G3X!pdr6b(?c?s;TP2S~*_MHcQ3jwe`JI^Tkj+6B-<xU#w1TQxTLS+4)V1gVm{K
zZ0(sF5O_|PO$LK0SE)8u_cqV&?VjB#*H&g1=bDYRnfX&^)=$y=IJHn++?>xgIJUML
z%#>$OE&rs*_&@o{uN8hYZi`eN#>E_NBv;M{#{=apjwYLoWlGhhGwa1<WV*guNzScq
z@2r*+F`vWi^v+hwD+{$!gB)#hp<bWeXUo;%CttjF?Wr>nCY7C>@>Xju%$_;Fw?BuW
zEuTKUapwHasok~g(uGr}78=#k(rh{3sN~Xx<wkXS5-g4>?+?UR5Xl2Ok@xw*<N6g>
zph2oqE-cT@o?4$x2R)NhQ|H#og(PSBEf<nI7j{l97Nb53d(jJ3Pi3ysTv|E3v%|ZZ
zKmYW+J#qcTof}s+PLrMFruJ$as<|?CVSA@mSecqTef84*-o-1|HX7Q<{@Ps0@ATLM
znRI!o+*mJW78j>~P4m6K!u9pZdwj{^FCJD53e<s@>y72L&7Jk-YO-8k*_zJf13|b+
zQ_a~jP4iRDSm6I-?mgh6y0Ua%?#%qAr*FUe=DydrJ>7OY$F|+J+X1&D7?VX%&N-og
z$Wb{}P-TTG<xF%U*~SSYOvW}6h%A9b29ZQg2HpQURSJMGavHHgrBkP>RCT^u@mp)}
z{m&<#muc-Tk%2Cr{*cxYKCWJo@l!nd#iu7ti;oNP^$84di--*kk77&O@zKFUo#~L8
z7&jqq+LZY5{{5bMJ7~n~&prA4OV9KhG<djwKxCM6pwAee+DDF8Ft&Pj1>%O|-a=)x
zH(MG8M8*b3P6!(|I5fo9*SQ}Pfm}RY*-0qCGdemp%;}9+pMQ1GfHz+o6)|>{mtWYp
zxL6wH!ZS3Jy~3g<PMJ7!f{&Y*zf(}m7-}EmV?xG6`8u;4$$*H&NmCN0PL3S@?3;a^
z20rz~-=BT%m7zn2xkpV2b@z|;i}2h0=!sd3?cO&a(e+Mmp)$}v2+|-ta;(R&flfpy
zp2Pn6kH?;V$J5Ql$1gH0IxH~MYY_Fb(Zl}H-z8vt<e12?sBshkeLYpC>C+;8qQ?=<
z28Z~1c?=8=^$UxcFm;0K=rKOS`}KY1#mLlY<7st@edpm<$eEv@M*rNK?xVdzQYO)p
z>mC^ESNqt>d2{E^-Qm*}h#QW33zfH=M+b$6M+f<g80Hy5Sn}4ZEafzWtj5jXpL!R;
z?&yI-=>vS{mFEWfg-=8pVkV7Y@0_vvX^AmYqNmQ7HgQ}??Dz<$VIFL{6E-Gl%&S8q
zU0;0espnsx9v2o)Wi@8#!%x3OrT*y`Sr?gwK>epig@*fk1O|H5KX&rH`Sa)P@Vx<v
zu6KG16(=vBs4-EV?^5k>rqiwe^H1IL_}flwtu!hmdRla7Sd5?ZNcL`j{q_ERhlj_+
z1qOu2PKpVLo|c@HIWsmccIJeMGh@RiPl*WdcVo}0uz+CKr=8qhWx17CUSg-sxY&qr
zpAq-{?d>NYc<OoYz;~E&<Qp}1Y)nv~m$Qf0R!{+!uBZrcThWQjPen!2A;oR|{C&y9
zlP&iP@r(>`dUv3Em`@06M?Uw+efPaI#D%RfJtD`_i!(MV$k%hk+d~Hoef3$7=<%^I
zvE#>uOj5^BN>7>|O1E3wWZE#M#fHa)c(H-8udl}&FF3vQ^z+ZX_<UdgG2`I1L;QT+
zb?*1~$6ogE8^Sypf7hrfAuhu`M)n`-UgwaNE*hkC3;x1hCm7rIxye7*Ge?B^htMfG
zV(4gh?;)=}ckdtn_cKFA5o`Dd({m9THhyemko!w7cno{>>DRoYCr7X)VodaeDJj$9
z6DLdx_KS?2F+OH|e00#*anW(nq44(uo_Y3_$7M3zO9LlG#YF~2M2-n@8#(lizJtlE
zhQ2v?*o#9WA_fk288jrobK_$t=g*th)vm~zrN@6^2bd5m?ey)>MI|cAcZjR^n1~?*
zMh<fu@cg6qK09c%i);!RLc2+D+_dpgfuo;%=<N~1JUqju#<CxLP;^vW1ogtWxR_v<
z(72gXCQh2*=TGAsZE#^D|M}>>4?O+!6OTXn{NLV+2!z-U^Mwu{{$ePxtq=R`xV-#)
zzfry;*_zkO&;2{GwsU58^+B2M{JeE2yF_q^N(X)Wb5V(lkR9H=hr9R=dO5&n=#T-!
z-Tiz51A@ZGOo<DPn?4nC#eMM8&w2#;xq8iv3J(eh5B2vB9y?|H*a@L*;XHNvjA;{M
zJj23VL)lhy_;U}k%-W-mJ@@wq9)G;AUs$+bu-_;r_9t=)j-L_d>`u9001evgR>k(K
z&VyGyc4E%#S+llzbs7?u&HhF6nL!7B1>y;0mj7&ir7bchGA`7^ZDgcde^)Oz7dD9T
z4Dt)~4f1iGJa*i)3ACex`crHk?CCwocUn|vXr!N~uh-a#lc!G^9~~AFH*v<4X_LmX
zdAzr;f2iMpr&!POq38OIbb0lqM_v#1gGmS&IDp+{{6hVL0)5y8F2Ik?eBGFINU7gr
z-J>S}rMhbr2R~Wy%QQ$#%1>Y4wu`LEVML6-KiqpTQzZR;Jl*}gM|k_mR>W@MQzoMv
zlcPfe{hj)~^Tv>2Z~KP9Qbz`Rg~v{bo=JE%HD<!tkckr}PnkM46!st}(034%sYVW)
z>@%$2Qx81wqLWW_O!Od@9q;EC6Fq)xz@UDEMg{nJxcG*S3JMxJ)MMfXqPXg+$}XrV
zlN)|nzpaRfm=>kA^yg|&Xf%b6FxS_H_yl|T)8j<ZG$1a}%`Gx|eEhWO<Nb#XV#|UT
z-g)blXCJ-)&-Xw4<ZG{b#YK%9J9TQ*)Wq?z<AP)3rc8>B!qoV<di(Z&J$Oc-TT*P_
z2OfCh)uAJU;$l4B?d#+`b=<^>GsduKlQX4S3Wx(;N58{Nq8V!+Jpm{cTRl27NP4q>
zS;xA4fdo5!`|~wu!uUxMvC$A|e!c<hV$N==p@E*xxQ?+?XC{mt@y^fzFFpPw9Zs+P
z^Wppc%(jlN1y6__6Bjl<VP@itaWN6T#I{kf(NRHuK5SC#95#8PZ(LgZIH#9J22lqg
zdKu+8&^2moK;X=<(SFFImp>al5Abq({k37ELsmU{0#M4gbfSV;`9<-Hqd11J{QP~%
zM1x|+C(`5xZ|xHv?&HBWs{UR9em+4#p_7uPMh@@$V&6C4y6;a9Jo4bv1D;{?!oIIW
zCXO9TPfF~h=~E^}MtFrxiHVGiiVbjOw^5gXF)=X_;ZxG4O`YcN9TO8W(#^}w*>_aG
z!NUfO9_i=iH^L{#YqSr+bf}MSz_4N7D<3%lC}mwy>5v-x!B36i<chkEpQ}ORqvOT}
zunn1uUu@(k@1WoiZ+F^P0>+J<k{avAE+`}4{pS;Zx$jSZyzd_m|M^cZIE5xo9~%)m
zZ9-h+xR@~%2ANbC85iPBbD_&f_sHnUQ$qYEjE$Q(c`8j$A>_)VN4XC1bqg5rn%kss
zw?Q7Ep&l+SLkGMQ8RX~T8NBk5;|eP7H(}9vx3^I7@sIL%^Kf>fK<4T1#qNhA+%cO$
zlcr6H^YI?-K5AfpWmVI^+<Wgmf4p~ClsawZG@sx}Q87_5F!n*-^aI94d3gG`(uW>B
zVeHg#K0)5^1VX({iuQHx`?hP}cSgI%#rwI88s;;4pu3xY<fs9|@Jb%RfuU2zej!Xk
zd0GA4hl&Sf4^Mx8S2wmF4)J$)b#?L!3yg@JIzGh5D`4bs7oUC)vvS-$tf>9x|8w7f
zv6|GG<2}bjL_|#r^MLD)jR}d0^ps6kN4brIt&Iur9_2Z9Vr+D5l$ZO6ci(=a?`!YI
z=@PsH-|aV$EhFFV?=<+$e-3nY3*bBO^8WIX<K^XLWn1n-RM<t<)z974-7nmKOyr26
zo<3uuBgaHci1zjJ_ILFQ4*BO_|JJYXgR=L>J^$<ZFxAW{F$D2rCXM%U_8dE5Y<OsF
zknASv;qD(kZF-cq>qyth$x|oB1`L1m?U!UxfHz&o1-SI5U)jmMKcykJ(WBlP$_B?i
z?#|xc%N{;nR$5wG?|ysUc6;v(PnR%%H#aA$9>Gk<9u*iBH!dO~jFvWbIQRAsjr4xy
z(TART{>4ZCde8s&zyEN5Nai$3gHd!~!&C=Oj2#n1U!(^eKcoG_hI+;Ly9^u}Gch)7
zB-5MUW<3ek1ojOd$WAdH9`BCy7%;+Z7|f@uPo$fl*T~U99-lsZtfZv0_%75SfB#4i
zm^0{(@Tl03h?uzPLEhnEVPPJ_hI#sX{?p61|6}*x`|vX_Jj+Va|MT84Gseb+1Vlwm
z7~|~X6CM*269gma<>c-hPN~pm5UY%j81%+~;cv1$%kyu)`0VSE@lmwFxcY>I1-OSt
zhJ|<zaSrry2@DEgBgJsfj~+T!TvS|KfA{gWKE6TTBZs`}85S847#$NH6*1Y<h4~qQ
z9!`T?{71j(<1zS=`~Hg!l^=ifk;fi?CTwbCgm-Z4*nm;}J%b`A5dj8zd5jtnGi{ou
z)8Oa-_J#+Qo;TlOZ?=~ozVE45-*F!^I%w2@AruUw0>@4a^ziWY2oLZeIr4IL^$GWX
zU)b!TyOGUyb_sPJJ$#S{O}1WvvEc#!VeWpRv}|}gzv~tf8cM1BiNCUV{!>ps{@CMB
z^$nRG9Y|+>ApPtiAycM?QV1CNu2Znz@Bw|_!MKj_q^bYSH{R<1#tZj7_4-I=oH={=
zNBa3WvrCGn%<qj13m!vDqW35#FZvkfJlK+-Ur?~wwbK>fbktj(*_nAvOq?4<MJy;V
zA}|7r5#Z<I?#r6TzWzb*v9CPvm;bu={=Yx}_a`2C>XBhnqeH?&!q}$RJ1%D8w2?zS
z+)4i2Ui#<A7Y94PGtAr5-`nGrH~YTv>Qm1#>z^*6(QX0ZqbU}>{1SU<GBYhG4B$q1
z(PI`J9aaV^He3FtyAKurXw0gQr!%e@K0kI`L?oYkpqGog+h}(`cluJE`tw69G5Gki
zk3Y<AC_|=31$#w=xO)3VjEfpOewas)=b+JUL;Cj{G;qY=exp6ye0+v7ZRqv>Lp<3E
z+?`si`|wfk40z+sw`u0_3-a<9<}$Ruo0ETtZwNd@=>siRo6UL`q7n_|7RlUN4_~jS
zvC+`d5rLxz_j7V}3-WbkRVq)XNB(l(J%76Av4{Tp*b|RG>k<(e;RBQ67ZDxG1eeIS
zoLz^oZRn_X2ZejSHJk}W9`5hH-hVVDS@w$ei}dO@e60VQPQwSjJvhLP#zVG`_Zv0L
zJHR(~jH|!%h%!*gv)a1!+cFii>oN&Hy;GyT(blm&*-wx7?SyaCn3VBBETw~;jV1Vs
z8{_W5F5RBa-eUq?U4{kuzxdESe|qr#M_7gZZ_hmaT)(jKF;PK50Rf@@;o~RA`V3}w
z-u}ZzdIpV&^BwKZ#@}8(FA>c;dwYe2cue%~@1#lg8$S5;H@pI+t&%=Dk6^!du{A-1
z2YC+o=e!44V?EEhscRQ<J-~Dtm!E7`+8b?u?m7t$!gqXFOk7w*U>s|vOo&MsAL+sJ
zy@Q8%dId#<dc5|KlmE;2|K+cb{ex{_{?5W@uAYNv(hv5h--+ZpdaN635qSg!zQc5X
zUvIzQQ6s_V<zZgIL8E-*6K90=dp;l|oNh8FR^<o`p|#9A)WhH1Wr%kiGkXKPoacfH
zi>!B9H(TLXei`dzXR?3pItdQKcl@}}F+t;^$H&BuqtX{J+IfUGQ!hOvs&)PA)4{%P
z-T&ZA14j;iY1oLjh79rYcsDjOG#ZLB$o+*ELIR!oIs5obo-#hzhut-q4$-gw%TK@S
z7ZMrdIc7pA+hDtexqAkAQHEq4mJk}1gM*oS<~kx^`jpAz5yd(8A7x9J+%EfkD00%J
zU+^c(3JJ3;o%nOtNoXg0B@!D$>*M%w)R|r19qHmW+<AnXw~w!HwDZfJ{)3&~cs*oX
zz?h*vks}7a@ygIqFTBE*Tfvbo|9D|o_{g{2C<DYyWlEiEzagIN4cKp}v!7o`sJ{=b
zyW=C>e0{x~142Dry#2j`JbbAx`FpueOHYcNo)jPBGs?44P|3;dx_^-HD_zz@{>i9N
z5TaA?XRnjcPWbwTj2{;hG;?gk7;iRvclUC0XW0v{5c21sU|+w1uLTSl9yBq?#m_%-
z#30!z_8+6CvI8v@qJ){Og*SO-a73VwtH;Q`{~YwLx7$cJ&yWCbFaO}s0N-&l$rxN*
zX^0Aqa2n<6HQYNq(9bU_C|MI9Jaxu&e;QG%?q^pe<_G<X>)RqLuyH?oorHG6H+t&C
zxY+1%G5#JS-CRA~hdR+<{@Q2{SO37I<oFp=#!n6P^AGTH3G)v09p(Ja^8<&wx(|J)
z@2l>)7317PX=DiUbEntV`Nb!mdCfo6!;>y{Umq_wPe1?gn8=uLuVJHId?UOD(^cv|
z%Gt{`AX69WG}0X}6yO^XRDS=_T$wdBqSL%`^oy)5s6g5(1w>hV^r!lucEWekq{vAV
zqy0QQJY)eX4`-iH_n~hO@eOv4%1BGsWsUQ4avJ>lE3c07p6L7hqfb2b%nSVnz4ZJu
ze;<-DX>3BYKi<g8&uxUqyD#+{?H=h(Cj*!7PS2rV@WhG1Ozn1a^K)~d<Q5p<?;Q~C
zF)1~gC4gwO3z{%_YEaSr%q6pAZ@dweUs6%+Xte#g>m=9--zk%rO&aL#>*+F-O&cli
zxd+j8GtzH(zlqb5GEHL#zUn;iZ!eAr4)byP+oOSTUV;7nLI=F~a$l$LNbdkwI1>K=
z_}YPk+^A@HxVpPL)5#GM>Fwbk%m&AP!`^iF8sq1iTbLT>>_cD}Jz<2WkEiEIPtU1&
z<~W}+P+=3hjZPi1BFiLnDKr1{c%{A3_UEEvCw!L&j)@HQ^LBnyHq#wGa>$4gp6*1Y
zkxtLXCMD_2<NCk#?n|$^g#|i2bN?S-n_H}n4;=N+SNgx%cO+YYyN?*@;=wu@o}N<Y
z@rxPc1Xtq~6dma8fva{KHPZ9#p`%8)jPaio>*7yN?KYaJYN4KE;+Sa@Gd?aPu=KBX
zREBq;a`VAYwzgeKTaJIK2DQK3D=5rw<cN1(={IZ`**%k0-2Ed%0)q$i4M<fRQ(azo
z?zI6P&Xh_Az3@O^>#~Z8ev_hHqg~h{wg2!T&Q5Ob?k-+K+*uRLEh2Hq8y;R>{{ACb
zQ7zcZ(`)32A){Sgz1>H;M1=WHQfG{FatjPq#fQ`M!_)k{0|H7wh5ZgU-hHUp4O8#j
zo;h}4-=V|DT8^JO(zI*qrn=fS>%XhrxNhxt-+i}!?W*O=KKuCNj~6fIW+7wA;spy9
zF8E+>^}IQ=D=R9hN(zfhit`H!3knKLN=wTst17A}qm)$7o;!E;?20+_=gxV5_WTb%
zSg>Tt;)V08E2}HZii--$O7d;_46BV?-I`xqT3KAk-zY39E-B%mygZvV2X3Rdckr;k
z>#3!)a?-~?`6O#BL*Ovj;Oeo*9<>h^KY4^5<U7VgorCRNyC0oTQI0xZYd=uVwZD)B
z&VOX|CMriNjmb|wU3}@%MaQ_%KF)WJb2pE(KV`JPxcxO}9OJZOw00e*I!14za@d^o
zm(o*vckSA_W5<r|+qP}px~0B;^QKLk>gsB1Yd3z6CVk7;uzvmeb?erxwU0GxR<B;g
zSh;fLH!@Z@h8%OwK31(-Z69kGYvqO)$qQE0EdToJWnX>y<riOk{`u!imoEME(@#D@
zN71uIixw?du;8PQKKk&(4|)}q#3xIS>;jY<P*GqJR1{bQ7hnMu2QH3F6j-`o0yGX(
z1e#SVyMO{L;37~8DxI*jqoQE4Wbxuf3m4i!`QU?IMde`d)29?r+EGDN6j>2r*~s|b
zE-o7sP})VM9Tt%a5s*${S@DgW5Kt6RktZT39WvGl%QBIc&p%@zDuN1_ELvm-1x((5
zzc*#&=yS!QK6X*rzRjUObuvU$I)r6|$cbE`eCaZfgbo$zR3MQSK?P7&t!@WHB+Maa
ziWZ5q)QA#&_2n0ze})F3Kz8*(R786|eE<FT-s??N4nBGMMo>26oq@vvNvEVJ8sJb0
z#i%$8i$hxMXxKqPQWzkJF>;J`@>@~BHHsQ3TC{ALA}w}Q7K{EUM&(11l-@<<&=Z&J
zHpOmh>%l~^C89Sn6jO`(ARHnZA_Jl}9i!u}9hQ}LlY;iFS-Woi26;7O14FqHJzTpM
zqpKK~<%kOw_p_y+qCtvLS*S<~puGRy{N9umP*JqU0m|mO@4w^ouV2q)*sn+Vj@PbP
z&GpLnuM9<G?DnGFEjcWQqABavualR5zY#V3-fo!M5tcuVCazwECt?ULXc5vPhDEU|
zc%KiDl=;1iO7jyJJ5a%>Y})u8-zS&2PLX-J1hFHl0cFL?6>DniP%XQ1$?v*Nw~o!q
zsIT9$W$U)>czfW+;VVNq*t%uQmio;&IlJBZ9v!tiINo&i>J>{q6iJy+yLfNP%3e^h
ze|BP(`pvc9e=FamVpZjP2NMwt5&4=G^HqtA<mBX}ByJcoH}A%g+BwqF*eXLtdU|@A
z+))NcX=yx3US|IzNeuohlON;bqo!4@UV@~&H*a3AqH^?!i|t?N)-9U_l?@%Jh*l_|
zAn=OBFU~Apw@I9}46(?lNEd0bi-}!U6j8yo?Ib)zM)<c~BuB&rX%S)RaC4Y2q(u?R
zWgn)8efS0XLt}Jr%E}QtDtu->?dHvOqCxTrKQ6T7lvGuf<yma+*I;Com}F&*sbJGK
zC7jv3nYd=l)~#C|+96kMR~Q9k&}i7br>VJl@7}#ldv+^hkBr^B8yh5!7OmpdqE7X8
zZNji`_;&r;MPqWmL{jF==}lA)c14Bjt(9-?+X~Bv8+IQ#aq85GBfGy{m{<6@xE6^+
zR^}8aU$jFYI#Cf&7zjfLDvf)Zz@#0O#@)Les3_9oKxOMzC1|Xx6QeBlWyAWf#}$0S
z+?-xT1-qgMwj$XGwgj~ATURunxhCw-b$+g$+q<f$<g0JQBY(4Ug`r^UCWorj+ta#c
z8R)}}pzLosdF;r(z5Dj<YZd`%w4<Vk$}VJRry?pMEJ`S?!~@@ci<qw4@Kx}__i3W<
zO<BPQiMA_WokQPki}qY>`{Byv%a<=*;^xW^ZI_!q&tAAf(!p=OS)N|C)s9MieQP^!
z*49?DaG}VGLy30oY!RsT?%i)k1yF#+p+F6d+v@ALZxsa+4YC^<iIVK7tlcnY?9w@N
zX7wg2A}e-K?9u+_4SDNNUcY>ylSVjy{=((!t>4<_el6x@Ma{=kHf_SOf()p%<I-9a
z+=)ufww;^nHq|U#ym#+r2PzE=fd#9wvvJ4jWy`;*!zyk6MzJemdhMv#qk^>)=FFen
ztEe1!;-VrbV*DgA++f{&;p+LbLV?)n4>>w}{>r8LlB%y(D4wX$ihUGVK&9C(Ev>B!
zn=2H9i?r;l*;HRwS5x!lrxne1R2mzwu)BaoOzn=wZ$DePV%e9qb(`y#+cgMO#Is5G
zD6VKjRpP?g)x9Yz`#{C+MigeH-dcb0!s%A1pOYPfJFREVU#>5#`a+nIua`~zL~+QQ
zH@BmLeOXvnvCR(4jvaN)t)~_)T(^72tj*2HO4IH}Nh$;u@ju(Qu3oySe%%+Jez)<v
zZ}=YUUK&*F4w|@N?N>32X7#G9fJ#?T@;972w=eeh|Bo_$KYn-1F~;%Z$4{I*d*NI2
z?9adYl7EFpCD_=sxw)-QWCc)~D+Cn>E}+snw-(P_BdF|c+T8$0uxQavv`GBV*41C2
ze%~$IT)Td`V1fccJuO`-sF0dVj5J|>@7k4pj|(b_;p1ytyyV2$V^ja__rL$$@BaOF
z|Msu{BXr-9qxR8q?98cUx_O_$6MeBXP6GeBc2oqE=877Ng05IxL8ZB=p>a>m-sZgu
zDwhG}@{XMfDBJ2cEJgq78*10DSgv5QY10WnIUxaypt5Gox`fK!)u3iU#qJI2>+5XI
zXOA9w?B9Q9*Xe)#m*4H!f8;RZ(7{88kDh6+GJi;0?$R&QDj;4IRNAl~xSxuOni`8e
zpc7Q;IAv*Q+)>lK6IAvz?%HvA(PgqC^oU?_<ND7xZrb$C^5tKC`K1Vo2;PaMCpt6;
z6-uk<U2D7h@r!o<C~?EQm8XvE-}i@q>$7UT1oVCW<@a@aj~qFC=+MFa`}Q9=(z-UY
zbkQfDeDYaIszm&Co5a?Nponc<Xd%w+0A|Oooehoa#WxEoJGXDY%%iw%K-pTqX8CFi
zldzyNB=WD@ctWDMc3D}SGOKrGrQz|5igy&Nx5?Ucd|y-3AO5}1x@~yTCQzvrR1lT@
z`<k2gAKz1|nGb39@#5I;6jZP(trKLVA{?nAaqSrZa<Qv%b!#1=ZS$UnodSje%l2)A
zC+oiXN`a!zj)<KKRbpy<5O!tlHwnG$nfE?^LHqz?^X9J?9NoXCarYnowa<6E4<9*l
zq|d+puC5+yv14^@GZ)vizhzlc>7vDpmMk6Hj!J9mgg*USTT@XY2P$@45R1m`t(!zx
zns+ydh-|4xSojV2bv4UZeJ`1%eJIQXq9VqY)O79I^&e-x-@6*r^!NoO(GyXr`u6Ca
zh6X|9`#o6MmOlUTzc#ID`u6+pH>}>Vhq!&u(eE{u4;C$4{OMG?2GzB-Hc#kpX>GNz
z07VBX3NG7sG_=-jko2%=_pTk1dDa7qfJ3hJ-SXw@g`bfj+^_^Il789am9^^%i+fpC
zwm$|c_EBeTIMleSVb34_rO(Euqd4RVeZseGTDk7~+TH7F8~1|Bp`G~|a~3XG{OQb%
zwPIK5TALU4uc@i4a|V?Oq9hOq@{jA^zIW@c-A%yKw3`q`!g@)u1r##D@78Uwqv3!=
zKoL}wbbZ}t<`3ueZoIPfu?tu{fn`%|!QKOn4UJ8|`<FhodjaLdkv%(_4(-|Auy6P3
zjk^iP_8e%co>9JF!J?0oH`adleeI_D8oW=1#bSX*njoksCW;$@WrxBgG&MCf?o{*!
zXS@ad;e9p&f$%f(-#&!Ew2KN%*RrDbKAhdV)^^)t7ZmNr7t~hm-A{VE=l*~BSMkgf
z4(s~l9NfLBasQs}-+tGymu&CAz7HprP=H^O_Wec$72%d-h?v-2ncYSSEZcVy$L(oq
z+S9N@C>iJ}U=c1w@<4$_8G?rlh4WqyExLAD!AGCU6zkrM_;);Z9_0oYH2ecx>!wXx
z1OEMg@QHrcXCJqR)-}}aU3qZ*x7&AZ+p=Tl_Rr#q7JRf|afXo8$ch6LJ21$I49F<q
zqa3L05mXcti!T<Fj;M&b+yV-gR(OOppJp%qijIcfwYHldJ&$fHcJKRzo4#55?WP@T
z2mJm&{^R$5jNYsMegA#C*M8UBuyWnz-MhEfeY<A!SFwduu@<GTT}QR&TVCk!BY?_q
z*a|d5V&BbMa5{u2TcF4lLJ7OAge2{}u)=`C5i3;{dkN*6g4~*AbLY$fmfn<=?-f)e
zW~=@FqpfQ;)NXCu+e`=skJfU!W#5t0#}6Jmb*Qmv|K43&Hm=|DMNIyOAAI;xOqR)P
z$;r*LG6$ezSRI32ZyumMrLc&ZN5w@2HadE9va@-<9MEuPHk&a<GB}c9atuq!m*0I1
zC<04wqVnCN=M`Z-c=X7T4;t1XDouxuRle|#7hPtZw!M&lx~gx%nS^)yI<MHfdt2Ri
z+rQA&P?c`jd+;DRz+ojxYH4w#O3E+79A$7vGRxz~j~{C}DuLi3o`2Y$J{;oJ2RWhq
zmg9p557@`igS!=iQ*L@06)|=POMJY&r#F4Kv3}RymNU<2i|2jma`Yd%Cyu}L%oE24
zc#j$~ps{hs=Gw;mXWnF6Y!;Vwl1=03Hj`dyWw5V;EcophzD(Z_3}z|j@bIu;CTDvy
zBge-tfWf*sJdMX?$SWPM@Rq@5ryZj=QK@_Myr6Q#o0O(z&t??pz{&H^sMIblhJ88z
zP#ws7BK5$GSBDIFWoyH(`uaWdK03k^|64{cqaw9a1(l{v4Yk{MA8tMW@C=vjjm<|-
zw;VWj_V|HgXO6z`&a3r}4O<%b*p{7gKyvB$LCK~Wq6_WAt`A+6;=ulH#-USJ?ucw}
zqVnw{=cFdApmOD_LtAz<A8kE%U*tQDEoUy|56L@I_*UMTOBeqBM&J59ySE?MkhAfk
z{c<iHyL`v%y8RQboj-8Lm-i+r>mE5reSL$1%JsEJcJJ7G^yIley1m+T`s&q?`k^h)
z`Mi1j;t$XEeR=bq-AzYl&)KU~MB1(&zuNVhum9w6;kZ;)er)t6Dr+7&Cw2D2VprN)
z*PLkBd-%kee|zFV1r_Uk`<`<h`oi<iJ^%OT>KdDl?KIWcN&V~B_TA~Ce(ZvI?ApGQ
zcX&o`qO$gpbJBls*h@a+58t)4G#@&Cy3c<;`2YXqnU{6iN1C6*{k-|=-~aYf?XII|
zOR5{~B698OeoAP+XzV|3m%7_x)0?PlP*7QCN2TrD@~cPox3vD}AO7>+zYX$CPI#(W
z)AvPW<?sI(U)y|Tg=O_=yNF!7y#EGJuKm<;{rdivA8reX@<4B*vKmxqOFE>;O53$V
z-?tq-dV1FX`JeyqfBfaa|9T<g;OP_lAp;tBY}s{ww|>b%$CdnW2~>V6687i+pp0wR
z_aD8%GTn+$Z=$jaRLDylsI*<#u?;4cP+wTIy?YOxx_s&U*|Vol9zAm5fN@^KCC7*V
z;o^;`*e~@b+=9xHJ2>ZFMrF;KwH>ImU97KbyLkTmxija^ojZU2;+1RHul?}Dl}ned
z?=jBWa=zWfUIi7-JH}47NMGB2r_1lFw;w;W?LX2Eu><J_{))bf$n+*Es~<T_&bqc;
zR@$y#*uLU=+tsT-T)TE148)+ybzWbkpSR^~J1A{8p;B@C%fHPdf{G*ZX$PXAqOEP+
zC++u`(b<b*)x&3LjO~<_w(A$0K5M{pDxfH^aCD%`vZSFyQrg<Ch^%y6@Q!jhT%*^Q
zUv1(0Zn?UH+wv<r%CE@JQSKbQa;02Obqqn}LMH-pq@cn(BQxuGiM|&>>9ZPCfaRdw
z+A5#(%Hg#iZ|xF#{?Pcoxq9`%OC6G8N9BhusL0hW*&#3h#1aLM@}mw^?5DPuU*><u
zxY`XWAR(fn2N{8=H&IzBsH|Gu6_vJYXPZ`j`0@H(2U}VWHGa3GC}&Ph<LMjxsL09>
z0)aB@XxL#`qDToBxc%~W`Nly)P6;G8qjFyP4mxfe8YI8&N>tj~uAbRn_w~ZLm1Sj>
zb3R&DySMdf7eV1ecZZ5zL}bYtx!nO4`Xhn@KTB3CcqrK1AS>OVa#F7-Qm>=3;^DJ&
zcC9|>+3}s(53XHmJ$e8Jd+&iGr!L+Sg<iSPDJ#mQD>nkc_RCA`QlUS*t^Cp@eim=L
zw3wrE<^CndxYD-&@VOh`(jhA+^^ywovIf~vS$PX8H-6%q?_EZNu6BI!A{0mTM-Yii
z+w^)M;8wp_5Ro7Isl|&gZYy_8%;J}za<i=PBGDeKZ9{LP@{J-ZKNS_xpiWc-o^~O)
z^>-%}U5>hum79_8O=}A((lPoIWko^dRsbAlx?KH@hZj1=U5-kP9hCz&+m)NYxf}1_
z9+ewm=z6aM5jnWaQTh7evn!Yx_cKtr()E&WKE45hZth&Z)!N>Od+)}!Ux7*usCeA`
zp?>uKm5Yb2{}?LW;Lzn1U8|R`A3k)G54!mcd(*Cb`Ouk~nwk|q5tU2F&t8+czFjW$
zmP4-n_T%CY=Nix4jKhuhdlQw<A3C!fSoV9gU2Q$o4IAJ6slykpUA_f|t|xAfhy9Ur
zmwq_g*!|ybKiiwAd<H7Ovfty<@zx8s^(wvbKyRY5R8UzCDkobzroZ28I(z4SZ=&*v
z0~Pmu7cZPYLJ!VwJB}y{)T8$)D57wmTV7aDTv$+2#Of3!C1piL1(ftzv%*%+O<{I^
zK}oUImRFFUmy=ywR9aG6QeILqYgS2Bd3j}7MR`SOd1ZA)Rb|!OxwGfYo>N^_RbD!a
zBPGErtDaR>Qe0Y8UQxkcFXN}8w5X)8qM*2_<Wo@jdinBw?)xvEKfLGSZ>=hO4g*Wi
z-X|~5R$wj6FU~D2v=rGu2s8={3X3aB3JOYQm6w$km)Y`dMftgUvpFXx&sJ1gT2@h3
zS~;t%qPo1QqO6QXKFZ4~r4?rO-1n<yzc;&bK95&bSI(*~FR!Sot|%=oEh#H5D=W(f
z6`ChXOK71`)(Js_Xw4T?E}aLIJ6XwJ{P-T|&z`-H&1%ZaEwZwjoh3(>B`GW^F0dAr
zAq~YPNI?<nk`xwMEe3;8r_~wE+4)7_Ql4K?T~^Nj^3vks{F3srs_Oak=ggb?-mL2C
z*|X;h7_%y?tE<aOD=J0!DnX{Ayrc|K1k_SFDna6wbfR)@_a(^M-+0J-^z3~~3v+Fz
zTx)KQ#fXZqz)M8|3$}>FfJ#Y;D40#!VsshW%uG#|)@(&^3JUUz$|?%VOUp}(ifk<D
zQd(Mp;#AL_H?O>E&g?3-shBG(!SL70!LYKbvb?;ynl)q4xDrs|WJPIV!N(7sS%$EP
z2AyrZc=k6R@*X{VpMw1C-0W;qezqywWX)yano_H^ppb90xS#+dQ)nwFv|5b@O%|x6
ztJPYAna%jDJhQy4u&A^gQNil41Wpl`UQsctstgROX3wgcHMa`;QdWVDsjMuo;Ghz1
z<e<0&WkQ!q3JbBe9jG+i8I@z(wo_R>{qw<-_vpd<@CF8x#cVKGva|JuT#JcLDO)}(
z`=A{av#U@P#J?cVVl<mHsi|ohTCFL^T1byowhi-KS(smfBo&vHR}>c%R#ak1SV+FS
zVqWzu#ARN2b!k<_?CQ$O>hhurR0(peMC>{Li%W`%3kwTC1yQlfN)JBmj>BzjtGA#0
zaagu}cJ}P~y&rW8UC&X;v6{?AeRj4{uQwWWdc7qFYg<xOP>snf7Dcj}btXfWCS8@3
zp~^CAEtZ13oV<KnZZ0b%6%?13qb1eV6~#7GN`#`cvI4V<_RN}9RaH?ryA<bBj_pNK
z%2{Q;tgHybBKlcqE5rx2qjF}~#WS}V2W8%%j16sDR<*9*&Fo5<jC-K<bayW}SaJBw
zrJA+fJ*2$H?cb;COLDSJ7Ly)v(dn}Vm|PZ*LIR3e5+478O=PuVgW06hvO~K%E8CEb
zmgQPy^TwjW{Cu1X#+UCs-)>xrOVOap>Z<DMIrC;?ZfA?fE(aB?uK<XX26BXjm)N?>
z%8#JZc$m+7095MQR@I+bSJ&9MpZRx9yN|bay^fCKh3n3=rf%)H+x0*Y=@}}yW|PHe
z)ETu}vq76>&f)tnF2}im2)3ZuX3fjXF`LmZO{PYpH)La0@{4d(*c`rYgef1~SUSsE
zj3Fv4F0dgSz%Xmp><U7a%F3$hDr{`k?AcZ550b(t6bD^gR9I;DL5c>Q*?C)8X*@&U
z-x^2ucIo8tmK`gkCvf+XQ(dpP<M^A3=DG>pqayEd`}gVi3mjw{F&g?T9lN}m3|hS<
zzo?{`ueP+ZoM^2y&z75Q$>E>LoT<_oOj$;gIA;PF8aImy^0H~;%qQfr=I2TyXFj3>
zB;}PAtW?Gp9<%3`^Q(-b%4*E3Z0dn&0e5+Eaq*%K&wTOp_6rC=x1;e4&5-NbE^cS$
z;LdHdw{Nqfa`;5IPp_@`*b>$4Bg%Wo`%tjF!^o!F6j9L|O-8dJ%U~%Wn5aVPiM~*h
zBAdmMlVi@NPc@ro5VaWf1anqI%7$q%89*#IR}qy0pdv0QDXExUQBg@~H*Z!I-K#hz
z7ILGCfi{W+IvfzfR#vvS)2{p|Ds+i%s#y*}rHq;t>qS-?Z-YvsC3QmD9Z)%Sr(rf4
zjAkv(xY-81#b~k?Rh7y`VKxhhV{<L2mCk6k<eGC#m|deuYd~Zy65-@p4O*>Hmy>G+
z5Nxm5nPS$XE0#0>lUg;as=T-g3tU-6j9h^?7WE+r#JCg@@0OO?WkodT!s#79A}gSB
ztc5`zt>9rFw?pN$dP3@&?opBVke@Yo0_Bv!WI{%=b(U<4E<>Zs%`YeX5GR^nP-F!v
zjb5kGX>)S4DvMdC)0m8`WNOmtEP2_+EVWv2vgH=qEChZwf<TO@a>eDPgtt}IIGyS$
z31+e0B^6jIL8O!;e#(nV7CqeVgD$jgyU==@fn8~72c;`2hmLpug65rdn;MvtdFzn(
zke@rFLiab;HZMEJnrqRUa%@}{DIBSr&6b~M)?@*SMsL9+YjSc$eUKeBM#yB;Yc*<J
zmeFjqTC4?mEPO~9T#{!klq)AXA)v#I5dDg`F2gt@99R`1W^rtiMiiEO+=0r)A3<gJ
zX^|7g4We?S@iwS5&no_=uI8ItF|i}kLsU$(wr5+#qFQqD@DGZ2K@)Pb%@(5?{n4t4
zXL8IsOD;i;*<dte>3~C>uFcBSsxUMb3qA6J3euHF&cH>NVL+<NsxYpl#4n5@B7EF&
zX(<|3R6>GSCLzm`4ph#c*m~~7ZALpPfYMci8ulOU<^>0u7g|23JG#x%&11@Y$ot$`
zR*X4VQxk^MWX`b`A=p)w^5F{#bMyvXmO-u30-K(!AV*`g81yC$;-gn-Q6`<vpw;NJ
zvMf2~Tq`e@+|pWDoNp^8K`t)Fo+v&CwxJwtsbDQlgh@n&_@=msgsA9~hhY-FUWQ${
zGb%@q!X7ehdmok7raill9NE<^D$Ol>Er;t4ubS}7P$9@?<XW@MMDfK{fHJG1I6u#p
zZPXgF)R<tsDK972oNLQ55#nYUvocj#S%^?p7Qkq;Oa_(Sl4Z#?Wn1$Jb|s!;3D6P@
z388-lL_<*-rWg4@QqUT1P#$i{v5E@OpykV#*-@$g5m`~B<S3n!GOo+my><U>P&vFU
z^~Ab`!EbbjioA#X+*wx4CaV<=p&&oU1_3~tTU<dpXt5gf2BSV*ms^sboo&s|E6mN$
z$<5KIvh-ORwMwVes`;<c>Oe?u(IG`h6LCwvjnuNJ5W|Fyz!*rlM?6R>P9BNl0hBVd
z6Z1kEBz9#v!lKB^?NQltx+^LQDAybJ)Nb!qR<<s*gq_$H6}9Y_p<>FxfNE_vu7#Yf
ztdc0JFh7s*#Gum{EGmmBC!g6kM7RaGW}_xclbMtXEGiX&pGK3JWgyDq356C*UO^!w
z1MwZfJW)N;P%bfSNk0Cks;I0mr?{ZBD8INGDIuBU4aKfFP`RLdhuvMti4%KT6;zHO
zD~_c$u3v9FwS8SvcXnl4arb~If4b+gl4Ud+v-z3}gcc&wP*%aUkwR<myB3QTuVTs1
z$3c-+!?I{p8EF}6Rc5A2gK^2q5_6OdFpvxO2}}6}9ARM)2iy*pM3UrUB0`evg2H^8
zFroRFE%YpZVHZ@k+*X73oVEujiUuj7a_w5<rPh5b_8sdU#@n8i_mH1EYmi1`Fy$0j
zZ4zsiR?V&`A*so?<>*aXl{Slq@GxdfhSh9f@>RA`rAg1wsnau5YCTq0PkaYlwmfSN
zNaW^Pa!D?&xrDuB1*DA#UTG0lCEtoofrDXc7Y`JIN)d0F_W`JoG)okBV)N}$X|<!W
zudU4<oV8xN*0A;aRV!8;`H8T|d&tk7QGt8Jv`F4tTwK9A%7sL+IXM<CnTc#UR+6}a
zJhLqy&kfgLHl`yaS(#}XjT%xWixWs%UIFVW<DS`^BHLzzW#HL1C_BVO;l#y;08$xY
z9#Js-gRJXZl5frXu){N7{80^Zpkg;E*Oc)Cy`?J-wA@xKx_zMM8brDWM-3!|5hX>a
ze?E6DA_eAbE|kTk^Ybk1JAq7OWtq)-f;f0ety-;8XK974!Wa|%i>=ME+6wcnunYxO
z<gFM&4?KuZ2vU?_hG5wS#AHyY4>twxcgRXlP}zI^dh2QawVrZx+pg%=-gb+J{bbKk
z$ubn6ANjClB^70bL}A7F8fGYxFJ`j`2bWcvn}eyyCJh29NNpSuo=BI4?pgBiU*yfX
zhz3%EdSGs$>9~4028;^16gHfxk-4nYUC6Tv@=QnzI+Tm;X-CCle-BZ)e%&r8G~qIS
zLsa;J3-U{0jnH}6075Y{8wXejVU5{VzFp#0Q$8^s%#;K%WX)!smOMZWCR#J@CtH^T
z48=m`A}Ufe$|Y?;Jir16Tmlr<Jj^V}V~DN!1<WqZ;}_pWy9RmeztjT_YQBEmk=31)
zC60bmRQQOnZ+QT~Bv%w5zsO?C#%{uH=RptQN}2nL(a;&QjQAXwTYVNW9LbT9l+tX%
zTN#lhUI+`W<irR9ZXP|ss3J1B9c+y}Dxe4~pd>G_=6>YxK|MpINf8u9O6=XXzoD!k
z{Y46KR8&aN&J|JYz=P&dC$tuq6R#H7vMnZqkr>~s*P%cLP|-+eYp@s~AebbK8X*r{
zEObA~CB~$%2#G<VfCAgA7!lYytPk$nR%jFLL8E$zN|VC}fl60dxq9_CL?suQw^+n4
z*s@`-g<`|<iZK+si8k=*4cJ(tPG{2TjTR&6kv3CDG-D7?jhdlw)D^Sw#t0oR%!6ye
zwxA`F8BuR6u;$1tYpfK(AsTBHWs~q`!NX^22;=tkP*&P)iXtgju3WhV6=jvdx}CSR
zw>`JE1|qO*GgpMK0TtM5$y_Q+_?7_(16i1tt=9_wPmW9ggU8O|Kuffb4w+1rJfq&E
z$4w(MvLAv_ba~=_31UEp3LB1FGOau)-yGZ;XL1y<ZDLoH*cMby)}O~#bUT_(**$a9
zwHsswR1UP<_ySqfsI8`={>HPN_vAg~=g#qpN@F4hGvyVMq~vE?OUnyNE6XT{imfat
zwsIL3jm4<SGLjf+^kzw<F)mu6Dh*josyAB9gmO9A*a{2b8<L0a<q9Bqf|A&f!h&p^
zRd%+S{0cHt0>fOMlbeeVqN%3_S-JdUsL0Yi3{Yt|DhP_m%FU=KOQqG+S#AeQ&r#89
zG)BTy*rMXH0*a`T-_9<rD6XP@ObIN%fFKt(g#=p9t;$Gjt5;{FVP;H3zQ~B#Xrlfs
z&YSDR7$F%%F;G@EL_`=}Y6J!wC|GQe-#N+=Ob#i8X}-wH^5u6xW#9I#%DA(v2r8`$
z?R?WsVx$O62P${qve&Fpt2KJP4&J_$aD{}9)U9|HNg`x6Y<zCENvo!0NW5k=Xmyz+
zg&FBOk^!9&Mw1JJqSTAzWb^%FONrA8^Dr_%BFj7EkPJ|yhR@0tfg(W0y-8-kvn^)J
zTw+_hUHLItIezqzvXFs8R<J5|QMpxCYD9xtm6@!qHTya>r~RlMmG=9$|DCB;!|%fu
zL7+(~u!4NQybMBtpqyH&fwEynrb<g}uh;2Ge;_P1YK?G|hAgse$%ZHmkYIv~%?dL^
z$^>OYm_tQ`DkEiDOe_Hqzo?&BvcXQC4AG~b?TGk)T!T)q284_bR2-mOzD0vTg{9K$
zsI)HJbIV2d92J#Hr8k>MXr;S^7M-dp*ld)kv>3}^MG`X7$&fWVEUp=Vv^q^Du|9+x
z6?q~$2uzbfXSSH~%zAjv0vlB{vyhvpifD<H*vKDqAcg@$V96s&By^VGdCtRUmMw#e
z6I8a`*4nmTT+`Otwe8gp`|q3WilD+0aw0IzEDYBE!j9ka9(R5pc{<JngGpFYR011c
z1}Y^*6~dGh7a;!{7UWJ&&df+x3&)hHfvL?>fsvYsKTC({C2!X0q;!Uw5Ruq&$P?iI
zAsED<LQ#m+Sd7RFB9bRXC9{e5Gf4T#j0SzR?5nT#dhEZ_gHL<Ru1Jn`LFCt=V;vW)
z94u^OrK37Q1$63u2`XHa-ekro<`<QtK=k5N78YmQa>(b*#$26Nqe)B6P^D|M=uwtR
zovzYoH7Xi6=<y-O)tRz$NhFQ%oA?=cP7CC=IokxsO}7}*fqAu&D2Ox8F%i5NO*9el
z6k);5a~?X)ej8uyb?*@>C+v!(Xp{Zs*om7_L4lf^MU7a-=NF-3LcsO7j=cP0D#KNk
zMdbzgB_wafW-$OpojNs{_1iU+nboQ4%rx>Jv9?*Ljh?I-9y3d0&{K#unuvVJEAjI=
zIAZjOt5>2oup)!RMNug*z!Q^Zp+R{1*$<um@{2FNZ0;E<HzLs8y@hPm8XT;6qSn?L
z%Pmjoxds6WRb)MZTtV5a3M%g05U-;SIXGRtlsHmT+2k)HL#5KF)6-PolaYz~XtLBQ
zJ=X>rcx?*-o+XD~7*N6M5T01X%Mg_)OgWrh9{MCjmTY1^f<Hl}`k~W+@<k72<(7-Q
z&561;k(9b$go+VRXvCluFu#OCa5-CbmD3w&vE>%nXy3@fF{h^pBdN~J$jHn{R;8gt
zI3)??sD+Ro3hlt_#j27UnUNQ9K@#6fnuP8s%PJAul6m8hXbPd;&vHseJ1Sp%-t5*R
z4Y~~ox16qN6HHjg^p;0DWJUDsM+YPdYHrIXA1cl*653XJC<-W&6<Fy&AQ;I=rgKG2
zpN1waLzMzNboXRxwHRFz0i24)VAjEDQ=vELgwe$LN_-E=O;U;6NSJR$djx*sU?LZy
z7wn7Ch^(+=?XQlCEbhw3NWCp8yZ3fihdyz>^DJMb%|g*#xcMStE(m#gG>S?j05j`z
zDWGPiWM-%{Q|JIoO-aVI5VTNCRf)VvdBmV1bV1oDEfVSGARq*9X5w4%$<#x{+EA-E
z@rz-E4^?WoywosDQ2Fe$re9Z9ZULj?M7yl)JlAom%R$ST&O4I85o+cXQQj*l%qyae
zYj!!+3Y$%QEHRiC;ZSQ-$w`SxNhztIlai9ECL&g6nJCNShIHb8glNG$nJ7e>^ND5=
z5R7g%e?qK_&5FHIe2<BYQczJ?n(~KEv#-(8Cf8q8gF3J6=A(90wo-w=bsRs}c@9dI
zHkEQAR*LBE6G~e;N3)4f3$oP~Gi-`ELzS74nvs;0o{X^235K+&v$9m=M>@3@(vDsZ
znxWw9h|)0KbYohqA}K%wH0X`!5#|SLqXf8OT6B;#WuU?aKA>{-)Ryx%v`^F#2<dM)
z^DEqu_mH2>7dv&O^Qfx^l}Q^Hu`HDd3Vc+7D`{DR6q4^b+hEP1EQX{I%%x`}&4?$U
zOHENj+-l%$DW_tOF`W|4OS2Rqt{7bd38Rw!NVr0Dht428H1uM2>4YIvq2887eu=Cs
zUHa*#d%8oV?9{261-}9kUH?QoDjP4K?Pi?3(0LMOsIUZPAJvgI6PyqYP7p&V73ML=
zLiDClr2$G>VoF+OTCyrVQ>)gKX-iNnHq(F<U_b;R!ADxBBu?SA60hWvRbpX*IFAlI
zaLJ*n&&y1jEJK!{^2sNk>~YzDwe=>ct}7$rs3Stv>uW@8YMQxemb?10R(WtinViwr
z$Z=1Hyoda3xIz>7ncC|5b4!W}mz=Awu9a0hPF>_i8E2Qk3Q^q5wH42z5ud!dBnS6H
z*M30(4NYdgP+W~lm6Dd0nw+LprzJ?yFa?#83{i}Vo{A8cOZyn0P%se|oLoqfK*Bjv
zB0?18PH^HO@RJe}0gjqDu=JtRpM0`p$?on@;ffb<wfZ`499LeqKshRF=6+onXvq1W
zgUZ^g$|S2zRdp@pMJ;tzo0Pk)my};}vz>?wF2q_OErKLM!ls!_`8HF2A(lahS;Yyb
z6St+MYcexa($guB;ggBzH2NHji?kVHPa&Y_;vir(LD1#kZz$-44DMJA6u^j)f#%f<
zDqsi0iJ>lisPz*zzuN758(FcV;JESyij)9WogkraN5n2YJ(HGpSy^RArM0GHtIf8x
zq^9*|R0<{0w`P~pLoEK7@_30+>ClE+)9JEIdZa>|N&v@ZO(chz>J%W+639uL69o|T
z2FFahkK&}UsDvlTip^riq~M9gz7Xn*j%A}+MrtPjLdXomsV;i36;WB#cpFrj^$tl8
z1QyiD9XZk?D=dNBMOMm0pn5RcQCV^EgffmStSTz5T6n~MujP#W_lXmq6e7-$+4&_^
zv&$>6wS~C`SOZKbiHvk0WRV=Er(~$plG4(M<<gQMo-}HcT2G-_r6+mR$?K^WWh)U2
z4VEwjA{aSVQfZ{c9_mXu$()6z!H82~BjFYbIRC-cB}*1BY8bu$hi>i4g4SkiiCtC}
z)L}~6QE}Loc4U4kD$CC)T@DAorKQ|fT=DHe<?i8A$}if73X8FTl>7>cDypEGN-!oS
z8f)p+$%D8zWa{+7IjMmqBP9((n@M;}q>E?9+^Xd(hjF6aNAeoN5Zq6WI3QAJY_OD`
zQ71BKLK%a}oP`~x%tnx-0~g3E>w~R}7cW}W*c~dU3eq6vRnZtZ5L6U%Qzv$}T~-_h
z=w?wlx@FV;o6oh&%JNHe@E$+bxOCo^Hrto;mNv@rrpJ$-mRrVWg<m7*R$CcmoYJ!D
ziXu#j4&n`p362eL)LOE_bXA5vlN&k_Bo|T(PRL0no|&h>T}ltGbmJm-Iq;Jbvq*qX
zASY&)ItL~fKLoo)7r05v16W&7%>$K1ixzYzD>q-zPrZMze(S1RItDvXxgff7baiD-
zv(46AQ@L8{glX5HU4>OABs8U5k(XOoRz17ail`fOIYzB9U9VN?jVeC8DmhbaOi$OT
zC2h{aC1G7u8M-W$$t+DSTC69s0?9)3Z$LI^M@4QV7sMgwkqDqpB+7VslMzZBz6zRC
zOjBm=gRQd7;IE9zkv)6%?62GM&Ek)5hO!-%6&HzOT6UGqZ{Ag!zpHtE*{&8&96QSm
zqr9;B6oCf479=UOs#j4IMg#cTb$WF=t&>8&Y1LU2J|z9Y^I&DQ>FHX?7HB8>bj3Ai
zp%hY<MuW_tA_y4?V{H<qAUa}WU@d`2(rdjDQ;V3;{-V|9K5$Alq}(;?R=aZZ1@-*?
z(LHC5p4q+?P#SK2Q9CLtFY?IBxz%e=E-x=!esXQ~+?AYgMEvg;7FM?A<``)OB*-eH
z%0W?B$^Q*n!V)U%P_{&Cbk^!M>9h%w6H*~dN#%fQA|0mEr2vZ3$WCBp#`ofYaKoUJ
zn}>@gU@;0snN3xe*cL(5!QnxFQ+))_><3OQ_~^r56_t~F_ng>s;c)AQuWtoKvFL)#
znmb1P6n+U=Of*oI(G^P>m1d;8>?|D&wpK&J1GAE<re{U3&mePFYiYmDP#ese6wY8a
zaaS<0_+{ZHO<Ec)Wd>t5vl+F*T9c6@hLnV8VK(F$tp@6_B+JyQMPN)1ocfUMD3O(G
zr?=8c{!7QHqX(PMU%h&2`<d?>KmGpJzb5Y?KN~J}#`c{@T_b+t3le=eguDW#Ysh>;
zjEsqlSo9yQk@VQ0mk>ikKu6I-t<B6JGfc(a;!P+Fp-T!X^yP}gU}N*BJnJ|TJ_WBt
z5Qo&5jIaqrK!i9_o}~>&WqRPGY|*)M<gbLv(Gyps27UR^x~*$geSCXVzQ5evbl27{
zlVpj&XwWFcDl(0Qt_-?a@@-}*DeG{+_+Jcwh&_G-Ku8qR($iAmR*<C(`O1wsXc8eD
z5+l_xp$W(o;1q<PMOutxLy)x?8$F^!0&XT^p;{@8sfPPO<-PekNBl~t9BVlXCKp>z
zG%wq*Z1JrVW!hzBQ@86Zbcy&c81pQJl_hyximlL!>@(-Eq6iXOC`b+e(^L{%=zxe5
zDqM0#N=ACB@J^Zx9pqa!*&YFlSQd*g{TLO+f*>d2gGiyp(8!b#J-S2M#GjL{AQVWe
zz5nF=`Sa)P0F^UaZ#!#>NlcEhNJjge?tY&*aQ4dC))PmXH-El(_pMKm_fUSiU8v;r
z<<8XyDAiE%fNvtep#Q{H!2G%baYV$QYDj~0+OY{Ppi}sEiPDA3R;Qs$L^VWlPzQ>k
zC21yX<N75HGVn(!kC|jvk#xAgCFrrV#I>XeSaHcJ`O&LDW!~JmJw`>@OY7E)?Q-Tw
z^KrJ+WY))`eO=DBAGV{i<EYZ?ansGY&ZYUTnhiu*1zd%Y@K(enzqAC-$zsB=XsNO@
zwHqG<agDl2ZA@y-nskj`h4V(9q}*kJTf&~AC`9o(aXZ+ST>glSvpT9GWYk%-bKtAg
z#vHZS6k+l7x{SY`WM0+m?M^+El{4(6)qaJy`Q5bXsDSc8w^QueQ8~jT#vdQFQ%KJV
zj>wcNBqfcMwDQ3T=t+cS3MNJsTg&BZ)dpx4+>wOrQY9k*l(a@mcLH(%kwB~uJdlvI
zWpadCim;Fr8n7?&6r8wZLi{69AUgi*3HC{twQYD$Q8{xbP|lobT76qk?Ap@<O+9l4
z!$8PS*@ie2{ej(w7cpZnlm;G+DqW~qgn|HtDhLxjFuw#ZltlQiG-(LEf}y2vLxK}2
zc+d`m+KA?mksIlr(*l^$L^(}R!JSL`gpmdncBQG>It)~{_2|>yMnbxt-d(e{dr3K?
zyhqR8hijoOY?XpIEwjwnD5h&mzHqS-C=EFelQ5~K65UI>Y!JhXSt02)(}1gVBV^;;
zbIs5vAWVc$WkY;3$s)vy@Z2Vy*kZFu$Qa?A025I42Gw6rFzH!A<?Qx5&wcL<Eq?T<
zY1x|FJTC9iv-hFJI6H?*Fp5Hu3ppusHkctuumQ1#oZy_v5()M3I+^L|k}p$MWfBZZ
zMNmSlX2q~@=@RopR?^xdl~`m4gG2p?CkUAf78d+CkqQdL%K*v<DwJ?5L{@tEX>W76
zJv`lWR3!Gy$s^&#LU4c&qGOQuST03L<@BU1bY@^#Np*2Rcp%6)YVg8Ma(xs>5D=kd
zNt>0aoz!S?M9@o8Srn**;uhZx-)X?2fCtg75!BM|J0TORwhX=NP{Ak=WMxw)rc;!;
zPX)|4E~Q_XPcB`xIs@G*A}|69b_K>Cb}mDM?C8z8hAav|v>DU*MbaQGDPSQ=f<79u
z1Qn?&>LLAwnZQ011nZeAE>s0iOu6qkQxnU!4B3DE-1h&5l}6+}diFlp2SwW@?KRLX
zOgnZyQ-Q?ek^~_n8a3W0ok&G1NT{<=B1sNaD3BqKlBv1S#!lo=aCjnO7YwhE+58ul
z+n~#4_K}HsoJ=7%isK>VBe8`1<_xGXi?vixIlsM2yxm<q{%f3*_vqRCkjKb3j7K2$
zG&2*7sR^u#KnN#F!)c;7=vjDeYzeU~=^}9)UpwVx1y4Gb;k_|JNSzc`VGI-sTL=m%
zhsktS7#NWatSxa15(7_#K<P8?I}RwN^@Hy|RERp{OC=iT>!zunC>JARzzGXD^s1;b
zC8Q?}LU!nVlIRwokO)d$z)7UTgbypgC_^}0qy*bS`xgN({p^w@W3`BBwdf9f41fqZ
zqf5W{IMeTnHiOEA?PqVz=6>xn+sS`=_C6%Ubha_)(nK^%n@K)X8F0lI6+OYLN=<Yt
zd<f5yxnr7S?5s-7<M>}fdI{e!Mpo>QV1k%nYo+mknlmW@Ni?bjLkARO5M&7kpvH5t
z1_9cXdhanBSp}6gJ}t!0Z#?X%^yE#Lf6J%TBIi=)f*C2uHsO4jp-bV1b~vt$PC@(z
ze7?9JX&r=wVjUK!B~ZvQFh86oQbfa~^l1?5kQJgfFfZ`5d7_&rmy#5cV4`<Q6f8xP
z_<N7h(_6TC(EhfIJO3MGWhePx&)x@_ATXmSA(j%~np-4kKFJ_SZDuOf4k8nQ1@aox
zqS9ekn9&Pc3kC&-yj)`*?QoRWg?=POmLQI_NUE$5H@IQUOO8&HjkpPUhX4|*2v8`f
zpd!68g36_x=eh={zuxfzW!V4TPIf%#+52QsS<htZt+c9fJ+eRzb|Fhe_ce@DCar>*
zDd-M9h*_x=MY5!6nKoRec@V8xj8JZny+k|)v(j2i3@d>$Vj?-TWQ^p6EHZ)qi2sqO
zj%HM8X*OsD6=2ysP*6E@y5T)Whb?JX+Hu(J!P55*b$kA%lMAGy(lKFCLFLR%Pw4h8
zRzjo2nu^IqD-anWg+zUj4Cp0F?ig4uDnk$<%*~YGl!Bo`un__>2Z(4kSD_KmD1-sq
zLODcm#`_`{$RZr3xE&y(sD@w0B4c}J{^c06X7V?^yT9$SpmGBaH{QGXv#)%w;pS7_
z-(TQBL>}FF<+8j_4+flx-o%0;I3UWy;$VS5OQJ(bEHg!;&PYusP?4IJu(wzTL|-y$
zG=n~U3&dtYuJCW!X6npx*-BfOTs|QQ{TQf<oC8QakI+-#LNp|3Wla}U@@<03m0b>0
z4k0ZoYfm2%xmn5QM}Qi@Yh}9>aUbyHS;~W8vy}UeXK}Dpd1<E@fr|Y<Pv1qaJMYtj
zfmxxc$v~quB$0S%GB;>9ipd%}o9NL<%E(G*(G{8hPoRc@AqJ5kmC2f7O|t3KA)wc@
zyafGA7Q#NBg_FmENNh~agm6zhkT@iz^e%a{$dq0;`7g(0(rVoRmIvQ;R?(oPr<XRI
zUV7;CdktLQ(%RFf-#dM1DUURqUMU!H|B!&zuym=w)BtdY1Qq+U1Rj34wLe!5MOH8^
zip1=KXX1T&FbL-<aFL!USuK&42tCXs$k0HlN=wEULtqQ3&59$$|0tYREhP`=YB*S=
z1^X&prL0yXa}tUCNT~5r(rQU&06C*fKoduV-;!vLNoi&wg=hSwh3RHiJ1VDJcP^z$
zQ(IemaH$+R{)@~gkI18~?MJom9c-;#$-SkmwY5Cg{w%qbzoFbZ9Pk3#v;`HptDwRp
z*E<isLx_(ozH9lg;vs-Z2oPBf0fEUN7lOr>uoimJ3}6z;NM#Iz!DDzH5=?SLiFx2q
z5D?+$Ab1r_^gzoqiIRzEsnZkxW5P6AgN7OO)BoHe(}-%{VcUUSc2sIt9$Z>m+YX6>
z4c8!u+<?kX%32C|wL4eZ;p=?XO6BEUu3Ws39Tnym@jg8mDxD<@e+%IVm%tBplpFBD
zd$N)USg11%QV5dfCZ2$afQ*KZ112RILP5xVh<J$pgm$1_FSukGR2kCQfrx3yoOr1v
z7gK{nQpnG&R0@$({*0{HQMtCuF8wIY(v?_+b`3hDc$x-oMV%OS4HCOjyApjlR9mZ<
z5-}vAJ^ZXh+Y~)go-a4;UTD`3*W`VAFtE1F<iM0LvmNJy8I@Y0SVMtC3d;OaAv7W-
zP>aZcP)^uh9>|1*5{dz*E;Nh~vOGjx1h<vJ0*xB}w2+#}idr$YI4>hJ#c6eyIA|KO
z!W_-o{%jsa`BU^j6hKtvAjj`XowHVcp(*l+44x!M@?1rJmL3!#ay&~p!$ZoSP@aCn
zO~bY8@;*HnYWh<MVI>&H4{-@{-87eAT?yr2ZIKT8G`I++G;o8T1r=#a5WSLmD=#37
zg_)wjBhzH;{EIXzb4XEu(=4w5>=5FJA2A}PoQV<|&CEZy$W*g-R2-jnX{~Z#*BJY`
zuE#yNrrSNG=cr^P$0swX1Dj~j;$aX0J}xagVn09xJHfY)JEm)rDj_Ry5V+B=Eutbl
z?8?PTNCH^YVAbHq_0qf`6*a*pjYd?NPa_@-9hKlEi@UrwEeX5Aq=y?(IoKf-4&jhX
z{BK7kDJd}}HBFVKLdf~n2~9u+AwUYSF+d`R0*<7;a3q8z@_<TZ(4jzN(Nb*|icPOm
zX^gTgqb#A2nTA!t0f9%V3XI?$uuzJn1~8crkdc~}I7v{+v7>UNLAoS<)3NIa8q~A*
zNli{p&q&TpWv)wxitm>z5laCQtl5P3kZ&BF(b8uu5j(Lu4$25r$N`NUN_`&9k??~H
zS7*p;1qXsZ<bjzpnNmTb-!LPC8COzdqMo0wr9mh)W#XS(h>CM+`|ZUZ9&Pxo$I)xD
z5mArcCt+st%#<{2DwF4+?}@{yydy4r=d#!poB@3VxLgPr$&vBegr=wmh+!<4R;J5<
z*#$SLxQa<aVn`~1Sb}4E|CvXVsYy*w;8wD3oq^|z>M^%w;(s|%Y53s>KCm*2`?tJt
z?9SAKw@65skwWDdQ71S<^cBOZqTx&2iQV{89Ltg}75F255!IS7LXz)EFEUR;ldve_
zRtWTHy3Asc7MAo$OIK$~i+f6PT1E;@-TXz~fDSWmQK7Wdw8{U~!ek<3rD^vC$0rsi
zdKZl3)YO@2X~`LUz4VM`WTqyi;YR>SaY9*`53)KMa9|yUR}xexh#)dzIZ-CUUg8na
zF^N(*fRZ7ABiT-;PLj@Kh(sn`rO?M9sT9dKYL-a_KaKNKkrf4%gF82_U3E7NzQyFU
z#CVzLqUe8mS{k2Q0#yE^OI)djwrXf3SXgNdle(zjK>~#dCPd3jPtJt5<EpcWk_pZ*
zx6I#6Po?9Mj&77FU7f~aP#OFs(NAftLr{`ZL{=y==G4C3a;T|c=iM}tQW7(h)8mt6
z)&dP*1TX2hT)ZovA9UoFf;t7`EU9!sutCZSYXmP%G=|@yy%K%Mq$1A+V>4)2hVQ23
zpV=YlX_?8W5Wv7k@L$A5;yhJ)Qfhos@_5Cr<kr4@;<#*De;17;gd;62F-e`8gri6i
z*NOr_F)0*_S{NfOa}y}elO<b-HYiyL3rjf0!cHps+r;I9MJif{eL@NO8~o7R4m_zz
zDa>0`L?$@}Lqpt)b>TfzlM@mqh+Pp`kxb>T8p%m`=A?A_VpI8=aSeQGd#f>yT1b99
zGjN%@fu9y48X4gq&W0RV>haR;Lu+zsI!cEm!0TqDVQaD5+BE)b0>(BzH9a|r2mnv6
z6Op0QBV{K4XU2)F<RL3|!t5@vvh5!sEh#lKJxw}`F^PzLItD;RfG@Ee;*KHE8K|vG
zp+i=s5%!+mQCI_*JG?dZc_F=-y($@ifP%A8skroXrp@4&L7ka-OhiME&>+N6BrzFD
ziBCj>WUZRJ5S3I=k%jhUemfGMl8&_`V$ra029+Ohp{asOU=Gtz$$5owmDmn)MJX!d
zp=6l=b*5hUf1H@SN{91FO;1WrVZhHM5t(3glT!$1F}n00XQ+}>6XN3&kQMTvyt=zj
zR+5$J$}|D;?ecjgSfyM@0G~;d3gHM>O+gv4APb_^f}{XyO~QX+c;Op)CPYLkqM?%&
z6$D67PKVgU&L+htB_yULCa0vOq%)B-g*!Zh`DjTADM<-}3X|@wcOfcV37=PH6Cx)N
z*T}yPl96bY@D-Cvv?i+xN&!?DJJ=Mng}R#b89+C1M#^jyqLDB>4h@zPwWeke(qdhi
zX_b_e%A}E$q~v5}(jqPnTg!~jl*E|{V?l*+7ow8F)u@=Mj5|q@Rs&3;5Rm8zwvm!4
z%{ufQNOz=`Y0D5xq(V|r0~R}(%j&L}A1H4Xm(M@qvkcK4G=@|sJwf6)+<!_+LQ*nm
zVLAaoQc7}Cd_rPU%snmnjJmh(I%}Imc8j+pM!}J$$y9%`8HI=<RHMoc?I?Ua#YG$t
z{l(G?D3g*Q^kE<IQgDv6wrA?KyjrDBB{~s2(93Bv5|ZMXKtp_s=TA(DPoViSHBFa}
z)62+6K!e6AsMt3343*`|22kx@;urlM+NbHqUyqYfNjS^m5TtYj6PfVZN~Meie&KT|
zfZ}<ijf<KW4#-BhFEi?J&RA7QIuJ$9q)`FIKwc1%Bqb?KM12y|FuKXfiK(f~<xFOV
z5w-`%M1+@=7#~03o)(tw$nPO4B}3cVn)>|s)%57m<$adl2^C0qY%HNYv4`Z!TG(e4
z1=C6hixnYclfoCB)=CvkoDVGva8MGwOWQ^|-UkhW*_9bYxEE|H2qd9N_@AVih)I&9
zh=l&h;+$BagB&O+F=6J6*n5u2LVKHgCM#2>*iliC8CufTR)X-fwTTE#X&TBeP;;DX
zQ-onkpXF^`j_glYaBI2~D)a&3OCg(tnN_REk7emIR7To-l&K2@`Lq(#IfwU=)%28R
zF`g@Pe4wkf%+JhJGd+e=*iw9ON<wOKVoGL8a$@2PE<Zjoi4zD&IuT2HN^&}jWhKl^
zOo*Q`7F2+xho}e;f{6T-^eJgu&V9};7x8HlNQO>nKiAero_ynt<LNy^g^9&P8EAoc
zT{vf%>@JlMX4ZlM6*MUWS`4{NZbxQ>K>#j`=$$0NQluuS#L}kVS-5gWLULkqVnRwr
zGM7GcCRR2PNH8|?IJt5%=_Im}l$aPl?jEVW7xoYp`Q{y{H1(OnRWnKe!j1}emW!|`
z=bHL(ynHB6>O68hq&(%0vI5y*=jI{kxp2zjQvIZ4qXe#muqaYau8IC9#XG}M(u4s;
z3nI8;nH2&vO9-f>KU$`2q9_Tnrb1G3VtjH6g2FAKB18+ql9-ku0dIOLk0-_>E3$HB
z&rlIS+EMAVTu>P*y3-XEo?$=7bNe(+DFL(2BgaEMLq!@!g}~Ni!SG{H=)#sBK`ML{
ziqa7brvAwOQWoR`j#6>jk_!mWDCRSh`FA+vbh2%TB)Eh0<QatdNeQGrsqxbj6Q@s0
z#NQxFL~?{JqGV!a5(!wM?5NcD$gYU7b)W(y@*g{Mv#hkA8_E;<i16^=apZWYr>F>@
zhVF<R0Rmc82wU}PP+|2VT9H9TI$NZ`L4qjLHKY$&SO*Z0IF&#azk@;H%GG$~w3(Qc
zq=fVYqLldf)T9}SBt0lmGUS$6Ua`W735khGGh^;K#&YAuJwrtl$bky@I8f=76|pOJ
zq&TO5g%}O(awMqmP|r}oLI`h-77?F7D~a*I@#tisA%mKEaWtGr3`>Zshm)1!nY3vW
zxJ!ObqNjm=NJ~j2azl4gm9-QkW=T$-fkDL`B@nI=wk4+V1f+(?$Q2W2B=9IcsHdpd
zgB6KbmMca<G>AK$vcePOlI`b|N0$qRokxy`cn(ixG%5Jp=0><S79<4}XnF!xGGyu8
zV$P|oF@r_H$`JXp?UF2l3_Ow=!!EJLAdCTOBuhSFMKiIn$q9)<NTiS-i$tWQ64YX3
zcqBCy6cUMYQ_{$ckfFqcgy}P}wt~u*9%v9>yM0Vq-ra>LMyI<6e&#u;Y{^6gsa_GD
zU{)w{SeW=j^^i_{YGSN>Ad|mPGrGd){=)kZ4rel-iU38Go<ht*E}W4<5}1^fAyi6Y
zS}Ni|nw%JqxWwBv2F%0+14=@2Lj25xnF&Pv$5@8F<Ss-7S^$3{4Jp_QLJ?^*K$Y;x
z(2%q}<zjDPnuy!rMx;)Up=E_m;pv5<r5b>3NyD~KD?ov;F$rR2QW9pSq$W(8JR@P+
zbjcBkSl|w3CZ;APCeNHPGhWmyKITuy*ej;=E<}azpGa0J%S;o*tkCl*yPQZd3=0Bd
zptK4~aajZfV*(6x9Y`3PA$+w8N)``9z{2_?+GHxI8N?~^2nNEEhVr0F2{V%7rzU1h
zn;D;$IAdb`%;d@O)27dyHYK*_sQgS#__;5G%ctx|iJdGM4}{2IWzE9kBRjM{+L;25
zao$F0Xc0P1NV_zm+RRK+WU2fB5iv_jJl>dW2*Z(>oHSE{6tY6@0F%Igd`yd<K4aRX
z$rENwpFU$s)Sr&gnq9i(&ATpVW)iwYtGH(r21SyYDzYvfdPB1byc>2{qI=*G|1Fc?
zNr+Jyf;Vc(!X3cNa2M7safYCfoH7#wn-o6-RT8s;nVp$5Jw9<-JoMX)8IzLZ<EKuK
zpFCyev@!pex%ZB;>pt#0O#<ld*Dv3k-+lS@>x4*vpa^CVAkY9h=bUry20(y86zQ?Y
z6Lx3M?w(!kj%7>Zv8^mwiIOODJhsQy;2e7_$r5SNVKn0)kyP-|KKlpv^Lt3$U^wii
z&!8`X?$_Z$>gxJced}A_s;i<{N5_B9j$*RK{}})+IYvmAeo1fwSVg=logi9Z6gNV<
zQ6e9SDo7KaeNwEZ5r)7wo_v<B58_kE0!|8W74{7`A<jO2;o^mhmo8qoaPcCP)A`Hm
zPh4KT_{8~@l?#{FSC;0NXIEC%*T%4l@RfUZoUh;t0;CB+m(Y`nRD&59CPm&R1f>L8
zMq$K&H<w_m;bI}(O4~J_VlT^69}<<{lR$fsb-*PTg}3m*WpF>vagi4U*NabFSigAT
z{ObC7{AGS+ab<aFd38z^Gavu&pB(+vn>UAMcf>1fKzuDV1z8qBfWbEiE~1r%3qe+w
zjtvQiJ}Jen;HjZ^@f8Z5%O85~si*%LWex}h4<YZ8axVzr0(>i_U+i-6^5u&cS1w&#
zf8xT0$CuYdlwFx$UYK84T*g<}@wgMMf({PC<ll&715QI#0bnChlW0og3<BOkNYMuS
zc_?}sMwgy?f^}dJZ14o@m!Ep(iKn2Hp8DV=P|D*^tUp1)Eb8GWIXLSV)-PQ=59PLg
z{sN|0Kfg{uSzTFLSy^41U0PaPT)`?lkLs7db@z^oD<Z@)SoyDiq14tBndZ3<3N=Nk
zi;mU_`2~G2a0v}jeteD#H7{;aDhNSqk6*fY`5A)jh0CNJyy61xf+a3qdSd1LdEQ+R
zq2=QFwbixt^_9gX;_QXx<;9iNrG=H1api{}`3Q4|cVBtO>piF{-tAkiyxSMw<!huM
zSnGfJFA#NcT15L#(2ip73R)cEh!A7&Y@FwwCX(P2l*U-)>BpZ0(uy6gPeQf{+5lK~
ziTY;k(uMVPQR47-b!817A(pJ2zp#4#{OaoZV#!a|Ru-36mKPW1=ZBRa@|4JrV3l{6
zW_aVuE%WJH{cyYYBijMeLop$$W{U=3<Qe!{p4=@G&ok7>#F>97^g9&D93WBWkZqoM
zs#FC-3{WbA-2ti>DU5}aJWgOef1W=p1d;XS)n)u+b!C}1OKYo(^NWjfD=TYrGfVTc
zv%)G|!YY6Bw$~e1u5AwA?z`>YPx?WB3}FqAAPhmnkj=h~Fc4P+7fanE6e$E)!7kA?
zhlzgT5}_8%Dr#ZT<{`v#PB6$ie=n>*v3~yi`E`6`eSK|tbrBDl=jdRWmDT0>h1t2~
z6-=`*H#^g-{OF^<`m4YC?RT-tKfb@~$~JFD6)AMb%pLs8e+3^6M5E>teJ<k6hgh`&
zEA<rThfi^wKqn=0JVCG(MC21sVF_}}`ST>3OP4Xm3IT+7;?3H+@DF0i{IW>HTnk)F
zbL-2qGs~+p^NVu>ScU65?_!mIcz@TGZQd@HIv_Mh@hL_V#5yNxVJc!#-Vj6tPmQmD
zQD}K#74RFMc?M>d5?Nr8OBbL@M3lu@uns6?eQ{y+;>ESa)e9>)g>Z`%;U*xIr5TJg
zH$Oi=H$62wyRa~%{OI3t{ppdnJ3->fb#GjGpXg<~_fs8H0*O+nH1bcKhrC2|MIi`?
zB?7jhaf4WbNr72Hp@dKtHvy&z8uHTR^~W#3TJr|?5IOk#+PtvA8h;m8mzEco7C<IA
z%$#r(PSD!?{KDMy<ow*?Lcj8(U*mdPtGxFAm8^1OHRRjAICku9KYjC)S8l$1>#LWK
zaXt6e&+{2@3XVdD^cQ~-l^-}BorX~4zz^Uu!URt}2aSf9fbx%^0>em$OEgF?twXcH
zGvXlx6O3|k{lfY6wUxECwPozGdVZCNvc8OY7UyS09GRb=o>^F4BFN0lOwG+K%#A9q
z{(G*sv&yUg@DC-cyz3bAH-?A5@vh(S_gCKS%P$>!>F-}U_O}0mknV%<S>=YR80JyX
zNmMqt3hsd{7W(z6pNEqF;B!I>NmO}4Fl|pf@eHt@!tdha#9E>%AZ?96vbMamxNu>1
z>HNjzg|(%*#id1Yisoh)@RZrv#mO1rF&JoC{FxqB#IBxS|L$8)(2w|im8^1ox$4`#
zfA*svefDj?aO0C#ZoGP%7vDSfy`TMT_@i(0m7l>LK)`|e!75^QMZAR?cv{H0;2-JV
zaD;@kjlKnJBw?0MP#%lZL|8cwIsv1dhbdUcEbFVwt1A~~7go*_MV1!$yR<|Y;mpj=
zEzZv`E=<lY&&^EEOwUeXl_BNT-{g9$RemVeL6ofWu6rSlefPV^zWc7<apm2<DsFy<
zf1ot#^ei~;7oMSq{w&Fd)QoEFLr-54{z6DW<zMRiaehe7oF3Z709p<YWWnm%>ZSDy
ztGvS`>nj*&d3k<?pMPa-afzt1xV$hmzpykpIWsdexwJ4ny@Y|LrZCIw{Oo}8>c?3E
z_Ptwu<?l-42_>t%+tkXh4FCAY!@u%w-|^!s@AlO{6>)`s<83Y^vWx*T!wrFp;tya#
zCm2x|GK*)B`arXx<RYku;z#WMeHzjpbh5U(ei>yO7#7NaFmmB>sK~X81lDWEX<=@D
z5oo_SKQlWsyEHp9En<m?E~7JZi*qwG)05*PL&|HP;Cks6t6Y1wW63Hd`@F-Op^v=&
z`bUP|;fq&4edXQ0`t4)ie*N_iz3o3Bdh235g%%>(6|6xki*QTd6UZXOj_5%NyaZqv
z0-}nj3OO_DR5vu%&#x|%c_{oa&ML*u`qC1f13X#AC*~GcmgW|4k~z-L^wiAk{LJFQ
z9PfpNFw5wO^4cf4UOK!vGym<?t7MgT8F%=$_*EY}_U(81me;Pl+ZVCQYp;Fv*xP-J
zASM4fi?D?>kWecMKoM3L#3a(<974n)_{gUp$0VFA>OlC$b$sK}1>!B`4R8(CWSzGV
zkE?SSWRajEQZhgdn}AG&9dMDUsoA-bRVFdY_}KWE@|viYH(TYeuU{pry!y`9GehEQ
zL(jbPcf9)Qm3RB%w~l@5)mN|nE4O}|FbeZybc;)wN9Y|P+kmrzNfBdkC5^ve?Xe7b
znUaTd1Ft4XSeyhO!5$X~vt;1K^`&`Y?mTICwS-h=fhn_7bF;Iv)4ZIRnwgxOn40G8
z?AZ9|7*=6r>1M0^_a9upN>=&NJ73417hik+*gJp6kA8IJ-M;uIC0~2n?_ec3Is;%m
z4sn&4Mm->=W1vvj2Y|K(@*2tsKuhxvR{_PIC$wCqf3dbo3c3hgvMN#!kyWJOrS+AC
z`8h!B!qO}$d1{_?Gcz?kJwue`<V+A^X8Cw(Y;<B&dF?Zw`Shn>-f)8c+h5+eN>&kD
zc;Cl$Wt;a>CkwUyFA7Pv=%EvBKlIFH6vHCIpnbwyXt84>GLv9tFI|K;c~TH2a7b&2
zP&hh*wWspKA_NmE9asYXt}f4VhGyobIW3dp6H~J@6LV8jC105$C-JEf<@L{f_OqY;
zvkg|k6dSHLuKeBmyS95jEsf_;a6R)Rnl>J70>DQ(4Z<bLVhG?1q9$Mp2j-~{Uc3y2
zLe5!RJHHBVLS)4zYip}8ju>PbI}l!HSC+x}D|0Jz^CHts&vIxcgfVcGsi}#v(W&9d
z$*JM-$;q){<@L{VegBpmbki(vT)7r`xBG6p_X{r}?}|&T#^x1&NkXL>@hOTT!myxg
zX?$^JR!PQGJr~bkxO^V2evNzsMX-RE5KG800<lr-0NDWaM3dRsxtXcSaSqVr_~h*P
z#Q6Bw@YvY+#MmU};RL<@TffD#8;-nV5qIULg|_u-yZ4JZOIQMAr2@PO%nv}}FUnhJ
zTCBoBBKLgo2@1eV5Gb$&SO@NPNf-pejes)8p;?}vo}9xbv-4nk((nwd(v$$O93T;5
z`8!E`ofsb)#BoOFI8s>U$6x#cPd_>Gjs)fH`T~qT904#EEgypotcwteos#Pa{StW@
z<c7Q&kWU^ikx7JG;D}%wiLuK|0?p1Y&H~sLre>Cwre+qW=kb&2>50+Nsp*Na@$ret
z@$q4-Fg7~Mhkaw?Bg0eUxXiG^(@%I(&XITI3$ARpC3@|?A8hk}`aeVyie&m;6hC74
zK!`*^Z35O}trE-?*=L1*&e}Y|RnSR-Ub-L{13@NX58&D?m}F)KtISQnvrThGh$ny&
zTw`){bYyH|bYx_Nu);AK9UdL#^@wuysY-Y6IIFOHhvpZN1#6IY#JmTgmeDd1Z3U=h
zu97l{4*JFOPY_zL22~HW@$%|<NZFP3b%>><#U+Bu%;d!E-2CL+9OsDBGePE=oEGMo
z7#qd}!-IpPm}YEpczkNOw|{7ObWHj2SDt_V`M=nCR$+k?l3Naom<U7w2&RR*$4Nw=
z6pcTfQqdDdn}UA`i3MHJ<@3}yfDt-?Py{##<QiaPZi=_S*tv<xY5ZZFcse;aK8<fo
zj0}wqVVSW}J|`Szc({M4dvIL&$yd4l;^>a^m0yB9V3wT*2hAU$F%UxvA_?(Fj8f4U
zeDdi_G|w+zSbhBb%Hz-|D{CB`wWXD10t!i(m_ibsBK1y8PEi|^U_{Cpo*W$-n;01z
z9~vDU92y-N9-bH)8XOrO>gOQwc4(w;LcRJV;+<y|8epsmq|fmSO!^a2SmPv~L-s7(
z5+X@4q#)RQ_%^UTMe&7oae`I_U$U^U0)s@Yv&;wc_y^I0z$)@Er)OehbZ~HDVsLnP
zXlP&rdkhWr_xBAB4-NJY4`HIdk&%HhRXmCKg}>T)R$-Tl=mb6c4E<)rT~O9|3R#F^
zNXXrUUicyd8puvAUR<XVe4Mg)?E*Cq;Ek^6;w&d<3`90PE6SX)5wZ;F7vMTHHqeiw
z;1)xJgZ+bp1A_yYW@Kz=h$u5UG&nIhHm3emJP>u0RYs1zyx}};AqQQZSP*(!@(%Ax
za>*^^piTD+t1!C3_#kKv5}#EPU|cXhftONI@b;^8N!Q>D7B8#`Taba4$jmGA)WUOf
zM3bpWvh4WO%=pyo#DvJg;{Y^p$>7Mu7}13Hn52J@Gc!6gIx#pjhIIx9Mteu6)Ste{
z^<VF~VTTuwy|_KAT$@<<un;F-6|R?*sPEY-x7^R%HTFQfgKkI6q~jmRL!Y^fL?3oV
z^uJ0XoHaOu6<QecBG>}*=U0~@V&O_=0BEyQlhZ>aoXI)h2#1GYIx+&OG&(*yI5JRj
z6W$DPd^kUSA}J3J_VH(0{po+;+F+G8-gtR?RuNL%SFVDSl3cl@zJ2q}_iUA0?iVA=
zWE>jG92#^fP%Nm<#VjJh7D43Gm$A(H+WEBw`a49F`4!{@OKS@&P$vs><0N3gHj;D3
zrpG6QMMlTQ2S$J<qav6L4-!85dI$OkdwcqZ#z#gw2Kt5u2KxJZdiuHs=GCA6N3I{-
z^p$@Ks|dNV5Y-AJZO1C&e!4&8Vrt{(p1lN6c^18+XmwBsp+<pQ64J+YK^D+47jR89
z&Vl#yFpsn{X0XHL)acCA$oM3$IXj?wqAvb0HipLt7wPZg-B5RTzX&iL{XOI#o&np}
z)p~MH``Pbu{on&PPS8JrRj!JZQ7dDV?O3IBKaZ_In?j2NF#?nuh2X`fpF?B~`y_&_
z5MID2(LaZGT$rQ$6XX&Ac6LT|Fi6IeBLvq;5DKQ??>I#cJ_Dc^wi)j0C!`GY4Gi@3
z4-WPB_4f|+3RfBG>ppX|W>)*z@BjYq{oa53C$$PQGNp^~vMsBW?ia_0Do{YVXBYwl
zp{zf}E5TDjR*FU`RSygStsdUOQ7=OgtU@uutx@t#PJvuOC!>?3AE25*vL!dcB%GhY
zJ|am^duM-NS04bSueYynxU;Ljx3}ZL{f>&S{3ovee(yh_uUt3Eo2Brw^%HdUexfR=
z`00NJ*~F8Wp9H(n>fro{A<8E}vUti0UGzm!2ny1E5>>(MJdgysgeW^EQqJr+CK(+A
zu?@nT5IqPfL-<G^=me___I6>9{sCZq_dxG(Yg<dh{YNsEsV-_i`vb0jLaV%T^@sZK
z3#C-FbzixD|7CoIfelgYJj3dX(xd{l;Zum%==VUmk&c&el6gcIf}f_;As^4pPft&A
zSSH57Dv$)@0M;>54xxndn0JHyoSS};ayT&qeSQ5sy?sNy{p|xigT3u1_j!_~>+v=H
z@Bi=*zxmC-zUeD3mZ;R5h~+)wm1`3VE5Mb~0L0aKyZ0VfZn+<liPJ*f5vqe{+5hn@
zGW-vI@NpE7=htDBs07bb?aVH((Y=@vsRtg3qL{!jImx+!Cjrim4NOd7lL=vr;r`)a
zBFV@A!M2YWGSJ`K(bv=0*WKRT-O=0M-*MvpoNhR}tt{(*|DU=3`q+jOwE5+Gw#wC5
z@|L$-I6<54g^K(j!Gt3tw&#dZ6{r+eI|z7Bw`XCw)H;S?TbZTZHNPs_UDFfOb2FTr
z!NC&3hprzQpwJl`8R;7Ulk^XD@s2>tN0_N^ptrNNv!`#Mr>Co<tNHXpckRpQuC1Ha
zn(_B6SiJH#_iZ-ChL3KSRWJwD&$FZ))UpT-n5ktH;nMjva0*1qvS1775DVTBkC|Q;
zbP}g$c80_=I)Z!5luphFAa<zqSD-fV$l&NecW3|bC=q1<H)-zZ>F@9CXl^{ZzfjC3
zgi$=}yzxK&i0g0f-(ZK$FK?Gs1eZc52-qeRUDSk^gjql;bV=8zAE#RibX#1So12`c
zJ4$hkS+Iv-9A_t|!1W_gu|vbdFl!(-5Q*@P-mcye07_Ta&|pVrcUMPyS8HciXM4+|
zk33TAI<8|9Rdm;S%KRUH{KtR%M}PakW>akV=yq8JLZ2jzMV?_0`w|Vp$3KX$`qKG@
zrN`;_JbnRL>=GGho+6NLDA|WNGP5v3=`)I9rXd?A#|MY7%P1#@1JldF=^5zn?(6UF
z>FDa~?da<1YHROkZR_l8J$L+}eHquWRo$>0OBYu8FI<23;5*Z^*IQ=)li!Q!W1Qpi
zWk#<>M0x7MlcGq5l%*L)dqXe=Xf77fn@|SMFM{wVXJ*Hy2qM%oBq3f62y+YxtR~FT
z)6>tf>Fw|7>%~oayZgJ_JDSh7_Vl(l-M24gS(fVBmSfnS_N4X3x4!i!fAV(^ZSaoG
zFK?Hxphm$-7+OJMeu*%9`Elm>MbmU`b&2j51`$--{Ot6E=mL&U&%vWW6~L;2VaLZ|
zkVG^Y=qn-E-p;PR!JfgM?%uxc*7mlJ?yk<BriSL`uEqx+ZE87we_hfrCBq8KrfJxg
z@wD~Ex4C}!@McqN_~>?7MF?g^`<M$Vh4+Z8849G8EJ`1GfJEBa`6Urx=cdLduns_0
zAhr@OO|8Q<0+tsiM=(o+Jzc%s-I%4LtG&CkyQjUOp{?ay<AcW@{=ofveOJdCj-hI%
zW|-PD_8Z^f`q3jB?6CRe?XwE1d**sD3Qc6hkmMdQ6?lmv5cWj0hv|wgPfj7u5&kkQ
z3S;2wFsFwg3#<pn0^$3+yTK$w1lsn__O`CBuI|pxp3cthw$rE2H8(XLKU|fr$vB2=
zy1JDxG*h)q?Vs6i{3+Luj&C-_hL3KSRZ26)NJP1q7-V9F5*gC^;)PY}9e5?+J?IUH
zGCsornwW-bn}9A5<=-$E1^S4J7?S|$Me6D4;rMiPc6If1w|91Qb#%6#IeoVA<f9K3
z6Hd0u(Nq(AsEVtaj%|O?{)g{<@4Mf9_0bJ>*!=Q#S%qjKhI!cXKt2}K0r*W!^3dv;
zou5WlFh!$>jwpQ6G%N}Y9%|$%%t9rIrwk7C4G#=J$@cd40qT2uNW^_z9o?O6q+`6M
zz4>h8xkv7*E4Y^JB~05iOx?CL)3O~;|9R&hUVizdmtH-w*%TW-x?NTgLrw_rOUDQG
zz2FW?YETZ)!u-_y3;_ieWoB}EVnp;arU)q%$hgWVr1U7131v<{aiymh!wmNJ;vSvd
zogM9M0F=(Q=H`ym4JYrZ&e~CfV<T&p<r=zb7>;FVM#(BKzx>+Cn|2tX5W4x%8{4o-
zX?}YfyzN!QfAz*!#2hw2h3T)0m(dV2slwa!)rD!~N(<vime3RkDFH1}1O`)dLLnbV
zCr1Qi<ID)Yq-T&E+}qdQ(bLn})!NqG-qq3C-rmvDgr~GNojdd3!IYx}G>61PR55s)
zu@atR8qYfa@Mm1FJ$AzmAN$xFZ;U*5<HK!OWn~2tPHYv~8gF~83c7aVD@b@QUV56H
z26T^MQ)q-ePF0AX08wZkQw`DxENLt-3NW9(s7OIW1EMbG=uj1l`md)KRMG=(>*^vS
zx3{&ncD6S)wzs#mo_*xlU1?L6O)H_QwrQG{rfJbw%yM<C!n2gW|N2d<2zz{N<b7BL
zChZ!3D>ksa_nLV_ZODzUAoF787$%Z%!oWJp6c8K?<Qh$lc?dT`ExZ8?)5KNz$p}4B
z63{TnZK$t*82+S7gcOmEJG-d=Iy;H79WBkREv=2`$j)ue_Z_ZFTDoRvHc`d3ZC#2P
zilrKw`XTopzyHcBue^ThrWttk-23sB6Ia(LY=gJGZkHFZ>MO|4MP<mi7Yvi2^XUnK
z-JoZY>X3vMk;qO%sEFe;HV*TKrwl=$fZGOp2Y5%I<skL+;wSCh1lX3A=Jr;YrKZ;A
z=C-!Bu7(d34aGDhMb|A&b#x-FYf7%EDEd?GKVp<ytg?yZ-)dYbZCrVUl^a{<ZLeD8
z+Kq_t0sJg95K04557Td=w}Cct4t?nCA_9YDI>~TMB`S7ojJP7s&mac}F180y%jxOr
zpxVJlI6bXxtu4(Rt>+p$Tbg-!>b`xR8rKZnvTRGSL=MstdOWJDrh3W!$3N%#@#&4e
za*WV&<JzKC#1e@cCuobj?R8%f{iHYP20rol3Zr0aP_w1cKxn2lRQMFigxZC9xD+Ap
zo0_EKH-evVcm}(vjR#=r@sd8SuI`Sm?vk?*WO0v{c1}-ITMO@74kc|hqN*Av$TU<_
zH#9x2nu;!Ix{R;9#VVVOvejsNl~KFKQi?4c+hLsq;d}mZmgcOj&@EkCT7XQsZ~;DY
z8IEawnbC~-<>~o(A<h|}SVUwnGTbx9!5JEy9PI0+u~RZiXJ_Blx|oC0(ZsO<qJZ%`
z+M3RsJl#;E$22VldJD^vu9KUksIEzhCCQfY>|3nz@@AuK)hgomEqrA=ylu%>uHAS7
z=!R>oqWXhjLJuk?;g%6HEi5taG`+BbP`1?9fQ1|)C!^94>?}=Ek&{Wx{XN|Rp>%b0
z;3XZM?alZ|V{2neOGo?JM;|?PYM&Wb^@xlmWL4F5DH4mT1Q~~X6#Ah1kAK1S<D1d;
zxe{;t;&xBab*sDrd0Sf8vQ=NXb|Z87g2qP=DJ0g24baTO<d+8HV3?+9CC|gCOivPO
z;ZMe<hDYF2Fv!^OK<^+dN>6uJXB*WZNvM^?)7I9~Dr|DDsipng$%juqvNs`1nx@Dy
zXGXy^a*Qx*l7LiMeyde(nB&@uEyk77?|b8$ty<;!y%*PDW>KUt-NaBjbAqJ~2gB*i
z)<UGr3+W?;^62Q`6pdrVej^hjqSH0lGlX3TC!NqqAp6d)_Lk<R=GOM+=0=WEQ)6Sx
z*@olCAKIJIbyZQxLb4T)DRJ2n#gL{b;gI&E`;ULcwZT_*idE<#Go?YGW$<a4_PPiv
zpjtGuGjup+=SC*yX6bND)6YPiGKv&s6wo%<*V6;k?<FO3e%iZQntD3h+FF}hTFJ<b
z0NSR;Gv^u}dEnSRwQk(dqKZsbRwY@IHB6*RagI`0CI@kV{(J{o1@J~r#w<)3<0;Fl
zz&GN`GL<qDgR|2^bU7#uMaOhva$<;Dkmk-{FD;GU4%%N`qMy;#)!f*Et6-Pbw&tdD
zEsagh=N^6R^rJ_Q?oXSNYRI~-#o{4FS0qJI3@sLmMF}vMT!Hvse(h#l*(tula4pfK
z6k|C(Vjx?Hbr|HCS`bqS3ox^&3?_%sVo(eYcM0){C=96wsR9L<?da%k?dk@mfbzSW
zPB)&#W17#LI{xs(NAtBciX0J{2beEK;)*0Ini`GAq{>jJQhmaG<2&E}_IG}GYRB=m
z%p-^v@+!(d{)pucz!VzmXsstuRug6+W~Zhnhv6jQ+6H>zn0h!zLVwc90m3#tU1a0-
zPJ(T7OLJpWBj>02<nc!zx&N+QzUXQ?I2I={q!`tZrpBXTDHIJw2r?gZ#njZtU)p)T
zvL=>Xh@naFy=W#QCT4n4*kyWtia<LzHbD`DB!z%GFgn-|h!g!&sO!O@P5@kIC+sXJ
zzq7rySs+^?%h_{{t*0J-=;7mcSEn+jY}%@-*p{qFrV^D@Nr@R|IIKxA>1p?`*|GdD
z{`1bW3L>3#rW3#_OH6Js@l;x6fUBUyADNgPABSO?okXxTGX{Vg8bw;r+dG7lbP-#y
z2y|q3Pg_$<R~u2by|t;Wy}9Ac*>k5JK791PNA_n_C2p9i5><_OT-9PKSU(mrjhGUv
zjNmJO{m;3+x$~?dbi_!CDG3+A`SjQML*Iuth-c9;Aq1SD^8<DRyun-3`574Q>FOp4
zb@q3*_x7|lQ53dxwh1z&1XY?^&YeEhaQtxn-H+arR-;kF)@4}<Norh`<D8#hup$x+
zM=Qhe%RAR9!2HD-Y97weED4!mY%v%}@v}HRH$F>N9v>Q`G#r^0$ab)Mgc_MhD|nS|
z2$i<ho<^vHmX5Yo>cXC`riPa0md3{(YdU`DuDYtalpc@SCRS0Us2YjNN-P!%#3G@J
zV2r@BgRR1HhqVQ!Y?%?9re`|2gz7+yeGy$y6vJIlA)TdH$Xn57r%yOc4FnAbbs(Ch
z?Si*%Jw*@sEJ3CDT;sWxhBFT}oPFrvU3dHONF=5zdQ`lZqiQIogv+8jo)QhmJ>!D=
z*Npf5^KWjdnKvcp+l6h}dBM2)oXEyBILJKUS;PlZV^qmZIWePvPKTD*%=j?XV0WkJ
z`Sf-{r(l(KsJAv^Njuy%`KPfFoYLCVbmrX2M^2r&|3LKtR|3~-ax5N;$Ky&U6sXkH
zKt*{t91X=2s<w(%Fv~`(z}s#howi&ZiaMr5O~Su!vt|~&?<>gN$U!tX0JC$b59SbI
z@DcR2(4|b^Bf>I6W21wJ&<A^Z04lw(k$rT3dLU>!`R{CVdq;m$TSxP`Gc7Q1&7ioG
zXBr+nSW|Q*fl$ai@o?0L><L8h5hYL|N65^2EdDq-2(xUk%8QUI$8Hvf+px;jN~T0l
z@^b5SP>J__Ma=9k(e^=mzA#OdJc-yE-425+h$A5ogj{rFxE}@%9s&6|v`SBBZ(Cb;
zA04ocb`o<(XY;w{mZmdMO{dO5!h!W0kDqBid*Waw7LCT^vLwaSkS6V^j7X8nAW$w4
zsf@%!!T2*JtNhXitBB(>vVnHm>Iu5GyY$9}(=A&C9zysE##mTHm(Rt#J}HOeBN$o+
z<0hbLMOT@2hY%Hm*aQ<v`k@^LqtemA@u5hD&2MhOKU!KE&r<(1o;`D}>Cs0{+;^l#
zje=+6k|b5e4I>te1^0w2DuS{UtPIO?G_;${%$}2tzJgIUiL<wEmD0)iFb8N`9RHhF
zdEZxH@EICJ962>7yk&ZBiQNu(31eRX`$>u)bonEF<Ye$0tTnA3#7o_<D(#J+wkAQ*
zc2Fd@oIBeDu;uUB(`On^oOq~SqTGpx6`f)*7>nESV5L+Mt^~$O5jji;J{rbXZjCDt
zEE^8cmQRp4KQN3d#1u9}Z~X*a=Y1!@vFoKekc=}u%LWWF8#gv8CVXfjGvhQYT0p2q
z;qnE(?`|9DY{xuQJ{>eRTALf2p;FGAJ98GJaD>jDg>^c4{9apyH;5{LwooV%jzojI
zHF0n%<(OIuE<ss+_HA>}`|Ae@cE7YzTbzWg#+4hqFEc*#KwHsJ7Q;O#nb-sZ#WX!8
zFg}@hWE4liPlg4TPaCYe4b@T)E+eRGO2U?wrY6Y9vuDq8c$zpvXHTCzb=O`$9E(Ws
zZt++^lFBPX6)`Co2q}i5Mxk)yl~F}8LHs3byE!wzuYM5z0q-iP*X>y42JgGRjPziZ
zNp--RSnM!8J~LSw0~-RK42>|mGSo95giHh7NSKH!-GmmH$o3Aw=2Hnaa|t$ue)8F~
z&8JT{oqO!~1DQD95sQFJv`Acy1}kDAtWqw!hGIl58T=x<wo6?3MV9z&h_)Z&_`Dxq
z5!o0rTUbP#qOJN0ca-iuK|gGHWg5tabO*4)@G()A7W*Uu3={_=qWJ0W8$yCXMn<H9
z2m=j96C7=Odt-Bxpi){|8ZZeg)7i#TXT+b!K48aVdMF%>M+3olM3Ta>KxI_Y4Kg)_
zqOHTsSw_Ns4y&*!c7s*Ks-+FB!!5@Zp|=%1!|PA4*m4fKYL%5~7^a13{!C3Vdkj!P
zpu%Y25Tk-fcKXNg5(HgP`m{E>p;NkgI*_<w5_&x#wzkI8*yT*aIr_<`&YeAV=G>_>
zr|&9SQZy6@2ZEtcOpQP>MJq#8%#vxOqPkou*_LEP75k}@ReoUyR)=D(-Sotq7zCRo
zu8^RCve4E@c95qG^bCykbqXTCtErPZnIf>ex48{DB+=v?8M#ELoO|qaQ&U63V-05;
z8cv^UxX%t(#6!_QM2brhDImuy1&eKKsidDYZ6z$(uBB+2E|>&-WhYu?X<=2!t!IYj
zrdOF+hhq|xwv!`Mw2+0HAcgE4=xph3Y40bHboRj<K%(@w(dcM^xo+)fJV$V8XgJH8
z(~q4#eg9(*@1rh`RRls2Rdynp7OIduN7X#dcfyYD#5GefT|X|z)t|>I?2P@xoyR1w
zP6(hvJQ))~g*i%^>q5sgJ~BAW6kPu>^GzLee$JkTo&~vygF^?o1!W4E=X7J^nTFFG
zopTLmPM<n;vf=ax?#er{V35i<sOp|q7S!T~t>~GA<s&^dTuV0$Q%<COBdYz9$jraE
z6Mbb)NDt<ie43wKVx0lAlng8g)AZ9xrr|Rn#P>*NTh6uuSlZ9FLs_@Aooj4qZEJ5j
zbEfIsSrlGa>CEZJPMtk{;@*3*NDd;Aa3B!0O;0O}S1R$if%4e#T%DGo>YJ9A&@81Q
z=KdS+Z^XkQzIl4b@wTk6hPoc3=R*x7vJV~uh#i3~=o{*%-_zXIK8R|m@yw%*;vFUd
z&9({!U}NXGa~OnDxv}ANOT)P{r;i_UOg&y%36l~lvl0n8s1j@~zsgH#GO`spNKQ5?
z!g5TP10nnW^!|otHT{eKycw@-q!PA@_(f{ncx@vGm2RhVit-$R7Zd6T-Z(r{lYOnN
zNV(d2hDMQbiL$Swt?~HLM^3eLwV#1=YoRJ`;|PIcX%RM^ZEiYy>M`Q%$%ppEg3)j|
z2vZP_#9f&_yXx6~B59ck3xS3v>1I3@t_%QVg0YzM%Zb1J-~QMC<zHWE*l37NuWy%C
zW)>D%oI^24A8dS_(J&;&z2_RcPM<j0*xldU*3jC}(AoajBM%<A?^H`ir>J?(ooS#H
zq|e@T=CQM9&YWt1rak%S@rUoLbAy#-0s3DNC2YH<8If$yPE^^Rmqa`18H(!~DiAKD
z$q@;0>96@b*^eiNp4nuHjUU`Dt1L_l?--dz7RfHEp<xJwiGi+18%`d3w4vclYwPI~
zkJ1-Ca(M5N`;HT5QCzps+h_sEHWFbQ&SH^MkDWX5z+=bi^G>)DjG`JQ{jh}XDqhyj
zBrV%WT85cO*q-U8Y_m*J;+7h$3<jjn_&jUs|M=hk=-fs_Y<hj$tTH=3!T>*n!6-Ds
z_)uS0%XrU&`|E0}?>+hG!>3N&f8=0&CXr8Ns_s1jT@8H#QlZ>AbB4<JRD<x86OWxf
z_3+(wvMdJz5yZu&?WRqPkWRbI0l691OS-1!+ZN{sYC%QD0znrJlzlq+!+-n#{NMlA
zA2)5X#KsS9n^oo^BaufAjZhFyj<?^PtbXXQi}2IQ-*Y5?@b0Q~#?%!A)m0}>6HS`v
zu(uFQ8u63IPMvCKIPuuYM;<+K;#k6>pC0pUN3}8ria^sb(iW{C%}lGdp(GT|t_($X
zM-&s;Ezoz*?(*GVNd4$nf903|?VmJnG{mOYx63MvEG}c>baI%JGtqp1!6vaL3`vi>
zZZ@r?eI#3k#f+1E@7dGvkC1JY#{75sY{O$`a1tElOv8Qk*>I)hrhPA!tKX};>4cTA
z(rzSXM{PTm)*Tg2MUU}sS*EXPjunrTmzVGQ?ewev{?|VC(QmhIw8XJvH^&a&dmVIx
zuzmCD^OCl~+itjVMeNE1p^%Zs2ajejf^4aXw4^v?i>6t!q-p>!-ON0Arhy(<6O0>x
z?KE-a^vN@)PM&)7#K}jF7INuiI!~jcw!YeR(itz8_3C^{_bi9LN774L)IxH3h3+6+
zK^e#KxpP+_@CTXKKK`4(@#}xuvB4_OJ-1D(TuaC$-c>w|t8{H4GjF<4(D`G;*zuX+
z_B8T=IEDaxO6az9$B`p(&JQ)NQh4B01EK?J<g-l;XHJ|ZqMST^^7tbU9lz)BJ(=9W
zOm6?)`s%tG-z%ay&ZV4`VaCzeru>AP_98~ojRYgIWNYwHmL->0?umr{Ap81fKK02@
zey{7MRZvjAFRQ>Iz#?pex7~c>Buf3!safdS@rO(k`9MbJcL~|bw4{@W$xOp3jxOtU
z_de3v-PwA&t@&hw@RNq)51u)G{Lu#=IgqO=6qqE;)))32tlgi>d1=#jQeN2bT+1o=
zx`oUsRcp(Y5SI8!Frr1Hfy%%gM)*qZ_22sZ=RW&#&rPe0ytrMfTy1q+<z2VI+it#5
zEY}&O*)u%WoYP4l3ZYPz6b5)K-F7UKT&gRwV%I&`+TGsRiaMnMhKYoH;?a{QA9&#2
z`l>=Mlgp$@IN4kxnK1o?m2qsGB<)zPZCJh$(UKWWv1Hpa)R-2R98D>^V|Q6a@Q?HC
z0Q=$>zTbDlDj$1p^HPm1MOz5lYrN~$dD~lV6sVT{Wy~pj0I3!#SlnAtH8C2<aE7U*
znM&Xk>9r@YN^=|Co^xd7hfh9u;`FHp>-QFtxnfnmD&cr`CS@p!o3L!xOQk$i*q-C#
zX`UUj^1`yZKrOOus<Dt>aYq2k|G(sa{QOtG{H0g=uUqA1CL6ZrD<X=#!0EZh8X=h#
zC+R(Nakt(m)EKKX1Kq6+MH{s+QejgjmC6*l%+~rI5?R%;6)nH_J{qTlm2;e*Gmo4)
zdEY(zYBGLxwk}swaFecAl{7RjS+KQS(MwSZ%89J*rVJOEEd$+BG@bEf$JLCut|!dc
z&xQ5`Bi}Ck<ZEC3>hpg-aNR0bN8dN7OSj}J9~O_871xKi%-i02<KzO3)8@m64%eAd
zL^b$TYO<k8D%jjL<*cV0iq0oh+d0<S+17FzM`-}3Jbbj6vot54&Frhm*_M}bfoXm&
z>FchaP6G5@#{jaJIu2t&REA{Ph@n%rY(=p=)w?qkyEE{;!cSiK`q#hq7lYTWBHnM$
zSFRDZc#QB7@psF-?Zz9YmIwMeYCM<UbWGPJRY%U3&^6l^F2bafXQ__HDU$uh-fq$|
zXyp`$_i)iQ(r&J(rPHR7P9%vyj-N?7cG7oU4_EOV-BLw2C>kSl2erz|uoN#>Wdb)@
zAK7iJJpA3lPrmWO3t#`sq4#f<>xAvKld~P(wshpK-8kQWkV$lzQKnc-))g_m!wk0S
znNc}uJEpBM(PP+%i2W15*)uI?&OUnlvHKeyuClUbRXUYSF!1APV4Gwj1+pi`nqE?r
zg0WzPrdR|4si}D3F#nPg4n{S!V6kv48VdyC<=-v*^tago_LsvOt+MI$mQIj}Ew@}-
zz$=^XJbr+vfx14X0`lR7Ow+LlvZkq6X&3<J;m8}RXbbD<x?`u#o)ki+Qx6>7pGoPC
z@0*}9Nw@7}p*ra&7_{^?$O6k%U~MadWn}?HwL%oh{Er07!zzsr%aTHh#J?8_39De1
zzuI|LQDZ<@O{O8?5?~!h-&9L6RnSU?1LSIojrt@Wh(>}HVLfy3{s$V4KYIF+gT;)N
zN*JyaS4>S#rjnU_m1n0?j-7F1!pKp)VfXH`N{J4$q{%XrOT3&8h^a+U$vL`O5h|;E
zNmzx=Xgkj;5~5F3uoSwsYQ~wVO(A)-f%p!ZHiC?7YOx4_g^C#Umf{>f`RF6}WL+y?
zODy3Y23#^#H8p7~t})l1pca<OEF&HW1S;;>6D<oFsujgH;h+|jWJ5CIQ8^wnGrCG!
z<j;1jRm5zH%+Dr*qozQYRizP?i~ONOu1Z)VjsRZ@2Sc$~Bo?X2KKQ`?BokqF!p~+*
z-*>W!jLUFx!cSll4WtuBAsDFGU9oHT9lI*HCtR^BOq(pK+h}gXv{_NenGrP<to);E
zRvFoGysa*)vIR8vNIB?X70vSvSBWv?1keZzK|w?@<QNA)QVd=wRYgCWH|<naZ6=rS
zGHDivxGX+MdS)aTwe)l@Z)>qoS$T9%WgsNQDtFzvyFyac03$+>xKSk>B@w~(Gkf@*
z>sHwmVK;toyP~bG0%em17{ZhdRgwHe8d%D}zRqtpsz_2a>PSSEN?p&mrfd4eLdJuI
zsy$FwRaI4+PpAC6mGM}BP+qA>H3yFFO_*wBs5}@b3t4JF+OwykEEG^or0OPYf4I_?
zj6~RA)UHx~iOl?sZ~XROZS0|Lw8<Oqok`e~L2iDq-5f-^NdRIkk03&4!cJ6EB7)@P
zm_eA;j2Qi4ezlJ3`Uxj#r>fIQH&cILA2>hd=a}8jrJXF~W5O(t+37-672zpdS-E@n
zo?uuHR_xwWrs65+vSVRb$;zM<(`hzSm8)v_JD|81$U!^LDh!KyU^ap#P4TGXXgMa-
zCFuE>1{<x$qH%r(Qm~gVru?j*N#zRZbZ&2bBA@hAkV`(_?h%GeIS|QYYLiv2tzrzc
z8In=CCs=W3C9+a2PEHElSymZ~qsca+j-F6-nd<N-U;p|GFYLe^<SD8Plc>2$Nk*Y7
zUIx5Rg-c#S<rkF6y-s~TUzN*NS>)fEefeZn+DRwiUx9i$Jq<M$ag|+nDp@~e`<@nw
zR_xjpsEq3}C@xSDGDFDW0_ByJWic#mpx%f@LxvU(>(tC&{o2>Rz5`L54)X>Fsby?O
z0(_|y%HeX?j>aStak&Chq^BI$&E)e*7y>V!&!tiY(rrB9l805(@SJ2a6WN7KC!tYv
zlX}CU(5|2qjK(-Hd!m))s1s0=R)(SxMM0`w5u!69$IJEv{}VOy^I!ei4z!Bpr>J~1
zIhF88nW8c@1f<g?i;s0J7;{xOlk?rAop5u0wve^Me4Cr9@`y&Bm8mWklNG_;KNquW
zJr|_`D!__hsH`lwJ6N&jj=-HFM+d@^95YdZ$x$+1Tq-ZG2*oP*g#RG-<1c^Z`LAxU
ziqNlY6vk~i2Z?%!%CJ;ALnplFXnXCB>-4YbI0Oz^haiDgVGu#n;h3~ErJ-(uRutIi
zS|@G0RU91G0L(clyd+L1S@j)6ZfZOf5AO;3IpTGc-g01f*{+JRvhv;KcieGj*`7ck
z%;=abhoB}^6`4~-T&b)mlOsx*`ujOpr!RlyFK$+cf?(NrZPhA*niMpGxP*xEJzM44
z9fD`!dO>HP)?yqm>LfKop`}O7uNX8ia2G95DW`Ke5_Q(|Q~5j%4Ly<d;if7gWiiEy
z#$_c=K*j?ySvUkWNO2PkmsNy9<$Lbjy=&K=-GN9*k`$W)NQ%)us6>$*)&RVM!_|H-
z_xcwx%b)+#Sp`b%I%!)n&X%mg9oMY#VG@L8A+(8GE)gayCu}IDSWKluUJ;L2$dbg0
z5K^+OB@za4S=U1$k`-*76eU?H29vqaO0r{wf>CiY$i{ni-*Lw-ILLAoPBD;5Ox6@q
zd<;Aokqo^;HiGO*P`;Ua{R?0C;+OvXCcpB26<}}v+)9ZM;P<_Cy)Ac$6C_+ME}5zk
zQ61DstSi$~S~#YJf{Y|Y4M&qJ_yvc&gkdHDEkqwm0Lin$CR1~^8I78Oa6G0`AGl#n
ztB94$;j-O<O1$LGvWh*s$^&7FV=>RIN60;nM%^uB{bhs~(6k|4$-e&i-}=HAU%A1>
zl@8DQQ43;>tCR0SU&^%=U%7h6)wP~fbx7CXl~gjct2wb~5QHnqQGUf?g)|b0d6w%b
z7GXx$!&(>zkyNsht&&cHGzAR!6gd(s-&3~d&ON(!RaD$rUKS|d6QE(D39d#=I9L)P
zJqU79Oh~9uoYsNrBwozE_Sw&U{<m(i%8MIf%a-E`wm4CWD_1*0Td~UZ9un4hL6fKm
z!;0)N7w9@U1uH~Vf{pCZD$`@(xMC&jl+UIR3TXv3S0yq?)zy6qib^Jt7kx!4FWa?i
z*PWFWca)d!-cw$_XV;w-QE(utCO9bvwG;G{#<m0n@KZrWC7DEC+5A%WwNHQMGoQc7
zW|w^B{pfAQPgXiY*M9L^u*!8;5z+btP}2!XGMF<CnzJZsgYg74f7D7uL`dL#Bwg1}
zdJ^3-CXz{4Y?e_BS3qJnQOx^lnSgD3$^yH00Zz!nckBwqqxhbpS?uNs8g?uY4xwL{
z)u<TZRc!uUS+`~Liy59v_UX_3*$s~W4T1ePkl9<VgT&73l2pC433*E=sC0*LGmhX2
zolesZFiacg#G6tG={<o(We-S@TpEyA8VM0=tB#*^RD+WMgQCzG6@0D_9SKuiQCY^o
z&u-2TRZlq~Hm)XQ17xVV@Z*f?>RQ;~E;!I=grlm&tcXFiV7-ue?GvB;<fmS~*$)zX
z5;lx{Y}qP=l~TL-1=054dhfn+^^WWGuZH%O+0nQWr78@^RVw``m5QvCSHx9mkLqc_
zk~D2Z-vI>Mu&<^@9m#r4rzWQpKZ3i;!Sm&TifAZYv70#trY_Ym?J><sQV}SeLz?c2
z5hin?NVZ_ID@@mLJVX8M%&Q;&_$NNO!73ZEig>-%xKc93hBxosDjRO%WjvA4Nt1CM
zT&`)62&*sTxE`qphGA~wAp>Skv;fm7(Xa?bqGpVrmp+H#`>;$>T*TJ$iaix5u;J}V
z>J0oxHN+TEKMS4ZvCv70I|LLNS^=DBP*}x16dg!zzmVaHp&$RmOTD)m<HpCg%_=$+
zA|W6M^$}JpDnr24@?azy(d`IrP#QQ!3ULlP9N0=37(;i_R6U&^Q;viyz-d^eoYSVF
zVNw-242du6AU)Uf3<EI3f-7L60-})++eR6K7XlXkGwm;DUi}TsvIDIWl_iTtm=TRe
zDBFTD@hcbLG+rL7q~l>|8qGs17-A+YPMV5KEKOw7fmIo)yrX<K1_?!oMR7tYvSOf*
z;P4GKk@vGubbJJnV#4$D*NmY5h_mR*^D`b4r)6Q4-`ts2AqN>rThf`(K*UEzj>H4I
zLcv{Py^fhR5IN~Uue20~Ix3T>uo<h2%M}!O6_{~1q1gr(YXl<1I#JyhdnQ52Qp86Q
zm$4kj(!8wd$Tmao3f(e;UjYXQ#@ungcKrnHINp}sA2Lc4IlMa%3=$|UJrKNu@)mN{
zwX?3~vRl+m`EpQJf<c8&7sX7dGFA!t#XyYE$trFH{HHBocnSJu>9i)HxJ`=Ad!mra
zW~+0VtYgFUk={~>D*4~DDG)4KMB7h%;*&e@1hLM664{{;3`kLSFDdczz|S#}5K>X0
z*sd$-30gW9XG>uV2E*BVc87x%0XZB8^J_@qG<x*_6Vpx5=b@aoGCl>Brh9s#u24)C
ztM(!0C}c93R3yq?PS1!d4lPOw^4K>r;_0#*GxLowd+o*Tind6+43NGWp$|;V0C%ti
zgmV<MKooJY_|AwLC;|0UEEL|2MfL>B%EJ*=qcWt{j?h*kXi!$GNur9TM{)%(A)AG4
zt}a=FvZXpvRadOZ)z<I#Nl&Ijp0aGsN*PoZUlAzoQ=k5`n|NiXSj7l4l#Z9MBqkc7
zp^8YDg}k9C>=S|3z?0%J1Qr%7Q7{moi4&*@Mj{b0R7gocEx_JDcuIcv2I3|skwnZ=
z%+>Ban9Ekz*V7lt<%*e9et%uIIzyqTG4i3s$x|9t=5J?T`_!kwwmZ)%ga{Z`xUz_(
zcoz8vyb+PYv=rlBlw*KWPO=TVd{?Nff_jG<Fox1Nt~)mAS8)qD^p#PC{df+o0@urC
zlewBh2Wk#|;K2U9_Z0KBsocI)x+-5+Tdc~~q^Qb$nUx82Bz4F9U97Sh@$VF05p!NK
z*!@@xI?ghq;M{OP7FuFr44r3A5lU-4xLeR_73I4_yUQY>I4H*RQrUEIU#h@)q3@CL
z(64yOlvjUf{|Am8JaXv%Vr_a~E$yR1HdT|V&iU!;d~%--@#&K62t-EW8^S6(@&w8B
z)yo;xXF)zelA<mgMZ<%b)IrYWA~dD?w^*AJqBx2Ng7nkFJYXP!1&ma_W`F&@9ML4<
z`L3C8Y>>#_Lx+ysf8=PkP+M2rTg+GOtI4Jl>8jf5Og@wHQuOu>C5EI!OQzfxvTu#H
zEK1nW9@>7iy{ewwF5=f><qSE&2$&I@l@|=cMd%Ho&rnmYZ>d7W!UF|j&?J%@CnOV_
zQ=F7!UiA|-b=B#tLz~QT^NA8|U>~^m?xXvQ`|JJc{reBzSC_V{ZO6}%fLyY)>DkG2
z!h@ViCir9j7S*B1%p2m$#&rN3r)^v1s(N+{)#0W(=mm<GaL`YX81!h^0**=^(1Nss
zmkT~Xv-Py+Q2q*^k5r~i9cn6NWwNQXSEyycg>k5qOp}_mL~`6YaNh%U*~8U`jy`<<
zJx32EGY&fBOtRE^^wJEHp<{811tVc4{dD9rqB{KeM#TT(20sxoX1i8_V<}b5+w~PO
zssk10I+|qIiDXRA*<>HIlxAFPaz;MrATA{e8-P>Ot@52z#>*r<rzVxiq*FqPo#%NB
zu+=oCGe_<@aNy_%?%Dr=dygKfDUy?th}ijN)2Yo>rTvuWIcQEZSsvX0x%X*dmEZjM
z_ipNKKPEOrGt+$i+OAcuuesg6Rl?C22{q$DKaogiela1Kqyhr|lb8{o`@l4mEJ6z9
z)#a;_UYc}Vmof|xD>G4P9|4o&VOceMXz#v*cONTMSLJF`S$HK{(-|7E33O0}Vs#bq
z$aPbhOxlZiUOMx6tU@95z3%Hqc;h*I<zvTge7Id-xxVgTyC>*Pq!X$MV~bO($WdUf
zJ<ZK(4pJ1+h4<Z50>=T;8@li0_f=<d@cn3ueVetLrpH27RnlFU7t(uj@1eVn?BAD8
z5Qn{jDHBT)iDXr>nDDZQa`&dKl;vs3oS)19`#go}5FP(-Y_tk1X*P-|x92ObT$9~y
zg>~8#SKbUM^uuyVmlCi%s3U;XXm(h#7cnJU7NSzTM`ni#4Q1OX=94xSU<Q|_yT&Ml
zgR$%|oD$z-B=_BQ@b0?`o}Sr@P+j(1H=RpYCq2KYoB3=Z<HH|lo`--tmCg7GNdfT-
zt9<vSuL#ce{afXQQtMEV{o6f3^k@=D4(RXE7gr<-A0>yTB_1{rI@0Q~4L8n~L_2FH
zNj0|aAS8sz<)smK;<AVC5}~218hZZT`-+Ea90%l*OXwN=&Q9g{@dc7`({{e9nsU)~
zg`}a7%VtxO2DU9(<>qvQu!uNC*RSpQiuk?1uW0*Wq$GeejkXS<1Bk29_d(PrI21c-
z#oeUlhUwmDPPRIg&g6`o<)uCJVFVtkJXxcojv9)7M*V$9_SV;>Y%5!pAuL&bn*MZ>
zfK_y@Y|76t0b%)td^$%*yQ(JZ81WF;_TwMNS8iH`pmJ<OSlMn|dB0Y9#Y*sa7O_7j
zDpB6WqBsGQK|~cb8iH!1kw|w)6`E_!OJqFcax8v`X|97rDk8Lzh-afL%&33pWL@oE
z&@J^20w^2tdVX&$;*DfB<t9^Ag@mssQb{3FP9#wV8C0de^H!@|cam%Gx9=-g<HUAP
zkY^?JkQnNSfnF8ONB}`3!LA~m3~NeA*6E=|k@u5t(6IZmf`}a<Zi*hM3e7@yr-JYB
zkKI@AWpt8QwvgtOB-4JjzBZl8IC`=syEmWljYK}3%==zlMuZs8lH4SS|5jhwAy!G6
zNm|9Mw`24LTF!T>$eIeuV%312qdq3dIE)fXRCZ31E)TPWiL|F>kkrCCp_rt*uIdMB
zi;1KV0g`2G&@T&IleK%(#hSe9S2JOjP2^G;W~rQf4kcYClhl-?N0)4eS|u*IXpd3b
zBP(V0#YNad6(o@@LQuJ~?m<68o*3*M66`(F0{TZno8U+Y+zf`36&B^?tJ1ag386U6
zrjuTERl@f&*{bS%Ree>q`aoUn{%nd7_-xWA!sK%KY#K<MO_Z$io15aw4)GNxj~Q%I
zgWyjn5|#cJeLbKS9Y4nUNlIvV2sDVn0;1u=%#-h^0KOQJK|<{nl|vCb!{BleMF%R}
zv@3E<!Z9<+T%k~1m#Zq)AKaT`%7(C%&*rkGZzXa$dT*xrx$JA70LFc<d&lv%j5Dy}
zE-F+gCao<1ikl!F5)PR8GGj5G^W)R?0_ax6P-sKY(&CU&=g5jH8nKYm`rf@YRaFH_
zr=*jvs>>9uRI!ju?XAgYi*<#3=0FWJs1Q?S!L!s0wwH4dU)uI(sF^?U@sDpnakse2
z`^Z7>FWQQ(1gqRcZ=AUgo?qi4^~z+^@bJvT&@O~@QQ4^<pdAX)ugfuZ;?cs0GB^{L
z=+wtkdx7}}_NH-^OtDy33wfKV&Q%wRHIORBVlkD~g#ZjCyqz#pj1Z-=)Kv(F%+JHG
zeDaf@c<E*xv{S5N(ZjRCff!XX8^05tnM&l+cBTf3jkXx=4_gnT&_I4b0mvul`mm~s
zhB40@pq{k!+<`-NNB1AC&1MqWM18f9^sK6ys`|QoI-kiWn5eSFW(1oJEH)&9?b;9#
zh9eQ2+%GVr`sq)9Y6o)sjxO=o4H|(oYM6p?{OU{wA#K{_*Q*=i<j5Jm90%jY5~dJV
zh9i-3#zYid(3r98{#<qP=+UEltE<eEUzZg%ak~0I4abPOm=SnpCW3K#sF^}-+U4MY
zdR<?kwn+G2$-Vx$&wci@JCL`HtBgkB;wW(FXo19Q_^s!7Y>R>dir#0;LL<hwM?9`+
z$QFpON|-IAP@0u+RH|{Hrs~MS!$nM)PbG8U5+{?bX6P;}3th8ly%V$OjahCYolN<T
z#n=qBgQ=6C{{xe|T;IQ`)YvH}h^mk2bVW*eR@zAvv#CNdna_#S#8g?zjnfx|rVF9&
zVLvSpUuEO9ju_XrqsYJHXr}(ILq#yG$Dq4Kjgz#KbvZwk1{^zysA8zTMl&A0hlgRP
zwC!9XQ{Y&!!pJS@;=b^OTeMCaEpxlDt;3MMtcTSM#c#2GU$w__5ab4Fja0;}wi=2n
z5!&!^;Z00{&}6sJx)E~2kaz(#o@4(;8pfKWZaEx1P4n{!KdHx5$z-~QDvOpptFsAG
zM#g6m81t+A4+!m4{P%^gd~u^L?&@<sZf>}J&sKRwl*uoUc&;u;;4S)|ZP(1NxbSGU
zuO^7JRiuk7^(@Go!Inf8CJKJi^7JS}LZ~1^%)`V`%*7e?N3Fy_awK3KdF0St*>t8l
z?Z&OFmt>sTL5+|UlUMZK#2jPDcBz=Sk$NlXz&1g;!004=;}3}|pMQ&5aN~m8Em%bu
z0i%=_B)q`et!pT+{tM#mD<-Sqb=6f<Rn>c|3x!;w8otp_Cab9Ha*iSX|D)*<>)z-N
zvuTH2J8Vm&WsDjU*@pMPzC(A{<o%4;XH{D;p{+9PbAq~p^fbkwsv!nF!NoC_J?YSL
zKo%(eYTu2jU(3Gsna_Og^WWdBq1=`(P7qC8Hx?vZv(GlG!&gkhX9zWE?aij^_EzPS
zsg&uGFLF6Mhhi|rI2mb3wG-6Ih}w|V2J|SCxQ2%+n^E7~J@?ku9M1CdGh<Yj^}Jjn
zT}_3M@oP+#UWlB8&c#pI4ow@*bkcd3@gk0r&xu8o@QF`;`ZKp^owmi>iW7vW?Z$!x
zF$j;9wrdqKt^@pHxk0MBmJUVIO=pv|Zde1zyd96<6Px30nnE~<Rmo~e$=2DcV#R2%
zM`L00$k9W!b@?P{&)`X*^hErsjB0s=U(@p->u@m^^dR^~|3Y^@nM^~(r87+BDc<MP
zum1XP+^Xu?C@kF?w%xGU7Jb_b7-hRwc~kRaNod4;zQ`5`41$CE$y_$gq7Va~nrg>j
zmIDa~3nb+L%O7l)85k4x8pUWdX5RJip+dEnqLoNQ)#)iFs`75SkV(5d%|Z_+8Q(+m
z!#rkXEGV;Kz-7e*Wg<PMg#GL3AARiK{o23Zz)+HZHg$yFb6gQ7KpQGFlvi1}(&NRp
zZ55PSP$3Dw8mN*?QO<gFGWcC0=0UqIDP)VVsDlvrBMglPHOo=7v?nW-l`#Z@HO0GX
z4%XWV$2D~bE6+{jGKEZzppDNYNbo$Pn*7b~A1Z6f^q9WNYV;jJ%`yE`sUQBzum0*s
zztg!P8E<lxt@#Q<Ss~uPW)<;r+g3?d!2+e2`4LrqCYJ-S6w;ZbuBf(+dejO<j4;oL
ziZUk`<FP*qp;>Z`h!l;{MTg_9-@CUyOSLR^TyYfLRKX_|`Kba6kP^0d=x`*?c9A#&
zN*?OxW#IGZCfE#>$?;F5e)!A3{E?4*yM2RIHtN;4&?UPjlob|XLBh75OD0^7>qOpX
zF-Sg_LrnphNa<2Qo&@e>&L80bI((U}7%Y~N89|gKw5JTd=%FBKh1KawtWZ~9U`-zT
zR%oeeMkWh=oq}~U@|o(C#xSsEg@h&(t4dA=Nt|W4Y{81lMk=m-GWElM%k{0cn^xJh
zOMDAfxh|Bwy650p?A^AntoRwz&DR%lRaGz{n8#076|!0e1}dndViUv6PTX=}W|;&M
zg5sc(Fn96vH6)XfO1masYZdb}ep1PT#KRr)5Z`$_OG<JQo}Oc;29g+9P9+#t=?&p2
zd@rX8#ZyfA&9_?RrhQ7UwiH*c{+>6z-DVDY6Nz=Y0M}YyWqJ8bGM)8la;1_$6ceGA
zguv27*2FXqWpczerC5+wv86`Xniw*zbX^TjQCCFP#3Z~}YU3vJ5=D2C{a0Q-rKVkz
zvdJeGX-=-jO=Kt_d?zVOY*LedBlW|NaBcLJ9b%Of5VlyI2UU@qi+NIz>yTE(iU1;r
zs`!l9QUX=t8a(_b!n3$Nk37wzI&c9!Ta(yZ+_&#Y{k_GatR~ShY1y=&Pm0)-wrZh)
z=^!SvUTuw`q_c<@vMJR{vCxN^BF*>&Ip|{_`{;Kz?f~0tmfPhkem2b-GqkZjL%7B2
z3}gNdvNbqqV2VlpfHUCfP=d9NvLb-JH4I#a_r!6fwCb_IXkYz-yY}t9FOy0!@Pa<K
zrclghi7Zw!$4Izfmy|?J4Z~>396jeWOKUROguy6`o&RJ8yuxO*4gH|aM%h{p+H`iV
zez4sWWa?SyG0>XNfMFg6I_W7&GMi0!R+OP0O^266Xb!^?jR$S$1dk;l)Xw+}`vwaL
z3=SVYc(^tf4<QFCk-$k(S+N>XMzWekgP1o(CC!j{Ca<S539+0n<tvIqqu|RWUEHT$
z>Un40_HBOB{~4b`KdNiw5M9fs;hGtw)AUq6?X&7S7BO`3pb}FKnoO2591=l6jG|q!
zm?dMtu25tLNA01i8gj5<CL}*?lV5bVm`*aifEq06(rrd^tWs^}p%>CsoF=LV5FBNs
z`Qi@dS7?tz8zjW;kQ$WLu90N4lI;m-zqlBEuoxj@HwN`GklkjGkkZd%e?}r-$m;v<
zt*)<PPr&}#6oe$oC&W$UdRa~AuqouCbe5-X(Mw|069%GQ<~3}EY3B3aDKO9c{8u(i
zW8QLrZrcg6LAFINm(CZ9)dexnoi0?nmK+jED2{-XT+GlNgLO1eZOme5z*~bUMAbiX
zw9Ze~967ju|2}A^oSUy=Wk6CFLso9Wgumq&stFcLC=mr)=!l+DCZ&~5I7(C(YVzN&
z5*v)Z@s}Ig?YEfac12sUffl_I1X-clH!|!Y^34b+3)E(mQ|%(I4D$q_5CZ;CP$D<M
z=d$Do4yyj4L%Eclsmtv<RFlh9I|=?Jh$>eIn%M2c)_`g|naw!99*&0-Y^m@~hwZ;n
zJ4v6BPEp$aPVuMz@ppdbcmC_xEw;G%;q9_YqAEk)sY%zPN%8VkR-S1lp0mIXjUdtl
zM6t9v#N$u#7p5s0?E$Ttt`ysK_sPQtQg*JsHd|zMQ95fS3ssqPZFSL;5`_dST{vLu
z1tX!!0fqor9_6NV6s2yW{+@I;@0q#6pA>)gyIeomc~<e$G(gkETsGlYd3LVqOyEXo
z$J??Lfn}0-+#K7fm<EYU?2`ePGHu8vA~|*cA?m`~s;avSRaUAx&u+DB%FEQ$7A!fH
zhs?BC!pL+T`^ALBf&F|Id<*iAm|Z+r1F7w&Q&{EqfA9Bx_Xp!Qo#U2Qx64<O9*w?2
z&M8p$>N%b!z=JDo20l<Go2Ygo(5|?OWJ~3tXfV!_W8K$7s+2xhf9PnoE?bY6WKd-5
z?27Yzv<S8xvC^nl9N0OVqeczIZ~(hpWZQSyzMxsznwnyPKpfY;^;WA0;&waxZLg(k
zQ4W<T+imQ(-H`EDa(N`?tp2J7-y;x?2Wa=`G}&Qk%Xvyim}mZ=(heZ_i3fwo*$5CQ
za;x`c4<6oIkLJzxGIkCy=M;^69UV5q4GA@RDv?d)S^t~j;ncRC<t`(^-nE#`vfG1I
zg=E?`B=g(FpZ(tE6C{+S+hQm;{78bay*`_~T@+WJOXYcJ0Mi}}z)6JFJ<usJp3h+`
zG0K0L;+VZXaM(=2D8A3Am=Y07o$6|!s7NO$F8%tdbT(C;VvHfj`V}FaQrR*{GsJeI
z@U}GFfrw&GQDTNfMJts;SjOYZz9Ztwf7}>t*;)F=M$PSZP7uV(4f=MwR$=8RlYl&N
zJZf1fRSGeLEd+5qXHK@l6=F_`iK@z|9*R`P6Bceyg_KoX#I(Q;*)}+PWMxRr1k8Tk
zLb?I355I3)z8N;5RP5?vI-w?x+;!hR^y<*RjO-=YI}e-p&Eijg=Xd_Yi+?qGGnyQG
zZlhRmTX+Rmxk2A<*DCbOi>XACdf3yGP^|o>X(o%w7>hYU^atXJg{&e$eV}L2SW5_q
zJ<TKiCV?`ZT@>KMX46J83Hu<0%cGSl|4<-gnpy-Yb}^q4y9A<#@49<0DLpDjcn*rf
zYz@n_zE<_q7g;X239r1*dFB#Nx&7yoT|bC52dnbcupu_<5=}Trq&rvz+D(<pBj`pg
zo=b=rS*&=%p%lcpDHFX4#SQ&6GcDvhKB{~~FuvzUrOH?+q5<c{>?OlB1@=WJ^jJjp
z@~lx~PSbV>%ZR{rmYF(VuKH<dJLk>af`XqM*#PRcae_ohxk2A<*H>z4SrX{@c|T5L
z&*2GkJXIR-CPmBjh@rt8Ahl)Nh)}N^Nhe9IS18s4ZCIn8q1r}B3TyA69nGc@1ED+h
zV6O-o6=5~vr+n97f1d2rRaYm`#H(y5QK**TDl|*VzffS?)z`lI7dNdUsO*hLXzNxf
ztvk3u-)`3`ezjkNR?Q<q8npA!-9p_f!9XN_hb|sYZe`ftORtNqr4>>HNtl~q_{mP%
zvR9L*MdCnd!et|?Mb8eubhx(muEW_tSeVk!FzFeVjr5Vb_8q8qA@O+XhuAo+y3q)W
z`oAi+{yzWwhC1juqV4-rte4guT%&Kd%}~Bstgo%At!IaxNnTE&S}{Xxc_<52R*DU*
zNU>R@2>U9gACN?a<2LjOEPlG+Rzcz?4ZAj<O(t_l1X=iMX6oxQ2Ol_apvETx`>4Lt
z>{fQOAfmgAszt9v<J|ewhbY}``%8tNeD(RSd}YH{nm2$e?+343YmU92=aQ8|OEuB9
zCgl+@qzax`0{0$^L;__Dp}HRHM`&FnBjt>OvpEFF!nRlVOcWRC>I|A%b_HZJF8vbE
zV}{wxWQzOu7Y;nM_nxD5G?((akF*J;6nqo)a=I=rI<$;Uu*5V`O=sncg`coD`^&G~
z+|_e48C`v~^%HbGUS55_-4k?he^m`yYkr0NSTY-Dq!_Dc0(%4l%a6@4OP;xSp5v&5
z<x1Jf9b}>f!pM_(I+89qsT|*zvm|({n4C-&kJO+=K79AyeZ@MU3&Q2B5y+~voRf5k
zj7ZpbXcZU%C65j{`FzPLU)q6INvG1R%xC#Q+KAiYv6Vbmy1X)09%nlo$%N=ic?fq+
zTPIdoIJ7tK32Ba{RRTqj`KR+V*<idO^9(;%Jh(rZDL8&MM-}ZM<7Q!p8uMxy0-#|;
z&l)j<QK`puiKRAf^6UAZd}U|)3X37&hY*;vsWe2!K*hu=R?w}*#!kRk%0;jOzaI}&
zR#p`5PC`|)APnph566RsR`6L3th4q>)2lO8`)ZRY_w78*GVF;qip5y5au{rOYUoyl
z#0q3ts9?;b7Kgq3YW~L<<;y!z)dRys5$B^`iy30xl96R4hHrqgGFpO4hT&bBpive+
z?+F@vtJ7x2^s?wl!=W%YCaL*6!i}#wHT(D17SSu`tJ82aGDDXzGh&)vjRxY8paZQR
z_pG=BB`Tgw#?Gg&m#p%oR|ejhxBbEGxfsz+I1KZH)ls{#2(U65-3>iyv!KXe#k%8B
zAtiE1{=#L!7;G9^TsumSm1VZHb_k`kO>HZrSO}!(iaBY2UrH6vG!MmtQIs7{ibu+_
zHkVaMFf)vfgZ6DdrMph-Yxy7JDp=*#AbaEE+ZAms4}BKTQWHvR8lNnL=Q;Iq6b&fK
z1G<G2JK-p8bB9W(tdb%*;elEhM&83zJkPseG{|P|CtX!jtWNWcEl+3a3O8YY071mc
z6n(1_c_x4-xv#qDGhhS{<)tEsm{s8`U;5Hcv`Wg0lP$q$2I2uWb4Fd2r+Ko}h~W;`
z*O=MR$kI%enTis!0Pte@mjei^pzF*BR?4<xPQ9=54G|`1Vj$xH550%o49Dp%lg|-K
zMcryV4`xnhveC#8SzMC*i#yg=5Wv~=gn|2><na_FA*f(d46qWnbheRZ@+M?lB}xo>
z8VMU-2@ML*9*`?d*lK7c;0J<bRwqQ12=aEvQ6rHU14nGkVjYqc3RNXFhgLm%dw2}7
z=@EySb|tL1_BYth$>UFU;0a39`W^}$7$+4<g+UIqurZg--z?SBY@X|q2x645lW?Ud
zpbiOSGQpxap4pdFvxo^<^P~L#&7I3`8)X#7+X~`a#-8!quisoe;~8ILH%%+GLaJDR
zK&;uZ;t~3EB^44vzy=BN0)bcP3&8KVcH%6@*~FWylE_EryZz7q5^-!BeP9Tf*PPIr
zb?z}yqy3=vWAAH^Iy$y316SiOI!R>WvWEOh*;Iw_lgGG%RElgzI3*C${gmN_DBEp(
z!Eo-{CFR7xxZ;QGI37*JxC<T~EO)+rSR_U6q;ANwx`X7QZ-GBz5@vxGn8X`;amLYP
zb<T#vk%7%Ac|z!}*lwY^l<-%}U+9&`S(UO`Zl{2+7PrpKFSa!xzRbt4%EL9o4Rdkt
z9iT3x5cUX389=Yx&VaO2PH1W<DL6vL9V4(pkZ6mB6Mh1*)Yt-JSm=(<(3F5vMA9Ib
zp>p6cLg0o-Rk*L*>lJX@BOswY>U1F5{&%WR!Vd7gX;xP&#Uxen^ldnIr!X^s6YzDz
z5e`7x!|#b#fS(YyR$x}-Fg${kk$^B5@CLE-!qbXfIf=SnK$cWWA~g&_I|kLq#YE-N
z$d*A0GZc<_0wRPW<ni3H10C1j-QD)?WEOp@yqgc7wkPu~(e_lIginC)&AgZvr1v3M
zfj+s0;{^T$mO`teOL)p4(CD8#z_OXI2!UalW!N304#AE=)Ns!7{ZU(D$7uILBK;UY
zb8Smul%kKv#wJ&$gAxcBh6lL-mX;cF=s7T}0{zcw_d5LNj>j+f%0qEm`C>o`CoxO+
zfbUJ&ESA%zDWR@Z#VS=f5M{vB6Ynl@y9GxXyJh{n%2x^%6q2VjV7ie2=4uiqH34mF
znpsShdR)&4r$fI<t6&^A)B+<o*D$Ups@lf~3{~_Pd7g)5ds#J8+yATjc+C<zs*3c<
zF<-E4ukcd-S;}#$Pr@GXy{WS0a)yu2YCY$jhhsYPF^sKnUXkO3;1?Ax>g-|$;f;sj
zOqlHqxB_q7?~zolrucg?G|agjL-&texMLpJzM*xxmQp&;9-oN^eooXPi{Xfw(Tl5S
zx!ly;k^ZPYeh_@+u2%$K`SD25+`1~Ch_)yDBpd?G=8H*#qfS}UCmfs-UlN2m%FKzE
zmQCWI2V1;)O`-=HWs>S5zgW~uxNg0=L50W2t3dKIga_3d1+{S9WBgi7pXX#q@8~!v
zn<`FVk(ndx1x4ChuM<|S1QY#6uK+t8SA`AbfxQCJ_H>_w1K?ZbNCqeMx`tSdIkxLS
znl?b>!m(I0mCbfu%x86z7Eaj2K#}DHy(w4W`peXZi&`SU^WCAwMOHU4-+;(Z?AX}D
zVNK2SAj%^+lbMTAhuFuN-FQ6@^xeJ_C&91uid5x?!{)mC`H<aKu%^3svi1n&0r0I$
zA_%6igA;|jgAWDN2afZ2FxJmE7b}MG=RH^Nce+osA>I$L=HOogsH_T)b;G@wgP7O>
z2(=C(W_&ov^J52rL{=C0)mU7Rae#urE3#;NP@(T;Yr)&3T1KoOdgZ74Rk_D4ZM%YQ
ziMD$#a$78J5BPpvOt%w8el;`-!cA=UMWoDG#1lB!ZZ;J`QI6LC{Mj?@$#9TeUcTAD
zgR9_mxy)f9{v~Fl#!m;`A<1;g3Gruj;nd}vUoNOkNU8&N0I$D!xiE+z9YwPMwKPDm
zp1izBt-q-X&2m%~u}L@@Gq=94+!Ae1tjZqneaB{*R|$Iqj~O-uZWTmsamBKtWVQZ6
z`B)B8lx}x~U;3+Wzj|{qn*+3Q6k%{h32c`|1bxuSuo`rQ=WZtnuC4*DlU(8O9)$m&
zB}`S9ld=kY;)&Bsq`>@7&;Okj^x^vY-}@`*csaH06<I;YpSHbn_+2sR5+N;zgGhXe
zJn>yZ98m=2SC<7ul`|p;KI>v<q&f5NzJI$|)%DvgBuGe1nb_uWh%+?~4d~mU&fUZ}
r*lr!8gA4tD>>W`*i(}7=`I@P;TW{x^DS9di;_}&TDa!jtSe5?)*9mtk

literal 0
HcmV?d00001

diff --git a/Tests/test_file_libtiff.py b/Tests/test_file_libtiff.py
index ea73a7ad50a..0f599346738 100644
--- a/Tests/test_file_libtiff.py
+++ b/Tests/test_file_libtiff.py
@@ -870,3 +870,13 @@ def test_sampleformat_not_corrupted(self):
         out.seek(0)
         with Image.open(out) as im:
             im.load()
+
+    def test_realloc_overflow(self):
+        TiffImagePlugin.READ_LIBTIFF = True
+        with Image.open(""Tests/images/tiff_overflow_rows_per_strip.tif"") as im:
+            with self.assertRaises(IOError) as e:
+                im.load()
+
+            # Assert that the error code is IMAGING_CODEC_MEMORY
+            self.assertEqual(str(e.exception), ""-9"")
+        TiffImagePlugin.READ_LIBTIFF = False
diff --git a/src/libImaging/TiffDecode.c b/src/libImaging/TiffDecode.c
index 7592f7f39d1..c3df1174eb0 100644
--- a/src/libImaging/TiffDecode.c
+++ b/src/libImaging/TiffDecode.c
@@ -353,16 +353,18 @@ int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_
 
         // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size
         row_byte_size = (tile_width * state->bits + 7) / 8;
-        state->bytes = row_byte_size * tile_length;
 
-        /* overflow check for malloc */
-        if (state->bytes > INT_MAX - 1) {
+        /* overflow check for realloc */
+        if (INT_MAX / row_byte_size < tile_length) {
             state->errcode = IMAGING_CODEC_MEMORY;
             TIFFClose(tiff);
             return -1;
         }
+        
+        state->bytes = row_byte_size * tile_length;
 
         /* realloc to fit whole tile */
+        /* malloc check above */
         new_data = realloc (state->buffer, state->bytes);
         if (!new_data) {
             state->errcode = IMAGING_CODEC_MEMORY;
@@ -415,11 +417,20 @@ int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_
 
         // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size
         row_byte_size = (state->xsize * state->bits + 7) / 8;
+
+        /* overflow check for realloc */
+        if (INT_MAX / row_byte_size < rows_per_strip) {
+            state->errcode = IMAGING_CODEC_MEMORY;
+            TIFFClose(tiff);
+            return -1;
+        }
+        
         state->bytes = rows_per_strip * row_byte_size;
 
         TRACE((""StripSize: %d \n"", state->bytes));
 
         /* realloc to fit whole strip */
+        /* malloc check above */
         new_data = realloc (state->buffer, state->bytes);
         if (!new_data) {
             state->errcode = IMAGING_CODEC_MEMORY;"
GHSA-pgcq-h79j-2f69,"From 4d74d8a00b07441cba090a02e0dd9ed385145bf4 Mon Sep 17 00:00:00 2001
From: Reed Wanderman-Milne <reedwm@google.com>
Date: Wed, 14 Jul 2021 20:49:08 -0700
Subject: [PATCH] Fix crash in softmax-xent when some input dimensions are 1.

Before, tf.nn.softmax_cross_entropy_with_logits would fail a CHECK if one input tensor had shape (1, 1) and the other did not.

In particular, the call to ToIndexArray<2> here https://github.com/tensorflow/tensorflow/blob/1f3da84a89702d3b4f234ee83762d738caffe098/tensorflow/core/kernels/xent_op.cc#L99 would fail, since the call assumed the array had two dimensions. If both dimensions were 1, BCast would merge the two dimensions into a single dimension. Passing fewer_dims_optimization=false stops this optimization

PiperOrigin-RevId: 384844496
Change-Id: Ifb02dc74964132c3ed3f3bc98b0858dbe4e258b7
---
 tensorflow/core/kernels/xent_op.cc            | 23 +++++++------------
 .../python/kernel_tests/xent_op_test.py       |  7 ++++++
 .../python/kernel_tests/xent_op_test_base.py  |  3 +++
 3 files changed, 18 insertions(+), 15 deletions(-)

diff --git a/tensorflow/core/kernels/xent_op.cc b/tensorflow/core/kernels/xent_op.cc
index 2c252b5f21e296..7d8ad52c8958db 100644
--- a/tensorflow/core/kernels/xent_op.cc
+++ b/tensorflow/core/kernels/xent_op.cc
@@ -46,7 +46,8 @@ class SoftmaxXentWithLogitsOp : public OpKernel {
     TensorShape shape_in = logits_in.shape();
 
     BCast bcast(BCast::FromShape(logits_in.shape()),
-                BCast::FromShape(labels_in.shape()));
+                BCast::FromShape(labels_in.shape()),
+                /*fewer_dims_optimization=*/false);
     if (!logits_in.IsSameSize(labels_in)) {
       OP_REQUIRES(context, bcast.IsValid(),
                   errors::InvalidArgument(
@@ -88,20 +89,12 @@ class SoftmaxXentWithLogitsOp : public OpKernel {
                                 {0}, 1, shape_in, &back_out));
     if (shape_in.dim_size(0) > 0) {
       functor::XentFunctor<Device, T> functor;
-      if (logits_in.IsSameSize(labels_in)) {
-        functor(context->eigen_device<Device>(), shape_in.AsEigenDSizes<2>(),
-                Eigen::array<Eigen::DenseIndex, 2>{1, 1},
-                Eigen::array<Eigen::DenseIndex, 2>{1, 1}, logits_in.matrix<T>(),
-                labels_in.matrix<T>(), scratch.matrix<T>(), loss_out->vec<T>(),
-                back_out->matrix<T>());
-      } else {
-        functor(context->eigen_device<Device>(), shape_in.AsEigenDSizes<2>(),
-                BCast::ToIndexArray<2>(bcast.x_bcast()),
-                BCast::ToIndexArray<2>(bcast.y_bcast()),
-                logits_in.template shaped<T, 2>(bcast.x_reshape()),
-                labels_in.template shaped<T, 2>(bcast.y_reshape()),
-                scratch.matrix<T>(), loss_out->vec<T>(), back_out->matrix<T>());
-      }
+      functor(context->eigen_device<Device>(), shape_in.AsEigenDSizes<2>(),
+              BCast::ToIndexArray<2>(bcast.x_bcast()),
+              BCast::ToIndexArray<2>(bcast.y_bcast()),
+              logits_in.template shaped<T, 2>(bcast.x_reshape()),
+              labels_in.template shaped<T, 2>(bcast.y_reshape()),
+              scratch.matrix<T>(), loss_out->vec<T>(), back_out->matrix<T>());
     }
   }
 };
diff --git a/tensorflow/python/kernel_tests/xent_op_test.py b/tensorflow/python/kernel_tests/xent_op_test.py
index 9195619b161eed..24f38ed9d430b0 100644
--- a/tensorflow/python/kernel_tests/xent_op_test.py
+++ b/tensorflow/python/kernel_tests/xent_op_test.py
@@ -63,6 +63,13 @@ def testFeaturesBroadcast(self):
     self.assertAllCloseAccordingToType(np_loss, tf_loss)
     self.assertAllCloseAccordingToType(np_gradient, tf_gradient)
 
+    tf_f = constant_op.constant(np.array([[1.]]).astype(np.float32))
+    tf_l = constant_op.constant(np.array([[1.], [1.]]).astype(np.float32))
+    tf_loss, tf_gradient = gen_nn_ops.softmax_cross_entropy_with_logits(
+        tf_f, tf_l)
+    self.assertAllClose([0, 0], tf_loss)
+    self.assertAllCloseAccordingToType([[0], [0]], tf_gradient)
+
   @test_util.run_deprecated_v1
   def testNotMatrix(self):
     with self.cached_session():
diff --git a/tensorflow/python/kernel_tests/xent_op_test_base.py b/tensorflow/python/kernel_tests/xent_op_test_base.py
index de464e9e277c25..0f7838c4260294 100644
--- a/tensorflow/python/kernel_tests/xent_op_test_base.py
+++ b/tensorflow/python/kernel_tests/xent_op_test_base.py
@@ -151,6 +151,9 @@ def _testLabelsBroadcast(self, uniform_labels_gradient):
     labels = np.array([[0., 0., 0., 1.]]).astype(np.float16)
     logits = np.array([[1., 1., 1., 1.], [1., 2., 3., 4.]]).astype(np.float16)
     self._testXent2D(labels, logits, with_placeholders=True)
+    labels = np.array([[1.]]).astype(np.float16)
+    logits = np.array([[1.], [2.]]).astype(np.float16)
+    self._testXent2D(labels, logits, with_placeholders=True)
     labels = np.array([[0.], [2.], [0.25]]).astype(np.float16)
     logits = np.array([[1., 1., 1., 1.], [1., 2., 3., 4.],
                        [1., 2., 3., 4.]]).astype(np.float16)"
CVE-2021-21354,"From 6db74a4fcbff258c7cdf51a6ff0724fc10c485e5 Mon Sep 17 00:00:00 2001
From: Mathieu Leplatre <mathieu@mozilla.com>
Date: Fri, 26 Feb 2021 11:26:06 +0100
Subject: [PATCH] Remove leading slashes in 404 redirections

When reaching http://server//page/ the server should not redirect to ``/page`` instead of ``//page``.
---
 pollbot/middlewares.py | 2 +-
 tests/test_views.py    | 5 +++++
 2 files changed, 6 insertions(+), 1 deletion(-)

diff --git a/pollbot/middlewares.py b/pollbot/middlewares.py
index 1c5d381..249cb80 100644
--- a/pollbot/middlewares.py
+++ b/pollbot/middlewares.py
@@ -61,7 +61,7 @@ async def handle_any(request, response):
 async def handle_404(request, response):
     if 'json' not in response.headers['Content-Type']:
         if request.path.endswith('/'):
-            return web.HTTPFound(request.path.rstrip('/'))
+            return web.HTTPFound('/' + request.path.strip('/'))
         return web.json_response({
             ""status"": 404,
             ""message"": ""Page '{}' not found"".format(request.path)
diff --git a/tests/test_views.py b/tests/test_views.py
index 6b262fe..baeb56a 100644
--- a/tests/test_views.py
+++ b/tests/test_views.py
@@ -61,6 +61,11 @@ async def test_redirects_trailing_slashes(cli):
     assert resp.headers['Location'] == ""/v1/firefox/54.0""
 
 
+async def test_redirects_strip_leading_slashes(cli):
+    resp = await check_response(cli, ""//page/"", status=302, allow_redirects=False)
+    assert resp.headers['Location'] == ""/page""
+
+
 async def check_yaml_resource(cli, url, filename, **kwargs):
     with open(os.path.join(HERE, "".."", ""pollbot"", filename)) as stream:
         content = yaml.safe_load(stream)"
GHSA-4rcq-jv2f-898j,"From 021ab572a319ca3db5907a33a59774f502b3b975 Mon Sep 17 00:00:00 2001
From: Florian Bruhin <me@the-compiler.org>
Date: Sat, 2 May 2020 18:54:05 +0200
Subject: [PATCH] Security: Remember hosts with ignored cert errors for load
 status

Without this change, we only set a flag when a certificate error occurred.
However, when the same certificate error then happens a second time (e.g.
because of a reload or opening the same URL again), we then colored the URL as
success_https (i.e. green) again.

See #5403
---
 qutebrowser/browser/browsertab.py             | 16 ++++++++++++----
 qutebrowser/browser/webengine/webenginetab.py |  4 ++--
 qutebrowser/browser/webkit/webkittab.py       |  6 +++---
 3 files changed, 17 insertions(+), 9 deletions(-)

diff --git a/qutebrowser/browser/browsertab.py b/qutebrowser/browser/browsertab.py
index 7e8ec478f74..6182b685dda 100644
--- a/qutebrowser/browser/browsertab.py
+++ b/qutebrowser/browser/browsertab.py
@@ -869,6 +869,13 @@ class AbstractTab(QWidget):
     # arg 1: The exit code.
     renderer_process_terminated = pyqtSignal(TerminationStatus, int)
 
+    # Hosts for which a certificate error happened. Shared between all tabs.
+    #
+    # Note that we remember hosts here, without scheme/port:
+    # QtWebEngine/Chromium also only remembers hostnames, and certificates are
+    # for a given hostname anyways.
+    _insecure_hosts = set()  # type: typing.Set[str]
+
     def __init__(self, *, win_id: int, private: bool,
                  parent: QWidget = None) -> None:
         self.is_private = private
@@ -886,7 +893,6 @@ def __init__(self, *, win_id: int, private: bool,
         self._layout = miscwidgets.WrapperLayout(self)
         self._widget = typing.cast(QWidget, None)
         self._progress = 0
-        self._has_ssl_errors = False
         self._load_status = usertypes.LoadStatus.none
         self._tab_event_filter = eventfilter.TabEventFilter(
             self, parent=self)
@@ -973,7 +979,6 @@ def _on_url_changed(self, url: QUrl) -> None:
     @pyqtSlot()
     def _on_load_started(self) -> None:
         self._progress = 0
-        self._has_ssl_errors = False
         self.data.viewing_source = False
         self._set_load_status(usertypes.LoadStatus.loading)
         self.load_started.emit()
@@ -1032,9 +1037,12 @@ def _update_load_status(self, ok: bool) -> None:
         Needs to be called by subclasses to trigger a load status update, e.g.
         as a response to a loadFinished signal.
         """"""
-        if ok and not self._has_ssl_errors:
+        if ok:
             if self.url().scheme() == 'https':
-                self._set_load_status(usertypes.LoadStatus.success_https)
+                if self.url().host() in self._insecure_hosts:
+                    self._set_load_status(usertypes.LoadStatus.warn)
+                else:
+                    self._set_load_status(usertypes.LoadStatus.success_https)
             else:
                 self._set_load_status(usertypes.LoadStatus.success)
         elif ok:
diff --git a/qutebrowser/browser/webengine/webenginetab.py b/qutebrowser/browser/webengine/webenginetab.py
index ffe2279883b..647fa60abcd 100644
--- a/qutebrowser/browser/webengine/webenginetab.py
+++ b/qutebrowser/browser/webengine/webenginetab.py
@@ -1549,9 +1549,9 @@ def _on_load_finished(self, ok: bool) -> None:
 
     @pyqtSlot(certificateerror.CertificateErrorWrapper)
     def _on_ssl_errors(self, error):
-        self._has_ssl_errors = True
-
         url = error.url()
+        self._insecure_hosts.add(url.host())
+
         log.webview.debug(""Certificate error: {}"".format(error))
 
         if error.is_overridable():
diff --git a/qutebrowser/browser/webkit/webkittab.py b/qutebrowser/browser/webkit/webkittab.py
index 4d412a38b46..d1122b78e19 100644
--- a/qutebrowser/browser/webkit/webkittab.py
+++ b/qutebrowser/browser/webkit/webkittab.py
@@ -849,9 +849,9 @@ def _on_navigation_request(self, navigation):
         if navigation.is_main_frame:
             self.settings.update_for_url(navigation.url)
 
-    @pyqtSlot()
-    def _on_ssl_errors(self):
-        self._has_ssl_errors = True
+    @pyqtSlot('QNetworkReply*')
+    def _on_ssl_errors(self, reply):
+        self._insecure_hosts.add(reply.url().host())
 
     def _connect_signals(self):
         view = self._widget"
PYSEC-2012-7,"From b45c377f8f488955e0c7069cad3f3dd21910b071 Mon Sep 17 00:00:00 2001
From: Preston Holmes <preston@ptone.com>
Date: Wed, 17 Oct 2012 14:43:08 -0700
Subject: [PATCH] Fixed a security issue related to password resets

Full disclosure and new release are forthcoming

backport from master
---
 django/contrib/auth/tests/urls.py  |  1 +
 django/contrib/auth/tests/views.py | 39 ++++++++++++++++++++++++++++++
 django/contrib/auth/views.py       |  2 +-
 django/http/__init__.py            |  5 ++++
 4 files changed, 46 insertions(+), 1 deletion(-)

diff --git a/django/contrib/auth/tests/urls.py b/django/contrib/auth/tests/urls.py
index 3d76a4e44394..c01964f83324 100644
--- a/django/contrib/auth/tests/urls.py
+++ b/django/contrib/auth/tests/urls.py
@@ -19,6 +19,7 @@ def remote_user_auth_view(request):
     (r'^logout/next_page/$', 'django.contrib.auth.views.logout', dict(next_page='/somewhere/')),
     (r'^remote_user/$', remote_user_auth_view),
     (r'^password_reset_from_email/$', 'django.contrib.auth.views.password_reset', dict(from_email='staffmember@example.com')),
+    (r'^admin_password_reset/$', 'django.contrib.auth.views.password_reset', dict(is_admin_site=True)),
     (r'^login_required/$', login_required(password_reset)),
     (r'^login_required_login_url/$', login_required(password_reset, login_url='/somewhere/')),
 )
diff --git a/django/contrib/auth/tests/views.py b/django/contrib/auth/tests/views.py
index b03489c7d205..046d00da0be9 100644
--- a/django/contrib/auth/tests/views.py
+++ b/django/contrib/auth/tests/views.py
@@ -9,6 +9,7 @@
 from django.contrib.auth.models import User
 from django.test import TestCase
 from django.core import mail
+from django.core.exceptions import SuspiciousOperation
 from django.core.urlresolvers import reverse
 from django.http import QueryDict
 
@@ -69,6 +70,44 @@ def test_email_found_custom_from(self):
         self.assertEqual(len(mail.outbox), 1)
         self.assertEqual(""staffmember@example.com"", mail.outbox[0].from_email)
 
+    def test_admin_reset(self):
+        ""If the reset view is marked as being for admin, the HTTP_HOST header is used for a domain override.""
+        response = self.client.post('/admin_password_reset/',
+            {'email': 'staffmember@example.com'},
+            HTTP_HOST='adminsite.com'
+        )
+        self.assertEqual(response.status_code, 302)
+        self.assertEqual(len(mail.outbox), 1)
+        self.assertTrue(""http://adminsite.com"" in mail.outbox[0].body)
+        self.assertEqual(settings.DEFAULT_FROM_EMAIL, mail.outbox[0].from_email)
+
+    def test_poisoned_http_host(self):
+        ""Poisoned HTTP_HOST headers can't be used for reset emails""
+        # This attack is based on the way browsers handle URLs. The colon
+        # should be used to separate the port, but if the URL contains an @,
+        # the colon is interpreted as part of a username for login purposes,
+        # making 'evil.com' the request domain. Since HTTP_HOST is used to
+        # produce a meaningful reset URL, we need to be certain that the
+        # HTTP_HOST header isn't poisoned. This is done as a check when get_host()
+        # is invoked, but we check here as a practical consequence.
+        def test_host_poisoning():
+            self.client.post('/password_reset/',
+                {'email': 'staffmember@example.com'},
+                HTTP_HOST='www.example:dr.frankenstein@evil.tld'
+            )
+        self.assertRaises(SuspiciousOperation, test_host_poisoning)
+        self.assertEqual(len(mail.outbox), 0)
+
+    def test_poisoned_http_host_admin_site(self):
+        ""Poisoned HTTP_HOST headers can't be used for reset emails on admin views""
+        def test_host_poisoning():
+            self.client.post('/admin_password_reset/',
+                {'email': 'staffmember@example.com'},
+                HTTP_HOST='www.example:dr.frankenstein@evil.tld'
+            )
+        self.assertRaises(SuspiciousOperation, test_host_poisoning)
+        self.assertEqual(len(mail.outbox), 0)
+
     def _test_confirm_start(self):
         # Start by creating the email
         response = self.client.post('/password_reset/', {'email': 'staffmember@example.com'})
diff --git a/django/contrib/auth/views.py b/django/contrib/auth/views.py
index eba83a269e52..727e9162bd5c 100644
--- a/django/contrib/auth/views.py
+++ b/django/contrib/auth/views.py
@@ -151,7 +151,7 @@ def password_reset(request, is_admin_site=False,
                 'request': request,
             }
             if is_admin_site:
-                opts = dict(opts, domain_override=request.META['HTTP_HOST'])
+                opts = dict(opts, domain_override=request.get_host())
             form.save(**opts)
             return HttpResponseRedirect(post_reset_redirect)
     else:
diff --git a/django/http/__init__.py b/django/http/__init__.py
index 2dfe12ee4bee..dddd9a89c472 100644
--- a/django/http/__init__.py
+++ b/django/http/__init__.py
@@ -165,6 +165,11 @@ def get_host(self):
             server_port = str(self.META['SERVER_PORT'])
             if server_port != (self.is_secure() and '443' or '80'):
                 host = '%s:%s' % (host, server_port)
+
+        # Disallow potentially poisoned hostnames.
+        if set(';/?@&=+$,').intersection(host):
+            raise SuspiciousOperation('Invalid HTTP_HOST header: %s' % host)
+
         return host
 
     def get_full_path(self):"
GHSA-6w9p-88qg-p3g3,"From 5a46989c0a4f2c2873ca182c196da83b82babd25 Mon Sep 17 00:00:00 2001
From: Sergey Motornyuk <sergey.motornyuk@linkdigital.com.au>
Date: Fri, 15 Oct 2021 15:08:11 +0300
Subject: [PATCH] Allow strict types for user/group uploads

---
 ckan/lib/uploader.py                   | 22 ++++++++++-
 ckan/logic/action/create.py            |  6 +++
 ckan/tests/logic/action/test_create.py | 52 +++++++++++++++++++++++++-
 dev-requirements.txt                   |  2 +
 4 files changed, 80 insertions(+), 2 deletions(-)

diff --git a/ckan/lib/uploader.py b/ckan/lib/uploader.py
index 9c5bd805e52..0b347f5ca1f 100644
--- a/ckan/lib/uploader.py
+++ b/ckan/lib/uploader.py
@@ -13,7 +13,7 @@
 import ckan.lib.munge as munge
 import ckan.logic as logic
 import ckan.plugins as plugins
-from ckan.common import config
+from ckan.common import config, aslist
 
 ALLOWED_UPLOAD_TYPES = (cgi.FieldStorage, FlaskFileStorage)
 MB = 1 << 20
@@ -192,6 +192,26 @@ def upload(self, max_size=2):
             except OSError:
                 pass
 
+    def verify_type(self):
+        if not self.filename:
+            return
+
+        actual = magic.from_buffer(self.upload_file.read(1024), mime=True)
+        self.upload_file.seek(0, os.SEEK_SET)
+
+        err = {self.file_field: [f""Unsupported upload type: {actual}""]}
+
+        mimetypes = aslist(
+            config.get(f""ckan.upload.{self.object_type}.mimetypes""))
+        if mimetypes and actual not in mimetypes:
+            raise logic.ValidationError(err)
+
+        type_ = actual.split(""/"")[0]
+        types = aslist(
+            config.get(f""ckan.upload.{self.object_type}.types""))
+        if types and type_ not in types:
+            raise logic.ValidationError(err)
+
 
 class ResourceUpload(object):
     def __init__(self, resource):
diff --git a/ckan/logic/action/create.py b/ckan/logic/action/create.py
index 3dcda38b1b3..6b384dd4d34 100644
--- a/ckan/logic/action/create.py
+++ b/ckan/logic/action/create.py
@@ -762,6 +762,9 @@ def _group_or_org_create(context, data_dict, is_org=False):
     }
     logic.get_action('activity_create')(activity_create_context, activity_dict)
 
+    if hasattr(upload, ""verify_type""):
+        upload.verify_type()
+
     upload.upload(uploader.get_max_image_size())
 
     if not context.get('defer_commit'):
@@ -1012,6 +1015,9 @@ def user_create(context, data_dict):
     }
     logic.get_action('activity_create')(activity_create_context, activity_dict)
 
+    if hasattr(upload, ""verify_type""):
+        upload.verify_type()
+
     upload.upload(uploader.get_max_image_size())
 
     if not context.get('defer_commit'):
diff --git a/ckan/tests/logic/action/test_create.py b/ckan/tests/logic/action/test_create.py
index 186fa9ac611..52988eaea24 100644
--- a/ckan/tests/logic/action/test_create.py
+++ b/ckan/tests/logic/action/test_create.py
@@ -1666,7 +1666,7 @@ def test_ignored_on_create_if_non_sysadmin(self):
 
 @pytest.mark.usefixtures(""clean_db"")
 class TestUserImageUrl(object):
-    def test_upload_picture(self):
+    def test_external_picture(self):
 
         params = {
             ""name"": ""test_user"",
@@ -1682,6 +1682,56 @@ def test_upload_picture(self):
             user_dict[""image_display_url""] == ""https://example.com/mypic.png""
         )
 
+    def test_upload_non_picture_works_without_extra_config(
+            self, create_with_upload, faker):
+        params = {
+            ""name"": faker.user_name(),
+            ""email"": faker.email(),
+            ""password"": ""12345678"",
+            ""action"": ""user_create"",
+            ""upload_field_name"": ""image_upload"",
+        }
+        assert create_with_upload(""hello world"", ""file.txt"", **params)
+
+    @pytest.mark.ckan_config(""ckan.upload.user.types"", ""image"")
+    def test_upload_non_picture(self, create_with_upload, faker):
+        params = {
+            ""name"": faker.user_name(),
+            ""email"": faker.email(),
+            ""password"": ""12345678"",
+            ""action"": ""user_create"",
+            ""upload_field_name"": ""image_upload"",
+        }
+        with pytest.raises(
+                logic.ValidationError, match=""Unsupported upload type""):
+            create_with_upload(""hello world"", ""file.txt"", **params)
+
+    @pytest.mark.ckan_config(""ckan.upload.user.types"", ""image"")
+    def test_upload_non_picture_with_png_extension(
+            self, create_with_upload, faker):
+        params = {
+            ""name"": faker.user_name(),
+            ""email"": faker.email(),
+            ""password"": ""12345678"",
+            ""action"": ""user_create"",
+            ""upload_field_name"": ""image_upload"",
+        }
+        with pytest.raises(
+                logic.ValidationError, match=""Unsupported upload type""):
+            create_with_upload(""hello world"", ""file.png"", **params)
+
+    @pytest.mark.ckan_config(""ckan.upload.user.types"", ""image"")
+    def test_upload_picture(self, create_with_upload, faker):
+        params = {
+            ""name"": faker.user_name(),
+            ""email"": faker.email(),
+            ""password"": ""12345678"",
+            ""action"": ""user_create"",
+            ""upload_field_name"": ""image_upload"",
+        }
+        assert create_with_upload(faker.image(), ""file.png"", **params)
+
+
 
 class TestVocabularyCreate(object):
     @pytest.mark.usefixtures(""clean_db"")
diff --git a/dev-requirements.txt b/dev-requirements.txt
index fb1c976d1c7..13e0ff86b38 100644
--- a/dev-requirements.txt
+++ b/dev-requirements.txt
@@ -4,12 +4,14 @@ beautifulsoup4==4.9.3
 cookiecutter==1.7.3
 coveralls   #Let Unpinned - Requires latest coveralls
 docutils==0.16
+Faker==9.3.1
 factory-boy==3.2.0
 flask-debugtoolbar==0.11.0
 freezegun==1.1.0
 ipdb==0.13.7
 pip-tools==5.1.2
 pycodestyle==2.5.0
+Pillow==8.4.0
 responses==0.13.3
 sphinx-rtd-theme==0.4.3
 sphinx==1.8.5"
CVE-2012-4573,"From efd7e75b1f419a52c7103c7840e24af8e5deb29d Mon Sep 17 00:00:00 2001
From: Brian Waldon <bcwaldon@gmail.com>
Date: Wed, 7 Nov 2012 10:06:43 -0500
Subject: [PATCH] Ensure image owned by user before delayed_deletion

Fixes bug 1065187.

Change-Id: Icf2f117a094c712bad645ef5f297e9f7da994c84
---
 glance/api/v1/images.py | 9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/glance/api/v1/images.py b/glance/api/v1/images.py
index 9bedf204df..1a8eac8b54 100644
--- a/glance/api/v1/images.py
+++ b/glance/api/v1/images.py
@@ -727,6 +727,15 @@ def delete(self, req, id):
                                 content_type=""text/plain"")
 
         image = self.get_image_meta_or_404(req, id)
+
+        if not (req.context.is_admin
+                or image['owner'] == None
+                or image['owner'] == req.context.owner):
+            msg = _(""Unable to delete image you do not own"")
+            logger.debug(msg)
+            raise HTTPForbidden(msg, request=req,
+                                content_type=""text/plain"")
+
         if image['protected']:
             msg = _(""Image is protected"")
             logger.debug(msg)"
GHSA-6r3c-8xf3-ggrr,"From f870c52398a55b9b5189932dd8caa24efb4bc1e1 Mon Sep 17 00:00:00 2001
From: Matt Molyneaux <moggers87+git@moggers87.co.uk>
Date: Wed, 17 Jun 2020 21:57:49 +0100
Subject: [PATCH] Merge pull request from GHSA-6r3c-8xf3-ggrr

* Fix directory traversal bug

First try for the fix.

Sanitization is done always on the url path. Removed
_convert_file_to_url()

* Restore use of _convert_file_to_url

This is now done for all backends, assuming that SENDFILE_URL is set

Also don't keep converting from Path object to str and back again

* Fix example application so it works again

* Update docs

Co-authored-by: Gianluca Pacchiella <gianluca.pacchiella@ktln2.org>
---
 .gitignore                                    |  1 +
 django_sendfile/backends/_internalredirect.py | 16 ----
 django_sendfile/backends/mod_wsgi.py          |  2 +-
 django_sendfile/backends/nginx.py             |  5 +-
 django_sendfile/backends/simple.py            | 20 +++--
 django_sendfile/tests.py                      | 79 ++++++++++++++++---
 django_sendfile/utils.py                      | 60 ++++++++++++--
 docs/backends.rst                             | 14 +---
 docs/getting-started.rst                      | 11 ++-
 .../protected_downloads/download/models.py    |  2 +-
 .../templates/download/download_list.html     |  0
 examples/protected_downloads/download/urls.py |  5 +-
 .../protected_downloads/download/views.py     | 13 ++-
 examples/protected_downloads/settings.py      | 21 ++++-
 14 files changed, 178 insertions(+), 71 deletions(-)
 delete mode 100644 django_sendfile/backends/_internalredirect.py
 rename examples/protected_downloads/{ => download}/templates/download/download_list.html (100%)

diff --git a/.gitignore b/.gitignore
index b74ec6f..17dd736 100644
--- a/.gitignore
+++ b/.gitignore
@@ -13,3 +13,4 @@
 .tox
 /examples/protected_downloads/htmlcov
 /examples/protected_downloads/.coverage
+/examples/protected_downloads/protected
diff --git a/django_sendfile/backends/_internalredirect.py b/django_sendfile/backends/_internalredirect.py
deleted file mode 100644
index 24bced6..0000000
--- a/django_sendfile/backends/_internalredirect.py
+++ /dev/null
@@ -1,16 +0,0 @@
-from urllib.parse import quote
-import os.path
-
-from django.conf import settings
-
-
-def _convert_file_to_url(filename):
-    relpath = os.path.relpath(filename, settings.SENDFILE_ROOT)
-
-    url = [settings.SENDFILE_URL]
-
-    while relpath:
-        relpath, head = os.path.split(relpath)
-        url.insert(1, head)
-
-    return quote('/'.join(url))
diff --git a/django_sendfile/backends/mod_wsgi.py b/django_sendfile/backends/mod_wsgi.py
index 7fcd104..07ba3f1 100644
--- a/django_sendfile/backends/mod_wsgi.py
+++ b/django_sendfile/backends/mod_wsgi.py
@@ -2,7 +2,7 @@
 
 from django.http import HttpResponse
 
-from ._internalredirect import _convert_file_to_url
+from ..utils import _convert_file_to_url
 
 
 def sendfile(request, filename, **kwargs):
diff --git a/django_sendfile/backends/nginx.py b/django_sendfile/backends/nginx.py
index 29dc348..8764309 100644
--- a/django_sendfile/backends/nginx.py
+++ b/django_sendfile/backends/nginx.py
@@ -2,12 +2,11 @@
 
 from django.http import HttpResponse
 
-from ._internalredirect import _convert_file_to_url
+from ..utils import _convert_file_to_url
 
 
 def sendfile(request, filename, **kwargs):
     response = HttpResponse()
-    url = _convert_file_to_url(filename)
-    response['X-Accel-Redirect'] = url.encode('utf-8')
+    response['X-Accel-Redirect'] = _convert_file_to_url(filename)
 
     return response
diff --git a/django_sendfile/backends/simple.py b/django_sendfile/backends/simple.py
index 11bc02c..0549b20 100644
--- a/django_sendfile/backends/simple.py
+++ b/django_sendfile/backends/simple.py
@@ -1,25 +1,29 @@
 from email.utils import mktime_tz, parsedate_tz
-import os
 import re
-import stat
 
 from django.core.files.base import File
 from django.http import HttpResponse, HttpResponseNotModified
 from django.utils.http import http_date
 
 
-def sendfile(request, filename, **kwargs):
-    # Respect the If-Modified-Since header.
-    statobj = os.stat(filename)
+def sendfile(request, filepath, **kwargs):
+    '''Use the SENDFILE_ROOT value composed with the path arrived as argument
+    to build an absolute path with which resolve and return the file contents.
+
+    If the path points to a file out of the root directory (should cover both
+    situations with '..' and symlinks) then a 404 is raised.
+    '''
+    statobj = filepath.stat()
 
+    # Respect the If-Modified-Since header.
     if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
-                              statobj[stat.ST_MTIME], statobj[stat.ST_SIZE]):
+                              statobj.st_mtime, statobj.st_size):
         return HttpResponseNotModified()
 
-    with File(open(filename, 'rb')) as f:
+    with File(filepath.open('rb')) as f:
         response = HttpResponse(f.chunks())
 
-    response[""Last-Modified""] = http_date(statobj[stat.ST_MTIME])
+    response[""Last-Modified""] = http_date(statobj.st_mtime)
     return response
 
 
diff --git a/django_sendfile/tests.py b/django_sendfile/tests.py
index f95b915..71c6279 100644
--- a/django_sendfile/tests.py
+++ b/django_sendfile/tests.py
@@ -6,6 +6,7 @@
 import shutil
 
 from django.conf import settings
+from django.core.exceptions import ImproperlyConfigured
 from django.http import Http404, HttpRequest, HttpResponse
 from django.test import TestCase
 from django.utils.encoding import smart_str
@@ -25,12 +26,22 @@ class TempFileTestCase(TestCase):
     def setUp(self):
         super(TempFileTestCase, self).setUp()
         self.TEMP_FILE_ROOT = mkdtemp()
+        self.setSendfileRoot(self.TEMP_FILE_ROOT)
 
     def tearDown(self):
         super(TempFileTestCase, self).tearDown()
         if os.path.exists(self.TEMP_FILE_ROOT):
             shutil.rmtree(self.TEMP_FILE_ROOT)
 
+    def setSendfileBackend(self, backend):
+        '''set the backend clearing the cache'''
+        settings.SENDFILE_BACKEND = backend
+        _get_sendfile.cache_clear()
+
+    def setSendfileRoot(self, path):
+        '''set the backend clearing the cache'''
+        settings.SENDFILE_ROOT = path
+
     def ensure_file(self, filename):
         path = os.path.join(self.TEMP_FILE_ROOT, filename)
         if not os.path.exists(path):
@@ -43,12 +54,21 @@ class TestSendfile(TempFileTestCase):
     def setUp(self):
         super(TestSendfile, self).setUp()
         # set ourselves to be the sendfile backend
-        settings.SENDFILE_BACKEND = 'django_sendfile.tests'
-        _get_sendfile.cache_clear()
+        self.setSendfileBackend('django_sendfile.tests')
 
     def _get_readme(self):
         return self.ensure_file('testfile.txt')
 
+    def test_backend_is_none(self):
+        self.setSendfileBackend(None)
+        with self.assertRaises(ImproperlyConfigured):
+            real_sendfile(HttpRequest(), ""notafile.txt"")
+
+    def test_root_is_none(self):
+        self.setSendfileRoot(None)
+        with self.assertRaises(ImproperlyConfigured):
+            real_sendfile(HttpRequest(), ""notafile.txt"")
+
     def test_404(self):
         try:
             real_sendfile(HttpRequest(), 'fhdsjfhjk.txt')
@@ -102,12 +122,33 @@ def test_attachment_filename_unicode(self):
                          response['Content-Disposition'])
 
 
+class TestSimpleSendfileBackend(TempFileTestCase):
+
+    def setUp(self):
+        super().setUp()
+        self.setSendfileBackend('django_sendfile.backends.simple')
+
+    def test_correct_file(self):
+        filepath = self.ensure_file('readme.txt')
+        response = real_sendfile(HttpRequest(), filepath)
+        self.assertTrue(response is not None)
+
+    def test_containing_unicode(self):
+        filepath = self.ensure_file(u'pter_l_gueule.txt')
+        response = real_sendfile(HttpRequest(), filepath)
+        self.assertTrue(response is not None)
+
+    def test_sensible_file_access_in_simplesendfile(self):
+        filepath = self.ensure_file('../../../etc/passwd')
+        with self.assertRaises(Http404):
+            real_sendfile(HttpRequest(), filepath)
+
+
 class TestXSendfileBackend(TempFileTestCase):
 
     def setUp(self):
         super(TestXSendfileBackend, self).setUp()
-        settings.SENDFILE_BACKEND = 'django_sendfile.backends.xsendfile'
-        _get_sendfile.cache_clear()
+        self.setSendfileBackend('django_sendfile.backends.xsendfile')
 
     def test_correct_file_in_xsendfile_header(self):
         filepath = self.ensure_file('readme.txt')
@@ -126,21 +167,30 @@ class TestNginxBackend(TempFileTestCase):
 
     def setUp(self):
         super(TestNginxBackend, self).setUp()
-        settings.SENDFILE_BACKEND = 'django_sendfile.backends.nginx'
-        settings.SENDFILE_ROOT = self.TEMP_FILE_ROOT
+        self.setSendfileBackend('django_sendfile.backends.nginx')
         settings.SENDFILE_URL = '/private'
-        _get_sendfile.cache_clear()
+
+    def test_sendfile_url_not_set(self):
+        settings.SENDFILE_URL = None
+        filepath = self.ensure_file('readme.txt')
+        response = real_sendfile(HttpRequest(), filepath)
+        self.assertTrue(response is not None)
+        self.assertEqual(response.content, b'')
+        self.assertEqual(os.path.join(self.TEMP_FILE_ROOT, 'readme.txt'),
+                         response['X-Accel-Redirect'])
 
     def test_correct_url_in_xaccelredirect_header(self):
         filepath = self.ensure_file('readme.txt')
         response = real_sendfile(HttpRequest(), filepath)
         self.assertTrue(response is not None)
+        self.assertEqual(response.content, b'')
         self.assertEqual('/private/readme.txt', response['X-Accel-Redirect'])
 
     def test_xaccelredirect_header_containing_unicode(self):
         filepath = self.ensure_file(u'pter_l_gueule.txt')
         response = real_sendfile(HttpRequest(), filepath)
         self.assertTrue(response is not None)
+        self.assertEqual(response.content, b'')
         self.assertEqual('/private/pter_l_gueule.txt', unquote(response['X-Accel-Redirect']))
 
 
@@ -148,19 +198,28 @@ class TestModWsgiBackend(TempFileTestCase):
 
     def setUp(self):
         super(TestModWsgiBackend, self).setUp()
-        settings.SENDFILE_BACKEND = 'django_sendfile.backends.mod_wsgi'
-        settings.SENDFILE_ROOT = self.TEMP_FILE_ROOT
+        self.setSendfileBackend('django_sendfile.backends.mod_wsgi')
         settings.SENDFILE_URL = '/private'
-        _get_sendfile.cache_clear()
+
+    def test_sendfile_url_not_set(self):
+        settings.SENDFILE_URL = None
+        filepath = self.ensure_file('readme.txt')
+        response = real_sendfile(HttpRequest(), filepath)
+        self.assertTrue(response is not None)
+        self.assertEqual(response.content, b'')
+        self.assertEqual(os.path.join(self.TEMP_FILE_ROOT, 'readme.txt'),
+                         response['Location'])
 
     def test_correct_url_in_location_header(self):
         filepath = self.ensure_file('readme.txt')
         response = real_sendfile(HttpRequest(), filepath)
         self.assertTrue(response is not None)
+        self.assertEqual(response.content, b'')
         self.assertEqual('/private/readme.txt', response['Location'])
 
     def test_location_header_containing_unicode(self):
         filepath = self.ensure_file(u'pter_l_gueule.txt')
         response = real_sendfile(HttpRequest(), filepath)
         self.assertTrue(response is not None)
+        self.assertEqual(response.content, b'')
         self.assertEqual('/private/pter_l_gueule.txt', unquote(response['Location']))
diff --git a/django_sendfile/utils.py b/django_sendfile/utils.py
index 25d117a..e5579f4 100644
--- a/django_sendfile/utils.py
+++ b/django_sendfile/utils.py
@@ -1,7 +1,9 @@
 from functools import lru_cache
 from importlib import import_module
 from mimetypes import guess_type
-import os.path
+from pathlib import Path, PurePath
+from urllib.parse import quote
+import logging
 import unicodedata
 
 from django.conf import settings
@@ -10,6 +12,8 @@
 from django.utils.encoding import force_str
 from django.utils.http import urlquote
 
+logger = logging.getLogger(__name__)
+
 
 @lru_cache(maxsize=None)
 def _get_sendfile():
@@ -20,6 +24,45 @@ def _get_sendfile():
     return module.sendfile
 
 
+def _convert_file_to_url(path):
+    try:
+        url_root = PurePath(getattr(settings, ""SENDFILE_URL"", None))
+    except TypeError:
+        return path
+
+    path_root = PurePath(settings.SENDFILE_ROOT)
+    path_obj = PurePath(path)
+
+    relpath = path_obj.relative_to(path_root)
+    # Python 3.5: Path.resolve() has no `strict` kwarg, so use pathmod from an
+    # already instantiated Path object
+    url = relpath._flavour.pathmod.normpath(str(url_root / relpath))
+
+    return quote(str(url))
+
+
+def _sanitize_path(filepath):
+    try:
+        path_root = Path(getattr(settings, 'SENDFILE_ROOT', None))
+    except TypeError:
+        raise ImproperlyConfigured('You must specify a value for SENDFILE_ROOT')
+
+    filepath_obj = Path(filepath)
+
+    # get absolute path
+    # Python 3.5: Path.resolve() has no `strict` kwarg, so use pathmod from an
+    # already instantiated Path object
+    filepath_abs = Path(filepath_obj._flavour.pathmod.normpath(str(path_root / filepath_obj)))
+
+    # if filepath_abs is not relative to path_root, relative_to throws an error
+    try:
+        filepath_abs.relative_to(path_root)
+    except ValueError:
+        raise Http404('{} wrt {} is impossible'.format(filepath_abs, path_root))
+
+    return filepath_abs
+
+
 def sendfile(request, filename, attachment=False, attachment_filename=None,
              mimetype=None, encoding=None):
     """"""
@@ -41,25 +84,28 @@ def sendfile(request, filename, attachment=False, attachment_filename=None,
     If neither ``mimetype`` or ``encoding`` are specified, then they will be guessed via the
     filename (using the standard Python mimetypes module)
     """"""
+    filepath_obj = _sanitize_path(filename)
+    logger.debug('filename \'%s\' requested ""\
+        ""-> filepath \'%s\' obtained', filename, filepath_obj)
     _sendfile = _get_sendfile()
 
-    if not os.path.exists(filename):
-        raise Http404('""%s"" does not exist' % filename)
+    if not filepath_obj.exists():
+        raise Http404('""%s"" does not exist' % filepath_obj)
 
-    guessed_mimetype, guessed_encoding = guess_type(filename)
+    guessed_mimetype, guessed_encoding = guess_type(str(filepath_obj))
     if mimetype is None:
         if guessed_mimetype:
             mimetype = guessed_mimetype
         else:
             mimetype = 'application/octet-stream'
 
-    response = _sendfile(request, filename, mimetype=mimetype)
+    response = _sendfile(request, filepath_obj, mimetype=mimetype)
 
     # Suggest to view (inline) or download (attachment) the file
     parts = ['attachment' if attachment else 'inline']
 
     if attachment_filename is None:
-        attachment_filename = os.path.basename(filename)
+        attachment_filename = filepath_obj.name
 
     if attachment_filename:
         attachment_filename = force_str(attachment_filename)
@@ -73,7 +119,7 @@ def sendfile(request, filename, attachment=False, attachment_filename=None,
 
     response['Content-Disposition'] = '; '.join(parts)
 
-    response['Content-length'] = os.path.getsize(filename)
+    response['Content-length'] = filepath_obj.stat().st_size
     response['Content-Type'] = mimetype
 
     if not encoding:
diff --git a/docs/backends.rst b/docs/backends.rst
index 9d6b0ac..7c77a94 100644
--- a/docs/backends.rst
+++ b/docs/backends.rst
@@ -43,10 +43,8 @@ embedded mode.  It requires a bit more work to get it to do the same job as
 xsendfile though.  However some may find it easier to setup, as they don't need
 to compile and install mod_xsendfile_.
 
-Firstly there are two more Django settings:
+Firstly there one more Django setting that needs to be given:
 
-* ``SENDFILE_ROOT`` - this is a directoy where all files that will be used with
-  sendfile must be located
 * ``SENDFILE_URL`` - internal URL prefix for all files served via sendfile
 
 These settings are needed as this backend makes mod_wsgi_ send an internal
@@ -93,10 +91,8 @@ Nginx backend
 
 :py:mod:`django_sendfile.backends.nginx`
 
-As with the mod_wsgi backend you need to set two extra settings:
+As with the mod_wsgi backend you need to set an extra settings:
 
-* ``SENDFILE_ROOT`` - this is a directory where all files that will be used with
-  sendfile must be located
 * ``SENDFILE_URL`` - internal URL prefix for all files served via sendfile
 
 You then need to configure Nginx to only allow internal access to the files you
@@ -141,12 +137,6 @@ configure mod_xsendfile_, but that should be as simple as:
 
 In your virtualhost file/conf file.
 
-As with the mod_wsgi backend you need to set two extra settings:
-
-* ``SENDFILE_ROOT`` - this is a directory where all files that will be used with
-  sendfile must be located
-* ``SENDFILE_URL`` - internal URL prefix for all files served via sendfile
-
 
 .. _mod_xsendfile: https://tn123.org/mod_xsendfile/
 .. _Apache: http://httpd.apache.org/
diff --git a/docs/getting-started.rst b/docs/getting-started.rst
index 8bd3c5e..a9b5ec4 100644
--- a/docs/getting-started.rst
+++ b/docs/getting-started.rst
@@ -17,9 +17,14 @@ And then add ``django_sendfile`` to ``INSTALLED_APPS`` in your settings module.
     It is not strictly nessessary to have django_sendfile in
     ``INSTALLED_APPS``, but this may change in future.
 
-You will also need to select a backend via ``SENDFILE_BACKEND`` in your
-settings module. Additionally, you may need to set ``SENDFILE_URL`` and
-``SENDFILE_ROOT``. See the :doc:`backends` documentation for more details.
+
+You will need to have the following set in your settings module:
+
+* ``SENDFILE_BACKEND`` - the dotted module notation of the backend you wish to use
+* ``SENDFILE_ROOT`` - the directory you wish to serve files from
+
+Additionally, you may need to set ``SENDFILE_URL`` . See the :doc:`backends`
+documentation for more details.
 
 
 Use In Views
diff --git a/examples/protected_downloads/download/models.py b/examples/protected_downloads/download/models.py
index 912e4d7..709fc4b 100644
--- a/examples/protected_downloads/download/models.py
+++ b/examples/protected_downloads/download/models.py
@@ -20,7 +20,7 @@ def __unicode__(self):
         return self.title
 
     def get_absolute_url(self):
-        return reverse('download', [self.pk], {})
+        return reverse('download', kwargs={""download_id"": self.pk})
 
     class Meta:
         app_label = ""download""
diff --git a/examples/protected_downloads/templates/download/download_list.html b/examples/protected_downloads/download/templates/download/download_list.html
similarity index 100%
rename from examples/protected_downloads/templates/download/download_list.html
rename to examples/protected_downloads/download/templates/download/download_list.html
diff --git a/examples/protected_downloads/download/urls.py b/examples/protected_downloads/download/urls.py
index 1af6826..2ce8a63 100644
--- a/examples/protected_downloads/download/urls.py
+++ b/examples/protected_downloads/download/urls.py
@@ -1,8 +1,9 @@
 from django.conf import urls
 
-from .views import download, download_list
+from .views import direct_download, download, download_list
 
 urlpatterns = [
-    urls.url(r'^$', download_list),
     urls.url(r'(?P<download_id>\d+)/$', download, name='download'),
+    urls.url(r'^$', download_list),
+    urls.url(r'direct/(?P<filename>.*)$', direct_download, name='direct_download'),
 ]
diff --git a/examples/protected_downloads/download/views.py b/examples/protected_downloads/download/views.py
index a06f929..e3f671c 100644
--- a/examples/protected_downloads/download/views.py
+++ b/examples/protected_downloads/download/views.py
@@ -2,7 +2,6 @@
 from django.db.models import Q
 from django.http import HttpResponseForbidden
 from django.shortcuts import get_object_or_404, render
-from django.template import RequestContext
 
 from django_sendfile import sendfile
 
@@ -25,10 +24,16 @@ def _auth_download(request, download):
 
 def download_list(request):
     downloads = Download.objects.all()
-    if request.user.is_authenticated():
+    if request.user.is_authenticated:
         downloads = downloads.filter(Q(is_public=True) | Q(users=request.user))
     else:
         downloads = downloads.filter(is_public=True)
     return render(request, 'download/download_list.html',
-                  {'download_list': downloads},
-                  context_instance=RequestContext(request))
+                  {'download_list': downloads})
+
+
+def direct_download(request, filename=None):
+    if not filename:
+        filename = request.GET.get(""filename"")
+
+    return sendfile(request, filename)
diff --git a/examples/protected_downloads/settings.py b/examples/protected_downloads/settings.py
index 147b4a2..29d4322 100644
--- a/examples/protected_downloads/settings.py
+++ b/examples/protected_downloads/settings.py
@@ -19,6 +19,21 @@
     }
 }
 
+LOGGING = {
+    'version': 1,
+    'disable_existing_loggers': False,
+    'handlers': {
+        'console': {
+            'class': 'logging.StreamHandler',
+        },
+    },
+    'loggers': {
+        'django_sendfile': {
+            'handlers': ['console'],
+            'level': os.getenv('DJANGO_LOG_LEVEL', 'INFO'),
+        },
+    },
+}
 # Local time zone for this installation. Choices can be found here:
 # http://en.wikipedia.org/wiki/List_of_tz_zones_by_name
 # although not all choices may be available on all operating systems.
@@ -69,12 +84,10 @@
             ""django.contrib.auth.context_processors.auth"",
             ""django.contrib.messages.context_processors.messages"",
         ],
-        'loaders': [
-            (
+        'loaders': (
                 'django.template.loaders.filesystem.Loader',
                 'django.template.loaders.app_directories.Loader',
-            ),
-        ],
+        ),
         'debug': DEBUG,
     },
 }]"
GHSA-g4rf-pc26-6hmr,"From 952f8e5d28532fbb14fb665982211329d137908c Mon Sep 17 00:00:00 2001
From: Jean-Marie Burel <j.burel@dundee.ac.uk>
Date: Wed, 17 Mar 2021 08:35:48 +0000
Subject: [PATCH] SV commits

---
 CHANGELOG.md                                  |  4 ++
 omeroweb/decorators.py                        |  3 +-
 omeroweb/settings.py                          | 30 ++++++++
 omeroweb/webclient/decorators.py              |  4 +-
 omeroweb/webclient/forms.py                   | 18 -----
 .../static/webclient/javascript/ome.tree.js   |  4 +-
 .../webclient/base/base_container.html        |  2 +-
 .../base/includes/toolbar_forms.html          | 69 +++----------------
 .../templates/webclient/data/containers.html  |  8 +--
 .../templates/webclient/public/public.html    | 10 ++-
 omeroweb/webclient/views.py                   | 59 +++++-----------
 .../templates/webgateway/core_html.html       |  1 +
 omeroweb/webgateway/views.py                  |  4 +-
 13 files changed, 84 insertions(+), 132 deletions(-)

diff --git a/CHANGELOG.md b/CHANGELOG.md
index b4d6f6312b..ec753baf23 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -22,6 +22,10 @@
 - Fix partial loading of annotations ([#256](https://github.com/ome/omero-web/pull/256))
 - Fix ignored limit in webgateway/table endpoint ([#268](https://github.com/ome/omero-web/pull/268))
 
+- Security vulnerability fixes for
+  [2021-SV1](https://www.openmicroscopy.org/security/advisories/2021-SV1-user-context/),
+  [2021-SV2](https://www.openmicroscopy.org/security/advisories/2021-SV2-url-validation/)
+
 5.8.1 (September 2020)
 ----------------------
 
diff --git a/omeroweb/decorators.py b/omeroweb/decorators.py
index 8ab85d4b43..b7cf301777 100644
--- a/omeroweb/decorators.py
+++ b/omeroweb/decorators.py
@@ -582,7 +582,8 @@ def __getattr__(self, name):
 
     def prepare_context(self, request, context, *args, **kwargs):
         """""" Hook for adding additional data to the context dict """"""
-        pass
+        context[""html""] = context.get(""html"", {})
+        context[""html""][""meta_referrer""] = settings.HTML_META_REFERRER
 
     def __call__(ctx, f):
         """""" Here we wrap the view method f and return the wrapped method """"""
diff --git a/omeroweb/settings.py b/omeroweb/settings.py
index 521f05d369..b7f6446e91 100644
--- a/omeroweb/settings.py
+++ b/omeroweb/settings.py
@@ -508,6 +508,12 @@ def leave_none_unset_int(s):
         leave_none_unset,
         ""The name to use for session cookies"",
     ],
+    ""omero.web.session_cookie_path"": [
+        ""SESSION_COOKIE_PATH"",
+        None,
+        leave_none_unset,
+        ""The path to use for session cookies"",
+    ],
     ""omero.web.session_cookie_secure"": [
         ""SESSION_COOKIE_SECURE"",
         ""false"",
@@ -866,6 +872,16 @@ def leave_none_unset_int(s):
             ' {""experimenter"": -1}}\'``'
         ),
     ],
+    ""omero.web.redirect_allowed_hosts"": [
+        ""REDIRECT_ALLOWED_HOSTS"",
+        ""[]"",
+        json.loads,
+        (
+            ""If you wish to allow redirects to an external site, ""
+            ""the domains must be listed here. ""
+            'For example [""openmicroscopy.org""].'
+        ),
+    ],
     ""omero.web.login.show_client_downloads"": [
         ""SHOW_CLIENT_DOWNLOADS"",
         ""true"",
@@ -1022,6 +1038,20 @@ def leave_none_unset_int(s):
             ""will be authorized to make cross-site HTTP requests.""
         ),
     ],
+    ""omero.web.html_meta_referrer"": [
+        ""HTML_META_REFERRER"",
+        ""origin-when-crossorigin"",
+        str,
+        (
+            ""Default content for the HTML Meta referrer tag. ""
+            ""See https://www.w3.org/TR/referrer-policy/#referrer-policies for ""
+            ""allowed values and https://caniuse.com/#feat=referrer-policy for ""
+            ""browser compatibility. ""
+            ""Warning: Internet Explorer 11 does not support the default value ""
+            'of this setting, you may want to change this to ""origin"" after '
+            ""reviewing the linked documentation.""
+        ),
+    ],
     ""omero.web.x_frame_options"": [
         ""X_FRAME_OPTIONS"",
         ""SAMEORIGIN"",
diff --git a/omeroweb/webclient/decorators.py b/omeroweb/webclient/decorators.py
index 591fa878db..eea31b00db 100644
--- a/omeroweb/webclient/decorators.py
+++ b/omeroweb/webclient/decorators.py
@@ -35,7 +35,6 @@
 
 from omeroweb.webclient.forms import GlobalSearchForm
 from omeroweb.utils import reverse_with_params
-from omeroweb.webgateway.marshal import eventContextMarshal
 
 logger = logging.getLogger(__name__)
 
@@ -116,6 +115,8 @@ def prepare_context(self, request, context, *args, **kwargs):
         context.
         """"""
 
+        super(render_response, self).prepare_context(request, context, *args, **kwargs)
+
         # we expect @login_required to pass us 'conn', but just in case...
         if ""conn"" not in kwargs:
             return
@@ -134,7 +135,6 @@ def prepare_context(self, request, context, *args, **kwargs):
         public_user = omeroweb.decorators.is_public_user(request)
         if public_user is not None:
             context[""ome""][""is_public_user""] = public_user
-        context[""ome""][""eventContext""] = eventContextMarshal(conn.getEventContext())
         context[""ome""][""user""] = conn.getUser
         context[""ome""][""user_id""] = request.session.get(""user_id"", conn.getUserId())
         context[""ome""][""group_id""] = request.session.get(""group_id"", None)
diff --git a/omeroweb/webclient/forms.py b/omeroweb/webclient/forms.py
index f31c95a5e9..6ac495d2a4 100644
--- a/omeroweb/webclient/forms.py
+++ b/omeroweb/webclient/forms.py
@@ -37,7 +37,6 @@
 from .custom_forms import AnnotationModelMultipleChoiceField
 from .custom_forms import ObjectModelMultipleChoiceField
 from omeroweb.webadmin.custom_forms import ExperimenterModelMultipleChoiceField
-from omeroweb.webadmin.custom_forms import GroupModelMultipleChoiceField
 from omeroweb.webadmin.custom_forms import GroupModelChoiceField
 from omeroweb.webclient.webclient_utils import formatPercentFraction
 
@@ -127,23 +126,6 @@ def clean_expiration(self):
         return self.cleaned_data[""expiration""]
 
 
-class BasketShareForm(ShareForm):
-    def __init__(self, *args, **kwargs):
-        super(BasketShareForm, self).__init__(*args, **kwargs)
-
-        try:
-            self.fields[""image""] = GroupModelMultipleChoiceField(
-                queryset=kwargs[""initial""][""images""],
-                initial=kwargs[""initial""][""selected""],
-                widget=forms.SelectMultiple(attrs={""size"": 10}),
-            )
-        except Exception:
-            self.fields[""image""] = GroupModelMultipleChoiceField(
-                queryset=kwargs[""initial""][""images""],
-                widget=forms.SelectMultiple(attrs={""size"": 10}),
-            )
-
-
 class ContainerForm(NonASCIIForm):
 
     name = forms.CharField(max_length=250, widget=forms.TextInput(attrs={""size"": 45}))
diff --git a/omeroweb/webclient/static/webclient/javascript/ome.tree.js b/omeroweb/webclient/static/webclient/javascript/ome.tree.js
index eefa1b2502..204746f388 100644
--- a/omeroweb/webclient/static/webclient/javascript/ome.tree.js
+++ b/omeroweb/webclient/static/webclient/javascript/ome.tree.js
@@ -1151,8 +1151,8 @@ $(function() {
 
                 var userId = WEBCLIENT.active_user.id,
                     // admin may be viewing a Group that they are not a member of
-                    memberOfGroup = WEBCLIENT.eventContext.memberOfGroups.indexOf(WEBCLIENT.active_group_id) > -1,
-                    writeOwned = WEBCLIENT.eventContext.adminPrivileges.indexOf(""WriteOwned"") > -1,
+                    memberOfGroup = WEBCLIENT.member_of_groups.indexOf(WEBCLIENT.active_group_id) > -1,
+                    writeOwned = WEBCLIENT.current_admin_privileges.indexOf(""WriteOwned"") > -1,
                     allMembers = userId === -1,
                     // canCreate if looking at your own data or 'All Members' OR User's data && writeOwned
                     canCreate = (userId === WEBCLIENT.USER.id || (allMembers && memberOfGroup) ||
diff --git a/omeroweb/webclient/templates/webclient/base/base_container.html b/omeroweb/webclient/templates/webclient/base/base_container.html
index 6efb62e300..b30c11c478 100644
--- a/omeroweb/webclient/templates/webclient/base/base_container.html
+++ b/omeroweb/webclient/templates/webclient/base/base_container.html
@@ -166,7 +166,7 @@
         WEBCLIENT.active_group_id = {{ active_group.id }};
         WEBCLIENT.USER = {'id': {{ ome.user.id }}, 'fullName': ""{{ ome.user.getFullName }}""};
         WEBCLIENT.active_user = {'id': {{ ome.user_id }}, 'fullName': ""{{ active_user.getFullName }}""};
-        WEBCLIENT.eventContext = {{ ome.eventContext|json_dumps|safe }};
+        WEBCLIENT.member_of_groups = {{ member_of_groups|json_dumps|safe }};
         WEBCLIENT.isAdmin = {% if ome.user.isAdmin %}true{% else %}false{% endif %};
         WEBCLIENT.CAN_CREATE = {{ ome.can_create|json_dumps|safe }};
         WEBCLIENT.current_admin_privileges = {{ current_admin_privileges|json_dumps|safe }};
diff --git a/omeroweb/webclient/templates/webclient/base/includes/toolbar_forms.html b/omeroweb/webclient/templates/webclient/base/includes/toolbar_forms.html
index ef58b6f5e2..4c8d7dd131 100644
--- a/omeroweb/webclient/templates/webclient/base/includes/toolbar_forms.html
+++ b/omeroweb/webclient/templates/webclient/base/includes/toolbar_forms.html
@@ -3,7 +3,7 @@
 
 {% comment %}
 <!--
-  Copyright (C) 2011 University of Dundee & Open Microscopy Environment.
+  Copyright (C) 2011-2021 University of Dundee & Open Microscopy Environment.
   All rights reserved.
   This program is free software: you can redistribute it and/or modify
   it under the terms of the GNU Affero General Public License as
@@ -25,82 +25,33 @@
 if (typeof OME === ""undefined"") { OME={}; }
 
     OME.createShare = function() {
-
-        var productListQuery = [];
-
-        // we do inst.get_selected() here, since we then get objects
-        // instead of ids for some reason?
-        var inst = $.jstree.reference('#dataTree');
-        data = inst.get_selected(true);
-        data.forEach(function(node){
-            productListQuery.push(node.type + ""="" + node.data.id);
-        });
-
-        var query = '{% url 'manage_action_containers' ""add"" ""share"" %}' + ""?""+productListQuery.join(""&"");
         $(""#create_share_form"").dialog(""open"");
-        $(""#create_share_form"").attr(""action"", query)
-        $(""#create_share_form"").load(query);
         return false;
     }
 
     $(document).ready(function(){
 
-        // AJAX handling of create-discussion form
-        $(""#create_share_form"").ajaxForm({
-            success: function(html) {
-                if (html.indexOf(""shareId"") > -1) {
-                    var shareId = html.replace(""shareId:"", """");
-                    $(""#create_share_form"").dialog( ""close"" );
-                    $(""#shareCreatedId"").text(shareId);
-                    $(""#share_dialog_form"").dialog(""open"").show();
-                } else {
-                    $(""#create_share_form"").html(html);
-                }
-            },
-        });
-
-        $(""#share_dialog_form"").dialog({
-            autoOpen: false,
-            resizable: true,
-            height: 150,
-            width:300,
-            modal: true,
-            buttons: {
-                ""OK"": function() {
-                    $( this ).dialog( ""close"" );
-                }
-            }
-        });
-
         $(""#create_share_form"").dialog({
+            title: ""Shares not supported"",
             autoOpen: false,
             resizable: true,
-            height: 600,
+            height: 250,
             width:450,
             modal: true,
             buttons: {
-                ""Accept"": function() {
-                    // simply submit the form
-                    $(""#create_share_form"").submit();
-                },
-                ""Cancel"": function() {
+                ""OK"": function() {
                     $( this ).dialog( ""close"" );
                 }
             }
         });
-
-
     });
 </script>
 
 
-
-<!-- hidden form for creating share - shown in dialog & loaded by AJAX -->
-<form id=""create_share_form"" action=""#"" method=""post"" title=""Create Share"" class=""standard_form"">{% csrf_token %}
-</form>
-
-<form id=""share_dialog_form"" action=""#"" title=""Create Share"" style=""display:none"">
-    <p style=""font-size: 120%; font-weight: bold"">
-        Share <span id=""shareCreatedId""></span> was created successfully.
+<!-- hidden dialog -->
+<div id=""create_share_form"" style=""display:none"">
+    <p>Share functionality is no longer supported.</p>
+    <p>Please see <a target=""_blank"" href=""https://www.openmicroscopy.org/omero/features/share/"">Sharing your data in OMERO</a>
+        for alternative workflows.
     </p>
-</form>
+</div>
diff --git a/omeroweb/webclient/templates/webclient/data/containers.html b/omeroweb/webclient/templates/webclient/data/containers.html
index e6e3d8b7fc..835962a9fb 100644
--- a/omeroweb/webclient/templates/webclient/data/containers.html
+++ b/omeroweb/webclient/templates/webclient/data/containers.html
@@ -208,9 +208,9 @@
             // If we are filtering to show another user's data,
             // we 'should' have writeOwned privilege
 
-            var writeOwned = WEBCLIENT.eventContext.adminPrivileges.indexOf(""WriteOwned"") > -1;
+            var writeOwned = WEBCLIENT.current_admin_privileges.indexOf(""WriteOwned"") > -1;
             var $f = $(""#new-container-form"");
-            var memberOfGroup = WEBCLIENT.eventContext.memberOfGroups.indexOf(WEBCLIENT.active_group_id) > -1;
+            var memberOfGroup = WEBCLIENT.member_of_groups.indexOf(WEBCLIENT.active_group_id) > -1;
 
             // clear fields
             $(""input[name='owner']"", $f).val("""");
@@ -289,8 +289,8 @@
 
             // We 'canCreate' top level items, E.g. Project, Dataset, Screen, if the current userId is self or 'All Members'
             var userId = {{ ome.user_id }},
-                memberOfGroup = WEBCLIENT.eventContext.memberOfGroups.indexOf(WEBCLIENT.active_group_id) > -1,
-                writeOwned = WEBCLIENT.eventContext.adminPrivileges.indexOf(""WriteOwned"") > -1,
+                memberOfGroup = WEBCLIENT.member_of_groups.indexOf(WEBCLIENT.active_group_id) > -1,
+                writeOwned = WEBCLIENT.current_admin_privileges.indexOf(""WriteOwned"") > -1,
                 allMembers = userId === -1,
                 // canCreate if looking at your own data or 'All Members' OR User's data with writeOwned
                 canCreate = (userId === WEBCLIENT.USER.id || (allMembers && memberOfGroup) ||
diff --git a/omeroweb/webclient/templates/webclient/public/public.html b/omeroweb/webclient/templates/webclient/public/public.html
index 59e65f0080..16c38e022e 100644
--- a/omeroweb/webclient/templates/webclient/public/public.html
+++ b/omeroweb/webclient/templates/webclient/public/public.html
@@ -489,7 +489,15 @@
 
 <div class=""left_panel_tree_container"">
 
-    <div id=""tree_details"" class=""left_panel_tree"">
+    <div style=""height: 110px; padding: 15px; box-sizing: border-box;"">
+        <p>Creating new shares is no longer supported. Previously created shares are shown below.</p>
+        <p>Please see <a target=""_blank"" href=""https://www.openmicroscopy.org/omero/features/share/"">Sharing your data in
+                OMERO</a>
+            for alternative workflows.
+        </p>
+    </div>
+
+    <div id=""tree_details"" class=""left_panel_tree"" style=""height: calc(100% - 110px)"">
         <div class=""datashareTree"" id=""dataTree""></div>
     </div>
 
diff --git a/omeroweb/webclient/views.py b/omeroweb/webclient/views.py
index ea17b390fa..e3972ac099 100755
--- a/omeroweb/webclient/views.py
+++ b/omeroweb/webclient/views.py
@@ -35,6 +35,7 @@
 import warnings
 from past.builtins import unicode
 from future.utils import bytes_to_native_str
+from django.utils.http import is_safe_url
 
 from time import time
 
@@ -67,7 +68,7 @@
 
 from omeroweb.webclient.webclient_utils import _formatReport, _purgeCallback
 from .forms import GlobalSearchForm, ContainerForm
-from .forms import ShareForm, BasketShareForm
+from .forms import ShareForm
 from .forms import ContainerNameForm, ContainerDescriptionForm
 from .forms import CommentAnnotationForm, TagsAnnotationForm
 from .forms import MetadataFilterForm, MetadataDetectorForm
@@ -176,6 +177,17 @@ def get_bool_or_default(request, name, default):
     return toBoolean(request.GET.get(name, default))
 
 
+def validate_redirect_url(url):
+    """"""
+    Returns a URL is safe to redirect to.
+    If url is a different host, not in settings.REDIRECT_ALLOWED_HOSTS
+    we return webclient index URL.
+    """"""
+    if not is_safe_url(url, allowed_hosts=settings.REDIRECT_ALLOWED_HOSTS):
+        url = reverse(""webindex"")
+    return url
+
+
 ##############################################################################
 # custom index page
 
@@ -257,6 +269,8 @@ def handle_logged_in(self, request, conn, connector):
                 url = parse_url(settings.LOGIN_REDIRECT)
             except Exception:
                 url = reverse(""webindex"")
+        else:
+            url = validate_redirect_url(url)
         return HttpResponseRedirect(url)
 
     def handle_not_logged_in(self, request, error=None, form=None):
@@ -335,6 +349,7 @@ def change_active_group(request, conn=None, url=None, **kwargs):
     """"""
     switch_active_group(request)
     url = url or reverse(""webindex"")
+    url = validate_redirect_url(url)
     return HttpResponseRedirect(url)
 
 
@@ -534,6 +549,7 @@ def _load_template(request, menu, conn=None, url=None, **kwargs):
     context[""thumbnails_batch""] = settings.THUMBNAILS_BATCH
     context[""current_admin_privileges""] = conn.getCurrentAdminPrivileges()
     context[""leader_of_groups""] = conn.getEventContext().leaderOfGroups
+    context[""member_of_groups""] = conn.getEventContext().memberOfGroups
 
     return context
 
@@ -2871,47 +2887,6 @@ def manage_action_containers(
                 d.update({e[0]: unicode(e[1])})
             rdict = {""bad"": ""true"", ""errs"": d}
             return JsonResponse(rdict)
-    elif action == ""add"":
-        template = ""webclient/public/share_form.html""
-        experimenters = list(conn.getExperimenters())
-        experimenters.sort(key=lambda x: x.getOmeName().lower())
-        if o_type == ""share"":
-            img_ids = request.GET.getlist(""image"", request.POST.getlist(""image""))
-            if request.method == ""GET"" and len(img_ids) == 0:
-                return HttpResponse(""No images specified"")
-            images_to_share = list(conn.getObjects(""Image"", img_ids))
-            if request.method == ""POST"":
-                form = BasketShareForm(
-                    initial={""experimenters"": experimenters, ""images"": images_to_share},
-                    data=request.POST.copy(),
-                )
-                if form.is_valid():
-                    images = form.cleaned_data[""image""]
-                    message = form.cleaned_data[""message""]
-                    expiration = form.cleaned_data[""expiration""]
-                    members = form.cleaned_data[""members""]
-                    # guests = request.POST['guests']
-                    enable = form.cleaned_data[""enable""]
-                    host = ""%s?server=%i"" % (
-                        request.build_absolute_uri(
-                            reverse(""load_template"", args=[""public""])
-                        ),
-                        int(conn.server_id),
-                    )
-                    shareId = manager.createShare(
-                        host, images, message, members, enable, expiration
-                    )
-                    return HttpResponse(""shareId:%s"" % shareId)
-            else:
-                initial = {
-                    ""experimenters"": experimenters,
-                    ""images"": images_to_share,
-                    ""enable"": True,
-                    ""selected"": request.GET.getlist(""image""),
-                }
-                form = BasketShareForm(initial=initial)
-        template = ""webclient/public/share_form.html""
-        context = {""manager"": manager, ""form"": form}
 
     elif action == ""edit"":
         # form for editing Shares only
diff --git a/omeroweb/webgateway/templates/webgateway/core_html.html b/omeroweb/webgateway/templates/webgateway/core_html.html
index b2a992acd7..6e39032827 100644
--- a/omeroweb/webgateway/templates/webgateway/core_html.html
+++ b/omeroweb/webgateway/templates/webgateway/core_html.html
@@ -25,6 +25,7 @@
 
 <head>
     <meta http-equiv=""X-UA-Compatible"" content=""IE=Edge"" />
+    <meta name=""referrer"" content=""{{ html.meta_referrer|default:""origin-when-crossorigin"" }}"">
 
     {% block link %}
 		<link rel=""stylesheet"" href=""{% static ""webgateway/css/reset.css""|add:url_suffix %}"" type=""text/css"" />   
diff --git a/omeroweb/webgateway/views.py b/omeroweb/webgateway/views.py
index a7b6167d82..eb3dba2d58 100644
--- a/omeroweb/webgateway/views.py
+++ b/omeroweb/webgateway/views.py
@@ -2960,10 +2960,10 @@ def _table_query(request, fileid, conn=None, query=None, lazy=False, **kwargs):
             limit = (
                 int(request.GET.get(""limit""))
                 if request.GET.get(""limit"") is not None
-                else None
+                else rows
             )
         range_start = offset
-        range_size = kwargs.get(""limit"", rows)
+        range_size = limit
         range_end = min(rows, range_start + range_size)
 
         if query == ""*"":"
GHSA-8jxq-75rw-fhj9,"From f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98 Mon Sep 17 00:00:00 2001
From: Nicola Iarocci <nicola@nicolaiarocci.com>
Date: Sun, 14 Jan 2018 17:51:26 +0100
Subject: [PATCH] fix mongo visitor parser

---
 eve/io/mongo/parser.py | 15 +++++++++------
 1 file changed, 9 insertions(+), 6 deletions(-)

diff --git a/eve/io/mongo/parser.py b/eve/io/mongo/parser.py
index 6b751203b..ac633c098 100644
--- a/eve/io/mongo/parser.py
+++ b/eve/io/mongo/parser.py
@@ -122,16 +122,19 @@ def visit_Call(self, node):
         datetime().
         """"""
         if isinstance(node.func, ast.Name):
-            expr = None
             if node.func.id == 'ObjectId':
-                expr = ""('"" + node.args[0].s + ""')""
+                try:
+                    self.current_value = ObjectId(node.args[0].s)
+                except:
+                    pass
             elif node.func.id == 'datetime':
                 values = []
                 for arg in node.args:
-                    values.append(str(arg.n))
-                expr = ""("" + "", "".join(values) + "")""
-            if expr:
-                self.current_value = eval(node.func.id + expr)
+                    values.append(arg.n)
+                try:
+                    self.current_value = datetime(*values)
+                except:
+                    pass
 
     def visit_Attribute(self, node):
         """""" Attribute handler ('Contact.Id')."
GHSA-wvcv-832q-fjg7,"From 793ba7ad984a08dd9e8b320c70cd45bc7dcb2a88 Mon Sep 17 00:00:00 2001
From: Hubert Kario <hkario@redhat.com>
Date: Thu, 26 Nov 2020 16:07:59 +0100
Subject: [PATCH 1/5] stop conversion from bytes to int to bytes with m2crypto

with M2Crypto we can process byte strings, and for padding/depadding
we need bytes, so don't convert back and forth between the
formats

also put all the integer to bytes conversion in a single place
for the implementations that can't handle bytes as input
---
 tlslite/utils/openssl_rsakey.py |  8 ++++
 tlslite/utils/rsakey.py         | 68 +++++++++++++++++----------------
 2 files changed, 43 insertions(+), 33 deletions(-)

diff --git a/tlslite/utils/openssl_rsakey.py b/tlslite/utils/openssl_rsakey.py
index 71cb1033..84b659c4 100644
--- a/tlslite/utils/openssl_rsakey.py
+++ b/tlslite/utils/openssl_rsakey.py
@@ -65,12 +65,20 @@ def _rawPrivateKeyOp(self, m):
             c = bytesToNumber(bytearray(s))
             return c
 
+        def _raw_private_key_op_bytes(self, message):
+            return bytearray(m2.rsa_private_encrypt(self.rsa, bytes(message),
+                                                    m2.no_padding))
+
         def _rawPublicKeyOp(self, c):
             b = numberToByteArray(c, numBytes(self.n))
             s = m2.rsa_public_decrypt(self.rsa, bytes(b), m2.no_padding)
             m = bytesToNumber(bytearray(s))
             return m
 
+        def _raw_public_key_op_bytes(self, ciphertext):
+            return bytearray(m2.rsa_public_decrypt(self.rsa, bytes(ciphertext),
+                                                   m2.no_padding))
+
         def acceptsPassword(self): return True
 
         def write(self, password=None):
diff --git a/tlslite/utils/rsakey.py b/tlslite/utils/rsakey.py
index 5c8c675b..026ba6f9 100644
--- a/tlslite/utils/rsakey.py
+++ b/tlslite/utils/rsakey.py
@@ -187,12 +187,11 @@ def RSASSA_PSS_sign(self, mHash, hAlg, sLen=0):
         :type sLen: int
         :param sLen: length of salt""""""
         EM = self.EMSA_PSS_encode(mHash, numBits(self.n) - 1, hAlg, sLen)
-        m = bytesToNumber(EM)
-        if m >= self.n:
+        try:
+            ret = self._raw_private_key_op_bytes(EM)
+        except ValueError:
             raise MessageTooLongError(""Encode output too long"")
-        s = self._rawPrivateKeyOp(m)
-        S = numberToByteArray(s, numBytes(self.n))
-        return S
+        return ret
 
     def EMSA_PSS_verify(self, mHash, EM, emBits, hAlg, sLen=0):
         """"""Verify signature in passed in encoded message
@@ -264,11 +263,10 @@ def RSASSA_PSS_verify(self, mHash, S, hAlg, sLen=0):
         :type sLen: int
         :param sLen: Length of salt
         """"""
-        if len(bytearray(S)) != len(numberToByteArray(self.n)):
+        try:
+            EM = self._raw_public_key_op_bytes(S)
+        except ValueError:
             raise InvalidSignature(""Invalid signature"")
-        s = bytesToNumber(S)
-        m = self._rawPublicKeyOp(s)
-        EM = numberToByteArray(m, divceil(numBits(self.n) - 1, 8))
         result = self.EMSA_PSS_verify(mHash, EM, numBits(self.n) - 1,
                                       hAlg, sLen)
         if result:
@@ -281,12 +279,7 @@ def _raw_pkcs1_sign(self, bytes):
         if not self.hasPrivateKey():
             raise AssertionError()
         paddedBytes = self._addPKCS1Padding(bytes, 1)
-        m = bytesToNumber(paddedBytes)
-        if m >= self.n:
-            raise ValueError()
-        c = self._rawPrivateKeyOp(m)
-        sigBytes = numberToByteArray(c, numBytes(self.n))
-        return sigBytes
+        return self._raw_private_key_op_bytes(paddedBytes)
 
     def sign(self, bytes, padding='pkcs1', hashAlg=None, saltLen=None):
         """"""Sign the passed-in bytes.
@@ -326,14 +319,11 @@ def sign(self, bytes, padding='pkcs1', hashAlg=None, saltLen=None):
 
     def _raw_pkcs1_verify(self, sigBytes, bytes):
         """"""Perform verification operation on raw PKCS#1 padded signature""""""
-        if len(sigBytes) != numBytes(self.n):
+        try:
+            checkBytes = self._raw_public_key_op_bytes(sigBytes)
+        except ValueError:
             return False
         paddedBytes = self._addPKCS1Padding(bytes, 1)
-        c = bytesToNumber(sigBytes)
-        if c >= self.n:
-            return False
-        m = self._rawPublicKeyOp(c)
-        checkBytes = numberToByteArray(m, numBytes(self.n))
         return checkBytes == paddedBytes
 
     def verify(self, sigBytes, bytes, padding='pkcs1', hashAlg=None,
@@ -384,12 +374,7 @@ def encrypt(self, bytes):
         :returns: A PKCS1 encryption of the passed-in data.
         """"""
         paddedBytes = self._addPKCS1Padding(bytes, 2)
-        m = bytesToNumber(paddedBytes)
-        if m >= self.n:
-            raise ValueError()
-        c = self._rawPublicKeyOp(m)
-        encBytes = numberToByteArray(c, numBytes(self.n))
-        return encBytes
+        return self._raw_public_key_op_bytes(paddedBytes)
 
     def decrypt(self, encBytes):
         """"""Decrypt the passed-in bytes.
@@ -406,13 +391,10 @@ def decrypt(self, encBytes):
         """"""
         if not self.hasPrivateKey():
             raise AssertionError()
-        if len(encBytes) != numBytes(self.n):
+        try:
+            decBytes = self._raw_private_key_op_bytes(encBytes)
+        except ValueError:
             return None
-        c = bytesToNumber(encBytes)
-        if c >= self.n:
-            return None
-        m = self._rawPrivateKeyOp(c)
-        decBytes = numberToByteArray(m, numBytes(self.n))
         #Check first two bytes
         if decBytes[0] != 0 or decBytes[1] != 2:
             return None
@@ -430,6 +412,26 @@ def _rawPrivateKeyOp(self, m):
     def _rawPublicKeyOp(self, c):
         raise NotImplementedError()
 
+    def _raw_private_key_op_bytes(self, message):
+        n = self.n
+        if len(message) != numBytes(n):
+            raise ValueError(""Message has incorrect length for the key size"")
+        m_int = bytesToNumber(message)
+        if m_int >= n:
+            raise ValueError(""Provided message value exceeds modulus"")
+        dec_int = self._rawPrivateKeyOp(m_int)
+        return numberToByteArray(dec_int, numBytes(n))
+
+    def _raw_public_key_op_bytes(self, ciphertext):
+        n = self.n
+        if len(ciphertext) != numBytes(n):
+            raise ValueError(""Message has incorrect length for the key size"")
+        c_int = bytesToNumber(ciphertext)
+        if c_int > n:
+            raise ValueError(""Provided message value exceeds modulus"")
+        enc_int = self._rawPublicKeyOp(c_int)
+        return numberToByteArray(enc_int, numBytes(n))
+
     def acceptsPassword(self):
         """"""Return True if the write() method accepts a password for use
         in encrypting the private key.

From 80de0509309bd756fc52a0329ce1c44ca8f97fa9 Mon Sep 17 00:00:00 2001
From: Hubert Kario <hkario@redhat.com>
Date: Thu, 3 Dec 2020 17:16:32 +0100
Subject: [PATCH 2/5] add ct_lsb_prop_u16

---
 tlslite/utils/constanttime.py                 | 17 ++++++++++++++++-
 unit_tests/test_tlslite_utils_constanttime.py | 10 +++++++++-
 2 files changed, 25 insertions(+), 2 deletions(-)

diff --git a/tlslite/utils/constanttime.py b/tlslite/utils/constanttime.py
index d4f5b1ce..950fca0c 100644
--- a/tlslite/utils/constanttime.py
+++ b/tlslite/utils/constanttime.py
@@ -23,6 +23,7 @@ def ct_lt_u32(val_a, val_b):
 
     return (val_a^((val_a^val_b)|(((val_a-val_b)&0xffffffff)^val_b)))>>31
 
+
 def ct_gt_u32(val_a, val_b):
     """"""
     Return 1 if val_a > val_b, 0 otherwise. Constant time.
@@ -35,6 +36,7 @@ def ct_gt_u32(val_a, val_b):
     """"""
     return ct_lt_u32(val_b, val_a)
 
+
 def ct_le_u32(val_a, val_b):
     """"""
     Return 1 if val_a <= val_b, 0 otherwise. Constant time.
@@ -47,14 +49,26 @@ def ct_le_u32(val_a, val_b):
     """"""
     return 1 ^ ct_gt_u32(val_a, val_b)
 
+
 def ct_lsb_prop_u8(val):
-    """"""Propagate LSB to all 8 bits of the returned byte. Constant time.""""""
+    """"""Propagate LSB to all 8 bits of the returned int. Constant time.""""""
+    val &= 0x01
+    val |= val << 1
+    val |= val << 2
+    val |= val << 4
+    return val
+
+
+def ct_lsb_prop_u16(val):
+    """"""Propagate LSB to all 16 bits of the returned int. Constant time.""""""
     val &= 0x01
     val |= val << 1
     val |= val << 2
     val |= val << 4
+    val |= val << 8
     return val
 
+
 def ct_isnonzero_u32(val):
     """"""
     Returns 1 if val is != 0, 0 otherwise. Constant time.
@@ -66,6 +80,7 @@ def ct_isnonzero_u32(val):
     val &= 0xffffffff
     return (val|(-val&0xffffffff)) >> 31
 
+
 def ct_neq_u32(val_a, val_b):
     """"""
     Return 1 if val_a != val_b, 0 otherwise. Constant time.
diff --git a/unit_tests/test_tlslite_utils_constanttime.py b/unit_tests/test_tlslite_utils_constanttime.py
index 0a6446d0..2c04da5c 100644
--- a/unit_tests/test_tlslite_utils_constanttime.py
+++ b/unit_tests/test_tlslite_utils_constanttime.py
@@ -11,7 +11,7 @@
 
 from tlslite.utils.constanttime import ct_lt_u32, ct_gt_u32, ct_le_u32, \
         ct_lsb_prop_u8, ct_isnonzero_u32, ct_neq_u32, ct_eq_u32, \
-        ct_check_cbc_mac_and_pad, ct_compare_digest
+        ct_check_cbc_mac_and_pad, ct_compare_digest, ct_lsb_prop_u16
 
 from hypothesis import given, example
 import hypothesis.strategies as st
@@ -80,6 +80,14 @@ def test_ct_lsb_prop_u8(self, i):
         self.assertEqual(((i & 0x1) == 1), (ct_lsb_prop_u8(i) == 0xff))
         self.assertEqual(((i & 0x1) == 0), (ct_lsb_prop_u8(i) == 0x00))
 
+    @given(i=st.integers(0, 2**16-1))
+    @example(i=0)
+    @example(i=255)
+    @example(i=2**16-1)
+    def test_ct_lsb_prop_u16(self, i):
+        self.assertEqual(((i & 0x1) == 1), (ct_lsb_prop_u16(i) == 0xffff))
+        self.assertEqual(((i & 0x1) == 0), (ct_lsb_prop_u16(i) == 0x0000))
+
     @given(i=st.integers(0,2**32 - 1))
     @example(i=0)
     def test_ct_isnonzero_u32(self, i):

From c653fd7586165f8ec7548ffe68128b84064101c2 Mon Sep 17 00:00:00 2001
From: Hubert Kario <hkario@redhat.com>
Date: Thu, 3 Dec 2020 17:21:58 +0100
Subject: [PATCH 3/5] expose the private exponent (d) with all backends

---
 tlslite/utils/keyfactory.py     | 16 +++++++++-------
 tlslite/utils/openssl_rsakey.py |  8 ++++++++
 2 files changed, 17 insertions(+), 7 deletions(-)

diff --git a/tlslite/utils/keyfactory.py b/tlslite/utils/keyfactory.py
index 2e31fd91..dbacd5c7 100644
--- a/tlslite/utils/keyfactory.py
+++ b/tlslite/utils/keyfactory.py
@@ -107,21 +107,23 @@ def parsePEMKey(s, private=False, public=False, passwordCallback=None,
 
 
 def _parseKeyHelper(key, private, public):
-    if private:
-        if not key.hasPrivateKey():
-            raise SyntaxError(""Not a private key!"")
+    if private and not key.hasPrivateKey():
+        raise SyntaxError(""Not a private key!"")
 
     if public:
         return _createPublicKey(key)
 
     if private:
-        if hasattr(key, ""d""):
-            return _createPrivateKey(key)
-        else:
+        if cryptomath.m2cryptoLoaded:
+            if type(key) == Python_RSAKey:
+                return _createPrivateKey(key)
+            assert type(key) in (OpenSSL_RSAKey, ), type(key)
             return key
-
+        elif hasattr(key, ""d""):
+            return _createPrivateKey(key)
     return key
 
+
 def parseAsPublicKey(s):
     """"""Parse a PEM-formatted public key.
 
diff --git a/tlslite/utils/openssl_rsakey.py b/tlslite/utils/openssl_rsakey.py
index 84b659c4..e5377690 100644
--- a/tlslite/utils/openssl_rsakey.py
+++ b/tlslite/utils/openssl_rsakey.py
@@ -8,6 +8,7 @@
 from .rsakey import *
 from .python_rsakey import Python_RSAKey
 from .compat import compatAscii2Bytes
+import sys
 
 #copied from M2Crypto.util.py, so when we load the local copy of m2
 #we can still use it
@@ -154,6 +155,13 @@ def f():pass
                         key._hasPrivateKey = False
                     else:
                         raise SyntaxError()
+                    if key._hasPrivateKey:
+                        if sys.version_info < (3, 0):
+                            b64_key = str(key.write())
+                        else:
+                            b64_key = str(key.write(), ""ascii"")
+                        py_key = Python_RSAKey.parsePEM(b64_key)
+                        key.d = py_key.d
                     return key
                 finally:
                     m2.bio_free(bio)

From eaffaa93c89cf25ff3e8964e6053b44b8cd74c31 Mon Sep 17 00:00:00 2001
From: Hubert Kario <hkario@redhat.com>
Date: Mon, 7 Dec 2020 21:17:43 +0100
Subject: [PATCH 4/5] add rough public key parser

---
 tlslite/utils/python_key.py    | 130 +++++++++++++++++++++++++++++++++
 tlslite/utils/python_rsakey.py |  77 +------------------
 2 files changed, 133 insertions(+), 74 deletions(-)
 create mode 100644 tlslite/utils/python_key.py

diff --git a/tlslite/utils/python_key.py b/tlslite/utils/python_key.py
new file mode 100644
index 00000000..356ff1bb
--- /dev/null
+++ b/tlslite/utils/python_key.py
@@ -0,0 +1,130 @@
+
+
+from .python_rsakey import Python_RSAKey
+from .pem import dePem, pemSniff
+from .asn1parser import ASN1Parser
+from .cryptomath import bytesToNumber
+
+
+class Python_Key(object):
+    """"""
+    Generic methods for parsing private keys from files.
+
+    Handles both RSA and ECDSA keys, irrespective of file format.
+    """"""
+
+    @staticmethod
+    def parsePEM(s, passwordCallback=None):
+        """"""Parse a string containing a PEM-encoded <privateKey>.""""""
+
+        if pemSniff(s, ""PRIVATE KEY""):
+            bytes = dePem(s, ""PRIVATE KEY"")
+            return Python_Key._parse_pkcs8(bytes)
+        elif pemSniff(s, ""RSA PRIVATE KEY""):
+            bytes = dePem(s, ""RSA PRIVATE KEY"")
+            return Python_Key._parse_ssleay(bytes)
+        elif pemSniff(s, ""DSA PRIVATE KEY""):
+            raise SyntaxError(""DSA private key files unsupported"")
+        elif pemSniff(s, ""EC PRIVATE KEY""):
+            raise SyntaxError(""ECDSA private key files unsupported"")
+        elif pemSniff(s, ""PUBLIC KEY""):
+            bytes = dePem(s, ""PUBLIC KEY"")
+            return Python_Key._parse_public_key(bytes)
+        else:
+            raise SyntaxError(""Not a PEM private key file"")
+
+    @staticmethod
+    def _parse_public_key(bytes):
+        # public keys are encoded as the subject_public_key_info objects
+        spk_info = ASN1Parser(bytes)
+
+        # first element of the SEQUENCE is the AlgorithmIdentifier
+        alg_id = spk_info.getChild(0)
+
+        # AlgId has two elements, the OID of the algorithm and parameters
+        # parameters generally have to be NULL, with exception of RSA-PSS
+
+        alg_oid = alg_id.getChild(0)
+
+        if list(alg_oid.value) != [42, 134, 72, 134, 247, 13, 1, 1, 1]:
+            raise SyntaxError(""Only RSA Public keys supported"")
+
+        subject_public_key = ASN1Parser(
+            ASN1Parser(spk_info.getChildBytes(1)).value[1:])
+
+        modulus = subject_public_key.getChild(0)
+        exponent = subject_public_key.getChild(1)
+
+        n = bytesToNumber(modulus.value)
+        e = bytesToNumber(exponent.value)
+
+        return Python_RSAKey(n, e)
+
+    @staticmethod
+    def _parse_pkcs8(bytes):
+        parser = ASN1Parser(bytes)
+
+        # first element in PrivateKeyInfo is an INTEGER
+        version = parser.getChild(0).value
+        if bytesToNumber(version) != 0:
+            raise SyntaxError(""Unrecognized PKCS8 version"")
+
+        # second element in PrivateKeyInfo is a SEQUENCE of type
+        # AlgorithmIdentifier
+        alg_ident = parser.getChild(1)
+        seq_len = alg_ident.getChildCount()
+        # first item of AlgorithmIdentifier is an OBJECT (OID)
+        oid = alg_ident.getChild(0)
+        if list(oid.value) == [42, 134, 72, 134, 247, 13, 1, 1, 1]:
+            key_type = ""rsa""
+        elif list(oid.value) == [42, 134, 72, 134, 247, 13, 1, 1, 10]:
+            key_type = ""rsa-pss""
+        else:
+            raise SyntaxError(""Unrecognized AlgorithmIdentifier: {0}""
+                              .format(list(oid.value)))
+        # second item of AlgorithmIdentifier are parameters (defined by
+        # above algorithm)
+        if key_type == ""rsa"":
+            if seq_len != 2:
+                raise SyntaxError(""Missing parameters for RSA algorithm ID"")
+            parameters = alg_ident.getChild(1)
+            if parameters.value != bytearray(0):
+                raise SyntaxError(""RSA parameters are not NULL"")
+        else:  # rsa-pss
+            pass  # ignore parameters - don't apply restrictions
+
+        if seq_len > 2:
+            raise SyntaxError(""Invalid encoding of AlgorithmIdentifier"")
+
+        #Get the privateKey
+        private_key_parser = parser.getChild(2)
+
+        #Adjust for OCTET STRING encapsulation
+        private_key_parser = ASN1Parser(private_key_parser.value)
+
+        return Python_Key._parse_asn1_private_key(private_key_parser)
+
+    @staticmethod
+    def _parse_ssleay(data):
+        """"""
+        Parse binary structure of the old SSLeay file format used by OpenSSL.
+
+        For RSA keys.
+        """"""
+        private_key_parser = ASN1Parser(data)
+        return Python_Key._parse_asn1_private_key(private_key_parser)
+
+    @staticmethod
+    def _parse_asn1_private_key(private_key_parser):
+        version = private_key_parser.getChild(0).value[0]
+        if version != 0:
+            raise SyntaxError(""Unrecognized RSAPrivateKey version"")
+        n = bytesToNumber(private_key_parser.getChild(1).value)
+        e = bytesToNumber(private_key_parser.getChild(2).value)
+        d = bytesToNumber(private_key_parser.getChild(3).value)
+        p = bytesToNumber(private_key_parser.getChild(4).value)
+        q = bytesToNumber(private_key_parser.getChild(5).value)
+        dP = bytesToNumber(private_key_parser.getChild(6).value)
+        dQ = bytesToNumber(private_key_parser.getChild(7).value)
+        qInv = bytesToNumber(private_key_parser.getChild(8).value)
+        return Python_RSAKey(n, e, d, p, q, dP, dQ, qInv)
diff --git a/tlslite/utils/python_rsakey.py b/tlslite/utils/python_rsakey.py
index 91387493..100f7e84 100644
--- a/tlslite/utils/python_rsakey.py
+++ b/tlslite/utils/python_rsakey.py
@@ -86,79 +86,8 @@ def generate(bits):
         return key
     generate = staticmethod(generate)
 
+    @staticmethod
     def parsePEM(s, passwordCallback=None):
         """"""Parse a string containing a PEM-encoded <privateKey>.""""""
-
-        if pemSniff(s, ""PRIVATE KEY""):
-            bytes = dePem(s, ""PRIVATE KEY"")
-            return Python_RSAKey._parsePKCS8(bytes)
-        elif pemSniff(s, ""RSA PRIVATE KEY""):
-            bytes = dePem(s, ""RSA PRIVATE KEY"")
-            return Python_RSAKey._parseSSLeay(bytes)
-        else:
-            raise SyntaxError(""Not a PEM private key file"")
-    parsePEM = staticmethod(parsePEM)
-
-    def _parsePKCS8(bytes):
-        p = ASN1Parser(bytes)
-
-        # first element in PrivateKeyInfo is an INTEGER
-        version = p.getChild(0).value
-        if bytesToNumber(version) != 0:
-            raise SyntaxError(""Unrecognized PKCS8 version"")
-
-        # second element in PrivateKeyInfo is a SEQUENCE of type
-        # AlgorithmIdentifier
-        algIdent = p.getChild(1)
-        seqLen = algIdent.getChildCount()
-        # first item of AlgorithmIdentifier is an OBJECT (OID)
-        oid = algIdent.getChild(0)
-        if list(oid.value) == [42, 134, 72, 134, 247, 13, 1, 1, 1]:
-            keyType = ""rsa""
-        elif list(oid.value) == [42, 134, 72, 134, 247, 13, 1, 1, 10]:
-            keyType = ""rsa-pss""
-        else:
-            raise SyntaxError(""Unrecognized AlgorithmIdentifier: {0}""
-                              .format(list(oid.value)))
-        # second item of AlgorithmIdentifier are parameters (defined by
-        # above algorithm)
-        if keyType == ""rsa"":
-            if seqLen != 2:
-                raise SyntaxError(""Missing parameters for RSA algorithm ID"")
-            parameters = algIdent.getChild(1)
-            if parameters.value != bytearray(0):
-                raise SyntaxError(""RSA parameters are not NULL"")
-        else:  # rsa-pss
-            pass  # ignore parameters - don't apply restrictions
-
-        if seqLen > 2:
-            raise SyntaxError(""Invalid encoding of AlgorithmIdentifier"")
-
-        #Get the privateKey
-        privateKeyP = p.getChild(2)
-
-        #Adjust for OCTET STRING encapsulation
-        privateKeyP = ASN1Parser(privateKeyP.value)
-
-        return Python_RSAKey._parseASN1PrivateKey(privateKeyP)
-    _parsePKCS8 = staticmethod(_parsePKCS8)
-
-    def _parseSSLeay(bytes):
-        privateKeyP = ASN1Parser(bytes)
-        return Python_RSAKey._parseASN1PrivateKey(privateKeyP)
-    _parseSSLeay = staticmethod(_parseSSLeay)
-
-    def _parseASN1PrivateKey(privateKeyP):
-        version = privateKeyP.getChild(0).value[0]
-        if version != 0:
-            raise SyntaxError(""Unrecognized RSAPrivateKey version"")
-        n = bytesToNumber(privateKeyP.getChild(1).value)
-        e = bytesToNumber(privateKeyP.getChild(2).value)
-        d = bytesToNumber(privateKeyP.getChild(3).value)
-        p = bytesToNumber(privateKeyP.getChild(4).value)
-        q = bytesToNumber(privateKeyP.getChild(5).value)
-        dP = bytesToNumber(privateKeyP.getChild(6).value)
-        dQ = bytesToNumber(privateKeyP.getChild(7).value)
-        qInv = bytesToNumber(privateKeyP.getChild(8).value)
-        return Python_RSAKey(n, e, d, p, q, dP, dQ, qInv)
-    _parseASN1PrivateKey = staticmethod(_parseASN1PrivateKey)
+        from .python_key import Python_Key
+        return Python_Key.parsePEM(s, passwordCallback)

From 2738f154a85795ea4a406d36353fba468700b6eb Mon Sep 17 00:00:00 2001
From: Hubert Kario <hkario@redhat.com>
Date: Thu, 3 Dec 2020 17:30:22 +0100
Subject: [PATCH 5/5] implement deterministic implicit rejection for RSA
 decryption

---
 tlslite/utils/compat.py                 |   14 +
 tlslite/utils/rsakey.py                 |  172 +++-
 unit_tests/test_tlslite_utils_rsakey.py | 1234 +++++++++++++++++++++++
 3 files changed, 1405 insertions(+), 15 deletions(-)

diff --git a/tlslite/utils/compat.py b/tlslite/utils/compat.py
index 7f019549..60f72c3a 100644
--- a/tlslite/utils/compat.py
+++ b/tlslite/utils/compat.py
@@ -5,6 +5,7 @@
 
 import sys
 import os
+import re
 import platform
 import math
 import binascii
@@ -68,6 +69,10 @@ def formatExceptionTrace(e):
         """"""Return exception information formatted as string""""""
         return str(e)
 
+    def remove_whitespace(text):
+        """"""Removes all whitespace from passed in string""""""
+        return re.sub(r""\s+"", """", text, flags=re.UNICODE)
+
 else:
     # Python 2.6 requires strings instead of bytearrays in a couple places,
     # so we define this function so it does the conversion if needed.
@@ -76,9 +81,18 @@ def formatExceptionTrace(e):
     if sys.version_info < (2, 7) or sys.version_info < (2, 7, 4) \
             or platform.system() == 'Java':
         def compat26Str(x): return str(x)
+
+        def remove_whitespace(text):
+            """"""Removes all whitespace from passed in string""""""
+            return re.sub(r""\s+"", """", text)
+
     else:
         def compat26Str(x): return x
 
+        def remove_whitespace(text):
+            """"""Removes all whitespace from passed in string""""""
+            return re.sub(r""\s+"", """", text, flags=re.UNICODE)
+
     def compatAscii2Bytes(val):
         """"""Convert ASCII string to bytes.""""""
         return val
diff --git a/tlslite/utils/rsakey.py b/tlslite/utils/rsakey.py
index 026ba6f9..e2bb8816 100644
--- a/tlslite/utils/rsakey.py
+++ b/tlslite/utils/rsakey.py
@@ -7,6 +7,8 @@
 from . import tlshashlib as hashlib
 from ..errors import MaskTooLongError, MessageTooLongError, EncodingError, \
     InvalidSignature, UnknownRSAType
+from .constanttime import ct_isnonzero_u32, ct_neq_u32, ct_lsb_prop_u8, \
+    ct_lsb_prop_u16, ct_lt_u32
 
 
 class RSAKey(object):
@@ -34,6 +36,7 @@ def __init__(self, n=0, e=0):
         :type e: int
         :param e: RSA public exponent.
         """"""
+        self._key_hash = None
         raise NotImplementedError()
 
     def __len__(self):
@@ -376,35 +379,174 @@ def encrypt(self, bytes):
         paddedBytes = self._addPKCS1Padding(bytes, 2)
         return self._raw_public_key_op_bytes(paddedBytes)
 
+    def _dec_prf(self, key, label, out_len):
+        """"""PRF for deterministic implicit rejection in the RSA decryption.
+
+        :param bytes key: key to use for derivation
+        :param bytes label: name of the keystream generated
+        :param int out_len: length of output, in bits
+        :rtype: bytes
+        :returns: a random bytestring
+        """"""
+        out = bytearray()
+
+        if out_len % 8 != 0:
+            raise ValueError(""only multiples of 8 supported as output size"")
+
+        iterator = 0
+        while len(out) < out_len // 8:
+            out += secureHMAC(
+                key,
+                numberToByteArray(iterator, 2) + label +
+                numberToByteArray(out_len, 2),
+                ""sha256"")
+            iterator += 1
+
+        return out[:out_len//8]
+
     def decrypt(self, encBytes):
         """"""Decrypt the passed-in bytes.
 
         This requires the key to have a private component.  It performs
-        PKCS1 decryption of the passed-in data.
+        PKCS#1 v1.5 decryption operation of the passed-in data.
+
+        Note: as a workaround against Bleichenbacher-like attacks, it will
+        return a deterministically selected random message in case the padding
+        checks failed. It returns an error (None) only in case the ciphertext
+        is of incorrect length or encodes an integer bigger than the modulus
+        of the key (i.e. it's publically invalid).
 
         :type encBytes: bytearray
         :param encBytes: The value which will be decrypted.
 
         :rtype: bytearray or None
-        :returns: A PKCS1 decryption of the passed-in data or None if
-            the data is not properly formatted.
+        :returns: A PKCS#1 v1.5 decryption of the passed-in data or None if
+            the provided data is not properly formatted. Note: encrypting
+            an empty string is correct, so it may return an empty bytearray
+            for some ciphertexts.
         """"""
         if not self.hasPrivateKey():
             raise AssertionError()
         try:
-            decBytes = self._raw_private_key_op_bytes(encBytes)
+            dec_bytes = self._raw_private_key_op_bytes(encBytes)
         except ValueError:
+            # _raw_private_key_op_bytes fails only when encBytes >= self.n,
+            # or when len(encBytes) != numBytes(self.n) and that's public
+            # information, so we don't have to handle it
+            # in sidechannel secure way
             return None
-        #Check first two bytes
-        if decBytes[0] != 0 or decBytes[1] != 2:
-            return None
-        #Scan through for zero separator
-        for x in range(1, len(decBytes)-1):
-            if decBytes[x]== 0:
-                break
-        else:
-            return None
-        return decBytes[x+1:] #Return everything after the separator
+
+        ###################
+        # here be dragons #
+        ###################
+        # While the code is written as-if it was side-channel secure, in
+        # practice, because of cPython implementation details IT IS NOT
+        # see:
+        # https://securitypitfalls.wordpress.com/2018/08/03/constant-time-compare-in-python/
+
+        n = self.n
+
+        # maximum length we can return is reduced by the mandatory prefix:
+        # (0x00 0x02), 8 bytes of padding, so this is the position of the
+        # null separator byte, as counted from the last position
+        max_sep_offset = numBytes(n) - 10
+
+        # the private exponent (d) doesn't change so `_key_hash` doesn't
+        # change, calculate it only once
+        if not hasattr(self, '_key_hash') or not self._key_hash:
+            self._key_hash = secureHash(numberToByteArray(self.d, numBytes(n)),
+                                        ""sha256"")
+
+        kdk = secureHMAC(self._key_hash, encBytes, ""sha256"")
+
+        # we need 128 2-byte numbers, encoded as the number of bits
+        length_randoms = self._dec_prf(kdk, b""length"", 128 * 2 * 8)
+
+        message_random = self._dec_prf(kdk, b""message"", numBytes(n) * 8)
+
+        # select the last length that's not too large to return
+        synth_length = 0
+        length_rand_iter = iter(length_randoms)
+        length_mask = (1 << numBits(max_sep_offset)) - 1
+        for high, low in zip(length_rand_iter, length_rand_iter):
+            # interpret the two bytes from the PRF output as 16-bit big-endian
+            # integer
+            len_candidate = (high << 8) + low
+            len_candidate &= length_mask
+            # equivalent to:
+            # if len_candidate < max_sep_offset:
+            #    synth_length = len_candidate
+            mask = ct_lt_u32(len_candidate, max_sep_offset)
+            mask = ct_lsb_prop_u16(mask)
+            synth_length = synth_length & (0xffff ^ mask) \
+                | len_candidate & mask
+
+        synth_msg_start = numBytes(n) - synth_length
+
+        error_detected = 0
+
+        # enumerate over all decrypted bytes
+        em_bytes = enumerate(dec_bytes)
+        # first check if first two bytes specify PKCS#1 v1.5 encryption padding
+        _, val = next(em_bytes)
+        error_detected |= ct_isnonzero_u32(val)
+        _, val = next(em_bytes)
+        error_detected |= ct_neq_u32(val, 0x02)
+        # then look for for the null separator byte among the padding bytes
+        # but inspect all decrypted bytes, even if we already find the
+        # separator earlier
+        msg_start = 0
+        for pos, val in em_bytes:
+            # padding must be at least 8 bytes long, fail if any of the first
+            # 8 bytes of it are zero
+            # equivalent to:
+            # if pos < 10 and not val:
+            #     error_detected = 0x01
+            error_detected |= ct_lt_u32(pos, 10) & (1 ^ ct_isnonzero_u32(val))
+
+            # update the msg_start only once; when it's 0
+            # (pos+1) because we want to skip the null separator
+            # equivalent to:
+            # if pos >= 10 and not msg_start and not val:
+            #     msg_start = pos+1
+            mask = (1 ^ ct_lt_u32(pos, 10)) & (1 ^ ct_isnonzero_u32(val)) \
+                & (1 ^ ct_isnonzero_u32(msg_start))
+            mask = ct_lsb_prop_u16(mask)
+            msg_start = msg_start & (0xffff ^ mask) | (pos+1) & mask
+
+        # if separator wasn't found, it's an error
+        # equivalent to:
+        # if not msg_start:
+        #     error_detected = 0x01
+        error_detected |= 1 ^ ct_isnonzero_u32(msg_start)
+
+        # equivalent to:
+        # if error_detected:
+        #     ret_msg_start = synth_msg_start
+        # else:
+        #     ret_msg_start = msg_start
+        mask = ct_lsb_prop_u16(error_detected)
+        ret_msg_start = msg_start & (0xffff ^ mask) | synth_msg_start & mask
+
+        # as at this point the length doesn't leak the information if the
+        # padding was correct or not, we don't have to worry about the
+        # length of the returned value (and thus the size of the buffer we
+        # pass to the caller); but we still need to read both buffers
+        # to ensure that the memory access patern is preserved (that both
+        # buffers are accessed, not just the one we return)
+
+        # equivalent to:
+        # if error_detected:
+        #     return message_random[ret_msg_start:]
+        # else:
+        #     return dec_bytes[ret_msg_start:]
+        mask = ct_lsb_prop_u8(error_detected)
+        not_mask = 0xff ^ mask
+        ret = bytearray(
+            x & not_mask | y & mask for x, y in
+            zip(dec_bytes[ret_msg_start:], message_random[ret_msg_start:]))
+
+        return ret
 
     def _rawPrivateKeyOp(self, m):
         raise NotImplementedError()
@@ -427,7 +569,7 @@ def _raw_public_key_op_bytes(self, ciphertext):
         if len(ciphertext) != numBytes(n):
             raise ValueError(""Message has incorrect length for the key size"")
         c_int = bytesToNumber(ciphertext)
-        if c_int > n:
+        if c_int >= n:
             raise ValueError(""Provided message value exceeds modulus"")
         enc_int = self._rawPublicKeyOp(c_int)
         return numberToByteArray(enc_int, numBytes(n))
diff --git a/unit_tests/test_tlslite_utils_rsakey.py b/unit_tests/test_tlslite_utils_rsakey.py
index 73331fa7..3fbcf62a 100644
--- a/unit_tests/test_tlslite_utils_rsakey.py
+++ b/unit_tests/test_tlslite_utils_rsakey.py
@@ -13,6 +13,8 @@
 from tlslite.utils.python_rsakey import Python_RSAKey
 from tlslite.utils.cryptomath import *
 from tlslite.errors import *
+from tlslite.utils.keyfactory import parsePEMKey
+from tlslite.utils.compat import a2b_hex, remove_whitespace
 try:
     import mock
     from mock import call
@@ -1642,3 +1644,1235 @@ def test_addPKCS1Prefix(self):
         self.assertEqual(RSAKey.addPKCS1Prefix(data, 'sha1'), bytearray(
             b'0!0\t\x06\x05+\x0e\x03\x02\x1a\x05\x00\x04\x14' +
             b' sha-1 hash of data '))
+
+
+class TestRSADecrypt(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        priv_key = """"""
+-----BEGIN RSA PRIVATE KEY-----
+MIIEowIBAAKCAQEAyMyDlxQJjaVsqiNkD5PciZfBY3KWj8Gwxt9RE8HJTosh5IrS
+KX5lQZARtObY9ec7G3iyV0ADIdHva2AtTsjOjRQclJBetK0wZjmkkgZTS25/JgdC
+Ppff/RM8iNchOZ3vvH6WzNy9fzquH+iScSv7SSmBfVEWZkQKH6y3ogj16hZZEK3Y
+o/LUlyAjYMy2MgJPDQcWnBkY8xb3lLFDrvVOyHUipMApePlomYC/+/ZJwwfoGBm/
++IQJY41IvZS+FStZ/2SfoL1inQ/6GBPDq/S1a9PC6lRl3/oUWJKSqdiiStJr5+4F
+EHQbY4LUPIPVv6QKRmE9BivkRVF9vK8MtOGnaQIDAQABAoIBABRVAQ4PLVh2Y6Zm
+pv8czbvw7dgQBkbQKgI5IpCJksStOeVWWSlybvZQjDpxFY7wtv91HTnQdYC7LS8G
+MhBELQYD/1DbvXs1/iybsZpHoa+FpMJJAeAsqLWLeRmyDt8yqs+/Ua20vEthubfp
+aMqk1XD3DvGNgGMiiJPkfUOe/KeTJZvPLNEIo9hojN8HjnrHmZafIznSwfUiuWlo
+RimpM7quwmgWJeq4T05W9ER+nYj7mhmc9xAj4OJXsURBszyE07xnyoAx0mEmGBA6
+egpAhEJi912IkM1hblH5A1SI/W4Jnej/bWWk/xGCVIB8n1jS+7qLoVHcjGi+NJyX
+eiBOBMECgYEA+PWta6gokxvqRZuKP23AQdI0gkCcJXHpY/MfdIYColY3GziD7UWe
+z5cFJkWe3RbgVSL1pF2UdRsuwtrycsf4gWpSwA0YCAFxY02omdeXMiL1G5N2MFSG
+lqn32MJKWUl8HvzUVc+5fuhtK200lyszL9owPwSZm062tcwLsz53Yd0CgYEAznou
+O0mpC5YzChLcaCvfvfuujdbcA7YUeu+9V1dD8PbaTYYjUGG3Gv2crS00Al5WrIaw
+93Q+s14ay8ojeJVCRGW3Bu0iF15XGMjHC2cD6o9rUQ+UW+SOWja7PDyRcytYnfwF
+1y2AkDGURSvaITSGR+xylD8RqEbmL66+jrU2sP0CgYB2/hXxiuI5zfHfa0RcpLxr
+uWjXiMIZM6T13NKAAz1nEgYswIpt8gTB+9C+RjB0Q+bdSmRWN1Qp1OA4yiVvrxyb
+3pHGsXt2+BmV+RxIy768e/DjSUwINZ5OjNalh9e5bWIh/X4PtcVXXwgu5XdpeYBx
+sru0oyI4FRtHMUu2VHkDEQKBgQCZiEiwVUmaEAnLx9KUs2sf/fICDm5zZAU+lN4a
+AA3JNAWH9+JydvaM32CNdTtjN3sDtvQITSwCfEs4lgpiM7qe2XOLdvEOp1vkVgeL
+9wH2fMaz8/3BhuZDNsdrNy6AkQ7ICwrcwj0C+5rhBIaigkgHW06n5W3fzziC5FFW
+FHGikQKBgGQ790ZCn32DZnoGUwITR++/wF5jUfghqd67YODszeUAWtnp7DHlWPfp
+LCkyjnRWnXzvfHTKvCs1XtQBoaCRS048uwZITlgZYFEWntFMqi76bqBE4FTSYUTM
+FinFUBBVigThM/RLfCRNrCW/kTxXuJDuSfVIJZzWNAT+9oWdz5da
+-----END RSA PRIVATE KEY-----
+""""""
+        cls.priv_key = parsePEMKey(priv_key, private=True)
+
+        pub_key = """"""
+-----BEGIN PUBLIC KEY-----
+MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAyMyDlxQJjaVsqiNkD5Pc
+iZfBY3KWj8Gwxt9RE8HJTosh5IrSKX5lQZARtObY9ec7G3iyV0ADIdHva2AtTsjO
+jRQclJBetK0wZjmkkgZTS25/JgdCPpff/RM8iNchOZ3vvH6WzNy9fzquH+iScSv7
+SSmBfVEWZkQKH6y3ogj16hZZEK3Yo/LUlyAjYMy2MgJPDQcWnBkY8xb3lLFDrvVO
+yHUipMApePlomYC/+/ZJwwfoGBm/+IQJY41IvZS+FStZ/2SfoL1inQ/6GBPDq/S1
+a9PC6lRl3/oUWJKSqdiiStJr5+4FEHQbY4LUPIPVv6QKRmE9BivkRVF9vK8MtOGn
+aQIDAQAB
+-----END PUBLIC KEY-----
+""""""
+        cls.pub_key = parsePEMKey(pub_key, public=True)
+
+    def test_sanity(self):
+        self.assertIsNotNone(self.priv_key)
+        self.assertIsNotNone(self.pub_key)
+
+        self.assertEqual(
+            self.priv_key.d,
+            bytesToNumber(a2b_hex(
+                ""1455010e0f2d587663a666a6ff1ccdbbf0edd8100646d02a023922908992""
+                ""c4ad39e5565929726ef6508c3a71158ef0b6ff751d39d07580bb2d2f0632""
+                ""10442d0603ff50dbbd7b35fe2c9bb19a47a1af85a4c24901e02ca8b58b79""
+                ""19b20edf32aacfbf51adb4bc4b61b9b7e968caa4d570f70ef18d80632288""
+                ""93e47d439efca793259bcf2cd108a3d8688cdf078e7ac799969f2339d2c1""
+                ""f522b969684629a933baaec2681625eab84f4e56f4447e9d88fb9a199cf7""
+                ""1023e0e257b14441b33c84d3bc67ca8031d2612618103a7a0a40844262f7""
+                ""5d8890cd616e51f9035488fd6e099de8ff6d65a4ff118254807c9f58d2fb""
+                ""ba8ba151dc8c68be349c977a204e04c1"")))
+
+    def test_simple_encypt_decrypt(self):
+        # just verify that decrypting encrypted message gives the expected
+        # message back
+        self.assertEqual(
+            self.priv_key.decrypt(self.pub_key.encrypt(b'message')),
+            b'message')
+
+    def test_decryption(self):
+        # a random positive test case
+        ciphertext = a2b_hex(remove_whitespace(""""""
+8bfe264e85d3bdeaa6b8851b8e3b956ee3d226fd3f69063a86880173a273d9f283b2eebdd1ed
+35f7e02d91c571981b6737d5320bd8396b0f3ad5b019daec1b0aab3cbbc026395f4fd14f1367
+3f2dfc81f9b660ec26ac381e6db3299b4e460b43fab9955df2b3cfaa20e900e19c856238fd37
+1899c2bf2ce8c868b76754e5db3b036533fd603746be13c10d4e3e6022ebc905d20c2a7f32b2
+15a4cd53b3f44ca1c327d2c2b651145821c08396c89071f665349c25e44d2733cd9305985cee
+f6430c3cf57af5fa224089221218fa34737c79c446d28a94c41c96e4e92ac53fbcf384dea841
+9ea089f8784445a492c812eb0d409467f75afd7d4d1078886205a066""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+        msg = self.priv_key.decrypt(ciphertext)
+        self.assertEqual(msg, b'lorem ipsum dolor sit amet')
+
+    def test_invalid_decrypting_to_empty(self):
+        ciphertext = a2b_hex(remove_whitespace(""""""
+20aaa8adbbc593a924ba1c5c7990b5c2242ae4b99d0fe636a19a4cf754edbcee774e472fe028
+160ed42634f8864900cb514006da642cae6ae8c7d087caebcfa6dad1551301e130344989a1d4
+62d4164505f6393933450c67bc6d39d8f5160907cabc251b737925a1cf21e5c6aa5781b7769f
+6a2a583d97cce008c0f8b6add5f0b2bd80bee60237aa39bb20719fe75749f4bc4e42466ef5a8
+61ae3a92395c7d858d430bfe38040f445ea93fa2958b503539800ffa5ce5f8cf51fa8171a91f
+36cb4f4575e8de6b4d3f096ee140b938fd2f50ee13f0d050222e2a72b0a3069ff3a6738e82c8
+7090caa5aed4fcbe882c49646aa250b98f12f83c8d528113614a29e7""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertNotEqual(dec[-1:], b'\x00')
+
+        msg = self.priv_key.decrypt(ciphertext)
+        self.assertEqual(msg, b'')
+
+    def test_invalid_decrypting_to_max_length(self):
+        # the last value from PRF is 245, which is exactly the max we
+        # can return
+        ciphertext = a2b_hex(remove_whitespace(""""""
+48cceab10f39a4db32f60074feea473cbcdb7accf92e150417f76b44756b190e843e79ec12aa
+85083a21f5437e7bad0a60482e601198f9d86923239c8786ee728285afd0937f7dde12717f28
+389843d7375912b07b991f4fdb0190fced8ba665314367e8c5f9d2981d0f5128feeb46cb50fc
+237e64438a86df198dd0209364ae3a842d77532b66b7ef263b83b1541ed671b120dfd660462e
+2107a4ee7b964e734a7bd68d90dda61770658a3c242948532da32648687e0318286473f675b4
+12d6468f013f14d760a358dfcad3cda2afeec5e268a37d250c37f722f468a70dfd92d7294c3c
+1ee1e7f8843b7d16f9f37ef35748c3ae93aa155cdcdfeb4e78567303""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(
+            dec[0:11],
+            b'\x78\x05\x5c\xc0\xd7\x02\xfe\xd7\x6a\xbe\x53')
+
+        plaintext = a2b_hex(remove_whitespace(""""""
+22d850137b9eebe092b24f602dc5bb7918c16bd89ddbf20467b119d205f9c2e4bd7d2592cf1e
+532106e0f33557565923c73a02d4f09c0c22bea89148183e60317f7028b3aa1f261f91c97939
+3101d7e15f4067e63979b32751658ef769610fe97cf9cef3278b3117d384051c3b1d82c251c2
+305418c8f6840530e631aad63e70e20e025bcd8efb54c92ec6d3b106a2f8e64eeff7d38495b0
+fc50c97138af4b1c0a67a1c4e27b077b8439332edfa8608dfeae653cd6a628ac550395f7e743
+90e42c11682234870925eeaa1fa71b76cf1f2ee3bda69f6717033ff8b7c95c9799e7a3bea5e7
+e4a1c359772fb6b1c6e6c516661dfe30c3""""""))
+        self.assertEqual(len(plaintext), 245)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_invalid_decrypting_to_length_second_to_last_from_prf(self):
+        # the last value from the PRF is 246, which is longer than the max
+        # allowed length: 245, so it needs to select second to last: 2
+        ciphertext = a2b_hex(remove_whitespace(""""""
+1439e08c3f84c1a7fec74ce07614b20e01f6fa4e8c2a6cffdc3520d8889e5d9a950c6425798f
+85d4be38d300ea5695f13ecd4cb389d1ff5b82484b494d6280ab7fa78e645933981cb934cce8
+bfcd114cc0e6811eefa47aae20af638a1cd163d2d3366186d0a07df0c81f6c9f3171cf356147
+2e98a6006bf75ddb457bed036dcce199369de7d94ef2c68e8467ee0604eea2b3009479162a78
+91ba5c40cab17f49e1c438cb6eaea4f76ce23cce0e483ff0e96fa790ea15be67671814342d0a
+23f4a20262b6182e72f3a67cd289711503c85516a9ed225422f98b116f1ab080a80abd6f0216
+df88d8cfd67c139243be8dd78502a7aaf6bc99d7da71bcdf627e7354""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertEqual(dec[-3:], b'\xd1\x90\x17')
+
+        plaintext = a2b_hex(remove_whitespace(""0f9b""))
+
+        self.assertEqual(len(plaintext), 2)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_invalid_decrypting_to_length_third_to_last_from_prf(self):
+        # the last three numbers from prf are: 2, 247, 255, so we need to
+        # pick 2, the third one from the end
+        ciphertext = a2b_hex(remove_whitespace(""""""
+1690ebcceece2ce024f382e467cf8510e74514120937978576caf684d4a02ad569e8d76cbe36
+5a060e00779de2f0865ccf0d923de3b4783a4e2c74f422e2f326086c390b658ba47f31ab013a
+a80f468c71256e5fa5679b24e83cd82c3d1e05e398208155de2212993cd2b8bab6987cf4cc12
+93f19909219439d74127545e9ed8a706961b8ee2119f6bfacafbef91b75a789ba65b8b833bc6
+149cf49b5c4d2c6359f62808659ba6541e1cd24bf7f7410486b5103f6c0ea29334ea6f4975b1
+7387474fe920710ea61568d7b7c0a7916acf21665ad5a31c4eabcde44f8fb6120d8457afa1f3
+c85d517cda364af620113ae5a3c52a048821731922737307f77a1081""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertEqual(dec[-3:], b'\xee\xaf\xde')
+
+        plaintext = a2b_hex(remove_whitespace(""4f02""))
+
+        self.assertEqual(len(plaintext), 2)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_11_byte_long(self):
+        # ciphertext that generates a fake 11 byte plaintext, but decrypts
+        # to real 11 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+6213634593332c485cef783ea2846e3d6e8b0e005cd8293eaebbaa5079712fd681579bdfbbda
+138ae4d9d952917a03c92398ec0cb2bb0c6b5a8d55061fed0d0d8d72473563152648cfe640b3
+35dc95331c21cb133a91790fa93ae44497c128708970d2beeb77e8721b061b1c44034143734a
+77be8220877415a6dba073c3871605380542a9f25252a4babe8331cdd53cf828423f3cc70b56
+0624d0581fb126b2ed4f4ed358f0eb8065cf176399ac1a846a31055f9ae8c9c24a1ba050bc20
+842125bc1753158f8065f3adb9cc16bfdf83816bdf38b624f12022c5a6fbfe29bc91542be8c0
+208a770bcd677dc597f5557dc2ce28a11bf3e3857f158717a33f6592""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        plaintext = b'lorem ipsum'
+
+        self.assertEqual(len(plaintext), 11)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_11_byte_long_with_null_padded_ciphertext(self):
+        # ciphertext that starts with a null byte, decrypts to real 11 byte
+        # long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+00a2e8f114ea8d05d12dc843e3cc3b2edc8229ff2a028bda29ba9d55e3cd02911902fef1f42a
+075bf05e8016e8567213d6f260fa49e360779dd81aeea3e04c2cb567e0d72b98bf754014561b
+7511e083d20e0bfb9cd23f8a0d3c88900c49d2fcd5843ff0765607b2026f28202a87aa94678a
+ed22a0c20724541394cd8f44e373eba1d2bae98f516c1e2ba3d86852d064f856b1daf24795e7
+67a2b90396e50743e3150664afab131fe40ea405dcf572dd1079af1d3f0392ccadcca0a12740
+dbb213b925ca2a06b1bc1383e83a658c82ba2e7427342379084d5f66b544579f07664cb26edd
+4f10fd913fdbc0de05ef887d4d1ec1ac95652397ea7fd4e4759fda8b""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        plaintext = b'lorem ipsum'
+
+        self.assertEqual(len(plaintext), 11)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_11_byte_long_with_double_null_padded_ciphertext(self):
+        # ciphertext that starts with two null bytes, decrypts to real 11 byte
+        # long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+00001f71879b426127f7dead621f7380a7098cf7d22173aa27991b143c46d53383c209bd0c9c
+00d84078037e715f6b98c65005a77120070522ede51d472c87ef94b94ead4c5428ee108a3455
+61658301911ec5a8f7dd43ed4a3957fd29fb02a3529bf63f8040d3953490939bd8f78b2a3404
+b6fb5ff70a4bfdaac5c541d6bcce49c9778cc390be24cbef1d1eca7e870457241d3ff72ca44f
+9f56bdf31a890fa5eb3a9107b603ccc9d06a5dd911a664c82b6abd4fe036f8db8d5a070c2d86
+386ae18d97adc1847640c211d91ff5c3387574a26f8ef27ca7f48d2dd1f0c7f14b81cc9d33ee
+6853031d3ecf10a914ffd90947909c8011fd30249219348ebff76bfc""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        plaintext = b'lorem ipsum'
+
+        self.assertEqual(len(plaintext), 11)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_11_byte_long_with_zero_generated_length(self):
+        # valid ciphertext that generates a zero length fake plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+b5e49308f6e9590014ffaffc5b8560755739dd501f1d4e9227a7d291408cf4b753f292322ff8
+bead613bf2caa181b221bc38caf6392deafb28eb21ad60930841ed02fd6225cc9c463409adbe
+7d8f32440212fbe3881c51375bb09565efb22e62b071472fb38676e5b4e23a0617db5d14d935
+19ac0007a30a9c822eb31c38b57fcb1be29608fcf1ca2abdcaf5d5752bbc2b5ac7dba5afcff4
+a5641da360dd01f7112539b1ed46cdb550a3b1006559b9fe1891030ec80f0727c42401ddd6cb
+b5e3c80f312df6ec89394c5a7118f573105e7ab00fe57833c126141b50a935224842addfb479
+f75160659ba28877b512bb9a93084ad8bec540f92640f63a11a010e0""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+        plaintext = b'lorem ipsum'
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_11_byte_long_with_245_generated_length(self):
+        # valid ciphertext that generates a 245 byte long fake plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+1ea0b50ca65203d0a09280d39704b24fe6e47800189db5033f202761a78bafb270c5e25abd1f
+7ecc6e7abc4f26d1b0cd9b8c648d529416ee64ccbdd7aa72a771d0353262b543f0e436076f40
+a1095f5c7dfd10dcf0059ccb30e92dfa5e0156618215f1c3ff3aa997a9d999e506924f5289e3
+ac72e5e2086cc7b499d71583ed561028671155db4005bee01800a7cdbdae781dd32199b8914b
+5d4011dd6ff11cd26d46aad54934d293b0bc403dd211bf13b5a5c6836a5e769930f437ffd863
+4fb7371776f4bc88fa6c271d8aa6013df89ae6470154497c4ac861be2a1c65ebffec139bf7aa
+ba3a81c7c5cdd84da9af5d3edfb957848074686b5837ecbcb6a41c50""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+        plaintext = b""lorem ipsum""
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long(self):
+        # a random ciphertext that generates a fake 11 byte plaintext
+        # and fails padding check
+        ciphertext = a2b_hex(remove_whitespace(""""""
+5f02f4b1f46935c742ebe62b6f05aa0a3286aab91a49b34780adde6410ab46f7386e05748331
+864ac98e1da63686e4babe3a19ed40a7f5ceefb89179596aab07ab1015e03b8f825084dab028
+b6731288f2e511a4b314b6ea3997d2e8fe2825cef8897cbbdfb6c939d441d6e04948414bb69e
+682927ef8576c9a7090d4aad0e74c520d6d5ce63a154720f00b76de8cc550b1aa14f016d63a7
+b6d6eaa1f7dbe9e50200d3159b3d099c900116bf4eba3b94204f18b1317b07529751abf64a26
+b0a0bf1c8ce757333b3d673211b67cc0653f2fe2620d57c8b6ee574a0323a167eab1106d9bc7
+fd90d415be5f1e9891a0e6c709f4fc0404e8226f8477b4e939b36eb2""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertNotEqual(dec[-12:-11], b'\x00')
+
+        plaintext = a2b_hex(remove_whitespace(""af9ac70191c92413cb9f2d""))
+
+        self.assertEqual(len(plaintext), 11)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'lorem ipsum')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long_wrong_version_byte(self):
+        # an otherwise correct plaintext, but with wrong first byte
+        # (0x01 instead of 0x00), generates a random 11 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+9b2ec9c0c917c98f1ad3d0119aec6be51ae3106e9af1914d48600ab6a2c0c0c8ae02a2dc3039
+906ff3aac904af32ec798fd65f3ad1afa2e69400e7c1de81f5728f3b3291f38263bc7a90a056
+3e43ce7a0d4ee9c0d8a716621ca5d3d081188769ce1b131af7d35b13dea99153579c86db31fe
+07d5a2c14d621b77854e48a8df41b5798563af489a291e417b6a334c63222627376118c02c53
+b6e86310f728734ffc86ef9d7c8bf56c0c841b24b82b59f51aee4526ba1c4268506d301e4ebc
+498c6aebb6fd5258c876bf900bac8ca4d309dd522f6a6343599a8bc3760f422c10c72d0ad527
+ce4af1874124ace3d99bb74db8d69d2528db22c3a37644640f95c05f""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x01\x02')
+        self.assertEqual(dec[-12:], b'\x00lorem ipsum')
+
+        plaintext = a2b_hex(remove_whitespace(""a1f8c9255c35cfba403ccc""))
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'lorem ipsum')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long_wrong_type_byte(self):
+        # an otherwise correct plaintext, but with wrong second byte
+        # (0x01 instead of 0x02), generates a random 11 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+782c2b59a21a511243820acedd567c136f6d3090c115232a82a5efb0b178285f55b5ec2d2bac
+96bf00d6592ea7cdc3341610c8fb07e527e5e2d20cfaf2c7f23e375431f45e998929a02f25fd
+95354c33838090bca838502259e92d86d568bc2cdb132fab2a399593ca60a015dc2bb1afcd64
+fef8a3834e17e5358d822980dc446e845b3ab4702b1ee41fe5db716d92348d5091c15d35a110
+555a35deb4650a5a1d2c98025d42d4544f8b32aa6a5e02dc02deaed9a7313b73b49b0d4772a3
+768b0ea0db5846ace6569cae677bf67fb0acf3c255dc01ec8400c963b6e49b1067728b4e563d
+7e1e1515664347b92ee64db7efb5452357a02fff7fcb7437abc2e579""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x00\x01')
+        self.assertEqual(dec[-12:], b'\x00lorem ipsum')
+
+        plaintext = a2b_hex(remove_whitespace(""e6d700309ca0ed62452254""))
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'lorem ipsum')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long_null_type_byte(self):
+        # an otherwise correct plaintext, but with wrong second byte
+        # (0x00 instead of 0x02), and a 0x02 on third position, generates a
+        # random 11 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+1786550ce8d8433052e01ecba8b76d3019f1355b212ac9d0f5191b023325a7e7714b7802f8e9
+a17c4cb3cd3a84041891471b10ca1fcfb5d041d34c82e6d0011cf4dc76b90e9c2e0743590579
+d55bcd7857057152c4a8040361343d1d22ba677d62b011407c652e234b1d663af25e2386251d
+7409190f19fc8ec3f9374fdf1254633874ce2ec2bff40ad0cb473f9761ec7b68da45a4bd5e33
+f5d7dac9b9a20821df9406b653f78a95a6c0ea0a4d57f867e4db22c17bf9a12c150f809a7b72
+b6db86c22a8732241ebf3c6a4f2cf82671d917aba8bc61052b40ccddd743a94ea9b538175106
+201971cca9d136d25081739aaf6cd18b2aecf9ad320ea3f89502f955""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:3], b'\x00\x00\x02')
+        self.assertEqual(dec[-12:], b'\x00lorem ipsum')
+
+        plaintext = a2b_hex(remove_whitespace(""3d4a054d9358209e9cbbb9""))
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'lorem ipsum')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long_null_byte_first_byte_of_padding(self):
+        # an otherwise correct plaintext, but with a null byte on third
+        # position (first byte of padding), generates a random 11 byte
+        # long payload
+        ciphertext = a2b_hex(remove_whitespace(""""""
+179598823812d2c58a7eb50521150a48bcca8b4eb53414018b6bca19f4801456c5e36a940037
+ac516b0d6412ba44ec6b4f268a55ef1c5ffbf18a2f4e3522bb7b6ed89774b79bffa22f7d3102
+165565642de0d43a955e96a1f2e80e5430671d7266eb4f905dc8ff5e106dc5588e5b0289e49a
+4913940e392a97062616d2bda38155471b7d360cfb94681c702f60ed2d4de614ea72bf1c5316
+0e63179f6c5b897b59492bee219108309f0b7b8cb2b136c346a5e98b8b4b8415fb1d713bae06
+7911e3057f1c335b4b7e39101eafd5d28f0189037e4334f4fdb9038427b1d119a6702aa82333
+19cc97d496cc289ae8c956ddc84042659a2d43d6aa22f12b81ab884e""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:3], b'\x00\x02\x00')
+        self.assertEqual(dec[-12:], b'\x00lorem ipsum')
+
+        plaintext = a2b_hex(""1f037dd717b07d3e7f7359"")
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b""lorem ipsum"")
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long_null_byte_at_eight_byte_of_padding(self):
+        # an otherwise correct plaintext, but with a null byte on tenth
+        # position (eight byte of padding), generates a random 11 byte long
+        # plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+a7a340675a82c30e22219a55bc07cdf36d47d01834c1834f917f18b517419ce9de2a96460e74
+5024436470ed85e94297b283537d52189c406a3f533cb405cc6a9dba46b482ce98b6e3dd52d8
+fce2237425617e38c11fbc46b61897ef200d01e4f25f5f6c4c5b38cd0de38ba11908b86595a8
+036a08a42a3d05b79600a97ac18ba368a08d6cf6ccb624f6e8002afc75599fba4de3d4f3ba7d
+208391ebe8d21f8282b18e2c10869eb2702e68f9176b42b0ddc9d763f0c86ba0ff92c957aaea
+b76d9ab8da52ea297ec11d92d770146faa1b300e0f91ef969b53e7d2907ffc984e9a9c9d11fb
+7d6cba91972059b46506b035efec6575c46d7114a6b935864858445f""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x00\x02')
+        self.assertNotEqual(dec[2:3], b'\x00')
+        self.assertEqual(dec[9:10], b'\x00')
+        self.assertEqual(dec[-12:], b'\x00lorem ipsum')
+
+        plaintext = a2b_hex(""63cb0bf65fc8255dd29e17"")
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b""lorem ipsum"")
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long_missing_null_separator(self):
+        # an otherwise correct plaintext, but with missing zero separator
+        # decrypts to 11 byte random synthethic plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+3d1b97e7aa34eaf1f4fc171ceb11dcfffd9a46a5b6961205b10b302818c1fcc9f4ec78bf18ea
+0cee7e9fa5b16fb4c611463b368b3312ac11cf9c06b7cf72b54e284848a508d3f02328c62c29
+99d0fb60929f81783c7a256891bc2ff4d91df2af96a24fc5701a1823af939ce6dbdc510608e3
+d41eec172ad2d51b9fc61b4217c923cadcf5bac321355ef8be5e5f090cdc2bd0c697d9058247
+db3ad613fdce87d2955a6d1c948a5160f93da21f731d74137f5d1f53a1923adb513d2e6e1589
+d44cc079f4c6ddd471d38ac82d20d8b1d21f8d65f3b6907086809f4123e08d86fb38729585de
+026a485d8f0e703fd4772f6668febf67df947b82195fa3867e3a3065""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x00\x02')
+        for val in dec[2:-12]:
+            self.assertNotEqual(val, 0)
+        self.assertEqual(dec[-12:], b'\x01lorem ipsum')
+
+        plaintext = a2b_hex(remove_whitespace(""6f09a0b62699337c497b0b""))
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'lorem ipsum')
+        self.assertEqual(msg, plaintext)
+
+
+class TestRSA2049Decrypt(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        priv_key = """"""
+-----BEGIN RSA PRIVATE KEY-----
+MIIEpQIBAAKCAQEBVfiJVWoXdfHHp3hqULGLwoyemG7eVmfKs5uEEk6Q66dcHbCD
+rD5EO7qU3CNWD3XjqBaToqQ73HQm2MTq/mjIXeD+dX9uSbue1EfmAkMIANuwTOsi
+5/pXoY0zj7ZgJs20Z+cMwEDn02fvQDx78ePfYkZQCUYx8h6v0vtbyRX/BDeazRES
+9zLAtGYHwXjTiiD1LtpQny+cBAXVEGnoDM+UFVTQRwRnUFw89UHqCJffyfQAzssp
+j/x1M3LZ9pM68XTMQO2W1GcDFzO5f4zd0/krw6A+qFdsQX8kAHteT3UBEFtUTen6
+3N/635jftLsFuBmfP4Ws/ZH3qaCUuaOD9QSQlwIDAQABAoIBAQEZwrP1CnrWFSZ5
+1/9RCVisLYym8AKFkvMy1VoWc2F4qOZ/F+cFzjAOPodUclEAYBP5dNCj20nvNEyl
+omo0wEUHBNDkIuDOI6aUJcFf77bybhBu7/ZMyLnXRC5NpOjIUAjq6zZYWaIpT6OT
+e8Jr5WMy59geLBYO9jXMUoqnvlXmM6cj28Hha6KeUrKa7y+eVlT9wGZrsPwlSsvo
+DmOHTw9fAgeC48nc/CUg0MnEp7Y05FA/u0k+Gq/us/iL16EzmHJdrm/jmed1zV1M
+8J/IODR8TJjasaSIPM5iBRNhWvqhCmM2jm17ed9BZqsWJznvUVpEAu4eBgHFpVvH
+HfDjDt+BAoGBAYj2k2DwHhjZot4pUlPSUsMeRHbOpf97+EE99/3jVlI83JdoBfhP
+wN3sdw3wbO0GXIETSHVLNGrxaXVod/07PVaGgsh4fQsxTvasZ9ZegTM5i2Kgg8D4
+dlxa1A1agfm73OJSftfpUAjLECnLTKvR+em+38KGyWVSJV2n6rGSF473AoGBAN7H
+zxHa3oOkxD0vgBl/If1dRv1XtDH0T+gaHeN/agkf/ARk7ZcdyFCINa3mzF9Wbzll
+YTqLNnmMkubiP1LvkH6VZ+NBvrxTNxiWJfu+qx87ez+S/7JoHm71p4SowtePfC2J
+qqok0s7b0GaBz+ZcNse/o8W6E1FiIi71wukUyYNhAoGAEgk/OnPK7dkPYKME5FQC
++HGrMsjJVbCa9GOjvkNw8tVYSpq7q2n9sDHqRPmEBl0EYehAqyGIhmAONxVUbIsL
+ha0m04y0MI9S0H+ZRH2R8IfzndNAONsuk46XrQU6cfvtZ3Xh3IcY5U5sr35lRn2c
+ut3H52XIWJ4smN/cJcpOyoECgYEAjM5hNHnPlgj392wkXPkbtJXWHp3mSISQVLTd
+G0MW8/mBQg3AlXi/eRb+RpHPrppk5jQLhgMjRSPyXXe2amb8PuWTqfGN6l32PtX3
+3+udILpppb71Wf+w7JTbcl9v9uq7o9SVR8DKdPA+AeweSQ0TmqCnlHuNZizOSjwP
+G16GF0ECgYEA+ZWbNMS8qM5IiHgbMbHptdit9dDT4+1UXoNn0/hUW6ZEMriHMDXv
+iBwrzeANGAn5LEDYeDe1xPms9Is2uNxTpZVhpFZSNALR6Po68wDlTJG2PmzuBv5t
+5mbzkpWCoD4fRU53ifsHgaTW+7Um74gWIf0erNIUZuTN2YrtEPTnb3k=
+-----END RSA PRIVATE KEY-----
+""""""
+        cls.priv_key = parsePEMKey(priv_key, private=True)
+
+        pub_key = """"""
+-----BEGIN PUBLIC KEY-----
+MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEBVfiJVWoXdfHHp3hqULGL
+woyemG7eVmfKs5uEEk6Q66dcHbCDrD5EO7qU3CNWD3XjqBaToqQ73HQm2MTq/mjI
+XeD+dX9uSbue1EfmAkMIANuwTOsi5/pXoY0zj7ZgJs20Z+cMwEDn02fvQDx78ePf
+YkZQCUYx8h6v0vtbyRX/BDeazRES9zLAtGYHwXjTiiD1LtpQny+cBAXVEGnoDM+U
+FVTQRwRnUFw89UHqCJffyfQAzsspj/x1M3LZ9pM68XTMQO2W1GcDFzO5f4zd0/kr
+w6A+qFdsQX8kAHteT3UBEFtUTen63N/635jftLsFuBmfP4Ws/ZH3qaCUuaOD9QSQ
+lwIDAQAB
+-----END PUBLIC KEY-----
+""""""
+        cls.pub_key = parsePEMKey(pub_key, public=True)
+
+    def test_sanity(self):
+        self.assertIsNotNone(self.priv_key)
+        self.assertIsNotNone(self.pub_key)
+
+        self.assertEqual(
+            self.priv_key.d,
+            bytesToNumber(a2b_hex(
+                ""0119c2b3f50a7ad6152679d7ff510958ac2d8ca6f0028592f332d55a1673""
+                ""6178a8e67f17e705ce300e3e87547251006013f974d0a3db49ef344ca5a2""
+                ""6a34c0450704d0e422e0ce23a69425c15fefb6f26e106eeff64cc8b9d744""
+                ""2e4da4e8c85008eaeb365859a2294fa3937bc26be56332e7d81e2c160ef6""
+                ""35cc528aa7be55e633a723dbc1e16ba29e52b29aef2f9e5654fdc0666bb0""
+                ""fc254acbe80e63874f0f5f020782e3c9dcfc2520d0c9c4a7b634e4503fbb""
+                ""493e1aafeeb3f88bd7a13398725dae6fe399e775cd5d4cf09fc838347c4c""
+                ""98dab1a4883cce620513615afaa10a63368e6d7b79df4166ab162739ef51""
+                ""5a4402ee1e0601c5a55bc71df0e30edf81"")))
+
+    def test_simple(self):
+        msg = b'some long message'
+        self.assertEqual(
+            msg,
+            self.priv_key.decrypt(self.pub_key.encrypt(msg)))
+
+    def test_with_ciphertext_length_from_third_prf_value(self):
+        # malformed plaintext that generates a fake plaintext of length
+        # specified by 3rd length from the end of PRF output
+        ciphertext = a2b_hex(remove_whitespace(""""""
+00b26f6404b82649629f2704494282443776929122e279a9cf30b0c6fe8122a0a9042870d97c
+c8ef65490fe58f031eb2442352191f5fbc311026b5147d32df914599f38b825ebb824af0d63f
+2d541a245c5775d1c4b78630e4996cc5fe413d38455a776cf4edcc0aa7fccb31c584d60502ed
+2b77398f536e137ff7ba6430e9258e21c2db5b82f5380f566876110ac4c759178900fbad7ab7
+0ea07b1daf7a1639cbb4196543a6cbe8271f35dddb8120304f6eef83059e1c5c5678710f904a
+6d760c4d1d8ad076be17904b9e69910040b47914a0176fb7eea0c06444a6c4b86d674d19a556
+a1de5490373cb01ce31bbd15a5633362d3d2cd7d4af1b4c5121288b894""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertEqual(dec[-2:], b'\xc8\xfa')
+
+        plaintext = b'\x42'
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_11_bytes_long(self):
+        # a valid ciphertext that decrypts to 11 byte long message
+        ciphertext = a2b_hex(remove_whitespace(""""""
+013300edbf0bb3571e59889f7ed76970bf6d57e1c89bbb6d1c3991d9df8e65ed54b556d928da
+7d768facb395bbcc81e9f8573b45cf8195dbd85d83a59281cddf4163aec11b53b4140053e3bd
+109f787a7c3cec31d535af1f50e0598d85d96d91ea01913d07097d25af99c67464ebf2bb396f
+b28a9233e56f31f7e105d71a23e9ef3b736d1e80e713d1691713df97334779552fc94b40dd73
+3c7251bc522b673d3ec9354af3dd4ad44fa71c0662213a57ada1d75149697d0eb55c053aaed5
+ffd0b815832f454179519d3736fb4faf808416071db0d0f801aca8548311ee708c131f4be658
+b15f6b54256872c2903ac708bd43b017b073b5707bc84c2cd9da70e967""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+        plaintext = b'lorem ipsum'
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_11_bytes_long_with_null_padded_ciphertext(self):
+        # a valid ciphertext that starts with a null byte, decrypts to 11 byte
+        # long value
+        ciphertext = a2b_hex(remove_whitespace(""""""
+0002aadf846a329fadc6760980303dbd87bfadfa78c2015ce4d6c5782fd9d3f1078bd3c0a2c5
+bfbdd1c024552e5054d98b5bcdc94e476dd280e64d650089326542ce7c61d4f1ab40004c2e6a
+88a883613568556a10f3f9edeab67ae8dddc1e6b0831c2793d2715de943f7ce34c5c05d1b09f
+14431fde566d17e76c9feee90d86a2c158616ec81dda0c642f58c0ba8fa4495843124a7235d4
+6fb4069715a51bf710fd024259131ba94da73597ace494856c94e7a3ec261545793b0990279b
+15fa91c7fd13dbfb1df2f221dab9fa9f7c1d21e48aa49f6aaecbabf5ee76dc6c2af2317ffb4e
+303115386a97f8729afc3d0c89419669235f1a3a69570e0836c79fc162""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+        plaintext = b'lorem ipsum'
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_11_bytes_long_with_double_null_padded_ciphertext(self):
+        # a valid ciphertext that starts with two null bytes, decrypts to
+        # 11 byte long value
+        ciphertext = a2b_hex(remove_whitespace(""""""
+0000f36da3b72d8ff6ded74e7efd08c01908f3f5f0de7b55eab92b5f875190809c39d4162e1e
+6649618f854fd84aeab03970d16bb814e999852c06de38d82b95c0f32e2a7b5714021fe30338
+9be9c0eac24c90a6b7210f929d390fabf903d44e04110bb7a7fd6c383c275804721efa6d7c93
+aa64c0bb2b18d97c5220a846c66a4895ae52adddbe2a9996825e013585adcec4b32ba61d7827
+37bd343e5fabd68e8a95b8b1340318559860792dd70dffbe05a1052b54cbfb48cfa7bb3c19ce
+a52076bddac5c25ee276f153a610f6d06ed696d192d8ae4507ffae4e5bdda10a625d6b67f32f
+7cffcd48dee2431fe66f6105f9d17e611cdcc674868e81692a360f4052""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+        plaintext = b'lorem ipsum'
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long(self):
+        # a random ciphertext that generates a fake 11 byte plaintext
+        # and fails the padding check
+        ciphertext = a2b_hex(remove_whitespace(""""""
+00f910200830fc8fff478e99e145f1474b312e2512d0f90b8cef77f8001d09861688c156d1cb
+af8a8957f7ebf35f724466952d0524cad48aad4fba1e45ce8ea27e8f3ba44131b7831b62d60c
+0762661f4c1d1a88cd06263a259abf1ba9e6b0b172069afb86a7e88387726f8ab3adb30bfd6b
+3f6be6d85d5dfd044e7ef052395474a9cbb1c3667a92780b43a22693015af6c513041bdaf87d
+43b24ddd244e791eeaea1066e1f4917117b3a468e22e0f7358852bb981248de4d720add2d15d
+ccba6280355935b67c96f9dcb6c419cc38ab9f6fba2d649ef2066e0c34c9f788ae49babd9025
+fa85b21113e56ce4f43aa134c512b030dd7ac7ce82e76f0be9ce09ebca""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertNotEqual(dec[-12:-11], b'\x00')
+
+        plaintext = a2b_hex(remove_whitespace(""1189b6f5498fd6df532b00""))
+
+        self.assertEqual(len(plaintext), 11)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'lorem ipsum')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long_wrong_version_byte(self):
+        # an otherwise correct plaintext, but with wrong first byte
+        # (0x01 instead of 0x00), generates a random 11 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+002c9ddc36ba4cf0038692b2d3a1c61a4bb3786a97ce2e46a3ba74d03158aeef456ce0f4db04
+dda3fe062268a1711250a18c69778a6280d88e133a16254e1f0e30ce8dac9b57d2e39a2f7d7b
+e3ee4e08aec2fdbe8dadad7fdbf442a29a8fb40857407bf6be35596b8eefb5c2b3f58b894452
+c2dc54a6123a1a38d642e23751746597e08d71ac92704adc17803b19e131b4d1927881f43b02
+00e6f95658f559f912c889b4cd51862784364896cd6e8618f485a992f82997ad6a0917e32ae5
+872eaf850092b2d6c782ad35f487b79682333c1750c685d7d32ab3e1538f31dcaa5e7d5d2825
+875242c83947308dcf63ba4bfff20334c9c140c837dbdbae7a8dee72ff""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x01\x02')
+        self.assertEqual(dec[-12:], b'\x00lorem ipsum')
+
+        plaintext = a2b_hex(remove_whitespace(""f6d0f5b78082fe61c04674""))
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'lorem ipsum')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_11_byte_long_wrong_type_byte(self):
+        # an otherwise correct plaintext, but with wrong second byte
+        # (0x01 instead of 0x02), generates a random 11 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+00c5d77826c1ab7a34d6390f9d342d5dbe848942e2618287952ba0350d7de6726112e9cebc39
+1a0fae1839e2bf168229e3e0d71d4161801509f1f28f6e1487ca52df05c466b6b0a6fbbe57a3
+268a970610ec0beac39ec0fa67babce1ef2a86bf77466dc127d7d0d2962c20e66593126f2768
+63cd38dc6351428f884c1384f67cad0a0ffdbc2af16711fb68dc559b96b37b4f04cd133ffc7d
+79c43c42ca4948fa895b9daeb853150c8a5169849b730cc77d68b0217d6c0e3dbf38d751a199
+8186633418367e7576530566c23d6d4e0da9b038d0bb5169ce40133ea076472d055001f01356
+45940fd08ea44269af2604c8b1ba225053d6db9ab43577689401bdc0f3""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x00\x01')
+        self.assertEqual(dec[-12:], b'\x00lorem ipsum')
+
+        plaintext = a2b_hex(remove_whitespace(""1ab287fcef3ff17067914d""))
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'lorem ipsum')
+        self.assertEqual(msg, plaintext)
+
+
+class TestRSA3072Decrypt(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        priv_key = """"""
+-----BEGIN RSA PRIVATE KEY-----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+-----END RSA PRIVATE KEY-----""""""
+        cls.priv_key = parsePEMKey(priv_key, private=True)
+
+        pub_key = """"""
+-----BEGIN PUBLIC KEY-----
+MIIBojANBgkqhkiG9w0BAQEFAAOCAY8AMIIBigKCAYEAr9ccqtXp9bjGw2cHCkfx
+nX5mrt4YpbJ0H7PE0zQ0VgaSotkJ72iI7GAv9rk68ljudDA8MBr81O2+xDMR3cjd
+vwDdu+OG0zuNDiKxtEk23EiYcbhSN7NM50etj9sMTk0dqnqt8HOFxchzLMt9Wkni
+5QyIPH16wQ7Wp02ayQ35EpkFoX1KCHIQ/Hi20EseuWlILBGm7recUOWxbz8lT3Vx
+UosvFxargW1uygcnveqYBZMpcw64wzznHWHdSsOTtiVuB6wdEk8CANHD4FpMG8fx
+7S/IPlcZnP5ZCLEAh+J/vZfSwkIUYZxxR8j778o5vCVnYqaCNTH34jTWjq56DZ+v
+EN0V6VI3gMfVrlgJStUlqQY7TDP5XhAG2i6xLTdDaJSVwfICPkBzU8XrPkyhxIz/
+gaEJANFIIOuAGvTxpZbEuc6aUx/PilTZ/9ckJYtu7CAQjfb9/XbUrgO6fqWY3LDk
+ooCElYcob01/JWzoXl61Z5sdrMH5CVZJty5foHKusAN5AgMBAAE=
+-----END PUBLIC KEY-----""""""
+        cls.pub_key = parsePEMKey(pub_key, public=True)
+
+    def test_sanity(self):
+        self.assertIsNotNone(self.priv_key)
+        self.assertIsNotNone(self.pub_key)
+
+        self.assertEqual(
+            self.priv_key.d,
+            bytesToNumber(a2b_hex(
+                ""2517eacb3afef4bffae60398df9957a5d2a154a83368d8e15842b2f59ee0""
+                ""9f79197bd2ef1e9addaf8786f6b4127447405e3042b21f2f50b7aa737716""
+                ""80c3bbcb6c225a5d5ff6b56c471c1882a0a33b0af165a3ed6c249dc7783e""
+                ""6bc758ac37e6572d33fe325078ed952650f2eb9604902ef99a511a1119d1""
+                ""3c4fc9a43a175dcdfbfb1a1400fe17093b69cd3cdb895f65432ea2195f90""
+                ""511c7336b58a685dacff2daf4c5e92e565b1665ae60e512baa9965b808d5""
+                ""ff119ceb7cd692cbf920067afacd809f66be706da26810ac790db156c948""
+                ""e6fe581bc9849157f4da493f3a64b0c6e119e031b107f8436ce29160b458""
+                ""b8f9f1095fdeb19263384ff5387557bc4f10b4034de841703bad2c1e769c""
+                ""23853eb630a36d1061dd46e2a6bbaf743a97f0b32c36f50c1a3722def3a3""
+                ""94d91c2e078bf09d795ecde5e56b8202f974026f75fc56e9a0dd6a88f2e7""
+                ""cb78ef1298cc6c65207ca45bd37188807b4fcdb1e60dd8e5b85648fb7efa""
+                ""8b6fdd448f39741a8d9809fe163af3de45bac24a5a841c81"")))
+
+    def test_simple(self):
+        msg = b'some long message'
+        self.assertEqual(
+            msg,
+            self.priv_key.decrypt(self.pub_key.encrypt(msg)))
+
+    def test_simple_max_len(self):
+        msg = b's' * (numBytes(self.pub_key.n)-2-8-1)
+        self.assertEqual(
+            msg,
+            self.priv_key.decrypt(self.pub_key.encrypt(msg)))
+
+    def test_simple_with_empty(self):
+        self.assertEqual(
+            b'',
+            self.priv_key.decrypt(self.pub_key.encrypt(b'')))
+
+    def test_negative_with_zero_length(self):
+        # and invalid ciphertext that generates a synthethic plaintext
+        # that's zero bytes in length
+        ciphertext = a2b_hex(remove_whitespace(""""""
+5e956cd9652f4a2ece902931013e09662b6a9257ad1e987fb75f73a0606df2a4b04789770820
+c2e02322c4e826f767bd895734a01e20609c3be4517a7a2a589ea1cdc137beb73eb38dac781b
+52e863de9620f79f9b90fd5b953651fcbfef4a9f1cc07421d511a87dd6942caab6a5a0f4df47
+3e62defb529a7de1509ab99c596e1dff1320402298d8be73a896cc86c38ae3f2f576e9ea70cc
+28ad575cb0f854f0be43186baa9c18e29c47c6ca77135db79c811231b7c1730955887d321fdc
+06568382b86643cf089b10e35ab23e827d2e5aa7b4e99ff2e914f302351819eb4d1693243b35
+f8bf1d42d08f8ec4acafa35f747a4a975a28643ec630d8e4fa5be59d81995660a14bb64c1fea
+5146d6b11f92da6a3956dd5cb5e0d747cf2ea23f81617769185336263d46ef4c144b754de62a
+6337342d6c85a95f19f015724546ee3fc4823eca603dbc1dc01c2d5ed50bd72d8e96df2dc048
+edde0081284068283fc5e73a6139851abf2f29977d0b3d160c883a42a37efba1be05c1a0b174
+1d7ddf59""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(b'', msg)
+
+    def test_negative_with_max_len_plus_one_in_first_value_from_prf(self):
+        # an invalid ciphertext that generates last length that's one byte
+        # too long for the key size, so the second to last value needs to get
+        # used
+        ciphertext = a2b_hex(remove_whitespace(""""""
+7db0390d75fcf9d4c59cf27b264190d856da9abd11e92334d0e5f71005cfed865a711dfa28b7
+91188374b61916dbc11339bf14b06f5f3f68c206c5607380e13da3129bfb744157e1527dd6fd
+f6651248b028a496ae1b97702d44706043cdaa7a59c0f41367303f21f268968bf3bd2904db3a
+e5239b55f8b438d93d7db9d1666c071c0857e2ec37757463769c54e51f052b2a71b04c2869e9
+e7049a1037b8429206c99726f07289bac18363e7eb2a5b417f47c37a55090cda676517b3549c
+873f2fe95da9681752ec9864b069089a2ed2f340c8b04ee00079055a817a3355b46ac7dc00d1
+7f4504ccfbcfcadb0c04cb6b22069e179385ae1eafabad5521bac2b8a8ee1dfff59a22eb3fda
+cfc87175d10d7894cfd869d056057dd9944b869c1784fcc27f731bc46171d39570fbffbadf08
+2d33f6352ecf44aca8d9478e53f5a5b7c852b401e8f5f74da49da91e65bdc97765a9523b7a08
+85a6f8afe5759d58009fbfa837472a968e6ae92026a5e0202a395483095302d6c3985b5f5831
+c521a271""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+
+        plaintext = a2b_hex(""56a3bea054e01338be9b7d7957539c"")
+
+        self.assertEqual(len(plaintext), 15)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_with_max_len(self):
+        # an invalid ciphertext that generates a plaintext of maximum size
+        # for this key size
+        ciphertext = a2b_hex(remove_whitespace(""""""
+1715065322522dff85049800f6a29ab5f98c465020467414b2a44127fe9446da47fa18047900
+f99afe67c2df6f50160bb8e90bff296610fde632b3859d4d0d2e644f23835028c46cca01b84b
+88231d7e03154edec6627bcba23de76740d839851fa12d74c8f92e540c73fe837b91b7d699b3
+11997d5f0f7864c486d499c3a79c111faaacbe4799597a25066c6200215c3d158f3817c1aa57
+f18bdaad0be1658da9da93f5cc6c3c4dd72788af57adbb6a0c26f42d32d95b8a4f95e8c6feb2
+f8a5d53b19a50a0b7cbc25e055ad03e5ace8f3f7db13e57759f67b65d143f08cca15992c6b2a
+ae643390483de111c2988d4e76b42596266005103c8de6044fb7398eb3c28a864fa672de5fd8
+774510ff45e05969a11a4c7d3f343e331190d2dcf24fb9154ba904dc94af98afc5774a9617d0
+418fe6d13f8245c7d7626c176138dd698a23547c25f27c2b98ea4d8a45c7842b81888e4cc14e
+5b72e9cf91f56956c93dbf2e5f44a8282a7813157fc481ff1371a0f66b31797e81ebdb09a673
+d4db96d6""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+
+        plaintext = a2b_hex(remove_whitespace(""""""
+7b036fcd6243900e4236c894e2462c17738acc87e01a76f4d95cb9a328d9acde81650283b8e8
+f60a217e3bdee835c7b222ad4c85d0acdb9a309bd2a754609a65dec50f3aa04c6d5891034566
+b9563d42668ede1f8992b17753a2132e28970584e255efc8b45a41c5dbd7567f014acec5fe6f
+db6d484790360a913ebb9defcd74ff377f2a8ba46d2ed85f733c9a3da08eb57ecedfafda8067
+78f03c66b2c5d2874cec1c291b2d49eb194c7b5d0dd2908ae90f4843268a2c45563092ade08a
+cb6ab481a08176102fc803fbb2f8ad11b0e1531bd37df543498daf180b12017f4d4d426ca29b
+4161075534bfb914968088a9d13785d0adc0e2580d3548494b2a9e91605f2b27e6cc701c796f
+0de7c6f471f6ab6cb9272a1ed637ca32a60d117505d82af3c1336104afb537d01a8f70b510e1
+eebf4869cb976c419473795a66c7f5e6e20a8094b1bb603a74330c537c5c0698c31538bd2e13
+8c1275a1bdf24c5fa8ab3b7b526324e7918a382d1363b3d463764222150e04""""""))
+        self.assertEqual(len(plaintext), 373)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_9_bytes_long(self):
+        ciphertext = a2b_hex(remove_whitespace(""""""
+6c60845a854b4571f678941ae35a2ac03f67c21e21146f9db1f2306be9f136453b86ad55647d
+4f7b5c9e62197aaff0c0e40a3b54c4cde14e774b1c5959b6c2a2302896ffae1f73b00b862a20
+ff4304fe06cea7ff30ecb3773ca9af27a0b54547350d7c07dfb0a39629c7e71e83fc5af9b2ad
+baf898e037f1de696a3f328cf45af7ec9aff7173854087fb8fbf34be981efbd8493f9438d1b2
+ba2a86af082662aa46ae9adfbec51e5f3d9550a4dd1dcb7c8969c9587a6edc82a8cabbc785c4
+0d9fbd12064559fb769450ac3e47e87bc046148130d7eaa843e4b3ccef3675d0630500803cb7
+ffee3882378c1a404e850c3e20707bb745e42b13c18786c4976076ed9fa8fd0ff15e571bef02
+cbbe2f90c908ac3734a433b73e778d4d17fcc28f49185ebc6e8536a06d293202d94496453bfd
+f1c2c7833a3f99fa38ca8a81f42eaa529d603b890308a319c0ab63a35ff8ebac965f6278f5a7
+e5d622be5d5fe55f0ca3ec993d55430d2bf59c5d3e860e90c16d91a04596f6fdf60d89ed95d8
+8c036dde""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        plaintext = b'forty two'
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_9_bytes_long_with_null_padded_ciphertext(self):
+        # a valid ciphertext that starts with a null byte and decrypts to
+        # 9 byte long value
+        ciphertext = a2b_hex(remove_whitespace(""""""
+00f4d565a3286784dbb85327db8807ae557ead229f92aba945cecda5225f606a7d6130edeeb6
+f26724d1eff1110f9eb18dc3248140ee3837e6688391e78796c526791384f045e21b6b853fb6
+342a11f309eb77962f37ce23925af600847fbd30e6e07e57de50b606e6b7f288cc777c1a6834
+f27e6edace508452128916eef7788c8bb227e3548c6a761cc4e9dd1a3584176dc053ba3500ad
+b1d5e1611291654f12dfc5722832f635db3002d73f9defc310ace62c63868d341619c7ee15b2
+0243b3371e05078e11219770c701d9f341af35df1bc729de294825ff2e416aa1152661285277
+7eb131f9c45151eb144980d70608d2fc4043477368369aa0fe487a48bd57e66b00c3c58f9415
+49f5ec050fca64449debe7a0c4ac51e55cb71620a70312aa4bd85fac1410c9c7f9d6ec610b7d
+11bf8faeffa20255d1a1bead9297d0aa8765cd2805847d639bc439f4a6c896e2008f746f9590
+ff4596de5ddde000ed666c452c978043ff4298461eb5a26d5e63d821438627f91201924bf7f2
+aeee1727""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        plaintext = b'forty two'
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_positive_9_bytes_long_with_double_null_padded_ciphertext(self):
+        # a valid ciphertext that starts with two null bytes and decrypts to
+        # 9 byte long value
+        ciphertext = a2b_hex(remove_whitespace(""""""
+00001ec97ac981dfd9dcc7a7389fdfa9d361141dac80c23a060410d472c16094e6cdffc0c368
+4d84aa402d7051dfccb2f6da33f66985d2a259f5b7fbf39ac537e95c5b7050eb18844a0513ab
+ef812cc8e74a3c5240009e6e805dcadf532bc1a2702d5acc9e585fad5b89d461fcc1397351cd
+ce35171523758b171dc041f412e42966de7f94856477356d06f2a6b40e3ff0547562a4d91bbf
+1338e9e049facbee8b20171164505468cd308997447d3dc4b0acb49e7d368fedd8c734251f30
+a83491d2506f3f87318cc118823244a393dc7c5c739a2733d93e1b13db6840a9429947357f47
+b23fbe39b7d2d61e5ee26f9946c4632f6c4699e452f412a26641d4751135400713cd56ec66f0
+370423d55d2af70f5e7ad0adea8e4a0d904a01e4ac272eba4af1a029dd53eb71f115bf31f7a6
+c8b19a6523adeecc0d4c3c107575e38572a8f8474ccad163e46e2e8b08111132aa97a16fb588
+c9b7e37b3b3d7490381f3c55d1a9869a0fd42cd86fed59ecec78cb6b2dfd06a497f5afe34196
+91314ba0""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        plaintext = b'forty two'
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_9_bytes_long(self):
+        ciphertext = a2b_hex(remove_whitespace(""""""
+5c8555f5cef627c15d37f85c7f5fd6e499264ea4b8e3f9112023aeb722eb38d8eac2be3751fd
+5a3785ab7f2d59fa3728e5be8c3de78a67464e30b21ee23b5484bb3cd06d0e1c6ad25649c851
+8165653eb80488bfb491b20c04897a6772f69292222fc5ef50b5cf9efc6d60426a449b6c4895
+69d48c83488df629d695653d409ce49a795447fcec2c58a1a672e4a391401d428baaf781516e
+11e323d302fcf20f6eab2b2dbe53a48c987e407c4d7e1cb41131329138313d330204173a4f3f
+f06c6fadf970f0ed1005d0b27e35c3d11693e0429e272d583e57b2c58d24315c397856b34485
+dcb077665592b747f889d34febf2be8fce66c265fd9fc3575a6286a5ce88b4b413a08efc57a0
+7a8f57a999605a837b0542695c0d189e678b53662ecf7c3d37d9dbeea585eebfaf79141118e0
+6762c2381fe27ca6288edddc19fd67cd64f16b46e06d8a59ac530f22cd83cc0bc4e37feb5201
+5cbb2283043ccf5e78a4eb7146827d7a466b66c8a4a4826c1bad68123a7f2d00fc1736525ff9
+0c058f56""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertNotEqual(dec[-10:-9], b'\x00')
+
+        plaintext = a2b_hex(remove_whitespace(""257906ca6de8307728""))
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'forty two')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_9_bytes_long_from_second_prf_value(self):
+        # malformed plaintext that generates a fake plaintext of length
+        # specified by 2nd to last value from PRF
+        ciphertext = a2b_hex(remove_whitespace(""""""
+758c215aa6acd61248062b88284bf43c13cb3b3d02410be4238607442f1c0216706e21a03a2c
+10eb624a63322d854da195c017b76fea83e274fa371834dcd2f3b7accf433fc212ad76c0bac3
+66e1ed32e25b279f94129be7c64d6e162adc08ccebc0cfe8e926f01c33ab9c065f0e0ac83ae5
+137a4cb66702615ad68a35707d8676d2740d7c1a954680c83980e19778ed11eed3a7c2dbdfc4
+61a9bbef671c1bc00c882d361d29d5f80c42bdf5efec886c34138f83369c6933b2ac4e93e764
+265351b4a0083f040e14f511f09b22f96566138864e4e6ff24da4810095da98e058541095153
+8ced2f757a277ff8e17172f06572c9024eeae503f176fd46eb6c5cd9ba07af11cde31dccac12
+eb3a4249a7bfd3b19797ad1656984bfcbf6f74e8f99d8f1ac420811f3d166d87f935ef15ae85
+8cf9e72c8e2b547bf16c3fb09a8c9bf88fd2e5d38bf24ed610896131a84df76b9f920fe76d71
+fff938e9199f3b8cd0c11fd0201f9139d7673a871a9e7d4adc3bbe360c8813617cd60a90128f
+be34c9d5""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertNotEqual(dec[-10:-9], b'\x00')
+
+        plaintext = a2b_hex(remove_whitespace(""043383c929060374ed""))
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'forty two')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_9_bytes_long_from_third_prf_value(self):
+        # malformed plaintext that generates a fake plaintext of length
+        # specified by 3rd to last value from PRF
+        ciphertext = a2b_hex(remove_whitespace(""""""
+7b22d5e62d287968c6622171a1f75db4b0fd15cdf3134a1895d235d56f8d8fe619f2bf486817
+4a91d7601a82975d2255190d28b869141d7c395f0b8c4e2be2b2c1b4ffc12ce749a6f6803d4c
+fe7fba0a8d6949c04151f981c0d84592aa2ff25d1bd3ce5d10cb03daca6b496c6ad40d30bfa8
+acdfd02cdb9326c4bdd93b949c9dc46caa8f0e5f429785bce64136a429a3695ee674b647452b
+ea1b0c6de9c5f1e8760d5ef6d5a9cfff40457b023d3c233c1dcb323e7808103e73963b2eafc9
+28c9eeb0ee3294955415c1ddd9a1bb7e138fecd79a3cb89c57bd2305524624814aaf0fd1acbf
+379f7f5b39421f12f115ba488d380586095bb53f174fae424fa4c8e3b299709cd344b9f949b1
+ab57f1c645d7ed3c8f81d5594197355029fee8960970ff59710dc0e5eb50ea6f4c3938e3f89e
+d7933023a2c2ddffaba07be147f686828bd7d520f300507ed6e71bdaee05570b27bc92741108
+ac2eb433f028e138dd6d63067bc206ea2d826a7f41c0d613daed020f0f30f4e272e9618e0a8c
+39018a83""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertNotEqual(dec[0:1], b'\x00')
+        self.assertNotEqual(dec[1:2], b'\x02')
+        self.assertNotEqual(dec[-10:-9], b'\x00')
+
+        plaintext = a2b_hex(remove_whitespace(""70263fa6050534b9e0""))
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'forty two')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_9_bytes_long_wrong_version_byte(self):
+        # an otherwise correct plaintext, but with wrong first byte
+        # (0x01 instead of 0x00), generates a random 9 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+6db80adb5ff0a768caf1378ecc382a694e7d1bde2eff4ba12c48aaf794ded7a994a5b2b57ace
+c20dbec4ae385c9dd531945c0f197a5496908725fc99d88601a17d3bb0b2d38d2c1c3100f399
+55a4cb3dbed5a38bf900f23d91e173640e4ec655c84fdfe71fcdb12a386108fcf718c9b7af37
+d39703e882436224c877a2235e8344fba6c951eb7e2a4d1d1de81fb463ac1b880f6cc0e59ade
+05c8ce35179ecd09546731fc07b141d3d6b342a97ae747e61a9130f72d37ac5a2c30215b6cbd
+66c7db893810df58b4c457b4b54f34428247d584e0fa71062446210db08254fb9ead1ba1a393
+c724bd291f0cf1a7143f32df849051dc896d7d176fef3b57ab6dffd626d0c3044e9edb2e3d01
+2ace202d2581df01bec7e9aa0727a6650dd373d374f0bc0f4a611f8139dfe97d63e70c6188f4
+df5b672e47c51d8aa567097293fbff127c75ec690b43407578b73c85451710a0cece58fd497d
+7f7bd36a8a92783ef7dc6265dff52aac8b70340b996508d39217f2783ce6fc91a1cc94bb2ac4
+87b84f62""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid in precisely
+        # one byte
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x01\x02')
+        for val in dec[2:-10]:
+            self.assertNotEqual(val, 0)
+        self.assertEqual(dec[-10:], b'\x00forty two')
+
+        plaintext = a2b_hex(""6d8d3a094ff3afff4c"")
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'forty two')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_9_bytes_long_wrong_type_byte(self):
+        # an otherwise correct plaintext, but with wrong second byte
+        # (0x01 instead of 0x02), generates a random 9 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+417328c034458563079a4024817d0150340c34e25ae16dcad690623f702e5c748a6ebb3419ff
+48f486f83ba9df35c05efbd7f40613f0fc996c53706c30df6bba6dcd4a40825f96133f3c2163
+8a342bd4663dffbd0073980dac47f8c1dd8e97ce1412e4f91f2a8adb1ac2b1071066efe8d718
+bbb88ca4a59bd61500e826f2365255a409bece0f972df97c3a55e09289ef5fa815a2353ef393
+fd1aecfc888d611c16aec532e5148be15ef1bf2834b8f75bb26db08b66d2baad6464f8439d19
+86b533813321dbb180080910f233bcc4dd784fb21871aef41be08b7bfad4ecc3b68f228cb531
+7ac6ec1227bc7d0e452037ba918ee1da9fdb8393ae93b1e937a8d4691a17871d5092d2384b61
+90a53df888f65b951b05ed4ad57fe4b0c6a47b5b22f32a7f23c1a234c9feb5d8713d94968676
+0680da4db454f4acad972470033472b9864d63e8d23eefc87ebcf464ecf33f67fbcdd48eab38
+c5292586b36aef5981ed2fa07b2f9e23fc57d9eb71bfff4111c857e9fff23ceb31e72592e70c
+874b4936""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid in precisely
+        # one byte
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x00\x01')
+        for val in dec[2:-10]:
+            self.assertNotEqual(val, 0)
+        self.assertEqual(dec[-10:], b'\x00forty two')
+
+        plaintext = a2b_hex(""c6ae80ffa80bc184b0"")
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'forty two')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_9_bytes_long_null_byte_in_first_byte_of_padding(self):
+        # an otherwise correct plaintext, but with wrong third byte
+        # (0x00 instead of non-zero), generates a random 9 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+8542c626fe533467acffcd4e617692244c9b5a3bf0a215c5d64891ced4bf4f9591b4b2aedff9
+843057986d81631b0acb3704ec2180e5696e8bd15b217a0ec36d2061b0e2182faa3d1c59bd3f
+9086a10077a3337a3f5da503ec3753535ffd25b837a12f2541afefd0cffb0224b8f874e4bed1
+3949e105c075ed44e287c5ae03b155e06b90ed247d2c07f1ef3323e3508cce4e4074606c5417
+2ad74d12f8c3a47f654ad671104bf7681e5b061862747d9afd37e07d8e0e2291e01f14a95a1b
+b4cbb47c304ef067595a3947ee2d722067e38a0f046f43ec29cac6a8801c6e3e9a2331b1d45a
+7aa2c6af3205be382dd026e389614ee095665a611ab2e8dced2ee1c9d08ac9de11aef5b3803f
+c9a9ce8231ec87b5fed386fb92ee3db995a89307bcba844bd0a691c29ae51216e949dfc81313
+3cb06a07265fd807bcb3377f6adb0a481d9b7f442003115895939773e6b95371c4febef29eda
+e946fa245e7c50729e2e558cfaad773d1fd5f67b457a6d9d17a847c6fcbdb103a86f35f228ce
+fc06cea0""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid in precisely
+        # one byte
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:3], b'\x00\x02\x00')
+        for val in dec[3:-10]:
+            self.assertNotEqual(val, 0)
+        self.assertEqual(dec[-10:], b'\x00forty two')
+
+        plaintext = a2b_hex(""a8a9301daa01bb25c7"")
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'forty two')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_9_bytes_long_null_byte_in_eighth_byte_of_padding(self):
+        # an otherwise correct plaintext, but with wrong tenth byte
+        # (0x00 instead of non-zero), generates a random 9 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+449dfa237a70a99cb0351793ec8677882021c2aa743580bf6a0ea672055cffe8303ac42855b1
+d1f3373aae6af09cb9074180fc963e9d1478a4f98b3b4861d3e7f0aa8560cf603711f139db77
+667ca14ba3a1acdedfca9ef4603d6d7eb0645bfc805304f9ad9d77d34762ce5cd84bd3ec9d35
+c30e3be72a1e8d355d5674a141b5530659ad64ebb6082e6f73a80832ab6388912538914654d3
+4602f4b3b1c78589b4a5d964b2efcca1dc7004c41f6cafcb5a7159a7fc7c0398604d0edbd4c8
+f4f04067da6a153a05e7cbeea13b5ee412400ef7d4f3106f4798da707ec37a11286df2b7a204
+856d5ff773613fd1e453a7114b78e347d3e8078e1cb3276b3562486ba630bf719697e0073a12
+3c3e60ebb5c7a1ccff4279faffa2402bc1109f8d559d6766e73591943dfcf25ba10c3762f02a
+f85187799b8b4b135c3990793a6fd32642f1557405ba55cc7cf7336a0e967073c5fa50743f9c
+c5e3017c172d9898d2af83345e71b3e0c22ab791eacb6484a32ec60ebc226ec9deaee91b1a05
+60c2b571""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid in precisely
+        # one byte
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x00\x02')
+        for val in dec[2:9]:
+            self.assertNotEqual(val, 0)
+        self.assertEqual(dec[9], 0)
+        for val in dec[10:-10]:
+            self.assertNotEqual(val, 0)
+        self.assertEqual(dec[-10:], b'\x00forty two')
+
+        plaintext = a2b_hex(""6c716fe01d44398018"")
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'forty two')
+        self.assertEqual(msg, plaintext)
+
+    def test_negative_9_bytes_long_missing_null_separator(self):
+        # an otherwise correct plaintext, but with the null byte specifying
+        # end of padding missing, generates a random 9 byte long plaintext
+        ciphertext = a2b_hex(remove_whitespace(""""""
+a7a5c99e50da48769ecb779d9abe86ef9ec8c38c6f43f17c7f2d7af608a4a1bd6cf695b47e97
+c191c61fb5a27318d02f495a176b9fae5a55b5d3fabd1d8aae4957e3879cb0c60f037724e11b
+e5f30f08fc51c033731f14b44b414d11278cd3dba7e1c8bfe208d2b2bb7ec36366dacb6c88b2
+4cd79ab394adf19dbbc21dfa5788bacbadc6a62f79cf54fd8cf585c615b5c0eb94c35aa9de25
+321c8ffefb8916bbaa2697cb2dd82ee98939df9b6704cee77793edd2b4947d82e00e57496649
+70736c59a84197bd72b5c71e36aae29cd39af6ac73a368edbc1ca792e1309f442aafcd77c992
+c88f8e4863149f221695cb7b0236e75b2339a02c4ea114854372c306b9412d8eedb600a31532
+002f2cea07b4df963a093185e4607732e46d753b540974fb5a5c3f9432df22e85bb176113709
+66c5522fd23f2ad3484341ba7fd8885fc8e6d379a611d13a2aca784fba2073208faad2137bf1
+979a0fa146c1880d4337db3274269493bab44a1bcd0681f7227ffdf589c2e925ed9d36302509
+d1109ba4""""""))
+        self.assertEqual(len(ciphertext), numBytes(self.pub_key.n))
+
+        # sanity check that the decrypted ciphertext is invalid in precisely
+        # one byte
+        dec = self.priv_key._raw_private_key_op_bytes(ciphertext)
+        self.assertEqual(dec[0:2], b'\x00\x02')
+        for val in dec[2:-10]:
+            self.assertNotEqual(val, 0)
+        self.assertEqual(dec[-10:], b'\x01forty two')
+
+        plaintext = a2b_hex(""aa2de6cde4e2442884"")
+
+        self.assertEqual(len(plaintext), 9)
+
+        msg = self.priv_key.decrypt(ciphertext)
+
+        self.assertNotEqual(msg, b'forty two')
+        self.assertEqual(msg, plaintext)"
GHSA-976r-qfjj-c24w,"From afa4b11fddfdbadb048f742cf66d5c21c675a5c8 Mon Sep 17 00:00:00 2001
From: tooptoop4 <33283496+tooptoop4@users.noreply.github.com>
Date: Fri, 27 Dec 2019 08:24:41 +0000
Subject: [PATCH] [AIRFLOW-6351] security - ui - Add Cross Site Scripting
 defence (#6913)

---
 airflow/www_rbac/views.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/airflow/www_rbac/views.py b/airflow/www_rbac/views.py
index 745c563a710da..4ea74f706b4b3 100644
--- a/airflow/www_rbac/views.py
+++ b/airflow/www_rbac/views.py
@@ -321,7 +321,7 @@ def get_int_arg(value, default=0):
             num_dag_to=min(end, num_of_all_dags),
             num_of_all_dags=num_of_all_dags,
             paging=wwwutils.generate_pages(current_page, num_of_pages,
-                                           search=arg_search_query,
+                                           search=escape(arg_search_query) if arg_search_query else None,
                                            showPaused=not hide_paused),
             num_runs=num_runs,
             tags=tags)"
GHSA-hmr4-m2h5-33qx,"From eb31d845323618d688ad429479c6dda973056136 Mon Sep 17 00:00:00 2001
From: Simon Charette <charette.s@gmail.com>
Date: Tue, 31 Dec 2019 12:46:06 -0500
Subject: [PATCH] Fixed CVE-2020-7471 -- Properly escaped StringAgg(delimiter)
 parameter.

---
 django/contrib/postgres/aggregates/general.py |  6 ++++--
 django/contrib/postgres/aggregates/mixins.py  |  4 ++--
 docs/releases/1.11.28.txt                     | 13 +++++++++++++
 docs/releases/2.2.10.txt                      | 13 +++++++++++++
 docs/releases/3.0.3.txt                       |  8 +++++++-
 docs/releases/index.txt                       |  2 ++
 tests/postgres_tests/test_aggregates.py       |  4 ++++
 7 files changed, 45 insertions(+), 5 deletions(-)
 create mode 100644 docs/releases/1.11.28.txt
 create mode 100644 docs/releases/2.2.10.txt

diff --git a/django/contrib/postgres/aggregates/general.py b/django/contrib/postgres/aggregates/general.py
index 918373e926e7..9616bc3e3e21 100644
--- a/django/contrib/postgres/aggregates/general.py
+++ b/django/contrib/postgres/aggregates/general.py
@@ -1,4 +1,5 @@
 from django.contrib.postgres.fields import ArrayField, JSONField
+from django.db.models import Value
 from django.db.models.aggregates import Aggregate
 
 from .mixins import OrderableAggMixin
@@ -51,11 +52,12 @@ def convert_value(self, value, expression, connection):
 
 class StringAgg(OrderableAggMixin, Aggregate):
     function = 'STRING_AGG'
-    template = ""%(function)s(%(distinct)s%(expressions)s, '%(delimiter)s'%(ordering)s)""
+    template = '%(function)s(%(distinct)s%(expressions)s %(ordering)s)'
     allow_distinct = True
 
     def __init__(self, expression, delimiter, **extra):
-        super().__init__(expression, delimiter=delimiter, **extra)
+        delimiter_expr = Value(str(delimiter))
+        super().__init__(expression, delimiter_expr, **extra)
 
     def convert_value(self, value, expression, connection):
         if not value:
diff --git a/django/contrib/postgres/aggregates/mixins.py b/django/contrib/postgres/aggregates/mixins.py
index 3a43ca1a63ff..82e8eebdf4cf 100644
--- a/django/contrib/postgres/aggregates/mixins.py
+++ b/django/contrib/postgres/aggregates/mixins.py
@@ -3,7 +3,7 @@
 
 class OrderableAggMixin:
 
-    def __init__(self, expression, ordering=(), **extra):
+    def __init__(self, *expressions, ordering=(), **extra):
         if not isinstance(ordering, (list, tuple)):
             ordering = [ordering]
         ordering = ordering or []
@@ -12,7 +12,7 @@ def __init__(self, expression, ordering=(), **extra):
             (OrderBy(F(o[1:]), descending=True) if isinstance(o, str) and o[0] == '-' else o)
             for o in ordering
         )
-        super().__init__(expression, **extra)
+        super().__init__(*expressions, **extra)
         self.ordering = self._parse_expressions(*ordering)
 
     def resolve_expression(self, *args, **kwargs):
diff --git a/docs/releases/1.11.28.txt b/docs/releases/1.11.28.txt
new file mode 100644
index 000000000000..81ccb0ce06f8
--- /dev/null
+++ b/docs/releases/1.11.28.txt
@@ -0,0 +1,13 @@
+============================
+Django 1.11.28 release notes
+============================
+
+*February 3, 2020*
+
+Django 1.11.28 fixes a security issue in 1.11.27.
+
+CVE-2020-7471: Potential SQL injection via ``StringAgg(delimiter)``
+===================================================================
+
+:class:`~django.contrib.postgres.aggregates.StringAgg` aggregation function was
+subject to SQL injection, using a suitably crafted ``delimiter``.
diff --git a/docs/releases/2.2.10.txt b/docs/releases/2.2.10.txt
new file mode 100644
index 000000000000..f82774dea096
--- /dev/null
+++ b/docs/releases/2.2.10.txt
@@ -0,0 +1,13 @@
+===========================
+Django 2.2.10 release notes
+===========================
+
+*February 3, 2020*
+
+Django 2.2.10 fixes a security issue in 2.2.9.
+
+CVE-2020-7471: Potential SQL injection via ``StringAgg(delimiter)``
+===================================================================
+
+:class:`~django.contrib.postgres.aggregates.StringAgg` aggregation function was
+subject to SQL injection, using a suitably crafted ``delimiter``.
diff --git a/docs/releases/3.0.3.txt b/docs/releases/3.0.3.txt
index ed92938e091c..2eed2654c862 100644
--- a/docs/releases/3.0.3.txt
+++ b/docs/releases/3.0.3.txt
@@ -4,7 +4,13 @@ Django 3.0.3 release notes
 
 *Expected February 3, 2020*
 
-Django 3.0.3 fixes several bugs in 3.0.2.
+Django 3.0.3 fixes a security issue and several bugs in 3.0.2.
+
+CVE-2020-7471: Potential SQL injection via ``StringAgg(delimiter)``
+===================================================================
+
+:class:`~django.contrib.postgres.aggregates.StringAgg` aggregation function was
+subject to SQL injection, using a suitably crafted ``delimiter``.
 
 Bugfixes
 ========
diff --git a/docs/releases/index.txt b/docs/releases/index.txt
index 411ca4805ce7..6a688587ef19 100644
--- a/docs/releases/index.txt
+++ b/docs/releases/index.txt
@@ -42,6 +42,7 @@ versions of the documentation contain the release notes for any later releases.
 .. toctree::
    :maxdepth: 1
 
+   2.2.10
    2.2.9
    2.2.8
    2.2.7
@@ -100,6 +101,7 @@ versions of the documentation contain the release notes for any later releases.
 .. toctree::
    :maxdepth: 1
 
+   1.11.28
    1.11.27
    1.11.26
    1.11.25
diff --git a/tests/postgres_tests/test_aggregates.py b/tests/postgres_tests/test_aggregates.py
index af84f12e916c..a1dbe4441c72 100644
--- a/tests/postgres_tests/test_aggregates.py
+++ b/tests/postgres_tests/test_aggregates.py
@@ -169,6 +169,10 @@ def test_string_agg_requires_delimiter(self):
         with self.assertRaises(TypeError):
             AggregateTestModel.objects.aggregate(stringagg=StringAgg('char_field'))
 
+    def test_string_agg_delimiter_escaping(self):
+        values = AggregateTestModel.objects.aggregate(stringagg=StringAgg('char_field', delimiter=""'""))
+        self.assertEqual(values, {'stringagg': ""Foo1'Foo2'Foo4'Foo3""})
+
     def test_string_agg_charfield(self):
         values = AggregateTestModel.objects.aggregate(stringagg=StringAgg('char_field', delimiter=';'))
         self.assertEqual(values, {'stringagg': 'Foo1;Foo2;Foo4;Foo3'})"
PYSEC-2012-7,"From 9305c0e12d43c4df999c3301a1f0c742264a657e Mon Sep 17 00:00:00 2001
From: Preston Holmes <preston@ptone.com>
Date: Wed, 17 Oct 2012 14:36:41 -0700
Subject: [PATCH] Fixed a security issue related to password resets

Full disclosure and new release are forthcoming
---
 django/contrib/auth/tests/urls.py  |  1 +
 django/contrib/auth/tests/views.py | 37 ++++++++++++++++++++++++++++++
 django/contrib/auth/views.py       |  2 +-
 django/http/__init__.py            |  5 ++++
 4 files changed, 44 insertions(+), 1 deletion(-)

diff --git a/django/contrib/auth/tests/urls.py b/django/contrib/auth/tests/urls.py
index 8f9e848aa952..4b498ceaf0a7 100644
--- a/django/contrib/auth/tests/urls.py
+++ b/django/contrib/auth/tests/urls.py
@@ -55,6 +55,7 @@ def userpage(request):
     (r'^logout/next_page/$', 'django.contrib.auth.views.logout', dict(next_page='/somewhere/')),
     (r'^remote_user/$', remote_user_auth_view),
     (r'^password_reset_from_email/$', 'django.contrib.auth.views.password_reset', dict(from_email='staffmember@example.com')),
+    (r'^admin_password_reset/$', 'django.contrib.auth.views.password_reset', dict(is_admin_site=True)),
     (r'^login_required/$', login_required(password_reset)),
     (r'^login_required_login_url/$', login_required(password_reset, login_url='/somewhere/')),
 
diff --git a/django/contrib/auth/tests/views.py b/django/contrib/auth/tests/views.py
index 5727dc289f77..bb17576d3146 100644
--- a/django/contrib/auth/tests/views.py
+++ b/django/contrib/auth/tests/views.py
@@ -5,6 +5,7 @@
 from django.contrib.sites.models import Site, RequestSite
 from django.contrib.auth.models import User
 from django.core import mail
+from django.core.exceptions import SuspiciousOperation
 from django.core.urlresolvers import reverse, NoReverseMatch
 from django.http import QueryDict
 from django.utils.encoding import force_text
@@ -103,6 +104,42 @@ def test_email_found_custom_from(self):
         self.assertEqual(len(mail.outbox), 1)
         self.assertEqual(""staffmember@example.com"", mail.outbox[0].from_email)
 
+    def test_admin_reset(self):
+        ""If the reset view is marked as being for admin, the HTTP_HOST header is used for a domain override.""
+        response = self.client.post('/admin_password_reset/',
+            {'email': 'staffmember@example.com'},
+            HTTP_HOST='adminsite.com'
+        )
+        self.assertEqual(response.status_code, 302)
+        self.assertEqual(len(mail.outbox), 1)
+        self.assertTrue(""http://adminsite.com"" in mail.outbox[0].body)
+        self.assertEqual(settings.DEFAULT_FROM_EMAIL, mail.outbox[0].from_email)
+
+    def test_poisoned_http_host(self):
+        ""Poisoned HTTP_HOST headers can't be used for reset emails""
+        # This attack is based on the way browsers handle URLs. The colon
+        # should be used to separate the port, but if the URL contains an @,
+        # the colon is interpreted as part of a username for login purposes,
+        # making 'evil.com' the request domain. Since HTTP_HOST is used to
+        # produce a meaningful reset URL, we need to be certain that the
+        # HTTP_HOST header isn't poisoned. This is done as a check when get_host()
+        # is invoked, but we check here as a practical consequence.
+        with self.assertRaises(SuspiciousOperation):
+            self.client.post('/password_reset/',
+                {'email': 'staffmember@example.com'},
+                HTTP_HOST='www.example:dr.frankenstein@evil.tld'
+            )
+        self.assertEqual(len(mail.outbox), 0)
+
+    def test_poisoned_http_host_admin_site(self):
+        ""Poisoned HTTP_HOST headers can't be used for reset emails on admin views""
+        with self.assertRaises(SuspiciousOperation):
+            self.client.post('/admin_password_reset/',
+                {'email': 'staffmember@example.com'},
+                HTTP_HOST='www.example:dr.frankenstein@evil.tld'
+            )
+        self.assertEqual(len(mail.outbox), 0)
+
     def _test_confirm_start(self):
         # Start by creating the email
         response = self.client.post('/password_reset/', {'email': 'staffmember@example.com'})
diff --git a/django/contrib/auth/views.py b/django/contrib/auth/views.py
index 747b5c0991d5..d27e2f5aba51 100644
--- a/django/contrib/auth/views.py
+++ b/django/contrib/auth/views.py
@@ -163,7 +163,7 @@ def password_reset(request, is_admin_site=False,
                 'request': request,
             }
             if is_admin_site:
-                opts = dict(opts, domain_override=request.META['HTTP_HOST'])
+                opts = dict(opts, domain_override=request.get_host())
             form.save(**opts)
             return HttpResponseRedirect(post_reset_redirect)
     else:
diff --git a/django/http/__init__.py b/django/http/__init__.py
index ecb39129addf..b385b450eeed 100644
--- a/django/http/__init__.py
+++ b/django/http/__init__.py
@@ -180,6 +180,11 @@ def get_host(self):
             server_port = str(self.META['SERVER_PORT'])
             if server_port != ('443' if self.is_secure() else '80'):
                 host = '%s:%s' % (host, server_port)
+
+        # Disallow potentially poisoned hostnames.
+        if set(';/?@&=+$,').intersection(host):
+            raise SuspiciousOperation('Invalid HTTP_HOST header: %s' % host)
+
         return host
 
     def get_full_path(self):"
CVE-2022-31508,"From fefef0d06816ac2d80ed3c80df20fa5deca43a48 Mon Sep 17 00:00:00 2001
From: Porcupiney Hairs <porucpiney.hairs@protonmail.com>
Date: Wed, 4 May 2022 00:21:36 +0530
Subject: [PATCH] # Absolute Path Traversal due to incorrect use of `send_file`
 call
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

A path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with dot-dot-slash (../) sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as dot-dot-slash, directory traversal, directory climbing and backtracking.

## Common Weakness Enumeration category
CWE - 36

## Root Cause Analysis

The `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.
```
>>> import os.path
>>> static = ""path/to/mySafeStaticDir""
>>> malicious = ""/../../../../../etc/passwd""
>>> os.path.join(t,malicious)
'/../../../../../etc/passwd'
```
Since the ""malicious"" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.

In this case, the problems occurs due to the following code :
https://github.com/idayrus/evoting/blob/d9ef8c7c0343c7986fe06ff976395775d5844732/app/helper/middleware.py#L23

Here, the `filename` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.

## Proof of Concept

The bug can be verified using a proof of concept similar to the one shown below.

```
curl --path-as-is 'http://<domain>/file/private//../../../../etc/passwd""'
```
## Remediation

This can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.

## Common Vulnerability Scoring System Vector

The attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be

(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]

This gives it a base score of 9.3/10 and a severity rating of critical.

## References
* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)
* github/securitylab#669

### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*
---
 app/helper/middleware.py | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/app/helper/middleware.py b/app/helper/middleware.py
index 736bff7..82bdc56 100644
--- a/app/helper/middleware.py
+++ b/app/helper/middleware.py
@@ -5,6 +5,7 @@
 from app.module.user.model import UserModel, UserTokenModel
 from app.module.user import UserSession
 from werkzeug.routing import BaseConverter, ValidationError
+from werkzeug.utils import safe_join
 from bson.objectid import ObjectId
 from bson.errors import InvalidId
 from os import path
@@ -18,7 +19,7 @@
 @login_required
 def private_static(filename):
     # Get path
-    filepath = path.join(app.config.get(""PRIVATE_DIR""), filename)
+    filepath = safe_join(app.config.get(""PRIVATE_DIR""), filename)
     if path.isfile(filepath):
         return send_file(filepath)
     # End"
CVE-2016-6903,"From e72dfcd1f258193f9aaea3591ecbdaed207661a0 Mon Sep 17 00:00:00 2001
From: Ignace Mouzannar <ignace@redhat.com>
Date: Sun, 21 Aug 2016 22:01:52 -0400
Subject: [PATCH] [security] MAJOR issue: catch ctrl escapes (Closes #149)

The was a major security issue with lshell that allows any user to
escape from lshell into bash (or any other available shell. This
was done by typing <CTRL-V><CTRL-J>bash after any allowed command.
For example:
~$ echo<CTRL-V><CTRL-J>bash

Thanks Vladislav Yarmak (@Snawoot) for reporting this major issue!
---
 lshell/sec.py           |  2 +-
 test/test_functional.py | 17 +++++++++++++++++
 2 files changed, 18 insertions(+), 1 deletion(-)

diff --git a/lshell/sec.py b/lshell/sec.py
index a6c317f..ea3561f 100644
--- a/lshell/sec.py
+++ b/lshell/sec.py
@@ -156,7 +156,7 @@ def check_secure(line, conf, strict=None, ssh=None):
     oline = line
 
     # strip all spaces/tabs
-    line = "" "".join(line.split())
+    line = line.strip()
 
     # init return code
     returncode = 0
diff --git a/test/test_functional.py b/test/test_functional.py
index f1135e1..d139e7e 100644
--- a/test/test_functional.py
+++ b/test/test_functional.py
@@ -384,6 +384,23 @@ def test_27_checksecure_awk(self):
 
         self.assertEqual(expected, result)
 
+    def test_28_catch_lnext_terminal_ctrl(self):
+        """""" F25 | test ctrl-v ctrl-j then command, forbidden/security """"""
+        self.child = pexpect.spawn('%s/bin/lshell '
+                                   '--config %s/etc/lshell.conf '
+                                   % (TOPDIR, TOPDIR))
+        self.child.expect('%s:~\$' % self.user)
+
+        expected = u'*** forbidden syntax: echo\r'
+        self.child.send('echo')
+        self.child.sendcontrol('v')
+        self.child.sendcontrol('j')
+        self.child.sendline('bash')
+        self.child.expect('%s:~\$' % self.user)
+
+        result = self.child.before.decode('utf8').split('\n')
+
+        self.assertIn(expected, result)
 
 if __name__ == '__main__':
     unittest.main()"
GHSA-7r87-cj48-wj45,"From 2811ae23a38d33b620fb7a07de8837c6d65c13e4 Mon Sep 17 00:00:00 2001
From: Joakim Uddholm <tethik@blacknode.se>
Date: Sat, 23 Apr 2022 23:40:14 +0200
Subject: [PATCH] add some extra tests to ensure False is returned

---
 test_flask_session_captcha.py | 8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/test_flask_session_captcha.py b/test_flask_session_captcha.py
index edf5332..0e74412 100644
--- a/test_flask_session_captcha.py
+++ b/test_flask_session_captcha.py
@@ -98,7 +98,13 @@ def test_captcha_validate_value(self):
         with self.app.test_request_context('/'):
             captcha.generate()
             answer = captcha.get_answer()
-            assert not captcha.validate(value=""wrong"")
+            assert captcha.validate(value=None) == False
+            captcha.generate()
+            answer = captcha.get_answer()
+            assert captcha.validate(value="""") == False
+            captcha.generate()
+            answer = captcha.get_answer()
+            assert captcha.validate(value=""wrong"") == False
             captcha.generate()
             answer = captcha.get_answer()
             assert captcha.validate(value=answer)"
GHSA-hpr6-f4vq-mxch,"From 01cd169ae5d077693d4c1a4679a95e30b8d44d54 Mon Sep 17 00:00:00 2001
From: Miguel Gagliardo <migag9@gmail.com>
Date: Mon, 5 Apr 2021 23:39:02 +0200
Subject: [PATCH] replace AWS CLI commands with boto3 calls for /graph endpoint
 (#3824)

---
 localstack/dashboard/infra.py      | 264 ++++++++++-------------------
 localstack/utils/aws/aws_models.py |   2 +-
 2 files changed, 90 insertions(+), 176 deletions(-)

diff --git a/localstack/dashboard/infra.py b/localstack/dashboard/infra.py
index 46c0dff310adc..8ac60ffc19935 100644
--- a/localstack/dashboard/infra.py
+++ b/localstack/dashboard/infra.py
@@ -1,22 +1,15 @@
 import re
 import os
-import json
 import logging
-import socket
 import tempfile
 from six import iteritems
-from localstack.config import DEFAULT_REGION
 from localstack.utils.aws import aws_stack
-from localstack.utils.common import (short_uid, parallelize, is_port_open, new_tmp_file,
-    to_str, rm_rf, unzip, download, clean_cache, mktime, load_file, mkdir, run, md5)
-from localstack.utils.bootstrap import is_api_enabled
+from localstack.utils.common import (short_uid, parallelize,
+    rm_rf, unzip, download, clean_cache, mktime, load_file, mkdir, md5)
 from localstack.utils.aws.aws_models import (ElasticSearch, S3Notification,
     EventSource, DynamoDB, DynamoDBStream, FirehoseStream, S3Bucket, SqsQueue,
     KinesisShard, KinesisStream, LambdaFunction)
 
-# TODO: CLI commands in this file need to be replaced with SDK calls!
-
-
 AWS_CACHE_TIMEOUT = 5  # 5 seconds
 AWS_LAMBDA_CODE_CACHE_TIMEOUT = 5 * 60  # 5 minutes
 MOCK_OBJ = False
@@ -31,94 +24,16 @@
 LOG = logging.getLogger(__name__)
 
 
-def run_cached(cmd, cache_duration_secs=None):
-    if cache_duration_secs is None:
-        cache_duration_secs = AWS_CACHE_TIMEOUT
-    env_vars = os.environ.copy()
-    env_vars.update({
-        'AWS_ACCESS_KEY_ID': os.environ.get('AWS_ACCESS_KEY_ID') or 'test',
-        'AWS_SECRET_ACCESS_KEY': os.environ.get('AWS_SECRET_ACCESS_KEY') or 'test',
-        'AWS_DEFAULT_REGION': DEFAULT_REGION or os.environ.get('AWS_DEFAULT_REGION'),
-        'PYTHONWARNINGS': 'ignore:Unverified HTTPS request'
-    })
-    tmp_file_path = new_tmp_file()
-    error = None
-    with open(tmp_file_path, 'w') as err_file:
-        try:
-            return run(cmd, cache_duration_secs=cache_duration_secs, env_vars=env_vars, stderr=err_file)
-        except Exception as e:
-            error = e
-    if error:
-        LOG.warning('Error running command: %s %s %s' % (cmd, error, load_file(tmp_file_path)))
-        raise error
-
-
-def run_aws_cmd(service, cmd_params, env=None, cache_duration_secs=None):
-    cmd = '%s %s' % (aws_cmd(service, env), cmd_params)
-    if not is_api_enabled(service):
-        return '{}'
-    return run_cached(cmd, cache_duration_secs=cache_duration_secs)
-
-
-def cmd_s3api(cmd_params, env):
-    return run_aws_cmd('s3api', cmd_params, env)
-
-
-def cmd_es(cmd_params, env):
-    return run_aws_cmd('es', cmd_params, env)
-
-
-def cmd_kinesis(cmd_params, env, cache_duration_secs=None):
-    return run_aws_cmd('kinesis', cmd_params, env,
-        cache_duration_secs=cache_duration_secs)
-
-
-def cmd_dynamodb(cmd_params, env):
-    return run_aws_cmd('dynamodb', cmd_params, env)
-
-
-def cmd_firehose(cmd_params, env):
-    return run_aws_cmd('firehose', cmd_params, env)
-
-
-def cmd_sqs(cmd_params, env):
-    return run_aws_cmd('sqs', cmd_params, env)
-
-
-def cmd_lambda(cmd_params, env, cache_duration_secs=None):
-    return run_aws_cmd('lambda', cmd_params, env,
-        cache_duration_secs=cache_duration_secs)
-
-
-def aws_cmd(service, env):
-    # TODO: use boto3 instead of running aws-cli commands here!
-
-    cmd = '{ test `which aws` || . .venv/bin/activate; }; aws'
-    endpoint_url = None
-    env = aws_stack.get_environment(env)
-    if aws_stack.is_local_env(env):
-        endpoint_url = aws_stack.get_local_service_url(service)
-    if endpoint_url:
-        if not is_port_open(endpoint_url):
-            raise socket.error()
-        if endpoint_url.startswith('https://'):
-            cmd += ' --no-verify-ssl'
-        cmd = '%s --endpoint-url=""%s""' % (cmd, endpoint_url)
-    cmd = '%s %s' % (cmd, service)
-    return cmd
-
-
 def get_kinesis_streams(filter='.*', pool={}, env=None):
     if MOCK_OBJ:
         return []
     result = []
     try:
-        out = cmd_kinesis('list-streams', env)
-        out = json.loads(out)
+        kinesis_client = aws_stack.connect_to_service('kinesis')
+        out = kinesis_client.list_streams()
         for name in out['StreamNames']:
             if re.match(filter, name):
-                details = cmd_kinesis('describe-stream --stream-name %s' % name, env=env)
-                details = json.loads(details)
+                details = kinesis_client.describe_stream(StreamArn=name)
                 arn = details['StreamDescription']['StreamARN']
                 stream = KinesisStream(arn)
                 pool[arn] = stream
@@ -131,9 +46,9 @@ def get_kinesis_streams(filter='.*', pool={}, env=None):
 
 def get_kinesis_shards(stream_name=None, stream_details=None, env=None):
     if not stream_details:
-        out = cmd_kinesis('describe-stream --stream-name %s' % stream_name, env)
-        stream_details = json.loads(out)
-    shards = stream_details['StreamDescription']['Shards']
+        kinesis_client = aws_stack.connect_to_service('kinesis')
+        out = kinesis_client.describe_stream(StreamArn=stream_name)
+    shards = out['StreamDescription']['Shards']
     result = []
     for s in shards:
         shard = KinesisShard(s['ShardId'])
@@ -146,10 +61,11 @@ def get_kinesis_shards(stream_name=None, stream_details=None, env=None):
 def get_sqs_queues(filter='.*', pool={}, env=None):
     result = []
     try:
-        out = cmd_sqs('list-queues', env)
+        sqs_client = aws_stack.connect_to_service('sqs')
+        out = sqs_client.list_queues()
         if not out.strip():
             return result
-        queues = json.loads(out)['QueueUrls']
+        queues = out['QueueUrls']
         for q in queues:
             name = q.split('/')[-1]
             arn = aws_stack.sqs_queue_arn(name)
@@ -161,57 +77,6 @@ def get_sqs_queues(filter='.*', pool={}, env=None):
     return result
 
 
-# TODO move to util
-def resolve_string_or_variable(string, code_map):
-    if re.match(r'^[""\'].*[""\']$', string):
-        return string.replace('""', '').replace(""'"", '')
-    LOG.warning('Variable resolution not implemented')
-    return None
-
-
-# TODO move to util
-def extract_endpoints(code_map, pool={}):
-    result = []
-    identifiers = []
-    for key, code in iteritems(code_map):
-        # Elasticsearch references
-        pattern = r'[\'""](.*\.es\.amazonaws\.com)[\'""]'
-        for es in re.findall(pattern, code):
-            if es not in identifiers:
-                identifiers.append(es)
-                es = EventSource.get(es, pool=pool, type=ElasticSearch)
-                if es:
-                    result.append(es)
-        # Elasticsearch references
-        pattern = r'\.put_record_batch\([^,]+,\s*([^,\s]+)\s*,'
-        for firehose in re.findall(pattern, code):
-            if firehose not in identifiers:
-                identifiers.append(firehose)
-                firehose = EventSource.get(firehose, pool=pool, type=FirehoseStream)
-                if firehose:
-                    result.append(firehose)
-        # DynamoDB references
-        # TODO fix pattern to be generic
-        pattern = r'\.(insert|get)_document\s*\([^,]+,\s*([^,\s]+)\s*,'
-        for (op, dynamo) in re.findall(pattern, code):
-            dynamo = resolve_string_or_variable(dynamo, code_map)
-            if dynamo not in identifiers:
-                identifiers.append(dynamo)
-                dynamo = EventSource.get(dynamo, pool=pool, type=DynamoDB)
-                if dynamo:
-                    result.append(dynamo)
-        # S3 references
-        pattern = r'\.upload_file\([^,]+,\s*([^,\s]+)\s*,'
-        for s3 in re.findall(pattern, code):
-            s3 = resolve_string_or_variable(s3, code_map)
-            if s3 not in identifiers:
-                identifiers.append(s3)
-                s3 = EventSource.get(s3, pool=pool, type=S3Bucket)
-                if s3:
-                    result.append(s3)
-    return result
-
-
 def get_lambda_functions(filter='.*', details=False, pool={}, env=None):
     if MOCK_OBJ:
         return []
@@ -237,8 +102,8 @@ def handle(func):
                     LOG.warning(""Unable to get code for lambda '%s'"" % func_name)
 
     try:
-        out = cmd_lambda('list-functions', env)
-        out = json.loads(out)
+        lambda_client = aws_stack.connect_to_service('lambda')
+        out = lambda_client.list_functions()
         parallelize(handle, out['Functions'])
     except Exception:
         pass
@@ -249,11 +114,11 @@ def get_lambda_event_sources(func_name=None, env=None):
     if MOCK_OBJ:
         return {}
 
-    cmd = 'list-event-source-mappings'
+    lambda_client = aws_stack.connect_to_service('lambda')
     if func_name:
-        cmd = '%s --function-name %s' % (cmd, func_name)
-    out = cmd_lambda(cmd, env=env)
-    out = json.loads(out)
+        out = lambda_client.list_event_source_mappings(FunctionName=func_name)
+    else:
+        out = lambda_client.list_event_source_mappings()
     result = out['EventSourceMappings']
     return result
 
@@ -264,8 +129,8 @@ def get_lambda_code(func_name, retries=1, cache_time=None, env=None):
     env = aws_stack.get_environment(env)
     if cache_time is None and not aws_stack.is_local_env(env):
         cache_time = AWS_LAMBDA_CODE_CACHE_TIMEOUT
-    out = cmd_lambda('get-function --function-name %s' % func_name, env, cache_time)
-    out = json.loads(out)
+    lambda_client = aws_stack.connect_to_service('lambda')
+    out = lambda_client.get_function(FunctionName=func_name)
     loc = out['Code']['Location']
     hash = md5(loc)
     folder = TMP_DOWNLOAD_FILE_PATTERN.replace('*', hash)
@@ -309,14 +174,14 @@ def get_lambda_code(func_name, retries=1, cache_time=None, env=None):
 def get_elasticsearch_domains(filter='.*', pool={}, env=None):
     result = []
     try:
-        out = cmd_es('list-domain-names', env)
-        out = json.loads(out)
+        es_client = aws_stack.connect_to_service('es')
+        out = es_client.list_domain_names()
 
         def handle(domain):
             domain = domain['DomainName']
             if re.match(filter, domain):
-                details = cmd_es('describe-elasticsearch-domain --domain-name %s' % domain, env)
-                details = json.loads(details)['DomainStatus']
+                details = es_client.describe_elasticsearch_domain(DomainName=domain)
+                details = details['DomainStatus']
                 arn = details['ARN']
                 es = ElasticSearch(arn)
                 es.endpoint = details.get('Endpoint', 'n/a')
@@ -332,13 +197,13 @@ def handle(domain):
 def get_dynamo_dbs(filter='.*', pool={}, env=None):
     result = []
     try:
-        out = cmd_dynamodb('list-tables', env)
-        out = json.loads(out)
+        dynamodb_client = aws_stack.connect_to_service('dynamodb')
+        out = dynamodb_client.list_tables()
 
         def handle(table):
             if re.match(filter, table):
-                details = cmd_dynamodb('describe-table --table-name %s' % table, env)
-                details = json.loads(details)['Table']
+                details = dynamodb_client.describe_table(TableName=table)
+                details = details['Table']
                 arn = details['TableArn']
                 db = DynamoDB(arn)
                 db.count = details['ItemCount']
@@ -364,9 +229,9 @@ def handle(bucket):
             pool[arn] = bucket
             if details:
                 try:
-                    out = cmd_s3api('get-bucket-notification-configuration --bucket %s' % bucket_name, env=env)
+                    s3_client = aws_stack.connect_to_service('s3')
+                    out = s3_client.get_bucket_notification(Bucket=bucket_name)
                     if out:
-                        out = json.loads(out)
                         if 'CloudFunctionConfiguration' in out:
                             func = out['CloudFunctionConfiguration']['CloudFunction']
                             func = EventSource.get(func, pool=pool)
@@ -377,8 +242,8 @@ def handle(bucket):
                     print('WARNING: Unable to get details for bucket: %s' % e)
 
     try:
-        out = cmd_s3api('list-buckets', env)
-        out = json.loads(out)
+        s3_client = aws_stack.connect_to_service('s3')
+        out = s3_client.list_buckets()
         parallelize(handle, out['Buckets'])
     except Exception:
         pass
@@ -388,13 +253,13 @@ def handle(bucket):
 def get_firehose_streams(filter='.*', pool={}, env=None):
     result = []
     try:
-        out = cmd_firehose('list-delivery-streams', env)
-        out = json.loads(out)
+        firehose_client = aws_stack.connect_to_service('firehose')
+        out = firehose_client.list_delivery_streams()
         for stream_name in out['DeliveryStreamNames']:
             if re.match(filter, stream_name):
-                details = cmd_firehose(
-                    'describe-delivery-stream --delivery-stream-name %s' % stream_name, env)
-                details = json.loads(details)['DeliveryStreamDescription']
+                details = firehose_client.describe_delivery_stream(
+                    DeliveryStreamName=stream_name)
+                details = details['DeliveryStreamDescription']
                 arn = details['DeliveryStreamARN']
                 s = FirehoseStream(arn)
                 for dest in details['Destinations']:
@@ -408,10 +273,8 @@ def get_firehose_streams(filter='.*', pool={}, env=None):
 
 
 def read_kinesis_iterator(shard_iterator, max_results=10, env=None):
-    data = cmd_kinesis('get-records --shard-iterator %s --limit %s' %
-        (shard_iterator, max_results), env, cache_duration_secs=0)
-    data = json.loads(to_str(data))
-    result = data
+    kinesis_client = aws_stack.connect_to_service('kinesis')
+    result = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=max_results)
     return result
 
 
@@ -497,3 +360,54 @@ def get_graph(name_filter='.*', env=None, **kwargs):
             result['edges'].append({'source': src_uid, 'target': tgt_uid})
 
     return result
+
+
+# TODO: Move to utils.common
+def extract_endpoints(code_map, pool={}):
+    result = []
+    identifiers = []
+    for key, code in iteritems(code_map):
+        # Elasticsearch references
+        pattern = r'[\'""](.*\.es\.amazonaws\.com)[\'""]'
+        for es in re.findall(pattern, code):
+            if es not in identifiers:
+                identifiers.append(es)
+                es = EventSource.get(es, pool=pool, type=ElasticSearch)
+                if es:
+                    result.append(es)
+        # Elasticsearch references
+        pattern = r'\.put_record_batch\([^,]+,\s*([^,\s]+)\s*,'
+        for firehose in re.findall(pattern, code):
+            if firehose not in identifiers:
+                identifiers.append(firehose)
+                firehose = EventSource.get(firehose, pool=pool, type=FirehoseStream)
+                if firehose:
+                    result.append(firehose)
+        # DynamoDB references
+        # TODO fix pattern to be generic
+        pattern = r'\.(insert|get)_document\s*\([^,]+,\s*([^,\s]+)\s*,'
+        for (op, dynamo) in re.findall(pattern, code):
+            dynamo = resolve_string_or_variable(dynamo, code_map)
+            if dynamo not in identifiers:
+                identifiers.append(dynamo)
+                dynamo = EventSource.get(dynamo, pool=pool, type=DynamoDB)
+                if dynamo:
+                    result.append(dynamo)
+        # S3 references
+        pattern = r'\.upload_file\([^,]+,\s*([^,\s]+)\s*,'
+        for s3 in re.findall(pattern, code):
+            s3 = resolve_string_or_variable(s3, code_map)
+            if s3 not in identifiers:
+                identifiers.append(s3)
+                s3 = EventSource.get(s3, pool=pool, type=S3Bucket)
+                if s3:
+                    result.append(s3)
+    return result
+
+
+# TODO: Move to utils.common
+def resolve_string_or_variable(string, code_map):
+    if re.match(r'^[""\'].*[""\']$', string):
+        return string.replace('""', '').replace(""'"", '')
+    LOG.warning('Variable resolution not implemented')
+    return None
diff --git a/localstack/utils/aws/aws_models.py b/localstack/utils/aws/aws_models.py
index 79a62f735a02a..bfe405e873f13 100644
--- a/localstack/utils/aws/aws_models.py
+++ b/localstack/utils/aws/aws_models.py
@@ -1,8 +1,8 @@
-from localstack.utils.common import timestamp_millis
 import time
 import json
 import six
 from datetime import datetime
+from localstack.utils.common import timestamp_millis
 
 if six.PY3:
     long = int"
