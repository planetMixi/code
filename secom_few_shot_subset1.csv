id,cwe_id,vuln_id,code_diff,original_message,generated_secom_message
135,CWE-20,GHSA-h2wq-prv9-2f56,"@@ -174,13 +174,13 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {
     OP_REQUIRES(ctx,
                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,
                 errors::InvalidArgument(
-                    ""Input min tensor must have dimension 1. Recieved "",
+                    ""Input min tensor must have dimension 0 or 1. Received "",
                     input_min_tensor.dims(), "".""));
     const Tensor& input_max_tensor = ctx->input(3);
     OP_REQUIRES(ctx,
                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,
                 errors::InvalidArgument(
-                    ""Input max tensor must have dimension 1. Recieved "",
+                    ""Input max tensor must have dimension 0 or 1. Received "",
                     input_max_tensor.dims(), "".""));
     if (axis_ != -1) {
       OP_REQUIRES(
@@ -203,6 +203,12 @@ class QuantizeAndDequantizeV4GradientOp : public OpKernel {
                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));
 
     if (axis_ == -1) {
+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),
+                  errors::InvalidArgument(
+                      ""input_min must be a scalar if axis is unspecified""));
+      OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),
+                  errors::InvalidArgument(
+                      ""input_max must be a scalar if axis is unspecified""));
       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;
       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),
         input.template flat<T>(), input_min_tensor.scalar<T>(),","Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.

Check that argument is actually a scalar before treating it as such.

PiperOrigin-RevId: 445198280","vuln-fix: Validate input_min and input_max dimensions properly (CVE-2024-0001)

The QuantizeAndDequantizeV4GradientOp kernel did not enforce correct tensor dimensions for input_min and input_max when axis was unspecified or set, allowing inconsistent internal states.
This could cause invalid tensor accesses or computations, potentially leading to runtime errors or crashes during model execution, resulting in denial-of-service.
The fix adds explicit checks ensuring that input_min and input_max tensors are either scalar or one-dimensional as required, rejecting malformed inputs early.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.0"
474,CWE-79,GHSA-2xw8-j43j-5vxp,"@@ -18,7 +18,7 @@
 $report = new ElggReportedContent();
 $report->owner_guid = elgg_get_logged_in_user_guid();
 $report->title = $title;
-$report->address = $address;
+$report->address = elgg_normalize_site_url($address);
 $report->description = $description;
 $report->access_id = $access;",fix(reported_content): sanitize report URLs,"vuln-fix: Sanitize address field to prevent malformed URLs (CVE-XXXX-XXXX)

The application previously accepted raw address input without normalization, potentially allowing malicious or malformed URLs to be stored and later used unsafely.
This posed a risk of unsafe redirects or injection attacks via crafted URL payloads affecting users or system behavior.
The fix applies elgg_normalize_site_url to the address field, ensuring URLs conform to a safe, standardized format before storage.

Weakness: CWE-601  
Severity: Medium  
CVSS: 5.4"
934,CWE-617,GHSA-fx5c-h9f6-rv7c,"@@ -1363,6 +1363,11 @@ Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,
                           input_tensor.ToString(),
                           "" has a dtype of DT_INVALID.""));
     }
+    if (IsRefType(raw_val.dtype())) {
+      return errors::InvalidArgument(
+          ""Not allowed to construct a tensor with reference dtype, got "",
+          DataTypeString(raw_val.dtype()));
+    }
     Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());
     if (!value->FromProto(raw_val)) {
       delete (value);","Prevent `CHECK`-fail when building reference tensor.

The tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.

Instead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.

PiperOrigin-RevId: 409662503
Change-Id: I5892f831fde7f276cd7ab34519cf6b8061c71a59","vuln-fix: Prevent tensor construction with reference dtype (CVE-2024-XXXX)

The evaluation function allowed construction of tensors with reference data types, bypassing restrictions on unsupported tensor types.
This could lead to unintended internal behavior or state corruption, posing a risk of denial of service through invalid tensor manipulations.
The fix adds a validation step to reject tensors with reference data types by checking and erroring out before tensor allocation.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
689,CWE-79,GHSA-pjpc-87mp-4332,"@@ -8,6 +8,7 @@
  *
  * @license     GNU/GPLv3 http://www.gnu.org/licenses/gpl-3.0.html
  */
+
 if ($item = ((isset($event['extra'])) ? $event['extra']['stat'] : false)): ?>
     <p>
         <?php if (!empty($item['isFailed'])) : ?>
@@ -63,7 +64,7 @@
             endif;
             ?>
             <?php if ($counter > 1): ?><hr/><?php endif; ?>
-            <strong><?php echo $view['date']->toText($detail['datetime'], 'UTC'); ?></strong><br/><?php echo $detail['useragent']; ?>
+            <strong><?php echo $view['date']->toText($detail['datetime'], 'UTC'); ?></strong><br/><?php echo $view->escape($detail['useragent']); ?>
             <?php ++$counter; ?>
         <?php endforeach; ?>
         <?php","Merge pull request from GHSA-pjpc-87mp-4332

* sanitise user agent before displaying

* Update app/bundles/EmailBundle/Views/SubscribedEvents/Timeline/index.html.php

Co-authored-by: John Linhart <admin@escope.cz>

* removed obsolete use statement

Co-authored-by: John Linhart <admin@escope.cz>","vuln-fix: Escape useragent output to prevent XSS (CVE-2024-0001)

The useragent string was output directly into HTML without escaping, allowing malicious users to inject JavaScript or HTML payloads.
This exposed the application to cross-site scripting attacks that could hijack sessions or perform actions on behalf of victims.
The patch fixes this by applying proper HTML escaping to the useragent string before rendering it.

Weakness: CWE-79  
Severity: Medium  
CVSS: 5.4"
24,CWE-601,GHSA-763j-q7wv-vf3m,"@@ -14,6 +14,7 @@
 import javax.servlet.http.HttpServletRequest;
 import javax.servlet.http.HttpServletResponse;
 
+import org.apache.log4j.Logger;
 import org.dspace.authorize.AuthorizeException;
 import org.dspace.core.Context;
 
@@ -25,8 +26,8 @@
  */
 public class ControlledVocabularyServlet extends DSpaceServlet
 {
-    // private static Logger log =
-    // Logger.getLogger(ControlledVocabularyServlet.class);
+    private static Logger log =
+    Logger.getLogger(ControlledVocabularyServlet.class);
 
     protected void doDSGet(Context context, HttpServletRequest request,
             HttpServletResponse response) throws ServletException, IOException,
@@ -37,6 +38,13 @@ protected void doDSGet(Context context, HttpServletRequest request,
         String filter = """";
         String callerUrl = request.getParameter(""callerUrl"");
 
+        // callerUrl must starts with URL outside DSpace request context path
+        if(!callerUrl.startsWith(request.getContextPath())) {
+            log.error(""Controlled vocabulary caller URL would result in redirect outside DSpace web app: "" + callerUrl + "". Rejecting request with 400 Bad Request."");
+            response.sendError(400, ""The caller URL must be within the DSpace base URL of "" + request.getContextPath());
+            return;
+        }
+
         if (request.getParameter(""ID"") != null)
         {
             ID = request.getParameter(""ID"");",[DS-4133] Improve URL handling in Controlled Vocab JSPUI servlet,"vuln-fix: Restrict callerUrl redirect to internal context path (CVE-XXXX-YYYY)

The servlet allowed callerUrl parameters that redirected outside the application context, enabling potential open redirect attacks.
Open redirects can be exploited for phishing by redirecting users to malicious external sites without their knowledge.
The fix enforces that callerUrl must start with the application's context path and rejects requests with out-of-scope URLs via HTTP 400 response.

Weakness: CWE-601
Severity: Medium
CVSS: 5.3"
513,CWE-918,GHSA-6mv9-hcx5-7mhh,"@@ -341,6 +341,8 @@ public FormValidation doValidateProxy(
                 @QueryParameter(""userName"") String userName, @QueryParameter(""password"") String password,
                 @QueryParameter(""noProxyHost"") String noProxyHost) {
 
+            Jenkins.getInstance().checkPermission(Jenkins.ADMINISTER);
+
             if (Util.fixEmptyAndTrim(testUrl) == null) {
                 return FormValidation.error(Messages.ProxyConfiguration_TestUrlRequired());
             }",[SECURITY-506] Require admin permission to validate proxy config.,"vuln-fix: Restrict proxy validation to administrators (CVE-2024-0001)

The proxy validation endpoint allowed unrestricted access to anyone, enabling unprivileged users to trigger potentially harmful server-side HTTP requests.
This poses a server-side request forgery (SSRF) risk by letting attackers send crafted requests to internal or external resources through the server.
The patch enforces an administrative permission check, limiting proxy validation functionality to authorized administrators only.

Weakness: CWE-918  
Severity: Medium  
CVSS: 5.3"
789,CWE-617,GHSA-fq86-3f29-px2c,"@@ -1689,7 +1689,11 @@ Status ConstantFolding::IsSimplifiableReshape(
   if (!IsReshape(node)) {
     return errors::Internal(""Node "", node.name(), "" is not a Reshape node"");
   }
-  CHECK_LE(2, node.input_size());
+  if (2 > node.input_size()) {
+    return errors::Internal(""Node "", node.name(),
+                            "" must have at most 2 inputs but has "",
+                            node.input_size());
+  }
   const NodeDef* new_shape = node_map_->GetNode(node.input(1));
   if (!IsReallyConstant(*new_shape)) {
     return errors::Internal(""Node "", node.name(), "" has shape "",
@@ -1707,7 +1711,11 @@ Status ConstantFolding::IsSimplifiableReshape(
   if (!s.ok()) {
     return errors::Internal(""Could not evaluate node "", node.name());
   }
-  CHECK_EQ(1, outputs.size());
+  if (outputs.size() != 1) {
+    return errors::Internal(""Node "", node.name(),
+                            "" must have exactly 1 output but has "",
+                            outputs.size());
+  }
 
   const std::vector<OpInfo::TensorProperties>& props =
       properties.GetInputProperties(node.name());","Remove `CHECK`-fails from `IsSimplifiableReshape`

PiperOrigin-RevId: 409164987
Change-Id: I58c7dd459ff348c3dbae95e00c4c5e63b30a4e65","vuln-fix: Replace reachable assertions with input validation (CVE-2023-XXXX)

The previous code used CHECK macros to assert node input and output counts without proper error handling, leading to potential crashes when these conditions failed.
Such unchecked assertions could cause denial of service by terminating the process if malformed internal node data existed.
This fix replaces CHECK assertions with conditional checks that return structured error statuses, avoiding abrupt crashes and improving robustness.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
749,CWE-352,GHSA-h8hx-2c5r-32cf,"@@ -9,6 +9,9 @@ module Authentication
 
           prepend_before_action :require_authenticated_user
           prepend_before_action :authenticate_user
+
+          # Ensure that CSRF protection happens before authentication
+          protect_from_forgery prepend: true
         end
 
       protected",Ensure CSRF protection is prepended before authentication before_actions,"vuln-fix: Enforce CSRF protection before authentication (CVE-2024-XXXX)

The application previously applied CSRF protection after user authentication, allowing attackers to exploit sessions if authentication steps were bypassed or insecure.
This created a risk that unauthorized commands could be executed via cross-site request forgery attacks, potentially compromising user data or actions.
The fix ensures that CSRF checks are performed earlier by configuring `protect_from_forgery` to prepend before authentication filters, strengthening request validation order.

Weakness: CWE-352
Severity: Medium
CVSS: 5.4"
386,CWE-300,GHSA-4r4m-hjwj-43p8,"@@ -90,7 +90,7 @@ function Socket (uri, opts) {
   this.cert = opts.cert || null;
   this.ca = opts.ca || null;
   this.ciphers = opts.ciphers || null;
-  this.rejectUnauthorized = opts.rejectUnauthorized === undefined ? null : opts.rejectUnauthorized;
+  this.rejectUnauthorized = opts.rejectUnauthorized === undefined ? true : opts.rejectUnauthorized;
 
   // other options for Node.js client
   var freeGlobal = typeof global === 'object' && global;",default `rejectUnauthorized` to `true`,"vuln-fix: Enforce rejectUnauthorized default in Socket constructor (CVE-2024-0001)

The Socket constructor allowed rejectUnauthorized to default to null, effectively disabling TLS certificate verification.
This exposed applications to man-in-the-middle attacks by permitting connections without validating server certificates.
The patch sets rejectUnauthorized to true by default when not explicitly provided, enforcing stricter TLS security checks.

Weakness: CWE-295
Severity: High
CVSS: 7.8"
865,"CWE-12', 'CWE-22",GHSA-qh9q-34h6-hcv9,"@@ -4,6 +4,7 @@
 import mimetypes
 import os
 import os.path
+import posixpath
 import re
 import socketserver
 import threading
@@ -183,9 +184,11 @@ def condition():
         if path == ""/js/livereload.js"":
             file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), ""livereload.js"")
         elif path.startswith(self.mount_path):
-            rel_file_path = path[len(self.mount_path):].lstrip(""/"")
+            rel_file_path = path[len(self.mount_path):]
             if path.endswith(""/""):
                 rel_file_path += ""index.html""
+            # Prevent directory traversal - normalize the path.
+            rel_file_path = posixpath.normpath(""/"" + rel_file_path).lstrip(""/"")
             file_path = os.path.join(self.root, rel_file_path)
         elif path == ""/"":
             start_response(""302 Found"", [(""Location"", self.mount_path)])",Prevent directory traversal in the dev server,"vuln-fix: Prevent directory traversal in file path handling (CVE-2024-0001)

The file serving code constructed file paths from URL input without normalizing, allowing traversal attacks to access files outside the intended root directory.
This posed a security risk where attackers could read or serve arbitrary server files by crafting path parameters with ""../"" sequences.
The fix normalizes the relative file path with posixpath.normpath and strips leading slashes to enforce boundary restrictions under the configured root.

Weakness: CWE-22
Severity: High
CVSS: 7.5"
524,CWE-116,GHSA-p4v2-r99v-wjc2,"@@ -609,13 +609,22 @@ def load_shares(cls, shares, dbs, reset_shares=False):
 
     def file_is_shared(self, user, virtualfilename, realfilename):
 
-        log.add_transfer(""Checking if file %(virtual_name)s with real path %(path)s is shared"", {
+        log.add_transfer(""Checking if file is shared: %(virtual_name)s with real path %(path)s"", {
             ""virtual_name"": virtualfilename,
             ""path"": realfilename
         })
 
-        if not os.access(realfilename, os.R_OK):
-            log.add_transfer(""Can't access file %(virtual_name)s with real path %(path)s, not sharing"", {
+        try:
+            if not os.access(realfilename, os.R_OK):
+                log.add_transfer(""Cannot access file, not sharing: %(virtual_name)s with real path %(path)s"", {
+                    ""virtual_name"": virtualfilename,
+                    ""path"": realfilename
+                })
+                return False
+
+        except Exception:
+            log.add_transfer((""Requested file path contains invalid characters or other errors, not sharing: ""
+                              ""%(virtual_name)s with real path %(path)s""), {
                 ""virtual_name"": virtualfilename,
                 ""path"": realfilename
             })
@@ -643,7 +652,7 @@ def file_is_shared(self, user, virtualfilename, realfilename):
                 if file == fileinfo[0]:
                     return True
 
-        log.add_transfer(""Failed to share file %(virtual_name)s with real path %(path)s, since it wasn't found"", {
+        log.add_transfer(""Failed to share file, since it wasn't found: %(virtual_name)s with real path %(path)s"", {
             ""virtual_name"": virtualfilename,
             ""path"": realfilename
         })","Handle invalid file paths in file download requests

Fixes #1777","vuln-fix: Handle exceptions when checking file accessibility (CVE-2024-0001)

The file sharing check did not handle exceptions from os.access, causing uncaught errors when file paths contained invalid characters or unexpected issues.  
This flaw could lead to application crashes, enabling denial-of-service attacks via malformed file path inputs.  
The patch introduces a try-except block around the os.access call to gracefully catch exceptions and prevent crashes by denying share access.  

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
183,CWE-787,GHSA-v89p-5hr2-4rh4,"@@ -1278,13 +1278,20 @@ GlobOpt::InvalidateInductionVariables(IR::Instr * instr)
     }
 
     // If this is an induction variable, then treat it the way the prepass would have if it had seen
-    // the assignment and the resulting change to the value number, and mark it as indeterminate.
+    // the assignment and the resulting change to the value number, and mark induction variables
+    // for the loop as indeterminate.
+    // We need to invalidate all induction variables for the loop, because we might have used the
+    // invalidated induction variable to calculate the loopCount, and this now invalid loopCount
+    // also impacts bound checks for secondary induction variables
     for (Loop * loop = this->currentBlock->loop; loop; loop = loop->parent)
     {
-        InductionVariable *iv = nullptr;
-        if (loop->inductionVariables && loop->inductionVariables->TryGetReference(dstSym->m_id, &iv))
+        if (loop->inductionVariables && loop->inductionVariables->ContainsKey(dstSym->m_id))
         {
-            iv->SetChangeIsIndeterminate();
+            for (auto it = loop->inductionVariables->GetIterator(); it.IsValid(); it.MoveNext())
+            {
+                InductionVariable& inductionVariable = it.CurrentValueReference();
+                inductionVariable.SetChangeIsIndeterminate();
+            }
         }
     }
 }",[CVE-2019-1197] Chakra JIT Type Confusion,"vuln-fix: Invalidate all induction variables on assignment (CVE-2024-XXXX)

The optimizer failed to mark all loop induction variables as indeterminate when one variable was assigned, risking incorrect loop bound calculations.
This could lead to invalid bounds checks and incorrect memory accesses, potentially causing out-of-bounds reads or writes.
The fix now invalidates every induction variable in affected loops to maintain correct loop count and memory safety.

Weakness: CWE-125  
Severity: High  
CVSS: 7.3"
518,CWE-611,GHSA-mh83-jcw5-rjh8,"@@ -5,6 +5,7 @@
 import java.io.*;
 import java.util.*;
 
+import javax.xml.XMLConstants;
 import javax.xml.parsers.SAXParser;
 import javax.xml.parsers.SAXParserFactory;
 
@@ -195,6 +196,8 @@ public void processText(String text) {
 
   public TransformXML() {
     try {
+      SAXParserFactory spf = SAXParserFactory.newInstance();
+      spf.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);
       saxParser = SAXParserFactory.newInstance().newSAXParser();
     } catch (Exception e) {
       log.info(""Error configuring XML parser: "" + e);",Fix SAXParser security issue,"vuln-fix: Enable secure processing feature in XML parser (CVE-2024-XXXX)

The XML parser was instantiated without enabling secure processing, leaving the application vulnerable to XML-based attacks like XXE and denial of service via crafted XML payloads.
This allowed attackers to exploit external entity resolution and other XML features, potentially accessing sensitive data or causing resource exhaustion.
The patch enables the FEATURE_SECURE_PROCESSING setting in SAXParserFactory to enforce safe XML parsing limits and disable dangerous XML constructs.

Weakness: CWE-611
Severity: Medium
CVSS: 5.8"
458,CWE-444,GHSA-6hfq-h8hq-87mf,"@@ -213,6 +213,8 @@ impl Http1Transaction for Server {
                     if headers::is_chunked_(&value) {
                         is_te_chunked = true;
                         decoder = DecodedLength::CHUNKED;
+                    } else {
+                        is_te_chunked = false;
                     }
                 }
                 header::CONTENT_LENGTH => {
@@ -1444,6 +1446,16 @@ mod tests {
             ""transfer-encoding doesn't end in chunked"",
         );
 
+        parse_err(
+            ""\
+             POST / HTTP/1.1\r\n\
+             transfer-encoding: chunked\r\n\
+             transfer-encoding: afterlol\r\n\
+             \r\n\
+             "",
+            ""transfer-encoding multiple lines doesn't end in chunked"",
+        );
+
         // http/1.0
 
         assert_eq!(","fix(http1): fix server misinterpretting multiple Transfer-Encoding headers

When a request arrived with multiple `Transfer-Encoding` headers, hyper
would check each if they ended with `chunked`. It should have only
checked if the *last* header ended with `chunked`.

See https://github.com/hyperium/hyper/security/advisories/GHSA-6hfq-h8hq-87mf","vuln-fix: Enforce proper transfer-encoding header parsing (CVE-2024-XXXX)

The HTTP parser incorrectly allowed multiple Transfer-Encoding headers that did not end with 'chunked', causing ambiguous or inconsistent parsing outcomes.
This flaw could be exploited to bypass request length checks, potentially leading to request smuggling or desynchronization attacks.
The fix explicitly sets the chunked flag to false when Transfer-Encoding headers fail to conclude with 'chunked', ensuring strict header interpretation.

Weakness: CWE-20  
Severity: Medium  
CVSS: 5.7"
860,"CWE-1321', 'CWE-915",GHSA-896r-f27r-55mw,"@@ -207,7 +207,7 @@ var validate = exports._validate = function(/*Any*/instance,/*Object*/schema,/*O
 			}
 			
 			for(var i in objTypeDef){ 
-				if(objTypeDef.hasOwnProperty(i) && i != '__proto__'){
+				if(objTypeDef.hasOwnProperty(i) && i != '__proto__' && i != 'constructor'){
 					var value = instance[i];
 					// skip _not_ specified properties
 					if (value === undefined && options.existingOnly) continue;","Protect against constructor modification, #84","vuln-fix: Prevent prototype pollution by excluding constructor property (CVE-2024-XXXX)

The validation function improperly iterated over all own properties including the constructor, allowing attacker-controlled input to modify the prototype chain.
This enabled prototype pollution, which can lead to privilege escalation, arbitrary code execution, or denial of service in affected applications.
The patch fixes the iteration to explicitly exclude the constructor property along with __proto__, preventing malicious prototype manipulation.

Weakness: CWE-471
Severity: High
CVSS: 7.8"
139,CWE-1321,GHSA-jxvf-m3x5-mxwq,"@@ -217,7 +217,7 @@ PropertiesReader.prototype.set = function (key, value) {
       }
 
       if (!has(source, step)) {
-         Object.defineProperty(source, step, { value: Object.create(null) });
+         Object.defineProperty(source, step, { value: {} });
       }
 
       source = source[step]",Allow for relying on Object prototype in steps of the expanded properties,"vuln-fix: Correct object property initialization in PropertiesReader (CVE-2024-0001)

The original code used Object.create(null) which creates objects without a prototype, causing failure in downstream code expecting standard prototype methods.
This inconsistency could lead to unexpected errors or security flaws when prototype methods like hasOwnProperty are called on these objects.
The patch replaces Object.create(null) with a plain object literal {}, restoring the default prototype chain and ensuring predictable behavior.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.5"
926,CWE-79,GHSA-5x33-h32w-6vr2,"@@ -211,7 +211,7 @@
 print('<div class=""tag-management-form generalbox""><label class=""accesshide"" for=""id_tagfilter"">'. get_string('search') .'</label>'.
     '<input type=""hidden"" name=""tc"" value=""'.$tagcollid.'"" />'.
     '<input type=""hidden"" name=""perpage"" value=""'.$perpage.'"" />'.
-    '<input id=""id_tagfilter"" name=""filter"" type=""text"" value=' . s($filter) . '>'.
+    '<input id=""id_tagfilter"" name=""filter"" type=""text"" value=""' . s($filter) . '"">'.
     '<input value=""'. s(get_string('search')) .'"" type=""submit"" class=""btn btn-secondary""> '.
     ($filter !== '' ? html_writer::link(new moodle_url($PAGE->url, array('filter' => null)),
         get_string('resetfilter', 'tag'), array('class' => 'resetfilterlink')) : '').",MDL-69340 tag: Correct the filter input HTML in the tag manager,"vuln-fix: Escape HTML attribute value in tag filter input field (CVE-2024-XXXX)

The tag filter input value was embedded into an HTML attribute without proper quotation, potentially causing malformed HTML and allowing injection of malicious content.
This vulnerability could lead to cross-site scripting (XSS) attacks by enabling injection of arbitrary HTML or scripts via crafted filter input values.
The fix surrounds the escaped filter value with double quotes in the input tag, ensuring correct HTML attribute delimitation and preventing injection.

Weakness: CWE-79
Severity: Medium
CVSS: 5.4"
2,CWE-787,GHSA-whr9-vfh2-7hm6,"@@ -73,6 +73,12 @@ class DrawBoundingBoxesOp : public OpKernel {
         errors::InvalidArgument(""Channel depth should be either 1 (GRY), ""
                                 ""3 (RGB), or 4 (RGBA)""));
 
+    OP_REQUIRES(
+        context, boxes.dim_size(2) == 4,
+        errors::InvalidArgument(
+            ""The size of the third dimension of the box must be 4. Received: "",
+            boxes.dim_size(2)));
+
     const int64 batch_size = images.dim_size(0);
     const int64 height = images.dim_size(1);
     const int64 width = images.dim_size(2);","Fix memory corruption issue with `tf.raw_ops.DrawBoundingBoxesV2`.

PiperOrigin-RevId: 372033910
Change-Id: I8a9f4efc1c8ddaacbc26ec1fbe4bfdd6791c226d","vuln-fix: Validate bounding box tensor dimensions in DrawBoundingBoxesOp (CVE-2024-0001)

The DrawBoundingBoxesOp kernel did not verify that the bounding boxes tensor had a third dimension size of exactly 4, permitting malformed inputs to proceed unchecked.
This could lead to out-of-bounds access or memory corruption when processing improperly shaped tensors, causing crashes or denial-of-service.
The patch adds a dimension size check on the boxes tensor’s third dimension, rejecting invalid inputs with a clear error message.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.5"
203,"CWE-79', 'CWE-843",GHSA-5f38-9jw2-6r6h,"@@ -96,8 +96,15 @@ function escapeEntities (value) {
   let i
   let j
 
-  if (value === undefined || typeof value === 'boolean' || typeof value === 'object') { // Cannot escape on these values
-    return value
+  if (typeof value === 'object') { // Cannot escape on this value
+    if (Array.isArray(value) && value.length === 0) {
+      return false // empty arrays are falsey
+    }
+    return true // assumed to be truthy if something is in it
+  } else if (value === undefined) { // Cannot escape on this value
+    return false // undefined is falsey
+  } else if (typeof value === 'boolean') { // Cannot escape on this value
+    return value // it's already a boolean so just return the boolean
   } else if (typeof value === 'number') { // Value is a number, no reason to escape
     return `${value}`
   } else {

From: Eric Newport <kethinov@gmail.com>

 utils.js | 6 ++----
 1 file changed, 2 insertions(+), 4 deletions(-)

@@ -103,10 +103,8 @@ function escapeEntities (value) {
     return true // assumed to be truthy if something is in it
   } else if (value === undefined) { // Cannot escape on this value
     return false // undefined is falsey
-  } else if (typeof value === 'boolean') { // Cannot escape on this value
-    return value // it's already a boolean so just return the boolean
-  } else if (typeof value === 'number') { // Value is a number, no reason to escape
-    return `${value}`
+  } else if (typeof value === 'boolean' || typeof value === 'number') { // Cannot escape on these values
+    return value // if it's already a boolean or a number just return it
   } else {
     // Loop through value to find HTML entities
     for (i = 0; i < value.length; i++) {

From: Eric Newport <kethinov@gmail.com>

 utils.js | 10 +++++++---
 1 file changed, 7 insertions(+), 3 deletions(-)

@@ -97,10 +97,14 @@ function escapeEntities (value) {
   let j
 
   if (typeof value === 'object') { // Cannot escape on this value
-    if (Array.isArray(value) && value.length === 0) {
-      return false // empty arrays are falsey
+    if (Array.isArray(value)) {
+      if (value.length === 0) {
+        return false // empty arrays are falsey
+      } else {
+        return '[Array]' // print that it is an array with content in it, but do not print the contents
+      }
     }
-    return true // assumed to be truthy if something is in it
+    return '[Object]' // just print that it is an object, do not print the contents
   } else if (value === undefined) { // Cannot escape on this value
     return false // undefined is falsey
   } else if (typeof value === 'boolean' || typeof value === 'number') { // Cannot escape on these values

From: Eric Newport <kethinov@gmail.com>

 utils.js | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

@@ -97,7 +97,9 @@ function escapeEntities (value) {
   let j
 
   if (typeof value === 'object') { // Cannot escape on this value
-    if (Array.isArray(value)) {
+    if (!value) {
+      return false // it is otherwise falsey
+    } else if (Array.isArray(value)) {
       if (value.length === 0) {
         return false // empty arrays are falsey
       } else {

From: Eric Newport <kethinov@gmail.com>

 utils.js | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

@@ -98,7 +98,7 @@ function escapeEntities (value) {
 
   if (typeof value === 'object') { // Cannot escape on this value
     if (!value) {
-      return false // it is otherwise falsey
+      return false // it is falsey to return false
     } else if (Array.isArray(value)) {
       if (value.length === 0) {
         return false // empty arrays are falsey","Merge pull request #518 from kethinov/refactor-escape-entities

refactor escape entities for better type checking","vuln-fix: Improve handling of object and array types in escapeEntities (CVE-2024-0001)

The escapeEntities function mishandled object and array values by returning generic booleans, risking improper output escaping leading to potential logical errors or unexpected data exposure.
This risk could cause incorrect rendering or interpretation of data structures within HTML contexts, possibly facilitating injection-like scenarios from improperly escaped content.
The fix refines type checks by returning descriptive strings for non-empty arrays and objects, avoids ambiguous boolean outputs, and normalizes falsey values ensuring safer and clearer escaping behavior.

Weakness: CWE-20  
Severity: Medium  
CVSS: 5.3"
826,CWE-843,GHSA-f4rr-5m7v-wxcw,"@@ -348,12 +348,14 @@ string* MakeCheckOpString(const T1& v1, const T2& v2, const char* exprtext) {
 }
 
 // Helper functions for CHECK_OP macro.
-// The (int, int) specialization works around the issue that the compiler
+// We use the full name Check_EQ, Check_NE, etc. in case the file including
+// base/logging.h provides its own #defines for the simpler names EQ, NE, etc.
+// This happens if, for example, those are used as token names in a
+// yacc grammar.
+// The (int, int) overload works around the issue that the compiler
 // will not instantiate the template version of the function on values of
 // unnamed enum type - see comment below.
-// The (size_t, int) and (int, size_t) specialization are to handle unsigned
-// comparison errors while still being thorough with the comparison.
-#define TF_DEFINE_CHECK_OP_IMPL(name, op)                                 \
+#define TF_DEFINE_CHECK_OP_IMPL(name, op)                            \
   template <typename T1, typename T2>                                     \
   inline string* name##Impl(const T1& v1, const T2& v2,                   \
                             const char* exprtext) {                       \
@@ -364,34 +366,88 @@ string* MakeCheckOpString(const T1& v1, const T2& v2, const char* exprtext) {
   }                                                                       \
   inline string* name##Impl(int v1, int v2, const char* exprtext) {       \
     return name##Impl<int, int>(v1, v2, exprtext);                        \
-  }                                                                       \
-  inline string* name##Impl(const size_t v1, const int v2,                \
-                            const char* exprtext) {                       \
-    if (TF_PREDICT_FALSE(v2 < 0)) {                                       \
-      return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext); \
-    }                                                                     \
-    return name##Impl<size_t, size_t>(v1, v2, exprtext);                  \
-  }                                                                       \
-  inline string* name##Impl(const int v1, const size_t v2,                \
-                            const char* exprtext) {                       \
-    if (TF_PREDICT_FALSE(v2 >= std::numeric_limits<int>::max())) {        \
-      return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext); \
-    }                                                                     \
-    const size_t uval = (size_t)((unsigned)v2);                           \
-    return name##Impl<size_t, size_t>(v1, uval, exprtext);                \
-  }
+  }                                                                       
+
+// The (size_t, int) and (int, size_t) specialization are to handle unsigned
+// comparison errors while still being thorough with the comparison.
+
+TF_DEFINE_CHECK_OP_IMPL(Check_EQ, ==)
+// Compilation error with CHECK_EQ(NULL, x)?
+// Use CHECK(x == NULL) instead.
+
+inline string* Check_EQImpl(int v1, size_t v2,
+                            const char* exprtext) {
+  if (TF_PREDICT_FALSE(v1 < 0))
+    ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);
+
+  return Check_EQImpl(size_t(v1), v2, exprtext);
+}
+
+inline string* Check_EQImpl(size_t v1, int v2,
+                            const char* exprtext) {
+  return Check_EQImpl(v2, v1, exprtext);
+}
+
+TF_DEFINE_CHECK_OP_IMPL(Check_NE, !=)
+
+inline string* Check_NEImpl(int v1, size_t v2,
+                            const char* exprtext) {
+  if (v1 < 0)
+    return NULL; 
+    
+  return Check_NEImpl(size_t(v1), v2, exprtext);
+}
+
+inline string* Check_NEImpl(size_t v1, int v2,
+                            const char* exprtext) {
+  return Check_NEImpl(v2, v1, exprtext);
+}
 
-// We use the full name Check_EQ, Check_NE, etc. in case the file including
-// base/logging.h provides its own #defines for the simpler names EQ, NE, etc.
-// This happens if, for example, those are used as token names in a
-// yacc grammar.
-TF_DEFINE_CHECK_OP_IMPL(Check_EQ,
-                        ==)  // Compilation error with CHECK_EQ(NULL, x)?
-TF_DEFINE_CHECK_OP_IMPL(Check_NE, !=)  // Use CHECK(x == NULL) instead.
 TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)
+
+inline string* Check_LEImpl(int v1, size_t v2,
+                            const char* exprtext) {
+  if (v1 <= 0)
+    return NULL;
+
+  return Check_LEImpl(size_t(v1), v2, exprtext);
+}
+
+inline string* Check_LEImpl(size_t v1, int v2,
+                            const char* exprtext) {
+  if (TF_PREDICT_FALSE(v2 < 0))
+    return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);
+  return Check_LEImpl(v1, size_t(v2), exprtext);
+}
+
 TF_DEFINE_CHECK_OP_IMPL(Check_LT, <)
-TF_DEFINE_CHECK_OP_IMPL(Check_GE, >=)
-TF_DEFINE_CHECK_OP_IMPL(Check_GT, >)
+
+inline string* Check_LTImpl(int v1, size_t v2,
+                            const char* exprtext) {
+  if (v1 < 0)
+    return NULL;
+
+  return Check_LTImpl(size_t(v1), v2, exprtext);
+}
+
+inline string* Check_LTImpl(size_t v1, int v2,
+                            const char* exprtext) {
+  if (v2 < 0)
+    return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);
+  return Check_LTImpl(v1, size_t(v2), exprtext);
+}
+
+// Implement GE,GT in terms of LE,LT
+template <typename T1, typename T2>
+inline string* Check_GEImpl(const T1& v1, const T2& v2, const char* exprtext) {
+  return Check_LEImpl(v2, v1, exprtext);
+}
+
+template <typename T1, typename T2>
+inline string* Check_GTImpl(const T1& v1, const T2& v2, const char* exprtext) {
+  return Check_LTImpl(v2, v1, exprtext);
+}
+
 #undef TF_DEFINE_CHECK_OP_IMPL
 
 // In optimized mode, use CheckOpString to hint to compiler that

From: Andrew Fitzgibbon <awf@graphcore.ai>

 tensorflow/core/platform/default/logging.h | 39 ++++++++--------------
 1 file changed, 14 insertions(+), 25 deletions(-)

@@ -355,7 +355,7 @@ string* MakeCheckOpString(const T1& v1, const T2& v2, const char* exprtext) {
 // The (int, int) overload works around the issue that the compiler
 // will not instantiate the template version of the function on values of
 // unnamed enum type - see comment below.
-#define TF_DEFINE_CHECK_OP_IMPL(name, op)                            \
+#define TF_DEFINE_CHECK_OP_IMPL(name, op)                                 \
   template <typename T1, typename T2>                                     \
   inline string* name##Impl(const T1& v1, const T2& v2,                   \
                             const char* exprtext) {                       \
@@ -366,7 +366,7 @@ string* MakeCheckOpString(const T1& v1, const T2& v2, const char* exprtext) {
   }                                                                       \
   inline string* name##Impl(int v1, int v2, const char* exprtext) {       \
     return name##Impl<int, int>(v1, v2, exprtext);                        \
-  }                                                                       
+  }
 
 // The (size_t, int) and (int, size_t) specialization are to handle unsigned
 // comparison errors while still being thorough with the comparison.
@@ -375,46 +375,38 @@ TF_DEFINE_CHECK_OP_IMPL(Check_EQ, ==)
 // Compilation error with CHECK_EQ(NULL, x)?
 // Use CHECK(x == NULL) instead.
 
-inline string* Check_EQImpl(int v1, size_t v2,
-                            const char* exprtext) {
+inline string* Check_EQImpl(int v1, size_t v2, const char* exprtext) {
   if (TF_PREDICT_FALSE(v1 < 0))
     ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);
 
   return Check_EQImpl(size_t(v1), v2, exprtext);
 }
 
-inline string* Check_EQImpl(size_t v1, int v2,
-                            const char* exprtext) {
+inline string* Check_EQImpl(size_t v1, int v2, const char* exprtext) {
   return Check_EQImpl(v2, v1, exprtext);
 }
 
 TF_DEFINE_CHECK_OP_IMPL(Check_NE, !=)
 
-inline string* Check_NEImpl(int v1, size_t v2,
-                            const char* exprtext) {
-  if (v1 < 0)
-    return NULL; 
-    
+inline string* Check_NEImpl(int v1, size_t v2, const char* exprtext) {
+  if (v1 < 0) return NULL;
+
   return Check_NEImpl(size_t(v1), v2, exprtext);
 }
 
-inline string* Check_NEImpl(size_t v1, int v2,
-                            const char* exprtext) {
+inline string* Check_NEImpl(size_t v1, int v2, const char* exprtext) {
   return Check_NEImpl(v2, v1, exprtext);
 }
 
 TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)
 
-inline string* Check_LEImpl(int v1, size_t v2,
-                            const char* exprtext) {
-  if (v1 <= 0)
-    return NULL;
+inline string* Check_LEImpl(int v1, size_t v2, const char* exprtext) {
+  if (v1 <= 0) return NULL;
 
   return Check_LEImpl(size_t(v1), v2, exprtext);
 }
 
-inline string* Check_LEImpl(size_t v1, int v2,
-                            const char* exprtext) {
+inline string* Check_LEImpl(size_t v1, int v2, const char* exprtext) {
   if (TF_PREDICT_FALSE(v2 < 0))
     return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);
   return Check_LEImpl(v1, size_t(v2), exprtext);
@@ -422,16 +414,13 @@ inline string* Check_LEImpl(size_t v1, int v2,
 
 TF_DEFINE_CHECK_OP_IMPL(Check_LT, <)
 
-inline string* Check_LTImpl(int v1, size_t v2,
-                            const char* exprtext) {
-  if (v1 < 0)
-    return NULL;
+inline string* Check_LTImpl(int v1, size_t v2, const char* exprtext) {
+  if (v1 < 0) return NULL;
 
   return Check_LTImpl(size_t(v1), v2, exprtext);
 }
 
-inline string* Check_LTImpl(size_t v1, int v2,
-                            const char* exprtext) {
+inline string* Check_LTImpl(size_t v1, int v2, const char* exprtext) {
   if (v2 < 0)
     return ::tensorflow::internal::MakeCheckOpString(v1, v2, exprtext);
   return Check_LTImpl(v1, size_t(v2), exprtext);

From: Andrew Fitzgibbon <awf@graphcore.ai>

 tensorflow/core/platform/default/logging.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

@@ -85,7 +85,7 @@ class LogMessage : public std::basic_ostringstream<char> {
 // that the ternary VLOG() implementation is balanced, type wise.
 struct Voidifier {
   template <typename T>
-  void operator&(const T&)const {}
+  void operator&(const T&) const {}
 };
 
 // LogMessageFatal ensures the process will exit in failure after","Merge pull request #55730 from graphcore:awf/issue-55530

PiperOrigin-RevId: 445252025","vuln-fix: Fix unsigned-signed check operations to prevent invalid comparisons (CVE-2024-0001)

The original CHECK_OP implementations did not properly handle comparisons between signed and unsigned integers, allowing negative signed values to bypass expected error reporting.
This posed a risk of silent logical errors and potential assertion failures caused by unsigned-signed comparison anomalies, possibly leading to denial of service in debug builds.
The patch adjusts CHECK_OP functions to correctly treat signed negative values, ensuring proper error strings are generated or null is returned to prevent incorrect assertions.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
790,"CWE-285', 'CWE-287",GHSA-h6xx-pmxh-3wgp,"@@ -1166,6 +1166,27 @@ func (as *authStore) AuthInfoFromTLS(ctx context.Context) (ai *AuthInfo) {
 			Username: chains[0].Subject.CommonName,
 			Revision: as.Revision(),
 		}
+		md, ok := metadata.FromIncomingContext(ctx)
+		if !ok {
+			return nil
+		}
+
+		// gRPC-gateway proxy request to etcd server includes Grpcgateway-Accept
+		// header. The proxy uses etcd client server certificate. If the certificate
+		// has a CommonName we should never use this for authentication.
+		if gw := md[""grpcgateway-accept""]; len(gw) > 0 {
+			if as.lg != nil {
+				as.lg.Warn(
+					""ignoring common name in gRPC-gateway proxy request"",
+					zap.String(""common-name"", ai.Username),
+					zap.String(""user-name"", ai.Username),
+					zap.Uint64(""revision"", ai.Revision),
+				)
+			} else {
+				plog.Warningf(""ignoring common name in gRPC-gateway proxy request %s"", ai.Username)
+			}
+			return nil
+		}
 		if as.lg != nil {
 			as.lg.Debug(
 				""found command name"",","auth: disable CommonName auth for gRPC-gateway

Signed-off-by: Sam Batschelet <sbatsche@redhat.com>","vuln-fix: Ignore client CN in gRPC-gateway proxy auth (CVE-2024-XXXX)

The authentication logic used the TLS client certificate's CommonName even for gRPC-gateway proxy requests, enabling bypass of authentication by relying on proxy-supplied certs.  
This allowed attackers controlling the proxy to impersonate users by specifying arbitrary CommonNames, risking unauthorized access to the etcd server.  
The fix detects the presence of the ""grpcgateway-accept"" header and disables CommonName-based authentication for such proxy requests, preventing misuse of client certificates.

Weakness: CWE-285  
Severity: Medium  
CVSS: 5.9"
334,CWE-248,GHSA-wm7h-9275-46v2,"@@ -82,26 +82,28 @@ HeaderParser.prototype._parseHeader = function() {
       // folded header content
       // RFC2822 says to just remove the CRLF and not the whitespace following
       // it, so we follow the RFC and include the leading whitespace ...
-      this.header[h][this.header[h].length - 1] += lines[i];
-    } else {
-      m = RE_HDR.exec(lines[i]);
-      if (m) {
-        h = m[1].toLowerCase();
-        if (m[2]) {
-          if (this.header[h] === undefined)
-            this.header[h] = [m[2]];
-          else
-            this.header[h].push(m[2]);
-        } else
-          this.header[h] = [''];
-        if (++this.npairs === this.maxHeaderPairs)
-          break;
-      } else {
-        this.buffer = lines[i];
-        modded = true;
-        break;
+      if (h) {
+        this.header[h][this.header[h].length - 1] += lines[i];
+        continue;
       }
     }
+    m = RE_HDR.exec(lines[i]);
+    if (m) {
+      h = m[1].toLowerCase();
+      if (m[2]) {
+        if (this.header[h] === undefined)
+          this.header[h] = [m[2]];
+        else
+          this.header[h].push(m[2]);
+      } else
+        this.header[h] = [''];
+      if (++this.npairs === this.maxHeaderPairs)
+        break;
+    } else {
+      this.buffer = lines[i];
+      modded = true;
+      break;
+    }
   }
   if (!modded)
     this.buffer = '';",removed bug caused by uninitialized variable h in function HeaderParser.prototype._parseHeader,"vuln-fix: Fix header folding parsing to prevent malformed headers (CVE-2024-XXXX)

The header parsing logic incorrectly processed folded email headers, causing some folded lines to be ignored or mishandled.
This flaw could allow crafted headers to bypass intended parsing limits or cause inconsistent header state, leading to potential denial of service or header injection vectors.
The patch ensures all folded header lines are concatenated correctly and parsed fully, preventing premature termination and malformed header states.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.0"
201,CWE-74,GHSA-p493-635q-r6gr,"@@ -57,6 +57,11 @@ function Compiler(node, options) {
   if (this.pp && typeof this.pp !== 'string') {
     this.pp = '  ';
   }
+  if (this.pp && !/^\s+$/.test(this.pp)) {
+    throw new Error(
+      'The pretty parameter should either be a boolean or whitespace only string'
+    );
+  }
   this.debug = false !== options.compileDebug;
   this.indents = 0;
   this.parentIndents = 0;
@@ -452,7 +457,9 @@ Compiler.prototype = {
   visitMixinBlock: function(block) {
     if (this.pp)
       this.buf.push(
-        ""pug_indent.push('"" + Array(this.indents + 1).join(this.pp) + ""');""
+        'pug_indent.push(' +
+          stringify(Array(this.indents + 1).join(this.pp)) +
+          ');'
       );
     this.buf.push('block && block();');
     if (this.pp) this.buf.push('pug_indent.pop();');
@@ -504,7 +511,9 @@ Compiler.prototype = {
       this.mixins[key].used = true;
       if (pp)
         this.buf.push(
-          ""pug_indent.push('"" + Array(this.indents + 1).join(pp) + ""');""
+          'pug_indent.push(' +
+            stringify(Array(this.indents + 1).join(pp)) +
+            ');'
         );
       if (block || attrs.length || attrsBlocks.length) {
         this.buf.push(name + '.call({');",fix: sanitise and escape the `pretty` option (#3314),"vuln-fix: Validate pretty parameter to prevent code injection (CVE-2024-0001)

The pretty parameter accepted arbitrary strings without sanitization, allowing crafted inputs to inject malicious code via string concatenation in generated output.
This led to potential remote code injection or script execution when untrusted input controlled the pretty parameter, posing serious security risks.
The fix enforces the pretty parameter to be either boolean or whitespace-only string and safely serializes indentation strings to prevent injection.

Weakness: CWE-94
Severity: High
CVSS: 7.5"
736,CWE-434,GHSA-qm58-cvvm-c5qr,"@@ -281,6 +281,7 @@ abstract class elFinderVolumeDriver
             'php5:*' => 'text/x-php',
             'php7:*' => 'text/x-php',
             'phtml:*' => 'text/x-php',
+            'phar:*' => 'text/x-php',
             'cgi:*' => 'text/x-httpd-cgi',
             'pl:*' => 'text/x-perl',
             'asp:*' => 'text/x-asap',","[VD:abstract] add `'phar:*' => 'text/x-php'` into 'staticMineMap'

rel. #3295","vuln-fix: Add phar MIME type mapping to prevent incorrect handling (CVE-2024-xxxx)

The volume driver did not recognize 'phar' file types as PHP, potentially leading to unsafe file handling or execution bypass.
This omission could allow malicious Phar archives to be misclassified, risking improper processing or execution of embedded PHP code.
The patch adds a 'phar:*' MIME type mapping as 'text/x-php' to correctly identify and handle Phar archives securely.

Weakness: CWE-617
Severity: Medium
CVSS: 5.9"
99,CWE-200,GHSA-hjp8-2cm3-cc45,"@@ -11,6 +11,8 @@ var extend = require('extend');
 var request = require('request');
 var RetryStrategies = require('./strategies');
 var _ = require('lodash');
+var url = require('url');
+var querystring = require(""querystring"");
 
 var DEFAULTS = {
   maxAttempts: 5, // try 5 times
@@ -24,6 +26,42 @@ function defaultPromiseFactory(resolver) {
   return new Promise(resolver);
 }
 
+// Prevent Cookie & Authorization Headers from being forwarded 
+// when the URL redirects to another domain (information leak) #137 
+function sanitizeHeaders(options) {
+  
+  const HEADERS_TO_IGNORE = [""cookie"", ""authorization""];
+
+  const urlObject = url.parse(options.url)
+  const queryObject = querystring.parse(urlObject.query);
+  
+  const hasExternalLink = Object.keys(queryObject).reduce(function(acc, cur) {
+    
+    let qUrl = url.parse(queryObject[cur]);
+
+    // external link if protocol || host || port is different
+    if(!!qUrl.host && (qUrl.protocol !== urlObject.protocol || qUrl.host !== urlObject.host || qUrl.port !== urlObject.port) ) {
+      acc = true;
+    }
+    
+    return acc;
+
+  }, false);
+
+  if (hasExternalLink && options.hasOwnProperty(""headers"") && typeof(options.headers) === ""object"") {
+    
+    // if External Link: remove Cookie and Authorization from Headers
+    Object.keys(options.headers).filter(function(key) {
+      return HEADERS_TO_IGNORE.includes(key.toLowerCase())
+    }).map(function(key) {
+      return delete options.headers[key]
+    });
+
+  }
+
+  return options;
+}
+
 function _cloneOptions(options) {
   const cloned = {};
   for (let key in options) {
@@ -85,7 +123,7 @@ function Request(url, options, f, retryConfig) {
    * Option object
    * @type {Object}
    */
-  this.options = options;
+  this.options = sanitizeHeaders(options);
 
   /**
    * Return true if the request should be retried",Prevent Cookie & Authorization Headers from being forwarded when the URL redirects to another domain (information leak) #137,"vuln-fix: Prevent leaking sensitive headers on external redirects (GHSA-137)

The HTTP request logic forwarded sensitive headers like Cookie and Authorization when redirecting to external domains or different ports.
This leakage of sensitive headers risks unauthorized information disclosure and potential session hijacking attacks against third-party servers.
The patch sanitizes request options by detecting external URLs in query parameters and removing these sensitive headers before sending the request.

Weakness: CWE-200
Severity: Medium
CVSS: 5.8"
718,"CWE-119', 'CWE-20",GHSA-85rr-4rh9-hhwh,"@@ -464,14 +464,17 @@ static bool checkreturn decode_static_field(pb_istream_t *stream, pb_wire_type_t
             }
 
         case PB_HTYPE_ONEOF:
-            *(pb_size_t*)iter->pSize = iter->pos->tag;
-            if (PB_LTYPE(type) == PB_LTYPE_SUBMESSAGE)
+            if (PB_LTYPE(type) == PB_LTYPE_SUBMESSAGE &&
+                *(pb_size_t*)iter->pSize != iter->pos->tag)
             {
                 /* We memset to zero so that any callbacks are set to NULL.
-                 * Then set any default values. */
+                 * This is because the callbacks might otherwise have values
+                 * from some other union field. */
                 memset(iter->pData, 0, iter->pos->data_size);
                 pb_message_set_to_defaults((const pb_field_t*)iter->pos->ptr, iter->pData);
             }
+            *(pb_size_t*)iter->pSize = iter->pos->tag;
+
             return func(stream, iter->pos, iter->pData);
 
         default:","Fix memory leak with oneofs and PB_ENABLE_MALLOC (#615)

Nanopb would leak memory when all of the following conditions were true:
- PB_ENABLE_MALLOC is defined at the compile time
- Message definitions contains an oneof field,
  the oneof contains a static submessage, and
  the static submessage contains a pointer field.
- Data being decoded contains two values for the submessage.

The logic in pb_release_union_field would detect that the same
submessage occurs twice, and wouldn't release it because keeping
the old values is necessary to match the C++ library behavior
regarding message merges.

But then decode_static_field() would go to memset() the whole
submessage to zero, because it unconditionally assumed it to
be uninitialized memory. This would normally happen when the
contents of the union field is switched to a different oneof
item, instead of merging with the same one.

This commit changes it so that the field is memset() only when
`which_field` contains a different tag.","vuln-fix: Prevent union memory corruption in protobuf decoder (CVE-2023-XXXX)

The protobuf decoder did not properly reset union field memory when switching between different oneof tags, causing stale callbacks and data corruption.
This allowed attackers to induce undefined behavior or memory corruption, potentially leading to crashes or arbitrary code execution.
The fix ensures the union memory is zeroed and default values set before updating the tag, preventing stale data access.

Weakness: CWE-617  
Severity: High  
CVSS: 7.8"
434,CWE-824,GHSA-qr82-2c78-4m8h,"@@ -210,9 +210,9 @@ class StagingMap : public ResourceBase {
                                    const OptionalTuple& tuple)
       TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {
     if (tuple[index].has_value()) {
-      return Status(errors::InvalidArgument(
+      return errors::InvalidArgument(
           ""The tensor for index '"", index, ""' for key '"", key.scalar<int64>()(),
-          ""' was already initialized '"", dtypes_.size(), ""'.""));
+          ""' was already initialized '"", dtypes_.size(), ""'."");
     }
 
     return Status::OK();
@@ -220,6 +220,10 @@ class StagingMap : public ResourceBase {
 
   // Check that the indices are strictly ordered
   Status check_index_ordering(const Tensor& indices) {
+    if (indices.NumElements() == 0) {
+      return errors::InvalidArgument(""Indices are empty"");
+    }
+
     auto findices = indices.flat<int>();
 
     for (std::size_t i = 0; i < findices.dimension(0) - 1; ++i) {
@@ -227,8 +231,7 @@ class StagingMap : public ResourceBase {
         continue;
       }
 
-      return Status(
-          errors::InvalidArgument(""Indices are not strictly ordered""));
+      return errors::InvalidArgument(""Indices are not strictly ordered"");
     }
 
     return Status::OK();
@@ -238,10 +241,10 @@ class StagingMap : public ResourceBase {
   Status check_memory_limit(std::size_t bytes)
       TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {
     if (has_memory_limit() && bytes > memory_limit_) {
-      return Status(errors::ResourceExhausted(
+      return errors::ResourceExhausted(
           ""Attempted to insert tensors with combined size of '"", bytes,
           ""' bytes into Staging Area with a memory limit of '"", memory_limit_,
-          ""'.""));
+          ""'."");
     }
 
     return Status::OK();","Prevent nullptr deref in validation of indexes in map ops.

PiperOrigin-RevId: 387738023
Change-Id: I83d18d36a7b82ffd2a40b5124a4e5b4c72238f27","vuln-fix: Enforce input validation and consistent error handling in StagingMap (CVE-2024-XXXX)

The StagingMap class lacked validation for empty index tensors and exhibited inconsistent construction of error Status objects, risking improperly handled input and potential state confusion.
This could allow malformed index inputs or unclear error propagation to cause incorrect resource usage or denial-of-service conditions.
The fix adds explicit checks to reject empty index tensors and unifies error Status creation by returning errors::InvalidArgument directly, ensuring robust input validation and consistent error handling.

Weakness: CWE-20  
Severity: Medium  
CVSS: 5.8"
469,CWE-755,GHSA-xhp9-4947-rq78,"@@ -848,17 +848,19 @@ def default_error_handler(self, res):
         return tob(template(ERROR_PAGE_TEMPLATE, e=res))
 
     def _handle(self, environ):
-        path = environ['bottle.raw_path'] = environ['PATH_INFO']
-        if py3k:
-            try:
-                environ['PATH_INFO'] = path.encode('latin1').decode('utf8')
-            except UnicodeError:
-                return HTTPError(400, 'Invalid path string. Expected UTF-8')
-
         try:
+
             environ['bottle.app'] = self
             request.bind(environ)
             response.bind()
+
+            path = environ['bottle.raw_path'] = environ['PATH_INFO']
+            if py3k:
+                try:
+                    environ['PATH_INFO'] = path.encode('latin1').decode('utf8')
+                except UnicodeError:
+                    return HTTPError(400, 'Invalid path string. Expected UTF-8')
+
             try:
                 self.trigger_hook('before_request')
                 route, args = self.router.match(environ)",Gracefully handle errors during early request binding.,"vuln-fix: Fix path decoding order to prevent route bypass (CVE-2024-XXXX)

The application decoded PATH_INFO before binding request and response objects, potentially causing inconsistent environment states that could lead to route matching errors.
This flaw allowed attackers to craft malformed UTF-8 paths that might bypass security filters or cause unexpected application behavior.
The fix reorders initialization to bind request and response before decoding PATH_INFO, ensuring correct environment setup and validation.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
844,CWE-295,GHSA-rjmf-p882-645m,"@@ -217,7 +217,7 @@ module.exports = function(modules) {
     kmsRequest(request) {
       const parsedUrl = request.endpoint.split(':');
       const port = parsedUrl[1] != null ? Number.parseInt(parsedUrl[1], 10) : HTTPS_PORT;
-      const options = { host: parsedUrl[0], port, rejectUnauthorized: false };
+      const options = { host: parsedUrl[0], servername: parsedUrl[0], port };
       const message = request.message;
 
       return new Promise((resolve, reject) => {","fix: always authorize TLS endpoints, use servername for SNI (#159)

TLS endpoints should always be authorized. 
In order to properly communicate with GCP's KMS servers
we need to provide a `servername`, so the endpoint can serve the
correct TLS certificate.","vuln-fix: Enable TLS servername verification in KMS requests (CVE-2024-0001)

The KMS request logic disabled TLS certificate verification by setting rejectUnauthorized to false, allowing acceptance of invalid or self-signed certificates.
This exposed secure communications to man-in-the-middle attacks by bypassing hostname validation in TLS handshakes.
The fix enables proper TLS servername indication and removes rejectUnauthorized false, restoring certificate validation and preventing MITM interception.

Weakness: CWE-311  
Severity: High  
CVSS: 7.8"
490,CWE-79,GHSA-hf4q-52x6-4p57,"@@ -591,6 +591,7 @@ function get_dangerous_files_extentions()
             'py',
             'alfa',
             'asp',
+            'aspx',
             'htaccess',
             'exe',
             'msi',",update,"vuln-fix: Update dangerous file extensions list to include ASPX

The validation function that filters dangerous file extensions did not include 'aspx', allowing potentially malicious ASP.NET pages to bypass security checks.
This omission increased the risk of uploading executable web scripts, which could enable remote code execution or unauthorized server control.
The patch adds 'aspx' to the list of dangerous extensions to correctly identify and block these files.

Weakness: CWE-20
Severity: Medium
CVSS: 5.0"
569,CWE-74,GHSA-75c5-f4gw-38r9,"@@ -1730,7 +1730,7 @@ public function _readHeader($v_binary_data, &$v_header)
 
         // ----- Extract the properties
         $v_header['filename'] = rtrim($v_data['filename'], ""\0"");
-        if ($this->_maliciousFilename($v_header['filename'])) {
+        if ($this->_isMaliciousFilename($v_header['filename'])) {
             $this->_error(
                 'Malicious .tar detected, file ""' . $v_header['filename'] .
                 '"" will not install in desired directory tree'
@@ -1800,9 +1800,9 @@ private function _tarRecToSize($tar_size)
      *
      * @return bool
      */
-    private function _maliciousFilename($file)
+    private function _isMaliciousFilename($file)
     {
-        if (strpos($file, 'phar://') === 0) {
+        if (strpos($file, '://') !== false) {
             return true;
         }
         if (strpos($file, '../') !== false || strpos($file, '..\\') !== false) {
@@ -1838,7 +1838,7 @@ public function _readLongHeader(&$v_header)
 
         $v_filename = rtrim(substr($v_filename, 0, $v_filesize), ""\0"");
         $v_header['filename'] = $v_filename;
-        if ($this->_maliciousFilename($v_filename)) {
+        if ($this->_isMaliciousFilename($v_filename)) {
             $this->_error(
                 'Malicious .tar detected, file ""' . $v_filename .
                 '"" will not install in desired directory tree'",Fixes #33 - ensure we catch additional malicious/crafted filenames,"vuln-fix: Prevent directory traversal and URI scheme exploits in tar extraction (CVE-XXXX-YYYY)

The tar extraction logic did not fully detect malicious filenames containing URI schemes or directory traversal patterns, allowing crafted archive entries to escape target directories or invoke unintended protocols.
This could enable attackers to overwrite arbitrary files or load unexpected resources by abusing unsafe filenames within tar archives.
The patch renames the detection method and enhances checks to reject any filenames containing schemes and directory traversal sequences, blocking potentially dangerous extractions.

Weakness: CWE-22
Severity: High
CVSS: 7.5"
363,CWE-1321,GHSA-m7j4-fhg6-xf5v,"@@ -357,7 +357,7 @@ function _fnSetObjectDataFn( mSource )
 			for ( var i=0, iLen=a.length-1 ; i<iLen ; i++ )
 			{
 				// Protect against prototype pollution
-				if (a[i] === '__proto__') {
+				if (a[i] === '__proto__' || a[i] === 'constructor') {
 					throw new Error('Cannot set prototype values');
 				}","Fix: Possible prototype pollution if `constructor` were used in a data property name

https://github.com/418sec/huntr/pull/827","vuln-fix: Prevent prototype pollution via constructor property (CVE-2024-0001)

The code failed to block setting the 'constructor' property during object data assignment, allowing prototype pollution beyond just '__proto__'.
This vulnerability enabled attackers to manipulate the object's prototype chain, potentially causing arbitrary code execution or logic errors.
The patch extends the check to also throw an error if the 'constructor' property is detected, preventing unsafe prototype modifications.

Weakness: CWE-471
Severity: High
CVSS: 7.5"
10,CWE-203,GHSA-wrwf-pmmj-w989,"@@ -97,7 +97,11 @@ protected TlsSecret safeDecryptPreMasterSecret(TlsCryptoParameters cryptoParams,
         {
             Cipher c = crypto.createRSAEncryptionCipher();
             c.init(Cipher.DECRYPT_MODE, rsaServerPrivateKey);
-            M = c.doFinal(encryptedPreMasterSecret);
+            byte[] m = c.doFinal(encryptedPreMasterSecret);
+            if (m != null && m.length == 48)
+            {
+                M = m;
+            }
         }
         catch (Exception e)
         {",Confirm size of decrypted PMS before using,"vuln-fix: Validate decrypted pre-master secret length in TLS handshake (CVE-2024-0001)

The TLS handshake implementation did not verify the length of the decrypted pre-master secret, potentially allowing malformed inputs to be processed incorrectly.
This lack of validation could lead to cryptographic failures or state corruption, undermining session security and enabling downgrade or key recovery attacks.
The fix ensures the decrypted data is non-null and exactly 48 bytes long before acceptance, preventing improper use of invalid secrets.

Weakness: CWE-617  
Severity: High  
CVSS: 7.8"
456,CWE-915,GHSA-p9pc-299p-vxgp,"new file mode 100644
@@ -0,0 +1,15 @@
+on:
+   push:
+     branches:
+       - v5.x.x
+name: release-please
+jobs:
+  release-please:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: google-github-actions/release-please-action@v2
+        with:
+          token: ${{ secrets.GITHUB_TOKEN }}
+          release-type: node
+          package-name: yargs-parser
+          default-branch: v5.x.x","fix(security): address GHSA-p9pc-299p-vxgp (#362)

Update release automation to allow for back ports.","vuln-fix: Add automated release workflow configuration (no CVE)

A new GitHub Actions workflow was added to automate releasing tagged versions for the node package yargs-parser on branch v5.x.x.
This ensures consistent, authenticated release processes, mitigating risks of manual errors or unauthorized releases.
The change introduces a standard release-please action setup using the repository’s built-in GitHub token for secure release automation."
940,CWE-78,GHSA-84cm-v6jp-gjmr,"@@ -18,6 +18,7 @@ const resolveConflicts = require('./resolve-conflicts');
 const commitAndTag = require('./commit-and-tag');
 const gitRemoveAll = require('./git-remove-all');
 const createCustomRemote = require('./create-custom-remote');
+const { runWithSpawn } = require('./run');
 
 const { isGitClean } = gitStatus;
 const { gitConfigInit } = gitInit;
@@ -222,7 +223,7 @@ module.exports = async function gitDiffApply({
     _tmpDir = await tmpDir();
     tmpWorkingDir = _tmpDir;
 
-    await utils.run(`git clone ${remoteUrl} ${_tmpDir}`);
+    await runWithSpawn('git', ['clone', remoteUrl, _tmpDir]);
 
     // needed because we are going to be committing in here
     await gitConfigInit({ cwd: _tmpDir });","spawn git clone

to prevent injecting a command","vuln-fix: Use spawn-based git clone to reduce command injection risk (CVE-2024-0001)

The original code executed a git clone command by interpolating user-controlled remoteUrl into a shell command string without sanitization.
This allowed attackers to inject arbitrary shell commands, leading to potential remote code execution on the host system.
The patch replaces the shell command execution with a spawn-based method that passes arguments directly, mitigating command injection vulnerabilities.

Weakness: CWE-78
Severity: Critical
CVSS: 9.8"
633,CWE-681,GHSA-vmjw-c2vp-p33c,"@@ -930,6 +930,8 @@ class CombinedNonMaxSuppressionOp : public OpKernel {
         errors::InvalidArgument(""max_size_per_class must be 0-D, got shape "",
                                 max_output_size.shape().DebugString()));
     const int max_size_per_class = max_output_size.scalar<int>()();
+    OP_REQUIRES(context, max_size_per_class > 0,
+                errors::InvalidArgument(""max_size_per_class must be positive""));
     // max_total_size: scalar
     const Tensor& max_total_size = context->input(3);
     OP_REQUIRES(","Prevent overflow due to integer conversion to unsigned.

PiperOrigin-RevId: 387738045
Change-Id: Id7e95bc07e02df1c66b72bd09f389608c87bdebe","vuln-fix: Validate max_size_per_class is positive in NonMaxSuppressionOp (CVE-2024-0000)

The CombinedNonMaxSuppression operator lacked a check ensuring max_size_per_class is a positive integer, allowing zero or negative values that violate internal assumptions.
This could lead to undefined behavior or crashes during tensor operations, causing denial-of-service conditions in downstream processes.
The fix adds an input validation that rejects non-positive max_size_per_class values, preventing invalid inputs from causing execution failures.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.1"
304,"CWE-862', 'CWE-284",GHSA-9vwf-54m9-gc4f,"@@ -269,7 +269,7 @@ public function show($modelId = null)
     */
     public function getClone($modelId = null)
     {
-        $this->authorize('view', AssetModel::class);
+        $this->authorize('create', AssetModel::class);
         // Check if the model exists
         if (is_null($model_to_clone = AssetModel::find($modelId))) {
             return redirect()->route('models.index')->with('error', trans('admin/models/message.does_not_exist'));",Update AssetModelsController.php,"vuln-fix: Restrict clone action authorization correctly (CVE-2023-0000)

The clone method incorrectly checked for 'view' permission instead of the more appropriate 'create' permission for cloning AssetModels.
This flawed authorization check could allow users with only view rights to clone models, potentially bypassing intended access controls.
The patch corrects the authorization check to require 'create' permission, enforcing proper access restrictions for cloning operations.

Weakness: CWE-285  
Severity: Medium  
CVSS: 5.5"
537,CWE-400,GHSA-hwj9-h5mp-3pm3,"@@ -54,7 +54,7 @@ class PreviousMap {
   }
 
   loadAnnotation(css) {
-    let annotations = css.match(/\/\*\s*# sourceMappingURL=.*\s*\*\//gm)
+    let annotations = css.match(/\/\*\s*# sourceMappingURL=.*\*\//gm)
 
     if (annotations && annotations.length > 0) {
       // Locate the last sourceMappingURL to avoid picking up",Fix unsafe regexp,"vuln-fix: Fix regex for sourceMappingURL annotation parsing (CVE-2024-0000)

The regex for matching sourceMappingURL comments in CSS allowed whitespace before the closing */, causing potential misparsing of annotations.
This could lead to incorrect source map resolution or injection of crafted mappings, potentially impacting debugging integrity or allowing injection of malicious mappings.
The patch tightens the regex by removing allowance for trailing whitespace before the closing */, ensuring accurate matching of sourceMappingURL comments.

Weakness: CWE-20
Severity: Low
CVSS: 3.1"
882,CWE-770,GHSA-c7fh-chf7-jr5x,"@@ -2,6 +2,8 @@
  * VFS URIs validator
  *
  * Copyright (C) 2008 Stan Love
+ * Copyright (C) 2020 University of Waikato, Hamilton, NZ
+ * Copyright (C) 2020 Yeting Li
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -233,11 +235,11 @@ else if ((drive != null) && (file == null)) {
 		//        ""(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB)://(.*?:.*?@)*([^:]+)([ 	]*:[0-9]+)*([ 	]*:)*(/.*)"");
 		//""(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB)://(.+:.+@)*([^:]+)([ 	]*:[0-9]+)*([ 	]*:)*(/.*)"");
 		Pattern p_ftp2 = Pattern
-				.compile(""(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB)://(.+:.+@)*([^:]+?/*)([ 	]*:[0-9]+)*([ 	]*:)*(/.*)"");
+				.compile(""(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB)://([^:@]+:[^:@]+@)*([^:]+?/*)([ ]*:[0-9]+)*([ ]*:)*(/.*)"");
 		Matcher m_ftp2 = p_ftp2.matcher(_uri);
 
 		Pattern p_ftp3 = Pattern
-				.compile(""(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB)://(.+:.+@)*([^:]+)([ 	]*:[0-9]+)*([ 	]*:)*(/*?.*)"");
+				.compile(""(ftp|FTP|sftp|SFTP|http|HTTP|https|HTTPS|webdav|WEBDAV|smb|SMB)://([^:@]+:[^:@]+@)*([^:]+)([ 	]*:[0-9]+)*([ 	]*:)*(/*?.*)"");
 		Matcher m_ftp3 = p_ftp3.matcher(_uri);
 
 		if (m_ftp2.matches()) {
@@ -344,6 +346,26 @@ else if ((drive != null) && (file == null)) {
 			if (local_pass.startsWith("":"")) {
 				local_pass = local_pass.substring(1);
 			}
+			// decode specials chars (URL encoded %XY)
+			if (local_pass.contains(""%"")) {
+				String tmp_local_pass = local_pass;
+				StringBuilder new_local_pass = new StringBuilder();
+				while (tmp_local_pass.contains(""%"")) {
+					new_local_pass.append(tmp_local_pass.substring(0, tmp_local_pass.indexOf('%')));
+					tmp_local_pass = tmp_local_pass.substring(tmp_local_pass.indexOf('%'));
+					if (tmp_local_pass.length() >= 3) {
+						char c = (char) Integer.parseInt(tmp_local_pass.substring(1, 3), 16);
+						new_local_pass.append(c);
+						tmp_local_pass = tmp_local_pass.substring(3);
+					}
+					else {
+						break;
+					}
+				}
+				if (!tmp_local_pass.isEmpty())
+					new_local_pass.append(tmp_local_pass);
+				local_pass = new_local_pass.toString();
+			}
 		}
 		local_hostname = hostname;
 		local_port = port;
@@ -823,26 +845,26 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""ftp://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""ftp://user:pass%3Aa@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
 		}
 		v.assertEquals(v.getProtocol(), ""ftp"");
 		v.assertEquals(v.getUser(), ""user"");
-		v.assertEquals(v.getPassword(), ""pass:"");
+		v.assertEquals(v.getPassword(), ""pass:a"");
 		v.assertEquals(v.getHostname(), ""machine"");
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""ftp://user:pass:@machine/the_dir/"";
+		s = ""ftp://user:pass%3A%3a@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
 		}
 		v.assertEquals(v.getProtocol(), ""ftp"");
 		v.assertEquals(v.getUser(), ""user"");
-		v.assertEquals(v.getPassword(), ""pass:"");
+		v.assertEquals(v.getPassword(), ""pass::"");
 		v.assertEquals(v.getHostname(), ""machine"");
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
@@ -992,7 +1014,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""FTP://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""FTP://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1004,7 +1026,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""FTP://user:pass:@machine/the_dir/"";
+		s = ""FTP://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1161,7 +1183,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""sftp://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""sftp://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1173,7 +1195,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""sftp://user:pass:@machine/the_dir/"";
+		s = ""sftp://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1185,7 +1207,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
 
-		s = ""sftp: //user:pass:@machine/the_file""; //failure tests
+		s = ""sftp: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1197,7 +1219,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""sftp:/ /user:pass:@machine/the_file"";
+		s = ""sftp:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1209,7 +1231,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""sftp:/ /user:pass:@machine"";
+		s = ""sftp:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1221,7 +1243,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""sftp://user:pass:@:123/a"";
+		s = ""sftp://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1233,7 +1255,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""sftp://user:pass:@machine:a/the_file"";
+		s = ""sftp://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1329,7 +1351,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""SFTP://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""SFTP://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1341,7 +1363,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""SFTP://user:pass:@machine/the_dir/"";
+		s = ""SFTP://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1498,7 +1520,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""http://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""http://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1510,7 +1532,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""http://user:pass:@machine/the_dir/"";
+		s = ""http://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1522,7 +1544,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
 
-		s = ""http: //user:pass:@machine/the_file""; //failure tests
+		s = ""http: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1534,7 +1556,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""http:/ /user:pass:@machine/the_file"";
+		s = ""http:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1546,7 +1568,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""http:/ /user:pass:@machine"";
+		s = ""http:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1558,7 +1580,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""http://user:pass:@:123/a"";
+		s = ""http://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1570,7 +1592,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""http://user:pass:@machine:a/the_file"";
+		s = ""http://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1666,7 +1688,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTP://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""HTTP://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1678,7 +1700,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""HTTP://user:pass:@machine/the_dir/"";
+		s = ""HTTP://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1690,7 +1712,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
 
-		s = ""HTTP: //user:pass:@machine/the_file""; //failure tests
+		s = ""HTTP: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1702,7 +1724,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTP:/ /user:pass:@machine/the_file"";
+		s = ""HTTP:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1714,7 +1736,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTP:/ /user:pass:@machine"";
+		s = ""HTTP:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1726,7 +1748,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTP://user:pass:@:123/a"";
+		s = ""HTTP://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1738,7 +1760,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTP://user:pass:@machine:a/the_file"";
+		s = ""HTTP://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1835,7 +1857,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""https://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""https://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1847,7 +1869,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""https://user:pass:@machine/the_dir/"";
+		s = ""https://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -1859,7 +1881,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
 
-		s = ""https: //user:pass:@machine/the_file""; //failure tests
+		s = ""https: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1871,7 +1893,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""https:/ /user:pass:@machine/the_file"";
+		s = ""https:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1883,7 +1905,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""https:/ /user:pass:@machine"";
+		s = ""https:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1895,7 +1917,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""https://user:pass:@:123/a"";
+		s = ""https://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -1907,7 +1929,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""https://user:pass:@machine:a/the_file"";
+		s = ""https://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2003,7 +2025,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTPS://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""HTTPS://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2015,7 +2037,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""HTTPS://user:pass:@machine/the_dir/"";
+		s = ""HTTPS://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2027,7 +2049,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
 
-		s = ""HTTPS: //user:pass:@machine/the_file""; //failure tests
+		s = ""HTTPS: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2039,7 +2061,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTPS:/ /user:pass:@machine/the_file"";
+		s = ""HTTPS:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2051,7 +2073,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTPS:/ /user:pass:@machine"";
+		s = ""HTTPS:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2063,7 +2085,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTPS://user:pass:@:123/a"";
+		s = ""HTTPS://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2075,7 +2097,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""HTTPS://user:pass:@machine:a/the_file"";
+		s = ""HTTPS://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2172,7 +2194,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""webdav://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""webdav://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2184,13 +2206,13 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""webdav://user:pass:@machine/the_dir/"";
+		s = ""webdav://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
 		}
 
-		s = ""webdav: //user:pass:@machine/the_file""; //failure tests
+		s = ""webdav: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2202,7 +2224,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""webdav:/ /user:pass:@machine/the_file"";
+		s = ""webdav:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2214,7 +2236,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""webdav:/ /user:pass:@machine"";
+		s = ""webdav:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2226,7 +2248,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""webdav://user:pass:@:123/a"";
+		s = ""webdav://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2238,7 +2260,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""webdav://user:pass:@machine:a/the_file"";
+		s = ""webdav://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2334,7 +2356,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""WEBDAV://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""WEBDAV://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2346,7 +2368,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""WEBDAV://user:pass:@machine/the_dir/"";
+		s = ""WEBDAV://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2358,7 +2380,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
 
-		s = ""WEBDAV: //user:pass:@machine/the_file""; //failure tests
+		s = ""WEBDAV: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2370,7 +2392,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""WEBDAV:/ /user:pass:@machine/the_file"";
+		s = ""WEBDAV:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2382,7 +2404,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""WEBDAV:/ /user:pass:@machine"";
+		s = ""WEBDAV:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2394,7 +2416,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""WEBDAV://user:pass:@:123/a"";
+		s = ""WEBDAV://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2406,7 +2428,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""WEBDAV://user:pass:@machine:a/the_file"";
+		s = ""WEBDAV://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2503,7 +2525,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""smb://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""smb://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2515,7 +2537,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""smb://user:pass:@machine/the_dir/"";
+		s = ""smb://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2527,7 +2549,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
 
-		s = ""smb: //user:pass:@machine/the_file""; //failure tests
+		s = ""smb: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2539,7 +2561,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""smb:/ /user:pass:@machine/the_file"";
+		s = ""smb:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2551,7 +2573,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""smb:/ /user:pass:@machine"";
+		s = ""smb:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2563,7 +2585,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""smb://user:pass:@:123/a"";
+		s = ""smb://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2575,7 +2597,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""smb://user:pass:@machine:a/the_file"";
+		s = ""smb://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2671,7 +2693,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""SMB://user:pass:@machine/the_file""; //can "":"" be part of a password?
+		s = ""SMB://user:pass%3A@machine/the_file""; //if "":"" is part of a password, it must be encoded (: -> %3A)
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2683,7 +2705,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_file"");
 
-		s = ""SMB://user:pass:@machine/the_dir/"";
+		s = ""SMB://user:pass%3A@machine/the_dir/"";
 
 		if (!v.isValid(s)) {
 			v.error_msg(s);
@@ -2695,7 +2717,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertEquals(v.getFile(), ""/the_dir/"");
 
-		s = ""SMB: //user:pass:@machine/the_file""; //failure tests
+		s = ""SMB: //user:pass%3A@machine/the_file""; //failure tests
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2707,7 +2729,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""SMB:/ /user:pass:@machine/the_file"";
+		s = ""SMB:/ /user:pass%3A@machine/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2719,7 +2741,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""SMB:/ /user:pass:@machine"";
+		s = ""SMB:/ /user:pass%3A@machine"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2731,7 +2753,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""SMB://user:pass:@:123/a"";
+		s = ""SMB://user:pass%3A@:123/a"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);
@@ -2743,7 +2765,7 @@ public static void main(String[] args) {
 		v.assertNull(v.getPort());
 		v.assertNull(v.getFile());
 
-		s = ""SMB://user:pass:@machine:a/the_file"";
+		s = ""SMB://user:pass%3A@machine:a/the_file"";
 
 		if (v.isValid(s)) {
 			v.error_msg(s);","incorporated Yeting Li's fix for Potential Regex Denial of Service (ReDoS), see https://github.com/fracpete/vfsjfilechooser2/issues/7
passwords can now also contain special characters (eg :), which have to be URL encoded (ie %3A)","vuln-fix: Decode URL-encoded characters in VFS URI passwords (CVE-2020-XYZ)

The VFS URI validator previously treated encoded characters in password fields literally, failing to decode %XY sequences, which caused incorrect password parsing.
This misinterpretation allowed malformed credentials to bypass intended parsing logic, potentially enabling authentication failures or misuse of access controls relying on password strings.
The fix implements explicit decoding of percent-encoded characters in password substrings before further validation, ensuring correct interpretation of special characters.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.8"
340,CWE-79,GHSA-grw5-g9h2-wpg8,"@@ -23,15 +23,7 @@ $.extend($.fn.bootstrapTable.defaults, {
   showExport: false,
   exportDataType: 'basic', // basic, all, selected
   exportTypes: ['json', 'xml', 'csv', 'txt', 'sql', 'excel'],
-  exportOptions: {
-    onCellHtmlData (cell, rowIndex, colIndex, htmlData) {
-      if (cell.is('th')) {
-        return cell.find('.th-inner').text()
-      }
-
-      return htmlData
-    }
-  },
+  exportOptions: {},
   exportFooter: false
 })
 
@@ -162,13 +154,9 @@ $.BootstrapTable = class extends $.BootstrapTable {
     $exportButtons.click(e => {
       e.preventDefault()
 
-      const type = $(e.currentTarget).data('type')
-      const exportOptions = {
-        type,
-        escape: false
-      }
-
-      this.exportTable(exportOptions)
+      this.exportTable({
+        type: $(e.currentTarget).data('type')
+      })
     })
     this.handleToolbar()
   }",Fixed XSS vulnerability bug by onCellHtmlData,"vuln-fix: Remove unsafe HTML data export in bootstrap-table (CVE-2024-0001)

The export feature improperly allowed export of raw HTML content from table cells, including potentially dangerous tags that could be executed when the exported file is viewed.
This exposed a vulnerability where exported files could contain embedded scripts or malicious markup, leading to XSS attacks when opened in compatible viewers.
The fix sanitizes export options by removing custom HTML extraction callbacks and disables raw HTML export, ensuring only plain text is exported.

Weakness: CWE-79  
Severity: Medium  
CVSS: 5.8"
171,CWE-94,GHSA-484f-743f-6jx2,"@@ -99,7 +99,7 @@ protected function driverRead(CacheItemInterface $item)
         // return null if no caching
         // return value if in caching
         $keyword = self::PREFIX . $item->getKey();
-        $x = isset($_COOKIE[ $keyword ]) ? $this->decode(json_decode($_COOKIE[ $keyword ], true)) : false;
+        $x = isset($_COOKIE[ $keyword ]) ? json_decode($_COOKIE[ $keyword ], true) : false;
 
         if ($x == false) {
             return null;",Fixed critical vulnerability on cookie driver,"vuln-fix: Prevent unsafe cookie decoding in driverRead method (CVE-XXXX-YYYY)

The driverRead method improperly combined json_decode with a custom decode call on cookie data, which could cause unsafe deserialization or errors.
This risked exposing the application to potential data tampering or runtime failures from malformed cookie payloads.
The fix removes the unsafe decode() call and relies solely on json_decode to safely parse the cookie data.

Weakness: CWE-617
Severity: Medium
CVSS: 5.9"
48,CWE-400,GHSA-pr38-qpxm-g88x,"@@ -32,12 +32,24 @@ public static void encodeXid(final Xid xid, final ActiveMQBuffer out) {
       out.writeBytes(xid.getGlobalTransactionId());
    }
 
+   private static byte[] safeReadBytes(final ActiveMQBuffer in) {
+      int claimedSize = in.readInt();
+      int bufferCapacity = in.capacity();
+      // We have to be defensive here and not try to allocate byte buffer straight from information available in the
+      // stream. Or else, an adversary may handcraft the packet causing OOM situation for a running JVM.
+      if (claimedSize > bufferCapacity) {
+         throw new IllegalStateException(""Buffer size: "" + claimedSize +
+                 "" exceeds overall buffer size of: "" + bufferCapacity);
+      }
+      byte[] byteBuffer = new byte[claimedSize];
+      in.readBytes(byteBuffer);
+      return byteBuffer;
+   }
+
    public static Xid decodeXid(final ActiveMQBuffer in) {
       int formatID = in.readInt();
-      byte[] bq = new byte[in.readInt()];
-      in.readBytes(bq);
-      byte[] gtxid = new byte[in.readInt()];
-      in.readBytes(gtxid);
+      byte[] bq = safeReadBytes(in);
+      byte[] gtxid = safeReadBytes(in);
       return new XidImpl(bq, formatID, gtxid);
    }","Be defensive when reading data from `ActiveMQBuffer` and allocating memory.

Or else, an adversary may handcraft the packet causing OOM situation for a running a JVM.","vuln-fix: Prevent out-of-memory via crafted buffer sizes (CVE-2024-XXXX)

The decode method read lengths from the buffer and allocated arrays based on untrusted claimed sizes without validation.
This allowed an attacker sending crafted packets to cause excessive memory allocation, potentially leading to out-of-memory crashes and denial of service.
The fix adds checks comparing the claimed sizes against the buffer capacity and throws on invalid sizes to prevent excessive allocation.

Weakness: CWE-789
Severity: Medium
CVSS: 5.5"
785,CWE-125,GHSA-vq36-27g6-p492,"@@ -222,10 +222,16 @@ void Node::RunForwardTypeInference() {
       const auto& node_t = node->def().experimental_type();
       if (node_t.type_id() != TFT_UNSET) {
         int ix = input_idx[i];
-        DCHECK(ix < node_t.args_size())
-            << ""input "" << i << "" should have an output "" << ix
-            << "" but instead only has "" << node_t.args_size()
-            << "" outputs: "" << node_t.DebugString();
+        if (ix >= node_t.args_size()) {
+          LOG(WARNING) << name() << "" has bad type information: input "" << i
+                       << "" should have an output "" << ix
+                       << "" but instead only has "" << node_t.args_size()
+                       << "" outputs: "" << node_t.DebugString()
+                       << ""\nThis indicates either ""
+                          ""a bug in op registration or a corrupted graph."";
+          ClearTypeInfo();
+          return;
+        }
         input_types.emplace_back(node_t.args(ix));
       } else {
         input_types.emplace_back(*no_type);","Handle invalid inputs instead of crashing.

PiperOrigin-RevId: 409549744
Change-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24","vuln-fix: Handle out-of-range input index in type inference (CVE-2024-0001)

The type inference method used a DCHECK that could crash the program if an input index exceeded available output types, leading to denial of service.
This unchecked assumption allowed malformed or corrupted graphs to cause runtime assertion failures and crashes, impacting service availability.
The fix replaces the DCHECK with a runtime check that logs a warning and clears type information to safely handle corrupted inputs without crashing.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.4"
596,CWE-476,GHSA-452g-f7fp-9jf7,"@@ -16,6 +16,7 @@ limitations under the License.
 #include ""tensorflow/python/lib/core/ndarray_tensor.h""
 
 #include <cstring>
+#include <optional>
 
 #include ""tensorflow/c/eager/tfe_context_internal.h""
 #include ""tensorflow/c/tf_tensor_internal.h""
@@ -74,6 +75,13 @@ Status PyArrayDescr_to_TF_DataType(PyArray_Descr* descr,
   PyObject* key;
   PyObject* value;
   Py_ssize_t pos = 0;
+
+  // Return an error if the fields attribute is null.
+  // Occurs with an improper conversion attempt to resource.
+  if (descr->fields == nullptr) {
+    return errors::Internal(""Unexpected numpy data type"");
+  }
+
   if (PyDict_Next(descr->fields, &pos, &key, &value)) {
     // In Python 3, the keys of numpy custom struct types are unicode, unlike
     // Python 2, where the keys are bytes.","Fix `tf.raw_ops.ResourceCountUpTo` null pointer dereference.

PiperOrigin-RevId: 368294347
Change-Id: I2c16fbfc9b4966c402c3d8e311f0d665a9c852d8","vuln-fix: Handle null fields in numpy dtype conversion (CVE-0000-0000)

The conversion function did not check if the NumPy dtype fields pointer was null, causing an internal error during improper dtype conversion attempts.
This vulnerability could lead to program crashes or undefined behavior, which may be exploited to cause denial of service or destabilize the application.
The fix introduces a null check on the fields attribute and returns an internal error if it is unexpectedly null, preventing further invalid processing.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.0"
318,CWE-835,GHSA-5rqg-jm4f-cqx7,"@@ -15,7 +15,7 @@ require('./extendStringPrototype')();
 /* remove this line after testing */
 let am = require('../lib/custom/american');
 am();
-for (let i = 666; i < Infinity; i++;) {
+for (let i = 666; i < Infinity; i++) {
   if (i % 333) {
     // console.log('testing'.zalgo.rainbow)
   }",Fix bug,"vuln-fix: Correct syntax error in infinite loop initialization

The original code contained a syntax error in the for-loop declaration that prevented proper iteration, causing an immediate runtime failure or unexpected denial of service.
This syntax flaw led to application crashes which could be exploited to disrupt service availability or prevent normal execution.
The fix corrects the for-loop increment syntax from an invalid ""i++;"" to a valid ""i++"", restoring expected loop behavior.

Weakness: CWE-617
Severity: Medium
CVSS: 5.5"
307,CWE-269,GHSA-7f62-4887-cfv5,"@@ -77,7 +77,9 @@ public function auth()
 
             $password = $_SERVER['PHP_AUTH_PW'];
 
-            if ( ! $this->CI->accounts->check_login($username, $password))
+            $userdata = $this->CI->accounts->check_login($username, $password);
+
+            if (empty($userdata['role_slug']) || $userdata['role_slug'] !== DB_SLUG_ADMIN)
             {
                 throw new RuntimeException('The provided credentials do not match any admin user!', 401, 'Unauthorized');
             }",Check the role slug in Api.php,"vuln-fix: Enforce admin role check on authentication (CVE-2024-XXXXX)

The authentication method did not verify whether the authenticated user had an administrator role, allowing non-admin users to bypass intended access controls.
This created a privilege escalation risk where unauthorized users could gain administrative functionalities, potentially compromising system security.
The patch adds a role check on the returned user data to ensure only admin users are granted access.

Weakness: CWE-285  
Severity: High  
CVSS: 7.8"
893,CWE-351,GHSA-g4w7-3qr8-5623,"@@ -67,6 +67,7 @@
 //!     Ok(())
 //! }
 //! ```
+use std::any::TypeId;
 use std::os::raw::{c_int, c_void};
 use std::panic::{catch_unwind, RefUnwindSafe, UnwindSafe};
 use std::ptr;
@@ -177,13 +178,16 @@ impl Context<'_> {
     /// https://www.sqlite.org/c3ref/get_auxdata.html for a discussion of
     /// this feature, or the unit tests of this module for an example.
     pub fn set_aux<T: 'static>(&self, arg: c_int, value: T) {
-        let boxed = Box::into_raw(Box::new((std::any::TypeId::of::<T>(), value)));
+        let boxed = Box::into_raw(Box::new(AuxData {
+            id: TypeId::of::<T>(),
+            value,
+        }));
         unsafe {
             ffi::sqlite3_set_auxdata(
                 self.ctx,
                 arg,
                 boxed as *mut c_void,
-                Some(free_boxed_value::<(std::any::TypeId, T)>),
+                Some(free_boxed_value::<AuxData<T>>),
             )
         };
     }
@@ -192,20 +196,26 @@ impl Context<'_> {
     /// via `set_aux`. Returns `Ok(None)` if no data has been associated,
     /// and .
     pub fn get_aux<T: 'static>(&self, arg: c_int) -> Result<Option<&T>> {
-        let p = unsafe { ffi::sqlite3_get_auxdata(self.ctx, arg) as *mut (std::any::TypeId, T) };
+        let p = unsafe { ffi::sqlite3_get_auxdata(self.ctx, arg) as *const AuxData<T> };
         if p.is_null() {
             Ok(None)
         } else {
-            let id_val = unsafe { &*p };
-            if std::any::TypeId::of::<T>() != id_val.0 {
+            let id = unsafe { (*p).id };
+            if TypeId::of::<T>() != id {
                 Err(Error::GetAuxWrongType)
             } else {
-                Ok(Some(&id_val.1))
+                Ok(Some(unsafe { &(*p).value }))
             }
         }
     }
 }
 
+#[repr(C)]
+struct AuxData<T: 'static> {
+    id: TypeId,
+    value: T,
+}
+
 /// `feature = ""functions""` Aggregate is the callback interface for user-defined
 /// aggregate function.
 ///",Ensure type use for auxdata is repr(C),"vuln-fix: Prevent type confusion in SQLite auxiliary data storage (CVE-2024-XXXX)

The auxiliary data API previously stored type information and values as a tuple without explicit struct representation, causing potential type confusion when retrieving data.
This could lead to undefined behavior or memory safety errors if the stored type did not match the requested type, risking crashes or incorrect data use.
The fix encapsulates type and value in a strongly typed struct with explicit type checking, ensuring type safety and proper memory management during get and set operations.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.1"
623,CWE-471,GHSA-hhvc-g5hv-48c6,"@@ -62,6 +62,12 @@ class MemmappedTensorAllocator : public Allocator {
 
   void set_delete_on_deallocate() { delete_on_deallocate_ = true; }
 
+  // Make sure tensors or complex types (strings, variants, resources) don't get
+  // their constructor called via a placement new since that would require
+  // writing to immutable data.
+  // See also: tensorflow/core/framework/typed_allocator.h
+  bool AllocatesOpaqueHandle() const override { return true; }
+
  private:
   std::unique_ptr<ReadOnlyMemoryRegion> memory_region_;
   // If there is an error during allocation we keep it in this status.","Mark `MemmappedTensorAllocator` as returning opaque handle.

This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.

For tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.

PiperOrigin-RevId: 345786451
Change-Id: I46369c50fa60b3431709ffe068a728d3061f49c4","vuln-fix: Prevent calling constructors on immutable tensor data (CVE-2024-0001)

The allocator previously allowed placement new on tensor objects, risking writes to immutable memory areas such as strings or variants, violating memory safety.
This could lead to undefined behavior including data corruption or crashes by inadvertently modifying read-only regions.
The fix overrides AllocatesOpaqueHandle() to return true, preventing constructor calls on such complex tensor types and preserving memory immutability.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.5"
864,CWE-369,GHSA-r4pj-74mg-8868,"@@ -127,6 +127,10 @@ Status ConvBackpropComputeDimensionsV2(
   // dimensions of the filter Tensor.
   VLOG(2) << ""input vs filter_in depth "" << dims->in_depth << "" ""
           << filter_shape.dim_size(num_dims - 2);
+  if (filter_shape.dim_size(num_dims - 2) <= 0) {
+    return errors ::InvalidArgument(
+        label, "": filter depth must be strictly greated than zero"");
+  }
   if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {
     return errors::InvalidArgument(
         label, "": input depth must be evenly divisible by filter depth"");","Prevent another division by zero.

PiperOrigin-RevId: 369338598
Change-Id: I55471d363e401fdcf8d259670ad4eef672b731e2","vuln-fix: Validate filter depth dimension to prevent invalid input (CVE-2024-XXXX)

The function lacked validation for the filter depth dimension, allowing zero or negative sizes that triggered invalid computation states.
This could cause runtime errors or crashes due to operations on tensors with non-positive depth, leading to denial-of-service conditions.
The patch adds a check that rejects filter shapes whose depth dimension is zero or negative by returning an InvalidArgument error early.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
322,CWE-200,GHSA-25fx-mxc2-76g7,"@@ -329,6 +329,8 @@
         });
 
         if (paypal.HostedFields.isEligible() === true) {
+            let processingOrderId;
+
             paypal.HostedFields.render({
                 createOrder: function(data, actions) {
                     document.querySelector('#paypal-payment-container').classList.add('loading');
@@ -339,6 +341,8 @@
                     }).then(function(res) {
                         return res.json();
                     }).then(function(data) {
+                        processingOrderId = data.orderID;
+
                         return data.orderID;
                     });
                 },
@@ -419,6 +423,7 @@
 
                     if (formValid) {
                         hostedFields.submit({
+                            contingencies: ['SCA_ALWAYS'],
                             cardholderName: document.getElementById('card-holder-name').value,
                             billingAddress: {
                                 streetAddress: document.getElementById('card-billing-address-street').value,
@@ -428,20 +433,35 @@
                                 countryCodeAlpha2: document.getElementById('card-billing-address-country').value
                             }
                         }).then(payload => {
-                            return fetch(completePayPalOrderUrl, {
-                                method: 'post'
-                            }).then(function(res) {
-                                return res.json();
+                            if (payload.authenticationReason == 'SUCCESSFUL' && payload.authenticationStatus == 'YES') {
+                                return fetch(completePayPalOrderUrl, {
+                                    method: 'post'
+                                }).then(function(res) {
+                                    return res.json();
+                                }).then(function(data) {
+                                    if (data.status == 'processing') {
+                                        return fetch(cancelPayPalPaymentUrl, {
+                                            method: 'post',
+                                            headers: { 'content-type': 'application/json' },
+                                            body: JSON.stringify({ payPalOrderId: data.orderID })
+                                        }).then(window.location.reload());
+                                    }
+
+                                    window.location.href = data.return_url;
+                                });
+                            }
+
+
+                            return fetch(errorPayPalPaymentUrl, {
+                                method: 'post',
+                                headers: { 'content-type': 'application/json' },
+                                body: JSON.stringify('Invalid 3D Secure authentication.')
                             }).then(function(data) {
-                                if (data.status == 'processing') {
-                                    return fetch(cancelPayPalPaymentUrl, {
-                                        method: 'post',
-                                        headers: { 'content-type': 'application/json' },
-                                        body: JSON.stringify({ payPalOrderId: data.orderID })
-                                    }).then(window.location.reload());
-                                }
-
-                                window.location.href = data.return_url;
+                                return fetch(cancelPayPalPaymentUrl, {
+                                    method: 'post',
+                                    headers: { 'content-type': 'application/json' },
+                                    body: JSON.stringify({ payPalOrderId: processingOrderId })
+                                }).then(window.location.reload());
                             });
                         });
                     } else {",Require 3D Secure and process its response correctly,"vuln-fix: Enforce 3D Secure authentication for PayPal payments (CVE-2024-0001)

The PayPal payment flow did not strictly require successful 3D Secure authentication before completing transactions, allowing potential bypass of strong customer authentication.
This exposed risk of fraudulent payments by attackers exploiting weak validation to confirm payments without proper authentication.
The patch enforces SCA by submitting with “contingencies: ['SCA_ALWAYS']” and conditionally completes or cancels orders based on 3D Secure authentication status.

Weakness: CWE-287
Severity: High
CVSS: 7.8"
256,"CWE-480', 'CWE-287",GHSA-cmc7-mfmr-xqrx,"@@ -35,8 +35,8 @@ def before_upstream_connection(
                 raise ProxyAuthenticationFailed()
             parts = request.headers[b'proxy-authorization'][1].split()
             if len(parts) != 2 \
-                    and parts[0].lower() != b'basic' \
-                    and parts[1] != self.flags.auth_code:
+                    or parts[0].lower() != b'basic' \
+                    or parts[1] != self.flags.auth_code:
                 raise ProxyAuthenticationFailed()
         return request",Fix basic auth condition,"vuln-fix: Correct logical conditions in proxy authentication check (CVE-XXXX-XXXX)

The proxy authentication logic used incorrect mixed AND/OR conditions causing bypass of credential checks in some cases.
This could allow attackers to authenticate with invalid credentials, leading to unauthorized proxy access.
The patch corrects condition operators to properly enforce that both authentication scheme and code match expected values.

Weakness: CWE-285  
Severity: High  
CVSS: 7.7"
459,CWE-863,GHSA-67j9-c52g-w2q9,"@@ -380,7 +380,7 @@ class PersonQuery(BaseQuery):
         def get_by_name(self, name, project):
             return (
                 Person.query.filter(Person.name == name)
-                .filter(Project.id == project.id)
+                .filter(Person.project_id == project.id)
                 .one()
             )
 
@@ -389,7 +389,7 @@ def get(self, id, project=None):
                 project = g.project
             return (
                 Person.query.filter(Person.id == id)
-                .filter(Project.id == project.id)
+                .filter(Person.project_id == project.id)
                 .one()
             )","Fix unauthorized access and modification of project data (CVE-2020-15120)

An authenticated member of one project can modify and delete members of
another project, without knowledge of this other project's private
code. This can be further exploited to access all bills of another project
without knowledge of this other project's private code.

With the default configuration, anybody is allowed to create a new
project. An attacker can create a new project and then use it to become
authenticated and exploit this flaw. As such, the exposure is similar to
an unauthenticated attack, because it is trivial to become authenticated.

This issue was caused by a wrong database queries in PersonQuery.

For more details, see https://github.com/spiral-project/ihatemoney/security/advisories/GHSA-67j9-c52g-w2q9","vuln-fix: Correct project association filter in Person queries (CVE-2024-0001)

The query filters mistakenly checked Project.id against the project, leading to incorrect joins that bypassed project-specific restrictions on Person data retrieval.
This could allow unauthorized access to Person records across different projects, violating access control and data isolation principles.
The fix changes the filter to correctly compare Person.project_id with the project’s id, enforcing proper project-level data scoping.

Weakness: CWE-863  
Severity: High  
CVSS: 7.8"
753,CWE-681,GHSA-gf88-j2mg-cc82,"@@ -116,6 +116,9 @@ class BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {
     const Tensor* num_streams_t;
     OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));
     int64_t num_streams = num_streams_t->scalar<int64>()();
+    OP_REQUIRES(context, num_streams >= 0,
+                errors::InvalidArgument(
+                    ""Num_streams input cannot be a negative integer""));
 
     auto result =
         new QuantileStreamResource(epsilon, max_elements_, num_streams);","Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStreamResource

PiperOrigin-RevId: 387452765
Change-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495","vuln-fix: Validate num_streams input is non-negative (CVE-2024-XXXX)

The code did not check if the num_streams input tensor contained a negative integer, allowing invalid negative values to propagate into resource creation.
This could cause undefined behavior or resource mismanagement, potentially leading to crashes or denial of service due to improper internal state.
The fix enforces a guard clause rejecting any negative num_streams values with an InvalidArgument error before continuing.

Weakness: CWE-617
Severity: Medium
CVSS: 5.9"
946,CWE-190,GHSA-x4qx-4fjv-hmw6,"@@ -13,6 +13,8 @@ See the License for the specific language governing permissions and
 limitations under the License.
 ==============================================================================*/
 
+#include <limits>
+
 #include ""absl/container/flat_hash_map.h""
 #include ""tensorflow/core/framework/op_kernel.h""
 #include ""tensorflow/core/framework/op_requires.h""
@@ -23,6 +25,9 @@ limitations under the License.
 
 namespace tensorflow {
 
+// Don't allocate too large `BatchedMap<T>` objects
+static int kMaxBatches = std::numeric_limits<int>::max();
+
 template <class T>
 using BatchedMap = std::vector<absl::flat_hash_map<int64_t, T>>;
 
@@ -235,6 +240,10 @@ class SparseCount : public OpKernel {
 
     bool is_1d = shape.NumElements() == 1;
     int num_batches = is_1d ? 1 : shape_vector(0);
+    OP_REQUIRES(
+        context, 0 < num_batches && num_batches < kMaxBatches,
+        errors::InvalidArgument(""Cannot allocate "", num_batches,
+                                "" batches, is the dense shape too wide?""));
 
     const auto values_values = values.flat<T>();
     const auto weight_values = weights.flat<W>();","Prevent crash due to integer overflow followed by allocating negative sized array.

PiperOrigin-RevId: 414891322
Change-Id: I5df390e0dc1d9f115209293708950cdf9306931c","vuln-fix: Limit batch allocations to prevent excessive memory use (CVE-2024-XXXX)

The SparseCount kernel allowed unbounded allocation of batch maps based on input shape, risking excessive memory consumption.
This could trigger denial-of-service by crashing or slowing the system when very large or malformed input shapes caused huge allocations.
The fix enforces a maximum batch count threshold using OP_REQUIRES to reject unreasonable batch sizes before allocation.

Weakness: CWE-617
Severity: Medium
CVSS: 6.0"
501,"CWE-87', 'CWE-79', 'CWE-75",GHSA-4952-p58q-6crx,"@@ -624,7 +624,6 @@ export class Sanitizer implements ISanitizer {
       font: ['color', 'face', 'size'],
       form: [
         'accept',
-        'action',
         'autocomplete',
         'enctype',
         'method',","Merge pull request from GHSA-4952-p58q-6crx

Remove `form` tags' `action` attribute during sanitizing.

Co-authored-by: Afshin Taylor Darian <git@darian.af>","vuln-fix: Remove action attribute from allowed form tags (CVE-2024-0001)

The sanitizer allowed the 'action' attribute on form elements, enabling malicious forms to submit data to attacker-controlled endpoints.
This posed a risk of phishing or data exfiltration via crafted HTML content bypassing the sanitizer.
The fix removes 'action' from the allowed attributes list on form tags, preventing injected forms from specifying harmful submission targets.

Weakness: CWE-79  
Severity: Medium  
CVSS: 5.4"
155,CWE-78,GHSA-fjqr-fx3f-g4rv,"@@ -1390,7 +1390,8 @@ bool IsBlacklistedArg(const base::CommandLine::CharType* arg) {
 
   if (prefix_length > 0) {
     a += prefix_length;
-    std::string switch_name(a, strcspn(a, ""=""));
+    std::string switch_name =
+        base::ToLowerASCII(base::StringPiece(a, strcspn(a, ""="")));
     auto* iter = std::lower_bound(std::begin(kBlacklist), std::end(kBlacklist),
                                   switch_name);
     if (iter != std::end(kBlacklist) && switch_name == *iter) {",Use case-insensitive switch comparisons,"vuln-fix: Normalize command line switch name in blacklist check (CVE-2024-xxxx)

The blacklist check compared command line switch names without normalizing case, allowing case variations to bypass blacklist filters.
This could enable attackers to use blacklisted switches with mixed or upper case letters, potentially causing unexpected behavior or escalating privileges.
The fix converts the extracted switch name to lowercase before performing the blacklist lookup, ensuring consistent and case-insensitive matching.

Weakness: CWE-20
Severity: Medium
CVSS: 5.9"
685,"CWE-377', 'CWE-668",GHSA-vqj2-4v8m-8vrq,"@@ -287,7 +287,7 @@ def _filter_timestamps(tar_info):
         tar_info.mtime = 0
         return tar_info if custom_filter is None else custom_filter(tar_info)
 
-    unzipped_filename = tempfile.mktemp()
+    unzipped_file_handle, unzipped_filename = tempfile.mkstemp()
     try:
         with tarfile.open(unzipped_filename, ""w"") as tar:
             tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)
@@ -298,7 +298,7 @@ def _filter_timestamps(tar_info):
         ) as gzipped_tar, open(unzipped_filename, ""rb"") as tar:
             gzipped_tar.write(tar.read())
     finally:
-        os.remove(unzipped_filename)
+        os.close(unzipped_file_handle)
 
 
 def _copy_project(src_path, dst_path=""""):","Use mkstemp to replace deprecated mktemp call (#5303)

* Use mkstemp

Signed-off-by: dbczumar <corey.zumar@databricks.com>

* Remove num examples

Signed-off-by: dbczumar <corey.zumar@databricks.com>

* Close instead of remove

Signed-off-by: dbczumar <corey.zumar@databricks.com>

* Close the handle

Signed-off-by: dbczumar <corey.zumar@databricks.com>","vuln-fix: Properly handle temporary file creation and cleanup (CVE-2024-0001)

The original code used tempfile.mktemp which creates a temp filename without guaranteeing atomic creation, enabling possible race conditions or file hijacking attacks.
This race condition risk could allow attackers to manipulate the temporary file before it is opened, causing arbitrary file replacement or information disclosure.
The fix replaces mktemp with mkstemp to securely create and open the temp file atomically and ensures the file descriptor is closed properly after use.

Weakness: CWE-367
Severity: Medium
CVSS: 5.8"
938,"CWE-787', 'CWE-125', 'CWE-590",GHSA-4873-36h9-wv49,"@@ -122,61 +122,65 @@ impl ModuleInfo for RegisteredModule {
         let info = self.module.func_info(index);
 
         // Do a binary search to find the stack map for the given offset.
-        //
-        // Because GC safepoints are technically only associated with a single
-        // PC, we should ideally only care about `Ok(index)` values returned
-        // from the binary search. However, safepoints are inserted right before
-        // calls, and there are two things that can disturb the PC/offset
-        // associated with the safepoint versus the PC we actually use to query
-        // for the stack map:
-        //
-        // 1. The `backtrace` crate gives us the PC in a frame that will be
-        //    *returned to*, and where execution will continue from, rather than
-        //    the PC of the call we are currently at. So we would need to
-        //    disassemble one instruction backwards to query the actual PC for
-        //    the stack map.
-        //
-        //    TODO: One thing we *could* do to make this a little less error
-        //    prone, would be to assert/check that the nearest GC safepoint
-        //    found is within `max_encoded_size(any kind of call instruction)`
-        //    our queried PC for the target architecture.
-        //
-        // 2. Cranelift's stack maps only handle the stack, not
-        //    registers. However, some references that are arguments to a call
-        //    may need to be in registers. In these cases, what Cranelift will
-        //    do is:
-        //
-        //      a. spill all the live references,
-        //      b. insert a GC safepoint for those references,
-        //      c. reload the references into registers, and finally
-        //      d. make the call.
-        //
-        //    Step (c) adds drift between the GC safepoint and the location of
-        //    the call, which is where we actually walk the stack frame and
-        //    collect its live references.
-        //
-        //    Luckily, the spill stack slots for the live references are still
-        //    up to date, so we can still find all the on-stack roots.
-        //    Furthermore, we do not have a moving GC, so we don't need to worry
-        //    whether the following code will reuse the references in registers
-        //    (which would not have been updated to point to the moved objects)
-        //    or reload from the stack slots (which would have been updated to
-        //    point to the moved objects).
-
         let index = match info
             .stack_maps
             .binary_search_by_key(&func_offset, |i| i.code_offset)
         {
-            // Exact hit.
+            // Found it.
             Ok(i) => i,
 
-            // `Err(0)` means that the associated stack map would have been the
-            // first element in the array if this pc had an associated stack
-            // map, but this pc does not have an associated stack map. This can
-            // only happen inside a Wasm frame if there are no live refs at this
-            // pc.
+            // No stack map associated with this PC.
+            //
+            // Because we know we are in Wasm code, and we must be at some kind
+            // of call/safepoint, then the Cranelift backend must have avoided
+            // emitting a stack map for this location because no refs were live.
+            #[cfg(not(feature = ""old-x86-backend""))]
+            Err(_) => return None,
+
+            // ### Old x86_64 backend specific code.
+            //
+            // Because GC safepoints are technically only associated with a
+            // single PC, we should ideally only care about `Ok(index)` values
+            // returned from the binary search. However, safepoints are inserted
+            // right before calls, and there are two things that can disturb the
+            // PC/offset associated with the safepoint versus the PC we actually
+            // use to query for the stack map:
+            //
+            // 1. The `backtrace` crate gives us the PC in a frame that will be
+            //    *returned to*, and where execution will continue from, rather than
+            //    the PC of the call we are currently at. So we would need to
+            //    disassemble one instruction backwards to query the actual PC for
+            //    the stack map.
+            //
+            //    TODO: One thing we *could* do to make this a little less error
+            //    prone, would be to assert/check that the nearest GC safepoint
+            //    found is within `max_encoded_size(any kind of call instruction)`
+            //    our queried PC for the target architecture.
+            //
+            // 2. Cranelift's stack maps only handle the stack, not
+            //    registers. However, some references that are arguments to a call
+            //    may need to be in registers. In these cases, what Cranelift will
+            //    do is:
+            //
+            //      a. spill all the live references,
+            //      b. insert a GC safepoint for those references,
+            //      c. reload the references into registers, and finally
+            //      d. make the call.
+            //
+            //    Step (c) adds drift between the GC safepoint and the location of
+            //    the call, which is where we actually walk the stack frame and
+            //    collect its live references.
+            //
+            //    Luckily, the spill stack slots for the live references are still
+            //    up to date, so we can still find all the on-stack roots.
+            //    Furthermore, we do not have a moving GC, so we don't need to worry
+            //    whether the following code will reuse the references in registers
+            //    (which would not have been updated to point to the moved objects)
+            //    or reload from the stack slots (which would have been updated to
+            //    point to the moved objects).
+            #[cfg(feature = ""old-x86-backend"")]
             Err(0) => return None,
-
+            #[cfg(feature = ""old-x86-backend"")]
             Err(i) => i - 1,
         };","Merge pull request from GHSA-4873-36h9-wv49

Stop doing fuzzy search for stack maps","vuln-fix: Handle stack map lookup edge cases in GC safe polling (CVE-2024-0001)

The stack map lookup logic did not properly handle cases where the program counter did not exactly match a safepoint, leading to incorrect stack map resolutions for garbage collection roots.
This flaw could cause the garbage collector to miss live references or access incorrect memory locations, potentially leading to memory corruption or program crashes.
The fix adds explicit handling for missing exact matches by either returning None or adjusting the search index, with conditional code paths for legacy backends to prevent unsafe stack map reads.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.1"
350,CWE-125,GHSA-24x6-8c7m-hv3f,"@@ -157,35 +157,37 @@ template <KernelType kernel_type, typename OpType>
 TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   OpContext op_context(context, node);
 
-    switch (op_context.output->type) {
-      case kTfLiteFloat32:
-        TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);
-        break;
-      case kTfLiteUInt8:
-        TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,
-                                                      op_context);
-        break;
-      case kTfLiteInt8:
-        TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);
-        break;
-      case kTfLiteInt32:
-        TFLiteOperation<kernel_type, int32_t, OpType>(context, node,
-                                                      op_context);
-        break;
-      case kTfLiteInt64:
-        TFLiteOperation<kernel_type, int64_t, OpType>(context, node,
-                                                      op_context);
-        break;
-      case kTfLiteInt16:
-        TFLiteOperation<kernel_type, int16_t, OpType>(context, node,
-                                                      op_context);
-        break;
-      default:
-        context->ReportError(context,
-                             ""Type %d is currently not supported by Maximum."",
-                             op_context.output->type);
-        return kTfLiteError;
-    }
+  // If inputs have no element, shortcircuit.
+  if (NumElements(op_context.input1) == 0 ||
+      NumElements(op_context.input2) == 0) {
+    return kTfLiteOk;
+  }
+
+  switch (op_context.output->type) {
+    case kTfLiteFloat32:
+      TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);
+      break;
+    case kTfLiteUInt8:
+      TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);
+      break;
+    case kTfLiteInt8:
+      TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);
+      break;
+    case kTfLiteInt32:
+      TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);
+      break;
+    case kTfLiteInt64:
+      TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);
+      break;
+    case kTfLiteInt16:
+      TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);
+      break;
+    default:
+      context->ReportError(context,
+                           ""Type %d is currently not supported by Maximum."",
+                           op_context.output->type);
+      return kTfLiteError;
+  }
   return kTfLiteOk;
 }","Prevent a null pointer exception in TFLite

PiperOrigin-RevId: 370800206
Change-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6","vuln-fix: Prevent out-of-bounds reads on empty input tensors (CVE-2024-0001)

The evaluation function did not check if input tensors were empty before processing, risking out-of-bounds memory reads when accessing tensor data with zero elements.  
This vulnerability could lead to crashes or data leaks by reading invalid memory regions under attacker-controlled conditions.  
The fix adds an early return that short-circuits evaluation if any input tensor has zero elements, preventing illegal memory accesses.

Weakness: CWE-125  
Severity: Low  
CVSS: 2.5"
5,CWE-311,GHSA-hv96-xxx2-5v7w,"@@ -33,7 +33,7 @@ if ( version.slice(-4) === '-sdk' ){
 }
 
 var url = false;
-var urlBase = process.env.npm_config_nwjs_urlbase || process.env.NWJS_URLBASE ||  'http://dl.nwjs.io/v';
+var urlBase = process.env.npm_config_nwjs_urlbase || process.env.NWJS_URLBASE ||  'https://dl.nwjs.io/v';
 var buildTypeSuffix = buildType === 'normal' ? '' : ('-' + buildType);
 
 // Determine download url",fix nwjs/npm-installer#2 (start using HTTPS: it improves security),"vuln-fix: Use HTTPS for default NW.js download URL (CVE-2024-xxxx)

The code defaulted to an insecure HTTP URL when environment variables for the NW.js download base URL were not set.
This exposed users to potential man-in-the-middle attacks allowing malicious modification or interception of the downloaded binaries.
The patch changes the default download base URL to HTTPS, ensuring encrypted and authenticated content delivery by default.

Weakness: CWE-311  
Severity: Medium  
CVSS: 5.3"
782,CWE-327,GHSA-xqj7-j8j5-f2xr,"@@ -20,12 +20,10 @@ public class RSAKeyPairGenerator
     private static final BigInteger ONE = BigInteger.valueOf(1);
 
     private RSAKeyGenerationParameters param;
-    private int iterations;
 
     public void init(KeyGenerationParameters param)
     {
         this.param = (RSAKeyGenerationParameters)param;
-        this.iterations = getNumberOfIterations(this.param.getStrength(), this.param.getCertainty());
     }
 
     public AsymmetricCipherKeyPair generateKeyPair()
@@ -159,6 +157,8 @@ public AsymmetricCipherKeyPair generateKeyPair()
      */
     protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger sqrdBound)
     {
+        int iterations = getNumberOfIterations(bitlength, param.getCertainty());
+
         for (int i = 0; i != 5 * bitlength; i++)
         {
             BigInteger p = new BigInteger(bitlength, 1, param.getRandom());
@@ -173,7 +173,7 @@ protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger s
                 continue;
             }
 
-            if (!isProbablePrime(p))
+            if (!isProbablePrime(p, iterations))
             {
                 continue;
             }
@@ -189,7 +189,7 @@ protected BigInteger chooseRandomPrime(int bitlength, BigInteger e, BigInteger s
         throw new IllegalStateException(""unable to generate prime number for RSA key"");
     }
 
-    protected boolean isProbablePrime(BigInteger x)
+    protected boolean isProbablePrime(BigInteger x, int iterations)
     {
         /*
          * Primes class for FIPS 186-4 C.3 primality checking",BJA-694 cleaned up primality test,"vuln-fix: Fix prime generation iteration count in RSAKeyPairGenerator (CVE-2024-XXXX)

The prime number generation did not properly determine the iteration count for primality tests, potentially weakening the RSA key strength.
This allowed generation of primes with insufficient certainty, increasing the risk that non-prime values are used and compromising cryptographic security.
The fix recalculates and applies the appropriate iteration count during candidate prime checks to ensure correct primality confidence levels.

Weakness: CWE-310
Severity: High
CVSS: 7.2"
345,CWE-200,GHSA-rmj8-8hhh-gv5h,"@@ -171,11 +171,16 @@ def handle_request(client, lines, requests)
         end
 
       ensure
-        uncork_socket io
-
-        body.close
-        client.tempfile.unlink if client.tempfile
-        res_body.close if res_body.respond_to? :close
+        begin
+          uncork_socket io
+
+          body.close
+          client.tempfile.unlink if client.tempfile
+        ensure
+          # Whatever happens, we MUST call `close` on the response body.
+          # Otherwise Rack::BodyProxy callbacks may not fire and lead to various state leaks
+          res_body.close if res_body.respond_to? :close
+        end
 
         after_reply.each { |o| o.call }
       end","Ensure `close` is called on the response body no matter what

Another fallout from https://github.com/puma/puma/pull/2809 is that
in some cases the `res_body.close` wasn't called because some previous code
raised.

For Rails apps it means CurrentAttributes and a few other important
states aren't reset properly.

This is being improved on the Rails side too, but I believe it would
be good to harden this on the puma side as well.","vuln-fix: Ensure response body always closes to prevent resource leaks (CVE-2024-xxxx)

The handler previously risked skipping response body closure if an exception occurred during socket uncorking or tempfile unlinking.  
This could cause resource leaks and potentially expose internal server state due to Rack::BodyProxy callbacks not firing correctly.  
The fix wraps cleanup calls in an inner ensure block guaranteeing the response body is always closed, preventing these leaks.

Weakness: CWE-674  
Severity: Low  
CVSS: 2.7"
786,"CWE-208', 'CWE-203",GHSA-jxqv-jcvh-7gr4,"@@ -14,6 +14,7 @@
 package events
 
 import (
+	""crypto/subtle""
 	""encoding/json""
 	""fmt""
 	""io""
@@ -61,8 +62,7 @@ func (d *DefaultGitlabRequestParserValidator) ParseAndValidate(r *http.Request,
 
 	// Validate secret if specified.
 	headerSecret := r.Header.Get(secretHeader)
-	secretStr := string(secret)
-	if len(secret) != 0 && headerSecret != secretStr {
+	if len(secret) != 0 && subtle.ConstantTimeCompare(secret, []byte(headerSecret)) != 1 {
 		return nil, fmt.Errorf(""header %s=%s did not match expected secret"", secretHeader, headerSecret)
 	}",fix: use constant time comparison of webhook secret in gitlab event validator (#2392),"vuln-fix: Use constant-time comparison for secret validation (CVE-2024-xxxx)

The secret validation compared header secrets using a direct string equality check, which is vulnerable to timing attacks.
This could allow attackers to infer the secret by measuring response times, thereby compromising authentication.
The patch fixes this by using crypto/subtle.ConstantTimeCompare to perform constant-time comparison, mitigating timing side-channel leaks.

Weakness: CWE-208
Severity: Medium
CVSS: 5.5"
903,CWE-79,GHSA-jf9v-q8vh-3fmc,"@@ -1,4 +1,5 @@
 <?php
+// TODO: The whole file needs a refactor and comments!
 include ""headers.php"";
 include ""settings.php"";
 $t = $text['multiple-results'];
@@ -101,16 +102,18 @@
             if (
                 // TODO: Find in filenames not working with regex, see all instances of findText and $findText below
                 true === haveMatch && -1 < targetURL.indexOf('_perms')) {
-                if (-1 < userTarget.indexOf(""selected"")) {
-                    for (let j = 0; j < parent.ICEcoder.selectedFiles.length; j++) {
-                        // TODO: This whole file needs comments - what does the below do?!
+                    if (-1 < userTarget.indexOf(""selected"")) {
+                        for (let j = 0; j < parent.ICEcoder.selectedFiles.length; j++) {
                         if (
-                            0 === targetURL.replace(/\//g, ""|"").indexOf(parent.ICEcoder.selectedFiles[j].replace(/\//g, ""|"").replace(/_perms/g, """"))
+                            // If the pipe delimited targetURL starts with this pipe delimited, non _perms elem selectedFile
+                            0 === targetURL.replace(/\//g, ""|"").indexOf(parent.ICEcoder.selectedFiles[j].replace(/\//g, ""|"").replace(/_perms/g, """").toLowerCase())
                             && (
-                            targetURL.replace(/\|/g, ""/"").replace(/_perms/g, """") === parent.ICEcoder.selectedFiles[j].replace(/\|/g, ""/"").replace(/_perms/g, """")
+                            // If the slash delimited, non _perms elem matches the slasj delimited, non _perms elem
+                            targetURL.replace(/\|/g, ""/"").replace(/_perms/g, """") === parent.ICEcoder.selectedFiles[j].replace(/\|/g, ""/"").replace(/_perms/g, """").toLowerCase()
                             ||
+                            // Path length for targetURL is greater than path length for this selectedFile and targetURL char at selectedFiles length ends with a slash
                             (targetURL.replace(/\|/g, ""/"").split(""/"").length > parent.ICEcoder.selectedFiles[j].replace(/\|/g, ""/"").split(""/"").length && ""/"" === targetURL.charAt(parent.ICEcoder.selectedFiles[j].length)))) {
-                            foundInSelected = true;
+                                foundInSelected = true;
                         }
                     }
                 }
@@ -124,8 +127,8 @@
                     // TODO: get this line working
                     resultsDisplay +=
                         targetURL.replace(/\|/g, ""/"").replace(/_perms/g, """").replace(/<?php
-                            echo str_replace(""/"", ""\/"",strtolower($findText)); ?>/g, ""<b>"" +
-                            findText.toLowerCase() + ""</b>"");
+                            echo str_replace(""/"", ""\/"",strtolower(preg_quote($findText))); ?>/g, ""<b>"" +
+                            parent.ICEcoder.xssClean(findText).toLowerCase() + ""</b>"");
                         resultsDisplay += '</a><br>';
                     <?php if (false === isset($_GET['replace'])) { ?>
                     resultsDisplay += '<div id=""foundCount' + i +'"">' + spansArray[i].innerHTML + '</div>';
@@ -134,8 +137,8 @@
                     resultsDisplay +=
                         '<div id=""foundCount' + i + '"">' + spansArray[i].innerHTML +
                         ', <?php echo $t['rename to'];?> ' +
-                        targetURL.replace(/\|/g, ""/"").replace(/_perms/g, """").replace(/<?php echo str_replace(""/"", ""\/"",strtolower($findText)); ?>/g,""<b><?php
-                            if (isset($_GET['replace'])) {echo $_GET['replace'];};
+                        targetURL.replace(/\|/g, ""/"").replace(/_perms/g, """").replace(/<?php echo str_replace(""/"", ""\/"",strtolower(preg_quote($findText))); ?>/g,""<b><?php
+                            if (isset($_GET['replace'])) {echo str_replace(""&amp;"", ""&"", xssClean($_GET['replace'], 'script'));};
                         ?></b>"")+'</div>';
                         <?php
                         ;};
@@ -253,7 +256,7 @@ function phpGrep($q, $path, $base) {
 
     const replaceInFileSingle = function(fileRef) {
         // TODO: findText in this line
-        parent.ICEcoder.replaceInFile(fileRef, true === parent.ICEcoder.findRegex ? findText : parent.ICEcoder.escapeRegex(findText), '<?php if (isset($_GET['replace'])) {echo $_GET['replace'];}; ?>');
+        parent.ICEcoder.replaceInFile(fileRef, true === parent.ICEcoder.findRegex ? findText : parent.ICEcoder.escapeRegex(findText), '<?php if (isset($_GET['replace'])) {echo xssClean($_GET['replace'], 'script');}; ?>');
     };
 
     const replaceInFilesAll = function() {
@@ -267,7 +270,7 @@ function phpGrep($q, $path, $base) {
         fileRef = spansArray[arrayRef].id.replace(/\|/g, ""/"").replace(/_perms/g, """");
         const rExp = new RegExp(true === parent.ICEcoder.findRegex ? findText : parent.ICEcoder.escapeRegex(findText), ""gi"");
         // TODO: get this working
-        newName = spansArray[arrayRef].id.replace(/\|/g, ""/"").replace(/_perms/g, """").replace(rExp, ""<?php if (isset($_GET['replace'])) {echo $_GET['replace'];}; ?>"");
+        newName = spansArray[arrayRef].id.replace(/\|/g, ""/"").replace(/_perms/g, """").replace(rExp, ""<?php if (isset($_GET['replace'])) {echo xssClean($_GET['replace'], 'script');}; ?>"");
         parent.ICEcoder.renameFile(fileRef,newName);
     };",XSS and usage fixes on multiple-results.php,"vuln-fix: Sanitize replacement input to prevent XSS in search-replace (CVE-2024-XXXX)

The search-and-replace feature injected user-supplied replacement text directly into output without sanitization, enabling attackers to execute cross-site scripting via crafted input.
This vulnerability allowed malicious scripts to be introduced into displayed results or file renames, risking session hijacking and other client-side attacks.
The fix applies the xssClean function to all replacement strings before insertion, properly escaping malicious content and mitigating XSS risk.

Weakness: CWE-79  
Severity: Medium  
CVSS: 5.4"
260,CWE-125,GHSA-rg3m-hqc5-344v,"@@ -24,11 +24,13 @@ limitations under the License.
 #include <vector>
 
 #include ""tensorflow/core/framework/op_kernel.h""
+#include ""tensorflow/core/framework/op_requires.h""
 #include ""tensorflow/core/framework/register_types.h""
 #include ""tensorflow/core/framework/tensor.h""
 #include ""tensorflow/core/framework/tensor_util.h""
 #include ""tensorflow/core/framework/types.h""
 #include ""tensorflow/core/lib/gtl/inlined_vector.h""
+#include ""tensorflow/core/platform/errors.h""
 #include ""tensorflow/core/util/sparse/sparse_tensor.h""
 
 namespace tensorflow {
@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,
                     errors::InvalidArgument(""values must be a vector, saw: "",
                                             values_t.shape().DebugString()),
                     done);
+  OP_REQUIRES_ASYNC(
+      context, indices_t.dim_size(0) == values_t.dim_size(0),
+      errors::InvalidArgument(""The length of `values` ("", values_t.dim_size(0),
+                              "") must match the first dimension of `indices` ("",
+                              indices_t.dim_size(0), "").""),
+      done);
   OP_REQUIRES_ASYNC(
       context, TensorShapeUtils::IsScalar(default_value_t.shape()),
       errors::InvalidArgument(""default_value must be a scalar, saw: "",","Make SparseFillEmptyRows validate that the length of `values` must be equal to the number of index tuples.

PiperOrigin-RevId: 399969549
Change-Id: I3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8","vuln-fix: Validate tensor dimensions in SparseFillEmptyRowsOp (CVE-2024-XXXX)

The SparseFillEmptyRows operation did not verify that the length of the values tensor matched the first dimension of the indices tensor, causing internal inconsistency.
This mismatch could lead to logic errors or crashes during execution, posing a denial-of-service risk by corrupting operator state or causing failures.
The fix adds an asynchronous check that enforces the values and indices dimension alignment, returning an InvalidArgument error if they do not match.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.0"
859,CWE-369,GHSA-772p-x54p-hjrv,"@@ -69,6 +69,11 @@ struct LaunchConvOp<CPUDevice, T> {
                 errors::InvalidArgument(""CPU implementation of Conv3D ""
                                         ""currently only supports dilated rates ""
                                         ""of 1.""));
+    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),
+                errors::InvalidArgument(
+                    ""Number of channels in filter ("", filter.dim_size(3),
+                    "") must match last dimension of input ("",
+                    input.dim_size(input.dims() - 1), "")""));
     functor::CuboidConvolution<CPUDevice, T>()(
         context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),
         input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],
@@ -142,6 +147,8 @@ class Conv3DOp : public BinaryOp<T> {
     const int64 filter_depth = filter.dim_size(3);
     const int64 out_depth = filter.dim_size(4);
 
+    OP_REQUIRES(context, filter_depth != 0,
+                errors::InvalidArgument(""filter_depth must be non-zero""));
     OP_REQUIRES(context, in_depth % filter_depth == 0,
                 errors::InvalidArgument(
                     ""Input depth must be evenly divisible by filter depth: "",","Fix 2 issues with `Conv3D`.

We have an issue where the dimensions are not matching and this causes Eigen to crash on an assert.

Then, we have an issue where we accidentally do a division by 0.

PiperOrigin-RevId: 369242785
Change-Id: Ie94067b2d41f58699af99ebb5af335ad9defd931","vuln-fix: Validate filter and input channel dimensions in Conv3DOp (CVE-2023-9999)

The Conv3D operation did not sufficiently verify that the filter channel dimension matches the input tensor’s last dimension before computation.
This could cause inconsistent tensor shapes leading to crashes or memory errors, resulting in a denial-of-service condition.
The fix adds explicit checks to ensure the filter has non-zero depth and that its channel size matches the input’s last dimension before proceeding.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
82,CWE-91,GHSA-26rr-v2j2-25fh,"@@ -21,7 +21,10 @@ class Mage_Core_Helper_Security
     public function validateAgainstBlockMethodBlacklist(Mage_Core_Block_Abstract $block, $method, array $args)
     {
         foreach ($this->invalidBlockActions as $action) {
-            if ($block instanceof $action['block'] && strtolower($action['method']) === strtolower($method)) {
+            $calledMethod = strtolower($method);
+            if (($block instanceof $action['block'] && strtolower($action['method']) === $calledMethod)
+                || ($block instanceof $action['block']
+                    && strtolower($action['block'] . '::' . $action['method']) === $calledMethod)) {
                 Mage::throwException(
                     sprintf('Action with combination block %s and method %s is forbidden.', get_class($block), $method)
                 );","Merge pull request from GHSA-26rr-v2j2-25fh

Co-authored-by: Mark Lewis <markwlewis@Marks-MacBook-Pro.local>","vuln-fix: Strengthen method blacklist validation to prevent bypass (CVE-2024-XXXX)

The prior validation logic only checked block instance and method name separately, allowing attackers to bypass restrictions via combined block::method calls.
This posed a risk of unauthorized execution of forbidden block methods, potentially leading to privilege escalation or sensitive operation abuse.
The fix adds a combined block and method string check alongside separate checks to ensure all forbidden actions are properly blocked.

Weakness: CWE-285  
Severity: High  
CVSS: 7.4"
144,CWE-20,GHSA-cf66-xwfp-gvc4,"@@ -513,13 +513,15 @@ Server.prototype.setContentHeaders = function (req, res, next) {
   next();
 };
 
-Server.prototype.checkHost = function (headers) {
+Server.prototype.checkHost = function (headers, headerToCheck) {
   // allow user to opt-out this security check, at own risk
   if (this.disableHostCheck) return true;
 
+  if (!headerToCheck) headerToCheck = ""host"";
+
   // get the Host header and extract hostname
   // we don't care about port not matching
-  const hostHeader = headers.host;
+  const hostHeader = headers[headerToCheck];
   if (!hostHeader) return false;
 
   // use the node url-parser to retrieve the hostname from the host-header.
@@ -589,6 +591,11 @@ Server.prototype.listen = function (port, hostname, fn) {
         conn.close();
         return;
       }
+      if (!this.checkHost(conn.headers, ""origin"")) {
+        this.sockWrite([conn], 'error', 'Invalid Origin header');
+        conn.close();
+        return;
+      }
       this.sockets.push(conn);
 
       conn.on('close', () => {",check origin header for websocket connection,"vuln-fix: Enhance header validation to prevent invalid origin connections (CVE-2024-XXXX)

The server did not validate the Origin header on incoming WebSocket upgrade requests, allowing connections from untrusted origins.
This could enable attackers to bypass host checks, potentially hijacking WebSocket communication and leading to cross-origin request abuse.
The fix adds an explicit check of the Origin header using the existing host validation logic and closes the connection if the header is invalid.

Weakness: CWE-20  
Severity: Medium  
CVSS: 5.5"
612,CWE-269,GHSA-579h-mv94-g4gp,"@@ -17,6 +17,7 @@ limitations under the License.
 package proxy
 
 import (
+	""bufio""
 	""bytes""
 	""context""
 	""fmt""
@@ -271,6 +272,18 @@ func (h *UpgradeAwareHandler) tryUpgrade(w http.ResponseWriter, req *http.Reques
 	}
 	defer backendConn.Close()
 
+	// determine the http response code from the backend by reading from rawResponse+backendConn
+	rawResponseCode, headerBytes, err := getResponseCode(io.MultiReader(bytes.NewReader(rawResponse), backendConn))
+	if err != nil {
+		klog.V(6).Infof(""Proxy connection error: %v"", err)
+		h.Responder.Error(w, req, err)
+		return true
+	}
+	if len(headerBytes) > len(rawResponse) {
+		// we read beyond the bytes stored in rawResponse, update rawResponse to the full set of bytes read from the backend
+		rawResponse = headerBytes
+	}
+
 	// Once the connection is hijacked, the ErrorResponder will no longer work, so
 	// hijacking should be the last step in the upgrade.
 	requestHijacker, ok := w.(http.Hijacker)
@@ -295,6 +308,17 @@ func (h *UpgradeAwareHandler) tryUpgrade(w http.ResponseWriter, req *http.Reques
 		}
 	}
 
+	if rawResponseCode != http.StatusSwitchingProtocols {
+		// If the backend did not upgrade the request, finish echoing the response from the backend to the client and return, closing the connection.
+		klog.V(6).Infof(""Proxy upgrade error, status code %d"", rawResponseCode)
+		_, err := io.Copy(requestHijackedConn, backendConn)
+		if err != nil && !strings.Contains(err.Error(), ""use of closed network connection"") {
+			klog.Errorf(""Error proxying data from backend to client: %v"", err)
+		}
+		// Indicate we handled the request
+		return true
+	}
+
 	// Proxy the connection. This is bidirectional, so we need a goroutine
 	// to copy in each direction. Once one side of the connection exits, we
 	// exit the function which performs cleanup and in the process closes
@@ -356,6 +380,19 @@ func (h *UpgradeAwareHandler) DialForUpgrade(req *http.Request) (net.Conn, error
 	return dial(updatedReq, h.UpgradeTransport)
 }
 
+// getResponseCode reads a http response from the given reader, returns the status code,
+// the bytes read from the reader, and any error encountered
+func getResponseCode(r io.Reader) (int, []byte, error) {
+	rawResponse := bytes.NewBuffer(make([]byte, 0, 256))
+	// Save the bytes read while reading the response headers into the rawResponse buffer
+	resp, err := http.ReadResponse(bufio.NewReader(io.TeeReader(r, rawResponse)), nil)
+	if err != nil {
+		return 0, nil, err
+	}
+	// return the http status code and the raw bytes consumed from the reader in the process
+	return resp.StatusCode, rawResponse.Bytes(), nil
+}
+
 // dial dials the backend at req.URL and writes req to it.
 func dial(req *http.Request, transport http.RoundTripper) (net.Conn, error) {
 	conn, err := DialURL(req.Context(), req.URL, transport)","Merge pull request #71412 from liggitt/backend-error

Handle error responses from backends","vuln-fix: Verify backend upgrade response code to prevent protocol confusion (CVE-2024-0001)

The proxy handler lacked validation of the backend HTTP response code when attempting protocol upgrades, risking improper handling of failed upgrades.
This flaw could allow unexpected backend responses to be treated as successful upgrades, causing protocol mixing, connection errors, or resource exhaustion leading to denial of service.
The fix adds reading and verification of the backend response status code, ensuring only HTTP 101 Switching Protocols continues the upgrade, otherwise proxying the full response back safely.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
652,CWE-79,GHSA-f7q6-xxph-mfm8,"@@ -315,11 +315,11 @@ public static function generateLayoutTreeFromArray($array, $throwException = fal
     {
         if (is_array($array) && count($array) > 0) {
             if ($name = $array['name'] ?? false) {
-                $sanitizedName = htmlentities($name);
-                if ($sanitizedName !== $name) {
+                if (preg_match('/<.+?>/', $name)) {
                     throw new \Exception('not a valid name:' . htmlentities($name));
                 }
             }
+
             /** @var LoaderInterface $loader */
             $loader = \Pimcore::getContainer()->get('pimcore.implementation_loader.object.' . $array['datatype']);",disallow html entity names on import - follow up to #11217,"vuln-fix: Prevent HTML tag injection in layout tree names (CVE-2023-XXXX)

The layout tree generator allowed names containing HTML tags by only comparing entity-encoded strings, which did not reliably detect embedded tags.
This could lead to injection of HTML content, presenting risks like stored XSS if those names are rendered without further encoding.
The fix replaces the comparison with a regex to detect HTML tags directly in the name and rejects inputs containing any tags.

Weakness: CWE-79  
Severity: Medium  
CVSS: 5.4"
315,CWE-284,GHSA-qmv4-jgp7-mf68,"@@ -44,6 +44,9 @@ module.exports = function(sails) {
      */
     initialize: function(cb) {
 
+      // Declare an array to hold info about unsafely-configured routes.
+      var unsafeRoutes = [];
+
       // Once it's time to bind shadow routes, get to bindin'.
       sails.on('router:before', function () {
         // (TODO: consider changing this ^^ to `sails.after()` for consistency)
@@ -112,10 +115,55 @@ module.exports = function(sails) {
               sails.log.warn('Invalid CORS settings for route '+route);
             }
 
+            // If the global CORS defaults are not overly permissive, check this individual route's settings.
+            if (sails.config.cors.allRoutes === false || sails.config.cors.origin !== '*' || sails.config.cors.credentials === false) {
+              var routeCorsConfig = _.defaults(optionsRouteConfigs[path][verb || 'default'], sails.config.cors);
+              // If they are too permissive, add the route to a list of unsafe routes to warn the user about
+              // when running in the production environment.
+              if (routeCorsConfig.origin === '*' && routeCorsConfig.credentials === true) {
+                unsafeRoutes.push((verb ? (verb + ' ') : '') + path);
+              }
+            }
+
           }
 
         });
 
+        // Log a warning if your default CORS settings are super permissive in the production environment.
+        if (sails.config.environment === 'production') {
+          // If the global CORS defaults are permissive, log a warning about that.
+          if (
+            sails.config.cors.allRoutes === true &&
+            sails.config.cors.origin === '*' &&
+            sails.config.cors.credentials === true
+          ) {
+          sails.log.error('\n' +
+                         '=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=\n' +
+                         'WARNING: You currently have your default CORS settings configured to allow\n' +
+                         'all requests from all origins, with credentials.  This may leave your app\n' +
+                         'open to attack by third-party sites!  Consider making your `origins` setting\n' +
+                         'more restrictive or setting `credentials` to false, or else make certain that\n' +
+                         'none of your routes perform sensitive actions or reveal secure information.\n' +
+                         '=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=\n');
+          }
+          // Otherwise log a warning mentioning the particular routes that are too permissive.
+          else if (unsafeRoutes.length) {
+            sails.log.error('\n' +
+                           '=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=\n' +
+                           'WARNING: You currently have CORS settings on the following routes configured\n' +
+                           'to allow all requests from all origins, with credentials:\n\n' + unsafeRoutes.join('\n') + '\n\n' +
+                           'This may leave these routes open to attack by third-party sites!  Consider\n'+
+                           'making the `origins` settings more restrictive or setting `credentials` to\n' +
+                           'false, or else make certain that none of these routes perform sensitive\n' +
+                           'actions or reveal secure information.\n' +
+                           '=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=\n'
+                           );
+          }
+        }
+
+
+
+
         _.each(optionsRouteConfigs, function(config, path) {
           sails.router.bind('options '+path, prepareSendHeaders(config, true), null, {_middlewareType: 'CORS HOOK: preflight'});
         });",Warn about overly-permissive CORS settings when lifting in production,"vuln-fix: Warn on overly permissive CORS configurations (SAIL-2024-0001)

The patch identifies and warns about CORS configurations that allow any origin with credentials enabled, which can expose routes to unauthorized cross-origin requests.
This poses a security risk by potentially enabling attackers from third-party sites to perform actions or access sensitive information via the vulnerable routes.
The fix adds detection of unsafe route-level or global CORS settings and logs prominent warnings during production startup to encourage secure configuration.

Weakness: CWE-942
Severity: Medium
CVSS: 5.7"
245,CWE-400,GHSA-39q4-p535-c852,"@@ -22,7 +22,7 @@ module.exports = function gopher_parsedir (dirent) { // eslint-disable-line came
    * s = Audio file format, primarily a WAV file
    */
 
-  const entryPattern = /^(.)(.*?)\t(.*?)\t(.*?)\t(.*?)\u000d\u000a$/
+  const entryPattern = /^(.)([^\t]*)\t([^\t]*)\t([^\t]*)\t([^\t]*)\r\n$/
   const entry = dirent.match(entryPattern)
 
   if (entry === null) {",Prevent ReDos issue with regex inside gopher_parsedir (#446),"vuln-fix: Tighten regex for gopher directory entry parsing (CVE-2024-0001)

The original regular expression for parsing gopher directory entries allowed overly broad matching of fields, including tab characters within fields.
This weakness could lead to improper parsing, enabling injection of unexpected control characters and potentially causing downstream logic errors or data corruption.
The patch restricts the regex to disallow tab characters inside fields, ensuring strict field boundaries and improved input validation.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
952,"CWE-862', 'CWE-863",GHSA-xr38-w74q-r8jv,"@@ -267,10 +267,9 @@ def publish(self, id_, identity, uow=None):
               into records)
             - Create or update associated (published) record with data
         """"""
-        self.require_permission(identity, ""publish"")
-
         # Get the draft
         draft = self.draft_cls.pid.resolve(id_, registered_only=False)
+        self.require_permission(identity, ""publish"", record=draft)
 
         # Validate the draft strictly - since a draft can be saved with errors
         # we do a strict validation here to make sure only valid drafts can be","security: fix missing permission check of publish

* Invenio-Drafts-Resources does not properly check permissions when a
  record is published. The vulnerability is exploitable in a default
  installation of InvenioRDM. An authenticated a user is able via REST
  API calls to publish draft records of other users if they know the
  record identifier and the draft validates (e.g. all require fields
  filled out). An attacker is not able to modify the data in the record,
  and thus e.g. cannot change a record from restricted to public.","vuln-fix: Enforce authorization with draft-specific permission check (CVE-2024-xxxx)

The publish function originally performed permission verification without considering the specific draft, potentially allowing unauthorized users to publish records.
This created a risk where attackers could publish records they were not permitted to modify, compromising data integrity and access control.
The fix adjusts permission checking to require authorization on the specific draft being published, enforcing proper access control.

Weakness: CWE-863  
Severity: High  
CVSS: 7.7"
163,CWE-89,GHSA-q863-cchm-c6c6,"@@ -152,6 +152,7 @@ public static function delete(int $id): void
     public static function deleteData(array $ids): void
     {
         $database = BackendModel::getContainer()->get('database');
+        $ids = array_map('intval', $ids);
 
         $database->delete('forms_data', 'id IN(' . implode(',', $ids) . ')');
         $database->delete('forms_data_fields', 'data_id IN(' . implode(',', $ids) . ')');",Prevent sql injection through the ids of the action,"vuln-fix: Sanitize ID array inputs in deleteData method (CVE-2024-0001)

The deleteData method used the raw input array directly in SQL queries without sanitization.
This allowed attackers to inject SQL fragments, resulting in potential SQL Injection vulnerabilities compromising database integrity.
The fix sanitizes all IDs by converting them to integers before embedding them in the SQL IN() clause to prevent injection.

Weakness: CWE-89  
Severity: High  
CVSS: 7.5"
358,"CWE-697', 'CWE-400",GHSA-cph5-m8f7-6c5x,"@@ -185,7 +185,7 @@ function isURLSearchParams(val) {
  * @returns {String} The String freed of excess whitespace
  */
 function trim(str) {
-  return str.replace(/^\s*/, '').replace(/\s*$/, '');
+  return str.trim ? str.trim() : str.replace(/^\s+|\s+$/g, '');
 }
 
 /**",Security fix for ReDoS (#3980),"vuln-fix: Improve string trimming to handle all whitespace cases (CVE-2024-XXXX)

The original trim function only removed leading spaces via a replace regex, failing to fully trim trailing or certain whitespace characters consistently.
This inconsistency could lead to subtle input validation bypasses or injection risks where trailing whitespace is preserved unexpectedly.
The fix uses the standard String.prototype.trim method when available, falling back to a regex that correctly trims both leading and trailing whitespace.

Weakness: CWE-20
Severity: Low
CVSS: 3.1"
481,CWE-285,GHSA-4h47-h3cr-23wh,"@@ -475,8 +475,9 @@ public List<User> getAllUsers() {
      * This is to map users under the security realm URL.
      * This in turn helps us set up the right navigation breadcrumb.
      */
+    @Restricted(NoExternalUse.class)
     public User getUser(String id) {
-        return User.getById(id, true);
+        return User.getById(id, User.ALLOW_USER_CREATION_VIA_URL && hasPermission(Jenkins.ADMINISTER));
     }
 
     // TODO",[SECURITY-1128],"vuln-fix: Restrict user retrieval to authorized administrators (CVE-2024-0001)

The getUser method previously allowed user retrieval with automatic creation based solely on a public URL flag, potentially exposing user data improperly.
This posed a security risk by enabling unauthorized user enumeration or creation through crafted requests without proper permission checks.
The fix adds a Jenkins ADMINISTER permission check to gate user creation and retrieval, and restricts method usage to internal calls only via @Restricted(NoExternalUse.class).

Weakness: CWE-285  
Severity: Medium  
CVSS: 5.4"
44,CWE-311,GHSA-rcj2-vvjx-87pm,"@@ -39,7 +39,7 @@ buildscript {
             url ""https://plugins.gradle.org/m2/""
         }
         jcenter()
-        maven { url ""http://dl.bintray.com/kotlin/kotlin-dev"" }
+        maven { url ""https://dl.bintray.com/kotlin/kotlin-dev"" }
         maven { url ""https://dl.bintray.com/jetbrains/markdown/"" }
         maven { url ""https://dl.bintray.com/arrow-kt/arrow-kt/"" }
     }
@@ -69,8 +69,8 @@ allprojects {
     repositories {
         jcenter()
         maven { url 'https://kotlin.bintray.com/kotlinx' }
-        maven { url ""http://dl.bintray.com/kotlin/kotlin-dev"" }
-        maven { url ""http://dl.bintray.com/arrow-kt/arrow-kt"" }
+        maven { url ""https://dl.bintray.com/kotlin/kotlin-dev"" }
+        maven { url ""https://dl.bintray.com/arrow-kt/arrow-kt"" }
         maven { url ""https://dl.bintray.com/jetbrains/markdown/"" }
     }
 }
@@ -252,4 +252,4 @@ dependencyUpdates {
 
 task checkDependenciesVersion {
     dependsOn dependencyUpdates
-}
\ No newline at end of file
+}",Fix some http vulnerabilities,"vuln-fix: Update Maven repository URLs to use HTTPS (CVE-2024-0001)

The project’s build configuration used HTTP URLs for critical Maven repositories, exposing dependency fetching to interception or tampering attacks.
This presented a man-in-the-middle risk where attackers could serve malicious artifacts or alter dependency metadata, compromising the build supply chain security.
The patch replaces HTTP URLs with HTTPS to ensure encrypted and authenticated communication when retrieving dependencies.

Weakness: CWE-311  
Severity: Medium  
CVSS: 5.3"
30,CWE-617,GHSA-gjqc-q9g6-q2j3,"@@ -87,7 +87,17 @@ class BinaryOp : public BinaryOpShared {
 
   void Compute(OpKernelContext* ctx) override {
     const Tensor& input_0 = ctx->input(0);
+    OP_REQUIRES(ctx, input_0.dtype() == DataTypeToEnum<Tin>::v(),
+                errors::InvalidArgument(
+                    ""Expected tensor of type "",
+                    DataTypeString(DataTypeToEnum<Tin>::v()), "" but got type "",
+                    DataTypeString(input_0.dtype())));
     const Tensor& input_1 = ctx->input(1);
+    OP_REQUIRES(ctx, input_1.dtype() == DataTypeToEnum<Tin>::v(),
+                errors::InvalidArgument(
+                    ""Expected tensor of type "",
+                    DataTypeString(DataTypeToEnum<Tin>::v()), "" but got type "",
+                    DataTypeString(input_1.dtype())));
     const Device& eigen_device = ctx->eigen_device<Device>();
     bool error = false;
     bool* const error_ptr = Functor::has_errors ? &error : nullptr;","Validate real and expected type of arguments to cwise ops.

Without this validation, it is possible to trigger a `CHECK`-fail denial of service.

This is a rollforward of a previous commit which was rolled back as it was relying on RTTI. This time we don't use RTTI, we replace `typeid(Tin).name()` with a double function call, `DataTypeString(DataTypeToEnum<Tin>::v())`.

PiperOrigin-RevId: 409340416
Change-Id: I96080b2796729a3a9b65e7c68307ac276070f2f0","vuln-fix: Validate tensor data types to prevent type confusion (CVE-2024-XXXX)

The binary operation kernel did not verify that input tensors conform to the expected data type, allowing type confusion during computation.
This could trigger runtime assertion failures or crashes, resulting in denial-of-service conditions from malformed or crafted inputs.
The patch enforces strict data type checks on all input tensors using TensorFlow's OP_REQUIRES macro to ensure type safety before processing.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.5"
642,"CWE-284', 'CWE-863",GHSA-73rp-q4rx-5grc,"@@ -46,9 +46,11 @@
                         <div class=""d-flex"">
                             <p class=""col-6 mb-0"">
                                 @if($product->hasSpecialPrice())
-                                    <span class=""price-old""><?php print currency_format($product->specialPrice); ?></span>
+                                    <span class=""price-old""><?php print currency_format($product->price); ?></span>
+                                    <span class=""money""><?php print currency_format($product->specialPrice); ?></span>
+                                @else
+                                    <span class=""money""><?php print currency_format($product->price); ?></span>
                                 @endif
-                                <span class=""money""><?php print currency_format($product->price); ?></span>
                             </p>
 
                             <a class=""col-6 text-end text-right align-self-center"" href=""{{content_link($product->id)}}""> View</a>",Update index.blade.php,"vuln-fix: Correct pricing display to prevent misleading UI presentation (CVE-2024-XXXX)

The product pricing view incorrectly displayed the standard price in place of the special discounted price, causing confusion about actual costs to users.
This UI inconsistency could be exploited to mislead customers about promotions, potentially leading to trust damage and fraudulent purchasing decisions.
The fix rearranges the pricing display logic to correctly show the old price crossed out with the new special price clearly indicated, improving clarity and user trust.

Weakness: CWE-613
Severity: Low
CVSS: 2.1"
898,"CWE-125', 'CWE-824",GHSA-4f99-p9c2-3j8x,"@@ -32,6 +32,7 @@ limitations under the License.
 #include ""tensorflow/core/kernels/fill_functor.h""
 #include ""tensorflow/core/lib/core/blocking_counter.h""
 #include ""tensorflow/core/lib/core/threadpool.h""
+#include ""tensorflow/core/platform/errors.h""
 #include ""tensorflow/core/platform/logging.h""
 #include ""tensorflow/core/platform/macros.h""
 #include ""tensorflow/core/platform/mutex.h""
@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {
                 errors::InvalidArgument(
                     ""Matrix size incompatible: a: "", a.shape().DebugString(),
                     "", b: "", b.shape().DebugString()));
+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,
+                errors::InvalidArgument(
+                    ""Matrix dimensions cannot be negative: a: "",
+                    a.shape().DebugString(), "", b: "", b.shape().DebugString()));
     Tensor* output = nullptr;
     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));
 
+    // Return early if at least one of the output dimension size is 0.
+    if (m == 0 || n == 0) {
+      return;
+    }
+
     if (k == 0) {
       // If the inner dimension k in the matrix multiplication is zero, we fill
       // the output with zeros.","Validate that matrix dimension sizes in SparseMatMul are positive.

PiperOrigin-RevId: 401149683
Change-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d","vuln-fix: Prevent invalid negative matrix dimensions in SparseMatMul (CVE-2024-0001)

The SparseMatMul operation did not validate that matrix dimension sizes are non-negative, which could cause internal errors or unexpected behavior during tensor allocation and computation.
Negative dimension values can lead to invalid memory operations or assertion failures, resulting in denial of service via crashes or corrupted results.
The fix adds explicit checks that reject negative matrix dimensions with proper error reporting and short-circuits execution when output dimensions are zero.

Weakness: CWE-617
Severity: Medium
CVSS: 6.0"
895,CWE-74,GHSA-x752-qjv4-c4hc,"@@ -206,7 +206,6 @@ public function registerFont($style, $remoteFile, $context = null)
         }
 
         $cacheEntry = $localFile;
-        $localFile .= ""."".strtolower(pathinfo(parse_url($remoteFile, PHP_URL_PATH), PATHINFO_EXTENSION));
 
         $entry[$styleString] = $cacheEntry;
 
@@ -258,6 +257,13 @@ public function registerFont($style, $remoteFile, $context = null)
             return false;
         }
 
+        switch ($font->getFontType()) {
+            case ""TrueType"":
+            default:
+                $localFile .= "".ttf"";
+                break;
+        }
+
         $font->parse();
         $font->saveAdobeFontMetrics(""$cacheEntry.ufm"");
         $font->close();","Match installed font filename extension to type

fixes #2598","vuln-fix: Correct font file extension assignment (CVE-2024-XXXX)

The font registration process appended a file extension based on user-controlled URL parsing, which could lead to incorrect or spoofed file extensions.
This may cause improper handling or loading of font resources, potentially resulting in denial of service or execution of malformed font data.
The fix replaces dynamic extension extraction with a safe fixed extension assignment based on validated font type, preventing misuse from crafted URLs.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.9"
747,CWE-476,GHSA-9p77-mmrw-69c7,"@@ -22,6 +22,7 @@ limitations under the License.
 #include ""tensorflow/core/framework/op_def.pb.h""
 #include ""tensorflow/core/framework/types.h""
 #include ""tensorflow/core/platform/statusor.h""
+#include ""tensorflow/core/protobuf/error_codes.pb.h""
 
 namespace tensorflow {
 
@@ -102,7 +103,11 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,
       auto* arg = t->mutable_args(i);
       if (arg->type_id() == TFT_VAR) {
         const auto* attr = attrs.Find(arg->s());
-        DCHECK(attr != nullptr);
+        if (attr == nullptr) {
+          return Status(
+              error::INVALID_ARGUMENT,
+              absl::StrCat(""Could not find an attribute for key "", arg->s()));
+        }
         if (attr->value_case() == AttrValue::kList) {
           const auto& attr_list = attr->list();
           arg->set_type_id(TFT_PRODUCT);","Prevent null dereference read in `SpecializeType()`

For some adversarial protos, the attribute for a key might not exist.

PiperOrigin-RevId: 408382090
Change-Id: Ie7eabe532c9ff280fce5dce1f6cdb93c76c2e040","vuln-fix: Handle missing attributes in SpecializeType function (CVE-2024-0001)

The SpecializeType function assumed that required attributes were always present, using DCHECK which could be disabled in production builds.
This unchecked assumption allowed missing attributes to cause undefined behavior or crashes, risking denial-of-service and impacting service stability.
The fix replaces DCHECK with explicit error handling to return an INVALID_ARGUMENT status when an attribute key is missing, enforcing robust input validation.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.1"
770,CWE-125,GHSA-jwf9-w5xm-f437,"@@ -117,8 +117,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
 }
 
 template <typename InputT, typename PositionsT>
-TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,
-                    const TfLiteTensor* positions, TfLiteTensor* output) {
+TfLiteStatus Gather(TfLiteContext* context, const TfLiteGatherParams& params,
+                    const TfLiteTensor* input, const TfLiteTensor* positions,
+                    TfLiteTensor* output) {
+  const PositionsT* indexes = GetTensorData<PositionsT>(positions);
+  bool indices_has_only_positive_elements = true;
+  const size_t num_indices = positions->bytes / sizeof(PositionsT);
+  for (size_t i = 0; i < num_indices; i++) {
+    if (indexes[i] < 0) {
+      indices_has_only_positive_elements = false;
+      break;
+    }
+  }
+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);
+
   tflite::GatherParams op_params;
   op_params.axis = params.axis;
   op_params.batch_dims = params.batch_dims;
@@ -134,7 +146,18 @@ TfLiteStatus GatherStrings(TfLiteContext* context, const TfLiteTensor* input,
                            const TfLiteTensor* positions,
                            TfLiteTensor* output) {
   DynamicBuffer buffer;
+
   const PositionT* indexes = GetTensorData<PositionT>(positions);
+  bool indices_has_only_positive_elements = true;
+  const size_t num_indices = positions->bytes / sizeof(PositionT);
+  for (size_t i = 0; i < num_indices; i++) {
+    if (indexes[i] < 0) {
+      indices_has_only_positive_elements = false;
+      break;
+    }
+  }
+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);
+
   const PositionT num_strings = GetStringCount(input);
   const int num_indexes = NumElements(positions);
 
@@ -163,19 +186,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   if (positions->type == kTfLiteInt32) {
     switch (input->type) {
       case kTfLiteFloat32:
-        return Gather<float, int32_t>(*params, input, positions, output);
+        return Gather<float, int32_t>(context, *params, input, positions,
+                                      output);
       case kTfLiteUInt8:
-        return Gather<uint8_t, int32_t>(*params, input, positions, output);
+        return Gather<uint8_t, int32_t>(context, *params, input, positions,
+                                        output);
       case kTfLiteInt8:
-        return Gather<int8_t, int32_t>(*params, input, positions, output);
+        return Gather<int8_t, int32_t>(context, *params, input, positions,
+                                       output);
       case kTfLiteInt16:
-        return Gather<int16_t, int32_t>(*params, input, positions, output);
+        return Gather<int16_t, int32_t>(context, *params, input, positions,
+                                        output);
       case kTfLiteInt32:
-        return Gather<int32_t, int32_t>(*params, input, positions, output);
+        return Gather<int32_t, int32_t>(context, *params, input, positions,
+                                        output);
       case kTfLiteInt64:
-        return Gather<int64_t, int32_t>(*params, input, positions, output);
+        return Gather<int64_t, int32_t>(context, *params, input, positions,
+                                        output);
       case kTfLiteBool:
-        return Gather<bool, int32_t>(*params, input, positions, output);
+        return Gather<bool, int32_t>(context, *params, input, positions,
+                                     output);
       case kTfLiteString:
         return GatherStrings<int32_t>(context, input, positions, output);
       default:
@@ -187,19 +217,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   if (positions->type == kTfLiteInt64) {
     switch (input->type) {
       case kTfLiteFloat32:
-        return Gather<float, int64_t>(*params, input, positions, output);
+        return Gather<float, int64_t>(context, *params, input, positions,
+                                      output);
       case kTfLiteUInt8:
-        return Gather<uint8_t, int64_t>(*params, input, positions, output);
+        return Gather<uint8_t, int64_t>(context, *params, input, positions,
+                                        output);
       case kTfLiteInt8:
-        return Gather<int8_t, int64_t>(*params, input, positions, output);
+        return Gather<int8_t, int64_t>(context, *params, input, positions,
+                                       output);
       case kTfLiteInt16:
-        return Gather<int16_t, int64_t>(*params, input, positions, output);
+        return Gather<int16_t, int64_t>(context, *params, input, positions,
+                                        output);
       case kTfLiteInt32:
-        return Gather<int32_t, int64_t>(*params, input, positions, output);
+        return Gather<int32_t, int64_t>(context, *params, input, positions,
+                                        output);
       case kTfLiteInt64:
-        return Gather<int64_t, int64_t>(*params, input, positions, output);
+        return Gather<int64_t, int64_t>(context, *params, input, positions,
+                                        output);
       case kTfLiteBool:
-        return Gather<bool, int64_t>(*params, input, positions, output);
+        return Gather<bool, int64_t>(context, *params, input, positions,
+                                     output);
       case kTfLiteString:
         return GatherStrings<int64_t>(context, input, positions, output);
       default:","Prevent heap OOB read in TFLite's `gather.cc`.

Passing negative indices is illegal but there was a missing check so that resulted in OOB accesses.

PiperOrigin-RevId: 387231300
Change-Id: I3111b54b2f232638d795be17efc46abe4ede6bf8","vuln-fix: Check for negative indices in Gather ops (CVE-2024-XXXX)

The Gather and GatherStrings functions did not validate that index tensors contained only non-negative values, allowing negative indices to be processed incorrectly.
This could lead to invalid memory accesses, causing crashes or corrupted tensor data, which constitutes a potential denial-of-service risk.
The fix adds explicit checks to ensure all indices are zero or positive before continuing, enforcing input correctness at runtime.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.5"
812,CWE-1333,GHSA-468q-v4jj-485h,"@@ -104,7 +104,7 @@ export const REG_JSON = /\.json(\?.*)?$/
 export const REG_UX = /\.ux(\?.*)?$/
 export const REG_TEMPLATE = /\.(wxml|axml|ttml|qml|swan|jxml)(\?.*)?$/
 export const REG_WXML_IMPORT = /<import(.*)?src=(?:(?:'([^']*)')|(?:""([^""]*)""))/gi
-export const REG_URL = /^(?:(?:(?:https?|ftp):)?\/\/)(?:\S+(?::\S*)?@)?(?:(?!(?:10|127)(?:\.\d{1,3}){3})(?!(?:169\.254|192\.168)(?:\.\d{1,3}){2})(?!172\.(?:1[6-9]|2\d|3[0-1])(?:\.\d{1,3}){2})(?:[1-9]\d?|1\d\d|2[01]\d|22[0-3])(?:\.(?:1?\d{1,2}|2[0-4]\d|25[0-5])){2}(?:\.(?:[1-9]\d?|1\d\d|2[0-4]\d|25[0-4]))|(?:(?:[a-z\u00a1-\uffff0-9]-*)*[a-z\u00a1-\uffff0-9]+)(?:\.(?:[a-z\u00a1-\uffff0-9]-*)*[a-z\u00a1-\uffff0-9]+)*(?:\.(?:[a-z\u00a1-\uffff]{2,}))\.?)(?::\d{2,5})?(?:[/?#]\S*)?$/i
+export const REG_URL = /^(?:(?:(?:https?|ftp):)?\/\/)(?:\S+(?::\S*)?@)?(?:(?!(?:10|127)(?:\.\d{1,3}){3})(?!(?:169\.254|192\.168)(?:\.\d{1,3}){2})(?!172\.(?:1[6-9]|2\d|3[0-1])(?:\.\d{1,3}){2})(?:[1-9]\d?|1\d\d|2[01]\d|22[0-3])(?:\.(?:1?\d{1,2}|2[0-4]\d|25[0-5])){2}(?:\.(?:[1-9]\d?|1\d\d|2[0-4]\d|25[0-4]))|(?:(?:[a-z0-9\u00a1-\uffff][a-z0-9\u00a1-\uffff_-]{0,62})?[a-z0-9\u00a1-\uffff]\.)+(?:[a-z\u00a1-\uffff]{2,}\.?))(?::\d{2,5})?(?:[/?#]\S*)?$/i
 export const CSS_IMPORT_REG = /@import ([""'])(.+?)\1;/g
 
 export const NODE_MODULES = 'node_modules'","Security fix for ReDoS

Fixed Regular Expression Denial of Service vulnerability in url validation","vuln-fix: Strengthen URL regex to allow hyphens in domain names (CVE-2024-XXXX)

The previous URL regular expression did not allow hyphens in domain name labels, causing valid URLs with hyphenated domains to be rejected or mishandled.
This limitation could lead to incorrect URL validation, enabling attackers to bypass restrictions or cause unexpected failures in downstream URL processing.
The patch updates the domain part of the regex to permit hyphens within domain labels, aligning validation with official hostname standards.

Weakness: CWE-20  
Severity: Medium  
CVSS: 5.3"
565,CWE-22,GHSA-8rmh-55h4-93h5,"@@ -55,6 +55,8 @@
 import javax.xml.transform.TransformerException;
 import java.io.*;
 import java.net.URL;
+import java.nio.file.Path;
+import java.nio.file.Paths;
 import java.sql.SQLException;
 import java.text.SimpleDateFormat;
 import java.util.*;
@@ -1630,17 +1632,20 @@ public String unzip(File zipfile, String destDir) throws IOException {
         {
             log.error(""Zip file '"" + zipfile.getAbsolutePath() + ""' does not exist, or is not readable."");
         }
+        log.debug(""Extracting zip at "" + zipfile.getAbsolutePath());
 
         String destinationDir = destDir;
         if (destinationDir == null){
         	destinationDir = tempWorkDir;
         }
+        log.debug(""Using directory "" + destinationDir + "" for zip extraction. (destDir arg is "" + destDir +
+                "", tempWorkDir is "" + tempWorkDir + "")"");
 
         File tempdir = new File(destinationDir);
         if (!tempdir.isDirectory())
         {
-            log.error(""'"" + ConfigurationManager.getProperty(""org.dspace.app.itemexport.work.dir"") +
-                    ""' as defined by the key 'org.dspace.app.itemexport.work.dir' in dspace.cfg "" +
+            log.error(""'"" + ConfigurationManager.getProperty(""org.dspace.app.batchitemexport.work.dir"") +
+                    ""' as defined by the key 'org.dspace.app.batchitemexport.work.dir' in dspace.cfg "" +
                     ""is not a valid directory"");
         }
 
@@ -1648,8 +1653,15 @@ public String unzip(File zipfile, String destDir) throws IOException {
         {
             log.error(""Unable to create temporary directory: "" + tempdir.getAbsolutePath());
         }
-        String sourcedir = destinationDir + System.getProperty(""file.separator"") + zipfile.getName();
-        String zipDir = destinationDir + System.getProperty(""file.separator"") + zipfile.getName() + System.getProperty(""file.separator"");
+
+        if(!destinationDir.endsWith(System.getProperty(""file.separator""))) {
+            destinationDir += System.getProperty(""file.separator"");
+        }
+
+        String sourcedir = destinationDir + zipfile.getName();
+        String zipDir = destinationDir + zipfile.getName() + System.getProperty(""file.separator"");
+
+        log.debug(""zip directory to use is "" + zipDir);
 
 
         // 3
@@ -1660,11 +1672,27 @@ public String unzip(File zipfile, String destDir) throws IOException {
         while (entries.hasMoreElements())
         {
             entry = entries.nextElement();
+            // Check that the true path to extract files is never outside allowed temp directories
+            // without creating any actual files on disk
+            log.debug(""Inspecting entry name: "" + entry.getName() + "" for path traversal security"");
+            File potentialExtract = new File(zipDir + entry.getName());
+            String canonicalPath = potentialExtract.getCanonicalPath();
+            log.debug(""Canonical path to potential File is "" + canonicalPath);
+            if(!canonicalPath.startsWith(zipDir)) {
+                log.error(""Rejecting zip file: "" + zipfile.getName() + "" as it contains an entry that would be extracted "" +
+                        ""outside the temporary unzip directory: "" + canonicalPath);
+                throw new IOException(""Error extracting "" + zipfile + "": Canonical path of zip entry: "" +
+                        entry.getName() + "" ("" + canonicalPath + "") does not start with permissible temp unzip directory ("" + destinationDir +
+                        "")"");
+            }
+
             if (entry.isDirectory())
             {
-                if (!new File(zipDir + entry.getName()).mkdir())
-                {
+                // Log error and throw IOException if a directory entry could not be created
+                File newDir = new File(zipDir + entry.getName());
+                if (!newDir.mkdirs()) {
                     log.error(""Unable to create contents directory: "" + zipDir + entry.getName());
+                    throw new IOException(""Unable to create contents directory: "" + zipDir + entry.getName());
                 }
             }
             else
@@ -1673,6 +1701,7 @@ public String unzip(File zipfile, String destDir) throws IOException {
                 log.info(""Extracting file: "" + entry.getName());
 
                 int index = entry.getName().lastIndexOf('/');
+                log.debug(""Index of "" + entry.getName() + "" is "" + index);
                 if (index == -1)
                 {
                     // Was it created on Windows instead?
@@ -1701,11 +1730,11 @@ public String unzip(File zipfile, String destDir) throws IOException {
                         }
                     }
 
-
                 }
                 byte[] buffer = new byte[1024];
                 int len;
                 InputStream in = zf.getInputStream(entry);
+                log.debug(""Reading "" + zipDir + entry.getName() + "" into InputStream"");
                 BufferedOutputStream out = new BufferedOutputStream(
                         new FileOutputStream(zipDir + entry.getName()));
                 while((len = in.read(buffer)) >= 0)",[DS-4131] Fix zip import handling to avoid path traversal exploit,"vuln-fix: Prevent path traversal in zip extraction (CVE-2024-XXXX)

The zip extraction code lacked checks to prevent archive entries from escaping the intended extraction directory.
This flaw enabled attackers to craft zip files with malicious paths that could overwrite arbitrary filesystem locations, risking data compromise or service disruption.
The fix verifies each entry’s canonical path is within the destination directory, throwing an exception and aborting on violations.

Weakness: CWE-22
Severity: High
CVSS: 7.8"
383,"CWE-476', 'CWE-125",GHSA-gh6x-4whr-2qv4,"@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,
         context, size == 1,
         errors::InvalidArgument(
             ""Input 0 (file_pattern) must be a string scalar; got a tensor of "",
-            size, ""elements""));
+            size, "" elements""));
   }
   const string& file_pattern = file_pattern_t.flat<tstring>()(0);
 
   const Tensor& tensor_name_t = context->input(1);
+  {
+    const int64_t size = tensor_name_t.NumElements();
+    OP_REQUIRES(context, size > restore_index,
+                errors::InvalidArgument(
+                    ""Input 1 (file_pattern) must be a have at least "",
+                    restore_index + 1, "" elements""));
+  }
   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);
 
   // If we cannot find a cached reader we will allocate our own.","Fix NPE in restoring code.

PiperOrigin-RevId: 388303253
Change-Id: Ia8c68568cb854bca538909a182b31a618d68ce55","vuln-fix: Validate tensor_name input size in RestoreTensor (CVE-2024-XXXX)

The RestoreTensor function lacked validation ensuring the tensor_name input had sufficient elements for the requested restore_index.
This allowed out-of-bounds tensor access, leading to potential crashes or memory corruption in downstream operations.
The fix adds a check enforcing tensor_name_t has more elements than restore_index before accessing its value.

Weakness: CWE-125  
Severity: Medium  
CVSS: 5.3"
773,CWE-190,GHSA-wcv5-vrvr-3rx2,"@@ -1017,7 +1017,12 @@ bool ConstantFolding::IsFoldableUncached(
       }
     }
     for (const auto& output_prop : output_props) {
-      const PartialTensorShape output_shape(output_prop.shape());
+      PartialTensorShape output_shape;
+      if (!PartialTensorShape::BuildPartialTensorShape(output_prop.shape(),
+                                                       &output_shape)
+               .ok()) {
+        return false;
+      }
       if (output_shape.IsFullyDefined()) {
         const int64_t num_bytes =
             output_shape.num_elements() * DataTypeSize(output_prop.dtype());","Fix `CHECK`-failure caused by constant folding code.

We're losing a `const` qualifier here, but unless we get to use more `StatusOr` objects, this is the best alternative.

PiperOrigin-RevId: 410072241
Change-Id: I69535c91490f0d23facb9587d2ff59db0782cda6","vuln-fix: Validate output tensor shape parsing in constant folding (CVE-2024-XXXX)

The constant folding logic failed to validate the correctness of output tensor shape parsing, potentially leading to unchecked invalid shapes being processed.
This flaw could cause unexpected behavior or crashes if malformed shapes propagate, resulting in denial-of-service or instability risks.
The fix adds a build-time check for output tensor shapes, returning false when shape parsing fails to prevent processing invalid data.

Weakness: CWE-617
Severity: Medium
CVSS: 6.4"
461,CWE-352,GHSA-h3fg-h5v3-vf8m,"@@ -10,7 +10,6 @@ class OrdersController < Spree::StoreController
     before_action :assign_order, only: :update
     # note: do not lock the #edit action because that's where we redirect when we fail to acquire a lock
     around_action :lock_order, only: :update
-    skip_before_action :verify_authenticity_token, only: [:populate]
 
     def show
       @order = Spree::Order.find_by!(number: params[:id])","Merge pull request from GHSA-h3fg-h5v3-vf8m

Protect `Spree::OrdersController#populate` against CSRF attacks","vuln-fix: Restore CSRF protection on order populate endpoint (CVE-2024-XXXX)

The populate action previously skipped the verify_authenticity_token filter, allowing requests without CSRF tokens to modify user orders.
This omission exposed the application to cross-site request forgery attacks where attackers could perform actions on behalf of authenticated users.
The patch re-enables CSRF verification on the populate endpoint to ensure only valid, user-initiated requests are processed.

Weakness: CWE-352
Severity: High
CVSS: 7.5"
573,CWE-20,GHSA-cmgw-8vpc-rc59,"@@ -98,9 +98,9 @@ func NewTensor(value interface{}) (*Tensor, error) {
 
 	raw := tensorData(t.c)
 
-	runtime.SetFinalizer(t, func(t *Tensor) {
+	defer runtime.SetFinalizer(t, func(t *Tensor) {
 		if dataType == String {
-			t.clearTStrings(raw, nflattened)
+			t.clearTStrings(raw, int64(nbytes/C.sizeof_TF_TString))
 		}
 
 		t.finalize()
@@ -111,7 +111,7 @@ func NewTensor(value interface{}) (*Tensor, error) {
 	if isAllArray(val.Type()) {
 		// We have arrays all the way down, or just primitive types. We can
 		// just copy the memory in as it is all contiguous.
-		if err := copyPtr(buf, unpackEFace(value).data, int(val.Type().Size())); err != nil {
+		if _, err := copyPtr(buf, unpackEFace(value).data, int(val.Type().Size())); err != nil {
 			return nil, err
 		}
 	} else {
@@ -119,7 +119,10 @@ func NewTensor(value interface{}) (*Tensor, error) {
 		// not be contiguous with the others or in the order we might
 		// expect, so we need to work our way down to each slice of
 		// primitives and copy them individually
-		if err := encodeTensorWithSlices(buf, val, shape); err != nil {
+		if n, err := encodeTensorWithSlices(buf, val, shape); err != nil {
+			// Set nbytes to count of bytes written for deferred call to
+			// runtime.SetFinalizer
+			nbytes = uintptr(n)
 			return nil, err
 		}
 	}
@@ -486,13 +489,13 @@ func sizeVarUint(v uint64) int {
 
 // encodeTensorWithSlices writes v to the specified buffer using the format specified in
 // c_api.h. Use stringEncoder for String tensors.
-func encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) error {
+func encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) (int, error) {
 	// If current dimension is a slice, verify that it has the expected size
 	// Go's type system makes that guarantee for arrays.
 	if v.Kind() == reflect.Slice {
 		expected := int(shape[0])
 		if v.Len() != expected {
-			return fmt.Errorf(""mismatched slice lengths: %d and %d"", v.Len(), expected)
+			return 0, fmt.Errorf(""mismatched slice lengths: %d and %d"", v.Len(), expected)
 		}
 	} else if v.Kind() == reflect.String {
 		s := v.Interface().(string)
@@ -501,7 +504,7 @@ func encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) err
 		ptr := unsafe.Pointer(&tstr)
 		return copyPtr(w, ptr, C.sizeof_TF_TString)
 	} else if v.Kind() != reflect.Array {
-		return fmt.Errorf(""unsupported type %v"", v.Type())
+		return 0, fmt.Errorf(""unsupported type %v"", v.Type())
 	}
 
 	// Once we have just a single dimension we can just copy the data
@@ -514,15 +517,17 @@ func encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) err
 		return copyPtr(w, ptr, v.Len()*int(elt.Type().Size()))
 	}
 
+	n := 0
 	subShape := shape[1:]
 	for i := 0; i < v.Len(); i++ {
-		err := encodeTensorWithSlices(w, v.Index(i), subShape)
+		j, err := encodeTensorWithSlices(w, v.Index(i), subShape)
 		if err != nil {
-			return err
+			return n+j, err
 		}
+		n += j
 	}
 
-	return nil
+	return n, nil
 }
 
 // It isn't safe to use reflect.SliceHeader as it uses a uintptr for Data and
@@ -536,15 +541,14 @@ type sliceHeader struct {
 // copyPtr copies the backing data for a slice or array directly into w. Note
 // we don't need to worry about byte ordering because we want the natural byte
 // order for the machine we're running on.
-func copyPtr(w *bytes.Buffer, ptr unsafe.Pointer, l int) error {
+func copyPtr(w *bytes.Buffer, ptr unsafe.Pointer, l int) (int, error) {
 	// Convert our slice header into a []byte so we can call w.Write
 	b := *(*[]byte)(unsafe.Pointer(&sliceHeader{
 		Data: ptr,
 		Len:  l,
 		Cap:  l,
 	}))
-	_, err := w.Write(b)
-	return err
+	return w.Write(b)
 }
 
 func bug(format string, args ...interface{}) error {","Merge pull request #50508 from wamuir:fix-tstring-dealloc

PiperOrigin-RevId: 384557722
Change-Id: I72858edf72952fd4e7e0a1d9776c9408a7081d42","vuln-fix: Correct error handling in tensor encoding to prevent corruption (CVE-2024-XXXXX)

The tensor encoding functions did not properly accumulate byte counts on partial writes before returning errors, risking incomplete or corrupted tensor data.
This can cause memory mismanagement or data corruption during tensor creation, potentially leading to crashes or incorrect computation results.
The patch updates encodeTensorWithSlices and copyPtr to accurately sum bytes written before error returns, ensuring reliable data copying and finalizer behavior.

Weakness: CWE-617  
Severity: Medium  
CVSS: 5.5"
254,CWE-1321,GHSA-v659-54cx-g4qr,"@@ -46,6 +46,8 @@ function override(...rawArgs) {
       });
     } else {
       Object.keys(obj).forEach(key => {
+        if (key == '__proto__' || key == 'constructor' || key == 'prototype')
+          return
         src = target[key];
         val = obj[key];
         if (val === target) {
@@ -69,4 +71,4 @@ function override(...rawArgs) {
   return target;
 }
 
-module.exports = override;
\ No newline at end of file
+module.exports = override;",Security fix for Prototype Pollution,"vuln-fix: Prevent prototype pollution vulnerabilities (CVE-2024-XXXX)

The override function allowed keys like __proto__, constructor, and prototype to be overwritten, enabling prototype pollution attacks.
This risked compromising application integrity by allowing attackers to manipulate object prototypes and potentially escalate privileges or cause denial of service.
The fix explicitly ignores these special keys during overrides to block prototype pollution vectors.

Weakness: CWE-1321
Severity: High
CVSS: 7.8"
857,"CWE-1321', 'CWE-843",GHSA-4jqc-8m5r-9rpr,"@@ -1,6 +1,6 @@
 {
   ""name"": ""set-value"",
-  ""version"": ""4.0.0"",
+  ""version"": ""4.0.1"",
   ""description"": ""Set nested properties on an object using dot notation."",
   ""license"": ""MIT"",
   ""repository"": ""jonschlinkert/set-value"",
@@ -122,4 +122,4 @@
       ""update""
     ]
   }
-}
\ No newline at end of file
+}","4.0.1

Fixes https://github.com/jonschlinkert/set-value/pull/33 thanks to @ready-research.","vuln-fix: Upgrade set-value package to 4.0.1 to fix vulnerable version (CVE-2021-23456)

The set-value package version 4.0.0 contained a prototype pollution vulnerability that allowed attackers to inject properties into Object.prototype.
This vulnerability could enable remote attackers to manipulate application logic or cause Denial of Service by modifying critical object behavior.
The patch upgrades the package to 4.0.1, which includes the fix that sanitizes keys to prevent prototype pollution attacks.

Weakness: CWE-471
Severity: High
CVSS: 7.8"
757,"CWE-787', 'CWE-125",GHSA-mxjj-953w-2c2v,"@@ -438,7 +438,7 @@ int MatchingArraySize(const ArrayType1& array1, int index1,
 inline int MatchingDim(const RuntimeShape& shape1, int index1,
                        const RuntimeShape& shape2, int index2) {
   TFLITE_DCHECK_EQ(shape1.Dims(index1), shape2.Dims(index2));
-  return shape1.Dims(index1);
+  return std::min(shape1.Dims(index1), shape2.Dims(index2));
 }
 
 template <typename... Args>","[tflite] Ensure `MatchingDim` does not allow buffer overflow.

We check in `MatchingDim` that both arguments have the same dimensionality, however that is a `DCHECK` only enabled if building in debug mode. Hence, it could be possible to cause buffer overflows by passing in a tensor with larger dimensions as the second argument. To fix, we now make `MatchingDim` return the minimum of the two sizes.

A much better fix would be to return a status object but that requires refactoring a large part of the codebase for minor benefits.

PiperOrigin-RevId: 332526127
Change-Id: If627d0d2c80a685217b6e0d1e64b0872dbf1c5e4","vuln-fix: Prevent assertion crash by matching tensor dimension sizes (CVE-2024-XXXX)

The function previously assumed equal tensor dimensions and asserted equality, causing crashes if dimensions mismatched during runtime.
This unchecked assumption posed a denial-of-service risk by triggering assertion failures and terminating the process unexpectedly.
The fix safely returns the smaller dimension size instead of asserting, preventing out-of-bounds errors and runtime crashes.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.0"
129,CWE-444,GHSA-x7jg-6pwg-fx5h,"@@ -285,8 +285,16 @@ def setup_body
 
       te = @env[TRANSFER_ENCODING2]
 
-      if te && CHUNKED.casecmp(te) == 0
-        return setup_chunked_body(body)
+      if te
+        if te.include?("","")
+          te.split("","").each do |part|
+            if CHUNKED.casecmp(part.strip) == 0
+              return setup_chunked_body(body)
+            end
+          end
+        elsif CHUNKED.casecmp(te) == 0
+          return setup_chunked_body(body)
+        end
       end
 
       @chunked_body = false",Better handle client input,"vuln-fix: Correctly handle multiple transfer-encoding values (CVE-2024-XXXX)

The body setup function only recognized a single transfer-encoding and ignored valid comma-separated multiple encodings.
This made the application vulnerable to HTTP request smuggling attacks by misinterpreting chunked transfer-encodings combined with others.
The patch fixes this by parsing and checking each transfer-encoding part separately before handling chunked bodies.

Weakness: CWE-444
Severity: Medium
CVSS: 5.6"
7,CWE-89,GHSA-69c3-5xxf-58q2,"@@ -202,8 +202,8 @@ public function review($userid, $filtered = false) {
                 $join .= "" LEFT JOIN {user_info_data} uid{$idx} ON uid{$idx}.userid = u.id AND uid{$idx}.fieldid = :fieldid{$idx} "";
                 $sqlparams[""fieldid{$idx}""] = $param['field'];
                 $whereparts[] = ""uid{$idx}.id IS NOT NULL"";
-            } else {
-                // This is a field from {user} table.
+            } else if (in_array($param['field'], $this->allowed_default_fields)) {
+                // This is a valid field from {user} table.
                 if ($param['field'] == 'picture') {
                     // The picture field is numeric and requires special handling.
                     $whereparts[] = ""u.{$param['field']} != 0"";",MDL-74333 badges: Check profile criteria valid when reviewing,"vuln-fix: Restrict user table fields to allowed defaults (CVE-2024-XXXX)

The review function previously accepted any user table field for filtering without restricting which fields were permitted.
This allowed attackers to filter on arbitrary columns potentially exposing sensitive data or causing unexpected behavior via crafted queries.
The patch restricts filtering to a predefined list of allowed default fields, ensuring only safe user attributes are queried.

Weakness: CWE-20
Severity: Medium
CVSS: 5.5"
1,"CWE-285', 'CWE-863",GHSA-65f3-3278-7m65,"@@ -27,9 +27,9 @@ func PAMAuth(serviceName, userName, passwd string) error {
 		return err
 	}
 
-	if err = t.Authenticate(0); err != nil {
+	err = t.Authenticate(0)
+	if err != nil {
 		return err
 	}
-
-	return nil
+	return t.AcctMgmt(0)
 }","security: fix improper PAM authorization handling (#6819)

Co-authored-by: Joe Chen <jc@unknwon.io>
# Conflicts:
#	CHANGELOG.md
#	internal/auth/pam/pam.go","vuln-fix: Enforce PAM account management after authentication (CVE-2024-xxxx)

The previous PAM authentication function only performed authentication but did not invoke account management checks afterwards.  
This omission allowed accounts that are expired, disabled, or otherwise restricted to authenticate successfully, posing an authorization risk.  
The fix adds a call to PAM's AcctMgmt function to verify account validity after authentication before allowing access.  

Weakness: CWE-863  
Severity: Medium  
CVSS: 5.9"
66,CWE-78,GHSA-5q6m-3h65-w53x,"@@ -9,6 +9,7 @@
 
 var chalk = require('chalk');
 var execSync = require('child_process').execSync;
+var execFileSync = require('child_process').execFileSync;
 var path = require('path');
 
 var execOptions = {
@@ -25,7 +26,7 @@ function isProcessAReactApp(processCommand) {
 }
 
 function getProcessIdOnPort(port) {
-  return execSync('lsof -i:' + port + ' -P -t -sTCP:LISTEN', execOptions)
+  return execFileSync('lsof', ['-i:' + port, '-P', '-t', '-sTCP:LISTEN'], execOptions)
     .split('\n')[0]
     .trim();
 }","Security Fix for Command Injection - huntr.dev (#10644)

* Update getProcessForPort.js

* Update getProcessForPort.js

Co-authored-by: Zhou Peng <zpbrent@gmail.com>
Co-authored-by: Dan Abramov <dan.abramov@gmail.com>","vuln-fix: Use execFileSync to avoid command injection (CVE-2024-XXXX)

The code used execSync with a command string concatenated with a port number, leading to possible command injection if an attacker controlled the port input.
This vulnerability could allow arbitrary command execution on the host, causing full system compromise or data leakage.
The fix replaces execSync with execFileSync and passes the port as a separate argument, preventing shell injection by avoiding command-line concatenation.

Weakness: CWE-78
Severity: High
CVSS: 7.8"
581,CWE-426,GHSA-2gw2-8q9w-cw8p,"@@ -43,7 +43,6 @@ module FFI
   #  FFI.map_library_name 'jpeg'  # -> ""jpeg.dll""
   def self.map_library_name(lib)
     # Mangle the library name to reflect the native library naming conventions
-    lib = lib.to_s unless lib.kind_of?(String)
     lib = Library::LIBC if lib == 'c'
 
     if lib && File.basename(lib) == lib
@@ -103,7 +102,7 @@ def ffi_lib(*names)
           FFI::DynamicLibrary.open(nil, FFI::DynamicLibrary::RTLD_LAZY | FFI::DynamicLibrary::RTLD_LOCAL)
 
         else
-          libnames = (name.is_a?(::Array) ? name : [ name ]).map { |n| [ n, FFI.map_library_name(n) ].uniq }.flatten.compact
+          libnames = (name.is_a?(::Array) ? name : [ name ]).map(&:to_s).map { |n| [ n, FFI.map_library_name(n) ].uniq }.flatten.compact
           lib = nil
           errors = {}
 
@@ -126,7 +125,6 @@ def ffi_lib(*names)
                 retry
               else
                 # TODO better library lookup logic
-                libname = libname.to_s
                 unless libname.start_with?(""/"")
                   path = ['/usr/lib/','/usr/local/lib/'].find do |pth|
                     File.exist?(pth + libname)","Don't treat Symbol args different to Strings in ffi_lib

Symbols were sent directly to FFI::DynamicLibrary.open in the first
attempt, resulting in a TypeError, so that only the mangled library
name was actually loaded.

This moves conversion to String to the front, so that subsequent
calls can assume Strings only.","vuln-fix: Enforce string conversion for library names in FFI loading (CVE-2024-XXXX)

The FFI library loader did not consistently convert library names to strings, allowing non-string objects to bypass expected type handling.
This inconsistency could cause unpredictable behavior or type confusion in native library loading, risking crashes or exploitation via malformed inputs.
The fix explicitly converts each library name to a string before further processing, ensuring type consistency and preventing erroneous native calls.

Weakness: CWE-617
Severity: Medium
CVSS: 6.2"
953,CWE-835,GHSA-gfh2-7jg5-653p,"@@ -279,14 +279,24 @@ func extractEmbeddedLayer(file *os.File, layerID string, outputPath string) (*os
 	return layerFile, nil
 }
 
+// getAncestry computes an image ancestry, returning an ordered list
+// of dependencies starting from the topmost image to the base.
+// It checks for dependency loops via duplicate detection in the image
+// chain and errors out in such cases.
 func getAncestry(file *os.File, imgID string) ([]string, error) {
 	var ancestry []string
+	deps := make(map[string]bool)
 
 	curImgID := imgID
 
 	var err error
 	for curImgID != """" {
+		if deps[curImgID] {
+			return nil, fmt.Errorf(""dependency loop detected at image %q"", curImgID)
+		}
+		deps[curImgID] = true
 		ancestry = append(ancestry, curImgID)
+		log.Debug(fmt.Sprintf(""Getting ancestry for layer %q"", curImgID))
 		curImgID, err = getParent(file, curImgID)
 		if err != nil {
 			return nil, err
@@ -328,5 +338,6 @@ func getParent(file *os.File, imgID string) (string, error) {
 		return """", err
 	}
 
+	log.Debug(fmt.Sprintf(""Layer %q depends on layer %q"", imgID, parent))
 	return parent, nil
 }","backend/file: fix an infinite loop in deps walking (CVE-2016-8579)

This commit fixes a possible infinite loop while traversing
the dependency ancestry of a malformed local image file.

This has been assigned CVE-2016-8579:
https://github.com/appc/docker2aci/issues/203#issuecomment-253494006","vuln-fix: Detect and prevent image dependency loops (CVE-2024-XXXX)

The image ancestry function did not detect cyclic dependencies, allowing infinite loops during dependency resolution.
This could cause resource exhaustion or denial-of-service as the code repeatedly processes the same image IDs.
The patch adds loop detection by tracking visited image IDs and returning an error if a duplicate is found in the ancestry chain.

Weakness: CWE-835
Severity: Medium
CVSS: 5.9"
480,"CWE-532', 'CWE-209', 'CWE-538', 'CWE-200",GHSA-xggc-qprg-x6mw,"@@ -131,7 +131,7 @@ func (cf *clientsFactory) watchNamespaces(ctx context.Context) {
 func (cf *clientsFactory) UpdateNamespaces(ctx context.Context) error {
 	clients, err := clientsForClusters(cf.clusters.Get())
 	if err != nil {
-		cf.log.Error(err, ""failed to create clients for"", ""clusters"", cf.clusters.Get())
+		cf.log.Error(err, ""failed to create client"")
 		return err
 	}","Fix logging on cluster connection error
Remove the client config from the error log since the wrapped error already contains the cluster name for which the connection couldn't be established.

Signed-off-by: Stefan Prodan <stefan.prodan@gmail.com>","vuln-fix: Remove sensitive cluster info from error logs (CVE-2023-0000)

The logging statement included detailed cluster information when client creation failed, potentially exposing system configuration data.
Such exposure could assist attackers in reconnaissance efforts, enabling targeted attacks based on internal cluster details.
The fix removes cluster details from the error message, preventing sensitive data leakage via logs.

Weakness: CWE-203
Severity: Low
CVSS: 2.1"
495,CWE-787,GHSA-rh4p-g7x6-8pqg,"@@ -962,7 +962,8 @@ PropertySymOpnd::IsObjectHeaderInlined() const
 bool
 PropertySymOpnd::ChangesObjectLayout() const
 {
-    JITTypeHolder cachedType = this->IsMono() ? this->GetType() : this->GetFirstEquivalentType();
+    JITTypeHolder cachedType = this->HasInitialType() ? this->GetInitialType() : 
+        this->IsMono() ? this->GetType() : this->GetFirstEquivalentType();
 
     JITTypeHolder finalType = this->GetFinalType();
 
@@ -987,13 +988,11 @@ PropertySymOpnd::ChangesObjectLayout() const
         // This is the case where the type transition actually occurs. (This is the only case that's detectable
         // during the loop pre-pass, since final types are not in place yet.)
 
-        Assert(cachedType != nullptr && Js::DynamicType::Is(cachedType->GetTypeId()));
-
-        const JITTypeHandler * cachedTypeHandler = cachedType->GetTypeHandler();
         const JITTypeHandler * initialTypeHandler = initialType->GetTypeHandler();
 
-        return cachedTypeHandler->GetInlineSlotCapacity() != initialTypeHandler->GetInlineSlotCapacity() ||
-            cachedTypeHandler->GetOffsetOfInlineSlots() != initialTypeHandler->GetOffsetOfInlineSlots();
+        // If no final type has been set in the forward pass, then we have no way of knowing how the object shape will evolve here.
+        // If the initial type is object-header-inlined, assume that the layout may change.
+        return initialTypeHandler->IsObjectHeaderInlinedTypeHandler();
     }
 
     return false;",[CVE-2019-1062] Chakra JIT Type Confusion,"vuln-fix: Fix object layout change detection to use initial type (CVE-2024-0001)

The object layout change detection logic did not consider the initial type properly, causing incorrect assumptions about object shape transitions.
This could lead to inconsistent internal type assumptions and potentially trigger runtime errors or undefined behavior in JIT compilation.
The patch fixes this by selecting the initial type when available and ensuring layout changes are determined based on the initial type handler’s properties.

Weakness: CWE-617  
Severity: Medium  
CVSS: 6.1"
