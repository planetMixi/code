vuln_id,code_diff,cwe_id
CVE-2021-43825,"From 148de954ed3585d8b4298b424aa24916d0de6136 Mon Sep 17 00:00:00 2001
From: Yan Avlasov <yavlasov@google.com>
Date: Tue, 1 Feb 2022 19:50:04 +0000
Subject: [PATCH] CVE-2021-43825

Response filter manager crash

Signed-off-by: Yan Avlasov <yavlasov@google.com>
---
 source/common/http/conn_manager_impl.cc       |  8 +-
 source/common/http/filter_manager.cc          | 15 +++-
 source/common/http/filter_manager.h           | 18 ++---
 test/integration/BUILD                        |  1 +
 test/integration/filters/BUILD                | 14 ++++
 .../filters/buffer_continue_filter.cc         | 74 +++++++++++++++++++
 test/integration/protocol_integration_test.cc | 52 +++++++++++++
 7 files changed, 166 insertions(+), 16 deletions(-)
 create mode 100644 test/integration/filters/buffer_continue_filter.cc

diff --git a/source/common/http/conn_manager_impl.cc b/source/common/http/conn_manager_impl.cc
index 3a763595455d..0f824751f668 100644
--- a/source/common/http/conn_manager_impl.cc
+++ b/source/common/http/conn_manager_impl.cc
@@ -205,8 +205,8 @@ void ConnectionManagerImpl::doEndStream(ActiveStream& stream) {
   // here is when Envoy ""ends"" the stream by calling recreateStream at which point recreateStream
   // explicitly nulls out response_encoder to avoid the downstream being notified of the
   // Envoy-internal stream instance being ended.
-  if (stream.response_encoder_ != nullptr &&
-      (!stream.filter_manager_.remoteComplete() || !stream.state_.codec_saw_local_complete_)) {
+  if (stream.response_encoder_ != nullptr && (!stream.filter_manager_.remoteDecodeComplete() ||
+                                              !stream.state_.codec_saw_local_complete_)) {
     // Indicate local is complete at this point so that if we reset during a continuation, we don't
     // raise further data or trailers.
     ENVOY_STREAM_LOG(debug, ""doEndStream() resetting stream"", stream);
@@ -249,7 +249,7 @@ void ConnectionManagerImpl::doEndStream(ActiveStream& stream) {
   // We also don't delay-close in the case of HTTP/1.1 where the request is
   // fully read, as there's no race condition to avoid.
   bool connection_close = stream.state_.saw_connection_close_;
-  bool request_complete = stream.filter_manager_.remoteComplete();
+  bool request_complete = stream.filter_manager_.remoteDecodeComplete();
 
   checkForDeferredClose(connection_close && (request_complete || http_10_sans_cl));
 }
@@ -1432,7 +1432,7 @@ void ConnectionManagerImpl::ActiveStream::encodeHeaders(ResponseHeaderMap& heade
   // If we are destroying a stream before remote is complete and the connection does not support
   // multiplexing, we should disconnect since we don't want to wait around for the request to
   // finish.
-  if (!filter_manager_.remoteComplete()) {
+  if (!filter_manager_.remoteDecodeComplete()) {
     if (connection_manager_.codec_->protocol() < Protocol::Http2) {
       connection_manager_.drain_state_ = DrainState::Closing;
     }
diff --git a/source/common/http/filter_manager.cc b/source/common/http/filter_manager.cc
index 7dd385416d55..ea5c18daca62 100644
--- a/source/common/http/filter_manager.cc
+++ b/source/common/http/filter_manager.cc
@@ -303,6 +303,12 @@ bool ActiveStreamDecoderFilter::canContinue() {
   return !parent_.state_.local_complete_;
 }
 
+bool ActiveStreamEncoderFilter::canContinue() {
+  // As with ActiveStreamDecoderFilter::canContinue() make sure we do not
+  // continue if a local reply has been sent.
+  return !parent_.state_.remote_encode_complete_;
+}
+
 Buffer::InstancePtr ActiveStreamDecoderFilter::createBuffer() {
   auto buffer = dispatcher().getWatermarkFactory().createBuffer(
       [this]() -> void { this->requestDataDrained(); },
@@ -316,7 +322,7 @@ Buffer::InstancePtr& ActiveStreamDecoderFilter::bufferedData() {
   return parent_.buffered_request_data_;
 }
 
-bool ActiveStreamDecoderFilter::complete() { return parent_.state_.remote_complete_; }
+bool ActiveStreamDecoderFilter::complete() { return parent_.state_.remote_decode_complete_; }
 
 void ActiveStreamDecoderFilter::doHeaders(bool end_stream) {
   parent_.decodeHeaders(this, *parent_.filter_manager_callbacks_.requestHeaders(), end_stream);
@@ -832,8 +838,8 @@ void FilterManager::decodeMetadata(ActiveStreamDecoderFilter* filter, MetadataMa
 }
 
 void FilterManager::maybeEndDecode(bool end_stream) {
-  ASSERT(!state_.remote_complete_);
-  state_.remote_complete_ = end_stream;
+  ASSERT(!state_.remote_decode_complete_);
+  state_.remote_decode_complete_ = end_stream;
   if (end_stream) {
     stream_info_.downstreamTiming().onLastDownstreamRxByteReceived(dispatcher().timeSource());
     ENVOY_STREAM_LOG(debug, ""request end stream"", *this);
@@ -1356,6 +1362,8 @@ void FilterManager::encodeTrailers(ActiveStreamEncoderFilter* filter,
 
 void FilterManager::maybeEndEncode(bool end_stream) {
   if (end_stream) {
+    ASSERT(!state_.remote_encode_complete_);
+    state_.remote_encode_complete_ = true;
     filter_manager_callbacks_.endStream();
   }
 }
@@ -1646,6 +1654,7 @@ Http1StreamEncoderOptionsOptRef ActiveStreamEncoderFilter::http1StreamEncoderOpt
 }
 
 void ActiveStreamEncoderFilter::responseDataTooLarge() {
+  ENVOY_STREAM_LOG(debug, ""response data too large watermark exceeded"", parent_);
   if (parent_.state_.encoder_filters_streaming_) {
     onEncoderFilterAboveWriteBufferHighWatermark();
   } else {
diff --git a/source/common/http/filter_manager.h b/source/common/http/filter_manager.h
index ff3c02ab85b9..d9c2a3d2adff 100644
--- a/source/common/http/filter_manager.h
+++ b/source/common/http/filter_manager.h
@@ -317,7 +317,7 @@ struct ActiveStreamEncoderFilter : public ActiveStreamFilterBase,
       : ActiveStreamFilterBase(parent, dual_filter, std::move(match_state)), handle_(filter) {}
 
   // ActiveStreamFilterBase
-  bool canContinue() override { return true; }
+  bool canContinue() override;
   Buffer::InstancePtr createBuffer() override;
   Buffer::InstancePtr& bufferedData() override;
   bool complete() override;
@@ -907,7 +907,7 @@ class FilterManager : public ScopeTrackedObject,
   /**
    * Whether remote processing has been marked as complete.
    */
-  bool remoteComplete() const { return state_.remote_complete_; }
+  bool remoteDecodeComplete() const { return state_.remote_decode_complete_; }
 
   /**
    * Instructs the FilterManager to not create a filter chain. This makes it possible to issue
@@ -1058,15 +1058,15 @@ class FilterManager : public ScopeTrackedObject,
 
   struct State {
     State()
-        : remote_complete_(false), local_complete_(false), has_1xx_headers_(false),
-          created_filter_chain_(false), is_head_request_(false), is_grpc_request_(false),
-          non_100_response_headers_encoded_(false), under_on_local_reply_(false),
-          decoder_filter_chain_aborted_(false), encoder_filter_chain_aborted_(false),
-          saw_downstream_reset_(false) {}
-
+        : remote_encode_complete_(false), remote_decode_complete_(false), local_complete_(false),
+          has_1xx_headers_(false), created_filter_chain_(false), is_head_request_(false),
+          is_grpc_request_(false), non_100_response_headers_encoded_(false),
+          under_on_local_reply_(false), decoder_filter_chain_aborted_(false),
+          encoder_filter_chain_aborted_(false), saw_downstream_reset_(false) {}
     uint32_t filter_call_state_{0};
 
-    bool remote_complete_ : 1;
+    bool remote_encode_complete_ : 1;
+    bool remote_decode_complete_ : 1;
     bool local_complete_ : 1; // This indicates that local is complete prior to filter processing.
                               // A filter can still stop the stream from being complete as seen
                               // by the codec.
diff --git a/test/integration/BUILD b/test/integration/BUILD
index 990e17b2d035..d93a55ba7dfd 100644
--- a/test/integration/BUILD
+++ b/test/integration/BUILD
@@ -517,6 +517,7 @@ envoy_cc_test_library(
         ""//source/extensions/filters/http/buffer:config"",
         ""//test/common/http/http2:http2_frame"",
         ""//test/integration/filters:add_invalid_data_filter_lib"",
+        ""//test/integration/filters:buffer_continue_filter_lib"",
         ""//test/integration/filters:continue_after_local_reply_filter_lib"",
         ""//test/integration/filters:continue_headers_only_inject_body"",
         ""//test/integration/filters:encoder_decoder_buffer_filter_lib"",
diff --git a/test/integration/filters/BUILD b/test/integration/filters/BUILD
index 7a39648ae150..e29fd05bd6e5 100644
--- a/test/integration/filters/BUILD
+++ b/test/integration/filters/BUILD
@@ -545,6 +545,20 @@ envoy_cc_test_library(
     ],
 )
 
+envoy_cc_test_library(
+    name = ""buffer_continue_filter_lib"",
+    srcs = [
+        ""buffer_continue_filter.cc"",
+    ],
+    deps = [
+        ""//envoy/http:filter_interface"",
+        ""//envoy/registry"",
+        ""//envoy/server:filter_config_interface"",
+        ""//source/extensions/filters/http/common:pass_through_filter_lib"",
+        ""//test/extensions/filters/http/common:empty_http_filter_config_lib"",
+    ],
+)
+
 envoy_cc_test_library(
     name = ""test_socket_interface_lib"",
     srcs = [
diff --git a/test/integration/filters/buffer_continue_filter.cc b/test/integration/filters/buffer_continue_filter.cc
new file mode 100644
index 000000000000..d5f5dadd690d
--- /dev/null
+++ b/test/integration/filters/buffer_continue_filter.cc
@@ -0,0 +1,74 @@
+#include <string>
+
+#include ""envoy/http/filter.h""
+#include ""envoy/registry/registry.h""
+#include ""envoy/server/filter_config.h""
+
+#include ""source/extensions/filters/http/common/pass_through_filter.h""
+
+#include ""test/extensions/filters/http/common/empty_http_filter_config.h""
+
+namespace Envoy {
+
+// A filter that buffers until the limit is reached and then continues.
+class BufferContinueStreamFilter : public Http::PassThroughFilter {
+public:
+  Http::FilterHeadersStatus decodeHeaders(Http::RequestHeaderMap&, bool end_stream) override {
+    return end_stream ? Http::FilterHeadersStatus::Continue
+                      : Http::FilterHeadersStatus::StopIteration;
+  }
+
+  Http::FilterDataStatus decodeData(Buffer::Instance&, bool end_stream) override {
+    return end_stream ? Http::FilterDataStatus::Continue
+                      : Http::FilterDataStatus::StopIterationAndBuffer;
+  }
+
+  Http::FilterHeadersStatus encodeHeaders(Http::ResponseHeaderMap& headers, bool) override {
+    response_headers_ = &headers;
+    return Http::FilterHeadersStatus::StopIteration;
+  }
+
+  Http::FilterDataStatus encodeData(Buffer::Instance& data, bool end_stream) override {
+    data_total_ += data.length();
+
+    const auto limit = encoder_callbacks_->encoderBufferLimit();
+    const auto header_size = response_headers_->byteSize();
+
+    if (limit && header_size + data_total_ > limit) {
+      // Give up since we've reached the buffer limit, Envoy should generate
+      // a 500 since it couldn't finished encoding.
+      return Http::FilterDataStatus::Continue;
+    }
+
+    encoder_callbacks_->addEncodedData(data, false);
+
+    if (!end_stream) {
+      return Http::FilterDataStatus::StopIterationAndBuffer;
+    }
+
+    return Http::FilterDataStatus::Continue;
+  }
+
+private:
+  Http::ResponseHeaderMap* response_headers_;
+  uint64_t data_total_{0};
+};
+
+class BufferContinueFilterConfig : public Extensions::HttpFilters::Common::EmptyHttpFilterConfig {
+public:
+  BufferContinueFilterConfig() : EmptyHttpFilterConfig(""buffer-continue-filter"") {}
+
+  Http::FilterFactoryCb createFilter(const std::string&,
+                                     Server::Configuration::FactoryContext&) override {
+    return [](Http::FilterChainFactoryCallbacks& callbacks) -> void {
+      callbacks.addStreamFilter(std::make_shared<::Envoy::BufferContinueStreamFilter>());
+    };
+  }
+};
+
+// perform static registration
+static Registry::RegisterFactory<BufferContinueFilterConfig,
+                                 Server::Configuration::NamedHttpFilterConfigFactory>
+    register_;
+
+} // namespace Envoy
diff --git a/test/integration/protocol_integration_test.cc b/test/integration/protocol_integration_test.cc
index 289ae403ca6c..33a65d23b4de 100644
--- a/test/integration/protocol_integration_test.cc
+++ b/test/integration/protocol_integration_test.cc
@@ -3450,6 +3450,58 @@ TEST_P(ProtocolIntegrationTest, FragmentStrippedFromPathWithOverride) {
   EXPECT_EQ(""200"", response->headers().getStatusValue());
 }
 
+// Test buffering and then continuing after too many response bytes to buffer.
+TEST_P(ProtocolIntegrationTest, BufferContinue) {
+  // Bytes sent is configured for http/2 flow control windows.
+  if (upstreamProtocol() != Http::CodecType::HTTP2) {
+    return;
+  }
+  config_helper_.addConfigModifier(
+      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&
+              hcm) -> void {
+        auto* route_config = hcm.mutable_route_config();
+        auto* virtual_host = route_config->mutable_virtual_hosts(0);
+        auto* header = virtual_host->mutable_response_headers_to_add()->Add()->mutable_header();
+        header->set_key(""foo"");
+        header->set_value(""bar"");
+      });
+
+  useAccessLog();
+  config_helper_.addFilter(""{ name: buffer-continue-filter, typed_config: { \""@type\"": ""
+                           ""type.googleapis.com/google.protobuf.Empty } }"");
+  config_helper_.setBufferLimits(1024, 1024);
+  initialize();
+
+  // Send the request.
+  codec_client_ = makeHttpConnection(lookupPort(""http""));
+  auto encoder_decoder = codec_client_->startRequest(default_request_headers_);
+  auto downstream_request = &encoder_decoder.first;
+  auto response = std::move(encoder_decoder.second);
+  Buffer::OwnedImpl data(""HTTP body content goes here"");
+  codec_client_->sendData(*downstream_request, data, true);
+  waitForNextUpstreamRequest();
+
+  // Send the response headers.
+  upstream_request_->encodeHeaders(default_response_headers_, false);
+
+  // Now send an overly large response body. At some point, too much data will
+  // be buffered, the stream will be reset, and the connection will disconnect.
+  upstream_request_->encodeData(512, false);
+  upstream_request_->encodeData(1024 * 100, false);
+
+  if (upstreamProtocol() == Http::CodecType::HTTP1) {
+    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());
+  } else {
+    ASSERT_TRUE(upstream_request_->waitForReset());
+    ASSERT_TRUE(fake_upstream_connection_->close());
+    ASSERT_TRUE(fake_upstream_connection_->waitForDisconnect());
+  }
+
+  ASSERT_TRUE(response->waitForEndStream());
+  EXPECT_TRUE(response->complete());
+  EXPECT_EQ(""500"", response->headers().getStatusValue());
+}
+
 TEST_P(DownstreamProtocolIntegrationTest, ContentLengthSmallerThanPayload) {
   initialize();
   codec_client_ = makeHttpConnection(lookupPort(""http""));",CWE-400
GHSA-25xm-hr59-7c27,"From 69c6093c7b2397b923acf82cb378f55ab2652b9b Mon Sep 17 00:00:00 2001
From: Ulrich Kunitz <ulikunitz@users.noreply.github.com>
Date: Wed, 19 Aug 2020 18:04:10 +0200
Subject: [PATCH] xz: fix a security issue for readUvarint

readUvarint could be provided a sequence of bytes where the application
would never stop. That is the same issue that has been recently
reported for the Go Standard Library as CVE-2020-16845.

The fix simply adds a check for the number of bytes read and reports an
overflow after more than 10 bytes are read, which is
$\ceil{\frac{64}{7}}$.

The commit also includes a test to ensure that the error is returned.

I thank Github user 0xdecaf for reporting the issue.
---
 bits.go      |  7 ++++++-
 bits_test.go | 11 +++++++++++
 2 files changed, 17 insertions(+), 1 deletion(-)

diff --git a/bits.go b/bits.go
index 364213d..dc8f328 100644
--- a/bits.go
+++ b/bits.go
@@ -54,6 +54,8 @@ var errOverflowU64 = errors.New(""xz: uvarint overflows 64-bit unsigned integer"")
 
 // readUvarint reads a uvarint from the given byte reader.
 func readUvarint(r io.ByteReader) (x uint64, n int, err error) {
+	const maxUvarintLen = 10
+
 	var s uint
 	i := 0
 	for {
@@ -62,8 +64,11 @@ func readUvarint(r io.ByteReader) (x uint64, n int, err error) {
 			return x, i, err
 		}
 		i++
+		if i > maxUvarintLen {
+			return x, i, errOverflowU64
+		}
 		if b < 0x80 {
-			if i > 10 || i == 10 && b > 1 {
+			if i == maxUvarintLen && b > 1 {
 				return x, i, errOverflowU64
 			}
 			return x | uint64(b)<<s, i, nil
diff --git a/bits_test.go b/bits_test.go
index 8530056..acf2303 100644
--- a/bits_test.go
+++ b/bits_test.go
@@ -31,3 +31,14 @@ func TestUvarint(t *testing.T) {
 		}
 	}
 }
+
+func TestUvarIntCVE_2020_16845(t *testing.T) {
+	var a = []byte{0x81, 0x82, 0x83, 0x84, 0x85, 0x86, 0x87,
+		0x88, 0x89, 0x8a, 0x8b}
+
+	r := bytes.NewReader(a)
+	_, _, err := readUvarint(r)
+	if err != errOverflowU64 {
+		t.Fatalf(""readUvarint overflow not detected"")
+	}
+}",CWE-400
CVE-2021-45462,"From a0f2535cb5a29bba6dbbccdb90c74ccd770cc700 Mon Sep 17 00:00:00 2001
From: Sukchan Lee <acetcom@gmail.com>
Date: Wed, 22 Dec 2021 20:55:48 +0900
Subject: [PATCH] A crafted packet from UE can crash SGW-U/UPF

---
 src/sgwu/gtp-path.c | 6 ++++++
 src/smf/gtp-path.c  | 6 ++++++
 src/upf/gtp-path.c  | 6 ++++++
 3 files changed, 18 insertions(+)

diff --git a/src/sgwu/gtp-path.c b/src/sgwu/gtp-path.c
index c523e3e3c5..b72f1aa5db 100644
--- a/src/sgwu/gtp-path.c
+++ b/src/sgwu/gtp-path.c
@@ -124,6 +124,12 @@ static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)
         ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);
         goto cleanup;
     }
+    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&
+        pkbuf->len <= len) {
+        ogs_error(""[DROP] Small GTPU packet(type:%d len:%d)"", gtp_h->type, len);
+        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);
+        goto cleanup;
+    }
     ogs_assert(ogs_pkbuf_pull(pkbuf, len));
 
     if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {
diff --git a/src/smf/gtp-path.c b/src/smf/gtp-path.c
index 8e825fe62c..821341ce83 100644
--- a/src/smf/gtp-path.c
+++ b/src/smf/gtp-path.c
@@ -186,6 +186,12 @@ static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)
         ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);
         goto cleanup;
     }
+    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&
+        pkbuf->len <= len) {
+        ogs_error(""[DROP] Small GTPU packet(type:%d len:%d)"", gtp_h->type, len);
+        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);
+        goto cleanup;
+    }
     ogs_assert(ogs_pkbuf_pull(pkbuf, len));
 
     if (gtp_h->type == OGS_GTPU_MSGTYPE_GPDU) {
diff --git a/src/upf/gtp-path.c b/src/upf/gtp-path.c
index b18b7c51b9..95bb5b99ac 100644
--- a/src/upf/gtp-path.c
+++ b/src/upf/gtp-path.c
@@ -304,6 +304,12 @@ static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)
         ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);
         goto cleanup;
     }
+    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&
+        pkbuf->len <= len) {
+        ogs_error(""[DROP] Small GTPU packet(type:%d len:%d)"", gtp_h->type, len);
+        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);
+        goto cleanup;
+    }
     ogs_assert(ogs_pkbuf_pull(pkbuf, len));
 
     if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {",CWE-400
CVE-2020-26164,"From 4fbd01a3d44a0bcca888c49a77ec7cfd10e113d7 Mon Sep 17 00:00:00 2001
From: Aleix Pol <aleixpol@kde.org>
Date: Wed, 16 Sep 2020 02:28:58 +0200
Subject: [PATCH] Limit identity packets to 8KiB

Healthy identity packages shouldn't be that big and we don't want to
allow systems around us to send us ever humongous packages that will
just leave us without any memory.

Thanks Matthias Gerstner <mgerstner@suse.de> for reporting this.
---
 core/backends/lan/lanlinkprovider.cpp | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/core/backends/lan/lanlinkprovider.cpp b/core/backends/lan/lanlinkprovider.cpp
index 0e14922ed..aeabc7f30 100644
--- a/core/backends/lan/lanlinkprovider.cpp
+++ b/core/backends/lan/lanlinkprovider.cpp
@@ -399,6 +399,14 @@ void LanLinkProvider::newConnection()
 void LanLinkProvider::dataReceived()
 {
     QSslSocket* socket = qobject_cast<QSslSocket*>(sender());
+    //the size here is arbitrary and is now at 8192 bytes. It needs to be considerably long as it includes the capabilities but there needs to be a limit
+    //Tested between my systems and I get around 2000 per identity package.
+    if (socket->bytesAvailable() > 8192) {
+        qCWarning(KDECONNECT_CORE) << ""LanLinkProvider/newConnection: Suspiciously long identity package received. Closing connection."" << socket->peerAddress() << socket->bytesAvailable();
+        socket->disconnectFromHost();
+        return;
+    }
+
 #if QT_VERSION < QT_VERSION_CHECK(5,7,0)
     if (!socket->canReadLine())
         return;",CWE-400
CVE-2020-21049,"From 0b1e0b3f7b44233f84e5c9f512f8c90d6bbbe33d Mon Sep 17 00:00:00 2001
From: Hayaki Saito <saitoha@me.com>
Date: Mon, 23 Dec 2019 13:20:08 +0000
Subject: [PATCH] Introduce SIXEL_ALLOCATE_BYTES_MAX macro and limit allocation
 size to 128MB(#74)

---
 include/sixel.h.in |  1 +
 src/allocator.c    | 29 +++++++++++++++++++++++++++++
 2 files changed, 30 insertions(+)

diff --git a/include/sixel.h.in b/include/sixel.h.in
index 5fc553f1..792bb1b0 100644
--- a/include/sixel.h.in
+++ b/include/sixel.h.in
@@ -39,6 +39,7 @@ typedef unsigned char sixel_index_t;
 #define SIXEL_PALETTE_MIN            2
 #define SIXEL_PALETTE_MAX            256
 #define SIXEL_USE_DEPRECATED_SYMBOLS 1
+#define SIXEL_ALLOCATE_BYTES_MAX     10248UL * 1024UL * 128UL   /* up to 128M */
 
 /* return value */
 typedef int SIXELSTATUS;
diff --git a/src/allocator.c b/src/allocator.c
index bb0c009f..5cee49c0 100644
--- a/src/allocator.c
+++ b/src/allocator.c
@@ -152,6 +152,11 @@ sixel_allocator_malloc(
             ""sixel_allocator_malloc: called with n == 0"");
         return NULL;
     }
+
+    if (n > SIXEL_ALLOCATE_BYTES_MAX) {
+        return NULL;
+    }
+
     return allocator->fn_malloc(n);
 }
 
@@ -163,10 +168,24 @@ sixel_allocator_calloc(
     size_t              /* in */ nelm,        /* number of elements */
     size_t              /* in */ elsize)      /* size of element */
 {
+    size_t n;
+
     /* precondition */
     assert(allocator);
     assert(allocator->fn_calloc);
 
+    n = nelm * elsize;
+
+    if (n == 0) {
+        sixel_helper_set_additional_message(
+            ""sixel_allocator_malloc: called with n == 0"");
+        return NULL;
+    }
+
+    if (n > SIXEL_ALLOCATE_BYTES_MAX) {
+        return NULL;
+    }
+
     return allocator->fn_calloc(nelm, elsize);
 }
 
@@ -182,6 +201,16 @@ sixel_allocator_realloc(
     assert(allocator);
     assert(allocator->fn_realloc);
 
+    if (n == 0) {
+        sixel_helper_set_additional_message(
+            ""sixel_allocator_malloc: called with n == 0"");
+        return NULL;
+    }
+
+    if (n > SIXEL_ALLOCATE_BYTES_MAX) {
+        return NULL;
+    }
+
     return allocator->fn_realloc(p, n);
 }",CWE-400
CVE-2022-23641,"From a34075d205a8857e29574ffd82aaece0c467565e Mon Sep 17 00:00:00 2001
From: Krzysztof Kotlarek <kotlarek.krzysztof@gmail.com>
Date: Mon, 14 Feb 2022 12:11:09 +1100
Subject: [PATCH] SECURITY: Onebox response timeout and size limit (#15927)

Validation to ensure that Onebox request is no longer than 10 seconds and response size is not bigger than 1 MB
---
 lib/final_destination.rb                  | 17 ++++++++++++++---
 spec/components/final_destination_spec.rb | 21 +++++++++++++++++++++
 2 files changed, 35 insertions(+), 3 deletions(-)

diff --git a/lib/final_destination.rb b/lib/final_destination.rb
index 2fbc5711b1833..078fd4fd781f7 100644
--- a/lib/final_destination.rb
+++ b/lib/final_destination.rb
@@ -8,6 +8,8 @@
 
 # Determine the final endpoint for a Web URI, following redirects
 class FinalDestination
+  MAX_REQUEST_TIME_SECONDS = 10
+  MAX_REQUEST_SIZE_BYTES = 1_048_576 # 1024 * 1024
 
   def self.clear_https_cache!(domain)
     key = redis_https_key(domain)
@@ -203,12 +205,21 @@ def resolve
     middlewares = Excon.defaults[:middlewares]
     middlewares << Excon::Middleware::Decompress if @http_verb == :get
 
+    request_start_time = Time.now
+    response_body = +""""
+    request_validator = lambda do |chunk, _remaining_bytes, _total_bytes|
+      response_body << chunk
+      raise Excon::Errors::ExpectationFailed.new(""response size too big: #{@uri.to_s}"") if response_body.bytesize > MAX_REQUEST_SIZE_BYTES
+      raise Excon::Errors::ExpectationFailed.new(""connect timeout reached: #{@uri.to_s}"") if Time.now - request_start_time > MAX_REQUEST_TIME_SECONDS
+    end
+
     response = Excon.public_send(@http_verb,
       @uri.to_s,
       read_timeout: timeout,
       connect_timeout: timeout,
       headers: headers,
-      middlewares: middlewares
+      middlewares: middlewares,
+      response_block: request_validator
     )
 
     location = nil
@@ -220,12 +231,12 @@ def resolve
       # Cache body of successful `get` requests
       if @http_verb == :get
         if Oneboxer.cache_response_body?(@uri)
-          Oneboxer.cache_response_body(@uri.to_s, response.body)
+          Oneboxer.cache_response_body(@uri.to_s, response_body)
         end
       end
 
       if @follow_canonical
-        next_url = fetch_canonical_url(response.body)
+        next_url = fetch_canonical_url(response_body)
 
         if next_url.to_s.present? && next_url != @uri
           @follow_canonical = false
diff --git a/spec/components/final_destination_spec.rb b/spec/components/final_destination_spec.rb
index e9548ead0b919..b1ce1a262a0fe 100644
--- a/spec/components/final_destination_spec.rb
+++ b/spec/components/final_destination_spec.rb
@@ -49,6 +49,13 @@
     }
   end
 
+  let(:body_response) do
+    {
+      status: 200,
+      body: ""<body>test</body>""
+    }
+  end
+
   def canonical_follow(from, dest)
     stub_request(:get, from).to_return(
       status: 200,
@@ -182,6 +189,20 @@ def fd(url)
       end
     end
 
+    it 'raises error when response is too big' do
+      stub_const(described_class, ""MAX_REQUEST_SIZE_BYTES"", 1) do
+        stub_request(:get, ""https://codinghorror.com/blog"").to_return(body_response)
+        final = FinalDestination.new('https://codinghorror.com/blog', opts.merge(follow_canonical: true))
+        expect { final.resolve }.to raise_error(Excon::Errors::ExpectationFailed, ""response size too big: https://codinghorror.com/blog"")
+      end
+    end
+
+    it 'raises error when response is too slow' do
+      stub_request(:get, ""https://codinghorror.com/blog"").to_return(lambda { |request| freeze_time(11.seconds.from_now) ; body_response })
+      final = FinalDestination.new('https://codinghorror.com/blog', opts.merge(follow_canonical: true))
+      expect { final.resolve }.to raise_error(Excon::Errors::ExpectationFailed, ""connect timeout reached: https://codinghorror.com/blog"")
+    end
+
     context 'follows canonical links' do
       it 'resolves the canonical link as the final destination' do
         canonical_follow(""https://eviltrout.com"", ""https://codinghorror.com/blog"")",CWE-400
GHSA-xcvv-84j5-jw9h,"From 19953a8c089b0328c470acaaaf6accdfcb34da11 Mon Sep 17 00:00:00 2001
From: doowb <brian.woodward@gmail.com>
Date: Wed, 7 Feb 2018 11:20:22 -0500
Subject: [PATCH] exclude __proto__

---
 index.js | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/index.js b/index.js
index b2e74cf..c5dc494 100644
--- a/index.js
+++ b/index.js
@@ -37,7 +37,7 @@ function extend(target, obj) {
   assignSymbols(target, obj);
 
   for (var key in obj) {
-    if (hasOwn(obj, key)) {
+    if (key !== '__proto__' && hasOwn(obj, key)) {
       var val = obj[key];
       if (isObject(val)) {
         if (typeOf(target[key]) === 'undefined' && typeOf(val) === 'function') {",CWE-400
