{
  "schema":{
    "fields":[
      {
        "name":"index",
        "type":"integer"
      },
      {
        "name":"vuln_id",
        "type":"string"
      },
      {
        "name":"cwe_id",
        "type":"string"
      },
      {
        "name":"score",
        "type":"number"
      },
      {
        "name":"chain",
        "type":"string"
      },
      {
        "name":"dataset",
        "type":"string"
      },
      {
        "name":"summary",
        "type":"string"
      },
      {
        "name":"published_date",
        "type":"string"
      },
      {
        "name":"chain_len",
        "type":"integer"
      },
      {
        "name":"project",
        "type":"string"
      },
      {
        "name":"commit_href",
        "type":"string"
      },
      {
        "name":"commit_sha",
        "type":"string"
      },
      {
        "name":"patch",
        "type":"string"
      },
      {
        "name":"chain_ord",
        "type":"string"
      },
      {
        "name":"before_first_fix_commit",
        "type":"string"
      },
      {
        "name":"last_fix_commit",
        "type":"string"
      },
      {
        "name":"chain_ord_pos",
        "type":"number"
      },
      {
        "name":"commit_datetime",
        "type":"string"
      },
      {
        "name":"message",
        "type":"string"
      },
      {
        "name":"author",
        "type":"string"
      },
      {
        "name":"comments",
        "type":"string"
      },
      {
        "name":"stats",
        "type":"string"
      },
      {
        "name":"files",
        "type":"string"
      },
      {
        "name":"message_norm",
        "type":"string"
      },
      {
        "name":"language",
        "type":"string"
      },
      {
        "name":"entities",
        "type":"string"
      },
      {
        "name":"classification_level_1",
        "type":"string"
      },
      {
        "name":"classification_level_2",
        "type":"string"
      },
      {
        "name":"list_files",
        "type":"string"
      },
      {
        "name":"num_files",
        "type":"number"
      },
      {
        "name":"patch_content",
        "type":"string"
      },
      {
        "name":"code_diff",
        "type":"string"
      }
    ],
    "primaryKey":[
      "index"
    ],
    "pandas_version":"1.4.0"
  },
  "data":[
    {
      "index":0,
      "vuln_id":"GHSA-vq36-27g6-p492",
      "cwe_id":"{'CWE-125'}",
      "score":8.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c99d98cd189839dcf51aee94e7437b54b31f8abd'}",
      "dataset":"osv",
      "summary":"Out of bounds read in Tensorflow ### Impact\nTensorFlow's [type inference](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/274df9b02330b790aa8de1cee164b70f72b9b244\/tensorflow\/core\/graph\/graph.cc#L223-L229) can cause a heap OOB read as the bounds checking is done in a `DCHECK` (which is a no-op during production):\n\n```cc\nif (node_t.type_id() != TFT_UNSET) {\n  int ix = input_idx[i];\n  DCHECK(ix < node_t.args_size())\n      << \"input \" << i << \" should have an output \" << ix\n      << \" but instead only has \" << node_t.args_size()\n      << \" outputs: \" << node_t.DebugString();\n  input_types.emplace_back(node_t.args(ix));\n  \/\/ ...\n}       \n```   \n      \nAn attacker can control `input_idx` such that `ix` would be larger than the number of values in `node_t.args`.\n        \n### Patches\nWe have patched the issue in GitHub commit [c99d98cd189839dcf51aee94e7437b54b31f8abd](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c99d98cd189839dcf51aee94e7437b54b31f8abd).\n  \nThe fix will be included in TensorFlow 2.8.0. This is the only affected version.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/c99d98cd189839dcf51aee94e7437b54b31f8abd",
      "commit_sha":"c99d98cd189839dcf51aee94e7437b54b31f8abd",
      "patch":"SINGLE",
      "chain_ord":"['c99d98cd189839dcf51aee94e7437b54b31f8abd']",
      "before_first_fix_commit":"{'c5ae019abd2f260cf3400abcce4962c75cc5182c'}",
      "last_fix_commit":"c99d98cd189839dcf51aee94e7437b54b31f8abd",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/13\/2021, 01:42:30",
      "message":"Handle invalid inputs instead of crashing.\n\nPiperOrigin-RevId: 409549744\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24",
      "author":"Dan Moldovan",
      "comments":null,
      "stats":"{'additions': 10, 'deletions': 4, 'total': 14}",
      "files":"{'tensorflow\/core\/graph\/graph.cc': {'additions': 10, 'deletions': 4, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/c99d98cd189839dcf51aee94e7437b54b31f8abd\/tensorflow%2Fcore%2Fgraph%2Fgraph.cc', 'patch': '@@ -222,10 +222,16 @@ void Node::RunForwardTypeInference() {\\n       const auto& node_t = node->def().experimental_type();\\n       if (node_t.type_id() != TFT_UNSET) {\\n         int ix = input_idx[i];\\n-        DCHECK(ix < node_t.args_size())\\n-            << \"input \" << i << \" should have an output \" << ix\\n-            << \" but instead only has \" << node_t.args_size()\\n-            << \" outputs: \" << node_t.DebugString();\\n+        if (ix >= node_t.args_size()) {\\n+          LOG(WARNING) << name() << \" has bad type information: input \" << i\\n+                       << \" should have an output \" << ix\\n+                       << \" but instead only has \" << node_t.args_size()\\n+                       << \" outputs: \" << node_t.DebugString()\\n+                       << \"\\\\nThis indicates either \"\\n+                          \"a bug in op registration or a corrupted graph.\";\\n+          ClearTypeInfo();\\n+          return;\\n+        }\\n         input_types.emplace_back(node_t.args(ix));\\n       } else {\\n         input_types.emplace_back(*no_type);'}}",
      "message_norm":"handle invalid inputs instead of crashing.\n\npiperorigin-revid: 409549744\nchange-id: i7f5935b34b53f7e426a5462fcc027bdbf5dcda24",
      "language":"en",
      "entities":"[('409549744', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/graph\/graph.cc'])",
      "num_files":1.0,
      "patch_content":"From c99d98cd189839dcf51aee94e7437b54b31f8abd Mon Sep 17 00:00:00 2001\nFrom: Dan Moldovan <mdan@google.com>\nDate: Fri, 12 Nov 2021 17:42:30 -0800\nSubject: [PATCH] Handle invalid inputs instead of crashing.\n\nPiperOrigin-RevId: 409549744\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24\n---\n tensorflow\/core\/graph\/graph.cc | 14 ++++++++++----\n 1 file changed, 10 insertions(+), 4 deletions(-)\n\ndiff --git a\/tensorflow\/core\/graph\/graph.cc b\/tensorflow\/core\/graph\/graph.cc\nindex 2e3703b66030f4..4af258a203813d 100644\n--- a\/tensorflow\/core\/graph\/graph.cc\n+++ b\/tensorflow\/core\/graph\/graph.cc\n@@ -222,10 +222,16 @@ void Node::RunForwardTypeInference() {\n       const auto& node_t = node->def().experimental_type();\n       if (node_t.type_id() != TFT_UNSET) {\n         int ix = input_idx[i];\n-        DCHECK(ix < node_t.args_size())\n-            << \"input \" << i << \" should have an output \" << ix\n-            << \" but instead only has \" << node_t.args_size()\n-            << \" outputs: \" << node_t.DebugString();\n+        if (ix >= node_t.args_size()) {\n+          LOG(WARNING) << name() << \" has bad type information: input \" << i\n+                       << \" should have an output \" << ix\n+                       << \" but instead only has \" << node_t.args_size()\n+                       << \" outputs: \" << node_t.DebugString()\n+                       << \"\\nThis indicates either \"\n+                          \"a bug in op registration or a corrupted graph.\";\n+          ClearTypeInfo();\n+          return;\n+        }\n         input_types.emplace_back(node_t.args(ix));\n       } else {\n         input_types.emplace_back(*no_type);",
      "code_diff":"@@ -222,10 +222,16 @@ void Node::RunForwardTypeInference() {\n       const auto& node_t = node->def().experimental_type();\n       if (node_t.type_id() != TFT_UNSET) {\n         int ix = input_idx[i];\n-        DCHECK(ix < node_t.args_size())\n-            << \"input \" << i << \" should have an output \" << ix\n-            << \" but instead only has \" << node_t.args_size()\n-            << \" outputs: \" << node_t.DebugString();\n+        if (ix >= node_t.args_size()) {\n+          LOG(WARNING) << name() << \" has bad type information: input \" << i\n+                       << \" should have an output \" << ix\n+                       << \" but instead only has \" << node_t.args_size()\n+                       << \" outputs: \" << node_t.DebugString()\n+                       << \"\\nThis indicates either \"\n+                          \"a bug in op registration or a corrupted graph.\";\n+          ClearTypeInfo();\n+          return;\n+        }\n         input_types.emplace_back(node_t.args(ix));\n       } else {\n         input_types.emplace_back(*no_type);"
    },
    {
      "index":1,
      "vuln_id":"GHSA-4873-36h9-wv49",
      "cwe_id":"{'CWE-787', 'CWE-125', 'CWE-590'}",
      "score":6.3,
      "chain":"{'https:\/\/github.com\/bytecodealliance\/wasmtime\/commit\/398a73f0dd862dbe703212ebae8e34036a18c11c'}",
      "dataset":"osv",
      "summary":"Out-of-bounds read\/write and invalid free with `externref`s and GC safepoints in Wasmtime  ### Impact\n\nThere was an invalid free and out-of-bounds read and write bug when running Wasm that uses `externref`s in Wasmtime.\n\nTo trigger this bug, Wasmtime needs to be running Wasm that uses `externref`s, the host creates non-null `externrefs`, Wasmtime performs a garbage collection (GC), and there has to be a Wasm frame on the stack that is at a GC safepoint where\n\n* there are no live references at this safepoint, and\n* there is a safepoint with live references earlier in this frame's function.\n\nUnder this scenario, Wasmtime would incorrectly use the GC stack map for the safepoint from earlier in the function instead of the empty safepoint. This would result in Wasmtime treating arbitrary stack slots as `externref`s that needed to be rooted for GC. At the *next* GC, it would be determined that nothing was referencing these bogus `externref`s (because nothing could ever reference them, because they are not really `externref`s) and then Wasmtime would deallocate them and run `<ExternRef as Drop>::drop` on them. This results in a free of memory that is not necessarily on the heap (and shouldn't be freed at this moment even if it was), as well as potential out-of-bounds reads and writes.\n\nEven though support for `externref`s (via the reference types proposal) is enabled by default, unless you are creating non-null `externref`s in your host code or explicitly triggering GCs, you cannot be affected by this bug.\n\nWe have reason to believe that the effective impact of this bug is relatively small because usage of `externref` is currently quite rare.\n\n### Patches\n\nThis bug has been patched and users should upgrade to Wasmtime version 0.30.0.\n\nAdditionally, we have updated [our primary `externref` fuzz target](https:\/\/github.com\/bytecodealliance\/wasmtime\/blob\/37c094faf53f1b356aab3c79d451395e4f7edb34\/fuzz\/fuzz_targets\/table_ops.rs) such that it better exercises these code paths and we can have greater confidence in their correctness going forward.\n\n### Workarounds\n\nIf you cannot upgrade Wasmtime at this time, you can avoid this bug by disabling the reference types proposal by passing `false` to [`wasmtime::Config::wasm_reference_types`](https:\/\/docs.rs\/wasmtime\/0.29.0\/wasmtime\/struct.Config.html#method.wasm_reference_types)\n\n### References\n\n* [The Wasm reference types proposal, which introduces `externref`](https:\/\/github.com\/WebAssembly\/reference-types\/)\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Reach out to us on [the Bytecode Alliance Zulip chat](https:\/\/bytecodealliance.zulipchat.com\/#narrow\/stream\/217126-wasmtime)\n* Open an issue in [the `bytecodealliance\/wasmtime` repository](https:\/\/github.com\/bytecodealliance\/wasmtime\/)",
      "published_date":"2021-09-20",
      "chain_len":1,
      "project":"https:\/\/github.com\/bytecodealliance\/wasmtime",
      "commit_href":"https:\/\/github.com\/bytecodealliance\/wasmtime\/commit\/398a73f0dd862dbe703212ebae8e34036a18c11c",
      "commit_sha":"398a73f0dd862dbe703212ebae8e34036a18c11c",
      "patch":"SINGLE",
      "chain_ord":"['398a73f0dd862dbe703212ebae8e34036a18c11c']",
      "before_first_fix_commit":"{'ec4e48d4cbc28bcfd99e25842a90704e765b800f', '101998733b74624cbd348a2366d05760b40181f3'}",
      "last_fix_commit":"398a73f0dd862dbe703212ebae8e34036a18c11c",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/17\/2021, 17:28:50",
      "message":"Merge pull request from GHSA-4873-36h9-wv49\n\nStop doing fuzzy search for stack maps",
      "author":"Nick Fitzgerald",
      "comments":null,
      "stats":"{'additions': 52, 'deletions': 48, 'total': 100}",
      "files":"{'crates\/wasmtime\/src\/module\/registry.rs': {'additions': 52, 'deletions': 48, 'changes': 100, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/bytecodealliance\/wasmtime\/raw\/398a73f0dd862dbe703212ebae8e34036a18c11c\/crates%2Fwasmtime%2Fsrc%2Fmodule%2Fregistry.rs', 'patch': '@@ -122,61 +122,65 @@ impl ModuleInfo for RegisteredModule {\\n         let info = self.module.func_info(index);\\n \\n         \/\/ Do a binary search to find the stack map for the given offset.\\n-        \/\/\\n-        \/\/ Because GC safepoints are technically only associated with a single\\n-        \/\/ PC, we should ideally only care about `Ok(index)` values returned\\n-        \/\/ from the binary search. However, safepoints are inserted right before\\n-        \/\/ calls, and there are two things that can disturb the PC\/offset\\n-        \/\/ associated with the safepoint versus the PC we actually use to query\\n-        \/\/ for the stack map:\\n-        \/\/\\n-        \/\/ 1. The `backtrace` crate gives us the PC in a frame that will be\\n-        \/\/    *returned to*, and where execution will continue from, rather than\\n-        \/\/    the PC of the call we are currently at. So we would need to\\n-        \/\/    disassemble one instruction backwards to query the actual PC for\\n-        \/\/    the stack map.\\n-        \/\/\\n-        \/\/    TODO: One thing we *could* do to make this a little less error\\n-        \/\/    prone, would be to assert\/check that the nearest GC safepoint\\n-        \/\/    found is within `max_encoded_size(any kind of call instruction)`\\n-        \/\/    our queried PC for the target architecture.\\n-        \/\/\\n-        \/\/ 2. Cranelift\\'s stack maps only handle the stack, not\\n-        \/\/    registers. However, some references that are arguments to a call\\n-        \/\/    may need to be in registers. In these cases, what Cranelift will\\n-        \/\/    do is:\\n-        \/\/\\n-        \/\/      a. spill all the live references,\\n-        \/\/      b. insert a GC safepoint for those references,\\n-        \/\/      c. reload the references into registers, and finally\\n-        \/\/      d. make the call.\\n-        \/\/\\n-        \/\/    Step (c) adds drift between the GC safepoint and the location of\\n-        \/\/    the call, which is where we actually walk the stack frame and\\n-        \/\/    collect its live references.\\n-        \/\/\\n-        \/\/    Luckily, the spill stack slots for the live references are still\\n-        \/\/    up to date, so we can still find all the on-stack roots.\\n-        \/\/    Furthermore, we do not have a moving GC, so we don\\'t need to worry\\n-        \/\/    whether the following code will reuse the references in registers\\n-        \/\/    (which would not have been updated to point to the moved objects)\\n-        \/\/    or reload from the stack slots (which would have been updated to\\n-        \/\/    point to the moved objects).\\n-\\n         let index = match info\\n             .stack_maps\\n             .binary_search_by_key(&func_offset, |i| i.code_offset)\\n         {\\n-            \/\/ Exact hit.\\n+            \/\/ Found it.\\n             Ok(i) => i,\\n \\n-            \/\/ `Err(0)` means that the associated stack map would have been the\\n-            \/\/ first element in the array if this pc had an associated stack\\n-            \/\/ map, but this pc does not have an associated stack map. This can\\n-            \/\/ only happen inside a Wasm frame if there are no live refs at this\\n-            \/\/ pc.\\n+            \/\/ No stack map associated with this PC.\\n+            \/\/\\n+            \/\/ Because we know we are in Wasm code, and we must be at some kind\\n+            \/\/ of call\/safepoint, then the Cranelift backend must have avoided\\n+            \/\/ emitting a stack map for this location because no refs were live.\\n+            #[cfg(not(feature = \"old-x86-backend\"))]\\n+            Err(_) => return None,\\n+\\n+            \/\/ ### Old x86_64 backend specific code.\\n+            \/\/\\n+            \/\/ Because GC safepoints are technically only associated with a\\n+            \/\/ single PC, we should ideally only care about `Ok(index)` values\\n+            \/\/ returned from the binary search. However, safepoints are inserted\\n+            \/\/ right before calls, and there are two things that can disturb the\\n+            \/\/ PC\/offset associated with the safepoint versus the PC we actually\\n+            \/\/ use to query for the stack map:\\n+            \/\/\\n+            \/\/ 1. The `backtrace` crate gives us the PC in a frame that will be\\n+            \/\/    *returned to*, and where execution will continue from, rather than\\n+            \/\/    the PC of the call we are currently at. So we would need to\\n+            \/\/    disassemble one instruction backwards to query the actual PC for\\n+            \/\/    the stack map.\\n+            \/\/\\n+            \/\/    TODO: One thing we *could* do to make this a little less error\\n+            \/\/    prone, would be to assert\/check that the nearest GC safepoint\\n+            \/\/    found is within `max_encoded_size(any kind of call instruction)`\\n+            \/\/    our queried PC for the target architecture.\\n+            \/\/\\n+            \/\/ 2. Cranelift\\'s stack maps only handle the stack, not\\n+            \/\/    registers. However, some references that are arguments to a call\\n+            \/\/    may need to be in registers. In these cases, what Cranelift will\\n+            \/\/    do is:\\n+            \/\/\\n+            \/\/      a. spill all the live references,\\n+            \/\/      b. insert a GC safepoint for those references,\\n+            \/\/      c. reload the references into registers, and finally\\n+            \/\/      d. make the call.\\n+            \/\/\\n+            \/\/    Step (c) adds drift between the GC safepoint and the location of\\n+            \/\/    the call, which is where we actually walk the stack frame and\\n+            \/\/    collect its live references.\\n+            \/\/\\n+            \/\/    Luckily, the spill stack slots for the live references are still\\n+            \/\/    up to date, so we can still find all the on-stack roots.\\n+            \/\/    Furthermore, we do not have a moving GC, so we don\\'t need to worry\\n+            \/\/    whether the following code will reuse the references in registers\\n+            \/\/    (which would not have been updated to point to the moved objects)\\n+            \/\/    or reload from the stack slots (which would have been updated to\\n+            \/\/    point to the moved objects).\\n+            #[cfg(feature = \"old-x86-backend\")]\\n             Err(0) => return None,\\n-\\n+            #[cfg(feature = \"old-x86-backend\")]\\n             Err(i) => i - 1,\\n         };'}}",
      "message_norm":"merge pull request from ghsa-4873-36h9-wv49\n\nstop doing fuzzy search for stack maps",
      "language":"en",
      "entities":"[('ghsa-4873-36h9-wv49', 'VULNID', 'GHSA'), ('fuzzy', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['crates\/wasmtime\/src\/module\/registry.rs'])",
      "num_files":1.0,
      "patch_content":"From ec4e48d4cbc28bcfd99e25842a90704e765b800f Mon Sep 17 00:00:00 2001\nFrom: Nick Fitzgerald <fitzgen@gmail.com>\nDate: Wed, 1 Sep 2021 15:40:18 -0700\nSubject: [PATCH] Stop doing fuzzy search for stack maps\n\nThe new backends will not emit a stack map for a safepoint if there are zero\nlive references. Our fuzzy search for stack maps, which was necessary for the\nold backend, caused us to use the wrong stack map for some PCs which would in\nturn cause us to treat arbitrary stack slots as reference types pointers.\n---\n crates\/wasmtime\/src\/module\/registry.rs | 100 +++++++++++++------------\n 1 file changed, 52 insertions(+), 48 deletions(-)\n\ndiff --git a\/crates\/wasmtime\/src\/module\/registry.rs b\/crates\/wasmtime\/src\/module\/registry.rs\nindex 08ebacdbe78e..89f851c488bf 100644\n--- a\/crates\/wasmtime\/src\/module\/registry.rs\n+++ b\/crates\/wasmtime\/src\/module\/registry.rs\n@@ -122,61 +122,65 @@ impl ModuleInfo for RegisteredModule {\n         let info = self.module.func_info(index);\n \n         \/\/ Do a binary search to find the stack map for the given offset.\n-        \/\/\n-        \/\/ Because GC safepoints are technically only associated with a single\n-        \/\/ PC, we should ideally only care about `Ok(index)` values returned\n-        \/\/ from the binary search. However, safepoints are inserted right before\n-        \/\/ calls, and there are two things that can disturb the PC\/offset\n-        \/\/ associated with the safepoint versus the PC we actually use to query\n-        \/\/ for the stack map:\n-        \/\/\n-        \/\/ 1. The `backtrace` crate gives us the PC in a frame that will be\n-        \/\/    *returned to*, and where execution will continue from, rather than\n-        \/\/    the PC of the call we are currently at. So we would need to\n-        \/\/    disassemble one instruction backwards to query the actual PC for\n-        \/\/    the stack map.\n-        \/\/\n-        \/\/    TODO: One thing we *could* do to make this a little less error\n-        \/\/    prone, would be to assert\/check that the nearest GC safepoint\n-        \/\/    found is within `max_encoded_size(any kind of call instruction)`\n-        \/\/    our queried PC for the target architecture.\n-        \/\/\n-        \/\/ 2. Cranelift's stack maps only handle the stack, not\n-        \/\/    registers. However, some references that are arguments to a call\n-        \/\/    may need to be in registers. In these cases, what Cranelift will\n-        \/\/    do is:\n-        \/\/\n-        \/\/      a. spill all the live references,\n-        \/\/      b. insert a GC safepoint for those references,\n-        \/\/      c. reload the references into registers, and finally\n-        \/\/      d. make the call.\n-        \/\/\n-        \/\/    Step (c) adds drift between the GC safepoint and the location of\n-        \/\/    the call, which is where we actually walk the stack frame and\n-        \/\/    collect its live references.\n-        \/\/\n-        \/\/    Luckily, the spill stack slots for the live references are still\n-        \/\/    up to date, so we can still find all the on-stack roots.\n-        \/\/    Furthermore, we do not have a moving GC, so we don't need to worry\n-        \/\/    whether the following code will reuse the references in registers\n-        \/\/    (which would not have been updated to point to the moved objects)\n-        \/\/    or reload from the stack slots (which would have been updated to\n-        \/\/    point to the moved objects).\n-\n         let index = match info\n             .stack_maps\n             .binary_search_by_key(&func_offset, |i| i.code_offset)\n         {\n-            \/\/ Exact hit.\n+            \/\/ Found it.\n             Ok(i) => i,\n \n-            \/\/ `Err(0)` means that the associated stack map would have been the\n-            \/\/ first element in the array if this pc had an associated stack\n-            \/\/ map, but this pc does not have an associated stack map. This can\n-            \/\/ only happen inside a Wasm frame if there are no live refs at this\n-            \/\/ pc.\n+            \/\/ No stack map associated with this PC.\n+            \/\/\n+            \/\/ Because we know we are in Wasm code, and we must be at some kind\n+            \/\/ of call\/safepoint, then the Cranelift backend must have avoided\n+            \/\/ emitting a stack map for this location because no refs were live.\n+            #[cfg(not(feature = \"old-x86-backend\"))]\n+            Err(_) => return None,\n+\n+            \/\/ ### Old x86_64 backend specific code.\n+            \/\/\n+            \/\/ Because GC safepoints are technically only associated with a\n+            \/\/ single PC, we should ideally only care about `Ok(index)` values\n+            \/\/ returned from the binary search. However, safepoints are inserted\n+            \/\/ right before calls, and there are two things that can disturb the\n+            \/\/ PC\/offset associated with the safepoint versus the PC we actually\n+            \/\/ use to query for the stack map:\n+            \/\/\n+            \/\/ 1. The `backtrace` crate gives us the PC in a frame that will be\n+            \/\/    *returned to*, and where execution will continue from, rather than\n+            \/\/    the PC of the call we are currently at. So we would need to\n+            \/\/    disassemble one instruction backwards to query the actual PC for\n+            \/\/    the stack map.\n+            \/\/\n+            \/\/    TODO: One thing we *could* do to make this a little less error\n+            \/\/    prone, would be to assert\/check that the nearest GC safepoint\n+            \/\/    found is within `max_encoded_size(any kind of call instruction)`\n+            \/\/    our queried PC for the target architecture.\n+            \/\/\n+            \/\/ 2. Cranelift's stack maps only handle the stack, not\n+            \/\/    registers. However, some references that are arguments to a call\n+            \/\/    may need to be in registers. In these cases, what Cranelift will\n+            \/\/    do is:\n+            \/\/\n+            \/\/      a. spill all the live references,\n+            \/\/      b. insert a GC safepoint for those references,\n+            \/\/      c. reload the references into registers, and finally\n+            \/\/      d. make the call.\n+            \/\/\n+            \/\/    Step (c) adds drift between the GC safepoint and the location of\n+            \/\/    the call, which is where we actually walk the stack frame and\n+            \/\/    collect its live references.\n+            \/\/\n+            \/\/    Luckily, the spill stack slots for the live references are still\n+            \/\/    up to date, so we can still find all the on-stack roots.\n+            \/\/    Furthermore, we do not have a moving GC, so we don't need to worry\n+            \/\/    whether the following code will reuse the references in registers\n+            \/\/    (which would not have been updated to point to the moved objects)\n+            \/\/    or reload from the stack slots (which would have been updated to\n+            \/\/    point to the moved objects).\n+            #[cfg(feature = \"old-x86-backend\")]\n             Err(0) => return None,\n-\n+            #[cfg(feature = \"old-x86-backend\")]\n             Err(i) => i - 1,\n         };",
      "code_diff":"@@ -122,61 +122,65 @@ impl ModuleInfo for RegisteredModule {\n         let info = self.module.func_info(index);\n \n         \/\/ Do a binary search to find the stack map for the given offset.\n-        \/\/\n-        \/\/ Because GC safepoints are technically only associated with a single\n-        \/\/ PC, we should ideally only care about `Ok(index)` values returned\n-        \/\/ from the binary search. However, safepoints are inserted right before\n-        \/\/ calls, and there are two things that can disturb the PC\/offset\n-        \/\/ associated with the safepoint versus the PC we actually use to query\n-        \/\/ for the stack map:\n-        \/\/\n-        \/\/ 1. The `backtrace` crate gives us the PC in a frame that will be\n-        \/\/    *returned to*, and where execution will continue from, rather than\n-        \/\/    the PC of the call we are currently at. So we would need to\n-        \/\/    disassemble one instruction backwards to query the actual PC for\n-        \/\/    the stack map.\n-        \/\/\n-        \/\/    TODO: One thing we *could* do to make this a little less error\n-        \/\/    prone, would be to assert\/check that the nearest GC safepoint\n-        \/\/    found is within `max_encoded_size(any kind of call instruction)`\n-        \/\/    our queried PC for the target architecture.\n-        \/\/\n-        \/\/ 2. Cranelift's stack maps only handle the stack, not\n-        \/\/    registers. However, some references that are arguments to a call\n-        \/\/    may need to be in registers. In these cases, what Cranelift will\n-        \/\/    do is:\n-        \/\/\n-        \/\/      a. spill all the live references,\n-        \/\/      b. insert a GC safepoint for those references,\n-        \/\/      c. reload the references into registers, and finally\n-        \/\/      d. make the call.\n-        \/\/\n-        \/\/    Step (c) adds drift between the GC safepoint and the location of\n-        \/\/    the call, which is where we actually walk the stack frame and\n-        \/\/    collect its live references.\n-        \/\/\n-        \/\/    Luckily, the spill stack slots for the live references are still\n-        \/\/    up to date, so we can still find all the on-stack roots.\n-        \/\/    Furthermore, we do not have a moving GC, so we don't need to worry\n-        \/\/    whether the following code will reuse the references in registers\n-        \/\/    (which would not have been updated to point to the moved objects)\n-        \/\/    or reload from the stack slots (which would have been updated to\n-        \/\/    point to the moved objects).\n-\n         let index = match info\n             .stack_maps\n             .binary_search_by_key(&func_offset, |i| i.code_offset)\n         {\n-            \/\/ Exact hit.\n+            \/\/ Found it.\n             Ok(i) => i,\n \n-            \/\/ `Err(0)` means that the associated stack map would have been the\n-            \/\/ first element in the array if this pc had an associated stack\n-            \/\/ map, but this pc does not have an associated stack map. This can\n-            \/\/ only happen inside a Wasm frame if there are no live refs at this\n-            \/\/ pc.\n+            \/\/ No stack map associated with this PC.\n+            \/\/\n+            \/\/ Because we know we are in Wasm code, and we must be at some kind\n+            \/\/ of call\/safepoint, then the Cranelift backend must have avoided\n+            \/\/ emitting a stack map for this location because no refs were live.\n+            #[cfg(not(feature = \"old-x86-backend\"))]\n+            Err(_) => return None,\n+\n+            \/\/ ### Old x86_64 backend specific code.\n+            \/\/\n+            \/\/ Because GC safepoints are technically only associated with a\n+            \/\/ single PC, we should ideally only care about `Ok(index)` values\n+            \/\/ returned from the binary search. However, safepoints are inserted\n+            \/\/ right before calls, and there are two things that can disturb the\n+            \/\/ PC\/offset associated with the safepoint versus the PC we actually\n+            \/\/ use to query for the stack map:\n+            \/\/\n+            \/\/ 1. The `backtrace` crate gives us the PC in a frame that will be\n+            \/\/    *returned to*, and where execution will continue from, rather than\n+            \/\/    the PC of the call we are currently at. So we would need to\n+            \/\/    disassemble one instruction backwards to query the actual PC for\n+            \/\/    the stack map.\n+            \/\/\n+            \/\/    TODO: One thing we *could* do to make this a little less error\n+            \/\/    prone, would be to assert\/check that the nearest GC safepoint\n+            \/\/    found is within `max_encoded_size(any kind of call instruction)`\n+            \/\/    our queried PC for the target architecture.\n+            \/\/\n+            \/\/ 2. Cranelift's stack maps only handle the stack, not\n+            \/\/    registers. However, some references that are arguments to a call\n+            \/\/    may need to be in registers. In these cases, what Cranelift will\n+            \/\/    do is:\n+            \/\/\n+            \/\/      a. spill all the live references,\n+            \/\/      b. insert a GC safepoint for those references,\n+            \/\/      c. reload the references into registers, and finally\n+            \/\/      d. make the call.\n+            \/\/\n+            \/\/    Step (c) adds drift between the GC safepoint and the location of\n+            \/\/    the call, which is where we actually walk the stack frame and\n+            \/\/    collect its live references.\n+            \/\/\n+            \/\/    Luckily, the spill stack slots for the live references are still\n+            \/\/    up to date, so we can still find all the on-stack roots.\n+            \/\/    Furthermore, we do not have a moving GC, so we don't need to worry\n+            \/\/    whether the following code will reuse the references in registers\n+            \/\/    (which would not have been updated to point to the moved objects)\n+            \/\/    or reload from the stack slots (which would have been updated to\n+            \/\/    point to the moved objects).\n+            #[cfg(feature = \"old-x86-backend\")]\n             Err(0) => return None,\n-\n+            #[cfg(feature = \"old-x86-backend\")]\n             Err(i) => i - 1,\n         };"
    },
    {
      "index":2,
      "vuln_id":"GHSA-24x6-8c7m-hv3f",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/953f28dca13c92839ba389c055587cfe6c723578'}",
      "dataset":"osv",
      "summary":"Heap OOB read in TFLite's implementation of `Minimum` or `Maximum` ### Impact\nThe implementations of the `Minimum` and `Maximum` TFLite operators can be used to read data outside of bounds of heap allocated objects, if any of the two input tensor arguments are empty.\n\nThis is because [the broadcasting implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7\/tensorflow\/lite\/kernels\/internal\/reference\/maximum_minimum.h#L52-L56) indexes in both tensors with the same index but does not validate that the index is within bounds:\n\n```cc\nauto maxmin_func = [&](int indexes[N]) {\n  output_data[SubscriptToIndex(output_desc, indexes)] =\n    op(input1_data[SubscriptToIndex(desc1, indexes)],\n        input2_data[SubscriptToIndex(desc2, indexes)]);\n};\n```\n\n### Patches\nWe have patched the issue in GitHub commit [953f28dca13c92839ba389c055587cfe6c723578](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/953f28dca13c92839ba389c055587cfe6c723578).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/953f28dca13c92839ba389c055587cfe6c723578",
      "commit_sha":"953f28dca13c92839ba389c055587cfe6c723578",
      "patch":"SINGLE",
      "chain_ord":"['953f28dca13c92839ba389c055587cfe6c723578']",
      "before_first_fix_commit":"{'801c1c6be5324219689c98e1bd3e0ca365ee834d'}",
      "last_fix_commit":"953f28dca13c92839ba389c055587cfe6c723578",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/28\/2021, 00:46:38",
      "message":"Prevent a null pointer exception in TFLite\n\nPiperOrigin-RevId: 370800206\nChange-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 31, 'deletions': 29, 'total': 60}",
      "files":"{'tensorflow\/lite\/kernels\/maximum_minimum.cc': {'additions': 31, 'deletions': 29, 'changes': 60, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/953f28dca13c92839ba389c055587cfe6c723578\/tensorflow%2Flite%2Fkernels%2Fmaximum_minimum.cc', 'patch': '@@ -157,35 +157,37 @@ template <KernelType kernel_type, typename OpType>\\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   OpContext op_context(context, node);\\n \\n-    switch (op_context.output->type) {\\n-      case kTfLiteFloat32:\\n-        TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\\n-        break;\\n-      case kTfLiteUInt8:\\n-        TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,\\n-                                                      op_context);\\n-        break;\\n-      case kTfLiteInt8:\\n-        TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\\n-        break;\\n-      case kTfLiteInt32:\\n-        TFLiteOperation<kernel_type, int32_t, OpType>(context, node,\\n-                                                      op_context);\\n-        break;\\n-      case kTfLiteInt64:\\n-        TFLiteOperation<kernel_type, int64_t, OpType>(context, node,\\n-                                                      op_context);\\n-        break;\\n-      case kTfLiteInt16:\\n-        TFLiteOperation<kernel_type, int16_t, OpType>(context, node,\\n-                                                      op_context);\\n-        break;\\n-      default:\\n-        context->ReportError(context,\\n-                             \"Type %d is currently not supported by Maximum.\",\\n-                             op_context.output->type);\\n-        return kTfLiteError;\\n-    }\\n+  \/\/ If inputs have no element, shortcircuit.\\n+  if (NumElements(op_context.input1) == 0 ||\\n+      NumElements(op_context.input2) == 0) {\\n+    return kTfLiteOk;\\n+  }\\n+\\n+  switch (op_context.output->type) {\\n+    case kTfLiteFloat32:\\n+      TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteUInt8:\\n+      TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteInt8:\\n+      TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteInt32:\\n+      TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteInt64:\\n+      TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);\\n+      break;\\n+    case kTfLiteInt16:\\n+      TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);\\n+      break;\\n+    default:\\n+      context->ReportError(context,\\n+                           \"Type %d is currently not supported by Maximum.\",\\n+                           op_context.output->type);\\n+      return kTfLiteError;\\n+  }\\n   return kTfLiteOk;\\n }'}}",
      "message_norm":"prevent a null pointer exception in tflite\n\npiperorigin-revid: 370800206\nchange-id: idd437ebce4ff224120d8eefc1c14c062173b71d6",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('null pointer exception', 'SECWORD', ''), ('370800206', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/maximum_minimum.cc'])",
      "num_files":1.0,
      "patch_content":"From 953f28dca13c92839ba389c055587cfe6c723578 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 27 Apr 2021 17:46:38 -0700\nSubject: [PATCH] Prevent a null pointer exception in TFLite\n\nPiperOrigin-RevId: 370800206\nChange-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6\n---\n tensorflow\/lite\/kernels\/maximum_minimum.cc | 60 +++++++++++-----------\n 1 file changed, 31 insertions(+), 29 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/maximum_minimum.cc b\/tensorflow\/lite\/kernels\/maximum_minimum.cc\nindex 777e51442f120e..176e020a5a8e55 100644\n--- a\/tensorflow\/lite\/kernels\/maximum_minimum.cc\n+++ b\/tensorflow\/lite\/kernels\/maximum_minimum.cc\n@@ -157,35 +157,37 @@ template <KernelType kernel_type, typename OpType>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpContext op_context(context, node);\n \n-    switch (op_context.output->type) {\n-      case kTfLiteFloat32:\n-        TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\n-        break;\n-      case kTfLiteUInt8:\n-        TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt8:\n-        TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\n-        break;\n-      case kTfLiteInt32:\n-        TFLiteOperation<kernel_type, int32_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt64:\n-        TFLiteOperation<kernel_type, int64_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt16:\n-        TFLiteOperation<kernel_type, int16_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      default:\n-        context->ReportError(context,\n-                             \"Type %d is currently not supported by Maximum.\",\n-                             op_context.output->type);\n-        return kTfLiteError;\n-    }\n+  \/\/ If inputs have no element, shortcircuit.\n+  if (NumElements(op_context.input1) == 0 ||\n+      NumElements(op_context.input2) == 0) {\n+    return kTfLiteOk;\n+  }\n+\n+  switch (op_context.output->type) {\n+    case kTfLiteFloat32:\n+      TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteUInt8:\n+      TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt8:\n+      TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt32:\n+      TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt64:\n+      TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt16:\n+      TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);\n+      break;\n+    default:\n+      context->ReportError(context,\n+                           \"Type %d is currently not supported by Maximum.\",\n+                           op_context.output->type);\n+      return kTfLiteError;\n+  }\n   return kTfLiteOk;\n }",
      "code_diff":"@@ -157,35 +157,37 @@ template <KernelType kernel_type, typename OpType>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   OpContext op_context(context, node);\n \n-    switch (op_context.output->type) {\n-      case kTfLiteFloat32:\n-        TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\n-        break;\n-      case kTfLiteUInt8:\n-        TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt8:\n-        TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\n-        break;\n-      case kTfLiteInt32:\n-        TFLiteOperation<kernel_type, int32_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt64:\n-        TFLiteOperation<kernel_type, int64_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      case kTfLiteInt16:\n-        TFLiteOperation<kernel_type, int16_t, OpType>(context, node,\n-                                                      op_context);\n-        break;\n-      default:\n-        context->ReportError(context,\n-                             \"Type %d is currently not supported by Maximum.\",\n-                             op_context.output->type);\n-        return kTfLiteError;\n-    }\n+  \/\/ If inputs have no element, shortcircuit.\n+  if (NumElements(op_context.input1) == 0 ||\n+      NumElements(op_context.input2) == 0) {\n+    return kTfLiteOk;\n+  }\n+\n+  switch (op_context.output->type) {\n+    case kTfLiteFloat32:\n+      TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteUInt8:\n+      TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt8:\n+      TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt32:\n+      TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt64:\n+      TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);\n+      break;\n+    case kTfLiteInt16:\n+      TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);\n+      break;\n+    default:\n+      context->ReportError(context,\n+                           \"Type %d is currently not supported by Maximum.\",\n+                           op_context.output->type);\n+      return kTfLiteError;\n+  }\n   return kTfLiteOk;\n }"
    },
    {
      "index":3,
      "vuln_id":"GHSA-rg3m-hqc5-344v",
      "cwe_id":"{'CWE-125'}",
      "score":7.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67bfd9feeecfb3c61d80f0e46d89c170fbee682b'}",
      "dataset":"osv",
      "summary":"`SparseFillEmptyRows` heap OOB ### Impact\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e71b86d47f8bc1816bf54d7bddc4170e47670b97\/tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc#L194-L241) of `SparseFillEmptyRows` can be made to trigger a heap OOB access:\n\n```python\nimport tensorflow as tf\n  \ndata=tf.raw_ops.SparseFillEmptyRows(\n  indices=[[0,0],[0,0],[0,0]],\n  values=['sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss'],\n  dense_shape=[5,3],\n  default_value='o')\n```\n  \nThis occurs whenever the size of `indices` does not match the size of `values`.\n\n### Patches\nWe have patched the issue in GitHub commit [67bfd9feeecfb3c61d80f0e46d89c170fbee682b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67bfd9feeecfb3c61d80f0e46d89c170fbee682b).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-11-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
      "commit_sha":"67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
      "patch":"SINGLE",
      "chain_ord":"['67bfd9feeecfb3c61d80f0e46d89c170fbee682b']",
      "before_first_fix_commit":"{'421fba8888bb8f8724bc2e35ca2fdcde16e1bfe5'}",
      "last_fix_commit":"67bfd9feeecfb3c61d80f0e46d89c170fbee682b",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/30\/2021, 17:44:33",
      "message":"Make SparseFillEmptyRows validate that the length of `values` must be equal to the number of index tuples.\n\nPiperOrigin-RevId: 399969549\nChange-Id: I3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8",
      "author":"Penporn Koanantakool",
      "comments":null,
      "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
      "files":"{'tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/67bfd9feeecfb3c61d80f0e46d89c170fbee682b\/tensorflow%2Fcore%2Fkernels%2Fsparse_fill_empty_rows_op.cc', 'patch': '@@ -24,11 +24,13 @@ limitations under the License.\\n #include <vector>\\n \\n #include \"tensorflow\/core\/framework\/op_kernel.h\"\\n+#include \"tensorflow\/core\/framework\/op_requires.h\"\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_util.h\"\\n #include \"tensorflow\/core\/framework\/types.h\"\\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/util\/sparse\/sparse_tensor.h\"\\n \\n namespace tensorflow {\\n@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\\n                     errors::InvalidArgument(\"values must be a vector, saw: \",\\n                                             values_t.shape().DebugString()),\\n                     done);\\n+  OP_REQUIRES_ASYNC(\\n+      context, indices_t.dim_size(0) == values_t.dim_size(0),\\n+      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\\n+                              \") must match the first dimension of `indices` (\",\\n+                              indices_t.dim_size(0), \").\"),\\n+      done);\\n   OP_REQUIRES_ASYNC(\\n       context, TensorShapeUtils::IsScalar(default_value_t.shape()),\\n       errors::InvalidArgument(\"default_value must be a scalar, saw: \",'}}",
      "message_norm":"make sparsefillemptyrows validate that the length of `values` must be equal to the number of index tuples.\n\npiperorigin-revid: 399969549\nchange-id: i3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8",
      "language":"en",
      "entities":"[('validate', 'ACTION', ''), ('399969549', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 67bfd9feeecfb3c61d80f0e46d89c170fbee682b Mon Sep 17 00:00:00 2001\nFrom: Penporn Koanantakool <penporn@google.com>\nDate: Thu, 30 Sep 2021 10:44:33 -0700\nSubject: [PATCH] Make SparseFillEmptyRows validate that the length of `values`\n must be equal to the number of index tuples.\n\nPiperOrigin-RevId: 399969549\nChange-Id: I3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8\n---\n tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc | 8 ++++++++\n 1 file changed, 8 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc b\/tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc\nindex e0c7e18090b66d..59eb6076ed528b 100644\n--- a\/tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_fill_empty_rows_op.cc\n@@ -24,11 +24,13 @@ limitations under the License.\n #include <vector>\n \n #include \"tensorflow\/core\/framework\/op_kernel.h\"\n+#include \"tensorflow\/core\/framework\/op_requires.h\"\n #include \"tensorflow\/core\/framework\/register_types.h\"\n #include \"tensorflow\/core\/framework\/tensor.h\"\n #include \"tensorflow\/core\/framework\/tensor_util.h\"\n #include \"tensorflow\/core\/framework\/types.h\"\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/util\/sparse\/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                     errors::InvalidArgument(\"values must be a vector, saw: \",\n                                             values_t.shape().DebugString()),\n                     done);\n+  OP_REQUIRES_ASYNC(\n+      context, indices_t.dim_size(0) == values_t.dim_size(0),\n+      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\n+                              \") must match the first dimension of `indices` (\",\n+                              indices_t.dim_size(0), \").\"),\n+      done);\n   OP_REQUIRES_ASYNC(\n       context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n       errors::InvalidArgument(\"default_value must be a scalar, saw: \",",
      "code_diff":"@@ -24,11 +24,13 @@ limitations under the License.\n #include <vector>\n \n #include \"tensorflow\/core\/framework\/op_kernel.h\"\n+#include \"tensorflow\/core\/framework\/op_requires.h\"\n #include \"tensorflow\/core\/framework\/register_types.h\"\n #include \"tensorflow\/core\/framework\/tensor.h\"\n #include \"tensorflow\/core\/framework\/tensor_util.h\"\n #include \"tensorflow\/core\/framework\/types.h\"\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/util\/sparse\/sparse_tensor.h\"\n \n namespace tensorflow {\n@@ -222,6 +224,12 @@ void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                     errors::InvalidArgument(\"values must be a vector, saw: \",\n                                             values_t.shape().DebugString()),\n                     done);\n+  OP_REQUIRES_ASYNC(\n+      context, indices_t.dim_size(0) == values_t.dim_size(0),\n+      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\n+                              \") must match the first dimension of `indices` (\",\n+                              indices_t.dim_size(0), \").\"),\n+      done);\n   OP_REQUIRES_ASYNC(\n       context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n       errors::InvalidArgument(\"default_value must be a scalar, saw: \","
    },
    {
      "index":4,
      "vuln_id":"GHSA-4f99-p9c2-3j8x",
      "cwe_id":"{'CWE-125', 'CWE-824'}",
      "score":7.8,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae'}",
      "dataset":"osv",
      "summary":"Undefined behavior via `nullptr` reference binding in sparse matrix multiplication ### Impact\nThe [code for sparse matrix multiplication](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/sparse_matmul_op.cc#L954-L1086) is vulnerable to undefined behavior via binding a reference to `nullptr`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.SparseMatMul(\n  a=[[1.0,1.0,1.0]],\n  b=[[],[],[]],\n  transpose_a=False,\n  transpose_b=False,\n  a_is_sparse=False, \n  b_is_sparse=True)\n```\n\nThis occurs whenever the dimensions of `a` or `b` are 0 or less. In the case on one of these is 0, an empty output tensor should be allocated (to conserve the invariant that output tensors are always allocated when the operation is successful) but nothing should be written to it (that is, we should return early from the kernel implementation). Otherwise, attempts to write to this empty tensor would result in heap OOB access.\n\n### Patches\nWe have patched the issue in GitHub commit [e6cf28c72ba2eb949ca950d834dd6d66bb01cfae](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-11-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
      "commit_sha":"e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
      "patch":"SINGLE",
      "chain_ord":"['e6cf28c72ba2eb949ca950d834dd6d66bb01cfae']",
      "before_first_fix_commit":"{'d4fdd7830befb1f3aed8b4d1681471531856ae77'}",
      "last_fix_commit":"e6cf28c72ba2eb949ca950d834dd6d66bb01cfae",
      "chain_ord_pos":1.0,
      "commit_datetime":"10\/06\/2021, 04:54:15",
      "message":"Validate that matrix dimension sizes in SparseMatMul are positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d",
      "author":"Penporn Koanantakool",
      "comments":null,
      "stats":"{'additions': 10, 'deletions': 0, 'total': 10}",
      "files":"{'tensorflow\/core\/kernels\/sparse_matmul_op.cc': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae\/tensorflow%2Fcore%2Fkernels%2Fsparse_matmul_op.cc', 'patch': '@@ -32,6 +32,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/kernels\/fill_functor.h\"\\n #include \"tensorflow\/core\/lib\/core\/blocking_counter.h\"\\n #include \"tensorflow\/core\/lib\/core\/threadpool.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/platform\/logging.h\"\\n #include \"tensorflow\/core\/platform\/macros.h\"\\n #include \"tensorflow\/core\/platform\/mutex.h\"\\n@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {\\n                 errors::InvalidArgument(\\n                     \"Matrix size incompatible: a: \", a.shape().DebugString(),\\n                     \", b: \", b.shape().DebugString()));\\n+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\\n+                errors::InvalidArgument(\\n+                    \"Matrix dimensions cannot be negative: a: \",\\n+                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\\n \\n+    \/\/ Return early if at least one of the output dimension size is 0.\\n+    if (m == 0 || n == 0) {\\n+      return;\\n+    }\\n+\\n     if (k == 0) {\\n       \/\/ If the inner dimension k in the matrix multiplication is zero, we fill\\n       \/\/ the output with zeros.'}}",
      "message_norm":"validate that matrix dimension sizes in sparsematmul are positive.\n\npiperorigin-revid: 401149683\nchange-id: ib33eafc561a39c8741ece80b2edce6d4aae9a57d",
      "language":"en",
      "entities":"[('validate', 'ACTION', ''), ('401149683', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_matmul_op.cc'])",
      "num_files":1.0,
      "patch_content":"From e6cf28c72ba2eb949ca950d834dd6d66bb01cfae Mon Sep 17 00:00:00 2001\nFrom: Penporn Koanantakool <penporn@google.com>\nDate: Tue, 5 Oct 2021 21:54:15 -0700\nSubject: [PATCH] Validate that matrix dimension sizes in SparseMatMul are\n positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d\n---\n tensorflow\/core\/kernels\/sparse_matmul_op.cc | 10 ++++++++++\n 1 file changed, 10 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_matmul_op.cc b\/tensorflow\/core\/kernels\/sparse_matmul_op.cc\nindex a02afafa33e3ad..6bf9dfa3d8bb75 100644\n--- a\/tensorflow\/core\/kernels\/sparse_matmul_op.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_matmul_op.cc\n@@ -32,6 +32,7 @@ limitations under the License.\n #include \"tensorflow\/core\/kernels\/fill_functor.h\"\n #include \"tensorflow\/core\/lib\/core\/blocking_counter.h\"\n #include \"tensorflow\/core\/lib\/core\/threadpool.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/logging.h\"\n #include \"tensorflow\/core\/platform\/macros.h\"\n #include \"tensorflow\/core\/platform\/mutex.h\"\n@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                     \", b: \", b.shape().DebugString()));\n+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\n+                errors::InvalidArgument(\n+                    \"Matrix dimensions cannot be negative: a: \",\n+                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n \n+    \/\/ Return early if at least one of the output dimension size is 0.\n+    if (m == 0 || n == 0) {\n+      return;\n+    }\n+\n     if (k == 0) {\n       \/\/ If the inner dimension k in the matrix multiplication is zero, we fill\n       \/\/ the output with zeros.",
      "code_diff":"@@ -32,6 +32,7 @@ limitations under the License.\n #include \"tensorflow\/core\/kernels\/fill_functor.h\"\n #include \"tensorflow\/core\/lib\/core\/blocking_counter.h\"\n #include \"tensorflow\/core\/lib\/core\/threadpool.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/logging.h\"\n #include \"tensorflow\/core\/platform\/macros.h\"\n #include \"tensorflow\/core\/platform\/mutex.h\"\n@@ -980,9 +981,18 @@ class SparseMatMulOp : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                     \", b: \", b.shape().DebugString()));\n+    OP_REQUIRES(ctx, m >= 0 && n >= 0 && k >= 0,\n+                errors::InvalidArgument(\n+                    \"Matrix dimensions cannot be negative: a: \",\n+                    a.shape().DebugString(), \", b: \", b.shape().DebugString()));\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n \n+    \/\/ Return early if at least one of the output dimension size is 0.\n+    if (m == 0 || n == 0) {\n+      return;\n+    }\n+\n     if (k == 0) {\n       \/\/ If the inner dimension k in the matrix multiplication is zero, we fill\n       \/\/ the output with zeros."
    },
    {
      "index":5,
      "vuln_id":"GHSA-jwf9-w5xm-f437",
      "cwe_id":"{'CWE-125'}",
      "score":5.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f'}",
      "dataset":"osv",
      "summary":"Heap OOB in TFLite's `Gather*` implementations ### Impact\nTFLite's [`GatherNd` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation.\n\nHence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`.\n\nSimilar issue exists in [`Gather` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/gather.cc).\n\n```python\nimport tensorflow as tf\nimport numpy as np\ntf.compat.v1.disable_v2_behavior()\n\nparams = tf.compat.v1.placeholder(name=\"params\", dtype=tf.int64, shape=(1,))\nindices = tf.compat.v1.placeholder(name=\"indices\", dtype=tf.int64, shape=())\n\nout = tf.gather(params, indices, name='out')\n\nwith tf.compat.v1.Session() as sess:\n   converter = tf.compat.v1.lite.TFLiteConverter.from_session(sess, [params, indices], [out])\n   tflite_model = converter.convert()\n\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nparams_data = np.reshape(np.array([1], dtype=np.int64), newshape=(1,))\nindices_data = np.reshape(np.array(-10, dtype=np.int64), newshape=())\ninterpreter.set_tensor(input_details[0]['index'], params_data)\ninterpreter.set_tensor(input_details[1]['index'], indices_data)\n\ninterpreter.invoke()\n```\n\n### Patches\nWe have patched the issue in GitHub commits [bb6a0383ed553c286f87ca88c207f6774d5c4a8f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f) and [eb921122119a6b6e470ee98b89e65d721663179d](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security  guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
      "published_date":"2021-08-25",
      "chain_len":2,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d",
      "commit_sha":"eb921122119a6b6e470ee98b89e65d721663179d",
      "patch":"MULTI",
      "chain_ord":"['bb6a0383ed553c286f87ca88c207f6774d5c4a8f', 'eb921122119a6b6e470ee98b89e65d721663179d']",
      "before_first_fix_commit":"{'ac72971cc6fbbfe4df7e67a8347ef1b6ab63b5fd'}",
      "last_fix_commit":"eb921122119a6b6e470ee98b89e65d721663179d",
      "chain_ord_pos":2.0,
      "commit_datetime":"07\/28\/2021, 00:11:14",
      "message":"Prevent heap OOB read in TFLite's `gather.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387231300\nChange-Id: I3111b54b2f232638d795be17efc46abe4ede6bf8",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 53, 'deletions': 16, 'total': 69}",
      "files":"{'tensorflow\/lite\/kernels\/gather.cc': {'additions': 53, 'deletions': 16, 'changes': 69, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/eb921122119a6b6e470ee98b89e65d721663179d\/tensorflow%2Flite%2Fkernels%2Fgather.cc', 'patch': '@@ -117,8 +117,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\\n }\\n \\n template <typename InputT, typename PositionsT>\\n-TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,\\n-                    const TfLiteTensor* positions, TfLiteTensor* output) {\\n+TfLiteStatus Gather(TfLiteContext* context, const TfLiteGatherParams& params,\\n+                    const TfLiteTensor* input, const TfLiteTensor* positions,\\n+                    TfLiteTensor* output) {\\n+  const PositionsT* indexes = GetTensorData<PositionsT>(positions);\\n+  bool indices_has_only_positive_elements = true;\\n+  const size_t num_indices = positions->bytes \/ sizeof(PositionsT);\\n+  for (size_t i = 0; i < num_indices; i++) {\\n+    if (indexes[i] < 0) {\\n+      indices_has_only_positive_elements = false;\\n+      break;\\n+    }\\n+  }\\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\\n+\\n   tflite::GatherParams op_params;\\n   op_params.axis = params.axis;\\n   op_params.batch_dims = params.batch_dims;\\n@@ -134,7 +146,18 @@ TfLiteStatus GatherStrings(TfLiteContext* context, const TfLiteTensor* input,\\n                            const TfLiteTensor* positions,\\n                            TfLiteTensor* output) {\\n   DynamicBuffer buffer;\\n+\\n   const PositionT* indexes = GetTensorData<PositionT>(positions);\\n+  bool indices_has_only_positive_elements = true;\\n+  const size_t num_indices = positions->bytes \/ sizeof(PositionT);\\n+  for (size_t i = 0; i < num_indices; i++) {\\n+    if (indexes[i] < 0) {\\n+      indices_has_only_positive_elements = false;\\n+      break;\\n+    }\\n+  }\\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\\n+\\n   const PositionT num_strings = GetStringCount(input);\\n   const int num_indexes = NumElements(positions);\\n \\n@@ -163,19 +186,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   if (positions->type == kTfLiteInt32) {\\n     switch (input->type) {\\n       case kTfLiteFloat32:\\n-        return Gather<float, int32_t>(*params, input, positions, output);\\n+        return Gather<float, int32_t>(context, *params, input, positions,\\n+                                      output);\\n       case kTfLiteUInt8:\\n-        return Gather<uint8_t, int32_t>(*params, input, positions, output);\\n+        return Gather<uint8_t, int32_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt8:\\n-        return Gather<int8_t, int32_t>(*params, input, positions, output);\\n+        return Gather<int8_t, int32_t>(context, *params, input, positions,\\n+                                       output);\\n       case kTfLiteInt16:\\n-        return Gather<int16_t, int32_t>(*params, input, positions, output);\\n+        return Gather<int16_t, int32_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt32:\\n-        return Gather<int32_t, int32_t>(*params, input, positions, output);\\n+        return Gather<int32_t, int32_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt64:\\n-        return Gather<int64_t, int32_t>(*params, input, positions, output);\\n+        return Gather<int64_t, int32_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteBool:\\n-        return Gather<bool, int32_t>(*params, input, positions, output);\\n+        return Gather<bool, int32_t>(context, *params, input, positions,\\n+                                     output);\\n       case kTfLiteString:\\n         return GatherStrings<int32_t>(context, input, positions, output);\\n       default:\\n@@ -187,19 +217,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\\n   if (positions->type == kTfLiteInt64) {\\n     switch (input->type) {\\n       case kTfLiteFloat32:\\n-        return Gather<float, int64_t>(*params, input, positions, output);\\n+        return Gather<float, int64_t>(context, *params, input, positions,\\n+                                      output);\\n       case kTfLiteUInt8:\\n-        return Gather<uint8_t, int64_t>(*params, input, positions, output);\\n+        return Gather<uint8_t, int64_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt8:\\n-        return Gather<int8_t, int64_t>(*params, input, positions, output);\\n+        return Gather<int8_t, int64_t>(context, *params, input, positions,\\n+                                       output);\\n       case kTfLiteInt16:\\n-        return Gather<int16_t, int64_t>(*params, input, positions, output);\\n+        return Gather<int16_t, int64_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt32:\\n-        return Gather<int32_t, int64_t>(*params, input, positions, output);\\n+        return Gather<int32_t, int64_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteInt64:\\n-        return Gather<int64_t, int64_t>(*params, input, positions, output);\\n+        return Gather<int64_t, int64_t>(context, *params, input, positions,\\n+                                        output);\\n       case kTfLiteBool:\\n-        return Gather<bool, int64_t>(*params, input, positions, output);\\n+        return Gather<bool, int64_t>(context, *params, input, positions,\\n+                                     output);\\n       case kTfLiteString:\\n         return GatherStrings<int64_t>(context, input, positions, output);\\n       default:'}}",
      "message_norm":"prevent heap oob read in tflite's `gather.cc`.\n\npassing negative indices is illegal but there was a missing check so that resulted in oob accesses.\n\npiperorigin-revid: 387231300\nchange-id: i3111b54b2f232638d795be17efc46abe4ede6bf8",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('missing check', 'SECWORD', ''), ('oob', 'SECWORD', ''), ('387231300', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/gather.cc'])",
      "num_files":1.0,
      "patch_content":"From eb921122119a6b6e470ee98b89e65d721663179d Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 27 Jul 2021 17:11:14 -0700\nSubject: [PATCH] Prevent heap OOB read in TFLite's `gather.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387231300\nChange-Id: I3111b54b2f232638d795be17efc46abe4ede6bf8\n---\n tensorflow\/lite\/kernels\/gather.cc | 69 ++++++++++++++++++++++++-------\n 1 file changed, 53 insertions(+), 16 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/gather.cc b\/tensorflow\/lite\/kernels\/gather.cc\nindex 9fe94821230c00..bdc2139d0fe7a5 100644\n--- a\/tensorflow\/lite\/kernels\/gather.cc\n+++ b\/tensorflow\/lite\/kernels\/gather.cc\n@@ -117,8 +117,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n template <typename InputT, typename PositionsT>\n-TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,\n-                    const TfLiteTensor* positions, TfLiteTensor* output) {\n+TfLiteStatus Gather(TfLiteContext* context, const TfLiteGatherParams& params,\n+                    const TfLiteTensor* input, const TfLiteTensor* positions,\n+                    TfLiteTensor* output) {\n+  const PositionsT* indexes = GetTensorData<PositionsT>(positions);\n+  bool indices_has_only_positive_elements = true;\n+  const size_t num_indices = positions->bytes \/ sizeof(PositionsT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indexes[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   tflite::GatherParams op_params;\n   op_params.axis = params.axis;\n   op_params.batch_dims = params.batch_dims;\n@@ -134,7 +146,18 @@ TfLiteStatus GatherStrings(TfLiteContext* context, const TfLiteTensor* input,\n                            const TfLiteTensor* positions,\n                            TfLiteTensor* output) {\n   DynamicBuffer buffer;\n+\n   const PositionT* indexes = GetTensorData<PositionT>(positions);\n+  bool indices_has_only_positive_elements = true;\n+  const size_t num_indices = positions->bytes \/ sizeof(PositionT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indexes[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   const PositionT num_strings = GetStringCount(input);\n   const int num_indexes = NumElements(positions);\n \n@@ -163,19 +186,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   if (positions->type == kTfLiteInt32) {\n     switch (input->type) {\n       case kTfLiteFloat32:\n-        return Gather<float, int32_t>(*params, input, positions, output);\n+        return Gather<float, int32_t>(context, *params, input, positions,\n+                                      output);\n       case kTfLiteUInt8:\n-        return Gather<uint8_t, int32_t>(*params, input, positions, output);\n+        return Gather<uint8_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt8:\n-        return Gather<int8_t, int32_t>(*params, input, positions, output);\n+        return Gather<int8_t, int32_t>(context, *params, input, positions,\n+                                       output);\n       case kTfLiteInt16:\n-        return Gather<int16_t, int32_t>(*params, input, positions, output);\n+        return Gather<int16_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt32:\n-        return Gather<int32_t, int32_t>(*params, input, positions, output);\n+        return Gather<int32_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt64:\n-        return Gather<int64_t, int32_t>(*params, input, positions, output);\n+        return Gather<int64_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteBool:\n-        return Gather<bool, int32_t>(*params, input, positions, output);\n+        return Gather<bool, int32_t>(context, *params, input, positions,\n+                                     output);\n       case kTfLiteString:\n         return GatherStrings<int32_t>(context, input, positions, output);\n       default:\n@@ -187,19 +217,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   if (positions->type == kTfLiteInt64) {\n     switch (input->type) {\n       case kTfLiteFloat32:\n-        return Gather<float, int64_t>(*params, input, positions, output);\n+        return Gather<float, int64_t>(context, *params, input, positions,\n+                                      output);\n       case kTfLiteUInt8:\n-        return Gather<uint8_t, int64_t>(*params, input, positions, output);\n+        return Gather<uint8_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt8:\n-        return Gather<int8_t, int64_t>(*params, input, positions, output);\n+        return Gather<int8_t, int64_t>(context, *params, input, positions,\n+                                       output);\n       case kTfLiteInt16:\n-        return Gather<int16_t, int64_t>(*params, input, positions, output);\n+        return Gather<int16_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt32:\n-        return Gather<int32_t, int64_t>(*params, input, positions, output);\n+        return Gather<int32_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt64:\n-        return Gather<int64_t, int64_t>(*params, input, positions, output);\n+        return Gather<int64_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteBool:\n-        return Gather<bool, int64_t>(*params, input, positions, output);\n+        return Gather<bool, int64_t>(context, *params, input, positions,\n+                                     output);\n       case kTfLiteString:\n         return GatherStrings<int64_t>(context, input, positions, output);\n       default:",
      "code_diff":"@@ -117,8 +117,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n template <typename InputT, typename PositionsT>\n-TfLiteStatus Gather(const TfLiteGatherParams& params, const TfLiteTensor* input,\n-                    const TfLiteTensor* positions, TfLiteTensor* output) {\n+TfLiteStatus Gather(TfLiteContext* context, const TfLiteGatherParams& params,\n+                    const TfLiteTensor* input, const TfLiteTensor* positions,\n+                    TfLiteTensor* output) {\n+  const PositionsT* indexes = GetTensorData<PositionsT>(positions);\n+  bool indices_has_only_positive_elements = true;\n+  const size_t num_indices = positions->bytes \/ sizeof(PositionsT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indexes[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   tflite::GatherParams op_params;\n   op_params.axis = params.axis;\n   op_params.batch_dims = params.batch_dims;\n@@ -134,7 +146,18 @@ TfLiteStatus GatherStrings(TfLiteContext* context, const TfLiteTensor* input,\n                            const TfLiteTensor* positions,\n                            TfLiteTensor* output) {\n   DynamicBuffer buffer;\n+\n   const PositionT* indexes = GetTensorData<PositionT>(positions);\n+  bool indices_has_only_positive_elements = true;\n+  const size_t num_indices = positions->bytes \/ sizeof(PositionT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indexes[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   const PositionT num_strings = GetStringCount(input);\n   const int num_indexes = NumElements(positions);\n \n@@ -163,19 +186,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   if (positions->type == kTfLiteInt32) {\n     switch (input->type) {\n       case kTfLiteFloat32:\n-        return Gather<float, int32_t>(*params, input, positions, output);\n+        return Gather<float, int32_t>(context, *params, input, positions,\n+                                      output);\n       case kTfLiteUInt8:\n-        return Gather<uint8_t, int32_t>(*params, input, positions, output);\n+        return Gather<uint8_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt8:\n-        return Gather<int8_t, int32_t>(*params, input, positions, output);\n+        return Gather<int8_t, int32_t>(context, *params, input, positions,\n+                                       output);\n       case kTfLiteInt16:\n-        return Gather<int16_t, int32_t>(*params, input, positions, output);\n+        return Gather<int16_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt32:\n-        return Gather<int32_t, int32_t>(*params, input, positions, output);\n+        return Gather<int32_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt64:\n-        return Gather<int64_t, int32_t>(*params, input, positions, output);\n+        return Gather<int64_t, int32_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteBool:\n-        return Gather<bool, int32_t>(*params, input, positions, output);\n+        return Gather<bool, int32_t>(context, *params, input, positions,\n+                                     output);\n       case kTfLiteString:\n         return GatherStrings<int32_t>(context, input, positions, output);\n       default:\n@@ -187,19 +217,26 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   if (positions->type == kTfLiteInt64) {\n     switch (input->type) {\n       case kTfLiteFloat32:\n-        return Gather<float, int64_t>(*params, input, positions, output);\n+        return Gather<float, int64_t>(context, *params, input, positions,\n+                                      output);\n       case kTfLiteUInt8:\n-        return Gather<uint8_t, int64_t>(*params, input, positions, output);\n+        return Gather<uint8_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt8:\n-        return Gather<int8_t, int64_t>(*params, input, positions, output);\n+        return Gather<int8_t, int64_t>(context, *params, input, positions,\n+                                       output);\n       case kTfLiteInt16:\n-        return Gather<int16_t, int64_t>(*params, input, positions, output);\n+        return Gather<int16_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt32:\n-        return Gather<int32_t, int64_t>(*params, input, positions, output);\n+        return Gather<int32_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteInt64:\n-        return Gather<int64_t, int64_t>(*params, input, positions, output);\n+        return Gather<int64_t, int64_t>(context, *params, input, positions,\n+                                        output);\n       case kTfLiteBool:\n-        return Gather<bool, int64_t>(*params, input, positions, output);\n+        return Gather<bool, int64_t>(context, *params, input, positions,\n+                                     output);\n       case kTfLiteString:\n         return GatherStrings<int64_t>(context, input, positions, output);\n       default:"
    },
    {
      "index":6,
      "vuln_id":"GHSA-gh6x-4whr-2qv4",
      "cwe_id":"{'CWE-476', 'CWE-125'}",
      "score":8.4,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622'}",
      "dataset":"osv",
      "summary":"Null pointer dereference and heap OOB read in operations restoring tensors ### Impact\nWhen restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.Restore(\n  file_pattern=['\/tmp'],\n  tensor_name=[], \n  default_value=21,\n  dt=tf.int,\n  preferred_shard=1)\n```\n  \nThe same undefined behavior can be triggered by `tf.raw_ops.RestoreSlice`:\n  \n```python\nimport tensorflow as tf\n\ntf.raw_ops.RestoreSlice(\n  file_pattern=['\/tmp'],\n  tensor_name=[], \n  shape_and_slice='2',\n  dt=inp.array([tf.int]),\n  preferred_shard=1)\n```\n\nAlternatively, attackers can read memory outside the bounds of heap allocated data by providing some tensor names but not enough for a successful restoration:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.Restore(\n  file_pattern=['\/tmp'],\n  tensor_name=['x'], \n  default_value=21,\n  dt=tf.int,\n  preferred_shard=42)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/47a06f40411a69c99f381495f490536972152ac0\/tensorflow\/core\/kernels\/save_restore_tensor.cc#L158-L159) retrieves the tensor list corresponding to the `tensor_name` user controlled input and immediately retrieves the tensor at the restoration index (controlled via `preferred_shard` argument). This occurs without validating that the provided list has enough values.\n\nIf the list is empty this results in dereferencing a null pointer (undefined behavior). If, however, the list has some elements, if the restoration index is outside the bounds this results in heap OOB read.\n\n### Patches \nWe have patched the issue in GitHub commit [9e82dce6e6bd1f36a57e08fa85af213e2b2f2622](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information \nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
      "commit_sha":"9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
      "patch":"SINGLE",
      "chain_ord":"['9e82dce6e6bd1f36a57e08fa85af213e2b2f2622']",
      "before_first_fix_commit":"{'e86605c0a336c088b638da02135ea6f9f6753618'}",
      "last_fix_commit":"9e82dce6e6bd1f36a57e08fa85af213e2b2f2622",
      "chain_ord_pos":1.0,
      "commit_datetime":"08\/02\/2021, 21:21:41",
      "message":"Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 8, 'deletions': 1, 'total': 9}",
      "files":"{'tensorflow\/core\/kernels\/save_restore_tensor.cc': {'additions': 8, 'deletions': 1, 'changes': 9, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622\/tensorflow%2Fcore%2Fkernels%2Fsave_restore_tensor.cc', 'patch': '@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\\n         context, size == 1,\\n         errors::InvalidArgument(\\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\\n-            size, \"elements\"));\\n+            size, \" elements\"));\\n   }\\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\\n \\n   const Tensor& tensor_name_t = context->input(1);\\n+  {\\n+    const int64_t size = tensor_name_t.NumElements();\\n+    OP_REQUIRES(context, size > restore_index,\\n+                errors::InvalidArgument(\\n+                    \"Input 1 (file_pattern) must be a have at least \",\\n+                    restore_index + 1, \" elements\"));\\n+  }\\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\\n \\n   \/\/ If we cannot find a cached reader we will allocate our own.'}}",
      "message_norm":"fix npe in restoring code.\n\npiperorigin-revid: 388303253\nchange-id: ia8c68568cb854bca538909a182b31a618d68ce55",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('npe', 'SECWORD', ''), ('388303253', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/save_restore_tensor.cc'])",
      "num_files":1.0,
      "patch_content":"From 9e82dce6e6bd1f36a57e08fa85af213e2b2f2622 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Mon, 2 Aug 2021 14:21:41 -0700\nSubject: [PATCH] Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55\n---\n tensorflow\/core\/kernels\/save_restore_tensor.cc | 9 ++++++++-\n 1 file changed, 8 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/save_restore_tensor.cc b\/tensorflow\/core\/kernels\/save_restore_tensor.cc\nindex 953c1dfb6290b4..dcbed428a5a5ac 100644\n--- a\/tensorflow\/core\/kernels\/save_restore_tensor.cc\n+++ b\/tensorflow\/core\/kernels\/save_restore_tensor.cc\n@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\n         context, size == 1,\n         errors::InvalidArgument(\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n-            size, \"elements\"));\n+            size, \" elements\"));\n   }\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n \n   const Tensor& tensor_name_t = context->input(1);\n+  {\n+    const int64_t size = tensor_name_t.NumElements();\n+    OP_REQUIRES(context, size > restore_index,\n+                errors::InvalidArgument(\n+                    \"Input 1 (file_pattern) must be a have at least \",\n+                    restore_index + 1, \" elements\"));\n+  }\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n \n   \/\/ If we cannot find a cached reader we will allocate our own.",
      "code_diff":"@@ -151,11 +151,18 @@ void RestoreTensor(OpKernelContext* context,\n         context, size == 1,\n         errors::InvalidArgument(\n             \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n-            size, \"elements\"));\n+            size, \" elements\"));\n   }\n   const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n \n   const Tensor& tensor_name_t = context->input(1);\n+  {\n+    const int64_t size = tensor_name_t.NumElements();\n+    OP_REQUIRES(context, size > restore_index,\n+                errors::InvalidArgument(\n+                    \"Input 1 (file_pattern) must be a have at least \",\n+                    restore_index + 1, \" elements\"));\n+  }\n   const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n \n   \/\/ If we cannot find a cached reader we will allocate our own."
    },
    {
      "index":7,
      "vuln_id":"GHSA-mxjj-953w-2c2v",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":7.4,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8ee24e7949a203d234489f9da2c5bf45a7d5157d'}",
      "dataset":"osv",
      "summary":"Data corruption in tensorflow-lite ### Impact\nWhen determining the common dimension size of two tensors, TFLite uses a `DCHECK` which is no-op outside of debug compilation modes:\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/kernels\/internal\/types.h#L437-L442\n\nSince the function always returns the dimension of the first tensor, malicious attackers can craft cases where this is larger than that of the second tensor. In turn, this would result in reads\/writes outside of bounds since the interpreter will wrongly assume that there is enough data in both tensors.\n\n### Patches\nWe have patched the issue in 8ee24e7949a20 and will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2020-09-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/8ee24e7949a203d234489f9da2c5bf45a7d5157d",
      "commit_sha":"8ee24e7949a203d234489f9da2c5bf45a7d5157d",
      "patch":"SINGLE",
      "chain_ord":"['8ee24e7949a203d234489f9da2c5bf45a7d5157d']",
      "before_first_fix_commit":"{'0b5662bc2be13a8c8f044d925d87fb6e56247cd8'}",
      "last_fix_commit":"8ee24e7949a203d234489f9da2c5bf45a7d5157d",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/18\/2020, 21:19:26",
      "message":"[tflite] Ensure `MatchingDim` does not allow buffer overflow.\n\nWe check in `MatchingDim` that both arguments have the same dimensionality, however that is a `DCHECK` only enabled if building in debug mode. Hence, it could be possible to cause buffer overflows by passing in a tensor with larger dimensions as the second argument. To fix, we now make `MatchingDim` return the minimum of the two sizes.\n\nA much better fix would be to return a status object but that requires refactoring a large part of the codebase for minor benefits.\n\nPiperOrigin-RevId: 332526127\nChange-Id: If627d0d2c80a685217b6e0d1e64b0872dbf1c5e4",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'tensorflow\/lite\/kernels\/internal\/types.h': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/8ee24e7949a203d234489f9da2c5bf45a7d5157d\/tensorflow%2Flite%2Fkernels%2Finternal%2Ftypes.h', 'patch': '@@ -438,7 +438,7 @@ int MatchingArraySize(const ArrayType1& array1, int index1,\\n inline int MatchingDim(const RuntimeShape& shape1, int index1,\\n                        const RuntimeShape& shape2, int index2) {\\n   TFLITE_DCHECK_EQ(shape1.Dims(index1), shape2.Dims(index2));\\n-  return shape1.Dims(index1);\\n+  return std::min(shape1.Dims(index1), shape2.Dims(index2));\\n }\\n \\n template <typename... Args>'}}",
      "message_norm":"[tflite] ensure `matchingdim` does not allow buffer overflow.\n\nwe check in `matchingdim` that both arguments have the same dimensionality, however that is a `dcheck` only enabled if building in debug mode. hence, it could be possible to cause buffer overflows by passing in a tensor with larger dimensions as the second argument. to fix, we now make `matchingdim` return the minimum of the two sizes.\n\na much better fix would be to return a status object but that requires refactoring a large part of the codebase for minor benefits.\n\npiperorigin-revid: 332526127\nchange-id: if627d0d2c80a685217b6e0d1e64b0872dbf1c5e4",
      "language":"en",
      "entities":"[('ensure', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('buffer overflows', 'SECWORD', ''), ('fix', 'ACTION', ''), ('332526127', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/internal\/types.h'])",
      "num_files":1.0,
      "patch_content":"From 8ee24e7949a203d234489f9da2c5bf45a7d5157d Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 18 Sep 2020 14:19:26 -0700\nSubject: [PATCH] [tflite] Ensure `MatchingDim` does not allow buffer overflow.\n\nWe check in `MatchingDim` that both arguments have the same dimensionality, however that is a `DCHECK` only enabled if building in debug mode. Hence, it could be possible to cause buffer overflows by passing in a tensor with larger dimensions as the second argument. To fix, we now make `MatchingDim` return the minimum of the two sizes.\n\nA much better fix would be to return a status object but that requires refactoring a large part of the codebase for minor benefits.\n\nPiperOrigin-RevId: 332526127\nChange-Id: If627d0d2c80a685217b6e0d1e64b0872dbf1c5e4\n---\n tensorflow\/lite\/kernels\/internal\/types.h | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/internal\/types.h b\/tensorflow\/lite\/kernels\/internal\/types.h\nindex 9db742ddf0376a..b077686dc1570d 100644\n--- a\/tensorflow\/lite\/kernels\/internal\/types.h\n+++ b\/tensorflow\/lite\/kernels\/internal\/types.h\n@@ -438,7 +438,7 @@ int MatchingArraySize(const ArrayType1& array1, int index1,\n inline int MatchingDim(const RuntimeShape& shape1, int index1,\n                        const RuntimeShape& shape2, int index2) {\n   TFLITE_DCHECK_EQ(shape1.Dims(index1), shape2.Dims(index2));\n-  return shape1.Dims(index1);\n+  return std::min(shape1.Dims(index1), shape2.Dims(index2));\n }\n \n template <typename... Args>",
      "code_diff":"@@ -438,7 +438,7 @@ int MatchingArraySize(const ArrayType1& array1, int index1,\n inline int MatchingDim(const RuntimeShape& shape1, int index1,\n                        const RuntimeShape& shape2, int index2) {\n   TFLITE_DCHECK_EQ(shape1.Dims(index1), shape2.Dims(index2));\n-  return shape1.Dims(index1);\n+  return std::min(shape1.Dims(index1), shape2.Dims(index2));\n }\n \n template <typename... Args>"
    },
    {
      "index":8,
      "vuln_id":"GHSA-j47f-4232-hvv8",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/44b7f486c0143f68b56c34e2d01e146ee445134a'}",
      "dataset":"osv",
      "summary":"Heap out of bounds read in `RaggedCross` ### Impact\nAn attacker can force accesses outside the bounds of heap allocated arrays by passing in invalid tensor values to `tf.raw_ops.RaggedCross`:\n\n```python\nimport tensorflow as tf\n\nragged_values = []\nragged_row_splits = [] \nsparse_indices = []\nsparse_values = []\nsparse_shape = []\n\ndense_inputs_elem = tf.constant([], shape=[92, 0], dtype=tf.int64)\ndense_inputs = [dense_inputs_elem]\n\ninput_order = \"R\"\nhashed_output = False\nnum_buckets = 0\nhash_key = 0 \n\ntf.raw_ops.RaggedCross(ragged_values=ragged_values,\n    ragged_row_splits=ragged_row_splits,\n    sparse_indices=sparse_indices,\n    sparse_values=sparse_values,\n    sparse_shape=sparse_shape,\n    dense_inputs=dense_inputs,\n    input_order=input_order,\n    hashed_output=hashed_output,\n    num_buckets=num_buckets,\n    hash_key=hash_key,\n    out_values_type=tf.int64,\n    out_row_splits_type=tf.int64)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/efea03b38fb8d3b81762237dc85e579cc5fc6e87\/tensorflow\/core\/kernels\/ragged_cross_op.cc#L456-L487) lacks validation for the user supplied arguments:\n\n```cc\nint next_ragged = 0;\nint next_sparse = 0;\nint next_dense = 0;\nfor (char c : input_order_) {\n  if (c == 'R') {\n    TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n        ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n        features));\n    next_ragged++;\n  } else if (c == 'S') {\n    TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n        sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n        batch_size, features));\n    next_sparse++;\n  } else if (c == 'D') {\n    TF_RETURN_IF_ERROR(\n        BuildDenseFeatureReader(dense_list[next_dense++], features));\n  }\n  ...\n}\n```\n\nEach of the above branches call a helper function after accessing array elements via a `*_list[next_*]` pattern, followed by incrementing the `next_*` index. However, as there is no validation that the `next_*` values are in the valid range for the corresponding `*_list` arrays, this results in heap OOB reads.\n\n### Patches\nWe have patched the issue in GitHub commit [44b7f486c0143f68b56c34e2d01e146ee445134a](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/44b7f486c0143f68b56c34e2d01e146ee445134a).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/44b7f486c0143f68b56c34e2d01e146ee445134a",
      "commit_sha":"44b7f486c0143f68b56c34e2d01e146ee445134a",
      "patch":"SINGLE",
      "chain_ord":"['44b7f486c0143f68b56c34e2d01e146ee445134a']",
      "before_first_fix_commit":"{'efea03b38fb8d3b81762237dc85e579cc5fc6e87'}",
      "last_fix_commit":"44b7f486c0143f68b56c34e2d01e146ee445134a",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/21\/2021, 23:19:54",
      "message":"Fix out of bounds read in `ragged_cross_op.cc`.\n\nPiperOrigin-RevId: 369757702\nChange-Id: Ie6e5d2c21513a8d56bf41fcf35960caf76e890f9",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 30, 'deletions': 0, 'total': 30}",
      "files":"{'tensorflow\/core\/kernels\/ragged_cross_op.cc': {'additions': 30, 'deletions': 0, 'changes': 30, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/44b7f486c0143f68b56c34e2d01e146ee445134a\/tensorflow%2Fcore%2Fkernels%2Fragged_cross_op.cc', 'patch': '@@ -21,6 +21,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\\n #include \"tensorflow\/core\/util\/util.h\"\\n #include \"tensorflow\/core\/util\/work_sharder.h\"\\n@@ -466,16 +467,45 @@ class RaggedCrossOp : public OpKernel {\\n     int next_dense = 0;\\n     for (char c : input_order_) {\\n       if (c == \\'R\\') {\\n+        if (next_ragged >= ragged_values_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a ragged tensor value at index \",\\n+              next_ragged, \" from a list of \", ragged_values_list.size(),\\n+              \" values.\");\\n+        if (next_ragged >= ragged_splits_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a ragged tensor split at index \",\\n+              next_ragged, \" from a list of \", ragged_splits_list.size(),\\n+              \" splits.\");\\n         TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\\n             ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\\n             features));\\n         next_ragged++;\\n       } else if (c == \\'S\\') {\\n+        if (next_sparse >= sparse_values_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a sparse tensor value at index \",\\n+              next_sparse, \" from a list of \", sparse_values_list.size(),\\n+              \" values.\");\\n+        if (next_sparse >= sparse_indices_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a sparse tensor index at index \",\\n+              next_sparse, \" from a list of \", sparse_indices_list.size(),\\n+              \" indices.\");\\n         TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\\n             sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\\n             batch_size, features));\\n         next_sparse++;\\n       } else if (c == \\'D\\') {\\n+        if (next_dense >= dense_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a dense tensor at index \", next_dense,\\n+              \" from a list of \", dense_list.size(), \" tensors.\");\\n         TF_RETURN_IF_ERROR(\\n             BuildDenseFeatureReader(dense_list[next_dense++], features));\\n       } else {'}}",
      "message_norm":"fix out of bounds read in `ragged_cross_op.cc`.\n\npiperorigin-revid: 369757702\nchange-id: ie6e5d2c21513a8d56bf41fcf35960caf76e890f9",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('out of bounds read', 'SECWORD', ''), ('369757702', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_cross_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 44b7f486c0143f68b56c34e2d01e146ee445134a Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 21 Apr 2021 16:19:54 -0700\nSubject: [PATCH] Fix out of bounds read in `ragged_cross_op.cc`.\n\nPiperOrigin-RevId: 369757702\nChange-Id: Ie6e5d2c21513a8d56bf41fcf35960caf76e890f9\n---\n tensorflow\/core\/kernels\/ragged_cross_op.cc | 30 ++++++++++++++++++++++\n 1 file changed, 30 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/ragged_cross_op.cc b\/tensorflow\/core\/kernels\/ragged_cross_op.cc\nindex ea65c0ee2b5b21..5dfe93f4166592 100644\n--- a\/tensorflow\/core\/kernels\/ragged_cross_op.cc\n+++ b\/tensorflow\/core\/kernels\/ragged_cross_op.cc\n@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/register_types.h\"\n #include \"tensorflow\/core\/framework\/tensor.h\"\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\n #include \"tensorflow\/core\/util\/util.h\"\n #include \"tensorflow\/core\/util\/work_sharder.h\"\n@@ -466,16 +467,45 @@ class RaggedCrossOp : public OpKernel {\n     int next_dense = 0;\n     for (char c : input_order_) {\n       if (c == 'R') {\n+        if (next_ragged >= ragged_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor value at index \",\n+              next_ragged, \" from a list of \", ragged_values_list.size(),\n+              \" values.\");\n+        if (next_ragged >= ragged_splits_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor split at index \",\n+              next_ragged, \" from a list of \", ragged_splits_list.size(),\n+              \" splits.\");\n         TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n             ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n             features));\n         next_ragged++;\n       } else if (c == 'S') {\n+        if (next_sparse >= sparse_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor value at index \",\n+              next_sparse, \" from a list of \", sparse_values_list.size(),\n+              \" values.\");\n+        if (next_sparse >= sparse_indices_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor index at index \",\n+              next_sparse, \" from a list of \", sparse_indices_list.size(),\n+              \" indices.\");\n         TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n             sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n             batch_size, features));\n         next_sparse++;\n       } else if (c == 'D') {\n+        if (next_dense >= dense_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a dense tensor at index \", next_dense,\n+              \" from a list of \", dense_list.size(), \" tensors.\");\n         TF_RETURN_IF_ERROR(\n             BuildDenseFeatureReader(dense_list[next_dense++], features));\n       } else {",
      "code_diff":"@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/register_types.h\"\n #include \"tensorflow\/core\/framework\/tensor.h\"\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\n #include \"tensorflow\/core\/util\/util.h\"\n #include \"tensorflow\/core\/util\/work_sharder.h\"\n@@ -466,16 +467,45 @@ class RaggedCrossOp : public OpKernel {\n     int next_dense = 0;\n     for (char c : input_order_) {\n       if (c == 'R') {\n+        if (next_ragged >= ragged_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor value at index \",\n+              next_ragged, \" from a list of \", ragged_values_list.size(),\n+              \" values.\");\n+        if (next_ragged >= ragged_splits_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor split at index \",\n+              next_ragged, \" from a list of \", ragged_splits_list.size(),\n+              \" splits.\");\n         TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n             ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n             features));\n         next_ragged++;\n       } else if (c == 'S') {\n+        if (next_sparse >= sparse_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor value at index \",\n+              next_sparse, \" from a list of \", sparse_values_list.size(),\n+              \" values.\");\n+        if (next_sparse >= sparse_indices_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor index at index \",\n+              next_sparse, \" from a list of \", sparse_indices_list.size(),\n+              \" indices.\");\n         TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n             sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n             batch_size, features));\n         next_sparse++;\n       } else if (c == 'D') {\n+        if (next_dense >= dense_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a dense tensor at index \", next_dense,\n+              \" from a list of \", dense_list.size(), \" tensors.\");\n         TF_RETURN_IF_ERROR(\n             BuildDenseFeatureReader(dense_list[next_dense++], features));\n       } else {"
    },
    {
      "index":9,
      "vuln_id":"GHSA-h9px-9vqg-222h",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/99085e8ff02c3763a0ec2263e44daec416f6a387'}",
      "dataset":"osv",
      "summary":"Heap OOB in `QuantizeAndDequantizeV3` ### Impact\nAn attacker can read data outside of bounds of heap allocated buffer in `tf.raw_ops.QuantizeAndDequantizeV3`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeAndDequantizeV3(\n  input=[2.5,2.5], input_min=[0,0], input_max=[1,1], num_bits=[30],\n  signed_input=False, range_given=False, narrow_range=False, axis=3)\n```   \n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/11ff7f80667e6490d7b5174aa6bf5e01886e770f\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc#L237) does not validate the value of user supplied `axis` attribute before using it to index in the array backing the `input` argument:\n\n```cc\nconst int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n```\n\n### Patches\nWe have patched the issue in GitHub commit [99085e8ff02c3763a0ec2263e44daec416f6a387](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/99085e8ff02c3763a0ec2263e44daec416f6a387).\n  \nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Aivul Team from Qihoo 360.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/99085e8ff02c3763a0ec2263e44daec416f6a387",
      "commit_sha":"99085e8ff02c3763a0ec2263e44daec416f6a387",
      "patch":"SINGLE",
      "chain_ord":"['99085e8ff02c3763a0ec2263e44daec416f6a387']",
      "before_first_fix_commit":"{'11ff7f80667e6490d7b5174aa6bf5e01886e770f'}",
      "last_fix_commit":"99085e8ff02c3763a0ec2263e44daec416f6a387",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/27\/2021, 00:32:41",
      "message":"Fix `tf.raw_ops.QuantizeAndDequantizeV3` array index failure.\n\nPiperOrigin-RevId: 370577691\nChange-Id: Ifeae64212f6bcd139435824fa2748d1329213c4c",
      "author":"Amit Patankar",
      "comments":null,
      "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
      "files":"{'tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/99085e8ff02c3763a0ec2263e44daec416f6a387\/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\\n limitations under the License.\\n ==============================================================================*\/\\n \\n+#include \"tensorflow\/core\/framework\/op_requires.h\"\\n #define EIGEN_USE_THREADS\\n \\n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\\\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& input = ctx->input(0);\\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\\n+                errors::InvalidArgument(\\n+                    \"Axis requested is larger than input dimensions. Axis: \",\\n+                    axis_, \" Input Dimensions: \", input.dims()));\\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));'}}",
      "message_norm":"fix `tf.raw_ops.quantizeanddequantizev3` array index failure.\n\npiperorigin-revid: 370577691\nchange-id: ifeae64212f6bcd139435824fa2748d1329213c4c",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('370577691', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 99085e8ff02c3763a0ec2263e44daec416f6a387 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Mon, 26 Apr 2021 17:32:41 -0700\nSubject: [PATCH] Fix `tf.raw_ops.QuantizeAndDequantizeV3` array index failure.\n\nPiperOrigin-RevId: 370577691\nChange-Id: Ifeae64212f6bcd139435824fa2748d1329213c4c\n---\n tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\nindex c2a7a90d8713d8..f01a70114591bf 100644\n--- a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*\/\n \n+#include \"tensorflow\/core\/framework\/op_requires.h\"\n #define EIGEN_USE_THREADS\n \n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\n+                errors::InvalidArgument(\n+                    \"Axis requested is larger than input dimensions. Axis: \",\n+                    axis_, \" Input Dimensions: \", input.dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
      "code_diff":"@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*\/\n \n+#include \"tensorflow\/core\/framework\/op_requires.h\"\n #define EIGEN_USE_THREADS\n \n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\n+                errors::InvalidArgument(\n+                    \"Axis requested is larger than input dimensions. Axis: \",\n+                    axis_, \" Input Dimensions: \", input.dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));"
    },
    {
      "index":10,
      "vuln_id":"GHSA-374m-jm66-3vj8",
      "cwe_id":"{'CWE-125'}",
      "score":7.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f410212e373eb2aec4c9e60bf3702eba99a38aba'}",
      "dataset":"osv",
      "summary":"Heap OOB in `SparseBinCount` ### Impact\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e71b86d47f8bc1816bf54d7bddc4170e47670b97\/tensorflow\/core\/kernels\/bincount_op.cc#L353-L417) of `SparseBinCount` is vulnerable to a heap OOB:\n\n```python\nimport tensorflow as tf\n  \n  \ntf.raw_ops.SparseBincount(\n  indices=[[0],[1],[2]]\n  values=[0,-10000000]\n  dense_shape=[1,1]\n  size=[1]\n  weights=[3,2,1]\n  binary_output=False)\n```\n\nThis is because of missing validation between the elements of the `values` argument and the shape of the sparse output:\n\n\n```cc\nfor (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n  const int64_t batch = indices_mat(i, 0);\n  const Tidx bin = values(i);\n  ...\n  out(batch, bin) = ...;\n}\n```\n\n### Patches\nWe have patched the issue in GitHub commit [f410212e373eb2aec4c9e60bf3702eba99a38aba](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f410212e373eb2aec4c9e60bf3702eba99a38aba).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-11-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f410212e373eb2aec4c9e60bf3702eba99a38aba",
      "commit_sha":"f410212e373eb2aec4c9e60bf3702eba99a38aba",
      "patch":"SINGLE",
      "chain_ord":"['f410212e373eb2aec4c9e60bf3702eba99a38aba']",
      "before_first_fix_commit":"{'4656caa7d74420454da967288af143ec73fb4c9b'}",
      "last_fix_commit":"f410212e373eb2aec4c9e60bf3702eba99a38aba",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/30\/2021, 13:36:55",
      "message":"Prevent out-of-bound accesses in SparseBincount.\n\nPiperOrigin-RevId: 399918616\nChange-Id: I11d154f4444d3fde1f09c5c40628b8671791a30d",
      "author":"Penporn Koanantakool",
      "comments":null,
      "stats":"{'additions': 10, 'deletions': 0, 'total': 10}",
      "files":"{'tensorflow\/core\/kernels\/bincount_op.cc': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f410212e373eb2aec4c9e60bf3702eba99a38aba\/tensorflow%2Fcore%2Fkernels%2Fbincount_op.cc', 'patch': '@@ -405,6 +405,16 @@ class SparseBincountOp : public OpKernel {\\n       for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\\n         const int64_t batch = indices_mat(i, 0);\\n         const Tidx bin = values(i);\\n+        OP_REQUIRES(\\n+            ctx, batch < out.dimension(0),\\n+            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\\n+                                    \") must be less than the dimension size (\",\\n+                                    out.dimension(0), \").\"));\\n+        OP_REQUIRES(\\n+            ctx, bin < out.dimension(1),\\n+            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,\\n+                                    \") must be less then the dimension size (\",\\n+                                    out.dimension(1), \").\"));\\n         if (bin < size) {\\n           if (binary_output_) {\\n             out(batch, bin) = T(1);'}}",
      "message_norm":"prevent out-of-bound accesses in sparsebincount.\n\npiperorigin-revid: 399918616\nchange-id: i11d154f4444d3fde1f09c5c40628b8671791a30d",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('out-of-bound', 'SECWORD', ''), ('399918616', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/bincount_op.cc'])",
      "num_files":1.0,
      "patch_content":"From f410212e373eb2aec4c9e60bf3702eba99a38aba Mon Sep 17 00:00:00 2001\nFrom: Penporn Koanantakool <penporn@google.com>\nDate: Thu, 30 Sep 2021 06:36:55 -0700\nSubject: [PATCH] Prevent out-of-bound accesses in SparseBincount.\n\nPiperOrigin-RevId: 399918616\nChange-Id: I11d154f4444d3fde1f09c5c40628b8671791a30d\n---\n tensorflow\/core\/kernels\/bincount_op.cc | 10 ++++++++++\n 1 file changed, 10 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/bincount_op.cc b\/tensorflow\/core\/kernels\/bincount_op.cc\nindex 6d668211da0968..0f661dd9f201a6 100644\n--- a\/tensorflow\/core\/kernels\/bincount_op.cc\n+++ b\/tensorflow\/core\/kernels\/bincount_op.cc\n@@ -405,6 +405,16 @@ class SparseBincountOp : public OpKernel {\n       for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n         const int64_t batch = indices_mat(i, 0);\n         const Tidx bin = values(i);\n+        OP_REQUIRES(\n+            ctx, batch < out.dimension(0),\n+            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\n+                                    \") must be less than the dimension size (\",\n+                                    out.dimension(0), \").\"));\n+        OP_REQUIRES(\n+            ctx, bin < out.dimension(1),\n+            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,\n+                                    \") must be less then the dimension size (\",\n+                                    out.dimension(1), \").\"));\n         if (bin < size) {\n           if (binary_output_) {\n             out(batch, bin) = T(1);",
      "code_diff":"@@ -405,6 +405,16 @@ class SparseBincountOp : public OpKernel {\n       for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n         const int64_t batch = indices_mat(i, 0);\n         const Tidx bin = values(i);\n+        OP_REQUIRES(\n+            ctx, batch < out.dimension(0),\n+            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\n+                                    \") must be less than the dimension size (\",\n+                                    out.dimension(0), \").\"));\n+        OP_REQUIRES(\n+            ctx, bin < out.dimension(1),\n+            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,\n+                                    \") must be less then the dimension size (\",\n+                                    out.dimension(1), \").\"));\n         if (bin < size) {\n           if (binary_output_) {\n             out(batch, bin) = T(1);"
    },
    {
      "index":11,
      "vuln_id":"GHSA-9697-98pf-4rw7",
      "cwe_id":"{'CWE-125'}",
      "score":5.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/42459e4273c2e47a3232cc16c4f4fff3b3a35c38'}",
      "dataset":"osv",
      "summary":"Heap OOB in `UpperBound` and `LowerBound` ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.UpperBound`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.UpperBound(\n  sorted_input=[1,2,3],\n  values=tf.constant(value=[[0,0,0],[1,1,1],[2,2,2]],dtype=tf.int64),\n  out_type=tf.int64)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/searchsorted_op.cc#L85-L104) does not validate the rank of `sorted_input` argument:\n\n```cc\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& sorted_inputs_t = ctx->input(0);\n    \/\/ ...\n    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                Status(error::INVALID_ARGUMENT,\n                       \"Leading dim_size of both tensors must match.\"));\n    \/\/ ...\n    if (output_t->dtype() == DT_INT32) {\n      OP_REQUIRES(ctx,\n                  FastBoundsCheck(sorted_inputs_t.dim_size(1), ...));\n      \/\/ ...\n    }\n```\n\nAs we access the first two dimensions of `sorted_inputs_t` tensor, it must have rank at least 2.\n\nA similar issue occurs in `tf.raw_ops.LowerBound`.\n\n### Patches\nWe have patched the issue in GitHub commit [42459e4273c2e47a3232cc16c4f4fff3b3a35c38](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/42459e4273c2e47a3232cc16c4f4fff3b3a35c38).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "commit_sha":"42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "patch":"SINGLE",
      "chain_ord":"['42459e4273c2e47a3232cc16c4f4fff3b3a35c38']",
      "before_first_fix_commit":"{'b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58'}",
      "last_fix_commit":"42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/30\/2021, 05:25:05",
      "message":"Prevent CHECK-fail\/heap OOB in UpperBound and LowerBound\n\nPiperOrigin-RevId: 387738073\nChange-Id: Iee74de95ddad18440d052a75a5a1cb67544f490a",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
      "files":"{'tensorflow\/core\/kernels\/searchsorted_op.cc': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/42459e4273c2e47a3232cc16c4f4fff3b3a35c38\/tensorflow%2Fcore%2Fkernels%2Fsearchsorted_op.cc', 'patch': '@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\\n     const Tensor& sorted_inputs_t = ctx->input(0);\\n     const Tensor& values_t = ctx->input(1);\\n \\n+    \/\/ inputs must be at least a matrix\\n+    OP_REQUIRES(\\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\\n     \/\/ must have same batch dim_size for both\\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\\n                 Status(error::INVALID_ARGUMENT,\\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\\n     const Tensor& sorted_inputs_t = ctx->input(0);\\n     const Tensor& values_t = ctx->input(1);\\n \\n+    \/\/ inputs must be at least a matrix\\n+    OP_REQUIRES(\\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\\n     \/\/ must have same batch dim_size for both\\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\\n                 Status(error::INVALID_ARGUMENT,'}}",
      "message_norm":"prevent check-fail\/heap oob in upperbound and lowerbound\n\npiperorigin-revid: 387738073\nchange-id: iee74de95ddad18440d052a75a5a1cb67544f490a",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('387738073', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/searchsorted_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 42459e4273c2e47a3232cc16c4f4fff3b3a35c38 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 22:25:05 -0700\nSubject: [PATCH] Prevent CHECK-fail\/heap OOB in UpperBound and LowerBound\n\nPiperOrigin-RevId: 387738073\nChange-Id: Iee74de95ddad18440d052a75a5a1cb67544f490a\n---\n tensorflow\/core\/kernels\/searchsorted_op.cc | 8 ++++++++\n 1 file changed, 8 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/searchsorted_op.cc b\/tensorflow\/core\/kernels\/searchsorted_op.cc\nindex 01e221dc471c4d..5f075a6a540e9f 100644\n--- a\/tensorflow\/core\/kernels\/searchsorted_op.cc\n+++ b\/tensorflow\/core\/kernels\/searchsorted_op.cc\n@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    \/\/ inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     \/\/ must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    \/\/ inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     \/\/ must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,",
      "code_diff":"@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    \/\/ inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     \/\/ must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    \/\/ inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     \/\/ must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,"
    },
    {
      "index":12,
      "vuln_id":"GHSA-4hvf-hxvg-f67v",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":8.8,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038'}",
      "dataset":"osv",
      "summary":"Read and Write outside of bounds in TensorFlow ### Impact\nAn attacker can craft a TFLite model that would allow limited reads and writes outside of arrays in TFLite. This exploits missing validation in [the conversion from sparse tensors to dense tensors](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ca6f96b62ad84207fbec580404eaa7dd7403a550\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc#L252-L293).\n\n### Patches\nWe have patched the issue in GitHub commit [6364463d6f5b6254cac3d6aedf999b6a96225038](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038",
      "commit_sha":"6364463d6f5b6254cac3d6aedf999b6a96225038",
      "patch":"SINGLE",
      "chain_ord":"['6364463d6f5b6254cac3d6aedf999b6a96225038']",
      "before_first_fix_commit":"{'3e49ff637ad4f05c133d235a568943d19216fa9a'}",
      "last_fix_commit":"6364463d6f5b6254cac3d6aedf999b6a96225038",
      "chain_ord_pos":1.0,
      "commit_datetime":"12\/16\/2021, 23:37:14",
      "message":"[lite] Add some safety checks to avoid out of bound access for sparsity format\n\nPiperOrigin-RevId: 416910386\nChange-Id: Ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
      "author":"Karim Nosir",
      "comments":null,
      "stats":"{'additions': 11, 'deletions': 7, 'total': 18}",
      "files":"{'tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc': {'additions': 11, 'deletions': 7, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6364463d6f5b6254cac3d6aedf999b6a96225038\/tensorflow%2Flite%2Fkernels%2Finternal%2Futils%2Fsparsity_format_converter.cc', 'patch': '@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\\n   block_size_.resize(block_map_.size());\\n   for (int i = 0; i < original_rank; i++) {\\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\\n-      int orig_dim = traversal_order_[original_rank + block_dim];\\n-      block_size_[block_dim] = dense_size[orig_dim];\\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\\n-      block_dim++;\\n+      if (original_rank + block_dim < traversal_order_.size()) {\\n+        int orig_dim = traversal_order_[original_rank + block_dim];\\n+        block_size_[block_dim] = dense_size[orig_dim];\\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\\n+        block_dim++;\\n+      }\\n     } else {\\n       blocked_shape_[i] = dense_shape_[i];\\n     }\\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\\n                src_data_ptr, dest_data);\\n     }\\n-  } else {\\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\\n     const auto& array_segments = dim_metadata_[metadata_idx];\\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\\n          i++) {\\n-      indices[level] = array_indices[i];\\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      if (i < array_indices.size() && level < indices.size()) {\\n+        indices[level] = array_indices[i];\\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      }\\n     }\\n   }\\n }'}}",
      "message_norm":"[lite] add some safety checks to avoid out of bound access for sparsity format\n\npiperorigin-revid: 416910386\nchange-id: ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
      "language":"en",
      "entities":"[('add', 'ACTION', ''), ('safety checks', 'SECWORD', ''), ('out of bound access', 'SECWORD', ''), ('416910386', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc'])",
      "num_files":1.0,
      "patch_content":"From 6364463d6f5b6254cac3d6aedf999b6a96225038 Mon Sep 17 00:00:00 2001\nFrom: Karim Nosir <karimnosseir@google.com>\nDate: Thu, 16 Dec 2021 15:37:14 -0800\nSubject: [PATCH] [lite] Add some safety checks to avoid out of bound access\n for sparsity format\n\nPiperOrigin-RevId: 416910386\nChange-Id: Ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a\n---\n ...\/utils\/sparsity_format_converter.cc         | 18 +++++++++++-------\n 1 file changed, 11 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc b\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\nindex 22aa5d019e7395..0595d49365c387 100644\n--- a\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\n+++ b\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\n@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\n   block_size_.resize(block_map_.size());\n   for (int i = 0; i < original_rank; i++) {\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\n-      int orig_dim = traversal_order_[original_rank + block_dim];\n-      block_size_[block_dim] = dense_size[orig_dim];\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n-      block_dim++;\n+      if (original_rank + block_dim < traversal_order_.size()) {\n+        int orig_dim = traversal_order_[original_rank + block_dim];\n+        block_size_[block_dim] = dense_size[orig_dim];\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n+        block_dim++;\n+      }\n     } else {\n       blocked_shape_[i] = dense_shape_[i];\n     }\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\n                src_data_ptr, dest_data);\n     }\n-  } else {\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\n     const auto& array_segments = dim_metadata_[metadata_idx];\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\n          i++) {\n-      indices[level] = array_indices[i];\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      if (i < array_indices.size() && level < indices.size()) {\n+        indices[level] = array_indices[i];\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      }\n     }\n   }\n }",
      "code_diff":"@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\n   block_size_.resize(block_map_.size());\n   for (int i = 0; i < original_rank; i++) {\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\n-      int orig_dim = traversal_order_[original_rank + block_dim];\n-      block_size_[block_dim] = dense_size[orig_dim];\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n-      block_dim++;\n+      if (original_rank + block_dim < traversal_order_.size()) {\n+        int orig_dim = traversal_order_[original_rank + block_dim];\n+        block_size_[block_dim] = dense_size[orig_dim];\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n+        block_dim++;\n+      }\n     } else {\n       blocked_shape_[i] = dense_shape_[i];\n     }\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\n                src_data_ptr, dest_data);\n     }\n-  } else {\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\n     const auto& array_segments = dim_metadata_[metadata_idx];\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\n          i++) {\n-      indices[level] = array_indices[i];\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      if (i < array_indices.size() && level < indices.size()) {\n+        indices[level] = array_indices[i];\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      }\n     }\n   }\n }"
    },
    {
      "index":13,
      "vuln_id":"GHSA-9xh4-23q4-v6wr",
      "cwe_id":"{'CWE-476', 'CWE-787', 'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0'}",
      "dataset":"osv",
      "summary":"Heap buffer overflow and undefined behavior in `FusedBatchNorm` ### Impact\nThe implementation of `tf.raw_ops.FusedBatchNorm` is vulnerable to a heap buffer overflow:\n      \n```python\nimport tensorflow as tf\n\nx = tf.zeros([10, 10, 10, 6], dtype=tf.float32)\nscale = tf.constant([0.0], shape=[1], dtype=tf.float32)\noffset = tf.constant([0.0], shape=[1], dtype=tf.float32)\nmean = tf.constant([0.0], shape=[1], dtype=tf.float32)\nvariance = tf.constant([0.0], shape=[1], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n    \ntf.raw_ops.FusedBatchNorm(\n  x=x, scale=scale, offset=offset, mean=mean, variance=variance,\n  epsilon=epsilon, exponential_avg_factor=exponential_avg_factor,\n  data_format=data_format, is_training=is_training)\n```\n  \nIf the tensors are empty, the same implementation can trigger undefined behavior by dereferencing null pointers:\n\n```python \nimport tensorflow as tf\nimport numpy as np\n\nx = tf.zeros([10, 10, 10, 1], dtype=tf.float32)\nscale = tf.constant([], shape=[0], dtype=tf.float32)\noffset = tf.constant([], shape=[0], dtype=tf.float32)\nmean = tf.constant([], shape=[0], dtype=tf.float32)\nvariance = tf.constant([], shape=[0], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n\ntf.raw_ops.FusedBatchNorm(\n  x=x, scale=scale, offset=offset, mean=mean, variance=variance, \n  epsilon=epsilon, exponential_avg_factor=exponential_avg_factor,\n  data_format=data_format, is_training=is_training)\n``` \n\nThe  [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/57d86e0db5d1365f19adcce848dfc1bf89fdd4c7\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc) fails to validate that `scale`, `offset`, `mean` and `variance` (the last two only when required) all have the same number of elements as the number of channels of `x`. This results in heap out of bounds reads when the buffers backing these tensors are indexed past their boundary.\n\nIf the tensors are empty, the validation mentioned in the above paragraph would also trigger and prevent the undefined behavior.\n\n### Patches\nWe have patched the issue in GitHub commit [6972f9dfe325636b3db4e0bc517ee22a159365c0](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0",
      "commit_sha":"6972f9dfe325636b3db4e0bc517ee22a159365c0",
      "patch":"SINGLE",
      "chain_ord":"['6972f9dfe325636b3db4e0bc517ee22a159365c0']",
      "before_first_fix_commit":"{'57d86e0db5d1365f19adcce848dfc1bf89fdd4c7'}",
      "last_fix_commit":"6972f9dfe325636b3db4e0bc517ee22a159365c0",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/07\/2021, 00:45:51",
      "message":"Add missing valuidation to FusedBatchNorm.\n\nPiperOrigin-RevId: 372460336\nChange-Id: Ic8c4e4de67c58a741bd87f2e182bed07247d1126",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 27, 'deletions': 1, 'total': 28}",
      "files":"{'tensorflow\/core\/kernels\/fused_batch_norm_op.cc': {'additions': 27, 'deletions': 1, 'changes': 28, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6972f9dfe325636b3db4e0bc517ee22a159365c0\/tensorflow%2Fcore%2Fkernels%2Ffused_batch_norm_op.cc', 'patch': '@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\\n     }\\n \\n+    const auto num_channels = GetTensorDim(x, tensor_format_, \\'C\\');\\n+    OP_REQUIRES(\\n+        context, scale.NumElements() == num_channels,\\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\\n+                                \"as the channels of x, got \",\\n+                                scale.NumElements(), \" and \", num_channels));\\n+    OP_REQUIRES(\\n+        context, offset.NumElements() == num_channels,\\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\\n+                                \"as the channels of x, got \",\\n+                                offset.NumElements(), \" and \", num_channels));\\n+    if (estimated_mean.NumElements() != 0) {\\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\\n+                  errors::InvalidArgument(\\n+                      \"mean must be empty or have the same number of \"\\n+                      \"elements as the channels of x, got \",\\n+                      estimated_mean.NumElements(), \" and \", num_channels));\\n+    }\\n+    if (estimated_variance.NumElements() != 0) {\\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\\n+                  errors::InvalidArgument(\\n+                      \"variance must be empty or have the same number of \"\\n+                      \"elements as the channels of x, got \",\\n+                      estimated_variance.NumElements(), \" and \", num_channels));\\n+    }\\n+\\n     if (has_side_input_) {\\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\\n                   errors::InvalidArgument(\\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\\n       \/\/ NOTE(ezhulenev): This requirement is coming from implementation\\n       \/\/ details of cudnnBatchNormalizationForwardTrainingEx.\\n       OP_REQUIRES(\\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\\n+          context, !is_training_ || num_channels % 4 == 0,\\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\\n                                   \"channel dimension to be a multiple of 4.\"));\\n     }'}}",
      "message_norm":"add missing valuidation to fusedbatchnorm.\n\npiperorigin-revid: 372460336\nchange-id: ic8c4e4de67c58a741bd87f2e182bed07247d1126",
      "language":"en",
      "entities":"[('add', 'ACTION', ''), ('372460336', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/fused_batch_norm_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 6972f9dfe325636b3db4e0bc517ee22a159365c0 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 6 May 2021 17:45:51 -0700\nSubject: [PATCH] Add missing valuidation to FusedBatchNorm.\n\nPiperOrigin-RevId: 372460336\nChange-Id: Ic8c4e4de67c58a741bd87f2e182bed07247d1126\n---\n ...\/core\/kernels\/fused_batch_norm_op.cc       | 28 ++++++++++++++++++-\n 1 file changed, 27 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc b\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\nindex e564b19857c383..7b0932d953261c 100644\n--- a\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\n+++ b\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\n@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\n     }\n \n+    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n+    OP_REQUIRES(\n+        context, scale.NumElements() == num_channels,\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                scale.NumElements(), \" and \", num_channels));\n+    OP_REQUIRES(\n+        context, offset.NumElements() == num_channels,\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                offset.NumElements(), \" and \", num_channels));\n+    if (estimated_mean.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"mean must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_mean.NumElements(), \" and \", num_channels));\n+    }\n+    if (estimated_variance.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"variance must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_variance.NumElements(), \" and \", num_channels));\n+    }\n+\n     if (has_side_input_) {\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\n                   errors::InvalidArgument(\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\n       \/\/ NOTE(ezhulenev): This requirement is coming from implementation\n       \/\/ details of cudnnBatchNormalizationForwardTrainingEx.\n       OP_REQUIRES(\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\n+          context, !is_training_ || num_channels % 4 == 0,\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                   \"channel dimension to be a multiple of 4.\"));\n     }",
      "code_diff":"@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\n     }\n \n+    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n+    OP_REQUIRES(\n+        context, scale.NumElements() == num_channels,\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                scale.NumElements(), \" and \", num_channels));\n+    OP_REQUIRES(\n+        context, offset.NumElements() == num_channels,\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                offset.NumElements(), \" and \", num_channels));\n+    if (estimated_mean.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"mean must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_mean.NumElements(), \" and \", num_channels));\n+    }\n+    if (estimated_variance.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"variance must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_variance.NumElements(), \" and \", num_channels));\n+    }\n+\n     if (has_side_input_) {\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\n                   errors::InvalidArgument(\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\n       \/\/ NOTE(ezhulenev): This requirement is coming from implementation\n       \/\/ details of cudnnBatchNormalizationForwardTrainingEx.\n       OP_REQUIRES(\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\n+          context, !is_training_ || num_channels % 4 == 0,\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                   \"channel dimension to be a multiple of 4.\"));\n     }"
    },
    {
      "index":14,
      "vuln_id":"GHSA-cgfm-62j4-v4rf",
      "cwe_id":"{'CWE-125'}",
      "score":7.3,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750'}",
      "dataset":"osv",
      "summary":"Heap out of bounds access in sparse reduction operations ### Impact\nThe implementation of sparse reduction operations in TensorFlow can trigger accesses outside of bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\nx = tf.SparseTensor(\n      indices=[[773, 773, 773], [773, 773, 773]],\n      values=[1, 1],\n      dense_shape=[337, 337, 337])\ntf.sparse.reduce_sum(x, 1)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1bc56203f21a5a4995311825ffaba7a670d7747\/tensorflow\/core\/kernels\/sparse_reduce_op.cc#L217-L228) fails to validate that each reduction group does not overflow and that each corresponding index does not point to outside the bounds of the input tensor.\n\n### Patches\nWe have patched the issue in GitHub commit [87158f43f05f2720a374f3e6d22a7aaa3a33f750](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750). \n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750",
      "commit_sha":"87158f43f05f2720a374f3e6d22a7aaa3a33f750",
      "patch":"SINGLE",
      "chain_ord":"['87158f43f05f2720a374f3e6d22a7aaa3a33f750']",
      "before_first_fix_commit":"{'9c7f40e5f1b5b74156ad4d7bc20b8d69bdedbe29'}",
      "last_fix_commit":"87158f43f05f2720a374f3e6d22a7aaa3a33f750",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/31\/2021, 04:11:18",
      "message":"Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
      "files":"{'tensorflow\/core\/kernels\/sparse_reduce_op.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/87158f43f05f2720a374f3e6d22a7aaa3a33f750\/tensorflow%2Fcore%2Fkernels%2Fsparse_reduce_op.cc', 'patch': '@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\\n     sp.Reorder<T>(reduction.reorder_dims);\\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\\n+      OP_REQUIRES(ctx,\\n+                  output_strides.empty() ||\\n+                  (g.group().size() == output_strides.size()),\\n+                  errors::Internal(\\n+                      \"Expected group size and output_strides size to match\",\\n+                      \", but got \", g.group().size(), \" and \",\\n+                      output_strides.size()));\\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\\n+      OP_REQUIRES(ctx,\\n+                  idx >= 0 && idx < out_flat.size(),\\n+                  errors::Internal(\\n+                      \"Obtained a write index of \", idx,\\n+                      \" which is outside of bounds of [0, \",\\n+                      out_flat.size(), \")\"));\\n       out_flat(idx) = reduced_val();\\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"'}}",
      "message_norm":"prevent heap oob in sparse reduction ops.\n\npiperorigin-revid: 387934524\nchange-id: i894aa30f1e454f09b471d565b4a325da49322c1a",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('387934524', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_reduce_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 87158f43f05f2720a374f3e6d22a7aaa3a33f750 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 21:11:18 -0700\nSubject: [PATCH] Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a\n---\n tensorflow\/core\/kernels\/sparse_reduce_op.cc | 13 +++++++++++++\n 1 file changed, 13 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_reduce_op.cc b\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\nindex 668ea5ae54084c..430be0a271742e 100644\n--- a\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\n@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\n     sp.Reorder<T>(reduction.reorder_dims);\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n+      OP_REQUIRES(ctx,\n+                  output_strides.empty() ||\n+                  (g.group().size() == output_strides.size()),\n+                  errors::Internal(\n+                      \"Expected group size and output_strides size to match\",\n+                      \", but got \", g.group().size(), \" and \",\n+                      output_strides.size()));\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n+      OP_REQUIRES(ctx,\n+                  idx >= 0 && idx < out_flat.size(),\n+                  errors::Internal(\n+                      \"Obtained a write index of \", idx,\n+                      \" which is outside of bounds of [0, \",\n+                      out_flat.size(), \")\"));\n       out_flat(idx) = reduced_val();\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"",
      "code_diff":"@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\n     sp.Reorder<T>(reduction.reorder_dims);\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n+      OP_REQUIRES(ctx,\n+                  output_strides.empty() ||\n+                  (g.group().size() == output_strides.size()),\n+                  errors::Internal(\n+                      \"Expected group size and output_strides size to match\",\n+                      \", but got \", g.group().size(), \" and \",\n+                      output_strides.size()));\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n+      OP_REQUIRES(ctx,\n+                  idx >= 0 && idx < out_flat.size(),\n+                  errors::Internal(\n+                      \"Obtained a write index of \", idx,\n+                      \" which is outside of bounds of [0, \",\n+                      out_flat.size(), \")\"));\n       out_flat(idx) = reduced_val();\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \""
    },
    {
      "index":15,
      "vuln_id":"GHSA-q3g3-h9r4-prrc",
      "cwe_id":"{'CWE-125'}",
      "score":7.3,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec'}",
      "dataset":"osv",
      "summary":"Reference binding to nullptr and heap OOB in binary cwise ops ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations):\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.SqrtGrad(y=[4, 16],dy=[])\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/cwise_ops_common.h#L264) assumes that the two inputs have exactly the same number of elements but does not check that. Hence, when the eigen functor executes it triggers heap OOB reads and undefined behavior due to binding to nullptr.\n\n### Patches\nWe have patched the issue in GitHub commit [93f428fd1768df147171ed674fee1fc5ab8309ec](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo  360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec",
      "commit_sha":"93f428fd1768df147171ed674fee1fc5ab8309ec",
      "patch":"SINGLE",
      "chain_ord":"['93f428fd1768df147171ed674fee1fc5ab8309ec']",
      "before_first_fix_commit":"{'bc9c546ce7015c57c2f15c168b3d9201de679a1d'}",
      "last_fix_commit":"93f428fd1768df147171ed674fee1fc5ab8309ec",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/31\/2021, 04:42:36",
      "message":"Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
      "files":"{'tensorflow\/core\/kernels\/cwise_ops_common.h': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/93f428fd1768df147171ed674fee1fc5ab8309ec\/tensorflow%2Fcore%2Fkernels%2Fcwise_ops_common.h', 'patch': '@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& in0 = ctx->input(0);\\n     const Tensor& in1 = ctx->input(1);\\n+    OP_REQUIRES(\\n+        ctx, in0.NumElements() == in1.NumElements(),\\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\\n+                                \"same number of elements, got \",\\n+                                in0.NumElements(), \" and \", in1.NumElements()));\\n     auto in0_flat = in0.flat<Tin>();\\n     auto in1_flat = in1.flat<Tin>();\\n     const Device& eigen_device = ctx->eigen_device<Device>();'}}",
      "message_norm":"fix nullptr deref and heap oob access in binary cwise ops.\n\npiperorigin-revid: 387936777\nchange-id: i608b8074cec36a982cca622b7144cb2c43e6e19f",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('heap oob', 'SECWORD', ''), ('387936777', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/cwise_ops_common.h'])",
      "num_files":1.0,
      "patch_content":"From 93f428fd1768df147171ed674fee1fc5ab8309ec Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 21:42:36 -0700\nSubject: [PATCH] Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f\n---\n tensorflow\/core\/kernels\/cwise_ops_common.h | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/cwise_ops_common.h b\/tensorflow\/core\/kernels\/cwise_ops_common.h\nindex 9adc628421d046..4f2c83322ba00f 100644\n--- a\/tensorflow\/core\/kernels\/cwise_ops_common.h\n+++ b\/tensorflow\/core\/kernels\/cwise_ops_common.h\n@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();",
      "code_diff":"@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();"
    },
    {
      "index":16,
      "vuln_id":"GHSA-5hj3-vjjf-f5m7",
      "cwe_id":"{'CWE-125'}",
      "score":5.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6'}",
      "dataset":"osv",
      "summary":"Heap OOB in `SdcaOptimizerV2` ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.SdcaOptimizerV2(\n  sparse_example_indices=[[1]],\n  sparse_feature_indices=[[1]],\n  sparse_feature_values=[[1.0,2.0]],\n  dense_features=[[1.0]],\n  example_weights=[1.0],\n  example_labels=[],\n  sparse_indices=[1],\n  sparse_weights=[1.0],\n  dense_weights=[[1.0]],\n  example_state_data=[[100.0,100.0,100.0,100.0]],\n  loss_type='logistic_loss',\n  l1=100.0,\n  l2=100.0,\n  num_loss_partitions=1,\n  num_inner_iterations=1,\n  adaptive=True)       \n``` \n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples.\n\n### Patches\nWe have patched the issue in GitHub commit [a4e138660270e7599793fa438cd7b2fc2ce215a6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6",
      "commit_sha":"a4e138660270e7599793fa438cd7b2fc2ce215a6",
      "patch":"SINGLE",
      "chain_ord":"['a4e138660270e7599793fa438cd7b2fc2ce215a6']",
      "before_first_fix_commit":"{'578e634b4f1c1c684d4b4294f9e5281b2133b3ed'}",
      "last_fix_commit":"a4e138660270e7599793fa438cd7b2fc2ce215a6",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/30\/2021, 05:24:27",
      "message":"Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
      "files":"{'tensorflow\/core\/kernels\/sdca_internal.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a4e138660270e7599793fa438cd7b2fc2ce215a6\/tensorflow%2Fcore%2Fkernels%2Fsdca_internal.cc', 'patch': '@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\\n   const Tensor* example_labels_t;\\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\\n   auto example_labels = example_labels_t->flat<float>();\\n+  if (example_labels.size() != num_examples) {\\n+    return errors::InvalidArgument(\"Expected \", num_examples,\\n+                                   \" example labels but got \",\\n+                                   example_labels.size());\\n+  }\\n \\n   OpInputList dense_features_inputs;\\n   TF_RETURN_IF_ERROR('}}",
      "message_norm":"add remaining validation to `sdca_internal.cc`\n\npiperorigin-revid: 387738010\nchange-id: i28eedcfd87a53aaf34deb075acea1f8c95470808",
      "language":"en",
      "entities":"[('add', 'ACTION', ''), ('387738010', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/sdca_internal.cc'])",
      "num_files":1.0,
      "patch_content":"From a4e138660270e7599793fa438cd7b2fc2ce215a6 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 22:24:27 -0700\nSubject: [PATCH] Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808\n---\n tensorflow\/core\/kernels\/sdca_internal.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sdca_internal.cc b\/tensorflow\/core\/kernels\/sdca_internal.cc\nindex 6c4a63b270c25b..164f9382724cac 100644\n--- a\/tensorflow\/core\/kernels\/sdca_internal.cc\n+++ b\/tensorflow\/core\/kernels\/sdca_internal.cc\n@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(",
      "code_diff":"@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR("
    },
    {
      "index":17,
      "vuln_id":"GHSA-77gp-3h4r-6428",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":8.8,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0657c83d08845cc434175934c642299de2c0f042'}",
      "dataset":"osv",
      "summary":"Out of bounds read and write in Tensorflow ### Impact\nThere is a typo in TensorFlow's [`SpecializeType`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/full_type_util.cc#L81-L102) which results in heap OOB read\/write:\n\n```cc\nfor (int i = 0; i < op_def.output_arg_size(); i++) {\n  \/\/ ...\n  for (int j = 0; j < t->args_size(); j++) {\n    auto* arg = t->mutable_args(i);\n    \/\/ ...\n  }\n} \n```\n\nDue to a typo, `arg` is initialized to the `i`th mutable argument in a loop where the loop index is `j`. Hence it is possible to assign to `arg` from outside the vector of arguments. Since this is a mutable proto value, it allows both read and write to outside of bounds data.\n\n### Patches\nWe have patched the issue in GitHub commit [0657c83d08845cc434175934c642299de2c0f042](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0657c83d08845cc434175934c642299de2c0f042).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0657c83d08845cc434175934c642299de2c0f042",
      "commit_sha":"0657c83d08845cc434175934c642299de2c0f042",
      "patch":"SINGLE",
      "chain_ord":"['0657c83d08845cc434175934c642299de2c0f042']",
      "before_first_fix_commit":"{'6e65b0b4ad12fdaa223e87b4ae6d8cb762fcae2b'}",
      "last_fix_commit":"0657c83d08845cc434175934c642299de2c0f042",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/09\/2021, 12:44:43",
      "message":"Fix heap OOB read\/write due to incorrect indexing.\n\nPiperOrigin-RevId: 408578046\nChange-Id: Ifc9ffea49e5890f55fcb2c27568611052c3ddcfa",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'tensorflow\/core\/framework\/full_type_util.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/0657c83d08845cc434175934c642299de2c0f042\/tensorflow%2Fcore%2Fframework%2Ffull_type_util.cc', 'patch': '@@ -100,7 +100,7 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\\n     \/\/ verifications are needed, they should be done by separately, and in a\\n     \/\/ way that can be reused for type inference.\\n     for (int j = 0; j < t->args_size(); j++) {\\n-      auto* arg = t->mutable_args(i);\\n+      auto* arg = t->mutable_args(j);\\n       if (arg->type_id() == TFT_VAR) {\\n         const auto* attr = attrs.Find(arg->s());\\n         if (attr == nullptr) {'}}",
      "message_norm":"fix heap oob read\/write due to incorrect indexing.\n\npiperorigin-revid: 408578046\nchange-id: ifc9ffea49e5890f55fcb2c27568611052c3ddcfa",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('408578046', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/framework\/full_type_util.cc'])",
      "num_files":1.0,
      "patch_content":"From 0657c83d08845cc434175934c642299de2c0f042 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 9 Nov 2021 04:44:43 -0800\nSubject: [PATCH] Fix heap OOB read\/write due to incorrect indexing.\n\nPiperOrigin-RevId: 408578046\nChange-Id: Ifc9ffea49e5890f55fcb2c27568611052c3ddcfa\n---\n tensorflow\/core\/framework\/full_type_util.cc | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/framework\/full_type_util.cc b\/tensorflow\/core\/framework\/full_type_util.cc\nindex e0d8ca0721c850..89617dc97f2496 100644\n--- a\/tensorflow\/core\/framework\/full_type_util.cc\n+++ b\/tensorflow\/core\/framework\/full_type_util.cc\n@@ -100,7 +100,7 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n     \/\/ verifications are needed, they should be done by separately, and in a\n     \/\/ way that can be reused for type inference.\n     for (int j = 0; j < t->args_size(); j++) {\n-      auto* arg = t->mutable_args(i);\n+      auto* arg = t->mutable_args(j);\n       if (arg->type_id() == TFT_VAR) {\n         const auto* attr = attrs.Find(arg->s());\n         if (attr == nullptr) {",
      "code_diff":"@@ -100,7 +100,7 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n     \/\/ verifications are needed, they should be done by separately, and in a\n     \/\/ way that can be reused for type inference.\n     for (int j = 0; j < t->args_size(); j++) {\n-      auto* arg = t->mutable_args(i);\n+      auto* arg = t->mutable_args(j);\n       if (arg->type_id() == TFT_VAR) {\n         const auto* attr = attrs.Find(arg->s());\n         if (attr == nullptr) {"
    },
    {
      "index":18,
      "vuln_id":"GHSA-83rh-hx5x-q9p5",
      "cwe_id":"{'CWE-125'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/opencv\/opencv\/pull\/10480\/commits\/4ca89db22dea962690f31c1781bce5937ee91837'}",
      "dataset":"osv",
      "summary":"Out-of-bounds Read in OpenCV In OpenCV 3.3.1 (corresponding with OpenCV-Python 3.3.1.11), a heap-based buffer over-read exists in the function cv::HdrDecoder::checkSignature in modules\/imgcodecs\/src\/grfmt_hdr.cpp.",
      "published_date":"2021-10-12",
      "chain_len":1,
      "project":"https:\/\/github.com\/opencv\/opencv",
      "commit_href":"https:\/\/github.com\/opencv\/opencv\/pull\/10480\/commits\/4ca89db22dea962690f31c1781bce5937ee91837",
      "commit_sha":"4ca89db22dea962690f31c1781bce5937ee91837",
      "patch":"SINGLE",
      "chain_ord":"['4ca89db22dea962690f31c1781bce5937ee91837']",
      "before_first_fix_commit":"{'30373d2566a3ec097f0418dc2661ec03fcfb71d6'}",
      "last_fix_commit":"4ca89db22dea962690f31c1781bce5937ee91837",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/01\/2018, 13:12:21",
      "message":"imgproc(hdr): fix bounds check in HdrDecoder::checkSignature()",
      "author":"Alexander Alekhin",
      "comments":null,
      "stats":"{'additions': 8, 'deletions': 4, 'total': 12}",
      "files":"{'modules\/imgcodecs\/src\/grfmt_hdr.cpp': {'additions': 8, 'deletions': 4, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencv\/opencv\/raw\/4ca89db22dea962690f31c1781bce5937ee91837\/modules%2Fimgcodecs%2Fsrc%2Fgrfmt_hdr.cpp', 'patch': '@@ -101,10 +101,14 @@ bool HdrDecoder::readData(Mat& _img)\\n \\n bool HdrDecoder::checkSignature( const String& signature ) const\\n {\\n-    if(signature.size() >= m_signature.size() &&\\n-       (!memcmp(signature.c_str(), m_signature.c_str(), m_signature.size()) ||\\n-       !memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())))\\n-       return true;\\n+    if (signature.size() >= m_signature.size() &&\\n+        0 == memcmp(signature.c_str(), m_signature.c_str(), m_signature.size())\\n+    )\\n+        return true;\\n+    if (signature.size() >= m_signature_alt.size() &&\\n+        0 == memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())\\n+    )\\n+        return true;\\n     return false;\\n }'}}",
      "message_norm":"imgproc(hdr): fix bounds check in hdrdecoder::checksignature()",
      "language":"en",
      "entities":"[('bounds check', 'SECWORD', ''), ('hdrdecoder::checksignature', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['modules\/imgcodecs\/src\/grfmt_hdr.cpp'])",
      "num_files":1.0,
      "patch_content":"From 4ca89db22dea962690f31c1781bce5937ee91837 Mon Sep 17 00:00:00 2001\nFrom: Alexander Alekhin <alexander.a.alekhin@gmail.com>\nDate: Mon, 1 Jan 2018 13:12:21 +0000\nSubject: [PATCH] imgproc(hdr): fix bounds check in\n HdrDecoder::checkSignature()\n\n---\n modules\/imgcodecs\/src\/grfmt_hdr.cpp | 12 ++++++++----\n 1 file changed, 8 insertions(+), 4 deletions(-)\n\ndiff --git a\/modules\/imgcodecs\/src\/grfmt_hdr.cpp b\/modules\/imgcodecs\/src\/grfmt_hdr.cpp\nindex f795120547eb..9801106506e2 100644\n--- a\/modules\/imgcodecs\/src\/grfmt_hdr.cpp\n+++ b\/modules\/imgcodecs\/src\/grfmt_hdr.cpp\n@@ -101,10 +101,14 @@ bool HdrDecoder::readData(Mat& _img)\n \n bool HdrDecoder::checkSignature( const String& signature ) const\n {\n-    if(signature.size() >= m_signature.size() &&\n-       (!memcmp(signature.c_str(), m_signature.c_str(), m_signature.size()) ||\n-       !memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())))\n-       return true;\n+    if (signature.size() >= m_signature.size() &&\n+        0 == memcmp(signature.c_str(), m_signature.c_str(), m_signature.size())\n+    )\n+        return true;\n+    if (signature.size() >= m_signature_alt.size() &&\n+        0 == memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())\n+    )\n+        return true;\n     return false;\n }",
      "code_diff":"@@ -101,10 +101,14 @@ bool HdrDecoder::readData(Mat& _img)\n \n bool HdrDecoder::checkSignature( const String& signature ) const\n {\n-    if(signature.size() >= m_signature.size() &&\n-       (!memcmp(signature.c_str(), m_signature.c_str(), m_signature.size()) ||\n-       !memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())))\n-       return true;\n+    if (signature.size() >= m_signature.size() &&\n+        0 == memcmp(signature.c_str(), m_signature.c_str(), m_signature.size())\n+    )\n+        return true;\n+    if (signature.size() >= m_signature_alt.size() &&\n+        0 == memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())\n+    )\n+        return true;\n     return false;\n }"
    }
  ]
}