{
  "schema":{
    "fields":[
      {
        "name":"index",
        "type":"integer"
      },
      {
        "name":"vuln_id",
        "type":"string"
      },
      {
        "name":"cwe_id",
        "type":"string"
      },
      {
        "name":"score",
        "type":"number"
      },
      {
        "name":"chain",
        "type":"string"
      },
      {
        "name":"dataset",
        "type":"string"
      },
      {
        "name":"summary",
        "type":"string"
      },
      {
        "name":"published_date",
        "type":"string"
      },
      {
        "name":"chain_len",
        "type":"integer"
      },
      {
        "name":"project",
        "type":"string"
      },
      {
        "name":"commit_href",
        "type":"string"
      },
      {
        "name":"commit_sha",
        "type":"string"
      },
      {
        "name":"patch",
        "type":"string"
      },
      {
        "name":"chain_ord",
        "type":"string"
      },
      {
        "name":"before_first_fix_commit",
        "type":"string"
      },
      {
        "name":"last_fix_commit",
        "type":"string"
      },
      {
        "name":"chain_ord_pos",
        "type":"number"
      },
      {
        "name":"commit_datetime",
        "type":"string"
      },
      {
        "name":"message",
        "type":"string"
      },
      {
        "name":"author",
        "type":"string"
      },
      {
        "name":"comments",
        "type":"string"
      },
      {
        "name":"stats",
        "type":"string"
      },
      {
        "name":"files",
        "type":"string"
      },
      {
        "name":"message_norm",
        "type":"string"
      },
      {
        "name":"language",
        "type":"string"
      },
      {
        "name":"entities",
        "type":"string"
      },
      {
        "name":"classification_level_1",
        "type":"string"
      },
      {
        "name":"classification_level_2",
        "type":"string"
      },
      {
        "name":"list_files",
        "type":"string"
      },
      {
        "name":"num_files",
        "type":"number"
      },
      {
        "name":"patch_content",
        "type":"string"
      },
      {
        "name":"code_diff",
        "type":"string"
      }
    ],
    "primaryKey":[
      "index"
    ],
    "pandas_version":"1.4.0"
  },
  "data":[
    {
      "index":0,
      "vuln_id":"GHSA-j47f-4232-hvv8",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/44b7f486c0143f68b56c34e2d01e146ee445134a'}",
      "dataset":"osv",
      "summary":"Heap out of bounds read in `RaggedCross` ### Impact\nAn attacker can force accesses outside the bounds of heap allocated arrays by passing in invalid tensor values to `tf.raw_ops.RaggedCross`:\n\n```python\nimport tensorflow as tf\n\nragged_values = []\nragged_row_splits = [] \nsparse_indices = []\nsparse_values = []\nsparse_shape = []\n\ndense_inputs_elem = tf.constant([], shape=[92, 0], dtype=tf.int64)\ndense_inputs = [dense_inputs_elem]\n\ninput_order = \"R\"\nhashed_output = False\nnum_buckets = 0\nhash_key = 0 \n\ntf.raw_ops.RaggedCross(ragged_values=ragged_values,\n    ragged_row_splits=ragged_row_splits,\n    sparse_indices=sparse_indices,\n    sparse_values=sparse_values,\n    sparse_shape=sparse_shape,\n    dense_inputs=dense_inputs,\n    input_order=input_order,\n    hashed_output=hashed_output,\n    num_buckets=num_buckets,\n    hash_key=hash_key,\n    out_values_type=tf.int64,\n    out_row_splits_type=tf.int64)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/efea03b38fb8d3b81762237dc85e579cc5fc6e87\/tensorflow\/core\/kernels\/ragged_cross_op.cc#L456-L487) lacks validation for the user supplied arguments:\n\n```cc\nint next_ragged = 0;\nint next_sparse = 0;\nint next_dense = 0;\nfor (char c : input_order_) {\n  if (c == 'R') {\n    TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n        ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n        features));\n    next_ragged++;\n  } else if (c == 'S') {\n    TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n        sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n        batch_size, features));\n    next_sparse++;\n  } else if (c == 'D') {\n    TF_RETURN_IF_ERROR(\n        BuildDenseFeatureReader(dense_list[next_dense++], features));\n  }\n  ...\n}\n```\n\nEach of the above branches call a helper function after accessing array elements via a `*_list[next_*]` pattern, followed by incrementing the `next_*` index. However, as there is no validation that the `next_*` values are in the valid range for the corresponding `*_list` arrays, this results in heap OOB reads.\n\n### Patches\nWe have patched the issue in GitHub commit [44b7f486c0143f68b56c34e2d01e146ee445134a](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/44b7f486c0143f68b56c34e2d01e146ee445134a).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/44b7f486c0143f68b56c34e2d01e146ee445134a",
      "commit_sha":"44b7f486c0143f68b56c34e2d01e146ee445134a",
      "patch":"SINGLE",
      "chain_ord":"['44b7f486c0143f68b56c34e2d01e146ee445134a']",
      "before_first_fix_commit":"{'efea03b38fb8d3b81762237dc85e579cc5fc6e87'}",
      "last_fix_commit":"44b7f486c0143f68b56c34e2d01e146ee445134a",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/21\/2021, 23:19:54",
      "message":"Fix out of bounds read in `ragged_cross_op.cc`.\n\nPiperOrigin-RevId: 369757702\nChange-Id: Ie6e5d2c21513a8d56bf41fcf35960caf76e890f9",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 30, 'deletions': 0, 'total': 30}",
      "files":"{'tensorflow\/core\/kernels\/ragged_cross_op.cc': {'additions': 30, 'deletions': 0, 'changes': 30, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/44b7f486c0143f68b56c34e2d01e146ee445134a\/tensorflow%2Fcore%2Fkernels%2Fragged_cross_op.cc', 'patch': '@@ -21,6 +21,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/register_types.h\"\\n #include \"tensorflow\/core\/framework\/tensor.h\"\\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\\n #include \"tensorflow\/core\/util\/util.h\"\\n #include \"tensorflow\/core\/util\/work_sharder.h\"\\n@@ -466,16 +467,45 @@ class RaggedCrossOp : public OpKernel {\\n     int next_dense = 0;\\n     for (char c : input_order_) {\\n       if (c == \\'R\\') {\\n+        if (next_ragged >= ragged_values_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a ragged tensor value at index \",\\n+              next_ragged, \" from a list of \", ragged_values_list.size(),\\n+              \" values.\");\\n+        if (next_ragged >= ragged_splits_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a ragged tensor split at index \",\\n+              next_ragged, \" from a list of \", ragged_splits_list.size(),\\n+              \" splits.\");\\n         TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\\n             ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\\n             features));\\n         next_ragged++;\\n       } else if (c == \\'S\\') {\\n+        if (next_sparse >= sparse_values_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a sparse tensor value at index \",\\n+              next_sparse, \" from a list of \", sparse_values_list.size(),\\n+              \" values.\");\\n+        if (next_sparse >= sparse_indices_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a sparse tensor index at index \",\\n+              next_sparse, \" from a list of \", sparse_indices_list.size(),\\n+              \" indices.\");\\n         TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\\n             sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\\n             batch_size, features));\\n         next_sparse++;\\n       } else if (c == \\'D\\') {\\n+        if (next_dense >= dense_list.size())\\n+          return errors::InvalidArgument(\\n+              \"input_order \\\\\"\", input_order_,\\n+              \"\\\\\" specifies reading a dense tensor at index \", next_dense,\\n+              \" from a list of \", dense_list.size(), \" tensors.\");\\n         TF_RETURN_IF_ERROR(\\n             BuildDenseFeatureReader(dense_list[next_dense++], features));\\n       } else {'}}",
      "message_norm":"fix out of bounds read in `ragged_cross_op.cc`.\n\npiperorigin-revid: 369757702\nchange-id: ie6e5d2c21513a8d56bf41fcf35960caf76e890f9",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('out of bounds read', 'SECWORD', ''), ('369757702', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_cross_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 44b7f486c0143f68b56c34e2d01e146ee445134a Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 21 Apr 2021 16:19:54 -0700\nSubject: [PATCH] Fix out of bounds read in `ragged_cross_op.cc`.\n\nPiperOrigin-RevId: 369757702\nChange-Id: Ie6e5d2c21513a8d56bf41fcf35960caf76e890f9\n---\n tensorflow\/core\/kernels\/ragged_cross_op.cc | 30 ++++++++++++++++++++++\n 1 file changed, 30 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/ragged_cross_op.cc b\/tensorflow\/core\/kernels\/ragged_cross_op.cc\nindex ea65c0ee2b5b21..5dfe93f4166592 100644\n--- a\/tensorflow\/core\/kernels\/ragged_cross_op.cc\n+++ b\/tensorflow\/core\/kernels\/ragged_cross_op.cc\n@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/register_types.h\"\n #include \"tensorflow\/core\/framework\/tensor.h\"\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\n #include \"tensorflow\/core\/util\/util.h\"\n #include \"tensorflow\/core\/util\/work_sharder.h\"\n@@ -466,16 +467,45 @@ class RaggedCrossOp : public OpKernel {\n     int next_dense = 0;\n     for (char c : input_order_) {\n       if (c == 'R') {\n+        if (next_ragged >= ragged_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor value at index \",\n+              next_ragged, \" from a list of \", ragged_values_list.size(),\n+              \" values.\");\n+        if (next_ragged >= ragged_splits_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor split at index \",\n+              next_ragged, \" from a list of \", ragged_splits_list.size(),\n+              \" splits.\");\n         TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n             ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n             features));\n         next_ragged++;\n       } else if (c == 'S') {\n+        if (next_sparse >= sparse_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor value at index \",\n+              next_sparse, \" from a list of \", sparse_values_list.size(),\n+              \" values.\");\n+        if (next_sparse >= sparse_indices_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor index at index \",\n+              next_sparse, \" from a list of \", sparse_indices_list.size(),\n+              \" indices.\");\n         TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n             sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n             batch_size, features));\n         next_sparse++;\n       } else if (c == 'D') {\n+        if (next_dense >= dense_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a dense tensor at index \", next_dense,\n+              \" from a list of \", dense_list.size(), \" tensors.\");\n         TF_RETURN_IF_ERROR(\n             BuildDenseFeatureReader(dense_list[next_dense++], features));\n       } else {",
      "code_diff":"@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/register_types.h\"\n #include \"tensorflow\/core\/framework\/tensor.h\"\n #include \"tensorflow\/core\/framework\/tensor_shape.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/fingerprint.h\"\n #include \"tensorflow\/core\/util\/util.h\"\n #include \"tensorflow\/core\/util\/work_sharder.h\"\n@@ -466,16 +467,45 @@ class RaggedCrossOp : public OpKernel {\n     int next_dense = 0;\n     for (char c : input_order_) {\n       if (c == 'R') {\n+        if (next_ragged >= ragged_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor value at index \",\n+              next_ragged, \" from a list of \", ragged_values_list.size(),\n+              \" values.\");\n+        if (next_ragged >= ragged_splits_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a ragged tensor split at index \",\n+              next_ragged, \" from a list of \", ragged_splits_list.size(),\n+              \" splits.\");\n         TF_RETURN_IF_ERROR(BuildRaggedFeatureReader(\n             ragged_values_list[next_ragged], ragged_splits_list[next_ragged],\n             features));\n         next_ragged++;\n       } else if (c == 'S') {\n+        if (next_sparse >= sparse_values_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor value at index \",\n+              next_sparse, \" from a list of \", sparse_values_list.size(),\n+              \" values.\");\n+        if (next_sparse >= sparse_indices_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a sparse tensor index at index \",\n+              next_sparse, \" from a list of \", sparse_indices_list.size(),\n+              \" indices.\");\n         TF_RETURN_IF_ERROR(BuildSparseFeatureReader(\n             sparse_indices_list[next_sparse], sparse_values_list[next_sparse],\n             batch_size, features));\n         next_sparse++;\n       } else if (c == 'D') {\n+        if (next_dense >= dense_list.size())\n+          return errors::InvalidArgument(\n+              \"input_order \\\"\", input_order_,\n+              \"\\\" specifies reading a dense tensor at index \", next_dense,\n+              \" from a list of \", dense_list.size(), \" tensors.\");\n         TF_RETURN_IF_ERROR(\n             BuildDenseFeatureReader(dense_list[next_dense++], features));\n       } else {"
    },
    {
      "index":1,
      "vuln_id":"GHSA-h9px-9vqg-222h",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/99085e8ff02c3763a0ec2263e44daec416f6a387'}",
      "dataset":"osv",
      "summary":"Heap OOB in `QuantizeAndDequantizeV3` ### Impact\nAn attacker can read data outside of bounds of heap allocated buffer in `tf.raw_ops.QuantizeAndDequantizeV3`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.QuantizeAndDequantizeV3(\n  input=[2.5,2.5], input_min=[0,0], input_max=[1,1], num_bits=[30],\n  signed_input=False, range_given=False, narrow_range=False, axis=3)\n```   \n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/11ff7f80667e6490d7b5174aa6bf5e01886e770f\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc#L237) does not validate the value of user supplied `axis` attribute before using it to index in the array backing the `input` argument:\n\n```cc\nconst int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n```\n\n### Patches\nWe have patched the issue in GitHub commit [99085e8ff02c3763a0ec2263e44daec416f6a387](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/99085e8ff02c3763a0ec2263e44daec416f6a387).\n  \nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Aivul Team from Qihoo 360.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/99085e8ff02c3763a0ec2263e44daec416f6a387",
      "commit_sha":"99085e8ff02c3763a0ec2263e44daec416f6a387",
      "patch":"SINGLE",
      "chain_ord":"['99085e8ff02c3763a0ec2263e44daec416f6a387']",
      "before_first_fix_commit":"{'11ff7f80667e6490d7b5174aa6bf5e01886e770f'}",
      "last_fix_commit":"99085e8ff02c3763a0ec2263e44daec416f6a387",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/27\/2021, 00:32:41",
      "message":"Fix `tf.raw_ops.QuantizeAndDequantizeV3` array index failure.\n\nPiperOrigin-RevId: 370577691\nChange-Id: Ifeae64212f6bcd139435824fa2748d1329213c4c",
      "author":"Amit Patankar",
      "comments":null,
      "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
      "files":"{'tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/99085e8ff02c3763a0ec2263e44daec416f6a387\/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc', 'patch': '@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\\n limitations under the License.\\n ==============================================================================*\/\\n \\n+#include \"tensorflow\/core\/framework\/op_requires.h\"\\n #define EIGEN_USE_THREADS\\n \\n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\\\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& input = ctx->input(0);\\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\\n+                errors::InvalidArgument(\\n+                    \"Axis requested is larger than input dimensions. Axis: \",\\n+                    axis_, \" Input Dimensions: \", input.dims()));\\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));'}}",
      "message_norm":"fix `tf.raw_ops.quantizeanddequantizev3` array index failure.\n\npiperorigin-revid: 370577691\nchange-id: ifeae64212f6bcd139435824fa2748d1329213c4c",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('370577691', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 99085e8ff02c3763a0ec2263e44daec416f6a387 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Mon, 26 Apr 2021 17:32:41 -0700\nSubject: [PATCH] Fix `tf.raw_ops.QuantizeAndDequantizeV3` array index failure.\n\nPiperOrigin-RevId: 370577691\nChange-Id: Ifeae64212f6bcd139435824fa2748d1329213c4c\n---\n tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\nindex c2a7a90d8713d8..f01a70114591bf 100644\n--- a\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantize_and_dequantize_op.cc\n@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*\/\n \n+#include \"tensorflow\/core\/framework\/op_requires.h\"\n #define EIGEN_USE_THREADS\n \n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\n+                errors::InvalidArgument(\n+                    \"Axis requested is larger than input dimensions. Axis: \",\n+                    axis_, \" Input Dimensions: \", input.dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
      "code_diff":"@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*\/\n \n+#include \"tensorflow\/core\/framework\/op_requires.h\"\n #define EIGEN_USE_THREADS\n \n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n@@ -234,6 +235,10 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, axis_ < input.dims(),\n+                errors::InvalidArgument(\n+                    \"Axis requested is larger than input dimensions. Axis: \",\n+                    axis_, \" Input Dimensions: \", input.dims()));\n     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));"
    },
    {
      "index":2,
      "vuln_id":"GHSA-374m-jm66-3vj8",
      "cwe_id":"{'CWE-125'}",
      "score":7.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f410212e373eb2aec4c9e60bf3702eba99a38aba'}",
      "dataset":"osv",
      "summary":"Heap OOB in `SparseBinCount` ### Impact\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/e71b86d47f8bc1816bf54d7bddc4170e47670b97\/tensorflow\/core\/kernels\/bincount_op.cc#L353-L417) of `SparseBinCount` is vulnerable to a heap OOB:\n\n```python\nimport tensorflow as tf\n  \n  \ntf.raw_ops.SparseBincount(\n  indices=[[0],[1],[2]]\n  values=[0,-10000000]\n  dense_shape=[1,1]\n  size=[1]\n  weights=[3,2,1]\n  binary_output=False)\n```\n\nThis is because of missing validation between the elements of the `values` argument and the shape of the sparse output:\n\n\n```cc\nfor (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n  const int64_t batch = indices_mat(i, 0);\n  const Tidx bin = values(i);\n  ...\n  out(batch, bin) = ...;\n}\n```\n\n### Patches\nWe have patched the issue in GitHub commit [f410212e373eb2aec4c9e60bf3702eba99a38aba](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f410212e373eb2aec4c9e60bf3702eba99a38aba).\n\nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-11-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/f410212e373eb2aec4c9e60bf3702eba99a38aba",
      "commit_sha":"f410212e373eb2aec4c9e60bf3702eba99a38aba",
      "patch":"SINGLE",
      "chain_ord":"['f410212e373eb2aec4c9e60bf3702eba99a38aba']",
      "before_first_fix_commit":"{'4656caa7d74420454da967288af143ec73fb4c9b'}",
      "last_fix_commit":"f410212e373eb2aec4c9e60bf3702eba99a38aba",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/30\/2021, 13:36:55",
      "message":"Prevent out-of-bound accesses in SparseBincount.\n\nPiperOrigin-RevId: 399918616\nChange-Id: I11d154f4444d3fde1f09c5c40628b8671791a30d",
      "author":"Penporn Koanantakool",
      "comments":null,
      "stats":"{'additions': 10, 'deletions': 0, 'total': 10}",
      "files":"{'tensorflow\/core\/kernels\/bincount_op.cc': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/f410212e373eb2aec4c9e60bf3702eba99a38aba\/tensorflow%2Fcore%2Fkernels%2Fbincount_op.cc', 'patch': '@@ -405,6 +405,16 @@ class SparseBincountOp : public OpKernel {\\n       for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\\n         const int64_t batch = indices_mat(i, 0);\\n         const Tidx bin = values(i);\\n+        OP_REQUIRES(\\n+            ctx, batch < out.dimension(0),\\n+            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\\n+                                    \") must be less than the dimension size (\",\\n+                                    out.dimension(0), \").\"));\\n+        OP_REQUIRES(\\n+            ctx, bin < out.dimension(1),\\n+            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,\\n+                                    \") must be less then the dimension size (\",\\n+                                    out.dimension(1), \").\"));\\n         if (bin < size) {\\n           if (binary_output_) {\\n             out(batch, bin) = T(1);'}}",
      "message_norm":"prevent out-of-bound accesses in sparsebincount.\n\npiperorigin-revid: 399918616\nchange-id: i11d154f4444d3fde1f09c5c40628b8671791a30d",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('out-of-bound', 'SECWORD', ''), ('399918616', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/bincount_op.cc'])",
      "num_files":1.0,
      "patch_content":"From f410212e373eb2aec4c9e60bf3702eba99a38aba Mon Sep 17 00:00:00 2001\nFrom: Penporn Koanantakool <penporn@google.com>\nDate: Thu, 30 Sep 2021 06:36:55 -0700\nSubject: [PATCH] Prevent out-of-bound accesses in SparseBincount.\n\nPiperOrigin-RevId: 399918616\nChange-Id: I11d154f4444d3fde1f09c5c40628b8671791a30d\n---\n tensorflow\/core\/kernels\/bincount_op.cc | 10 ++++++++++\n 1 file changed, 10 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/bincount_op.cc b\/tensorflow\/core\/kernels\/bincount_op.cc\nindex 6d668211da0968..0f661dd9f201a6 100644\n--- a\/tensorflow\/core\/kernels\/bincount_op.cc\n+++ b\/tensorflow\/core\/kernels\/bincount_op.cc\n@@ -405,6 +405,16 @@ class SparseBincountOp : public OpKernel {\n       for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n         const int64_t batch = indices_mat(i, 0);\n         const Tidx bin = values(i);\n+        OP_REQUIRES(\n+            ctx, batch < out.dimension(0),\n+            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\n+                                    \") must be less than the dimension size (\",\n+                                    out.dimension(0), \").\"));\n+        OP_REQUIRES(\n+            ctx, bin < out.dimension(1),\n+            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,\n+                                    \") must be less then the dimension size (\",\n+                                    out.dimension(1), \").\"));\n         if (bin < size) {\n           if (binary_output_) {\n             out(batch, bin) = T(1);",
      "code_diff":"@@ -405,6 +405,16 @@ class SparseBincountOp : public OpKernel {\n       for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n         const int64_t batch = indices_mat(i, 0);\n         const Tidx bin = values(i);\n+        OP_REQUIRES(\n+            ctx, batch < out.dimension(0),\n+            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\n+                                    \") must be less than the dimension size (\",\n+                                    out.dimension(0), \").\"));\n+        OP_REQUIRES(\n+            ctx, bin < out.dimension(1),\n+            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,\n+                                    \") must be less then the dimension size (\",\n+                                    out.dimension(1), \").\"));\n         if (bin < size) {\n           if (binary_output_) {\n             out(batch, bin) = T(1);"
    },
    {
      "index":3,
      "vuln_id":"GHSA-9697-98pf-4rw7",
      "cwe_id":"{'CWE-125'}",
      "score":5.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/42459e4273c2e47a3232cc16c4f4fff3b3a35c38'}",
      "dataset":"osv",
      "summary":"Heap OOB in `UpperBound` and `LowerBound` ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.UpperBound`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.UpperBound(\n  sorted_input=[1,2,3],\n  values=tf.constant(value=[[0,0,0],[1,1,1],[2,2,2]],dtype=tf.int64),\n  out_type=tf.int64)\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/searchsorted_op.cc#L85-L104) does not validate the rank of `sorted_input` argument:\n\n```cc\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor& sorted_inputs_t = ctx->input(0);\n    \/\/ ...\n    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                Status(error::INVALID_ARGUMENT,\n                       \"Leading dim_size of both tensors must match.\"));\n    \/\/ ...\n    if (output_t->dtype() == DT_INT32) {\n      OP_REQUIRES(ctx,\n                  FastBoundsCheck(sorted_inputs_t.dim_size(1), ...));\n      \/\/ ...\n    }\n```\n\nAs we access the first two dimensions of `sorted_inputs_t` tensor, it must have rank at least 2.\n\nA similar issue occurs in `tf.raw_ops.LowerBound`.\n\n### Patches\nWe have patched the issue in GitHub commit [42459e4273c2e47a3232cc16c4f4fff3b3a35c38](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/42459e4273c2e47a3232cc16c4f4fff3b3a35c38).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "commit_sha":"42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "patch":"SINGLE",
      "chain_ord":"['42459e4273c2e47a3232cc16c4f4fff3b3a35c38']",
      "before_first_fix_commit":"{'b5cdbf12ffcaaffecf98f22a6be5a64bb96e4f58'}",
      "last_fix_commit":"42459e4273c2e47a3232cc16c4f4fff3b3a35c38",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/30\/2021, 05:25:05",
      "message":"Prevent CHECK-fail\/heap OOB in UpperBound and LowerBound\n\nPiperOrigin-RevId: 387738073\nChange-Id: Iee74de95ddad18440d052a75a5a1cb67544f490a",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 8, 'deletions': 0, 'total': 8}",
      "files":"{'tensorflow\/core\/kernels\/searchsorted_op.cc': {'additions': 8, 'deletions': 0, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/42459e4273c2e47a3232cc16c4f4fff3b3a35c38\/tensorflow%2Fcore%2Fkernels%2Fsearchsorted_op.cc', 'patch': '@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\\n     const Tensor& sorted_inputs_t = ctx->input(0);\\n     const Tensor& values_t = ctx->input(1);\\n \\n+    \/\/ inputs must be at least a matrix\\n+    OP_REQUIRES(\\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\\n     \/\/ must have same batch dim_size for both\\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\\n                 Status(error::INVALID_ARGUMENT,\\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\\n     const Tensor& sorted_inputs_t = ctx->input(0);\\n     const Tensor& values_t = ctx->input(1);\\n \\n+    \/\/ inputs must be at least a matrix\\n+    OP_REQUIRES(\\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\\n     \/\/ must have same batch dim_size for both\\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\\n                 Status(error::INVALID_ARGUMENT,'}}",
      "message_norm":"prevent check-fail\/heap oob in upperbound and lowerbound\n\npiperorigin-revid: 387738073\nchange-id: iee74de95ddad18440d052a75a5a1cb67544f490a",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('387738073', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/searchsorted_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 42459e4273c2e47a3232cc16c4f4fff3b3a35c38 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 22:25:05 -0700\nSubject: [PATCH] Prevent CHECK-fail\/heap OOB in UpperBound and LowerBound\n\nPiperOrigin-RevId: 387738073\nChange-Id: Iee74de95ddad18440d052a75a5a1cb67544f490a\n---\n tensorflow\/core\/kernels\/searchsorted_op.cc | 8 ++++++++\n 1 file changed, 8 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/searchsorted_op.cc b\/tensorflow\/core\/kernels\/searchsorted_op.cc\nindex 01e221dc471c4d..5f075a6a540e9f 100644\n--- a\/tensorflow\/core\/kernels\/searchsorted_op.cc\n+++ b\/tensorflow\/core\/kernels\/searchsorted_op.cc\n@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    \/\/ inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     \/\/ must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    \/\/ inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     \/\/ must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,",
      "code_diff":"@@ -86,6 +86,10 @@ class UpperBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    \/\/ inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     \/\/ must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,\n@@ -127,6 +131,10 @@ class LowerBoundOp : public OpKernel {\n     const Tensor& sorted_inputs_t = ctx->input(0);\n     const Tensor& values_t = ctx->input(1);\n \n+    \/\/ inputs must be at least a matrix\n+    OP_REQUIRES(\n+        ctx, sorted_inputs_t.shape().dims() >= 2,\n+        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n     \/\/ must have same batch dim_size for both\n     OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                 Status(error::INVALID_ARGUMENT,"
    },
    {
      "index":4,
      "vuln_id":"GHSA-4hvf-hxvg-f67v",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":8.8,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038'}",
      "dataset":"osv",
      "summary":"Read and Write outside of bounds in TensorFlow ### Impact\nAn attacker can craft a TFLite model that would allow limited reads and writes outside of arrays in TFLite. This exploits missing validation in [the conversion from sparse tensors to dense tensors](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ca6f96b62ad84207fbec580404eaa7dd7403a550\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc#L252-L293).\n\n### Patches\nWe have patched the issue in GitHub commit [6364463d6f5b6254cac3d6aedf999b6a96225038](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038).\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6364463d6f5b6254cac3d6aedf999b6a96225038",
      "commit_sha":"6364463d6f5b6254cac3d6aedf999b6a96225038",
      "patch":"SINGLE",
      "chain_ord":"['6364463d6f5b6254cac3d6aedf999b6a96225038']",
      "before_first_fix_commit":"{'3e49ff637ad4f05c133d235a568943d19216fa9a'}",
      "last_fix_commit":"6364463d6f5b6254cac3d6aedf999b6a96225038",
      "chain_ord_pos":1.0,
      "commit_datetime":"12\/16\/2021, 23:37:14",
      "message":"[lite] Add some safety checks to avoid out of bound access for sparsity format\n\nPiperOrigin-RevId: 416910386\nChange-Id: Ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
      "author":"Karim Nosir",
      "comments":null,
      "stats":"{'additions': 11, 'deletions': 7, 'total': 18}",
      "files":"{'tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc': {'additions': 11, 'deletions': 7, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6364463d6f5b6254cac3d6aedf999b6a96225038\/tensorflow%2Flite%2Fkernels%2Finternal%2Futils%2Fsparsity_format_converter.cc', 'patch': '@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\\n   block_size_.resize(block_map_.size());\\n   for (int i = 0; i < original_rank; i++) {\\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\\n-      int orig_dim = traversal_order_[original_rank + block_dim];\\n-      block_size_[block_dim] = dense_size[orig_dim];\\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\\n-      block_dim++;\\n+      if (original_rank + block_dim < traversal_order_.size()) {\\n+        int orig_dim = traversal_order_[original_rank + block_dim];\\n+        block_size_[block_dim] = dense_size[orig_dim];\\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\\n+        block_dim++;\\n+      }\\n     } else {\\n       blocked_shape_[i] = dense_shape_[i];\\n     }\\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\\n                src_data_ptr, dest_data);\\n     }\\n-  } else {\\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\\n     const auto& array_segments = dim_metadata_[metadata_idx];\\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\\n          i++) {\\n-      indices[level] = array_indices[i];\\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      if (i < array_indices.size() && level < indices.size()) {\\n+        indices[level] = array_indices[i];\\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\\n+      }\\n     }\\n   }\\n }'}}",
      "message_norm":"[lite] add some safety checks to avoid out of bound access for sparsity format\n\npiperorigin-revid: 416910386\nchange-id: ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a",
      "language":"en",
      "entities":"[('add', 'ACTION', ''), ('safety checks', 'SECWORD', ''), ('out of bound access', 'SECWORD', ''), ('416910386', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc'])",
      "num_files":1.0,
      "patch_content":"From 6364463d6f5b6254cac3d6aedf999b6a96225038 Mon Sep 17 00:00:00 2001\nFrom: Karim Nosir <karimnosseir@google.com>\nDate: Thu, 16 Dec 2021 15:37:14 -0800\nSubject: [PATCH] [lite] Add some safety checks to avoid out of bound access\n for sparsity format\n\nPiperOrigin-RevId: 416910386\nChange-Id: Ic0b4dc048dc4b5a6309c572b8c4c9f776e4db60a\n---\n ...\/utils\/sparsity_format_converter.cc         | 18 +++++++++++-------\n 1 file changed, 11 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc b\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\nindex 22aa5d019e7395..0595d49365c387 100644\n--- a\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\n+++ b\/tensorflow\/lite\/kernels\/internal\/utils\/sparsity_format_converter.cc\n@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\n   block_size_.resize(block_map_.size());\n   for (int i = 0; i < original_rank; i++) {\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\n-      int orig_dim = traversal_order_[original_rank + block_dim];\n-      block_size_[block_dim] = dense_size[orig_dim];\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n-      block_dim++;\n+      if (original_rank + block_dim < traversal_order_.size()) {\n+        int orig_dim = traversal_order_[original_rank + block_dim];\n+        block_size_[block_dim] = dense_size[orig_dim];\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n+        block_dim++;\n+      }\n     } else {\n       blocked_shape_[i] = dense_shape_[i];\n     }\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\n                src_data_ptr, dest_data);\n     }\n-  } else {\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\n     const auto& array_segments = dim_metadata_[metadata_idx];\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\n          i++) {\n-      indices[level] = array_indices[i];\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      if (i < array_indices.size() && level < indices.size()) {\n+        indices[level] = array_indices[i];\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      }\n     }\n   }\n }",
      "code_diff":"@@ -282,10 +282,12 @@ void FormatConverter<T>::InitSparseToDenseConverter(\n   block_size_.resize(block_map_.size());\n   for (int i = 0; i < original_rank; i++) {\n     if (block_dim < block_map_.size() && block_map_[block_dim] == i) {\n-      int orig_dim = traversal_order_[original_rank + block_dim];\n-      block_size_[block_dim] = dense_size[orig_dim];\n-      blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n-      block_dim++;\n+      if (original_rank + block_dim < traversal_order_.size()) {\n+        int orig_dim = traversal_order_[original_rank + block_dim];\n+        block_size_[block_dim] = dense_size[orig_dim];\n+        blocked_shape_[i] = dense_shape_[i] \/ dense_size[orig_dim];\n+        block_dim++;\n+      }\n     } else {\n       blocked_shape_[i] = dense_shape_[i];\n     }\n@@ -328,13 +330,15 @@ void FormatConverter<T>::Populate(const T* src_data, std::vector<int> indices,\n       Populate(src_data, indices, level + 1, prev_idx * shape_of_level + i,\n                src_data_ptr, dest_data);\n     }\n-  } else {\n+  } else if (prev_idx + 1 < dim_metadata_[metadata_idx].size()) {\n     const auto& array_segments = dim_metadata_[metadata_idx];\n     const auto& array_indices = dim_metadata_[metadata_idx + 1];\n     for (int i = array_segments[prev_idx]; i < array_segments[prev_idx + 1];\n          i++) {\n-      indices[level] = array_indices[i];\n-      Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      if (i < array_indices.size() && level < indices.size()) {\n+        indices[level] = array_indices[i];\n+        Populate(src_data, indices, level + 1, i, src_data_ptr, dest_data);\n+      }\n     }\n   }\n }"
    },
    {
      "index":5,
      "vuln_id":"GHSA-9xh4-23q4-v6wr",
      "cwe_id":"{'CWE-476', 'CWE-787', 'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0'}",
      "dataset":"osv",
      "summary":"Heap buffer overflow and undefined behavior in `FusedBatchNorm` ### Impact\nThe implementation of `tf.raw_ops.FusedBatchNorm` is vulnerable to a heap buffer overflow:\n      \n```python\nimport tensorflow as tf\n\nx = tf.zeros([10, 10, 10, 6], dtype=tf.float32)\nscale = tf.constant([0.0], shape=[1], dtype=tf.float32)\noffset = tf.constant([0.0], shape=[1], dtype=tf.float32)\nmean = tf.constant([0.0], shape=[1], dtype=tf.float32)\nvariance = tf.constant([0.0], shape=[1], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n    \ntf.raw_ops.FusedBatchNorm(\n  x=x, scale=scale, offset=offset, mean=mean, variance=variance,\n  epsilon=epsilon, exponential_avg_factor=exponential_avg_factor,\n  data_format=data_format, is_training=is_training)\n```\n  \nIf the tensors are empty, the same implementation can trigger undefined behavior by dereferencing null pointers:\n\n```python \nimport tensorflow as tf\nimport numpy as np\n\nx = tf.zeros([10, 10, 10, 1], dtype=tf.float32)\nscale = tf.constant([], shape=[0], dtype=tf.float32)\noffset = tf.constant([], shape=[0], dtype=tf.float32)\nmean = tf.constant([], shape=[0], dtype=tf.float32)\nvariance = tf.constant([], shape=[0], dtype=tf.float32)\nepsilon = 0.0\nexponential_avg_factor = 0.0\ndata_format = \"NHWC\"\nis_training = False\n\ntf.raw_ops.FusedBatchNorm(\n  x=x, scale=scale, offset=offset, mean=mean, variance=variance, \n  epsilon=epsilon, exponential_avg_factor=exponential_avg_factor,\n  data_format=data_format, is_training=is_training)\n``` \n\nThe  [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/57d86e0db5d1365f19adcce848dfc1bf89fdd4c7\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc) fails to validate that `scale`, `offset`, `mean` and `variance` (the last two only when required) all have the same number of elements as the number of channels of `x`. This results in heap out of bounds reads when the buffers backing these tensors are indexed past their boundary.\n\nIf the tensors are empty, the validation mentioned in the above paragraph would also trigger and prevent the undefined behavior.\n\n### Patches\nWe have patched the issue in GitHub commit [6972f9dfe325636b3db4e0bc517ee22a159365c0](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/6972f9dfe325636b3db4e0bc517ee22a159365c0",
      "commit_sha":"6972f9dfe325636b3db4e0bc517ee22a159365c0",
      "patch":"SINGLE",
      "chain_ord":"['6972f9dfe325636b3db4e0bc517ee22a159365c0']",
      "before_first_fix_commit":"{'57d86e0db5d1365f19adcce848dfc1bf89fdd4c7'}",
      "last_fix_commit":"6972f9dfe325636b3db4e0bc517ee22a159365c0",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/07\/2021, 00:45:51",
      "message":"Add missing valuidation to FusedBatchNorm.\n\nPiperOrigin-RevId: 372460336\nChange-Id: Ic8c4e4de67c58a741bd87f2e182bed07247d1126",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 27, 'deletions': 1, 'total': 28}",
      "files":"{'tensorflow\/core\/kernels\/fused_batch_norm_op.cc': {'additions': 27, 'deletions': 1, 'changes': 28, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/6972f9dfe325636b3db4e0bc517ee22a159365c0\/tensorflow%2Fcore%2Fkernels%2Ffused_batch_norm_op.cc', 'patch': '@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\\n     }\\n \\n+    const auto num_channels = GetTensorDim(x, tensor_format_, \\'C\\');\\n+    OP_REQUIRES(\\n+        context, scale.NumElements() == num_channels,\\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\\n+                                \"as the channels of x, got \",\\n+                                scale.NumElements(), \" and \", num_channels));\\n+    OP_REQUIRES(\\n+        context, offset.NumElements() == num_channels,\\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\\n+                                \"as the channels of x, got \",\\n+                                offset.NumElements(), \" and \", num_channels));\\n+    if (estimated_mean.NumElements() != 0) {\\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\\n+                  errors::InvalidArgument(\\n+                      \"mean must be empty or have the same number of \"\\n+                      \"elements as the channels of x, got \",\\n+                      estimated_mean.NumElements(), \" and \", num_channels));\\n+    }\\n+    if (estimated_variance.NumElements() != 0) {\\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\\n+                  errors::InvalidArgument(\\n+                      \"variance must be empty or have the same number of \"\\n+                      \"elements as the channels of x, got \",\\n+                      estimated_variance.NumElements(), \" and \", num_channels));\\n+    }\\n+\\n     if (has_side_input_) {\\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\\n                   errors::InvalidArgument(\\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\\n       \/\/ NOTE(ezhulenev): This requirement is coming from implementation\\n       \/\/ details of cudnnBatchNormalizationForwardTrainingEx.\\n       OP_REQUIRES(\\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\\n+          context, !is_training_ || num_channels % 4 == 0,\\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\\n                                   \"channel dimension to be a multiple of 4.\"));\\n     }'}}",
      "message_norm":"add missing valuidation to fusedbatchnorm.\n\npiperorigin-revid: 372460336\nchange-id: ic8c4e4de67c58a741bd87f2e182bed07247d1126",
      "language":"en",
      "entities":"[('add', 'ACTION', ''), ('372460336', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/fused_batch_norm_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 6972f9dfe325636b3db4e0bc517ee22a159365c0 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 6 May 2021 17:45:51 -0700\nSubject: [PATCH] Add missing valuidation to FusedBatchNorm.\n\nPiperOrigin-RevId: 372460336\nChange-Id: Ic8c4e4de67c58a741bd87f2e182bed07247d1126\n---\n ...\/core\/kernels\/fused_batch_norm_op.cc       | 28 ++++++++++++++++++-\n 1 file changed, 27 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc b\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\nindex e564b19857c383..7b0932d953261c 100644\n--- a\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\n+++ b\/tensorflow\/core\/kernels\/fused_batch_norm_op.cc\n@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\n     }\n \n+    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n+    OP_REQUIRES(\n+        context, scale.NumElements() == num_channels,\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                scale.NumElements(), \" and \", num_channels));\n+    OP_REQUIRES(\n+        context, offset.NumElements() == num_channels,\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                offset.NumElements(), \" and \", num_channels));\n+    if (estimated_mean.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"mean must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_mean.NumElements(), \" and \", num_channels));\n+    }\n+    if (estimated_variance.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"variance must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_variance.NumElements(), \" and \", num_channels));\n+    }\n+\n     if (has_side_input_) {\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\n                   errors::InvalidArgument(\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\n       \/\/ NOTE(ezhulenev): This requirement is coming from implementation\n       \/\/ details of cudnnBatchNormalizationForwardTrainingEx.\n       OP_REQUIRES(\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\n+          context, !is_training_ || num_channels % 4 == 0,\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                   \"channel dimension to be a multiple of 4.\"));\n     }",
      "code_diff":"@@ -1282,6 +1282,32 @@ class FusedBatchNormOpBase : public OpKernel {\n                   errors::InvalidArgument(\"Error during tensor copy.\"));\n     }\n \n+    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n+    OP_REQUIRES(\n+        context, scale.NumElements() == num_channels,\n+        errors::InvalidArgument(\"scale must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                scale.NumElements(), \" and \", num_channels));\n+    OP_REQUIRES(\n+        context, offset.NumElements() == num_channels,\n+        errors::InvalidArgument(\"offset must have the same number of elements \"\n+                                \"as the channels of x, got \",\n+                                offset.NumElements(), \" and \", num_channels));\n+    if (estimated_mean.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"mean must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_mean.NumElements(), \" and \", num_channels));\n+    }\n+    if (estimated_variance.NumElements() != 0) {\n+      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n+                  errors::InvalidArgument(\n+                      \"variance must be empty or have the same number of \"\n+                      \"elements as the channels of x, got \",\n+                      estimated_variance.NumElements(), \" and \", num_channels));\n+    }\n+\n     if (has_side_input_) {\n       OP_REQUIRES(context, side_input->shape() == x.shape(),\n                   errors::InvalidArgument(\n@@ -1294,7 +1320,7 @@ class FusedBatchNormOpBase : public OpKernel {\n       \/\/ NOTE(ezhulenev): This requirement is coming from implementation\n       \/\/ details of cudnnBatchNormalizationForwardTrainingEx.\n       OP_REQUIRES(\n-          context, !is_training_ || x.dim_size(3) % 4 == 0,\n+          context, !is_training_ || num_channels % 4 == 0,\n           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                   \"channel dimension to be a multiple of 4.\"));\n     }"
    },
    {
      "index":6,
      "vuln_id":"GHSA-cgfm-62j4-v4rf",
      "cwe_id":"{'CWE-125'}",
      "score":7.3,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750'}",
      "dataset":"osv",
      "summary":"Heap out of bounds access in sparse reduction operations ### Impact\nThe implementation of sparse reduction operations in TensorFlow can trigger accesses outside of bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\nx = tf.SparseTensor(\n      indices=[[773, 773, 773], [773, 773, 773]],\n      values=[1, 1],\n      dense_shape=[337, 337, 337])\ntf.sparse.reduce_sum(x, 1)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1bc56203f21a5a4995311825ffaba7a670d7747\/tensorflow\/core\/kernels\/sparse_reduce_op.cc#L217-L228) fails to validate that each reduction group does not overflow and that each corresponding index does not point to outside the bounds of the input tensor.\n\n### Patches\nWe have patched the issue in GitHub commit [87158f43f05f2720a374f3e6d22a7aaa3a33f750](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750). \n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/87158f43f05f2720a374f3e6d22a7aaa3a33f750",
      "commit_sha":"87158f43f05f2720a374f3e6d22a7aaa3a33f750",
      "patch":"SINGLE",
      "chain_ord":"['87158f43f05f2720a374f3e6d22a7aaa3a33f750']",
      "before_first_fix_commit":"{'9c7f40e5f1b5b74156ad4d7bc20b8d69bdedbe29'}",
      "last_fix_commit":"87158f43f05f2720a374f3e6d22a7aaa3a33f750",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/31\/2021, 04:11:18",
      "message":"Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 13, 'deletions': 0, 'total': 13}",
      "files":"{'tensorflow\/core\/kernels\/sparse_reduce_op.cc': {'additions': 13, 'deletions': 0, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/87158f43f05f2720a374f3e6d22a7aaa3a33f750\/tensorflow%2Fcore%2Fkernels%2Fsparse_reduce_op.cc', 'patch': '@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\\n     sp.Reorder<T>(reduction.reorder_dims);\\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\\n+      OP_REQUIRES(ctx,\\n+                  output_strides.empty() ||\\n+                  (g.group().size() == output_strides.size()),\\n+                  errors::Internal(\\n+                      \"Expected group size and output_strides size to match\",\\n+                      \", but got \", g.group().size(), \" and \",\\n+                      output_strides.size()));\\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\\n+      OP_REQUIRES(ctx,\\n+                  idx >= 0 && idx < out_flat.size(),\\n+                  errors::Internal(\\n+                      \"Obtained a write index of \", idx,\\n+                      \" which is outside of bounds of [0, \",\\n+                      out_flat.size(), \")\"));\\n       out_flat(idx) = reduced_val();\\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"'}}",
      "message_norm":"prevent heap oob in sparse reduction ops.\n\npiperorigin-revid: 387934524\nchange-id: i894aa30f1e454f09b471d565b4a325da49322c1a",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('387934524', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/sparse_reduce_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 87158f43f05f2720a374f3e6d22a7aaa3a33f750 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 21:11:18 -0700\nSubject: [PATCH] Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a\n---\n tensorflow\/core\/kernels\/sparse_reduce_op.cc | 13 +++++++++++++\n 1 file changed, 13 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sparse_reduce_op.cc b\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\nindex 668ea5ae54084c..430be0a271742e 100644\n--- a\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\n+++ b\/tensorflow\/core\/kernels\/sparse_reduce_op.cc\n@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\n     sp.Reorder<T>(reduction.reorder_dims);\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n+      OP_REQUIRES(ctx,\n+                  output_strides.empty() ||\n+                  (g.group().size() == output_strides.size()),\n+                  errors::Internal(\n+                      \"Expected group size and output_strides size to match\",\n+                      \", but got \", g.group().size(), \" and \",\n+                      output_strides.size()));\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n+      OP_REQUIRES(ctx,\n+                  idx >= 0 && idx < out_flat.size(),\n+                  errors::Internal(\n+                      \"Obtained a write index of \", idx,\n+                      \" which is outside of bounds of [0, \",\n+                      out_flat.size(), \")\"));\n       out_flat(idx) = reduced_val();\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \"",
      "code_diff":"@@ -219,7 +219,20 @@ class SparseReduceOp : public OpKernel {\n     sp.Reorder<T>(reduction.reorder_dims);\n     for (const auto &g : sp.group(reduction.group_by_dims)) {\n       Op::template Run<T>(ctx, reduced_val, g.template values<T>());\n+      OP_REQUIRES(ctx,\n+                  output_strides.empty() ||\n+                  (g.group().size() == output_strides.size()),\n+                  errors::Internal(\n+                      \"Expected group size and output_strides size to match\",\n+                      \", but got \", g.group().size(), \" and \",\n+                      output_strides.size()));\n       const int64_t idx = CoordinatesToFlatIndex(g.group(), output_strides);\n+      OP_REQUIRES(ctx,\n+                  idx >= 0 && idx < out_flat.size(),\n+                  errors::Internal(\n+                      \"Obtained a write index of \", idx,\n+                      \" which is outside of bounds of [0, \",\n+                      out_flat.size(), \")\"));\n       out_flat(idx) = reduced_val();\n       VLOG(2) << \"coords: \" << absl::StrJoin(g.group(), \",\")\n               << \"; idx: \" << idx << \"; group \" << Op::Name() << \": \""
    },
    {
      "index":7,
      "vuln_id":"GHSA-q3g3-h9r4-prrc",
      "cwe_id":"{'CWE-125'}",
      "score":7.3,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec'}",
      "dataset":"osv",
      "summary":"Reference binding to nullptr and heap OOB in binary cwise ops ### Impact\nAn attacker can cause undefined behavior via binding a reference to null pointer in all binary cwise operations that don't require broadcasting (e.g., gradients of binary cwise operations):\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.SqrtGrad(y=[4, 16],dy=[])\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/cwise_ops_common.h#L264) assumes that the two inputs have exactly the same number of elements but does not check that. Hence, when the eigen functor executes it triggers heap OOB reads and undefined behavior due to binding to nullptr.\n\n### Patches\nWe have patched the issue in GitHub commit [93f428fd1768df147171ed674fee1fc5ab8309ec](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution \nThis vulnerability has been reported by members of the Aivul Team from Qihoo  360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/93f428fd1768df147171ed674fee1fc5ab8309ec",
      "commit_sha":"93f428fd1768df147171ed674fee1fc5ab8309ec",
      "patch":"SINGLE",
      "chain_ord":"['93f428fd1768df147171ed674fee1fc5ab8309ec']",
      "before_first_fix_commit":"{'bc9c546ce7015c57c2f15c168b3d9201de679a1d'}",
      "last_fix_commit":"93f428fd1768df147171ed674fee1fc5ab8309ec",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/31\/2021, 04:42:36",
      "message":"Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
      "files":"{'tensorflow\/core\/kernels\/cwise_ops_common.h': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/93f428fd1768df147171ed674fee1fc5ab8309ec\/tensorflow%2Fcore%2Fkernels%2Fcwise_ops_common.h', 'patch': '@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& in0 = ctx->input(0);\\n     const Tensor& in1 = ctx->input(1);\\n+    OP_REQUIRES(\\n+        ctx, in0.NumElements() == in1.NumElements(),\\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\\n+                                \"same number of elements, got \",\\n+                                in0.NumElements(), \" and \", in1.NumElements()));\\n     auto in0_flat = in0.flat<Tin>();\\n     auto in1_flat = in1.flat<Tin>();\\n     const Device& eigen_device = ctx->eigen_device<Device>();'}}",
      "message_norm":"fix nullptr deref and heap oob access in binary cwise ops.\n\npiperorigin-revid: 387936777\nchange-id: i608b8074cec36a982cca622b7144cb2c43e6e19f",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('nullptr', 'SECWORD', ''), ('heap oob', 'SECWORD', ''), ('387936777', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/cwise_ops_common.h'])",
      "num_files":1.0,
      "patch_content":"From 93f428fd1768df147171ed674fee1fc5ab8309ec Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 21:42:36 -0700\nSubject: [PATCH] Fix nullptr deref and heap OOB access in binary cwise ops.\n\nPiperOrigin-RevId: 387936777\nChange-Id: I608b8074cec36a982cca622b7144cb2c43e6e19f\n---\n tensorflow\/core\/kernels\/cwise_ops_common.h | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/cwise_ops_common.h b\/tensorflow\/core\/kernels\/cwise_ops_common.h\nindex 9adc628421d046..4f2c83322ba00f 100644\n--- a\/tensorflow\/core\/kernels\/cwise_ops_common.h\n+++ b\/tensorflow\/core\/kernels\/cwise_ops_common.h\n@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();",
      "code_diff":"@@ -265,6 +265,11 @@ class SimpleBinaryOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& in0 = ctx->input(0);\n     const Tensor& in1 = ctx->input(1);\n+    OP_REQUIRES(\n+        ctx, in0.NumElements() == in1.NumElements(),\n+        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n+                                \"same number of elements, got \",\n+                                in0.NumElements(), \" and \", in1.NumElements()));\n     auto in0_flat = in0.flat<Tin>();\n     auto in1_flat = in1.flat<Tin>();\n     const Device& eigen_device = ctx->eigen_device<Device>();"
    },
    {
      "index":8,
      "vuln_id":"GHSA-5hj3-vjjf-f5m7",
      "cwe_id":"{'CWE-125'}",
      "score":5.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6'}",
      "dataset":"osv",
      "summary":"Heap OOB in `SdcaOptimizerV2` ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`:\n\n```python\nimport tensorflow as tf\n  \ntf.raw_ops.SdcaOptimizerV2(\n  sparse_example_indices=[[1]],\n  sparse_feature_indices=[[1]],\n  sparse_feature_values=[[1.0,2.0]],\n  dense_features=[[1.0]],\n  example_weights=[1.0],\n  example_labels=[],\n  sparse_indices=[1],\n  sparse_weights=[1.0],\n  dense_weights=[[1.0]],\n  example_state_data=[[100.0,100.0,100.0,100.0]],\n  loss_type='logistic_loss',\n  l1=100.0,\n  l2=100.0,\n  num_loss_partitions=1,\n  num_inner_iterations=1,\n  adaptive=True)       \n``` \n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/460e000de3a83278fb00b61a16d161b1964f15f4\/tensorflow\/core\/kernels\/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples.\n\n### Patches\nWe have patched the issue in GitHub commit [a4e138660270e7599793fa438cd7b2fc2ce215a6](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a4e138660270e7599793fa438cd7b2fc2ce215a6",
      "commit_sha":"a4e138660270e7599793fa438cd7b2fc2ce215a6",
      "patch":"SINGLE",
      "chain_ord":"['a4e138660270e7599793fa438cd7b2fc2ce215a6']",
      "before_first_fix_commit":"{'578e634b4f1c1c684d4b4294f9e5281b2133b3ed'}",
      "last_fix_commit":"a4e138660270e7599793fa438cd7b2fc2ce215a6",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/30\/2021, 05:24:27",
      "message":"Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
      "files":"{'tensorflow\/core\/kernels\/sdca_internal.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a4e138660270e7599793fa438cd7b2fc2ce215a6\/tensorflow%2Fcore%2Fkernels%2Fsdca_internal.cc', 'patch': '@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\\n   const Tensor* example_labels_t;\\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\\n   auto example_labels = example_labels_t->flat<float>();\\n+  if (example_labels.size() != num_examples) {\\n+    return errors::InvalidArgument(\"Expected \", num_examples,\\n+                                   \" example labels but got \",\\n+                                   example_labels.size());\\n+  }\\n \\n   OpInputList dense_features_inputs;\\n   TF_RETURN_IF_ERROR('}}",
      "message_norm":"add remaining validation to `sdca_internal.cc`\n\npiperorigin-revid: 387738010\nchange-id: i28eedcfd87a53aaf34deb075acea1f8c95470808",
      "language":"en",
      "entities":"[('add', 'ACTION', ''), ('387738010', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/sdca_internal.cc'])",
      "num_files":1.0,
      "patch_content":"From a4e138660270e7599793fa438cd7b2fc2ce215a6 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 29 Jul 2021 22:24:27 -0700\nSubject: [PATCH] Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808\n---\n tensorflow\/core\/kernels\/sdca_internal.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/sdca_internal.cc b\/tensorflow\/core\/kernels\/sdca_internal.cc\nindex 6c4a63b270c25b..164f9382724cac 100644\n--- a\/tensorflow\/core\/kernels\/sdca_internal.cc\n+++ b\/tensorflow\/core\/kernels\/sdca_internal.cc\n@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(",
      "code_diff":"@@ -380,6 +380,11 @@ Status Examples::Initialize(OpKernelContext* const context,\n   const Tensor* example_labels_t;\n   TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n   auto example_labels = example_labels_t->flat<float>();\n+  if (example_labels.size() != num_examples) {\n+    return errors::InvalidArgument(\"Expected \", num_examples,\n+                                   \" example labels but got \",\n+                                   example_labels.size());\n+  }\n \n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR("
    },
    {
      "index":9,
      "vuln_id":"GHSA-77gp-3h4r-6428",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":8.8,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0657c83d08845cc434175934c642299de2c0f042'}",
      "dataset":"osv",
      "summary":"Out of bounds read and write in Tensorflow ### Impact\nThere is a typo in TensorFlow's [`SpecializeType`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/full_type_util.cc#L81-L102) which results in heap OOB read\/write:\n\n```cc\nfor (int i = 0; i < op_def.output_arg_size(); i++) {\n  \/\/ ...\n  for (int j = 0; j < t->args_size(); j++) {\n    auto* arg = t->mutable_args(i);\n    \/\/ ...\n  }\n} \n```\n\nDue to a typo, `arg` is initialized to the `i`th mutable argument in a loop where the loop index is `j`. Hence it is possible to assign to `arg` from outside the vector of arguments. Since this is a mutable proto value, it allows both read and write to outside of bounds data.\n\n### Patches\nWe have patched the issue in GitHub commit [0657c83d08845cc434175934c642299de2c0f042](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0657c83d08845cc434175934c642299de2c0f042).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0657c83d08845cc434175934c642299de2c0f042",
      "commit_sha":"0657c83d08845cc434175934c642299de2c0f042",
      "patch":"SINGLE",
      "chain_ord":"['0657c83d08845cc434175934c642299de2c0f042']",
      "before_first_fix_commit":"{'6e65b0b4ad12fdaa223e87b4ae6d8cb762fcae2b'}",
      "last_fix_commit":"0657c83d08845cc434175934c642299de2c0f042",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/09\/2021, 12:44:43",
      "message":"Fix heap OOB read\/write due to incorrect indexing.\n\nPiperOrigin-RevId: 408578046\nChange-Id: Ifc9ffea49e5890f55fcb2c27568611052c3ddcfa",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'tensorflow\/core\/framework\/full_type_util.cc': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/0657c83d08845cc434175934c642299de2c0f042\/tensorflow%2Fcore%2Fframework%2Ffull_type_util.cc', 'patch': '@@ -100,7 +100,7 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\\n     \/\/ verifications are needed, they should be done by separately, and in a\\n     \/\/ way that can be reused for type inference.\\n     for (int j = 0; j < t->args_size(); j++) {\\n-      auto* arg = t->mutable_args(i);\\n+      auto* arg = t->mutable_args(j);\\n       if (arg->type_id() == TFT_VAR) {\\n         const auto* attr = attrs.Find(arg->s());\\n         if (attr == nullptr) {'}}",
      "message_norm":"fix heap oob read\/write due to incorrect indexing.\n\npiperorigin-revid: 408578046\nchange-id: ifc9ffea49e5890f55fcb2c27568611052c3ddcfa",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('408578046', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/framework\/full_type_util.cc'])",
      "num_files":1.0,
      "patch_content":"From 0657c83d08845cc434175934c642299de2c0f042 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 9 Nov 2021 04:44:43 -0800\nSubject: [PATCH] Fix heap OOB read\/write due to incorrect indexing.\n\nPiperOrigin-RevId: 408578046\nChange-Id: Ifc9ffea49e5890f55fcb2c27568611052c3ddcfa\n---\n tensorflow\/core\/framework\/full_type_util.cc | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/framework\/full_type_util.cc b\/tensorflow\/core\/framework\/full_type_util.cc\nindex e0d8ca0721c850..89617dc97f2496 100644\n--- a\/tensorflow\/core\/framework\/full_type_util.cc\n+++ b\/tensorflow\/core\/framework\/full_type_util.cc\n@@ -100,7 +100,7 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n     \/\/ verifications are needed, they should be done by separately, and in a\n     \/\/ way that can be reused for type inference.\n     for (int j = 0; j < t->args_size(); j++) {\n-      auto* arg = t->mutable_args(i);\n+      auto* arg = t->mutable_args(j);\n       if (arg->type_id() == TFT_VAR) {\n         const auto* attr = attrs.Find(arg->s());\n         if (attr == nullptr) {",
      "code_diff":"@@ -100,7 +100,7 @@ StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n     \/\/ verifications are needed, they should be done by separately, and in a\n     \/\/ way that can be reused for type inference.\n     for (int j = 0; j < t->args_size(); j++) {\n-      auto* arg = t->mutable_args(i);\n+      auto* arg = t->mutable_args(j);\n       if (arg->type_id() == TFT_VAR) {\n         const auto* attr = attrs.Find(arg->s());\n         if (attr == nullptr) {"
    },
    {
      "index":10,
      "vuln_id":"GHSA-83rh-hx5x-q9p5",
      "cwe_id":"{'CWE-125'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/opencv\/opencv\/pull\/10480\/commits\/4ca89db22dea962690f31c1781bce5937ee91837'}",
      "dataset":"osv",
      "summary":"Out-of-bounds Read in OpenCV In OpenCV 3.3.1 (corresponding with OpenCV-Python 3.3.1.11), a heap-based buffer over-read exists in the function cv::HdrDecoder::checkSignature in modules\/imgcodecs\/src\/grfmt_hdr.cpp.",
      "published_date":"2021-10-12",
      "chain_len":1,
      "project":"https:\/\/github.com\/opencv\/opencv",
      "commit_href":"https:\/\/github.com\/opencv\/opencv\/pull\/10480\/commits\/4ca89db22dea962690f31c1781bce5937ee91837",
      "commit_sha":"4ca89db22dea962690f31c1781bce5937ee91837",
      "patch":"SINGLE",
      "chain_ord":"['4ca89db22dea962690f31c1781bce5937ee91837']",
      "before_first_fix_commit":"{'30373d2566a3ec097f0418dc2661ec03fcfb71d6'}",
      "last_fix_commit":"4ca89db22dea962690f31c1781bce5937ee91837",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/01\/2018, 13:12:21",
      "message":"imgproc(hdr): fix bounds check in HdrDecoder::checkSignature()",
      "author":"Alexander Alekhin",
      "comments":null,
      "stats":"{'additions': 8, 'deletions': 4, 'total': 12}",
      "files":"{'modules\/imgcodecs\/src\/grfmt_hdr.cpp': {'additions': 8, 'deletions': 4, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/opencv\/opencv\/raw\/4ca89db22dea962690f31c1781bce5937ee91837\/modules%2Fimgcodecs%2Fsrc%2Fgrfmt_hdr.cpp', 'patch': '@@ -101,10 +101,14 @@ bool HdrDecoder::readData(Mat& _img)\\n \\n bool HdrDecoder::checkSignature( const String& signature ) const\\n {\\n-    if(signature.size() >= m_signature.size() &&\\n-       (!memcmp(signature.c_str(), m_signature.c_str(), m_signature.size()) ||\\n-       !memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())))\\n-       return true;\\n+    if (signature.size() >= m_signature.size() &&\\n+        0 == memcmp(signature.c_str(), m_signature.c_str(), m_signature.size())\\n+    )\\n+        return true;\\n+    if (signature.size() >= m_signature_alt.size() &&\\n+        0 == memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())\\n+    )\\n+        return true;\\n     return false;\\n }'}}",
      "message_norm":"imgproc(hdr): fix bounds check in hdrdecoder::checksignature()",
      "language":"en",
      "entities":"[('bounds check', 'SECWORD', ''), ('hdrdecoder::checksignature', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['modules\/imgcodecs\/src\/grfmt_hdr.cpp'])",
      "num_files":1.0,
      "patch_content":"From 4ca89db22dea962690f31c1781bce5937ee91837 Mon Sep 17 00:00:00 2001\nFrom: Alexander Alekhin <alexander.a.alekhin@gmail.com>\nDate: Mon, 1 Jan 2018 13:12:21 +0000\nSubject: [PATCH] imgproc(hdr): fix bounds check in\n HdrDecoder::checkSignature()\n\n---\n modules\/imgcodecs\/src\/grfmt_hdr.cpp | 12 ++++++++----\n 1 file changed, 8 insertions(+), 4 deletions(-)\n\ndiff --git a\/modules\/imgcodecs\/src\/grfmt_hdr.cpp b\/modules\/imgcodecs\/src\/grfmt_hdr.cpp\nindex f795120547eb..9801106506e2 100644\n--- a\/modules\/imgcodecs\/src\/grfmt_hdr.cpp\n+++ b\/modules\/imgcodecs\/src\/grfmt_hdr.cpp\n@@ -101,10 +101,14 @@ bool HdrDecoder::readData(Mat& _img)\n \n bool HdrDecoder::checkSignature( const String& signature ) const\n {\n-    if(signature.size() >= m_signature.size() &&\n-       (!memcmp(signature.c_str(), m_signature.c_str(), m_signature.size()) ||\n-       !memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())))\n-       return true;\n+    if (signature.size() >= m_signature.size() &&\n+        0 == memcmp(signature.c_str(), m_signature.c_str(), m_signature.size())\n+    )\n+        return true;\n+    if (signature.size() >= m_signature_alt.size() &&\n+        0 == memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())\n+    )\n+        return true;\n     return false;\n }",
      "code_diff":"@@ -101,10 +101,14 @@ bool HdrDecoder::readData(Mat& _img)\n \n bool HdrDecoder::checkSignature( const String& signature ) const\n {\n-    if(signature.size() >= m_signature.size() &&\n-       (!memcmp(signature.c_str(), m_signature.c_str(), m_signature.size()) ||\n-       !memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())))\n-       return true;\n+    if (signature.size() >= m_signature.size() &&\n+        0 == memcmp(signature.c_str(), m_signature.c_str(), m_signature.size())\n+    )\n+        return true;\n+    if (signature.size() >= m_signature_alt.size() &&\n+        0 == memcmp(signature.c_str(), m_signature_alt.c_str(), m_signature_alt.size())\n+    )\n+        return true;\n     return false;\n }"
    },
    {
      "index":11,
      "vuln_id":"GHSA-r4c4-5fpq-56wg",
      "cwe_id":"{'CWE-125'}",
      "score":7.3,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378'}",
      "dataset":"osv",
      "summary":"Heap OOB in boosted trees ### Impact\nAn attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `BoostedTreesSparseCalculateBestFeatureSplit`:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(\n  node_id_range=[0,10],\n  stats_summary_indices=[[1, 2, 3, 0x1000000]],\n  stats_summary_values=[1.0],\n  stats_summary_shape=[1,1,1,1],\n  l1=l2=[1.0],\n  tree_complexity=[0.5],\n  min_node_weight=[1.0],\n  logits_dimension=3,\n  split_type='inequality')                                                                                                                                                                                                                                                                \n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/84d053187cb80d975ef2b9684d4b61981bca0c41\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc) needs to validate that each value in `stats_summary_indices` is in range.\n  \n### Patches\nWe have patched the issue in GitHub commit [e84c975313e8e8e38bb2ea118196369c45c51378](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378).\n  \nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e84c975313e8e8e38bb2ea118196369c45c51378",
      "commit_sha":"e84c975313e8e8e38bb2ea118196369c45c51378",
      "patch":"SINGLE",
      "chain_ord":"['e84c975313e8e8e38bb2ea118196369c45c51378']",
      "before_first_fix_commit":"{'2e0ee46f1a47675152d3d865797a18358881d7a6'}",
      "last_fix_commit":"e84c975313e8e8e38bb2ea118196369c45c51378",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/27\/2021, 19:35:03",
      "message":"In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaa",
      "author":"Laura Pak",
      "comments":null,
      "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
      "files":"{'tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e84c975313e8e8e38bb2ea118196369c45c51378\/tensorflow%2Fcore%2Fkernels%2Fboosted_trees%2Fstats_ops.cc', 'patch': '@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\\n+      OP_REQUIRES(context, stat_dim < stats_dims,\\n+                  errors::InvalidArgument(\\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\\n+                      \"stats_summary_indices, cannot be greater than stats \"\\n+                      \"dims, the last value in stats_summary_shape, which was \",\\n+                      stats_dims, \". At index (\", idx,\\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\\n       auto& b_map = f_insert_result.first->second;'}}",
      "message_norm":"in tf.raw_ops.boostedtreessparsecalculatebestfeaturesplit, limit stat_dim in stats_summary_indices to under stats_dims in stats_summary_shape\n\npiperorigin-revid: 387171191\nchange-id: i83ca8a75b22aa78c037e8b98779da6cced16bfaa",
      "language":"en",
      "entities":"[('387171191', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc'])",
      "num_files":1.0,
      "patch_content":"From e84c975313e8e8e38bb2ea118196369c45c51378 Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Tue, 27 Jul 2021 12:35:03 -0700\nSubject: [PATCH] In tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit,\n limit stat_dim in stats_summary_indices to under stats_dims in\n stats_summary_shape\n\nPiperOrigin-RevId: 387171191\nChange-Id: I83ca8a75b22aa78c037e8b98779da6cced16bfaa\n---\n tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc | 7 +++++++\n 1 file changed, 7 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc b\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\nindex 014c2ec22c9cf6..2636909855a386 100644\n--- a\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\n+++ b\/tensorflow\/core\/kernels\/boosted_trees\/stats_ops.cc\n@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\n+      OP_REQUIRES(context, stat_dim < stats_dims,\n+                  errors::InvalidArgument(\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\n+                      \"stats_summary_indices, cannot be greater than stats \"\n+                      \"dims, the last value in stats_summary_shape, which was \",\n+                      stats_dims, \". At index (\", idx,\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\n       auto& b_map = f_insert_result.first->second;",
      "code_diff":"@@ -1050,6 +1050,13 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n       const int32_t feature_dim = stats_summary_indices(idx, 1);\n       const int32_t bucket_id = stats_summary_indices(idx, 2);\n       const int32_t stat_dim = stats_summary_indices(idx, 3);\n+      OP_REQUIRES(context, stat_dim < stats_dims,\n+                  errors::InvalidArgument(\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\n+                      \"stats_summary_indices, cannot be greater than stats \"\n+                      \"dims, the last value in stats_summary_shape, which was \",\n+                      stats_dims, \". At index (\", idx,\n+                      \", 4), stats_summary_indices contains value \", stat_dim));\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\n       auto& b_map = f_insert_result.first->second;"
    },
    {
      "index":12,
      "vuln_id":"GHSA-23hm-7w47-xw72",
      "cwe_id":"{'CWE-125'}",
      "score":8.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/23968a8bf65b009120c43b5ebcceaf52dbc9e943'}",
      "dataset":"osv",
      "summary":"Out of bounds read in Tensorflow ### Impact \nThe [implementation of `Dequantize`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/dequantize_op.cc#L92-L153) does not fully validate the value of `axis` and can result in heap OOB accesses:\n\n```python\nimport tensorflow as tf\n\n@tf.function\ndef test():\n  y = tf.raw_ops.Dequantize(\n    input=tf.constant([1,1],dtype=tf.qint32),\n    min_range=[1.0],\n    max_range=[10.0],\n    mode='MIN_COMBINED',\n    narrow_range=False,\n    axis=2**31-1,\n    dtype=tf.bfloat16)\n  return y\n\ntest()\n```\n\nThe `axis` argument can be `-1` (the default value for the optional argument) or any other positive value at most the number of dimensions of the input. Unfortunately, the upper bound is not checked and this results in reading past the end of the array containing the dimensions of the input tensor:\n    \n```cc   \n  if (axis_ > -1) {\n    num_slices = input.dim_size(axis_);\n  }\n  \/\/ ...\n  int64_t pre_dim = 1, post_dim = 1;\n  for (int i = 0; i < axis_; ++i) {\n    pre_dim *= float_output.dim_size(i);\n  }\n  for (int i = axis_ + 1; i < float_output.dims(); ++i) {\n    post_dim *= float_output.dim_size(i);\n  }\n``` \n      \n### Patches\nWe have patched the issue in GitHub commit [23968a8bf65b009120c43b5ebcceaf52dbc9e943](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/23968a8bf65b009120c43b5ebcceaf52dbc9e943).\n  \nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n      \n### Attribution\nThis vulnerability has been reported by Yu Tian of Qihoo 360 AIVul Team.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/23968a8bf65b009120c43b5ebcceaf52dbc9e943",
      "commit_sha":"23968a8bf65b009120c43b5ebcceaf52dbc9e943",
      "patch":"SINGLE",
      "chain_ord":"['23968a8bf65b009120c43b5ebcceaf52dbc9e943']",
      "before_first_fix_commit":"{'566576746f47ebf42c38ebe01cca6dbb8832a9ef'}",
      "last_fix_commit":"23968a8bf65b009120c43b5ebcceaf52dbc9e943",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/20\/2021, 07:16:11",
      "message":"Fix out of bound access in DequantizeOp by adding check for axis < input dimension\n\nPiperOrigin-RevId: 411214268\nChange-Id: I3249d2a69ddc82f182c589a3a5bbfb71543f4b29",
      "author":"Isha Arkatkar",
      "comments":null,
      "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
      "files":"{'tensorflow\/core\/kernels\/dequantize_op.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/23968a8bf65b009120c43b5ebcceaf52dbc9e943\/tensorflow%2Fcore%2Fkernels%2Fdequantize_op.cc', 'patch': '@@ -94,6 +94,11 @@ class DequantizeOp : public OpKernel {\\n     const Tensor& input_min_tensor = ctx->input(1);\\n     const Tensor& input_max_tensor = ctx->input(2);\\n \\n+    OP_REQUIRES(\\n+        ctx, axis_ < input.dims(),\\n+        errors::InvalidArgument(\"Axis must be less than input dimension(\",\\n+                                input.dims(), \"), got \", axis_));\\n+\\n     int num_slices = 1;\\n     if (axis_ > -1) {\\n       num_slices = input.dim_size(axis_);'}}",
      "message_norm":"fix out of bound access in dequantizeop by adding check for axis < input dimension\n\npiperorigin-revid: 411214268\nchange-id: i3249d2a69ddc82f182c589a3a5bbfb71543f4b29",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('out of bound access', 'SECWORD', ''), ('adding', 'ACTION', ''), ('411214268', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/dequantize_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 23968a8bf65b009120c43b5ebcceaf52dbc9e943 Mon Sep 17 00:00:00 2001\nFrom: Isha Arkatkar <ishark@google.com>\nDate: Fri, 19 Nov 2021 23:16:11 -0800\nSubject: [PATCH] Fix out of bound access in DequantizeOp by adding check for\n axis < input dimension\n\nPiperOrigin-RevId: 411214268\nChange-Id: I3249d2a69ddc82f182c589a3a5bbfb71543f4b29\n---\n tensorflow\/core\/kernels\/dequantize_op.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/dequantize_op.cc b\/tensorflow\/core\/kernels\/dequantize_op.cc\nindex 31a7a7498cf0c8..0a466f1cf118e2 100644\n--- a\/tensorflow\/core\/kernels\/dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/dequantize_op.cc\n@@ -94,6 +94,11 @@ class DequantizeOp : public OpKernel {\n     const Tensor& input_min_tensor = ctx->input(1);\n     const Tensor& input_max_tensor = ctx->input(2);\n \n+    OP_REQUIRES(\n+        ctx, axis_ < input.dims(),\n+        errors::InvalidArgument(\"Axis must be less than input dimension(\",\n+                                input.dims(), \"), got \", axis_));\n+\n     int num_slices = 1;\n     if (axis_ > -1) {\n       num_slices = input.dim_size(axis_);",
      "code_diff":"@@ -94,6 +94,11 @@ class DequantizeOp : public OpKernel {\n     const Tensor& input_min_tensor = ctx->input(1);\n     const Tensor& input_max_tensor = ctx->input(2);\n \n+    OP_REQUIRES(\n+        ctx, axis_ < input.dims(),\n+        errors::InvalidArgument(\"Axis must be less than input dimension(\",\n+                                input.dims(), \"), got \", axis_));\n+\n     int num_slices = 1;\n     if (axis_ > -1) {\n       num_slices = input.dim_size(axis_);"
    },
    {
      "index":13,
      "vuln_id":"GHSA-c45w-2wxr-pp53",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b'}",
      "dataset":"osv",
      "summary":"Heap OOB read in `tf.raw_ops.Dequantize` ### Impact\nDue to lack of validation in `tf.raw_ops.Dequantize`, an attacker can trigger a read from outside of bounds of heap allocated data:\n\n```python\nimport tensorflow as tf\n\ninput_tensor=tf.constant(\n  [75, 75, 75, 75, -6, -9, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10, -10,\\\n  -10, -10, -10, -10], shape=[5, 10], dtype=tf.int32)\ninput_tensor=tf.cast(input_tensor, dtype=tf.quint8)\nmin_range = tf.constant([-10], shape=[1], dtype=tf.float32)\nmax_range = tf.constant([24, 758, 758, 758, 758], shape=[5], dtype=tf.float32)\n  \ntf.raw_ops.Dequantize( \n  input=input_tensor, min_range=min_range, max_range=max_range, mode='SCALED',\n  narrow_range=True, axis=0, dtype=tf.dtypes.float32)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/26003593aa94b1742f34dc22ce88a1e17776a67d\/tensorflow\/core\/kernels\/dequantize_op.cc#L106-L131) accesses the `min_range` and `max_range` tensors in parallel but fails to check that they have the same shape:\n\n```cc\nif (num_slices == 1) {\n  const float min_range = input_min_tensor.flat<float>()(0);\n  const float max_range = input_max_tensor.flat<float>()(0);\n  DequantizeTensor(ctx, input, min_range, max_range, &float_output);\n} else {\n  ...\n  auto min_ranges = input_min_tensor.vec<float>();\n  auto max_ranges = input_max_tensor.vec<float>();\n  for (int i = 0; i < num_slices; ++i) {\n    DequantizeSlice(ctx->eigen_device<Device>(), ctx,\n                    input_tensor.template chip<1>(i), min_ranges(i),\n                    max_ranges(i), output_tensor.template chip<1>(i));\n    ...\n  }\n}\n```\n\n### Patches\nWe have patched the issue in GitHub commit [5899741d0421391ca878da47907b1452f06aaf1b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/5899741d0421391ca878da47907b1452f06aaf1b",
      "commit_sha":"5899741d0421391ca878da47907b1452f06aaf1b",
      "patch":"SINGLE",
      "chain_ord":"['5899741d0421391ca878da47907b1452f06aaf1b']",
      "before_first_fix_commit":"{'26003593aa94b1742f34dc22ce88a1e17776a67d'}",
      "last_fix_commit":"5899741d0421391ca878da47907b1452f06aaf1b",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/06\/2021, 22:31:05",
      "message":"Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
      "files":"{'tensorflow\/core\/kernels\/dequantize_op.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/5899741d0421391ca878da47907b1452f06aaf1b\/tensorflow%2Fcore%2Fkernels%2Fdequantize_op.cc', 'patch': '@@ -98,6 +98,18 @@ class DequantizeOp : public OpKernel {\\n     if (axis_ > -1) {\\n       num_slices = input.dim_size(axis_);\\n     }\\n+    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\\n+                errors::InvalidArgument(\\n+                    \"input_min_tensor must have as many elements as input on \"\\n+                    \"the dequantization axis (\",\\n+                    axis_, \"), got \", input_min_tensor.NumElements(),\\n+                    \", expected \", num_slices));\\n+    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,\\n+                errors::InvalidArgument(\\n+                    \"input_max_tensor must have as many elements as input on \"\\n+                    \"the dequantization axis (\",\\n+                    axis_, \"), got \", input_max_tensor.NumElements(),\\n+                    \", expected \", num_slices));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));'}}",
      "message_norm":"fix heap oob read in dequantize op.\n\nalso fixes segv in same op\n\npiperorigin-revid: 372437896\nchange-id: i135e94d360c2a1ce374c10f7e0fed1af603dbc02",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('372437896', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/dequantize_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 5899741d0421391ca878da47907b1452f06aaf1b Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Thu, 6 May 2021 15:31:05 -0700\nSubject: [PATCH] Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02\n---\n tensorflow\/core\/kernels\/dequantize_op.cc | 12 ++++++++++++\n 1 file changed, 12 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/dequantize_op.cc b\/tensorflow\/core\/kernels\/dequantize_op.cc\nindex 5393a677db242a..7a90e0c340b093 100644\n--- a\/tensorflow\/core\/kernels\/dequantize_op.cc\n+++ b\/tensorflow\/core\/kernels\/dequantize_op.cc\n@@ -98,6 +98,18 @@ class DequantizeOp : public OpKernel {\n     if (axis_ > -1) {\n       num_slices = input.dim_size(axis_);\n     }\n+    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_min_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_min_tensor.NumElements(),\n+                    \", expected \", num_slices));\n+    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_max_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_max_tensor.NumElements(),\n+                    \", expected \", num_slices));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
      "code_diff":"@@ -98,6 +98,18 @@ class DequantizeOp : public OpKernel {\n     if (axis_ > -1) {\n       num_slices = input.dim_size(axis_);\n     }\n+    OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_min_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_min_tensor.NumElements(),\n+                    \", expected \", num_slices));\n+    OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,\n+                errors::InvalidArgument(\n+                    \"input_max_tensor must have as many elements as input on \"\n+                    \"the dequantization axis (\",\n+                    axis_, \"), got \", input_max_tensor.NumElements(),\n+                    \", expected \", num_slices));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));"
    },
    {
      "index":14,
      "vuln_id":"GHSA-cvpc-8phh-8f45",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":4.8,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/00302787b788c5ff04cb6f62aed5a74d936e86c0', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e11f55585f614645b360563072ffeb5c3eeff162', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/46d5b0852528ddfd614ded79bccc75589f801bd9', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1970c2158b1ffa416d159d03c3370b9a462aee35', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/fff2c8326280c07733828f990548979bdc893859'}",
      "dataset":"osv",
      "summary":"Out of bounds access in tensorflow-lite ### Impact\nIn TensorFlow Lite, saved models in the flatbuffer format use a double indexing scheme: a model has a set of subgraphs, each subgraph has a set of operators and each operator has a set of input\/output tensors. The flatbuffer format uses indices for the tensors, indexing into an array of tensors that is owned by the subgraph. This results in a pattern of double array indexing when trying to get the data of each tensor:https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/kernels\/kernel_util.cc#L36\n\nHowever, some operators can have some tensors be optional. To handle this scenario, the flatbuffer model uses a negative `-1` value as index for these tensors:\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/c\/common.h#L82\n\nThis results in special casing during validation at model loading time: https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/core\/subgraph.cc#L566-L580\n\nUnfortunately, this means that the `-1` index is a valid tensor index for any operator, including those that don't expect optional inputs and including for output tensors. Thus, this allows writing and reading from outside the bounds of heap allocated arrays, although only at a specific offset from the start of these arrays.\n\nThis results in both read and write gadgets, albeit very limited in scope.\n\n### Patches\nWe have patched the issue in several commits (46d5b0852, 00302787b7, e11f5558, cd31fd0ce, 1970c21, and fff2c83). We will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### Workarounds\nA potential workaround would be to add a custom `Verifier` to the model loading code to ensure that only operators which accept optional inputs use the `-1` special value and only for the tensors that they expect to be optional. Since this allow-list type approach is erro-prone, we advise upgrading to the patched code.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2020-09-25",
      "chain_len":6,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f",
      "commit_sha":"cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f",
      "patch":"MULTI",
      "chain_ord":"['46d5b0852528ddfd614ded79bccc75589f801bd9', '00302787b788c5ff04cb6f62aed5a74d936e86c0', 'e11f55585f614645b360563072ffeb5c3eeff162', 'cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'fff2c8326280c07733828f990548979bdc893859', '1970c2158b1ffa416d159d03c3370b9a462aee35']",
      "before_first_fix_commit":"{'fff2c8326280c07733828f990548979bdc893859'}",
      "last_fix_commit":"1970c2158b1ffa416d159d03c3370b9a462aee35",
      "chain_ord_pos":4.0,
      "commit_datetime":"09\/18\/2020, 20:44:32",
      "message":"[tflite]: Insert `nullptr` checks when obtaining tensors.\n\nAs part of ongoing refactoring, `tflite::GetInput`, `tflite::GetOutput`, `tflite::GetTemporary` and `tflite::GetIntermediates` will return `nullptr` in some cases. Hence, we insert the `nullptr` checks on all usages.\n\nWe also insert `nullptr` checks on usages of `tflite::GetVariableInput` and `tflite::GetOptionalInputTensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\nPiperOrigin-RevId: 332518902\nChange-Id: I92eb164a6101ac3cca66090061a9b56a97288236",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 16, 'deletions': 7, 'total': 23}",
      "files":"{'tensorflow\/lite\/micro\/test_helpers.cc': {'additions': 16, 'deletions': 7, 'changes': 23, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f\/tensorflow%2Flite%2Fmicro%2Ftest_helpers.cc', 'patch': '@@ -601,7 +601,8 @@ TfLiteStatus SimpleStatefulOp::Prepare(TfLiteContext* context,\\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\\n \\n   \/\/ Make sure that the input is in uint8_t with at least 1 data entry.\\n-  const TfLiteTensor* input = tflite::GetInput(context, node, kInputTensor);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\\n   if (input->type != kTfLiteUInt8) return kTfLiteError;\\n   if (NumElements(input->dims) == 0) return kTfLiteError;\\n \\n@@ -622,7 +623,8 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\\n   *data->invoke_count += 1;\\n \\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\\n   const uint8_t* input_data = GetTensorData<uint8_t>(input);\\n   int size = NumElements(input->dims);\\n \\n@@ -641,9 +643,13 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\\n     }\\n   }\\n \\n-  TfLiteTensor* median = GetOutput(context, node, kMedianTensor);\\n+  TfLiteTensor* median;\\n+  TF_LITE_ENSURE_OK(context,\\n+                    GetOutputSafe(context, node, kMedianTensor, &median));\\n   uint8_t* median_data = GetTensorData<uint8_t>(median);\\n-  TfLiteTensor* invoke_count = GetOutput(context, node, kInvokeCount);\\n+  TfLiteTensor* invoke_count;\\n+  TF_LITE_ENSURE_OK(context,\\n+                    GetOutputSafe(context, node, kInvokeCount, &invoke_count));\\n   int32_t* invoke_count_data = GetTensorData<int32_t>(invoke_count);\\n \\n   median_data[0] = sorting_buffer[size \/ 2];\\n@@ -681,11 +687,14 @@ TfLiteStatus MockCustom::Prepare(TfLiteContext* context, TfLiteNode* node) {\\n }\\n \\n TfLiteStatus MockCustom::Invoke(TfLiteContext* context, TfLiteNode* node) {\\n-  const TfLiteTensor* input = tflite::GetInput(context, node, 0);\\n+  const TfLiteTensor* input;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\\n   const int32_t* input_data = input->data.i32;\\n-  const TfLiteTensor* weight = tflite::GetInput(context, node, 1);\\n+  const TfLiteTensor* weight;\\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &weight));\\n   const uint8_t* weight_data = weight->data.uint8;\\n-  TfLiteTensor* output = GetOutput(context, node, 0);\\n+  TfLiteTensor* output;\\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\\n   int32_t* output_data = output->data.i32;\\n   output_data[0] =\\n       0;  \/\/ Catch output tensor sharing memory with an input tensor'}}",
      "message_norm":"[tflite]: insert `nullptr` checks when obtaining tensors.\n\nas part of ongoing refactoring, `tflite::getinput`, `tflite::getoutput`, `tflite::gettemporary` and `tflite::getintermediates` will return `nullptr` in some cases. hence, we insert the `nullptr` checks on all usages.\n\nwe also insert `nullptr` checks on usages of `tflite::getvariableinput` and `tflite::getoptionalinputtensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\npiperorigin-revid: 332518902\nchange-id: i92eb164a6101ac3cca66090061a9b56a97288236",
      "language":"en",
      "entities":"[('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('nullptr', 'SECWORD', ''), ('332518902', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/micro\/test_helpers.cc'])",
      "num_files":1.0,
      "patch_content":"From cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 18 Sep 2020 13:44:32 -0700\nSubject: [PATCH] [tflite]: Insert `nullptr` checks when obtaining tensors.\n\nAs part of ongoing refactoring, `tflite::GetInput`, `tflite::GetOutput`, `tflite::GetTemporary` and `tflite::GetIntermediates` will return `nullptr` in some cases. Hence, we insert the `nullptr` checks on all usages.\n\nWe also insert `nullptr` checks on usages of `tflite::GetVariableInput` and `tflite::GetOptionalInputTensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\nPiperOrigin-RevId: 332518902\nChange-Id: I92eb164a6101ac3cca66090061a9b56a97288236\n---\n tensorflow\/lite\/micro\/test_helpers.cc | 23 ++++++++++++++++-------\n 1 file changed, 16 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/micro\/test_helpers.cc b\/tensorflow\/lite\/micro\/test_helpers.cc\nindex dd5e996ac26aa6..26575a4d98da9f 100644\n--- a\/tensorflow\/lite\/micro\/test_helpers.cc\n+++ b\/tensorflow\/lite\/micro\/test_helpers.cc\n@@ -601,7 +601,8 @@ TfLiteStatus SimpleStatefulOp::Prepare(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n   \/\/ Make sure that the input is in uint8_t with at least 1 data entry.\n-  const TfLiteTensor* input = tflite::GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   if (input->type != kTfLiteUInt8) return kTfLiteError;\n   if (NumElements(input->dims) == 0) return kTfLiteError;\n \n@@ -622,7 +623,8 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n   *data->invoke_count += 1;\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const uint8_t* input_data = GetTensorData<uint8_t>(input);\n   int size = NumElements(input->dims);\n \n@@ -641,9 +643,13 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\n     }\n   }\n \n-  TfLiteTensor* median = GetOutput(context, node, kMedianTensor);\n+  TfLiteTensor* median;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kMedianTensor, &median));\n   uint8_t* median_data = GetTensorData<uint8_t>(median);\n-  TfLiteTensor* invoke_count = GetOutput(context, node, kInvokeCount);\n+  TfLiteTensor* invoke_count;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kInvokeCount, &invoke_count));\n   int32_t* invoke_count_data = GetTensorData<int32_t>(invoke_count);\n \n   median_data[0] = sorting_buffer[size \/ 2];\n@@ -681,11 +687,14 @@ TfLiteStatus MockCustom::Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus MockCustom::Invoke(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = tflite::GetInput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   const int32_t* input_data = input->data.i32;\n-  const TfLiteTensor* weight = tflite::GetInput(context, node, 1);\n+  const TfLiteTensor* weight;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &weight));\n   const uint8_t* weight_data = weight->data.uint8;\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   int32_t* output_data = output->data.i32;\n   output_data[0] =\n       0;  \/\/ Catch output tensor sharing memory with an input tensor",
      "code_diff":"@@ -601,7 +601,8 @@ TfLiteStatus SimpleStatefulOp::Prepare(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n   \/\/ Make sure that the input is in uint8_t with at least 1 data entry.\n-  const TfLiteTensor* input = tflite::GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   if (input->type != kTfLiteUInt8) return kTfLiteError;\n   if (NumElements(input->dims) == 0) return kTfLiteError;\n \n@@ -622,7 +623,8 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n   *data->invoke_count += 1;\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const uint8_t* input_data = GetTensorData<uint8_t>(input);\n   int size = NumElements(input->dims);\n \n@@ -641,9 +643,13 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\n     }\n   }\n \n-  TfLiteTensor* median = GetOutput(context, node, kMedianTensor);\n+  TfLiteTensor* median;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kMedianTensor, &median));\n   uint8_t* median_data = GetTensorData<uint8_t>(median);\n-  TfLiteTensor* invoke_count = GetOutput(context, node, kInvokeCount);\n+  TfLiteTensor* invoke_count;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kInvokeCount, &invoke_count));\n   int32_t* invoke_count_data = GetTensorData<int32_t>(invoke_count);\n \n   median_data[0] = sorting_buffer[size \/ 2];\n@@ -681,11 +687,14 @@ TfLiteStatus MockCustom::Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus MockCustom::Invoke(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = tflite::GetInput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   const int32_t* input_data = input->data.i32;\n-  const TfLiteTensor* weight = tflite::GetInput(context, node, 1);\n+  const TfLiteTensor* weight;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &weight));\n   const uint8_t* weight_data = weight->data.uint8;\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   int32_t* output_data = output->data.i32;\n   output_data[0] =\n       0;  \/\/ Catch output tensor sharing memory with an input tensor"
    },
    {
      "index":15,
      "vuln_id":"GHSA-545v-42p7-98fq",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886'}",
      "dataset":"osv",
      "summary":"Heap out of bounds read in `MaxPoolGradWithArgmax` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGradWithArgmax` can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([10.0, 10.0, 10.0], shape=[1, 1, 3, 1], dtype=tf.float32)\ngrad = tf.constant([10.0, 10.0, 10.0, 10.0], shape=[1, 1, 1, 4], dtype=tf.float32)\nargmax = tf.constant([1], shape=[1], dtype=tf.int64)\nksize = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\n  \ntf.raw_ops.MaxPoolGradWithArgmax(\n  input=input, grad=grad, argmax=argmax, ksize=ksize, strides=strides,\n  padding='SAME', include_batch_in_index=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e\/tensorflow\/core\/kernels\/maxpooling_op.cc#L1016-L1017) uses the same value to index in two different arrays but there is no guarantee that the sizes are identical. \n\n### Patches\nWe have patched the issue in GitHub commit [dcd7867de0fea4b72a2b34bd41eb74548dc23886](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions. \n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/dcd7867de0fea4b72a2b34bd41eb74548dc23886",
      "commit_sha":"dcd7867de0fea4b72a2b34bd41eb74548dc23886",
      "patch":"SINGLE",
      "chain_ord":"['dcd7867de0fea4b72a2b34bd41eb74548dc23886']",
      "before_first_fix_commit":"{'ef0c008ee84bad91ec6725ddc42091e19a30cf0e'}",
      "last_fix_commit":"dcd7867de0fea4b72a2b34bd41eb74548dc23886",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/05\/2021, 15:38:03",
      "message":"Fix heap buffer overflow\n\nPiperOrigin-RevId: 372132844\nChange-Id: Idef9895efaf145f2b1c23d31983601ec980cd5e4",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
      "files":"{'tensorflow\/core\/kernels\/maxpooling_op.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/dcd7867de0fea4b72a2b34bd41eb74548dc23886\/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc', 'patch': '@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\\n         const int input_start = start * input_size_per_batch;\\n         const int input_end = limit * input_size_per_batch;\\n         for (int64 index = input_start; index < input_end; index++) {\\n+          if (index >= argmax.NumElements()) {\\n+            break;\\n+          }\\n           int64 grad_out_index = argmax_flat(index);\\n           if (!include_batch_in_index) {\\n             const int64 cur_batch = index \/ input_size_per_batch;'}}",
      "message_norm":"fix heap buffer overflow\n\npiperorigin-revid: 372132844\nchange-id: idef9895efaf145f2b1c23d31983601ec980cd5e4",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('372132844', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/maxpooling_op.cc'])",
      "num_files":1.0,
      "patch_content":"From dcd7867de0fea4b72a2b34bd41eb74548dc23886 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 5 May 2021 08:38:03 -0700\nSubject: [PATCH] Fix heap buffer overflow\n\nPiperOrigin-RevId: 372132844\nChange-Id: Idef9895efaf145f2b1c23d31983601ec980cd5e4\n---\n tensorflow\/core\/kernels\/maxpooling_op.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/maxpooling_op.cc b\/tensorflow\/core\/kernels\/maxpooling_op.cc\nindex b60d54533be689..003d2e94b99cd5 100644\n--- a\/tensorflow\/core\/kernels\/maxpooling_op.cc\n+++ b\/tensorflow\/core\/kernels\/maxpooling_op.cc\n@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\n         const int input_start = start * input_size_per_batch;\n         const int input_end = limit * input_size_per_batch;\n         for (int64 index = input_start; index < input_end; index++) {\n+          if (index >= argmax.NumElements()) {\n+            break;\n+          }\n           int64 grad_out_index = argmax_flat(index);\n           if (!include_batch_in_index) {\n             const int64 cur_batch = index \/ input_size_per_batch;",
      "code_diff":"@@ -1014,6 +1014,9 @@ struct LaunchMaxPoolingGradWithArgmax<CPUDevice, T> {\n         const int input_start = start * input_size_per_batch;\n         const int input_end = limit * input_size_per_batch;\n         for (int64 index = input_start; index < input_end; index++) {\n+          if (index >= argmax.NumElements()) {\n+            break;\n+          }\n           int64 grad_out_index = argmax_flat(index);\n           if (!include_batch_in_index) {\n             const int64 cur_batch = index \/ input_size_per_batch;"
    },
    {
      "index":16,
      "vuln_id":"GHSA-4fg4-p75j-w5xj",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b'}",
      "dataset":"osv",
      "summary":"Heap out of bounds in `QuantizedBatchNormWithGlobalNormalization` ### Impact\nAn attacker can cause a segfault and denial of service via accessing data outside of bounds in `tf.raw_ops.QuantizedBatchNormWithGlobalNormalization`:\n\n```python\nimport tensorflow as tf\n\nt = tf.constant([1], shape=[1, 1, 1, 1], dtype=tf.quint8)\nt_min = tf.constant([], shape=[0], dtype=tf.float32)\nt_max = tf.constant([], shape=[0], dtype=tf.float32)\nm = tf.constant([1], shape=[1], dtype=tf.quint8)\nm_min = tf.constant([], shape=[0], dtype=tf.float32)\nm_max = tf.constant([], shape=[0], dtype=tf.float32)\nv = tf.constant([1], shape=[1], dtype=tf.quint8)\nv_min = tf.constant([], shape=[0], dtype=tf.float32)\nv_max = tf.constant([], shape=[0], dtype=tf.float32)\nbeta = tf.constant([1], shape=[1], dtype=tf.quint8)\nbeta_min = tf.constant([], shape=[0], dtype=tf.float32)\nbeta_max = tf.constant([], shape=[0], dtype=tf.float32)\ngamma = tf.constant([1], shape=[1], dtype=tf.quint8)\ngamma_min = tf.constant([], shape=[0], dtype=tf.float32)\ngamma_max = tf.constant([], shape=[0], dtype=tf.float32) \n\ntf.raw_ops.QuantizedBatchNormWithGlobalNormalization(\n  t=t, t_min=t_min, t_max=t_max, m=m, m_min=m_min, m_max=m_max,\n  v=v, v_min=v_min, v_max=v_max, beta=beta, beta_min=beta_min,\n  beta_max=beta_max, gamma=gamma, gamma_min=gamma_min,\n  gamma_max=gamma_max, out_type=tf.qint32,\n  variance_epsilon=0.1, scale_after_normalization=True)\n```                         \n                            \nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/55a97caa9e99c7f37a0bbbeb414dc55553d3ae7f\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc#L176-L189) assumes the inputs are not empty: \n  \n```cc\nconst float input_min = context->input(1).flat<float>()(0);\nconst float input_max = context->input(2).flat<float>()(0);\n...\nconst float mean_min = context->input(4).flat<float>()(0);\nconst float mean_max = context->input(5).flat<float>()(0);\n...\nconst float var_min = context->input(7).flat<float>()(0);\nconst float var_max = context->input(8).flat<float>()(0);\n...\nconst float beta_min = context->input(10).flat<float>()(0);\nconst float beta_max = context->input(11).flat<float>()(0);\n...\nconst float gamma_min = context->input(13).flat<float>()(0);\nconst float gamma_max = context->input(14).flat<float>()(0);\n```\n\nIf any of these inputs is empty, `.flat<T>()` is an empty buffer, so accessing the element at index 0 is accessing data outside of bounds.\n\n### Patches\nWe have patched the issue in GitHub commit [d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang and Ying Wang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
      "commit_sha":"d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
      "patch":"SINGLE",
      "chain_ord":"['d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b']",
      "before_first_fix_commit":"{'55a97caa9e99c7f37a0bbbeb414dc55553d3ae7f'}",
      "last_fix_commit":"d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/23\/2021, 18:40:06",
      "message":"Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 67, 'deletions': 10, 'total': 77}",
      "files":"{'tensorflow\/core\/kernels\/quantized_batch_norm_op.cc': {'additions': 67, 'deletions': 10, 'changes': 77, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b\/tensorflow%2Fcore%2Fkernels%2Fquantized_batch_norm_op.cc', 'patch': '@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* context) override {\\n     const Tensor& input = context->input(0);\\n-    const float input_min = context->input(1).flat<float>()(0);\\n-    const float input_max = context->input(2).flat<float>()(0);\\n+    const auto& input_min_tensor = context->input(1);\\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\\n+    const float input_min = input_min_tensor.flat<float>()(0);\\n+    const auto& input_max_tensor = context->input(2);\\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\\n+    const float input_max = input_max_tensor.flat<float>()(0);\\n     const Tensor& mean = context->input(3);\\n-    const float mean_min = context->input(4).flat<float>()(0);\\n-    const float mean_max = context->input(5).flat<float>()(0);\\n+    const auto& mean_min_tensor = context->input(4);\\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\\n+    const auto& mean_max_tensor = context->input(5);\\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\\n     const Tensor& var = context->input(6);\\n-    const float var_min = context->input(7).flat<float>()(0);\\n-    const float var_max = context->input(8).flat<float>()(0);\\n+    const auto& var_min_tensor = context->input(7);\\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\\n+    const float var_min = var_min_tensor.flat<float>()(0);\\n+    const auto& var_max_tensor = context->input(8);\\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\\n+    const float var_max = var_max_tensor.flat<float>()(0);\\n     const Tensor& beta = context->input(9);\\n-    const float beta_min = context->input(10).flat<float>()(0);\\n-    const float beta_max = context->input(11).flat<float>()(0);\\n+    const auto& beta_min_tensor = context->input(10);\\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\\n+    const auto& beta_max_tensor = context->input(11);\\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\\n     const Tensor& gamma = context->input(12);\\n-    const float gamma_min = context->input(13).flat<float>()(0);\\n-    const float gamma_max = context->input(14).flat<float>()(0);\\n+    const auto& gamma_min_tensor = context->input(13);\\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\\n+    const auto& gamma_max_tensor = context->input(14);\\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\\n \\n     OP_REQUIRES(context, input.dims() == 4,\\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\\n     OP_REQUIRES(context, gamma.dims() == 1,\\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\\n                                         gamma.shape().DebugString()));\\n+    OP_REQUIRES(context, mean.NumElements() > 1,\\n+                errors::InvalidArgument(\"Must have at least a mean value\",\\n+                                        gamma.shape().DebugString()));\\n+    OP_REQUIRES(context, mean.NumElements() > 1,\\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\\n+    const auto last_dim = input.shape().dims() - 1;\\n+    OP_REQUIRES(context,\\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\\n+                errors::InvalidArgument(\"Must provide as many means as the \"\\n+                                        \"last dimension of the input tensor: \",\\n+                                        mean.shape().DebugString(), \" vs. \",\\n+                                        input.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and variance tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and beta tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\\n+    OP_REQUIRES(\\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\\n+        errors::InvalidArgument(\\n+            \"Mean and gamma tensors must have the same shape: \",\\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\\n \\n     Tensor* output = nullptr;\\n     OP_REQUIRES_OK(context,'}}",
      "message_norm":"add missing validation in `quantizedbatchnormwithglobalnormalization`\n\npiperorigin-revid: 370123451\nchange-id: id234d6dab1ec21230bb8e503dba30f899af87f33",
      "language":"en",
      "entities":"[('add', 'ACTION', ''), ('missing validation', 'SECWORD', ''), ('370123451', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/quantized_batch_norm_op.cc'])",
      "num_files":1.0,
      "patch_content":"From d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 23 Apr 2021 11:40:06 -0700\nSubject: [PATCH] Add missing validation in\n `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33\n---\n ...\/core\/kernels\/quantized_batch_norm_op.cc   | 77 ++++++++++++++++---\n 1 file changed, 67 insertions(+), 10 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc b\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc\nindex b03da7ad17fab4..6dfe07f97a4007 100644\n--- a\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc\n+++ b\/tensorflow\/core\/kernels\/quantized_batch_norm_op.cc\n@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float input_min = context->input(1).flat<float>()(0);\n-    const float input_max = context->input(2).flat<float>()(0);\n+    const auto& input_min_tensor = context->input(1);\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\n+    const float input_min = input_min_tensor.flat<float>()(0);\n+    const auto& input_max_tensor = context->input(2);\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\n+    const float input_max = input_max_tensor.flat<float>()(0);\n     const Tensor& mean = context->input(3);\n-    const float mean_min = context->input(4).flat<float>()(0);\n-    const float mean_max = context->input(5).flat<float>()(0);\n+    const auto& mean_min_tensor = context->input(4);\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\n+    const auto& mean_max_tensor = context->input(5);\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\n     const Tensor& var = context->input(6);\n-    const float var_min = context->input(7).flat<float>()(0);\n-    const float var_max = context->input(8).flat<float>()(0);\n+    const auto& var_min_tensor = context->input(7);\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\n+    const float var_min = var_min_tensor.flat<float>()(0);\n+    const auto& var_max_tensor = context->input(8);\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\n+    const float var_max = var_max_tensor.flat<float>()(0);\n     const Tensor& beta = context->input(9);\n-    const float beta_min = context->input(10).flat<float>()(0);\n-    const float beta_max = context->input(11).flat<float>()(0);\n+    const auto& beta_min_tensor = context->input(10);\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\n+    const auto& beta_max_tensor = context->input(11);\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\n     const Tensor& gamma = context->input(12);\n-    const float gamma_min = context->input(13).flat<float>()(0);\n-    const float gamma_max = context->input(14).flat<float>()(0);\n+    const auto& gamma_min_tensor = context->input(13);\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n+    const auto& gamma_max_tensor = context->input(14);\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n \n     OP_REQUIRES(context, input.dims() == 4,\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\n     OP_REQUIRES(context, gamma.dims() == 1,\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                         gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\",\n+                                        gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\n+    const auto last_dim = input.shape().dims() - 1;\n+    OP_REQUIRES(context,\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n+                errors::InvalidArgument(\"Must provide as many means as the \"\n+                                        \"last dimension of the input tensor: \",\n+                                        mean.shape().DebugString(), \" vs. \",\n+                                        input.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and variance tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and beta tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and gamma tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,",
      "code_diff":"@@ -173,20 +173,50 @@ class QuantizedBatchNormOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float input_min = context->input(1).flat<float>()(0);\n-    const float input_max = context->input(2).flat<float>()(0);\n+    const auto& input_min_tensor = context->input(1);\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\n+    const float input_min = input_min_tensor.flat<float>()(0);\n+    const auto& input_max_tensor = context->input(2);\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\n+    const float input_max = input_max_tensor.flat<float>()(0);\n     const Tensor& mean = context->input(3);\n-    const float mean_min = context->input(4).flat<float>()(0);\n-    const float mean_max = context->input(5).flat<float>()(0);\n+    const auto& mean_min_tensor = context->input(4);\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\n+    const auto& mean_max_tensor = context->input(5);\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\n     const Tensor& var = context->input(6);\n-    const float var_min = context->input(7).flat<float>()(0);\n-    const float var_max = context->input(8).flat<float>()(0);\n+    const auto& var_min_tensor = context->input(7);\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\n+    const float var_min = var_min_tensor.flat<float>()(0);\n+    const auto& var_max_tensor = context->input(8);\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\n+    const float var_max = var_max_tensor.flat<float>()(0);\n     const Tensor& beta = context->input(9);\n-    const float beta_min = context->input(10).flat<float>()(0);\n-    const float beta_max = context->input(11).flat<float>()(0);\n+    const auto& beta_min_tensor = context->input(10);\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\n+    const auto& beta_max_tensor = context->input(11);\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\n     const Tensor& gamma = context->input(12);\n-    const float gamma_min = context->input(13).flat<float>()(0);\n-    const float gamma_max = context->input(14).flat<float>()(0);\n+    const auto& gamma_min_tensor = context->input(13);\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n+    const auto& gamma_max_tensor = context->input(14);\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n \n     OP_REQUIRES(context, input.dims() == 4,\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\n@@ -203,6 +233,33 @@ class QuantizedBatchNormOp : public OpKernel {\n     OP_REQUIRES(context, gamma.dims() == 1,\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                         gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\",\n+                                        gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\n+    const auto last_dim = input.shape().dims() - 1;\n+    OP_REQUIRES(context,\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n+                errors::InvalidArgument(\"Must provide as many means as the \"\n+                                        \"last dimension of the input tensor: \",\n+                                        mean.shape().DebugString(), \" vs. \",\n+                                        input.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and variance tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and beta tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and gamma tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,"
    },
    {
      "index":17,
      "vuln_id":"GHSA-q263-fvxm-m5mw",
      "cwe_id":"{'CWE-908', 'CWE-125'}",
      "score":4.4,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0cc38aaa4064fd9e79101994ce9872c6d91f816b'}",
      "dataset":"osv",
      "summary":"Heap out of bounds access in MakeEdge in TensorFlow ### Impact\nUnder certain cases, loading a saved model can result in accessing uninitialized memory while building the computation graph. The [`MakeEdge` function](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/3616708cb866365301d8e67b43b32b46d94b08a0\/tensorflow\/core\/common_runtime\/graph_constructor.cc#L1426-L1438) creates an edge between one output tensor of the `src` node (given by `output_index`) and the input slot of the `dst` node (given by `input_index`). This is only possible if the types of the tensors on both sides coincide, so the function begins by obtaining the corresponding `DataType` values and comparing these for equality:\n\n```cc\n  DataType src_out = src->output_type(output_index);\n  DataType dst_in = dst->input_type(input_index);\n  \/\/...\n```\n\nHowever, there is no check that the indices point to inside of the arrays they index into. Thus, this can result in accessing data out of bounds of the corresponding heap allocated arrays.\n\nIn most scenarios, this can manifest as unitialized data access, but if the index points far away from the boundaries of the arrays this can be used to leak addresses from the library.\n\n### Patches\nWe have patched the issue in GitHub commit [0cc38aaa4064fd9e79101994ce9872c6d91f816b](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0cc38aaa4064fd9e79101994ce9872c6d91f816b) and will release TensorFlow 2.4.0 containing the patch. TensorFlow nightly packages after this commit will also have the issue resolved.\n\nSince this issue also impacts TF versions before 2.4, we will patch all releases between 1.15 and 2.3 inclusive.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date":"2020-12-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0cc38aaa4064fd9e79101994ce9872c6d91f816b",
      "commit_sha":"0cc38aaa4064fd9e79101994ce9872c6d91f816b",
      "patch":"SINGLE",
      "chain_ord":"['0cc38aaa4064fd9e79101994ce9872c6d91f816b']",
      "before_first_fix_commit":"{'3616708cb866365301d8e67b43b32b46d94b08a0'}",
      "last_fix_commit":"0cc38aaa4064fd9e79101994ce9872c6d91f816b",
      "chain_ord_pos":1.0,
      "commit_datetime":"12\/08\/2020, 17:31:57",
      "message":"Prevent unitialized memory access in `GraphConstructor::MakeEdge`\n\nThe `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\n\nPiperOrigin-RevId: 346343288\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
      "files":"{'tensorflow\/core\/common_runtime\/graph_constructor.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/0cc38aaa4064fd9e79101994ce9872c6d91f816b\/tensorflow%2Fcore%2Fcommon_runtime%2Fgraph_constructor.cc', 'patch': '@@ -44,6 +44,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\\n #include \"tensorflow\/core\/lib\/strings\/scanner.h\"\\n #include \"tensorflow\/core\/lib\/strings\/str_util.h\"\\n+#include \"tensorflow\/core\/platform\/errors.h\"\\n #include \"tensorflow\/core\/platform\/logging.h\"\\n #include \"tensorflow\/core\/platform\/macros.h\"\\n #include \"tensorflow\/core\/public\/version.h\"\\n@@ -1425,6 +1426,17 @@ void GraphConstructor::Undo() {\\n \\n Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\\n                                   int input_index) {\\n+  if (output_index >= src->num_outputs()) {\\n+    return errors::InvalidArgument(\\n+        \"Output \", output_index, \" of node \", src->name(),\\n+        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\\n+  }\\n+  if (input_index >= dst->num_inputs()) {\\n+    return errors::InvalidArgument(\\n+        \"Input \", input_index, \" of node \", dst->name(),\\n+        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\\n+  }\\n+\\n   DataType src_out = src->output_type(output_index);\\n   DataType dst_in = dst->input_type(input_index);\\n   if (!TypesCompatible(dst_in, src_out)) {'}}",
      "message_norm":"prevent unitialized memory access in `graphconstructor::makeedge`\n\nthe `makeedge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. however, if this is not the case this results in accessing data out of bounds. because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. however, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\n\npiperorigin-revid: 346343288\nchange-id: i2127da27c2023d27f26efd39afa6c853385cab6f",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('out of bounds', 'SECWORD', ''), ('malicious', 'SECWORD', ''), ('manipulate', 'ACTION', ''), ('information leakage', 'SECWORD', ''), ('exploits', 'SECWORD', ''), ('346343288', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/common_runtime\/graph_constructor.cc'])",
      "num_files":1.0,
      "patch_content":"From 0cc38aaa4064fd9e79101994ce9872c6d91f816b Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 8 Dec 2020 09:31:57 -0800\nSubject: [PATCH] Prevent unitialized memory access in\n `GraphConstructor::MakeEdge`\n\nThe `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\n\nPiperOrigin-RevId: 346343288\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f\n---\n tensorflow\/core\/common_runtime\/graph_constructor.cc | 12 ++++++++++++\n 1 file changed, 12 insertions(+)\n\ndiff --git a\/tensorflow\/core\/common_runtime\/graph_constructor.cc b\/tensorflow\/core\/common_runtime\/graph_constructor.cc\nindex 92b07682d76cd8..639739e9cac8c2 100644\n--- a\/tensorflow\/core\/common_runtime\/graph_constructor.cc\n+++ b\/tensorflow\/core\/common_runtime\/graph_constructor.cc\n@@ -44,6 +44,7 @@ limitations under the License.\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\n #include \"tensorflow\/core\/lib\/strings\/scanner.h\"\n #include \"tensorflow\/core\/lib\/strings\/str_util.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/logging.h\"\n #include \"tensorflow\/core\/platform\/macros.h\"\n #include \"tensorflow\/core\/public\/version.h\"\n@@ -1425,6 +1426,17 @@ void GraphConstructor::Undo() {\n \n Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                   int input_index) {\n+  if (output_index >= src->num_outputs()) {\n+    return errors::InvalidArgument(\n+        \"Output \", output_index, \" of node \", src->name(),\n+        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\n+  }\n+  if (input_index >= dst->num_inputs()) {\n+    return errors::InvalidArgument(\n+        \"Input \", input_index, \" of node \", dst->name(),\n+        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\n+  }\n+\n   DataType src_out = src->output_type(output_index);\n   DataType dst_in = dst->input_type(input_index);\n   if (!TypesCompatible(dst_in, src_out)) {",
      "code_diff":"@@ -44,6 +44,7 @@ limitations under the License.\n #include \"tensorflow\/core\/lib\/gtl\/inlined_vector.h\"\n #include \"tensorflow\/core\/lib\/strings\/scanner.h\"\n #include \"tensorflow\/core\/lib\/strings\/str_util.h\"\n+#include \"tensorflow\/core\/platform\/errors.h\"\n #include \"tensorflow\/core\/platform\/logging.h\"\n #include \"tensorflow\/core\/platform\/macros.h\"\n #include \"tensorflow\/core\/public\/version.h\"\n@@ -1425,6 +1426,17 @@ void GraphConstructor::Undo() {\n \n Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                   int input_index) {\n+  if (output_index >= src->num_outputs()) {\n+    return errors::InvalidArgument(\n+        \"Output \", output_index, \" of node \", src->name(),\n+        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\n+  }\n+  if (input_index >= dst->num_inputs()) {\n+    return errors::InvalidArgument(\n+        \"Input \", input_index, \" of node \", dst->name(),\n+        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\n+  }\n+\n   DataType src_out = src->output_type(output_index);\n   DataType dst_in = dst->input_type(input_index);\n   if (!TypesCompatible(dst_in, src_out)) {"
    },
    {
      "index":18,
      "vuln_id":"GHSA-9c8h-vvrj-w2p8",
      "cwe_id":"{'CWE-125'}",
      "score":7.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a2b743f6017d7b97af1fe49087ae15f0ac634373'}",
      "dataset":"osv",
      "summary":"Heap OOB in `RaggedGather` ### Impact\nIf the arguments to `tf.raw_ops.RaggedGather` don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers.\n                                                                                                                                                                                                                                                                                          \n```python\nimport tensorflow as tf\n\ntf.raw_ops.RaggedGather(\n  params_nested_splits = [0,0,0],\n  params_dense_values = [1,1],\n  indices = [0,0,9,0,0],\n  OUTPUT_RAGGED_RANK=0)\n```\n\nIn debug mode, the same code triggers a `CHECK` failure.\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/kernels\/ragged_gather_op.cc#L70) directly reads the first dimension of a tensor shape before checking that said tensor has rank of at least 1 (i.e., it is not a scalar). Furthermore, the implementation does not check that the list given by `params_nested_splits` is not an empty list of tensors.\n\n### Patches\nWe have patched the issue in GitHub commit [a2b743f6017d7b97af1fe49087ae15f0ac634373](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a2b743f6017d7b97af1fe49087ae15f0ac634373).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a2b743f6017d7b97af1fe49087ae15f0ac634373",
      "commit_sha":"a2b743f6017d7b97af1fe49087ae15f0ac634373",
      "patch":"SINGLE",
      "chain_ord":"['a2b743f6017d7b97af1fe49087ae15f0ac634373']",
      "before_first_fix_commit":"{'4979e3b104cede96958ea88be5ce5fc584949340'}",
      "last_fix_commit":"a2b743f6017d7b97af1fe49087ae15f0ac634373",
      "chain_ord_pos":1.0,
      "commit_datetime":"08\/03\/2021, 02:05:27",
      "message":"Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 7, 'deletions': 1, 'total': 8}",
      "files":"{'tensorflow\/core\/kernels\/ragged_gather_op.cc': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a2b743f6017d7b97af1fe49087ae15f0ac634373\/tensorflow%2Fcore%2Fkernels%2Fragged_gather_op.cc', 'patch': '@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\\n \\n   void Compute(OpKernelContext* context) override {\\n     \/\/ Get the input Tensors.\\n+\\n     OpInputList params_nested_splits_in;\\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\\n                                                 &params_nested_splits_in));\\n+    OP_REQUIRES(\\n+        context, params_nested_splits_in.size() > 0,\\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\\n+\\n     const Tensor& params_dense_values_in =\\n         context->input(params_nested_splits_in.size());\\n     const Tensor& indices_in =\\n         context->input(params_nested_splits_in.size() + 1);\\n \\n-    DCHECK_GT(params_nested_splits_in.size(), 0);  \/\/ Enforced by REGISTER_OP.\\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));'}}",
      "message_norm":"fix heap oob in `tf.raw_ops.raggedgather`\n\npiperorigin-revid: 388355464\nchange-id: if14d96231d1cd7aad7c4d1c22c1bab1576b75717",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('388355464', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_gather_op.cc'])",
      "num_files":1.0,
      "patch_content":"From a2b743f6017d7b97af1fe49087ae15f0ac634373 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Mon, 2 Aug 2021 19:05:27 -0700\nSubject: [PATCH] Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717\n---\n tensorflow\/core\/kernels\/ragged_gather_op.cc | 8 +++++++-\n 1 file changed, 7 insertions(+), 1 deletion(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/ragged_gather_op.cc b\/tensorflow\/core\/kernels\/ragged_gather_op.cc\nindex 3bf82cba050e3b..d6d51c770bbb7a 100644\n--- a\/tensorflow\/core\/kernels\/ragged_gather_op.cc\n+++ b\/tensorflow\/core\/kernels\/ragged_gather_op.cc\n@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     \/\/ Get the input Tensors.\n+\n     OpInputList params_nested_splits_in;\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                 &params_nested_splits_in));\n+    OP_REQUIRES(\n+        context, params_nested_splits_in.size() > 0,\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\n+\n     const Tensor& params_dense_values_in =\n         context->input(params_nested_splits_in.size());\n     const Tensor& indices_in =\n         context->input(params_nested_splits_in.size() + 1);\n \n-    DCHECK_GT(params_nested_splits_in.size(), 0);  \/\/ Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));",
      "code_diff":"@@ -58,15 +58,21 @@ class RaggedGatherOpBase : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     \/\/ Get the input Tensors.\n+\n     OpInputList params_nested_splits_in;\n     OP_REQUIRES_OK(context, context->input_list(\"params_nested_splits\",\n                                                 &params_nested_splits_in));\n+    OP_REQUIRES(\n+        context, params_nested_splits_in.size() > 0,\n+        errors::InvalidArgument(\"params_nested_splits must be non empty\"));\n+\n     const Tensor& params_dense_values_in =\n         context->input(params_nested_splits_in.size());\n     const Tensor& indices_in =\n         context->input(params_nested_splits_in.size() + 1);\n \n-    DCHECK_GT(params_nested_splits_in.size(), 0);  \/\/ Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, params_nested_splits_in[0].dims() > 0,\n+                errors::InvalidArgument(\"Split tensors must not be scalars\"));\n     SPLITS_TYPE num_params = params_nested_splits_in[0].dim_size(0) - 1;\n     OP_REQUIRES_OK(context, ValidateIndices(indices_in, num_params));"
    },
    {
      "index":19,
      "vuln_id":"GHSA-c545-c4f9-rf6v",
      "cwe_id":"{'CWE-125'}",
      "score":5.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d94ffe08a65400f898241c0374e9edc6fa8ed257'}",
      "dataset":"osv",
      "summary":"Heap OOB in TFLite ### Impact\nTFLite's [`expand_dims.cc`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/expand_dims.cc#L36-L50) contains a vulnerability which allows reading one element outside of bounds of heap allocated data:\n\n```cc\n  if (axis < 0) { \n    axis = input_dims.size + 1 + axis;\n  }   \n  TF_LITE_ENSURE(context, axis <= input_dims.size);\n\n  TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\n  for (int i = 0; i < output_dims->size; ++i) {\n    if (i < axis) {\n      output_dims->data[i] = input_dims.data[i];\n    } else if (i == axis) {\n      output_dims->data[i] = 1;\n    } else {\n      output_dims->data[i] = input_dims.data[i - 1];\n    }\n  }\n```\n\nIf `axis` is a large negative value (e.g., `-100000`), then after the first `if` it would still be negative. The check following the `if` statement will pass and the `for` loop would read one element before the start of `input_dims.data` (when `i = 0`).\n\n### Patches\nWe have patched the issue in GitHub commit [d94ffe08a65400f898241c0374e9edc6fa8ed257](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d94ffe08a65400f898241c0374e9edc6fa8ed257).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/d94ffe08a65400f898241c0374e9edc6fa8ed257",
      "commit_sha":"d94ffe08a65400f898241c0374e9edc6fa8ed257",
      "patch":"SINGLE",
      "chain_ord":"['d94ffe08a65400f898241c0374e9edc6fa8ed257']",
      "before_first_fix_commit":"{'e95fc647063378993ec84d41cbbda6dcb60bad4e'}",
      "last_fix_commit":"d94ffe08a65400f898241c0374e9edc6fa8ed257",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/27\/2021, 21:42:54",
      "message":"Prevent an OOB read in `expand_dims.cc`\n\nThe for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. If user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in Python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\nPiperOrigin-RevId: 387200206\nChange-Id: I162f4feba12d547c3a4340833ae682016a2ebfab",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 0, 'total': 1}",
      "files":"{'tensorflow\/lite\/kernels\/expand_dims.cc': {'additions': 1, 'deletions': 0, 'changes': 1, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/d94ffe08a65400f898241c0374e9edc6fa8ed257\/tensorflow%2Flite%2Fkernels%2Fexpand_dims.cc', 'patch': '@@ -37,6 +37,7 @@ TfLiteStatus ExpandTensorDim(TfLiteContext* context, const TfLiteTensor& input,\\n     axis = input_dims.size + 1 + axis;\\n   }\\n   TF_LITE_ENSURE(context, axis <= input_dims.size);\\n+  TF_LITE_ENSURE(context, axis >= 0);\\n \\n   TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\\n   for (int i = 0; i < output_dims->size; ++i) {'}}",
      "message_norm":"prevent an oob read in `expand_dims.cc`\n\nthe for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. if user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\npiperorigin-revid: 387200206\nchange-id: i162f4feba12d547c3a4340833ae682016a2ebfab",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('oob', 'SECWORD', ''), ('387200206', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/expand_dims.cc'])",
      "num_files":1.0,
      "patch_content":"From d94ffe08a65400f898241c0374e9edc6fa8ed257 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 27 Jul 2021 14:42:54 -0700\nSubject: [PATCH] Prevent an OOB read in `expand_dims.cc`\n\nThe for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`. If user supplied `axis` is negative, the if code before this check is supposed to bring it back to positive (similar to how in Python one can do `l[-3]` to mean `l[-3 + len(l)]`).\n\nPiperOrigin-RevId: 387200206\nChange-Id: I162f4feba12d547c3a4340833ae682016a2ebfab\n---\n tensorflow\/lite\/kernels\/expand_dims.cc | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/expand_dims.cc b\/tensorflow\/lite\/kernels\/expand_dims.cc\nindex 231ba6df8ba735..c8d0270551c192 100644\n--- a\/tensorflow\/lite\/kernels\/expand_dims.cc\n+++ b\/tensorflow\/lite\/kernels\/expand_dims.cc\n@@ -37,6 +37,7 @@ TfLiteStatus ExpandTensorDim(TfLiteContext* context, const TfLiteTensor& input,\n     axis = input_dims.size + 1 + axis;\n   }\n   TF_LITE_ENSURE(context, axis <= input_dims.size);\n+  TF_LITE_ENSURE(context, axis >= 0);\n \n   TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\n   for (int i = 0; i < output_dims->size; ++i) {",
      "code_diff":"@@ -37,6 +37,7 @@ TfLiteStatus ExpandTensorDim(TfLiteContext* context, const TfLiteTensor& input,\n     axis = input_dims.size + 1 + axis;\n   }\n   TF_LITE_ENSURE(context, axis <= input_dims.size);\n+  TF_LITE_ENSURE(context, axis >= 0);\n \n   TfLiteIntArray* output_dims = TfLiteIntArrayCreate(input_dims.size + 1);\n   for (int i = 0; i < output_dims->size; ++i) {"
    },
    {
      "index":20,
      "vuln_id":"GHSA-3h8m-483j-7xxm",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e'}",
      "dataset":"osv",
      "summary":"Heap out of bounds read in `RequantizationRange` ### Impact\nThe implementation of `tf.raw_ops.MaxPoolGradWithArgmax` can cause reads outside of bounds of heap allocated data if attacker supplies specially crafted inputs:\n\n```python\nimport tensorflow as tf\n\ninput = tf.constant([1], shape=[1], dtype=tf.qint32) \ninput_max = tf.constant([], dtype=tf.float32)\ninput_min = tf.constant([], dtype=tf.float32)\n\ntf.raw_ops.RequantizationRange(input=input, input_min=input_min, input_max=input_max)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/ac328eaa3870491ababc147822cd04e91a790643\/tensorflow\/core\/kernels\/requantization_range_op.cc#L49-L50) assumes that the `input_min` and `input_max` tensors have at least one element, as it accesses the first element in two arrays:\n\n```cc\nconst float input_min_float = ctx->input(1).flat<float>()(0);\nconst float input_max_float = ctx->input(2).flat<float>()(0);\n```\n\nIf the tensors are empty, `.flat<T>()` is an empty object, backed by an empty array. Hence, accesing even the 0th element is a read outside the bounds.\n\n### Patches\nWe have patched the issue in GitHub commit [ef0c008ee84bad91ec6725ddc42091e19a30cf0e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e",
      "commit_sha":"ef0c008ee84bad91ec6725ddc42091e19a30cf0e",
      "patch":"SINGLE",
      "chain_ord":"['ef0c008ee84bad91ec6725ddc42091e19a30cf0e']",
      "before_first_fix_commit":"{'ac328eaa3870491ababc147822cd04e91a790643'}",
      "last_fix_commit":"ef0c008ee84bad91ec6725ddc42091e19a30cf0e",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/05\/2021, 15:16:13",
      "message":"Fix out of bound read in requantization_range_op.cc\n\nPiperOrigin-RevId: 372129031\nChange-Id: Ie684ab98a3840c5186ead3eafffc0e0ed0e8030d",
      "author":"Laura Pak",
      "comments":null,
      "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
      "files":"{'tensorflow\/core\/kernels\/requantization_range_op.cc': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ef0c008ee84bad91ec6725ddc42091e19a30cf0e\/tensorflow%2Fcore%2Fkernels%2Frequantization_range_op.cc', 'patch': '@@ -46,6 +46,10 @@ class RequantizationRangeOp : public OpKernel {\\n \\n   void Compute(OpKernelContext* ctx) override {\\n     const Tensor& input = ctx->input(0);\\n+    OP_REQUIRES(ctx, ctx->input(1).NumElements() > 0,\\n+                errors::InvalidArgument(\"Input min must not be empty.\"));\\n+    OP_REQUIRES(ctx, ctx->input(2).NumElements() > 0,\\n+                errors::InvalidArgument(\"Input max must not be empty.\"));\\n     const float input_min_float = ctx->input(1).flat<float>()(0);\\n     const float input_max_float = ctx->input(2).flat<float>()(0);\\n     Tensor* output_min = nullptr;'}}",
      "message_norm":"fix out of bound read in requantization_range_op.cc\n\npiperorigin-revid: 372129031\nchange-id: ie684ab98a3840c5186ead3eafffc0e0ed0e8030d",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('out of bound read', 'SECWORD', ''), ('372129031', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/requantization_range_op.cc'])",
      "num_files":1.0,
      "patch_content":"From ef0c008ee84bad91ec6725ddc42091e19a30cf0e Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Wed, 5 May 2021 08:16:13 -0700\nSubject: [PATCH] Fix out of bound read in requantization_range_op.cc\n\nPiperOrigin-RevId: 372129031\nChange-Id: Ie684ab98a3840c5186ead3eafffc0e0ed0e8030d\n---\n tensorflow\/core\/kernels\/requantization_range_op.cc | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/requantization_range_op.cc b\/tensorflow\/core\/kernels\/requantization_range_op.cc\nindex cc6e891a6b352b..f6e217499d1983 100644\n--- a\/tensorflow\/core\/kernels\/requantization_range_op.cc\n+++ b\/tensorflow\/core\/kernels\/requantization_range_op.cc\n@@ -46,6 +46,10 @@ class RequantizationRangeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, ctx->input(1).NumElements() > 0,\n+                errors::InvalidArgument(\"Input min must not be empty.\"));\n+    OP_REQUIRES(ctx, ctx->input(2).NumElements() > 0,\n+                errors::InvalidArgument(\"Input max must not be empty.\"));\n     const float input_min_float = ctx->input(1).flat<float>()(0);\n     const float input_max_float = ctx->input(2).flat<float>()(0);\n     Tensor* output_min = nullptr;",
      "code_diff":"@@ -46,6 +46,10 @@ class RequantizationRangeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n+    OP_REQUIRES(ctx, ctx->input(1).NumElements() > 0,\n+                errors::InvalidArgument(\"Input min must not be empty.\"));\n+    OP_REQUIRES(ctx, ctx->input(2).NumElements() > 0,\n+                errors::InvalidArgument(\"Input max must not be empty.\"));\n     const float input_min_float = ctx->input(1).flat<float>()(0);\n     const float input_max_float = ctx->input(2).flat<float>()(0);\n     Tensor* output_min = nullptr;"
    },
    {
      "index":21,
      "vuln_id":"GHSA-cvgx-3v3q-m36c",
      "cwe_id":"{'CWE-125'}",
      "score":7.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a0d64445116c43cf46a5666bd4eee28e7a82f244'}",
      "dataset":"osv",
      "summary":"Heap OOB in shape inference for `QuantizeV2` ### Impact\nThe [shape inference code for `QuantizeV2`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8d72537c6abf5a44103b57b9c2e22c14f5f49698\/tensorflow\/core\/framework\/common_shape_fns.cc#L2509-L2530) can trigger a read outside of bounds of heap allocated array:\n\n```python\nimport tensorflow as tf\n\n@tf.function\ndef test():\n  data=tf.raw_ops.QuantizeV2(\n    input=[1.0,1.0],\n    min_range=[1.0,10.0],\n    max_range=[1.0,10.0],\n    T=tf.qint32,\n    mode='MIN_COMBINED',\n    round_mode='HALF_TO_EVEN',\n    narrow_range=False,\n    axis=-100,\n    ensure_minimum_range=10)\n  return data\n\ntest()\n```\n\nThis occurs whenever `axis` is a negative value less than `-1`. In this case, we are accessing data before the start of a heap buffer:\n    \n```cc\nint axis = -1;\nStatus s = c->GetAttr(\"axis\", &axis);\nif (!s.ok() && s.code() != error::NOT_FOUND) {\n  return s;\n}   \n... \nif (axis != -1) {\n  ...\n  TF_RETURN_IF_ERROR(\n      c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n}\n```\n\nThe code allows `axis` to be an optional argument (`s` would contain an `error::NOT_FOUND` error code). Otherwise, it assumes that `axis` is a valid index into the dimensions of the `input` tensor. If `axis` is less than `-1` then this results in a heap OOB read.\n    \n### Patches\nWe have patched the issue in GitHub commit [a0d64445116c43cf46a5666bd4eee28e7a82f244](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a0d64445116c43cf46a5666bd4eee28e7a82f244).\n    \nThe fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, as this version is the only one that is also affected.\n  \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-11-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a0d64445116c43cf46a5666bd4eee28e7a82f244",
      "commit_sha":"a0d64445116c43cf46a5666bd4eee28e7a82f244",
      "patch":"SINGLE",
      "chain_ord":"['a0d64445116c43cf46a5666bd4eee28e7a82f244']",
      "before_first_fix_commit":"{'4a7c71d60c94ae3bc8149429988eeeb1d5466f00'}",
      "last_fix_commit":"a0d64445116c43cf46a5666bd4eee28e7a82f244",
      "chain_ord_pos":1.0,
      "commit_datetime":"10\/01\/2021, 22:52:56",
      "message":"Prevent OOB access in QuantizeV2 shape inference\n\nPiperOrigin-RevId: 400309614\nChange-Id: I31412c71b05b4f21b677f7fa715a61499cbee39d",
      "author":"Yu-Cheng Ling",
      "comments":null,
      "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
      "files":"{'tensorflow\/core\/framework\/common_shape_fns.cc': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a0d64445116c43cf46a5666bd4eee28e7a82f244\/tensorflow%2Fcore%2Fframework%2Fcommon_shape_fns.cc', 'patch': '@@ -2559,6 +2559,9 @@ Status QuantizeV2Shape(InferenceContext* c) {\\n   if (!s.ok() && s.code() != error::NOT_FOUND) {\\n     return s;\\n   }\\n+  if (axis < -1) {\\n+    return errors::InvalidArgument(\"axis should be at least -1, got \", axis);\\n+  }\\n   const int minmax_rank = (axis == -1) ? 0 : 1;\\n   TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\\n   ShapeHandle minmax;'}}",
      "message_norm":"prevent oob access in quantizev2 shape inference\n\npiperorigin-revid: 400309614\nchange-id: i31412c71b05b4f21b677f7fa715a61499cbee39d",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('oob', 'SECWORD', ''), ('400309614', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/framework\/common_shape_fns.cc'])",
      "num_files":1.0,
      "patch_content":"From a0d64445116c43cf46a5666bd4eee28e7a82f244 Mon Sep 17 00:00:00 2001\nFrom: Yu-Cheng Ling <ycling@google.com>\nDate: Fri, 1 Oct 2021 15:52:56 -0700\nSubject: [PATCH] Prevent OOB access in QuantizeV2 shape inference\n\nPiperOrigin-RevId: 400309614\nChange-Id: I31412c71b05b4f21b677f7fa715a61499cbee39d\n---\n tensorflow\/core\/framework\/common_shape_fns.cc | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/core\/framework\/common_shape_fns.cc b\/tensorflow\/core\/framework\/common_shape_fns.cc\nindex 8c1b3bf1d1c9d8..95f2670e0571da 100644\n--- a\/tensorflow\/core\/framework\/common_shape_fns.cc\n+++ b\/tensorflow\/core\/framework\/common_shape_fns.cc\n@@ -2559,6 +2559,9 @@ Status QuantizeV2Shape(InferenceContext* c) {\n   if (!s.ok() && s.code() != error::NOT_FOUND) {\n     return s;\n   }\n+  if (axis < -1) {\n+    return errors::InvalidArgument(\"axis should be at least -1, got \", axis);\n+  }\n   const int minmax_rank = (axis == -1) ? 0 : 1;\n   TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n   ShapeHandle minmax;",
      "code_diff":"@@ -2559,6 +2559,9 @@ Status QuantizeV2Shape(InferenceContext* c) {\n   if (!s.ok() && s.code() != error::NOT_FOUND) {\n     return s;\n   }\n+  if (axis < -1) {\n+    return errors::InvalidArgument(\"axis should be at least -1, got \", axis);\n+  }\n   const int minmax_rank = (axis == -1) ? 0 : 1;\n   TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n   ShapeHandle minmax;"
    },
    {
      "index":22,
      "vuln_id":"GHSA-7fvx-3jfc-2cpc",
      "cwe_id":"{'CWE-125'}",
      "score":7.3,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/01cff3f986259d661103412a20745928c727326f'}",
      "dataset":"osv",
      "summary":"Heap OOB in `ResourceScatterUpdate` ### Impact\nAn attacker can trigger a read from outside of bounds of heap allocated data by sending invalid arguments to `tf.raw_ops.ResourceScatterUpdate`:\n\n```python\nimport tensorflow as tf\n\nv = tf.Variable([b'vvv'])\ntf.raw_ops.ResourceScatterUpdate(\n  resource=v.handle,\n  indices=[0],\n  updates=['1', '2', '3', '4', '5'])\n```\n  \nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/resource_variable_ops.cc#L919-L923) has an incomplete validation of the relationship between the shapes of `indices` and `updates`: instead of checking that the shape of `indices` is a prefix of the shape of `updates` (so that broadcasting can happen), code only checks that the number of elements in these two tensors are in a divisibility relationship.\n\n### Patches \nWe have patched the issue in GitHub commit [01cff3f986259d661103412a20745928c727326f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/01cff3f986259d661103412a20745928c727326f).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n    \n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n    \n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/01cff3f986259d661103412a20745928c727326f",
      "commit_sha":"01cff3f986259d661103412a20745928c727326f",
      "patch":"SINGLE",
      "chain_ord":"['01cff3f986259d661103412a20745928c727326f']",
      "before_first_fix_commit":"{'96f364a1ca3009f98980021c4b32be5fdcca33a1'}",
      "last_fix_commit":"01cff3f986259d661103412a20745928c727326f",
      "chain_ord_pos":1.0,
      "commit_datetime":"08\/02\/2021, 20:33:05",
      "message":"Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`\n\nPiperOrigin-RevId: 388292801\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 6, 'deletions': 5, 'total': 11}",
      "files":"{'tensorflow\/core\/kernels\/resource_variable_ops.cc': {'additions': 6, 'deletions': 5, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/01cff3f986259d661103412a20745928c727326f\/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.cc', 'patch': '@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\\n                         params->dim_size(0), \")\"));\\n       } else {\\n         int64_t num_updates = updates.NumElements();\\n-        OP_REQUIRES(c, num_updates % N == 0,\\n-                    errors::InvalidArgument(\\n-                        \"shape of indices (\", indices.shape().DebugString(),\\n-                        \") is not compatible with the shape of updates (\",\\n-                        updates.shape().DebugString(), \")\"));\\n+        OP_REQUIRES(\\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\\n+            errors::InvalidArgument(\\n+                \"The shape of indices (\", indices.shape().DebugString(),\\n+                \") must be a prefix of the shape of updates (\",\\n+                updates.shape().DebugString(), \")\"));\\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates \/ N});\\n \\n         functor::ScatterFunctor<Device, T, Index, op> functor;'}}",
      "message_norm":"fix heap oob due to dimension mismatch in `resourcescatterupdate`\n\npiperorigin-revid: 388292801\nchange-id: id9bd7244d98d41b1517d4771850b32782c0cc949",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('388292801', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/resource_variable_ops.cc'])",
      "num_files":1.0,
      "patch_content":"From 01cff3f986259d661103412a20745928c727326f Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Mon, 2 Aug 2021 13:33:05 -0700\nSubject: [PATCH] Fix heap OOB due to dimension mismatch in\n `ResourceScatterUpdate`\n\nPiperOrigin-RevId: 388292801\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949\n---\n tensorflow\/core\/kernels\/resource_variable_ops.cc | 11 ++++++-----\n 1 file changed, 6 insertions(+), 5 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/resource_variable_ops.cc b\/tensorflow\/core\/kernels\/resource_variable_ops.cc\nindex 8b9610724e5826..b81a7a517ea6d2 100644\n--- a\/tensorflow\/core\/kernels\/resource_variable_ops.cc\n+++ b\/tensorflow\/core\/kernels\/resource_variable_ops.cc\n@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                         params->dim_size(0), \")\"));\n       } else {\n         int64_t num_updates = updates.NumElements();\n-        OP_REQUIRES(c, num_updates % N == 0,\n-                    errors::InvalidArgument(\n-                        \"shape of indices (\", indices.shape().DebugString(),\n-                        \") is not compatible with the shape of updates (\",\n-                        updates.shape().DebugString(), \")\"));\n+        OP_REQUIRES(\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n+            errors::InvalidArgument(\n+                \"The shape of indices (\", indices.shape().DebugString(),\n+                \") must be a prefix of the shape of updates (\",\n+                updates.shape().DebugString(), \")\"));\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates \/ N});\n \n         functor::ScatterFunctor<Device, T, Index, op> functor;",
      "code_diff":"@@ -955,11 +955,12 @@ class ResourceScatterUpdateOp : public OpKernel {\n                         params->dim_size(0), \")\"));\n       } else {\n         int64_t num_updates = updates.NumElements();\n-        OP_REQUIRES(c, num_updates % N == 0,\n-                    errors::InvalidArgument(\n-                        \"shape of indices (\", indices.shape().DebugString(),\n-                        \") is not compatible with the shape of updates (\",\n-                        updates.shape().DebugString(), \")\"));\n+        OP_REQUIRES(\n+            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n+            errors::InvalidArgument(\n+                \"The shape of indices (\", indices.shape().DebugString(),\n+                \") must be a prefix of the shape of updates (\",\n+                updates.shape().DebugString(), \")\"));\n         auto updates_flat = updates.shaped<T, 2>({N, num_updates \/ N});\n \n         functor::ScatterFunctor<Device, T, Index, op> functor;"
    },
    {
      "index":23,
      "vuln_id":"GHSA-59q2-x2qc-4c97",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/51300ba1cc2f487aefec6e6631fef03b0e08b298'}",
      "dataset":"osv",
      "summary":"Heap OOB access in unicode ops ### Impact\nAn attacker can access data outside of bounds of heap allocated array in `tf.raw_ops.UnicodeEncode`:\n\n```python\nimport tensorflow as tf\n\ninput_values = tf.constant([58], shape=[1], dtype=tf.int32)\ninput_splits = tf.constant([[81, 101, 0]], shape=[3], dtype=tf.int32)\noutput_encoding = \"UTF-8\"\n\ntf.raw_ops.UnicodeEncode(\n    input_values=input_values, input_splits=input_splits,\n    output_encoding=output_encoding)\n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/472c1f12ad9063405737679d4f6bd43094e1d36d\/tensorflow\/core\/kernels\/unicode_ops.cc)\nassumes that the `input_value`\/`input_splits` pair specify a valid sparse tensor.\n\n### Patches\nWe have patched the issue in GitHub commit [51300ba1cc2f487aefec6e6631fef03b0e08b298](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/51300ba1cc2f487aefec6e6631fef03b0e08b298).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/51300ba1cc2f487aefec6e6631fef03b0e08b298",
      "commit_sha":"51300ba1cc2f487aefec6e6631fef03b0e08b298",
      "patch":"SINGLE",
      "chain_ord":"['51300ba1cc2f487aefec6e6631fef03b0e08b298']",
      "before_first_fix_commit":"{'472c1f12ad9063405737679d4f6bd43094e1d36d'}",
      "last_fix_commit":"51300ba1cc2f487aefec6e6631fef03b0e08b298",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/03\/2021, 16:53:26",
      "message":"Fix heap buffer overflow in tf.raw_ops.UnicodeEncode.\n\nPiperOrigin-RevId: 371717714\nChange-Id: If33443b28f158e58078f1268f6b92f2728d219e0",
      "author":"Laura Pak",
      "comments":null,
      "stats":"{'additions': 19, 'deletions': 0, 'total': 19}",
      "files":"{'tensorflow\/core\/kernels\/unicode_ops.cc': {'additions': 19, 'deletions': 0, 'changes': 19, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/51300ba1cc2f487aefec6e6631fef03b0e08b298\/tensorflow%2Fcore%2Fkernels%2Funicode_ops.cc', 'patch': '@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\\n     const Tensor& input_splits = context->input(1);\\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\\n \\n+    \/\/ Operation will treat first argument in input_splits as if it were zero\\n+    \/\/ regardless of its actual value since splits should begin with zero and\\n+    \/\/ end with the length of the input values vector.\\n+    OP_REQUIRES(\\n+        context, input_splits_flat(0) == 0,\\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\\n+    OP_REQUIRES(context,\\n+                input_splits_flat(input_splits_flat.size() - 1) ==\\n+                    input_tensor_flat.size(),\\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\\n+                                        \"equal to length of input_tensor.\"));\\n     \/\/ Since we limit to a 2-D input (flat_values of rank 1 and a single splits\\n     \/\/ tensor), our output dimension will be 1 with it\\'s size equal to the\\n     \/\/ number of splits (outer dimension or ragged tensor).\\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\\n       icu::UnicodeString unicode_string;\\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\\n+      OP_REQUIRES(\\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\\n+          errors::InvalidArgument(\\n+              \"Values in input_splits must be equal or in ascending order.\"));\\n+      OP_REQUIRES(\\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\\n+                                  \"equal to input_tensor length.\"));\\n       for (; idx < input_splits_flat(i); ++idx) {\\n         int32 code_point = input_tensor_flat(idx);\\n         \/\/ Check for invalid code point'}}",
      "message_norm":"fix heap buffer overflow in tf.raw_ops.unicodeencode.\n\npiperorigin-revid: 371717714\nchange-id: if33443b28f158e58078f1268f6b92f2728d219e0",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('buffer overflow', 'SECWORD', ''), ('tf.raw_ops.unicodeencode', 'SECWORD', ''), ('371717714', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/unicode_ops.cc'])",
      "num_files":1.0,
      "patch_content":"From 51300ba1cc2f487aefec6e6631fef03b0e08b298 Mon Sep 17 00:00:00 2001\nFrom: Laura Pak <lpak@google.com>\nDate: Mon, 3 May 2021 09:53:26 -0700\nSubject: [PATCH] Fix heap buffer overflow in tf.raw_ops.UnicodeEncode.\n\nPiperOrigin-RevId: 371717714\nChange-Id: If33443b28f158e58078f1268f6b92f2728d219e0\n---\n tensorflow\/core\/kernels\/unicode_ops.cc | 19 +++++++++++++++++++\n 1 file changed, 19 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/unicode_ops.cc b\/tensorflow\/core\/kernels\/unicode_ops.cc\nindex d3a7ad7b2866f7..e6c8f4dfc42284 100644\n--- a\/tensorflow\/core\/kernels\/unicode_ops.cc\n+++ b\/tensorflow\/core\/kernels\/unicode_ops.cc\n@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    \/\/ Operation will treat first argument in input_splits as if it were zero\n+    \/\/ regardless of its actual value since splits should begin with zero and\n+    \/\/ end with the length of the input values vector.\n+    OP_REQUIRES(\n+        context, input_splits_flat(0) == 0,\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\n+    OP_REQUIRES(context,\n+                input_splits_flat(input_splits_flat.size() - 1) ==\n+                    input_tensor_flat.size(),\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\n+                                        \"equal to length of input_tensor.\"));\n     \/\/ Since we limit to a 2-D input (flat_values of rank 1 and a single splits\n     \/\/ tensor), our output dimension will be 1 with it's size equal to the\n     \/\/ number of splits (outer dimension or ragged tensor).\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\n       icu::UnicodeString unicode_string;\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\n+      OP_REQUIRES(\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\n+          errors::InvalidArgument(\n+              \"Values in input_splits must be equal or in ascending order.\"));\n+      OP_REQUIRES(\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\n+                                  \"equal to input_tensor length.\"));\n       for (; idx < input_splits_flat(i); ++idx) {\n         int32 code_point = input_tensor_flat(idx);\n         \/\/ Check for invalid code point",
      "code_diff":"@@ -533,6 +533,17 @@ class UnicodeEncodeOp : public OpKernel {\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    \/\/ Operation will treat first argument in input_splits as if it were zero\n+    \/\/ regardless of its actual value since splits should begin with zero and\n+    \/\/ end with the length of the input values vector.\n+    OP_REQUIRES(\n+        context, input_splits_flat(0) == 0,\n+        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\n+    OP_REQUIRES(context,\n+                input_splits_flat(input_splits_flat.size() - 1) ==\n+                    input_tensor_flat.size(),\n+                errors::InvalidArgument(\"Last value in input_splits must be \"\n+                                        \"equal to length of input_tensor.\"));\n     \/\/ Since we limit to a 2-D input (flat_values of rank 1 and a single splits\n     \/\/ tensor), our output dimension will be 1 with it's size equal to the\n     \/\/ number of splits (outer dimension or ragged tensor).\n@@ -548,6 +559,14 @@ class UnicodeEncodeOp : public OpKernel {\n     for (int i = 1; i < input_splits_flat.size(); ++i) {\n       icu::UnicodeString unicode_string;\n       icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\n+      OP_REQUIRES(\n+          context, input_splits_flat(i - 1) <= input_splits_flat(i),\n+          errors::InvalidArgument(\n+              \"Values in input_splits must be equal or in ascending order.\"));\n+      OP_REQUIRES(\n+          context, input_splits_flat(i) <= input_tensor_flat.size(),\n+          errors::InvalidArgument(\"Values in input_splits must be less than or \"\n+                                  \"equal to input_tensor length.\"));\n       for (; idx < input_splits_flat(i); ++idx) {\n         int32 code_point = input_tensor_flat(idx);\n         \/\/ Check for invalid code point"
    },
    {
      "index":24,
      "vuln_id":"GHSA-jwf9-w5xm-f437",
      "cwe_id":"{'CWE-125'}",
      "score":5.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f'}",
      "dataset":"osv",
      "summary":"Heap OOB in TFLite's `Gather*` implementations ### Impact\nTFLite's [`GatherNd` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation.\n\nHence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`.\n\nSimilar issue exists in [`Gather` implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/149562d49faa709ea80df1d99fc41d005b81082a\/tensorflow\/lite\/kernels\/gather.cc).\n\n```python\nimport tensorflow as tf\nimport numpy as np\ntf.compat.v1.disable_v2_behavior()\n\nparams = tf.compat.v1.placeholder(name=\"params\", dtype=tf.int64, shape=(1,))\nindices = tf.compat.v1.placeholder(name=\"indices\", dtype=tf.int64, shape=())\n\nout = tf.gather(params, indices, name='out')\n\nwith tf.compat.v1.Session() as sess:\n   converter = tf.compat.v1.lite.TFLiteConverter.from_session(sess, [params, indices], [out])\n   tflite_model = converter.convert()\n\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nparams_data = np.reshape(np.array([1], dtype=np.int64), newshape=(1,))\nindices_data = np.reshape(np.array(-10, dtype=np.int64), newshape=())\ninterpreter.set_tensor(input_details[0]['index'], params_data)\ninterpreter.set_tensor(input_details[1]['index'], indices_data)\n\ninterpreter.invoke()\n```\n\n### Patches\nWe have patched the issue in GitHub commits [bb6a0383ed553c286f87ca88c207f6774d5c4a8f](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f) and [eb921122119a6b6e470ee98b89e65d721663179d](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/eb921122119a6b6e470ee98b89e65d721663179d).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security  guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yakun Zhang of Baidu Security.",
      "published_date":"2021-08-25",
      "chain_len":2,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
      "commit_sha":"bb6a0383ed553c286f87ca88c207f6774d5c4a8f",
      "patch":"MULTI",
      "chain_ord":"['bb6a0383ed553c286f87ca88c207f6774d5c4a8f', 'eb921122119a6b6e470ee98b89e65d721663179d']",
      "before_first_fix_commit":"{'ac72971cc6fbbfe4df7e67a8347ef1b6ab63b5fd'}",
      "last_fix_commit":"eb921122119a6b6e470ee98b89e65d721663179d",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/27\/2021, 22:20:26",
      "message":"Prevent heap OOB read in TFLite's `gather_nd.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 11, 'deletions': 0, 'total': 11}",
      "files":"{'tensorflow\/lite\/kernels\/gather_nd.cc': {'additions': 11, 'deletions': 0, 'changes': 11, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/bb6a0383ed553c286f87ca88c207f6774d5c4a8f\/tensorflow%2Flite%2Fkernels%2Fgather_nd.cc', 'patch': '@@ -123,6 +123,17 @@ TfLiteStatus GatherNdString(const TfLiteTensor* params,\\n template <typename IndicesT>\\n TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\\n                           const TfLiteTensor* indices, TfLiteTensor* output) {\\n+  bool indices_has_only_positive_elements = true;\\n+  const auto* indices_values = GetTensorData<IndicesT>(indices);\\n+  const size_t num_indices = indices->bytes \/ sizeof(IndicesT);\\n+  for (size_t i = 0; i < num_indices; i++) {\\n+    if (indices_values[i] < 0) {\\n+      indices_has_only_positive_elements = false;\\n+      break;\\n+    }\\n+  }\\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\\n+\\n   switch (params->type) {\\n     case kTfLiteFloat32:\\n       return GatherNd<float, IndicesT>(params, indices, output);'}}",
      "message_norm":"prevent heap oob read in tflite's `gather_nd.cc`.\n\npassing negative indices is illegal but there was a missing check so that resulted in oob accesses.\n\npiperorigin-revid: 387208551\nchange-id: i6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('missing check', 'SECWORD', ''), ('oob', 'SECWORD', ''), ('387208551', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/gather_nd.cc'])",
      "num_files":1.0,
      "patch_content":"From bb6a0383ed553c286f87ca88c207f6774d5c4a8f Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 27 Jul 2021 15:20:26 -0700\nSubject: [PATCH] Prevent heap OOB read in TFLite's `gather_nd.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd\n---\n tensorflow\/lite\/kernels\/gather_nd.cc | 11 +++++++++++\n 1 file changed, 11 insertions(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/gather_nd.cc b\/tensorflow\/lite\/kernels\/gather_nd.cc\nindex 3ded771382569e..c39917b478505f 100644\n--- a\/tensorflow\/lite\/kernels\/gather_nd.cc\n+++ b\/tensorflow\/lite\/kernels\/gather_nd.cc\n@@ -123,6 +123,17 @@ TfLiteStatus GatherNdString(const TfLiteTensor* params,\n template <typename IndicesT>\n TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                           const TfLiteTensor* indices, TfLiteTensor* output) {\n+  bool indices_has_only_positive_elements = true;\n+  const auto* indices_values = GetTensorData<IndicesT>(indices);\n+  const size_t num_indices = indices->bytes \/ sizeof(IndicesT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indices_values[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   switch (params->type) {\n     case kTfLiteFloat32:\n       return GatherNd<float, IndicesT>(params, indices, output);",
      "code_diff":"@@ -123,6 +123,17 @@ TfLiteStatus GatherNdString(const TfLiteTensor* params,\n template <typename IndicesT>\n TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                           const TfLiteTensor* indices, TfLiteTensor* output) {\n+  bool indices_has_only_positive_elements = true;\n+  const auto* indices_values = GetTensorData<IndicesT>(indices);\n+  const size_t num_indices = indices->bytes \/ sizeof(IndicesT);\n+  for (size_t i = 0; i < num_indices; i++) {\n+    if (indices_values[i] < 0) {\n+      indices_has_only_positive_elements = false;\n+      break;\n+    }\n+  }\n+  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n+\n   switch (params->type) {\n     case kTfLiteFloat32:\n       return GatherNd<float, IndicesT>(params, indices, output);"
    },
    {
      "index":25,
      "vuln_id":"GHSA-cvpc-8phh-8f45",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":4.8,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/00302787b788c5ff04cb6f62aed5a74d936e86c0', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e11f55585f614645b360563072ffeb5c3eeff162', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/46d5b0852528ddfd614ded79bccc75589f801bd9', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1970c2158b1ffa416d159d03c3370b9a462aee35', 'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/fff2c8326280c07733828f990548979bdc893859'}",
      "dataset":"osv",
      "summary":"Out of bounds access in tensorflow-lite ### Impact\nIn TensorFlow Lite, saved models in the flatbuffer format use a double indexing scheme: a model has a set of subgraphs, each subgraph has a set of operators and each operator has a set of input\/output tensors. The flatbuffer format uses indices for the tensors, indexing into an array of tensors that is owned by the subgraph. This results in a pattern of double array indexing when trying to get the data of each tensor:https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/kernels\/kernel_util.cc#L36\n\nHowever, some operators can have some tensors be optional. To handle this scenario, the flatbuffer model uses a negative `-1` value as index for these tensors:\nhttps:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/c\/common.h#L82\n\nThis results in special casing during validation at model loading time: https:\/\/github.com\/tensorflow\/tensorflow\/blob\/0e68f4d3295eb0281a517c3662f6698992b7b2cf\/tensorflow\/lite\/core\/subgraph.cc#L566-L580\n\nUnfortunately, this means that the `-1` index is a valid tensor index for any operator, including those that don't expect optional inputs and including for output tensors. Thus, this allows writing and reading from outside the bounds of heap allocated arrays, although only at a specific offset from the start of these arrays.\n\nThis results in both read and write gadgets, albeit very limited in scope.\n\n### Patches\nWe have patched the issue in several commits (46d5b0852, 00302787b7, e11f5558, cd31fd0ce, 1970c21, and fff2c83). We will release patch releases for all versions between 1.15 and 2.3.\n\nWe recommend users to upgrade to TensorFlow 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\n\n### Workarounds\nA potential workaround would be to add a custom `Verifier` to the model loading code to ensure that only operators which accept optional inputs use the `-1` special value and only for the tensors that they expect to be optional. Since this allow-list type approach is erro-prone, we advise upgrading to the patched code.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2020-09-25",
      "chain_len":6,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/00302787b788c5ff04cb6f62aed5a74d936e86c0",
      "commit_sha":"00302787b788c5ff04cb6f62aed5a74d936e86c0",
      "patch":"MULTI",
      "chain_ord":"['46d5b0852528ddfd614ded79bccc75589f801bd9', '00302787b788c5ff04cb6f62aed5a74d936e86c0', 'e11f55585f614645b360563072ffeb5c3eeff162', 'cd31fd0ce0449a9e0f83dcad08d6ed7f1d6bef3f', 'fff2c8326280c07733828f990548979bdc893859', '1970c2158b1ffa416d159d03c3370b9a462aee35']",
      "before_first_fix_commit":"{'fff2c8326280c07733828f990548979bdc893859'}",
      "last_fix_commit":"1970c2158b1ffa416d159d03c3370b9a462aee35",
      "chain_ord_pos":2.0,
      "commit_datetime":"09\/18\/2020, 20:16:53",
      "message":"[tflite] Make `GetOptionalInputTensor` the same as `GetInput`.\n\nWith the previous change, there is no more need for two separate APIs. We would deprecate `GetOptionalInputTensor` in the future.\n\nPiperOrigin-RevId: 332513386\nChange-Id: Id7110271c25ebd6126ad8c82a493e37e0e0756b3",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 6, 'total': 7}",
      "files":"{'tensorflow\/lite\/kernels\/kernel_util.cc': {'additions': 1, 'deletions': 6, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/00302787b788c5ff04cb6f62aed5a74d936e86c0\/tensorflow%2Flite%2Fkernels%2Fkernel_util.cc', 'patch': '@@ -75,12 +75,7 @@ TfLiteTensor* GetOutput(TfLiteContext* context, const TfLiteNode* node,\\n \\n const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\\n                                            const TfLiteNode* node, int index) {\\n-  const bool use_tensor = index < node->inputs->size &&\\n-                          node->inputs->data[index] != kTfLiteOptionalTensor;\\n-  if (use_tensor) {\\n-    return GetMutableInput(context, node, index);\\n-  }\\n-  return nullptr;\\n+  return GetInput(context, node, index);\\n }\\n \\n \/\/ Per-axis'}}",
      "message_norm":"[tflite] make `getoptionalinputtensor` the same as `getinput`.\n\nwith the previous change, there is no more need for two separate apis. we would deprecate `getoptionalinputtensor` in the future.\n\npiperorigin-revid: 332513386\nchange-id: id7110271c25ebd6126ad8c82a493e37e0e0756b3",
      "language":"en",
      "entities":"[('332513386', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/kernel_util.cc'])",
      "num_files":1.0,
      "patch_content":"From 00302787b788c5ff04cb6f62aed5a74d936e86c0 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 18 Sep 2020 13:16:53 -0700\nSubject: [PATCH] [tflite] Make `GetOptionalInputTensor` the same as\n `GetInput`.\n\nWith the previous change, there is no more need for two separate APIs. We would deprecate `GetOptionalInputTensor` in the future.\n\nPiperOrigin-RevId: 332513386\nChange-Id: Id7110271c25ebd6126ad8c82a493e37e0e0756b3\n---\n tensorflow\/lite\/kernels\/kernel_util.cc | 7 +------\n 1 file changed, 1 insertion(+), 6 deletions(-)\n\ndiff --git a\/tensorflow\/lite\/kernels\/kernel_util.cc b\/tensorflow\/lite\/kernels\/kernel_util.cc\nindex fab884bc90c9a0..cd243335c9ca15 100644\n--- a\/tensorflow\/lite\/kernels\/kernel_util.cc\n+++ b\/tensorflow\/lite\/kernels\/kernel_util.cc\n@@ -75,12 +75,7 @@ TfLiteTensor* GetOutput(TfLiteContext* context, const TfLiteNode* node,\n \n const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                            const TfLiteNode* node, int index) {\n-  const bool use_tensor = index < node->inputs->size &&\n-                          node->inputs->data[index] != kTfLiteOptionalTensor;\n-  if (use_tensor) {\n-    return GetMutableInput(context, node, index);\n-  }\n-  return nullptr;\n+  return GetInput(context, node, index);\n }\n \n \/\/ Per-axis",
      "code_diff":"@@ -75,12 +75,7 @@ TfLiteTensor* GetOutput(TfLiteContext* context, const TfLiteNode* node,\n \n const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                            const TfLiteNode* node, int index) {\n-  const bool use_tensor = index < node->inputs->size &&\n-                          node->inputs->data[index] != kTfLiteOptionalTensor;\n-  if (use_tensor) {\n-    return GetMutableInput(context, node, index);\n-  }\n-  return nullptr;\n+  return GetInput(context, node, index);\n }\n \n \/\/ Per-axis"
    },
    {
      "index":26,
      "vuln_id":"GHSA-8gv3-57p6-g35r",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a84358aa12f0b1518e606095ab9cfddbf597c121'}",
      "dataset":"osv",
      "summary":"Heap buffer overflow in `RaggedTensorToTensor` ### Impact\nAn attacker can cause a heap buffer overflow in `tf.raw_ops.RaggedTensorToTensor`:\n\n```python\nimport tensorflow as tf\n\nshape = tf.constant([10, 10], shape=[2], dtype=tf.int64)\nvalues = tf.constant(0, shape=[1], dtype=tf.int64)\ndefault_value = tf.constant(0, dtype=tf.int64)\nl = [849, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nrow = tf.constant(l, shape=[5, 43], dtype=tf.int64)\nrows = [row]\ntypes = ['ROW_SPLITS']\n\ntf.raw_ops.RaggedTensorToTensor(\n    shape=shape, values=values, default_value=default_value,\n    row_partition_tensors=rows, row_partition_types=types) \n```\n\nThis is because the [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/d94227d43aa125ad8b54115c03cece54f6a1977b\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc#L219-L222) uses the same index to access two arrays in parallel:\n\n```cc\nfor (INDEX_TYPE i = 0; i < row_split_size - 1; ++i) {\n  INDEX_TYPE row_length = row_split(i + 1) - row_split(i);\n  INDEX_TYPE real_length = std::min(output_size, row_length);\n  INDEX_TYPE parent_output_index_current = parent_output_index[i];\n  ...\n}\n```\n\nSince the user controls the shape of the input arguments, an attacker could trigger a heap OOB access when `parent_output_index` is shorter than `row_split`.\n\n### Patches\nWe have patched the issue in GitHub commit [a84358aa12f0b1518e606095ab9cfddbf597c121](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a84358aa12f0b1518e606095ab9cfddbf597c121).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ying Wang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/a84358aa12f0b1518e606095ab9cfddbf597c121",
      "commit_sha":"a84358aa12f0b1518e606095ab9cfddbf597c121",
      "patch":"SINGLE",
      "chain_ord":"['a84358aa12f0b1518e606095ab9cfddbf597c121']",
      "before_first_fix_commit":"{'d94227d43aa125ad8b54115c03cece54f6a1977b'}",
      "last_fix_commit":"a84358aa12f0b1518e606095ab9cfddbf597c121",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/04\/2021, 20:45:57",
      "message":"Fix heap-buffer-overflow issue with `tf.raw_ops.RaggedTensorToTensor`.\n\nPiperOrigin-RevId: 371986929\nChange-Id: I79ab962a22c5867f36f7f45b780a1ac881b1dbdd",
      "author":"Amit Patankar",
      "comments":null,
      "stats":"{'additions': 6, 'deletions': 0, 'total': 6}",
      "files":"{'tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc': {'additions': 6, 'deletions': 0, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/a84358aa12f0b1518e606095ab9cfddbf597c121\/tensorflow%2Fcore%2Fkernels%2Fragged_tensor_to_tensor_op.cc', 'patch': '@@ -313,6 +313,12 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\\n             output_index_multiplier, output_size, result);\\n         return tensorflow::Status::OK();\\n       case RowPartitionType::ROW_SPLITS:\\n+        if (row_partition_tensor.size() - 1 > parent_output_index.size()) {\\n+          return errors::InvalidArgument(\\n+              \"Row partition size is greater than output size: \",\\n+              row_partition_tensor.size() - 1, \" > \",\\n+              parent_output_index.size());\\n+        }\\n         CalculateOutputIndexRowSplit(\\n             context, row_partition_tensor, parent_output_index,\\n             output_index_multiplier, output_size, result);'}}",
      "message_norm":"fix heap-buffer-overflow issue with `tf.raw_ops.raggedtensortotensor`.\n\npiperorigin-revid: 371986929\nchange-id: i79ab962a22c5867f36f7f45b780a1ac881b1dbdd",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('issue', 'FLAW', ''), ('371986929', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc'])",
      "num_files":1.0,
      "patch_content":"From a84358aa12f0b1518e606095ab9cfddbf597c121 Mon Sep 17 00:00:00 2001\nFrom: Amit Patankar <amitpatankar@google.com>\nDate: Tue, 4 May 2021 13:45:57 -0700\nSubject: [PATCH] Fix heap-buffer-overflow issue with\n `tf.raw_ops.RaggedTensorToTensor`.\n\nPiperOrigin-RevId: 371986929\nChange-Id: I79ab962a22c5867f36f7f45b780a1ac881b1dbdd\n---\n tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc | 6 ++++++\n 1 file changed, 6 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc b\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc\nindex 434c853b63daa4..376d55945d2ce8 100644\n--- a\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc\n+++ b\/tensorflow\/core\/kernels\/ragged_tensor_to_tensor_op.cc\n@@ -313,6 +313,12 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n             output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       case RowPartitionType::ROW_SPLITS:\n+        if (row_partition_tensor.size() - 1 > parent_output_index.size()) {\n+          return errors::InvalidArgument(\n+              \"Row partition size is greater than output size: \",\n+              row_partition_tensor.size() - 1, \" > \",\n+              parent_output_index.size());\n+        }\n         CalculateOutputIndexRowSplit(\n             context, row_partition_tensor, parent_output_index,\n             output_index_multiplier, output_size, result);",
      "code_diff":"@@ -313,6 +313,12 @@ class RaggedTensorToTensorBaseOp : public OpKernel {\n             output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       case RowPartitionType::ROW_SPLITS:\n+        if (row_partition_tensor.size() - 1 > parent_output_index.size()) {\n+          return errors::InvalidArgument(\n+              \"Row partition size is greater than output size: \",\n+              row_partition_tensor.size() - 1, \" > \",\n+              parent_output_index.size());\n+        }\n         CalculateOutputIndexRowSplit(\n             context, row_partition_tensor, parent_output_index,\n             output_index_multiplier, output_size, result);"
    },
    {
      "index":27,
      "vuln_id":"GHSA-2r8p-fg3c-wcj4",
      "cwe_id":"{'CWE-125'}",
      "score":7.3,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bc9c546ce7015c57c2f15c168b3d9201de679a1d'}",
      "dataset":"osv",
      "summary":"Heap OOB and CHECK fail in `ResourceGather` ### Impact\nAn attacker can trigger a crash via a `CHECK`-fail in debug builds of TensorFlow using `tf.raw_ops.ResourceGather` or a read from outside the bounds of heap allocated data in the same API in a release build:\n\n```python\nimport tensorflow as tf\n\ntensor = tf.constant(value=[[1,2],[3,4],[5,6]],shape=(3,2),dtype=tf.uint32)\nv = tf.Variable(tensor)\ntf.raw_ops.ResourceGather(\n  resource=v.handle,\n  indices=[0],\n  dtype=tf.uint32,\n  batch_dims=10,\n  validate_indices=False)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/resource_variable_ops.cc#L660-L668) does not check that the `batch_dims` value that the user supplies is less than the rank of the input tensor.\n\nSince the implementation uses several for loops over the dimensions of `tensor`, this results in reading data from outside the bounds of heap allocated buffer backing the tensor:\n\n```cc\n    \/\/ batch_dims_ = > params.dims() (10 > 2)\n    for (int i = 0; i < batch_dims_; ++i) {\n      result_shape.AddDim(params.dim_size(i));\n    }\n    for (int i = batch_dims_; i < indices.dims(); ++i) {\n      result_shape.AddDim(indices.dim_size(i));\n    }\n    for (int i = batch_dims_ + 1; i < params.dims(); ++i) {\n      result_shape.AddDim(params.dim_size(i));\n    }\n```\n\nIn debug mode, `.dim_size(i)` validates that the argument is less than `.dims()` using a `DCHECK`. But the `DCHECK` is a no-op in release builds.\n\n### Patches\nWe have patched the issue in GitHub commit [bc9c546ce7015c57c2f15c168b3d9201de679a1d](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bc9c546ce7015c57c2f15c168b3d9201de679a1d).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bc9c546ce7015c57c2f15c168b3d9201de679a1d",
      "commit_sha":"bc9c546ce7015c57c2f15c168b3d9201de679a1d",
      "patch":"SINGLE",
      "chain_ord":"['bc9c546ce7015c57c2f15c168b3d9201de679a1d']",
      "before_first_fix_commit":"{'d5f28c9b17220a9c7b3a4c93fc6c3fea6949cadd'}",
      "last_fix_commit":"bc9c546ce7015c57c2f15c168b3d9201de679a1d",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/31\/2021, 04:37:59",
      "message":"Prevent heap oob access in `resource_variable_ops.cc`\n\nPiperOrigin-RevId: 387936433\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 5, 'deletions': 0, 'total': 5}",
      "files":"{'tensorflow\/core\/kernels\/resource_variable_ops.cc': {'additions': 5, 'deletions': 0, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/bc9c546ce7015c57c2f15c168b3d9201de679a1d\/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.cc', 'patch': '@@ -660,6 +660,11 @@ class ResourceGatherOp : public OpKernel {\\n     OP_REQUIRES(\\n         c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\\n         errors::InvalidArgument(\"params must be at least 1 dimensional\"));\\n+    OP_REQUIRES(\\n+        c, params.shape().dims() >= batch_dims_,\\n+        errors::InvalidArgument(\"params must have at least \", batch_dims_,\\n+                                \" (batch_dims) dimensions but it has shape \",\\n+                                params.shape().DebugString()));\\n \\n     \/\/ Check that we have enough index space\\n     const int64_t N = indices.NumElements();'}}",
      "message_norm":"prevent heap oob access in `resource_variable_ops.cc`\n\npiperorigin-revid: 387936433\nchange-id: i9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('heap oob', 'SECWORD', ''), ('387936433', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/resource_variable_ops.cc'])",
      "num_files":1.0,
      "patch_content":"From bc9c546ce7015c57c2f15c168b3d9201de679a1d Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 30 Jul 2021 21:37:59 -0700\nSubject: [PATCH] Prevent heap oob access in `resource_variable_ops.cc`\n\nPiperOrigin-RevId: 387936433\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6\n---\n tensorflow\/core\/kernels\/resource_variable_ops.cc | 5 +++++\n 1 file changed, 5 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/resource_variable_ops.cc b\/tensorflow\/core\/kernels\/resource_variable_ops.cc\nindex 71aead55690d65..32a0a43364deae 100644\n--- a\/tensorflow\/core\/kernels\/resource_variable_ops.cc\n+++ b\/tensorflow\/core\/kernels\/resource_variable_ops.cc\n@@ -660,6 +660,11 @@ class ResourceGatherOp : public OpKernel {\n     OP_REQUIRES(\n         c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\n         errors::InvalidArgument(\"params must be at least 1 dimensional\"));\n+    OP_REQUIRES(\n+        c, params.shape().dims() >= batch_dims_,\n+        errors::InvalidArgument(\"params must have at least \", batch_dims_,\n+                                \" (batch_dims) dimensions but it has shape \",\n+                                params.shape().DebugString()));\n \n     \/\/ Check that we have enough index space\n     const int64_t N = indices.NumElements();",
      "code_diff":"@@ -660,6 +660,11 @@ class ResourceGatherOp : public OpKernel {\n     OP_REQUIRES(\n         c, TensorShapeUtils::IsVectorOrHigher(params.shape()),\n         errors::InvalidArgument(\"params must be at least 1 dimensional\"));\n+    OP_REQUIRES(\n+        c, params.shape().dims() >= batch_dims_,\n+        errors::InvalidArgument(\"params must have at least \", batch_dims_,\n+                                \" (batch_dims) dimensions but it has shape \",\n+                                params.shape().DebugString()));\n \n     \/\/ Check that we have enough index space\n     const int64_t N = indices.NumElements();"
    },
    {
      "index":28,
      "vuln_id":"GHSA-h4pc-gx2w-f2xv",
      "cwe_id":"{'CWE-125'}",
      "score":7.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412'}",
      "dataset":"osv",
      "summary":"Heap OOB read in TFLite ### Impact\nA specially crafted TFLite model could trigger an OOB read on heap in the TFLite implementation of [`Split_V`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/c59c37e7b2d563967da813fa50fe20b21f4da683\/tensorflow\/lite\/kernels\/split_v.cc#L99):\n\n```cc\nconst int input_size = SizeOfDimension(input, axis_value);\n``` \n\nIf `axis_value` is not a value between 0 and `NumDimensions(input)`, then the [`SizeOfDimension` function](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/102b211d892f3abc14f845a72047809b39cc65ab\/tensorflow\/lite\/kernels\/kernel_util.h#L148-L150) will access data outside the bounds of the tensor shape array:\n\n```cc\ninline int SizeOfDimension(const TfLiteTensor* t, int dim) {\n  return t->dims->data[dim];\n}\n```\n  \n### Patches \nWe have patched the issue in GitHub commit [ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412",
      "commit_sha":"ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412",
      "patch":"SINGLE",
      "chain_ord":"['ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412']",
      "before_first_fix_commit":"{'c59c37e7b2d563967da813fa50fe20b21f4da683'}",
      "last_fix_commit":"ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/29\/2021, 01:12:15",
      "message":"Prevent array OOB read\/write\n\nPiperOrigin-RevId: 371026165\nChange-Id: I26ac6372c87246e03c7eb8c94e84c84d86054b36",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
      "files":"{'tensorflow\/lite\/kernels\/split_v.cc': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412\/tensorflow%2Flite%2Fkernels%2Fsplit_v.cc', 'patch': '@@ -96,6 +96,8 @@ TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\\n     }\\n   }\\n \\n+  TF_LITE_ENSURE(context, axis_value >= 0);\\n+  TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\\n   const int input_size = SizeOfDimension(input, axis_value);\\n \\n   if (minus_one_index != -1) {'}}",
      "message_norm":"prevent array oob read\/write\n\npiperorigin-revid: 371026165\nchange-id: i26ac6372c87246e03c7eb8c94e84c84d86054b36",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('oob', 'SECWORD', ''), ('371026165', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/lite\/kernels\/split_v.cc'])",
      "num_files":1.0,
      "patch_content":"From ae2daeb45abfe2c6dda539cf8d0d6f653d3ef412 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 28 Apr 2021 18:12:15 -0700\nSubject: [PATCH] Prevent array OOB read\/write\n\nPiperOrigin-RevId: 371026165\nChange-Id: I26ac6372c87246e03c7eb8c94e84c84d86054b36\n---\n tensorflow\/lite\/kernels\/split_v.cc | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/tensorflow\/lite\/kernels\/split_v.cc b\/tensorflow\/lite\/kernels\/split_v.cc\nindex 054e00572f5a60..ed8a4851c1e97e 100644\n--- a\/tensorflow\/lite\/kernels\/split_v.cc\n+++ b\/tensorflow\/lite\/kernels\/split_v.cc\n@@ -96,6 +96,8 @@ TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n     }\n   }\n \n+  TF_LITE_ENSURE(context, axis_value >= 0);\n+  TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\n   const int input_size = SizeOfDimension(input, axis_value);\n \n   if (minus_one_index != -1) {",
      "code_diff":"@@ -96,6 +96,8 @@ TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n     }\n   }\n \n+  TF_LITE_ENSURE(context, axis_value >= 0);\n+  TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\n   const int input_size = SizeOfDimension(input, axis_value);\n \n   if (minus_one_index != -1) {"
    },
    {
      "index":29,
      "vuln_id":"GHSA-vqw6-72r7-fgw7",
      "cwe_id":"{'CWE-125'}",
      "score":2.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/480641e3599775a8895254ffbc0fc45621334f68'}",
      "dataset":"osv",
      "summary":"OOB read in `MatrixTriangularSolve` ### Impact\nThe implementation of [`MatrixTriangularSolve`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/8cae746d8449c7dda5298327353d68613f16e798\/tensorflow\/core\/kernels\/linalg\/matrix_triangular_solve_op_impl.h#L160-L240) fails to terminate kernel execution if one validation condition fails:\n\n```cc\nvoid ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0,\n                            const Tensor& in1) override {\n  OP_REQUIRES(\n      ctx, in0.dims() >= 2,\n      errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n\n  OP_REQUIRES(\n      ctx, in1.dims() >= 2,\n      errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in1.dims()));\n}\n  \nvoid Compute(OpKernelContext* ctx) override {\n  const Tensor& in0 = ctx->input(0);\n  const Tensor& in1 = ctx->input(1);\n\n  ValidateInputTensors(ctx, in0, in1);\n\n  MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\n  ...\n}\n```\n  \nSince `OP_REQUIRES` only sets `ctx->status()` to a non-OK value and calls `return`, this allows malicious attackers to trigger an out of bounds read:\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nmatrix_array = np.array([])\nmatrix_tensor = tf.convert_to_tensor(np.reshape(matrix_array,(1,0)),dtype=tf.float32)\nrhs_array = np.array([])\nrhs_tensor = tf.convert_to_tensor(np.reshape(rhs_array,(0,1)),dtype=tf.float32)\n\ntf.raw_ops.MatrixTriangularSolve(matrix=matrix_tensor,rhs=rhs_tensor,lower=False,adjoint=False)\n```\n\nAs the two input tensors are empty, the `OP_REQUIRES` in `ValidateInputTensors` should fire and interrupt execution. However, given the implementation of `OP_REQUIRES`, after the `in0.dims() >= 2` fails, execution moves to the initialization of the `bcast` object. This initialization is done with invalid data and results in heap OOB read.\n\n### Patches\nWe have patched the issue in GitHub commit [480641e3599775a8895254ffbc0fc45621334f68](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/480641e3599775a8895254ffbc0fc45621334f68).\n\nThe fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Ye Zhang and Yakun Zhang of Baidu X-Team.",
      "published_date":"2021-05-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/480641e3599775a8895254ffbc0fc45621334f68",
      "commit_sha":"480641e3599775a8895254ffbc0fc45621334f68",
      "patch":"SINGLE",
      "chain_ord":"['480641e3599775a8895254ffbc0fc45621334f68']",
      "before_first_fix_commit":"{'8cae746d8449c7dda5298327353d68613f16e798'}",
      "last_fix_commit":"480641e3599775a8895254ffbc0fc45621334f68",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/24\/2021, 23:47:25",
      "message":"Validate (and ensure validation sticks) inputs for `MatrixTriangularSolve`.\n\nPiperOrigin-RevId: 370282444\nChange-Id: Iaed61a0b0727cc42c830658b72eb69f785f48dc5",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 16, 'deletions': 4, 'total': 20}",
      "files":"{'tensorflow\/core\/kernels\/linalg\/matrix_triangular_solve_op_impl.h': {'additions': 16, 'deletions': 4, 'changes': 20, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/480641e3599775a8895254ffbc0fc45621334f68\/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_triangular_solve_op_impl.h', 'patch': '@@ -162,6 +162,9 @@ class BaseMatrixTriangularSolveOp : public OpKernel {\\n     const Tensor& in1 = ctx->input(1);\\n \\n     ValidateInputTensors(ctx, in0, in1);\\n+    if (!ctx->status().ok()) {\\n+      return;\\n+    }\\n \\n     MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\\n     OP_REQUIRES(\\n@@ -230,13 +233,22 @@ class MatrixTriangularSolveOp\\n  private:\\n   void ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0,\\n                             const Tensor& in1) override {\\n+    const auto in0_num_dims = in0.dims();\\n     OP_REQUIRES(\\n-        ctx, in0.dims() >= 2,\\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\\n+        ctx, in0_num_dims >= 2,\\n+        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0_num_dims));\\n \\n+    const auto in1_num_dims = in1.dims();\\n     OP_REQUIRES(\\n-        ctx, in1.dims() >= 2,\\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in1.dims()));\\n+        ctx, in1_num_dims >= 2,\\n+        errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1_num_dims));\\n+\\n+    const auto in0_last_dim = in0.dim_size(in0_num_dims - 1);\\n+    const auto in0_prev_dim = in0.dim_size(in0_num_dims - 2);\\n+    OP_REQUIRES(ctx, in0_last_dim == in0_prev_dim,\\n+                errors::InvalidArgument(\\n+                    \"In[0] matrices in the last dimensions must be square (\",\\n+                    in0_last_dim, \" =\/= \", in0_prev_dim, \")\"));\\n   }\\n };'}}",
      "message_norm":"validate (and ensure validation sticks) inputs for `matrixtriangularsolve`.\n\npiperorigin-revid: 370282444\nchange-id: iaed61a0b0727cc42c830658b72eb69f785f48dc5",
      "language":"en",
      "entities":"[('validate', 'ACTION', ''), ('ensure', 'ACTION', ''), ('370282444', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/linalg\/matrix_triangular_solve_op_impl.h'])",
      "num_files":1.0,
      "patch_content":"From 480641e3599775a8895254ffbc0fc45621334f68 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Sat, 24 Apr 2021 16:47:25 -0700\nSubject: [PATCH] Validate (and ensure validation sticks) inputs for\n `MatrixTriangularSolve`.\n\nPiperOrigin-RevId: 370282444\nChange-Id: Iaed61a0b0727cc42c830658b72eb69f785f48dc5\n---\n ...\/linalg\/matrix_triangular_solve_op_impl.h  | 20 +++++++++++++++----\n 1 file changed, 16 insertions(+), 4 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/linalg\/matrix_triangular_solve_op_impl.h b\/tensorflow\/core\/kernels\/linalg\/matrix_triangular_solve_op_impl.h\nindex 99249f792b6ed8..ce5392e62b9fa6 100644\n--- a\/tensorflow\/core\/kernels\/linalg\/matrix_triangular_solve_op_impl.h\n+++ b\/tensorflow\/core\/kernels\/linalg\/matrix_triangular_solve_op_impl.h\n@@ -162,6 +162,9 @@ class BaseMatrixTriangularSolveOp : public OpKernel {\n     const Tensor& in1 = ctx->input(1);\n \n     ValidateInputTensors(ctx, in0, in1);\n+    if (!ctx->status().ok()) {\n+      return;\n+    }\n \n     MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\n     OP_REQUIRES(\n@@ -230,13 +233,22 @@ class MatrixTriangularSolveOp\n  private:\n   void ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0,\n                             const Tensor& in1) override {\n+    const auto in0_num_dims = in0.dims();\n     OP_REQUIRES(\n-        ctx, in0.dims() >= 2,\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n+        ctx, in0_num_dims >= 2,\n+        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0_num_dims));\n \n+    const auto in1_num_dims = in1.dims();\n     OP_REQUIRES(\n-        ctx, in1.dims() >= 2,\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in1.dims()));\n+        ctx, in1_num_dims >= 2,\n+        errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1_num_dims));\n+\n+    const auto in0_last_dim = in0.dim_size(in0_num_dims - 1);\n+    const auto in0_prev_dim = in0.dim_size(in0_num_dims - 2);\n+    OP_REQUIRES(ctx, in0_last_dim == in0_prev_dim,\n+                errors::InvalidArgument(\n+                    \"In[0] matrices in the last dimensions must be square (\",\n+                    in0_last_dim, \" =\/= \", in0_prev_dim, \")\"));\n   }\n };",
      "code_diff":"@@ -162,6 +162,9 @@ class BaseMatrixTriangularSolveOp : public OpKernel {\n     const Tensor& in1 = ctx->input(1);\n \n     ValidateInputTensors(ctx, in0, in1);\n+    if (!ctx->status().ok()) {\n+      return;\n+    }\n \n     MatMulBCast bcast(in0.shape().dim_sizes(), in1.shape().dim_sizes());\n     OP_REQUIRES(\n@@ -230,13 +233,22 @@ class MatrixTriangularSolveOp\n  private:\n   void ValidateInputTensors(OpKernelContext* ctx, const Tensor& in0,\n                             const Tensor& in1) override {\n+    const auto in0_num_dims = in0.dims();\n     OP_REQUIRES(\n-        ctx, in0.dims() >= 2,\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0.dims()));\n+        ctx, in0_num_dims >= 2,\n+        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in0_num_dims));\n \n+    const auto in1_num_dims = in1.dims();\n     OP_REQUIRES(\n-        ctx, in1.dims() >= 2,\n-        errors::InvalidArgument(\"In[0] ndims must be >= 2: \", in1.dims()));\n+        ctx, in1_num_dims >= 2,\n+        errors::InvalidArgument(\"In[1] ndims must be >= 2: \", in1_num_dims));\n+\n+    const auto in0_last_dim = in0.dim_size(in0_num_dims - 1);\n+    const auto in0_prev_dim = in0.dim_size(in0_num_dims - 2);\n+    OP_REQUIRES(ctx, in0_last_dim == in0_prev_dim,\n+                errors::InvalidArgument(\n+                    \"In[0] matrices in the last dimensions must be square (\",\n+                    in0_last_dim, \" =\/= \", in0_prev_dim, \")\"));\n   }\n };"
    },
    {
      "index":30,
      "vuln_id":"GHSA-8g7p-74h8-hg48",
      "cwe_id":"{'CWE-400', 'CWE-125'}",
      "score":9.1,
      "chain":"{'https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/commit\/1c24219df87524e6ed973127e81f30801d658f07'}",
      "dataset":"osv",
      "summary":"Denial of Service in https-proxy-agent Versions of `https-proxy-agent` before 2.2.0 are vulnerable to denial of service. This is due to unsanitized options (proxy.auth) being passed to `Buffer()`.\n\n\n## Recommendation\n\nUpdate to version 2.2.0 or later.",
      "published_date":"2018-07-27",
      "chain_len":1,
      "project":"https:\/\/github.com\/TooTallNate\/node-https-proxy-agent",
      "commit_href":"https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/commit\/1c24219df87524e6ed973127e81f30801d658f07",
      "commit_sha":"1c24219df87524e6ed973127e81f30801d658f07",
      "patch":"SINGLE",
      "chain_ord":"['1c24219df87524e6ed973127e81f30801d658f07']",
      "before_first_fix_commit":"{'c58d365dd153104d1147967a0a6b4e1dd1698e50'}",
      "last_fix_commit":"1c24219df87524e6ed973127e81f30801d658f07",
      "chain_ord_pos":1.0,
      "commit_datetime":"03\/03\/2018, 19:31:04",
      "message":"Use `Buffer.from()`\n\n`new Buffer()` is deprecated and unsafe.",
      "author":"Nathan Rajlich",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/raw\/1c24219df87524e6ed973127e81f30801d658f07\/index.js', 'patch': \"@@ -204,7 +204,7 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\\n   var headers = Object.assign({}, proxy.headers);\\n   if (proxy.auth) {\\n     headers['Proxy-Authorization'] =\\n-      'Basic ' + new Buffer(proxy.auth).toString('base64');\\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64');\\n   }\\n \\n   \/\/ the Host header should only include the port\"}}",
      "message_norm":"use `buffer.from()`\n\n`new buffer()` is deprecated and unsafe.",
      "language":"en",
      "entities":"[('unsafe', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['index.js'])",
      "num_files":1.0,
      "patch_content":"From 1c24219df87524e6ed973127e81f30801d658f07 Mon Sep 17 00:00:00 2001\nFrom: Nathan Rajlich <nathan@tootallnate.net>\nDate: Sat, 3 Mar 2018 11:31:04 -0800\nSubject: [PATCH] Use `Buffer.from()`\n\n`new Buffer()` is deprecated and unsafe.\n---\n index.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/index.js b\/index.js\nindex 69985780..4e007128 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -204,7 +204,7 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\n   var headers = Object.assign({}, proxy.headers);\n   if (proxy.auth) {\n     headers['Proxy-Authorization'] =\n-      'Basic ' + new Buffer(proxy.auth).toString('base64');\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64');\n   }\n \n   \/\/ the Host header should only include the port",
      "code_diff":"@@ -204,7 +204,7 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\n   var headers = Object.assign({}, proxy.headers);\n   if (proxy.auth) {\n     headers['Proxy-Authorization'] =\n-      'Basic ' + new Buffer(proxy.auth).toString('base64');\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64');\n   }\n \n   \/\/ the Host header should only include the port"
    },
    {
      "index":31,
      "vuln_id":"GHSA-hpv4-7p9c-mvfr",
      "cwe_id":"{'CWE-787', 'CWE-125'}",
      "score":7.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0f931751fb20f565c4e94aa6df58d54a003cdb30'}",
      "dataset":"osv",
      "summary":"Heap buffer overflow in `FractionalAvgPoolGrad` ### Impact\nThe implementation for `tf.raw_ops.FractionalAvgPoolGrad` can be tricked into accessing data outside of bounds of heap allocated buffers:\n\n```python\nimport tensorflow as tf\n\ntf.raw_ops.FractionalAvgPoolGrad(\n  orig_input_tensor_shape=[0,1,2,3],\n  out_backprop = np.array([[[[541],[541]],[[541],[541]]]]),\n  row_pooling_sequence=[0, 0, 0, 0, 0],\n  col_pooling_sequence=[-2, 0, 0, 2, 0],\n  overlapping=True)\n```\n\nThe [implementation](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f24faa153ad31a4b51578f8181d3aaab77a1ddeb\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc#L205) does not validate that the input tensor is non-empty. Thus, code constructs an empty `EigenDoubleMatrixMap` and then accesses this buffer with indices that are outside of the empty area.\n\n### Patches\nWe have patched the issue in GitHub commit [0f931751fb20f565c4e94aa6df58d54a003cdb30](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0f931751fb20f565c4e94aa6df58d54a003cdb30).\n\nThe fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by members of the Aivul Team from Qihoo 360.",
      "published_date":"2021-08-25",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/0f931751fb20f565c4e94aa6df58d54a003cdb30",
      "commit_sha":"0f931751fb20f565c4e94aa6df58d54a003cdb30",
      "patch":"SINGLE",
      "chain_ord":"['0f931751fb20f565c4e94aa6df58d54a003cdb30']",
      "before_first_fix_commit":"{'55e763ffe2b348a61ab1c2fcfedc7bdf05c91990'}",
      "last_fix_commit":"0f931751fb20f565c4e94aa6df58d54a003cdb30",
      "chain_ord_pos":1.0,
      "commit_datetime":"08\/02\/2021, 20:03:44",
      "message":"Validate dimensions of input tensor in `FractionalAvgPoolGrad`\n\nPiperOrigin-RevId: 388286227\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 12, 'deletions': 0, 'total': 12}",
      "files":"{'tensorflow\/core\/kernels\/fractional_avg_pool_op.cc': {'additions': 12, 'deletions': 0, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/0f931751fb20f565c4e94aa6df58d54a003cdb30\/tensorflow%2Fcore%2Fkernels%2Ffractional_avg_pool_op.cc', 'patch': '@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\\n+    OP_REQUIRES(\\n+        context, in_batch != 0,\\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\\n+    OP_REQUIRES(\\n+        context, in_rows != 0,\\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\\n+    OP_REQUIRES(\\n+        context, in_cols != 0,\\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\\n+    OP_REQUIRES(\\n+        context, in_depth != 0,\\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\\n \\n     constexpr int tensor_in_and_out_dims = 4;\\n     \/\/ Transform orig_input_tensor_shape into TensorShape'}}",
      "message_norm":"validate dimensions of input tensor in `fractionalavgpoolgrad`\n\npiperorigin-revid: 388286227\nchange-id: ieb7566155e92acc8993a2212c76deacadc0edc8a",
      "language":"en",
      "entities":"[('validate', 'ACTION', ''), ('388286227', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/fractional_avg_pool_op.cc'])",
      "num_files":1.0,
      "patch_content":"From 0f931751fb20f565c4e94aa6df58d54a003cdb30 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Mon, 2 Aug 2021 13:03:44 -0700\nSubject: [PATCH] Validate dimensions of input tensor in\n `FractionalAvgPoolGrad`\n\nPiperOrigin-RevId: 388286227\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a\n---\n tensorflow\/core\/kernels\/fractional_avg_pool_op.cc | 12 ++++++++++++\n 1 file changed, 12 insertions(+)\n\ndiff --git a\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc b\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc\nindex 3c80e87bcf76dc..63f8d67d93cc47 100644\n--- a\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc\n+++ b\/tensorflow\/core\/kernels\/fractional_avg_pool_op.cc\n@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     \/\/ Transform orig_input_tensor_shape into TensorShape",
      "code_diff":"@@ -271,6 +271,18 @@ class FractionalAvgPoolGradOp : public OpKernel {\n     const int64_t in_rows = orig_input_tensor_shape_flat(1);\n     const int64_t in_cols = orig_input_tensor_shape_flat(2);\n     const int64_t in_depth = orig_input_tensor_shape_flat(3);\n+    OP_REQUIRES(\n+        context, in_batch != 0,\n+        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_rows != 0,\n+        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_cols != 0,\n+        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n+    OP_REQUIRES(\n+        context, in_depth != 0,\n+        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n \n     constexpr int tensor_in_and_out_dims = 4;\n     \/\/ Transform orig_input_tensor_shape into TensorShape"
    },
    {
      "index":32,
      "vuln_id":"GHSA-qpw2-xchm-655q",
      "cwe_id":"{'CWE-125'}",
      "score":6.5,
      "chain":"{'https:\/\/github.com\/mhart\/StringStream\/commit\/2f4a9d496f94b0880e01a26857aa266a5a3ef274'}",
      "dataset":"osv",
      "summary":"Out-of-Bounds read in stringstream Versions less than 0.0.6 of the Node.js stringstream module are vulnerable to an out-of-bounds read because of allocation of uninitialized buffers when a number is passed in the input stream (when using Node.js 4.x).\n\n# WITHDRAWN\n\nThis is a duplicate of GHSA-mf6x-7mm4-x2g7",
      "published_date":"2022-01-06",
      "chain_len":1,
      "project":"https:\/\/github.com\/mhart\/StringStream",
      "commit_href":"https:\/\/github.com\/mhart\/StringStream\/commit\/2f4a9d496f94b0880e01a26857aa266a5a3ef274",
      "commit_sha":"2f4a9d496f94b0880e01a26857aa266a5a3ef274",
      "patch":"SINGLE",
      "chain_ord":"['2f4a9d496f94b0880e01a26857aa266a5a3ef274']",
      "before_first_fix_commit":"{'1efe3bf507bf3a1161f8473908b60e881d41422b', 'afbc7442220358419e330618e47f3a65fc265b1b'}",
      "last_fix_commit":"2f4a9d496f94b0880e01a26857aa266a5a3ef274",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/17\/2018, 10:22:09",
      "message":"Merge pull request #9 from mhart\/fix-buffer-constructor-vuln\n\nEnsure data is not a number in Buffer constructor",
      "author":"Michael Hart",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'stringstream.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mhart\/StringStream\/raw\/2f4a9d496f94b0880e01a26857aa266a5a3ef274\/stringstream.js', 'patch': \"@@ -28,7 +28,7 @@ StringStream.prototype.write = function(data) {\\n     return false\\n   }\\n   if (this.fromEncoding) {\\n-    if (Buffer.isBuffer(data)) data = data.toString()\\n+    if (Buffer.isBuffer(data) || typeof data === 'number') data = data.toString()\\n     data = new Buffer(data, this.fromEncoding)\\n   }\\n   var string = this.decoder.write(data)\"}}",
      "message_norm":"merge pull request #9 from mhart\/fix-buffer-constructor-vuln\n\nensure data is not a number in buffer constructor",
      "language":"en",
      "entities":"[('#9', 'ISSUE', ''), ('ensure', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['stringstream.js'])",
      "num_files":1.0,
      "patch_content":"From afbc7442220358419e330618e47f3a65fc265b1b Mon Sep 17 00:00:00 2001\nFrom: Michael Hart <michael.hart.au@gmail.com>\nDate: Thu, 17 May 2018 19:07:21 +1000\nSubject: [PATCH] Ensure data is not a number in Buffer constructor\n\nFixes #7\n---\n stringstream.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/stringstream.js b\/stringstream.js\nindex 4ece127..6732b9d 100644\n--- a\/stringstream.js\n+++ b\/stringstream.js\n@@ -28,7 +28,7 @@ StringStream.prototype.write = function(data) {\n     return false\n   }\n   if (this.fromEncoding) {\n-    if (Buffer.isBuffer(data)) data = data.toString()\n+    if (Buffer.isBuffer(data) || typeof data === 'number') data = data.toString()\n     data = new Buffer(data, this.fromEncoding)\n   }\n   var string = this.decoder.write(data)",
      "code_diff":"@@ -28,7 +28,7 @@ StringStream.prototype.write = function(data) {\n     return false\n   }\n   if (this.fromEncoding) {\n-    if (Buffer.isBuffer(data)) data = data.toString()\n+    if (Buffer.isBuffer(data) || typeof data === 'number') data = data.toString()\n     data = new Buffer(data, this.fromEncoding)\n   }\n   var string = this.decoder.write(data)"
    },
    {
      "index":33,
      "vuln_id":"GHSA-6gmv-pjp9-p8w8",
      "cwe_id":"{'CWE-125'}",
      "score":8.1,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/37c01fb5e25c3d80213060460196406c43d31995'}",
      "dataset":"osv",
      "summary":"Out of bounds read in Tensorflow ### Impact \nThe [implementation of shape inference for `ReverseSequence`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/ops\/array_ops.cc#L1636-L1671) does not fully validate the value of `batch_dim` and can result in a heap OOB read:\n\n```python\nimport tensorflow as tf\n\n@tf.function\ndef test():\n  y = tf.raw_ops.ReverseSequence(\n    input = ['aaa','bbb'],\n    seq_lengths = [1,1,1],\n    seq_dim = -10,\n    batch_dim = -10 )\n  return y\n    \ntest()\n```\n\nThere is a check to make sure the value of `batch_dim` does not go over the rank of the input, but there is no check for negative values:\n\n```cc\n  const int32_t input_rank = c->Rank(input);\n  if (batch_dim >= input_rank) {\n    return errors::InvalidArgument( \n        \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\n  }\n  \/\/ ...\n  \n  DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\n``` \n    \nNegative dimensions are allowed in some cases to mimic Python's negative indexing (i.e., indexing from the end of the array), however if the value is too negative then [the implementation of `Dim`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/framework\/shape_inference.h#L415-L428) would access elements before the start of an array:\n\n```cc\n  DimensionHandle Dim(ShapeHandle s, int64_t idx) {\n    if (!s.Handle() || s->rank_ == kUnknownRank) {\n      return UnknownDim();\n    }\n    return DimKnownRank(s, idx);\n  } \n\u00b7\n  static DimensionHandle DimKnownRank(ShapeHandle s, int64_t idx) {\n    CHECK_NE(s->rank_, kUnknownRank);\n    if (idx < 0) {\n      return s->dims_[s->dims_.size() + idx];\n    }\n    return s->dims_[idx];\n  }\n```\n\n### Patches\nWe have patched the issue in GitHub commit [37c01fb5e25c3d80213060460196406c43d31995](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/37c01fb5e25c3d80213060460196406c43d31995).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yu Tian of Qihoo 360 AIVul Team.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/37c01fb5e25c3d80213060460196406c43d31995",
      "commit_sha":"37c01fb5e25c3d80213060460196406c43d31995",
      "patch":"SINGLE",
      "chain_ord":"['37c01fb5e25c3d80213060460196406c43d31995']",
      "before_first_fix_commit":"{'3218043d6d3a019756607643cf65574fbfef5d7a'}",
      "last_fix_commit":"37c01fb5e25c3d80213060460196406c43d31995",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/23\/2021, 22:27:30",
      "message":"Fix out of bound error in ReverseSequence Op shape function\n\nPiperOrigin-RevId: 411896080\nChange-Id: I7e59a38e2f960886edf2b6c54ed5a84e86a9b193",
      "author":"Isha Arkatkar",
      "comments":null,
      "stats":"{'additions': 10, 'deletions': 0, 'total': 10}",
      "files":"{'tensorflow\/core\/ops\/array_ops.cc': {'additions': 10, 'deletions': 0, 'changes': 10, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/37c01fb5e25c3d80213060460196406c43d31995\/tensorflow%2Fcore%2Fops%2Farray_ops.cc', 'patch': '@@ -1653,11 +1653,21 @@ REGISTER_OP(\"ReverseSequence\")\\n         return errors::InvalidArgument(\\n             \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\\n       }\\n+\\n       if (seq_dim >= input_rank) {\\n         return errors::InvalidArgument(\\n             \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);\\n       }\\n \\n+      \/\/ To prevent out of bound access when calling c->Dim(input, batch_dim),\\n+      \/\/ batch_dim range [-1 * input rank, input rank) is allowed. However,\\n+      \/\/ the op implementation has a stricter bound for batch_dim requiring >= 0\\n+      \/\/ value. Thus, perform strict check here.\\n+      if (batch_dim < 0) {\\n+        return errors::InvalidArgument(\"batch_dim must be >=0, got \",\\n+                                       batch_dim);\\n+      }\\n+\\n       DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\\n       TF_RETURN_IF_ERROR(\\n           c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));'}}",
      "message_norm":"fix out of bound error in reversesequence op shape function\n\npiperorigin-revid: 411896080\nchange-id: i7e59a38e2f960886edf2b6c54ed5a84e86a9b193",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('out of bound', 'SECWORD', ''), ('error', 'FLAW', ''), ('411896080', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/ops\/array_ops.cc'])",
      "num_files":1.0,
      "patch_content":"From 37c01fb5e25c3d80213060460196406c43d31995 Mon Sep 17 00:00:00 2001\nFrom: Isha Arkatkar <ishark@google.com>\nDate: Tue, 23 Nov 2021 14:27:30 -0800\nSubject: [PATCH] Fix out of bound error in ReverseSequence Op shape function\n\nPiperOrigin-RevId: 411896080\nChange-Id: I7e59a38e2f960886edf2b6c54ed5a84e86a9b193\n---\n tensorflow\/core\/ops\/array_ops.cc | 10 ++++++++++\n 1 file changed, 10 insertions(+)\n\ndiff --git a\/tensorflow\/core\/ops\/array_ops.cc b\/tensorflow\/core\/ops\/array_ops.cc\nindex bcdc6643c89adb..1a88b16b865dd4 100644\n--- a\/tensorflow\/core\/ops\/array_ops.cc\n+++ b\/tensorflow\/core\/ops\/array_ops.cc\n@@ -1653,11 +1653,21 @@ REGISTER_OP(\"ReverseSequence\")\n         return errors::InvalidArgument(\n             \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\n       }\n+\n       if (seq_dim >= input_rank) {\n         return errors::InvalidArgument(\n             \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);\n       }\n \n+      \/\/ To prevent out of bound access when calling c->Dim(input, batch_dim),\n+      \/\/ batch_dim range [-1 * input rank, input rank) is allowed. However,\n+      \/\/ the op implementation has a stricter bound for batch_dim requiring >= 0\n+      \/\/ value. Thus, perform strict check here.\n+      if (batch_dim < 0) {\n+        return errors::InvalidArgument(\"batch_dim must be >=0, got \",\n+                                       batch_dim);\n+      }\n+\n       DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\n       TF_RETURN_IF_ERROR(\n           c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));",
      "code_diff":"@@ -1653,11 +1653,21 @@ REGISTER_OP(\"ReverseSequence\")\n         return errors::InvalidArgument(\n             \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\n       }\n+\n       if (seq_dim >= input_rank) {\n         return errors::InvalidArgument(\n             \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);\n       }\n \n+      \/\/ To prevent out of bound access when calling c->Dim(input, batch_dim),\n+      \/\/ batch_dim range [-1 * input rank, input rank) is allowed. However,\n+      \/\/ the op implementation has a stricter bound for batch_dim requiring >= 0\n+      \/\/ value. Thus, perform strict check here.\n+      if (batch_dim < 0) {\n+        return errors::InvalidArgument(\"batch_dim must be >=0, got \",\n+                                       batch_dim);\n+      }\n+\n       DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\n       TF_RETURN_IF_ERROR(\n           c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));"
    }
  ]
}