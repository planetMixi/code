{
  "schema":{
    "fields":[
      {
        "name":"index",
        "type":"integer"
      },
      {
        "name":"vuln_id",
        "type":"string"
      },
      {
        "name":"cwe_id",
        "type":"string"
      },
      {
        "name":"score",
        "type":"number"
      },
      {
        "name":"chain",
        "type":"string"
      },
      {
        "name":"dataset",
        "type":"string"
      },
      {
        "name":"summary",
        "type":"string"
      },
      {
        "name":"published_date",
        "type":"string"
      },
      {
        "name":"chain_len",
        "type":"integer"
      },
      {
        "name":"project",
        "type":"string"
      },
      {
        "name":"commit_href",
        "type":"string"
      },
      {
        "name":"commit_sha",
        "type":"string"
      },
      {
        "name":"patch",
        "type":"string"
      },
      {
        "name":"chain_ord",
        "type":"string"
      },
      {
        "name":"before_first_fix_commit",
        "type":"string"
      },
      {
        "name":"last_fix_commit",
        "type":"string"
      },
      {
        "name":"chain_ord_pos",
        "type":"number"
      },
      {
        "name":"commit_datetime",
        "type":"string"
      },
      {
        "name":"message",
        "type":"string"
      },
      {
        "name":"author",
        "type":"string"
      },
      {
        "name":"comments",
        "type":"string"
      },
      {
        "name":"stats",
        "type":"string"
      },
      {
        "name":"files",
        "type":"string"
      },
      {
        "name":"message_norm",
        "type":"string"
      },
      {
        "name":"language",
        "type":"string"
      },
      {
        "name":"entities",
        "type":"string"
      },
      {
        "name":"classification_level_1",
        "type":"string"
      },
      {
        "name":"classification_level_2",
        "type":"string"
      },
      {
        "name":"list_files",
        "type":"string"
      },
      {
        "name":"num_files",
        "type":"number"
      },
      {
        "name":"patch_content",
        "type":"string"
      },
      {
        "name":"code_diff",
        "type":"string"
      }
    ],
    "primaryKey":[
      "index"
    ],
    "pandas_version":"1.4.0"
  },
  "data":[
    {
      "index":0,
      "vuln_id":"GHSA-rhcw-wjcm-9h6g",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/undertow-io\/undertow\/pull\/997\/commits\/98a9ab7f2d7fe7a7254eaf17d47816c452169c90'}",
      "dataset":"osv",
      "summary":"Denial of service in Undertow A flaw was found in the Undertow AJP connector. Malicious requests and abrupt connection closes could be triggered by an attacker using query strings with non-RFC compliant characters resulting in a denial of service. The highest threat from this vulnerability is to system availability. This affects Undertow 2.1.5.SP1, 2.0.33.SP2, and 2.2.3.SP1.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/undertow-io\/undertow",
      "commit_href":"https:\/\/github.com\/undertow-io\/undertow\/pull\/997\/commits\/98a9ab7f2d7fe7a7254eaf17d47816c452169c90",
      "commit_sha":"98a9ab7f2d7fe7a7254eaf17d47816c452169c90",
      "patch":"SINGLE",
      "chain_ord":"['98a9ab7f2d7fe7a7254eaf17d47816c452169c90']",
      "before_first_fix_commit":"{'47dc5e37cb20d8eeb4d4f632fe959d436f86128a'}",
      "last_fix_commit":"98a9ab7f2d7fe7a7254eaf17d47816c452169c90",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/29\/2020, 13:24:40",
      "message":"UNDERTOW-1813 Make PathResourceManager.getResource rethrow a SecurityException",
      "author":"Boris Unckel",
      "comments":null,
      "stats":"{'additions': 7, 'deletions': 1, 'total': 8}",
      "files":"{'core\/src\/main\/java\/io\/undertow\/server\/handlers\/resource\/PathResourceManager.java': {'additions': 7, 'deletions': 1, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/undertow-io\/undertow\/raw\/98a9ab7f2d7fe7a7254eaf17d47816c452169c90\/core%2Fsrc%2Fmain%2Fjava%2Fio%2Fundertow%2Fserver%2Fhandlers%2Fresource%2FPathResourceManager.java', 'patch': '@@ -230,9 +230,15 @@ public Resource getResource(final String p) {\\n                 log.tracef(\"Failed to get path resource %s from path resource manager with base %s, as the path did not exist\", p, base);\\n                 return null;\\n             }\\n-        } catch (Exception e) {\\n+        } catch (IOException e) {\\n             UndertowLogger.REQUEST_LOGGER.debugf(e, \"Invalid path %s\", p);\\n             return null;\\n+        } catch (SecurityException e) {\\n+            UndertowLogger.REQUEST_LOGGER.errorf(e, \"Missing JSM permissions for path %s\", p);\\n+            throw e;\\n+        } catch (Exception e) {\\n+            UndertowLogger.REQUEST_LOGGER.debugf(e, \"Other issue for path %s\", p);\\n+            return null;\\n         }\\n     }'}}",
      "message_norm":"undertow-1813 make pathresourcemanager.getresource rethrow a securityexception",
      "language":"en",
      "entities":"[('securityexception', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['core\/src\/main\/java\/io\/undertow\/server\/handlers\/resource\/PathResourceManager.java'])",
      "num_files":1.0,
      "patch_content":"From 98a9ab7f2d7fe7a7254eaf17d47816c452169c90 Mon Sep 17 00:00:00 2001\nFrom: Boris Unckel <boris@unckel.net>\nDate: Sun, 29 Nov 2020 14:24:40 +0100\nSubject: [PATCH] UNDERTOW-1813 Make PathResourceManager.getResource rethrow a\n SecurityException\n\n---\n ...\/server\/handlers\/resource\/PathResourceManager.java     | 8 +++++++-\n 1 file changed, 7 insertions(+), 1 deletion(-)\n\ndiff --git a\/core\/src\/main\/java\/io\/undertow\/server\/handlers\/resource\/PathResourceManager.java b\/core\/src\/main\/java\/io\/undertow\/server\/handlers\/resource\/PathResourceManager.java\nindex a13b082f46..d48ea9d375 100644\n--- a\/core\/src\/main\/java\/io\/undertow\/server\/handlers\/resource\/PathResourceManager.java\n+++ b\/core\/src\/main\/java\/io\/undertow\/server\/handlers\/resource\/PathResourceManager.java\n@@ -230,9 +230,15 @@ public Resource getResource(final String p) {\n                 log.tracef(\"Failed to get path resource %s from path resource manager with base %s, as the path did not exist\", p, base);\n                 return null;\n             }\n-        } catch (Exception e) {\n+        } catch (IOException e) {\n             UndertowLogger.REQUEST_LOGGER.debugf(e, \"Invalid path %s\", p);\n             return null;\n+        } catch (SecurityException e) {\n+            UndertowLogger.REQUEST_LOGGER.errorf(e, \"Missing JSM permissions for path %s\", p);\n+            throw e;\n+        } catch (Exception e) {\n+            UndertowLogger.REQUEST_LOGGER.debugf(e, \"Other issue for path %s\", p);\n+            return null;\n         }\n     }",
      "code_diff":"@@ -230,9 +230,15 @@ public Resource getResource(final String p) {\n                 log.tracef(\"Failed to get path resource %s from path resource manager with base %s, as the path did not exist\", p, base);\n                 return null;\n             }\n-        } catch (Exception e) {\n+        } catch (IOException e) {\n             UndertowLogger.REQUEST_LOGGER.debugf(e, \"Invalid path %s\", p);\n             return null;\n+        } catch (SecurityException e) {\n+            UndertowLogger.REQUEST_LOGGER.errorf(e, \"Missing JSM permissions for path %s\", p);\n+            throw e;\n+        } catch (Exception e) {\n+            UndertowLogger.REQUEST_LOGGER.debugf(e, \"Other issue for path %s\", p);\n+            return null;\n         }\n     }"
    },
    {
      "index":1,
      "vuln_id":"GHSA-57f3-gghm-9mhc",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/MrRio\/jsPDF\/commit\/d8bb3b39efcd129994f7a3b01b632164144ec43e'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service (ReDoS) This affects the package jspdf before 2.3.1. ReDoS is possible via the addImage function.",
      "published_date":"2021-03-12",
      "chain_len":1,
      "project":"https:\/\/github.com\/MrRio\/jsPDF",
      "commit_href":"https:\/\/github.com\/MrRio\/jsPDF\/commit\/d8bb3b39efcd129994f7a3b01b632164144ec43e",
      "commit_sha":"d8bb3b39efcd129994f7a3b01b632164144ec43e",
      "patch":"SINGLE",
      "chain_ord":"['d8bb3b39efcd129994f7a3b01b632164144ec43e']",
      "before_first_fix_commit":"{'c91995de97c598deaf6fda7109ea886a50f50109'}",
      "last_fix_commit":"d8bb3b39efcd129994f7a3b01b632164144ec43e",
      "chain_ord_pos":1.0,
      "commit_datetime":"02\/11\/2021, 15:50:17",
      "message":"fix ReDoS-vulnerable regexp in addImage (#3091)",
      "author":"Yeting Li",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'src\/modules\/addimage.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/parallax\/jsPDF\/raw\/d8bb3b39efcd129994f7a3b01b632164144ec43e\/src%2Fmodules%2Faddimage.js', 'patch': '@@ -630,7 +630,7 @@ import { atob, btoa } from \"..\/libs\/AtobBtoa.js\";\\n     var result = null;\\n \\n     if (dataUrlParts.length === 2) {\\n-      var extractedInfo = \/^data:(\\\\w*\\\\\/\\\\w*);*(charset=[\\\\w=-]*)*;*$\/.exec(\\n+      var extractedInfo = \/^data:(\\\\w*\\\\\/\\\\w*);*(charset=(?!charset=)[\\\\w=-]*)*;*$\/.exec(\\n         dataUrlParts[0]\\n       );\\n       if (Array.isArray(extractedInfo)) {'}}",
      "message_norm":"fix redos-vulnerable regexp in addimage (#3091)",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('vulnerable', 'SECWORD', ''), ('#3091', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/modules\/addimage.js'])",
      "num_files":1.0,
      "patch_content":"From d8bb3b39efcd129994f7a3b01b632164144ec43e Mon Sep 17 00:00:00 2001\nFrom: Yeting Li <liyt@ios.ac.cn>\nDate: Thu, 11 Feb 2021 23:50:17 +0800\nSubject: [PATCH] fix ReDoS-vulnerable regexp in addImage (#3091)\n\n---\n src\/modules\/addimage.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/modules\/addimage.js b\/src\/modules\/addimage.js\nindex 5d206606f..d0295d0ca 100644\n--- a\/src\/modules\/addimage.js\n+++ b\/src\/modules\/addimage.js\n@@ -630,7 +630,7 @@ import { atob, btoa } from \"..\/libs\/AtobBtoa.js\";\n     var result = null;\n \n     if (dataUrlParts.length === 2) {\n-      var extractedInfo = \/^data:(\\w*\\\/\\w*);*(charset=[\\w=-]*)*;*$\/.exec(\n+      var extractedInfo = \/^data:(\\w*\\\/\\w*);*(charset=(?!charset=)[\\w=-]*)*;*$\/.exec(\n         dataUrlParts[0]\n       );\n       if (Array.isArray(extractedInfo)) {",
      "code_diff":"@@ -630,7 +630,7 @@ import { atob, btoa } from \"..\/libs\/AtobBtoa.js\";\n     var result = null;\n \n     if (dataUrlParts.length === 2) {\n-      var extractedInfo = \/^data:(\\w*\\\/\\w*);*(charset=[\\w=-]*)*;*$\/.exec(\n+      var extractedInfo = \/^data:(\\w*\\\/\\w*);*(charset=(?!charset=)[\\w=-]*)*;*$\/.exec(\n         dataUrlParts[0]\n       );\n       if (Array.isArray(extractedInfo)) {"
    },
    {
      "index":2,
      "vuln_id":"GHSA-394c-5j6w-4xmx",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/faisalman\/ua-parser-js\/commit\/6d1f26df051ba681463ef109d36c9cf0f7e32b18'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service (ReDoS) in ua-parser-js The package ua-parser-js before 0.7.23 are vulnerable to Regular Expression Denial of Service (ReDoS) in multiple regexes (see linked commit for more info).",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/faisalman\/ua-parser-js",
      "commit_href":"https:\/\/github.com\/faisalman\/ua-parser-js\/commit\/6d1f26df051ba681463ef109d36c9cf0f7e32b18",
      "commit_sha":"6d1f26df051ba681463ef109d36c9cf0f7e32b18",
      "patch":"SINGLE",
      "chain_ord":"['6d1f26df051ba681463ef109d36c9cf0f7e32b18']",
      "before_first_fix_commit":"{'86471ad7e24724757e6147cd449cc2af4fab6280'}",
      "last_fix_commit":"6d1f26df051ba681463ef109d36c9cf0f7e32b18",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/30\/2020, 17:50:19",
      "message":"Fix ReDoS vulnerabilities reported by Snyk",
      "author":"Faisal Salman",
      "comments":null,
      "stats":"{'additions': 14, 'deletions': 14, 'total': 28}",
      "files":"{'src\/ua-parser.js': {'additions': 14, 'deletions': 14, 'changes': 28, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/faisalman\/ua-parser-js\/raw\/6d1f26df051ba681463ef109d36c9cf0f7e32b18\/src%2Fua-parser.js', 'patch': \"@@ -222,7 +222,7 @@\\n \\n             \/\/ Presto based\\n             \/(opera\\\\smini)\\\\\/([\\\\w\\\\.-]+)\/i,                                       \/\/ Opera Mini\\n-            \/(opera\\\\s[mobiletab]+).+version\\\\\/([\\\\w\\\\.-]+)\/i,                      \/\/ Opera Mobi\/Tablet\\n+            \/(opera\\\\s[mobiletab]{3,6}).+version\\\\\/([\\\\w\\\\.-]+)\/i,                  \/\/ Opera Mobi\/Tablet\\n             \/(opera).+version\\\\\/([\\\\w\\\\.]+)\/i,                                     \/\/ Opera > 9.80\\n             \/(opera)[\\\\\/\\\\s]+([\\\\w\\\\.]+)\/i                                          \/\/ Opera < 9.80\\n             ], [NAME, VERSION], [\\n@@ -252,7 +252,7 @@\\n             \/(konqueror)\\\\\/([\\\\w\\\\.]+)\/i                                           \/\/ Konqueror\\n             ], [[NAME, 'Konqueror'], VERSION], [\\n \\n-            \/(trident).+rv[:\\\\s]([\\\\w\\\\.]+).+like\\\\sgecko\/i                         \/\/ IE11\\n+            \/(trident).+rv[:\\\\s]([\\\\w\\\\.]{1,9}).+like\\\\sgecko\/i                     \/\/ IE11\\n             ], [[NAME, 'IE'], VERSION], [\\n \\n             \/(edge|edgios|edga|edg)\\\\\/((\\\\d+)?[\\\\w\\\\.]+)\/i                          \/\/ Microsoft Edge\\n@@ -362,13 +362,13 @@\\n             \/fxios\\\\\/([\\\\w\\\\.-]+)\/i                                                \/\/ Firefox for iOS\\n             ], [VERSION, [NAME, 'Firefox']], [\\n \\n-            \/version\\\\\/([\\\\w\\\\.]+).+?mobile\\\\\/\\\\w+\\\\s(safari)\/i                       \/\/ Mobile Safari\\n+            \/version\\\\\/([\\\\w\\\\.]+)\\\\s.*mobile\\\\\/\\\\w+\\\\s(safari)\/i                      \/\/ Mobile Safari\\n             ], [VERSION, [NAME, 'Mobile Safari']], [\\n \\n-            \/version\\\\\/([\\\\w\\\\.]+).+?(mobile\\\\s?safari|safari)\/i                    \/\/ Safari & Safari Mobile\\n+            \/version\\\\\/([\\\\w\\\\.]+)\\\\s.*(mobile\\\\s?safari|safari)\/i                   \/\/ Safari & Safari Mobile\\n             ], [VERSION, NAME], [\\n \\n-            \/webkit.+?(gsa)\\\\\/([\\\\w\\\\.]+).+?(mobile\\\\s?safari|safari)(\\\\\/[\\\\w\\\\.]+)\/i  \/\/ Google Search Appliance on iOS\\n+            \/webkit.+?(gsa)\\\\\/([\\\\w\\\\.]+)\\\\s.*(mobile\\\\s?safari|safari)(\\\\\/[\\\\w\\\\.]+)\/i \/\/ Google Search Appliance on iOS\\n             ], [[NAME, 'GSA'], VERSION], [\\n \\n             \/webkit.+?(mobile\\\\s?safari|safari)(\\\\\/[\\\\w\\\\.]+)\/i                     \/\/ Safari < 3.0\\n@@ -387,7 +387,7 @@\\n \\n                                                                                 \/\/ Firefox\/SeaMonkey\/K-Meleon\/IceCat\/IceApe\/Firebird\/Phoenix\\n             \/(firefox)\\\\\/([\\\\w\\\\.]+)\\\\s[\\\\w\\\\s\\\\-]+\\\\\/[\\\\w\\\\.]+$\/i,                       \/\/ Other Firefox-based\\n-            \/(mozilla)\\\\\/([\\\\w\\\\.]+).+rv\\\\:.+gecko\\\\\/\\\\d+\/i,                          \/\/ Mozilla\\n+            \/(mozilla)\\\\\/([\\\\w\\\\.]+)\\\\s.+rv\\\\:.+gecko\\\\\/\\\\d+\/i,                        \/\/ Mozilla\\n \\n             \/\/ Other\\n             \/(polaris|lynx|dillo|icab|doris|amaya|w3m|netsurf|sleipnir)[\\\\\/\\\\s]?([\\\\w\\\\.]+)\/i,\\n@@ -487,7 +487,7 @@\\n             \/(sprint\\\\s(\\\\w+))\/i                                                  \/\/ Sprint Phones\\n             ], [[VENDOR, mapper.str, maps.device.sprint.vendor], [MODEL, mapper.str, maps.device.sprint.model], [TYPE, MOBILE]], [\\n \\n-            \/(htc)[;_\\\\s-]+([\\\\w\\\\s]+(?=\\\\)|\\\\sbuild)|\\\\w+)\/i,                        \/\/ HTC\\n+            \/(htc)[;_\\\\s-]{1,2}([\\\\w\\\\s]+(?=\\\\)|\\\\sbuild)|\\\\w+)\/i,                    \/\/ HTC\\n             \/(zte)-(\\\\w*)\/i,                                                     \/\/ ZTE\\n             \/(alcatel|geeksphone|nexian|panasonic|(?=;\\\\s)sony)[_\\\\s-]?([\\\\w-]*)\/i\\n                                                                                 \/\/ Alcatel\/GeeksPhone\/Nexian\/Panasonic\/Sony\\n@@ -591,13 +591,13 @@\\n             ], [MODEL, [VENDOR, 'Google'], [TYPE, MOBILE]], [\\n \\n             \/android.+;\\\\s(\\\\w+)\\\\s+build\\\\\/hm\\\\1\/i,                                 \/\/ Xiaomi Hongmi 'numeric' models\\n-            \/android.+(hm[\\\\s\\\\-_]*note?[\\\\s_]*(?:\\\\d\\\\w)?)\\\\s+build\/i,               \/\/ Xiaomi Hongmi\\n-            \/android.+(redmi[\\\\s\\\\-_]*(?:note|k)?(?:[\\\\s_]?[\\\\w\\\\s]+))(?:\\\\s+build|\\\\))\/i,      \\n+            \/android.+(hm[\\\\s\\\\-_]?note?[\\\\s_]?(?:\\\\d\\\\w)?)\\\\sbuild\/i,                \/\/ Xiaomi Hongmi\\n+            \/android.+(redmi[\\\\s\\\\-_]?(?:note|k)?(?:[\\\\s_]?[\\\\w\\\\s]+))(?:\\\\sbuild|\\\\))\/i,      \\n                                                                                 \/\/ Xiaomi Redmi\\n-            \/android.+(mi[\\\\s\\\\-_]*(?:a\\\\d|one|one[\\\\s_]plus|note lte)?[\\\\s_]?(?:\\\\d?\\\\w?)[\\\\s_]*(?:plus)?)\\\\s+build\/i    \\n+            \/android.+(mi[\\\\s\\\\-_]?(?:a\\\\d|one|one[\\\\s_]plus|note lte)?[\\\\s_]?(?:\\\\d?\\\\w?)[\\\\s_]?(?:plus)?)\\\\sbuild\/i    \\n                                                                                 \/\/ Xiaomi Mi\\n             ], [[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, MOBILE]], [\\n-            \/android.+(mi[\\\\s\\\\-_]*(?:pad)(?:[\\\\s_]?[\\\\w\\\\s]+))(?:\\\\s+build|\\\\))\/i     \/\/ Mi Pad tablets\\n+            \/android.+(mi[\\\\s\\\\-_]?(?:pad)(?:[\\\\s_]?[\\\\w\\\\s]+))(?:\\\\sbuild|\\\\))\/i     \/\/ Mi Pad tablets\\n             ],[[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, TABLET]], [\\n             \/android.+;\\\\s(m[1-5]\\\\snote)\\\\sbuild\/i                                \/\/ Meizu\\n             ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], [\\n@@ -611,7 +611,7 @@\\n             \/android.+[;\\\\\/]\\\\s*(RCT[\\\\d\\\\w]+)\\\\s+build\/i                            \/\/ RCA Tablets\\n             ], [MODEL, [VENDOR, 'RCA'], [TYPE, TABLET]], [\\n \\n-            \/android.+[;\\\\\/\\\\s]+(Venue[\\\\d\\\\s]{2,7})\\\\s+build\/i                      \/\/ Dell Venue Tablets\\n+            \/android.+[;\\\\\/\\\\s](Venue[\\\\d\\\\s]{2,7})\\\\s+build\/i                       \/\/ Dell Venue Tablets\\n             ], [MODEL, [VENDOR, 'Dell'], [TYPE, TABLET]], [\\n \\n             \/android.+[;\\\\\/]\\\\s*(Q[T|M][\\\\d\\\\w]+)\\\\s+build\/i                         \/\/ Verizon Tablet\\n@@ -669,8 +669,8 @@\\n             \/android.+[;\\\\\/]\\\\s*TU_(1491)\\\\s+build\/i                               \/\/ Rotor Tablets\\n             ], [MODEL, [VENDOR, 'Rotor'], [TYPE, TABLET]], [\\n \\n-            \/android.+(KS(.+))\\\\s+build\/i                                        \/\/ Amazon Kindle Tablets\\n-            ], [MODEL, [VENDOR, 'Amazon'], [TYPE, TABLET]], [\\n+            \/\/android.+(KS(.+))\\\\s+build\/i                                        \/\/ Amazon Kindle Tablets\\n+            \/\/], [MODEL, [VENDOR, 'Amazon'], [TYPE, TABLET]], [\\n \\n             \/android.+(Gigaset)[\\\\s\\\\-]+(Q\\\\w{1,9})\\\\s+build\/i                      \/\/ Gigaset Tablets\\n             ], [VENDOR, MODEL, [TYPE, TABLET]], [\"}}",
      "message_norm":"fix redos vulnerabilities reported by snyk",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/ua-parser.js'])",
      "num_files":1.0,
      "patch_content":"From 6d1f26df051ba681463ef109d36c9cf0f7e32b18 Mon Sep 17 00:00:00 2001\nFrom: Faisal Salman <f@faisalman.com>\nDate: Tue, 1 Dec 2020 00:50:19 +0700\nSubject: [PATCH] Fix ReDoS vulnerabilities reported by Snyk\n\n---\n src\/ua-parser.js | 28 ++++++++++++++--------------\n 1 file changed, 14 insertions(+), 14 deletions(-)\n\ndiff --git a\/src\/ua-parser.js b\/src\/ua-parser.js\nindex e522d9317..5ea799f83 100755\n--- a\/src\/ua-parser.js\n+++ b\/src\/ua-parser.js\n@@ -222,7 +222,7 @@\n \n             \/\/ Presto based\n             \/(opera\\smini)\\\/([\\w\\.-]+)\/i,                                       \/\/ Opera Mini\n-            \/(opera\\s[mobiletab]+).+version\\\/([\\w\\.-]+)\/i,                      \/\/ Opera Mobi\/Tablet\n+            \/(opera\\s[mobiletab]{3,6}).+version\\\/([\\w\\.-]+)\/i,                  \/\/ Opera Mobi\/Tablet\n             \/(opera).+version\\\/([\\w\\.]+)\/i,                                     \/\/ Opera > 9.80\n             \/(opera)[\\\/\\s]+([\\w\\.]+)\/i                                          \/\/ Opera < 9.80\n             ], [NAME, VERSION], [\n@@ -252,7 +252,7 @@\n             \/(konqueror)\\\/([\\w\\.]+)\/i                                           \/\/ Konqueror\n             ], [[NAME, 'Konqueror'], VERSION], [\n \n-            \/(trident).+rv[:\\s]([\\w\\.]+).+like\\sgecko\/i                         \/\/ IE11\n+            \/(trident).+rv[:\\s]([\\w\\.]{1,9}).+like\\sgecko\/i                     \/\/ IE11\n             ], [[NAME, 'IE'], VERSION], [\n \n             \/(edge|edgios|edga|edg)\\\/((\\d+)?[\\w\\.]+)\/i                          \/\/ Microsoft Edge\n@@ -362,13 +362,13 @@\n             \/fxios\\\/([\\w\\.-]+)\/i                                                \/\/ Firefox for iOS\n             ], [VERSION, [NAME, 'Firefox']], [\n \n-            \/version\\\/([\\w\\.]+).+?mobile\\\/\\w+\\s(safari)\/i                       \/\/ Mobile Safari\n+            \/version\\\/([\\w\\.]+)\\s.*mobile\\\/\\w+\\s(safari)\/i                      \/\/ Mobile Safari\n             ], [VERSION, [NAME, 'Mobile Safari']], [\n \n-            \/version\\\/([\\w\\.]+).+?(mobile\\s?safari|safari)\/i                    \/\/ Safari & Safari Mobile\n+            \/version\\\/([\\w\\.]+)\\s.*(mobile\\s?safari|safari)\/i                   \/\/ Safari & Safari Mobile\n             ], [VERSION, NAME], [\n \n-            \/webkit.+?(gsa)\\\/([\\w\\.]+).+?(mobile\\s?safari|safari)(\\\/[\\w\\.]+)\/i  \/\/ Google Search Appliance on iOS\n+            \/webkit.+?(gsa)\\\/([\\w\\.]+)\\s.*(mobile\\s?safari|safari)(\\\/[\\w\\.]+)\/i \/\/ Google Search Appliance on iOS\n             ], [[NAME, 'GSA'], VERSION], [\n \n             \/webkit.+?(mobile\\s?safari|safari)(\\\/[\\w\\.]+)\/i                     \/\/ Safari < 3.0\n@@ -387,7 +387,7 @@\n \n                                                                                 \/\/ Firefox\/SeaMonkey\/K-Meleon\/IceCat\/IceApe\/Firebird\/Phoenix\n             \/(firefox)\\\/([\\w\\.]+)\\s[\\w\\s\\-]+\\\/[\\w\\.]+$\/i,                       \/\/ Other Firefox-based\n-            \/(mozilla)\\\/([\\w\\.]+).+rv\\:.+gecko\\\/\\d+\/i,                          \/\/ Mozilla\n+            \/(mozilla)\\\/([\\w\\.]+)\\s.+rv\\:.+gecko\\\/\\d+\/i,                        \/\/ Mozilla\n \n             \/\/ Other\n             \/(polaris|lynx|dillo|icab|doris|amaya|w3m|netsurf|sleipnir)[\\\/\\s]?([\\w\\.]+)\/i,\n@@ -487,7 +487,7 @@\n             \/(sprint\\s(\\w+))\/i                                                  \/\/ Sprint Phones\n             ], [[VENDOR, mapper.str, maps.device.sprint.vendor], [MODEL, mapper.str, maps.device.sprint.model], [TYPE, MOBILE]], [\n \n-            \/(htc)[;_\\s-]+([\\w\\s]+(?=\\)|\\sbuild)|\\w+)\/i,                        \/\/ HTC\n+            \/(htc)[;_\\s-]{1,2}([\\w\\s]+(?=\\)|\\sbuild)|\\w+)\/i,                    \/\/ HTC\n             \/(zte)-(\\w*)\/i,                                                     \/\/ ZTE\n             \/(alcatel|geeksphone|nexian|panasonic|(?=;\\s)sony)[_\\s-]?([\\w-]*)\/i\n                                                                                 \/\/ Alcatel\/GeeksPhone\/Nexian\/Panasonic\/Sony\n@@ -591,13 +591,13 @@\n             ], [MODEL, [VENDOR, 'Google'], [TYPE, MOBILE]], [\n \n             \/android.+;\\s(\\w+)\\s+build\\\/hm\\1\/i,                                 \/\/ Xiaomi Hongmi 'numeric' models\n-            \/android.+(hm[\\s\\-_]*note?[\\s_]*(?:\\d\\w)?)\\s+build\/i,               \/\/ Xiaomi Hongmi\n-            \/android.+(redmi[\\s\\-_]*(?:note|k)?(?:[\\s_]?[\\w\\s]+))(?:\\s+build|\\))\/i,      \n+            \/android.+(hm[\\s\\-_]?note?[\\s_]?(?:\\d\\w)?)\\sbuild\/i,                \/\/ Xiaomi Hongmi\n+            \/android.+(redmi[\\s\\-_]?(?:note|k)?(?:[\\s_]?[\\w\\s]+))(?:\\sbuild|\\))\/i,      \n                                                                                 \/\/ Xiaomi Redmi\n-            \/android.+(mi[\\s\\-_]*(?:a\\d|one|one[\\s_]plus|note lte)?[\\s_]?(?:\\d?\\w?)[\\s_]*(?:plus)?)\\s+build\/i    \n+            \/android.+(mi[\\s\\-_]?(?:a\\d|one|one[\\s_]plus|note lte)?[\\s_]?(?:\\d?\\w?)[\\s_]?(?:plus)?)\\sbuild\/i    \n                                                                                 \/\/ Xiaomi Mi\n             ], [[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, MOBILE]], [\n-            \/android.+(mi[\\s\\-_]*(?:pad)(?:[\\s_]?[\\w\\s]+))(?:\\s+build|\\))\/i     \/\/ Mi Pad tablets\n+            \/android.+(mi[\\s\\-_]?(?:pad)(?:[\\s_]?[\\w\\s]+))(?:\\sbuild|\\))\/i     \/\/ Mi Pad tablets\n             ],[[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, TABLET]], [\n             \/android.+;\\s(m[1-5]\\snote)\\sbuild\/i                                \/\/ Meizu\n             ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], [\n@@ -611,7 +611,7 @@\n             \/android.+[;\\\/]\\s*(RCT[\\d\\w]+)\\s+build\/i                            \/\/ RCA Tablets\n             ], [MODEL, [VENDOR, 'RCA'], [TYPE, TABLET]], [\n \n-            \/android.+[;\\\/\\s]+(Venue[\\d\\s]{2,7})\\s+build\/i                      \/\/ Dell Venue Tablets\n+            \/android.+[;\\\/\\s](Venue[\\d\\s]{2,7})\\s+build\/i                       \/\/ Dell Venue Tablets\n             ], [MODEL, [VENDOR, 'Dell'], [TYPE, TABLET]], [\n \n             \/android.+[;\\\/]\\s*(Q[T|M][\\d\\w]+)\\s+build\/i                         \/\/ Verizon Tablet\n@@ -669,8 +669,8 @@\n             \/android.+[;\\\/]\\s*TU_(1491)\\s+build\/i                               \/\/ Rotor Tablets\n             ], [MODEL, [VENDOR, 'Rotor'], [TYPE, TABLET]], [\n \n-            \/android.+(KS(.+))\\s+build\/i                                        \/\/ Amazon Kindle Tablets\n-            ], [MODEL, [VENDOR, 'Amazon'], [TYPE, TABLET]], [\n+            \/\/android.+(KS(.+))\\s+build\/i                                        \/\/ Amazon Kindle Tablets\n+            \/\/], [MODEL, [VENDOR, 'Amazon'], [TYPE, TABLET]], [\n \n             \/android.+(Gigaset)[\\s\\-]+(Q\\w{1,9})\\s+build\/i                      \/\/ Gigaset Tablets\n             ], [VENDOR, MODEL, [TYPE, TABLET]], [",
      "code_diff":"@@ -222,7 +222,7 @@\n \n             \/\/ Presto based\n             \/(opera\\smini)\\\/([\\w\\.-]+)\/i,                                       \/\/ Opera Mini\n-            \/(opera\\s[mobiletab]+).+version\\\/([\\w\\.-]+)\/i,                      \/\/ Opera Mobi\/Tablet\n+            \/(opera\\s[mobiletab]{3,6}).+version\\\/([\\w\\.-]+)\/i,                  \/\/ Opera Mobi\/Tablet\n             \/(opera).+version\\\/([\\w\\.]+)\/i,                                     \/\/ Opera > 9.80\n             \/(opera)[\\\/\\s]+([\\w\\.]+)\/i                                          \/\/ Opera < 9.80\n             ], [NAME, VERSION], [\n@@ -252,7 +252,7 @@\n             \/(konqueror)\\\/([\\w\\.]+)\/i                                           \/\/ Konqueror\n             ], [[NAME, 'Konqueror'], VERSION], [\n \n-            \/(trident).+rv[:\\s]([\\w\\.]+).+like\\sgecko\/i                         \/\/ IE11\n+            \/(trident).+rv[:\\s]([\\w\\.]{1,9}).+like\\sgecko\/i                     \/\/ IE11\n             ], [[NAME, 'IE'], VERSION], [\n \n             \/(edge|edgios|edga|edg)\\\/((\\d+)?[\\w\\.]+)\/i                          \/\/ Microsoft Edge\n@@ -362,13 +362,13 @@\n             \/fxios\\\/([\\w\\.-]+)\/i                                                \/\/ Firefox for iOS\n             ], [VERSION, [NAME, 'Firefox']], [\n \n-            \/version\\\/([\\w\\.]+).+?mobile\\\/\\w+\\s(safari)\/i                       \/\/ Mobile Safari\n+            \/version\\\/([\\w\\.]+)\\s.*mobile\\\/\\w+\\s(safari)\/i                      \/\/ Mobile Safari\n             ], [VERSION, [NAME, 'Mobile Safari']], [\n \n-            \/version\\\/([\\w\\.]+).+?(mobile\\s?safari|safari)\/i                    \/\/ Safari & Safari Mobile\n+            \/version\\\/([\\w\\.]+)\\s.*(mobile\\s?safari|safari)\/i                   \/\/ Safari & Safari Mobile\n             ], [VERSION, NAME], [\n \n-            \/webkit.+?(gsa)\\\/([\\w\\.]+).+?(mobile\\s?safari|safari)(\\\/[\\w\\.]+)\/i  \/\/ Google Search Appliance on iOS\n+            \/webkit.+?(gsa)\\\/([\\w\\.]+)\\s.*(mobile\\s?safari|safari)(\\\/[\\w\\.]+)\/i \/\/ Google Search Appliance on iOS\n             ], [[NAME, 'GSA'], VERSION], [\n \n             \/webkit.+?(mobile\\s?safari|safari)(\\\/[\\w\\.]+)\/i                     \/\/ Safari < 3.0\n@@ -387,7 +387,7 @@\n \n                                                                                 \/\/ Firefox\/SeaMonkey\/K-Meleon\/IceCat\/IceApe\/Firebird\/Phoenix\n             \/(firefox)\\\/([\\w\\.]+)\\s[\\w\\s\\-]+\\\/[\\w\\.]+$\/i,                       \/\/ Other Firefox-based\n-            \/(mozilla)\\\/([\\w\\.]+).+rv\\:.+gecko\\\/\\d+\/i,                          \/\/ Mozilla\n+            \/(mozilla)\\\/([\\w\\.]+)\\s.+rv\\:.+gecko\\\/\\d+\/i,                        \/\/ Mozilla\n \n             \/\/ Other\n             \/(polaris|lynx|dillo|icab|doris|amaya|w3m|netsurf|sleipnir)[\\\/\\s]?([\\w\\.]+)\/i,\n@@ -487,7 +487,7 @@\n             \/(sprint\\s(\\w+))\/i                                                  \/\/ Sprint Phones\n             ], [[VENDOR, mapper.str, maps.device.sprint.vendor], [MODEL, mapper.str, maps.device.sprint.model], [TYPE, MOBILE]], [\n \n-            \/(htc)[;_\\s-]+([\\w\\s]+(?=\\)|\\sbuild)|\\w+)\/i,                        \/\/ HTC\n+            \/(htc)[;_\\s-]{1,2}([\\w\\s]+(?=\\)|\\sbuild)|\\w+)\/i,                    \/\/ HTC\n             \/(zte)-(\\w*)\/i,                                                     \/\/ ZTE\n             \/(alcatel|geeksphone|nexian|panasonic|(?=;\\s)sony)[_\\s-]?([\\w-]*)\/i\n                                                                                 \/\/ Alcatel\/GeeksPhone\/Nexian\/Panasonic\/Sony\n@@ -591,13 +591,13 @@\n             ], [MODEL, [VENDOR, 'Google'], [TYPE, MOBILE]], [\n \n             \/android.+;\\s(\\w+)\\s+build\\\/hm\\1\/i,                                 \/\/ Xiaomi Hongmi 'numeric' models\n-            \/android.+(hm[\\s\\-_]*note?[\\s_]*(?:\\d\\w)?)\\s+build\/i,               \/\/ Xiaomi Hongmi\n-            \/android.+(redmi[\\s\\-_]*(?:note|k)?(?:[\\s_]?[\\w\\s]+))(?:\\s+build|\\))\/i,      \n+            \/android.+(hm[\\s\\-_]?note?[\\s_]?(?:\\d\\w)?)\\sbuild\/i,                \/\/ Xiaomi Hongmi\n+            \/android.+(redmi[\\s\\-_]?(?:note|k)?(?:[\\s_]?[\\w\\s]+))(?:\\sbuild|\\))\/i,      \n                                                                                 \/\/ Xiaomi Redmi\n-            \/android.+(mi[\\s\\-_]*(?:a\\d|one|one[\\s_]plus|note lte)?[\\s_]?(?:\\d?\\w?)[\\s_]*(?:plus)?)\\s+build\/i    \n+            \/android.+(mi[\\s\\-_]?(?:a\\d|one|one[\\s_]plus|note lte)?[\\s_]?(?:\\d?\\w?)[\\s_]?(?:plus)?)\\sbuild\/i    \n                                                                                 \/\/ Xiaomi Mi\n             ], [[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, MOBILE]], [\n-            \/android.+(mi[\\s\\-_]*(?:pad)(?:[\\s_]?[\\w\\s]+))(?:\\s+build|\\))\/i     \/\/ Mi Pad tablets\n+            \/android.+(mi[\\s\\-_]?(?:pad)(?:[\\s_]?[\\w\\s]+))(?:\\sbuild|\\))\/i     \/\/ Mi Pad tablets\n             ],[[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, TABLET]], [\n             \/android.+;\\s(m[1-5]\\snote)\\sbuild\/i                                \/\/ Meizu\n             ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], [\n@@ -611,7 +611,7 @@\n             \/android.+[;\\\/]\\s*(RCT[\\d\\w]+)\\s+build\/i                            \/\/ RCA Tablets\n             ], [MODEL, [VENDOR, 'RCA'], [TYPE, TABLET]], [\n \n-            \/android.+[;\\\/\\s]+(Venue[\\d\\s]{2,7})\\s+build\/i                      \/\/ Dell Venue Tablets\n+            \/android.+[;\\\/\\s](Venue[\\d\\s]{2,7})\\s+build\/i                       \/\/ Dell Venue Tablets\n             ], [MODEL, [VENDOR, 'Dell'], [TYPE, TABLET]], [\n \n             \/android.+[;\\\/]\\s*(Q[T|M][\\d\\w]+)\\s+build\/i                         \/\/ Verizon Tablet\n@@ -669,8 +669,8 @@\n             \/android.+[;\\\/]\\s*TU_(1491)\\s+build\/i                               \/\/ Rotor Tablets\n             ], [MODEL, [VENDOR, 'Rotor'], [TYPE, TABLET]], [\n \n-            \/android.+(KS(.+))\\s+build\/i                                        \/\/ Amazon Kindle Tablets\n-            ], [MODEL, [VENDOR, 'Amazon'], [TYPE, TABLET]], [\n+            \/\/android.+(KS(.+))\\s+build\/i                                        \/\/ Amazon Kindle Tablets\n+            \/\/], [MODEL, [VENDOR, 'Amazon'], [TYPE, TABLET]], [\n \n             \/android.+(Gigaset)[\\s\\-]+(Q\\w{1,9})\\s+build\/i                      \/\/ Gigaset Tablets\n             ], [VENDOR, MODEL, [TYPE, TABLET]], ["
    },
    {
      "index":3,
      "vuln_id":"GHSA-f8m6-h2c7-8h9x",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/nltk\/nltk\/commit\/1405aad979c6b8080dbbc8e0858f89b2e3690341'}",
      "dataset":"osv",
      "summary":"Inefficient Regular Expression Complexity in nltk (word_tokenize, sent_tokenize) ### Impact\nThe vulnerability is present in [`PunktSentenceTokenizer`](https:\/\/www.nltk.org\/api\/nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer), [`sent_tokenize`](https:\/\/www.nltk.org\/api\/nltk.tokenize.html#nltk.tokenize.sent_tokenize)  and [`word_tokenize`](https:\/\/www.nltk.org\/api\/nltk.tokenize.html#nltk.tokenize.word_tokenize). Any users of this class, or these two functions, are vulnerable to a Regular Expression Denial of Service (ReDoS) attack. \nIn short, a specifically crafted long input to any of these vulnerable functions will cause them to take a significant amount of execution time. The effect of this vulnerability is noticeable with the following example:\n```python\nfrom nltk.tokenize import word_tokenize\n\nn = 8\nfor length in [10**i for i in range(2, n)]:\n    # Prepare a malicious input\n    text = \"a\" * length\n    start_t = time.time()\n    # Call `word_tokenize` and naively measure the execution time\n    word_tokenize(text)\n    print(f\"A length of {length:<{n}} takes {time.time() - start_t:.4f}s\")\n```\nWhich gave the following output during testing:\n```python\nA length of 100      takes 0.0060s\nA length of 1000     takes 0.0060s\nA length of 10000    takes 0.6320s\nA length of 100000   takes 56.3322s\n...\n```\nI canceled the execution of the program after running it for several hours.\n\nIf your program relies on any of the vulnerable functions for tokenizing unpredictable user input, then we would strongly recommend upgrading to a version of NLTK without the vulnerability, or applying the workaround described below.\n\n### Patches\nThe problem has been patched in NLTK 3.6.6. After the fix, running the above program gives the following result:\n```python\nA length of 100      takes 0.0070s\nA length of 1000     takes 0.0010s\nA length of 10000    takes 0.0060s\nA length of 100000   takes 0.0400s\nA length of 1000000  takes 0.3520s\nA length of 10000000 takes 3.4641s\n```\nThis output shows a linear relationship in execution time versus input length, which is desirable for regular expressions.\nWe recommend updating to NLTK 3.6.6+ if possible.\n\n### Workarounds\nThe execution time of the vulnerable functions is exponential to the length of a malicious input. With other words, the execution time can be bounded by limiting the maximum length of an input to any of the vulnerable functions. Our recommendation is to implement such a limit.\n\n### References\n* The issue showcasing the vulnerability: https:\/\/github.com\/nltk\/nltk\/issues\/2866\n* The pull request containing considerably more information on the vulnerability, and the fix: https:\/\/github.com\/nltk\/nltk\/pull\/2869\n* The commit containing the fix: 1405aad979c6b8080dbbc8e0858f89b2e3690341\n* Information on CWE-1333: Inefficient Regular Expression Complexity: https:\/\/cwe.mitre.org\/data\/definitions\/1333.html\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [github.com\/nltk\/nltk](https:\/\/github.com\/nltk\/nltk)\n* Email us at [nltk.team@gmail.com](mailto:nltk.team@gmail.com)",
      "published_date":"2022-01-06",
      "chain_len":1,
      "project":"https:\/\/github.com\/nltk\/nltk",
      "commit_href":"https:\/\/github.com\/nltk\/nltk\/commit\/1405aad979c6b8080dbbc8e0858f89b2e3690341",
      "commit_sha":"1405aad979c6b8080dbbc8e0858f89b2e3690341",
      "patch":"SINGLE",
      "chain_ord":"['1405aad979c6b8080dbbc8e0858f89b2e3690341']",
      "before_first_fix_commit":"{'0b7b076247ec41f9b6b8a94400d48ea299e4b507'}",
      "last_fix_commit":"1405aad979c6b8080dbbc8e0858f89b2e3690341",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/26\/2021, 11:58:19",
      "message":"Resolved serious ReDoS in PunktSentenceTokenizer (#2869)\n\n* Resolved serious ReDOS in PunktSentenceTokenizer\r\n\r\n* Improve performance by relying on string split instead of re.search\r\n\r\n* Solved issue if sentence contains just one token",
      "author":"Tom Aarsen",
      "comments":null,
      "stats":"{'additions': 61, 'deletions': 5, 'total': 66}",
      "files":"{'nltk\/tokenize\/punkt.py': {'additions': 61, 'deletions': 5, 'changes': 66, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nltk\/nltk\/raw\/1405aad979c6b8080dbbc8e0858f89b2e3690341\/nltk%2Ftokenize%2Fpunkt.py', 'patch': '@@ -266,7 +266,6 @@ def word_tokenize(self, s):\\n         return self._word_tokenizer_re().findall(s)\\n \\n     _period_context_fmt = r\"\"\"\\n-        \\\\S*                          # some word material\\n         %(SentEndChars)s             # a potential sentence ending\\n         (?=(?P<after_tok>\\n             %(NonWord)s              # either other punctuation\\n@@ -1284,8 +1283,7 @@ def debug_decisions(self, text):\\n         See format_debug_decision() to help make this output readable.\\n         \"\"\"\\n \\n-        for match in self._lang_vars.period_context_re().finditer(text):\\n-            decision_text = match.group() + match.group(\"after_tok\")\\n+        for match, decision_text in self._match_potential_end_contexts(text):\\n             tokens = self._tokenize_words(decision_text)\\n             tokens = list(self._annotate_first_pass(tokens))\\n             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars):\\n@@ -1333,10 +1331,68 @@ def sentences_from_text(self, text, realign_boundaries=True):\\n         \"\"\"\\n         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\\n \\n+    def _match_potential_end_contexts(self, text):\\n+        \"\"\"\\n+        Given a text, find the matches of potential sentence breaks,\\n+        alongside the contexts surrounding these sentence breaks.\\n+\\n+        Since the fix for the ReDOS discovered in issue #2866, we no longer match\\n+        the word before a potential end of sentence token. Instead, we use a separate\\n+        regex for this. As a consequence, `finditer`\\'s desire to find non-overlapping\\n+        matches no longer aids us in finding the single longest match.\\n+        Where previously, we could use::\\n+\\n+            >>> pst = PunktSentenceTokenizer()\\n+            >>> text = \"Very bad acting!!! I promise.\"\\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP\\n+            [<re.Match object; span=(9, 18), match=\\'acting!!!\\'>]\\n+\\n+        Now we have to find the word before (i.e. \\'acting\\') separately, and `finditer`\\n+        returns::\\n+\\n+            >>> pst = PunktSentenceTokenizer()\\n+            >>> text = \"Very bad acting!!! I promise.\"\\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE\\n+            [<re.Match object; span=(15, 16), match=\\'!\\'>,\\n+            <re.Match object; span=(16, 17), match=\\'!\\'>,\\n+            <re.Match object; span=(17, 18), match=\\'!\\'>]\\n+\\n+        So, we need to find the word before the match from right to left, and then manually remove\\n+        the overlaps. That is what this method does::\\n+\\n+            >>> pst = PunktSentenceTokenizer()\\n+            >>> text = \"Very bad acting!!! I promise.\"\\n+            >>> pst._match_potential_end_contexts(text)\\n+            [(<re.Match object; span=(17, 18), match=\\'!\\'>, \\'acting!!! I\\')]\\n+\\n+        :param text: String of one or more sentences\\n+        :type text: str\\n+        :return: List of match-context tuples.\\n+        :rtype: List[Tuple[re.Match, str]]\\n+        \"\"\"\\n+        before_words = {}\\n+        matches = []\\n+        for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):\\n+            # Ignore matches that have already been captured by matches to the right of this match\\n+            if matches and match.end() > before_start:\\n+                continue\\n+            # Find the word before the current match\\n+            split = text[: match.start()].rsplit(maxsplit=1)\\n+            before_start = len(split[0]) if len(split) == 2 else 0\\n+            before_words[match] = split[-1]\\n+            matches.append(match)\\n+\\n+        return [\\n+            (\\n+                match,\\n+                before_words[match] + match.group() + match.group(\"after_tok\"),\\n+            )\\n+            for match in matches[::-1]\\n+        ]\\n+\\n     def _slices_from_text(self, text):\\n         last_break = 0\\n-        for match in self._lang_vars.period_context_re().finditer(text):\\n-            context = match.group() + match.group(\"after_tok\")\\n+        for match, context in self._match_potential_end_contexts(text):\\n             if self.text_contains_sentbreak(context):\\n                 yield slice(last_break, match.end())\\n                 if match.group(\"next_tok\"):'}}",
      "message_norm":"resolved serious redos in punktsentencetokenizer (#2869)\n\n* resolved serious redos in punktsentencetokenizer\r\n\r\n* improve performance by relying on string split instead of re.search\r\n\r\n* solved issue if sentence contains just one token",
      "language":"en",
      "entities":"[('redos', 'SECWORD', ''), ('#2869', 'ISSUE', ''), ('redos', 'SECWORD', ''), ('improve', 'ACTION', ''), ('issue', 'FLAW', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['nltk\/tokenize\/punkt.py'])",
      "num_files":1.0,
      "patch_content":"From 1405aad979c6b8080dbbc8e0858f89b2e3690341 Mon Sep 17 00:00:00 2001\nFrom: Tom Aarsen <37621491+tomaarsen@users.noreply.github.com>\nDate: Fri, 26 Nov 2021 12:58:19 +0100\nSubject: [PATCH] Resolved serious ReDoS in PunktSentenceTokenizer (#2869)\n\n* Resolved serious ReDOS in PunktSentenceTokenizer\n\n* Improve performance by relying on string split instead of re.search\n\n* Solved issue if sentence contains just one token\n---\n nltk\/tokenize\/punkt.py | 66 ++++++++++++++++++++++++++++++++++++++----\n 1 file changed, 61 insertions(+), 5 deletions(-)\n\ndiff --git a\/nltk\/tokenize\/punkt.py b\/nltk\/tokenize\/punkt.py\nindex a08ff4c903..54937b9ecd 100644\n--- a\/nltk\/tokenize\/punkt.py\n+++ b\/nltk\/tokenize\/punkt.py\n@@ -266,7 +266,6 @@ def word_tokenize(self, s):\n         return self._word_tokenizer_re().findall(s)\n \n     _period_context_fmt = r\"\"\"\n-        \\S*                          # some word material\n         %(SentEndChars)s             # a potential sentence ending\n         (?=(?P<after_tok>\n             %(NonWord)s              # either other punctuation\n@@ -1284,8 +1283,7 @@ def debug_decisions(self, text):\n         See format_debug_decision() to help make this output readable.\n         \"\"\"\n \n-        for match in self._lang_vars.period_context_re().finditer(text):\n-            decision_text = match.group() + match.group(\"after_tok\")\n+        for match, decision_text in self._match_potential_end_contexts(text):\n             tokens = self._tokenize_words(decision_text)\n             tokens = list(self._annotate_first_pass(tokens))\n             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars):\n@@ -1333,10 +1331,68 @@ def sentences_from_text(self, text, realign_boundaries=True):\n         \"\"\"\n         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n \n+    def _match_potential_end_contexts(self, text):\n+        \"\"\"\n+        Given a text, find the matches of potential sentence breaks,\n+        alongside the contexts surrounding these sentence breaks.\n+\n+        Since the fix for the ReDOS discovered in issue #2866, we no longer match\n+        the word before a potential end of sentence token. Instead, we use a separate\n+        regex for this. As a consequence, `finditer`'s desire to find non-overlapping\n+        matches no longer aids us in finding the single longest match.\n+        Where previously, we could use::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP\n+            [<re.Match object; span=(9, 18), match='acting!!!'>]\n+\n+        Now we have to find the word before (i.e. 'acting') separately, and `finditer`\n+        returns::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE\n+            [<re.Match object; span=(15, 16), match='!'>,\n+            <re.Match object; span=(16, 17), match='!'>,\n+            <re.Match object; span=(17, 18), match='!'>]\n+\n+        So, we need to find the word before the match from right to left, and then manually remove\n+        the overlaps. That is what this method does::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> pst._match_potential_end_contexts(text)\n+            [(<re.Match object; span=(17, 18), match='!'>, 'acting!!! I')]\n+\n+        :param text: String of one or more sentences\n+        :type text: str\n+        :return: List of match-context tuples.\n+        :rtype: List[Tuple[re.Match, str]]\n+        \"\"\"\n+        before_words = {}\n+        matches = []\n+        for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):\n+            # Ignore matches that have already been captured by matches to the right of this match\n+            if matches and match.end() > before_start:\n+                continue\n+            # Find the word before the current match\n+            split = text[: match.start()].rsplit(maxsplit=1)\n+            before_start = len(split[0]) if len(split) == 2 else 0\n+            before_words[match] = split[-1]\n+            matches.append(match)\n+\n+        return [\n+            (\n+                match,\n+                before_words[match] + match.group() + match.group(\"after_tok\"),\n+            )\n+            for match in matches[::-1]\n+        ]\n+\n     def _slices_from_text(self, text):\n         last_break = 0\n-        for match in self._lang_vars.period_context_re().finditer(text):\n-            context = match.group() + match.group(\"after_tok\")\n+        for match, context in self._match_potential_end_contexts(text):\n             if self.text_contains_sentbreak(context):\n                 yield slice(last_break, match.end())\n                 if match.group(\"next_tok\"):",
      "code_diff":"@@ -266,7 +266,6 @@ def word_tokenize(self, s):\n         return self._word_tokenizer_re().findall(s)\n \n     _period_context_fmt = r\"\"\"\n-        \\S*                          # some word material\n         %(SentEndChars)s             # a potential sentence ending\n         (?=(?P<after_tok>\n             %(NonWord)s              # either other punctuation\n@@ -1284,8 +1283,7 @@ def debug_decisions(self, text):\n         See format_debug_decision() to help make this output readable.\n         \"\"\"\n \n-        for match in self._lang_vars.period_context_re().finditer(text):\n-            decision_text = match.group() + match.group(\"after_tok\")\n+        for match, decision_text in self._match_potential_end_contexts(text):\n             tokens = self._tokenize_words(decision_text)\n             tokens = list(self._annotate_first_pass(tokens))\n             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars):\n@@ -1333,10 +1331,68 @@ def sentences_from_text(self, text, realign_boundaries=True):\n         \"\"\"\n         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n \n+    def _match_potential_end_contexts(self, text):\n+        \"\"\"\n+        Given a text, find the matches of potential sentence breaks,\n+        alongside the contexts surrounding these sentence breaks.\n+\n+        Since the fix for the ReDOS discovered in issue #2866, we no longer match\n+        the word before a potential end of sentence token. Instead, we use a separate\n+        regex for this. As a consequence, `finditer`'s desire to find non-overlapping\n+        matches no longer aids us in finding the single longest match.\n+        Where previously, we could use::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP\n+            [<re.Match object; span=(9, 18), match='acting!!!'>]\n+\n+        Now we have to find the word before (i.e. 'acting') separately, and `finditer`\n+        returns::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE\n+            [<re.Match object; span=(15, 16), match='!'>,\n+            <re.Match object; span=(16, 17), match='!'>,\n+            <re.Match object; span=(17, 18), match='!'>]\n+\n+        So, we need to find the word before the match from right to left, and then manually remove\n+        the overlaps. That is what this method does::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> pst._match_potential_end_contexts(text)\n+            [(<re.Match object; span=(17, 18), match='!'>, 'acting!!! I')]\n+\n+        :param text: String of one or more sentences\n+        :type text: str\n+        :return: List of match-context tuples.\n+        :rtype: List[Tuple[re.Match, str]]\n+        \"\"\"\n+        before_words = {}\n+        matches = []\n+        for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):\n+            # Ignore matches that have already been captured by matches to the right of this match\n+            if matches and match.end() > before_start:\n+                continue\n+            # Find the word before the current match\n+            split = text[: match.start()].rsplit(maxsplit=1)\n+            before_start = len(split[0]) if len(split) == 2 else 0\n+            before_words[match] = split[-1]\n+            matches.append(match)\n+\n+        return [\n+            (\n+                match,\n+                before_words[match] + match.group() + match.group(\"after_tok\"),\n+            )\n+            for match in matches[::-1]\n+        ]\n+\n     def _slices_from_text(self, text):\n         last_break = 0\n-        for match in self._lang_vars.period_context_re().finditer(text):\n-            context = match.group() + match.group(\"after_tok\")\n+        for match, context in self._match_potential_end_contexts(text):\n             if self.text_contains_sentbreak(context):\n                 yield slice(last_break, match.end())\n                 if match.group(\"next_tok\"):"
    },
    {
      "index":4,
      "vuln_id":"GHSA-hf44-3mx6-vhhw",
      "cwe_id":"{'CWE-400'}",
      "score":6.5,
      "chain":"{'https:\/\/github.com\/graphhopper\/graphhopper\/commit\/eb189be1fa7443ebf4ae881e737a18f818c95f41'}",
      "dataset":"osv",
      "summary":"Navigate endpoint is vulnerable to regex injection that may lead to Denial of Service. ### Impact\nThe regex injection that may lead to Denial of Service.\n\n### Patches\nWill be patched in 2.4 and 3.0\n\n### Workarounds\nVersions lower than 2.x are only affected if the navigation module is added\n\n### References\nSee this pull request for the fix: https:\/\/github.com\/graphhopper\/graphhopper\/pull\/2304\n\nIf you have any questions or comments about this advisory please [send us an Email](https:\/\/www.graphhopper.com\/contact-form\/) or create a topic [here](https:\/\/discuss.graphhopper.com\/).",
      "published_date":"2021-05-19",
      "chain_len":1,
      "project":"https:\/\/github.com\/graphhopper\/graphhopper",
      "commit_href":"https:\/\/github.com\/graphhopper\/graphhopper\/commit\/eb189be1fa7443ebf4ae881e737a18f818c95f41",
      "commit_sha":"eb189be1fa7443ebf4ae881e737a18f818c95f41",
      "patch":"SINGLE",
      "chain_ord":"['eb189be1fa7443ebf4ae881e737a18f818c95f41']",
      "before_first_fix_commit":"{'744f0e2535355e67aefbb6906303332b8aff0a7f'}",
      "last_fix_commit":"eb189be1fa7443ebf4ae881e737a18f818c95f41",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/04\/2021, 18:03:31",
      "message":"avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexOf\r\n\r\n* make check stricter\r\n\r\n* use @easbar's suggestion",
      "author":"Peter",
      "comments":null,
      "stats":"{'additions': 3, 'deletions': 5, 'total': 8}",
      "files":"{'navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java': {'additions': 3, 'deletions': 5, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/graphhopper\/graphhopper\/raw\/eb189be1fa7443ebf4ae881e737a18f818c95f41\/navigation%2Fsrc%2Fmain%2Fjava%2Fcom%2Fgraphhopper%2Fnavigation%2FNavigateResource.java', 'patch': '@@ -188,13 +188,11 @@ private GHResponse calcRoute(List<Double> favoredHeadings, List<GHPoint> request\\n      * The url looks like: \"...\/{profile}\/1.522438,42.504606;1.527209,42.504776;1.526113,42.505144;1.527218,42.50529?..\"\\n      *\/\\n     private List<GHPoint> getPointsFromRequest(HttpServletRequest httpServletRequest, String profile) {\\n-\\n         String url = httpServletRequest.getRequestURI();\\n-        url = url.replaceFirst(\"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\", \"\");\\n-        url = url.replaceAll(\"\\\\\\\\?[*]\", \"\");\\n-\\n+        String urlStart = \"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\";\\n+        if (!url.startsWith(urlStart)) throw new IllegalArgumentException(\"Incorrect URL \" + url);\\n+        url = url.substring(urlStart.length());\\n         String[] pointStrings = url.split(\";\");\\n-\\n         List<GHPoint> points = new ArrayList<>(pointStrings.length);\\n         for (int i = 0; i < pointStrings.length; i++) {\\n             points.add(GHPoint.fromStringLonLat(pointStrings[i]));'}}",
      "message_norm":"avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexof\r\n\r\n* make check stricter\r\n\r\n* use @easbar's suggestion",
      "language":"en",
      "entities":"[('#2304', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java'])",
      "num_files":1.0,
      "patch_content":"From eb189be1fa7443ebf4ae881e737a18f818c95f41 Mon Sep 17 00:00:00 2001\nFrom: Peter <graphhopper@gmx.de>\nDate: Tue, 4 May 2021 20:03:31 +0200\nSubject: [PATCH] avoid regex in navigate module (#2304)\n\n* replace two regexs with one indexOf\n\n* make check stricter\n\n* use @easbar's suggestion\n---\n ...\/java\/com\/graphhopper\/navigation\/NavigateResource.java | 8 +++-----\n 1 file changed, 3 insertions(+), 5 deletions(-)\n\ndiff --git a\/navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java b\/navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java\nindex 75c61c5f3b8..66880307cba 100644\n--- a\/navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java\n+++ b\/navigation\/src\/main\/java\/com\/graphhopper\/navigation\/NavigateResource.java\n@@ -188,13 +188,11 @@ private GHResponse calcRoute(List<Double> favoredHeadings, List<GHPoint> request\n      * The url looks like: \"...\/{profile}\/1.522438,42.504606;1.527209,42.504776;1.526113,42.505144;1.527218,42.50529?..\"\n      *\/\n     private List<GHPoint> getPointsFromRequest(HttpServletRequest httpServletRequest, String profile) {\n-\n         String url = httpServletRequest.getRequestURI();\n-        url = url.replaceFirst(\"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\", \"\");\n-        url = url.replaceAll(\"\\\\?[*]\", \"\");\n-\n+        String urlStart = \"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\";\n+        if (!url.startsWith(urlStart)) throw new IllegalArgumentException(\"Incorrect URL \" + url);\n+        url = url.substring(urlStart.length());\n         String[] pointStrings = url.split(\";\");\n-\n         List<GHPoint> points = new ArrayList<>(pointStrings.length);\n         for (int i = 0; i < pointStrings.length; i++) {\n             points.add(GHPoint.fromStringLonLat(pointStrings[i]));",
      "code_diff":"@@ -188,13 +188,11 @@ private GHResponse calcRoute(List<Double> favoredHeadings, List<GHPoint> request\n      * The url looks like: \"...\/{profile}\/1.522438,42.504606;1.527209,42.504776;1.526113,42.505144;1.527218,42.50529?..\"\n      *\/\n     private List<GHPoint> getPointsFromRequest(HttpServletRequest httpServletRequest, String profile) {\n-\n         String url = httpServletRequest.getRequestURI();\n-        url = url.replaceFirst(\"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\", \"\");\n-        url = url.replaceAll(\"\\\\?[*]\", \"\");\n-\n+        String urlStart = \"\/navigate\/directions\/v5\/gh\/\" + profile + \"\/\";\n+        if (!url.startsWith(urlStart)) throw new IllegalArgumentException(\"Incorrect URL \" + url);\n+        url = url.substring(urlStart.length());\n         String[] pointStrings = url.split(\";\");\n-\n         List<GHPoint> points = new ArrayList<>(pointStrings.length);\n         for (int i = 0; i < pointStrings.length; i++) {\n             points.add(GHPoint.fromStringLonLat(pointStrings[i]));"
    },
    {
      "index":5,
      "vuln_id":"GHSA-hp68-xhvj-x6j6",
      "cwe_id":"{'CWE-400'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/yhatt\/jsx-slack\/commit\/46bc88391d89d5fda4ce689e18ca080bcdd29ecc'}",
      "dataset":"osv",
      "summary":"jsx-slack insufficient patch for CVE-2021-43838 ReDoS We found the patch for CVE-2021-43838 in jsx-slack v4.5.1 is insufficient to save from Regular Expression Denial of Service (ReDoS) attack.\n\nThis vulnerability affects to jsx-slack v4.5.1 and earlier versions.\n\n### Impact\n\nIf attacker can put a lot of JSX elements into `<blockquote>` tag _with including multibyte characters_, an internal regular expression for escaping characters may consume an excessive amount of computing resources.\n\n```javascript\n\/** @jsxImportSource jsx-slack *\/\nimport { Section } from 'jsx-slack'\n\nconsole.log(\n  <Section>\n    <blockquote>\n      {[...Array(40)].map(() => (\n        <p>\u4e9c<\/p>\n      ))}\n    <\/blockquote>\n  <\/Section>\n)\n```\n\nv4.5.1 has released by passing the test against ASCII characters but missed the case of multibyte characters.\nhttps:\/\/github.com\/yhatt\/jsx-slack\/security\/advisories\/GHSA-55xv-f85c-248q\n\n### Patches\n\njsx-slack v4.5.2 has updated regular expressions for escaping blockquote characters to prevent catastrophic backtracking. It is also including an updated test case to confirm rendering multiple tags in `<blockquote>` with multibyte characters.\n\n### References\n\n- https:\/\/github.com\/yhatt\/jsx-slack\/commit\/46bc88391d89d5fda4ce689e18ca080bcdd29ecc\n\n### Credits\n\nThanks to @hieki for finding out this vulnerability.",
      "published_date":"2022-01-06",
      "chain_len":1,
      "project":"https:\/\/github.com\/yhatt\/jsx-slack",
      "commit_href":"https:\/\/github.com\/yhatt\/jsx-slack\/commit\/46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
      "commit_sha":"46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
      "patch":"SINGLE",
      "chain_ord":"['46bc88391d89d5fda4ce689e18ca080bcdd29ecc']",
      "before_first_fix_commit":"{'c3722705c8aadf544f922a974883578aa27dbea3'}",
      "last_fix_commit":"46bc88391d89d5fda4ce689e18ca080bcdd29ecc",
      "chain_ord_pos":1.0,
      "commit_datetime":"12\/18\/2021, 07:03:24",
      "message":"Prevent catastrophic backtracking in blockquote escape replacer",
      "author":"Yuki Hattori",
      "comments":null,
      "stats":"{'additions': 7, 'deletions': 6, 'total': 13}",
      "files":"{'src\/mrkdwn\/escape.ts': {'additions': 7, 'deletions': 6, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/yhatt\/jsx-slack\/raw\/46bc88391d89d5fda4ce689e18ca080bcdd29ecc\/src%2Fmrkdwn%2Fescape.ts', 'patch': '@@ -1,20 +1,21 @@\\n \/\/ An internal HTML tag and emoji shorthand should not escape\\n const preventEscapeRegex =\\n-  \/(<.*?>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b\\'\\\\u1100-\\\\u11ff\\\\u2e80-\\\\u2fd5\\\\u3005\\\\u3041-\\\\u3096\\\\u30a0-\\\\u30ff\\\\u3130-\\\\u318f\\\\u3400-\\\\u4db5\\\\u4e00-\\\\u9fcb\\\\ua960-\\\\ua97f\\\\uac00-\\\\ud7ff\\\\uff10-\\\\uff19\\\\uff41-\\\\uff5a\\\\uff61-\\\\uff9f]+:)\/\\n+  \/(<[^>]*>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b\\'\\\\u1100-\\\\u11ff\\\\u2e80-\\\\u2fd5\\\\u3005\\\\u3041-\\\\u3096\\\\u30a0-\\\\u30ff\\\\u3130-\\\\u318f\\\\u3400-\\\\u4db5\\\\u4e00-\\\\u9fcb\\\\ua960-\\\\ua97f\\\\uac00-\\\\ud7ff\\\\uff10-\\\\uff19\\\\uff41-\\\\uff5a\\\\uff61-\\\\uff9f]+:)\/\\n \\n const generateReplacerForEscape = (fallback: string) => (matched: string) =>\\n   `<span data-escape=\"${fallback.repeat(matched.length)}\">${matched}<\/span>`\\n \\n export const escapeReplacers = {\\n   blockquote: (partial: string) =>\\n     partial\\n-      .replace(\/^((?:<.*?>)*)(.{4})\/gm, (matched, leading, character) =>\\n-        character === \\'&gt;\\' ? `${leading}\\\\u00ad&gt;` : matched\\n+      .replace(\\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(&gt;)\/gm,\\n+        (_, leadingTags, character) => `${leadingTags}\\\\u00ad${character}`\\n       )\\n       .replace(\\n-        \/^((?:<.*?>)*)(\uff1e)\/gm,\\n-        (_, leading, character) =>\\n-          `${leading}${generateReplacerForEscape(\\'\\\\u00ad\uff1e\\')(character)}`\\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(\uff1e)\/gm,\\n+        (_, leadingTags, character) =>\\n+          `${leadingTags}${generateReplacerForEscape(\\'\\\\u00ad\uff1e\\')(character)}`\\n       ),\\n   bold: (partial: string) =>\\n     partial'}}",
      "message_norm":"prevent catastrophic backtracking in blockquote escape replacer",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('escape', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/mrkdwn\/escape.ts'])",
      "num_files":1.0,
      "patch_content":"From 46bc88391d89d5fda4ce689e18ca080bcdd29ecc Mon Sep 17 00:00:00 2001\nFrom: Yuki Hattori <yukihattori1116@gmail.com>\nDate: Sat, 18 Dec 2021 16:03:24 +0900\nSubject: [PATCH] Prevent catastrophic backtracking in blockquote escape\n replacer\n\n---\n src\/mrkdwn\/escape.ts | 13 +++++++------\n 1 file changed, 7 insertions(+), 6 deletions(-)\n\ndiff --git a\/src\/mrkdwn\/escape.ts b\/src\/mrkdwn\/escape.ts\nindex 5702c5f..abb2491 100644\n--- a\/src\/mrkdwn\/escape.ts\n+++ b\/src\/mrkdwn\/escape.ts\n@@ -1,6 +1,6 @@\n \/\/ An internal HTML tag and emoji shorthand should not escape\n const preventEscapeRegex =\n-  \/(<.*?>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b'\\u1100-\\u11ff\\u2e80-\\u2fd5\\u3005\\u3041-\\u3096\\u30a0-\\u30ff\\u3130-\\u318f\\u3400-\\u4db5\\u4e00-\\u9fcb\\ua960-\\ua97f\\uac00-\\ud7ff\\uff10-\\uff19\\uff41-\\uff5a\\uff61-\\uff9f]+:)\/\n+  \/(<[^>]*>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b'\\u1100-\\u11ff\\u2e80-\\u2fd5\\u3005\\u3041-\\u3096\\u30a0-\\u30ff\\u3130-\\u318f\\u3400-\\u4db5\\u4e00-\\u9fcb\\ua960-\\ua97f\\uac00-\\ud7ff\\uff10-\\uff19\\uff41-\\uff5a\\uff61-\\uff9f]+:)\/\n \n const generateReplacerForEscape = (fallback: string) => (matched: string) =>\n   `<span data-escape=\"${fallback.repeat(matched.length)}\">${matched}<\/span>`\n@@ -8,13 +8,14 @@ const generateReplacerForEscape = (fallback: string) => (matched: string) =>\n export const escapeReplacers = {\n   blockquote: (partial: string) =>\n     partial\n-      .replace(\/^((?:<.*?>)*)(.{4})\/gm, (matched, leading, character) =>\n-        character === '&gt;' ? `${leading}\\u00ad&gt;` : matched\n+      .replace(\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(&gt;)\/gm,\n+        (_, leadingTags, character) => `${leadingTags}\\u00ad${character}`\n       )\n       .replace(\n-        \/^((?:<.*?>)*)(\uff1e)\/gm,\n-        (_, leading, character) =>\n-          `${leading}${generateReplacerForEscape('\\u00ad\uff1e')(character)}`\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(\uff1e)\/gm,\n+        (_, leadingTags, character) =>\n+          `${leadingTags}${generateReplacerForEscape('\\u00ad\uff1e')(character)}`\n       ),\n   bold: (partial: string) =>\n     partial",
      "code_diff":"@@ -1,6 +1,6 @@\n \/\/ An internal HTML tag and emoji shorthand should not escape\n const preventEscapeRegex =\n-  \/(<.*?>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b'\\u1100-\\u11ff\\u2e80-\\u2fd5\\u3005\\u3041-\\u3096\\u30a0-\\u30ff\\u3130-\\u318f\\u3400-\\u4db5\\u4e00-\\u9fcb\\ua960-\\ua97f\\uac00-\\ud7ff\\uff10-\\uff19\\uff41-\\uff5a\\uff61-\\uff9f]+:)\/\n+  \/(<[^>]*>|:[-a-z0-9\u00c0\u00c1\u00c2\u00c3\u00c4\u00c7\u00c8\u00c9\u00ca\u00cb\u00cd\u00ce\u00cf\u00d1\u00d3\u00d4\u00d5\u00d6\u0152\u0153\u00d9\u00da\u00db\u00dc\u0178\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e7\u00e8\u00e9\u00ea\u00eb\u00ed\u00ee\u00ef\u00f1\u00f3\u00f4\u00f5\u00f6\u00f9\u00fa\u00fb\u00fc\u00ff_\uff3f+\uff0b'\\u1100-\\u11ff\\u2e80-\\u2fd5\\u3005\\u3041-\\u3096\\u30a0-\\u30ff\\u3130-\\u318f\\u3400-\\u4db5\\u4e00-\\u9fcb\\ua960-\\ua97f\\uac00-\\ud7ff\\uff10-\\uff19\\uff41-\\uff5a\\uff61-\\uff9f]+:)\/\n \n const generateReplacerForEscape = (fallback: string) => (matched: string) =>\n   `<span data-escape=\"${fallback.repeat(matched.length)}\">${matched}<\/span>`\n@@ -8,13 +8,14 @@ const generateReplacerForEscape = (fallback: string) => (matched: string) =>\n export const escapeReplacers = {\n   blockquote: (partial: string) =>\n     partial\n-      .replace(\/^((?:<.*?>)*)(.{4})\/gm, (matched, leading, character) =>\n-        character === '&gt;' ? `${leading}\\u00ad&gt;` : matched\n+      .replace(\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(&gt;)\/gm,\n+        (_, leadingTags, character) => `${leadingTags}\\u00ad${character}`\n       )\n       .replace(\n-        \/^((?:<.*?>)*)(\uff1e)\/gm,\n-        (_, leading, character) =>\n-          `${leading}${generateReplacerForEscape('\\u00ad\uff1e')(character)}`\n+        \/^((?:<(?:[^>]|>(?=<))*>)?)(\uff1e)\/gm,\n+        (_, leadingTags, character) =>\n+          `${leadingTags}${generateReplacerForEscape('\\u00ad\uff1e')(character)}`\n       ),\n   bold: (partial: string) =>\n     partial"
    },
    {
      "index":6,
      "vuln_id":"GHSA-43f8-2h32-f4cj",
      "cwe_id":"{'CWE-400'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/npm\/hosted-git-info\/commit\/bede0dc38e1785e732bf0a48ba6f81a4a908eba3', 'https:\/\/github.com\/npm\/hosted-git-info\/commit\/8d4b3697d79bcd89cdb36d1db165e3696c783a01', 'https:\/\/github.com\/npm\/hosted-git-info\/commit\/29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in hosted-git-info The npm package `hosted-git-info` before 3.0.8 are vulnerable to Regular Expression Denial of Service (ReDoS) via regular expression shortcutMatch in the fromUrl function in index.js. The affected regular expression exhibits polynomial worst-case time complexity",
      "published_date":"2021-05-06",
      "chain_len":3,
      "project":"https:\/\/github.com\/npm\/hosted-git-info",
      "commit_href":"https:\/\/github.com\/npm\/hosted-git-info\/commit\/29adfe5ef789784c861b2cdeb15051ec2ba651a7",
      "commit_sha":"29adfe5ef789784c861b2cdeb15051ec2ba651a7",
      "patch":"MULTI",
      "chain_ord":"['bede0dc38e1785e732bf0a48ba6f81a4a908eba3', '29adfe5ef789784c861b2cdeb15051ec2ba651a7', '8d4b3697d79bcd89cdb36d1db165e3696c783a01']",
      "before_first_fix_commit":"{'29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
      "last_fix_commit":"8d4b3697d79bcd89cdb36d1db165e3696c783a01",
      "chain_ord_pos":2.0,
      "commit_datetime":"04\/07\/2021, 19:31:52",
      "message":"fix: backport regex fix from #76\n\nPR-URL: https:\/\/github.com\/npm\/hosted-git-info\/pull\/84\nCredit: @nlf\nClose: #84\nReviewed-by: @wraithgar",
      "author":"nlf",
      "comments":null,
      "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
      "files":"{'index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/npm\/hosted-git-info\/raw\/29adfe5ef789784c861b2cdeb15051ec2ba651a7\/index.js', 'patch': \"@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\\n   )\\n   var parsed = parseGitUrl(url)\\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\\\/)?([^#]+)\/)\\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\\n     try {\\n       var gitHostInfo = gitHosts[gitHostName]\\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\\n       var defaultRepresentation = null\\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\\n-        project = decodeURIComponent(shortcutMatch[3])\\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\\\.git$\/, ''))\\n         defaultRepresentation = 'shortcut'\\n       } else {\\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return\"}}",
      "message_norm":"fix: backport regex fix from #76\n\npr-url: https:\/\/github.com\/npm\/hosted-git-info\/pull\/84\ncredit: @nlf\nclose: #84\nreviewed-by: @wraithgar",
      "language":"en",
      "entities":"[('#76', 'ISSUE', ''), ('https:\/\/github.com\/npm\/hosted-git-info\/pull\/84', 'URL', ''), ('#84', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['index.js'])",
      "num_files":1.0,
      "patch_content":"From 29adfe5ef789784c861b2cdeb15051ec2ba651a7 Mon Sep 17 00:00:00 2001\nFrom: nlf <quitlahok@gmail.com>\nDate: Wed, 7 Apr 2021 12:31:52 -0700\nSubject: [PATCH] fix: backport regex fix from #76\n\nPR-URL: https:\/\/github.com\/npm\/hosted-git-info\/pull\/84\nCredit: @nlf\nClose: #84\nReviewed-by: @wraithgar\n---\n index.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/index.js b\/index.js\nindex 21e53fe..0885772 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\n   )\n   var parsed = parseGitUrl(url)\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\/)?([^#]+)\/)\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\n     try {\n       var gitHostInfo = gitHosts[gitHostName]\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\n       var defaultRepresentation = null\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\n-        project = decodeURIComponent(shortcutMatch[3])\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\.git$\/, ''))\n         defaultRepresentation = 'shortcut'\n       } else {\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return",
      "code_diff":"@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\n   )\n   var parsed = parseGitUrl(url)\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\/)?([^#]+)\/)\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\n     try {\n       var gitHostInfo = gitHosts[gitHostName]\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\n       var defaultRepresentation = null\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\n-        project = decodeURIComponent(shortcutMatch[3])\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\.git$\/, ''))\n         defaultRepresentation = 'shortcut'\n       } else {\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return"
    },
    {
      "index":7,
      "vuln_id":"GHSA-247x-2f9f-5wp7",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/448a16182065bd08a202d9057dd8ca541e67996c'}",
      "dataset":"osv",
      "summary":"Stack overflow in TensorFlow ### Impact\nThe `GraphDef` format in TensorFlow does not allow self recursive functions. The runtime assumes that this invariant is satisfied. However, a `GraphDef` containing a fragment such as the following can be consumed when loading a `SavedModel`:\n\n```\n  library {\n    function {\n      signature {\n        name: \"SomeOp\"\n        description: \"Self recursive op\"\n      }\n      node_def {\n        name: \"1\"\n        op: \"SomeOp\"\n      }\n      node_def {\n        name: \"2\"\n        op: \"SomeOp\"\n      }\n    }\n  } \n```\n\nThis would result in a stack overflow during execution as resolving each `NodeDef` means resolving the function itself and its nodes.\n\n### Patches\nWe have patched the issue in GitHub commit [448a16182065bd08a202d9057dd8ca541e67996c](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/448a16182065bd08a202d9057dd8ca541e67996c).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/448a16182065bd08a202d9057dd8ca541e67996c",
      "commit_sha":"448a16182065bd08a202d9057dd8ca541e67996c",
      "patch":"SINGLE",
      "chain_ord":"['448a16182065bd08a202d9057dd8ca541e67996c']",
      "before_first_fix_commit":"{'7b1eba4193a389c7e92e01e585aeb71be97529cd'}",
      "last_fix_commit":"448a16182065bd08a202d9057dd8ca541e67996c",
      "chain_ord_pos":1.0,
      "commit_datetime":"12\/08\/2021, 00:49:32",
      "message":"Prevent stack overflow when FunctionLib in GraphDef has a self-recursive function.\n\nIt is likely that no recursivity is supported, but we should handle this separately.\n\nPiperOrigin-RevId: 414860329\nChange-Id: I02a2270e86282b37362ddd485eeef16fb986a9e0",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 18, 'deletions': 0, 'total': 18}",
      "files":"{'tensorflow\/cc\/saved_model\/loader.cc': {'additions': 18, 'deletions': 0, 'changes': 18, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/448a16182065bd08a202d9057dd8ca541e67996c\/tensorflow%2Fcc%2Fsaved_model%2Floader.cc', 'patch': '@@ -25,6 +25,7 @@ limitations under the License.\\n #include \"tensorflow\/core\/framework\/attr_value.pb.h\"\\n #include \"tensorflow\/core\/framework\/function.pb.h\"\\n #include \"tensorflow\/core\/framework\/node_def.pb.h\"\\n+#include \"tensorflow\/core\/framework\/op_def.pb.h\"\\n #include \"tensorflow\/core\/framework\/tensor.pb.h\"\\n #include \"tensorflow\/core\/lib\/io\/path.h\"\\n #include \"tensorflow\/core\/lib\/monitoring\/counter.h\"\\n@@ -99,6 +100,19 @@ static Status ValidateNode(const NodeDef& node) {\\n   return Status::OK();\\n }\\n \\n+static Status ValidateFunctionNotRecursive(const FunctionDef& function) {\\n+  const auto& function_name = function.signature().name();\\n+  for (const auto& node : function.node_def()) {\\n+    if (node.op() == function_name) {\\n+      return errors::FailedPrecondition(\\n+          \"Function \", function_name,\\n+          \" is self recursive and TensorFlow does not support this scenario.\");\\n+    }\\n+  }\\n+\\n+  return Status::OK();\\n+}\\n+\\n static Status ValidateSavedTensors(const GraphDef& graph_def) {\\n   for (const auto& node : graph_def.node()) {\\n     TF_RETURN_IF_ERROR(ValidateNode(node));\\n@@ -110,6 +124,10 @@ static Status ValidateSavedTensors(const GraphDef& graph_def) {\\n       for (const auto& node : function.node_def()) {\\n         TF_RETURN_IF_ERROR(ValidateNode(node));\\n       }\\n+\\n+      \/\/ Also check that there is no recursivity in the library\\n+      \/\/ TODO(mihaimaruseac): Do more than self-recursivity\\n+      TF_RETURN_IF_ERROR(ValidateFunctionNotRecursive(function));\\n     }\\n   }'}}",
      "message_norm":"prevent stack overflow when functionlib in graphdef has a self-recursive function.\n\nit is likely that no recursivity is supported, but we should handle this separately.\n\npiperorigin-revid: 414860329\nchange-id: i02a2270e86282b37362ddd485eeef16fb986a9e0",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('overflow', 'SECWORD', ''), ('414860329', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/cc\/saved_model\/loader.cc'])",
      "num_files":1.0,
      "patch_content":"From 448a16182065bd08a202d9057dd8ca541e67996c Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Tue, 7 Dec 2021 16:49:32 -0800\nSubject: [PATCH] Prevent stack overflow when FunctionLib in GraphDef has a\n self-recursive function.\n\nIt is likely that no recursivity is supported, but we should handle this separately.\n\nPiperOrigin-RevId: 414860329\nChange-Id: I02a2270e86282b37362ddd485eeef16fb986a9e0\n---\n tensorflow\/cc\/saved_model\/loader.cc | 18 ++++++++++++++++++\n 1 file changed, 18 insertions(+)\n\ndiff --git a\/tensorflow\/cc\/saved_model\/loader.cc b\/tensorflow\/cc\/saved_model\/loader.cc\nindex b06f2281d6a595..1022793fda08ef 100644\n--- a\/tensorflow\/cc\/saved_model\/loader.cc\n+++ b\/tensorflow\/cc\/saved_model\/loader.cc\n@@ -25,6 +25,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/attr_value.pb.h\"\n #include \"tensorflow\/core\/framework\/function.pb.h\"\n #include \"tensorflow\/core\/framework\/node_def.pb.h\"\n+#include \"tensorflow\/core\/framework\/op_def.pb.h\"\n #include \"tensorflow\/core\/framework\/tensor.pb.h\"\n #include \"tensorflow\/core\/lib\/io\/path.h\"\n #include \"tensorflow\/core\/lib\/monitoring\/counter.h\"\n@@ -99,6 +100,19 @@ static Status ValidateNode(const NodeDef& node) {\n   return Status::OK();\n }\n \n+static Status ValidateFunctionNotRecursive(const FunctionDef& function) {\n+  const auto& function_name = function.signature().name();\n+  for (const auto& node : function.node_def()) {\n+    if (node.op() == function_name) {\n+      return errors::FailedPrecondition(\n+          \"Function \", function_name,\n+          \" is self recursive and TensorFlow does not support this scenario.\");\n+    }\n+  }\n+\n+  return Status::OK();\n+}\n+\n static Status ValidateSavedTensors(const GraphDef& graph_def) {\n   for (const auto& node : graph_def.node()) {\n     TF_RETURN_IF_ERROR(ValidateNode(node));\n@@ -110,6 +124,10 @@ static Status ValidateSavedTensors(const GraphDef& graph_def) {\n       for (const auto& node : function.node_def()) {\n         TF_RETURN_IF_ERROR(ValidateNode(node));\n       }\n+\n+      \/\/ Also check that there is no recursivity in the library\n+      \/\/ TODO(mihaimaruseac): Do more than self-recursivity\n+      TF_RETURN_IF_ERROR(ValidateFunctionNotRecursive(function));\n     }\n   }",
      "code_diff":"@@ -25,6 +25,7 @@ limitations under the License.\n #include \"tensorflow\/core\/framework\/attr_value.pb.h\"\n #include \"tensorflow\/core\/framework\/function.pb.h\"\n #include \"tensorflow\/core\/framework\/node_def.pb.h\"\n+#include \"tensorflow\/core\/framework\/op_def.pb.h\"\n #include \"tensorflow\/core\/framework\/tensor.pb.h\"\n #include \"tensorflow\/core\/lib\/io\/path.h\"\n #include \"tensorflow\/core\/lib\/monitoring\/counter.h\"\n@@ -99,6 +100,19 @@ static Status ValidateNode(const NodeDef& node) {\n   return Status::OK();\n }\n \n+static Status ValidateFunctionNotRecursive(const FunctionDef& function) {\n+  const auto& function_name = function.signature().name();\n+  for (const auto& node : function.node_def()) {\n+    if (node.op() == function_name) {\n+      return errors::FailedPrecondition(\n+          \"Function \", function_name,\n+          \" is self recursive and TensorFlow does not support this scenario.\");\n+    }\n+  }\n+\n+  return Status::OK();\n+}\n+\n static Status ValidateSavedTensors(const GraphDef& graph_def) {\n   for (const auto& node : graph_def.node()) {\n     TF_RETURN_IF_ERROR(ValidateNode(node));\n@@ -110,6 +124,10 @@ static Status ValidateSavedTensors(const GraphDef& graph_def) {\n       for (const auto& node : function.node_def()) {\n         TF_RETURN_IF_ERROR(ValidateNode(node));\n       }\n+\n+      \/\/ Also check that there is no recursivity in the library\n+      \/\/ TODO(mihaimaruseac): Do more than self-recursivity\n+      TF_RETURN_IF_ERROR(ValidateFunctionNotRecursive(function));\n     }\n   }"
    },
    {
      "index":8,
      "vuln_id":"GHSA-566m-qj78-rww5",
      "cwe_id":"{'CWE-400'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/postcss\/postcss\/commit\/2b1d04c867995e55124e0a165b7c6622c1735956'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in postcss The package postcss versions before 7.0.36 or between 8.0.0 and 8.2.13 are vulnerable to Regular Expression Denial of Service (ReDoS) via getAnnotationURL() and loadAnnotation() in lib\/previous-map.js. The vulnerable regexes are caused mainly by the sub-pattern \\\/\\*\\s* sourceMappingURL=(.*).",
      "published_date":"2022-01-07",
      "chain_len":1,
      "project":"https:\/\/github.com\/postcss\/postcss",
      "commit_href":"https:\/\/github.com\/postcss\/postcss\/commit\/2b1d04c867995e55124e0a165b7c6622c1735956",
      "commit_sha":"2b1d04c867995e55124e0a165b7c6622c1735956",
      "patch":"SINGLE",
      "chain_ord":"['2b1d04c867995e55124e0a165b7c6622c1735956']",
      "before_first_fix_commit":"{'dc6cff1d7f9e0d6cba440d1b4f797a0f57b13595', '2ad1ca9b965dde32223bee28dc259c339cbaaa05'}",
      "last_fix_commit":"2b1d04c867995e55124e0a165b7c6622c1735956",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/26\/2021, 12:08:17",
      "message":"Merge pull request #1567 from yetingli\/main\n\nFix ReDoS in previous-map",
      "author":"Andrey Sitnik",
      "comments":"{'com_1': {'author': 'abergmann', 'datetime': '04\/27\/2021, 06:37:03', 'body': '[CVE-2021-23382](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-23382) was assigned to this commit.'}}",
      "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
      "files":"{'lib\/previous-map.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/postcss\/postcss\/raw\/2b1d04c867995e55124e0a165b7c6622c1735956\/lib%2Fprevious-map.js', 'patch': '@@ -48,11 +48,11 @@ class PreviousMap {\\n   }\\n \\n   getAnnotationURL(sourceMapString) {\\n-    return sourceMapString.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\*\\\\\/\/)[1].trim()\\n+    return sourceMapString.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\\\*\\\\\/\/)[1].trim()\\n   }\\n \\n   loadAnnotation(css) {\\n-    let annotations = css.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=.*\\\\*\\\\\/\/gm)\\n+    let annotations = css.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\\\*\\\\\/\/gm)\\n \\n     if (annotations && annotations.length > 0) {\\n       \/\/ Locate the last sourceMappingURL to avoid picking up'}}",
      "message_norm":"merge pull request #1567 from yetingli\/main\n\nfix redos in previous-map",
      "language":"en",
      "entities":"[('#1567', 'ISSUE', ''), ('redos', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/previous-map.js'])",
      "num_files":1.0,
      "patch_content":"From 2ad1ca9b965dde32223bee28dc259c339cbaaa05 Mon Sep 17 00:00:00 2001\nFrom: Yeting Li <liyt@ios.ac.cn>\nDate: Mon, 26 Apr 2021 14:26:52 +0800\nSubject: [PATCH] Fix ReDoS in previous-map\n\nFix Strategy: Replace `(.*)` with `(?:(?!sourceMappingURL=).)*`\n---\n lib\/previous-map.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/lib\/previous-map.js b\/lib\/previous-map.js\nindex d9308ff26..4928e1c23 100644\n--- a\/lib\/previous-map.js\n+++ b\/lib\/previous-map.js\n@@ -48,11 +48,11 @@ class PreviousMap {\n   }\n \n   getAnnotationURL(sourceMapString) {\n-    return sourceMapString.match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\*\\\/\/)[1].trim()\n+    return sourceMapString.match(\/\\\/\\*\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\*\\\/\/)[1].trim()\n   }\n \n   loadAnnotation(css) {\n-    let annotations = css.match(\/\\\/\\*\\s*# sourceMappingURL=.*\\*\\\/\/gm)\n+    let annotations = css.match(\/\\\/\\*\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\*\\\/\/gm)\n \n     if (annotations && annotations.length > 0) {\n       \/\/ Locate the last sourceMappingURL to avoid picking up",
      "code_diff":"@@ -48,11 +48,11 @@ class PreviousMap {\n   }\n \n   getAnnotationURL(sourceMapString) {\n-    return sourceMapString.match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\*\\\/\/)[1].trim()\n+    return sourceMapString.match(\/\\\/\\*\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\*\\\/\/)[1].trim()\n   }\n \n   loadAnnotation(css) {\n-    let annotations = css.match(\/\\\/\\*\\s*# sourceMappingURL=.*\\*\\\/\/gm)\n+    let annotations = css.match(\/\\\/\\*\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\*\\\/\/gm)\n \n     if (annotations && annotations.length > 0) {\n       \/\/ Locate the last sourceMappingURL to avoid picking up"
    },
    {
      "index":9,
      "vuln_id":"GHSA-97gv-3p2c-xw7j",
      "cwe_id":"{'CWE-74', 'CWE-400'}",
      "score":8.2,
      "chain":"{'https:\/\/github.com\/oliversalzburg\/i18n-node-angular\/commit\/877720d2d9bb90dc8233706e81ffa03f99fc9dc8'}",
      "dataset":"osv",
      "summary":"Denial of Service and Content Injection in i18n-node-angular Versions of `i18n-node-angular` prior to 1.4.0 are affected by denial of service and cross-site scripting vulnerabilities. The vulnerabilities exist in a REST endpoint that was created for development purposes, but was not disabled in production in affected versions.\n\n\n## Recommendation\n\nUpdate to version 1.4.0 or later.",
      "published_date":"2019-02-18",
      "chain_len":1,
      "project":"https:\/\/github.com\/oliversalzburg\/i18n-node-angular",
      "commit_href":"https:\/\/github.com\/oliversalzburg\/i18n-node-angular\/commit\/877720d2d9bb90dc8233706e81ffa03f99fc9dc8",
      "commit_sha":"877720d2d9bb90dc8233706e81ffa03f99fc9dc8",
      "patch":"SINGLE",
      "chain_ord":"['877720d2d9bb90dc8233706e81ffa03f99fc9dc8']",
      "before_first_fix_commit":"{'85ba51ac9dc47a3e232a19926791219ef9de20ee'}",
      "last_fix_commit":"877720d2d9bb90dc8233706e81ffa03f99fc9dc8",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/07\/2016, 08:40:02",
      "message":"[FIX] Only register translate route during development",
      "author":"Oliver Salzburg",
      "comments":null,
      "stats":"{'additions': 4, 'deletions': 1, 'total': 5}",
      "files":"{'i18n-node-routes.js': {'additions': 4, 'deletions': 1, 'changes': 5, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/oliversalzburg\/i18n-node-angular\/raw\/877720d2d9bb90dc8233706e81ffa03f99fc9dc8\/i18n-node-routes.js', 'patch': '@@ -49,7 +49,10 @@ var configure = function( app, configObject ) {\\n \\n \\t\/\/ Register routes\\n \\tapp.get( \"\/i18n\/:locale\", i18nRoutes.i18n );\\n-\\tapp.get( \"\/i18n\/:locale\/:phrase\", i18nRoutes.translate );\\n+\\n+\\tif( process.env.NODE_ENV === \"development\" ) {\\n+\\t\\tapp.get( \"\/i18n\/:locale\/:phrase\", i18nRoutes.translate );\\n+\\t}\\n };\\n \\n \/**'}}",
      "message_norm":"[fix] only register translate route during development",
      "language":"en",
      "entities":"[('fix', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['i18n-node-routes.js'])",
      "num_files":1.0,
      "patch_content":"From 877720d2d9bb90dc8233706e81ffa03f99fc9dc8 Mon Sep 17 00:00:00 2001\nFrom: Oliver Salzburg <oliver.salzburg@gmail.com>\nDate: Thu, 7 Jan 2016 09:40:02 +0100\nSubject: [PATCH] [FIX] Only register translate route during development\n\n---\n i18n-node-routes.js | 5 ++++-\n 1 file changed, 4 insertions(+), 1 deletion(-)\n\ndiff --git a\/i18n-node-routes.js b\/i18n-node-routes.js\nindex 0083412..cfe0b1a 100644\n--- a\/i18n-node-routes.js\n+++ b\/i18n-node-routes.js\n@@ -49,7 +49,10 @@ var configure = function( app, configObject ) {\n \n \t\/\/ Register routes\n \tapp.get( \"\/i18n\/:locale\", i18nRoutes.i18n );\n-\tapp.get( \"\/i18n\/:locale\/:phrase\", i18nRoutes.translate );\n+\n+\tif( process.env.NODE_ENV === \"development\" ) {\n+\t\tapp.get( \"\/i18n\/:locale\/:phrase\", i18nRoutes.translate );\n+\t}\n };\n \n \/**",
      "code_diff":"@@ -49,7 +49,10 @@ var configure = function( app, configObject ) {\n \n \t\/\/ Register routes\n \tapp.get( \"\/i18n\/:locale\", i18nRoutes.i18n );\n-\tapp.get( \"\/i18n\/:locale\/:phrase\", i18nRoutes.translate );\n+\n+\tif( process.env.NODE_ENV === \"development\" ) {\n+\t\tapp.get( \"\/i18n\/:locale\/:phrase\", i18nRoutes.translate );\n+\t}\n };\n \n \/**"
    },
    {
      "index":10,
      "vuln_id":"GHSA-f7r3-p866-q9qr",
      "cwe_id":"{'CWE-400'}",
      "score":3.7,
      "chain":"{'https:\/\/github.com\/Twipped\/ircdkit\/pull\/2\/commits\/595ed02cde517fad57854d2ac2855a09a626e665', 'https:\/\/github.com\/Twipped\/ircdkit\/commit\/f0cc6dc913ec17b499fa33a676bb72c624456f2c'}",
      "dataset":"osv",
      "summary":"ircdkit vulnerable to Denial of Service due to unhandled connection end event Versions of `ircdkit` 1.0.3 and prior are vulnerable to a remote denial of service.\n\n\n## Recommendation\n\nUpgrade to version 1.0.4.",
      "published_date":"2019-06-03",
      "chain_len":2,
      "project":"https:\/\/github.com\/Twipped\/ircdkit",
      "commit_href":"https:\/\/github.com\/Twipped\/ircdkit\/pull\/2\/commits\/595ed02cde517fad57854d2ac2855a09a626e665",
      "commit_sha":"595ed02cde517fad57854d2ac2855a09a626e665",
      "patch":"MULTI",
      "chain_ord":"['f0cc6dc913ec17b499fa33a676bb72c624456f2c', '595ed02cde517fad57854d2ac2855a09a626e665']",
      "before_first_fix_commit":"{'74aa751e75a90af34ef63377fcbd41285d155380'}",
      "last_fix_commit":"595ed02cde517fad57854d2ac2855a09a626e665",
      "chain_ord_pos":2.0,
      "commit_datetime":"05\/30\/2019, 03:10:50",
      "message":"Update index.js\n\ncorrected unhandled connection 'end' event, fixes issue #1",
      "author":"Trinity Fox",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'lib\/index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Twipped\/ircdkit\/raw\/595ed02cde517fad57854d2ac2855a09a626e665\/lib%2Findex.js', 'patch': \"@@ -47,7 +47,7 @@ function create (options) {\\n \\n \\t\\tclient.on('end', function () {\\n \\t\\t\\tdebug('connection ended');\\n-\\t\\t\\tremoveClient(client);\\n+\\t\\t\\tclient.close();\\n \\t\\t\\tapp.emit('connection:end', client);\\n \\t\\t});\"}}",
      "message_norm":"update index.js\n\ncorrected unhandled connection 'end' event, fixes issue #1",
      "language":"en",
      "entities":"[('update', 'ACTION', ''), ('#1', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/index.js'])",
      "num_files":1.0,
      "patch_content":"From 595ed02cde517fad57854d2ac2855a09a626e665 Mon Sep 17 00:00:00 2001\nFrom: Trinity Fox <671259+cottonflop@users.noreply.github.com>\nDate: Wed, 29 May 2019 20:10:50 -0700\nSubject: [PATCH] Update index.js\n\ncorrected unhandled connection 'end' event, fixes issue #1\n---\n lib\/index.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/index.js b\/lib\/index.js\nindex 5088eca..6349746 100644\n--- a\/lib\/index.js\n+++ b\/lib\/index.js\n@@ -47,7 +47,7 @@ function create (options) {\n \n \t\tclient.on('end', function () {\n \t\t\tdebug('connection ended');\n-\t\t\tremoveClient(client);\n+\t\t\tclient.close();\n \t\t\tapp.emit('connection:end', client);\n \t\t});",
      "code_diff":"@@ -47,7 +47,7 @@ function create (options) {\n \n \t\tclient.on('end', function () {\n \t\t\tdebug('connection ended');\n-\t\t\tremoveClient(client);\n+\t\t\tclient.close();\n \t\t\tapp.emit('connection:end', client);\n \t\t});"
    },
    {
      "index":11,
      "vuln_id":"GHSA-7q4h-pj78-j7vg",
      "cwe_id":"{'CWE-400', 'CWE-918'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/apache\/cxf\/commit\/aa789c5c4686597a7bdef2443909ab491fc2bc04', 'https:\/\/github.com\/apache\/cxf\/commit\/40503a53914758759894f704bbf139ae89ace286'}",
      "dataset":"osv",
      "summary":"Authorization service vulnerable to DDos attacks in Apache CFX CXF supports (via JwtRequestCodeFilter) passing OAuth 2 parameters via a JWT token as opposed to query parameters (see: The OAuth 2.0 Authorization Framework: JWT Secured Authorization Request (JAR)). Instead of sending a JWT token as a \"request\" parameter, the spec also supports specifying a URI from which to retrieve a JWT token from via the \"request_uri\" parameter. CXF was not validating the \"request_uri\" parameter (apart from ensuring it uses \"https) and was making a REST request to the parameter in the request to retrieve a token. This means that CXF was vulnerable to DDos attacks on the authorization server, as specified in section 10.4.1 of the spec. This issue affects Apache CXF versions prior to 3.4.3; Apache CXF versions prior to 3.3.10.",
      "published_date":"2021-05-13",
      "chain_len":2,
      "project":"https:\/\/github.com\/apache\/cxf",
      "commit_href":"https:\/\/github.com\/apache\/cxf\/commit\/aa789c5c4686597a7bdef2443909ab491fc2bc04",
      "commit_sha":"aa789c5c4686597a7bdef2443909ab491fc2bc04",
      "patch":"MULTI",
      "chain_ord":"['40503a53914758759894f704bbf139ae89ace286', 'aa789c5c4686597a7bdef2443909ab491fc2bc04']",
      "before_first_fix_commit":"{'40503a53914758759894f704bbf139ae89ace286'}",
      "last_fix_commit":"aa789c5c4686597a7bdef2443909ab491fc2bc04",
      "chain_ord_pos":2.0,
      "commit_datetime":"01\/06\/2021, 10:38:21",
      "message":"Make sure both a request + request_uri can't be specified",
      "author":"Colm O hEigeartaigh",
      "comments":null,
      "stats":"{'additions': 11, 'deletions': 1, 'total': 12}",
      "files":"{'rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java': {'additions': 11, 'deletions': 1, 'changes': 12, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/cxf\/raw\/aa789c5c4686597a7bdef2443909ab491fc2bc04\/rt%2Frs%2Fsecurity%2Foauth-parent%2Foauth2%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fcxf%2Frs%2Fsecurity%2Foauth2%2Fgrants%2Fcode%2FJwtRequestCodeFilter.java', 'patch': '@@ -21,9 +21,11 @@\\n import java.security.cert.X509Certificate;\\n import java.util.List;\\n import java.util.Map;\\n+import java.util.logging.Logger;\\n \\n import javax.ws.rs.core.MultivaluedMap;\\n \\n+import org.apache.cxf.common.logging.LogUtils;\\n import org.apache.cxf.helpers.CastUtils;\\n import org.apache.cxf.jaxrs.client.WebClient;\\n import org.apache.cxf.jaxrs.impl.MetadataMap;\\n@@ -42,23 +44,31 @@\\n import org.apache.cxf.rt.security.crypto.CryptoUtils;\\n \\n public class JwtRequestCodeFilter extends OAuthJoseJwtConsumer implements AuthorizationRequestFilter {\\n+    protected static final Logger LOG = LogUtils.getL7dLogger(JwtRequestCodeFilter.class);\\n     private static final String REQUEST_URI_CONTENT_TYPE = \"application\/oauth-authz-req+jwt\";\\n     private static final String REQUEST_PARAM = \"request\";\\n     private static final String REQUEST_URI_PARAM = \"request_uri\";\\n+\\n     private boolean verifyWithClientCertificates;\\n     private String issuer;\\n     private JsonMapObjectReaderWriter jsonHandler = new JsonMapObjectReaderWriter();\\n+\\n     @Override\\n     public MultivaluedMap<String, String> process(MultivaluedMap<String, String> params,\\n                                                   UserSubject endUser,\\n                                                   Client client) {\\n         String requestToken = params.getFirst(REQUEST_PARAM);\\n+        String requestUri = params.getFirst(REQUEST_URI_PARAM);\\n+\\n         if (requestToken == null) {\\n-            String requestUri = params.getFirst(REQUEST_URI_PARAM);\\n             if (isRequestUriValid(client, requestUri)) {\\n                 requestToken = WebClient.create(requestUri).accept(REQUEST_URI_CONTENT_TYPE).get(String.class);\\n             }\\n+        } else if (requestUri != null) {\\n+            LOG.warning(\"It is not valid to specify both a request and request_uri value\");\\n+            throw new SecurityException();\\n         }\\n+\\n         if (requestToken != null) {\\n             JweDecryptionProvider theDecryptor = super.getInitializedDecryptionProvider(client.getClientSecret());\\n             JwsSignatureVerifier theSigVerifier = getInitializedSigVerifier(client);'}}",
      "message_norm":"make sure both a request + request_uri can't be specified",
      "language":"en",
      "entities":null,
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java'])",
      "num_files":1.0,
      "patch_content":"From aa789c5c4686597a7bdef2443909ab491fc2bc04 Mon Sep 17 00:00:00 2001\nFrom: Colm O hEigeartaigh <coheigea@apache.org>\nDate: Wed, 6 Jan 2021 10:38:21 +0000\nSubject: [PATCH] Make sure both a request + request_uri can't be specified\n\n---\n ...\/oauth2\/grants\/code\/JwtRequestCodeFilter.java     | 12 +++++++++++-\n 1 file changed, 11 insertions(+), 1 deletion(-)\n\ndiff --git a\/rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java b\/rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java\nindex 29ac00020d4..15fe40b0a74 100644\n--- a\/rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java\n+++ b\/rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java\n@@ -21,9 +21,11 @@\n import java.security.cert.X509Certificate;\n import java.util.List;\n import java.util.Map;\n+import java.util.logging.Logger;\n \n import javax.ws.rs.core.MultivaluedMap;\n \n+import org.apache.cxf.common.logging.LogUtils;\n import org.apache.cxf.helpers.CastUtils;\n import org.apache.cxf.jaxrs.client.WebClient;\n import org.apache.cxf.jaxrs.impl.MetadataMap;\n@@ -42,23 +44,31 @@\n import org.apache.cxf.rt.security.crypto.CryptoUtils;\n \n public class JwtRequestCodeFilter extends OAuthJoseJwtConsumer implements AuthorizationRequestFilter {\n+    protected static final Logger LOG = LogUtils.getL7dLogger(JwtRequestCodeFilter.class);\n     private static final String REQUEST_URI_CONTENT_TYPE = \"application\/oauth-authz-req+jwt\";\n     private static final String REQUEST_PARAM = \"request\";\n     private static final String REQUEST_URI_PARAM = \"request_uri\";\n+\n     private boolean verifyWithClientCertificates;\n     private String issuer;\n     private JsonMapObjectReaderWriter jsonHandler = new JsonMapObjectReaderWriter();\n+\n     @Override\n     public MultivaluedMap<String, String> process(MultivaluedMap<String, String> params,\n                                                   UserSubject endUser,\n                                                   Client client) {\n         String requestToken = params.getFirst(REQUEST_PARAM);\n+        String requestUri = params.getFirst(REQUEST_URI_PARAM);\n+\n         if (requestToken == null) {\n-            String requestUri = params.getFirst(REQUEST_URI_PARAM);\n             if (isRequestUriValid(client, requestUri)) {\n                 requestToken = WebClient.create(requestUri).accept(REQUEST_URI_CONTENT_TYPE).get(String.class);\n             }\n+        } else if (requestUri != null) {\n+            LOG.warning(\"It is not valid to specify both a request and request_uri value\");\n+            throw new SecurityException();\n         }\n+\n         if (requestToken != null) {\n             JweDecryptionProvider theDecryptor = super.getInitializedDecryptionProvider(client.getClientSecret());\n             JwsSignatureVerifier theSigVerifier = getInitializedSigVerifier(client);",
      "code_diff":"@@ -21,9 +21,11 @@\n import java.security.cert.X509Certificate;\n import java.util.List;\n import java.util.Map;\n+import java.util.logging.Logger;\n \n import javax.ws.rs.core.MultivaluedMap;\n \n+import org.apache.cxf.common.logging.LogUtils;\n import org.apache.cxf.helpers.CastUtils;\n import org.apache.cxf.jaxrs.client.WebClient;\n import org.apache.cxf.jaxrs.impl.MetadataMap;\n@@ -42,23 +44,31 @@\n import org.apache.cxf.rt.security.crypto.CryptoUtils;\n \n public class JwtRequestCodeFilter extends OAuthJoseJwtConsumer implements AuthorizationRequestFilter {\n+    protected static final Logger LOG = LogUtils.getL7dLogger(JwtRequestCodeFilter.class);\n     private static final String REQUEST_URI_CONTENT_TYPE = \"application\/oauth-authz-req+jwt\";\n     private static final String REQUEST_PARAM = \"request\";\n     private static final String REQUEST_URI_PARAM = \"request_uri\";\n+\n     private boolean verifyWithClientCertificates;\n     private String issuer;\n     private JsonMapObjectReaderWriter jsonHandler = new JsonMapObjectReaderWriter();\n+\n     @Override\n     public MultivaluedMap<String, String> process(MultivaluedMap<String, String> params,\n                                                   UserSubject endUser,\n                                                   Client client) {\n         String requestToken = params.getFirst(REQUEST_PARAM);\n+        String requestUri = params.getFirst(REQUEST_URI_PARAM);\n+\n         if (requestToken == null) {\n-            String requestUri = params.getFirst(REQUEST_URI_PARAM);\n             if (isRequestUriValid(client, requestUri)) {\n                 requestToken = WebClient.create(requestUri).accept(REQUEST_URI_CONTENT_TYPE).get(String.class);\n             }\n+        } else if (requestUri != null) {\n+            LOG.warning(\"It is not valid to specify both a request and request_uri value\");\n+            throw new SecurityException();\n         }\n+\n         if (requestToken != null) {\n             JweDecryptionProvider theDecryptor = super.getInitializedDecryptionProvider(client.getClientSecret());\n             JwsSignatureVerifier theSigVerifier = getInitializedSigVerifier(client);"
    },
    {
      "index":12,
      "vuln_id":"GHSA-6cf8-qhqj-vjqm",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/totaljs\/framework\/commit\/b3f901561d66ab799a4a99279893b94cad7ae4ff'}",
      "dataset":"osv",
      "summary":"Prototype pollution in total.js There is a prototype pollution vulnerability in the package total.js before version 3.4.7. The set function can be used to set a value into the object according to the path. However the keys of the path being set are not properly sanitized, leading to a prototype pollution vulnerability. The impact depends on the application. In some cases it is possible to achieve Denial of service (DoS), Remote Code Execution or Property Injection.",
      "published_date":"2021-02-05",
      "chain_len":1,
      "project":"https:\/\/github.com\/totaljs\/framework",
      "commit_href":"https:\/\/github.com\/totaljs\/framework\/commit\/b3f901561d66ab799a4a99279893b94cad7ae4ff",
      "commit_sha":"b3f901561d66ab799a4a99279893b94cad7ae4ff",
      "patch":"SINGLE",
      "chain_ord":"['b3f901561d66ab799a4a99279893b94cad7ae4ff']",
      "before_first_fix_commit":"{'1e1faeb20d2291038e10b98f2046a4058135e767'}",
      "last_fix_commit":"b3f901561d66ab799a4a99279893b94cad7ae4ff",
      "chain_ord_pos":1.0,
      "commit_datetime":"12\/31\/2020, 10:41:21",
      "message":"Fixed `U.set()` by adding check for `Prototype pollution`.",
      "author":"Peter Sirka",
      "comments":null,
      "stats":"{'additions': 4, 'deletions': 0, 'total': 4}",
      "files":"{'utils.js': {'additions': 4, 'deletions': 0, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/totaljs\/framework\/raw\/b3f901561d66ab799a4a99279893b94cad7ae4ff\/utils.js', 'patch': \"@@ -6621,6 +6621,10 @@ exports.set = function(obj, path, value) {\\n \\tvar v = arr[arr.length - 1];\\n \\tvar ispush = v.lastIndexOf('[]') !== -1;\\n \\tvar a = builder.join(';') + ';var v=typeof(a)===\\\\'function\\\\'?a(U.get(b)):a;w' + (v[0] === '[' ? '' : '.') + (ispush ? v.replace(REGREPLACEARR, '.push(v)') : (v + '=v')) + ';return v';\\n+\\n+\\tif ((\/__proto__|constructor|prototype\/).test(a))\\n+\\t\\tthrow new Error('Prototype pollution');\\n+\\n \\tvar fn = new Function('w', 'a', 'b', a);\\n \\tF.temporary.other[cachekey] = fn;\\n \\tfn(obj, value, path);\"}}",
      "message_norm":"fixed `u.set()` by adding check for `prototype pollution`.",
      "language":"en",
      "entities":"[('fixed', 'ACTION', ''), ('adding', 'ACTION', ''), ('prototype pollution', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['utils.js'])",
      "num_files":1.0,
      "patch_content":"From b3f901561d66ab799a4a99279893b94cad7ae4ff Mon Sep 17 00:00:00 2001\nFrom: Peter Sirka <petersirka@gmail.com>\nDate: Thu, 31 Dec 2020 11:41:21 +0100\nSubject: [PATCH] Fixed `U.set()` by adding check for `Prototype pollution`.\n\n---\n utils.js | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a\/utils.js b\/utils.js\nindex 2b2959dd7..916954343 100755\n--- a\/utils.js\n+++ b\/utils.js\n@@ -6621,6 +6621,10 @@ exports.set = function(obj, path, value) {\n \tvar v = arr[arr.length - 1];\n \tvar ispush = v.lastIndexOf('[]') !== -1;\n \tvar a = builder.join(';') + ';var v=typeof(a)===\\'function\\'?a(U.get(b)):a;w' + (v[0] === '[' ? '' : '.') + (ispush ? v.replace(REGREPLACEARR, '.push(v)') : (v + '=v')) + ';return v';\n+\n+\tif ((\/__proto__|constructor|prototype\/).test(a))\n+\t\tthrow new Error('Prototype pollution');\n+\n \tvar fn = new Function('w', 'a', 'b', a);\n \tF.temporary.other[cachekey] = fn;\n \tfn(obj, value, path);",
      "code_diff":"@@ -6621,6 +6621,10 @@ exports.set = function(obj, path, value) {\n \tvar v = arr[arr.length - 1];\n \tvar ispush = v.lastIndexOf('[]') !== -1;\n \tvar a = builder.join(';') + ';var v=typeof(a)===\\'function\\'?a(U.get(b)):a;w' + (v[0] === '[' ? '' : '.') + (ispush ? v.replace(REGREPLACEARR, '.push(v)') : (v + '=v')) + ';return v';\n+\n+\tif ((\/__proto__|constructor|prototype\/).test(a))\n+\t\tthrow new Error('Prototype pollution');\n+\n \tvar fn = new Function('w', 'a', 'b', a);\n \tF.temporary.other[cachekey] = fn;\n \tfn(obj, value, path);"
    },
    {
      "index":13,
      "vuln_id":"GHSA-jxwx-85vp-gvwm",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/jquery-validation\/jquery-validation\/commit\/5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in jquery-validation The GitHub Security Lab team has identified potential security vulnerabilities in jquery.validation.\n\nThe project contains one or more regular expressions that are vulnerable to ReDoS (Regular Expression Denial of Service)\n\nThis issue was discovered and reported by GitHub team member @erik-krogh (Erik Krogh Kristensen).",
      "published_date":"2021-01-13",
      "chain_len":1,
      "project":"https:\/\/github.com\/jquery-validation\/jquery-validation",
      "commit_href":"https:\/\/github.com\/jquery-validation\/jquery-validation\/commit\/5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d",
      "commit_sha":"5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d",
      "patch":"SINGLE",
      "chain_ord":"['5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d']",
      "before_first_fix_commit":"{'b8d6646ec67c73372dddfbc9aadff45571a96136'}",
      "last_fix_commit":"5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/09\/2021, 15:28:00",
      "message":"Core: fixed Regular Expression Denial of Service vulnerability (#2371)\n\nReDoS, or Regular Expression Denial of Service, is a vulnerability affecting\r\npoorly constructed and potentially inefficient regular expressions which can\r\nmake them perform extremely badly given a creatively constructed input string.\r\n\r\nGHSL-2020-294\r\n\r\ncredits to @erik-krogh for reporting the issue and providing a fix",
      "author":"Markus Staab",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'src\/core.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/jquery-validation\/jquery-validation\/raw\/5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d\/src%2Fcore.js', 'patch': '@@ -1412,7 +1412,7 @@ $.extend( $.validator, {\\n \\t\\t\\t\/\/ https:\/\/gist.github.com\/dperini\/729294\\n \\t\\t\\t\/\/ see also https:\/\/mathiasbynens.be\/demo\/url-regex\\n \\t\\t\\t\/\/ modified to allow protocol-relative URLs\\n-\\t\\t\\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:\\\\S+(?::\\\\S*)?@)?(?:(?!(?:10|127)(?:\\\\.\\\\d{1,3}){3})(?!(?:169\\\\.254|192\\\\.168)(?:\\\\.\\\\d{1,3}){2})(?!172\\\\.(?:1[6-9]|2\\\\d|3[0-1])(?:\\\\.\\\\d{1,3}){2})(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)*(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,})).?)(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i.test( value );\\n+\\t\\t\\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:\\\\S+(?::\\\\S*)?@)?(?:(?!(?:10|127)(?:\\\\.\\\\d{1,3}){3})(?!(?:169\\\\.254|192\\\\.168)(?:\\\\.\\\\d{1,3}){2})(?!172\\\\.(?:1[6-9]|2\\\\d|3[0-1])(?:\\\\.\\\\d{1,3}){2})(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z0-9\\\\u00a1-\\\\uffff][a-z0-9\\\\u00a1-\\\\uffff_-]{0,62})?[a-z0-9\\\\u00a1-\\\\uffff]\\\\.)+(?:[a-z\\\\u00a1-\\\\uffff]{2,}\\\\.?))(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i.test( value );\\n \\t\\t},\\n \\n \\t\\t\/\/ https:\/\/jqueryvalidation.org\/date-method\/'}}",
      "message_norm":"core: fixed regular expression denial of service vulnerability (#2371)\n\nredos, or regular expression denial of service, is a vulnerability affecting\r\npoorly constructed and potentially inefficient regular expressions which can\r\nmake them perform extremely badly given a creatively constructed input string.\r\n\r\nghsl-2020-294\r\n\r\ncredits to @erik-krogh for reporting the issue and providing a fix",
      "language":"en",
      "entities":"[('fixed', 'ACTION', ''), ('denial of service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('#2371', 'ISSUE', ''), ('redos', 'SECWORD', ''), ('denial of service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('issue', 'FLAW', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/core.js'])",
      "num_files":1.0,
      "patch_content":"From 5d8f29eef363d043a8fec4eb86d42cadb5fa5f7d Mon Sep 17 00:00:00 2001\nFrom: Markus Staab <markus.staab@redaxo.de>\nDate: Sat, 9 Jan 2021 16:28:00 +0100\nSubject: [PATCH] Core: fixed Regular Expression Denial of Service\n vulnerability (#2371)\n\nReDoS, or Regular Expression Denial of Service, is a vulnerability affecting\npoorly constructed and potentially inefficient regular expressions which can\nmake them perform extremely badly given a creatively constructed input string.\n\nGHSL-2020-294\n\ncredits to @erik-krogh for reporting the issue and providing a fix\n---\n src\/core.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/core.js b\/src\/core.js\nindex 4674710f4..afcdbe820 100644\n--- a\/src\/core.js\n+++ b\/src\/core.js\n@@ -1412,7 +1412,7 @@ $.extend( $.validator, {\n \t\t\t\/\/ https:\/\/gist.github.com\/dperini\/729294\n \t\t\t\/\/ see also https:\/\/mathiasbynens.be\/demo\/url-regex\n \t\t\t\/\/ modified to allow protocol-relative URLs\n-\t\t\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:\\S+(?::\\S*)?@)?(?:(?!(?:10|127)(?:\\.\\d{1,3}){3})(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*(?:\\.(?:[a-z\\u00a1-\\uffff]{2,})).?)(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test( value );\n+\t\t\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:\\S+(?::\\S*)?@)?(?:(?!(?:10|127)(?:\\.\\d{1,3}){3})(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z0-9\\u00a1-\\uffff][a-z0-9\\u00a1-\\uffff_-]{0,62})?[a-z0-9\\u00a1-\\uffff]\\.)+(?:[a-z\\u00a1-\\uffff]{2,}\\.?))(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test( value );\n \t\t},\n \n \t\t\/\/ https:\/\/jqueryvalidation.org\/date-method\/",
      "code_diff":"@@ -1412,7 +1412,7 @@ $.extend( $.validator, {\n \t\t\t\/\/ https:\/\/gist.github.com\/dperini\/729294\n \t\t\t\/\/ see also https:\/\/mathiasbynens.be\/demo\/url-regex\n \t\t\t\/\/ modified to allow protocol-relative URLs\n-\t\t\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:\\S+(?::\\S*)?@)?(?:(?!(?:10|127)(?:\\.\\d{1,3}){3})(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*(?:\\.(?:[a-z\\u00a1-\\uffff]{2,})).?)(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test( value );\n+\t\t\treturn this.optional( element ) || \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:\\S+(?::\\S*)?@)?(?:(?!(?:10|127)(?:\\.\\d{1,3}){3})(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z0-9\\u00a1-\\uffff][a-z0-9\\u00a1-\\uffff_-]{0,62})?[a-z0-9\\u00a1-\\uffff]\\.)+(?:[a-z\\u00a1-\\uffff]{2,}\\.?))(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test( value );\n \t\t},\n \n \t\t\/\/ https:\/\/jqueryvalidation.org\/date-method\/"
    },
    {
      "index":14,
      "vuln_id":"GHSA-9hx2-hgq2-2g4f",
      "cwe_id":"{'CWE-400'}",
      "score":6.5,
      "chain":"{'https:\/\/github.com\/python-pillow\/Pillow\/commit\/6207b44ab1ff4a91d8ddc7579619876d0bb191a4', 'https:\/\/github.com\/python-pillow\/Pillow\/commit\/3bce145966374dd39ce58a6fc0083f8d1890719c'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service (ReDoS) in Pillow An issue was discovered in Pillow before 8.1.1. The PDF parser allows a regular expression DoS (ReDoS) attack via a crafted PDF file because of a catastrophic backtracking regex.",
      "published_date":"2021-03-29",
      "chain_len":2,
      "project":"https:\/\/github.com\/python-pillow\/Pillow",
      "commit_href":"https:\/\/github.com\/python-pillow\/Pillow\/commit\/3bce145966374dd39ce58a6fc0083f8d1890719c",
      "commit_sha":"3bce145966374dd39ce58a6fc0083f8d1890719c",
      "patch":"MULTI",
      "chain_ord":"['6207b44ab1ff4a91d8ddc7579619876d0bb191a4', '3bce145966374dd39ce58a6fc0083f8d1890719c']",
      "before_first_fix_commit":"{'cbdce6c5d054fccaf4af34b47f212355c64ace7a'}",
      "last_fix_commit":"3bce145966374dd39ce58a6fc0083f8d1890719c",
      "chain_ord_pos":2.0,
      "commit_datetime":"01\/09\/2021, 13:53:09",
      "message":"Use more specific regex chars to prevent ReDoS\n\n* CVE-2021-25292",
      "author":"Hugo van Kemenade",
      "comments":null,
      "stats":"{'additions': 2, 'deletions': 1, 'total': 3}",
      "files":"{'src\/PIL\/PdfParser.py': {'additions': 2, 'deletions': 1, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/python-pillow\/Pillow\/raw\/3bce145966374dd39ce58a6fc0083f8d1890719c\/src%2FPIL%2FPdfParser.py', 'patch': '@@ -580,8 +580,9 @@ def next_object_id(self, offset=None):\\n     whitespace_or_hex = br\"[\\\\000\\\\011\\\\012\\\\014\\\\015\\\\0400-9a-fA-F]\"\\n     whitespace_optional = whitespace + b\"*\"\\n     whitespace_mandatory = whitespace + b\"+\"\\n+    whitespace_optional_no_nl = br\"[\\\\000\\\\011\\\\014\\\\015\\\\040]*\"  # no \"\\\\012\" aka \"\\\\n\"\\n     newline_only = br\"[\\\\r\\\\n]+\"\\n-    newline = whitespace_optional + newline_only + whitespace_optional\\n+    newline = whitespace_optional_no_nl + newline_only + whitespace_optional_no_nl\\n     re_trailer_end = re.compile(\\n         whitespace_mandatory\\n         + br\"trailer\"'}}",
      "message_norm":"use more specific regex chars to prevent redos\n\n* cve-2021-25292",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('redos', 'SECWORD', ''), ('cve-2021-25292', 'VULNID', 'CVE')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/PIL\/PdfParser.py'])",
      "num_files":1.0,
      "patch_content":"From 3bce145966374dd39ce58a6fc0083f8d1890719c Mon Sep 17 00:00:00 2001\nFrom: Hugo van Kemenade <hugovk@users.noreply.github.com>\nDate: Sat, 9 Jan 2021 15:53:09 +0200\nSubject: [PATCH] Use more specific regex chars to prevent ReDoS\n\n* CVE-2021-25292\n---\n src\/PIL\/PdfParser.py | 3 ++-\n 1 file changed, 2 insertions(+), 1 deletion(-)\n\ndiff --git a\/src\/PIL\/PdfParser.py b\/src\/PIL\/PdfParser.py\nindex 975905f9693..86d78a95c2b 100644\n--- a\/src\/PIL\/PdfParser.py\n+++ b\/src\/PIL\/PdfParser.py\n@@ -580,8 +580,9 @@ def next_object_id(self, offset=None):\n     whitespace_or_hex = br\"[\\000\\011\\012\\014\\015\\0400-9a-fA-F]\"\n     whitespace_optional = whitespace + b\"*\"\n     whitespace_mandatory = whitespace + b\"+\"\n+    whitespace_optional_no_nl = br\"[\\000\\011\\014\\015\\040]*\"  # no \"\\012\" aka \"\\n\"\n     newline_only = br\"[\\r\\n]+\"\n-    newline = whitespace_optional + newline_only + whitespace_optional\n+    newline = whitespace_optional_no_nl + newline_only + whitespace_optional_no_nl\n     re_trailer_end = re.compile(\n         whitespace_mandatory\n         + br\"trailer\"",
      "code_diff":"@@ -580,8 +580,9 @@ def next_object_id(self, offset=None):\n     whitespace_or_hex = br\"[\\000\\011\\012\\014\\015\\0400-9a-fA-F]\"\n     whitespace_optional = whitespace + b\"*\"\n     whitespace_mandatory = whitespace + b\"+\"\n+    whitespace_optional_no_nl = br\"[\\000\\011\\014\\015\\040]*\"  # no \"\\012\" aka \"\\n\"\n     newline_only = br\"[\\r\\n]+\"\n-    newline = whitespace_optional + newline_only + whitespace_optional\n+    newline = whitespace_optional_no_nl + newline_only + whitespace_optional_no_nl\n     re_trailer_end = re.compile(\n         whitespace_mandatory\n         + br\"trailer\""
    },
    {
      "index":15,
      "vuln_id":"GHSA-rc8h-3fv6-pxv8",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/hapijs\/hapi\/commit\/aab2496e930dce5ee1ab28eecec94e0e45f03580'}",
      "dataset":"osv",
      "summary":"Denial of Service in hapi Versions of `hapi` prior to 11.1.3 are affected by a denial of service vulnerability.\n\nThe vulnerability is triggered when certain input is passed into the If-Modified-Since or Last-Modified headers.\n\nThis causes an 'illegal access' exception to be raised, and instead of sending a HTTP 500 error back to the sender, hapi will continue to hold the socket open until timed out (default node timeout is 2 minutes).\n\n\n\n\n\n## Recommendation\n\nUpdate to v11.1.3 or later",
      "published_date":"2018-06-07",
      "chain_len":1,
      "project":"https:\/\/github.com\/hapijs\/hapi",
      "commit_href":"https:\/\/github.com\/hapijs\/hapi\/commit\/aab2496e930dce5ee1ab28eecec94e0e45f03580",
      "commit_sha":"aab2496e930dce5ee1ab28eecec94e0e45f03580",
      "patch":"SINGLE",
      "chain_ord":"['aab2496e930dce5ee1ab28eecec94e0e45f03580']",
      "before_first_fix_commit":"{'1ad65ba793377928aa5a2dfc819888c5c9793394', 'ef2a0f85d558eeb102c512fac45386b2145cb903'}",
      "last_fix_commit":"aab2496e930dce5ee1ab28eecec94e0e45f03580",
      "chain_ord_pos":1.0,
      "commit_datetime":"12\/23\/2015, 21:54:47",
      "message":"Merge pull request #2988 from hapijs\/v11.1.x\n\nHandle invalid date exceptions",
      "author":"Eran Hammer",
      "comments":null,
      "stats":"{'additions': 11, 'deletions': 2, 'total': 13}",
      "files":"{'lib\/transmit.js': {'additions': 11, 'deletions': 2, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/hapijs\/hapi\/raw\/aab2496e930dce5ee1ab28eecec94e0e45f03580\/lib%2Ftransmit.js', 'patch': '@@ -82,8 +82,8 @@ internals.marshal = function (request, next) {\\n \\n                 \/\/ Weak verifier\\n \\n-                const ifModifiedSince = Date.parse(ifModifiedSinceHeader);\\n-                const lastModified = Date.parse(lastModifiedHeader);\\n+                const ifModifiedSince = internals.parseDate(ifModifiedSinceHeader);\\n+                const lastModified = internals.parseDate(lastModifiedHeader);\\n \\n                 if (ifModifiedSince &&\\n                     lastModified &&\\n@@ -147,6 +147,15 @@ internals.marshal = function (request, next) {\\n };\\n \\n \\n+internals.parseDate = function (string) {\\n+\\n+    try {\\n+        return Date.parse(string);\\n+    }\\n+    catch (errIgnore) { }\\n+};\\n+\\n+\\n internals.fail = function (request, boom, callback) {\\n \\n     const error = boom.output;'}}",
      "message_norm":"merge pull request #2988 from hapijs\/v11.1.x\n\nhandle invalid date exceptions",
      "language":"en",
      "entities":"[('#2988', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/transmit.js'])",
      "num_files":1.0,
      "patch_content":"From 14ca827cb6501b88a5452054f429a92ee3fe0b6e Mon Sep 17 00:00:00 2001\nFrom: Eran Hammer <eran@hammer.io>\nDate: Wed, 23 Dec 2015 13:51:44 -0800\nSubject: [PATCH 1\/3] Handle invalid date exceptions. Closes #2987\n\n---\n lib\/transmit.js     | 13 +++++++++++--\n npm-shrinkwrap.json |  2 +-\n package.json        |  2 +-\n 3 files changed, 13 insertions(+), 4 deletions(-)\n\ndiff --git a\/lib\/transmit.js b\/lib\/transmit.js\nindex 5ab2d0d48..d4ee1f5fd 100755\n--- a\/lib\/transmit.js\n+++ b\/lib\/transmit.js\n@@ -82,8 +82,8 @@ internals.marshal = function (request, next) {\n \n                 \/\/ Weak verifier\n \n-                const ifModifiedSince = Date.parse(ifModifiedSinceHeader);\n-                const lastModified = Date.parse(lastModifiedHeader);\n+                const ifModifiedSince = internals.parseDate(ifModifiedSinceHeader);\n+                const lastModified = internals.parseDate(lastModifiedHeader);\n \n                 if (ifModifiedSince &&\n                     lastModified &&\n@@ -147,6 +147,15 @@ internals.marshal = function (request, next) {\n };\n \n \n+internals.parseDate = function (string) {\n+\n+    try {\n+        return Date.parse(string);\n+    }\n+    catch (errIgnore) { }\n+};\n+\n+\n internals.fail = function (request, boom, callback) {\n \n     const error = boom.output;\ndiff --git a\/npm-shrinkwrap.json b\/npm-shrinkwrap.json\nindex 1e611ff2d..fa06071ff 100755\n--- a\/npm-shrinkwrap.json\n+++ b\/npm-shrinkwrap.json\n@@ -1,6 +1,6 @@\n {\n     \"name\": \"hapi\",\n-    \"version\": \"11.1.1\",\n+    \"version\": \"11.1.3\",\n     \"dependencies\": {\n         \"accept\": {\n             \"version\": \"2.0.0\"\ndiff --git a\/package.json b\/package.json\nindex a67947141..776b696b5 100755\n--- a\/package.json\n+++ b\/package.json\n@@ -2,7 +2,7 @@\n   \"name\": \"hapi\",\n   \"description\": \"HTTP Server framework\",\n   \"homepage\": \"http:\/\/hapijs.com\",\n-  \"version\": \"11.1.2\",\n+  \"version\": \"11.1.3\",\n   \"repository\": {\n     \"type\": \"git\",\n     \"url\": \"git:\/\/github.com\/hapijs\/hapi\"\n\nFrom 9f328465611dd81f7dc40b065eb34d5f04f9c8e1 Mon Sep 17 00:00:00 2001\nFrom: Eran Hammer <eran@hammer.io>\nDate: Wed, 23 Dec 2015 13:54:29 -0800\nSubject: [PATCH 2\/3] Update npm-shrinkwrap.json\n\n---\n npm-shrinkwrap.json | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/npm-shrinkwrap.json b\/npm-shrinkwrap.json\nindex fa06071ff..1e611ff2d 100755\n--- a\/npm-shrinkwrap.json\n+++ b\/npm-shrinkwrap.json\n@@ -1,6 +1,6 @@\n {\n     \"name\": \"hapi\",\n-    \"version\": \"11.1.3\",\n+    \"version\": \"11.1.1\",\n     \"dependencies\": {\n         \"accept\": {\n             \"version\": \"2.0.0\"\n\nFrom ef2a0f85d558eeb102c512fac45386b2145cb903 Mon Sep 17 00:00:00 2001\nFrom: Eran Hammer <eran@hammer.io>\nDate: Wed, 23 Dec 2015 13:54:39 -0800\nSubject: [PATCH 3\/3] Update package.json\n\n---\n package.json | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/package.json b\/package.json\nindex 776b696b5..a67947141 100755\n--- a\/package.json\n+++ b\/package.json\n@@ -2,7 +2,7 @@\n   \"name\": \"hapi\",\n   \"description\": \"HTTP Server framework\",\n   \"homepage\": \"http:\/\/hapijs.com\",\n-  \"version\": \"11.1.3\",\n+  \"version\": \"11.1.2\",\n   \"repository\": {\n     \"type\": \"git\",\n     \"url\": \"git:\/\/github.com\/hapijs\/hapi\"",
      "code_diff":"@@ -82,8 +82,8 @@ internals.marshal = function (request, next) {\n \n                 \/\/ Weak verifier\n \n-                const ifModifiedSince = Date.parse(ifModifiedSinceHeader);\n-                const lastModified = Date.parse(lastModifiedHeader);\n+                const ifModifiedSince = internals.parseDate(ifModifiedSinceHeader);\n+                const lastModified = internals.parseDate(lastModifiedHeader);\n \n                 if (ifModifiedSince &&\n                     lastModified &&\n@@ -147,6 +147,15 @@ internals.marshal = function (request, next) {\n };\n \n \n+internals.parseDate = function (string) {\n+\n+    try {\n+        return Date.parse(string);\n+    }\n+    catch (errIgnore) { }\n+};\n+\n+\n internals.fail = function (request, boom, callback) {\n \n     const error = boom.output;\n@@ -1,6 +1,6 @@\n {\n     \"name\": \"hapi\",\n-    \"version\": \"11.1.1\",\n+    \"version\": \"11.1.3\",\n     \"dependencies\": {\n         \"accept\": {\n             \"version\": \"2.0.0\"\n@@ -2,7 +2,7 @@\n   \"name\": \"hapi\",\n   \"description\": \"HTTP Server framework\",\n   \"homepage\": \"http:\/\/hapijs.com\",\n-  \"version\": \"11.1.2\",\n+  \"version\": \"11.1.3\",\n   \"repository\": {\n     \"type\": \"git\",\n     \"url\": \"git:\/\/github.com\/hapijs\/hapi\"\n\nFrom: Eran Hammer <eran@hammer.io>\n\n npm-shrinkwrap.json | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\n@@ -1,6 +1,6 @@\n {\n     \"name\": \"hapi\",\n-    \"version\": \"11.1.3\",\n+    \"version\": \"11.1.1\",\n     \"dependencies\": {\n         \"accept\": {\n             \"version\": \"2.0.0\"\n\nFrom: Eran Hammer <eran@hammer.io>\n\n package.json | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\n@@ -2,7 +2,7 @@\n   \"name\": \"hapi\",\n   \"description\": \"HTTP Server framework\",\n   \"homepage\": \"http:\/\/hapijs.com\",\n-  \"version\": \"11.1.3\",\n+  \"version\": \"11.1.2\",\n   \"repository\": {\n     \"type\": \"git\",\n     \"url\": \"git:\/\/github.com\/hapijs\/hapi\""
    },
    {
      "index":16,
      "vuln_id":"GHSA-f7r3-p866-q9qr",
      "cwe_id":"{'CWE-400'}",
      "score":3.7,
      "chain":"{'https:\/\/github.com\/Twipped\/ircdkit\/pull\/2\/commits\/595ed02cde517fad57854d2ac2855a09a626e665', 'https:\/\/github.com\/Twipped\/ircdkit\/commit\/f0cc6dc913ec17b499fa33a676bb72c624456f2c'}",
      "dataset":"osv",
      "summary":"ircdkit vulnerable to Denial of Service due to unhandled connection end event Versions of `ircdkit` 1.0.3 and prior are vulnerable to a remote denial of service.\n\n\n## Recommendation\n\nUpgrade to version 1.0.4.",
      "published_date":"2019-06-03",
      "chain_len":2,
      "project":"https:\/\/github.com\/Twipped\/ircdkit",
      "commit_href":"https:\/\/github.com\/Twipped\/ircdkit\/commit\/f0cc6dc913ec17b499fa33a676bb72c624456f2c",
      "commit_sha":"f0cc6dc913ec17b499fa33a676bb72c624456f2c",
      "patch":"MULTI",
      "chain_ord":"['f0cc6dc913ec17b499fa33a676bb72c624456f2c', '595ed02cde517fad57854d2ac2855a09a626e665']",
      "before_first_fix_commit":"{'74aa751e75a90af34ef63377fcbd41285d155380'}",
      "last_fix_commit":"595ed02cde517fad57854d2ac2855a09a626e665",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/30\/2019, 03:09:45",
      "message":"DOS fix\n\ncorrected unhandled connection 'end' event, fixes issue #1",
      "author":"Trinity Fox",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'lib\/index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Twipped\/ircdkit\/raw\/f0cc6dc913ec17b499fa33a676bb72c624456f2c\/lib%2Findex.js', 'patch': \"@@ -47,7 +47,7 @@ function create (options) {\\n \\n \\t\\tclient.on('end', function () {\\n \\t\\t\\tdebug('connection ended');\\n-\\t\\t\\tremoveClient(client);\\n+\\t\\t\\tclient.close();\\n \\t\\t\\tapp.emit('connection:end', client);\\n \\t\\t});\"}}",
      "message_norm":"dos fix\n\ncorrected unhandled connection 'end' event, fixes issue #1",
      "language":"en",
      "entities":"[('dos', 'SECWORD', ''), ('fix', 'ACTION', ''), ('#1', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/index.js'])",
      "num_files":1.0,
      "patch_content":"From f0cc6dc913ec17b499fa33a676bb72c624456f2c Mon Sep 17 00:00:00 2001\nFrom: Trinity Fox <671259+cottonflop@users.noreply.github.com>\nDate: Wed, 29 May 2019 20:09:45 -0700\nSubject: [PATCH] DOS fix\n\ncorrected unhandled connection 'end' event, fixes issue #1\n---\n lib\/index.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/index.js b\/lib\/index.js\nindex 5088eca..6349746 100644\n--- a\/lib\/index.js\n+++ b\/lib\/index.js\n@@ -47,7 +47,7 @@ function create (options) {\n \n \t\tclient.on('end', function () {\n \t\t\tdebug('connection ended');\n-\t\t\tremoveClient(client);\n+\t\t\tclient.close();\n \t\t\tapp.emit('connection:end', client);\n \t\t});",
      "code_diff":"@@ -47,7 +47,7 @@ function create (options) {\n \n \t\tclient.on('end', function () {\n \t\t\tdebug('connection ended');\n-\t\t\tremoveClient(client);\n+\t\t\tclient.close();\n \t\t\tapp.emit('connection:end', client);\n \t\t});"
    },
    {
      "index":17,
      "vuln_id":"GHSA-p55x-7x9v-q8m4",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/miekg\/dns\/commit\/43913f2f4fbd7dcff930b8a809e709591e4dd79e'}",
      "dataset":"osv",
      "summary":"Denial of Service in miekg-dns A denial of service flaw was found in miekg-dns before 1.0.4. A remote attacker could use carefully timed TCP packets to block the DNS server from accepting new connections.",
      "published_date":"2021-06-29",
      "chain_len":1,
      "project":"https:\/\/github.com\/miekg\/dns",
      "commit_href":"https:\/\/github.com\/miekg\/dns\/commit\/43913f2f4fbd7dcff930b8a809e709591e4dd79e",
      "commit_sha":"43913f2f4fbd7dcff930b8a809e709591e4dd79e",
      "patch":"SINGLE",
      "chain_ord":"['43913f2f4fbd7dcff930b8a809e709591e4dd79e']",
      "before_first_fix_commit":"{'862243b3b1e77ca9f73771fc95a7148d11cebb55'}",
      "last_fix_commit":"43913f2f4fbd7dcff930b8a809e709591e4dd79e",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/25\/2018, 10:36:19",
      "message":"Fix for CVE-2017-15133 TCP DOS (#631)\n\nserveTCP calls reader.ReadTCP in the accept loop rather than in\r\nthe per-connection goroutine. If an attacker opens a connection\r\nand leaves it idle, this will block the accept loop until the\r\nconnection times out (2s by default). During this time no other\r\nincoming connections will succeed, preventing legitimate queries\r\nfrom being answered.\r\n\r\nThis commit moves the call to reader.ReadTCP into the per-connection\r\ngoroutine. It also adds a missing call to Close whose absence allowed\r\nfile-descirptors to leak in select cases.\r\n\r\nThis attack and fix have no impact on serving UDP queries.",
      "author":"Miek Gieben",
      "comments":null,
      "stats":"{'additions': 8, 'deletions': 5, 'total': 13}",
      "files":"{'server.go': {'additions': 8, 'deletions': 5, 'changes': 13, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/miekg\/dns\/raw\/43913f2f4fbd7dcff930b8a809e709591e4dd79e\/server.go', 'patch': '@@ -472,11 +472,14 @@ func (srv *Server) serveTCP(l net.Listener) error {\\n \\t\\t\\t}\\n \\t\\t\\treturn err\\n \\t\\t}\\n-\\t\\tm, err := reader.ReadTCP(rw, rtimeout)\\n-\\t\\tif err != nil {\\n-\\t\\t\\tcontinue\\n-\\t\\t}\\n-\\t\\tgo srv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\\n+\\t\\tgo func() {\\n+\\t\\t\\tm, err := reader.ReadTCP(rw, rtimeout)\\n+\\t\\t\\tif err != nil {\\n+\\t\\t\\t\\trw.Close()\\n+\\t\\t\\t\\treturn\\n+\\t\\t\\t}\\n+\\t\\t\\tsrv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\\n+\\t\\t}()\\n \\t}\\n }'}}",
      "message_norm":"fix for cve-2017-15133 tcp dos (#631)\n\nservetcp calls reader.readtcp in the accept loop rather than in\r\nthe per-connection goroutine. if an attacker opens a connection\r\nand leaves it idle, this will block the accept loop until the\r\nconnection times out (2s by default). during this time no other\r\nincoming connections will succeed, preventing legitimate queries\r\nfrom being answered.\r\n\r\nthis commit moves the call to reader.readtcp into the per-connection\r\ngoroutine. it also adds a missing call to close whose absence allowed\r\nfile-descirptors to leak in select cases.\r\n\r\nthis attack and fix have no impact on serving udp queries.",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('cve-2017-15133', 'VULNID', 'CVE'), ('dos', 'SECWORD', ''), ('#631', 'ISSUE', ''), ('attacker', 'SECWORD', ''), ('preventing', 'ACTION', ''), ('adds', 'ACTION', ''), ('leak', 'SECWORD', ''), ('attack', 'FLAW', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['server.go'])",
      "num_files":1.0,
      "patch_content":"From 43913f2f4fbd7dcff930b8a809e709591e4dd79e Mon Sep 17 00:00:00 2001\nFrom: Miek Gieben <miek@miek.nl>\nDate: Thu, 25 Jan 2018 10:36:19 +0000\nSubject: [PATCH] Fix for CVE-2017-15133 TCP DOS (#631)\n\nserveTCP calls reader.ReadTCP in the accept loop rather than in\nthe per-connection goroutine. If an attacker opens a connection\nand leaves it idle, this will block the accept loop until the\nconnection times out (2s by default). During this time no other\nincoming connections will succeed, preventing legitimate queries\nfrom being answered.\n\nThis commit moves the call to reader.ReadTCP into the per-connection\ngoroutine. It also adds a missing call to Close whose absence allowed\nfile-descirptors to leak in select cases.\n\nThis attack and fix have no impact on serving UDP queries.\n---\n server.go | 13 ++++++++-----\n 1 file changed, 8 insertions(+), 5 deletions(-)\n\ndiff --git a\/server.go b\/server.go\nindex b6ce5b5f6..685753f43 100644\n--- a\/server.go\n+++ b\/server.go\n@@ -472,11 +472,14 @@ func (srv *Server) serveTCP(l net.Listener) error {\n \t\t\t}\n \t\t\treturn err\n \t\t}\n-\t\tm, err := reader.ReadTCP(rw, rtimeout)\n-\t\tif err != nil {\n-\t\t\tcontinue\n-\t\t}\n-\t\tgo srv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\n+\t\tgo func() {\n+\t\t\tm, err := reader.ReadTCP(rw, rtimeout)\n+\t\t\tif err != nil {\n+\t\t\t\trw.Close()\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\tsrv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\n+\t\t}()\n \t}\n }",
      "code_diff":"@@ -472,11 +472,14 @@ func (srv *Server) serveTCP(l net.Listener) error {\n \t\t\t}\n \t\t\treturn err\n \t\t}\n-\t\tm, err := reader.ReadTCP(rw, rtimeout)\n-\t\tif err != nil {\n-\t\t\tcontinue\n-\t\t}\n-\t\tgo srv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\n+\t\tgo func() {\n+\t\t\tm, err := reader.ReadTCP(rw, rtimeout)\n+\t\t\tif err != nil {\n+\t\t\t\trw.Close()\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\tsrv.serve(rw.RemoteAddr(), handler, m, nil, nil, rw)\n+\t\t}()\n \t}\n }"
    },
    {
      "index":18,
      "vuln_id":"GHSA-fq6p-x6j3-cmmq",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/mrdoob\/three.js\/pull\/21143\/commits\/4a582355216b620176a291ff319d740e619d583e'}",
      "dataset":"osv",
      "summary":"Denial of service in three This affects the package three before 0.125.0. This can happen when handling rgb or hsl colors. PoC: var three = require('three') function build_blank (n) { var ret = \"rgb(\" for (var i = 0; i < n; i++) { ret += \" \" } return ret + \"\"; } var Color = three.Color var time = Date.now(); new Color(build_blank(50000)) var time_cost = Date.now() - time; console.log(time_cost+\" ms\")",
      "published_date":"2021-03-01",
      "chain_len":1,
      "project":"https:\/\/github.com\/mrdoob\/three.js",
      "commit_href":"https:\/\/github.com\/mrdoob\/three.js\/pull\/21143\/commits\/4a582355216b620176a291ff319d740e619d583e",
      "commit_sha":"4a582355216b620176a291ff319d740e619d583e",
      "patch":"SINGLE",
      "chain_ord":"['4a582355216b620176a291ff319d740e619d583e']",
      "before_first_fix_commit":"{'0f5de4f5da1014f81c00d309f93b1a1e709341e4'}",
      "last_fix_commit":"4a582355216b620176a291ff319d740e619d583e",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/25\/2021, 11:45:42",
      "message":"Fix ReDoS",
      "author":"Yeting Li",
      "comments":null,
      "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
      "files":"{'src\/math\/Color.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mrdoob\/three.js\/raw\/4a582355216b620176a291ff319d740e619d583e\/src%2Fmath%2FColor.js', 'patch': \"@@ -169,14 +169,14 @@ class Color {\\n \\n \\t\\t\\tlet color;\\n \\t\\t\\tconst name = m[ 1 ];\\n-\\t\\t\\tconst components = m[ 2 ].replace(\/^\\\\s*\/, '');\\n+\\t\\t\\tconst components = m[ 2 ];\\n \\n \\t\\t\\tswitch ( name ) {\\n \\n \\t\\t\\t\\tcase 'rgb':\\n \\t\\t\\t\\tcase 'rgba':\\n \\n-\\t\\t\\t\\t\\tif ( color = \/^(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = \/^\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t\/\/ rgb(255,0,0) rgba(255,0,0,0.5)\\n \\t\\t\\t\\t\\t\\tthis.r = Math.min( 255, parseInt( color[ 1 ], 10 ) ) \/ 255;\\n@@ -189,7 +189,7 @@ class Color {\\n \\n \\t\\t\\t\\t\\t}\\n \\n-\\t\\t\\t\\t\\tif ( color = \/^(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = \/^\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t\/\/ rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\\n \\t\\t\\t\\t\\t\\tthis.r = Math.min( 100, parseInt( color[ 1 ], 10 ) ) \/ 100;\\n@@ -207,7 +207,7 @@ class Color {\\n \\t\\t\\t\\tcase 'hsl':\\n \\t\\t\\t\\tcase 'hsla':\\n \\n-\\t\\t\\t\\t\\tif ( color = \/^(\\\\d*\\\\.?\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n+\\t\\t\\t\\t\\tif ( color = \/^\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*,\\\\s*(\\\\d+)\\\\%\\\\s*(?:,\\\\s*(\\\\d*\\\\.?\\\\d+)\\\\s*)?$\/.exec( components ) ) {\\n \\n \\t\\t\\t\\t\\t\\t\/\/ hsl(120,50%,50%) hsla(120,50%,50%,0.5)\\n \\t\\t\\t\\t\\t\\tconst h = parseFloat( color[ 1 ] ) \/ 360;\"}}",
      "message_norm":"fix redos",
      "language":"pt",
      "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/math\/Color.js'])",
      "num_files":1.0,
      "patch_content":"From 4a582355216b620176a291ff319d740e619d583e Mon Sep 17 00:00:00 2001\nFrom: Yeting Li <liyt@ios.ac.cn>\nDate: Mon, 25 Jan 2021 19:45:42 +0800\nSubject: [PATCH] Fix ReDoS\n\n---\n src\/math\/Color.js | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/math\/Color.js b\/src\/math\/Color.js\nindex 7bc9a11405157b..f2ea4f82edac0b 100644\n--- a\/src\/math\/Color.js\n+++ b\/src\/math\/Color.js\n@@ -169,14 +169,14 @@ class Color {\n \n \t\t\tlet color;\n \t\t\tconst name = m[ 1 ];\n-\t\t\tconst components = m[ 2 ].replace(\/^\\s*\/, '');\n+\t\t\tconst components = m[ 2 ];\n \n \t\t\tswitch ( name ) {\n \n \t\t\t\tcase 'rgb':\n \t\t\t\tcase 'rgba':\n \n-\t\t\t\t\tif ( color = \/^(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ rgb(255,0,0) rgba(255,0,0,0.5)\n \t\t\t\t\t\tthis.r = Math.min( 255, parseInt( color[ 1 ], 10 ) ) \/ 255;\n@@ -189,7 +189,7 @@ class Color {\n \n \t\t\t\t\t}\n \n-\t\t\t\t\tif ( color = \/^(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\n \t\t\t\t\t\tthis.r = Math.min( 100, parseInt( color[ 1 ], 10 ) ) \/ 100;\n@@ -207,7 +207,7 @@ class Color {\n \t\t\t\tcase 'hsl':\n \t\t\t\tcase 'hsla':\n \n-\t\t\t\t\tif ( color = \/^(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ hsl(120,50%,50%) hsla(120,50%,50%,0.5)\n \t\t\t\t\t\tconst h = parseFloat( color[ 1 ] ) \/ 360;",
      "code_diff":"@@ -169,14 +169,14 @@ class Color {\n \n \t\t\tlet color;\n \t\t\tconst name = m[ 1 ];\n-\t\t\tconst components = m[ 2 ].replace(\/^\\s*\/, '');\n+\t\t\tconst components = m[ 2 ];\n \n \t\t\tswitch ( name ) {\n \n \t\t\t\tcase 'rgb':\n \t\t\t\tcase 'rgba':\n \n-\t\t\t\t\tif ( color = \/^(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ rgb(255,0,0) rgba(255,0,0,0.5)\n \t\t\t\t\t\tthis.r = Math.min( 255, parseInt( color[ 1 ], 10 ) ) \/ 255;\n@@ -189,7 +189,7 @@ class Color {\n \n \t\t\t\t\t}\n \n-\t\t\t\t\tif ( color = \/^(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\n \t\t\t\t\t\tthis.r = Math.min( 100, parseInt( color[ 1 ], 10 ) ) \/ 100;\n@@ -207,7 +207,7 @@ class Color {\n \t\t\t\tcase 'hsl':\n \t\t\t\tcase 'hsla':\n \n-\t\t\t\t\tif ( color = \/^(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n+\t\t\t\t\tif ( color = \/^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$\/.exec( components ) ) {\n \n \t\t\t\t\t\t\/\/ hsl(120,50%,50%) hsla(120,50%,50%,0.5)\n \t\t\t\t\t\tconst h = parseFloat( color[ 1 ] ) \/ 360;"
    },
    {
      "index":19,
      "vuln_id":"GHSA-7f53-fmmv-mfjv",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/facebook\/react-native\/commit\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7'}",
      "dataset":"osv",
      "summary":"Regular expression denial of service in react-native A regular expression denial of service (ReDoS) vulnerability in the validateBaseUrl function can cause the application to use excessive resources, become unresponsive, or crash. This was introduced in react-native version 0.59.0 and fixed in version 0.64.1.",
      "published_date":"2021-07-20",
      "chain_len":1,
      "project":"https:\/\/github.com\/facebook\/react-native",
      "commit_href":"https:\/\/github.com\/facebook\/react-native\/commit\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
      "commit_sha":"ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
      "patch":"SINGLE",
      "chain_ord":"['ca09ae82715e33c9ac77b3fa55495cf84ba891c7']",
      "before_first_fix_commit":"{'166a5ddf88aca0d0235e48c624681eec095e9ef8'}",
      "last_fix_commit":"ca09ae82715e33c9ac77b3fa55495cf84ba891c7",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/29\/2021, 21:51:29",
      "message":"Update validateBaseUrl to use latest regex\n\nSummary:\nUpdating the regex to avoid a potential regular expression denial-of-service vulnerability.\n\nChangelog: Update validateBaseUrl to use a more robust regular expression. Fixes CVE-2020-1920, GHSL-2020-293\n\nReviewed By: lunaleaps\n\nDifferential Revision: D25507604\n\nfbshipit-source-id: c36a03c456881bc655c861e1a2c5cd41a7127c9d",
      "author":"Neal Poole",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'Libraries\/Blob\/URL.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/facebook\/react-native\/raw\/ca09ae82715e33c9ac77b3fa55495cf84ba891c7\/Libraries%2FBlob%2FURL.js', 'patch': '@@ -107,7 +107,7 @@ export class URLSearchParams {\\n \\n function validateBaseUrl(url: string) {\\n   \/\/ from this MIT-licensed gist: https:\/\/gist.github.com\/dperini\/729294\\n-  return \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]-*)*[a-z\\\\u00a1-\\\\uffff0-9]+)*(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,}))?)(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/i.test(\\n+  return \/^(?:(?:(?:https?|ftp):)?\\\\\/\\\\\/)(?:(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[1-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z0-9\\\\u00a1-\\\\uffff][a-z0-9\\\\u00a1-\\\\uffff_-]{0,62})?[a-z0-9\\\\u00a1-\\\\uffff]\\\\.)*(?:[a-z\\\\u00a1-\\\\uffff]{2,}\\\\.?))(?::\\\\d{2,5})?(?:[\/?#]\\\\S*)?$\/.test(\\n     url,\\n   );\\n }'}}",
      "message_norm":"update validatebaseurl to use latest regex\n\nsummary:\nupdating the regex to avoid a potential regular expression denial-of-service vulnerability.\n\nchangelog: update validatebaseurl to use a more robust regular expression. fixes cve-2020-1920, ghsl-2020-293\n\nreviewed by: lunaleaps\n\ndifferential revision: d25507604\n\nfbshipit-source-id: c36a03c456881bc655c861e1a2c5cd41a7127c9d",
      "language":"en",
      "entities":"[('update', 'ACTION', ''), ('updating', 'ACTION', ''), ('denial-of-service', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('update', 'ACTION', ''), ('cve-2020-1920', 'VULNID', 'CVE'), ('d25507604', 'SHA', 'generic_sha'), ('c36a03c456881bc655c861e1a2c5cd41a7127c9d', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['Libraries\/Blob\/URL.js'])",
      "num_files":1.0,
      "patch_content":"From ca09ae82715e33c9ac77b3fa55495cf84ba891c7 Mon Sep 17 00:00:00 2001\nFrom: Neal Poole <neal@fb.com>\nDate: Thu, 29 Apr 2021 14:51:29 -0700\nSubject: [PATCH] Update validateBaseUrl to use latest regex\n\nSummary:\nUpdating the regex to avoid a potential regular expression denial-of-service vulnerability.\n\nChangelog: Update validateBaseUrl to use a more robust regular expression. Fixes CVE-2020-1920, GHSL-2020-293\n\nReviewed By: lunaleaps\n\nDifferential Revision: D25507604\n\nfbshipit-source-id: c36a03c456881bc655c861e1a2c5cd41a7127c9d\n---\n Libraries\/Blob\/URL.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/Libraries\/Blob\/URL.js b\/Libraries\/Blob\/URL.js\nindex f2b6f7f277cb7e..df186f36de1ac4 100644\n--- a\/Libraries\/Blob\/URL.js\n+++ b\/Libraries\/Blob\/URL.js\n@@ -107,7 +107,7 @@ export class URLSearchParams {\n \n function validateBaseUrl(url: string) {\n   \/\/ from this MIT-licensed gist: https:\/\/gist.github.com\/dperini\/729294\n-  return \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*(?:\\.(?:[a-z\\u00a1-\\uffff]{2,}))?)(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test(\n+  return \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z0-9\\u00a1-\\uffff][a-z0-9\\u00a1-\\uffff_-]{0,62})?[a-z0-9\\u00a1-\\uffff]\\.)*(?:[a-z\\u00a1-\\uffff]{2,}\\.?))(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/.test(\n     url,\n   );\n }",
      "code_diff":"@@ -107,7 +107,7 @@ export class URLSearchParams {\n \n function validateBaseUrl(url: string) {\n   \/\/ from this MIT-licensed gist: https:\/\/gist.github.com\/dperini\/729294\n-  return \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)(?:\\.(?:[a-z\\u00a1-\\uffff0-9]-*)*[a-z\\u00a1-\\uffff0-9]+)*(?:\\.(?:[a-z\\u00a1-\\uffff]{2,}))?)(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/i.test(\n+  return \/^(?:(?:(?:https?|ftp):)?\\\/\\\/)(?:(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z0-9\\u00a1-\\uffff][a-z0-9\\u00a1-\\uffff_-]{0,62})?[a-z0-9\\u00a1-\\uffff]\\.)*(?:[a-z\\u00a1-\\uffff]{2,}\\.?))(?::\\d{2,5})?(?:[\/?#]\\S*)?$\/.test(\n     url,\n   );\n }"
    },
    {
      "index":20,
      "vuln_id":"GHSA-cwpm-f78v-7m5c",
      "cwe_id":"{'CWE-400', 'CWE-20'}",
      "score":5.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bd4d5583ff9c8df26d47a23e508208844297310e'}",
      "dataset":"osv",
      "summary":"Denial of service in `tf.ragged.constant` due to lack of validation ### Impact\nThe implementation of [`tf.ragged.constant`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/f3b9bf4c3c0597563b289c0512e98d4ce81f886e\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py#L146-L239) does not fully validate the input arguments. This results in a denial of service by consuming all available memory:\n\n```python\nimport tensorflow as tf\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [bd4d5583ff9c8df26d47a23e508208844297310e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bd4d5583ff9c8df26d47a23e508208844297310e).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [GitHub issue](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/55199).",
      "published_date":"2022-05-24",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/bd4d5583ff9c8df26d47a23e508208844297310e",
      "commit_sha":"bd4d5583ff9c8df26d47a23e508208844297310e",
      "patch":"SINGLE",
      "chain_ord":"['bd4d5583ff9c8df26d47a23e508208844297310e']",
      "before_first_fix_commit":"{'e74ef072ecd54ca54f3940ce9b98af796ded2a1a'}",
      "last_fix_commit":"bd4d5583ff9c8df26d47a23e508208844297310e",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/15\/2022, 16:11:43",
      "message":"Prevent denial of service in `tf.ragged.constant`\n\nFixes #55199\n\nPiperOrigin-RevId: 442029525",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 3, 'deletions': 0, 'total': 3}",
      "files":"{'tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py': {'additions': 3, 'deletions': 0, 'changes': 3, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/bd4d5583ff9c8df26d47a23e508208844297310e\/tensorflow%2Fpython%2Fops%2Fragged%2Fragged_factory_ops.py', 'patch': '@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\\n     if max_depth > scalar_depth:\\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\\n                        \"than scalar value nesting\" % pylist)\\n+    if ragged_rank is not None and max_depth < ragged_rank:\\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\\n+                       f\"ragged_rank={ragged_rank}\")\\n \\n   # If both inner_shape and ragged_rank were specified, then check that\\n   # they are compatible with pylist.'}}",
      "message_norm":"prevent denial of service in `tf.ragged.constant`\n\nfixes #55199\n\npiperorigin-revid: 442029525",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('denial of service', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#55199', 'ISSUE', ''), ('442029525', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py'])",
      "num_files":1.0,
      "patch_content":"From bd4d5583ff9c8df26d47a23e508208844297310e Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Fri, 15 Apr 2022 09:11:43 -0700\nSubject: [PATCH] Prevent denial of service in `tf.ragged.constant`\n\nFixes #55199\n\nPiperOrigin-RevId: 442029525\n---\n tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py b\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py\nindex a1906c469beb46..457b3a04618a81 100644\n--- a\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py\n+++ b\/tensorflow\/python\/ops\/ragged\/ragged_factory_ops.py\n@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist.",
      "code_diff":"@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist."
    },
    {
      "index":21,
      "vuln_id":"GHSA-h6rj-8r3c-9gpj",
      "cwe_id":"{'CWE-400'}",
      "score":9.8,
      "chain":"{'https:\/\/github.com\/mongodb\/bson-ruby\/commit\/976da329ff03ecdfca3030eb6efe3c85e6db9999'}",
      "dataset":"osv",
      "summary":"bson is vulnerable to denial of service due to incorrect regex validation BSON injection vulnerability in the legal? function in BSON (bson-ruby) gem before 3.0.4 for Ruby allows remote attackers to cause a denial of service (resource consumption) or inject arbitrary data via a crafted string.",
      "published_date":"2018-03-05",
      "chain_len":1,
      "project":"https:\/\/github.com\/mongodb\/bson-ruby",
      "commit_href":"https:\/\/github.com\/mongodb\/bson-ruby\/commit\/976da329ff03ecdfca3030eb6efe3c85e6db9999",
      "commit_sha":"976da329ff03ecdfca3030eb6efe3c85e6db9999",
      "patch":"SINGLE",
      "chain_ord":"['976da329ff03ecdfca3030eb6efe3c85e6db9999']",
      "before_first_fix_commit":"{'7446d7c6764dfda8dc4480ce16d5c023e74be5ca'}",
      "last_fix_commit":"976da329ff03ecdfca3030eb6efe3c85e6db9999",
      "chain_ord_pos":1.0,
      "commit_datetime":"06\/04\/2015, 04:19:42",
      "message":"Use \\A \\z for checking regex on legal",
      "author":"Durran Jordan",
      "comments":"{'com_1': {'author': 'judofyr', 'datetime': '06\/04\/2015, 16:53:06', 'body': 'Yay! Thanks for a quick patch.'}, 'com_2': {'author': 'cheald', 'datetime': '06\/04\/2015, 19:17:08', 'body': \"Is the 1.x series going to see a patch? Users who aren't using bson_ext (such as users on JRuby) are still vulnerable.\"}, 'com_3': {'author': 'estolfo', 'datetime': '06\/04\/2015, 19:19:06', 'body': 'Yes, it will be released this afternoon.'}, 'com_4': {'author': 'estolfo', 'datetime': '06\/04\/2015, 19:20:30', 'body': \"It's in master already.\"}, 'com_5': {'author': 'cheald', 'datetime': '06\/04\/2015, 19:21:58', 'body': 'Perfect, thanks. https:\/\/github.com\/mongodb\/mongo-ruby-driver\/blob\/1.x-stable\/lib\/bson\/types\/object_id.rb for anyone else who ends up here looking for it, like me. :)'}, 'com_6': {'author': 'estolfo', 'datetime': '06\/04\/2015, 20:44:37', 'body': 'mongo 1.12.3 and bson 1.12.3 are released with this fix.'}}",
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'lib\/bson\/object_id.rb': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mongodb\/bson-ruby\/raw\/976da329ff03ecdfca3030eb6efe3c85e6db9999\/lib%2Fbson%2Fobject_id.rb', 'patch': '@@ -282,7 +282,7 @@ def from_time(time, options = {})\\n       #\\n       # @since 2.0.0\\n       def legal?(string)\\n-        string.to_s =~ \/^[0-9a-f]{24}$\/i ? true : false\\n+        string.to_s =~ \/\\\\A[0-9a-f]{24}\\\\z\/i ? true : false\\n       end\\n \\n       # Executes the provided block only if the size of the provided object is'}}",
      "message_norm":"use \\a \\z for checking regex on legal",
      "language":"en",
      "entities":null,
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/bson\/object_id.rb'])",
      "num_files":1.0,
      "patch_content":"From 976da329ff03ecdfca3030eb6efe3c85e6db9999 Mon Sep 17 00:00:00 2001\nFrom: Durran Jordan <durran@gmail.com>\nDate: Thu, 4 Jun 2015 00:19:42 -0400\nSubject: [PATCH] Use \\A \\z for checking regex on legal\n\n---\n lib\/bson\/object_id.rb | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/bson\/object_id.rb b\/lib\/bson\/object_id.rb\nindex d39314465..b8503f3b4 100644\n--- a\/lib\/bson\/object_id.rb\n+++ b\/lib\/bson\/object_id.rb\n@@ -282,7 +282,7 @@ def from_time(time, options = {})\n       #\n       # @since 2.0.0\n       def legal?(string)\n-        string.to_s =~ \/^[0-9a-f]{24}$\/i ? true : false\n+        string.to_s =~ \/\\A[0-9a-f]{24}\\z\/i ? true : false\n       end\n \n       # Executes the provided block only if the size of the provided object is",
      "code_diff":"@@ -282,7 +282,7 @@ def from_time(time, options = {})\n       #\n       # @since 2.0.0\n       def legal?(string)\n-        string.to_s =~ \/^[0-9a-f]{24}$\/i ? true : false\n+        string.to_s =~ \/\\A[0-9a-f]{24}\\z\/i ? true : false\n       end\n \n       # Executes the provided block only if the size of the provided object is"
    },
    {
      "index":22,
      "vuln_id":"GHSA-hwj9-h5mp-3pm3",
      "cwe_id":"{'CWE-400'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734', 'https:\/\/github.com\/postcss\/postcss\/commit\/b6f3e4d5a8d7504d553267f80384373af3a3dec5', 'https:\/\/github.com\/postcss\/postcss\/commit\/8682b1e4e328432ba692bed52326e84439cec9e4'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in postcss The npm package `postcss` from 7.0.0 and before versions 7.0.36 and 8.2.10 is vulnerable to Regular Expression Denial of Service (ReDoS) during source map parsing.",
      "published_date":"2021-05-10",
      "chain_len":3,
      "project":"https:\/\/github.com\/postcss\/postcss",
      "commit_href":"https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734",
      "commit_sha":"54cbf3c4847eb0fb1501b9d2337465439e849734",
      "patch":"MULTI",
      "chain_ord":"['8682b1e4e328432ba692bed52326e84439cec9e4', 'b6f3e4d5a8d7504d553267f80384373af3a3dec5', '54cbf3c4847eb0fb1501b9d2337465439e849734']",
      "before_first_fix_commit":"{'12832f3d203474bd273bd06bd3b2407567bfe09e'}",
      "last_fix_commit":"54cbf3c4847eb0fb1501b9d2337465439e849734",
      "chain_ord_pos":3.0,
      "commit_datetime":"06\/11\/2021, 02:38:48",
      "message":"Backport ReDoS vulnerabilities from PostCSS 8",
      "author":"Andrey Sitnik",
      "comments":null,
      "stats":"{'additions': 4, 'deletions': 2, 'total': 6}",
      "files":"{'lib\/previous-map.es6': {'additions': 4, 'deletions': 2, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/postcss\/postcss\/raw\/54cbf3c4847eb0fb1501b9d2337465439e849734\/lib%2Fprevious-map.es6', 'patch': '@@ -73,12 +73,14 @@ class PreviousMap {\\n \\n   getAnnotationURL (sourceMapString) {\\n     return sourceMapString\\n-      .match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\s*\\\\*\\\\\/\/)[1]\\n+      .match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\\\*\\\\\/\/)[1]\\n       .trim()\\n   }\\n \\n   loadAnnotation (css) {\\n-    let annotations = css.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\s*\\\\*\\\\\/\/mg)\\n+    let annotations = css.match(\\n+      \/\\\\\/\\\\*\\\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\\\*\\\\\/\/gm\\n+    )\\n \\n     if (annotations && annotations.length > 0) {\\n       \/\/ Locate the last sourceMappingURL to avoid picking up'}}",
      "message_norm":"backport redos vulnerabilities from postcss 8",
      "language":"en",
      "entities":"[('redos', 'SECWORD', ''), ('vulnerabilities', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/previous-map.es6'])",
      "num_files":1.0,
      "patch_content":"From 54cbf3c4847eb0fb1501b9d2337465439e849734 Mon Sep 17 00:00:00 2001\nFrom: Andrey Sitnik <andrey@sitnik.ru>\nDate: Thu, 10 Jun 2021 22:38:48 -0400\nSubject: [PATCH] Backport ReDoS vulnerabilities from PostCSS 8\n\n---\n lib\/previous-map.es6 | 6 ++++--\n 1 file changed, 4 insertions(+), 2 deletions(-)\n\ndiff --git a\/lib\/previous-map.es6 b\/lib\/previous-map.es6\nindex 2f36f0aef..d2c44b814 100644\n--- a\/lib\/previous-map.es6\n+++ b\/lib\/previous-map.es6\n@@ -73,12 +73,14 @@ class PreviousMap {\n \n   getAnnotationURL (sourceMapString) {\n     return sourceMapString\n-      .match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\s*\\*\\\/\/)[1]\n+      .match(\/\\\/\\*\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\*\\\/\/)[1]\n       .trim()\n   }\n \n   loadAnnotation (css) {\n-    let annotations = css.match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\s*\\*\\\/\/mg)\n+    let annotations = css.match(\n+      \/\\\/\\*\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\*\\\/\/gm\n+    )\n \n     if (annotations && annotations.length > 0) {\n       \/\/ Locate the last sourceMappingURL to avoid picking up",
      "code_diff":"@@ -73,12 +73,14 @@ class PreviousMap {\n \n   getAnnotationURL (sourceMapString) {\n     return sourceMapString\n-      .match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\s*\\*\\\/\/)[1]\n+      .match(\/\\\/\\*\\s*# sourceMappingURL=((?:(?!sourceMappingURL=).)*)\\*\\\/\/)[1]\n       .trim()\n   }\n \n   loadAnnotation (css) {\n-    let annotations = css.match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\s*\\*\\\/\/mg)\n+    let annotations = css.match(\n+      \/\\\/\\*\\s*# sourceMappingURL=(?:(?!sourceMappingURL=).)*\\*\\\/\/gm\n+    )\n \n     if (annotations && annotations.length > 0) {\n       \/\/ Locate the last sourceMappingURL to avoid picking up"
    },
    {
      "index":23,
      "vuln_id":"GHSA-v2p6-4mp7-3r9v",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/epeli\/underscore.string\/commit\/f486cd684c94c12db48b45d52b1472a1b9661029'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in underscore.string Versions of `underscore.string` prior to *3.3.5* are vulnerable to Regular Expression Denial of Service (ReDoS).\n\nThe function `unescapeHTML` is vulnerable to ReDoS due to an overly-broad regex. The slowdown is approximately 2s for 50,000 characters but grows exponentially with larger inputs.\n\n\n## Recommendation\n\nUpgrade to version 3.3.5 or higher.",
      "published_date":"2019-06-14",
      "chain_len":1,
      "project":"https:\/\/github.com\/epeli\/underscore.string",
      "commit_href":"https:\/\/github.com\/epeli\/underscore.string\/commit\/f486cd684c94c12db48b45d52b1472a1b9661029",
      "commit_sha":"f486cd684c94c12db48b45d52b1472a1b9661029",
      "patch":"SINGLE",
      "chain_ord":"['f486cd684c94c12db48b45d52b1472a1b9661029']",
      "before_first_fix_commit":"{'2f78f0d6e36d553484a1bf5fe5ed1998f013dea5'}",
      "last_fix_commit":"f486cd684c94c12db48b45d52b1472a1b9661029",
      "chain_ord_pos":1.0,
      "commit_datetime":"10\/03\/2018, 21:34:42",
      "message":"Try to fix regexp redos\n\nfixes  #510",
      "author":"Esa-Matti Suuronen",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'unescapeHTML.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/esamattis\/underscore.string\/raw\/f486cd684c94c12db48b45d52b1472a1b9661029\/unescapeHTML.js', 'patch': \"@@ -2,7 +2,7 @@ var makeString = require('.\/helper\/makeString');\\n var htmlEntities = require('.\/helper\/htmlEntities');\\n \\n module.exports = function unescapeHTML(str) {\\n-  return makeString(str).replace(\/\\\\&([^;]+);\/g, function(entity, entityCode) {\\n+  return makeString(str).replace(\/\\\\&([^;]{1,10});\/g, function(entity, entityCode) {\\n     var match;\\n \\n     if (entityCode in htmlEntities) {\"}}",
      "message_norm":"try to fix regexp redos\n\nfixes  #510",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#510', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['unescapeHTML.js'])",
      "num_files":1.0,
      "patch_content":"From f486cd684c94c12db48b45d52b1472a1b9661029 Mon Sep 17 00:00:00 2001\nFrom: Esa-Matti Suuronen <esa-matti@suuronen.org>\nDate: Thu, 4 Oct 2018 00:34:42 +0300\nSubject: [PATCH] Try to fix regexp redos\n\nfixes  #510\n---\n unescapeHTML.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/unescapeHTML.js b\/unescapeHTML.js\nindex 78b59c28..df1d18ef 100644\n--- a\/unescapeHTML.js\n+++ b\/unescapeHTML.js\n@@ -2,7 +2,7 @@ var makeString = require('.\/helper\/makeString');\n var htmlEntities = require('.\/helper\/htmlEntities');\n \n module.exports = function unescapeHTML(str) {\n-  return makeString(str).replace(\/\\&([^;]+);\/g, function(entity, entityCode) {\n+  return makeString(str).replace(\/\\&([^;]{1,10});\/g, function(entity, entityCode) {\n     var match;\n \n     if (entityCode in htmlEntities) {",
      "code_diff":"@@ -2,7 +2,7 @@ var makeString = require('.\/helper\/makeString');\n var htmlEntities = require('.\/helper\/htmlEntities');\n \n module.exports = function unescapeHTML(str) {\n-  return makeString(str).replace(\/\\&([^;]+);\/g, function(entity, entityCode) {\n+  return makeString(str).replace(\/\\&([^;]{1,10});\/g, function(entity, entityCode) {\n     var match;\n \n     if (entityCode in htmlEntities) {"
    },
    {
      "index":24,
      "vuln_id":"GHSA-r33q-22hv-j29q",
      "cwe_id":"{'CWE-400'}",
      "score":6.5,
      "chain":"{'https:\/\/github.com\/ethereum\/go-ethereum\/commit\/bddd103a9f0af27ef533f04e06ea429cf76b6d46'}",
      "dataset":"osv",
      "summary":"Denial of service in github.com\/ethereum\/go-ethereum ### Impact\n\nA DoS vulnerability can make a LES server crash via malicious `GetProofsV2` request from a connected LES client.\n\n### Patches\n\nThe vulnerability was patched in https:\/\/github.com\/ethereum\/go-ethereum\/pull\/21896. \n\n### Workarounds\n\nThis vulnerability only concerns users explicitly enabling `les` server; disabling `les` prevents the exploit. \nIt can also be patched by manually applying the patch in https:\/\/github.com\/ethereum\/go-ethereum\/pull\/21896. \n\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [go-ethereum](https:\/\/github.com\/ethereum\/go-ethereum)\n* Email us at [security@ethereum.org](mailto:security@ethereum.org)",
      "published_date":"2021-06-29",
      "chain_len":1,
      "project":"https:\/\/github.com\/ethereum\/go-ethereum",
      "commit_href":"https:\/\/github.com\/ethereum\/go-ethereum\/commit\/bddd103a9f0af27ef533f04e06ea429cf76b6d46",
      "commit_sha":"bddd103a9f0af27ef533f04e06ea429cf76b6d46",
      "patch":"SINGLE",
      "chain_ord":"['bddd103a9f0af27ef533f04e06ea429cf76b6d46']",
      "before_first_fix_commit":"{'6b5840961407960a06ed20cb5dd1b782080653ff'}",
      "last_fix_commit":"bddd103a9f0af27ef533f04e06ea429cf76b6d46",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/24\/2020, 09:55:17",
      "message":"les: fix GetProofsV2 bug (#21896)",
      "author":"Felf\u00f6ldi Zsolt",
      "comments":null,
      "stats":"{'additions': 2, 'deletions': 4, 'total': 6}",
      "files":"{'les\/server_handler.go': {'additions': 2, 'deletions': 4, 'changes': 6, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/ethereum\/go-ethereum\/raw\/bddd103a9f0af27ef533f04e06ea429cf76b6d46\/les%2Fserver_handler.go', 'patch': '@@ -610,6 +610,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\\n \\t\\tvar (\\n \\t\\t\\tlastBHash common.Hash\\n \\t\\t\\troot      common.Hash\\n+\\t\\t\\theader    *types.Header\\n \\t\\t)\\n \\t\\treqCnt := len(req.Reqs)\\n \\t\\tif accept(req.ReqID, uint64(reqCnt), MaxProofsFetch) {\\n@@ -624,10 +625,6 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\\n \\t\\t\\t\\t\\t\\treturn\\n \\t\\t\\t\\t\\t}\\n \\t\\t\\t\\t\\t\/\/ Look up the root hash belonging to the request\\n-\\t\\t\\t\\t\\tvar (\\n-\\t\\t\\t\\t\\t\\theader *types.Header\\n-\\t\\t\\t\\t\\t\\ttrie   state.Trie\\n-\\t\\t\\t\\t\\t)\\n \\t\\t\\t\\t\\tif request.BHash != lastBHash {\\n \\t\\t\\t\\t\\t\\troot, lastBHash = common.Hash{}, request.BHash\\n \\n@@ -654,6 +651,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\\n \\t\\t\\t\\t\\t\/\/ Open the account or storage trie for the request\\n \\t\\t\\t\\t\\tstatedb := h.blockchain.StateCache()\\n \\n+\\t\\t\\t\\t\\tvar trie state.Trie\\n \\t\\t\\t\\t\\tswitch len(request.AccKey) {\\n \\t\\t\\t\\t\\tcase 0:\\n \\t\\t\\t\\t\\t\\t\/\/ No account key specified, open an account trie'}}",
      "message_norm":"les: fix getproofsv2 bug (#21896)",
      "language":"af",
      "entities":"[('bug', 'FLAW', ''), ('#21896', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['les\/server_handler.go'])",
      "num_files":1.0,
      "patch_content":"From bddd103a9f0af27ef533f04e06ea429cf76b6d46 Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Felf=C3=B6ldi=20Zsolt?= <zsfelfoldi@gmail.com>\nDate: Tue, 24 Nov 2020 10:55:17 +0100\nSubject: [PATCH] les: fix GetProofsV2 bug (#21896)\n\n---\n les\/server_handler.go | 6 ++----\n 1 file changed, 2 insertions(+), 4 deletions(-)\n\ndiff --git a\/les\/server_handler.go b\/les\/server_handler.go\nindex d3e2c956b3ea..c0600b3686d3 100644\n--- a\/les\/server_handler.go\n+++ b\/les\/server_handler.go\n@@ -610,6 +610,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\tvar (\n \t\t\tlastBHash common.Hash\n \t\t\troot      common.Hash\n+\t\t\theader    *types.Header\n \t\t)\n \t\treqCnt := len(req.Reqs)\n \t\tif accept(req.ReqID, uint64(reqCnt), MaxProofsFetch) {\n@@ -624,10 +625,6 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\t\t\t\t\treturn\n \t\t\t\t\t}\n \t\t\t\t\t\/\/ Look up the root hash belonging to the request\n-\t\t\t\t\tvar (\n-\t\t\t\t\t\theader *types.Header\n-\t\t\t\t\t\ttrie   state.Trie\n-\t\t\t\t\t)\n \t\t\t\t\tif request.BHash != lastBHash {\n \t\t\t\t\t\troot, lastBHash = common.Hash{}, request.BHash\n \n@@ -654,6 +651,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\t\t\t\t\/\/ Open the account or storage trie for the request\n \t\t\t\t\tstatedb := h.blockchain.StateCache()\n \n+\t\t\t\t\tvar trie state.Trie\n \t\t\t\t\tswitch len(request.AccKey) {\n \t\t\t\t\tcase 0:\n \t\t\t\t\t\t\/\/ No account key specified, open an account trie",
      "code_diff":"@@ -610,6 +610,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\tvar (\n \t\t\tlastBHash common.Hash\n \t\t\troot      common.Hash\n+\t\t\theader    *types.Header\n \t\t)\n \t\treqCnt := len(req.Reqs)\n \t\tif accept(req.ReqID, uint64(reqCnt), MaxProofsFetch) {\n@@ -624,10 +625,6 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\t\t\t\t\treturn\n \t\t\t\t\t}\n \t\t\t\t\t\/\/ Look up the root hash belonging to the request\n-\t\t\t\t\tvar (\n-\t\t\t\t\t\theader *types.Header\n-\t\t\t\t\t\ttrie   state.Trie\n-\t\t\t\t\t)\n \t\t\t\t\tif request.BHash != lastBHash {\n \t\t\t\t\t\troot, lastBHash = common.Hash{}, request.BHash\n \n@@ -654,6 +651,7 @@ func (h *serverHandler) handleMsg(p *clientPeer, wg *sync.WaitGroup) error {\n \t\t\t\t\t\/\/ Open the account or storage trie for the request\n \t\t\t\t\tstatedb := h.blockchain.StateCache()\n \n+\t\t\t\t\tvar trie state.Trie\n \t\t\t\t\tswitch len(request.AccKey) {\n \t\t\t\t\tcase 0:\n \t\t\t\t\t\t\/\/ No account key specified, open an account trie"
    },
    {
      "index":25,
      "vuln_id":"GHSA-4gw3-8f77-f72c",
      "cwe_id":"{'CWE-400'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/codemirror\/CodeMirror\/commit\/55d0333907117c9231ffdf555ae8824705993bbb'}",
      "dataset":"osv",
      "summary":"Regular expression denial of service in codemirror This affects the package codemirror before 5.58.2; the package org.apache.marmotta.webjars:codemirror before 5.58.2.\n The vulnerable regular expression is located in https:\/\/github.com\/codemirror\/CodeMirror\/blob\/cdb228ac736369c685865b122b736cd0d397836c\/mode\/javascript\/javascript.jsL129. The ReDOS vulnerability of the regex is mainly due to the sub-pattern (s|\/*.*?*\/)*",
      "published_date":"2021-05-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/codemirror\/CodeMirror",
      "commit_href":"https:\/\/github.com\/codemirror\/CodeMirror\/commit\/55d0333907117c9231ffdf555ae8824705993bbb",
      "commit_sha":"55d0333907117c9231ffdf555ae8824705993bbb",
      "patch":"SINGLE",
      "chain_ord":"['55d0333907117c9231ffdf555ae8824705993bbb']",
      "before_first_fix_commit":"{'cdb228ac736369c685865b122b736cd0d397836c'}",
      "last_fix_commit":"55d0333907117c9231ffdf555ae8824705993bbb",
      "chain_ord_pos":1.0,
      "commit_datetime":"10\/09\/2020, 13:38:39",
      "message":"[javascript mode] Fix potentially-exponential regexp",
      "author":"Marijn Haverbeke",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'mode\/javascript\/javascript.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/codemirror\/codemirror5\/raw\/55d0333907117c9231ffdf555ae8824705993bbb\/mode%2Fjavascript%2Fjavascript.js', 'patch': '@@ -126,7 +126,7 @@ CodeMirror.defineMode(\"javascript\", function(config, parserConfig) {\\n           var kw = keywords[word]\\n           return ret(kw.type, kw.style, word)\\n         }\\n-        if (word == \"async\" && stream.match(\/^(\\\\s|\\\\\/\\\\*.*?\\\\*\\\\\/)*[\\\\[\\\\(\\\\w]\/, false))\\n+        if (word == \"async\" && stream.match(\/^(\\\\s|\\\\\/\\\\*([^*]|\\\\*(?!\\\\\/))*?\\\\*\\\\\/)*[\\\\[\\\\(\\\\w]\/, false))\\n           return ret(\"async\", \"keyword\", word)\\n       }\\n       return ret(\"variable\", \"variable\", word)'}}",
      "message_norm":"[javascript mode] fix potentially-exponential regexp",
      "language":"ca",
      "entities":"[('fix', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['mode\/javascript\/javascript.js'])",
      "num_files":1.0,
      "patch_content":"From 55d0333907117c9231ffdf555ae8824705993bbb Mon Sep 17 00:00:00 2001\nFrom: Marijn Haverbeke <marijn@haverbeke.nl>\nDate: Fri, 9 Oct 2020 15:38:39 +0200\nSubject: [PATCH] [javascript mode] Fix potentially-exponential regexp\n\n---\n mode\/javascript\/javascript.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/mode\/javascript\/javascript.js b\/mode\/javascript\/javascript.js\nindex 66e5a308d4..3139fd00d2 100644\n--- a\/mode\/javascript\/javascript.js\n+++ b\/mode\/javascript\/javascript.js\n@@ -126,7 +126,7 @@ CodeMirror.defineMode(\"javascript\", function(config, parserConfig) {\n           var kw = keywords[word]\n           return ret(kw.type, kw.style, word)\n         }\n-        if (word == \"async\" && stream.match(\/^(\\s|\\\/\\*.*?\\*\\\/)*[\\[\\(\\w]\/, false))\n+        if (word == \"async\" && stream.match(\/^(\\s|\\\/\\*([^*]|\\*(?!\\\/))*?\\*\\\/)*[\\[\\(\\w]\/, false))\n           return ret(\"async\", \"keyword\", word)\n       }\n       return ret(\"variable\", \"variable\", word)",
      "code_diff":"@@ -126,7 +126,7 @@ CodeMirror.defineMode(\"javascript\", function(config, parserConfig) {\n           var kw = keywords[word]\n           return ret(kw.type, kw.style, word)\n         }\n-        if (word == \"async\" && stream.match(\/^(\\s|\\\/\\*.*?\\*\\\/)*[\\[\\(\\w]\/, false))\n+        if (word == \"async\" && stream.match(\/^(\\s|\\\/\\*([^*]|\\*(?!\\\/))*?\\*\\\/)*[\\[\\(\\w]\/, false))\n           return ret(\"async\", \"keyword\", word)\n       }\n       return ret(\"variable\", \"variable\", word)"
    },
    {
      "index":26,
      "vuln_id":"GHSA-43f8-2h32-f4cj",
      "cwe_id":"{'CWE-400'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/npm\/hosted-git-info\/commit\/bede0dc38e1785e732bf0a48ba6f81a4a908eba3', 'https:\/\/github.com\/npm\/hosted-git-info\/commit\/8d4b3697d79bcd89cdb36d1db165e3696c783a01', 'https:\/\/github.com\/npm\/hosted-git-info\/commit\/29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in hosted-git-info The npm package `hosted-git-info` before 3.0.8 are vulnerable to Regular Expression Denial of Service (ReDoS) via regular expression shortcutMatch in the fromUrl function in index.js. The affected regular expression exhibits polynomial worst-case time complexity",
      "published_date":"2021-05-06",
      "chain_len":3,
      "project":"https:\/\/github.com\/npm\/hosted-git-info",
      "commit_href":"https:\/\/github.com\/npm\/hosted-git-info\/commit\/bede0dc38e1785e732bf0a48ba6f81a4a908eba3",
      "commit_sha":"bede0dc38e1785e732bf0a48ba6f81a4a908eba3",
      "patch":"MULTI",
      "chain_ord":"['bede0dc38e1785e732bf0a48ba6f81a4a908eba3', '29adfe5ef789784c861b2cdeb15051ec2ba651a7', '8d4b3697d79bcd89cdb36d1db165e3696c783a01']",
      "before_first_fix_commit":"{'29adfe5ef789784c861b2cdeb15051ec2ba651a7'}",
      "last_fix_commit":"8d4b3697d79bcd89cdb36d1db165e3696c783a01",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/28\/2021, 17:22:16",
      "message":"fix: simplify the regular expression for shortcut matching\n\nPR-URL: https:\/\/github.com\/npm\/hosted-git-info\/pull\/76\nCredit: @nlf\nClose: #76\nReviewed-by: @isaacs",
      "author":"nlf",
      "comments":null,
      "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
      "files":"{'index.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/npm\/hosted-git-info\/raw\/bede0dc38e1785e732bf0a48ba6f81a4a908eba3\/index.js', 'patch': \"@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\\n   )\\n   var parsed = parseGitUrl(url)\\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\\\/)?([^#]+)\/)\\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\\n     try {\\n       var gitHostInfo = gitHosts[gitHostName]\\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\\n       var defaultRepresentation = null\\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\\n-        project = decodeURIComponent(shortcutMatch[3])\\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\\\.git$\/, ''))\\n         defaultRepresentation = 'shortcut'\\n       } else {\\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return\"}}",
      "message_norm":"fix: simplify the regular expression for shortcut matching\n\npr-url: https:\/\/github.com\/npm\/hosted-git-info\/pull\/76\ncredit: @nlf\nclose: #76\nreviewed-by: @isaacs",
      "language":"en",
      "entities":"[('https:\/\/github.com\/npm\/hosted-git-info\/pull\/76', 'URL', ''), ('#76', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['index.js'])",
      "num_files":1.0,
      "patch_content":"From bede0dc38e1785e732bf0a48ba6f81a4a908eba3 Mon Sep 17 00:00:00 2001\nFrom: nlf <quitlahok@gmail.com>\nDate: Thu, 28 Jan 2021 09:22:16 -0800\nSubject: [PATCH] fix: simplify the regular expression for shortcut matching\n\nPR-URL: https:\/\/github.com\/npm\/hosted-git-info\/pull\/76\nCredit: @nlf\nClose: #76\nReviewed-by: @isaacs\n---\n index.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/index.js b\/index.js\nindex 0b08be1..8b3eaba 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\n   )\n   var parsed = parseGitUrl(url)\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\/)?([^#]+)\/)\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\n     try {\n       var gitHostInfo = gitHosts[gitHostName]\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\n       var defaultRepresentation = null\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\n-        project = decodeURIComponent(shortcutMatch[3])\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\.git$\/, ''))\n         defaultRepresentation = 'shortcut'\n       } else {\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return",
      "code_diff":"@@ -41,7 +41,7 @@ function fromUrl (giturl, opts) {\n     isGitHubShorthand(giturl) ? 'github:' + giturl : giturl\n   )\n   var parsed = parseGitUrl(url)\n-  var shortcutMatch = url.match(new RegExp('^([^:]+):(?:(?:[^@:]+(?:[^@]+)?@)?([^\/]*))[\/](.+?)(?:[.]git)?($|#)'))\n+  var shortcutMatch = url.match(\/^([^:]+):(?:[^@]+@)?(?:([^\/]*)\\\/)?([^#]+)\/)\n   var matches = Object.keys(gitHosts).map(function (gitHostName) {\n     try {\n       var gitHostInfo = gitHosts[gitHostName]\n@@ -55,7 +55,7 @@ function fromUrl (giturl, opts) {\n       var defaultRepresentation = null\n       if (shortcutMatch && shortcutMatch[1] === gitHostName) {\n         user = shortcutMatch[2] && decodeURIComponent(shortcutMatch[2])\n-        project = decodeURIComponent(shortcutMatch[3])\n+        project = decodeURIComponent(shortcutMatch[3].replace(\/\\.git$\/, ''))\n         defaultRepresentation = 'shortcut'\n       } else {\n         if (parsed.host && parsed.host !== gitHostInfo.domain && parsed.host.replace(\/^www[.]\/, '') !== gitHostInfo.domain) return"
    },
    {
      "index":27,
      "vuln_id":"GHSA-662x-fhqg-9p8v",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/faisalman\/ua-parser-js\/commit\/233d3bae22a795153a7e6638887ce159c63e557d'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in ua-parser-js The package ua-parser-js before 0.7.22 are vulnerable to Regular Expression Denial of Service (ReDoS) via the regex for Redmi Phones and Mi Pad Tablets UA.",
      "published_date":"2021-05-07",
      "chain_len":1,
      "project":"https:\/\/github.com\/faisalman\/ua-parser-js",
      "commit_href":"https:\/\/github.com\/faisalman\/ua-parser-js\/commit\/233d3bae22a795153a7e6638887ce159c63e557d",
      "commit_sha":"233d3bae22a795153a7e6638887ce159c63e557d",
      "patch":"SINGLE",
      "chain_ord":"['233d3bae22a795153a7e6638887ce159c63e557d']",
      "before_first_fix_commit":"{'5230745280ba8aee775b0f5d2c8a2332f8ef2c4e'}",
      "last_fix_commit":"233d3bae22a795153a7e6638887ce159c63e557d",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/12\/2020, 08:47:15",
      "message":"Fix potential ReDoS vulnerability",
      "author":"Faisal Salman",
      "comments":null,
      "stats":"{'additions': 2, 'deletions': 2, 'total': 4}",
      "files":"{'src\/ua-parser.js': {'additions': 2, 'deletions': 2, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/faisalman\/ua-parser-js\/raw\/233d3bae22a795153a7e6638887ce159c63e557d\/src%2Fua-parser.js', 'patch': \"@@ -585,9 +585,9 @@\\n             \/android.+(hm[\\\\s\\\\-_]*note?[\\\\s_]*(?:\\\\d\\\\w)?)\\\\s+build\/i,               \/\/ Xiaomi Hongmi\\n             \/android.+(mi[\\\\s\\\\-_]*(?:a\\\\d|one|one[\\\\s_]plus|note lte)?[\\\\s_]*(?:\\\\d?\\\\w?)[\\\\s_]*(?:plus)?)\\\\s+build\/i,    \\n                                                                                 \/\/ Xiaomi Mi\\n-            \/android.+(redmi[\\\\s\\\\-_]*(?:note)?(?:[\\\\s_]*[\\\\w\\\\s]+))\\\\s+build\/i       \/\/ Redmi Phones\\n+            \/android.+(redmi[\\\\s\\\\-_]*(?:note)?(?:[\\\\s_]?[\\\\w\\\\s]+))\\\\s+build\/i       \/\/ Redmi Phones\\n             ], [[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, MOBILE]], [\\n-            \/android.+(mi[\\\\s\\\\-_]*(?:pad)(?:[\\\\s_]*[\\\\w\\\\s]+))\\\\s+build\/i            \/\/ Mi Pad tablets\\n+            \/android.+(mi[\\\\s\\\\-_]*(?:pad)(?:[\\\\s_]?[\\\\w\\\\s]+))\\\\s+build\/i            \/\/ Mi Pad tablets\\n             ],[[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, TABLET]], [\\n             \/android.+;\\\\s(m[1-5]\\\\snote)\\\\sbuild\/i                                \/\/ Meizu\\n             ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], [\"}}",
      "message_norm":"fix potential redos vulnerability",
      "language":"ca",
      "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('vulnerability', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/ua-parser.js'])",
      "num_files":1.0,
      "patch_content":"From 233d3bae22a795153a7e6638887ce159c63e557d Mon Sep 17 00:00:00 2001\nFrom: Faisal Salman <f@faisalman.com>\nDate: Sat, 12 Sep 2020 15:47:15 +0700\nSubject: [PATCH] Fix potential ReDoS vulnerability\n\n---\n src\/ua-parser.js | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a\/src\/ua-parser.js b\/src\/ua-parser.js\nindex d89312c60..3d807e1a7 100755\n--- a\/src\/ua-parser.js\n+++ b\/src\/ua-parser.js\n@@ -585,9 +585,9 @@\n             \/android.+(hm[\\s\\-_]*note?[\\s_]*(?:\\d\\w)?)\\s+build\/i,               \/\/ Xiaomi Hongmi\n             \/android.+(mi[\\s\\-_]*(?:a\\d|one|one[\\s_]plus|note lte)?[\\s_]*(?:\\d?\\w?)[\\s_]*(?:plus)?)\\s+build\/i,    \n                                                                                 \/\/ Xiaomi Mi\n-            \/android.+(redmi[\\s\\-_]*(?:note)?(?:[\\s_]*[\\w\\s]+))\\s+build\/i       \/\/ Redmi Phones\n+            \/android.+(redmi[\\s\\-_]*(?:note)?(?:[\\s_]?[\\w\\s]+))\\s+build\/i       \/\/ Redmi Phones\n             ], [[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, MOBILE]], [\n-            \/android.+(mi[\\s\\-_]*(?:pad)(?:[\\s_]*[\\w\\s]+))\\s+build\/i            \/\/ Mi Pad tablets\n+            \/android.+(mi[\\s\\-_]*(?:pad)(?:[\\s_]?[\\w\\s]+))\\s+build\/i            \/\/ Mi Pad tablets\n             ],[[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, TABLET]], [\n             \/android.+;\\s(m[1-5]\\snote)\\sbuild\/i                                \/\/ Meizu\n             ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], [",
      "code_diff":"@@ -585,9 +585,9 @@\n             \/android.+(hm[\\s\\-_]*note?[\\s_]*(?:\\d\\w)?)\\s+build\/i,               \/\/ Xiaomi Hongmi\n             \/android.+(mi[\\s\\-_]*(?:a\\d|one|one[\\s_]plus|note lte)?[\\s_]*(?:\\d?\\w?)[\\s_]*(?:plus)?)\\s+build\/i,    \n                                                                                 \/\/ Xiaomi Mi\n-            \/android.+(redmi[\\s\\-_]*(?:note)?(?:[\\s_]*[\\w\\s]+))\\s+build\/i       \/\/ Redmi Phones\n+            \/android.+(redmi[\\s\\-_]*(?:note)?(?:[\\s_]?[\\w\\s]+))\\s+build\/i       \/\/ Redmi Phones\n             ], [[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, MOBILE]], [\n-            \/android.+(mi[\\s\\-_]*(?:pad)(?:[\\s_]*[\\w\\s]+))\\s+build\/i            \/\/ Mi Pad tablets\n+            \/android.+(mi[\\s\\-_]*(?:pad)(?:[\\s_]?[\\w\\s]+))\\s+build\/i            \/\/ Mi Pad tablets\n             ],[[MODEL, \/_\/g, ' '], [VENDOR, 'Xiaomi'], [TYPE, TABLET]], [\n             \/android.+;\\s(m[1-5]\\snote)\\sbuild\/i                                \/\/ Meizu\n             ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], ["
    },
    {
      "index":28,
      "vuln_id":"GHSA-vp56-6g26-6827",
      "cwe_id":"{'CWE-400'}",
      "score":5.9,
      "chain":"{'https:\/\/github.com\/node-fetch\/node-fetch\/commit\/28802387292baee467e042e168d92597b5bbbe3d'}",
      "dataset":"osv",
      "summary":"node-fetch Inefficient Regular Expression Complexity  [node-fetch](https:\/\/www.npmjs.com\/package\/node-fetch) is a light-weight module that brings window.fetch to node.js.\n\nAffected versions of this package are vulnerable to Regular Expression Denial of Service (ReDoS) in the `isOriginPotentiallyTrustworthy()` function in `referrer.js`, when processing a URL string with alternating letters and periods, such as `'http:\/\/' + 'a.a.'.repeat(i) + 'a'`.",
      "published_date":"2022-08-02",
      "chain_len":1,
      "project":"https:\/\/github.com\/node-fetch\/node-fetch",
      "commit_href":"https:\/\/github.com\/node-fetch\/node-fetch\/commit\/28802387292baee467e042e168d92597b5bbbe3d",
      "commit_sha":"28802387292baee467e042e168d92597b5bbbe3d",
      "patch":"SINGLE",
      "chain_ord":"['28802387292baee467e042e168d92597b5bbbe3d']",
      "before_first_fix_commit":"{'e87b093fd678a9ea39c5b17b2a1bdfc4691eedc7'}",
      "last_fix_commit":"28802387292baee467e042e168d92597b5bbbe3d",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/31\/2022, 08:01:29",
      "message":"fix: ReDoS referrer (#1611)\n\n* fix ReDoS referrer\r\n\r\n* Update src\/utils\/referrer.js\r\n\r\nEliminate regex and use string matcher\r\n\r\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>\r\n\r\nCo-authored-by: Khang. V\u00f5 V\u0129 <khangvv@vng.com.vn>\r\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>",
      "author":"Khang Vo (doublevkay)",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'src\/utils\/referrer.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/node-fetch\/node-fetch\/raw\/28802387292baee467e042e168d92597b5bbbe3d\/src%2Futils%2Freferrer.js', 'patch': '@@ -119,7 +119,7 @@ export function isOriginPotentiallyTrustworthy(url) {\\n \\t\/\/ 5. If origin\\'s host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\\n \\t\/\/ We are returning FALSE here because we cannot ensure conformance to\\n \\t\/\/ let-localhost-be-loalhost (https:\/\/tools.ietf.org\/html\/draft-west-let-localhost-be-localhost)\\n-\\tif (\/^(.+\\\\.)*localhost$\/.test(url.host)) {\\n+\\tif (url.host === \\'localhost\\' || url.host.endsWith(\\'.localhost\\')) {\\n \\t\\treturn false;\\n \\t}'}}",
      "message_norm":"fix: redos referrer (#1611)\n\n* fix redos referrer\r\n\r\n* update src\/utils\/referrer.js\r\n\r\neliminate regex and use string matcher\r\n\r\nco-authored-by: linus unneb\u00e4ck <linus@folkdatorn.se>\r\n\r\nco-authored-by: khang. v\u00f5 v\u0129 <khangvv@vng.com.vn>\r\nco-authored-by: linus unneb\u00e4ck <linus@folkdatorn.se>",
      "language":"en",
      "entities":"[('redos', 'SECWORD', ''), ('#1611', 'ISSUE', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('linus@folkdatorn.se', 'EMAIL', ''), ('linus@folkdatorn.se', 'EMAIL', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/utils\/referrer.js'])",
      "num_files":1.0,
      "patch_content":"From 28802387292baee467e042e168d92597b5bbbe3d Mon Sep 17 00:00:00 2001\nFrom: \"Khang Vo (doublevkay)\" <45411113+vovikhangcdv@users.noreply.github.com>\nDate: Sun, 31 Jul 2022 15:01:29 +0700\nSubject: [PATCH] fix: ReDoS referrer (#1611)\nMIME-Version: 1.0\nContent-Type: text\/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\n\n* fix ReDoS referrer\n\n* Update src\/utils\/referrer.js\n\nEliminate regex and use string matcher\n\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>\n\nCo-authored-by: Khang. V\u00f5 V\u0129 <khangvv@vng.com.vn>\nCo-authored-by: Linus Unneb\u00e4ck <linus@folkdatorn.se>\n---\n src\/utils\/referrer.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/utils\/referrer.js b\/src\/utils\/referrer.js\nindex c8c668671..6741f2fcc 100644\n--- a\/src\/utils\/referrer.js\n+++ b\/src\/utils\/referrer.js\n@@ -119,7 +119,7 @@ export function isOriginPotentiallyTrustworthy(url) {\n \t\/\/ 5. If origin's host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\n \t\/\/ We are returning FALSE here because we cannot ensure conformance to\n \t\/\/ let-localhost-be-loalhost (https:\/\/tools.ietf.org\/html\/draft-west-let-localhost-be-localhost)\n-\tif (\/^(.+\\.)*localhost$\/.test(url.host)) {\n+\tif (url.host === 'localhost' || url.host.endsWith('.localhost')) {\n \t\treturn false;\n \t}",
      "code_diff":"@@ -119,7 +119,7 @@ export function isOriginPotentiallyTrustworthy(url) {\n \t\/\/ 5. If origin's host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\n \t\/\/ We are returning FALSE here because we cannot ensure conformance to\n \t\/\/ let-localhost-be-loalhost (https:\/\/tools.ietf.org\/html\/draft-west-let-localhost-be-localhost)\n-\tif (\/^(.+\\.)*localhost$\/.test(url.host)) {\n+\tif (url.host === 'localhost' || url.host.endsWith('.localhost')) {\n \t\treturn false;\n \t}"
    },
    {
      "index":29,
      "vuln_id":"GHSA-xfhp-gmh8-r8v2",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/adaltas\/node-printf\/commit\/a8502e7c9b0b22555696a2d8ef67722086413a68'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service (ReDoS) The package printf before 0.6.1 are vulnerable to Regular Expression Denial of Service (ReDoS) via the regex string \/\\%(?:\\(([\\w_.]+)\\)|([1-9]\\d*)\\$)?([0 +\\-\\]*)(\\*|\\d+)?(\\.)?(\\*|\\d+)?[hlL]?([\\%bscdeEfFgGioOuxX])\/g in lib\/printf.js. The vulnerable regular expression has cubic worst-case time complexity.",
      "published_date":"2021-03-19",
      "chain_len":1,
      "project":"https:\/\/github.com\/adaltas\/node-printf",
      "commit_href":"https:\/\/github.com\/adaltas\/node-printf\/commit\/a8502e7c9b0b22555696a2d8ef67722086413a68",
      "commit_sha":"a8502e7c9b0b22555696a2d8ef67722086413a68",
      "patch":"SINGLE",
      "chain_ord":"['a8502e7c9b0b22555696a2d8ef67722086413a68']",
      "before_first_fix_commit":"{'1456b115685791329c6fa6ca4237b7965f10cf82'}",
      "last_fix_commit":"a8502e7c9b0b22555696a2d8ef67722086413a68",
      "chain_ord_pos":1.0,
      "commit_datetime":"02\/10\/2021, 13:28:56",
      "message":"Fix ReDoS",
      "author":"Yeting Li",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'lib\/printf.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/adaltas\/node-printf\/raw\/a8502e7c9b0b22555696a2d8ef67722086413a68\/lib%2Fprintf.js', 'patch': '@@ -41,7 +41,7 @@ var Formatter = function(\/*String*\/ format){\\n   this._tokens = tokenize(format, this._re, this._parseDelim, this);\\n };\\n \\n-Formatter.prototype._re = \/\\\\%(?:\\\\(([\\\\w_.]+)\\\\)|([1-9]\\\\d*)\\\\$)?([0 +\\\\-\\\\#]*)([\\\\*1-9]0*)*(?:(\\\\.)(\\\\*|\\\\d+)?)?[hlL]?([\\\\%bscdeEfFgGioOuxX])\/g;\\n+Formatter.prototype._re = \/\\\\%(?:\\\\(([\\\\w_.]+)\\\\)|([1-9]\\\\d*)\\\\$)?([0 +\\\\-\\\\#]*)(\\\\*|\\\\d+)?(?:(\\\\.)(\\\\*|\\\\d+)?)?[hlL]?([\\\\%bscdeEfFgGioOuxX])\/g;\\n Formatter.prototype._parseDelim = function(mapping, intmapping, flags, minWidth, period, precision, specifier){\\n   if(mapping){\\n     this._mapped = true;'}}",
      "message_norm":"fix redos",
      "language":"pt",
      "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/printf.js'])",
      "num_files":1.0,
      "patch_content":"From a8502e7c9b0b22555696a2d8ef67722086413a68 Mon Sep 17 00:00:00 2001\nFrom: Yeting Li <liyt@ios.ac.cn>\nDate: Wed, 10 Feb 2021 21:28:56 +0800\nSubject: [PATCH] Fix ReDoS\n\n---\n lib\/printf.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/printf.js b\/lib\/printf.js\nindex 34afd6f..c263acf 100755\n--- a\/lib\/printf.js\n+++ b\/lib\/printf.js\n@@ -41,7 +41,7 @@ var Formatter = function(\/*String*\/ format){\n   this._tokens = tokenize(format, this._re, this._parseDelim, this);\n };\n \n-Formatter.prototype._re = \/\\%(?:\\(([\\w_.]+)\\)|([1-9]\\d*)\\$)?([0 +\\-\\#]*)([\\*1-9]0*)*(?:(\\.)(\\*|\\d+)?)?[hlL]?([\\%bscdeEfFgGioOuxX])\/g;\n+Formatter.prototype._re = \/\\%(?:\\(([\\w_.]+)\\)|([1-9]\\d*)\\$)?([0 +\\-\\#]*)(\\*|\\d+)?(?:(\\.)(\\*|\\d+)?)?[hlL]?([\\%bscdeEfFgGioOuxX])\/g;\n Formatter.prototype._parseDelim = function(mapping, intmapping, flags, minWidth, period, precision, specifier){\n   if(mapping){\n     this._mapped = true;",
      "code_diff":"@@ -41,7 +41,7 @@ var Formatter = function(\/*String*\/ format){\n   this._tokens = tokenize(format, this._re, this._parseDelim, this);\n };\n \n-Formatter.prototype._re = \/\\%(?:\\(([\\w_.]+)\\)|([1-9]\\d*)\\$)?([0 +\\-\\#]*)([\\*1-9]0*)*(?:(\\.)(\\*|\\d+)?)?[hlL]?([\\%bscdeEfFgGioOuxX])\/g;\n+Formatter.prototype._re = \/\\%(?:\\(([\\w_.]+)\\)|([1-9]\\d*)\\$)?([0 +\\-\\#]*)(\\*|\\d+)?(?:(\\.)(\\*|\\d+)?)?[hlL]?([\\%bscdeEfFgGioOuxX])\/g;\n Formatter.prototype._parseDelim = function(mapping, intmapping, flags, minWidth, period, precision, specifier){\n   if(mapping){\n     this._mapped = true;"
    },
    {
      "index":30,
      "vuln_id":"GHSA-j4f2-536g-r55m",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/socketio\/engine.io\/commit\/734f9d1268840722c41219e69eb58318e0b2ac6b'}",
      "dataset":"osv",
      "summary":"Resource exhaustion in engine.io  Engine.IO before 4.0.0 and 3.6.0 allows attackers to cause a denial of service (resource consumption) via a POST request to the long polling transport.",
      "published_date":"2022-02-09",
      "chain_len":1,
      "project":"https:\/\/github.com\/socketio\/engine.io",
      "commit_href":"https:\/\/github.com\/socketio\/engine.io\/commit\/734f9d1268840722c41219e69eb58318e0b2ac6b",
      "commit_sha":"734f9d1268840722c41219e69eb58318e0b2ac6b",
      "patch":"SINGLE",
      "chain_ord":"['734f9d1268840722c41219e69eb58318e0b2ac6b']",
      "before_first_fix_commit":"{'61b949259ed966ef6fc8bfd61f14d1a2ef06d319'}",
      "last_fix_commit":"734f9d1268840722c41219e69eb58318e0b2ac6b",
      "chain_ord_pos":1.0,
      "commit_datetime":"02\/11\/2020, 06:57:29",
      "message":"feat: decrease the default value of maxHttpBufferSize\n\nThis change reduces the default value from 100 mb to a more sane 1 mb.\n\nThis helps protect the server against denial of service attacks by\nmalicious clients sending huge amounts of data.",
      "author":"Damien Arrachequesne",
      "comments":"{'com_1': {'author': 'abergmann', 'datetime': '01\/08\/2021, 09:14:06', 'body': '[CVE-2020-36048](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-36048) was assigned to this commit.'}, 'com_2': {'author': 'ixevix', 'datetime': '05\/11\/2022, 18:37:43', 'body': 'Any luck getting this into an official release on some version of engine.io that socket.io v2.4.x depends on?'}, 'com_3': {'author': 'darrachequesne', 'datetime': '06\/27\/2022, 05:35:10', 'body': '@ixevix here we go:\\r\\n\\r\\n- https:\/\/github.com\/socketio\/engine.io\/releases\/tag\/3.6.0\\r\\n- https:\/\/github.com\/socketio\/socket.io\/releases\/tag\/2.5.0'}}",
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'lib\/server.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/socketio\/engine.io\/raw\/734f9d1268840722c41219e69eb58318e0b2ac6b\/lib%2Fserver.js', 'patch': '@@ -26,7 +26,7 @@ class Server extends EventEmitter {\\n         pingTimeout: 5000,\\n         pingInterval: 25000,\\n         upgradeTimeout: 10000,\\n-        maxHttpBufferSize: 10e7,\\n+        maxHttpBufferSize: 1e6,\\n         transports: Object.keys(transports),\\n         allowUpgrades: true,\\n         perMessageDeflate: {'}}",
      "message_norm":"feat: decrease the default value of maxhttpbuffersize\n\nthis change reduces the default value from 100 mb to a more sane 1 mb.\n\nthis helps protect the server against denial of service attacks by\nmalicious clients sending huge amounts of data.",
      "language":"en",
      "entities":"[('protect', 'SECWORD', ''), ('server', 'SECWORD', ''), ('denial of service', 'SECWORD', ''), ('attacks', 'SECWORD', ''), ('malicious', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/server.js'])",
      "num_files":1.0,
      "patch_content":"From 734f9d1268840722c41219e69eb58318e0b2ac6b Mon Sep 17 00:00:00 2001\nFrom: Damien Arrachequesne <damien.arrachequesne@gmail.com>\nDate: Tue, 11 Feb 2020 07:57:29 +0100\nSubject: [PATCH] feat: decrease the default value of maxHttpBufferSize\n\nThis change reduces the default value from 100 mb to a more sane 1 mb.\n\nThis helps protect the server against denial of service attacks by\nmalicious clients sending huge amounts of data.\n---\n lib\/server.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/server.js b\/lib\/server.js\nindex 527c7a0f9..9b30a4abe 100644\n--- a\/lib\/server.js\n+++ b\/lib\/server.js\n@@ -26,7 +26,7 @@ class Server extends EventEmitter {\n         pingTimeout: 5000,\n         pingInterval: 25000,\n         upgradeTimeout: 10000,\n-        maxHttpBufferSize: 10e7,\n+        maxHttpBufferSize: 1e6,\n         transports: Object.keys(transports),\n         allowUpgrades: true,\n         perMessageDeflate: {",
      "code_diff":"@@ -26,7 +26,7 @@ class Server extends EventEmitter {\n         pingTimeout: 5000,\n         pingInterval: 25000,\n         upgradeTimeout: 10000,\n-        maxHttpBufferSize: 10e7,\n+        maxHttpBufferSize: 1e6,\n         transports: Object.keys(transports),\n         allowUpgrades: true,\n         perMessageDeflate: {"
    },
    {
      "index":31,
      "vuln_id":"GHSA-hwj9-h5mp-3pm3",
      "cwe_id":"{'CWE-400'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/postcss\/postcss\/commit\/54cbf3c4847eb0fb1501b9d2337465439e849734', 'https:\/\/github.com\/postcss\/postcss\/commit\/b6f3e4d5a8d7504d553267f80384373af3a3dec5', 'https:\/\/github.com\/postcss\/postcss\/commit\/8682b1e4e328432ba692bed52326e84439cec9e4'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in postcss The npm package `postcss` from 7.0.0 and before versions 7.0.36 and 8.2.10 is vulnerable to Regular Expression Denial of Service (ReDoS) during source map parsing.",
      "published_date":"2021-05-10",
      "chain_len":3,
      "project":"https:\/\/github.com\/postcss\/postcss",
      "commit_href":"https:\/\/github.com\/postcss\/postcss\/commit\/b6f3e4d5a8d7504d553267f80384373af3a3dec5",
      "commit_sha":"b6f3e4d5a8d7504d553267f80384373af3a3dec5",
      "patch":"MULTI",
      "chain_ord":"['8682b1e4e328432ba692bed52326e84439cec9e4', 'b6f3e4d5a8d7504d553267f80384373af3a3dec5', '54cbf3c4847eb0fb1501b9d2337465439e849734']",
      "before_first_fix_commit":"{'12832f3d203474bd273bd06bd3b2407567bfe09e'}",
      "last_fix_commit":"54cbf3c4847eb0fb1501b9d2337465439e849734",
      "chain_ord_pos":2.0,
      "commit_datetime":"04\/11\/2021, 13:03:12",
      "message":"Fix unsafe regexp in getAnnotationURL() too",
      "author":"Andrey Sitnik",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 3, 'total': 4}",
      "files":"{'lib\/previous-map.js': {'additions': 1, 'deletions': 3, 'changes': 4, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/postcss\/postcss\/raw\/b6f3e4d5a8d7504d553267f80384373af3a3dec5\/lib%2Fprevious-map.js', 'patch': '@@ -48,9 +48,7 @@ class PreviousMap {\\n   }\\n \\n   getAnnotationURL(sourceMapString) {\\n-    return sourceMapString\\n-      .match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\s*\\\\*\\\\\/\/)[1]\\n-      .trim()\\n+    return sourceMapString.match(\/\\\\\/\\\\*\\\\s*# sourceMappingURL=(.*)\\\\*\\\\\/\/)[1].trim()\\n   }\\n \\n   loadAnnotation(css) {'}}",
      "message_norm":"fix unsafe regexp in getannotationurl() too",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('unsafe', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/previous-map.js'])",
      "num_files":1.0,
      "patch_content":"From b6f3e4d5a8d7504d553267f80384373af3a3dec5 Mon Sep 17 00:00:00 2001\nFrom: Andrey Sitnik <andrey@sitnik.ru>\nDate: Sun, 11 Apr 2021 09:03:12 -0400\nSubject: [PATCH] Fix unsafe regexp in getAnnotationURL() too\n\n---\n lib\/previous-map.js | 4 +---\n 1 file changed, 1 insertion(+), 3 deletions(-)\n\ndiff --git a\/lib\/previous-map.js b\/lib\/previous-map.js\nindex ff474a2bf..d9308ff26 100644\n--- a\/lib\/previous-map.js\n+++ b\/lib\/previous-map.js\n@@ -48,9 +48,7 @@ class PreviousMap {\n   }\n \n   getAnnotationURL(sourceMapString) {\n-    return sourceMapString\n-      .match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\s*\\*\\\/\/)[1]\n-      .trim()\n+    return sourceMapString.match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\*\\\/\/)[1].trim()\n   }\n \n   loadAnnotation(css) {",
      "code_diff":"@@ -48,9 +48,7 @@ class PreviousMap {\n   }\n \n   getAnnotationURL(sourceMapString) {\n-    return sourceMapString\n-      .match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\s*\\*\\\/\/)[1]\n-      .trim()\n+    return sourceMapString.match(\/\\\/\\*\\s*# sourceMappingURL=(.*)\\*\\\/\/)[1].trim()\n   }\n \n   loadAnnotation(css) {"
    },
    {
      "index":32,
      "vuln_id":"GHSA-hj5v-574p-mj7c",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/pytest-dev\/py\/pull\/257\/commits\/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144'}",
      "dataset":"osv",
      "summary":"Regular expression deinal of service in py A denial of service via regular expression in the py.path.svnwc component of py (aka python-py) through 1.9.0 could be used by attackers to cause a compute-time denial of service attack by supplying malicious input to the blame functionality.",
      "published_date":"2021-04-20",
      "chain_len":1,
      "project":"https:\/\/github.com\/pytest-dev\/py",
      "commit_href":"https:\/\/github.com\/pytest-dev\/py\/pull\/257\/commits\/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144",
      "commit_sha":"4a9017dc6199d2a564b6e4b0aa39d6d8870e4144",
      "patch":"SINGLE",
      "chain_ord":"['4a9017dc6199d2a564b6e4b0aa39d6d8870e4144']",
      "before_first_fix_commit":"{'2da2caea38812eaa3ce09dd5292e3635ce9b16c8'}",
      "last_fix_commit":"4a9017dc6199d2a564b6e4b0aa39d6d8870e4144",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/04\/2020, 10:57:26",
      "message":"svnwc: fix regular expression vulnerable to DoS in blame functionality\n\nThe subpattern `\\d+\\s*\\S+` is ambiguous which makes the pattern subject\nto catastrophic backtracing given a string like `\"1\" * 5000`.\n\nSVN blame output seems to always have at least one space between the\nrevision number and the user name, so the ambiguity can be fixed by\nchanging the `*` to `+`.\n\nFixes #256.",
      "author":"Ran Benita",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'py\/_path\/svnwc.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/pytest-dev\/py\/raw\/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144\/py%2F_path%2Fsvnwc.py', 'patch': '@@ -396,7 +396,7 @@ def makecmdoptions(self):\\n     def __str__(self):\\n         return \"<SvnAuth username=%s ...>\" %(self.username,)\\n \\n-rex_blame = re.compile(r\\'\\\\s*(\\\\d+)\\\\s*(\\\\S+) (.*)\\')\\n+rex_blame = re.compile(r\\'\\\\s*(\\\\d+)\\\\s+(\\\\S+) (.*)\\')\\n \\n class SvnWCCommandPath(common.PathBase):\\n     \"\"\" path implementation offering access\/modification to svn working copies.'}}",
      "message_norm":"svnwc: fix regular expression vulnerable to dos in blame functionality\n\nthe subpattern `\\d+\\s*\\s+` is ambiguous which makes the pattern subject\nto catastrophic backtracing given a string like `\"1\" * 5000`.\n\nsvn blame output seems to always have at least one space between the\nrevision number and the user name, so the ambiguity can be fixed by\nchanging the `*` to `+`.\n\nfixes #256.",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('vulnerable', 'SECWORD', ''), ('dos', 'SECWORD', ''), ('user name', 'SECWORD', ''), ('fixed', 'ACTION', ''), ('changing', 'ACTION', ''), ('fixes', 'ACTION', ''), ('#256', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['py\/_path\/svnwc.py'])",
      "num_files":1.0,
      "patch_content":"From 4a9017dc6199d2a564b6e4b0aa39d6d8870e4144 Mon Sep 17 00:00:00 2001\nFrom: Ran Benita <ran@unusedvar.com>\nDate: Fri, 4 Sep 2020 13:57:26 +0300\nSubject: [PATCH] svnwc: fix regular expression vulnerable to DoS in blame\n functionality\n\nThe subpattern `\\d+\\s*\\S+` is ambiguous which makes the pattern subject\nto catastrophic backtracing given a string like `\"1\" * 5000`.\n\nSVN blame output seems to always have at least one space between the\nrevision number and the user name, so the ambiguity can be fixed by\nchanging the `*` to `+`.\n\nFixes #256.\n---\n py\/_path\/svnwc.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/py\/_path\/svnwc.py b\/py\/_path\/svnwc.py\nindex 3138dd85..b5b9d8d5 100644\n--- a\/py\/_path\/svnwc.py\n+++ b\/py\/_path\/svnwc.py\n@@ -396,7 +396,7 @@ def makecmdoptions(self):\n     def __str__(self):\n         return \"<SvnAuth username=%s ...>\" %(self.username,)\n \n-rex_blame = re.compile(r'\\s*(\\d+)\\s*(\\S+) (.*)')\n+rex_blame = re.compile(r'\\s*(\\d+)\\s+(\\S+) (.*)')\n \n class SvnWCCommandPath(common.PathBase):\n     \"\"\" path implementation offering access\/modification to svn working copies.",
      "code_diff":"@@ -396,7 +396,7 @@ def makecmdoptions(self):\n     def __str__(self):\n         return \"<SvnAuth username=%s ...>\" %(self.username,)\n \n-rex_blame = re.compile(r'\\s*(\\d+)\\s*(\\S+) (.*)')\n+rex_blame = re.compile(r'\\s*(\\d+)\\s+(\\S+) (.*)')\n \n class SvnWCCommandPath(common.PathBase):\n     \"\"\" path implementation offering access\/modification to svn working copies."
    },
    {
      "index":33,
      "vuln_id":"GHSA-7q4h-pj78-j7vg",
      "cwe_id":"{'CWE-400', 'CWE-918'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/apache\/cxf\/commit\/aa789c5c4686597a7bdef2443909ab491fc2bc04', 'https:\/\/github.com\/apache\/cxf\/commit\/40503a53914758759894f704bbf139ae89ace286'}",
      "dataset":"osv",
      "summary":"Authorization service vulnerable to DDos attacks in Apache CFX CXF supports (via JwtRequestCodeFilter) passing OAuth 2 parameters via a JWT token as opposed to query parameters (see: The OAuth 2.0 Authorization Framework: JWT Secured Authorization Request (JAR)). Instead of sending a JWT token as a \"request\" parameter, the spec also supports specifying a URI from which to retrieve a JWT token from via the \"request_uri\" parameter. CXF was not validating the \"request_uri\" parameter (apart from ensuring it uses \"https) and was making a REST request to the parameter in the request to retrieve a token. This means that CXF was vulnerable to DDos attacks on the authorization server, as specified in section 10.4.1 of the spec. This issue affects Apache CXF versions prior to 3.4.3; Apache CXF versions prior to 3.3.10.",
      "published_date":"2021-05-13",
      "chain_len":2,
      "project":"https:\/\/github.com\/apache\/cxf",
      "commit_href":"https:\/\/github.com\/apache\/cxf\/commit\/40503a53914758759894f704bbf139ae89ace286",
      "commit_sha":"40503a53914758759894f704bbf139ae89ace286",
      "patch":"MULTI",
      "chain_ord":"['40503a53914758759894f704bbf139ae89ace286', 'aa789c5c4686597a7bdef2443909ab491fc2bc04']",
      "before_first_fix_commit":"{'40503a53914758759894f704bbf139ae89ace286'}",
      "last_fix_commit":"aa789c5c4686597a7bdef2443909ab491fc2bc04",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/06\/2021, 09:30:08",
      "message":"Disallow OAuth2 request_uri by default",
      "author":"Colm O hEigeartaigh",
      "comments":null,
      "stats":"{'additions': 13, 'deletions': 4, 'total': 17}",
      "files":"{'rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java': {'additions': 13, 'deletions': 4, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apache\/cxf\/raw\/40503a53914758759894f704bbf139ae89ace286\/rt%2Frs%2Fsecurity%2Foauth-parent%2Foauth2%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fcxf%2Frs%2Fsecurity%2Foauth2%2Fgrants%2Fcode%2FJwtRequestCodeFilter.java', 'patch': '@@ -42,6 +42,7 @@\\n import org.apache.cxf.rt.security.crypto.CryptoUtils;\\n \\n public class JwtRequestCodeFilter extends OAuthJoseJwtConsumer implements AuthorizationRequestFilter {\\n+    private static final String REQUEST_URI_CONTENT_TYPE = \"application\/oauth-authz-req+jwt\";\\n     private static final String REQUEST_PARAM = \"request\";\\n     private static final String REQUEST_URI_PARAM = \"request_uri\";\\n     private boolean verifyWithClientCertificates;\\n@@ -55,7 +56,7 @@ public MultivaluedMap<String, String> process(MultivaluedMap<String, String> par\\n         if (requestToken == null) {\\n             String requestUri = params.getFirst(REQUEST_URI_PARAM);\\n             if (isRequestUriValid(client, requestUri)) {\\n-                requestToken = WebClient.create(requestUri).get(String.class);\\n+                requestToken = WebClient.create(requestUri).accept(REQUEST_URI_CONTENT_TYPE).get(String.class);\\n             }\\n         }\\n         if (requestToken != null) {\\n@@ -101,9 +102,17 @@ public MultivaluedMap<String, String> process(MultivaluedMap<String, String> par\\n         }\\n         return params;\\n     }\\n-    private boolean isRequestUriValid(Client client, String requestUri) {\\n-        \/\/TODO: consider restricting to specific hosts\\n-        return requestUri != null && requestUri.startsWith(\"https:\/\/\");\\n+\\n+    \/**\\n+     * This method must be overridden to support request_uri. Take care to validate the request_uri properly,\\n+     * as otherwise it could lead to a security problem\\n+     * (https:\/\/tools.ietf.org\/html\/draft-ietf-oauth-jwsreq-30#section-10.4)\\n+     * @param client the Client object\\n+     * @param requestUri the request_uri parameter to validate\\n+     * @return whether the requestUri is permitted or not\\n+     *\/\\n+    protected boolean isRequestUriValid(Client client, String requestUri) {\\n+        return false;\\n     }\\n     protected JwsSignatureVerifier getInitializedSigVerifier(Client c) {\\n         if (verifyWithClientCertificates) {'}}",
      "message_norm":"disallow oauth2 request_uri by default",
      "language":"en",
      "entities":null,
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java'])",
      "num_files":1.0,
      "patch_content":"From 40503a53914758759894f704bbf139ae89ace286 Mon Sep 17 00:00:00 2001\nFrom: Colm O hEigeartaigh <coheigea@apache.org>\nDate: Wed, 6 Jan 2021 09:30:08 +0000\nSubject: [PATCH] Disallow OAuth2 request_uri by default\n\n---\n ...\/grants\/code\/JwtRequestCodeFilter.java       | 17 +++++++++++++----\n 1 file changed, 13 insertions(+), 4 deletions(-)\n\ndiff --git a\/rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java b\/rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java\nindex 4ef8dc96439..29ac00020d4 100644\n--- a\/rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java\n+++ b\/rt\/rs\/security\/oauth-parent\/oauth2\/src\/main\/java\/org\/apache\/cxf\/rs\/security\/oauth2\/grants\/code\/JwtRequestCodeFilter.java\n@@ -42,6 +42,7 @@\n import org.apache.cxf.rt.security.crypto.CryptoUtils;\n \n public class JwtRequestCodeFilter extends OAuthJoseJwtConsumer implements AuthorizationRequestFilter {\n+    private static final String REQUEST_URI_CONTENT_TYPE = \"application\/oauth-authz-req+jwt\";\n     private static final String REQUEST_PARAM = \"request\";\n     private static final String REQUEST_URI_PARAM = \"request_uri\";\n     private boolean verifyWithClientCertificates;\n@@ -55,7 +56,7 @@ public MultivaluedMap<String, String> process(MultivaluedMap<String, String> par\n         if (requestToken == null) {\n             String requestUri = params.getFirst(REQUEST_URI_PARAM);\n             if (isRequestUriValid(client, requestUri)) {\n-                requestToken = WebClient.create(requestUri).get(String.class);\n+                requestToken = WebClient.create(requestUri).accept(REQUEST_URI_CONTENT_TYPE).get(String.class);\n             }\n         }\n         if (requestToken != null) {\n@@ -101,9 +102,17 @@ public MultivaluedMap<String, String> process(MultivaluedMap<String, String> par\n         }\n         return params;\n     }\n-    private boolean isRequestUriValid(Client client, String requestUri) {\n-        \/\/TODO: consider restricting to specific hosts\n-        return requestUri != null && requestUri.startsWith(\"https:\/\/\");\n+\n+    \/**\n+     * This method must be overridden to support request_uri. Take care to validate the request_uri properly,\n+     * as otherwise it could lead to a security problem\n+     * (https:\/\/tools.ietf.org\/html\/draft-ietf-oauth-jwsreq-30#section-10.4)\n+     * @param client the Client object\n+     * @param requestUri the request_uri parameter to validate\n+     * @return whether the requestUri is permitted or not\n+     *\/\n+    protected boolean isRequestUriValid(Client client, String requestUri) {\n+        return false;\n     }\n     protected JwsSignatureVerifier getInitializedSigVerifier(Client c) {\n         if (verifyWithClientCertificates) {",
      "code_diff":"@@ -42,6 +42,7 @@\n import org.apache.cxf.rt.security.crypto.CryptoUtils;\n \n public class JwtRequestCodeFilter extends OAuthJoseJwtConsumer implements AuthorizationRequestFilter {\n+    private static final String REQUEST_URI_CONTENT_TYPE = \"application\/oauth-authz-req+jwt\";\n     private static final String REQUEST_PARAM = \"request\";\n     private static final String REQUEST_URI_PARAM = \"request_uri\";\n     private boolean verifyWithClientCertificates;\n@@ -55,7 +56,7 @@ public MultivaluedMap<String, String> process(MultivaluedMap<String, String> par\n         if (requestToken == null) {\n             String requestUri = params.getFirst(REQUEST_URI_PARAM);\n             if (isRequestUriValid(client, requestUri)) {\n-                requestToken = WebClient.create(requestUri).get(String.class);\n+                requestToken = WebClient.create(requestUri).accept(REQUEST_URI_CONTENT_TYPE).get(String.class);\n             }\n         }\n         if (requestToken != null) {\n@@ -101,9 +102,17 @@ public MultivaluedMap<String, String> process(MultivaluedMap<String, String> par\n         }\n         return params;\n     }\n-    private boolean isRequestUriValid(Client client, String requestUri) {\n-        \/\/TODO: consider restricting to specific hosts\n-        return requestUri != null && requestUri.startsWith(\"https:\/\/\");\n+\n+    \/**\n+     * This method must be overridden to support request_uri. Take care to validate the request_uri properly,\n+     * as otherwise it could lead to a security problem\n+     * (https:\/\/tools.ietf.org\/html\/draft-ietf-oauth-jwsreq-30#section-10.4)\n+     * @param client the Client object\n+     * @param requestUri the request_uri parameter to validate\n+     * @return whether the requestUri is permitted or not\n+     *\/\n+    protected boolean isRequestUriValid(Client client, String requestUri) {\n+        return false;\n     }\n     protected JwsSignatureVerifier getInitializedSigVerifier(Client c) {\n         if (verifyWithClientCertificates) {"
    },
    {
      "index":34,
      "vuln_id":"GHSA-35q2-47q7-3pc3",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/NodeRedis\/node-redis\/commit\/2d11b6dc9b9774464a91fb4b448bad8bf699629e'}",
      "dataset":"osv",
      "summary":"Node-Redis potential exponential regex in monitor mode ### Impact\nWhen a client is in monitoring mode, the regex begin used to detected monitor messages could cause exponential backtracking on some strings. This issue could lead to a denial of service.\n\n### Patches\nThe problem was fixed in commit [`2d11b6d`](https:\/\/github.com\/NodeRedis\/node-redis\/commit\/2d11b6dc9b9774464a91fb4b448bad8bf699629e) and was released in version `3.1.1`.\n\n### References\n#1569 (GHSL-2021-026)",
      "published_date":"2021-04-27",
      "chain_len":1,
      "project":"https:\/\/github.com\/NodeRedis\/node-redis",
      "commit_href":"https:\/\/github.com\/NodeRedis\/node-redis\/commit\/2d11b6dc9b9774464a91fb4b448bad8bf699629e",
      "commit_sha":"2d11b6dc9b9774464a91fb4b448bad8bf699629e",
      "patch":"SINGLE",
      "chain_ord":"['2d11b6dc9b9774464a91fb4b448bad8bf699629e']",
      "before_first_fix_commit":"{'7e77de84bc80b0742321939c59612dc27559bbff'}",
      "last_fix_commit":"2d11b6dc9b9774464a91fb4b448bad8bf699629e",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/08\/2021, 22:04:34",
      "message":"fix #1569 - improve monitor_regex (#1595)\n\nCo-authored-by: Guy Korland <gkorland@gmail.com>",
      "author":"Leibale Eidelman",
      "comments":"{'com_1': {'author': 'Plavit', 'datetime': '04\/27\/2021, 21:27:30', 'body': 'lemme check compatibility'}}",
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'lib\/utils.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/redis\/node-redis\/raw\/2d11b6dc9b9774464a91fb4b448bad8bf699629e\/lib%2Futils.js', 'patch': '@@ -127,7 +127,7 @@ module.exports = {\\n     reply_to_object: replyToObject,\\n     print: print,\\n     err_code: \/^([A-Z]+)\\\\s+(.+)$\/,\\n-    monitor_regex: \/^[0-9]{10,11}\\\\.[0-9]+ \\\\[[0-9]+ .+\\\\]( \".+?\")+$\/,\\n+    monitor_regex: \/^[0-9]{10,11}\\\\.[0-9]+ \\\\[[0-9]+ .+\\\\].*\"$\/,\\n     clone: convenienceClone,\\n     callback_or_emit: callbackOrEmit,\\n     reply_in_order: replyInOrder'}}",
      "message_norm":"fix #1569 - improve monitor_regex (#1595)\n\nco-authored-by: guy korland <gkorland@gmail.com>",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('#1569', 'ISSUE', ''), ('improve', 'ACTION', ''), ('#1595', 'ISSUE', ''), ('gkorland@gmail.com', 'EMAIL', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/utils.js'])",
      "num_files":1.0,
      "patch_content":"From 2d11b6dc9b9774464a91fb4b448bad8bf699629e Mon Sep 17 00:00:00 2001\nFrom: Leibale Eidelman <leibale1998@gmail.com>\nDate: Thu, 8 Apr 2021 18:04:34 -0400\nSubject: [PATCH] fix #1569 - improve monitor_regex (#1595)\n\nCo-authored-by: Guy Korland <gkorland@gmail.com>\n---\n lib\/utils.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/utils.js b\/lib\/utils.js\nindex 52e58ecfa6c..d0336ae9c1d 100644\n--- a\/lib\/utils.js\n+++ b\/lib\/utils.js\n@@ -127,7 +127,7 @@ module.exports = {\n     reply_to_object: replyToObject,\n     print: print,\n     err_code: \/^([A-Z]+)\\s+(.+)$\/,\n-    monitor_regex: \/^[0-9]{10,11}\\.[0-9]+ \\[[0-9]+ .+\\]( \".+?\")+$\/,\n+    monitor_regex: \/^[0-9]{10,11}\\.[0-9]+ \\[[0-9]+ .+\\].*\"$\/,\n     clone: convenienceClone,\n     callback_or_emit: callbackOrEmit,\n     reply_in_order: replyInOrder",
      "code_diff":"@@ -127,7 +127,7 @@ module.exports = {\n     reply_to_object: replyToObject,\n     print: print,\n     err_code: \/^([A-Z]+)\\s+(.+)$\/,\n-    monitor_regex: \/^[0-9]{10,11}\\.[0-9]+ \\[[0-9]+ .+\\]( \".+?\")+$\/,\n+    monitor_regex: \/^[0-9]{10,11}\\.[0-9]+ \\[[0-9]+ .+\\].*\"$\/,\n     clone: convenienceClone,\n     callback_or_emit: callbackOrEmit,\n     reply_in_order: replyInOrder"
    },
    {
      "index":35,
      "vuln_id":"GHSA-8462-q7x7-g2x4",
      "cwe_id":"{'CWE-400', 'CWE-185'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/mongodb\/js-bson\/commit\/bd61c45157c53a1698ff23770160cf4783e9ea4a'}",
      "dataset":"osv",
      "summary":"High severity vulnerability that affects bson The MongoDB bson JavaScript module (also known as js-bson) versions 0.5.0 to 1.0.x before 1.0.5 is vulnerable to a Regular Expression Denial of Service (ReDoS) in lib\/bson\/decimal128.js. The flaw is triggered when the Decimal128.fromString() function is called to parse a long untrusted string.",
      "published_date":"2018-09-17",
      "chain_len":1,
      "project":"https:\/\/github.com\/mongodb\/js-bson",
      "commit_href":"https:\/\/github.com\/mongodb\/js-bson\/commit\/bd61c45157c53a1698ff23770160cf4783e9ea4a",
      "commit_sha":"bd61c45157c53a1698ff23770160cf4783e9ea4a",
      "patch":"SINGLE",
      "chain_ord":"['bd61c45157c53a1698ff23770160cf4783e9ea4a']",
      "before_first_fix_commit":"{'e403bd94faadee80cd82bae888e28b8b4d6d1e8d'}",
      "last_fix_commit":"bd61c45157c53a1698ff23770160cf4783e9ea4a",
      "chain_ord_pos":1.0,
      "commit_datetime":"02\/26\/2018, 20:09:27",
      "message":"fix(decimal128): add basic guard against REDOS attacks\n\nThis is a naive approach to reducing the efficacy of a REDOS attack\nagainst this module. A refactor of the regular expression or a\ncustom parser substitute would be ideal, however this solution\nsuffices as a stopgap until such work is completed.\n\nMany thanks to James Davis who graciously alterted us to the\nattack",
      "author":"Matt Broadstone",
      "comments":null,
      "stats":"{'additions': 7, 'deletions': 0, 'total': 7}",
      "files":"{'lib\/bson\/decimal128.js': {'additions': 7, 'deletions': 0, 'changes': 7, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/mongodb\/js-bson\/raw\/bd61c45157c53a1698ff23770160cf4783e9ea4a\/lib%2Fbson%2Fdecimal128.js', 'patch': \"@@ -235,6 +235,13 @@ Decimal128.fromString = function(string) {\\n   \/\/ Trim the string\\n   string = string.trim();\\n \\n+  \/\/ Naively prevent against REDOS attacks.\\n+  \/\/ TODO: implementing a custom parsing for this, or refactoring the regex would yield\\n+  \/\/       further gains.\\n+  if (string.length >= 7000) {\\n+    throw new Error('' + string + ' not a valid Decimal128 string');\\n+  }\\n+\\n   \/\/ Results\\n   var stringMatch = string.match(PARSE_STRING_REGEXP);\\n   var infMatch = string.match(PARSE_INF_REGEXP);\"}}",
      "message_norm":"fix(decimal128): add basic guard against redos attacks\n\nthis is a naive approach to reducing the efficacy of a redos attack\nagainst this module. a refactor of the regular expression or a\ncustom parser substitute would be ideal, however this solution\nsuffices as a stopgap until such work is completed.\n\nmany thanks to james davis who graciously alterted us to the\nattack",
      "language":"en",
      "entities":"[('fix(decimal128', 'ACTION', ''), ('add', 'ACTION', ''), ('redos', 'SECWORD', ''), ('attacks', 'FLAW', ''), ('redos', 'SECWORD', ''), ('attack', 'FLAW', ''), ('attack', 'FLAW', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/bson\/decimal128.js'])",
      "num_files":1.0,
      "patch_content":"From bd61c45157c53a1698ff23770160cf4783e9ea4a Mon Sep 17 00:00:00 2001\nFrom: Matt Broadstone <mbroadst@gmail.com>\nDate: Mon, 26 Feb 2018 15:09:27 -0500\nSubject: [PATCH] fix(decimal128): add basic guard against REDOS attacks\n\nThis is a naive approach to reducing the efficacy of a REDOS attack\nagainst this module. A refactor of the regular expression or a\ncustom parser substitute would be ideal, however this solution\nsuffices as a stopgap until such work is completed.\n\nMany thanks to James Davis who graciously alterted us to the\nattack\n---\n lib\/bson\/decimal128.js | 7 +++++++\n 1 file changed, 7 insertions(+)\n\ndiff --git a\/lib\/bson\/decimal128.js b\/lib\/bson\/decimal128.js\nindex 6cf24331..1dc2f003 100644\n--- a\/lib\/bson\/decimal128.js\n+++ b\/lib\/bson\/decimal128.js\n@@ -235,6 +235,13 @@ Decimal128.fromString = function(string) {\n   \/\/ Trim the string\n   string = string.trim();\n \n+  \/\/ Naively prevent against REDOS attacks.\n+  \/\/ TODO: implementing a custom parsing for this, or refactoring the regex would yield\n+  \/\/       further gains.\n+  if (string.length >= 7000) {\n+    throw new Error('' + string + ' not a valid Decimal128 string');\n+  }\n+\n   \/\/ Results\n   var stringMatch = string.match(PARSE_STRING_REGEXP);\n   var infMatch = string.match(PARSE_INF_REGEXP);",
      "code_diff":"@@ -235,6 +235,13 @@ Decimal128.fromString = function(string) {\n   \/\/ Trim the string\n   string = string.trim();\n \n+  \/\/ Naively prevent against REDOS attacks.\n+  \/\/ TODO: implementing a custom parsing for this, or refactoring the regex would yield\n+  \/\/       further gains.\n+  if (string.length >= 7000) {\n+    throw new Error('' + string + ' not a valid Decimal128 string');\n+  }\n+\n   \/\/ Results\n   var stringMatch = string.match(PARSE_STRING_REGEXP);\n   var infMatch = string.match(PARSE_INF_REGEXP);"
    },
    {
      "index":36,
      "vuln_id":"GHSA-3pcq-34w5-p4g2",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/nicolas-van\/modern-async\/commit\/0010d28de1b15d51db3976080e26357fa7144436'}",
      "dataset":"osv",
      "summary":"forEachSeries and forEachLimit do not limit the number of requests ### Impact\n\nThis is a bug affecting two of the functions in this library: forEachSeries and forEachLimit. They should limit the concurrency of some actions but, in practice, they don't. Any code calling these functions will be written thinking they would limit the concurrency but they won't. This could lead to potential security issues in other projects.\n\n### Patches\n\nThe problem has been patched in 1.0.4.\n\n### Workarounds\n\nThere is no workaround aside from upgrading to 1.0.4.",
      "published_date":"2021-10-21",
      "chain_len":1,
      "project":"https:\/\/github.com\/nicolas-van\/modern-async",
      "commit_href":"https:\/\/github.com\/nicolas-van\/modern-async\/commit\/0010d28de1b15d51db3976080e26357fa7144436",
      "commit_sha":"0010d28de1b15d51db3976080e26357fa7144436",
      "patch":"SINGLE",
      "chain_ord":"['0010d28de1b15d51db3976080e26357fa7144436']",
      "before_first_fix_commit":"{'7aa934294e59bc7359651a852e73bd5785b9b99b'}",
      "last_fix_commit":"0010d28de1b15d51db3976080e26357fa7144436",
      "chain_ord_pos":1.0,
      "commit_datetime":"10\/19\/2021, 21:22:02",
      "message":"Fix #5",
      "author":"Nicolas Vanhoren",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'src\/forEachLimit.mjs': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/nicolas-van\/modern-async\/raw\/0010d28de1b15d51db3976080e26357fa7144436\/src%2FforEachLimit.mjs', 'patch': \"@@ -35,7 +35,7 @@ import mapLimit from '.\/mapLimit.mjs'\\n  *\/\\n async function forEachLimit (iterable, iteratee, concurrency) {\\n   await mapLimit(iterable, async (v, i, t) => {\\n-    iteratee(v, i, t)\\n+    await iteratee(v, i, t)\\n   }, concurrency)\\n }\"}}",
      "message_norm":"fix #5",
      "language":"ca",
      "entities":"[('fix', 'ACTION', ''), ('#5', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/forEachLimit.mjs'])",
      "num_files":1.0,
      "patch_content":"From 0010d28de1b15d51db3976080e26357fa7144436 Mon Sep 17 00:00:00 2001\nFrom: Nicolas Vanhoren <nicolas.vanhoren@gmail.com>\nDate: Tue, 19 Oct 2021 23:22:02 +0200\nSubject: [PATCH] Fix #5\n\n---\n src\/forEachLimit.mjs | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/forEachLimit.mjs b\/src\/forEachLimit.mjs\nindex 08841a7..e6c44fe 100644\n--- a\/src\/forEachLimit.mjs\n+++ b\/src\/forEachLimit.mjs\n@@ -35,7 +35,7 @@ import mapLimit from '.\/mapLimit.mjs'\n  *\/\n async function forEachLimit (iterable, iteratee, concurrency) {\n   await mapLimit(iterable, async (v, i, t) => {\n-    iteratee(v, i, t)\n+    await iteratee(v, i, t)\n   }, concurrency)\n }",
      "code_diff":"@@ -35,7 +35,7 @@ import mapLimit from '.\/mapLimit.mjs'\n  *\/\n async function forEachLimit (iterable, iteratee, concurrency) {\n   await mapLimit(iterable, async (v, i, t) => {\n-    iteratee(v, i, t)\n+    await iteratee(v, i, t)\n   }, concurrency)\n }"
    },
    {
      "index":37,
      "vuln_id":"GHSA-74cr-77xc-8g6r",
      "cwe_id":"{'CWE-400', 'CWE-1321'}",
      "score":7.3,
      "chain":"{'https:\/\/github.com\/apollographql\/apollo-server\/commit\/cea7397582a293af6a5f60947da34b95e669c6c1'}",
      "dataset":"osv",
      "summary":"Prototype Pollution in @apollo\/gateway Versions of `@apollo\/gateway` prior to 0.6.2 are vulnerable to Prototype Pollution. The package uses deepMerge() to merge objects, which may allow attackers to alter the Object prototype through queries with GraphQL aliases. Carefully constructed payloads can override properties of all objects in the application. This may lead to Denial of Service or may be chained with other vulnerabilities leading to Remote Code Execution.\n\n\n## Recommendation\n\nUpgrade to version 0.6.2 or later.",
      "published_date":"2019-06-13",
      "chain_len":1,
      "project":"https:\/\/github.com\/apollographql\/apollo-server",
      "commit_href":"https:\/\/github.com\/apollographql\/apollo-server\/commit\/cea7397582a293af6a5f60947da34b95e669c6c1",
      "commit_sha":"cea7397582a293af6a5f60947da34b95e669c6c1",
      "patch":"SINGLE",
      "chain_ord":"['cea7397582a293af6a5f60947da34b95e669c6c1']",
      "before_first_fix_commit":"{'116e1b46ae8a58d5b77038d66588f208eb9b6e2a'}",
      "last_fix_commit":"cea7397582a293af6a5f60947da34b95e669c6c1",
      "chain_ord_pos":1.0,
      "commit_datetime":"06\/04\/2019, 22:58:07",
      "message":"Ignore __proto__ fields in deepMerge",
      "author":"Trevor Scheer",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'packages\/apollo-gateway\/src\/utilities\/deepMerge.ts': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/apollographql\/apollo-server\/raw\/cea7397582a293af6a5f60947da34b95e669c6c1\/packages%2Fapollo-gateway%2Fsrc%2Futilities%2FdeepMerge.ts', 'patch': \"@@ -4,7 +4,7 @@ export function deepMerge(target: any, source: any): any {\\n   if (source === undefined || source === null) return target;\\n \\n   for (const key of Object.keys(source)) {\\n-    if (source[key] === undefined) continue;\\n+    if (source[key] === undefined || key === '__proto__') continue;\\n \\n     if (target[key] && isObject(source[key])) {\\n       deepMerge(target[key], source[key]);\"}}",
      "message_norm":"ignore __proto__ fields in deepmerge",
      "language":"nl",
      "entities":null,
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['packages\/apollo-gateway\/src\/utilities\/deepMerge.ts'])",
      "num_files":1.0,
      "patch_content":"From cea7397582a293af6a5f60947da34b95e669c6c1 Mon Sep 17 00:00:00 2001\nFrom: Trevor Scheer <trevor@apollographql.com>\nDate: Tue, 4 Jun 2019 15:58:07 -0700\nSubject: [PATCH] Ignore __proto__ fields in deepMerge\n\n---\n packages\/apollo-gateway\/src\/utilities\/deepMerge.ts | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/packages\/apollo-gateway\/src\/utilities\/deepMerge.ts b\/packages\/apollo-gateway\/src\/utilities\/deepMerge.ts\nindex 27f135103dc..6756a36cac2 100644\n--- a\/packages\/apollo-gateway\/src\/utilities\/deepMerge.ts\n+++ b\/packages\/apollo-gateway\/src\/utilities\/deepMerge.ts\n@@ -4,7 +4,7 @@ export function deepMerge(target: any, source: any): any {\n   if (source === undefined || source === null) return target;\n \n   for (const key of Object.keys(source)) {\n-    if (source[key] === undefined) continue;\n+    if (source[key] === undefined || key === '__proto__') continue;\n \n     if (target[key] && isObject(source[key])) {\n       deepMerge(target[key], source[key]);",
      "code_diff":"@@ -4,7 +4,7 @@ export function deepMerge(target: any, source: any): any {\n   if (source === undefined || source === null) return target;\n \n   for (const key of Object.keys(source)) {\n-    if (source[key] === undefined) continue;\n+    if (source[key] === undefined || key === '__proto__') continue;\n \n     if (target[key] && isObject(source[key])) {\n       deepMerge(target[key], source[key]);"
    },
    {
      "index":38,
      "vuln_id":"GHSA-6fc8-4gx4-v693",
      "cwe_id":"{'CWE-400', 'CWE-345'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/websockets\/ws\/commit\/00c425ec77993773d823f018f64a5c44e17023ff'}",
      "dataset":"osv",
      "summary":"ReDoS in Sec-Websocket-Protocol header ### Impact\n\nA specially crafted value of the `Sec-Websocket-Protocol` header can be used to significantly slow down a ws server.\n\n### Proof of concept\n\n```js\nfor (const length of [1000, 2000, 4000, 8000, 16000, 32000]) {\n  const value = 'b' + ' '.repeat(length) + 'x';\n  const start = process.hrtime.bigint();\n\n  value.trim().split(\/ *, *\/);\n\n  const end = process.hrtime.bigint();\n\n  console.log('length = %d, time = %f ns', length, end - start);\n}\n```\n\n### Patches\n\nThe vulnerability was fixed in ws@7.4.6 (https:\/\/github.com\/websockets\/ws\/commit\/00c425ec77993773d823f018f64a5c44e17023ff) and backported to ws@6.2.2 (https:\/\/github.com\/websockets\/ws\/commit\/78c676d2a1acefbc05292e9f7ea0a9457704bf1b) and ws@5.2.3 (https:\/\/github.com\/websockets\/ws\/commit\/76d47c1479002022a3e4357b3c9f0e23a68d4cd2).\n\n### Workarounds\n\nIn vulnerable versions of ws, the issue can be mitigated by reducing the maximum allowed length of the request headers using the [`--max-http-header-size=size`](https:\/\/nodejs.org\/api\/cli.html#cli_max_http_header_size_size) and\/or the [`maxHeaderSize`](https:\/\/nodejs.org\/api\/http.html#http_http_createserver_options_requestlistener) options.\n\n### Credits\n\nThe vulnerability was responsibly disclosed along with a fix in private by [Robert McLaughlin](https:\/\/github.com\/robmcl4) from University of California, Santa Barbara.",
      "published_date":"2021-05-28",
      "chain_len":1,
      "project":"https:\/\/github.com\/websockets\/ws",
      "commit_href":"https:\/\/github.com\/websockets\/ws\/commit\/00c425ec77993773d823f018f64a5c44e17023ff",
      "commit_sha":"00c425ec77993773d823f018f64a5c44e17023ff",
      "patch":"SINGLE",
      "chain_ord":"['00c425ec77993773d823f018f64a5c44e17023ff']",
      "before_first_fix_commit":"{'990306d1446faf346c76452409a4c11455690514'}",
      "last_fix_commit":"00c425ec77993773d823f018f64a5c44e17023ff",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/25\/2021, 09:00:58",
      "message":"[security] Fix ReDoS vulnerability\n\nA specially crafted value of the `Sec-Websocket-Protocol` header could\nbe used to significantly slow down a ws server.\n\nPoC and fix were sent privately by Robert McLaughlin from University of\nCalifornia, Santa Barbara.",
      "author":"Luigi Pinca",
      "comments":null,
      "stats":"{'additions': 13, 'deletions': 1, 'total': 14}",
      "files":"{'lib\/websocket-server.js': {'additions': 13, 'deletions': 1, 'changes': 14, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/websockets\/ws\/raw\/00c425ec77993773d823f018f64a5c44e17023ff\/lib%2Fwebsocket-server.js', 'patch': \"@@ -286,7 +286,7 @@ class WebSocketServer extends EventEmitter {\\n     let protocol = req.headers['sec-websocket-protocol'];\\n \\n     if (protocol) {\\n-      protocol = protocol.trim().split(\/ *, *\/);\\n+      protocol = protocol.split(',').map(trim);\\n \\n       \/\/\\n       \/\/ Optionally call external protocol selection handler.\\n@@ -404,3 +404,15 @@ function abortHandshake(socket, code, message, headers) {\\n   socket.removeListener('error', socketOnError);\\n   socket.destroy();\\n }\\n+\\n+\/**\\n+ * Remove whitespace characters from both ends of a string.\\n+ *\\n+ * @param {String} str The string\\n+ * @return {String} A new string representing `str` stripped of whitespace\\n+ *     characters from both its beginning and end\\n+ * @private\\n+ *\/\\n+function trim(str) {\\n+  return str.trim();\\n+}\"}}",
      "message_norm":"[security] fix redos vulnerability\n\na specially crafted value of the `sec-websocket-protocol` header could\nbe used to significantly slow down a ws server.\n\npoc and fix were sent privately by robert mclaughlin from university of\ncalifornia, santa barbara.",
      "language":"en",
      "entities":"[('security', 'SECWORD', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('vulnerability', 'SECWORD', ''), ('protocol', 'SECWORD', ''), ('server', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/websocket-server.js'])",
      "num_files":1.0,
      "patch_content":"From 00c425ec77993773d823f018f64a5c44e17023ff Mon Sep 17 00:00:00 2001\nFrom: Luigi Pinca <luigipinca@gmail.com>\nDate: Tue, 25 May 2021 11:00:58 +0200\nSubject: [PATCH] [security] Fix ReDoS vulnerability\n\nA specially crafted value of the `Sec-Websocket-Protocol` header could\nbe used to significantly slow down a ws server.\n\nPoC and fix were sent privately by Robert McLaughlin from University of\nCalifornia, Santa Barbara.\n---\n lib\/websocket-server.js | 14 +++++++++++++-\n 1 file changed, 13 insertions(+), 1 deletion(-)\n\ndiff --git a\/lib\/websocket-server.js b\/lib\/websocket-server.js\nindex b99ad050a..3c3bbe0b0 100644\n--- a\/lib\/websocket-server.js\n+++ b\/lib\/websocket-server.js\n@@ -286,7 +286,7 @@ class WebSocketServer extends EventEmitter {\n     let protocol = req.headers['sec-websocket-protocol'];\n \n     if (protocol) {\n-      protocol = protocol.trim().split(\/ *, *\/);\n+      protocol = protocol.split(',').map(trim);\n \n       \/\/\n       \/\/ Optionally call external protocol selection handler.\n@@ -404,3 +404,15 @@ function abortHandshake(socket, code, message, headers) {\n   socket.removeListener('error', socketOnError);\n   socket.destroy();\n }\n+\n+\/**\n+ * Remove whitespace characters from both ends of a string.\n+ *\n+ * @param {String} str The string\n+ * @return {String} A new string representing `str` stripped of whitespace\n+ *     characters from both its beginning and end\n+ * @private\n+ *\/\n+function trim(str) {\n+  return str.trim();\n+}",
      "code_diff":"@@ -286,7 +286,7 @@ class WebSocketServer extends EventEmitter {\n     let protocol = req.headers['sec-websocket-protocol'];\n \n     if (protocol) {\n-      protocol = protocol.trim().split(\/ *, *\/);\n+      protocol = protocol.split(',').map(trim);\n \n       \/\/\n       \/\/ Optionally call external protocol selection handler.\n@@ -404,3 +404,15 @@ function abortHandshake(socket, code, message, headers) {\n   socket.removeListener('error', socketOnError);\n   socket.destroy();\n }\n+\n+\/**\n+ * Remove whitespace characters from both ends of a string.\n+ *\n+ * @param {String} str The string\n+ * @return {String} A new string representing `str` stripped of whitespace\n+ *     characters from both its beginning and end\n+ * @private\n+ *\/\n+function trim(str) {\n+  return str.trim();\n+}"
    },
    {
      "index":39,
      "vuln_id":"GHSA-h6ch-v84p-w6p9",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/kpdecker\/jsdiff\/commit\/2aec4298639bf30fb88a00b356bf404d3551b8c0'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service (ReDoS) A vulnerability was found in diff before v3.5.0, the affected versions of this package are vulnerable to Regular Expression Denial of Service (ReDoS) attacks.",
      "published_date":"2019-06-13",
      "chain_len":1,
      "project":"https:\/\/github.com\/kpdecker\/jsdiff",
      "commit_href":"https:\/\/github.com\/kpdecker\/jsdiff\/commit\/2aec4298639bf30fb88a00b356bf404d3551b8c0",
      "commit_sha":"2aec4298639bf30fb88a00b356bf404d3551b8c0",
      "patch":"SINGLE",
      "chain_ord":"['2aec4298639bf30fb88a00b356bf404d3551b8c0']",
      "before_first_fix_commit":"{'a47aca9cb199d558e02ce406e9838356803e204f'}",
      "last_fix_commit":"2aec4298639bf30fb88a00b356bf404d3551b8c0",
      "chain_ord_pos":1.0,
      "commit_datetime":"03\/05\/2018, 04:00:42",
      "message":"Optimize parch header parser",
      "author":"Kevin Decker",
      "comments":"{'com_1': {'author': 'mariosanchezgarcia', 'datetime': '07\/30\/2019, 17:32:24', 'body': 'Mario'}}",
      "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
      "files":"{'src\/patch\/parse.js': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/kpdecker\/jsdiff\/raw\/2aec4298639bf30fb88a00b356bf404d3551b8c0\/src%2Fpatch%2Fparse.js', 'patch': '@@ -53,16 +53,16 @@ export function parsePatch(uniDiff, options = {}) {\\n   \/\/ Parses the --- and +++ headers, if none are found, no lines\\n   \/\/ are consumed.\\n   function parseFileHeader(index) {\\n-    const headerPattern = \/^(---|\\\\+\\\\+\\\\+)\\\\s+([\\\\S ]*)(?:\\\\t(.*?)\\\\s*)?$\/;\\n-    const fileHeader = headerPattern.exec(diffstr[i]);\\n+    const fileHeader = (\/^(---|\\\\+\\\\+\\\\+)\\\\s+(.*)$\/).exec(diffstr[i]);\\n     if (fileHeader) {\\n       let keyPrefix = fileHeader[1] === \\'---\\' ? \\'old\\' : \\'new\\';\\n-      let fileName = fileHeader[2].replace(\/\\\\\\\\\\\\\\\\\/g, \\'\\\\\\\\\\');\\n+      const data = fileHeader[2].split(\\'\\\\t\\', 2);\\n+      let fileName = data[0].replace(\/\\\\\\\\\\\\\\\\\/g, \\'\\\\\\\\\\');\\n       if (\/^\".*\"$\/.test(fileName)) {\\n         fileName = fileName.substr(1, fileName.length - 2);\\n       }\\n       index[keyPrefix + \\'FileName\\'] = fileName;\\n-      index[keyPrefix + \\'Header\\'] = fileHeader[3];\\n+      index[keyPrefix + \\'Header\\'] = (data[1] || \\'\\').trim();\\n \\n       i++;\\n     }'}}",
      "message_norm":"optimize parch header parser",
      "language":"en",
      "entities":"[('optimize', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/patch\/parse.js'])",
      "num_files":1.0,
      "patch_content":"From 2aec4298639bf30fb88a00b356bf404d3551b8c0 Mon Sep 17 00:00:00 2001\nFrom: Kevin Decker <kpdecker@gmail.com>\nDate: Sun, 4 Mar 2018 22:00:42 -0600\nSubject: [PATCH] Optimize parch header parser\n\n---\n src\/patch\/parse.js | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/src\/patch\/parse.js b\/src\/patch\/parse.js\nindex 310e3a94..dd2df2ff 100755\n--- a\/src\/patch\/parse.js\n+++ b\/src\/patch\/parse.js\n@@ -53,16 +53,16 @@ export function parsePatch(uniDiff, options = {}) {\n   \/\/ Parses the --- and +++ headers, if none are found, no lines\n   \/\/ are consumed.\n   function parseFileHeader(index) {\n-    const headerPattern = \/^(---|\\+\\+\\+)\\s+([\\S ]*)(?:\\t(.*?)\\s*)?$\/;\n-    const fileHeader = headerPattern.exec(diffstr[i]);\n+    const fileHeader = (\/^(---|\\+\\+\\+)\\s+(.*)$\/).exec(diffstr[i]);\n     if (fileHeader) {\n       let keyPrefix = fileHeader[1] === '---' ? 'old' : 'new';\n-      let fileName = fileHeader[2].replace(\/\\\\\\\\\/g, '\\\\');\n+      const data = fileHeader[2].split('\\t', 2);\n+      let fileName = data[0].replace(\/\\\\\\\\\/g, '\\\\');\n       if (\/^\".*\"$\/.test(fileName)) {\n         fileName = fileName.substr(1, fileName.length - 2);\n       }\n       index[keyPrefix + 'FileName'] = fileName;\n-      index[keyPrefix + 'Header'] = fileHeader[3];\n+      index[keyPrefix + 'Header'] = (data[1] || '').trim();\n \n       i++;\n     }",
      "code_diff":"@@ -53,16 +53,16 @@ export function parsePatch(uniDiff, options = {}) {\n   \/\/ Parses the --- and +++ headers, if none are found, no lines\n   \/\/ are consumed.\n   function parseFileHeader(index) {\n-    const headerPattern = \/^(---|\\+\\+\\+)\\s+([\\S ]*)(?:\\t(.*?)\\s*)?$\/;\n-    const fileHeader = headerPattern.exec(diffstr[i]);\n+    const fileHeader = (\/^(---|\\+\\+\\+)\\s+(.*)$\/).exec(diffstr[i]);\n     if (fileHeader) {\n       let keyPrefix = fileHeader[1] === '---' ? 'old' : 'new';\n-      let fileName = fileHeader[2].replace(\/\\\\\\\\\/g, '\\\\');\n+      const data = fileHeader[2].split('\\t', 2);\n+      let fileName = data[0].replace(\/\\\\\\\\\/g, '\\\\');\n       if (\/^\".*\"$\/.test(fileName)) {\n         fileName = fileName.substr(1, fileName.length - 2);\n       }\n       index[keyPrefix + 'FileName'] = fileName;\n-      index[keyPrefix + 'Header'] = fileHeader[3];\n+      index[keyPrefix + 'Header'] = (data[1] || '').trim();\n \n       i++;\n     }"
    },
    {
      "index":40,
      "vuln_id":"GHSA-xfhh-g9f5-x4m4",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/socketio\/socket.io-parser\/commit\/dcb942d24db97162ad16a67c2a0cf30875342d55'}",
      "dataset":"osv",
      "summary":"Resource exhaustion in socket.io-parser The `socket.io-parser` npm package before versions 3.3.2 and 3.4.1 allows attackers to cause a denial of service (memory consumption) via a large packet because a concatenation approach is used.",
      "published_date":"2021-06-30",
      "chain_len":1,
      "project":"https:\/\/github.com\/socketio\/socket.io-parser",
      "commit_href":"https:\/\/github.com\/socketio\/socket.io-parser\/commit\/dcb942d24db97162ad16a67c2a0cf30875342d55",
      "commit_sha":"dcb942d24db97162ad16a67c2a0cf30875342d55",
      "patch":"SINGLE",
      "chain_ord":"['dcb942d24db97162ad16a67c2a0cf30875342d55']",
      "before_first_fix_commit":"{'a5d04354e6e98b5318d5276123b0b5a5e698bf8e'}",
      "last_fix_commit":"dcb942d24db97162ad16a67c2a0cf30875342d55",
      "chain_ord_pos":1.0,
      "commit_datetime":"05\/13\/2020, 05:37:32",
      "message":"fix: prevent DoS (OOM) via massive packets (#95)\n\nWhen maxHttpBufferSize is large (1e8 bytes), a payload of length 100MB\r\ncan be sent like so:\r\n\r\n99999991:422222222222222222222222222222222222222222222...\r\n\r\nThis massive packet can cause OOM via building up many many\r\n`ConsOneByteString` objects due to concatenation:\r\n99999989 `ConsOneByteString`s and then converting the massive integer to\r\na `Number`.\r\n\r\nThe performance can be improved to avoid this by using `substring`\r\nrather than building the string via concatenation.\r\n\r\nBelow I tried one payload of length 7e7 as the 1e8 payload took so\r\nlong to process that it timed out before running out of memory.\r\n\r\n```\r\n==== JS stack trace =========================================\r\n\r\n    0: ExitFrame [pc: 0x13c5b79]\r\nSecurity context: 0x152fe7b808d1 <JSObject>\r\n    1: decodeString [0x2dd385fb5d1] [\/node_modules\/socket.io-parser\/index.js:~276] [pc=0xf59746881be](this=0x175d34c42b69 <JSGlobal Object>,0x14eccff10fe1 <Very long string[69999990]>)\r\n    2: add [0x31fc2693da29] [\/node_modules\/socket.io-parser\/index.js:242] [bytecode=0xa7ed6554889 offset=11](this=0x0a2881be5069 <Decoder map = 0x3ceaa8bf48c9>,0x14eccff10fe1 <Very...\r\n\r\nFATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory\r\n 1: 0xa09830 node::Abort() [node]\r\n 2: 0xa09c55 node::OnFatalError(char const*, char const*) [node]\r\n 3: 0xb7d71e v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [node]\r\n 4: 0xb7da99 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [node]\r\n 5: 0xd2a1f5  [node]\r\n 6: 0xd2a886 v8::internal::Heap::RecomputeLimits(v8::internal::GarbageCollector) [node]\r\n 7: 0xd37105 v8::internal::Heap::PerformGarbageCollection(v8::internal::GarbageCollector, v8::GCCallbackFlags) [node]\r\n 8: 0xd37fb5 v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [node]\r\n 9: 0xd3965f v8::internal::Heap::HandleGCRequest() [node]\r\n10: 0xce8395 v8::internal::StackGuard::HandleInterrupts() [node]\r\n11: 0x1042cb6 v8::internal::Runtime_StackGuard(int, unsigned long*, v8::internal::Isolate*) [node]\r\n12: 0x13c5b79  [node]\r\n```",
      "author":"bcaller",
      "comments":"{'com_1': {'author': 'abergmann', 'datetime': '01\/08\/2021, 09:15:14', 'body': '[CVE-2020-36049](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-36049) was assigned to this commit.'}}",
      "stats":"{'additions': 7, 'deletions': 10, 'total': 17}",
      "files":"{'index.js': {'additions': 7, 'deletions': 10, 'changes': 17, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/socketio\/socket.io-parser\/raw\/dcb942d24db97162ad16a67c2a0cf30875342d55\/index.js', 'patch': \"@@ -286,11 +286,9 @@ function decodeString(str) {\\n \\n   \/\/ look up attachments if type binary\\n   if (exports.BINARY_EVENT === p.type || exports.BINARY_ACK === p.type) {\\n-    var buf = '';\\n-    while (str.charAt(++i) !== '-') {\\n-      buf += str.charAt(i);\\n-      if (i == str.length) break;\\n-    }\\n+    var start = i + 1;\\n+    while (str.charAt(++i) !== '-' && i != str.length) {}\\n+    var buf = str.substring(start, i);\\n     if (buf != Number(buf) || str.charAt(i) !== '-') {\\n       throw new Error('Illegal attachments');\\n     }\\n@@ -299,31 +297,30 @@ function decodeString(str) {\\n \\n   \/\/ look up namespace (if any)\\n   if ('\/' === str.charAt(i + 1)) {\\n-    p.nsp = '';\\n+    var start = i + 1;\\n     while (++i) {\\n       var c = str.charAt(i);\\n       if (',' === c) break;\\n-      p.nsp += c;\\n       if (i === str.length) break;\\n     }\\n+    p.nsp = str.substring(start, i);\\n   } else {\\n     p.nsp = '\/';\\n   }\\n \\n   \/\/ look up id\\n   var next = str.charAt(i + 1);\\n   if ('' !== next && Number(next) == next) {\\n-    p.id = '';\\n+    var start = i + 1;\\n     while (++i) {\\n       var c = str.charAt(i);\\n       if (null == c || Number(c) != c) {\\n         --i;\\n         break;\\n       }\\n-      p.id += str.charAt(i);\\n       if (i === str.length) break;\\n     }\\n-    p.id = Number(p.id);\\n+    p.id = Number(str.substring(start, i + 1));\\n   }\\n \\n   \/\/ look up json data\"}}",
      "message_norm":"fix: prevent dos (oom) via massive packets (#95)\n\nwhen maxhttpbuffersize is large (1e8 bytes), a payload of length 100mb\r\ncan be sent like so:\r\n\r\n99999991:422222222222222222222222222222222222222222222...\r\n\r\nthis massive packet can cause oom via building up many many\r\n`consonebytestring` objects due to concatenation:\r\n99999989 `consonebytestring`s and then converting the massive integer to\r\na `number`.\r\n\r\nthe performance can be improved to avoid this by using `substring`\r\nrather than building the string via concatenation.\r\n\r\nbelow i tried one payload of length 7e7 as the 1e8 payload took so\r\nlong to process that it timed out before running out of memory.\r\n\r\n```\r\n==== js stack trace =========================================\r\n\r\n    0: exitframe [pc: 0x13c5b79]\r\nsecurity context: 0x152fe7b808d1 <jsobject>\r\n    1: decodestring [0x2dd385fb5d1] [\/node_modules\/socket.io-parser\/index.js:~276] [pc=0xf59746881be](this=0x175d34c42b69 <jsglobal object>,0x14eccff10fe1 <very long string[69999990]>)\r\n    2: add [0x31fc2693da29] [\/node_modules\/socket.io-parser\/index.js:242] [bytecode=0xa7ed6554889 offset=11](this=0x0a2881be5069 <decoder map = 0x3ceaa8bf48c9>,0x14eccff10fe1 <very...\r\n\r\nfatal error: ineffective mark-compacts near heap limit allocation failed - javascript heap out of memory\r\n 1: 0xa09830 node::abort() [node]\r\n 2: 0xa09c55 node::onfatalerror(char const*, char const*) [node]\r\n 3: 0xb7d71e v8::utils::reportoomfailure(v8::internal::isolate*, char const*, bool) [node]\r\n 4: 0xb7da99 v8::internal::v8::fatalprocessoutofmemory(v8::internal::isolate*, char const*, bool) [node]\r\n 5: 0xd2a1f5  [node]\r\n 6: 0xd2a886 v8::internal::heap::recomputelimits(v8::internal::garbagecollector) [node]\r\n 7: 0xd37105 v8::internal::heap::performgarbagecollection(v8::internal::garbagecollector, v8::gccallbackflags) [node]\r\n 8: 0xd37fb5 v8::internal::heap::collectgarbage(v8::internal::allocationspace, v8::internal::garbagecollectionreason, v8::gccallbackflags) [node]\r\n 9: 0xd3965f v8::internal::heap::handlegcrequest() [node]\r\n10: 0xce8395 v8::internal::stackguard::handleinterrupts() [node]\r\n11: 0x1042cb6 v8::internal::runtime_stackguard(int, unsigned long*, v8::internal::isolate*) [node]\r\n12: 0x13c5b79  [node]\r\n```",
      "language":"en",
      "entities":"[('prevent', 'ACTION', ''), ('dos', 'SECWORD', ''), ('#95', 'ISSUE', ''), ('99999989', 'SHA', 'generic_sha'), ('improved', 'ACTION', ''), ('out of memory', 'SECWORD', ''), ('security', 'SECWORD', ''), ('decodestring', 'SECWORD', ''), ('add', 'ACTION', ''), ('decoder', 'SECWORD', ''), ('error', 'FLAW', ''), ('out of memory', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['index.js'])",
      "num_files":1.0,
      "patch_content":"From dcb942d24db97162ad16a67c2a0cf30875342d55 Mon Sep 17 00:00:00 2001\nFrom: bcaller <bcaller@users.noreply.github.com>\nDate: Wed, 13 May 2020 06:37:32 +0100\nSubject: [PATCH] fix: prevent DoS (OOM) via massive packets (#95)\n\nWhen maxHttpBufferSize is large (1e8 bytes), a payload of length 100MB\ncan be sent like so:\n\n99999991:422222222222222222222222222222222222222222222...\n\nThis massive packet can cause OOM via building up many many\n`ConsOneByteString` objects due to concatenation:\n99999989 `ConsOneByteString`s and then converting the massive integer to\na `Number`.\n\nThe performance can be improved to avoid this by using `substring`\nrather than building the string via concatenation.\n\nBelow I tried one payload of length 7e7 as the 1e8 payload took so\nlong to process that it timed out before running out of memory.\n\n```\n==== JS stack trace =========================================\n\n    0: ExitFrame [pc: 0x13c5b79]\nSecurity context: 0x152fe7b808d1 <JSObject>\n    1: decodeString [0x2dd385fb5d1] [\/node_modules\/socket.io-parser\/index.js:~276] [pc=0xf59746881be](this=0x175d34c42b69 <JSGlobal Object>,0x14eccff10fe1 <Very long string[69999990]>)\n    2: add [0x31fc2693da29] [\/node_modules\/socket.io-parser\/index.js:242] [bytecode=0xa7ed6554889 offset=11](this=0x0a2881be5069 <Decoder map = 0x3ceaa8bf48c9>,0x14eccff10fe1 <Very...\n\nFATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory\n 1: 0xa09830 node::Abort() [node]\n 2: 0xa09c55 node::OnFatalError(char const*, char const*) [node]\n 3: 0xb7d71e v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [node]\n 4: 0xb7da99 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [node]\n 5: 0xd2a1f5  [node]\n 6: 0xd2a886 v8::internal::Heap::RecomputeLimits(v8::internal::GarbageCollector) [node]\n 7: 0xd37105 v8::internal::Heap::PerformGarbageCollection(v8::internal::GarbageCollector, v8::GCCallbackFlags) [node]\n 8: 0xd37fb5 v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [node]\n 9: 0xd3965f v8::internal::Heap::HandleGCRequest() [node]\n10: 0xce8395 v8::internal::StackGuard::HandleInterrupts() [node]\n11: 0x1042cb6 v8::internal::Runtime_StackGuard(int, unsigned long*, v8::internal::Isolate*) [node]\n12: 0x13c5b79  [node]\n```\n---\n index.js | 17 +++++++----------\n 1 file changed, 7 insertions(+), 10 deletions(-)\n\ndiff --git a\/index.js b\/index.js\nindex 102615a..ff613cc 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -286,11 +286,9 @@ function decodeString(str) {\n \n   \/\/ look up attachments if type binary\n   if (exports.BINARY_EVENT === p.type || exports.BINARY_ACK === p.type) {\n-    var buf = '';\n-    while (str.charAt(++i) !== '-') {\n-      buf += str.charAt(i);\n-      if (i == str.length) break;\n-    }\n+    var start = i + 1;\n+    while (str.charAt(++i) !== '-' && i != str.length) {}\n+    var buf = str.substring(start, i);\n     if (buf != Number(buf) || str.charAt(i) !== '-') {\n       throw new Error('Illegal attachments');\n     }\n@@ -299,13 +297,13 @@ function decodeString(str) {\n \n   \/\/ look up namespace (if any)\n   if ('\/' === str.charAt(i + 1)) {\n-    p.nsp = '';\n+    var start = i + 1;\n     while (++i) {\n       var c = str.charAt(i);\n       if (',' === c) break;\n-      p.nsp += c;\n       if (i === str.length) break;\n     }\n+    p.nsp = str.substring(start, i);\n   } else {\n     p.nsp = '\/';\n   }\n@@ -313,17 +311,16 @@ function decodeString(str) {\n   \/\/ look up id\n   var next = str.charAt(i + 1);\n   if ('' !== next && Number(next) == next) {\n-    p.id = '';\n+    var start = i + 1;\n     while (++i) {\n       var c = str.charAt(i);\n       if (null == c || Number(c) != c) {\n         --i;\n         break;\n       }\n-      p.id += str.charAt(i);\n       if (i === str.length) break;\n     }\n-    p.id = Number(p.id);\n+    p.id = Number(str.substring(start, i + 1));\n   }\n \n   \/\/ look up json data",
      "code_diff":"@@ -286,11 +286,9 @@ function decodeString(str) {\n \n   \/\/ look up attachments if type binary\n   if (exports.BINARY_EVENT === p.type || exports.BINARY_ACK === p.type) {\n-    var buf = '';\n-    while (str.charAt(++i) !== '-') {\n-      buf += str.charAt(i);\n-      if (i == str.length) break;\n-    }\n+    var start = i + 1;\n+    while (str.charAt(++i) !== '-' && i != str.length) {}\n+    var buf = str.substring(start, i);\n     if (buf != Number(buf) || str.charAt(i) !== '-') {\n       throw new Error('Illegal attachments');\n     }\n@@ -299,13 +297,13 @@ function decodeString(str) {\n \n   \/\/ look up namespace (if any)\n   if ('\/' === str.charAt(i + 1)) {\n-    p.nsp = '';\n+    var start = i + 1;\n     while (++i) {\n       var c = str.charAt(i);\n       if (',' === c) break;\n-      p.nsp += c;\n       if (i === str.length) break;\n     }\n+    p.nsp = str.substring(start, i);\n   } else {\n     p.nsp = '\/';\n   }\n@@ -313,17 +311,16 @@ function decodeString(str) {\n   \/\/ look up id\n   var next = str.charAt(i + 1);\n   if ('' !== next && Number(next) == next) {\n-    p.id = '';\n+    var start = i + 1;\n     while (++i) {\n       var c = str.charAt(i);\n       if (null == c || Number(c) != c) {\n         --i;\n         break;\n       }\n-      p.id += str.charAt(i);\n       if (i === str.length) break;\n     }\n-    p.id = Number(p.id);\n+    p.id = Number(str.substring(start, i + 1));\n   }\n \n   \/\/ look up json data"
    },
    {
      "index":41,
      "vuln_id":"GHSA-wc69-rhjr-hc9g",
      "cwe_id":"{'CWE-400', 'CWE-1333'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/moment\/moment\/commit\/9a3b5894f3d5d602948ac8a02e4ee528a49ca3a3'}",
      "dataset":"osv",
      "summary":"Inefficient Regular Expression Complexity in moment ### Impact\n\n* using string-to-date parsing in moment (more specifically rfc2822 parsing, which is tried by default) has quadratic (N^2) complexity on specific inputs\n* noticeable slowdown is observed with inputs above 10k characters\n* users who pass user-provided strings without sanity length checks to moment constructor are vulnerable to (Re)DoS attacks\n\n### Patches\nThe problem is patched in 2.29.4, the patch can be applied to all affected versions with minimal tweaking.\n\n### Workarounds\nIn general, given the proliferation of ReDoS attacks, it makes sense to limit the length of the user input to something sane, like 200 characters or less. I haven't seen legitimate cases of date-time strings longer than that, so all moment users who do pass a user-originating string to constructor are encouraged to apply such a rudimentary filter, that would help with this but also most future ReDoS vulnerabilities.\n\n### References\nThere is an excellent writeup of the issue here: https:\/\/github.com\/moment\/moment\/pull\/6015#issuecomment-1152961973=\n\n### Details\nThe issue is rooted in the code that removes legacy comments (stuff inside parenthesis) from strings during rfc2822 parsing. `moment(\"(\".repeat(500000))` will take a few minutes to process, which is unacceptable.",
      "published_date":"2022-07-06",
      "chain_len":1,
      "project":"https:\/\/github.com\/moment\/moment",
      "commit_href":"https:\/\/github.com\/moment\/moment\/commit\/9a3b5894f3d5d602948ac8a02e4ee528a49ca3a3",
      "commit_sha":"9a3b5894f3d5d602948ac8a02e4ee528a49ca3a3",
      "patch":"SINGLE",
      "chain_ord":"['9a3b5894f3d5d602948ac8a02e4ee528a49ca3a3']",
      "before_first_fix_commit":"{'6374fd860aeff75e6c9d9d11540c6b22bc7ef175'}",
      "last_fix_commit":"9a3b5894f3d5d602948ac8a02e4ee528a49ca3a3",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/06\/2022, 15:28:25",
      "message":"[bugfix] Fix redos in preprocessRFC2822 regex (#6015)\n\n* fix ReDoS in preprocessRFC2822 regex\r\n\r\nFixes: [#2936](https:\/\/github.com\/moment\/moment\/issues\/6012)\r\n\r\nDisallow nested rfc2822 comments to prevent quadratic regex execution time (i.e each open bracket is considered at most twice).",
      "author":"Khang Vo (doublevkay)",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'src\/lib\/create\/from-string.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/moment\/moment\/raw\/9a3b5894f3d5d602948ac8a02e4ee528a49ca3a3\/src%2Flib%2Fcreate%2Ffrom-string.js', 'patch': \"@@ -151,7 +151,7 @@ function untruncateYear(yearStr) {\\n function preprocessRFC2822(s) {\\n     \/\/ Remove comments and folding whitespace and replace multiple-spaces with a single space\\n     return s\\n-        .replace(\/\\\\([^)]*\\\\)|[\\\\n\\\\t]\/g, ' ')\\n+        .replace(\/\\\\([^()]*\\\\)|[\\\\n\\\\t]\/g, ' ')\\n         .replace(\/(\\\\s\\\\s+)\/g, ' ')\\n         .replace(\/^\\\\s\\\\s*\/, '')\\n         .replace(\/\\\\s\\\\s*$\/, '');\"}}",
      "message_norm":"[bugfix] fix redos in preprocessrfc2822 regex (#6015)\n\n* fix redos in preprocessrfc2822 regex\r\n\r\nfixes: [#2936](https:\/\/github.com\/moment\/moment\/issues\/6012)\r\n\r\ndisallow nested rfc2822 comments to prevent quadratic regex execution time (i.e each open bracket is considered at most twice).",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('preprocessrfc2822', 'SECWORD', ''), ('#6015', 'ISSUE', ''), ('fix', 'ACTION', ''), ('redos', 'SECWORD', ''), ('preprocessrfc2822', 'SECWORD', ''), ('fixes', 'ACTION', ''), ('#2936](https:\/\/github.com', 'ISSUE', ''), ('issues\/6012', 'FLAW', ''), ('prevent', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/lib\/create\/from-string.js'])",
      "num_files":1.0,
      "patch_content":"From 9a3b5894f3d5d602948ac8a02e4ee528a49ca3a3 Mon Sep 17 00:00:00 2001\nFrom: \"Khang Vo (doublevkay)\" <45411113+vovikhangcdv@users.noreply.github.com>\nDate: Wed, 6 Jul 2022 22:28:25 +0700\nSubject: [PATCH] [bugfix] Fix redos in preprocessRFC2822 regex (#6015)\n\n* fix ReDoS in preprocessRFC2822 regex\n\nFixes: [#2936](https:\/\/github.com\/moment\/moment\/issues\/6012)\n\nDisallow nested rfc2822 comments to prevent quadratic regex execution time (i.e each open bracket is considered at most twice).\n---\n src\/lib\/create\/from-string.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/lib\/create\/from-string.js b\/src\/lib\/create\/from-string.js\nindex 5c4d11f740..58739b9d7c 100644\n--- a\/src\/lib\/create\/from-string.js\n+++ b\/src\/lib\/create\/from-string.js\n@@ -151,7 +151,7 @@ function untruncateYear(yearStr) {\n function preprocessRFC2822(s) {\n     \/\/ Remove comments and folding whitespace and replace multiple-spaces with a single space\n     return s\n-        .replace(\/\\([^)]*\\)|[\\n\\t]\/g, ' ')\n+        .replace(\/\\([^()]*\\)|[\\n\\t]\/g, ' ')\n         .replace(\/(\\s\\s+)\/g, ' ')\n         .replace(\/^\\s\\s*\/, '')\n         .replace(\/\\s\\s*$\/, '');",
      "code_diff":"@@ -151,7 +151,7 @@ function untruncateYear(yearStr) {\n function preprocessRFC2822(s) {\n     \/\/ Remove comments and folding whitespace and replace multiple-spaces with a single space\n     return s\n-        .replace(\/\\([^)]*\\)|[\\n\\t]\/g, ' ')\n+        .replace(\/\\([^()]*\\)|[\\n\\t]\/g, ' ')\n         .replace(\/(\\s\\s+)\/g, ' ')\n         .replace(\/^\\s\\s*\/, '')\n         .replace(\/\\s\\s*$\/, '');"
    },
    {
      "index":42,
      "vuln_id":"GHSA-hq37-853p-g5cf",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/Kozea\/CairoSVG\/commit\/cfc9175e590531d90384aa88845052de53d94bf3'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in CairoSVG # Doyensec Vulnerability Advisory \n\n* Regular Expression Denial of Service (REDoS) in cairosvg\n* Affected Product: CairoSVG v2.0.0+\n* Vendor: https:\/\/github.com\/Kozea\n* Severity: Medium\n* Vulnerability Class: Denial of Service\n* Author(s): Ben Caller ([Doyensec](https:\/\/doyensec.com))\n\n## Summary\n\nWhen processing SVG files, the python package CairoSVG uses two regular expressions which are vulnerable to Regular Expression Denial of Service (REDoS).\nIf an attacker provides a malicious SVG, it can make cairosvg get stuck processing the file for a very long time.\n\n## Technical description\n\nThe vulnerable regular expressions are\n\nhttps:\/\/github.com\/Kozea\/CairoSVG\/blob\/9c4a982b9a021280ad90e89707eacc1d114e4ac4\/cairosvg\/colors.py#L190-L191\n\nThe section between 'rgb(' and the final ')' contains multiple overlapping groups.\n\nSince all three infinitely repeating groups accept spaces, a long string of spaces causes catastrophic backtracking when it is not followed by a closing parenthesis.\n\nThe complexity is cubic, so doubling the length of the malicious string of spaces makes processing take 8 times as long.\n\n## Reproduction steps\n\nCreate a malicious SVG of the form:\n\n    <svg width=\"1\" height=\"1\"><rect fill=\"rgb(                     ;\"\/><\/svg>\n\nwith the following code:\n\n    '<svg width=\"1\" height=\"1\"><rect fill=\"rgb(' + (' ' * 3456) + ';\"\/><\/svg>'\n\nNote that there is no closing parenthesis before the semi-colon.\n\nRun cairosvg e.g.:\n\n    cairosvg cairo-redos.svg -o x.png\n\nand notice that it hangs at 100% CPU. Increasing the number of spaces increases the processing time with cubic complexity.\n\n## Remediation\n\nFix the regexes to avoid overlapping parts. Perhaps remove the [ \\n\\r\\t]* groups from the regex, and use .strip() on the returned capture group.\n\n## Disclosure timeline\n\n- 2020-12-30: Vulnerability disclosed via email to CourtBouillon",
      "published_date":"2021-01-06",
      "chain_len":1,
      "project":"https:\/\/github.com\/Kozea\/CairoSVG",
      "commit_href":"https:\/\/github.com\/Kozea\/CairoSVG\/commit\/cfc9175e590531d90384aa88845052de53d94bf3",
      "commit_sha":"cfc9175e590531d90384aa88845052de53d94bf3",
      "patch":"SINGLE",
      "chain_ord":"['cfc9175e590531d90384aa88845052de53d94bf3']",
      "before_first_fix_commit":"{'9c4a982b9a021280ad90e89707eacc1d114e4ac4', '063185b60588a41d4df661ad70f9f7b699901abc'}",
      "last_fix_commit":"cfc9175e590531d90384aa88845052de53d94bf3",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/06\/2021, 14:43:14",
      "message":"Merge pull request from GHSA-hq37-853p-g5cf\n\nDon\u2019t use overlapping groups for regular expressions",
      "author":"Guillaume Ayoub",
      "comments":null,
      "stats":"{'additions': 4, 'deletions': 4, 'total': 8}",
      "files":"{'cairosvg\/colors.py': {'additions': 4, 'deletions': 4, 'changes': 8, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/Kozea\/CairoSVG\/raw\/cfc9175e590531d90384aa88845052de53d94bf3\/cairosvg%2Fcolors.py', 'patch': \"@@ -187,8 +187,8 @@\\n     'transparent': (0, 0, 0, 0),\\n }\\n \\n-RGBA = re.compile(r'rgba\\\\([ \\\\n\\\\r\\\\t]*(.+?)[ \\\\n\\\\r\\\\t]*\\\\)')\\n-RGB = re.compile(r'rgb\\\\([ \\\\n\\\\r\\\\t]*(.+?)[ \\\\n\\\\r\\\\t]*\\\\)')\\n+RGBA = re.compile(r'rgba\\\\((.+?)\\\\)')\\n+RGB = re.compile(r'rgb\\\\((.+?)\\\\)')\\n HEX_RRGGBB = re.compile('#[0-9a-f]{6}')\\n HEX_RGB = re.compile('#[0-9a-f]{3}')\\n \\n@@ -212,14 +212,14 @@ def color(string, opacity=1):\\n     if match:\\n         r, g, b, a = tuple(\\n             float(i.strip(' %')) \/ 100 if '%' in i else float(i) \/ 255\\n-            for i in match.group(1).split(','))\\n+            for i in match.group(1).strip().split(','))\\n         return (r, g, b, a * 255 * opacity)\\n \\n     match = RGB.search(string)\\n     if match:\\n         r, g, b = tuple(\\n             float(i.strip(' %')) \/ 100 if '%' in i else float(i) \/ 255\\n-            for i in match.group(1).split(','))\\n+            for i in match.group(1).strip().split(','))\\n         return (r, g, b, opacity)\\n \\n     match = HEX_RRGGBB.search(string)\"}}",
      "message_norm":"merge pull request from ghsa-hq37-853p-g5cf\n\ndon\u2019t use overlapping groups for regular expressions",
      "language":"en",
      "entities":"[('ghsa-hq37-853p-g5cf', 'VULNID', 'GHSA')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['cairosvg\/colors.py'])",
      "num_files":1.0,
      "patch_content":"From 063185b60588a41d4df661ad70f9f7b699901abc Mon Sep 17 00:00:00 2001\nFrom: Guillaume Ayoub <guillaume@courtbouillon.org>\nDate: Fri, 1 Jan 2021 00:05:55 +0100\nSubject: [PATCH] =?UTF-8?q?Don=E2=80=99t=20use=20overlapping=20groups=20fo?=\n =?UTF-8?q?r=20regular=20expressions?=\nMIME-Version: 1.0\nContent-Type: text\/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\n\nThe section between 'rgb(' and the final ')' contains multiple overlapping\ngroups.\n\nSince all three infinitely repeating groups accept spaces, a long string of\nspaces causes catastrophic backtracking when it is not followed by a closing\nparenthesis.\n\nThe complexity is cubic, so doubling the length of the malicious string of\nspaces makes processing take 8 times as long.\n---\n cairosvg\/colors.py | 8 ++++----\n 1 file changed, 4 insertions(+), 4 deletions(-)\n\ndiff --git a\/cairosvg\/colors.py b\/cairosvg\/colors.py\nindex 96d94e1a..68eed88d 100644\n--- a\/cairosvg\/colors.py\n+++ b\/cairosvg\/colors.py\n@@ -187,8 +187,8 @@\n     'transparent': (0, 0, 0, 0),\n }\n \n-RGBA = re.compile(r'rgba\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)')\n-RGB = re.compile(r'rgb\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)')\n+RGBA = re.compile(r'rgba\\((.+?)\\)')\n+RGB = re.compile(r'rgb\\((.+?)\\)')\n HEX_RRGGBB = re.compile('#[0-9a-f]{6}')\n HEX_RGB = re.compile('#[0-9a-f]{3}')\n \n@@ -212,14 +212,14 @@ def color(string, opacity=1):\n     if match:\n         r, g, b, a = tuple(\n             float(i.strip(' %')) \/ 100 if '%' in i else float(i) \/ 255\n-            for i in match.group(1).split(','))\n+            for i in match.group(1).strip().split(','))\n         return (r, g, b, a * 255 * opacity)\n \n     match = RGB.search(string)\n     if match:\n         r, g, b = tuple(\n             float(i.strip(' %')) \/ 100 if '%' in i else float(i) \/ 255\n-            for i in match.group(1).split(','))\n+            for i in match.group(1).strip().split(','))\n         return (r, g, b, opacity)\n \n     match = HEX_RRGGBB.search(string)",
      "code_diff":"@@ -187,8 +187,8 @@\n     'transparent': (0, 0, 0, 0),\n }\n \n-RGBA = re.compile(r'rgba\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)')\n-RGB = re.compile(r'rgb\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)')\n+RGBA = re.compile(r'rgba\\((.+?)\\)')\n+RGB = re.compile(r'rgb\\((.+?)\\)')\n HEX_RRGGBB = re.compile('#[0-9a-f]{6}')\n HEX_RGB = re.compile('#[0-9a-f]{3}')\n \n@@ -212,14 +212,14 @@ def color(string, opacity=1):\n     if match:\n         r, g, b, a = tuple(\n             float(i.strip(' %')) \/ 100 if '%' in i else float(i) \/ 255\n-            for i in match.group(1).split(','))\n+            for i in match.group(1).strip().split(','))\n         return (r, g, b, a * 255 * opacity)\n \n     match = RGB.search(string)\n     if match:\n         r, g, b = tuple(\n             float(i.strip(' %')) \/ 100 if '%' in i else float(i) \/ 255\n-            for i in match.group(1).split(','))\n+            for i in match.group(1).strip().split(','))\n         return (r, g, b, opacity)\n \n     match = HEX_RRGGBB.search(string)"
    },
    {
      "index":43,
      "vuln_id":"GHSA-cwfw-4gq5-mrqx",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/micromatch\/braces\/commit\/abdafb0cae1e0c00f184abbadc692f4eaa98f451'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service (ReDoS) in braces A vulnerability was found in Braces versions prior to 2.3.1. Affected versions of this package are vulnerable to Regular Expression Denial of Service (ReDoS) attacks.",
      "published_date":"2022-01-06",
      "chain_len":1,
      "project":"https:\/\/github.com\/micromatch\/braces",
      "commit_href":"https:\/\/github.com\/micromatch\/braces\/commit\/abdafb0cae1e0c00f184abbadc692f4eaa98f451",
      "commit_sha":"abdafb0cae1e0c00f184abbadc692f4eaa98f451",
      "patch":"SINGLE",
      "chain_ord":"['abdafb0cae1e0c00f184abbadc692f4eaa98f451']",
      "before_first_fix_commit":"{'37934142c1aeea48b6fb03edbdcf90e45b5cb4a1'}",
      "last_fix_commit":"abdafb0cae1e0c00f184abbadc692f4eaa98f451",
      "chain_ord_pos":1.0,
      "commit_datetime":"02\/16\/2018, 21:09:36",
      "message":"optimize regex",
      "author":"jonschlinkert",
      "comments":"{'com_1': {'author': 'sathish-spidie', 'datetime': '04\/18\/2019, 03:42:11', 'body': \"can you explain, how to achieve this? I'm a low-level developer and didn't understand why this code stands for and what to do with it! sorry if I waste your time by making you read this comment, in case you find this comment useless.\\r\\n\\r\\nmy error is\\r\\n\\r\\n` Low             Regular Expression Denial of Service                          \\r\\n                                                                                \\r\\n  Package         braces                                                        \\r\\n                                                                                \\r\\n  Patched in      >=2.3.1                                                       \\r\\n                                                                                \\r\\n  Dependency of   browser-sync [dev]                                            \\r\\n                                                                                \\r\\n  Path            browser-sync > micromatch > braces                            \\r\\n                                                                                \\r\\n  More info       https:\/\/npmjs.com\/advisories\/786         `\"}, 'com_2': {'author': 'kousu', 'datetime': '04\/18\/2019, 18:24:04', 'body': '@sathish-spidie , you can find out the solution on the link there: https:\/\/npmjs.com\/advisories\/786:\\r\\n\\r\\n> Remediation\\r\\n> \\r\\n> Upgrade to version 2.3.1 or higher.\\r\\n\\r\\nWhat this means is that in your package.json you should make sure the line for \"braces\" under \"dependencies\"  says\\r\\n\\r\\n```\\r\\n\"braces\": \"^2.3.1\",\\r\\n```\\r\\n\\r\\nand then delete your cached npm packages by \\r\\n\\r\\n```\\r\\nrm -r node_modules\/ package-lock.json\\r\\n```\\r\\n\\r\\nand then\\r\\n\\r\\n```\\r\\nnpm install\\r\\n```\\r\\n\\r\\n---\\r\\n\\r\\nIf you don\\'t directly depend on \"braces\", which is the situation I am in, you can use\\r\\n\\r\\n```\\r\\nnpm list\\r\\n```\\r\\n\\r\\nto figure out which of your packages is depending on \"braces\", and then go make sure to update each of those packages in the same way: version bump them, make sure to prefix the versions of everything with \"^\", and then delete your packages and regenerate package-lock.json by redoing `npm install`; that will get the latest, hopefully bugfixed, versions of all your packages; but if any of your packages have not yet updated to use `\"braces\": \"^2.3.1\"` then you will have to go to their github projects and file an issue. \\r\\n\\r\\n---\\r\\n\\r\\nA comment on a commit inside the braces project isn\\'t really a proper general support forum for npm. For that, and for future questions, you will probably have good luck asking at https:\/\/npm.community\/c\/support.  I hope the above helps and lets you extend your developer skills.'}, 'com_3': {'author': 'jonschlinkert', 'datetime': '04\/18\/2019, 20:01:13', 'body': \"@kousu that was a fantastic description, and a really good summary of the steps that need to be taken. Thank you!\\r\\n\\r\\n> you will probably have good luck asking at https:\/\/npm.community\/c\/support. I hope the above helps and lets you extend your developer skills.\\r\\n\\r\\nOnly one thing I'd like to point out. Generally, https:\/\/npm.community\/c\/support is for **NPM** support, not for packages like this one. Meaning, if you need something directly related to the package manager itself, that's the place to go. But ideally, when a user has an issue or support question like this, the best place to get answers is to:\\r\\n\\r\\n1. read through previous issues first - @sathish-spidie would have seen that this question has been answered a couple of dozen times already on this project and other projects that depend on this one\\r\\n1. StackOverflow - people get reputation points for helping others\\r\\n1. if it seems like no one has addressed the issue already, and you have genuinely stumbled across a previously undiscovered bug, then create a new issue on the GitHub repository of the code project.\"}, 'com_4': {'author': 'KevinGrant12', 'datetime': '05\/08\/2019, 23:49:41', 'body': \"Hello, I have the same exact issue that stems from babel.\\r\\nI was unable to run this line rm -r node_modules\/ package-lock.json and it makes sense because the packag-lock is not inside the node_modules directory.\\r\\nWhen I run npm list I can see that instances of 'braces' are at 2.3.2.\\r\\n\\r\\nAny thoughts on how to fix?\\r\\nThanks!\"}, 'com_5': {'author': 'biggianteye', 'datetime': '06\/07\/2019, 12:57:09', 'body': \"> I was unable to run this line rm -r node_modules\/ package-lock.json and it makes sense because the packag-lock is not inside the node_modules directory.\\r\\n\\r\\nThere is a space between `node_modules` and `package-lock.json`. The lock file is not inside the node_modules folder. It's at the same level.\"}, 'com_6': {'author': 'robpl1', 'datetime': '07\/14\/2019, 08:57:18', 'body': 'The problem I have here is that the braces package itself is showing \\r\\n{  \"_from\": \"braces@^1.8.2\",\\r\\n  \"_id\": \"braces@1.8.5\",\\r\\n\\r\\nSo how to update that would help.'}, 'com_7': {'author': 'martynawilkonska', 'datetime': '07\/16\/2019, 08:45:50', 'body': 'I have the same problem. I am unable to update braces, after reinstall they are still 1.8.5.'}, 'com_8': {'author': 'janzenz', 'datetime': '10\/08\/2019, 02:02:12', 'body': \"@martynawilkonska have you removed your `node_modules` cache and `package-lock.json` file? If not, try that and `npm install` again. If it still does that, my next hunch is that you're `braces` is a transitive dependency in your package. Try `npm ls braces` and see which package requires it and maybe you can try and upgrade that parent package which potentially will fix your problem.\"}}",
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'lib\/parsers.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/micromatch\/braces\/raw\/abdafb0cae1e0c00f184abbadc692f4eaa98f451\/lib%2Fparsers.js', 'patch': \"@@ -127,7 +127,7 @@ module.exports = function(braces, options) {\\n     .set('multiplier', function() {\\n       var isInside = this.isInside('brace');\\n       var pos = this.position();\\n-      var m = this.match(\/^\\\\{(,+(?:(\\\\{,+\\\\})*),*|,*(?:(\\\\{,+\\\\})*),+)\\\\}\/);\\n+      var m = this.match(\/^\\\\{((?:,|\\\\{,+\\\\})+)\\\\}\/);\\n       if (!m) return;\\n \\n       this.multiplier = true;\"}}",
      "message_norm":"optimize regex",
      "language":"ro",
      "entities":"[('optimize', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/parsers.js'])",
      "num_files":1.0,
      "patch_content":"From abdafb0cae1e0c00f184abbadc692f4eaa98f451 Mon Sep 17 00:00:00 2001\nFrom: jonschlinkert <jon.schlinkert@sellside.com>\nDate: Fri, 16 Feb 2018 16:09:36 -0500\nSubject: [PATCH] optimize regex\n\n---\n lib\/parsers.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/parsers.js b\/lib\/parsers.js\nindex 42730fe..b14bc83 100644\n--- a\/lib\/parsers.js\n+++ b\/lib\/parsers.js\n@@ -127,7 +127,7 @@ module.exports = function(braces, options) {\n     .set('multiplier', function() {\n       var isInside = this.isInside('brace');\n       var pos = this.position();\n-      var m = this.match(\/^\\{(,+(?:(\\{,+\\})*),*|,*(?:(\\{,+\\})*),+)\\}\/);\n+      var m = this.match(\/^\\{((?:,|\\{,+\\})+)\\}\/);\n       if (!m) return;\n \n       this.multiplier = true;",
      "code_diff":"@@ -127,7 +127,7 @@ module.exports = function(braces, options) {\n     .set('multiplier', function() {\n       var isInside = this.isInside('brace');\n       var pos = this.position();\n-      var m = this.match(\/^\\{(,+(?:(\\{,+\\})*),*|,*(?:(\\{,+\\})*),+)\\}\/);\n+      var m = this.match(\/^\\{((?:,|\\{,+\\})+)\\}\/);\n       if (!m) return;\n \n       this.multiplier = true;"
    },
    {
      "index":44,
      "vuln_id":"GHSA-qhmp-h54x-38qr",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/caronc\/apprise\/commit\/e20fce630d55e4ca9b0a1e325a5fea6997489831'}",
      "dataset":"osv",
      "summary":"CWE-730 Regex injection with IFTTT Plugin ### Impact\r\nAnyone _publicly_ hosting the Apprise library and granting them access to the IFTTT notification service.\r\n\r\n### Patches\r\nUpdate to Apprise v0.9.5.1\r\n   ```bash\r\n   # Install Apprise v0.9.5.1 from PyPI\r\n   pip install apprise==0.9.5.1\r\n   ```\r\n\r\nThe patch to the problem was performed [here](https:\/\/github.com\/caronc\/apprise\/pull\/436\/files).\r\n\r\n### Workarounds\r\nAlternatively, if upgrading is not an option, you can safely remove the following file:\r\n- `apprise\/plugins\/NotifyIFTTT.py` \r\n\r\nThe above will eliminate the ability to use IFTTT, but everything else will work smoothly.\r\n\r\n### For more information\r\nIf you have any questions or comments about this advisory:\r\n* Open an issue in [Apprise](https:\/\/github.com\/caronc\/apprise\/issues)\r\n* Email me at [lead2gold@gmail.com](mailto:lead2gold@gmail.com)\r\n\r\n### Additional Credit\r\nGithub would not allow me to additionally credit **Rasmus Petersen**, but I would like to put that here at the very least - thank you for finding and reporting this issue along with those already credited\r\n\r\n## Additional Notes:\r\n- Github would not allow me to add\/tag the 2 CWE's this issue is applicable to (only CWE-400).  The other is: CWE-730 (placed in the title)",
      "published_date":"2021-09-20",
      "chain_len":1,
      "project":"https:\/\/github.com\/caronc\/apprise",
      "commit_href":"https:\/\/github.com\/caronc\/apprise\/commit\/e20fce630d55e4ca9b0a1e325a5fea6997489831",
      "commit_sha":"e20fce630d55e4ca9b0a1e325a5fea6997489831",
      "patch":"SINGLE",
      "chain_ord":"['e20fce630d55e4ca9b0a1e325a5fea6997489831']",
      "before_first_fix_commit":"{'81d1ea72bcee4441278a809a95fc0f91dc916402'}",
      "last_fix_commit":"e20fce630d55e4ca9b0a1e325a5fea6997489831",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/06\/2021, 17:51:32",
      "message":"Slight bulletproofing to IFTTT regex handling (#436)",
      "author":"Chris Caron",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'apprise\/plugins\/NotifyIFTTT.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/caronc\/apprise\/raw\/e20fce630d55e4ca9b0a1e325a5fea6997489831\/apprise%2Fplugins%2FNotifyIFTTT.py', 'patch': \"@@ -355,7 +355,7 @@ def parse_native_url(url):\\n         result = re.match(\\n             r'^https?:\/\/maker\\\\.ifttt\\\\.com\/use\/'\\n             r'(?P<webhook_id>[A-Z0-9_-]+)'\\n-            r'\/?(?P<events>([A-Z0-9_-]+\/?)+)?'\\n+            r'((?P<events>(\/[A-Z0-9_-]+)+))?'\\n             r'\/?(?P<params>\\\\?.+)?$', url, re.I)\\n \\n         if result:\"}}",
      "message_norm":"slight bulletproofing to ifttt regex handling (#436)",
      "language":"no",
      "entities":"[('#436', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['apprise\/plugins\/NotifyIFTTT.py'])",
      "num_files":1.0,
      "patch_content":"From e20fce630d55e4ca9b0a1e325a5fea6997489831 Mon Sep 17 00:00:00 2001\nFrom: Chris Caron <lead2gold@gmail.com>\nDate: Mon, 6 Sep 2021 13:51:32 -0400\nSubject: [PATCH] Slight bulletproofing to IFTTT regex handling (#436)\n\n---\n apprise\/plugins\/NotifyIFTTT.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/apprise\/plugins\/NotifyIFTTT.py b\/apprise\/plugins\/NotifyIFTTT.py\nindex c038a9e7e..b735a4d07 100644\n--- a\/apprise\/plugins\/NotifyIFTTT.py\n+++ b\/apprise\/plugins\/NotifyIFTTT.py\n@@ -355,7 +355,7 @@ def parse_native_url(url):\n         result = re.match(\n             r'^https?:\/\/maker\\.ifttt\\.com\/use\/'\n             r'(?P<webhook_id>[A-Z0-9_-]+)'\n-            r'\/?(?P<events>([A-Z0-9_-]+\/?)+)?'\n+            r'((?P<events>(\/[A-Z0-9_-]+)+))?'\n             r'\/?(?P<params>\\?.+)?$', url, re.I)\n \n         if result:",
      "code_diff":"@@ -355,7 +355,7 @@ def parse_native_url(url):\n         result = re.match(\n             r'^https?:\/\/maker\\.ifttt\\.com\/use\/'\n             r'(?P<webhook_id>[A-Z0-9_-]+)'\n-            r'\/?(?P<events>([A-Z0-9_-]+\/?)+)?'\n+            r'((?P<events>(\/[A-Z0-9_-]+)+))?'\n             r'\/?(?P<params>\\?.+)?$', url, re.I)\n \n         if result:"
    },
    {
      "index":45,
      "vuln_id":"GHSA-3q6g-vf58-7m4g",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/python-restx\/flask-restx\/commit\/bab31e085f355dd73858fd3715f7ed71849656da'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service in flask-restx Flask RESTX contains a regular expression that is vulnerable to [ReDoS](https:\/\/owasp.org\/www-community\/attacks\/Regular_expression_Denial_of_Service_-_ReDoS) (Regular Expression Denial of Service) in `email_regex`.",
      "published_date":"2021-09-08",
      "chain_len":1,
      "project":"https:\/\/github.com\/python-restx\/flask-restx",
      "commit_href":"https:\/\/github.com\/python-restx\/flask-restx\/commit\/bab31e085f355dd73858fd3715f7ed71849656da",
      "commit_sha":"bab31e085f355dd73858fd3715f7ed71849656da",
      "patch":"SINGLE",
      "chain_ord":"['bab31e085f355dd73858fd3715f7ed71849656da']",
      "before_first_fix_commit":"{'e1ab7e34a47fa8c2fd025402b9c65afbe24d5e98'}",
      "last_fix_commit":"bab31e085f355dd73858fd3715f7ed71849656da",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/01\/2021, 19:53:02",
      "message":"optimize email regex (credits: @kevinbackhouse, fix: #372)",
      "author":"ziirish",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'flask_restx\/inputs.py': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/python-restx\/flask-restx\/raw\/bab31e085f355dd73858fd3715f7ed71849656da\/flask_restx%2Finputs.py', 'patch': '@@ -48,7 +48,7 @@ def my_type(value):\\n \\n \\n email_regex = re.compile(\\n-    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@]+(?:\\\\.[^@]+)*)\" r\"$\",\\n+    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@\\\\.]+(?:\\\\.[^@\\\\.]+)*)\" r\"$\",\\n     re.IGNORECASE,\\n )'}}",
      "message_norm":"optimize email regex (credits: @kevinbackhouse, fix: #372)",
      "language":"en",
      "entities":"[('optimize', 'ACTION', ''), ('#372', 'ISSUE', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['flask_restx\/inputs.py'])",
      "num_files":1.0,
      "patch_content":"From bab31e085f355dd73858fd3715f7ed71849656da Mon Sep 17 00:00:00 2001\nFrom: ziirish <ziirish@ziirish.info>\nDate: Wed, 1 Sep 2021 21:53:02 +0200\nSubject: [PATCH] optimize email regex (credits: @kevinbackhouse, fix: #372)\n\n---\n flask_restx\/inputs.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/flask_restx\/inputs.py b\/flask_restx\/inputs.py\nindex b05532f3..9c76d8a0 100644\n--- a\/flask_restx\/inputs.py\n+++ b\/flask_restx\/inputs.py\n@@ -48,7 +48,7 @@ def my_type(value):\n \n \n email_regex = re.compile(\n-    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@]+(?:\\.[^@]+)*)\" r\"$\",\n+    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@\\.]+(?:\\.[^@\\.]+)*)\" r\"$\",\n     re.IGNORECASE,\n )",
      "code_diff":"@@ -48,7 +48,7 @@ def my_type(value):\n \n \n email_regex = re.compile(\n-    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@]+(?:\\.[^@]+)*)\" r\"$\",\n+    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@\\.]+(?:\\.[^@\\.]+)*)\" r\"$\",\n     re.IGNORECASE,\n )"
    },
    {
      "index":46,
      "vuln_id":"GHSA-8g7p-74h8-hg48",
      "cwe_id":"{'CWE-400', 'CWE-125'}",
      "score":9.1,
      "chain":"{'https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/commit\/1c24219df87524e6ed973127e81f30801d658f07'}",
      "dataset":"osv",
      "summary":"Denial of Service in https-proxy-agent Versions of `https-proxy-agent` before 2.2.0 are vulnerable to denial of service. This is due to unsanitized options (proxy.auth) being passed to `Buffer()`.\n\n\n## Recommendation\n\nUpdate to version 2.2.0 or later.",
      "published_date":"2018-07-27",
      "chain_len":1,
      "project":"https:\/\/github.com\/TooTallNate\/node-https-proxy-agent",
      "commit_href":"https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/commit\/1c24219df87524e6ed973127e81f30801d658f07",
      "commit_sha":"1c24219df87524e6ed973127e81f30801d658f07",
      "patch":"SINGLE",
      "chain_ord":"['1c24219df87524e6ed973127e81f30801d658f07']",
      "before_first_fix_commit":"{'c58d365dd153104d1147967a0a6b4e1dd1698e50'}",
      "last_fix_commit":"1c24219df87524e6ed973127e81f30801d658f07",
      "chain_ord_pos":1.0,
      "commit_datetime":"03\/03\/2018, 19:31:04",
      "message":"Use `Buffer.from()`\n\n`new Buffer()` is deprecated and unsafe.",
      "author":"Nathan Rajlich",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'index.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/TooTallNate\/node-https-proxy-agent\/raw\/1c24219df87524e6ed973127e81f30801d658f07\/index.js', 'patch': \"@@ -204,7 +204,7 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\\n   var headers = Object.assign({}, proxy.headers);\\n   if (proxy.auth) {\\n     headers['Proxy-Authorization'] =\\n-      'Basic ' + new Buffer(proxy.auth).toString('base64');\\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64');\\n   }\\n \\n   \/\/ the Host header should only include the port\"}}",
      "message_norm":"use `buffer.from()`\n\n`new buffer()` is deprecated and unsafe.",
      "language":"en",
      "entities":"[('unsafe', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['index.js'])",
      "num_files":1.0,
      "patch_content":"From 1c24219df87524e6ed973127e81f30801d658f07 Mon Sep 17 00:00:00 2001\nFrom: Nathan Rajlich <nathan@tootallnate.net>\nDate: Sat, 3 Mar 2018 11:31:04 -0800\nSubject: [PATCH] Use `Buffer.from()`\n\n`new Buffer()` is deprecated and unsafe.\n---\n index.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/index.js b\/index.js\nindex 69985780..4e007128 100644\n--- a\/index.js\n+++ b\/index.js\n@@ -204,7 +204,7 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\n   var headers = Object.assign({}, proxy.headers);\n   if (proxy.auth) {\n     headers['Proxy-Authorization'] =\n-      'Basic ' + new Buffer(proxy.auth).toString('base64');\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64');\n   }\n \n   \/\/ the Host header should only include the port",
      "code_diff":"@@ -204,7 +204,7 @@ HttpsProxyAgent.prototype.callback = function connect(req, opts, fn) {\n   var headers = Object.assign({}, proxy.headers);\n   if (proxy.auth) {\n     headers['Proxy-Authorization'] =\n-      'Basic ' + new Buffer(proxy.auth).toString('base64');\n+      'Basic ' + Buffer.from(proxy.auth).toString('base64');\n   }\n \n   \/\/ the Host header should only include the port"
    },
    {
      "index":47,
      "vuln_id":"GHSA-627q-g293-49q7",
      "cwe_id":"{'CWE-400'}",
      "score":6.5,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1361fb7e29449629e1df94d44e0427ebec8c83c7'}",
      "dataset":"osv",
      "summary":"Abort caused by allocating a vector that is too large in Tensorflow ### Impact\nDuring shape inference, TensorFlow can [allocate a large vector](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/a1320ec1eac186da1d03f033109191f715b2b130\/tensorflow\/core\/framework\/shape_inference.cc#L788-L790) based on a value from a tensor controlled by the user:\n\n```cc\n  const auto num_dims = Value(shape_dim);\n  std::vector<DimensionHandle> dims;\n  dims.reserve(num_dims);\n``` \n  \n### Patches           \nWe have patched the issue in GitHub commit [1361fb7e29449629e1df94d44e0427ebec8c83c7](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1361fb7e29449629e1df94d44e0427ebec8c83c7).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
      "published_date":"2022-02-07",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/1361fb7e29449629e1df94d44e0427ebec8c83c7",
      "commit_sha":"1361fb7e29449629e1df94d44e0427ebec8c83c7",
      "patch":"SINGLE",
      "chain_ord":"['1361fb7e29449629e1df94d44e0427ebec8c83c7']",
      "before_first_fix_commit":"{'f6e7c84316c9fe416ea32086fa3c64fee21fafab'}",
      "last_fix_commit":"1361fb7e29449629e1df94d44e0427ebec8c83c7",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/10\/2021, 23:52:57",
      "message":"Fix abort caused by allocating a too large vector.\n\nWe need to make sure that the number of dimensions in a shape is within limits.\n\nPiperOrigin-RevId: 408997911\nChange-Id: If59e1c23f2ec9c2d4ff4d8632fd62b2a7773a4eb",
      "author":"Mihai Maruseac",
      "comments":null,
      "stats":"{'additions': 15, 'deletions': 0, 'total': 15}",
      "files":"{'tensorflow\/core\/framework\/shape_inference.cc': {'additions': 15, 'deletions': 0, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/1361fb7e29449629e1df94d44e0427ebec8c83c7\/tensorflow%2Fcore%2Fframework%2Fshape_inference.cc', 'patch': '@@ -14,6 +14,8 @@ limitations under the License.\\n ==============================================================================*\/\\n #include \"tensorflow\/core\/framework\/shape_inference.h\"\\n \\n+#include <cstdint>\\n+\\n #include \"tensorflow\/core\/framework\/bounds_check.h\"\\n #include \"tensorflow\/core\/framework\/full_type_util.h\"\\n #include \"tensorflow\/core\/framework\/node_def.pb.h\"\\n@@ -789,6 +791,19 @@ Status InferenceContext::InternalMakeShapeFromTensor(\\n       return ReturnUnknownShape(out);\\n     }\\n     const auto num_dims = Value(shape_dim);\\n+    \/\/ TODO(mihaimaruseac): Should be `TensorShape::MaxDimensions()` as we are\\n+    \/\/ not able to materialize shapes with more than this number of dimensions\\n+    \/\/ but then shape inference would fail for operations such as\\n+    \/\/ `tf.range`\/`tf.ones`, etc. where the shape is not really materialized,\\n+    \/\/ only used during the inference. Hence, just prevent doing a `reserve`\\n+    \/\/ with a very large argument.\\n+    const int64_t max_dimensions = 1 << 20;\\n+    if (num_dims >= max_dimensions) {\\n+      return errors::Internal(\\n+          \"Cannot create a tensor with \", num_dims,\\n+          \" dimensions, as these would be more than maximum of \",\\n+          max_dimensions);\\n+    }\\n     std::vector<DimensionHandle> dims;\\n     dims.reserve(num_dims);\\n     for (int i = 0; i < num_dims; i++) dims.push_back(UnknownDim());'}}",
      "message_norm":"fix abort caused by allocating a too large vector.\n\nwe need to make sure that the number of dimensions in a shape is within limits.\n\npiperorigin-revid: 408997911\nchange-id: if59e1c23f2ec9c2d4ff4d8632fd62b2a7773a4eb",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('408997911', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/framework\/shape_inference.cc'])",
      "num_files":1.0,
      "patch_content":"From 1361fb7e29449629e1df94d44e0427ebec8c83c7 Mon Sep 17 00:00:00 2001\nFrom: Mihai Maruseac <mihaimaruseac@google.com>\nDate: Wed, 10 Nov 2021 15:52:57 -0800\nSubject: [PATCH] Fix abort caused by allocating a too large vector.\n\nWe need to make sure that the number of dimensions in a shape is within limits.\n\nPiperOrigin-RevId: 408997911\nChange-Id: If59e1c23f2ec9c2d4ff4d8632fd62b2a7773a4eb\n---\n tensorflow\/core\/framework\/shape_inference.cc | 15 +++++++++++++++\n 1 file changed, 15 insertions(+)\n\ndiff --git a\/tensorflow\/core\/framework\/shape_inference.cc b\/tensorflow\/core\/framework\/shape_inference.cc\nindex 077837721ae4fa..3316759aed5a7d 100644\n--- a\/tensorflow\/core\/framework\/shape_inference.cc\n+++ b\/tensorflow\/core\/framework\/shape_inference.cc\n@@ -14,6 +14,8 @@ limitations under the License.\n ==============================================================================*\/\n #include \"tensorflow\/core\/framework\/shape_inference.h\"\n \n+#include <cstdint>\n+\n #include \"tensorflow\/core\/framework\/bounds_check.h\"\n #include \"tensorflow\/core\/framework\/full_type_util.h\"\n #include \"tensorflow\/core\/framework\/node_def.pb.h\"\n@@ -789,6 +791,19 @@ Status InferenceContext::InternalMakeShapeFromTensor(\n       return ReturnUnknownShape(out);\n     }\n     const auto num_dims = Value(shape_dim);\n+    \/\/ TODO(mihaimaruseac): Should be `TensorShape::MaxDimensions()` as we are\n+    \/\/ not able to materialize shapes with more than this number of dimensions\n+    \/\/ but then shape inference would fail for operations such as\n+    \/\/ `tf.range`\/`tf.ones`, etc. where the shape is not really materialized,\n+    \/\/ only used during the inference. Hence, just prevent doing a `reserve`\n+    \/\/ with a very large argument.\n+    const int64_t max_dimensions = 1 << 20;\n+    if (num_dims >= max_dimensions) {\n+      return errors::Internal(\n+          \"Cannot create a tensor with \", num_dims,\n+          \" dimensions, as these would be more than maximum of \",\n+          max_dimensions);\n+    }\n     std::vector<DimensionHandle> dims;\n     dims.reserve(num_dims);\n     for (int i = 0; i < num_dims; i++) dims.push_back(UnknownDim());",
      "code_diff":"@@ -14,6 +14,8 @@ limitations under the License.\n ==============================================================================*\/\n #include \"tensorflow\/core\/framework\/shape_inference.h\"\n \n+#include <cstdint>\n+\n #include \"tensorflow\/core\/framework\/bounds_check.h\"\n #include \"tensorflow\/core\/framework\/full_type_util.h\"\n #include \"tensorflow\/core\/framework\/node_def.pb.h\"\n@@ -789,6 +791,19 @@ Status InferenceContext::InternalMakeShapeFromTensor(\n       return ReturnUnknownShape(out);\n     }\n     const auto num_dims = Value(shape_dim);\n+    \/\/ TODO(mihaimaruseac): Should be `TensorShape::MaxDimensions()` as we are\n+    \/\/ not able to materialize shapes with more than this number of dimensions\n+    \/\/ but then shape inference would fail for operations such as\n+    \/\/ `tf.range`\/`tf.ones`, etc. where the shape is not really materialized,\n+    \/\/ only used during the inference. Hence, just prevent doing a `reserve`\n+    \/\/ with a very large argument.\n+    const int64_t max_dimensions = 1 << 20;\n+    if (num_dims >= max_dimensions) {\n+      return errors::Internal(\n+          \"Cannot create a tensor with \", num_dims,\n+          \" dimensions, as these would be more than maximum of \",\n+          max_dimensions);\n+    }\n     std::vector<DimensionHandle> dims;\n     dims.reserve(num_dims);\n     for (int i = 0; i < num_dims; i++) dims.push_back(UnknownDim());"
    },
    {
      "index":48,
      "vuln_id":"GHSA-fj7c-vg2v-ccrm",
      "cwe_id":"{'CWE-400'}",
      "score":0.0,
      "chain":"{'https:\/\/github.com\/undertow-io\/undertow\/commit\/c7e84a0b7efced38506d7d1dfea5902366973877'}",
      "dataset":"osv",
      "summary":"Undertow vulnerable to memory exhaustion due to buffer leak Buffer leak on incoming WebSocket PONG message(s) in Undertow before 2.0.40 and 2.2.10 can lead to memory exhaustion and allow a denial of service.",
      "published_date":"2022-07-15",
      "chain_len":1,
      "project":"https:\/\/github.com\/undertow-io\/undertow",
      "commit_href":"https:\/\/github.com\/undertow-io\/undertow\/commit\/c7e84a0b7efced38506d7d1dfea5902366973877",
      "commit_sha":"c7e84a0b7efced38506d7d1dfea5902366973877",
      "patch":"SINGLE",
      "chain_ord":"['c7e84a0b7efced38506d7d1dfea5902366973877']",
      "before_first_fix_commit":"{'87f31ddaac835e3b41db339c1841760a1bac004f'}",
      "last_fix_commit":"c7e84a0b7efced38506d7d1dfea5902366973877",
      "chain_ord_pos":1.0,
      "commit_datetime":"07\/30\/2021, 21:26:57",
      "message":"[UNDERTOW-1935] - buffer leak on incoming websocket PONG message",
      "author":"Andrey Marinchuk",
      "comments":null,
      "stats":"{'additions': 2, 'deletions': 0, 'total': 2}",
      "files":"{'websockets-jsr\/src\/main\/java\/io\/undertow\/websockets\/jsr\/FrameHandler.java': {'additions': 2, 'deletions': 0, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/undertow-io\/undertow\/raw\/c7e84a0b7efced38506d7d1dfea5902366973877\/websockets-jsr%2Fsrc%2Fmain%2Fjava%2Fio%2Fundertow%2Fwebsockets%2Fjsr%2FFrameHandler.java', 'patch': '@@ -152,6 +152,8 @@ public void run() {\\n                     }\\n                 }\\n             });\\n+        } else {\\n+            bufferedBinaryMessage.getData().free();\\n         }\\n     }'}}",
      "message_norm":"[undertow-1935] - buffer leak on incoming websocket pong message",
      "language":"en",
      "entities":"[('leak', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['websockets-jsr\/src\/main\/java\/io\/undertow\/websockets\/jsr\/FrameHandler.java'])",
      "num_files":1.0,
      "patch_content":"From c7e84a0b7efced38506d7d1dfea5902366973877 Mon Sep 17 00:00:00 2001\nFrom: Andrey Marinchuk <radist.nt@gmail.com>\nDate: Sat, 31 Jul 2021 00:26:57 +0300\nSubject: [PATCH] [UNDERTOW-1935] - buffer leak on incoming websocket PONG\n message\n\n---\n ...\/src\/main\/java\/io\/undertow\/websockets\/jsr\/FrameHandler.java  | 2 ++\n 1 file changed, 2 insertions(+)\n\ndiff --git a\/websockets-jsr\/src\/main\/java\/io\/undertow\/websockets\/jsr\/FrameHandler.java b\/websockets-jsr\/src\/main\/java\/io\/undertow\/websockets\/jsr\/FrameHandler.java\nindex 12ae5bb38c..a93822587d 100644\n--- a\/websockets-jsr\/src\/main\/java\/io\/undertow\/websockets\/jsr\/FrameHandler.java\n+++ b\/websockets-jsr\/src\/main\/java\/io\/undertow\/websockets\/jsr\/FrameHandler.java\n@@ -152,6 +152,8 @@ public void run() {\n                     }\n                 }\n             });\n+        } else {\n+            bufferedBinaryMessage.getData().free();\n         }\n     }",
      "code_diff":"@@ -152,6 +152,8 @@ public void run() {\n                     }\n                 }\n             });\n+        } else {\n+            bufferedBinaryMessage.getData().free();\n         }\n     }"
    },
    {
      "index":49,
      "vuln_id":"GHSA-gx8x-g87m-h5q6",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/sparklemotion\/nekohtml\/commit\/a800fce3b079def130ed42a408ff1d09f89e773d'}",
      "dataset":"osv",
      "summary":"Denial of Service (DoS) in Nokogiri on JRuby ## Summary\n\nNokogiri `v1.13.4` updates the vendored `org.cyberneko.html` library to `1.9.22.noko2` which addresses [CVE-2022-24839](https:\/\/github.com\/sparklemotion\/nekohtml\/security\/advisories\/GHSA-9849-p7jc-9rmv). That CVE is rated 7.5 (High Severity).\n\nSee [GHSA-9849-p7jc-9rmv](https:\/\/github.com\/sparklemotion\/nekohtml\/security\/advisories\/GHSA-9849-p7jc-9rmv) for more information.\n\nPlease note that this advisory only applies to the **JRuby** implementation of Nokogiri `< 1.13.4`.\n\n\n## Mitigation\n\nUpgrade to Nokogiri `>= 1.13.4`.\n\n\n## Impact\n\n### [CVE-2022-24839](https:\/\/github.com\/sparklemotion\/nekohtml\/security\/advisories\/GHSA-9849-p7jc-9rmv) in nekohtml\n\n- **Severity**: High 7.5\n- **Type**: [CWE-400](https:\/\/cwe.mitre.org\/data\/definitions\/400.html) Uncontrolled Resource Consumption\n- **Description**: The fork of `org.cyberneko.html` used by Nokogiri (Rubygem) raises a `java.lang.OutOfMemoryError` exception when parsing ill-formed HTML markup.\n- **See also**: [GHSA-9849-p7jc-9rmv](https:\/\/github.com\/sparklemotion\/nekohtml\/security\/advisories\/GHSA-9849-p7jc-9rmv)",
      "published_date":"2022-04-11",
      "chain_len":1,
      "project":"https:\/\/github.com\/sparklemotion\/nekohtml",
      "commit_href":"https:\/\/github.com\/sparklemotion\/nekohtml\/commit\/a800fce3b079def130ed42a408ff1d09f89e773d",
      "commit_sha":"a800fce3b079def130ed42a408ff1d09f89e773d",
      "patch":"SINGLE",
      "chain_ord":"['a800fce3b079def130ed42a408ff1d09f89e773d']",
      "before_first_fix_commit":"{'6fe9b53bc289d0e90d684c0f4a8e9f2b19f3460f'}",
      "last_fix_commit":"a800fce3b079def130ed42a408ff1d09f89e773d",
      "chain_ord_pos":1.0,
      "commit_datetime":"04\/03\/2022, 23:03:39",
      "message":"fix: ensure ill-formed PIs are parsed correctly",
      "author":"Mike Dalessio",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'src\/org\/cyberneko\/html\/HTMLScanner.java': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/sparklemotion\/nekohtml\/raw\/a800fce3b079def130ed42a408ff1d09f89e773d\/src%2Forg%2Fcyberneko%2Fhtml%2FHTMLScanner.java', 'patch': \"@@ -2588,7 +2588,7 @@ protected void scanPI() throws IOException {\\n                     if (c == '?' || c == '\/') {\\n                         char c0 = (char)c;\\n                         c = fCurrentEntity.read();\\n-                        if (c == '>') {\\n+                        if (c == '>' || c == -1) {\\n                             break;\\n                         }\\n                         fStringBuffer.append(c0);\"}}",
      "message_norm":"fix: ensure ill-formed pis are parsed correctly",
      "language":"en",
      "entities":"[('fix', 'ACTION', ''), ('ensure', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['src\/org\/cyberneko\/html\/HTMLScanner.java'])",
      "num_files":1.0,
      "patch_content":"From a800fce3b079def130ed42a408ff1d09f89e773d Mon Sep 17 00:00:00 2001\nFrom: Mike Dalessio <mike.dalessio@gmail.com>\nDate: Sun, 3 Apr 2022 19:03:39 -0400\nSubject: [PATCH] fix: ensure ill-formed PIs are parsed correctly\n\n---\n src\/org\/cyberneko\/html\/HTMLScanner.java | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/src\/org\/cyberneko\/html\/HTMLScanner.java b\/src\/org\/cyberneko\/html\/HTMLScanner.java\nindex fe414a4..0519316 100644\n--- a\/src\/org\/cyberneko\/html\/HTMLScanner.java\n+++ b\/src\/org\/cyberneko\/html\/HTMLScanner.java\n@@ -2588,7 +2588,7 @@ protected void scanPI() throws IOException {\n                     if (c == '?' || c == '\/') {\n                         char c0 = (char)c;\n                         c = fCurrentEntity.read();\n-                        if (c == '>') {\n+                        if (c == '>' || c == -1) {\n                             break;\n                         }\n                         fStringBuffer.append(c0);",
      "code_diff":"@@ -2588,7 +2588,7 @@ protected void scanPI() throws IOException {\n                     if (c == '?' || c == '\/') {\n                         char c0 = (char)c;\n                         c = fCurrentEntity.read();\n-                        if (c == '>') {\n+                        if (c == '>' || c == -1) {\n                             break;\n                         }\n                         fStringBuffer.append(c0);"
    },
    {
      "index":50,
      "vuln_id":"GHSA-23fp-fmrv-f5px",
      "cwe_id":"{'CWE-400'}",
      "score":4.9,
      "chain":"{'https:\/\/github.com\/strapi\/strapi\/commit\/c0c191c08f05fe10d7a6b1bf9475c1a651a89362'}",
      "dataset":"osv",
      "summary":"Uncontrolled Resource Consumption in strapi A denial of service exists in strapi v3.0.0-beta.18.3 and earlier that can be abused in the admin console using admin rights can lead to arbitrary restart of the application.",
      "published_date":"2021-12-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/strapi\/strapi",
      "commit_href":"https:\/\/github.com\/strapi\/strapi\/commit\/c0c191c08f05fe10d7a6b1bf9475c1a651a89362",
      "commit_sha":"c0c191c08f05fe10d7a6b1bf9475c1a651a89362",
      "patch":"SINGLE",
      "chain_ord":"['c0c191c08f05fe10d7a6b1bf9475c1a651a89362']",
      "before_first_fix_commit":"{'7e3f7ee2de9eecd0bc098d7b77940b64f48b3a96'}",
      "last_fix_commit":"c0c191c08f05fe10d7a6b1bf9475c1a651a89362",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/07\/2020, 13:15:16",
      "message":"chore(admin): Improve plugin name validator in install\/uninstall plugin",
      "author":"Alexandre Bodin",
      "comments":null,
      "stats":"{'additions': 13, 'deletions': 2, 'total': 15}",
      "files":"{'packages\/strapi-admin\/controllers\/Admin.js': {'additions': 13, 'deletions': 2, 'changes': 15, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/strapi\/strapi\/raw\/c0c191c08f05fe10d7a6b1bf9475c1a651a89362\/packages%2Fstrapi-admin%2Fcontrollers%2FAdmin.js', 'patch': '@@ -7,6 +7,17 @@ const formatError = error => [\\n   { messages: [{ id: error.id, message: error.message, field: error.field }] },\\n ];\\n \\n+const PLUGIN_NAME_REGEX = \/^[A-Za-z][A-Za-z0-9-_]+$\/;\\n+\\n+\/**\\n+ * Validates a plugin name format\\n+ *\/\\n+const isValidPluginName = plugin => {\\n+  return (\\n+    _.isString(plugin) && !_.isEmpty(plugin) && PLUGIN_NAME_REGEX.test(plugin)\\n+  );\\n+};\\n+\\n \/**\\n  * A set of functions called \"actions\" for `Admin`\\n  *\/\\n@@ -67,7 +78,7 @@ module.exports = {\\n     try {\\n       const { plugin } = ctx.request.body;\\n \\n-      if (!\/^[A-Za-z0-9_-]+$\/.test(plugin)) {\\n+      if (!isValidPluginName(plugin)) {\\n         return ctx.badRequest(\\'Invalid plugin name\\');\\n       }\\n \\n@@ -107,7 +118,7 @@ module.exports = {\\n     try {\\n       const { plugin } = ctx.params;\\n \\n-      if (!\/^[A-Za-z0-9_-]+$\/.test(plugin)) {\\n+      if (!isValidPluginName(plugin)) {\\n         return ctx.badRequest(\\'Invalid plugin name\\');\\n       }'}}",
      "message_norm":"chore(admin): improve plugin name validator in install\/uninstall plugin",
      "language":"it",
      "entities":"[('chore(admin', 'SECWORD', ''), ('improve', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['packages\/strapi-admin\/controllers\/Admin.js'])",
      "num_files":1.0,
      "patch_content":"From c0c191c08f05fe10d7a6b1bf9475c1a651a89362 Mon Sep 17 00:00:00 2001\nFrom: Alexandre Bodin <bodin.alex@gmail.com>\nDate: Tue, 7 Jan 2020 14:15:16 +0100\nSubject: [PATCH] chore(admin): Improve plugin name validator in\n install\/uninstall plugin\n\n---\n packages\/strapi-admin\/controllers\/Admin.js | 15 +++++++++++++--\n 1 file changed, 13 insertions(+), 2 deletions(-)\n\ndiff --git a\/packages\/strapi-admin\/controllers\/Admin.js b\/packages\/strapi-admin\/controllers\/Admin.js\nindex d888e95d7a3f..ea5ed8ae12b1 100644\n--- a\/packages\/strapi-admin\/controllers\/Admin.js\n+++ b\/packages\/strapi-admin\/controllers\/Admin.js\n@@ -7,6 +7,17 @@ const formatError = error => [\n   { messages: [{ id: error.id, message: error.message, field: error.field }] },\n ];\n \n+const PLUGIN_NAME_REGEX = \/^[A-Za-z][A-Za-z0-9-_]+$\/;\n+\n+\/**\n+ * Validates a plugin name format\n+ *\/\n+const isValidPluginName = plugin => {\n+  return (\n+    _.isString(plugin) && !_.isEmpty(plugin) && PLUGIN_NAME_REGEX.test(plugin)\n+  );\n+};\n+\n \/**\n  * A set of functions called \"actions\" for `Admin`\n  *\/\n@@ -67,7 +78,7 @@ module.exports = {\n     try {\n       const { plugin } = ctx.request.body;\n \n-      if (!\/^[A-Za-z0-9_-]+$\/.test(plugin)) {\n+      if (!isValidPluginName(plugin)) {\n         return ctx.badRequest('Invalid plugin name');\n       }\n \n@@ -107,7 +118,7 @@ module.exports = {\n     try {\n       const { plugin } = ctx.params;\n \n-      if (!\/^[A-Za-z0-9_-]+$\/.test(plugin)) {\n+      if (!isValidPluginName(plugin)) {\n         return ctx.badRequest('Invalid plugin name');\n       }",
      "code_diff":"@@ -7,6 +7,17 @@ const formatError = error => [\n   { messages: [{ id: error.id, message: error.message, field: error.field }] },\n ];\n \n+const PLUGIN_NAME_REGEX = \/^[A-Za-z][A-Za-z0-9-_]+$\/;\n+\n+\/**\n+ * Validates a plugin name format\n+ *\/\n+const isValidPluginName = plugin => {\n+  return (\n+    _.isString(plugin) && !_.isEmpty(plugin) && PLUGIN_NAME_REGEX.test(plugin)\n+  );\n+};\n+\n \/**\n  * A set of functions called \"actions\" for `Admin`\n  *\/\n@@ -67,7 +78,7 @@ module.exports = {\n     try {\n       const { plugin } = ctx.request.body;\n \n-      if (!\/^[A-Za-z0-9_-]+$\/.test(plugin)) {\n+      if (!isValidPluginName(plugin)) {\n         return ctx.badRequest('Invalid plugin name');\n       }\n \n@@ -107,7 +118,7 @@ module.exports = {\n     try {\n       const { plugin } = ctx.params;\n \n-      if (!\/^[A-Za-z0-9_-]+$\/.test(plugin)) {\n+      if (!isValidPluginName(plugin)) {\n         return ctx.badRequest('Invalid plugin name');\n       }"
    },
    {
      "index":51,
      "vuln_id":"GHSA-29mw-wpgm-hmr9",
      "cwe_id":"{'CWE-400'}",
      "score":5.3,
      "chain":"{'https:\/\/github.com\/lodash\/lodash\/pull\/5065\/commits\/02906b8191d3c100c193fe6f7b27d1c40f200bb7'}",
      "dataset":"osv",
      "summary":"Regular Expression Denial of Service (ReDoS) in lodash All versions of package lodash prior to 4.17.21 are vulnerable to Regular Expression Denial of Service (ReDoS) via the toNumber, trim and trimEnd functions. Steps to reproduce (provided by reporter Liyuan Chen): var lo = require('lodash'); function build_blank (n) { var ret = \"1\" for (var i = 0; i < n; i++) { ret += \" \" } return ret + \"1\"; } var s = build_blank(50000) var time0 = Date.now(); lo.trim(s) var time_cost0 = Date.now() - time0; console.log(\"time_cost0: \" + time_cost0) var time1 = Date.now(); lo.toNumber(s) var time_cost1 = Date.now() - time1; console.log(\"time_cost1: \" + time_cost1) var time2 = Date.now(); lo.trimEnd(s) var time_cost2 = Date.now() - time2; console.log(\"time_cost2: \" + time_cost2)",
      "published_date":"2022-01-06",
      "chain_len":1,
      "project":"https:\/\/github.com\/lodash\/lodash",
      "commit_href":"https:\/\/github.com\/lodash\/lodash\/pull\/5065\/commits\/02906b8191d3c100c193fe6f7b27d1c40f200bb7",
      "commit_sha":"02906b8191d3c100c193fe6f7b27d1c40f200bb7",
      "patch":"SINGLE",
      "chain_ord":"['02906b8191d3c100c193fe6f7b27d1c40f200bb7']",
      "before_first_fix_commit":"{'ded9bc66583ed0b4e3b7dc906206d40757b4a90a'}",
      "last_fix_commit":"02906b8191d3c100c193fe6f7b27d1c40f200bb7",
      "chain_ord_pos":1.0,
      "commit_datetime":"01\/26\/2021, 22:17:05",
      "message":"perf: improve performance of `toNumber`, `trim` and `trimEnd` on large input strings",
      "author":"Micha\u0142 Lipi\u0144ski",
      "comments":null,
      "stats":"{'additions': 36, 'deletions': 7, 'total': 43}",
      "files":"{'lodash.js': {'additions': 36, 'deletions': 7, 'changes': 43, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/lodash\/lodash\/raw\/02906b8191d3c100c193fe6f7b27d1c40f200bb7\/lodash.js', 'patch': \"@@ -152,10 +152,11 @@\\n   var reRegExpChar = \/[\\\\\\\\^$.*+?()[\\\\]{}|]\/g,\\n       reHasRegExpChar = RegExp(reRegExpChar.source);\\n \\n-  \/** Used to match leading and trailing whitespace. *\/\\n-  var reTrim = \/^\\\\s+|\\\\s+$\/g,\\n-      reTrimStart = \/^\\\\s+\/,\\n-      reTrimEnd = \/\\\\s+$\/;\\n+  \/** Used to match leading whitespace. *\/\\n+  var reTrimStart = \/^\\\\s+\/;\\n+\\n+  \/** Used to match a single whitespace character. *\/\\n+  var reWhitespace = \/\\\\s\/;\\n \\n   \/** Used to match wrap detail comments. *\/\\n   var reWrapComment = \/\\\\{(?:\\\\n\\\\\/\\\\* \\\\[wrapped with .+\\\\] \\\\*\\\\\/)?\\\\n?\/,\\n@@ -993,6 +994,19 @@\\n     });\\n   }\\n \\n+  \/**\\n+   * The base implementation of `_.trim`.\\n+   *\\n+   * @private\\n+   * @param {string} string The string to trim.\\n+   * @returns {string} Returns the trimmed string.\\n+   *\/\\n+  function baseTrim(string) {\\n+    return string\\n+      ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\\n+      : string;\\n+  }\\n+\\n   \/**\\n    * The base implementation of `_.unary` without support for storing metadata.\\n    *\\n@@ -1326,6 +1340,21 @@\\n       : asciiToArray(string);\\n   }\\n \\n+  \/**\\n+   * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\\n+   * character of `string`.\\n+   *\\n+   * @private\\n+   * @param {string} string The string to inspect.\\n+   * @returns {number} Returns the index of the last non-whitespace character.\\n+   *\/\\n+  function trimmedEndIndex(string) {\\n+    var index = string.length;\\n+\\n+    while (index-- && reWhitespace.test(string.charAt(index))) {}\\n+    return index;\\n+  }\\n+\\n   \/**\\n    * Used by `_.unescape` to convert HTML entities to characters.\\n    *\\n@@ -12494,7 +12523,7 @@\\n       if (typeof value != 'string') {\\n         return value === 0 ? value : +value;\\n       }\\n-      value = value.replace(reTrim, '');\\n+      value = baseTrim(value);\\n       var isBinary = reIsBinary.test(value);\\n       return (isBinary || reIsOctal.test(value))\\n         ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\\n@@ -14979,7 +15008,7 @@\\n     function trim(string, chars, guard) {\\n       string = toString(string);\\n       if (string && (guard || chars === undefined)) {\\n-        return string.replace(reTrim, '');\\n+        return baseTrim(string);\\n       }\\n       if (!string || !(chars = baseToString(chars))) {\\n         return string;\\n@@ -15014,7 +15043,7 @@\\n     function trimEnd(string, chars, guard) {\\n       string = toString(string);\\n       if (string && (guard || chars === undefined)) {\\n-        return string.replace(reTrimEnd, '');\\n+        return string.slice(0, trimmedEndIndex(string) + 1);\\n       }\\n       if (!string || !(chars = baseToString(chars))) {\\n         return string;\"}}",
      "message_norm":"perf: improve performance of `tonumber`, `trim` and `trimend` on large input strings",
      "language":"en",
      "entities":"[('improve', 'ACTION', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lodash.js'])",
      "num_files":1.0,
      "patch_content":"From 02906b8191d3c100c193fe6f7b27d1c40f200bb7 Mon Sep 17 00:00:00 2001\nFrom: =?UTF-8?q?Micha=C5=82=20Lipi=C5=84ski?= <mylith@gmail.com>\nDate: Tue, 26 Jan 2021 23:17:05 +0100\nSubject: [PATCH] perf: improve performance of `toNumber`, `trim` and `trimEnd`\n on large input strings\n\n---\n lodash.js | 43 ++++++++++++++++++++++++++++++++++++-------\n 1 file changed, 36 insertions(+), 7 deletions(-)\n\ndiff --git a\/lodash.js b\/lodash.js\nindex 1fd7116f42..7d40df0305 100644\n--- a\/lodash.js\n+++ b\/lodash.js\n@@ -152,10 +152,11 @@\n   var reRegExpChar = \/[\\\\^$.*+?()[\\]{}|]\/g,\n       reHasRegExpChar = RegExp(reRegExpChar.source);\n \n-  \/** Used to match leading and trailing whitespace. *\/\n-  var reTrim = \/^\\s+|\\s+$\/g,\n-      reTrimStart = \/^\\s+\/,\n-      reTrimEnd = \/\\s+$\/;\n+  \/** Used to match leading whitespace. *\/\n+  var reTrimStart = \/^\\s+\/;\n+\n+  \/** Used to match a single whitespace character. *\/\n+  var reWhitespace = \/\\s\/;\n \n   \/** Used to match wrap detail comments. *\/\n   var reWrapComment = \/\\{(?:\\n\\\/\\* \\[wrapped with .+\\] \\*\\\/)?\\n?\/,\n@@ -993,6 +994,19 @@\n     });\n   }\n \n+  \/**\n+   * The base implementation of `_.trim`.\n+   *\n+   * @private\n+   * @param {string} string The string to trim.\n+   * @returns {string} Returns the trimmed string.\n+   *\/\n+  function baseTrim(string) {\n+    return string\n+      ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n+      : string;\n+  }\n+\n   \/**\n    * The base implementation of `_.unary` without support for storing metadata.\n    *\n@@ -1326,6 +1340,21 @@\n       : asciiToArray(string);\n   }\n \n+  \/**\n+   * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n+   * character of `string`.\n+   *\n+   * @private\n+   * @param {string} string The string to inspect.\n+   * @returns {number} Returns the index of the last non-whitespace character.\n+   *\/\n+  function trimmedEndIndex(string) {\n+    var index = string.length;\n+\n+    while (index-- && reWhitespace.test(string.charAt(index))) {}\n+    return index;\n+  }\n+\n   \/**\n    * Used by `_.unescape` to convert HTML entities to characters.\n    *\n@@ -12494,7 +12523,7 @@\n       if (typeof value != 'string') {\n         return value === 0 ? value : +value;\n       }\n-      value = value.replace(reTrim, '');\n+      value = baseTrim(value);\n       var isBinary = reIsBinary.test(value);\n       return (isBinary || reIsOctal.test(value))\n         ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n@@ -14979,7 +15008,7 @@\n     function trim(string, chars, guard) {\n       string = toString(string);\n       if (string && (guard || chars === undefined)) {\n-        return string.replace(reTrim, '');\n+        return baseTrim(string);\n       }\n       if (!string || !(chars = baseToString(chars))) {\n         return string;\n@@ -15014,7 +15043,7 @@\n     function trimEnd(string, chars, guard) {\n       string = toString(string);\n       if (string && (guard || chars === undefined)) {\n-        return string.replace(reTrimEnd, '');\n+        return string.slice(0, trimmedEndIndex(string) + 1);\n       }\n       if (!string || !(chars = baseToString(chars))) {\n         return string;",
      "code_diff":"@@ -152,10 +152,11 @@\n   var reRegExpChar = \/[\\\\^$.*+?()[\\]{}|]\/g,\n       reHasRegExpChar = RegExp(reRegExpChar.source);\n \n-  \/** Used to match leading and trailing whitespace. *\/\n-  var reTrim = \/^\\s+|\\s+$\/g,\n-      reTrimStart = \/^\\s+\/,\n-      reTrimEnd = \/\\s+$\/;\n+  \/** Used to match leading whitespace. *\/\n+  var reTrimStart = \/^\\s+\/;\n+\n+  \/** Used to match a single whitespace character. *\/\n+  var reWhitespace = \/\\s\/;\n \n   \/** Used to match wrap detail comments. *\/\n   var reWrapComment = \/\\{(?:\\n\\\/\\* \\[wrapped with .+\\] \\*\\\/)?\\n?\/,\n@@ -993,6 +994,19 @@\n     });\n   }\n \n+  \/**\n+   * The base implementation of `_.trim`.\n+   *\n+   * @private\n+   * @param {string} string The string to trim.\n+   * @returns {string} Returns the trimmed string.\n+   *\/\n+  function baseTrim(string) {\n+    return string\n+      ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n+      : string;\n+  }\n+\n   \/**\n    * The base implementation of `_.unary` without support for storing metadata.\n    *\n@@ -1326,6 +1340,21 @@\n       : asciiToArray(string);\n   }\n \n+  \/**\n+   * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n+   * character of `string`.\n+   *\n+   * @private\n+   * @param {string} string The string to inspect.\n+   * @returns {number} Returns the index of the last non-whitespace character.\n+   *\/\n+  function trimmedEndIndex(string) {\n+    var index = string.length;\n+\n+    while (index-- && reWhitespace.test(string.charAt(index))) {}\n+    return index;\n+  }\n+\n   \/**\n    * Used by `_.unescape` to convert HTML entities to characters.\n    *\n@@ -12494,7 +12523,7 @@\n       if (typeof value != 'string') {\n         return value === 0 ? value : +value;\n       }\n-      value = value.replace(reTrim, '');\n+      value = baseTrim(value);\n       var isBinary = reIsBinary.test(value);\n       return (isBinary || reIsOctal.test(value))\n         ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n@@ -14979,7 +15008,7 @@\n     function trim(string, chars, guard) {\n       string = toString(string);\n       if (string && (guard || chars === undefined)) {\n-        return string.replace(reTrim, '');\n+        return baseTrim(string);\n       }\n       if (!string || !(chars = baseToString(chars))) {\n         return string;\n@@ -15014,7 +15043,7 @@\n     function trimEnd(string, chars, guard) {\n       string = toString(string);\n       if (string && (guard || chars === undefined)) {\n-        return string.replace(reTrimEnd, '');\n+        return string.slice(0, trimmedEndIndex(string) + 1);\n       }\n       if (!string || !(chars = baseToString(chars))) {\n         return string;"
    },
    {
      "index":52,
      "vuln_id":"GHSA-jgrx-mgxx-jf9v",
      "cwe_id":"{'CWE-400'}",
      "score":7.5,
      "chain":"{'https:\/\/github.com\/daaku\/nodejs-tmpl\/commit\/4c654e4d1542f329ed561fd95ccd80f30c6872d6'}",
      "dataset":"osv",
      "summary":"tmpl vulnerable to Inefficient Regular Expression Complexity which may lead to resource exhaustion nodejs-tmpl is simple string formatting. tmpl is vulnerable to Inefficient Regular Expression Complexity which may lead to resource exhaustion.",
      "published_date":"2021-09-20",
      "chain_len":1,
      "project":"https:\/\/github.com\/daaku\/nodejs-tmpl",
      "commit_href":"https:\/\/github.com\/daaku\/nodejs-tmpl\/commit\/4c654e4d1542f329ed561fd95ccd80f30c6872d6",
      "commit_sha":"4c654e4d1542f329ed561fd95ccd80f30c6872d6",
      "patch":"SINGLE",
      "chain_ord":"['4c654e4d1542f329ed561fd95ccd80f30c6872d6']",
      "before_first_fix_commit":"{'1dbd350783f04743bd759cc5ae1e1e3633d550ff'}",
      "last_fix_commit":"4c654e4d1542f329ed561fd95ccd80f30c6872d6",
      "chain_ord_pos":1.0,
      "commit_datetime":"09\/07\/2021, 06:41:06",
      "message":"fix potential dos in regex",
      "author":"Naitik Shah",
      "comments":null,
      "stats":"{'additions': 1, 'deletions': 1, 'total': 2}",
      "files":"{'lib\/tmpl.js': {'additions': 1, 'deletions': 1, 'changes': 2, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/daaku\/nodejs-tmpl\/raw\/4c654e4d1542f329ed561fd95ccd80f30c6872d6\/lib%2Ftmpl.js', 'patch': \"@@ -1,4 +1,4 @@\\n-var INTERPOLATE = \/{([\\\\s\\\\S]+?)}\/g\\n+var INTERPOLATE = \/{([^{]+?)}\/g\\n \\n module.exports = function(str, data) {\\n   var tmpl = 'var __p=[],print=function(){__p.push.apply(__p,arguments);};' +\"}}",
      "message_norm":"fix potential dos in regex",
      "language":"ca",
      "entities":"[('fix', 'ACTION', ''), ('dos', 'SECWORD', '')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['lib\/tmpl.js'])",
      "num_files":1.0,
      "patch_content":"From 4c654e4d1542f329ed561fd95ccd80f30c6872d6 Mon Sep 17 00:00:00 2001\nFrom: Naitik Shah <n@daaku.org>\nDate: Tue, 7 Sep 2021 10:41:06 +0400\nSubject: [PATCH] fix potential dos in regex\n\n---\n lib\/tmpl.js | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a\/lib\/tmpl.js b\/lib\/tmpl.js\nindex 8fed3a8..63ed9b2 100644\n--- a\/lib\/tmpl.js\n+++ b\/lib\/tmpl.js\n@@ -1,4 +1,4 @@\n-var INTERPOLATE = \/{([\\s\\S]+?)}\/g\n+var INTERPOLATE = \/{([^{]+?)}\/g\n \n module.exports = function(str, data) {\n   var tmpl = 'var __p=[],print=function(){__p.push.apply(__p,arguments);};' +",
      "code_diff":"@@ -1,4 +1,4 @@\n-var INTERPOLATE = \/{([\\s\\S]+?)}\/g\n+var INTERPOLATE = \/{([^{]+?)}\/g\n \n module.exports = function(str, data) {\n   var tmpl = 'var __p=[],print=function(){__p.push.apply(__p,arguments);};' +"
    },
    {
      "index":53,
      "vuln_id":"GHSA-c582-c96p-r5cq",
      "cwe_id":"{'CWE-400', 'CWE-770'}",
      "score":4.3,
      "chain":"{'https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e'}",
      "dataset":"osv",
      "summary":"Memory exhaustion in Tensorflow ### Impact \nThe [implementation of `ThreadPoolHandle`](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/5100e359aef5c8021f2e71c7b986420b85ce7b3d\/tensorflow\/core\/kernels\/data\/experimental\/threadpool_dataset_op.cc#L79-L135) can be used to trigger a denial of service attack by allocating too much memory:\n\n```python\nimport tensorflow as tf\ny = tf.raw_ops.ThreadPoolHandle(num_threads=0x60000000,display_name='tf')\n```\n\nThis is because the `num_threads` argument is only checked to not be negative, but there is no upper bound on its value.\n    \n### Patches\nWe have patched the issue in GitHub commit [e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e](https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e).\n\nThe fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/master\/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported by Yu Tian of Qihoo 360 AIVul Team.",
      "published_date":"2022-02-10",
      "chain_len":1,
      "project":"https:\/\/github.com\/tensorflow\/tensorflow",
      "commit_href":"https:\/\/github.com\/tensorflow\/tensorflow\/commit\/e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e",
      "commit_sha":"e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e",
      "patch":"SINGLE",
      "chain_ord":"['e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e']",
      "before_first_fix_commit":"{'dc94fe9983e3deca817b7a081fa43c4e3b1ddec8'}",
      "last_fix_commit":"e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e",
      "chain_ord_pos":1.0,
      "commit_datetime":"11\/19\/2021, 00:10:34",
      "message":"[tf.data] Set limit on number of threads used in threadpool_dataset.\n\nPiperOrigin-RevId: 410922677\nChange-Id: Ib25814a99043ab10805b5d2d7088ae0e0b7b04fd",
      "author":"Andrew Audibert",
      "comments":null,
      "stats":"{'additions': 19, 'deletions': 7, 'total': 26}",
      "files":"{'tensorflow\/core\/kernels\/data\/experimental\/threadpool_dataset_op.cc': {'additions': 19, 'deletions': 7, 'changes': 26, 'status': 'modified', 'raw_url': 'https:\/\/github.com\/tensorflow\/tensorflow\/raw\/e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e\/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fthreadpool_dataset_op.cc', 'patch': '@@ -39,6 +39,22 @@ namespace experimental {\\n     PrivateThreadPoolDatasetOp::kDatasetType;\\n \/* static *\/ constexpr const char* const PrivateThreadPoolDatasetOp::kDatasetOp;\\n \\n+namespace {\\n+\/\/ To prevent integer overflow issues when allocating threadpool memory for an\\n+\/\/ unreasonable number of threads.\\n+constexpr int kThreadLimit = 65536;\\n+\\n+Status ValidateNumThreads(int32_t num_threads) {\\n+  if (num_threads < 0) {\\n+    return errors::InvalidArgument(\"`num_threads` must be >= 0\");\\n+  }\\n+  if (num_threads >= kThreadLimit) {\\n+    return errors::InvalidArgument(\"`num_threads` must be < \", kThreadLimit);\\n+  }\\n+  return Status::OK();\\n+}\\n+}  \/\/ namespace\\n+\\n class ThreadPoolResource : public ResourceBase {\\n  public:\\n   ThreadPoolResource(Env* env, const ThreadOptions& thread_options,\\n@@ -83,9 +99,7 @@ class ThreadPoolHandleOp : public OpKernel {\\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_threads\", &num_threads_));\\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"max_intra_op_parallelism\",\\n                                      &max_intra_op_parallelism_));\\n-    OP_REQUIRES(\\n-        ctx, num_threads_ > 0,\\n-        errors::InvalidArgument(\"`num_threads` must be greater than zero.\"));\\n+    OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads_));\\n   }\\n \\n   \/\/ The resource is deleted from the resource manager only when it is private\\n@@ -531,8 +545,7 @@ void PrivateThreadPoolDatasetOp::MakeDatasetFromOptions(OpKernelContext* ctx,\\n                                                         DatasetBase* input,\\n                                                         int32_t num_threads,\\n                                                         DatasetBase** output) {\\n-  OP_REQUIRES(ctx, num_threads >= 0,\\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\\n   *output = new Dataset(ctx,\\n                         DatasetContext(DatasetContext::Params(\\n                             {PrivateThreadPoolDatasetOp::kDatasetType,\\n@@ -546,8 +559,7 @@ void PrivateThreadPoolDatasetOp::MakeDataset(OpKernelContext* ctx,\\n   int64_t num_threads = 0;\\n   OP_REQUIRES_OK(\\n       ctx, ParseScalarArgument<int64_t>(ctx, \"num_threads\", &num_threads));\\n-  OP_REQUIRES(ctx, num_threads >= 0,\\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\\n   *output = new Dataset(ctx, input, num_threads);\\n }'}}",
      "message_norm":"[tf.data] set limit on number of threads used in threadpool_dataset.\n\npiperorigin-revid: 410922677\nchange-id: ib25814a99043ab10805b5d2d7088ae0e0b7b04fd",
      "language":"en",
      "entities":"[('410922677', 'SHA', 'generic_sha')]",
      "classification_level_1":null,
      "classification_level_2":null,
      "list_files":"dict_keys(['tensorflow\/core\/kernels\/data\/experimental\/threadpool_dataset_op.cc'])",
      "num_files":1.0,
      "patch_content":"From e3749a6d5d1e8d11806d4a2e9cc3123d1a90b75e Mon Sep 17 00:00:00 2001\nFrom: Andrew Audibert <aaudibert@google.com>\nDate: Thu, 18 Nov 2021 16:10:34 -0800\nSubject: [PATCH] [tf.data] Set limit on number of threads used in\n threadpool_dataset.\n\nPiperOrigin-RevId: 410922677\nChange-Id: Ib25814a99043ab10805b5d2d7088ae0e0b7b04fd\n---\n ...\/experimental\/threadpool_dataset_op.cc     | 26 ++++++++++++++-----\n 1 file changed, 19 insertions(+), 7 deletions(-)\n\ndiff --git a\/tensorflow\/core\/kernels\/data\/experimental\/threadpool_dataset_op.cc b\/tensorflow\/core\/kernels\/data\/experimental\/threadpool_dataset_op.cc\nindex c58e5f68e6c6c6..fefaf8249b76bc 100644\n--- a\/tensorflow\/core\/kernels\/data\/experimental\/threadpool_dataset_op.cc\n+++ b\/tensorflow\/core\/kernels\/data\/experimental\/threadpool_dataset_op.cc\n@@ -39,6 +39,22 @@ namespace experimental {\n     PrivateThreadPoolDatasetOp::kDatasetType;\n \/* static *\/ constexpr const char* const PrivateThreadPoolDatasetOp::kDatasetOp;\n \n+namespace {\n+\/\/ To prevent integer overflow issues when allocating threadpool memory for an\n+\/\/ unreasonable number of threads.\n+constexpr int kThreadLimit = 65536;\n+\n+Status ValidateNumThreads(int32_t num_threads) {\n+  if (num_threads < 0) {\n+    return errors::InvalidArgument(\"`num_threads` must be >= 0\");\n+  }\n+  if (num_threads >= kThreadLimit) {\n+    return errors::InvalidArgument(\"`num_threads` must be < \", kThreadLimit);\n+  }\n+  return Status::OK();\n+}\n+}  \/\/ namespace\n+\n class ThreadPoolResource : public ResourceBase {\n  public:\n   ThreadPoolResource(Env* env, const ThreadOptions& thread_options,\n@@ -83,9 +99,7 @@ class ThreadPoolHandleOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_threads\", &num_threads_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"max_intra_op_parallelism\",\n                                      &max_intra_op_parallelism_));\n-    OP_REQUIRES(\n-        ctx, num_threads_ > 0,\n-        errors::InvalidArgument(\"`num_threads` must be greater than zero.\"));\n+    OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads_));\n   }\n \n   \/\/ The resource is deleted from the resource manager only when it is private\n@@ -531,8 +545,7 @@ void PrivateThreadPoolDatasetOp::MakeDatasetFromOptions(OpKernelContext* ctx,\n                                                         DatasetBase* input,\n                                                         int32_t num_threads,\n                                                         DatasetBase** output) {\n-  OP_REQUIRES(ctx, num_threads >= 0,\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\n   *output = new Dataset(ctx,\n                         DatasetContext(DatasetContext::Params(\n                             {PrivateThreadPoolDatasetOp::kDatasetType,\n@@ -546,8 +559,7 @@ void PrivateThreadPoolDatasetOp::MakeDataset(OpKernelContext* ctx,\n   int64_t num_threads = 0;\n   OP_REQUIRES_OK(\n       ctx, ParseScalarArgument<int64_t>(ctx, \"num_threads\", &num_threads));\n-  OP_REQUIRES(ctx, num_threads >= 0,\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\n   *output = new Dataset(ctx, input, num_threads);\n }",
      "code_diff":"@@ -39,6 +39,22 @@ namespace experimental {\n     PrivateThreadPoolDatasetOp::kDatasetType;\n \/* static *\/ constexpr const char* const PrivateThreadPoolDatasetOp::kDatasetOp;\n \n+namespace {\n+\/\/ To prevent integer overflow issues when allocating threadpool memory for an\n+\/\/ unreasonable number of threads.\n+constexpr int kThreadLimit = 65536;\n+\n+Status ValidateNumThreads(int32_t num_threads) {\n+  if (num_threads < 0) {\n+    return errors::InvalidArgument(\"`num_threads` must be >= 0\");\n+  }\n+  if (num_threads >= kThreadLimit) {\n+    return errors::InvalidArgument(\"`num_threads` must be < \", kThreadLimit);\n+  }\n+  return Status::OK();\n+}\n+}  \/\/ namespace\n+\n class ThreadPoolResource : public ResourceBase {\n  public:\n   ThreadPoolResource(Env* env, const ThreadOptions& thread_options,\n@@ -83,9 +99,7 @@ class ThreadPoolHandleOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_threads\", &num_threads_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"max_intra_op_parallelism\",\n                                      &max_intra_op_parallelism_));\n-    OP_REQUIRES(\n-        ctx, num_threads_ > 0,\n-        errors::InvalidArgument(\"`num_threads` must be greater than zero.\"));\n+    OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads_));\n   }\n \n   \/\/ The resource is deleted from the resource manager only when it is private\n@@ -531,8 +545,7 @@ void PrivateThreadPoolDatasetOp::MakeDatasetFromOptions(OpKernelContext* ctx,\n                                                         DatasetBase* input,\n                                                         int32_t num_threads,\n                                                         DatasetBase** output) {\n-  OP_REQUIRES(ctx, num_threads >= 0,\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\n   *output = new Dataset(ctx,\n                         DatasetContext(DatasetContext::Params(\n                             {PrivateThreadPoolDatasetOp::kDatasetType,\n@@ -546,8 +559,7 @@ void PrivateThreadPoolDatasetOp::MakeDataset(OpKernelContext* ctx,\n   int64_t num_threads = 0;\n   OP_REQUIRES_OK(\n       ctx, ParseScalarArgument<int64_t>(ctx, \"num_threads\", &num_threads));\n-  OP_REQUIRES(ctx, num_threads >= 0,\n-              errors::InvalidArgument(\"`num_threads` must be >= 0\"));\n+  OP_REQUIRES_OK(ctx, ValidateNumThreads(num_threads));\n   *output = new Dataset(ctx, input, num_threads);\n }"
    }
  ]
}